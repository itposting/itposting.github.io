<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/47" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/47" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="홈 어시스턴트에 MQTT 서버를 설치하고 추가하는 방법" href="/post/2024-06-20-InstallandaddingMQTTservertotheHomeAssistant"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="홈 어시스턴트에 MQTT 서버를 설치하고 추가하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-InstallandaddingMQTTservertotheHomeAssistant_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="홈 어시스턴트에 MQTT 서버를 설치하고 추가하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">홈 어시스턴트에 MQTT 서버를 설치하고 추가하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="70달러 AI 키트로 나만의 GPT와 비슷한 어시스턴트를 만들어보세요" href="/post/2024-06-20-BuildYourOwnGPT-likeAssistantwiththis70AIKit"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="70달러 AI 키트로 나만의 GPT와 비슷한 어시스턴트를 만들어보세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-BuildYourOwnGPT-likeAssistantwiththis70AIKit_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="70달러 AI 키트로 나만의 GPT와 비슷한 어시스턴트를 만들어보세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">70달러 AI 키트로 나만의 GPT와 비슷한 어시스턴트를 만들어보세요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이 파일 및 미디어 서버 구축하기 홈 콘텐츠 공유를 위한 DIY 가이드" href="/post/2024-06-20-BuildingaRaspberryPiFileandMediaServerADIYGuideforSeamlessHomeContentSharing"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이 파일 및 미디어 서버 구축하기 홈 콘텐츠 공유를 위한 DIY 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-BuildingaRaspberryPiFileandMediaServerADIYGuideforSeamlessHomeContentSharing_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이 파일 및 미디어 서버 구축하기 홈 콘텐츠 공유를 위한 DIY 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">라즈베리 파이 파일 및 미디어 서버 구축하기 홈 콘텐츠 공유를 위한 DIY 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이에서 도커 스웜 도커 인 도커DinD로 스웜 시뮬레이션하기" href="/post/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이에서 도커 스웜 도커 인 도커DinD로 스웜 시뮬레이션하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이에서 도커 스웜 도커 인 도커DinD로 스웜 시뮬레이션하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">라즈베리 파이에서 도커 스웜 도커 인 도커DinD로 스웜 시뮬레이션하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이로 홈 네트워크를 안전하게 보호하세요, 와줄 보안 솔루션 2023 에디션" href="/post/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이로 홈 네트워크를 안전하게 보호하세요, 와줄 보안 솔루션 2023 에디션" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이로 홈 네트워크를 안전하게 보호하세요, 와줄 보안 솔루션 2023 에디션" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">라즈베리 파이로 홈 네트워크를 안전하게 보호하세요, 와줄 보안 솔루션 2023 에디션</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이 AI 키트를 사용한 비구조화 데이터 처리 - Hailo Edge AI" href="/post/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이 AI 키트를 사용한 비구조화 데이터 처리 - Hailo Edge AI" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이 AI 키트를 사용한 비구조화 데이터 처리 - Hailo Edge AI" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">라즈베리 파이 AI 키트를 사용한 비구조화 데이터 처리 - Hailo Edge AI</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="최고의 직접 만든 생일 스프" href="/post/2024-06-20-TheBestHomemadeBirthdaySoup"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="최고의 직접 만든 생일 스프" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="최고의 직접 만든 생일 스프" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">최고의 직접 만든 생일 스프</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="간자시 꽃 머리 스크런치 만들기 안내" href="/post/2024-06-20-KanzashiFlowerHairScrunchieTutorial"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="간자시 꽃 머리 스크런치 만들기 안내" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="간자시 꽃 머리 스크런치 만들기 안내" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">간자시 꽃 머리 스크런치 만들기 안내</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리 파이를 위한 자체 Linux 이미지 만들기" href="/post/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리 파이를 위한 자체 Linux 이미지 만들기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리 파이를 위한 자체 Linux 이미지 만들기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">라즈베리 파이를 위한 자체 Linux 이미지 만들기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="주말 AI 프로젝트 라즈베리 파이에서 음성 인식, PTT 및 대규모 액션 모델 사용하기" href="/post/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="주말 AI 프로젝트 라즈베리 파이에서 음성 인식, PTT 및 대규모 액션 모델 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="주말 AI 프로젝트 라즈베리 파이에서 음성 인식, PTT 및 대규모 액션 모델 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">주말 AI 프로젝트 라즈베리 파이에서 음성 인식, PTT 및 대규모 액션 모델 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link posts_-active__YVJEi" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"홈 어시스턴트에 MQTT 서버를 설치하고 추가하는 방법","description":"","date":"2024-06-20 17:36","slug":"2024-06-20-InstallandaddingMQTTservertotheHomeAssistant","content":"\n\n만약 홈 어시스턴트 인스턴스가 있으면 Mosquitto가 유용할 수 있습니다. Mosquitto를 사용하면 이 프로토콜을 지원하는 여러 IoT 장치를 연결할 수 있습니다. 예를 들어, OSS 펌웨어를 실행할 수 있는 Tasmota, ESPHome, OpenBeken 등이 있습니다.\n\n나는 라즈베리 파이에서 홈 어시스턴트를 사용하고 있어서 이를 몇 단계만 거쳐 쉽게 설정하는 방법을 보여줄게요. 만약 아직 홈 어시스턴트를 설치하지 않았다면, 이 문서를 확인하세요.\n\n## MQTT 서버 설치\n\n이 과정은 간단하며, 터미널에 간단한 명령어 한 줄로 설치할 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo apt-get install mosquitto mosquitto-clients \n```\n\n이게 전부에요 🐧.\n\n이제 Mosquitto 브로커에 대한 액세스를 보호하는 것이 중요합니다.\n\n## MQTT 시작 및 부팅 시 추가\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금 MQTT를 시작할 수 있고, 장치 부팅 후 내장 서비스를 사용할 수 있습니다:\n\n```js\nsudo systemctl enable mosquitto\nsudo systemctl start mosquitto\n```\n\n## 사용자 및 비밀번호 생성\n\nmosquitto_passwd를 사용하여 새로운 사용자 이름과 비밀번호를 만들 수 있습니다. YOUR_MQTT_USER를 사용하려는 사용자로 대체해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo mosquitto_passwd -c /etc/mosquitto/passw YOUR_MQTT_USER\n```\n\n암호를 설정하고 기억하세요.\n\n이제 익명 사용자를 비활성화해야 합니다:\n\n```js\necho -e \"allow_anonymous false\\npassword_file /etc/mosquitto/passw\" | sudo tee -a sudo nano /etc/mosquitto/mosquitto.conf\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 Mosquitto 브로커를 다시 시작해주세요:\n\n```js\nsudo systemctl restart mosquitto\n```\n\n좋아요, 이제 Home Assistant를 구성해보겠습니다!\n\n## Home Assistant MQTT 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내장된 HASS 통합을 사용하여 MQTT 브로커에 쉽게 연결할 수 있어요. \"설정\" - \"장치 및 서비스\" - \"+ 통합 추가\"로 이동하신 후 MQTT를 목록에서 찾아보세요. MQTT 브로커 세부 정보를 사용하여 연결하세요.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*KCF19chIplt1xq_1AQr2bw.gif)\n\n이제 Mosquitto 호환 장치를 홈 어시스턴트에서 사용할 수 있어요 👌.\n\n## localhost 외부에서 듣기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 라즈베리 파이 밖에서 MQTT를 사용하여 LAN 또는 인터넷에서 IoT 장치를 설정하려는 경우, Mosquitto 브로커가 아웃바운드 연결 요청을 수신하도록 설정해야 합니다:\n\n```sh\necho -e \"listener 1883\" | sudo tee -a sudo nano /etc/mosquitto/mosquitto.conf\n```\n\n## Tasmota 예시\n\nTasmota를 실행 중인 장치가 있다면 Home Assistant에서 MQTT를 사용하여 해당 장치를 제어할 수 있습니다. Tasmota에서 MQTT를 설정하려면 \"Configuration\" - \"Configure MQTT\"로 이동한 후 MQTT 브로커 데이터를 추가하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라즈베리 파이의 로컬 네트워크 IP로 YOUR_MQTT_DEVICE_IP를 대체하고, 위에서 사용한 YOUR_MQTT_USER 및 YOUR_PASSWORD로 대체하십시오.\n\n이후에는 Tasmota 엔티티가 홈 어시스턴트 내에서 자동으로 나타날 것입니다.\n\n만약 나타나지 않는다면 \"통합 추가\"를 눌러 추가하십시오. MQTT 연결이 제대로 작동하는지 확인하려면 Tasmota \"콘솔\"을 확인하십시오.\n\n이제 Tasmota 엔티티 ID를 알고 있다면 대시보드에 버튼을 추가할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 수동 통합\n\n다른 IoT 장치는 수동 구성이 필요할 수 있으며 MQTT 통합 내에 나타날 수도 있습니다. 또는 MQTT 서비스를 사용하여 스크립트 및 자동화 내에서 데이터를 송수신할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-InstallandaddingMQTTservertotheHomeAssistant_0.png)\n\n스크립트에서 사용할 수 있는 발행 및 수신 MQTT 서비스가 모두 있어서 HASS 인터페이스에 버튼을 추가할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## MQTT 클라이언트로 테스트해보기\n\nWindows/Linux 또는 다른 기계에서 Mosquitto 브로커를 테스트하기 위해 MQTTX를 사용할 수 있습니다. [여기](링크)에서 다운로드할 수 있어요.\n\n장치 데이터를 사용해보세요. Raspberry Pi IP인 192.168.0.190을(를) 교체해주세요.\n\n## 대박!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 디바이스와 홈 어시스턴트에서 MQTT를 구성하는 방법을 알게 되셨군요.\n\n⚠️ 인터넷을 통해 이 MQTT 서버를 직접 노출하려는 경우, TLS / SSL로 보호되지 않았으므로 악의적인 사용자가 로그인 자격 증명을 읽을 수 있습니다. 일반적인 것과 다른 사용자 이름 및 비밀번호를 사용하면 상대적으로 안전합니다. 그러나 그래도 악의적인 사용자가 당신의 디바이스를 제어하고, 네트워크 전체에 액세스할 수 있는 악성 코드를 주입할 수도 있습니다. 언제나 IoT 장치를 최신으로 유지하세요!\n\nMQTT에 TLS / SSL을 빠르게 추가할 수 있지만 모든 IoT 장치와 호환되지 않을 수 있으므로 보다 안전하게 로컬에 유지하고 MQTT 포트를 인터넷에 노출하지 마세요.\n\n이것은 홈 어시스턴트를 통해 MQTT 장치를 인터넷을 통해 제어할 수 없다는 뜻인가요? 아니요! 당신의 HASS 인스턴스는 Mosquitto 브로커와 별도입니다. 브로커는 로컬 네트워크에서만 IoT 장치를 처리하고 홈 어시스턴트와 인터페이스할 것이며, 암호화된 연결을 통해 인터넷에 노출될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 목록에서 더 많은 관련 기사를 찾을 수 있어요:","ogImage":{"url":"/assets/img/2024-06-20-InstallandaddingMQTTservertotheHomeAssistant_0.png"},"coverImage":"/assets/img/2024-06-20-InstallandaddingMQTTservertotheHomeAssistant_0.png","tag":["Tech"],"readingTime":4},{"title":"70달러 AI 키트로 나만의 GPT와 비슷한 어시스턴트를 만들어보세요","description":"","date":"2024-06-20 17:35","slug":"2024-06-20-BuildYourOwnGPT-likeAssistantwiththis70AIKit","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-BuildYourOwnGPT-likeAssistantwiththis70AIKit_0.png\" /\u003e\n\n만약 예산 제약으로 인해 인공 지능 세계에 뛰어들고 싶었지만 그렇지 못했다면, 새로운 Raspberry Pi AI 키트가 혁신으로 통하는 게이트웨이가 될 수 있습니다. 매력적인 가격인 70달러에 예약 주문 가능한 이 키트는 다재다능한 Raspberry Pi 5에서 인공 지능을 탐험하는 새로운 기회를 제공합니다. 이 키트는 강력한 Raspberry Pi의 기능과 결합하여 AI 실험과 학습의 민주화를 실현하고 있습니다.\n\n# 키트 뒤에 있는 파워하우스: Hailo\n\n\u003cimg src=\"/assets/img/2024-06-20-BuildYourOwnGPT-likeAssistantwiththis70AIKit_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRaspberry Pi AI Kit은 고성능 AI 프로세서로 유명한 선도적인 AI 하드웨어 업체인 Hailo와의 협업 제품입니다. Hailo의 칩은 신경망 연산을 최적화하여 우수한 처리 성능을 제공하면서도 에너지 효율성을 유지합니다. Hailo의 고급 AI 기술을 통합함으로써, Raspberry Pi AI Kit은 사용자가 Raspberry Pi 5에서 복잡한 AI 모델을 원활하게 실행할 수 있도록 보장합니다.\n\nHailo의 미션은 엣지 장치가 효율적이고 효과적으로 딥러닝 작업을 수행할 수 있도록 하는 것입니다. Raspberry Pi와의 파트너십은 AI를 일상 응용 프로그램에서 보다 접근 가능하고 실용적으로 만들기 위한 중요한 한걸음을 의미합니다. Hailo의 AI 역량과 Raspberry Pi의 가격 대비 성능 및 유연성이 결합되면 혁신적인 프로젝트에 대한 다양한 가능성이 열립니다.\n\n# Raspberry Pi AI Kit으로 만들 수 있는 GenAI 프로젝트\n\nRaspberry Pi AI Kit을 손에 넣으면 General AI (GenAI) 프로젝트의 세계가 펼쳐집니다. 아래는 시작할 수 있는 몇 가지 흥미로운 프로젝트입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 스마트 홈 자동화: 인공지능을 활용하여 스마트 홈 설정을 강화하세요. 얼굴을 인식하고 감정을 감지하며 목소리 명령에 반응할 수 있는 시스템을 만들어, 집을 더 직관적이고 안전하게 만드세요.\n- 인공지능 보안 카메라: 이상 활동을 감지하고 경고하는 보안 카메라를 구축하세요. 실시간 물체 감지와 인식을 통해 소유물을 더 정확하게 감시할 수 있습니다.\n- 개인 비서: 자연어를 이해하고 일정을 관리하며 알림을 설정하고 집의 다른 스마트 기기를 제어할 수 있는 AI 개인 비서를 개발하세요.\n- 건강 모니터링 시스템: AI를 활용하여 생체 신호를 추적하고 이상을 감지하며 실시간 건강 정보를 제공하는 건강 모니터링 시스템을 설계하세요. 이는 노인 요양이나 개인 피트니스 모니터링에 특히 유용할 수 있습니다.\n- 교육용 도구: AI를 활용한 맞춤형 학습 경험을 제공하는 상호 작용 교육 도구를 만드세요. 언어 학습 앱, 수학 가르침, 또는 학습자의 속도와 스타일에 맞춰 적응하는 가상 과학 실험실 등이 포함될 수 있습니다.\n- 자율 주행 차량: AI 모델을 기반으로 내비게이션하고 결정을 내릴 수 있는 소형 자율 주행 차량을 실험해보세요. 이 프로젝트는 단순한 선 따라가기 로봇부터 좀 더 복잡한 장애물 회피 및 경로 계획 기기까지 다양할 수 있습니다.\n- AI 아트와 음악: AI의 창의적인 면에 뛰어든 개발 알고리즘을 만드세요. 자동화된 작품 생성이나 음악 작곡이 가능합니다. 기술과 창의성의 교차로를 탐색하면 독특하고 영감을 주는 결과물이 나올 것입니다.\n- 음성 인식 시스템: 여러 언어로 명령을 이해하고 대답하는 음성 인식 시스템을 구축하세요. 대화식 키오스크부터 무선 조절까지 다양한 응용 분야에서 활용할 수 있습니다.\n\n# 라즈베리 파이 AI 키트를 선택하는 이유?\n\n라즈베리 파이 AI 키트는 AI 애호가를 위한 비용 효율적이고 강력한 솔루션을 제공합니다. 70달러에 Hailo의 최첨단 AI 기술을 이용할 수 있으며, Raspberry Pi 5의 다재다능함과 결합하여 다양한 AI 응용 프로그램을 구축할 수 있습니다. AI에 대해 배우려는 초보자든 혁신적인 솔루션을 원하는 경험있는 개발자든, 이 키트는 훌륭한 자원입니다.\n\n또한 라즈베리 파이 제품에 대한 커뮤니티 지원과 상세한 문서가 제공되어 프로젝트에 대해 충분한 지속적인 지원과 영감을 받을 수 있습니다. 이 AI 키트는 도구뿐만 아니라 AI로 가능한 가능성을 넓히는 메이커와 혁신가들의 글로벌 커뮤니티에 초대하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약하자면, Hailo의 고급 AI 기술을 통해 구동되는 라즈베리 파이 AI 키트는 가격이 저렴하고 접근성이 좋은 AI 실험을 위한 게임 체인저입니다. 이 제품 출시로 AI 개발에 대한 진입 장벽이 크게 낮아져 더 많은 사람들이 이 흥미로운 분야에 참여하고 기여할 수 있게 되었습니다. 지금 당장 키트를 예약하고 라즈베리 파이 5에서 AI의 끝없는 가능성을 탐험해 보세요.\n\n제게 대리기를 할 수 없는 분들을 위해 Hailo-8L Accelerator 모듈을 기다리지 못하시는 경우 Coral M.2 Accelerator with Dual Edge TPU를 시도해 보세요. 4TFlops의 성능을 자랑하며 Hailo-8L이 약속한 13 TFlops는 아니지만 여러 사용 사례에 대해 충분히 대응할 것입니다.\n\nCoral M.2 Accelerator with Dual Edge TPU는 M.2 E-key 슬롯이있는 기기의 AI 능력을 향상시키기 위해 설계된 강력한 AI 처리 모듈입니다. 두 개의 엣지 텐서 처리 유닛(TPU)을 갖춘 이 가속기는 머신 러닝 모델을 빠르고 효율적으로 실행할 수 있습니다. TensorFlow Lite를 지원하여 최소한의 지연 시간과 전력 소비로 엣지에서 복잡한 신경망을 실행하는 데 이상적입니다.\n\n# Coral M.2 Accelerator Dual Edge TPU로 할 수 있는 일:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 실시간 객체 감지: 보안 카메라, 로봇 및 스마트 홈 기기에 대한 고속 객체 감지 및 인식 구현\n- 이미지 분류: 제조업에서의 자동화된 품질 검사 또는 의료 분석 등 이미지 처리 응용 프로그램 강화\n- 자연어 처리: 음성 인식 시스템, 챗봇 및 번역 서비스의 성능 향상\n- 엣지 AI 응용: 엣지 장치에 직접 AI 모델을 개발 및 배포하여 클라우드 서비스의 의존성을 줄이고 더 빠르고 오프라인 데이터 처리 보장\n- 스마트 기기: 얼굴 인식, 동작 감지 및 예측 유지보수와 같은 복잡한 작업을 수행할 수 있도록 스마트 홈 기기 업그레이드\n\nCoral M.2 Accelerator with Dual Edge TPU는 프로젝트의 AI 성능을 최소한의 통합 노력으로 향상시키고자 하는 개발자와 엔지니어에게 최적입니다.","ogImage":{"url":"/assets/img/2024-06-20-BuildYourOwnGPT-likeAssistantwiththis70AIKit_0.png"},"coverImage":"/assets/img/2024-06-20-BuildYourOwnGPT-likeAssistantwiththis70AIKit_0.png","tag":["Tech"],"readingTime":4},{"title":"라즈베리 파이 파일 및 미디어 서버 구축하기 홈 콘텐츠 공유를 위한 DIY 가이드","description":"","date":"2024-06-20 17:33","slug":"2024-06-20-BuildingaRaspberryPiFileandMediaServerADIYGuideforSeamlessHomeContentSharing","content":"\n\n집 컴퓨터에 흩뿌려진 동영상과 사진들의 바다 속에서, 가족 간 콘텐츠 공유와 접근이 조금 꼬였죠. Windows, Linux, macOS, Android, 심지어 우리 TV와 호환되는 파일 및 미디어 서버 역할을 할 수 있는 중앙 허브가 필요했습니다.\n\n처음에는 상용 NAS 솔루션을 눈여겨 봤지만, 가격이 부담스러워 금방 포기했어요. 그래서 Raspberry Pi 4와 오래된 외장 하드 드라이브를 활용해 나만의 파일 및 미디어 서버를 만들기로 결심했습니다.\n\n가장 어려웠던 부분은 외장 하드 드라이브를 Windows, Raspberry Pi 그리고 때로는 macOS에 매끄럽게 연결할 수 있는 것이었죠. 제가 선택한 exFAT 파일 시스템으로 하드 드라이브를 포맷하고 하나의 깔끔한 파티션을 이용할 준비를 마쳤습니다.\n\n이후, OpenMediaVault를 우연히 발견했는데 처음에는 유망해 보였습니다. 알고 보니 exFAT과 잘 어우러지지 않았어요. 시간이 지날수록 오류를 다루고, 포맷을 하고, RaspberryOS를 다시 설치하는 등의 번거로움에 좌절했죠. 연결 문제의 연속 끝에, OpenMediaVault를 포기하고 파일 공유에는 SMB를, 미디어는 MiniDLNA를 활용해 직접 설정하기로 결심했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리눅스 터미널에 익숙해지긴 했지만, 좀 더 사용자 친화적인 것을 찾고 있었어요. 그래서 Cockpit 프로젝트를 발견하게 되었죠. \"파일 공유\"로 Samba와 NFS를 관리하는 편리한 애드온과, 세련된 파일 관리자인 \"Navigator\", 그리고 웹 기반 터미널 에뮬레이터까지 함께 사용하니 정말 편리했어요. 이제 Cockpit과 MiniDLNA로 만든 솔루션이 원활하게 작동하며, 라즈베리 파이가 가족들을 위한 콘텐츠 허브로 변모했어요.\n\n결국, exFAT을 사용해 불복종적인 라즈베리 파이 4가 가족들이 파일과 미디어를 찾는 곳이 되었고, Cockpit을 통해 깔끔하게 관리되는 모습이었어요. 하나의 개인 서버 이야기 — 만들고, 다듬고, 받아들이는 과정이에요.\n\n처음에는 최신 라즈베리 파이 OS인 Bookworm 데스크톱 버전을 획득하려 했어요. 그러나 소프트웨어 호환성 문제에 직면하여, \"Bullseye\" 릴리스 서버 이미지가 요구사항을 충족하는 더 실용적인 선택이라는 결론에 도달했어요.\n\n내 솔루션은 다음과 같은 하드웨어와 소프트웨어를 사용해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Raspberry Pi 4 Model B Rev 1.4, 쿼드 코어 CPU, 8GB RAM\n- 라즈베리 파이 OS Lite Legacy (Bullseye, Server)가 설치된 32GB SD 카드\n- 라즈베리 파이 전용 전원 어댑터\n- exFAT 파일 시스템이 적용된 외장 USB 하드 디스크\n- 라즈베리 파이 USB 포트에 직접 연결 시 전원이 부족하여 작동하지 않아서 필요한 파워드 USB 3.0 허브\n- 라즈베리 파이에 SSH로 연결하기 위한 PuTTY 소프트웨어\n\n라즈베리 파이 설정 및 exFAT로 하드 디스크를 포맷하는 과정은 수많은 자원에서 자세히 설명되어 있어서 이 기사에서는 해당 부분에 대해 다루지 않습니다.\n\n# 라즈베리 파이 설정 시작\n\n![라즈베리 파이 설정](/assets/img/2024-06-20-BuildingaRaspberryPiFileandMediaServerADIYGuideforSeamlessHomeContentSharing_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 연결이 안전하게 완료되었는지 확인하고 라즈베리 파이를 켭니다. 최적의 안정성을 위해 WiFi보다는 유선 LAN 연결을 선택하는 것이 좋습니다. 왜냐하면 WiFi 연결은 추가적인 문제 해결 단계를 요구하는 구성에서 도전이 될 수 있습니다. 라즈베리 파이가 가동된 후에는 SSH 연결을 설정하기 위해 해당 IP 주소를 찾아야 합니다. 집 라우터에 액세스할 수 있다면, 라우터의 DHCP 클라이언트 목록에서 손쉽게 라즈베리 파이의 IP 주소를 찾을 수 있습니다.\n\n또는 모니터와 키보드를 라즈베리 파이에 직접 연결하여 SSH를 필요로하지 않게 할 수도 있습니다. 그러나 설정을 실행하는 컴퓨터에서 SSH를 활용하거나 PuTTY와 같은 도구를 사용하면 더욱 간편한 접근 방법이 제공됩니다. 이 방법은 편리할 뿐만 아니라 온라인 소스에서 명령을 복사하고 붙여넣는 프로세스를 간소화하여 설정 경험을 더욱 효율적으로 만들어줍니다.\n\n라즈베리 파이에 SSH를 사용하여 IP 주소 또는 호스트 이름(제 경우에는 \"rpi-home\") 및 SD 카드 준비 시 설정한 사용자 ID(제 경우에는 \"admin\")로 접속합니다. 문서의 나머지 부분은 이 사용자 ID 및 호스트 이름을 전제로 합니다. 사용자 ID 및 호스트 이름에 따라 바꿔주시기 바랍니다.\n\n# 라즈베리 파이 OS 업데이트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 확인해야 할 사항으로 운영 체제가 완전히 최신 상태인지 확인하는 것이 중요합니다.\n\n```js\nsudo apt-get update\nsudo apt-get upgrade\n```\n\n# exFAT 지원 추가\n\nexFAT는 Microsoft에서 플래시 메모리용으로 개발한 파일 시스템입니다. 이는 프로프리어터리 파일 시스템으로 Linux의 공식적인 부분이 아닙니다. FUSE를 통해 exFAT 포맷을 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 명령어를 사용하여 FUSE를 설치하세요.\n\n```js\nsudo apt-get install exfat-fuse\nsudo apt-get install exfat-utils\n```\n\n# 외장 하드 디스크 마운트\n\n하드 디스크가 RPi에 전원 USB 허브를 통해 연결되었는지 확인하고 RPi의 USB 3 포트에 연결되었는지 확인하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 단계는 하드 디스크가 감지되었는지 확인하는 것입니다. 다음 명령어는 연결된 모든 디스크를 나열합니다.\n\n```js\nlsblk\n```\n\n저는 USB 하드 디스크 하나만 가지고 있으며 \"sda\"로 나타납니다. 이 디스크에는 하나의 파티션이 있고 \"sda1\"로 나타납니다.\n\n이 디스크를 어떤 폴더에 장착하여 디스크에 액세스할 수 있게 합니다. 폴더를 생성하고 소유권을 현재 사용자 \"admin\"에게 변경해줍시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```bash\nsudo mkdir /media/exthdd\nsudo chown -R admin:admin /media/exthdd\n```\n\n첫째로 파일 시스템을 수동으로 마운트하여 모든 것이 잘 작동하는지 확인하십시오.\n\n```bash\nsudo mount -t exfat /dev/sda1 /media/exthdd\n```\n\n모든 것이 잘 되면 다음 명령어를 사용하여 디스크의 내용을 볼 수 있어야 합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nls /media/exthdd\n```\n\n라즈베리 파이 부팅 시 이 디스크를 자동으로 마운트하도록 구성할 것입니다. 먼저 디스크를 언마운트하세요.\n\n```js\nsudo umount /media/exthdd\n```\n\n구성에 필요한 UUID를 알아내야 합니다. 아래 명령어를 실행해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo blkid\n```\n\n이 명령어를 실행하면 다음과 같은 출력이 표시됩니다.\n\n```js\n/dev/sda1: LABEL=\"Data\" UUID=\"0AC8-A364\" BLOCK_SIZE=\"512\" TYPE=\"exfat\" PARTLABEL=\"Basic data partition\" PARTUUID=\"6ad9b0ee-2ecc-4b70–99b5-dce69e214493\"\n```\n\n다음 단계를 위해 UUID인 “0AC8-A364”가 필요합니다. /etc/fstab 파일을 수정하고 마운트를 구성하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo vi /etc/fstab\n```\n\n이 파일의 끝에 다음 줄을 추가하고 저장하세요. 디스크 UUID를 사용해야 합니다.\n\n```js\nUUID=0AC8-A364 /media/exthdd exfat rw,user,dmask=0000,fmask=0000,nosuid,nodev,nofail 0 0\n```\n\n이번에는 fstab을 사용하여 다시 마운트해 보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo mount -a\n```\n\n다시 한 번 디스크에 접근할 수 있는지 확인해 봅시다. 또한 테스트 파일을 생성하고 삭제하여 디스크에 쓰기 작업이 가능한지도 확인해 봅시다.\n\n```js\nls /media/exthdd\ntouch /media/exthdd/test.txt\nrm -f /media/exthdd/test.txt\n```\n\n모든 작업이 잘 되었다면, 재부팅 후에도 디스크가 마운트되어 접근 가능한 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Samba 설정\n\n이제 네트워크를 통해 폴더를 공유할 수 있는 Samba 서버를 설정해보겠습니다. 이 설정을 통해 이 서버의 폴더를 읽기/쓰기 권한으로 공유할 수 있게 될 거에요.\n\n다음 명령어를 실행하여 Samba를 설치해보세요.\n\n```js\nsudo apt-get install samba samba-common-bin\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 모든 사람들과 함께 전체 폴더 /media/exthdd를 공유할 수 있지만, 공유를 원하지 않는 다른 데이터를 저장할 수 있도록 별도의 공유 폴더를 유지하는 것이 좋습니다. \"media-library\"라는 이름의 공유 폴더를 만들어봅시다.\n\n```bash\nmkdir /media/exthdd/media-library\n```\n\n이 공유 폴더에 특정 사용자들에게 액세스 권한을 부여해야 합니다. 이 사용자들은 리눅스 사용자여야 합니다. 가족 구성원마다 쓰기 액세스 권한이 있는 사용자를 만들고, 읽기 전용 액세스 권한만 있는 \"guest\" 사용자를 만들 수 있습니다. 우선, 가족 구성원 모두가 사용할 수 있는 쓰기 액세스 권한이 있는 \"family\"라는 공통 사용자를 만들고 이 사용자에게 비밀번호를 설정해봅시다.\n\n```bash\nsudo adduser family\nsudo passwd family\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사용자 \"admin\"과 \"family\"에 Samba 액세스 권한을 부여할 것입니다. 이 명령어들은 Samba 액세스용 별도의 비밀번호를 입력하도록 요청할 것입니다.\n\n```js\nsudo smbpasswd -a admin\nsudo smbpasswd -a family\n```\n\n우리는 Samba 서비스에게 이 폴더를 네트워크 상에서 노출해야 한다고 알려줘야 합니다. Samba 구성을 업데이트해야 합니다. 구성 파일을 편집해봅시다.\n\n```js\nsudo vi /etc/samba/smb.conf\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 현재 파일에 추가할 섹션입니다. 파일을 저장해주세요.\n\n```js\n[media-library]\npath = /media/exthdd/media-library\nvalid users = admin family\nwriteable=Yes\ncreate mask=0777\ndirectory mask=0777\npublic=no\n```\n\n본 폴더는 \"valid users\" 목록의 사용자에게 접근 가능합니다. 곧 \"family\"라는 새 사용자를 추가할 예정입니다. 폴더는 쓰기 가능하며, 모든 로그인한 사용자에게 권한이 부여됩니다(777). 하지만 공개 접속은 \"no\"입니다.\n\n서비스를 재시작해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo systemctl restart smbd\n```\n\n이제 Windows 파일 탐색기에서 \\\\rpi-home\\media-library 폴더에 액세스할 수 있습니다. 이 폴더를 탐색기 또는 명령 프롬프트를 사용하여 다음 명령으로 드라이브에 매핑할 수 있습니다.\n\n```js\nnet use Z: \"\\\\rpi-home\\media-library /user:\u003cusername\u003e \u003cpassword\u003e\n```\n\nmacOS에서는 “smb:\\\\rpi-home\\media-library” URL을 사용하여 Finder에서 서버에 연결할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 미디어 서버 설정하기\n\n미디어 서버를 설정하기 위해 miniDLNA를 사용할 것입니다. 먼저 miniDLNA를 설치하세요.\n\n```js\nsudo apt-get install minidlna\n```\n\n미디어 서버의 이름을 설정하고 폴더를 노출시키기 위해 miniDLNA를 구성해야 합니다. 구성 파일을 편집해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo vi /etc/minidlna.conf\n```\n\n이 파일에서 서버의 friendly name을 찾아 수정하세요. 파일 내에 media_dir로 시작하는 줄을 찾아서 아래와 같이 추가하세요.\n\n```js\nfriendly_name=rpi-mediaserver\n\nmedia_dir=A,/media/exthdd/media-library/music\nmedia_dir=P,/media/exthdd/media-library/photos\nmedia_dir=V,/media/exthdd/media-library/videos\n```\n\n이 예시에서는 데이터를 이러한 방식으로 구조화했기 때문에 음악, 사진 및 비디오를 위한 별도 폴더를 추가했습니다. A, P 및 V는 해당 폴더를 각각 오디오, 이미지 및 비디오로 노출할 것을 미디어 서버에 전달하는 파일 유형입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n서비스를 다시 시작해 주세요.\n\n```js\nsudo systemctl restart minidlna\n```\n\n만약 TV가 DLNA에 연결할 수 있고 동일한 네트워크에 연결되어 있다면 \"rpi-mediaserver\"가 TV에 표시됩니다. Windows Media Player도 이 서버를 볼 수 있고 파일을 재생할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-BuildingaRaspberryPiFileandMediaServerADIYGuideforSeamlessHomeContentSharing_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 단계들로 충분히 시작할 수 있지만, 모든 설정 및 유지 관리는 터미널과 ssh를 통해 진행해야 합니다. 그러나 cockpit을 사용하면 웹 UI를 통해 모든 작업을 관리할 수 있는 도구들이 있습니다.\n\n# Cockpit 설정하기\n\nCockpit은 리눅스 서버를 관리하기 위해 설계된 사용자 친화적인 웹 기반 인터페이스입니다. 시스템 관리자를 위한 중앙 통합형 대시보드를 제공하여 실시간 모니터링, 설정, 문제 해결 기능을 제공합니다. 깔끔하고 직관적인 인터페이스로, Cockpit은 사용자 관리, 소프트웨어 업데이트, 네트워크 구성 등과 같은 작업을 간편하게 처리합니다. 모듈식 디자인으로 다양한 플러그인을 지원하며, Linux 배포판 간 서버 관리를 위한 다양한 기능을 지원하는 다목적 도구로 만들어졌습니다.\n\n우선 cockpit을 설치하고 다음 명령어로 정상 작동하는지 확인해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsudo apt install cockpit\nsystemctl status cockpit.socket\n```\n\n이제 http://rpi-home:9090에서 cockpit에 액세스할 수 있습니다. 셀프 사인된 인증서 때문에 나타나는 보안 경고를 무시해주세요. 로그인할 때는 Linux 사용자로 cockpit에 로그인해야 합니다. \"admin\"으로 로그인해보세요.\n\n추가 보너스로, 다양한 서비스를 관리할 수 있는 많은 cockpit 응용 프로그램 (애드인)이 있습니다. 실제로 cockpit (파일 공유 애드인)에서 Samba(및 NFS)를 관리하고 파일 시스템 (Navigator 애드인)도 관리할 수 있습니다. 이러한 애드인들은 라즈베리파이 OS 저장소에서 직접적으로 사용할 수 없습니다. 먼저 저장소를 설정하고 그 후 설치해야 합니다. 다음 명령어로 이 모든 것을 할 수 있습니다.\n\n```js\ncurl -sSL https://repo.45drives.com/setup -o setup-repo.sh\nsudo bash setup-repo.sh\nsudo apt install cockpit-navigator\nsudo apt install cockpit-file-sharing\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCockpit 콘솔의 파일 공유 메뉴에서 기존의 samba.conf 파일을 가져와서 Samba를 Cockpit에서 관리할 수 있습니다.\n\n이제 Cockpit 콘솔에서 웹 기반 SSH 터미널을 사용할 수 있습니다.\n\n공유와 스트리밍을 즐기세요!","ogImage":{"url":"/assets/img/2024-06-20-BuildingaRaspberryPiFileandMediaServerADIYGuideforSeamlessHomeContentSharing_0.png"},"coverImage":"/assets/img/2024-06-20-BuildingaRaspberryPiFileandMediaServerADIYGuideforSeamlessHomeContentSharing_0.png","tag":["Tech"],"readingTime":9},{"title":"라즈베리 파이에서 도커 스웜 도커 인 도커DinD로 스웜 시뮬레이션하기","description":"","date":"2024-06-20 17:31","slug":"2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD","content":"\n\n![이미지](/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_0.png)\n\n이 프로젝트에서는 Raspberry Pi 4B 4Gb Raspberry Pi OS Lite 64비트 및 도커를 사용하여 놀고 있었어요. 가이드가 아닌 과정 보고서이니 먼저 전체 내용을 읽어보시는 걸 추천해요.\n\n## 1) Raspberry Pi OS Lite 64비트에 도커 설치하기\n\n## 2) 매니저 설정하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3) 작업자를 배포하세요.\n\n## 4) Docker Swarm을 Docker-in-Docker (DinD)로 시뮬레이션하는 단계\n\n## 1) Raspberry Pi OS Lite 64비트에 Docker 설치하기\n\n```js\nsudo apt-get update \u0026\u0026 sudo apt-get upgrade -y\nfor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done\n# 도커의 공식 GPG 키 추가:\nsudo apt-get update\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n# Apt 소스에 저장소 추가:\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian $(. /etc/os-release \u0026\u0026 echo \"$VERSION_CODENAME\") stable\" | sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\nsudo docker run hello-world\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 매니저 설정하기\n\n다음 단계에서는 tmux를 사용하는 것이 좋습니다.\n\n![이미지](/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_1.png)\n\n저는 호스트 머신을 위해 하나의 큰 수평 창을 사용했고, 워커들을 위해 두 개의 수직 창을 사용했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 명령어 중 하나를 사용하여 IP를 확인해보세요.\n\n```js\ndocker swarm init --advertise-addr \u003c매니저-IP\u003e\n```\n\n```js\ndocker swarm init --advertise-addr 192.168.99.100\n스웜이 초기화되었습니다: 현재 노드 (dxn1zf6l61qsb1josjja83ngz)가 이제 매니저가 되었습니다.\n```\n\n```js\n이 스웜에 워커를 추가하려면 다음 명령어를 실행하세요:\n    docker swarm join \\\n    --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \\\n    192.168.99.100:2377\n매니저를 추가하려면 'docker swarm join-token manager'를 실행하고 안내를 따르세요.\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_2.png)\n\n## 워커들을 배포하세요.\n\n먼저 워커들을 위한 OS 이미지가 필요합니다:\n\n```js\nsudo docker pull alpine\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 아치를 사용해보려고 했는데 아치64용 빌드가 없었어요.\n\n(참고: 알파인 이미지는 종종 /bin/bash 대신에 /bin/sh를 사용합니다.)\n\n![이미지](/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_3.png)\n\n운영 체제 이미지를 받은 후에 워커들을 배포해야 해요. 여기서 두 가지 상황이 있어요. `sudo docker run alpine`으로 컨테이너를 만드는 경우 랜덤한 이름이 생성되므로, 이름을 얻으려면 `docker ps -a`를 사용하고, 그 후 새 이름으로 변경해야 해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nsudo docker rename helloworld.1.6mwtenk3wdxik9kpposg6hd3j Worker1\nsudo docker start Worker1\nsudo docker exec -it Worker1 /bin/sh\n```\n\n두 번째 시나리오에서는 사용자 정의 이름으로 컨테이너를 직접 설정했습니다:\n\n```js\nsudo docker run -itd --name worker2 alpine /bin/sh\nsudo docker exec -it worker2 /bin/sh\n```\n\n이 방법은 VM이나 클러스터를 사용하는 경우에 적합하지만, 제 경우에는 도커 내부에서 도커를 실행해야 합니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 도커 인 디 도커 (DinD)를 사용하여 도커 스웜 시뮬레이션하기\n\n도커 스웜을 설정하려면 워커 노드는 도커 컨테이너가 아닌 물리적 또는 가상 머신이어야 합니다. 도커 스웜은 각 호스트 머신(물리 서버, VM 또는 클라우드 인스턴스)의 도커 데몬이 통신하여 스웜을 형성하는 방식으로 작동합니다. 컨테이너 자체는 도커 데몬을 실행하지 않으며 직접 스웜에 참여할 수 없습니다.\n\n그러나 도커 스웜 환경을 도커 컨테이너를 사용하여 단일 호스트에서 시뮬레이션하려고 합니다. 따라서 도커 인 디 도커 (DinD)를 사용할 것입니다. 이는 도커 컨테이너 내부에서 도커를 실행하는 것을 의미합니다.\n\n```js\n#호스트 머신\nsudo docker pull docker:19.03-dind\ndocker swarm init --advertise-addr Your_IP #만약 이전에 수행했다면 다시 수행할 필요가 없습니다\n\n#워커 추가 토큰을 잊어버린 경우 다음을 사용하세요:\nsudo docker swarm join-token worker\n\n#워커1 창:\nsudo docker run -d --privileged --name worker1 docker:19.03-dind\nsudo docker exec -it worker1 /bin/sh\ndocker swarm join --token YOUR_TOKEN YOUR_IP_PORT\n\n#워커2 창:\nsudo docker run -d --privileged --name worker2 docker:19.03-dind\nsudo docker exec -it worker2 /bin/sh\ndocker swarm join --token YOUR_TOKEN YOUR_IP_PORT\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_4.png\" /\u003e\n\n이제 중첩된 도커 컨테이너가 작동 중이지만 몇 번의 시도 끝에 각 워커에 작업을 제대로 배포할 수 없었습니다.\n\n이것은 실험으로써 도커 명령어와 스왐 관리 방법을 배우는 흥미로운 방법이지만, 경험을 통해 굴러간 뒤에는, 하나의 라즈베리파이에 도커를 중첩하는 대신 세 개 이상의 라즈베리파이를 사용하는 것을 권장드립니다. 그러나 DinD는 다른 많은 작업에 유용할 수 있으며 하나의 싱글 보드 컴퓨터에서 도커를 사용하여 여러 개의 운영 체제를 실행할 수 있다는 것은 정말 놀라운 일이죠.\n\n# 참고사항:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 Alpine 컨테이너에 neofetch를 설치하는 방법입니다. Alpine의 커뮤니티 저장소를 활성화해야 합니다.\n\n```sh\necho \"http://dl-cdn.alpinelinux.org/alpine/edge/community\" \u003e\u003e /etc/apk/repositories\napk update\napk add neofetch\n```\n\n기존 컨테이너를 중지하고 제거하는 방법은 다음과 같습니다.\n\n```sh\nsudo docker ps -a\nsudo docker stop worker1 worker2\nsudo docker rm worker1 worker2\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가상 머신/머신에 작업자를 배포하는 방법 안내서\n\nhttps://docs.docker.com/engine/swarm/swarm-tutorial/","ogImage":{"url":"/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_0.png"},"coverImage":"/assets/img/2024-06-20-DockerSwarminaRaspberryPiSimulatingaSwarmwithDocker-in-DockerDinD_0.png","tag":["Tech"],"readingTime":5},{"title":"라즈베리 파이로 홈 네트워크를 안전하게 보호하세요, 와줄 보안 솔루션 2023 에디션","description":"","date":"2024-06-20 17:29","slug":"2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_0.png\" /\u003e\n\n환영합니다! 디지털 자산을 보호하는 것이 최우선 과제인 홈 보안 세계로 오신 것을 환영합니다. 오늘날의 연결된 환경에서는 잠재적인 위협을 감지하고 대응할 강력한 방어 시스템을 갖추는 것이 중요합니다.\n\n그래서 저희가 여러분을 안내하고자 합니다. 라즈베리 파이를 사용하여 보안 네트워크를 구축하는 흥미로운 튜토리얼을 통해 Wazuh(놀랍도록 오픈소스 보안 모니터링 플랫폼)의 사용법을 알려드릴 것입니다. 더불어, 최신 알림과 업데이트를 위한 편리한 알림 센터를 만들기 위해 텔레그램의 힘을 활용하는 방법까지 함께 알려드릴 예정입니다.\n\n이 튜토리얼을 완료하면 네트워크 보안을 모니터링하고 실시간 알림을 통해 정보를 파악할 수 있는 신뢰할 수 있고 예산을 절감할 수 있는 솔루션이 준비될 것입니다. 소규모 비즈니스 소유자, 홈 네트워크 애호가 또는 개인 정보와 안심을 중요시하는 분이든 상관없이 모두를 위해 준비되어 있습니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 단계별 가이드는 디지털 방어 체계를 강화하기 위해 필요한 지식과 도구를 제공할 것입니다.\n\n라즈베리 파이를 가져오고 준비해봅시다 — 이제 네트워크를 더 안전하고 똑똑하며, 무척 멋지게 만들 시간입니다.\n\n## 하드웨어 장비\n\n본 튜토리얼을 실행하는 데 주요 캐릭터 없이는 꽤 어려울 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 라즈베리 파이 4 모델 B — 8GB 램\n- 마이크로 SD 카드 — 이상적으로 125G이지만 32G으로 충분\n- 당신이 좋아하는 라즈베리 박스\n\n📝 메모 — Wazuh는 1-25 에이전트 및 90일 감시를 위한 50GB 저장소에 최소 8GB 램이 필요하다고 발표했습니다.\n\n# 소프트웨어 요구 사항\n\n- 라즈베리용으로 Ubuntu Server 22.04.5 LTS (64-bit)를 선택할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지를 설치하려면 Raspberry Pi Imager를 추천합니다. 이 도구를 사용하면 설치 프로세스가 훨씬 쉬워지며 온라인에서 찾아야할 이미지를 찾을 필요가 없습니다. 이미지 목록을 제공합니다.\n\n이 옵션을 선택하면:\n\n- OS 선택 ` 기타 일반 용도 OS ` Ubuntu ` Ubuntu Server 22.04.5 LTS (64비트)\n- 저장소 선택 ` SD 카드 선택\n- Write 버튼 클릭하기 전에 — 오른쪽 하단의 설정을 클릭하여 확인해주세요. 후에 감사할 겁니다:\n\n`\u003cimg src=\"/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_1.png\" /\u003e`\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서는 SSH 액세스 및 라스피에 대한 Wifi 액세스를 미리 설정할 수 있으며, 기본적으로 openssh-server와 같은 것을 수동으로 만들 필요가 없습니다.\n\n🔒 고지 사항 — 보안 전문가 분들을 위해 말씀드리자면, SSH에 대한 비밀번호 인증은 공개 키로 보호된 비밀번호보다 물론 최선의 방법은 아닙니다만, 우리의 초보자들을 위해 간단하게 유지해 보겠습니다.\n\n⭐️ 전문가 팁 — 처음에는 호스트 이름으로 \"wazuh\"를 선택하지 않는 것이 좋습니다. 이는 네트워크에서 누군가가 소중한 자산을 식별하는 데 도움이 될 수 있기 때문입니다.\n\n마지막으로 쓰기 버튼을 눌러주세요, 이제 일이 정말 뜨겁게 될 것입니다 🔥!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 내 파이는 어디에 있나요?\n\n파이에 새 OS를 삽입한 후, 네트워크에 연결되기까지 약간의 시간이 걸릴 수 있습니다.\n\n네트워킹에 대해 아직 초보인 경우, 내 네트워크에서 Raspi를 찾을 수 있는 방법을 궁금해 할 수 있습니다. 음, 간단한 방법을 알려드릴게요:\n\n```js \nnmap 192.168.1.1-254\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당신의 로컬 네트워크에서 호스트 이름 \"wazuh\"을 찾을 수있는 모든 장치를 나열해야합니다.\n\n# Wazuh 설치\n\nRaspberry용 Wazuh 설치에 대해 알아야 할 몇 가지 사항이 있습니다.\n\n우선, Wazuh는 몇 분 안에 완전한 Wazuh 팩을 설치할 수 있도록하는 사용 준비 스크립트를 제공하여 AMD 아키텍처에 대해 기본적으로 적용되는데, Raspberry는 실제로 arm을 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 표 태그를 Markdown 형식으로 바꾸세요.\n\n\nCreate a Markdown table:\n\n| Header 1 | Header 2 |\n|----------|----------|\n| Content 1| Content 2|\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제시되는 다음 단계는 Wazuh 4.4 버전에 유효하며 다음 섹션으로 구분됩니다:\n\n1. 전제 조건 설치하기 - `curl` 또는 `unzip`과 같은 추가 패키지가 필요하며 이는 추후 단계에서 사용됩니다. 그러나 서버에 이미 `curl` 및 `unzip`이 설치되어 있는 경우 이 단계를 건너뛸 수 있습니다.\n\n2. Elasticsearch 설치하기 - Elasticsearch는 높은 확장성을 가진 풀 텍스트 검색 및 분석 엔진입니다.\n\n3. Wazuh Server 설치하기 - Wazuh 서버는 배포된 에이전트로부터 데이터를 수집하고 분석합니다. Wazuh 매니저, Wazuh API 및 Filebeat을 실행합니다. Wazuh를 설정하는 첫 번째 단계는 Wazuh 리포지토리를 서버에 추가한 다음 매니저 자체를 설치하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. Filebeat 설치 - Filebeat는 Wazuh 서버에서 경고 및 보관된 이벤트를 안전하게 Elasticsearch로 전달하는 도구입니다.\n\n5. Kibana 설치 - Kibana는 Elasticsearch에 저장된 이벤트 및 보관된 데이터를 채굴하고 시각화하는 유연하고 직관적인 웹 인터페이스입니다.\n\n공식 문서에서 많은 복사/붙여넣기를 할 필요가 없습니다. 그들은 문서를 이 기사보다 더 최신 상태로 유지할 것입니다. 단계별 안내서를 확인하고 적절한 패키지 관리자 및 시스템 및 서비스 관리자를 선택했는지 확인하세요.\n\n우리 경우에는 Ubuntu Server를 사용하고 있으므로 `apt` 및 `systemctl`을 사용할 것입니다. 💻👌\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 스파이를 배치하세요 — 개인 스파이들을\n\n지금은 첫 번째 와주 서버를 가지고 있습니다. 아래와 비슷한 대시보드가 있습니다:\n\n![대시보드 이미지](/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_3.png)\n\n하지만 이제 첫 번째 에이전트를 설치할 시간입니다 🔍🕵️!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 일반 시민이라면, 집에서는 MacOs 또는 Windows를 실행해야 합니다. (👋 안녕하세요 Linux 사용자 🐧). 다행히도, 모든 운영 체제에 대해 GUI 설치가 가능한 에이전트가 있습니다:\n\n- Windows 에이전트\n- MacOS 에이전트\n\n두 경우 모두 실행 파일을 실행하면 됩니다. 그러면 끝! 사실, 지금은 에이전트가 누구에게 보고해야 하는지 이해하도록 만들어야 합니다. 요점은 Wazuh 서버가 어디에 있는지입니다. 현재 단계에서 당신에겐 매우 쉬운 과제입니다. 이미 Pi의 IP 주소를 알고 있으니까요. 가령 IP 주소가 `192.168.1.43` 라고 해봅시다.\n\n에이전트를 등록하는 방법은 두 가지가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 대리인 구성을 통한 등록\n- 매니저 API를 통한 등록\n\n우리가 정통 자리인으로, 옵션 1을 선택할 거에요:\n\nMacOS \u0026 Linux\n\n1. 루트 사용자로 터미널을 열어서 Wazuh 에이전트 구성 파일인 /Library/Ossec/etc/ossec.conf을 편집하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. ``client``server``address`` 섹션에 Wazuh 매니저 IP 주소를 추가하십시오:\n\n```js\n\u003cclient\u003e\n    \u003cserver\u003e\n      \u003caddress\u003eMANAGER_IP\u003c/address\u003e (여기에는 192.168.1.43을 입력)\n    \u003c/server\u003e\n \u003c/client\u003e\n```\n\nWindows\n\n동일한 로직이지만, 차이점은 에이전트의 위치가 다르다는 것입니다. Wazuh 에이전트 설치 디렉토리는 호스트의 아키텍처에 따라 다릅니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 64비트 시스템용 \\ossec-agent\\Program Files (x86)\\C: 폴더에서 사용합니다.\n- 32비트 시스템용 \\ossec-agent\\Program Files\\C: 폴더에서 사용합니다.\n\n관리자 계정을 사용하여 설치 디렉터리의 ossec.conf라는 Wazuh 에이전트 구성 파일을 수정하세요.\n\nWazuh에 데이터를 가져오도록 몇 분 정도 기다리시고, 여기서 출발! 대시보드가 데이터를받기 시작해야 합니다.\n\n# 텔레그램 — 개인 알림 센터 🌟\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 SIEM을 갖고 있으셨으니, 이제 실시간 알림 시스템을 제공해 드릴 시간입니다. Wazuh는 Slack, Jira 또는 이메일로 통합을 제공하지만 솔직히 말해서, 집에서 보안 이벤트 알림을 받는 가장 편한 방법은 아닙니다.\n\n## 텔레그램 봇 만들기\n\n봇을 만드는 것이 코드 범위와 API 문서 작성에 많은 시간이 걸릴 것이라고 생각할 수 있습니다. 사실, 텔레그램에 메시지를 보내는 것만큼 쉬울 정도로 간단합니다: BotFather에게 연락하면 됩니다.\n\n봇을 관리하는 데 도움이 될 쉬운 명령어를 확인할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Get your Home Network Secured with Raspberry Pi Wazuh 2023 Edition](/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_4.png)\n\nThen create your bot, and fetch your HTTP API Token:\n\n![Get your Home Network Secured with Raspberry Pi Wazuh 2023 Edition](/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_5.png)\n\n## 텔레그램과의 사용자 정의 통합 관리 방법\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 작업을 이해하는 데 중요한 두 군데가 있습니다:\n\n- 로컬 구성: /var/ossec/etc/ossec.conf — 와주(Wazuh)의 구성이 위치한 곳입니다.\n- 통합 위치: /var/ossec/integrations/ — 통합 항목을 찾을 수 있는 곳입니다.\n\n간편하게 하기 위해, 통합 항목을 만들었으면 로컬 구성이 해당 사용자 정의 통합 항목의 존재를 알도록 이를 참조해야 합니다.\n\n## 스크립트 요구 사항\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스크립트가 작동하려면 두 가지 요구 사항이 있어요:\n\n- 파이썬 스크립트에서 텔레그램 API에 호출을 하기 때문에 requests 패키지를 설치해야 해요\n\n```js\npip3 install requests\n```\n\n- 텔레그램 CHATID가 필요해요. id를 찾기 전에 봇에 작은 \"안녕\" 메시지를 보내 채팅을 만들어두세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nhttps://api.telegram.org/bot\u003cYOUR-BOT-TOKEN\u003e/getUpdates\n```\n\n이렇게 하면 이와 유사한 결과가 표시됩니다:\n\n```js\n{\"ok\":true,\"result\":[{\"update_id\":534302469,\"message\":{\"message_id\":2,\"from\":{\"id\":38475931,\"is_bot\":false,\"ﬁrst_name\":\"xxxxxx\",\"last_name\":\"xxxxxx\",\"username\":\"xxxxxx\" ,\"language_code\":\"ua\"},\n```\n\n## 커스텀 통합용 스크립트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 이상 설명하지 않고, /var/ossec/integrations/로 이동하여 다음 명령을 실행해주세요:\n\n```js\nnano custom-telegram\n```\n\n다음 스크립트를 복사하여 붙여넣기 해주세요 (ChatID 변경하는 것을 잊지 마세요):\n\n```js\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport sys\nimport json\n\ntry:\n    import requests\nexcept Exception:\n    print(\"모듈 'requests'를 찾을 수 없습니다. 설치: pip3 install requests\")\n    sys.exit(1)\n\nCHAT_ID = \"xxxxxxxx\"\n\n\ndef create_message(alert_json):\n    # 경고 정보 가져오기\n    title = alert_json['rule']['description'] if 'description' in alert_json['rule'] else ''\n    description = alert_json['full_log'] if 'full_log' in alert_json else ''\n    description.replace(\"\\\\n\", \"\\n\")\n    alert_level = alert_json['rule']['level'] if 'level' in alert_json['rule'] else ''\n    groups = ', '.join(alert_json['rule']['groups']) if 'groups' in alert_json['rule'] else ''\n    rule_id = alert_json['rule']['id'] if 'rule' in alert_json else ''\n    agent_name = alert_json['agent']['name'] if 'name' in alert_json['agent'] else ''\n    agent_id = alert_json['agent']['id'] if 'id' in alert_json['agent'] else ''\n\n    # 마크다운으로 메시지 포맷팅\n    msg_content = f'*{title}*\\n\\n'\n    msg_content += f'_{description}_\\n'\n    msg_content += f'*그룹:* {groups}\\n' if len(groups) \u003e 0 else ''\n    msg_content += f'*룰:* {rule_id} (레벨 {alert_level})\\n'\n    msg_content += f'*에이전트:* {agent_name} ({agent_id})\\n' if len(agent_name) \u003e 0 else ''\n\n    msg_data = {}\n    msg_data['chat_id'] = CHAT_ID\n    msg_data['text'] = msg_content\n    msg_data['parse_mode'] = 'markdown'\n\n    # 디버그 정보\n    with open('/var/ossec/logs/integrations.log', 'a') as f:\n        f.write(f'MSG: {msg_data}\\n')\n\n    return json.dumps(msg_data)\n\n\n# 설정 매개변수 읽기\nalert_file = open(sys.argv[1])\nhook_url = sys.argv[3]\n\n# 경고 파일 읽기\nalert_json = json.loads(alert_file.read())\nalert_file.close()\n\n# 요청 보내기\nmsg_data = create_message(alert_json)\nheaders = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\nresponse = requests.post(hook_url, headers=headers, data=msg_data)\n\n# 디버그 정보\nwith open('/var/ossec/logs/integrations.log', 'a') as f:\n    f.write(f'RESPONSE: {response}\\n')\n\nsys.exit(0)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(더 많은 정보가 필요하시다면 @jesusjimsa 님의 훌륭한 노력으로 스크립트를 제공하고 세부적으로 설명한 다음 기사를 확인해보세요.)\n\n스크립트를 실행 가능하게 만들고 적절한 권한을 부여하세요:\n\n```js\nchmod 750 /var/ossec/integrations/custom-telegram\nchown root:wazuh /var/ossec/integrations/custom-telegram\n```\n\n⚠️ 엄청난 경고 — 통합 이름은 반드시 \"custom-\"으로 시작해야 합니다. 그렇지 않으면 우리 친애하는 Wazuh가 여러분이 무엇을 기대하는지 이해하지 못할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로 해야 할 일은 다음과 같이 /var/ossec/etc/ossec.conf를 업데이트하는 것입니다:\n\n```js\n\u003cintegration\u003e\n  \u003cname\u003ecustom-telegram\u003c/name\u003e\n  \u003chook_url\u003ehttps://api.telegram.org/bot\u003cYOUR-BOT-TOKEN\u003e/sendMessage\u003c/hook_url\u003e\n  \u003calert_format\u003ejson\u003c/alert_format\u003e\n\u003c/integration\u003e\n```\n\nWazuh 관리자를 재시작하려면 systemctl restart wazuh-manager를 실행하십시오.\n\n재시작 후 첫 번째 알림을 볼 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Raspberry Pi Wazuh Edition](/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_6.png)\n\nCongratulations!\n\nFeel free to add me on LinkedIn!\n","ogImage":{"url":"/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_0.png"},"coverImage":"/assets/img/2024-06-20-GetyourHomeNetworkSecuredwithRaspberryPiWazuh2023Edition_0.png","tag":["Tech"],"readingTime":10},{"title":"라즈베리 파이 AI 키트를 사용한 비구조화 데이터 처리 - Hailo Edge AI","description":"","date":"2024-06-20 17:27","slug":"2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI","content":"\n\n비구조화된 데이터 처리, Raspberry Pi 5, Raspberry Pi AI-Kit, Milvus, Zilliz, 데이터, 이미지, 컴퓨터 비전, 딥 러닝, 파이썬\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_0.png)\n\n# 엣지에서 라이브 카메라 스트림에서 이미지를 감지, 표시 및 저장하기\n\nRaspberry Pi 5와 NVIDIA Jetson Orin Nano와 같은 장치의 성능 덕분에 소규모 예산으로도 Edge AI 사용 사례를 구축할 수 있습니다. 최근에 Raspberry Pi AI Kit이 RPI5 플랫폼용으로 출시되었으므로 한 번 사용해보기로 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 키트는 초당 13 테라 오퍼레이션(TOPS)을 처리할 수 있는 신경망 추론 가속기를 추가합니다. 이것은 70달러에 구매할 수 있어서 정말 좋은 거죠. 이 M.2 Hat에 부착된 Hailo-8L M.2 Entry-Level 가속 모듈은 우리에게 AI 기능을 제공할 겁니다.\n\n첫 번째 데모에서는 제가 제공된 RPI5 Hailo AI Python 예제 중 하나를 수정하여 웹캠에서 실시간 이미지 감지를 수행한 다음 검출된 내용을 Slack 채널로 보내고 중요한 메타데이터를 Milvus로 벡터화했습니다.\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_1.png)\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 라즈베리 파이 5에서 진행 중인 라이브 실행\n\n우리는 Hailo의 예제 RPI5 객체 탐지 프로그램을 사용 중입니다. 이 프로그램은 Slack, MiNio 및 Milvus로 보내기 위해 향상시켰습니다.\n\n따라서 예제 객체 탐지 프로그램을 사용 중인데, 먼저 Slack, Milvus, S3, TIMM, Sci-Kit Learn, Pytorch 및 UUID를 위한 내 라이브러리를 임포트하기 위해 일부 임포트를 추가했습니다. 나중에 사용할 몇 가지 상수를 설정했습니다. 그런 다음 Milvus 서버와 Slack 채널에 연결하고 GStreamer 루프를 시작했습니다. 시간을 확인하고 무언가를 감지한 경우 카메라 프레임을 파일에 저장하여 S3에 업로드하고 Slack 채널로 보냈습니다. 마지막으로 S3 경로, 파일 이름, 레이블 및 신뢰도의 중요한 메타데이터와 벡터화된 이미지를 추가했습니다. 각 항목에 대해 자동 생성된 ID를 받았습니다.\n\n우리의 이미지는 MinIO에 업로드되었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image 1](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_3.png)\n\n우리는 또한 텍스트 메시지와 함께 #reports 슬랙 채널로 보냈습니다.\n\n![image 2](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_4.png)\n\n가장 중요한 것은 메타데이터와 벡터를 업로드했고 이미 매우 빠른 검색을 위해 사용 가능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_5.png)\n\nNow, we can begin querying our vectors, and I will demonstrate how to do it using a Jupyter notebook.\n\n## Querying the Database and Displaying Images\n\n![image](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_6.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 이 데모 실행 화면을 녹화했으니, 실시간으로 무슨 일이 일어나는지 확인해 보실 수 있습니다.\n\n![Demo Screenshot](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_7.png)\n\n만약 하나를 구매하셔서 나의 데모를 복제하고 싶으시다면, 이 기사의 끝에 있는 단계들을 확인해 주세요.\n\n# 데모 패킹 목록\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMinIO/S3, Milvus, Slack, Python, Boto3, OpenCV2, Pytorch, Sci-Kit Learn, TIMM, Hailo, YOLOv6n, Object Detection, Raspberry Pi AI Kit, Raspberry Pi 5 with 8GB RAM, logi webcam, resnet34, Torchvision, PyMilvus, Hailo8L M.2 module, M.2 M-Key Hat, Heat Sink.\n\n# 시작하기\n\n하드웨어를 추가한 후 (아래의 비디오 및 링크를 참조하세요), 라이브러리를 설치하고 재부팅하시면 준비가 된 것입니다.\n\n```js\ntspann@five:/opt/demo $ \nhailortcli fw-control identify\n\n장치에서 실행 중: 0000:01:00.0\n보드 식별 중\n제어 프로토콜 버전: 2\n펌웨어 버전: 4.17.0 (릴리스, 앱, 확장 컨텍스트 스위치 버퍼)\n로거 버전: 0\n보드 이름: Hailo-8\n장치 아키텍처: HAILO8L\n일련 번호: HLDDLBB241601635\n파트 번호: HM21LB1C2LAE\n제품 이름: HAILO-8L AI ACC M.2 B+M KEY MODULE EXT TMP\n\ntspann@five:/opt/demo $ \ndmesg | grep -i hailo\n\n[    3.155152] hailo: 모듈 초기화. 드라이버 버전 4.17.0\n[    3.155295] hailo 0000:01:00.0: Probing on: 1e60:2864...\n[    3.155301] hailo 0000:01:00.0: Probing: 장치 확장용 메모리 할당, 11600\n[    3.155321] hailo 0000:01:00.0: 장치 활성화 (0000 -\u003e 0002)\n[    3.155327] hailo 0000:01:00.0: Probing: 장치 활성화됨\n[    3.155350] hailo 0000:01:00.0: Probing: 매핑된 바 0 - 0000000095e362ea 16384\n[    3.155357] hailo 0000:01:00.0: Probing: 매핑된 바 2 - 000000005e2b2b7e 4096\n[    3.155362] hailo 0000:01:00.0: Probing: 매핑된 바 4 - 000000008db50d03 16384\n[    3.155365] hailo 0000:01:00.0: Probing: 최대_desc_page_size를 4096로 강제 설정 (권장값은 16384)\n[    3.155375] hailo 0000:01:00.0: Probing: 64비트 dma 활성화\n[    3.155378] hailo 0000:01:00.0: Probing: 사용자 공간 할당 VDMA 버퍼 사용\n[    3.155382] hailo 0000:01:00.0: ASPM L0s 비활성화\n[    3.155385] hailo 0000:01:00.0: ASPM L0s 성공적으로 비활성화\n[    3.417111] hailo 0000:01:00.0: 펌웨어가 성공적으로 로드되었습니다\n[    3.427885] hailo 0000:01:00.0: Probing: 보드 1e60-2864 추가, /dev/hailo0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_8.png)\n\n# 예제 코드\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_9.png)\n\n# 모델 동물원\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_10.png)\n\n동영상 안내\n\n# 추가 명령어\n\n```js\ngst-inspect-1.0 hailotools\nlspci | grep Hailo\nuname -a\nv4l2-ctl --list-formats-ext -d /dev/video0\nls /dev/video*\nffplay -f v4l2 /dev/video0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 자료\n\n- [Raspberry Pi AI Kit 제품](https://www.raspberrypi.com/products/ai-kit/)\n- [Raspberry Pi AI Kit 관련 문서](https://www.raspberrypi.com/documentation/accessories/ai-kit.html)\n\n보시는 것이 마음에 드셨다면, 어떻게 개선할 수 있는지 댓글로 알려주세요. 또 다음에 어떤 것을 보여드려야 할지도 알려주시면 감사하겠습니다. 프린스턴, 필라델피아, 뉴욕시에서의 밋업이나 유튜브에서 뵙기를 기대합니다.👋\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMilvus로 오세요!\n\n매주 제 뉴스레터를 읽어보세요!\n\n더 많은 멋진 비구조화 데이터, AI 및 Vector Database 비디오를 보려면 Milvus 벡터 데이터베이스 비디오를 여기에서 확인하세요:\n\nhttps://www.linkedin.com/company/zilliz/\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://www.linkedin.com/in/timothyspann/\n\nhttps://milvusio.medium.com","ogImage":{"url":"/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_0.png"},"coverImage":"/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_0.png","tag":["Tech"],"readingTime":6},{"title":"최고의 직접 만든 생일 스프","description":"","date":"2024-06-20 17:25","slug":"2024-06-20-TheBestHomemadeBirthdaySoup","content":"\n\n## 음식과 이야기\n\n![생일날 만들었을 때 가장 좋은 홈메이드 수프](/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_0.png)\n\n오늘은 \"외로움 전염병\"에 대해 읽다가 있습니다. 저는 외로움을 전혀 느끼지 않은 것인지, 아니면 사실 대부분의 시간이 외로움을 느끼는 것인지 확신이 안 드는데요. 외로움은 우리가 혼자 있을 때만이 아니라(저는 혼자 있는 것을 좋아해요), 거부당한 느낌이든, 오해받은 느낌이든, 배제된 느낌이든 발생할 수 있어요. 이런 종류의 외로움은 우리 사랑하는 리틀 베어에게도 거의 닥쳤었지만, 제발, 그곰은 긍정적인 태도를 유지하고 있어요.\n\n리틀 베어를 아시나요? 그는 엘스 홀멜런드 미나릭(Elsie Holmelund Minarik)에 의해 창조되고, 모리스 센댁(Maurice Sendak)에 의해 살아있게 되었어요. 한 이야기에서 리틀 베어는 생일에 홀로 있게 되어요. 그는 어머니를 찾으며 그녀를 부르지만, 어머니는 없어요. 그리고 더 최악인 건, 생일 케이크도 없다는 거죠. 생일에 잊히거나 버려진다는 느낌은 우리 중 몇몇은 울게 할지도 몰라요. 하지만 리틀 베어는 그렇지 않아요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작은 곰이 친구들이 올 것을 희망하며, 무엇이든 손에 있는 재료로 생일 수프를 만들기로 결심합니다.\n\n우리는 아들이 어렸을 때 많은 시간동안 이 이야기(그리고 모든 작은 곰 이야기)를 읽었습니다. 그래서 저녁에 \"당근과 콩, 감자로 어떤 종류의 수프를 만들 계획이라고 말했을 때, 배우자에게 작은 곰 이야기를 떠올리며 \"당근과 콩, 감자로 생일 수프를 만들 수 있어\" 라고 말했습니다. 나는 미소를 지었습니다. 오늘은 우리의 생일 중 아무것도 아니었지만, 난 여전히 생일 수프를 만들 것이었습니다.\n\n내가 그렇게 한 방법은 다음과 같습니다.\n\n# 최고의 생일 수프\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리틀 베어처럼 시작을 했습니다. 손에 있는 재료부터 사용했어요.\n\n- 당근\n- 감자\n- 통조림 콩 (검은 콩, 핑토 콩, 가방조 콩)\n- 신선한 타임\n- 셀러리\n- 채소 육수\n- 채소 증류용 조미료\n- 건조한 허브와 양념\n- 소금\n- 버터\n- 크림\n\n육수가 하나밖에 없어서 채소 증류용 조미료가 필요했어요. 여분이 생기도록 해야 했거든요. 선택할 수 있는 다양한 통조림 콩 중에서 핑토 콩이 이번 수프에 가장 잘 어울릴 것 같아 골랐어요.\n\n일단 수프 냄비(우리는 '대야'라고 부르죠)에 육수를 붓고, 그 다음에 감자, 당근, 셀러리를 다져 넣었어요. 셀러리는 다른 야채보다 더 빨리 부드러워지기 때문에 나중에 조금씩 넣는 게 더 좋았을 텐데, 저는 서두르다 보니 한꺼번에 다 넣었죠. 😉\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로 시간(Thyme)을 통째로 넣고, 싸늘한 세이지로 된 소량의 작은 언더플로우형(SAG), 그리고 탈머릭 작은 언더플로우도 넣었어요. 이 모든 것을 뚜껑을 덮고 끓였죠. 여기에 베이리프도 추가했어야 하는데, 깜빡했네요. 소금도 뿌려야 했어요.\n\n수프는 뚜껑을 덮은 채로 좋은 30분간 끓였고, 그 후로는 수프를 들여다보고 축축한 시간(Thyme)을 체에 걸러내었어요. 이제 콩과 두꺼운 버터 한 조각도 넣을 때가 왔어요. 이들을 추가한 뒤, 뚜껑을 벗고 몇 분 동안 계속 끓였어요.\n\n수프가 준비된 것 같아 보일 때, 불을 끄고 조금 식힌 뒤, 아름다운 크림 줄기를 휘젓었어요. 그리고 결국 소금도 뿌렸죠 (충분하지 않은 것 같아요).\n\n드디어 우리에게는 생일 수프가 준비되었어요. 지금 필요한 것과 정확히 맞는 최고의 생일 수프였어요. 여러분의 최고의 생일 수프에는 다른 재료가 들어갈 수도 있어요. 더 많은 정보를 위해서 냉장고와 식료품 저장실(pantry)을 확인해 보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_1.png\" /\u003e\n\nDIY 프로젝트와 레시피는 자주 혼자서 즐기기 좋지만, 때로는 우리가 연결이 끊어지거나 잊힌 것처럼 느낄 때의 외로움을 해소해 주지 못할 수도 있어요. 그럴 때에는 생일 수프(또는 요리 과정)를 친구와 함께 나누는 것이 필요할지도 모르겠어요. 곰, 오리, 고양이와 함께 생일 수프를 즐겨보세요. 그들은 모두 생일 수프를 좋아해요.\n\n🥣\n\n💛 내 이야기 구독하기","ogImage":{"url":"/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_0.png"},"coverImage":"/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_0.png","tag":["Tech"],"readingTime":3},{"title":"간자시 꽃 머리 스크런치 만들기 안내","description":"","date":"2024-06-20 17:24","slug":"2024-06-20-KanzashiFlowerHairScrunchieTutorial","content":"\n\n🔍 지금 칸자시 꽃 헤어 스크런치 만들기 튜토리얼을 확인해보세요! 이 📁 소잉 패턴을 살펴보고 여기에서 🆓 무료 다운로드 혜택을 받아보세요. 함께 공예를 시작해봐요! 🚀\n\n밝은 색 조화로운 칸자시 스타일의 손톱으로 만든 아름다운 헤어 스크런치. 이 밝은 컬러의 칸자시 스타일 헤어 스크런치는 모든 헤어스타일에 아름다움을 더해주고 멋진 분위기를 조성합니다. 이 튜토리얼에는 사진과 상세한 지침이 포함되어 있어 여러분이 쉽게 직접 만들 수 있는 방법을 알려줄 거에요. 이 사랑스러운 헤어 스크런치(크기 2.7인치 (7cm))는 여러분과 여러분의 아기에게 모두 완벽하며 기쁜 선물이 될 거예요. 당신의 스타일을 돋보이게 하고 휴일을 화려하게 만들어줄 칸자시 꽃이 달린 헤어 스크런치. 이 칸자시 스크런치는 연한 색상으로 제작할 수도 있으며 어떤 의상에도 완벽하게 장식해줄 거예요. 간단한 관리 팁: 칸자시 액세서리의 아름다움을 유지하려면 빨거나 다리지 마세요. 적절한 관리로 많은 해 동안 그들의 빛을 유지할 수 있어요.\n\n![이미지](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_0.png)\n\n![이미지](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Kanzashi Flower Hair Scrunchie Tutorial Part 2](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_2.png)\n\n![Kanzashi Flower Hair Scrunchie Tutorial Part 3](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_3.png)\n\nPhoto by Hobby3DStudio on Creative Fabrica\n\nDisclaimer: This article contains affiliate links, which means we may earn a commission at no additional cost to you if you make a purchase through these links.\n","ogImage":{"url":"/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_0.png"},"coverImage":"/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_0.png","tag":["Tech"],"readingTime":2},{"title":"라즈베리 파이를 위한 자체 Linux 이미지 만들기","description":"","date":"2024-06-20 17:22","slug":"2024-06-20-BuildyourownLinuxImagefortheRaspberryPi","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_0.png\" /\u003e\n\n라즈베리 파이와 유사한 싱글 보드 컴퓨터는 요즘 매우 인기가 많습니다. 그 가능성은 거의 무한합니다. 홈 서버부터 미디어 스테이션, IoT 프로젝트까지 모든 것이 가능합니다. 사용하기 쉽게 만드는 두 가지 요소는 아마도 거대한 커뮤니티와 Raspian과 같은 준비된 SD 카드 이미지일 것입니다. 웹에서 최신 이미지를 다운로드하고 SD 카드에 플래싱하는 것은 시작하는 가장 쉽고 빠른 방법입니다. Raspberry를 사용하거나 자체 프로젝트를 수행하고 싶을 경우에는 문제가 없습니다. 그러나 동일한 시스템을 다른 시스템이나 여러 시스템에 복제하려 한다면 복잡해집니다. 이미지의 크기와 보안을 신경 쓴다면 더 복잡해집니다. 안전한 리눅스 시스템의 솔루션을 제시할 수 있는 능력이 있다면 상상할 수 없습니다. 그러나 자신만의 이미지를 빌드하고 정확히 이미지에 무엇이 포함되어 있는지를 파악하는 것은 좋은 시작점입니다. 마지막으로 리눅스 작동 방식에 대해 좀 더 배우고, 스크래치에서 자신의 리눅스를 빌드했다고 말할 수 있는 것은 흥미로울 것입니다.\n\n이 첫 번째 기사에서는 깊이에 대해 다루지 않겠습니다. 전체 시스템을 이해하고 필요에 맞게 사용자 정의하고자 한다면 알아야 할 것이 훨씬 더 많습니다. 대신, 빠른 성공을 원하고 첫 번째 이미지를 빌드하는 것에 집중하겠습니다. 깊게 이해하고 싶다면 더 많은 기사를 기대해 주세요.\n\n# Yocto Project\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nYocto를 사용하여 자체 Linux 배포판을 빌드할 거에요.\n\n\"Yocto Project, 임베디드 Linux 배포판이 아니에요. 당신을 위해 커스텀한 배포판을 만들어줘요.\" 이 공식 웹사이트의 설명은 Yocto가 무엇인지 가장 잘 표현한 것 같아요. Yocto를 사용하면 자신만의 Linux 이미지를 만드는 데 도움이 되는 유용한 도구와 구성 요소의 모음으로 생각해야 해요. 대안이 있지만, Yocto는 아마도 가장 인기 있는 것 중 하나일 거에요.\n\nYocto Project의 다양한 부분을 자세히 살펴보려면 공식 웹사이트를 확인해보세요.\n\n첫 번째 이미지를 위해 접하게 되는 것은 메타 레이어와 BitBake입니다. 이 두 요소가 시스템의 핵심을 형성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 메타 레이어\n\nYocto는 대부분 레시피와 구성 데이터를 포함하는 여러 가지 레이어 위에 구축됩니다. 레시피는 무엇이 어떻게 빌드되는지 설명하는 데 사용됩니다. 예를 들어, 리눅스 커널의 소스 코드를 다운로드하는 위치와 올바르게 컴파일하기 위해 어떤 명령어 및 도구를 사용해야 하는지가 포함되어 있습니다. 구성 데이터는 예를 들어, Raspberry Pi가 어떤 아키텍처를 사용하는지 설명하므로 레시피가 컴파일해야 하는 대상을 알 수 있습니다. 이것은 과소 평가일 수 있지만, 목표 시스템에 맞는 올바른 메타 레이어가 필요하다는 것을 알면 충분할 것입니다. 이 모든 것 안에 빌드 시스템에서 필요한 모든 것이 제공됩니다.\n\n# BitBake\n\nBitBake는 빌드를 위한 중앙 명령줄 도구입니다. 이것은 원래 OpenEmbedded 프로젝트의 일부였지만, 현재 Yocto 프로젝트와 OpenEmbedded 프로젝트에서 유지보수되는 독립적인 도구입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 빌드 시스템 설정\n\n이제 처음으로 자신만의 이미지를 설정하는 시간입니다. 빌드 환경을 설정하는 단계는 꽤 간단하지만 빌드가 완료될 때까지 시간이 걸립니다. Linux 이미지를 처음부터 빌드하는 것은 단점이 있습니다. 모든 것을 빌드해야 하며 이 과정은 CPU, RAM 및 HDD를 많이 사용합니다. 보통 컴퓨터에서 최대 8시간이 걸릴 수 있습니다. 하지만 걱정하지 마세요. 첫 번째 빌드가 완료되면 Yocto의 좋은 캐싱 알고리즘이 실행되어 새로운 요소와 변경된 요소만 빌드됩니다. 컴퓨터의 최소 무료 디스크 공간은 적어도 50GB여야 합니다. (참고: 저는 16 코어 AWS 클라우드 인스턴스에서 약 1시간 정도에 이 이미지를 빌드했습니다. 빌드 시간은 CPU 성능 및 다운로드 속도에 매우 의존적입니다. 클라우드에서 Yocto 이미지를 빌드하는 주제에 대해 자세한 내용은 후속 기사에서 다룰 수 있습니다.)\n\nYocto 프로젝트의 Mega Manual에서 빌드 시스템 호스트로 최종 테스트된 Linux 배포판 목록을 찾을 수 있습니다. 다른 배포판에서도 작동하지만 예상치 못한 문제가 발생할 수 있습니다. 이 기사의 모든 예제에서 나는 Ubuntu 18.04 LTS를 사용할 것입니다.\n\n첫 번째 단계는 Yocto의 선행 조건을 설치하는 것입니다. 이 명령어는 Ubuntu 또는 Debian에서 모든 패키지를 설치합니다. Mega Manual에서 다른 예제를 찾을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 메타 레이어 가져오기\n\n모든 메타 레이어는 일반적으로 git을 통해 사용할 수 있습니다. 지금은 git이 무엇인지 알지 못해도 걱정하지 마세요. 우리는 지금 하나의 명령어만 사용할 것입니다. git clone 명령은 인터넷에서 저장소를 가져옵니다. 우리가 사용하는 -b dunfell 스위치는 가져올 버전을 지정합니다. 작성 시점에서 던펠(dunfell) 버전은 장기 지원을 받는 최신 버전입니다. 가장 최근 릴리스에 대한 개요는 https://wiki.yoctoproject.org/wiki/Releases를 참조하세요.\n\n어떤 메타 레이어도 가져오기 전에 우리는 yocto라는 프로젝트 폴더와 모든 메타 레이어를 담을 source 폴더를 만들 것입니다.\n\n```bash\nmkdir yocto\ncd yocto\nmkdir sources\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n항상 필요한 메타 레이어는 poky입니다. yocto가 작동하는 데 필요한 모든 기본적인 것들이 포함되어 있어요. 아래의 git 명령어를 실행하여 가져올 수 있어요.\n\n```js\ngit clone git://git.yoctoproject.org/poky -b dunfell\n```\n\n라즈베리 파이를 위한 메타 레이어도 있어요. 라즈베리 파이를 실행하는 데 필요한 모든 정의가 포함되어 있는 멋지게 제작된 메타 레이어에요. 아래 명령어로 가져올 수 있어요.\n\n```js\ngit clone git://git.yoctoproject.org/meta-raspberrypi -b dunfell\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메타 레이어는 항상 어떤 메타 레이어에 의존하는지를 명시합니다. meta-raspberrypi의 readme에는 우리가 이미 가지고 있는 poky와 meta-openembedded이 필요하다고 나와 있습니다. 이 메타 레이어 자체는 여러 레이어로 나뉘어져 있습니다. 이 명령어를 통해 그 모든 레이어를 가져올 수 있습니다.\n\n```js\ngit clone https://git.openembedded.org/meta-openembedded -b dunfell\n```\n\n우리가 필요한 모든 메타 레이어입니다. 이제 프로젝트 폴더로 돌아가서 빌드 환경을 초기화해봅시다.\n\n```js\ncd ..\n. sources/poky/oe-init-build-env\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 이미지를 생성할 준비가 거의 끝났어요. 두 개의 구성 파일을 편집하기만 하면 됩니다.\n\nconf 폴더에 있는 bblayers.conf 파일은 사용할 메타 레이어의 모든 경로가 들어 있어요.\n\n```js\nnano conf/bblayers.conf\n```\n\n마지막으로, conf 폴더에 있는 local.conf 파일은 몇 가지 기본 구성 및 우리에게 가장 중요한 빌드할 기기의 이름이 포함되어 있어요. 만약 라즈베리 파이 4를 위해 빌드하려면 raspberrypi4를 사용하고, 라즈베리 파이 3을 위해 빌드하려면 raspberrypi3를 사용하세요. 이게 Yocto를 사용하는 큰 이점 중 하나에요. 다른 시스템을 위해 동일한 이미지를 빌드하려면 한 줄의 구성만 바꾸면 돼요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnano conf/local.conf\n[...]\nMACHINE ?= \"raspberrypi4\"\n[...]\n```\n\n위 모든 단계를 완료했으므로 이제 실제 빌드를 시작하고 완료될 때까지 기다리면서 커피를 한 잔 이상 마실 시간입니다.\n\n```js\nbitbake core-image-base\n```\n\n축하합니다! 라즈베리 파이를 위한 첫 번째 Linux 이미지를 빌드했습니다. 완성된 이미지는 tmp/deploy/images/repberrypi4/core-image-base-raspberrypi4.wic.bz2 경로에 있습니다. 이 파일은 압축되어 있습니다. 압축을 해제하려면 bzip2 명령 또는 7zip과 같은 도구를 사용하세요. \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nbzip2 -d -f tmp/deploy/images/raspberrypi4/core-image-base-raspberrypi4.wic.bz2\n```\n\n우리는 다른 라스비안 이미지처럼 SD 카드에 플래시만 하면 바로 부팅할 수 있어요. https://www.raspberrypi.org/documentation/installation/installing-images/\n\n![Image](/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_1.png)\n\n기본적으로 사용자 이름은 root이고 비밀번호는 비어 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 다음 단계\n\n이 이정표를 달성하여 자랑스러워하는 것을 기대합니다. Yocto는 강력한 도구이며 더 많은 것을 배울 수 있습니다. 더 많은 정보를 얻고 싶다면 저를 팔로우해 다음 Yocto 관련 글을 놓치지 않도록 하세요.\n\n그동안 당신이 Yocto에 대해 계속 학습하고자 한다면, 스스로 학습을 계속하기 위한 시작점을 제공하겠습니다. 이미지에 추가 소프트웨어가 필요하다면, 먼저 OpenEmbedded Layer Index에서 시작해보세요. 거기서 소프트웨어 레시피가 포함된 메타 레이어를 검색할 수 있습니다. 그 레이어를 다운로드하여 bblayers.conf에 추가하고, 이미 존재하지 않은 경우에만 추가하세요. 그런 다음 레시피 이름을 local.conf 파일의 IMAGE_INSTALL_append에 추가하세요.\n\n```js\nIMAGE_INSTALL_append = \" nano\"\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지를 다시 빌드하고 플래시하세요. 그러면 준비 끝!","ogImage":{"url":"/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_0.png","tag":["Tech"],"readingTime":6},{"title":"주말 AI 프로젝트 라즈베리 파이에서 음성 인식, PTT 및 대규모 액션 모델 사용하기","description":"","date":"2024-06-20 17:19","slug":"2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi","content":"\n\n![2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0](/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0.png)\n\n2024년 초에는 거의 모든 기술 리뷰어가 Rabbit R1에 대해 썼어요. 이 제품은 가격이 $199인 첫 번째 휴대용 \"AI 어시스턴트\" 입니다. 작성자들에 따르면 \"신경 기호 프로그래밍\"과 LAM (\"대규모 액션 모델\")을 사용하여 다양한 작업을 수행합니다. 그런데 어떻게 작동할까요? 자신의 프로토 타입을 만드는 것이 가장 좋은 방법이죠!\n\n이전에 Rabbit R1에 대해 듣지 못한 독자들은 이와 유사한 많은 YouTube 리뷰를 찾을 수 있습니다. 이 글은 Rabbit R1을 어떻게 만들 수 있는가에 대한 흥미로운 분석을 한 Nabil Alouani의 게시물에 영감을 받았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 파이썬 코드에서 비슷한 아이디어를 구현하고, 실제 라즈베리 파이 하드웨어에서 어떻게 작동하는지 그리고 어떤 종류의 문제를 해결해야 하는지 살펴볼 것입니다.\n\n시작하기 전에 한 가지 알림: 저는 Rabbit 팀이나 그 판매와 관련이 없습니다.\n\n## 구성 요소\n\n이 글에서는 여러 구성 요소를 포함한 AI 어시스턴트를 만들 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 마이크와 Push-to-Talk (PTT) 버튼\n- 자동 음성 인식 (ASR), 녹음된 오디오 데이터를 텍스트로 변환할 수 있습니다.\n- 장치에 로컬로 실행되는 작은 언어 모델. 이 모델은 ASR에서 인식한 텍스트에서 작업을 구문 분석할 것입니다.\n- 작업이 로컬 모델에서 알 수 없는 경우 장치가 공용 API를 호출합니다. 여기에서 두 가지 옵션이 제공됩니다: 키를 가진 사람들을 위해 OpenAI API를 사용할 것이고, 무료 솔루션을 원하는 사람들을 위해 LLaMA 모델을 사용할 것입니다.\n- 결과(로컬 모델의 작업 또는 “큰” 모델에서의 텍스트 응답)는 장치 화면에 표시됩니다.\n\n이 기사의 코드는 라즈베리 파이용으로 작성되었지만, 일반 PC에서도 테스트할 수 있습니다. 그럼, 시작해봅시다!\n\n## 하드웨어\n\n이 프로젝트에는 리눅스가 실행되는 싱글 보드 컴퓨터인 라즈베리 파이 4를 사용할 것입니다. 라즈베리 파이에는 다양한 하드웨어를 연결할 수 있도록 여러 개의 GPIO (일반 목적 입출력) 핀이 있습니다. 휴대 가능하며 5V DC 전원만 필요합니다. 또한 128x64 OLED 디스플레이와 버튼을 연결할 것이며, 연결 다이어그램은 다음과 같습니다:\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_1.png)\n\n이 글을 쓰는 시점에 라즈베리파이 모델마다 (RPi 5는 더 빠르지만 더 비싸다) 및 RAM 크기에 따라 약 $80-120 정도의 비용이 듭니다 (최소 4GB RAM이 필요함). 디스플레이, 버튼 및 와이어 세트는 아마존에서 $10-15 정도로 구매할 수 있습니다. 소리 녹음을 위해서는 USB 마이크로폰이면 됩니다. 라즈베리파이 설정은 간단합니다. 이에 대한 충분한 자습서가 있습니다. 언급해야 할 점은 Raspbian의 32비트 및 64비트 버전이 모두 사용 가능하다는 것입니다. 대부분의 현대적인 Python 라이브러리는 더 이상 32비트 버전으로 제공되지 않기 때문에 64비트 버전이 필요합니다.\n\n이제 소프트웨어 부분에 대해 이야기해 봅시다.\n\n## Push-to-Talk (PTT)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라즈베리 파이에서 푸시투톡 모드를 구현하는 것은 비교적 간단합니다. 배선 다이어그램에서 볼 수 있듯이 PTT(푸시투톡) 버튼은 핀 중 하나에 연결되어 있습니다 (우리의 경우 핀 21번). 그 값을 읽으려면 먼저 GPIO 라이브러리를 가져와 핀을 구성해야 합니다:\n\n```js\ntry:\n    import RPi.GPIO as gpio\nexcept (RuntimeError, ImportError):\n    gpio = None\n\nbutton_pin = 21\ngpio.setup(button_pin, gpio.IN, pull_up_down=gpio.PUD_UP)\n```\n\n여기서 저는 핀 21을 “input(입력)”으로 설정하고 pull-up 저항을 활성화했습니다. \"pull-up(풀업)\"이란 버튼이 눌리지 않을 때 입력이 내부 저항을 통해 \"전원\"에 연결되어 있고, 그 값은 \"1\"인 상태를 의미합니다. 버튼이 눌리면 입력 값은 \"0\"이 됩니다 (따라서 Python 코드에서의 값은 반대로 됩니다: 버튼이 눌리지 않으면 \"1\", 눌리면 \"0\"이 됩니다).\n\n입력 핀이 구성되면, 그 값을 읽기 위해 필요한 코드는 한 줄뿐입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nvalue = gpio.input(button_pin)\n```\n\n코딩을 좀 더 편리하게 하기 위해, 마지막 버튼 상태를 기억할 수 있는 GPIOButton 클래스를 만들었어요. 상태를 비교해서 버튼이 눌리거나 놓였는지 쉽게 감지할 수 있게 돼요.\n\n```js\nclass GPIOButton:\n    def __init__(self, pin_number: int):\n        self.pin = pin_number\n        self.is_pressed = False\n        self.is_pressed_prev = False\n        if gpio is not None:\n            gpio.setup(self.pin, gpio.IN, pull_up_down=gpio.PUD_UP)\n\n    def update_state(self):\n        \"\"\" Update button state \"\"\"\n        self.is_pressed_prev = self.is_pressed\n        self.is_pressed = self._pin_read(self.pin) == 0\n\n    def is_button_pressed(self) -\u003e bool:\n        \"\"\" Button was pressed by user \"\"\"\n        return self.is_pressed and not self.is_pressed_prev\n\n    def is_button_hold(self) -\u003e bool:\n        \"\"\" Button still pressed by user \"\"\"\n        return self.is_pressed and self.is_pressed_prev\n\n    def is_button_released(self) -\u003e bool:\n        \"\"\" Button released by user \"\"\"\n        return not self.is_pressed and self.is_pressed_prev\n\n    def reset_state(self):\n        \"\"\" Clear the button state \"\"\"\n        self.is_pressed = False\n        self.is_pressed_prev = False\n\n    def _pin_read(self, pin: int) -\u003e int:\n        \"\"\" Read pin value \"\"\"\n        return gpio.input(pin) if gpio is not None else 0\n```\n\n이 방식을 통해 라즈베리 파이가 없는 사용자들을 위해 “가상 버튼”을 만들 수도 있어요. 예를 들어, 이 “버튼”은 애플리케이션이 시작된 후 처음 5초 동안 눌린 상태일 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nclass VirtualButton(GPIOButton):\n    def __init__(self, delay_sec: int):\n        super().__init__(pin_number=-1)\n        self.start_time = time.monotonic()\n        self.delay_sec = delay_sec\n\n    def update_state(self):\n        \"\"\" Update button state: button is pressed first N seconds \"\"\"\n        self.is_pressed_prev = self.is_pressed\n        self.is_pressed = time.monotonic() - self.start_time \u003c self.delay_sec\n```\n\n가상 버튼을 사용하면 해당 코드를 Windows, Mac 또는 Linux PC에서 쉽게 테스트할 수 있습니다.\n\n## 소리 녹음 및 음성 인식\n\nPTT(푸시 투 토크) 버튼을 사용하여 소리를 녹음할 수 있습니다. 이를 위해 Python 사운드카드 라이브러리를 사용할 것입니다. 0.5초씩 오디오를 녹음하며, 이 정확도는 우리의 작업에 충분히 적합합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport soundcard as sc\n\n\nclass SoundRecorder:\n    \"\"\" 사운드 레코더 클래스 \"\"\"\n    SAMPLE_RATE = 16000\n    BUF_LEN_SEC = 60\n    CHUNK_SIZE_SEC = 0.5\n    CHUNK_SIZE = int(SAMPLE_RATE*CHUNK_SIZE_SEC)\n\n    def __init__(self):\n        self.data_buf: np.array = None\n        self.chunks_num = 0\n\n    def get_microphone(self):\n        \"\"\" 기본 마이크 가져오기 \"\"\"\n        mic = sc.default_microphone()\n        logging.debug(f\"녹음 장치: {mic}\")\n        return mic.recorder(samplerate=SoundRecorder.SAMPLE_RATE)\n\n    def record_chunk(self, mic: Any) -\u003e np.array:\n        \"\"\" 새로운 데이터 청크 녹음하기 \"\"\"\n        return mic.record(numframes=SoundRecorder.CHUNK_SIZE)\n\n    def start_recording(self, chunk_data: np.array):\n        \"\"\" 새로운 문구 녹음 시작하기 \"\"\"\n        self.chunks_num = 0\n        self.data_buf = np.zeros(SoundRecorder.SAMPLE_RATE * SoundRecorder.BUF_LEN_SEC, dtype=np.float32)\n        self._add_to_buffer(chunk_data)\n\n    def continue_recording(self, chunk_data: np.array):\n        \"\"\" 문구 녹음 계속하기 \"\"\"\n        self.chunks_num += 1\n        self._add_to_buffer(chunk_data)\n\n    def get_audio_buffer(self) -\u003e Optional[np.array]:\n        \"\"\" 오디오 버퍼 가져오기 \"\"\"\n        if self.chunks_num \u003e 0:\n            logging.debug(f\"오디오 길이: {self.chunks_num*SoundRecorder.CHUNK_SIZE_SEC}s\")\n            return self.data_buf[:self.chunks_num*SoundRecorder.CHUNK_SIZE]\n        return None\n\n    def _add_to_buffer(self, chunk_data: np.array):\n        \"\"\" 버퍼에 새 데이터 추가하기 \"\"\"\n        ind_start = self.chunks_num*SoundRecorder.CHUNK_SIZE\n        ind_end = (self.chunks_num + 1)*SoundRecorder.CHUNK_SIZE\n        self.data_buf[ind_start:ind_end] = chunk_data.reshape(-1)\n```\n\nPTT 버튼과 사운드 레코더로 “스마트 어시스턴트” 파이프라인의 첫 부분을 구현할 수 있습니다:\n\n```js\nptt = GPIOButton(pin_number=button_pin)\n\nrecorder = SoundRecorder()\nwith recorder.get_microphone() as mic:\n    while True:\n        new_chunk = recorder.record_chunk(mic)\n        ptt.update_state()\n\n        if ptt.is_button_pressed():\n            # 녹음 시작\n            recorder.start_recording(new_chunk)\n        elif ptt.is_button_hold():\n            recorder.continue_recording(new_chunk)\n        elif ptt.is_button_released():\n            buffer = recorder.get_audio_buffer()\n            if buffer is not None:\n                # 녹음 종료\n                # ...\n\n            # 새 문구를 위해 준비\n            ptt.reset_state()\n```\n\n전체 코드는 기사의 끝에 제공되지만, 이 부분만으로 아이디어를 이해할 수 있습니다. 여기서는 무한한 “메인” 루프가 있습니다. 마이크는 항상 활성화되어 있지만, 녹음은 버튼이 눌릴 때만 시작됩니다. PTT 버튼이 놓일 때, 오디오 버퍼를 음성 인식에 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nASR(Automatic Speech Recognition)은 이미 이전 게시물에서 설명했습니다:\n\n이 텍스트를 간결하게 만들기 위해 코드를 다시 반복하지 않겠습니다. 독자들께서 스스로 이전 부분을 확인하시기 바랍니다.\n\n## 디스플레이\n\n이 프로젝트에서는 Amazon에서 $3-5에 구매할 수 있는 작은 1.4인치 128x64 OLED 디스플레이를 사용했습니다. 코드는 이미 이전 게시물에서 제시되었습니다. 저는 단지 작은 리팩토링을 수행하고 모든 메서드를 OLEDDisplay 클래스에 넣었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nclass OLEDDisplay:\n    \"\"\" I2C OLED 화면에 정보 표시 \"\"\"\n    def __init__(self):\n        self.pixels_size = (128, 64)\n        ...\n        self.app_logo = Image.open(\"bunny.png\").convert('1')\n        if adafruit_ssd1306 is not None and i2c is not None:\n            self.oled = adafruit_ssd1306.SSD1306_I2C(self.pixels_size[0],\n                                                     self.pixels_size[1],\n                                                     i2c)\n        else:\n            self.oled = None        \n\n    def add_line(self, text: str):\n        \"\"\" 스크롤링되는 새로운 라인 추가 \"\"\"\n\n    def add_tokens(self, text: str):\n        \"\"\" 추가 줄바꿈 여부에 따라 새로운 토큰 추가 \"\"\"\n\n    def draw_record_screen(self, text: str):\n        \"\"\" 로고와 텍스트를 그림 \"\"\"\n        logging.debug(f\"Draw_record_screen: \\033[0;31m{text}\\033[0m\")\n        if self.oled is None:\n            return\n\n        image = Image.new(\"1\", self.pixels_size)\n        img_pos = (self.pixels_size[0] - self.image_logo.size[0])//2\n        image.paste(self.image_logo, (img_pos, 0))\n        draw = ImageDraw.Draw(image)\n        text_size = self._get_text_size(text)\n        txt_pos = (self.pixels_size[0]//2 - text_size[0]//2,\n                   self.pixels_size[1] - text_size[1])\n        draw.text(txt_pos, text, font=self.font, fill=255, align=\"center\")\n\n        self._draw_image(image)\n\n    def _get_text_size(self, text):\n        \"\"\" 텍스트 크기 가져오기 \"\"\"\n        _, descent = self.font.getmetrics()\n        text_width = self.font.getmask(text).getbbox()[2]\n        text_height = self.font.getmask(text).getbbox()[3] + descent\n        return (text_width, text_height)\n\n    def _draw_image(self, image: Image):\n        \"\"\" 디스플레이에 이미지 그리기 \"\"\"\n``` \n\n또한 PTT 버튼이 눌렸는지 여부를 나타내는 \"rabbit\" 로고와 텍스트를 표시하는 draw_record_screen 메서드를 추가했습니다. 텍스트는 다른 상태 메시지에도 유용합니다. 라즈베리 파이에 연결된 디스플레이는 다음과 같이 보입니다:\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*o863KNDptmNqkTmz1kBamw.gif\" /\u003e\n\n깜박임은 비디오 녹화의 부작용이며, 인간 눈에는 보이지 않습니다. 미술가가 아니라서 제 그림 실력이 죄송합니다 ;)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지난 글에서 언급한 것처럼 이 코드는 라즈베리 파이 없이 일반 PC에서 테스트할 수 있어요. 이 경우 oled 변수가 None이 되며 표준 logging.debug 출력만 사용하게 됩니다.\n\n## 대형 액션 모델\n\n이제 재밌는 부분에 다가가고 있어요 — LLMs와 놀아보죠. 우리 AI 어시스턴트의 논리는 간단해요:\n\n- 마이크로폰에서 문구를 가져옵니다.\n- 이 문구를 장치 내에서 실행되는 작은 언어 모델로 구문 분석합니다.\n- 문구가 특정 작업에 해당하는 경우, 어시스턴트가 해당 작업을 수행합니다 (예: 스마트 LED 전구에 명령을 보내어 등을 켤 수 있습니다). 작업이 알려지지 않은 경우에만 어시스턴트가 \"큰\" 모델에 도움을 요청합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n장치에서 모델을 로컬에서 실행하는 것은 간단한 이유로 매우 중요합니다: 클라우드 API는 무료가 아닙니다. 예를 들어, 이 글을 쓰는 시점에서, Rabbit R1의 가격은 $199이며, 그들의 웹사이트에서 약속한 대로 \"구독이 필요하지 않습니다.\" 가능한 한 많은 작업을 로컬에서 실행하는 것이 가능하게 만드는 것이 중요합니다. 저희의 스마트 어시스턴트에게도 같은 방식을 사용할 것입니다.\n\n장난감 예시로, 하나의 작업만 있는 경우를 가정해보겠습니다. 저희의 스마트 어시스턴트는 불을 켜고 끌 수밖에 없다고 가정해봅시다. 이 작업을 감지하기 위한 가능한 LLM 프롬프트는 다음과 같이 보일 수 있습니다:\n\n```js\n당신은 사용자 어시스턴트입니다.\n사용자가 불을 켜고 싶다면 라이트 온리를 작성하십시오.\n사용자가 불을 끄고 싶다면 라이트 오프만 작성하십시오.\n다른 경우에는 알 수 없음이라고만 작성하십시오.\n예시.\n사용자: 불을 켜주세요. 어시스턴트: 라이트 온.\n사용자: 불을 끄세요. 어시스턴트: 라이트 오프.\n사용자: 문을 열어주세요. 어시스턴트: 알 수 없음.\n이제 다음 사용자 텍스트를 읽으세요. 간단한 답변만 작성하십시오.\n사용자: {질문}\n어시스턴트:\n```\n\n실제 사용 사례에서는 많은 작업이 있을 수 있고, 사용자 요청에 가장 잘 맞는 프롬프트를 얻기 위해 작은 RAG 데이터베이스가 사용되지만, 테스트를 위해서는 충분합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라즈베리 파이에서 언어 모델을 사용하려면 LLM 클래스를 만들어 봅시다. 또한 3가지 가능한 동작을 포함한 LLMAction 클래스를 만들었습니다:\n\n```js\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain_community.llms import LlamaCpp\n\nclass LLMAction:\n    \"\"\" 가능한 동작 \"\"\"\n    UNKNOWN = 0\n    LIGHTS_ON = 1\n    LIGHTS_OFF = 2\n\n    @staticmethod\n    def get_action(response: str) -\u003e int:\n        \"\"\" 텍스트 응답에서 동작을 가져옵니다 \"\"\"\n        \n        actions = [(LLMAction.LIGHTS_ON, \"LIGHT ON\"),\n                   (LLMAction.LIGHTS_OFF, \"LIGHT OFF\")]\n        for action, action_text in actions:\n            if action_text.lower() in response.lower():\n                return action\n        return LLMAction.UNKNOWN\n\nclass LLM:\n    \"\"\" LLM 상호작용 \"\"\"\n    def __init__(self):\n        self.model_file = \"...\"\n        self.llm = LlamaCpp(\n            model_path=self.model_file,\n            temperature=0.1,\n            max_tokens=8,\n            n_gpu_layers=0,\n            n_batch=256,\n            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n            verbose=True,\n        )\n\n    def get_action_code(self, question: str) -\u003e int:\n        \"\"\" LLM에게 질문하고 동작 코드를 반환합니다 \"\"\"\n        res_str = self._inference(question)\n        return LLMAction.get_action(res_str)\n\n    def _inference(self, question: str) -\u003e str:\n        \"\"\" LLM에게 질문합니다 \"\"\"\n        template = self._get_prompt_template()\n        prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n        chain = prompt | self.llm | StrOutputParser()\n        resp = chain.invoke({\"question\": question}, config={}).strip()\n        return resp\n      \n    def _get_prompt_template(self) -\u003e str:\n        \"\"\" 다른 모델에 대한 프롬프트를 가져옵니다 \"\"\"\n        if \"tinyllama\" in self.model_file:\n            return \"\"\"\u003c|system|\u003e\n                사용자 보조 기능입니다. 사용자가 빛을 켜려면 LIGHT ON이라고만 적어주세요. \n                빛을 끄려면 LIGHT OFF라고만 적어주세요. 다른 경우에는 I DON'T KNOW이라고만 적어주세요.\n                예시.\n                사용자: 불을 켜줘. 보조 기능: \"LIGHT ON\". \n                사용자: 불을 끄어줘. 보조 기능: \"LIGHT OFF\".\n                사용자: 문을 열어줘. 보조 기능: \"I DON'T KNOW\".\n                이제 이 사용자 질문에 답해주세요. LIGHT ON, LIGHT OFF 또는 I DON'T KNOW 중에 선택해 적어주세요.\n                \u003c/s\u003e\n                \u003c|user|\u003e\n                {question}\u003c/s\u003e\n                \u003c|assistant|\u003e\"\"\"\n        ...\n```\n\n여기서 LlamaCpp를 사용하여 언어 모델을 로드하고 응답을 얻기 위한 _inference 메서드를 만들었습니다. 서로 다른 모델은 서로 다른 프롬프트 구문을 갖기 때문에, 모델 이름에 따라 다른 프롬프트를 선택합니다. LlamaCpp 라이브러리는 라즈베리 파이에 쿠다 GPU가 없어도 작동할 수 있고 평범한 C/C++로 작성되어 있어 우리의 작업에 탁월합니다.\n\n어떤 모델을 사용해야 할까요? 라즈베리 파이는 계산 자원이 제한적이기 때문에 답은 그리 쉽지 않습니다. GPU가 없고 CPU 추론 속도가 느립니다. 실제로 라즈베리 파이에서 모델을 실행할 때, 1–2B 모델에만 제한됩니다. 그 외에는 추론에 너무 많은 시간이 걸립니다. \"작은 대형 언어 모델\"은 모순적으로 들릴 수 있지만, 우리의 경우 선택지가 매우 제한적입니다. HuggingFace에서 라즈베리 파이에 적합한 1B Tiny Vicuna, 1.1B Tiny Llama, 그리고 2.7B Phi-2 모델을 찾을 수 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장 좋은 작은 모델을 찾기 위해 작은 벤치마크를 만들어 봅시다. 우리의 3가지 액션을 테스트하기 위해 4개씩 총 12개의 문구를 만들었습니다.\n\n```python\nqa_pairs = [(\"Switch on the light\", LLMAction.LIGHTS_ON),\n            (\"Switch on the light please\", LLMAction.LIGHTS_ON),\n            (\"Turn on the light\", LLMAction.LIGHTS_ON),\n            (\"Turn on the light please\", LLMAction.LIGHTS_ON),\n            (\"Switch off the light\", LLMAction.LIGHTS_OFF),\n            (\"Switch off the light please\", LLMAction.LIGHTS_OFF),\n            (\"Turn off the light\", LLMAction.LIGHTS_OFF),\n            (\"Turn off the light please\", LLMAction.LIGHTS_OFF),\n            (\"Buy me the ticket\", LLMAction.UNKNOWN),\n            (\"Where is the nearest library?\", LLMAction.UNKNOWN),\n            (\"What is the weather today?\", LLMAction.UNKNOWN),\n            (\"Give me a receipt of an apple pie\", LLMAction.UNKNOWN)]\n```\n\n코드를 실행하기 전에 huggingface-cli 도구를 사용하여 모델을 다운로드해야 합니다:\n\n```python\nhuggingface-cli download afrideva/Tiny-Vicuna-1B-GGUF tiny-vicuna-1b.q4_k_m.gguf --local-dir . --local-dir-use-symlinks False\nhuggingface-cli download TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\nhuggingface-cli download TheBloke/phi-2-GGUF phi-2.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\nhuggingface-cli download TheBloke/Llama-2-7b-Chat-GGUF llama-2-7b-chat.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기, 더 나은 성능을 위해 7B Llama-2 모델을 \"참조\"로 다운로드했습니다.\n\n라즈베리 파이 4에서의 시험 결과는 다음과 같습니다:\n\n```js\nTiny Vicuna 1B: 정확도: 66%, 평균 응답 시간: 4.2초\nTiny Llama 1.1B: 정확도: 0%, 평균 응답 시간: 4.9초\nPhi-2 2.7B: 정확도: 75%, 평균 응답 시간: 24.6초\nLlama-2 7B: 정확도: 83%, 평균 응답 시간: 19.3초\n```\n\n결과는 흥미로웠습니다. 첫째, Tiny Llama 모델의 0% 정확도에 놀랐습니다. 여전히 응답을 제공할 수는 있었지만 정확하지 않았습니다. 예를 들어, Tiny Llama는 \"불을 켜라\"라는 문구에 \"사용자: 불 켜기\"라는 답변을 할 수 있고, 이는 \"어느 정도\" 정확하며 핵심 문구를 쉽게 찾을 수 있습니다. 둘째, 7B Llama-2가 2.7B Phi-2보다 더 빠르게 작동하는 것을 보는 것이 흥미로웠습니다. 셋째, 모델들에게 가장 \"어려웠던\" 것은 마지막 질문 그룹이었습니다. 거의 모든 모델이 \"모르겠다.\" 대신에 스스로 답을 만들려고 시도했습니다. 재미있게도 \"작은\" 모델뿐만 아니라 Google Bard도 이 실수를 범했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_2.png\" /\u003e\n\n어쨌든 라즈베리 파이에서 1-2B 모델을 사용할 수 있지만 두 가지 문제점이 있습니다. 첫째, 라즈베리 파이 4가 충분히 빠르지 않다는 것을 알 수 있습니다. 모델은 작동하지만 추론하는 데 4초는 다소 느립니다. 라즈베리 파이 5는 거의 2배 빠를 것으로 예상되지만, 심지어 2초도 상당한 지연입니다. 둘째, 작은 LLM은 종종 충분히 정확하지 않습니다. 우리의 프로토타입에는 문제가 되지 않지만, 생산 장치의 경우 세밀한 조정이 필요할 것입니다.\n\n테스트 결과를 얻은 후 Rabbit R1 개발자들이 LLM을 구현한 방법을 생각해 보는 것도 흥미롭습니다. R1 설명에서 \"500ms\" 응답 시간을 본 적이 있습니다. 결과에서 볼 수 있듯이 이 시간 제한은 정말 도전적입니다. 당연히 실제 답변을 모르지만, 몇 가지 교육된 추측을 할 수 있습니다.\n\n- 사용자 조작에만 초점을 맞춘 작은 0.1-0.5B 언어 모델을 만들어 실제 데이터셋에서 학습했을 것입니다.\n- 더 빠른 처리를 위해 별도의 칩을 사용했을 것입니다. \"Intel Neural Compute Stick\"과 같은 장치들이 여러 년 동안 알려져 왔으며, 현대의 coprocessors가 LLM 계산을 수행할 수 있는 수단이 있을지도 모릅니다 (이 방법은 새로운 것은 아닙니다; 저와 같은 세대의 사람들은 Intel 8087 수학 coprocessors를 기억할 수 있습니다.).\n- LLM 이외에도 더 많이 사용할 수 있습니다. 텍스트 파싱은 \"클래식\" 파이썬 도구인 정규 표현식, 코딩된 규칙 등을 사용하여 수행할 수 있으며, 모든 방법을 결합하는 것이 유익할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로 Rabbit R1은 꽤 좋은 MediaTek MT6765 옥타코어 프로세서를 갖추고 있으며 몇 가지 테스트에서 Raspberry Pi 4보다 상당히(4-8배) 빠르다고 명시되어 있습니다. 따라서 이 CPU에서는 심지어 1B 모델이 충분히 빠르게 작동할 수도 있습니다.\n\n## 클라우드 모델\n\n이전에 토론한 대로 로컬 모델이 답을 알지 못하는 경우 \"모르겠어요\"라는 응답을 반환하고 이 경우 질문을 \"큰 동생\"에게 전달할 것입니다. 시작해봅시다!\n\n라즈베리 파이에서 클라우드 모델을 사용하는 것은 간단합니다. OpenAILLM 클래스를 생성하고, 이름에서 알 수 있듯이 OpenAI API를 사용할 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom langchain_openai import OpenAI\n\nOPENAI_BASE_URL = \"...\"\nOPENAI_API_KEY = \"여기에 키를 입력하세요\"\n\nclass OpenAILLM:\n    \"\"\" OpenAI API Handler \"\"\"\n    def __init__(self):\n        self.llm = OpenAI(openai_api_key=OPENAI_API_KEY,\n                          base_url=OPENAI_BASE_URL)\n        self.template = \"\"\"도와드리는 어시스턴트입니다.\n                           질문에 대한 간단한 답변을 작성해주세요.\n                           질문: {question}\n                           답변:\"\"\"\n\n    def inference(self, question: str, callback: Callable):\n        \"\"\" OpenAI 모델에 질문하기 \"\"\"\n        prompt = PromptTemplate(template=self.template,\n                                input_variables=[\"question\"])\n\n        chain = prompt | self.llm | StrOutputParser()\n        for token in chain.stream({\"question\": question}):\n            callback(token)\n```\n\n여기서 OLED 디스플레이를 업데이트하기 위해 스트리밍 모드와 콜백 핸들러를 사용했기 때문에 답변은 토큰 단위로 즉시 표시됩니다.\n\n코드에서 OPENAI_API_KEY 변수를 볼 수 있습니다. OpenAI 구독이 없는 경우 어떻게 할 수 있을까요? LlamaCPP는 훌륭한 라이브러리이며 이를 해결해 줍니다. 이것을 통해 로컬 인스턴스로 OpenAI API를 모사할 수 있어서 다른 PC에서 실행할 수 있습니다. 예를 들어, 다음 명령을 사용하여 데스크탑에서 7B Llama-2 모델을 실행할 수 있습니다:\n\n```js\npython3 -m llama_cpp.server --model llama-2-7b-chat.Q4_K_M.gguf --n_ctx 16192 --host 0.0.0.0 --port 8000\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그런 다음 코드에서 OPENAI_BASE_URL을 \"http://192.168.1.10:8000/v1\"과 같은 것으로 조정하면 됩니다. 흥미롭게도 OpenAI 라이브러리는 여전히 키가 필요합니다(키가 비어 있으면 내부적으로 확인하도록 되어 있습니다), 그러나 일반적인 숫자 \"42\"도 충분합니다 ;)\n\n그런데 우리의 프로토타입에서는 먼저 로컬 모델을 사용하여 클라우드 비용을 줄이지만, OpenAI 키를 가지고 있고 가격에 신경 쓰지 않는 독자들은 API 호출을 사용하여 로컬 작업을 분석할 수도 있습니다. 무료는 아니지만 더 빠르고 정확할 것입니다. 이 경우 LLM 클래스를 LlamaCPP 모델 대신 OpenAI로 작업 프롬프트를 보낼 수 있도록 약간 수정할 수 있습니다.\n\n## 결과\n\n마지막으로, 모든 부분을 결합할 때가 왔습니다! 최종 코드는 다음과 같이 보입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nif __name__ == \"__main__\":\n    display = OLEDDisplay()\n    display.add_line(\"자동 음성 인식 초기화 중...\")    \n    asr = ASR()\n\n    display.add_line(\"GPT 모델 초기화 중...\")\n    llm = LLM()\n\n    ptt = GPIOButton(pin_number=button_pin)\n    if gpio is None:\n        ptt = VirtualButton(delay_sec=5)\n\n    def on_recording_finished(audio_buffer: np.array):\n        \"\"\" 녹음이 완료되었으며 오디오 데이터를 처리합니다 \"\"\"\n        question = asr.transcribe(audio_buffer)\n        display.add_line(f\"\u003e {question}\\n\")\n\n        # 처리\n        action = llm.get_action_code(question)\n        if action != LLMAction.UNKNOWN:\n            process_action(action)\n        else:\n            process_unknown(question)\n\n        display.add_line(\"\\n5초 후에 다시 이동합니다...\\n\")\n        time.sleep(5)\n\n    def process_action(action: int):\n        \"\"\" 더미 작업을 처리합니다 \"\"\"\n        ...\n\n    def process_unknown(question: str):\n        \"\"\" OpenAI에 질문합니다 \"\"\"\n        display.add_line(\"\\n\")\n        # 대답을 스트리밍\n        openai_llm = OpenAILLM()\n        openai_llm.inference(question=question,\n                             callback=display.add_tokens)\n\n      # 메인 루프\n      recorder = SoundRecorder()\n      with recorder.get_microphone() as mic:\n          ptt.reset_state()\n          display.draw_record_screen(\"PTT 준비됨\")\n          while True:\n              new_chunk = recorder.record_chunk(mic)\n              ptt.update_state()\n\n              if ptt.is_button_pressed():\n                  display.draw_record_screen(\"PTT 활성화\")\n                  recorder.start_recording(new_chunk)\n              elif ptt.is_button_hold():\n                  recorder.continue_recording(new_chunk)\n              elif ptt.is_button_released():\n                  display.draw_record_screen(\"잠시 기다려주세요...\")\n                  buffer = recorder.get_audio_buffer()\n                  on_recording_finished(buffer)\n\n                  # 다시 준비\n                  ptt.reset_state()\n                  display.draw_record_screen(\"PTT 준비됨\")\n```\n\n\n실제로는 이렇게 동작합니다.\n\n로컬 동작을 실행하는 중:\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*Qmwb-hB7Hyd4dCxd37e8-w.gif\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서, 나는 더미 작업을 사용 중이에요; 스마트 램프에 연결하거나 라즈베리 파이에 릴레이 쉴드를 사용하는 것은 이 기사의 범위를 벗어날 것입니다.\n\n원격 LLM에서 답변을 받는 중입니다:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*8jaqi_8ld923YcuZNO6iuQ.gif)\n\n여기서, 저는 데스크톱에서 실행되는 LLaMA-2 모델을 OpenAI 대체재로 사용하고 있어요. 이 모델은 라즈베리 파이에서 로컬로 실행되는 모델과 비교해서 응답이 훨씬 빠르다는 것을 알 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결론\n\n이번 \"주말\" 프로젝트에서는 라즈베리 파이를 기반으로 한 스마트 어시스턴트를 만들었습니다. 이 스마트 어시스턴트는 다양한 기능을 수행할 수 있습니다:\n\n- 푸시 투 토크 버튼과 음성 인식을 사용할 수 있습니다.\n- 다양한 사용자 동작을 감지할 수 있는 로컬 언어 모델을 실행할 수 있습니다.\n- 만약 사용자의 요청이 로컬 LLM에 알려지지 않은 경우 더 강력한 원격 모델을 요청할 수 있습니다. 이 경우 OpenAI API나 호환 가능한 로컬 서버를 사용할 수 있습니다.\n\n우리는 이와 같은 프로젝트를 만드는 데 많은 도전이 있다는 것을 알 수 있습니다. 대규모 언어 모델은 많은 계산 능력이 필요하며, 휴대용 장치에는 도전적입니다. 좋은 결과를 얻기 위해서는 조정된 모델 뿐만 아니라 그 모델을 빠르게 실행할 충분히 강력한 하드웨어도 필요합니다 (20초의 지연 후에 \"스마트 어시스턴트\" 응답을 받은 사용자는 아무도 관심을 갖지 않을 것입니다). 클라우드 API는 빠릅니다만 무료가 아니며, 하드웨어 비용, 계산 속도, 판매 가격 및 클라우드 비용 사이의 균형을 찾는 것은 까다로울 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이 이야기를 즐기셨다면 Medium에 구독해 주시고, 새로운 기사가 발행될 때 알림을 받으며 다른 저자들의 수천 개 이야기에 완전한 액세스 권한을 얻을 수 있습니다. 또한 LinkedIn을 통해 연락하실 수도 있습니다. 이와 함께 이와 다른 게시물의 전체 소스 코드를 받고 싶다면 Patreon 페이지를 방문해주세요.\n\n언어 모델과 자연어 처리에 관심이 있는 분들은 다른 기사들을 읽어보시기를 환영합니다:\n\n- 주말 AI 프로젝트 (제1부): 라즈베리 파이에서 음성 인식 및 LLaMA-2 GPT 실행\n- 모든 사람을 위한 LLMs: LangChain 및 MistralAI 7B 모델을 Google Colab에서 실행\n- 모든 사람을 위한 LLMs: LLaMA-13B 모델 및 LangChain을 Google Colab에서 실행\n- 모든 사람을 위한 LLMs: Google Colab에서 HuggingFace 텍스트 생성 추론 실행\n- 절대 초보자를 위한 자연어 처리\n- 16, 8 및 4비트 부동 소수점 형식 - 어떻게 동작하는가?\n\n읽어 주셔서 감사합니다.","ogImage":{"url":"/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0.png","tag":["Tech"],"readingTime":23}],"page":"47","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"47"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>