<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/8" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/8" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="SageMaker 비동기 추론으로 대형 언어 모델 배포하는 방법" href="/post/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="SageMaker 비동기 추론으로 대형 언어 모델 배포하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="SageMaker 비동기 추론으로 대형 언어 모델 배포하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">SageMaker 비동기 추론으로 대형 언어 모델 배포하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLM API 비교 모델별 가격 분석" href="/post/2024-06-23-LLMAPIsPriceComparisonbyModel"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLM API 비교 모델별 가격 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-LLMAPIsPriceComparisonbyModel_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLM API 비교 모델별 가격 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">LLM API 비교 모델별 가격 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">1<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Transformer 아키텍처 완벽 설명" href="/post/2024-06-23-TransformerArchitectureexplained"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Transformer 아키텍처 완벽 설명" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-TransformerArchitectureexplained_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Transformer 아키텍처 완벽 설명" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Transformer 아키텍처 완벽 설명</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="텍스트 임베딩 종합 가이드 2024 최신" href="/post/2024-06-23-TextEmbeddingsComprehensiveGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="텍스트 임베딩 종합 가이드 2024 최신" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="텍스트 임베딩 종합 가이드 2024 최신" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">텍스트 임베딩 종합 가이드 2024 최신</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">24<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="심리 상담 챗봇  정신 건강을 위한 LLMs 사용 방법" href="/post/2024-06-23-TherapistChatbotLLMsforMentalHealth"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="심리 상담 챗봇  정신 건강을 위한 LLMs 사용 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-TherapistChatbotLLMsforMentalHealth_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="심리 상담 챗봇  정신 건강을 위한 LLMs 사용 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">심리 상담 챗봇  정신 건강을 위한 LLMs 사용 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="컴퓨터는 왜 이진수Binary 체계를 사용할까" href="/post/2024-06-23-WhydoComputersevenuseBinary"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="컴퓨터는 왜 이진수Binary 체계를 사용할까" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-WhydoComputersevenuseBinary_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="컴퓨터는 왜 이진수Binary 체계를 사용할까" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">컴퓨터는 왜 이진수Binary 체계를 사용할까</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="주식 예측에서 머신러닝이 실패하는 주요 이유 파트 01" href="/post/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="주식 예측에서 머신러닝이 실패하는 주요 이유 파트 01" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="주식 예측에서 머신러닝이 실패하는 주요 이유 파트 01" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">주식 예측에서 머신러닝이 실패하는 주요 이유 파트 01</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="컴퓨터는 실제로 어떻게 계산할까" href="/post/2024-06-23-HowDoComputersActuallyCompute"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="컴퓨터는 실제로 어떻게 계산할까" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-HowDoComputersActuallyCompute_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="컴퓨터는 실제로 어떻게 계산할까" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">컴퓨터는 실제로 어떻게 계산할까</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="에이전트 AI의 핵심 과제인 계획 문제 강화학습으로 해결하는 방법" href="/post/2024-06-23-PlanningastheCoreChallengeinAgenticAISolvingitwithReinforcementLearning"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="에이전트 AI의 핵심 과제인 계획 문제 강화학습으로 해결하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-PlanningastheCoreChallengeinAgenticAISolvingitwithReinforcementLearning_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="에이전트 AI의 핵심 과제인 계획 문제 강화학습으로 해결하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">에이전트 AI의 핵심 과제인 계획 문제 강화학습으로 해결하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLM 출력 구조화하는 방법 안내" href="/post/2024-06-23-GuidinganLLMsResponsetoCreateStructuredOutput"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLM 출력 구조화하는 방법 안내" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-GuidinganLLMsResponsetoCreateStructuredOutput_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLM 출력 구조화하는 방법 안내" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">LLM 출력 구조화하는 방법 안내</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link posts_-active__YVJEi" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"SageMaker 비동기 추론으로 대형 언어 모델 배포하는 방법","description":"","date":"2024-06-23 19:59","slug":"2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_0.png\" /\u003e\n\nLLM(대규모 언어 모델)은 인기를 얻고 있으며 이를 추측하는 방법도 늘어가고 있습니다. LLM 호스팅에는 모델의 크기와 배포된 하드웨어의 최적 사용을 보장해야 한다는 어려움이 잘 알려져 있습니다. LLM 사용 사례도 다양합니다. 어떤 것은 실시간 응답 시간이 필요할 수 있고, 다른 것은 거의 실시간 기반의 지연 시간 요구 사항일 수 있습니다.\n\n후자와 더 많은 오프라인 추측 사용 사례를 위해, SageMaker 비동기 추론이 좋은 옵션으로 제공됩니다. 비동기 추론에서는 이름에서 알 수 있듯이 지연 시간이 굉장히 엄격하지 않지만 필요에 따라 호출하고 확장할 수 있는 활성화된 엔드포인트가 필요합니다. 특히 LLM에서 이러한 유형의 작업 부하는 내용 편집/생성, 요약 등과 같은 사용 사례로 인해 점점 인기를 얻고 있습니다. 이러한 작업 부하들은 하위 초 단위 응답이 필요하지는 않지만 필요에 따라 호출할 수 있는 적시의 추론을 필요로 하며, SageMaker Batch Transform과 같은 완전히 오프라인적인 성격과는 대조적입니다.\n\n이 예시에서는 HuggingFace 텍스트 생성 추론 서버를 SageMaker 비동기 엔드포인트와 함께 사용하여 Flan-T-5-XXL 모델을 호스팅하는 방법을 살펴볼 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참고: 본 글은 Python, LLMs 및 Amazon SageMaker에 대한 기본적인 이해를 전제로 합니다. Amazon SageMaker 추론을 시작하려면 다음 가이드를 참조해주세요. SageMaker 비동기 추론의 기초를 다룰 것이지만 더 깊은 소개를 원하시면 다음에 나오는 스타터 예제를 참조해주세요.\n\n공지: 저는 AWS의 머신 러닝 아키텍트이며, 이견은 제 개인적인 의견입니다.\n\n# 목차\n\n- SageMaker 비동기 추론을 사용하는 시점\n- TGI 비동기 추론 구현\n   a. 설정 및 엔드포인트 배포\n   b. 비동기 추론 호출\n   c. 자동 스케일링 설정\n- 추가 자료 및 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1. SageMaker 비동기 추론 사용 시점\n\nSageMaker 추론은 현재 사용 사례에 따라 활용할 수 있는 네 가지 옵션이 있습니다. 세 가지 엔드포인트 기반 옵션이 있고 완전 오프라인 추론을 위한 한 가지 옵션이 있습니다:\n\n- 엔드포인트 기반 옵션:\n    - SageMaker 실시간 추론: 서브초/밀리초 응답 시간과 고 처리량 워크로드를 위한 옵션입니다. 이 엔드포인트는 CPU, GPU 또는 Inferentia 칩을 활용하며 하드웨어 단계에서 AutoScaling을 적용하여 인프라를 확장할 수 있습니다. 일반적인 사용 사례로는 Ad-Tech 기반 예측, 실시간 챗봇 등이 있습니다.\n    - SageMaker 서버리스 추론: 갑작스럽고 간헐적인 워크로드에 최적화되어 있으며 cold-start를 허용할 수 있는 옵션입니다 (Provisioned Concurrency를 통해 완화할 수 있음). 여기서는 엔드포인트 뒤에 있는 모든 인프라를 관리하지 않으며 확장은 자동으로 처리됩니다.\n    - SageMaker 비동기 추론: 오늘 다룰 옵션으로, 비동기 추론을 통해 거의 실시간 기반의 응답 시간 요구 사항을 충족하고 여전히 엔드포인트를 위해 정의한 전용 하드웨어를 사용합니다. 그러나 비동기 추론의 경우 실시간 추론과 달리 0 개의 인스턴스로 축소할 수 있는 옵션이 있습니다. 비동기 추론을 통해 내장 큐를 사용하여 요청을 관리하고이 큐의 가득 찬 정도에 따라 확장할 수 있습니다.\n\n- 오프라인 추론:\n    - SageMaker 배치 변환: 데이터셋이 있고 데이터셋으로 반환된 출력만 필요할 때 최적입니다. 영구적인 엔드포인트는 없으며 완전히 오프라인 추론입니다. 일반적인 사용 사례로는 특정 주기에 추론이 필요한 데이터셋이 있는 경우 일정 시간에 배치 변환 작업을 실행하는 것이 있습니다.\n\n이 사용 사례에서는 특히 비동기 추론에 초점을 맞추고 있습니다. 이 옵션은 거의 실시간 능력과 0 인스턴스로 축소할 수 있는 능력 때문에 Batch Transform과 Real-Time Inference 사이에서 결혼 생각할 수 있는 옵션입니다. 즉시 생성이 필요하지 않은 사용 사례를 위한 LLM을 호스팅하는 데 효율적인 방법으로 기능을 제공할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 사용 사례의 예시로는 요약, 콘텐츠 생성, 편집 등이 있습니다. 이러한 사용 사례는 모두 가변 시간에 activation이 필요할 수 있으므로 지속적인 엔드포인트가 필요하지만 실시간 추론의 응답 시간은 필요로 하지 않을 수도 있습니다. 비동기 추론을 통해 성능과 비용 측면에서 이러한 종류의 사용 사례들을 다룰 수 있습니다.\n\n오늘의 예시로, 우리는 인기 있는 Flan 모델을 SageMaker 비동기 추론에 적용해 보겠습니다. SageMaker 비동기 추론 엔드포인트를 생성하는 것은 실시간 엔드포인트 생성과 매우 유사합니다. 주요 차이점은 실시간 추론처럼 페이로드를 직접 전달하는 대신 입력 데이터에 대한 S3 경로가 필요하다는 점입니다.\n\n![이미지](/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_1.png)\n\n비동기 엔드포인트 내에는 내부 대기열도 있음을 유의해야 합니다. 모든 추론마다 SageMaker는 요청을 대기열에 넣고 결과 위치를 S3에 반환합니다. 비동기 엔드포인트에 대해 AutoScaling을 구성할 때 이 대기열 내의 요청 수에 따라 스케일을 조정할 수 있습니다. 또한 출력 S3 경로에서 직접 폴링하는 대신 성공 또는 오류 있는 추론 알림을 수신하기 위해 선택적으로 SNS 토픽을 통합할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 비동기 추론에 대한 이해가 조금 더 깊어졌으니 구현부로 넘어가 봅시다!\n\n# 2. TGI 비동기 추론 구현\n\n우리는 새로운 SageMaker Studio 환경에서 Base Python3 커널과 ml.c5.xlarge 인스턴스로 작업할 것입니다. 비동기 추론을 위해 익숙한 Boto3 AWS Python SDK 및 상위 레벨 SageMaker Python SDK를 사용할 것입니다.\n\n## a. 설정 및 엔드포인트 배포\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비동기 추론을 사용하려면 먼저 데이터가 저장될 출력 S3 경로를 정의해야 합니다.\n\n```js\nsagemaker_session = sagemaker.Session()\ndefault_bucket = sagemaker_session.default_bucket()\nbucket_prefix = \"async-llm-output\"\nasync_output_path = f\"s3://{default_bucket}/{bucket_prefix}/output\"\nprint(f\"내 모델 추론 결과는 다음 S3 경로에 저장될 것입니다: {async_output_path}\")\n```\n\n그런 다음 이 S3 경로를 사용하여 비동기 추론 구성을 지정할 수 있습니다. 이 경우 SNS 주제를 지정하지 않지만, 성공적이거나 오류가 발생했을 때 서비스를 통해 알림을받기를 원하는 경우 선택적으로 포함할 수 있습니다.\n\n```js\nfrom sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n\nasync_config = AsyncInferenceConfig(\n    output_path=async_output_path,\n    max_concurrent_invocations_per_instance=10,\n    # 선택적으로 Amazon SNS 주제 지정\n    # notification_config = {\n    # \"SuccessTopic\": \"arn:aws:sns:\u003caws-region\u003e:\u003caccount-id\u003e:\u003ctopic-name\u003e\",\n    # \"ErrorTopic\": \"arn:aws:sns:\u003caws-region\u003e:\u003caccount-id\u003e:\u003ctopic-name\u003e\",\n    # }\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 정의된 후에는 Flan T-5-XXL 모델을 위한 HuggingFace Hub 링크에서 SageMaker 코드를 직접 가져올 수 있습니다. 이 코드는 Text Generation Inference 모델 서버를 활용하며, Tensor Parallelism과 같은 내장 최적화가 포함되어 있습니다.\n\n```js\n# huggingface hub에서 배포 코드 직접 가져와서 비동기 구성 추가\nhub = {\n   'HF_MODEL_ID':'google/flan-t5-xxl',\n   'SM_NUM_GPUS': json.dumps(4)\n}\n\nhuggingface_model = HuggingFaceModel(\n   image_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n   env=hub,\n   role=role, \n)\r\n```\n\n그런 다음 SageMaker 모델 객체와 비동기 구성을 함께 사용하여 엔드포인트를 생성할 수 있습니다.\n\n```js\n# SageMaker 추론을 위해 모델 배포\npredictor = huggingface_model.deploy(\n initial_instance_count=1,\n instance_type=\"ml.g5.12xlarge\",\n container_startup_health_check_timeout=300,\n async_inference_config=async_config\n)\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n콘솔 또는 UI에서 엔드포인트가 비동기 타입으로 지정되었음을 확인할 수 있습니다.\n\n![image](/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_2.png)\n\n## b. 비동기 추론 호출\n\n단일 페이로드로 엔드포인트를 호출하려면 실시간 추론과 같이 \"predict\" 내장 메소드를 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\n# 단일 호출\n\npayload = \"미국의 수도는 어디인가요?\"\ninput_data = {\n    \"inputs\": payload,\n    \"parameters\": {\n        \"early_stopping\": True,\n        \"length_penalty\": 2.0,\n        \"max_new_tokens\": 50,\n        \"temperature\": 1,\n        \"min_length\": 10,\n        \"no_repeat_ngram_size\": 3,\n        },\n}\npredictor.predict(input_data)\r\n```\n\n그러나 현실적인 사용 사례에 대한 비동기 추론을 확장하려면 S3에서 데이터로 엔드포인트를 호출할 수 있습니다. 비동기 추론의 아이디어는 여러 요청이 입력 S3 버킷에 저장되어 있고 호출은 각 데이터 포인트에 대한 결과와 해당하는 S3 출력 파일을 반환한다는 것입니다. 여기서 한 가지 더 강조하고 싶은 것은 전체 데이터 집합이 처리되고 요청에 의해 호출할 엔드포인트가 없는 Batch Transform과 다르다는 점입니다.\n\n이제 우리는 이 데모를 위해 동일한 데이터포인트를 가진 가짜 데이터 집합을 만들어 S3로 옮기겠습니다. 다음 코드는 입력 파일을 포함하는 로컬 디렉터리를 생성합니다:\n\n```py\nimport json\nimport os\n\noutput_directory = 'inputs'\nos.makedirs(output_directory, exist_ok=True)\n\nfor i in range(1, 20):\n    json_data = [input_data.copy()]\n\n    file_path = os.path.join(output_directory, f'input_{i}.jsonl')\n    with open(file_path, 'w') as input_file:\n        for line in json_data:\n            json.dump(line, input_file)\n            input_file.write('\\n')\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미 제공된 유틸리티 함수를 사용하여 로컬 파일을 S3에 업로드하여 추론할 수 있습니다.\n\n```js\ndef upload_file(input_location):\n    prefix = f\"{bucket_prefix}/input\"\n    return sagemaker_session.upload_data(\n        input_location,\n        bucket=default_bucket,\n        key_prefix=prefix,\n        extra_args={\"ContentType\": \"application/json\"} # 꼭 지정해야함\n    )\n\nsample_data_point = upload_file(\"inputs/input_1.jsonl\")\nprint(f\"샘플 데이터 포인트가 업로드되었습니다: {sample_data_point}\")\n```\n\n그런 다음 Boto3 SDK를 통해 \"invoke_endpoint_async\" API 호출로이 S3 경로에서 샘플 추론을 실행할 수 있습니다.\n\n```js\nimport boto3\nruntime = boto3.client(\"sagemaker-runtime\")\n\nresponse = runtime.invoke_endpoint_async(\n    EndpointName=predictor.endpoint_name,\n    InputLocation=sample_data_point,\n    Accept='application/json',\n    ContentType=\"application/json\"\n)\n\noutput_location = response[\"OutputLocation\"]\nprint(f\"출력 위치: {output_location}\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 번 더 제공된 유틸리티 함수를 사용하여 출력 파일의 출력을 관찰합니다. LLM을 사용하여 실제 추론을 수행하고 S3 파일을 생성하는 데 시간이 걸릴 수 있습니다. 따라서 제공된 함수에서는 화면에 표시할 내용이 포함된 데이터 파일이 나타날 때까지 데이터 파일을 확인합니다.\n\n```js\nimport urllib, time\nfrom botocore.exceptions import ClientError\n\n# 함수 참조/크레딧: https://github.com/aws/amazon-sagemaker-examples/blob/main/async-inference/Async-Inference-Walkthrough-SageMaker-Python-SDK.ipynb\ndef get_output(output_location):\n    output_url = urllib.parse.urlparse(output_location)\n    bucket = output_url.netloc\n    key = output_url.path[1:]\n    while True:\n        try:\n            return sagemaker_session.read_s3_file(bucket=output_url.netloc, key_prefix=output_url.path[1:])\n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\n                print(\"output을 기다리는 중...\")\n                time.sleep(60)\n                continue\n            raise\n\noutput = get_output(output_location)\nprint(f\"Output: {output}\")\n```\n\n그런 다음 모든 샘플 데이터 포인트를 실행하여 모든 입력 파일에서 추론을 수행할 수 있습니다:\n\n```js\ninferences = []\nfor i in range(1, 20):\n    input_file = f\"inputs/input_{i}.jsonl\"\n    input_file_s3_location = upload_file(input_file)\n    print(f\"{input_file}을 사용하여 Endpoint를 호출 중\")\n    async_response = predictor.predict_async(input_path=input_file_s3_location)\n    output_location = async_response.output_path\n    print(output_location)\n    inferences += [(input_file, output_location)]\n    time.sleep(0.5)\n\nfor input_file, output_location in inferences:\n    output = get_output(output_location)\n    print(f\"입력 파일: {input_file}, 출력: {output}\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_3.png\" /\u003e\n\n## c. AutoScaling 설정\n\n비동기 추론에서 자동 스케일링은 실시간 추론과 마찬가지로 Application AutoScaling을 통해 설정됩니다. 이곳에서의 차이점은 스케일링할 수 있는 새로운 메트릭이 있다는 점입니다.\n\n비동기 추론 내에서 이미 구현된 내부 대기열이 있음을 이해했듯이, 자동 스케일링은 이 대기열에 있는 항목의 수에 따라 확장하거나 축소할 수 있습니다. 이는 CloudWatch 메트릭 \"ApproximateBackLogSize\"로 캡처됩니다. 이 요청은 이미 처리 중인 것이거나 아직 처리되지 않은 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nReal-Time Inference와 비슷한 방식으로 Boto3 SDK를 사용하여 정책을 설정했습니다. 최소 인스턴스 수를 0으로 정의했는데, 이 기능은 Asynchronous Inference에서만 지원됩니다.\n\n```js\nclient = boto3.client(\n    \"application-autoscaling\"\n)  # SageMaker를 포함한 다른 서비스의 Application Auto Scaling을 나타내는 일반 클래스\n\nresource_id = (\n    \"endpoint/\" + predictor.endpoint_name + \"/variant/\" + \"AllTraffic\"\n)  # application autoscaling이 엔드포인트를 참조하는 형식\n\n# 비동기 엔드포인트에서 인스턴스 수를 0으로 설정하여 Autoscaling 구성\nresponse = client.register_scalable_target(\n    ServiceNamespace=\"sagemaker\",\n    ResourceId=resource_id,\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n    MinCapacity=0,\n    MaxCapacity=5,\n)\n```\n\n최소 및 최대 인스턴스 수를 지정한 후, 확장 및 축소에 대한 쿨다운 기간을 정의할 수 있습니다. 여기에서 \"MetricName\"을 \"ApproximateBackLogSize\" 메트릭으로 지정하였음을 알려드립니다.\n\n```js\nresponse = client.put_scaling_policy(\n    PolicyName=\"Invocations-ScalingPolicy\",\n    ServiceNamespace=\"sagemaker\",  # 리소스를 제공하는 AWS 서비스의 이름 공간\n    ResourceId=resource_id,  # 엔드포인트 이름\n    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",  # SageMaker는 인스턴스 수만 지원\n    PolicyType=\"TargetTrackingScaling\",  # 'StepScaling'|'TargetTrackingScaling'\n    TargetTrackingScalingPolicyConfiguration={\n        \"TargetValue\": 5.0,  # 메트릭의 목표 값 - 여기서 메트릭은 SageMakerVariantInvocationsPerInstance입니다.\n        \"CustomizedMetricSpecification\": {\n            \"MetricName\": \"ApproximateBacklogSizePerInstance\",\n            \"Namespace\": \"AWS/SageMaker\",\n            \"Dimensions\": [{\"Name\": \"EndpointName\", \"Value\": predictor.endpoint_name}],\n            \"Statistic\": \"Average\",\n        },\n        \"ScaleInCooldown\": 600,  # 쿨다운 기간은 이전 작업의 영향이 나타나기 전에 추가 인스턴스를 시작하거나 종료하는 것을 방지합니다.\n        \"ScaleOutCooldown\": 100,  # ScaleOutCooldown - 확장 작업 완료 후 다른 확장 작업을 시작하기 전의 시간 간격.\n    },\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAutoScaling을 테스트하려면 일정 기간 동안 요청을 보낼 수 있습니다. 스케일링 정책에 따르면 대상 값은 엔드포인트 뒤에 있는 큐에서 아직 처리 중이거나 처리되지 않은 요청 또는 호출을 5회로 설정됩니다.\n\n```js\nrequest_duration = 60 * 15 # 15분\nend_time = time.time() + request_duration\nprint(f\"{request_duration}초 동안 테스트가 실행됩니다.\")\nwhile time.time() \u003c end_time:\n    predictor.predict(input_data)\n```\n\n일정 시간 동안 요청을 보내지 않은 후에는 인스턴스 수가 제로로 축소되고, 큐가 완전히 비어 있는 것을 주의하세요:\n\n![이미지](/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3. 추가 자료 및 결론\n\n전체 예제 코드는 위 링크에서 찾을 수 있습니다. SageMaker 비동기 추론은 전적으로 실시간이나 일괄 처리가 아닌 특정 LLM 사용 사례에 사용할 수 있는 기능입니다. 이 기사가 귀하에게 LLM을 규모 확장하여 인퍼런스를 제공하는 다른 방법에 대한 유용한 소개였기를 바랍니다. 이 분야에서 더 많은 콘텐츠를 기대해 주세요!\n\n항상 읽어 주셔서 감사합니다. 읽은 후 의견을 자유롭게 남겨 주세요.\n\n이 기사를 즐겁게 보셨다면 LinkedIn에서 저와 연락하고 Medium 뉴스레터를 구독해 주시기 바랍니다.","ogImage":{"url":"/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_0.png"},"coverImage":"/assets/img/2024-06-23-DeployingLargeLanguageModelswithSageMakerAsynchronousInference_0.png","tag":["Tech"],"readingTime":12},{"title":"LLM API 비교 모델별 가격 분석","description":"","date":"2024-06-23 19:58","slug":"2024-06-23-LLMAPIsPriceComparisonbyModel","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-LLMAPIsPriceComparisonbyModel_0.png\" /\u003e\n\n이 블로그 게시물은 점점 진화하는 대형 언어 모델(LLM) API 및 관련 가격 구조에 대해 다룹니다.\n\n우리의 목표는 성능이 우수한 LLM 중에서 가장 경쟁력 있는 LLM API 모델을 가격 측면에서 강조하는 지속적으로 업데이트되는 리소스를 만드는 것입니다.\n\n이 게시물을 쉽게 참조하기 위해 즐겨찾기해 두고, 새로운 LLM API 모델을 제안하거나 제공된 정보의 부정확성을 지적해 주십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비교의 세부 사항에 대해 파헤치기 전에 맥락 개요부터 시작해보죠...\n\n## 모델은 어떻게 선택되나요?\n\n최고의 모델은 대규모 멀티태스크 언어 이해 (MMLU) 벤치마크 및 LMSYS 챗봇 아레나의 리더보드 테이블에서 추출됩니다.\n\n## 제공자는 어떻게 선택되나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일단 모델을 식별하면 다양한 공급업체에서 그 모델을 추적합니다. 여기서는 각 모델에 대한 최상의 가격 옵션을 제시합니다. 추론용 API 공급업체가 없는 경우 목록에서 제거됩니다.\n\n## 가격이 어떻게 계산됩니까?\n\n가격은 토큰당 계산되며, 백만 개 토큰당 미국 달러로 표시되며, 입력 및 출력 토큰 가격을 3대 1의 비율로 섞은 가격입니다.\n\n## 모델별 LLM API 요금 살펴보기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장 강력한 LLM 모델들의 표:\n\n이 페이지를 쉽게 참조하기 위해 즐겨찾기를 해두세요. 댓글 섹션에서 기여해도 괜찮아요!","ogImage":{"url":"/assets/img/2024-06-23-LLMAPIsPriceComparisonbyModel_0.png"},"coverImage":"/assets/img/2024-06-23-LLMAPIsPriceComparisonbyModel_0.png","tag":["Tech"],"readingTime":1},{"title":"Transformer 아키텍처 완벽 설명","description":"","date":"2024-06-23 19:57","slug":"2024-06-23-TransformerArchitectureexplained","content":"\n\nTransfomers은 최근에 많은 소음을 일으키고 있는 머신 러닝의 새로운 개발입니다. 그들은 맥락을 잘 추적하는 데 놀라울 정도로 뛰어납니다. 그래서 그들이 쓰는 텍스트가 이치에 맞는 것입니다. 이 장에서는 변압기의 아키텍처와 작동 방식에 대해 알아볼 것입니다.\n\n![이미지](/assets/img/2024-06-23-TransformerArchitectureexplained_0.png)\n\n변압기 모델은 머신 러닝의 가장 흥미로운 새로운 발전 중 하나입니다. Attention is All You Need 논문에서 소개되었습니다. 변압기는 이야기, 수필, 시를 쓰거나, 질문에 답하거나, 다국어 간 번역하거나, 사람들과 대화하거나, 심지어 인간에게 어려운 시험도 패스할 수 있습니다! 하지만 그것들은 무엇인가요? 변압기 모델의 아키텍처는 그다지 복잡하지 않습니다. 그것은 단지 매우 유용한 구성 요소들을 연결한 것으로, 각각의 구성 요소는 자체 기능을 가지고 있습니다. 이 장에서는 이러한 구성 요소들을 모두 배우게 될 것입니다.\n\n요약하면, 변압기는 무엇을 하는 걸까요? 핸드폰에서 텍스트 메시지를 작성하고 있다고 상상해 보세요. 각 단어 뒤에는 세 개의 단어가 제안될 수 있습니다. 예를 들어, \"안녕, 어떻게\"를 입력하면 핸드폰은 \"당신\"이나 \"당신의\"와 같은 단어를 다음 단어로 제안할 수 있습니다. 물론, 핸드폰에서 제안된 단어를 계속 선택하면 이러한 단어로 이루어진 메시지가 이치에 맞지 않음을 빨리 알 수 있습니다. 각각 3개 또는 4개의 연속된 단어 집합을 살펴보면 이치가 맞을 수 있지만, 이러한 단어들은 의미 있는 내용으로 이어지지 않습니다. 이는 핸드폰에서 사용된 모델이 메시지의 전반적인 맥락을 가지고 있지 않기 때문에 발생합니다. 그 모델은 단순히 최근 몇 단어 뒤에 어떤 단어가 더 자주 나올지 예측하는 것입니다. 반면에 변압기는 쓰여지는 내용의 맥락을 추적하고, 그래서 그들이 쓰는 텍스트가 의미가 있는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n휴대폰은 텍스트 메시지에서 사용할 다음 단어를 제안할 수 있지만, 일관된 텍스트를 생성할 수 있는 능력은 없습니다.\n\n![Transformer Architecture](/assets/img/2024-06-23-TransformerArchitectureexplained_1.png)\n\n솔직하게 말하자면, 트랜스포머가 한 번에 한 단어씩 텍스트를 작성한다는 것을 처음 알게 되었을 때, 믿을 수가 없었습니다. 우선, 이것이 인간이 문장을 형성하고 생각하는 방법이 아닙니다. 우리는 먼저 기본적인 생각을 형성한 후, 점차 정제하고 단어를 추가합니다. 이것은 또한 ML 모델이 다른 작업을 하는 방식이 아닙니다. 예를 들어, 이미지는 이렇게 만들어지지 않습니다. 대부분의 신경망 기반의 그래픽 모델은 이미지의 대략적인 버전을 형성하고, 점진적으로 정제하거나 세부 정보를 추가하여 완벽하게 만듭니다. 그렇다면 왜 트랜스포머 모델이 한 단어씩 텍스트를 작성하는 걸까요? 한 가지 답은, 그렇게 하는 것이 정말 잘 작동하기 때문입니다. 더 만족스러운 답은, 트랜스포머가 맥락을 매우 잘 추적하여 다음 단어가 아이디어를 이어나가는 데 정확히 필요한 것이기 때문입니다.\n\n그러면 트랜스포머는 어떻게 훈련되는 걸까요? 많은 양의 데이터로, 사실상 인터넷의 모든 데이터로 말이죠. 그래서 \"안녕, 어떻게\"라는 문장을 트랜스포머에 입력하면, 인터넷의 모든 텍스트를 기반으로 \"당신\"이라는 다음 단어가 가장 좋다는 것을 단순히 알고 있습니다. 좀 더 복잡한 명령을 주면, 예를 들어, \"이야기를 써봐.\" 라고 주면, 좋은 다음 단어로 \"한 번\"을 사용할 수 있음을 알아낼 수도 있습니다. 그러면 이 단어를 명령에 추가하고, 좋은 다음 단어가 \"있던\", 이어갈 다음 단어가 무엇인지 찾아나갑니다. 그리고 한 단어씩, 이렇게 이어가면서 이야기를 써 나갈 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n명령: 이야기를 쓰세요\n응답: 한 번에\n\n다음 명령: 이야기를 쓰세요. 한 번에\n응답: 옛날에\n\n다음 명령: 이야기를 쓰세요. 한 번에 옛날에\n응답: 한\n\n다음 명령: 이야기를 쓰세요. 한 번에 옛날에 한\n응답: 시간\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한때 가족들이 모여 있던 어느 편안한 마을에서 다섯 형제가 살았어요. 그들의 이름은 래리, 루이스, 레오나르도, 루이라, 그리고 루카스였죠. 모두가 가난한 환경에서 자라났지만, 그들은 서로를 깊이 사랑하는 특별한 유대 관계를 형성했어요.\n\n하루, 마을에 한 노인이 나타났어요. 그 노인은 썩은 소나무 막대기를 들고 다니며 지쳐 보이더라구요. 형제들은 노인을 도와주기로 했어요. 그들은 함께 얘기를 나누고, 노인에게 식사와 숙소를 제공했어요.\n\n이야기를 나누는 동안, 노인은 금지된 섬의 보물이 있는 곳을 가리키며 이야기를 풀어냈어요. 형제들은 노인을 따라가기로 결심했고, 어려운 여정을 통해 함께 고난과 역경을 극복하며 결국 보물을 찾아냈어요.\n\n그들은 이 경험을 통해 서로의 용기, 협력, 그리고 신뢰를 배웠어요. 이들은 함께한 경험이 더 이상 그들을 나눌 수 없는 특별한 유대 관계를 형성하는 데 도움이 되었죠. 이제 형제들은 당신의 도움이 주변에 필요한 이웃을 발견하고 노인처럼 따뜻한 마음으로 도와줄 준비가 되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-TransformerArchitectureexplained_2.png)\n\n# 토큰화\n\n토큰화는 가장 기본적인 단계입니다. 단어, 구두점 등을 포함한 토큰 데이터 세트로 이루어져 있습니다. 토큰화 단계는 각 단어, 접두사, 접미사, 구두점을 포함하여 해당 라이브러리의 알려진 토큰으로 보냅니다.\n\n![이미지](/assets/img/2024-06-23-TransformerArchitectureexplained_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 포함\n\n입력이 토큰화되면 단어를 숫자로 변환해야 합니다. 이를 위해 임베딩을 사용합니다. 이전 장에서 텍스트 임베딩이 모든 텍스트를 숫자 목록으로 변환한다는 것을 배웠습니다. 두 개의 텍스트가 유사하면 해당 벡터의 숫자도 서로 유사합니다(요소별로, 즉 동일한 위치의 각 숫자 쌍이 유사함을 의미). 그렇지 않으면 두 개의 텍스트가 다르면 해당 벡터의 숫자도 다릅니다.\n\n![transformer](/assets/img/2024-06-23-TransformerArchitectureexplained_4.png)\n\n# 위치 인코딩\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문장의 각 토큰에 해당하는 벡터를 가지고 나면, 다음 단계는 이 모든 것을 하나의 벡터로 결합하는 것입니다. 여러 벡터를 하나의 벡터로 변환하는 가장 일반적인 방법은 각 요소를 더하는 것입니다. 즉, 각 좌표를 따로 더합니다. 예를 들어, 길이가 2인 벡터 [1,2]와 [3,4]가 있다면, 이에 해당하는 합은 [1+3, 2+4]로 [4, 6]이 됩니다. 이 방법은 작동할 수 있지만 한 가지 주의할 점이 있습니다. 덧셈은 교환법칙이 성립하므로, 숫자를 다른 순서로 더하더라도 동일한 결과를 얻을 수 있습니다. 이 경우 \"I'm not sad, I'm happy\"와 \"I'm not happy, I'm sad\"는 같은 결과 벡터를 얻게 됩니다. 이러한 경우는 바람직하지 않습니다. 그래서 두 문장에 대해 서로 다른 벡터를 얻기 위한 방법을 고안해야 합니다. 여러 방법이 있지만, 우리는 그 중 하나를 선택할 것입니다: 위치 인코딩(Positional Encoding). 위치 인코딩은 단어의 임베딩 벡터에 미리 정의된 벡터 시퀀스를 추가하는 것으로, 이를 통해 각 문장에 대해 고유한 벡터를 얻고 같은 단어가 다른 순서로 나타난 문장에는 서로 다른 벡터가 할당됩니다. 아래 예시에서 단어 \"Write\", \"a\", \"story\", \".\"에 해당하는 벡터가 각 단어의 위치 정보를 담고 있는 수정된 벡터로 변환됩니다. \"Write (1)\", \"a (2)\", \"story (3)\", \". (4)\"으로 레이블이 지정됩니다.\n\n![Transformer Architecture Explained](/assets/img/2024-06-23-TransformerArchitectureexplained_5.png)\n\n# 트랜스포머 블록\n\n지금까지의 내용을 요약해보겠습니다. 단어가 들어오면 토큰으로 변환되고(tokenization), 토큰화된 단어들은 숫자로 변환됩니다(임베딩), 그리고 순서가 고려됩니다(위치 인코딩). 이렇게 모델에 입력되는 각 토큰에 대해 하나의 벡터가 생성됩니다. 이제 다음 단계는 이 문장에서 다음 단어를 예측하는 것입니다. 이 작업은 실제로 매우 큰 신경망으로 수행되며, 해당 목표에 정확하게 훈련된 모델을 사용하여 이 문장에서 다음 단어를 예측합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n큰 신경망을 교육할 수는 있지만, 주요 단계인 주의 메커니즘을 추가함으로써 크게 개선할 수 있습니다. Attention is All you Need 논문에서 소개된 이 주의 메커니즘은 트랜스포머 모델의 주요 구성 요소 중 하나로, 그들이 잘 동작하는 이유 중 하나입니다. 주의는 이전 섹션에서 설명되었지만, 지금은 이것을 텍스트의 각 단어에 맥락을 추가하는 방법으로 상상해 보세요.\n\n주의 구성 요소는 피드포워드 신경망의 각 블록에 추가됩니다. 따라서 다음 단어를 예측하는 것을 목표로 하는 대형 피드포워드 신경망을 상상해보면, 여러 개의 작은 신경망 블록으로 구성된 것이라고 생각할 수 있습니다. 각 블록에 주의 구성 요소가 추가됩니다. 각 트랜스포머 구성 요소는 트랜스포머 블록이라고 불리고 주로 다음 두 가지 구성 요소로 형성됩니다:\n\n- 주의 구성 요소.\n- 피드포워드 구성 요소.\n\n![image](/assets/img/2024-06-23-TransformerArchitectureexplained_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 주의\n\n다음 단계는 주의입니다.  어텐션 메커니즘은 매우 중요한 문제, 즉 문맥의 문제를 다룹니다. 가끔은 동일한 단어라고 하더라도 다른 의미로 사용될 수 있습니다. 이것은 임베딩이 단어를 벡터로 보내기만 하고 사용 중인 단어의 정의가 무엇인지 알지 못하기 때문에 언어 모델을 혼란스럽게 만듭니다.\n\n어텐션이라는 기술은 언어 모델이 문맥을 이해하는 데 도움이 되는 매우 유용한 기술입니다. 어텐션이 어떻게 작동하는지 이해하기 위해 다음 두 문장을 살펴보겠습니다:\n\n- 문장 1: 강의 둑.\n- 문장 2: 은행에 있는 돈.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! '은행'이라는 단어가 두 번 나오지만 다른 의미를 갖고 있음을 알 수 있습니다. 제1문장에서는 강가의 땅을 가리키고, 두 번째 문장에서는 돈을 보관하는 기관을 가리키고 있죠. 컴퓨터는 이를 모르기 때문에 이 지식을 주입해야 합니다. 그럼 무엇이 도움이 될까요? 문장 안의 다른 단어들이 우리 구조에 도움이 될 수 있습니다. 첫 번째 문장에서는 'the'나 'of'는 도움이 되지 않지만, 'river'라는 단어는 강가의 땅을 언급하고 있음을 알려줍니다. 마찬가지로, 두 번째 문장에서는 'money'라는 단어가 우리에게 돈을 보관하는 기관을 가리킨다는 것을 이해할 수 있게 해줍니다.\n\n요약하자면, 어텐션은 문장(또는 텍스트 조각) 안의 단어들을 단어 임베딩에서 가깝게 이동시키는 역할을 합니다. 이렇게 하면 \"은행에 돈\"이라는 문장에서 \"은행\"이 \"돈\"이라는 단어와 가까워집니다. 마찬가지로, \"강가의 은행\"이라는 문장에서 \"은행\"은 \"강\"이라는 단어와 가까워집니다. 이렇게 두 문장 각각의 수정된 \"은행\"은 주변 단어의 일부 정보를 함께 전달하여 맥락을 추가합니다.\n\n트랜스포머 모델에서 사용되는 어텐션 단계는 실제로 훨씬 강력하며, 멀티헤드 어텐션이라고 불립니다. 멀티헤드 어텐션에서는 여러 다른 임베딩이 사용되어 벡터를 수정하고 맥락을 추가합니다. 멀티헤드 어텐션은 언어 모델이 텍스트를 처리하고 생성할 때 효과적인 수준으로 도달하도록 도와주었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 소프트맥스 레이어\n\n이제 여러 개의 변형 블록으로 구성된 변압기 계층들이 형성됨을 알게 되었으니, 각각이 주의 및 피드포워드 레이어를 포함하는 많은 계층의 변압기를 문장에서 다음 단어를 예측하는 대규모 신경망으로 생각할 수 있습니다. 변압기는 모든 단어에 대한 점수를 출력하며, 문장에서 다음으로 가장 가능성이 높은 단어들에 가장 높은 점수를 부여합니다.\n\n변압기의 마지막 단계는 소프트맥스 레이어로, 이 점수를 확률로 변환(합이 1이 되는)하여 가장 높은 점수가 가장 높은 확률에 해당하도록 합니다. 그런 다음 이러한 확률 중에서 다음 단어를 샘플링할 수 있습니다. 아래 예시에서 변압기는 \"Once\"에 0.5의 가장 높은 확률을 부여하고 \"Somewhere\"에는 0.3, \"There\"에는 0.2의 확률을 부여합니다. 한 번 샘플링하면 단어 \"once\"가 선택되어 변압기의 출력이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자 이제 뭐 할까요? 우리는 단계를 반복해요. 이제 텍스트 \"한 이야기를 써보세요. 한 번\"을 모델에 입력하면, 아마도 출력은 \"upon\"이 될 거에요. 이 단계를 계속 반복하면, 변환기는 \"한 번에 어느 날, ... 이었어요.\"와 같은 이야기를 쓰게 될 거에요.\n\n## 훈련 후\n\n이제 변환기가 어떻게 작동하는지 알았으니, 아직 해야 할 일이 있어요. 다음을 상상해보세요. 변환기에게 \"알제리의 수도는 무엇인가요?\"라고 물어봤을 때, \"알제\"라고 대답하고 넘어가길 원할 거에요. 그러나 변환기는 전체 인터넷으로 훈련받았어요. 인터넷은 큰 공간이고, 그것이 반드시 최선의 질문/답변 저장소라는 보장은 없어요. 예를 들어 많은 페이지가 답변이 없는 질문 목록을 갖고 있을 수 있어요. 이 경우 \"알제리의 수도는 무엇인가요?\" 다음 문장에는 \"알제리의 인구는 어떻게 되나요?\"나 \"부르키나파소의 수도는 무엇인가요?\"와 같은 다른 질문이 나올 수 있어요. 변환기는 자신의 응답을 고려하는 인간이 아니에요, 단지 인터넷(또는 제공된 데이터셋)에서 본 것을 모방할 뿐이에요. 그렇다면 변환기에게 질문에 대답하게 하려면 어떻게 해야 할까요?\n\n답은 후훈련(post-training)에 있어요. 사람에게 특정 작업을 가르치듯이, 변환기에게도 작업을 수행하도록 시킬 수 있어요. 변환기가 전체 인터넷에 훈련을 받은 후, 많은 질문과 그에 해당하는 답변의 대형 데이터셋으로 다시 훈련받아요. 변환기(사람과도 같이)는 학습한 마지막 것에 편향을 가지기 때문에 후훈련은 변환기가 요청받은 작업들에 성공하는 데 매우 유용한 단계로 입증되었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n포스트 트레이닝은 많은 다른 작업에도 도움이 됩니다. 예를 들어, 대화 데이터셋을 사용하여 트랜스포머를 포스트 트레이닝하면 챗봇으로 잘 작동하도록 돕거나, 이야기, 시, 코드를 작성하는 데 도움을 줄 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-23-TransformerArchitectureexplained_0.png"},"coverImage":"/assets/img/2024-06-23-TransformerArchitectureexplained_0.png","tag":["Tech"],"readingTime":8},{"title":"텍스트 임베딩 종합 가이드 2024 최신","description":"","date":"2024-06-23 19:53","slug":"2024-06-23-TextEmbeddingsComprehensiveGuide","content":"\n\n## 텍스트 임베딩의 진화, 시각화, 그리고 응용\n\n우리 인간은 텍스트를 읽고 이해할 수 있습니다 (적어도 일부분은요). 컴퓨터는 반대로 \"숫자로 생각\"하기 때문에 단어와 문장의 의미를 자동으로 파악할 수 없습니다. 만약 우리가 컴퓨터가 자연어를 이해하도록 하려면, 이 정보를 컴퓨터가 작업할 수 있는 형식인 숫자 벡터로 변환해야 합니다.\n\n수십 년 전에 사람들은 텍스트를 기계가 이해할 수 있는 형식으로 변환하는 방법을 배웠습니다 (그 중 하나는 ASCII였습니다). 이러한 방식은 텍스트를 렌더링하고 전송하는 데 도움이 되지만 단어의 의미를 부호화하지는 않습니다. 당시에는 키워드 검색 기술이 표준 검색 기술이었으며 특정 단어나 N-gram을 포함하는 모든 문서를 찾는 방식이었습니다.\n\n그 후 몇 10년이 지난 후, 임베딩이 등장했습니다. 우리는 단어, 문장, 심지어 이미지에 대한 임베딩을 계산할 수 있습니다. 임베딩도 숫자의 벡터입니다만, 의미를 포착할 수 있습니다. 그래서 의미 검색을 수행하거나 다양한 언어로 된 문서를 다루는 데 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글에서는 임베딩 주제를 깊이 있게 다루어보고자 합니다:\n\n- 임베딩이 만들어지기 전의 역사와 진화에 대해,\n- OpenAI 도구를 사용하여 임베딩을 계산하는 방법,\n- 문장이 서로 가까운지 판단하는 방법,\n- 임베딩을 시각화하는 방법,\n- 가장 흥미로운 부분은 임베딩을 실제로 활용하는 방법입니다.\n\n이어서 나아가서 임베딩의 진화에 대해 배워보겠습니다.\n\n# 임베딩의 진화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 텍스트 표현의 역사로 간단한 여행을 시작할 것입니다.\n\n## 단어 가방\n\n텍스트를 벡터로 변환하는 가장 기본적인 방법은 단어 가방입니다. 리처드 P. 페이만의 유명한 명언 중 하나를 살펴보겠습니다. \"우리는 아직 발견들을 만들어내는 시대에 살고 있다\". 이를 통해 단어 가방 접근법을 설명해보겠습니다.\n\n단어 가방 벡터를 얻는 첫 번째 단계는 텍스트를 단어(토큰)로 나눈 다음, 단어를 기본 형태로 줄이는 것입니다. 예를 들어, \"running\"은 \"run\"으로 변환됩니다. 이 과정을 어간 추출(stemming)이라고 합니다. NLTK Python 패키지를 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nfrom nltk.stem import SnowballStemmer\nfrom nltk.tokenize import word_tokenize\n\ntext = 'We are lucky to live in an age in which we are still making discoveries'\n\n# 토큰화 - 텍스트를 단어로 나누기\nwords = word_tokenize(text)\nprint(words)\n# ['We', 'are', 'lucky', 'to', 'live', 'in', 'an', 'age', 'in', 'which',\n#  'we', 'are', 'still', 'making', 'discoveries']\n\nstemmer = SnowballStemmer(language=\"english\")\nstemmed_words = list(map(lambda x: stemmer.stem(x), words))\nprint(stemmed_words)\n# ['we', 'are', 'lucki', 'to', 'live', 'in', 'an', 'age', 'in', 'which',\n#  'we', 'are', 'still', 'make', 'discoveri']\r\n```\n\n자, 이제 우리 단어들의 기본 형태 리스트가 있습니다. 다음 단계는 이들 빈도를 계산하여 벡터를 만드는 것입니다.\n\n```js\r\nimport collections\nbag_of_words = collections.Counter(stemmed_words)\nprint(bag_of_words)\n# {'we': 2, 'are': 2, 'in': 2, 'lucki': 1, 'to': 1, 'live': 1, \n# 'an': 1, 'age': 1, 'which': 1, 'still': 1, 'make': 1, 'discoveri': 1}\r\n```\n\n사실, 만약 텍스트를 벡터로 변환하고 싶다면, 텍스트에 있는 단어뿐만 아니라 전체 어휘를 고려해야 합니다. \"i\", \"you\", \"study\"도 어휘에 있다고 가정하고, 파인만의 명언에서 벡터를 만들어 봅시다.\r\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_0.png)\n\n이 방법은 꽤 기본적이며 단어의 의미를 고려하지 않기 때문에 \"그 여자는 데이터 과학을 공부하고 있다\"와 \"젊은 여성이 AI와 ML을 배우고 있다.\"라는 문장이 서로 가까운 위치에 있지 않을 수 있습니다.\n\n## TF-IDF\n\n단어 가방 접근법의 약간 개선된 버전인 TF-IDF(Term Frequency — Inverse Document Frequency)입니다. 이것은 두 가지 지표의 곱셈입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Markdown Table](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_1.png)\n\n- 용어 빈도는 문서에서 단어의 빈도를 보여줍니다. 이를 계산하는 가장 흔한 방법은 이 문서에서 용어의 로우 카운트(단어 가방에 있는 것처럼)을 전체 용어(단어) 수로 나누는 것입니다. 그러나 로우 카운트, 부욜리언 \"빈도\", 정규화에 대한 다양한 접근 방법이 많이 있습니다. 위키피디아에서 다양한 접근 방법에 대해 더 배울 수 있습니다.\n\n![Markdown Table](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_2.png)\n\n- 역문서 주파수는 단어가 얼마나 많은 정보를 제공하는지를 나타냅니다. 예를 들어, \"a\"나 \"that\" 같은 단어는 문서 주제에 대해 추가 정보를 제공하지 않습니다. 대조적으로, \"ChatGPT\"나 \"생물정보학\" 같은 단어는 도메인을 정의하는 데 도움이 될 수 있습니다 (하지만 이 문장에는 해당하지 않음). 이는 전체 문서 수와 해당 단어를 포함하는 문서 수의 비율의 로그함수로 계산됩니다. IDF가 0에 가까울수록 단어가 흔하고 제공하는 정보가 더 적습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_3.png\" /\u003e\n\n그래서 결과적으로 우리는 일반적인 단어 (\"I\"나 \"you\"와 같은)이 낮은 가중치를 갖는 벡터를 얻게됩니다. 한편, 문서에서 여러 번 발생하는 드문 단어들은 더 높은 가중치를 갖게 됩니다. 이 전략은 약간 더 나은 결과를 제공하지만 여전히 의미적 의미를 잡아내기는 어렵습니다.\n\n이 방법론의 다른 어려움은 상당히 희소한 벡터를 생성한다는 점입니다. 벡터의 길이는 말뭉치 크기와 동일합니다. 영어에는 약 470,000개의 고유 단어가 있습니다(출처). 그러므로 우리는 거대한 벡터를 갖게 될 것입니다. 하지만 문장에는 50개 이상의 고유 단어가 나타나지 않을 것이므로 벡터의 값 중 99.99%는 0일 것입니다. 이는 어떤 정보도 인코딩하지 않습니다. 이에 대해 과학자들은 밀도 있는 벡터 표현에 대해 고민하기 시작했습니다.\n\n## Word2Vec\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장 유명한 밀집 표현 방법 중 하나는 구글이 2013년에 Mikolov 등이 제안한 \"효율적인 단어 표현 추정을 위한 Word2Vec\" 논문에서 소개한 word2vec입니다.\n\n논문에서 언급된 두 가지 word2vec 접근 방식은 Continuous Bag of Words(주변 단어를 기반으로 단어를 예측하는 방법)와 Skip-gram(반대 작업인 단어를 기반으로 문맥을 예측하는 방법)입니다.\n\n밀집 벡터 표현의 핵심 아이디어는 두 모델을 훈련하는 것입니다: 인코더와 디코더. 예를 들어, Skip-gram의 경우 \"christmas\"라는 단어를 인코더에 전달할 수 있습니다. 그런 다음, 인코더가 \"merry\", \"to\", \"you\"와 같은 단어를 얻을 것으로 예상하여 디코더에 전달할 수 있는 벡터를 생성할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_5.png)\n\n이 모델은 이제 단어의 의미를 고려하기 시작했습니다. 단어의 맥락에서 훈련되었기 때문입니다. 그러나 형태학(예: \"-less\"는 무언가의 부족을 의미함)을 무시합니다. 나중에는 GloVe에서 서브워드 스킵-그램을 살펴봄으로써 이 단점을 개선했습니다.\n\n또한, word2vec은 단어와만 작동할 수 있었지만, 우리는 전체 문장을 인코딩하고 싶습니다. 그러니, 트랜스포머로 다음 진화 단계로 넘어가 봅시다.\n\n## 트랜스포머와 문장 임베딩\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 진화는 Vaswani 등이 발표한 \"Attention Is All You Need\" 논문에서 소개된 트랜스포머 접근 방식과 관련이 있었습니다. 트랜스포머는 정보가 풍부한 밀집 벡터를 생성할 수 있었고 현대 언어 모델의 주요 기술로 자리 잡게 되었습니다.\n\n저는 트랜스포머의 구조 세부 사항에 대해 다루지 않겠습니다. 왜냐하면 이것은 우리 주제와 관련이 그리 크지 않고 많은 시간이 소요되기 때문입니다. 더 배우고 싶다면 \"Transformers, Explained\" 또는 \"The Illustrated Transformer\"와 같은 다양한 자료가 많이 있습니다.\n\n트랜스포머를 사용하면 동일한 \"핵심\" 모델을 사용하여 다른 사용 사례에 대해 미세 조정할 수 있으며, 핵심 모델을 다시 학습시킬 필요가 없습니다(시간이 많이 소요되고 상당한 비용이 듭니다). 이것은 사전 훈련된 모델의 등장으로 이어졌습니다. 가장 인기 있는 최초의 모델 중 하나는 Google AI가 개발한 BERT(Bidirectional Encoder Representations from Transformers)였습니다.\n\n내부적으로 BERT는 여전히 word2vec과 유사한 토큰 수준에서 작동하지만, 우리는 여전히 문장 임베딩을 얻고 싶습니다. 따라서, 모든 토큰 벡터의 평균을 취하는 단순한 방법을 적용할 수 있습니다. 유감스럽게도, 이 방법은 좋은 성능을 보여주지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2019년에 이 문제는 Sentence-BERT가 출시되면서 해결되었습니다. 이는 의미론적 텍스트 유사성 작업에서 이전 방법들을 모두 능가하며 문장 포함 벡터의 계산을 가능하게 했습니다.\n\n이 주제는 매우 방대하기 때문에 이 기사에서 모두 다 다룰 수는 없을 거예요. 그러니 진지하게 관심이 있다면 이 기사에서 문장 포함 벡터에 대해 더 배울 수 있습니다.\n\n우리는 임베딩의 발전을 간략히 다뤘고 이론에 대한 고수준 이해를 얻었습니다. 이제 실습으로 넘어가서 OpenAI 도구를 사용하여 어떻게 임베딩을 계산하는지 배워보겠습니다.\n\n# 임베딩 계산\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 OpenAI 임베딩을 사용할 것입니다. 최근에 출시된 새로운 모델인 text-embedding-3-small을 시도해볼 것입니다. 이 새로운 모델은 text-embedding-ada-002보다 성능이 더 좋게 나타났습니다:\n\n- 널리 사용되는 다국어 검색 (MIRACL) 벤치마크의 평균 점수가 31.4%에서 44.0%로 상승했습니다.\n- 영어 작업에 대한 자주 사용되는 벤치마크인 MTEB의 평균 성능도 향상되어 61.0%에서 62.3%로 상승했습니다.\n\nOpenAI는 또한 새로운 큰 모델인 text-embedding-3-large를 출시했습니다. 이제 이것이 가장 우수한 임베딩 모델입니다.\n\n데이터 소스로는 Stack Exchange Data Dump의 작은 샘플을 사용할 것입니다. 이는 Stack Exchange 네트워크에서 모든 사용자 기여 콘텐츠의 익명화된 덤프입니다. 저는 흥미로운 주제를 선택하고 각각에서 100개의 질문을 샘플링했습니다. 주제는 생성적 AI부터 커피 또는 자전거까지 다양합니다. 그래서 다양한 주제를 볼 수 있을 겁니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 모든 스택 오버플로우 질문에 대한 임베딩을 계산해야 합니다. 한 번 실행하고 결과를 로컬로 저장하는 것이 좋습니다(파일이나 벡터 저장소에). OpenAI Python 패키지를 사용하여 임베딩을 생성할 수 있습니다.\n\n```python\nfrom openai import OpenAI\nclient = OpenAI()\n\ndef get_embedding(text, model=\"text-embedding-3-small\"):\n   text = text.replace(\"\\n\", \" \")\n   return client.embeddings.create(input = [text], model=model)\\\n       .data[0].embedding\n\nget_embedding(\"We are lucky to live in an age in which we are still making discoveries.\")\n```\n\n결과적으로, 우리는 부동 소수점 숫자로 이루어진 1536차원 벡터를 얻습니다. 이제 이를 모든 데이터에 대해 반복하고 값을 분석할 수 있습니다.\n\n가장 궁금할 수 있는 주요 질문은 의미적으로 문장들이 얼마나 가까운지입니다. 답을 발견하기 위해 벡터 간의 거리 개념을 논의해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 벡터 간 거리\n\n임베딩은 사실 벡터입니다. 따라서 두 문장이 얼마나 가까운지 이해하려면 벡터 간 거리를 계산할 수 있습니다. 더 작은 거리는 더 가까운 의미를 나타낼 것입니다.\n\n두 벡터 간의 거리를 측정하는 데 사용할 수 있는 다양한 메트릭이 있습니다:\n\n- 유클리디안 거리 (L2),\n- 맨하탄 거리 (L1),\n- 내적 (Dot product),\n- 코사인 거리.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그들에 대해 이야기해 봅시다. 간단한 예로, 우리는 두 개의 2D 벡터를 사용할 것입니다.\n\n```js\nvector1 = [1, 4]\nvector2 = [2, 2]\n```\n\n## 유클리디안 거리 (L2)\n\n두 지점(또는 벡터) 사이의 거리를 정의하는 가장 표준적인 방법은 유클리디안 거리 또는 L2 norm입니다. 이 측정 기준은 일상생활에서 가장 많이 사용되며, 예를 들어 2개의 도시 사이의 거리를 언급할 때 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nL2 거리에 대한 시각적 표현과 공식이 있습니다.\n\n![Image](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_6.png)\n\n파이썬 또는 numpy 함수를 사용하여 이 메트릭을 계산할 수 있습니다.\n\n```python\nimport numpy as np\n\nsum(list(map(lambda x, y: (x - y) ** 2, vector1, vector2))) ** 0.5\n# 2.2361\n\nnp.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 2)\n# 2.2361\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 맨해튼 거리 (L1)\n\n다른 일반적으로 사용되는 거리 측정 방법은 L1 노름 또는 맨해튼 거리입니다. 이 거리는 뉴욕의 맨해튼 섬에서 명명되었습니다. 이 섬은 거리가 격자 레이아웃으로 되어 있고, 맨해튼에서 두 지점 사이의 가장 짧은 경로는 격자 모양을 따라야 하므로 L1 거리가 됩니다.\n\n![image](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_7.png)\n\n우리는 이를 처음부터 구현하거나 numpy 함수를 사용하여 구현할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nsum(list(map(lambda x, y: abs(x - y), vector1, vector2)))\r\n# 3\r\n\r\nnp.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 1)\r\n# 3.0\r\n```\r\n\r\n## 내적(Dot product)\r\n\r\n벡터 간 거리를 계산하는 다른 방법은 내적 또는 스칼라 곱을 계산하는 것입니다. 다음은 해당 공식이며 쉽게 구현할 수 있습니다.\r\n\r\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_8.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nsum(list(map(lambda x, y: x*y, vector1, vector2)))\n# 11\n\nnp.dot(vector1, vector2)\n# 11\n```\n\n이 메트릭은 해석하기가 조금 까다로운 편이에요. 한편으로는 벡터가 한 방향을 향하고 있는지를 보여줍니다. 다른 한편으로는 결과는 벡터들의 크기에 크게 의존합니다. 예를 들어 두 쌍의 벡터 간의 내적을 계산해볼게요:\n\n- (1, 1) vs (1, 1)\n- (1, 1) vs (10, 10).\n\n두 경우 모두 벡터가 일직선상에 있지만, 두 번째 경우에 내적은 10배 크게 나와요: 2 대 20.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 코사인 유사도\n\n많은 경우, 코사인 유사도가 사용됩니다. 코사인 유사도는 벡터의 크기(또는 노름)에 의해 정규화된 내적입니다.\n\n![Image](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_9.png)\n\n이전처럼 직접 모든 것을 계산하거나 sklearn의 함수를 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndot_product = sum(list(map(lambda x, y: x*y, vector1, vector2)))\nnorm_vector1 = sum(list(map(lambda x: x ** 2, vector1))) ** 0.5\nnorm_vector2 = sum(list(map(lambda x: x ** 2, vector2))) ** 0.5\n\ndot_product/norm_vector1/norm_vector2\n\n# 0.8575\n\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ncosine_similarity(\n  np.array(vector1).reshape(1, -1), \n  np.array(vector2).reshape(1, -1))[0][0]\n\n# 0.8575\n```\n\ncosine_similarity 함수는 2차원 배열을 기대합니다. 그래서 numpy 배열을 reshape 해주어야 합니다.\n\n이 메트릭의 물리적 의미에 대해 조금 이야기해 봅시다. Cosine similarity는 두 벡터 사이의 코사인 값과 같습니다. 벡터가 서로 가까울수록 메트릭 값이 높아집니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_10.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 심지어 벡터 사이의 정확한 각도를 도 단위로 계산할 수도 있어요. 약 30도 정도의 결과를 얻었고, 꽤 합리적으로 보이네요.\n\n```js\nimport math\nmath.degrees(math.acos(0.8575))\n\n# 30.96\n```\n\n## 어떤 측정 지표를 사용할까요?\n\n우리는 두 벡터 사이의 거리를 계산하는 다양한 방법에 대해 토론해 왔고, 여러분은 어떤 방법을 사용할지 고려하기 시작할 수 있을 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내가 가진 임베딩을 비교하기 위해 어떤 거리든 사용할 수 있어요. 예를 들어, 다른 클러스터 사이의 평균 거리를 계산했어요. L2 거리와 코사인 유사도 모두 비슷한 결과를 보여줘요:\n\n- 클러스터 내의 객체들은 다른 클러스터보다 서로 더 가까워요. L2 거리에 대해 가까울수록 낮은 거리를 의미하지만 코사인 유사도에서는 가까운 객체일수록 값이 높아져요. 헷갈리지 마세요.\n- \"정치\"와 \"경제\" 또는 \"ai\"와 \"데이터과학\"과 같이 일부 주제들이 서로 아주 가까운 것을 알 수 있어요.\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_11.png\" /\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_12.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 NLP 작업에 대해서는 일반적으로 코사인 유사도를 사용하는 것이 최선의 방법입니다. 몇 가지 그 이유는:\n\n- 코사인 유사도는 -1과 1 사이에 있으며, L1과 L2는 무제한이기 때문에 해석하기 쉽습니다.\n- 실용적인 측면에서 유클리드 거리의 제곱근보다 내적을 계산하는 것이 더 효과적입니다.\n- 코사인 유사도는 차원의 저주에 영향을 덜 받습니다 (이에 대해 뒤에서 더 얘기할 것입니다).\n\n위의 결과에서 인트라 및 인터 클러스터 거리 간의 차이가 크지 않다는 점을 알 수 있을 것입니다. 이 현상의 원인은 벡터의 고차원성 때문입니다. 이 효과는 \"차원의 저주\"라고 불리며, 차원이 높을수록 벡터 간 거리 분포가 좁아진다는 것을 알 수 있습니다. 이에 대해 더 자세히 알아보려면 이 글을 참조해보세요.\n\n간단히 설명드리겠습니다. OpenAI 임베딩 값의 분포를 계산하고 차원이 다른 300개의 벡터 집합을 생성했습니다. 그런 다음, 모든 벡터 사이의 거리를 계산하고 히스토그램을 그렸습니다. 차원이 증가함에 따라 벡터의 거리 분포가 좁아진다는 것을 쉽게 확인할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_13.png)\n\n임베딩 사이의 유사성을 측정하는 방법을 배웠어요. 여기서 이론적인 부분은 마쳤고, 더 실용적인 부분(시각화 및 실용적인 응용)으로 넘어가겠습니다. 데이터를 보는 것이 가장 중요하니, 시각화부터 시작해봐요.\n\n# 임베딩 시각화\n\n데이터를 이해하는 가장 좋은 방법은 시각적으로 나타내는 것이에요. 아쉽지만, 임베딩은 1536차원이 있어서 데이터를 살펴보기가 꽤 어려워요. 그러나, 한 가지 방법이 있어요: 차원 축소 기술을 사용하여 벡터를 이차원 공간에 투영하는 것이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## PCA\n\n가장 기본적인 차원 축소 기술은 PCA(주성분 분석)입니다. 이를 사용해 봅시다.\n\n먼저, sklearn에 전달하기 위해 임베딩을 2D numpy 배열로 변환해야 합니다.\n\n```python\nimport numpy as np\nembeddings_array = np.array(df.embedding.values.tolist())\nprint(embeddings_array.shape)\n# (1400, 1536)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼, 우리는 PCA 모델을 n_components = 2로 초기화해야 해요 (2D 시각화를 생성하고 싶기 때문에), 전체 데이터에서 모델을 학습하고 새로운 값을 예측해야 해요.\n\n```js\nfrom sklearn.decomposition import PCA\n\npca_model = PCA(n_components = 2)\npca_model.fit(embeddings_array)\n\npca_embeddings_values = pca_model.transform(embeddings_array)\nprint(pca_embeddings_values.shape)\n# (1400, 2)\n```\n\n결과적으로, 우리는 각 질문에 대해 두 개의 특성을 가진 행렬을 얻었으므로, scatter plot에서 쉽게 시각화할 수 있어요.\n\n```js\nfig = px.scatter(\n    x = pca_embeddings_values[:,0], \n    y = pca_embeddings_values[:,1],\n    color = df.topic.values,\n    hover_name = df.full_text.values,\n    title = 'PCA embeddings', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n)\n\nfig.update_layout(\n    xaxis_title = 'first component', \n    yaxis_title = 'second component')\nfig.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![img](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_14.png)\n\n각 주제의 질문들이 서로 꽤 가까이 위치해 있는 것을 볼 수 있어 좋습니다. 그러나 모든 클러스터가 혼재되어 있어서 개선할 부분이 있습니다.\n\n## t-SNE\n\nPCA는 선형 알고리즘이지만, 대부분의 관계는 실제로는 비선형입니다. 그래서 비선형성 때문에 클러스터를 분리할 수 없을 수도 있습니다. 비선형 알고리즘인 t-SNE을 사용해보고 더 나은 결과를 보여줄 수 있는지 확인해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n거의 동일한 코드를 사용했습니다. PCA 대신 t-SNE 모델을 사용했어요.\n\n```js\nfrom sklearn.manifold import TSNE\ntsne_model = TSNE(n_components=2, random_state=42)\ntsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\n\nfig = px.scatter(\n    x = tsne_embeddings_values[:,0], \n    y = tsne_embeddings_values[:,1],\n    color = df.topic.values,\n    hover_name = df.full_text.values,\n    title = 't-SNE embeddings', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n)\n\nfig.update_layout(\n    xaxis_title = 'first component', \n    yaxis_title = 'second component')\nfig.show()\n```\n\nt-SNE 결과가 훨씬 좋아 보여요. 대부분의 클러스터가 분리되어 있지만 \"genai\", \"datascience\", \"ai\" 는 분리되지 않았어요. 그러나 이건 예상한대로에요 - 이러한 주제를 내가 분리할 수 있을지 의심스러워요.\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_15.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 시각화를 보면 임베딩이 의미적 의미를 인코딩하는 데 상당히 효과적임을 확인할 수 있어요.\n\n또한, 데이터를 3D로 시각화할 수 있는 사영(projection)을 만들어볼 수 있어요. 실용적일지는 확실하지 않지만, 데이터를 3D로 살펴보는 것은 흥미롭고 관심을 끌 수 있어요.\n\n```js\ntsne_model_3d = TSNE(n_components=3, random_state=42)\ntsne_3d_embeddings_values = tsne_model_3d.fit_transform(embeddings_array)\n\nfig = px.scatter_3d(\n    x = tsne_3d_embeddings_values[:,0], \n    y = tsne_3d_embeddings_values[:,1],\n    z = tsne_3d_embeddings_values[:,2],\n    color = df.topic.values,\n    hover_name = df.full_text.values,\n    title = 't-SNE embeddings', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r,\n    opacity = 0.7\n)\nfig.update_layout(xaxis_title = 'first component', yaxis_title = 'second component')\nfig.show()\n```\n\n![3D 시각화](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_16.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 바코드\n\n임베딩을 이해하는 방법은 몇 개를 바코드처럼 시각화하여 상관 관계를 확인하는 것입니다. 나는 세 가지 임베딩 예시를 선택했습니다: 두 개는 서로에게 가장 가깝고, 나머지 하나는 데이터 세트에서 가장 멀리 떨어져 있는 예시입니다.\n\n```js\nembedding1 = df.loc[1].embedding\nembedding2 = df.loc[616].embedding\nembedding3 = df.loc[749].embedding\n```\n\n```js\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nembed_len_thr = 1536\n\nsns.heatmap(np.array(embedding1[:embed_len_thr]).reshape(-1, embed_len_thr),\n    cmap = \"Greys\", center = 0, square = False, \n    xticklabels = False, cbar = False)\nplt.gcf().set_size_inches(15,1)\nplt.yticks([0.5], labels = ['AI'])\nplt.show()\n\nsns.heatmap(np.array(embedding3[:embed_len_thr]).reshape(-1, embed_len_thr),\n    cmap = \"Greys\", center = 0, square = False, \n    xticklabels = False, cbar = False)\nplt.gcf().set_size_inches(15,1)\nplt.yticks([0.5], labels = ['AI'])\nplt.show()\n\nsns.heatmap(np.array(embedding2[:embed_len_thr]).reshape(-1, embed_len_thr),\n    cmap = \"Greys\", center = 0, square = False, \n    xticklabels = False, cbar = False)\nplt.gcf().set_size_inches(15,1)\nplt.yticks([0.5], labels = ['바이오인포매틱스'])\nplt.show()\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_17.png)\n\n우리 경우에는 고차원 때문에 벡터가 서로 가까운지 쉽게 보기 어려울 수 있습니다. 그래도 나는 이 시각화를 좋아합니다. 몇 가지 경우에 도움이 될 수도 있으니, 나는 이 아이디어를 당신과 공유하고자 합니다.\n\n우리는 임베딩을 시각화하는 방법을 배웠고, 텍스트의 의미를 파악하는 능력에 대한 의문은 남지 않았습니다. 이제 실제로 임베딩을 어떻게 활용할 수 있는지에 대해 논의하는 가장 흥미로운 부분으로 넘어가 보겠습니다.\n\n# 실용적인 응용\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n물론, 임베딩의 주요 목표는 텍스트를 숫자의 벡터로 인코딩하거나 시각화하기 위해서만 하는 것이 아닙니다. 우리는 텍스트의 의미를 포착하는 능력에서 많은 이점을 얻을 수 있습니다. 실용적인 예제들을 함께 살펴보겠습니다.\n\n## 클러스터링\n\n먼저 클러스터링부터 시작해보죠. 클러스터링은 초기 레이블 없이 데이터를 그룹으로 분할할 수 있는 비지도학습 기술입니다. 클러스터링을 통해 데이터의 내부 구조적 패턴을 이해하는 데 도움을 받을 수 있습니다.\n\n가장 기본적인 클러스터링 알고리즘 중 하나인 K-평균을 사용할 것입니다. K-평균 알고리즘을 위해서는 클러스터의 개수를 지정해야 합니다. 실루엣 스코어를 사용하여 최적의 클러스터 수를 정의할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2부터 50까지의 k (클러스터 수)를 시도해 보겠습니다. 각 k에 대해 모델을 훈련하고 실루엣 점수를 계산할 것입니다. 실루엣 점수가 높을수록, 더 좋은 클러스터링 결과를 얻을 수 있습니다.\n\n```python\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nimport tqdm\n\nsilhouette_scores = []\nfor k in tqdm.tqdm(range(2, 51)):\n    kmeans = KMeans(n_clusters=k, \n                    random_state=42, \n                    n_init='auto').fit(embeddings_array)\n    kmeans_labels = kmeans.labels_\n    silhouette_scores.append(\n        {\n            'k': k,\n            'silhouette_score': silhouette_score(embeddings_array, \n                                                 kmeans_labels, metric='cosine')\n        }\n    )\n\nfig = px.line(pd.DataFrame(silhouette_scores).set_index('k'),\n              title='\u003cb\u003eK-means 클러스터링을 위한 실루엣 점수\u003c/b\u003e',\n              labels={'value': '실루엣 점수'}, \n              color_discrete_sequence=plotly.colors.qualitative.Alphabet)\nfig.update_layout(showlegend=False)\n```\n\n우리의 경우, k가 11일 때 실루엣 점수가 최대치에 도달합니다. 따라서 최종 모델에는 이 클러스터 수를 사용합시다.\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_18.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클러스터를 시각화해 보는 t-SNE를 이용한 차원 축소를 이미 이전에 수행한 것처럼 해보겠습니다.\n\n```js\ntsne_model = TSNE(n_components=2, random_state=42)\ntsne_embeddings_values = tsne_model.fit_transform(embeddings_array)\n\nfig = px.scatter(\n    x = tsne_embeddings_values[:,0], \n    y = tsne_embeddings_values[:,1],\n    color = list(map(lambda x: '클러스터 %s' % x, kmeans_labels)),\n    hover_name = df.full_text.values,\n    title = '클러스터링을 위한 t-SNE 임베딩', width = 800, height = 600,\n    color_discrete_sequence = plotly.colors.qualitative.Alphabet_r\n)\nfig.update_layout(\n    xaxis_title = '첫 번째 성분', \n    yaxis_title = '두 번째 성분')\nfig.show()\n```\n\n시각적으로 알고리즘이 클러스터를 상당히 잘 정의했음을 확인할 수 있습니다 — 그들은 꽤 잘 분리되어 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_19.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 사실적인 주제 라벨을 가지고 있으므로, 클러스터링이 얼마나 좋은지를 심층적으로 판단할 수도 있어요. 각 클러스터에 대한 주제 혼합을 살펴봅시다.\n\n```js\ndf['cluster'] = list(map(lambda x: '클러스터 %s' % x, kmeans_labels))\ncluster_stats_df = df.reset_index().pivot_table(\n    index='cluster', values='id',\n    aggfunc='count', columns='topic').fillna(0).applymap(int)\n\ncluster_stats_df = cluster_stats_df.apply(\n  lambda x: 100*x/cluster_stats_df.sum(axis=1))\n\nfig = px.imshow(\n    cluster_stats_df.values, \n    x=cluster_stats_df.columns,\n    y=cluster_stats_df.index,\n    text_auto='.2f', aspect=\"auto\",\n    labels=dict(x=\"클러스터\", y=\"팩트 주제\", color=\"비율, %\"),\n    color_continuous_scale='pubugn',\n    title='\u003cb\u003e각 클러스터의 주제 비율\u003c/b\u003e', height=550)\n\nfig.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_20.png\" /\u003e\n\n대부분의 경우, 클러스터링은 완벽하게 작동했어요. 예를 들어, 클러스터 5에는 거의 자전거에 관한 질문만 있고, 클러스터 6은 커피에 관한 것이에요. 그러나 유사한 주제를 구별하지 못했어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- \"ai,\" \"genai,\" and \"datascience\"은 동일한 클러스터에 있습니다.\n- \"economics\"와 \"politics\"은 같은 그룹에 속합니다.\n\n이 예제에서는 피처로써 임베딩만 사용했지만, 질문을 한 사용자의 나이, 성별 또는 국가와 같은 추가 정보가 있다면 모델에 포함시킬 수도 있습니다.\n\n## 분류\n\n임베딩을 분류 또는 회귀 작업에 사용할 수 있습니다. 예를 들어 고객 리뷰 감정을 예측하는 (분류)이나 NPS 점수를 예측하는 (회귀) 등 다양한 작업에 활용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n분류 및 회귀는 지도 학습이므로 레이블이 필요합니다. 다행히도, 우리는 질문의 주제를 알고 있으므로 모델을 적합시켜 예측할 수 있습니다.\n\n저는 랜덤 포레스트 분류기를 사용할 것입니다. 랜덤 포레스트에 대해 간단히 상기하고 싶다면 여기에서 확인할 수 있어요. 분류 모델의 성능을 올바르게 평가하려면 데이터 세트를 학습 및 테스트 세트(80% 대 20%)로 분할할 것입니다. 그런 다음 학습 데이터 세트에서 모델을 훈련하고 테스트 데이터 세트에서 품질을 측정할 수 있습니다(모델이 이전에 보지 못한 질문).\n\n```js\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nclass_model = RandomForestClassifier(max_depth = 10)\n\n# 특징 및 대상 정의\nX = embeddings_array\ny = df.topic\n\n# 데이터를 학습 및 테스트 세트로 분할\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, random_state = 42, test_size=0.2, stratify=y\n)\n\n# 적합 및 예측\nclass_model.fit(X_train, y_train)\ny_pred = class_model.predict(X_test)\n```\n\n모델의 성능을 추정하기 위해 혼동 행렬을 계산해 보겠습니다. 이상적인 상황에서는 비대각 요소가 모두 0이어야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\nfig = px.imshow(\n  cm, x = class_model.classes_,\n  y = class_model.classes_, text_auto='d', \n  aspect=\"auto\", \n  labels=dict(\n      x=\"predicted label\", y=\"true label\", \n      color=\"cases\"), \n  color_continuous_scale='pubugn',\n  title = '\u003cb\u003e혼동 행렬\u003c/b\u003e', height = 550)\n\nfig.show()\n```\n\n![이미지](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_21.png)\n\n군집화와 유사한 결과를 확인할 수 있습니다. 일부 주제는 쉽게 분류되고 정확도가 100%인 반면, 다른 주제들은 구별하기 어려운 경우도 있습니다(특히 \"ai\" 주제).\n\n하지만 전체적으로 91.8%의 정확도를 달성했으며, 이는 꽤 좋은 성과입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 이상 징후 찾기\n\n데이터에서 이상 징후를 찾기 위해 임베딩을 사용할 수도 있습니다. 예를 들어, t-SNE 그래프에서 \"여행\" 주제에 대한 몇 가지 질문이 군집에서 꽤 멀리 떨어져 있는 것을 볼 수 있었습니다. 이 테마를 살펴보고 이상 징후를 찾아보겠습니다. 이를 위해 이상 탐지 알고리즘인 Isolation Forest를 사용할 것입니다.\n\n```js\nfrom sklearn.ensemble import IsolationForest\n\ntopic_df = df[df.topic == 'travel']\ntopic_embeddings_array = np.array(topic_df.embedding.values.tolist())\n\nclf = IsolationForest(contamination=0.03, random_state=42)\ntopic_df['is_anomaly'] = clf.fit_predict(topic_embeddings_array)\n\ntopic_df[topic_df.is_anomaly == -1][['full_text']]\n```\n\n여기에서, 여행 주제에 대한 가장 흔하지 않은 댓글을 찾았습니다 (원본).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n로마 구역의 곳곳에 있는 분수에서 물을 마셔도 안전한가요?\n\n로마를 방문했을 때 오래된 지역을 거닐며 다양한 종류의 분수를 보았습니다. 물이 끊임없이 흘러나오는 분수들이 많았는데, 땅으로 흘러가는 분수도 있고, 대야에 모이는 분수도 있었습니다.\n\n이런 분수에서 나오는 물을 마셔도 괜찮을까요? 방문객이 마실 수 있는 안전한 물일까요? 분수 사용에 대한 방문자들이 알아야 할 예절이 있을까요?\n```\n\n물에 관한 이야기이기 때문에 이 주석의 기능은 사람들이 물을 따르는 커피 주제와 밀접하게 관련되어 있습니다. 그래서 이 주석의 삽입 표현은 커피 클러스터와 꽤 가까운 것으로 보입니다.\n\nt-SNE 시각화에서 찾아보면 실제로 커피 클러스터에 가까운 것을 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_22.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## RAG — 검색 증가 생성\n\n최근 LLM의 인기가 높아지면서, 임베딩이 RAG 사용 사례에서 널리 사용되고 있습니다.\n\n우리는 많은 문서가 있는 경우(예: 스택 오버플로우의 모든 질문)에 검색 증가 생성이 필요합니다. 그리고 모든 정보를 항상 LLM에 전달할 수 없기 때문에\n\n- LLM은 컨텍스트 크기에 제한이 있습니다(현재 GPT-4 Turbo의 경우 128K입니다).\n- 우리는 토큰을 구매해야 하므로 모든 정보를 항상 전달하는 것이 더 비십니다.\n- LLM은 더 큰 컨텍스트에서 성능이 떨어집니다. 자세한 내용은 \"바늘 찾기\" - LLM의 압력 테스트를 확인할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대규모 지식 베이스와 함께 작업할 수 있도록 RAG 방법론을 활용할 수 있어요:\n\n- 모든 문서에 대한 임베딩을 계산하고 벡터 저장소에 저장합니다.\n- 사용자 요청을 받으면 해당 요청의 임베딩을 계산하여 저장소에서 관련 문서를 검색할 수 있어요.\n- 최종 답변을 얻기 위해 LLM에게 관련 문서만 전달하면 돼요.\n\nRAG에 대해 더 자세히 알고 싶다면 여기에 더 많은 내용을 담은 제 논문을 읽어보세요.\n\n# 요약\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 텍스트 임베딩에 대해 많은 세부 내용을 논의했습니다. 이제 여러분은 이 주제에 대해 완전하고 심도 있는 이해를 가졌을 것입니다. 저희 여정을 간단히 요약하면 다음과 같습니다:\n\n- 먼저, 텍스트 작업 방법의 진화를 살펴보았습니다.\n- 그 다음으로, 텍스트 간에 유사한 의미를 가지고 있는지를 이해하는 방법에 대해 논의했습니다.\n- 그 후에는 텍스트 임베딩 시각화의 다양한 접근 방법을 살펴보았습니다.\n- 마지막으로, 임베딩을 클러스터링, 분류, 이상 탐지 및 RAG와 같은 다양한 실용적인 작업에서 특징으로 사용해 보았습니다.\n\n# 참고\n\n이 기사에서는 크리에이티브 커먼즈 라이센스 하에 공개된 스택 엑스체인지 데이터 덤프에서 데이터 세트를 사용했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글은 다음 강좌에서 영감을 받았습니다:\n\n- DeepLearning.AI와 Google Cloud의 협력으로 진행되는 \"Understanding and Applying Text Embeddings\",\n- DeepLearning.AI와 Weaviate의 협력으로 진행되는 \"Vector Databases: From Embeddings to Applications\".","ogImage":{"url":"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_0.png"},"coverImage":"/assets/img/2024-06-23-TextEmbeddingsComprehensiveGuide_0.png","tag":["Tech"],"readingTime":24},{"title":"심리 상담 챗봇  정신 건강을 위한 LLMs 사용 방법","description":"","date":"2024-06-23 19:51","slug":"2024-06-23-TherapistChatbotLLMsforMentalHealth","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-TherapistChatbotLLMsforMentalHealth_0.png\" /\u003e\n\n요즘 빠르게 변화하는 세상에서 우리의 정신 건강을 우선시할 시간을 찾기는 어려울 수 있어요. 업무, 가족, 그리고 일상 생활의 요구들은 종종 자기 관리를 할 시간을 남기지 않아서 정기적인 치료 세션은 물론 스스로를 돌보는 시간을 가져다주지 않을 때가 많아요. 시간을 내기로 결심했다고 해도, 자격 있는 치료사의 이용 가능성이 부족하면 예약을 기다리는 사람들이 많아질 수 있어요. 그리고 마침내 소중한 세션이 확보되더라도, 비용이 부담스러울 수 있어 이미 부담스러운 마음에 금전적인 압박을 느끼게 해요.\n\n이 딜레마는 정신 건강 치료 분야에서 혁신적인 해결책에 대한 점점 더 커지는 필요성을 강조해요. 진출하게 된 것이 바로 언어 모델(Language Models, LLMs)을 기반으로 하는 치료사 챗봇들의 시대입니다. 이 가상 상담가들은 우리가 스마트폰이나 컴퓨터의 편안함 속에서 24시간 365일 즉각적인 지원을 받을 수 있도록하여 우리가 지원을 받는 방식을 혁신하려고 합니다.\n\n인공 지능(AI)과 자연어 처리(NLP)를 활용하여, 이 챗봇들은 실제 치료 대화를 시뮬레이션할 수 있어요. 이들은 공감, 지도, 그리고 개인의 필요에 맞게 맞춤형 대처 전략을 제공할 수 있어요. 이러한 접근 방식은 특히 사회적 편견이나 물리적인 장벽 때문에 전통적인 치료를 받기 주저하는 분들에게 접근하는 데 매우 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 중요한 점은 심리상담사 챗봇은 정신 건강 관리를 보완할 수 있지만 전문 상담의 대체품이 아니라는 것입니다. 훈련받은 심리상담사들의 세밀한 이해력과 공감적인 대응을 갖추지 못합니다. 그들은 교육과 경험에 기초한 맞춤형 치료를 제공할 수 있는 훈련받은 상담사들의 심리 마음을 나타내지 못합니다.\n\n심리건강 관리에 LLMs를 통합하는 목표는 접근성을 증대하고 확대하는 데 있습니다. 더 나은 심리적 안녕을 향한 여정을 하는 사람들에게 발판을 제공합니다. 심리 건강 문제에 직면한 모든 사람들에게 전문적인 도움을 구하는 것이 중요한 단계이며, 이러한 혁신은 자기 돌봄과 지원을 위한 우리 도구상자에 유망한 추가 요소로 작용합니다.\n\n그런데, 이 기술을 활용하여 우리 자신의 심리 상담사 AI를 만들어보는 방법에 대해 깊이 파고들어 보겠습니다!\n\n전체 프로젝트와 함께 제 GitHub는 다음에서 확인할 수 있습니다 — https://github.com/Dev-Pandey-0302/Therapist-Chatbot\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n유튜브의 Nicholas Renotte에 대한 큰 찬사를 드립니다 (Nicholas Renotte를 검색해보세요, 놀라운 데이터 과학자!)\n\n# 코딩을 시작합니다.\n\n이 프로젝트의 핵심은 Llama_cpp 프레임워크를 기반으로 구축될 것입니다. 간단한 접근 방식은 ollama를 사용하는 것일 수 있지만, 이 안내서에서는 Llama_cpp를 사용하는 데 중점을 둘 것입니다.\n\n먼저, 우리는 ~특정 부분이 누락되었습니다~\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\ngit clone https://github.com/ggerganov/llama.cpp\r\n```\r\n\r\n원하는 기계에 llama_cpp를 설치할 거예요.\r\n\r\n다음으로, make 명령을 실행해야 해요:\r\n\r\n- Mac: cd llama.cpp \u0026\u0026 make\r\n- Windows (from here):\r\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 최신 Fortran 버전의 w64devkit을 다운로드하세요.\n- PC에 w64devkit을 압축 해제하세요.\n- w64devkit.exe를 실행하세요.\n- cd 명령어를 사용하여 llama.cpp 폴더로 이동하세요.\n- 여기서\n\n```js\nmake\n```\n\n위 명령어를 실행하세요. 그 후에는 의존성을 설치합니다. 가능하다면 의존성을 설치하기 전 가상 환경을 만들어도 좋습니다. 가상 환경을 만드는 방법을 모르신다면 아래 링크를 확인해보세요- https://www.freecodecamp.org/news/how-to-setup-virtual-environments-in-python/\n\n```js\npip install openai 'llama-cpp-python[server]' pydantic instructor streamlit gtts\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# GGUF 모델 다운로드\n\nGGUF가 무엇인가요?\n\n물어봐 주셔서 감사합니다!\n\n이 애플리케이션에서는 다음을 사용할 것입니다-\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWesselvanGils/MentaLLaMA-chat-7b-GGUF-q8\n\n이는 8비트 양자화된 GGUF 모델입니다. 따라서 전용 서버가 필요하지 않고 로컬 머신에서 실행할 수 있습니다.\n\n이 모델을 오픈 소스로 만들어준 Wessel van Gils에게 감사드립니다. 여기에 그들의 GitHub이 있습니다!\n\n더 자세한 정보를 알고 싶다면 자유롭게 이 글을 읽어보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델 다운로드로 돌아가기\n\n여기로 이동해주세요- https://huggingface.co/WesselvanGils/MentaLLaMA-chat-7b-GGUF-q8\n\n파일 및 버전 탭을 클릭하고 .gguf 파일을 다운로드하세요. 용량이 7GB가 넘는 파일이라 시간이 조금 걸릴 수 있으니 참고해 주세요.\n\n# app.py 파일 만들기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 app.py 파일을 만들어 봅시다.\n\n이 튜토리얼에서는 streamlit을 사용할 것입니다. 그러나 gradio와 같은 대체 솔루션을 사용해도 괜찮습니다.\n\n```python\nfrom openai import OpenAI\nfrom gtts import gTTS\nfrom io import BytesIO, StringIO\n# streamlit 앱 프레임워크 사용\nimport streamlit as st\n\n# 클라이언트 생성\nclient = OpenAI(\n    api_key=\"sk-1234567890\",\n    base_url='http://localhost:8000/v1'\n)\n\n# 앱의 제목\nst.title(\"TherapyBot- Mental Health Support를 위한 챗봇\")\n\n# 의료 기록 업로드\nuploaded_file = st.file_uploader(\"\", type=[\"txt\"], label_visibility=\"collapsed\")\ncss = '''\n\u003cstyle\u003e\n    [data-testid='stFileUploader'] {\n        width: max-content;\n    }\n    [data-testid='stFileUploader'] section {\n        padding: 0;\n        float: left;\n    }\n    [data-testid='stFileUploader'] section \u003e input + div {\n        display: none;\n    }\n    [data-testid='stFileUploader'] section + div {\n        float: right;\n        padding-top: 0;\n    }\n\n\u003c/style\u003e\n'''\nst.markdown(css, unsafe_allow_html=True)\n\ndoc_data = \"\"\n# 파일 업로드 시\nif uploaded_file is not None:\n    # 파일을 문자열로 읽기\n    stringio = StringIO(uploaded_file.getvalue().decode(\"utf-8\"))\n    doc_data = stringio.read()\n    doc_data = \"This is my medical record - \" + doc_data + \" Please answer the following question based on the earlier medical record- \"\n    \n# 사용자 입력 받기\nprompt = st.chat_input('채팅을 시작하거나 의료 기록을 업로드하십시오. 어떻게 도와드릴까요?')\n...\n```\n\n이 특정 app.py 파일은 구글의 gtts 라이브러리를 사용한 텍스트 음성 변환 기능도 제공합니다. 이를 위해서는 인터넷 연결이 필요하지만, 오프라인으로 완전히 실행하려면 gtts를 import하지 않고 마지막 4줄을 주석 처리하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 파일을 저장한 후 로컬 서버를 실행해 보겠습니다.\n\n# 라마.cpp 서버\n\n터미널에서 다음을 실행하면 서버가 가동될 것입니다. 다운로드한 GGUF 모델의 경로가 올바른지 확인하세요.\n\n```js\npython -m llama_cpp.server --model D:\\CHATBOT_PROJ_NEW\\MentaLLaMA-chat-7b-GGUF-q8\\MentaLLaMA-chat-7b-GGUF-q8.gguf --n_gpu -1\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# App.py 실행\n\n로컬호스트 서버가 시작된 후, 별도의 터미널에서 다음 명령을 실행하세요\n\n```js\nstreamlit run app.py\n```\n\n축하합니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지역 컴퓨터에서 실행 중인 자체 치료사 AI를 만들었습니다. .txt 파일을 제공하든 일반적인 질문을 하든 자유롭게 진행해주세요!\n\n![이미지](/assets/img/2024-06-23-TherapistChatbotLLMsforMentalHealth_1.png)\n\n읽어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-23-TherapistChatbotLLMsforMentalHealth_0.png"},"coverImage":"/assets/img/2024-06-23-TherapistChatbotLLMsforMentalHealth_0.png","tag":["Tech"],"readingTime":5},{"title":"컴퓨터는 왜 이진수Binary 체계를 사용할까","description":"","date":"2024-06-23 19:49","slug":"2024-06-23-WhydoComputersevenuseBinary","content":"\n\n# 소개적인 쓰레기\n\n데이터 과학자의 주된 도구는 무엇인가요? 공정하고 명백한 답은 컴퓨터입니다. 컴퓨터는 우리보다 훨씬 빠르게 데이터를 처리하기 때문에 데이터를 활용하는 모든 작업을 컴퓨터 없이 하는 것을 상상해 보세요. 곁에 연필과 종이가 있어 손으로 수많은 표와 그래프, 계산식을 지쳐하며 그리는 과정을 생각해 보세요. 이 모든 작업은 컴퓨터에서 몇 초만에 처리될 것을 알고 있지만요. 데이터 과학은 컴퓨터 없이는 존재하지 않을 것이라고 하더군요.\n\n컴퓨터가 데이터 과학을 수행하는 데 필수적인 도구라는 사실을 감안하면, 해당 직업에는 컴퓨터 작동 원리를 이해하는 것이 필요할 것으로 예상됩니다. 결국, 도구를 이해하지 못할 때 작업을 올바르게 수행하는 것은 어려운 일입니다. 그러나 지망하는 데이터 과학자에게는 해당 분야에 대한 기초 지식을 습득하는 데 시간을 할애하는 것이 너무 쉬울 수도 있습니다.\n\n![그림](/assets/img/2024-06-23-WhydoComputersevenuseBinary_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알겠어요. 수학, 컴퓨터 과학 및 공학의 이론적 주제는 종종 Python, Tensorflow 또는 Amazon Web Services와 같은 응용 중심 학습 목표보다 즉각적으로 보상을 받기가 어려워서(또는 솔직히 말해 즉각적으로 고용가능하지 않아서) 부차적인 학습 목표로 밀려납니다. 신진 데이터 과학자가 왜 이러한 종류의 주제로 향하는지 이해할 수밖에 없죠. 이러한 주제는 프로젝트 포트폴리오가 빠르게 성장함에 따라 기술과 이해력의 즉각적이고 실질적인 향상을 제공하기 때문입니다.\n\n데이터 과학 여정을 시작하는 데 좋은 시작점이기는 하지만, 더 이론적인 측면을 학습하면 시작 단계를 넘어 다음 단계를 나아갈 수 있습니다. 이 문서의 목적은 당신에게 데이터 과학에서 매일 사용하는 기술의 이론적 배경을 소개하는 데 있습니다.\n\n좋아요, 이제 소개가 끝났으니 재미있는 내용으로 들어가볼게요. 우리는 아마도 잠깐이라도 생각해 봤을 질문으로 시작할 거에요: 컴퓨터가 왜 이진수를 사용할까요? 결과부터 말하자면: 그렇지 않으면 비효율적일 것이기 때문입니다. 이 문서의 목적은 왜 그것이 비효율적인지 설명하는 것입니다.\n\n# 이진수란 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미 이진수가 무엇인지를 알고 계시다면, 이 섹션을 건너 뛰셔도 좋아요. 아니라면, 이 내용이 귀하를 위한 것입니다!\n\n상상해보세요. 만약 우리가 지적인 외계 생명체를 만난다면. 손가락이 5개가 아니라 3개씩 두 손에 각각 있는 특이한 생물이 있다고 상상해보세요. 그들은 어떻게 세어갈까요? 우리는 1부터 9까지의 숫자를 사용하지만, 그 이후에는 첫 번째 숫자를 0으로 되돌리고 다음 자리를 1부터 열어 10을 만듭니다. 그러나 우리의 외계 친구들은 이것이 별로 이해하기 어렵다고 생각할지도 모릅니다. 왜냐하면 그들은 6개의 손가락밖에 없고 우리는 10개이기 때문입니다. 당신이 숫자에 할당하는 자리값이 얼마나 임의적인지 알게 되고 있나요? 만약 사람들이 10개의 손가락을 태어나지 않았다면, 우리는 아마 우리가 하는 방식으로 세지 않을 것입니다. 우리는 10부터 새로운 숫자를 시작하기 대신에, 6, 2, 16, 46 또는 다른 어떤 숫자든, 각 값을 나타내는 고유한 기호가 있으면 됩니다. 외계인이 어떻게 세는지와 우리가 어떻게 세는지 비교해 봅시다. 각 행에 있는 값은 서로 동일합니다:\n\n![image](/assets/img/2024-06-23-WhydoComputersevenuseBinary_1.png)\n\n우리는 이러한 새로운 숫자 시스템을 'X 진수' 숫자 시스템이라고 합니다. 여기서 X는 새로운 자리로 넘어가는 값입니다. 예를 들어, 우리의 숫자 시스템은 각 자리가 10보다 더 커지기 전에 끝나므로 10 진수 시스템이라고 합니다. 반면에, 우리의 외계인 친구들은 6 진수 시스템을 갖게 될 것입니다. 왜냐하면 그들의 숫자는 6보다 작아지기 때문입니다. 컴퓨터는 2 진수 시스템에서 작동하며 바이너리로 알려져 있습니다. 바이너리 시스템에 적용된 외계인의 6 진수 시스템에 적용된 동일한 계산 논리를 적용해 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Binary Explanation](/assets/img/2024-06-23-WhydoComputersevenuseBinary_2.png)\n\n만약 그 이해가 당신에게 의미가 있다면, 이진법이 어떻게 작동하는지 이해하고 있는 것입니다. 너무 겁나지 않았으면 좋겠어요! 많은 사람들이 이것을 \"언어\"로 지칭해서 겁을 먹는데, 이진법은 그냥 다른 숫자 체계일 뿐이며, 우리가 익숙한 10진법처럼 작동합니다. 산술도 기본적으로 우리 체계에서 하는 것과 동일하게 작동합니다.\n\n우리 숫자가 10의 거듭제곱의 합으로 나타낼 수 있는 것과 같이, 이진수는 2의 거듭제곱의 합으로 나타낼 수 있습니다. 설명하는 가장 좋은 방법은 예를 통해 설명하는 것입니다. (참고로, 이진수는 숫자 앞에 0b를 붙여서 표시되기도 합니다. 이 글에서는 이 방식으로 계속해서 표시할 것입니다).\n\n10진법에서\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n`\u003cimg src=\"/assets/img/2024-06-23-WhydoComputersevenuseBinary_3.png\" /\u003e`\n\n마찬가지로, 2진법의 경우,\n\n`\u003cimg src=\"/assets/img/2024-06-23-WhydoComputersevenuseBinary_4.png\" /\u003e`\n\n위의 합산을 수행하면, ob1101은 13이 됩니다. 2진수를 10진수로 변환하는 쉬운 방법입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 왜 컴퓨터는 이진수를 사용할까요?\n\n이제 이진수가 어떻게 작동하는지 기본적으로 이해했으니, 이 기사의 중심 질문에 대해 다룰 수 있습니다. 컴퓨터가 정보를 이진수로 표현하는 이유는 무엇일까요? 컴퓨터가 정보를 이진수로 표현해야 하는 유일한 방법이기 때문은 아닙니다. 이것은 흔한 오해입니다. 사실, ENIAC과 같은 최초의 컴퓨터들 중 일부는 10진수를 사용했습니다. 현대 컴퓨터가 정보를 표현할 때 이진수를 사용하는 큰 이유는 세 가지가 있습니다.\n\n# 첫 번째 이유, 공간 효율성\n\n우리가 이진수 체계를 사용하는 큰 이유 중 하나는 다른 체계보다 간단하기 때문입니다. 간단히 말하면, 오로지 2 상태(0 또는 1)만을 표현하는 것은 더 쉽고 더 적은 물리적 부품이 필요합니다. 이것이 왜 그런지 이해하려면, 컴퓨터와 같은 디지털 시스템이... 음... 디지털이라는 것을 이해해야 합니다. 즉, 컴퓨터는 연속적인 수 대신 숫자의 이산적 표현을 사용하는 하드웨어를 사용합니다. 수학 수업에서 기억할 수 있겠지만, 이산적인 수는 정수(0, 1, -4 등)이고 연속적인 수는 정수와 각 소수부(0 1, -4, .2, -.2343 등)가 있는 수입니다. 그러나 컴퓨터는 전기를 사용하여 동작하는 실제 시스템이기 때문에 전압 수준을 정보로 표현하는 경우가 많습니다. 전압은 연속적인 값이며(3.22682393 볼트인 것이 가능합니다), 컴퓨터는 디지털입니다 — 오직 이산적인 값만을 사용하는 방식을 알고 있습니다. 어떻게 하면 연속적인 값(전압)을 디지털 시스템으로 표현할 수 있을까요? 우리는 전압 값을 디지털 값에 상응하는 전압 범위로 설정하여 그 방법을 찾습니다. 아래는 그러한 설정의 예시입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-WhydoComputersevenuseBinary_5.png)\n\n상기 도표를 사용하는 회로는 0부터 2 V 사이의 전압을 0b0으로 간주하고, 4V부터 6 V 사이를 0b1로, 그 이외의 값은 시스템이 문제가 있다는 것을 알려줍니다. 중간에 전환 존이 포함되어 있는 것을 주목하세요. 물리적 시스템에 대해 생각하는 것에 익숙하지 않다면, 우리가 0과 1 사이를 즉시 왔다갔다할 수 있어야 할 것 같다는 것이 이상할 수 있습니다. 그러나 물리적 시스템에서는 오차 여유를 만들어야 합니다. 그렇지 않으면 시스템이 필요 이상으로 매우 취약해질 수 있습니다. 토론을 벌이지는 않지만, 디지털 회로는 논리 게이트로 이루어져 있고, 논리 게이트는 켜고 끄기 위한 공간이 필요합니다. 이 낮음과 높음 사이의 전압 범위는 게이트가 \"종류\"로 켜진 상태입니다. 이 범위에 머무르면 구성 요소에 손상을 줄 수 있으므로, 구성 요소를 쉬게 두지 않는 전환 존을 계획합니다.\n\n만약 3진법 시스템을 만들고 싶다면, 또 다른 상태를 추가해야 합니다:\n\n![이미지](/assets/img/2024-06-23-WhydoComputersevenuseBinary_6.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자연스럽게 다른 상태를 추가하려면 더 많은 하드웨어 구성 요소가 필요합니다. 이는 더 높은 기수 체계를 사용하는 시스템을 설계할 때 하드웨어 면에서 복잡해지는 점을 의미합니다(설계 및 구성 요소 수 측면에서). 이것이 컴퓨터가 이진수를 사용하는 근본적인 이유입니다. 그러나 높은 기수 체계를 사용하는 것이 더 중요한 두 가지 영향을 주목해 보겠습니다.\n\n# 두 번째 이유, 전력 효율성\n\n전기 전력을 정의하는 것에 대해 잠시 이야기해 봅시다. 방정식은 정말로 간단합니다:\n\n![전기 전력](/assets/img/2024-06-23-WhydoComputersevenuseBinary_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nP는 전력(Watts), I는 전류(Amps), R은 저항(Ohms), V는 전압(Voltz)를 나타냅니다. 각 새로운 논리 수준마다 전압을 높일수록, 전체 장치의 전력 소비가 지수적으로 증가함에 따라 동등한 전압이 가정되며, 이는 대부분의 경우 합리적인 가정입니다. 소비 전력이 많을수록 장치를 실행하는 데 소비되는 비용이 더 많아지므로 대부분의 경우 이러한 시스템을 피하는 이유가 큽니다.\n\n# 세 번째 이유, 열 효율성\n\n랩톱이 한 두 시간 동안 열심히 작동한 후 뒷면을 만져본 적이 있나요? 아마도 많은 열을 느꼈을 것입니다. 과도한 열은 전자제품의 적이며, 그 생성을 피하는 것이 엔지니어들에게 우선 과제입니다. 열에 관한 방정식을 살펴 보세요:\n\n![Heat Equation](/assets/img/2024-06-23-WhydoComputersevenuseBinary_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nQ는 열(쥴), t는 시간(초), 그리고 R과 I는 다시 저항과 전류를 나타냅니다. 회로에 사용하는 각 새로운 구성 요소는 작동에 더 많은 전류를 그리는 결과를 가져올 것입니다. 이에 따라 열이 증가합니다.\n\n# 결론적인 발언\n\n이 기사에서는 컴퓨터가 왜 이진수를 사용하는지(이진수가 무엇인지 소개하는 것 외에도) 다루었습니다. 우리는 이것이 비효율적이라는 것을 알고 있고, 그 이유에 대한 메커니즘인 전압, 전류, 그리고 전력 등의 개념을 소개했습니다. 컴퓨팅에서 다른 숫자 체계를 사용하려면 디지털 논리 회로로 더 많은 상태를 나타내야 한다는 것을 보았습니다. 그 결과 전력과 회로 구성 요소가 더 필요하며 더 많은 열을 발생시키면서, 엔지니어와 소비자가 피하려고 하는 것입니다.\n\n하지만, 우리는 실제로 컴퓨터가 이 정보를 어떻게 나타내는지를 정말 다루지 않았습니다 — 그저 디지털 회로를 사용한다고 말했을 뿐입니다. 다음 몇 개의 기사에서는 이 질문을 더 자세히 탐구할 것입니다. 디지털 논리 회로가 어떻게 작동하는지 설명해 보겠습니다 — 가능한 최하위 수준인 반도체부터 시작해서요. 이에 관심이 있다면, 많이 기대해 주세요! 이 기사와 같이 저는 전기 공학 개념을 아는 것으로 상정하지 않고 성장 중인 데이터 과학자들을 대상으로 하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아마도 당신은 새로운 데이터 과학자이거나 이미 경험 많은 데이터 과학자이실 것입니다. 이 기사가 흥미롭게 느껴졌으면 좋겠습니다. 컴퓨터 하드웨어가 데이터 과학이나 머신 러닝 개념과 정확히 관련이 없지만, 이것들은 우리의 전문 분야 도구이며, 이에 대한 기본적인 이해를 가지는 것이 가치 있다고 생각합니다. 동의하시고 이 기사가 흥미롭다고 생각하셨다면, 다음에는 실제 컴퓨터 계산 방식에 대해 다룰 예정이니, 그때 뵐 수 있기를 희망합니다!\n\n# 참고자료\n\n[1] R. Palaniappan, Digital Systems Design (2011), https://dvikan.no/ntnu-studentserver/kompendier/digital-systems-design.pdf","ogImage":{"url":"/assets/img/2024-06-23-WhydoComputersevenuseBinary_0.png"},"coverImage":"/assets/img/2024-06-23-WhydoComputersevenuseBinary_0.png","tag":["Tech"],"readingTime":7},{"title":"주식 예측에서 머신러닝이 실패하는 주요 이유 파트 01","description":"","date":"2024-06-23 19:47","slug":"2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01","content":"\n\n이 블로그 시리즈에서는 머신 러닝이 주식 가격을 예측하는 데 실패하는 이유 또는 일반적으로 머신 러닝 기반 투자 펀드가 실패하는 이유에 대해 논의하려 합니다. 이 블로그의 내용은 Marcos Lopez de Prado의 \"금융 머신 러닝 발전\"이라는 책에서 가져왔습니다. 이 책은 금융에 관심 있는 모든 사람들에게 필독서입니다. 이 책은 금융 데이터를 처리하는 동안 머신 러닝 실무자들이 범한 모든 실수를 언급합니다. 이 블로그를 통해 이 책에서의 학습 내용을 요약하려고 합니다.\n\n- Reason 1 : 메모리 vs 정상성 트레이드 오프 :\n\n주식의 가격을 예측하고 싶다고 가정해 봅시다. ARMA와 같은 모든 전통적인 방법이 정상성 데이터에 작용한다는 것을 알고 있습니다. 일반적으로 정상 데이터는 일련의 시리즈 전체에서 일정한 평균과 일정한 분산을 의미합니다. 데이터를 정상으로 만들기 위해 시계열 데이터에서 차분을 수행합니다. 1차 차분은 현재 주가 값을 이전 값에서 뺀 것을 의미합니다.\n\n![Image](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n차이를 만들면 데이터가 정체성을 띄게 됩니다. 그러나 1차 차이를 구할 때는 데이터의 모든 과거적인 패턴을 잃어버리게 됩니다(그림 참조). 이로 인해 그 데이터의 내용을 잃게 됩니다. 그리고 기억력은 모델의 예측 능력을 결정하는 중요한 요소입니다. 데이터를 정체성을 갖도록 만드는 중간 과정에서 기억력을 잃게 됩니다. 이런 실수가 학술 논문이나 업무 현장에서 많이 발생합니다. 그렇다면 어떻게 데이터를 정체성을 갖게 하면서도 정보를 완전히 잃지 않을 수 있을까요? 그 대답은 없습니다. 따라서 더 많이 정체성을 갖도록 만드는 경우에는 더 많은 기억력을 잃게 됩니다. 릴라이언스의 과거 가격을 통해 이러한 경우를 이해해봅시다.\n\n![image](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_1.png)\n\n위 그래프에서 보듯이 데이터를 정체성을 갖도록 만들면 가격이 시간에 따라 어떻게 변동하는지에 대한 정보를 모두 잃고 따라서 그 기억력도 잃게 됩니다. 그리고 이에 따라 그런 데이터로 만든 모델의 예측 능력도 잃게 됩니다. 그렇다면 어떻게 해야 할까요? 부분적인 정체성을 달성하면서 부분적인 기억력을 잃지 않도록 하는 방법을 찾아야 합니다. 그렇게 되면 분수 차이화라는 개념이 등장합니다. 분수 차이화에서는 1차 차이화 대신 어떤 분수 값을 사용하여 차이화를 수행하게 되어 모든 정보를 완전히 잃지 않습니다. 그렇다면 분수 차이화를 어떻게 수행할까요? 함께 살펴봅시다.\n\n![image](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 보시다시피 주문 차이를 확장했습니다. 이제 만약 d=0.3의 값을 넣으면 0.2의 분수 차이 값이 나올 것입니다. 이것은 무한급수이므로 어떤 지점까지 값을 취할 수 있고, 그 이후에는 시리즈를 잘라내도 괜찮습니다. 왜냐하면 B^n 계수 값이 높아질수록 거의 제로에 가까워질 것이기 때문입니다. 아래 그래프는 일정 지점 이후에 서로 다른 d 값에 대한 B^n 계수를 보여줍니다.\n\n이제 동일한 플롯을 동일한 차수의 분수 차이로 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상단 차트에서 확인할 수 있듯이, 차분의 순서를 증가할수록 점점 더 많은 메모리를 잃고 더욱 안정화됩니다. 차분이 0일 때는 모든 메모리를 가지고 있지만, 시리즈는 안정적이지 않고 차분이 1일 때는 시리즈가 메모리를 가지고 있지 않지만 완전히 안정화됩니다. 그래서 우리는 어느 정도의 메모리를 잃으면서 데이터를 의미 있는 확률로 안정화할지 교환해야 합니다. 그래서 이제 d값을 어떻게 찾아야 할까요?\n\n시계열의 안정성을 위한 ADF(Augmented Dickey-Fuller) 검정이 관련됩니다. ADF 검정은 시리즈가 안정적인지 여부를 테스트하는 데 사용됩니다. 다양한 d 값에 대해 ADF 검정을 수행한 후, 아래 빨간색 선 그래프는 다양한 d 값에 대한 검정 통계 값입니다. 검정 통계 값이 수평선보다 낮다면 해당 시리즈가 안정적이라고 할 수 있습니다. 따라서 아래 차트에서 d=0.4가 시리즈를 안정화시키는 데 충분하다고 할 수 있습니다. 그래서 시리즈에서 최소한의 메모리 손실로 안정화된 시리즈를 얻으려면 d=0.4를 사용할 수 있습니다.\n\n2. 이유 2: 비효율적인 샘플링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 많은 실무자와 학술 논문 작성자들이 하는 또 다른 흔한 실수는 데이터 샘플링이 비효율적인 것입니다. 대부분의 경우 그들은 데이터를 시간 간격마다 샘플링합니다. 예를 들어, 5분마다 또는 10분마다 데이터를 샘플링합니다. 시간 프레임에 기반한 데이터 샘플링 시 주요 문제점이 있습니다.\n\n- 시장이 정규시간 간격에 맞춰 정보를 처리하지 않기 때문에 문제가 발생합니다. 예를 들어 시장은 오픈할 때보다 정오에 활동성이 높으므로, 높은 활동성 시간 동안 정보를 과소샘플링하고 낮은 활동성 시간 동안 정보를 과대샘플링합니다.\n- 시간 샘플링된 데이터는 연쇄상관, 이분산성 및 수익의 비정상성과 같은 부정적인 통계적 특성을 보입니다.\n\n이 문제를 극복하기 위해 다양한 바(bar)가 정의될 것입니다. \n\n- 틱 바(Tick bar): 타임스탬프, 거래량, 오픈 가격, 종가 등의 모든 변수를 일정 거래 횟수 이후 추출합니다. 예를 들어, 1000 거래가 이루어진 후 모든 변수를 샘플링합니다. Mandelbrot 및 Taylor [1967]은 거래 횟수에 따른 샘플링이 우수한 통계적 특성을 보인다는 것을 처음으로 깨달았습니다: \"고정된 거래 횟수에 따른 가격 변동이 가우시안 분포를 가질 수 있습니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_6.png)\n\n![이미지](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_7.png)\n\n- 볼륨 바: 틱 바는 주문 조각화(쪼개짐) 문제가 있습니다. 예를 들어, 어떤 가격에 어떤 가격에 10주를 매도하는 경우, 10주를 사 실 때 1틱으로 기록됩니다. 하지만 만약 1주를 10번 사면 10개의 거래로 기록됩니다. 이 문제를 해결하기 위해 일정 거래량이 발생한 후 정보를 샘플링합니다. 이것이 볼륨 바라고 알려져 있습니다.\n- 달러 바: 달러 바는 일정 거래가 발생한 후 정보를 샘플링하여 형성됩니다. 예를 들어, $5000의 거래가 발생한 후에 정보를 샘플링합니다. \"값\"은 반드시 $로만 측정되는 것은 아니고, Rs, 유로 등이 될 수 있습니다. 달러 바가 필요한 이유는 무엇일까요? 특정 기간 동안 100%의 평가 상승을 보인 주식을 분석하려고 할 때, 그 기간 끝에 $1,000가치의 그 주식을 판매하려면, 그 주식을 $1,000가치 살 때와는 반의 주식을 거래해야 합니다. 다시 말해, 거래된 주식 수는 실제 교환된 가치에 따라 결정됩니다. 그러므로, 주요 가격 변동이 있는 분석에 관여할 때, 거래된 값의 관점에서 바를 샘플링하는 것이 의미가 있습니다. 또 다른 주장은 보너스 주식, 주식 분할로 주식 수가 자주 변경되므로 거래량보다는 가격을 기준으로 샘플링하는 것이 더 합리적이라는 점입니다.\n\n다음 파트에서는 정보 주도의 일부 고급 정보 바에 대해 이야기해보겠습니다. 즉, 시장에 새로운 정보가 들어오면 정보를 샘플링하는 것을 의미합니다. 다음 블로그 시리즈에서 정보 주도형 바에 대해 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 블로그를 좋아하신다면 꼭 의겢이나 좋아요를 클릭해 주세요!\n\n참고:\n\n1) Marcos López de Prado의 금융 기계 학습 발전","ogImage":{"url":"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png"},"coverImage":"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png","tag":["Tech"],"readingTime":5},{"title":"컴퓨터는 실제로 어떻게 계산할까","description":"","date":"2024-06-23 19:45","slug":"2024-06-23-HowDoComputersActuallyCompute","content":"\n\n# 소개글\n\n컴퓨터가 숫자를 계산하는 장치라는 말은 항상 듣고 다닙니다. 그들은 인간이 희망하기 힘든 속도로 데이터를 처리하며, 초당 수천 개의 논리적인 결정을 내릴 수 있다는데요. 하지만 그들이 이를 물리적으로 어떻게 하는 걸까요? 이러한 매우 비싼 기기가 자신들의 창조자들을 (어느 면에서는) 능가할 수 있는 무엇이 그리 특별한 걸까요? 이 질문에 우리는 이 기사에서 다룰 것입니다.\n\n![이미지](/assets/img/2024-06-23-HowDoComputersActuallyCompute_0.png)\n\n이것은 내가 쓰는 새로운 시리즈, \"데이터 과학자를 위한 컴퓨터 하드웨어 입문\"의 두 번째 부분입니다. 물리학, 전기 공학 또는 저수준 컴퓨터 과학 관련 지식을 전제로 하지 않는 이 시리즈는 새로운 (또는 경험이 풍부한) 데이터 과학자가 전문 도구에 대한 이해를 깊이 있게 하고자 합니다. 결국, 어떤 뛰어난 장인이 자신의 도구에 대해 익숙하지 않겠습니까?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시리즈의 이전 설치 파일을 따라 가기 위해서는 필요하지 않아요 (원한다면 다음에서 읽을 수 있어요: 컴퓨터는 왜 이진수를 사용할까요?). 컴퓨터가 어떻게 작동하는지 궁금하지만 해당 분야에 대한 배경이 많이 없다면 이 시리즈는 시작하기에 좋은 장소가 될 거예요.\n\n멋진데요, 입문부터 떨어뜨렸어요. 이제 재미있는 부분으로 들어가볼까요?\n\n# 가장 기본적인 디지털 회로 요소: 트랜지스터\n\n디지털 회로에서 가장 기본적인 요소는 트랜지스터에요. 트랜지스터는 반도체 기반 구성 요소로 스위치처럼 작용할 수 있어요. 반도체(예를 들면 실리콘)는 특정 조건 하에서 전기를 전도하고, 다른 조건 하에서 전기를 차단하는 재료들의 한 종류에요. 반도체 재료를 재빠르게 활용함으로써 회로 구성 요소를 \"켜고\" \"끌\" 수 있어요. (트랜지스터로 가능한 다른 것들도 있지만, 이 기사에서는 다루지 않을 거예요). 재료를 \"재빠르게 활용\"하는 방법은 반도체로 트랜지스터를 만드는 것이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n트랜지스터는 베이스(base), 콜렉터(collector), 그리고 에미터(emitter)의 세 개의 I/O 위치를 가지고 있어요. 아래의 트랜지스터 다이어그램에서 콜렉터는 상단에 있고, 베이스는 중간 왼쪽에 위치하며, 에미터는 하단에 위치합니다. 이런 트랜지스터의 배치는 NPN (부정-긍정-부정) BJT(양극성 접합 트랜지스터)라고 불립니다. BJTs보다 더 인기 있는 많은 종류의 트랜지스터가 있어요. 실제로 디지털 응용에서 사용되는 트랜지스터는 주로 FETs (장효과 트랜지스터)이고, BJTs는 아닙니다. 그렇지만 기술적 세부사항이 약간 다르더라도 최종 결과는 대부분 동일합니다 — 모든 트랜지스터는 여전히 스위치 역할을 합니다. BJTs가 약간 더 간단하기 때문에, 이 점에 중점을 두겠어요.\n\n![트랜지스터 다이어그램](/assets/img/2024-06-23-HowDoComputersActuallyCompute_1.png)\n\n트랜지스터에 관한 한 가지를 기억해주세요. 베이스에 약간의 전기를 가하면 콜렉터에서 에미터로 더 많은 양의 전기가 흐를 수 있습니다. 이를 수도꼭지를 켜고 끄는 것처럼 생각해보세요. 우리는 스지(Ge이미터)를 통해 물(전기)이 물 공급원(콜렉터)에서 나가게 하기 위해 수도선을 돌리는 것처럼, 베이스에 약간의 전기를 가해서 전류를 제어합니다. BJTs의 경우, 우리는 전류를 다루어 전류 흐름을 조절합니다. FETs의 경우, 전압을 다루어 전압 \"흐름\"을 조절합니다. 그러나 두 방법 모두 개념은 동일합니다.\n\n좋아요, 이제 우리는 트랜지스터가 무엇이며, 스위치를 만들기 위해 반도체를 사용한다는 것을 이해했습니다. 우리는 베이스에 약간의 전기를 제어하여 콜렉터와 에미터 간의 전기 흐름을 켜고 끕니다. 믿든 안 믿든, 이 아이디어 — 스위치 — 가 컴퓨터 안에서 일어나는 모든 것의 기본 구성 요소입니다. 우리는 트랜지스터를 사용하여 논리 회로를 설계할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 논리 게이트: 컴퓨터가 어떻게 계산하는지\n\n논리 게이트는 기본 논리 기능을 구현하는 회로 요소들로 (다소 자명하게) 설계됩니다. 논리 게이트의 예로는 AND, OR, NOT 게이트가 있습니다. 논리 게이트의 출력은 입력 조건이 충족될 때 켜지고, 그렇지 않으면 꺼집니다.\n\n우리가 깊게 들어가기 전, 전기를 데이터로 어떻게 이해하는지 간단히 다시 살펴보겠습니다. 디지털 회로에 대해 이야기할 때, 보통 0을 나타내는 전압 범위와 1을 나타내는 전압 범위가 있습니다. 간단히 말해, 입력/출력에 전기가 적게 있다면 해당 입력/출력 값이 0임을 이해합니다. 전기가 조금 이상 있다면 1로 간주합니다. 이를 통해 이진수로 회로 작업을 수행할 수 있습니다. (이전 기사인 '컴퓨터가 왜 이진수를 사용할까?'를 읽었으면, 더 자세히 다룬 내용일 것입니다). 입력 또는 출력의 전기 양 대신 입력 또는 출력의 0 또는 1에 대해 이야기함으로써 문제를 단순화합니다. 그러나 이러한 숫자들이 전기 양으로 모델링된다는 것을 잊지 마세요.\n\n(부가 설명 — 간단히 설명하기 위해 약간 우외해주고 있습니다. 전압은 단순히 전기의 양이라고 말하기 정확하지 않습니다. 그러나 두 가지를 동일시함으로써 전체 개념을 조금 더 쉽게 이해하고, 디지털 논리 회로 작동 방식을 이해하는 데 지장이 없게 합니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대박이네요! 이제 이해하셨으니 논리 게이트로 빠져들어볼까요! 예를 들어, AND 게이트를 살펴봅시다.\n\n![AND Gate](/assets/img/2024-06-23-HowDoComputersActuallyCompute_2.png)\n\n왼쪽에 있는 두 개의 도일은 입력이고, 오른쪽에 있는 도일이 출력입니다. AND 게이트 안에는 잘 배치된 수많은 트랜지스터가 있지만, 그것에 대해서는 나중에 다뤄보겠습니다. AND 게이트는 어떻게 작동할까요? 입력 두 곳에 모두 1(전기가 많음)이 있을 때 출력이 1이 됩니다. 그렇지 않으면 출력은 0이 됩니다. 이는 파이썬의 \"and\" 키워드와 마찬가지로 작동합니다! 사실, 파이썬(그리고 어떤 프로그래밍 언어든, 정말로)은 실제로 “and”, “or”, “not”과 같은 기능을 수행하기 위해 논리 게이트를 사용합니다. 멋지지 않나요? 파이썬에서 “and”를 호출하면 실제로 컴퓨터의 CPU 내부에 있는 단일 논리 게이트를 사용하고 있는 것이죠! 이 하드웨어 구성요소를 (거의) 직접 사용해오셨는데 그것을 몰랐다니 대단하시네요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n디지턈 회로에 대해 이야기할 때는 입력과 출력에 대해 정확하게 설명할 방법이 필요합니다. 이를 위해, 참진리표(truth table)라 불리는 것을 사용합니다. 여기 AND 게이트의 참진리표가 있어요.\n\n![AND Gate Truth Table](/assets/img/2024-06-23-HowDoComputersActuallyCompute_3.png)\n\n2개의 입력이 각각 2가지 상태를 가지기 때문에 입력에 대한 2² = 4개의 다른 배열이 있습니다. 따라서 참진리표는 4행을 가지게 됩니다. 우리는 두 입력이 모두 1이면 켜지는(1인) 회로를 원했기 때문에 참진리표에 1을 확인할 수 있습니다.\n\nAND 게이트의 경우, 참진리표는 명백하지만 더 복잡한 회로의 경우, 참진리표는 입력을 출력에 매핑하는 회로를 추적하는 데 매우 유용한 도구입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 논리 게이트의 하부 구조\n\n좋아요, 이제 논리 게이트가 어떻게 작동하는지 알게 되었어요. 그리고 트랜지스터의 기본 개념도 이해했군요. 이제 이 둘을 어떻게 결합하여 AND 게이트를 만들 수 있는지 알아볼까요? 아래의 회로를 살펴보세요.\n\n![image](/assets/img/2024-06-23-HowDoComputersActuallyCompute_4.png)\n\n위쪽에 전기원이 있습니다. 기억하세요, 트랜지스터는 스위치처럼 작동하기 때문에 소스에서 전기가 흐를 수 있기 위해서는 해당 트랜지스터의 베이스에서 전기가 존재해야 합니다. 양 입력에 각각 1이 입력되면 어떻게 될까요? 소스에서 출력까지 전기가 흐를 수 있기 때문에 출력 값은 1이 됩니다. 그러나 어느 하나의 트랜지스터라도 꺼져 있다면 (즉, 입력 중 하나에 0이 입력된 경우), 전기가 차단되어 출력 값이 0이 됩니다. 이는 AND에 대한 참 진리표와 일치합니다! 이제 AND의 논리를 구현하는 물리적인 구성 요소를 가졌습니다! OR 및 NOT에 대해서도 비슷한 설계 과정을 따를 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사이드 노트: 그렇다고 계속 괴롭힐 필요는 없어요 — 이 회로가 AND를 위한 실제 회로보다는 조금 더 간단합니다. 실제로, 원하는대로 전기를 흘리기 위해 저항기와 전기 접지와 같은 몇 가지 전기 부품이 필요합니다. 그러나 이 간단화된 버전은 일어나는 대부분의 것을 대표하고 있으며 주된 개념도 전달하고 있습니다.\n\n# 논리 게이트 결합: 복잡한 계산\n\n그래서, 우리는 트랜지스터 수준에서 논리 게이트가 어떻게 동작하는지 알고 있습니다. AND, OR, NOT와 같은 함수를 구현할 수 있습니다. 그러나 거기서부터 더 복잡한 것으로 어떻게 나아가야 할까요? 결국, 논리는 컴퓨터가 수행할 수 있는 유일한 계산이 아닙니다. 저희는 데이터 과학을 할 때 덧셈, 곱셈, 나눗셈 등을 자주 진행하니까 뭔가 더 있어야 한다는 것이 맞죠.\n\n이러한 고차 함수 중 많은 것들이 논리 게이트를 사용하여 구현될 수 있다는 것이 밝혀졌습니다. 예를 들어, 덧셈을 살펴보죠. AND와 XOR 두 개의 게이트만 사용합니다. XOR은 베타식 OR의 약자입니다. 입력 중 하나라도 1이면 XOR의 출력이 켜집니다. 그러나 모두 1이거나 아무도 아니면 출력은 0이 됩니다. XOR의 진리표는 다음과 같습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 서킷을 살펴보세요:\n\n![circut](/assets/img/2024-06-23-HowDoComputersActuallyCompute_6.png)\n\n만약 하실 마음이 있다면 아래 진리표를 스스로 채워보세요. 머리 속에서 채워도 괜찮아요. 결과물이 궁금하시겠죠?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-HowDoComputersActuallyCompute_7.png)\n\n두 입력이 모두 0 인 경우에는 어떻게 되나요? 그럼 AND 와 XOR가 꺼져서, Output과 Carry가 모두 꺼집니다.\n\n![이미지](/assets/img/2024-06-23-HowDoComputersActuallyCompute_8.png)\n\n0 과 1 은 어떤가요? XOR이 켜져 있고 AND는 꺼져 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 마크다운 형식으로 변경해야 합니다.\n\n\n\u003cimg src=\"/assets/img/2024-06-23-HowDoComputersActuallyCompute_9.png\" /\u003e\n1 and 0 would be the same, then.\n\n\u003cimg src=\"/assets/img/2024-06-23-HowDoComputersActuallyCompute_10.png\" /\u003e\nWhat about 1 and 1? The XOR is off and AND is on!\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-HowDoComputersActuallyCompute_11.png\" /\u003e\n\n이진 덧셈 회로의 진리표를 보셨나요? Carry는 다음 자리로 1을 옮기는 것을 나타내며 (일반 덧셈에서 1의 자리에서 10의 자리로 1을 옮기는 것과 같습니다), 출력은 해당 자리의 값을 나타냅니다! 수동으로 확인해볼 수도 있어요: 1 + 1 = 2. 2를 이진수로 표현하면 0b10입니다. 1은 Carry로, 0은 출력으로 표현됩니다.\n\n1비트 더하는 회로는 두 개의 간단한 게이트로 표현할 수 있어요. 더 많은 비트를 추가하려면 동일한 더하는 회로를 더 이어붙이기만 하면 돼요 (이를 캐스케이딩이라고 해요). 논리 게이트와 진리표를 사용하여 다양하고 중요한 회로를 만들어낼 수 있어요.\n\n# 마무리맺음\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이번 글에서는 트랜지스터가 논리 게이트를 만드는 데 어떻게 사용되는지 다루었으며, 논리 게이트가 결합되어 컴퓨터가 수행하는 계산 기능을 많이 생성하는 방법도 다뤘습니다. 아직 궁금증이 남아 계신다면 댓글에서 질문해 주세요! 하나 더 언급하지 못한 점은 진리 표에서 회로 설계로 어떻게 이어지는지 입니다. 이 글은 하드웨어 작동 방식보다는 설계 프로세스에 더 초점을 맞추었기 때문에 여기에는 잘 맞지 않는 부분이었습니다. 그러나 답변을 드리겠습니다. - 부울 대수를 사용합니다. 이 시리즈의 후속 섹션에서 부울 대수에 대해 다룰 예정입니다.\n\n이로써 마무리 지었습니다! 본 글은 저의 컴퓨터 하드웨어 시리즈 중 두 번째 글입니다. 다음에는 컴퓨터가 실제로 기억하는 방법에 대해 이야기할 예정입니다!\n\n이 시리즈를 좋아하시나요? 개선할 점이 있나요? 다루어보기를 원하는 하드웨어 주제가 있나요? 깊이 들어갈 부분이 있나요? 과하게 다루어진 부분이 있나요? 댓글에서 제안해 주시면 대답해 드리겠습니다. 피드백은 이 글이 하드웨어 배경이 없는 독자를 위해 적절한 수준에서 쓰여져 있는지, 그리고 흥미롭고 교육적인 내용으로 써졌는지 확인하는 데 도움이 됩니다. 읽어 주셔서 감사합니다. 다음에 뵙겠습니다!","ogImage":{"url":"/assets/img/2024-06-23-HowDoComputersActuallyCompute_0.png"},"coverImage":"/assets/img/2024-06-23-HowDoComputersActuallyCompute_0.png","tag":["Tech"],"readingTime":7},{"title":"에이전트 AI의 핵심 과제인 계획 문제 강화학습으로 해결하는 방법","description":"","date":"2024-06-23 19:42","slug":"2024-06-23-PlanningastheCoreChallengeinAgenticAISolvingitwithReinforcementLearning","content":"\n\n창의력을 발휘하여 복잡한 비즈니스 전략 문제를 해결하기 위해 원활하게 협업하는 AI 에이전트 팀을 상상해보세요. 시장 동향을 조사하는 한 명의 에이전트, 재무 데이터를 분석하는 다른 한 명, 그리고 권고 사항을 준비하는 세 번째 에이전트가 모두 공통 목표를 향해 노력하고 있습니다.\n\n이 협력적 인 인공 지능의 논리, 즉 앤젠틱 AI를 알아보면 자동화와 문제 해결의 다음 단계를 나타냅니다. AI 시스템이 더욱 정교해지면서 미리 정의된 고정적인 프로세스를 벗어나 유연성, 적응력 및 AI 에이전트 간의 팀워크를 받아들이는 데 관심이 증가하고 있습니다.\n\n앤젠틱 AI는 기존의 전통적인 자동화 기술로 해결하기 어려웠던 복잡한, 개방형 작업을 자동화하는데 큰 약속을 합니다. 복잡한 문제를 전문화된 역할로 분해하고 개별 AI 에이전트의 고유한 능력을 활용함으로써, 다양한 에이전트 시스템은 이전에 상상도 못 했던 방식으로 지능적인 자동화를 조율할 수 있습니다. CrewAI, Langraph, Autogen과 같은 개척적인 프레임워크는 이 새로운 패러다임을 위한 길을 열며, 개발자가 복잡한 워크플로를 자율적으로 탐색하고 실행할 수 있는 AI 에이전트 팀을 디자인하고 배포할 수 있도록 도와주고 있습니다.\n\n그러나 이 새로운 협업 AI 영역으로 나아가면 앤젠틱 시스템의 핵심에 있는 근본적인 도전 과제를 마주하게 됩니다: 계획.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 에이전트들이 효과적으로 행동을 계획하고 서로 협력하며 동적이고 개방적인 환경에서 자신들의 전략을 적응시킬 수 있게 하는 방법은 무엇일까요?\n\n이 문서는 계획이 에이전트 AI의 핵심 과제이며 강화 학습(RL)이 이 중요한 문제에 대한 유망한 해결책을 제시한다고 주장합니다.\n\n다음 섹션에서는 에이전트 AI의 부상과 주요 원칙에 대해 탐구하고, 이러한 시스템에서 계획이 이러한 의미 있는 과제로 작용하는 이유를 설명하며, 강화 학습 기법이 이러한 어려움을 해결할 수 있는 방법을 살펴볼 것입니다.\n\n에이전트 AI에서 계획과 강화 학습의 상호작용을 이해함으로써, 지능적 자동화와 협력적인 인공지능의 미래에 대한 중요한 통찰을 얻을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Planning as the Core Challenge in Agentic AI: Solving it with Reinforcement Learning](/assets/img/2024-06-23-PlanningastheCoreChallengeinAgenticAISolvingitwithReinforcementLearning_0.png)\n\n# Agentic AI의 부상\n\nAgentic AI는 인공지능 시스템을 개념화하고 구현하는 방식에서 패러다임이 바뀌었다. 핵심적으로, Agentic AI는 자율적인 AI 에이전트들이 복잡하고 개방적인 과제에 대처하기 위해 팀 또는 \"크루\"로 함께 일하는 모습을 상상한다. 이 접근 방식은 단일 모델 AI 시스템의 제약을 넘어서 전문화와 협력의 힘을 활용하여 더 정교하고 유연한 문제 해결 능력을 실현한다.\n\n이 Agentic AI 혁명의 전선에는 다수의 에이전트들 사이의 협력에 대한 독특한 접근 방식을 제공하는 여러 중요한 프레임워크들이 등장했다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- CrewAI: 이 프레임워크는 특정 역할을 갖는 AI 팀을 설계할 수 있게 해 주어, 그들이 특정 작업에 따라 선별된 연구 및 분석 도구 세트를 갖추도록 돕습니다.\n- Langraph: Langraph는 더 구조화된 방식을 채택하여, 명시적인 방향 그래프를 사용하여 에이전트 간의 작업 흐름을 정의합니다. 이를 통해 개발자들은 에이전트 조정과 작업 할당에 대해 세밀한 제어를 할 수 있습니다.\n- Autogen: Autogen은 에이전트 간의 다중 대화로부터 발생하는 신생 작업 흐름에 의존하여, 보다 동적이고 적응적인 협업 패턴을 가능하게 합니다.\n\n이 프레임워크들은 구체적인 구현에서 차이가 있지만, 모두 에이전틱 AI 접근 방식을 정의하는 중심 원칙을 공유합니다:\n\n전문화와 협업: 이러한 시스템 전반에 걸쳐 두드러지는 공통점 중 하나는 다수의 특화된 에이전트를 활용하여 스스로 작업하는 방식입니다. 단일 대형 모델에 의존하는 대신, 에이전틱 AI는 작업을 하위 작업으로 분해하여 각각 다른 역할과 기술을 갖춘 에이전트에 위임합니다. 이러한 전문화는 각 에이전트가 자신의 전문 분야에 집중할 수 있도록 하고, 협업은 팀이 어떤 개별 에이전트에겐 도전적일 수 있는 문제들을 해결할 수 있도록 돕습니다.\n\n예를 들어 채용 상황에서, 크루는 기술 직군 연구, 인적 프로필 엔지니어링, 이력서 전략 및 면접 준비에 특화된 에이전트로 구성될 수 있습니다. 이러한 특화된 에이전트들이 함께 작업하여 단일 일반적 AI보다 개인을 고용 전 과정에서 효과적으로 안내할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n언어 모델과 외부 도구의 활용: 에이전트 AI 시스템에서 또 다른 중요한 패턴은 각 에이전트를 뒷받침하는 \"두뇌\"로서 대형 언어 모델(LLMs)을 사용하는 것입니다. 이러한 미리 학습된 모델은 에이전트가 열린 대화를 할 수 있게 하며 자연어 질의를 해석하고 유창한 응답을 생성하며 판단을 내릴 수 있도록 합니다.\n\n그러나 에이전트 AI는 언어 모델만을 의존하지는 않습니다. 에이전트의 지식을 기반을 다지고 그들의 능력을 확장하기 위해, 이러한 시스템은 또한 외부 도구와 데이터 소스에 연결합니다. 웹에서 단락을 검색하거나 구조화된 데이터베이스를 질의하거나 타사 API를 호출하는 등의 방식으로, 에이전트들은 실제 세계 정보를 활용하여 자신들의 결정과 행동에 영감을 얻습니다.\n\n이러한 언어적 유연성과 외부 기반의 결합으로 인해 에이전트 AI 시스템은 넓은 세계로부터 통찰을 얻으면서 일관된 대화를 유지할 수 있습니다. 이는 인간이 언어를 지식과 행동의 관문으로 활용하는 방식을 재현하는 데 필수적인 한 걸음입니다.\n\n에이전트 상태 및 워크플로우 관리: 에이전트 AI 설계의 가장 다양한 측면은 플랫폼이 에이전트 팀의 상태와 워크플로우 오케스트레이션을 어떻게 다루는지입니다. 에이전트 작업은 종종 다수의 단계와 에이전트 출력 간의 의존성을 포함하므로 일관된 전역 상태와 제어 흐름을 유지하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 도전 과제에 대한 접근 방식은 플랫폼마다 다양합니다. Langraph는 워크플로우를 정의하기 위해 명시적인 방향 그래프를 사용하여 개발자에게 세밀한 제어를 제공합니다. Autogen은 에이전트 간의 멀티턴 대화에서 발생하는 신흥 워크플로에 더 의존합니다. CrewAI는 상호 작용을 안내하는 고수준 태스크 플로우를 갖추고 있지만 에이전트들이 서브태스크를 자율적으로 위임하고 응답할 수 있는 유연성을 가지고 있습니다.\n\n이러한 차이점에도 불구하고, 에이전트 상태 및 워크플로우 관리를 위한 일관된 우선순위 목록이 도출됩니다:\n\n- 에이전트가 시간이 지남에 따라 다른 에이전트들의 작업 및 결정을 발전시킬 수 있는 메커니즘 제공\n- 태스크 분할 및 에이전트 조정 패턴의 유연한 정의 가능\n- 에이전트 역할, 도구 및 위임 권한의 태스크별 맞춤화 허용\n- 예외 처리 및 에이전트 출력 간 비선형 종속성 그래프 우아하게 처리\n\n보다시피, 에이전트 AI의 부상은 유연하고 지능적인 자동화의 엄청난 잠재력을 가져옵니다. 특화, 협업, 외부 데이터를 기반으로 한 언어 모델의 강점을 활용하여 이러한 시스템은 기존의 전통적인 AI 접근 방식으로는 이루기 힘든 복잡하고 개방적인 작업에 대처할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이러한 잠재력은 상당한 도전과 함께 옵니다. 그 중에서도 가장 중요한 것은 계획 문제입니다. 어떻게 하면 다양한 AI 에이전트 팀이 효과적으로 행동을 조정하고 불확실성 하에서 결정을 내리며, 동적 환경에서 전략을 적응할 수 있도록 할 수 있을까요? 이것이 에이전트 AI 시스템의 핵심 도전에 대한 핵심을 담고 있습니다.\n\n# 핵심 도전으로서의 계획\n\n에이전트 AI 시스템이 복잡성과 능력을 키우면 효과적인 계획의 필요성이 점점 더 중요해집니다. 이 문맥에서의 계획은 AI 에이전트들이 목표를 달성하기 위해 행동 순서를 결정하고, 다른 에이전트들과 협력하며, 변화하는 상황에 적응하는 과정을 말합니다. 계획은 지적 행동의 기본적인 측면이지만, 에이전트 AI의 영역에서 특히 어려운 도전을 제기합니다.\n\n왜 계획이 특히 복잡한가요, 특히 다중 에이전트 시나리오에서? 이러한 어려움에 기여하는 몇 가지 주요 요소가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 고차원 상태 및 행동 공간: 에이전틱 인공지능에서 상태 공간(환경 및 에이전트의 모든 가능한 구성)과 행동 공간(에이전트가 취할 수 있는 모든 가능한 행동)은 매우 크고 복잡합니다. 이는 각각의 능력과 잠재적 행동을 갖는 여러 에이전트가 상호작용하는 경우 조합 폭발로 인한 것입니다.\n- 부분 관측성: 에이전트들은 종종 환경의 상태와 다른 에이전트의 행동에 대해 불완전한 정보를 갖습니다. 이러한 불확실성으로 인해 행동의 결과를 예측하고 효과적으로 계획하기 어려워집니다.\n- 비정상적인 환경: 다중 에이전트 시스템에서는 환경이 에이전트가 행동을 취하고 서로 상호작용함에 따라 지속적으로 변화합니다. 이러한 비정상성은 시간이 지남에 따라 작용의 효과가 일관되지 않아 계획 과정을 복잡하게 만듭니다.\n- 장기 의존성: 에이전틱 AI의 많은 작업은 단계 간에 의존성을 가진 장기적인 행동 시퀀스를 필요로 합니다. 이러한 확장된 시간 경계를 통해 계획을 수행하는 것은 계산적으로 어려우며 즉시적 보상과 장기적 목표를 균형있게 유지해야 합니다.\n- 조정 및 통신 부담: 다중 에이전트 시스템에서 효과적인 계획은 에이전트 간의 조정이 필요하며 이는 의사 결정 과정에서 추가 복잡성과 병목현상을 초래할 수 있습니다.\n\n이러한 도전에 대처하기 위해 연구자들은 에이전틱 AI의 계획 문제를 마르코프 결정 과정(MDP)으로 정의하고 있습니다. MDP는 상황에 따라 결과가 일부적으로 무작위이고 일부적으로 의사 결정자의 통제 아래 있는 상황에서 의사 결정을 모델링하기 위한 수학적인 프레임워크를 제공합니다.\n\n에이전틱 AI의 맥락에서 MDP의 구성 요소를 다음과 같이 정의할 수 있습니다:\n\n- 상태 공간 (S): 모든 가능한 사고 과정 및 환경 구성의 공간\n- 동작 공간 (A): 사고나 문서 검색의 모든 가능한 조합\n- 전이 역학 (P): 이전 사고와 행동을 기반으로 새로운 사고가 생성되는 방법\n- 보상 함수 (R): 답변의 품질이나 목표에 대한 진전을 평가하는 것\n- 할인 계수 (γ): 단기 vs. 장기적 보상의 우선순위\n- 문제 기간 (T): 허용되는 추론 단계의 최대 수\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n계획 문제를 MDP로 프레임화함으로써, 강화 학습 분야의 다양한 기술을 활용하여 AI의 계획 과제를 해결할 수 있습니다. 그러나 이 정식화는 계획 과정에서 근본적인 긴장을 강조하기도 합니다: 탐험-활용 딜레마.\n\n탐험-활용 딜레마는 새로운 것을 탐색하거나 잘 알려진 좋은 솔루션을 활용하는 사이의 교환 비용을 가리킵니다. 에이전트 AI 계획의 맥락에서 이것은 다음과 같은 균형으로 나타납니다:\n\n- 탐험: 새로운 사고 조합을 시도하거나 다양한 문서를 검색하거나 혁신적인 추론 방향을 추구하여 중요한 솔루션에 이르는 일들에 대한 베스트.\n- 활용: 이미 알려진 효과적인 전략에 초점을 맞추거나 성공적인 사고 과정을 발전시키거나 최대의 즉각적 보상을 위해 기존 솔루션을 정제하는 일에 베스트.\n\n탐험과 활용 사이의 적절한 균형을 찾는 것은 에이전트 AI 시스템에서의 효과적인 계획에 중요합니다. 탐험이 과도하면 낭비되는 컴퓨팅 자원과 일관성 없는 성능을 야기할 수 있으며, 활용이 지나치다면 최적의 솔루션을 허술하게 만들거나 새로운 상황에 적응하지 못하는 문제를 야기할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전통적인 계획 접근 방식인 상징적 AI나 철저한 검색을 기반으로 한 방법은 종종 에이전틱 AI의 맥락에서 이러한 도전 과제를 해결하는 데 어려움을 겪는다. 이러한 방법들은 일반적으로 환경의 완전한 지식, 결정론적 행동 결과, 명확히 정의된 목표 상태에 의존하는데, 이는 에이전틱 AI가 활동하는 복잡하고 불확실하며 개방적인 도메인에서 거의 적용되지 않는 가정들이다.\n\n대신 필요한 건 유연하고 적응적인 계획 접근 방식으로, 다음과 같은 기능을 갖추어야 한다:\n\n- 고차원 상태 및 행동 공간을 효율적으로 처리\n- 부분 관찰 가능성과 불확실성 다루기\n- 비정상적인 환경에 적응하기\n- 복잡한 종속성이 있는 긴 시간 범위에 계획 수립\n- 탐색과 활용을 동적으로 균형있게 유지\n- 여러 전문화된 에이전트 간의 행동 조정\n\n여기서 강화 학습이 등장하여 에이전틱 AI 시스템이 제기하는 독특한 계획 도전 과제를 해결하기에 적합한 강력한 기법 세트를 제공한다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 강화 학습 및 고급 기술로서의 솔루션\n\n강화 학습(RL)은 에이전트형 AI에서 복잡한 계획 도전에 대처하는 유망한 접근법으로 부각되었습니다. RL은 에이전트가 환경과 상호 작용하면서 보상이나 처벌의 형태로 피드백을 받아 결정을 내리는 방식의 머신러닝 유형입니다.\n\n이러한 학습 패러다임은 에이전트형 AI에서 계획 문제에 특히 적합한 이유가 여럿 있습니다:\n\n- 경험으로부터 학습: RL 에이전트들은 환경의 완전한 모델을 요구하지 않고 시행착오를 통해 최적의 전략을 학습할 수 있습니다. 이는 에이전트형 AI가 작동하는 복잡한, 부분 관측 가능한 도메인에서 중요합니다.\n- 탐험과 이용 사이의 균형 유지: RL 알고리즘에는 탐사-이용 교환을 관리하는 내장 기구가 있어, 에이전트들이 새로운 전략을 발견하면서도 알려진 좋은 해결책을 활용할 수 있게 합니다.\n- 불확실성 다루기: RL 방법은 확률적 환경에서 작동하도록 설계되어, 다중 에이전트 시스템에 내재된 불확실성에 탄력적으로 대처할 수 있습니다.\n- 장기 계획: 많은 RL 알고리즘은 명시적으로 장기 보상을 최적화하기 위해 설계되어 있어, 긴 시간 대역으로 계획을 수립하고 행위 간의 복잡한 종속성을 포착할 수 있습니다.\n- 적응성: RL 에이전트들은 새로운 경험을 기반으로 전략을 지속적으로 업데이트할 수 있어, 변동성 있는 환경에 적합합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특히 계획 도전 과제를 해결하는 데 유망한 강화 학습 기법 중 하나는 몬테 카를로 트리 탐색(Monte Carlo Tree Search, MCTS)입니다. MCTS는 휴리스틱 탐색 알고리즘이며, 랜덤 샘플링과 트리 탐색을 결합하여 복잡한 공간에서 결정을 내립니다. 이 기법은 다양한 분야에 성공적으로 적용되었으며, 알파고(AlphaGo)와 같은 게임 플레이 인공지능에서 사용되었습니다.\n\n에이전틱 인공지능 계획의 맥락에서, MCTS는 가능한 사고 과정과 행동 시퀀스의 광범위한 공간을 효율적으로 탐색하는 데 사용될 수 있습니다. MCTS의 주요 단계는 다음과 같습니다:\n\n- 선택(Selection): 루트에서 시작하여 탐색하는 동안 탐색과 활용을 균형있게 고려하는 트리 정책(예: 상한 신뢰 경계)을 사용합니다.\n- 확장(Expansion): 새로운 자식 노드를 추가하여 트리를 확장합니다.\n- 시뮬레이션(Simulation): 새 노드에서 랜덤 시뮬레이션을 실행하여 값을 추정합니다.\n- 역전파(Backpropagation): 루트에 되돌아가는 경로를 따라 노드 통계를 업데이트합니다.\n\n이러한 단계를 반복적으로 적용함으로써, MCTS는 검색 공간의 가장 유망한 지역에 계산 리소스를 집중할 수 있어 에이전틱 인공지능 계획에서 마주치는 고차원 상태 및 행동 공간에 적합합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 중요한 강화 학습 개념 중 하나는 에이전틱 AI 계획에 적용할 수 있는 Q-러닝입니다. Q-러닝은 모델이 없는 강화 학습 알고리즘으로, 주어진 상태에서 특정 행동을 취했을 때 기대되는 누적 보상(Q-값)을 추정하는 방법을 학습합니다. 에이전틱 AI 환경에서는 Q-러닝을 사용하여 다양한 사고 과정이나 문서 검색의 가치를 추정할 수 있습니다.\n\n이 분야의 최근 발전은 이러한 기본적인 강화 학습 개념을 바탕으로 한 몇 가지 혁신적인 접근 방식의 발전을 이끌어내어, 에이전틱 AI 시스템에서 계획 및 추론의 특정 도전 과제를 해결하기 위한 기술적 발전을 이끌어내고 있습니다.\n\n또한 특히 유망한 세 가지 혁신적 기술을 살펴보겠습니다:\n\n## Q*: 딥러닝 계획을 통한 다단계 추론 개선\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWang 및 다른 사람(2024)이 소개한 Q* 프레임워크는 대형 언어 모델(Large Language Models, LLMs)의 다단계 추론 능력을 향상시키는 데 중요한 발전을 이끌어냅니다. Q*는 A* 검색의 능력을 결합하여 학습된 Q-value 모델로 LLMs을 복잡한 추론 작업 중에서 가장 유망한 다음 단계를 선택하도록 안내합니다.\n\nQ*의 주요 특징은 다음과 같습니다:\n\n- 각 노드가 주어진 문제에 대한 부분 솔루션을 나타내는 그래프로 추론 프로세스를 모델링합니다.\n- A* 검색을 위한 학습된 Q-value 모델을 휴리스틱 함수로 사용하여, 전체 문제를 해결하는 데 각 잠재적인 다음 단계가 얼마나 유망한지를 추정합니다.\n- 가능한 추론 경로의 방대한 공간을 효율적으로 탐색하기 위해 몬테카를로 트리 탐색(Monte Carlo Tree Search, MCTS)을 사용합니다.\n- LLM이 자체 정제된 답변에 대한 점수를 매기는 자가 평가 메커니즘을 통합하여 추론 프로세스를 지속적으로 향상시킬 수 있습니다.\n\nQ* 프레임워크는 에이전트 AI 계획에서 몇 가지 중요한 도전에 대처합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 긴 콘텍스트 처리: Q*는 전통적인 LLM의 고정된 콘텍스트 창의 제약을 극복하기 위해 지식 원본에서 대규모 문서 배치를 처리할 수 있습니다.\n- 무관한 정보에 대한 견고성: 다양한 추론 분기를 탐색함으로써 Q*는 실패한 정보 검색 및 오도된 문서에 대해 저항력을 갖습니다.\n- 적응성: 이 프레임워크는 기본 LLM의 작업별 특정 조정 없이 다양한 추론 작업에 적용할 수 있습니다.\n\n실험 결과에 따르면 Q*는 다양한 수학적 추론 및 코드 생성 작업에서 기준선 방법을 크게 앞섰으며, 지식 기반 AI 시스템의 계획 및 추론 능력을 향상시킬 잠재력을 입증했습니다.\n\n## 병렬 함수 호출을 위한 LLM 컴파일러\n\nQ*가 추론 프로세스 자체를 개선하는 데 초점을 맞추고 있을 때, LLM 컴파일러 접근 방식은 에이전틱 AI 계획의 또 다른 중요한 측면을 다룹니다: 병렬 함수 호출의 효율적인 조율. 이 기법은 고전 컴파일러 설계에서 영감을 받아 대규모 언어 모델에서 여러 함수 호출을 실행을 최적화하는 것을 목표로 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM 컴파일러 방식의 주요 측면은 다음과 같습니다:\n\n- 사용자 입력을 상호 의존성을 가진 일련의 작업으로 자동 분해합니다.\n- 독립적인 작업을 병렬로 실행하여 복잡한 워크플로에서 발생하는 지연 시간을 크게 감소시킵니다.\n- 작업의 방향성 비순환 그래프(DAG)를 생성하는 계획 단계를 통해 효율적인 일정 계획 및 실행이 가능합니다.\n- 외부 도구 및 API와 통합하여 LLM의 능력을 언어 처리 이상으로 확장합니다.\n\nLLM 컴파일러는 공별한 AI 계획에서 여러 중요한 도전 과제를 다룹니다:\n\n- 효율성: 병렬화 가능한 패턴을 식별하고 함수 호출 의존성을 관리함으로써, 컴파일러는 복잡한 작업의 지연 시간을 크게 줄일 수 있습니다.\n- 확장성: 이 방식은 다수의 함수 호출과 데이터 의존성이 포함된 대규모 및 복잡한 작업을 다루도록 설계되었습니다.\n- 유연성: 컴파일러는 다양한 종류의 LLM 및 작업 부하에 적응할 수 있어 다양한 AI 응용 프로그램에 대한 다재다능한 도구가 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n초기 결과에 따르면, LLM 컴파일러는 순차 실행 방법과 비교하여 상당한 속도 향상을 달성할 수 있다는 것이 밝혀졌습니다. 최대 3.7배의 대기 시간 개선과 일부 작업에서 최대 6.7배까지의 비용 절감이 가능합니다.\n\n## 수학 올림피아드 솔루션을 위한 몬테카를로 트리 자기 수정\n\n타 분야에서 MCTS의 성공을 바탕으로, 연구자들은 복잡한 수리 추론 작업, 특히 수학 올림피아드에서 마주하는 작업들을 처리하기 위해 특별히 개발된 몬테카를로 트리 자기 수정(MCTSr) 알고리즘을 개발했습니다.\n\nMCTSr의 주요 기능은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 대규모 언어 모델과 몬테카를로 트리 탐색을 통합하여 문제 해결 능력을 향상시킵니다.\n- 선택, 자가 세부화, 자가 평가 및 역전파 단계를 포함하는 반복적인 과정입니다.\n- 모델이 솔루션을 반복적으로 향상시킬 수 있는 피드백 안내형 세분화 과정입니다.\n- 진정으로 개선된 솔루션이 높은 점수를 받도록 하는 엄격하고 비판적인 점수 매커니즘입니다.\n\nMCTSr은 수학적 추론과 계획에서 여러 가지 도전에 대응합니다:\n\n- 복잡한 다단계 문제 다루기: 이 알고리즘은 다단계 추론 단계와 전략적 사고가 필요한 복잡한 수학적 작업을 다루도록 설계되었습니다.\n- 지속적인 개선: 자가 세부화 및 자가 평가 메커니즘을 통해 MCTSr은 솔루션 품질을 점진적으로 향상시킬 수 있습니다.\n- 다양한 문제 유형에 대한 적응성: 이 프레임워크는 초등학교 산술부터 올림피아드 수준의 도전 과제까지 다양한 수학 영역에서 성공을 거두었습니다.\n\n실험 결과에서는 MCTSr이 LLaMA-3 8B와 같은 훨씬 작은 모델을 사용하여 수학 올림피아드 문제에서 GPT-4 수준의 성능을 달성할 수 있다는 것을 입증하였으며, 이는 인공지능 시스템의 추론 능력을 혁신적으로 향상시킬 잠재력을 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 세 가지 접근법인 Q*, LLM Compiler 및 MCTSr은 에이전틱 AI의 계획 및 추론 기술의 최신 동향을 대표합니다. 이러한 방법들은 강화 학습 원칙과 혁신적인 탐색 및 최적화 전략을 결합하여 AI 주도 문제 해결에서 가능한 범위를 넓히고 있습니다.\n\n그러나 이러한 고급 기술을 에이전틱 AI 계획에 적용하는 데는 다음과 같은 도전 과제가 있습니다:\n\n- 계산 복잡성: 이러한 방법들은 대부분 고도의 계산 과정을 통합하며, 대규모 응용 프로그램에는 리소스가 많이 필요할 수 있습니다.\n- 탐험과 활용의 균형: 새로운 솔루션을 발견하고 기존의 좋은 전략을 활용하는 적절한 균형을 찾는 것은 여전히 까다로운 작업입니다.\n- 해석 가능성: 이러한 시스템이 더 복잡해지면서 의사 결정 과정에서의 투명성과 해석 가능성을 보장하는 것이 점점 어려워지고 있습니다.\n- 일반화: 이러한 방법은 특정 도메인에서 인상적인 결과를 보여주었지만, 다양한 작업 유형 간의 일반화 능력을 평가하기 위해 추가 연구가 필요합니다.","ogImage":{"url":"/assets/img/2024-06-23-PlanningastheCoreChallengeinAgenticAISolvingitwithReinforcementLearning_0.png"},"coverImage":"/assets/img/2024-06-23-PlanningastheCoreChallengeinAgenticAISolvingitwithReinforcementLearning_0.png","tag":["Tech"],"readingTime":12},{"title":"LLM 출력 구조화하는 방법 안내","description":"","date":"2024-06-23 19:40","slug":"2024-06-23-GuidinganLLMsResponsetoCreateStructuredOutput","content":"\n\n![2024-06-23-GuidinganLLMsResponsetoCreateStructuredOutput_0.png](/assets/img/2024-06-23-GuidinganLLMsResponsetoCreateStructuredOutput_0.png)\n\n이 기사는 Python에서 유효성 검사 라이브러리를 사용하여 GPT-4 또는 Llama 3와 같은 LLM 응답을 구조화하는 방법을 가르쳐줍니다.\n\nJSON 형식에서 구조화된 정보를 추출해야 하는 필요성은 매우 중요한 주제이며, 이것은 데이터 마이닝 작업에서 정확한 정보를 비구조적 형식(예: 자유 텍스트)에서 추출하는 데 기본적입니다.\n\n또한, LLM의 출력 토큰을 생성하는 과정에서 발생하는 확률적 특성으로 인해 GPT와 같은 상업용 시스템에서도 구조화된 응답 형식이 신뢰할 수 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 유효성 검사와 스키마 모델링을 위해 Pydantic와 Instructor와 같은 여러 라이브러리를 사용할 것이고, LLM 부분에는 OpenAI와 ollama를 활용할 것입니다. 제안된 내용은 OpenAI나 Anthropic과 같은 폐쇄 소스 모델뿐만 아니라 Llama 3와 같은 오픈 소스 모델에 대해서도 유효합니다.\n\n본 기사를 통해 아래 내용을 배울 수 있습니다:\n\n- 데이터 모델을 정의하는 방법과 그것이 무엇인지\n- LLM이 출력 형식을 준수하는지를 유효성 규칙을 통해 확인하는 방법\n- Instructor와 Pydantic 라이브러리를 사용하는 방법\n\n즐거운 독해 되세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 구조화된 출력이 필요한 이유\n\nGPT-4와 같은 LLM은 특정 패턴을 따르지 않고도 상당한 가치를 제공할 수 있습니다. 하지만 데이터를 다루는 프로그래머들에게는 사용자의 의지에 따라 가능한 출력 패턴을 준수하는 것이 중요합니다.\n\nGPT-3.5의 특정 버전부터 OpenAI는 완성 API에 response_format 매개변수를 추가했습니다. 이를 통해 사용자는 json_object와 같은 다른 키를 정의하여 모델을 입력한 프롬프트에 더 적합한 응답 방향으로 안내할 수 있습니다.\n\n다음은 예시입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo-0125\",\n  response_format={ \"type\": \"json_object\" },\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}\n  ]\n)\nprint(response.choices[0].message.content)\n\n\u003e\u003e\u003e \"content\": \"{\\\"winner\\\": \\\"Los Angeles Dodgers\\\"}\"\n```\n\n하지만 이러한 로직이 항상 작동하는 것은 아닙니다. 실제로 OpenAI의 문서에서는 GPT가 이를 생성하는 데 도움을 주기 위해 프롬프트에 \"JSON\"이라는 단어를 명확하게 작성할 것을 제안합니다. 이는 \"response_format={ \"type\": \"json_object\" }\"를 사용할 때 프롬프트 어딘가에 이를 작성해야만 하는 중요한 팁이기 때문에 강제적으로 작성해야 합니다.\n\n## LLM이 일관된 JSON 출력을 생성하기 어려운 이유는 무엇인가요?\n\nLLM은 입력 프롬프트가 주어졌을 때 이전 토큰 다음에 더 많이 나올 가능성이 있는 다음 토큰을 반환하는 기계로서의 역할을 합니다. 실제로 이러한 형식을 보고 이해하려면 모델이 훈련 단계에서 명시적으로 이러한 형식을 보고 이해하기 위해 안내받아야만 하므로 이러한 패턴을 \"자연\"에서 만나기 어렵습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최신 LLM의 JSON 모드는 출력이 특정 패턴과 일치한다고 보장하지 않습니다. 단지 유효하고 오류 없이 파싱된다는 것만을 보장합니다.\n\n따라서 이러한 출력물 안에 무엇이 포함되어 있는지를 유효성 검사할 수 있고, 데이터 모델과 일치하지 않는 경우 예외와 오류를 발생시키는 것이 중요합니다.\n\n# 사용 사례\n\n우리는 GPT-4 또는 Llama3와 같은 LLM에 간단한 질문에서 시작하여 JSON에서 정보를 추출하는 예제를 살펴볼 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 무엇이든 물어볼 수 있지만, 모델에게 시간이 지남에 따른 축구 월드컵 우승팀에 관한 질문을 하려고 합니다.\n\n특히 우리는 다음을 추출하고 싶습니다.\n\n- 결승 일자\n- 대회의 개최 국가\n- 우승 팀\n- 최다 득점자\n\n우리는 데이터의 정확성을 확인하는 것이 아니라, LLM의 문장 응답을 다음으로 보여줄 스키마에 맞추는 것에만 신경을 쓸 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 이 예제를 살펴보고 다른 것들도 살펴볼 수 있을 것 같아요.\n\n## 필수 종속성\n\n이제 이 튜토리얼을 실행하기 위해 설치해야 할 종속성을 살펴봅시다.\n\n당연히, 이미 활성화된 개발 환경이 있다고 가정하고 Pydantic, Instructor, OpenAI 클라이언트 및 ollama를 설치할 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Pydantic: 커뮤니티에서 널리 사용되는 데이터 모델 정의 및 유효성 검사 라이브러리로, 사용 편의성, 효율성 및 데이터 과학에서의 중요성으로 유명합니다.\n- Instructor: LLMs와 작업하기 위해 특별히 제작된 Pydantic을 감싸는 래퍼로, 유효성 검사 로직을 생성할 수 있는 라이브러리입니다.\n- OpenAI: GPT와 다른 OpenAI 모델에 쿼리를 요청하기 위한 유명한 클라이언트입니다.\n- ollama: llama3와 같은 오픈 소스 LLM에 대한 매우 편리한 인터페이스입니다.\n\n개발 환경에서는 다음 명령어를 사용하여 시작합니다.\n\n```bash\npip install pydantic instructor openai ollama\n```\n\n오픈 소스 모델을 테스트하고자 하기 때문에 다음 단계는 ollama를 시스템 전역에 설치하는 것입니다. ollama의 설치 및 사용 방법은 이 특별한 기사에서 읽어보실 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 개발에 집중할 수 있겠네요.\n\n## 데이터 모델 정의\n\n데이터 모델은 데이터를 구조화하기 위해 따를 논리적인 패턴입니다. 데이터베이스의 테이블을 정의하는 것부터 입력 데이터를 유효성 검사하는 데까지 여러 맥락에서 사용됩니다.\n\n아래 포스트에서 Pydantic을 활용한 데이터 과학과 머신러닝에서의 데이터 모델링에 대해 이미 약간 다룬 적이 있습니다 👇\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이던틱 데이터 모델을 만들어 보면 좋겠어요:\n\n```js\nfrom pydantic import BaseModel, Field\nfrom typing import List\nimport datetime\n\nclass SoccerData(BaseModel):\n    date_of_final: datetime.date = Field(..., description=\"최종 이벤트 날짜\")\n    hosting_country: str = Field(..., description=\"대회를 개최하는 국가\")\n    winner: str = Field(..., description=\"최종 경기에서 우승한 축구팀\")\n    top_scorers: list = Field(\n        ..., description=\"대회의 상위 3명 스코어러 목록\"\n    )\n\nclass SoccerDataset(BaseModel):\n    reports: List[SoccerData] = []\n```\n\n이 스크립트에서는 Pydantic에서 BaseModel 및 Field 클래스를 가져와 데이터 모델을 만드는 작업을 시작합니다. 사실, 최종 결과가 가져야 할 구조를 만들고 있습니다.\n\nPydantic은 모델에 들어가는 데이터 유형을 선언해야 합니다. 예를 들어 datetime.date는 날짜 필드가 문자열이 아니라 날짜여야 함을 강제합니다. 동시에 top_scorers 필드는 반드시 목록이어야 하며, 그렇지 않으면 Pydantic이 유효성 검사 오류를 반환할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마침내, 여러 인스턴스를 수집하는 데이터 모델을 만들었습니다. 이것은 SoccerData 모델의 모음을 수집하는 SoccerDataset이라고 합니다. 이 모델은 한 개 이상의 보고서가 있는지 확인하기 위해 강사에 의해 사용될 것입니다.\n\n# 시스템 프롬프트 생성\n\n매우 간단히, 모델이 수행해야 하는 작업을 영어로 적어봅시다. 예를 통해 결과의 의도와 구조를 강조하면서 설명합니다.\n\n```js\nsystem_prompt = \"\"\"당신은 숙련된 스포츠 기자입니다. 특정 연도의 축구 월드컵에서 우승한 팀에 대한 작은 리포트를 작성할 것입니다. 대회 결승전 날짜, 대회 전체에서 상위 3 스코어러, 우승 팀, 그리고 대회를 주최한 국가를 보고합니다. 다음 필드를 포함하는 JSON 객체를 반환하세요: date_of_final, hosting_country, winner, top_scorers.\\\n \n만약 다수 연도가 입력되면, 보고서를 쉼표로 구분하세요.\\\n \n다음은 예시입니다.\n [\n    {\n        \"date_of_final\": \"1966\",\n        \"hosting_country\": \"England\",\n        \"winner\": \"England\",\n        \"top_scorers\": [\"Player A\", \"Player B\", \"Player C\"]\n    },\n    {\n        \"date_of_final\": ...\n        \"hosting_country\": ...\n        \"winner\": ...\n        \"top_scorers\": ...\n    },\n\n]\n\n다음 연도들에 대해 보고해야 할 것입니다:\n\n \"\"\"\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템 프롬프트로 사용되며 단순히 쉼표로 구분된 연도를 전달할 수 있습니다.\n\n# 강사 코드 생성\n\n여기서는 Instructor를 사용하여 JSON 유효성 검사 및 구조화의 주요 로직을 만들 것입니다. 이를 통해 GPT를 API를 통해 호출하는 OpenAI에서 제공하는 인터페이스와 유사한 인터페이스를 사용합니다.\n\n먼저 우리는 query_gpt라는 함수를 사용하여 OpenAI를 사용하여 프롬프트를 매개변수화할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom openai import OpenAI\nimport instructor\n\ndef query_gpt(prompt: str) -\u003e list:\n    client = instructor.from_openai(OpenAI(api_key=\"...\"))\n    resp = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=SoccerDataset,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": prompt},\n        ],\n    )\n    return resp.model_dump_json(indent=4)\n```\n\nOpenAI API 키를 새롭게 생성된 클라이언트에 전달하는 것을 잊지 말자. 우리는 GPT-3.5-Turbo를 사용하고, 응답 모델로 SoccerDataset을 전달할 것이다. 또한, 이 기사를 작성하는 시점에서 가장 강력한 모델인 \"gpt-4o\"를 사용할 수도 있다.\n\n모든 것을 함께 조합하여 소프트웨어를 실행해 보자. 사용자 프롬프트로 입력할 내용으로 \"2010, 2014 및 2018\"년을 내용으로 전달하여 구조화된 보고서를 생성하고자 한다. \n\n```js\nfrom openai import OpenAI\nimport instructor\n\nfrom typing import List\nfrom pydantic import BaseModel, Field\nimport datetime\n\n\nclass SoccerData(BaseModel):\n    date_of_final: datetime.date = Field(..., description=\"최종 이벤트의 날짜\")\n    hosting_country: str = Field(..., description=\"대회를 주최하는 나라\")\n    winner: str = Field(..., description=\"최종 경기에서 승리한 축구팀\")\n    top_scorers: list = Field(\n        ..., description=\"대회의 상위 3명의 득점수 리스트\"\n    )\n\n\nclass SoccerDataset(BaseModel):\n    reports: List[SoccerData] = []\n\n\nsystem_prompt = \"\"\"당신은 전문 스포츠 기자입니다. 특정 연도의 축구 월드컵에서 승자를 작은 보고서로 작성해야 합니다.\n대회 최종일, 대회의 전체 득점수 상위 3명, 우승 팀 및 대회를 개최하는 국가를 보고해야 합니다.\n다음 필드를 포함한 JSON 객체를 반환하세요: date_of_final, hosting_country, winner, top_scorers.\n\n쿼리가 유효하지 않은 경우 빈 보고서를 반환하세요.\n\n여러 연도가 입력된 경우 보고서를 쉼표로 구분하세요.\n\n예시입니다\n[\n    {\n        \"date_of_final\": \"1966\",\n        \"hosting_country\": \"England\",\n        \"winner\": \"England\",\n        \"top_scorers\": [\"Player A\", \"Player B\", \"Player C\"]\n    },\n    {\n        \"date_of_final\": ...\n        \"hosting_country\": ...\n        \"winner\": ...\n        \"top_scorers\": ...\n    },\n\n]\n\n다음 보고가 필요한 연도입니다:\n\n\"\"\"\n\ndef query_gpt(prompt: str) -\u003e list:\n    client = instructor.from_openai(OpenAI())\n    resp = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=SoccerDataset,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": prompt},\n        ],\n    )\n    return resp.model_dump_json(indent=4)\n\nif __name__ == \"__main__\":\n  resp = query_llm(\"2010, 2014, 2018\")\n  print(resp)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 문구를 Markdown 형식으로 변환한 결과입니다:\n\n```json\n{\n    \"reports\": [\n        {\n            \"date_of_final\": \"2010-07-11\",\n            \"hosting_country\": \"South Africa\",\n            \"winner\": \"Spain\",\n            \"top_scorers\": [\n                \"Thomas Müller\",\n                \"David Villa\",\n                \"Wesley Sneijder\"\n            ]\n        },\n        {\n            \"date_of_final\": \"2014-07-13\",\n            \"hosting_country\": \"Brazil\",\n            \"winner\": \"Germany\",\n            \"top_scorers\": [\n                \"James Rodríguez\",\n                \"Thomas Müller\",\n                \"Neymar\"\n            ]\n        },\n        {\n            \"date_of_final\": \"2018-07-15\",\n            \"hosting_country\": \"Russia\",\n            \"winner\": \"France\",\n            \"top_scorers\": [\n                \"Harry Kane\",\n                \"Antoine Griezmann\",\n                \"Romelu Lukaku\"\n            ]\n        }\n    ]\n}\n```\n\n멋지네요. GPT-3.5-Turbo가 우리의 지시를 완벽하게 따르고, Instructor가 데이터 모델과 일치하는 구조를 만들어내었습니다. 실제로 이 결과는 GPT와 같은 대형 언어 모델이 일반적으로 반환하는 문자열이 아니라, 파이썬 사전의 리스트입니다.\n\n이제 이상한 입력을 넣어보려고 해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nif __name__ == \"__main()\":\n      print(query_gpt(\"안녕, 어떻게 지내?\"))\n\n\u003e\u003e\u003e\n{\n \"리포트\": []\n}\n```\n\nLLM은 시스템 프롬프트를 통해 잘못된 쿼리를 처리하는 방법을 요청했기 때문에 올바르게 비어있는 리포트를 반환합니다.\n\n# Instructor와 함께 오픈 소스 템플릿 사용\n\nInstructor를 사용하여 GPT를 어떻게 사용하여 구조화된 JSON 출력을 얻는지 알아보았습니다. 이제 llama3와 같은 오픈 소스 템플릿을 사용하는 방법을 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새로운 함수인 query_llama을 생성해 봅시다.\n\n```js\ndef query_llama(prompt: str) -\u003e list:\n    client = instructor.from_openai(\n        OpenAI(\n            base_url=\"http://localhost:11434/v1\",\n            api_key=\"ollama\",  # 요청은 필요하지만 영향을 미치지 않습니다\n        ),\n        mode=instructor.Mode.JSON,\n    )\n    resp = client.chat.completions.create(\n        model=\"llama3\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": system_prompt\n            },\n            {\n                \"role\": \"user\",\n                \"content\": prompt\n            }\n        ],\n        response_model=SoccerDataset,\n    )\n    return resp.model_dump_json(indent=4)\n```\n\nGPT 코드와 약간의 차이가 있습니다. 함께 살펴보겠습니다.\n\n- ollama는 GPT와 동일한 인터페이스를 통해 호출되지만, 기본 URL 포인터(base_url) 및 필수적이지만 올바른 작동에 필요하지 않은 API 키를 변경합니다(왜냐면 모르겠어요)\n- JSON 모드를 mode 매개변수를 통해 설명해야 합니다.\n새로운 함수를 실행해 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n함수를 실행해 봅시다.\n\n```js\r\nif __name__ == \"__main__\":\n    print(query_llama(\"2010, 2014, 2018\"))\r\n```\n\n그리고 여기에 결과가 있습니다:\n\n```js\r\n{\n    \"reports\": [\n        {\n            \"date_of_final\": \"2010-07-11\",\n            \"hosting_country\": \"South Africa\",\n            \"winner\": \"Spain\",\n            \"top_scorers\": [\n                \"Thomas Müller\",\n                \"Wolfram Toloi\",\n                \"Landon Donovan\"\n            ]\n        },\n        {\n            \"date_of_final\": \"2014-07-13\",\n            \"hosting_country\": \"Brazil\",\n            \"winner\": \"Germany\",\n            \"top_scorers\": [\n                \"James Rodríguez\",\n                \"Miroslav Klose\",\n                \"Thomas Müller\"\n            ]\n        },\n        {\n            \"date_of_final\": \"2018-07-15\",\n            \"hosting_country\": \"Russia\",\n            \"winner\": \"France\",\n            \"top_scorers\": [\n                \"Harry Kane\",\n                \"Kylian Mbappé\",\n                \"Antoine Griezmann\"\n            ]\n        }\n    ]\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 올바른 JSON이 있는 목록을 가지고 있어요! 이 모든 것은 Llama 3로 로컬에서 이루어져요.\n\n이전에 말한대로, 유효성 검사는 구조를 기반으로 하고 있어요. 실제로, 이 내용은 GPT에서 생성된 내용과 다를 수 있어요.\n\n어떻게 마커들이 다른지 살펴봅시다. 아마도 우리가 받고 싶은 마커들을 명확히 지정하면 올바른 목록을 얻을 수도 있겠죠.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPydantic, Instructors, 그리고 ollama를 사용하여 LLM의 출력을 JSON과 같은 구조화된 형식으로 변환하는 방법을 살펴봤습니다.\n\n이 과정에서 모델이 실제로 지도되므로 결정론적이지 않습니다. JSON이 LLM의 결정론적이지 않은 성질로 인해 준수되지 않을 수 있는 경우가 있을 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-GuidinganLLMsResponsetoCreateStructuredOutput_0.png"},"coverImage":"/assets/img/2024-06-23-GuidinganLLMsResponsetoCreateStructuredOutput_0.png","tag":["Tech"],"readingTime":12}],"page":"8","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"8"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>