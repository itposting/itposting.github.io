<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/25" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/25" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-2d104a861d88ea21.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="PDF 파싱의 신비를 해부하다 03 OCR이 필요 없는 소형 모델 기반 방법" href="/post/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="PDF 파싱의 신비를 해부하다 03 OCR이 필요 없는 소형 모델 기반 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="PDF 파싱의 신비를 해부하다 03 OCR이 필요 없는 소형 모델 기반 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">PDF 파싱의 신비를 해부하다 03 OCR이 필요 없는 소형 모델 기반 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">27<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="문서챗 데이터를 손쉽게 탐색하고 이해하는 데 도움이 되는 방법  파트 1" href="/post/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="문서챗 데이터를 손쉽게 탐색하고 이해하는 데 도움이 되는 방법  파트 1" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="문서챗 데이터를 손쉽게 탐색하고 이해하는 데 도움이 되는 방법  파트 1" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">문서챗 데이터를 손쉽게 탐색하고 이해하는 데 도움이 되는 방법  파트 1</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="주식 예측을 위한 심층 강화학습" href="/post/2024-06-19-ForecastingStockUsingDeepReinforcementLearning"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="주식 예측을 위한 심층 강화학습" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="주식 예측을 위한 심층 강화학습" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">주식 예측을 위한 심층 강화학습</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">62<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="다중 헤드 어텐션  공식적으로 설명하고 정의하기" href="/post/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="다중 헤드 어텐션  공식적으로 설명하고 정의하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="다중 헤드 어텐션  공식적으로 설명하고 정의하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">다중 헤드 어텐션  공식적으로 설명하고 정의하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법" href="/post/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="시계열 분할 기술 정확한 모델 유효성 검증 보장하기" href="/post/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="시계열 분할 기술 정확한 모델 유효성 검증 보장하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="시계열 분할 기술 정확한 모델 유효성 검증 보장하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">시계열 분할 기술 정확한 모델 유효성 검증 보장하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="죄를 사과하지 않는 일로 상처 받은 모든 것에 대해 치유되길 바라요" href="/post/2024-06-19-ihopeyouhealfromthethingsthatnooneeverapologizedfor"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="죄를 사과하지 않는 일로 상처 받은 모든 것에 대해 치유되길 바라요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ihopeyouhealfromthethingsthatnooneeverapologizedfor_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="죄를 사과하지 않는 일로 상처 받은 모든 것에 대해 치유되길 바라요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">죄를 사과하지 않는 일로 상처 받은 모든 것에 대해 치유되길 바라요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="장기 단기 메모리 LSTM  RNN 개선하기" href="/post/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="장기 단기 메모리 LSTM  RNN 개선하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="장기 단기 메모리 LSTM  RNN 개선하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">장기 단기 메모리 LSTM  RNN 개선하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="왜 나는 글쓰기를 그만두지 않을 것인지 이유" href="/post/2024-06-19-ThisIsWhyIWillNotStopWriting"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="왜 나는 글쓰기를 그만두지 않을 것인지 이유" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ThisIsWhyIWillNotStopWriting_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="왜 나는 글쓰기를 그만두지 않을 것인지 이유" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">왜 나는 글쓰기를 그만두지 않을 것인지 이유</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">1<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="위성 이미지에서 GANs적대적 생성 신경망을 사용하여 구름 제거하기" href="/post/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="위성 이미지에서 GANs적대적 생성 신경망을 사용하여 구름 제거하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="위성 이미지에서 GANs적대적 생성 신경망을 사용하여 구름 제거하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">위성 이미지에서 GANs적대적 생성 신경망을 사용하여 구름 제거하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">25<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link posts_-active__YVJEi" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"PDF 파싱의 신비를 해부하다 03 OCR이 필요 없는 소형 모델 기반 방법","description":"","date":"2024-06-19 19:16","slug":"2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod","content":"\n\nPDF 파일을 다른 형식으로 변환하는 것은 도전적일 수 있습니다. 종종 AI 애플리케이션에서 접근할 수 없는 형식에 상당한 정보를 잠그기 때문입니다. 만약 PDF 파일이나 해당 이미지를 기계가 읽을 수 있는 구조화된 또는 반구조화된 형식으로 변환할 수 있다면, 이 문제를 상당히 완화할 수 있을 것입니다. 이는 인공지능 애플리케이션의 지식 베이스를 크게 향상시킬 수도 있습니다.\n\n이 연재는 PDF 구문 분석을 해석하는 데 전념하고 있습니다. 본 시리즈의 첫 번째 기사에서는 PDF 구문 분석의 주요 작업을 소개하고 기존 방법을 분류하며 각 방법에 대한 간략한 소개를 제공했습니다. 그리고 이 시리즈의 두 번째 기사에서는 파이프라인 기반 방법에 초점을 맞췄습니다.\n\n본 기사는 이 시리즈의 세 번째로, PDF 구문 분석에 대한 또 다른 접근 방식을 소개합니다: OCR 없는 소형 모델 기반 방법. 접근 방식을 개괄한 다음, 다양한 대표적인 OCR 없는 소형 모델 기반 PDF 구문 분석 솔루션의 원칙을 소개합니다. 마지막으로, 얻은 통찰과 생각을 공유합니다.\n\n본 기사에서 언급하는 \"소형 모델\"은 일반적으로 30억 개의 파라미터보다 적은 파라미터를 가질 정도로 상대적으로 작은 모델을 의미합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 개요\n\n이전에 소개된 파이프라인 기반 PDF 구문 분석 방법은 주로 텍스트 인식을 위해 OCR 엔진을 사용합니다. 그러나 이는 계산 비용이 높아지고 언어 및 문서 유형에 대한 유연성이 결여되며, 잠재적인 OCR 오류가 후속 작업에 영향을 줄 수 있습니다.\n\n따라서 OCR 없는 방법이 개발되어야 합니다. 이는 그림 1에 설명된 대로 OCR을 명시적으로 사용하지 않습니다. 대신, 신경망을 사용하여 암묵적으로 작업을 완료합니다. 본질적으로 이러한 방법은 끝에서 끝까지 접근 방식을 채택하여 PDF 구문 분석 결과를 직접 출력합니다.\n\n구조적 관점에서 OCR 없는 방법은 파이프라인 기반 방법보다 간단합니다. 관심을 불러일으킬 OCR 없는 방법의 주요 측면은 모델 구조의 설계와 훈련 데이터의 구축입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 몇 가지 대표적인 OCR 미사용 소형 모델 기반 PDF 구문 분석 프레임워크를 소개하겠습니다:\n\n- Donut: OCR 미사용 문서 이해 트랜스포머.\n- Nougat: Donut 아키텍처를 기반으로 하며, PDF 문서, 수식 및 표와 같은 문서에서 특히 효과적입니다.\n- Pix2Struct: 시각 언어 이해를 위한 사전 교육으로 스크린샷 파싱.\n\n## Donut\n\n그림 2에서 설명한 것처럼 Donut은 문서 이미지를 종합적으로 이해하기 위해 설계된 엔드투엔드 모델입니다. 그 아키텍처는 transformer 기반의 시각 인코더와 텍스트 디코더 모듈로 구성되어 간단합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도넛은 OCR과 관련된 어떤 모듈에도 의존하지 않습니다. 대신 문서 이미지에서 특징을 추출하기 위해 시각 인코더를 사용하고, 텍스트 디코더를 사용하여 토큰 시퀀스를 직접 생성합니다. 출력된 시퀀스는 JSON과 같은 구조화된 형식으로 변환할 수 있습니다.\n\n다음은 코드입니다:\n\n```js\nclass DonutModel(PreTrainedModel):\n    r\"\"\"\n    도넛(Donut): OCR 미사용 문서 이해 트랜스포머.\n    인코더는 입력 문서 이미지를 임베딩 세트로 매핑하고,\n    디코더는 원하는 토큰 시퀀스를 예측합니다. 이는 구조화된 형식으로 변환될 수 있으며,\n    프롬프트와 인코더 출력 임베딩이 주어질 때\n    \"\"\"\n    config_class = DonutConfig\n    base_model_prefix = \"donut\"\n\n    def __init__(self, config: DonutConfig):\n        super().__init__(config)\n        self.config = config\n        self.encoder = SwinEncoder(\n            input_size=self.config.input_size,\n            align_long_axis=self.config.align_long_axis,\n            window_size=self.config.window_size,\n            encoder_layer=self.config.encoder_layer,\n            name_or_path=self.config.name_or_path,\n        )\n        self.decoder = BARTDecoder(\n            max_position_embeddings=self.config.max_position_embeddings,\n            decoder_layer=self.config.decoder_layer,\n            name_or_path=self.config.name_or_path,\n        )\n\n    def forward(self, image_tensors: torch.Tensor, decoder_input_ids: torch.Tensor, decoder_labels: torch.Tensor):\n        \"\"\"\n        입력 이미지와 원하는 토큰 시퀀스가 주어졌을 때 손실을 계산하고,\n        모델은 teacher-forcing 방식으로 훈련될 것입니다.\n\n        Args:\n            image_tensors: (batch_size, num_channels, height, width)\n            decoder_input_ids: (batch_size, sequence_length, embedding_dim)\n            decode_labels: (batch_size, sequence_length)\n        \"\"\"\n        encoder_outputs = self.encoder(image_tensors)\n        decoder_outputs = self.decoder(\n            input_ids=decoder_input_ids,\n            encoder_hidden_states=encoder_outputs,\n            labels=decoder_labels,\n        )\n        return decoder_outputs\n    ...\n    ...\n```\n\n## 인코더\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도넛은 초기 문서 구문 분석 연구에서 우수한 성능을 나타낸 Swin-Transformer를 이미지 인코더로 활용합니다. 이 이미지 인코더는 입력 문서 이미지를 고차원 임베딩 집합으로 변환합니다. 이러한 임베딩은 텍스트 디코더의 입력으로 사용될 것입니다.\n\n해당 코드는 다음과 같습니다.\n\n```js\nclass SwinEncoder(nn.Module):\n    r\"\"\"\n    SwinTransformer를 기반으로 한 도넛 인코더\n    사전 훈련된 SwinTransformer를 사용하여 초기 가중치와 구성을 설정한 후, \n    도넛 인코더로 세부 구성을 수정합니다.\n\n    매개변수:\n        input_size: 입력 이미지 크기 (폭, 높이)\n        align_long_axis: 높이가 폭보다 크면 이미지를 회전할지 여부\n        window_size: SwinTransformer의 창 크기(=패치 크기)\n        encoder_layer: SwinTransformer 인코더의 레이어 수\n        name_or_path: huggingface.co에 등록된 사전 훈련된 모델 이름 또는 로컬에 저장된 모델 이름\n                      그렇지 않으면 `swin_base_patch4_window12_384`가 설정될 것입니다(`timm` 사용).\n    \"\"\"\n\n    def __init__(\n        self,\n        input_size: List[int],\n        align_long_axis: bool,\n        window_size: int,\n        encoder_layer: List[int],\n        name_or_path: Union[str, bytes, os.PathLike] = None,\n    ):\n        super().__init__()\n        self.input_size = input_size\n        self.align_long_axis = align_long_axis\n        self.window_size = window_size\n        self.encoder_layer = encoder_layer\n\n        self.to_tensor = transforms.Compose(\n            [\n                transforms.ToTensor(),\n                transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n            ]\n        )\n\n        self.model = SwinTransformer(\n            img_size=self.input_size,\n            depths=self.encoder_layer,\n            window_size=self.window_size,\n            patch_size=4,\n            embed_dim=128,\n            num_heads=[4, 8, 16, 32],\n            num_classes=0,\n        )\n        self.model.norm = None\n\n        # Swin 가중치 초기화\n        if not name_or_path:\n            swin_state_dict = timm.create_model(\"swin_base_patch4_window12_384\", pretrained=True).state_dict()\n            new_swin_state_dict = self.model.state_dict()\n            for x in new_swin_state_dict:\n                if x.endswith(\"relative_position_index\") or x.endswith(\"attn_mask\"):\n                    pass\n                elif (\n                    x.endswith(\"relative_position_bias_table\")\n                    and self.model.layers[0].blocks[0].attn.window_size[0] != 12\n                ):\n                    pos_bias = swin_state_dict[x].unsqueeze(0)[0]\n                    old_len = int(math.sqrt(len(pos_bias)))\n                    new_len = int(2 * window_size - 1)\n                    pos_bias = pos_bias.reshape(1, old_len, old_len, -1).permute(0, 3, 1, 2)\n                    pos_bias = F.interpolate(pos_bias, size=(new_len, new_len), mode=\"bicubic\", align_corners=False)\n                    new_swin_state_dict[x] = pos_bias.permute(0, 2, 3, 1).reshape(1, new_len ** 2, -1).squeeze(0)\n                else:\n                    new_swin_state_dict[x] = swin_state_dict[x]\n            self.model.load_state_dict(new_swin_state_dict)\n\n    def forward(self, x: torch.Tensor) -\u003e torch.Tensor:\n        \"\"\"\n        매개변수:\n            x: (배치 크기, 채널 수, 높이, 너비)\n        \"\"\"\n        x = self.model.patch_embed(x)\n        x = self.model.pos_drop(x)\n        x = self.model.layers(x)\n        return x\n    ...\n    ...\n```\n\n## 디코더\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도넛은 디코더로 BART를 사용합니다.\n\n```js\nclass BARTDecoder(nn.Module):\n    \"\"\"\n    다국어 BART 기반의 도넛 디코더\n    사전 훈련된 다국어 BART 모델의 초기 가중치와 구성을 설정하고,\n    이를 도넛 디코더로 수정해 세부 구성을 변경합니다.\n\n    Args:\n        decoder_layer:\n            BARTDecoder의 레이어 수\n        max_position_embeddings:\n            훈련할 최대 시퀀스 길이\n        name_or_path:\n            huggingface.co에 등록되어 있거나 로컬에 저장된 사전 훈련 모델 이름,\n            그렇지 않은 경우 `hyunwoongko/asian-bart-ecjk`를 사용합니다 (`transformers`)\n    \"\"\"\n\n    def __init__(\n        self, decoder_layer: int, max_position_embeddings: int, name_or_path: Union[str, bytes, os.PathLike] = None\n    ):\n        super().__init__()\n        self.decoder_layer = decoder_layer\n        self.max_position_embeddings = max_position_embeddings\n\n        self.tokenizer = XLMRobertaTokenizer.from_pretrained(\n            \"hyunwoongko/asian-bart-ecjk\" if not name_or_path else name_or_path\n        )\n\n        self.model = MBartForCausalLM(\n            config=MBartConfig(\n                is_decoder=True,\n                is_encoder_decoder=False,\n                add_cross_attention=True,\n                decoder_layers=self.decoder_layer,\n                max_position_embeddings=self.max_position_embeddings,\n                vocab_size=len(self.tokenizer),\n                scale_embedding=True,\n                add_final_layer_norm=True,\n            )\n        )\n        self.model.forward = self.forward  # 교차 어텐션을 가져오고 `generate` 함수 활용\n\n        self.model.config.is_encoder_decoder = True  # 교차 어텐션을 가져오기 위해\n        self.add_special_tokens([\"\u003csep/\u003e\"])  # \u003csep/\u003e은 JSON에서 목록을 나타내는 데 사용됨\n        self.model.model.decoder.embed_tokens.padding_idx = self.tokenizer.pad_token_id\n        self.model.prepare_inputs_for_generation = self.prepare_inputs_for_inference\n\n        # asian-bart로 가중치 초기화\n        if not name_or_path:\n            bart_state_dict = MBartForCausalLM.from_pretrained(\"hyunwoongko/asian-bart-ecjk\").state_dict()\n            new_bart_state_dict = self.model.state_dict()\n            for x in new_bart_state_dict:\n                if x.endswith(\"embed_positions.weight\") and self.max_position_embeddings != 1024:\n                    new_bart_state_dict[x] = torch.nn.Parameter(\n                        self.resize_bart_abs_pos_emb(\n                            bart_state_dict[x],\n                            self.max_position_embeddings\n                            + 2,  # https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/models/mbart/modeling_mbart.py#L118-L119\n                        )\n                    )\n                elif x.endswith(\"embed_tokens.weight\") or x.endswith(\"lm_head.weight\"):\n                    new_bart_state_dict[x] = bart_state_dict[x][: len(self.tokenizer), :]\n                else:\n                    new_bart_state_dict[x] = bart_state_dict[x]\n            self.model.load_state_dict(new_bart_state_dict)\n\n    ...\n    ...\n\n    def forward(\n        self,\n        input_ids,\n        attention_mask: Optional[torch.Tensor] = None,\n        encoder_hidden_states: Optional[torch.Tensor] = None,\n        past_key_values: Optional[torch.Tensor] = None,\n        labels: Optional[torch.Tensor] = None,\n        use_cache: bool = None,\n        output_attentions: Optional[torch.Tensor] = None,\n        output_hidden_states: Optional[torch.Tensor] = None,\n        return_dict: bool = None,\n    ):\n        \"\"\"\n        교차 어텐션을 가져오고 `generate` 함수를 활용하기 위한 포워드 함수\n\n        소스:\n        https://github.com/huggingface/transformers/blob/v4.11.3/src/transformers/models/mbart/modeling_mbart.py#L1669-L1810\n\n        Args:\n            input_ids: (배치 크기, 시퀀스 길이)\n            attention_mask: (배치 크기, 시퀀스 길이)\n            encoder_hidden_states: (배치 크기, 시퀀스 길이, 히든 크기)\n\n        Returns:\n            loss: (1, )\n            logits: (배치 크기, 시퀀스 길이, 히든 차원)\n            hidden_states: (배치 크기, 시퀀스 길이, 히든 크기)\n            decoder_attentions: (배치 크기, 헤드 수, 시퀀스 길이, 시퀀스 길이)\n            cross_attentions: (배치 크기, 헤드 수, 시퀀스 길이, 시퀀스 길이)\n        \"\"\"\n        output_attentions = output_attentions if output_attentions is not None else self.model.config.output_attentions\n        output_hidden_states = (\n            output_hidden_states if output_hidden_states is not None else self.model.config.output_hidden_states\n        )\n        return_dict = return_dict if return_dict is not None else self.model.config.use_return_dict\n        outputs = self.model.model.decoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            encoder_hidden_states=encoder_hidden_states,\n            past_key_values=past_key_values,\n            use_cache=use_cache,\n            output_attentions=output_attentions,\n            output_hidden_states=output_hidden_states,\n            return_dict=return_dict,\n        )\n\n        logits = self.model.lm_head(outputs[0])\n\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss(ignore_index=-100)\n            loss = loss_fct(logits.view(-1, self.model.config.vocab_size), labels.view(-1))\n\n        if not return_dict:\n            output = (logits,) + outputs[1:]\n            return (loss,) + output if loss is not None else output\n\n        return ModelOutput(\n            loss=loss,\n            logits=logits,\n            past_key_values=outputs.past_key_values,\n            hidden_states=outputs.hidden_states,\n            decoder_attentions=outputs.attentions,\n            cross_attentions=outputs.cross_attentions,\n        )\n    ...\n    ...\n```\n\n도넛은 공개적으로 이용 가능한 사전 훈련된 다국어 BART 모델의 가중치를 사용해 초기화합니다.\n\n텍스트 디코더의 출력은 생성된 토큰 시퀀스입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 훈련\n\n사전 훈련\n\n사전 훈련의 목표는 다음 토큰 예측의 교차 엔트로피 손실을 최소화하는 것입니다. 이는 이미지와 이전 맥락을 함께 고려함으로써 달성됩니다. 이 작업은 의사 OCR 작업과 유사합니다. 모델은 주로 문서 이미지와 같은 시각적 말뭉치를 통해 시각 언어 모델로 훈련됩니다.\n\n사용된 훈련 데이터는 1100만 장의 스캔된 영어 문서 이미지인 IIT-CDIP입니다. 한편, 다국어 데이터를 생성하기 위해 합성 문서 생성기(SynthDoG)가 사용되었는데, 영어, 중국어, 일본어, 한국어를 포함한 데이터를 생성했습니다. 각 언어 당 50만 장의 이미지가 생성되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_0.png)\n\n생성된 예시는 그림 3에 나와 있습니다. 샘플은 여러 구성 요소로 구성됩니다: 배경, 문서, 텍스트, 레이아웃.\n\n- 배경 이미지는 ImageNet 샘플에서 가져옵니다.\n- 문서의 질감은 수집된 종이 사진에서 파생됩니다.\n- 단어와 구절은 위키피디아에서 샘플링합니다.\n- 레이아웃은 그리드를 무작위로 배치하는 간단한 규칙 기반 알고리즘에 의해 생성됩니다.\n\n또한 다양한 이미지 렌더링 기술을 사용하여 실제 문서를 흉내 냅니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, 표 4는 상업용 CLOVA OCR API를 통해 얻은 훈련 데이터의 라벨을 표시하고 있습니다.\n\n![이미지](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_1.png)\n\n## 파인 튜닝\n\n파인 튜닝의 주된 목적은 하류 작업에 적응하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 문서 분류 작업에서 디코더는 [START class][memo][END class] 토큰 시퀀스를 생성하는 방식으로 훈련됩니다. 이 시퀀스는 '\"class\": \"memo\"'와 같은 JSON 형식으로 직접 변환될 수 있습니다.\n\n# Nougat\n\n누가(Nougat)는 2023년 8월에 소개된 OCR이 필요 없는 end-to-end 작은 모델입니다. Nougat은 이미지의 내용을 직접 파싱할 수 있습니다. Nougat은 문학작품에서 스캔된 이미지나 PDF로 변환된 이미지를 입력으로 받아들이고, 결과를 마크다운 형식으로 출력합니다.\n\n## 모델 아키텍처\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**노가(Nougat)**는 **도넛(Donut) 아키텍처** 위에 개발되었습니다. **도넛 아키텍처**를 기반으로 **신경망**을 통해 텍스트를 인식하며, 그림 5에서 시연된 것처럼 **OCR 관련 입력이나 모듈이 필요 없이** 암묵적으로 작동합니다.\n\n## 교육 데이터셋 구축\n\n**노가(Nougat)** 모델은 특히 혁신적이지는 않으며, 주요 초점은 **대규모 교육 데이터셋**을 구축하는 데 있습니다. 이는 매우 어려운 작업입니다.\n\n**노가(Nougat)**는 이미지와 **마크다운**의 쌍으로 이루어진 대규모 교육 데이터를 생성하여 비용 효율적인 접근 방식을 구현했습니다. 이는 **노가(Nougat)**가 배울 수 있는 가장 중요한 측면입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 소스\n\nPDF 이미지와 마크다운 쌍을 포함한 대규모 데이터셋이 없어서, Nougat은 세 곳의 소스로부터 데이터셋을 구성했습니다: arXiv, PMC (PubMed Central) 및 IDL (Industry Documents Library), Figure 6에 나와 있습니다.\n\n![Figure 6](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_2.png)\n\n전반적인 프로세스\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nArXiv 데이터는 대부분 TeX 소스 코드가 포함되어 있기 때문에 주로 사용됩니다. 처리 흐름은 도표 7에 나와 있습니다.\n\n도표 7에 설명된 대로, 주요 목표는 기존 자원, 즉 PDF 논문과 해당 TeX 소스 코드를 쌍으로 변환하는 것입니다. 각 쌍은 각 PDF 페이지에 대한 이미지와 해당 Markdown으로 구성됩니다.\n\n입력으로 이미지 가져오기\n\nPDF 페이지의 이미지를 얻는 과정은 비교적 간단합니다. PyPDFium2의 관련 API를 직접 사용하면 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\ndef rasterize_paper(\n    pdf: Union[Path, bytes],\n    outpath: Optional[Path] = None,\n    dpi: int = 96,\n    return_pil=False,\n    pages=None,\n) -\u003e Optional[List[io.BytesIO]]:\n    \"\"\"\n    PDF 파일을 PNG 이미지로 래스터화합니다.\n\n    매개변수:\n        pdf (Path): PDF 파일의 경로입니다.\n        outpath (Optional[Path], optional): 출력 디렉토리입니다. None이면 PIL 이미지가 반환됩니다. 기본값은 None입니다.\n        dpi (int, optional): 출력 DPI입니다. 기본값은 96입니다.\n        return_pil (bool, optional): 디스크에 쓰는 대신 PIL 이미지를 반환할지 여부입니다. 기본값은 False입니다.\n        pages (Optional[List[int]], optional): 래스터화할 페이지입니다. None이면 모든 페이지가 래스터화됩니다. 기본값은 None입니다.\n\n    반환값:\n        Optional[List[io.BytesIO]]: `return_pil`이 True인 경우 PIL 이미지, 그렇지 않으면 None입니다.\n    \"\"\"\n    pils = []\n    if outpath is None:\n        return_pil = True\n    try:\n        if isinstance(pdf, (str, Path)):\n            pdf = pypdfium2.PdfDocument(pdf)\n        if pages is None:\n            pages = range(len(pdf))\n        renderer = pdf.render(\n            pypdfium2.PdfBitmap.to_pil,\n            page_indices=pages,\n            scale=dpi / 72,\n        )\n        for i, image in zip(pages, renderer):\n            if return_pil:\n                page_bytes = io.BytesIO()\n                image.save(page_bytes, \"bmp\")\n                pils.append(page_bytes)\n            else:\n                image.save((outpath / (\"%02d.png\" % (i + 1))), \"png\")\n    except Exception as e:\n        logging.error(e)\n    if return_pil:\n        return pils\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 과제는 각 PDF 페이지에서 이미지로 된 학습 데이터와 해당하는 마크다운 레이블이 함께 있는 것 때문에 마크다운을 페이지별로 구분하는 방법을 찾는 것입니다.\n\n각 논문의 LaTeX 소스 파일이 다시 컴파일되지 않았기 때문에 LaTeX 컴파일러와 같은 방식으로 PDF 파일의 페이지 나누기를 자동으로 결정할 수 없습니다.\n\n이 목표를 달성하기 위해서 현재 사용 가능한 리소스를 활용해야 합니다. 전략은 원본 PDF 페이지의 텍스트와 마크다운 텍스트를 휴리스틱하게 매칭하는 것입니다.\n\n구체적으로는 먼저 PDFMiner를 사용하여 PDF에서 텍스트 라인을 추출하고, 그 다음 텍스트를 전처리하여 페이지 번호와 가능한 헤더 또는 푸터를 제거합니다. 그런 다음 PDF 라인을 입력으로 사용하고 페이지 번호를 레이블로 사용하여 tfidf_transformer 모델을 훈련시킵니다. 이후 훈련된 모델을 적용하여 마크다운을 단락으로 나누고 각 단락에 대해 페이지 번호를 예측합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\ndef split_markdown(\n    doc: str,\n    pdf_file: str,\n    figure_info: Optional[List[Dict]] = None,\n    doc_fig: Dict[str, str] = {},\n    minlen: int = 3,\n    min_num_words: int = 22,\n    doc_paragraph_chars: int = 1000,\n    min_score: float = 0.75,\n    staircase: bool = True,\n) -\u003e Tuple[List[str], Dict]:\n    ...\n    ...\n       if staircase:\n            # train bag of words\n            page_target = np.zeros(len(paragraphs))\n            page_target[num_paragraphs[1:-1] - 1] = 1\n            page_target = np.cumsum(page_target).astype(int)\n            model = BagOfWords(paragraphs, target=page_target)\n            labels = model(doc_paragraphs)\n\n            # fit stair case function\n            x = np.arange(len(labels))\n            stairs = Staircase(len(labels), labels.max() + 1)\n            stairs.fit(x, labels)\n            boundaries = (stairs.get_boundaries().astype(int)).tolist()\n            boundaries.insert(0, 0)\n        else:\n            boundaries = [0] * (len(pdf.pages))\n    ...\n    ...\n```\n\n마지막으로 마무리 작업을 합니다.\n\n두 번째 도전 과제는 PDF의 차트가 마크다운 파일의 위치와 정렬되지 않는 것입니다.\n\n이를 해결하기 위해 누가트는 먼저 pdffigures2를 사용하여 차트를 추출합니다. 인식된 제목은 TeX 소스 코드 내의 제목들과 Levenshtein 거리를 기반으로 일치시킵니다. 이 방법을 사용하면 각 그림 또는 표의 TeX 소스 코드 및 페이지 번호를 결정할 수 있습니다. Figure 7의 JSON 구조는 차트 제목과 해당 페이지 번호를 포함합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마크다운이 개별 페이지로 분할되면 이전에 추출한 차트가 각 해당 페이지의 끝에 다시 삽입됩니다.\n\n```js\ndef split_markdown(\n    doc: str,\n    pdf_file: str,\n    figure_info: Optional[List[Dict]] = None,\n    doc_fig: Dict[str, str] = {},\n    minlen: int = 3,\n    min_num_words: int = 22,\n    doc_paragraph_chars: int = 1000,\n    min_score: float = 0.75,\n    staircase: bool = True,\n) -\u003e Tuple[List[str], Dict]:\n    ...\n    ...\n\n    # 도표, 표 및 각주 다시 삽입\n    figure_tex = list(doc_fig.keys()), list(doc_fig.values())\n    if len(doc_fig) \u003e 0:\n        iterator = figure_info.values() if type(figure_info) == dict else [figure_info]\n        for figure_list in iterator:\n            if not figure_list:\n                continue\n            for i, f in enumerate(figure_list):\n                if \"caption\" in f:\n                    fig_string = f[\"caption\"]\n                elif \"text\" in f:\n                    fig_string = f[\"text\"]\n                else:\n                    continue\n                ratios = []\n                for tex in figure_tex[1]:\n                    if f[\"figType\"] == \"Table\":\n                        tex = tex.partition(r\"\\end{table}\")[2]\n                    ratios.append(Levenshtein.ratio(tex, fig_string))\n                k = np.argmax(ratios)\n                if ratios[k] \u003c 0.8:\n                    continue\n                if f[\"page\"] \u003c len(out) and out[f[\"page\"]] != \"\":\n                    out[f[\"page\"]] += \"\\n\\n\" + remove_pretty_linebreaks(\n                        figure_tex[1][k].strip()\n                    )\n\n    for i in range(len(out)):\n        foot_match = re.findall(r\"\\[FOOTNOTE(.*?)\\]\\[ENDFOOTNOTE\\]\", out[i])\n        for match in foot_match:\n            out[i] = out[i].replace(\n                \"[FOOTNOTE%s][ENDFOOTNOTE]\" % match,\n                doc_fig.get(\"FOOTNOTE%s\" % match, \"\"),\n            )\n\n        out[i] = re.sub(r\"\\[(FIGURE|TABLE)(.*?)\\](.*?)\\[END\\1\\]\", \"\", out[i])\n    return out, meta\n```\n\n# Pix2Struct\n\nPix2Struct은 순수한 시각 언어 이해를 위해 특별히 설계된 사전 훈련된 이미지 - 텍스트 모델입니다. 또한 많은 하향 작업에 대해 세밀하게 조정할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 모델 구조\n\nPix2Struct은 ViT를 기반으로 한 이미지 인코더-텍스트 디코더입니다.\n\nPix2Struct의 구조는 논문에 그림으로 표시되어 있지 않으며 온라인에서도 찾을 수 없기 때문에, ViT 구조를 기반으로 한 참조 다이어그램을 제공합니다. Figure 8에 나와있는 것과 같이.\n\n\n![Pix2Struct Architecture](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적인 ViT 방법을 사용할 때 입력 이미지를 미리 정의된 해상도로 조정한 후 고정 크기 블록을 추출하면 두 가지 부정적인 영향을 줄 수 있습니다:\n\n- 문서, 모바일 UI 및 그래픽과 같이 실제 종횡비가 크게 다를 수 있습니다.\n- 전달 작업으로 모델을 고해상도로 이동하는 것이 어렵습니다. 이는 모델이 사전 학습 중에 특정 해상도만 본다는 점에서 나타납니다.\n\n따라서 Pix2Struct는 Figure 9에서 보여지는 것처럼 입력 이미지의 종횡비를 보존하는 스케일링을 가능하게 하는 소규모 향상을 도입했습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_4.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 사전 훈련 작업\n\nPix2Struct은 웹 페이지의 가림막이 적용된 스크린샷으로부터 HTML 기반 파싱을 예측하는 작업을 제안합니다.\n\n- 입력을 가리는 것은 그들의 동시 발생에 대한 공동 추론을 장려합니다.\n- 간소화된 HTML을 출력으로 사용하는 것은 텍스트, 이미지 및 레이아웃에 대한 명확한 신호를 제공하기 때문에 유리합니다.\n\n![이미지](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nFigure 10에 표시된 것처럼, Pix2Struct에 의해 제안된 스크린샷 구문 분석은 여러 잘 알려진 사전 학습 전략에서 신호를 효과적으로 결합합니다:\n\n- 미권한 부분 복원. 이 작업은 OCR과 유사하며 언어 이해를 위한 기본 기술입니다. Donut에서는 OCR 사전 학습을 위해 합성 렌더링이나 OCR 출력 사용이 제안되었습니다. Figure 10에서 `C++`을 예측하는 것이 이러한 학습 신호의 예입니다.\n- 가리기된 부분 복원. 이 작업은 BERT의 가리기된 언어 모델링과 유사합니다. 그러나 시각적 맥락은 종종 추가적인 강력한 단서를 제공합니다. Figure 10에서 `Python`을 예측하는 것은 이러한 유형의 신호의 예입니다.\n- 이미지에서 대체 텍스트 복원. 이미지 제목 전략의 사전 학습에 널리 사용되는 방법입니다. 이 접근 방식에서 모델은 웹 페이지를 추가적인 맥락으로 사용할 수 있습니다. Figure 10에 나타난 대로 img alt=C++를 예측하는 것이 이러한 학습 신호를 보여줍니다.\n\nPix2Struct는 두 가지 모델 변형을 사전 학습했습니다:\n\n- 282백만 개의 매개변수로 구성된 기본 모델.\n- 13억 개의 매개변수로 구성된 대형 모델.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 사전 훈련 데이터셋\n\n사전 훈련의 목표는 Pix2Struct가 입력 이미지의 기본 구조를 나타내는 능력을 갖추는 것입니다. 이를 달성하기 위해 Pix2Struct는 C4 말뭉치의 URL을 기반으로 자체 감독적인 방식으로 입력 이미지와 대상 텍스트의 쌍을 생성합니다.\n\nPix2Struct는 HTML 소스 파일과 쌍을 이루는 8000만 개의 스크린샷을 수집했습니다. 이는 총 문서 수의 약 1/3에 해당합니다. 각 스크린샷은 폭이 1024 픽셀이며, 높이는 콘텐츠의 높이에 맞게 조정됩니다. 또한 얻어진 HTML 소스 파일은 단순화된 HTML로 변환될 것입니다.\n\n도표 11은 사전 훈련 데이터의 스크린샷을 보여주며, 실제 값과 예측된 파싱을 함께 제시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_6.png)\n\n## Fine-tuning\n\nFine-tuning Pix2Struct starts with preprocessing the downstream data. This step guarantees that the image input and text output precisely reflect the task.\n\n![image](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_7.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다운스트림 작업의 예는 그림 12에 나와 있습니다.\n\n전처리에 대해:\n\n- Screen2Words 캡션 작업의 경우 입력 이미지와 출력 텍스트를 직접 사용할 수 있습니다.\n- DocVQA 시각적 질문 응답 작업의 경우, Pix2Struct는 다중 모달 모델이 일반적으로 질문을 위한 특수 텍스트 채널을 예약하는 반면 질문을 원본 이미지의 맨 위에 제목으로 직접 제시합니다.\n- AI2D와 같은 객관식 답변의 경우, Pix2Struct는 제목의 일부로 질문에 포함하여 제시하기로 선택합니다.\n\n# 통찰과 생각\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대표적인 OCR 무료 솔루션에 대한 소개는 여기까지입니다. 이제 통찰과 생각에 대해 이야기해 봅시다.\n\n## 사전 훈련 작업에 관하여\n\n이미지나 PDF에서 레이아웃, 텍스트, 의미 정보를 종합적으로 이해하기 위해, Donut, Nougat, 그리고 Pix2Struct는 유사한 훈련 작업을 개발했습니다:\n\n- Donut: 이미지 → JSON 형식\n- Nougat: 이미지 → Markdown\n- Pix2Struct: 마스크 처리된 이미지 → 간소화된 HTML\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리만의 OCR이 필요 없는 PDF 구문 분석 도구를 개발하려면, 먼저 훈련 작업을 설계해야 합니다. 원하는 출력 형식과 관련된 훈련 데이터를 획득하는 데 어려움이 있는 과제를 고려하는 것이 중요합니다.\n\n## 사전 훈련 데이터에 대해\n\n훈련 데이터는 OCR이 필요 없는 방법에서 중요합니다.\n\nDonut 및 Nougat의 훈련 데이터 획득은 (이미지, JSON) 및 (이미지, Markdown) 쌍이 쉽게 이용 가능하지 않기 때문에 도전적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n반면에, Pix2Struct은 공개 데이터셋에서 제공된 웹 페이지를 직접 적용하여 데이터 획득을 더 편리하게 만든 것입니다. 그러나 Pix2Struct의 훈련 데이터는 웹 페이지에서 가져왔기 때문에 유해한 콘텐츠를 도입할 수도 있습니다. 이는 특히 다중 모달 모델에 민감할 수 있습니다. Pix2Struct은 아직 이러한 유해 콘텐츠를 다루기 위한 조치를 시행하지 않았습니다.\n\n만일 OCR 없는 PDF 구문 분석 도구를 개발하려고 한다면, 하나의 전략은 훈련을 위한 (입력, 출력) 쌍을 점진적으로 구축하는 데 공개 데이터를 활용하는 것입니다.\n\n뿐만 아니라, 입력 이미지의 적절한 해상도와 하나의 이미지에 포함할 PDF 페이지 수를 결정하는 것도 중요한 고려 사항입니다.\n\n## 성능 관련\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도넛(Donut)과 Pix2Struct은 모두 다양한 하향 작업을 지원하는 일반 사전 학습 모델입니다. 따라서 그들의 평가 방법은 이러한 작업들의 벤치마크에 기반을 두고 있습니다.\n\nPix2Struct의 실험에 따르면, 그의 성능은 여러 작업에서 도넛보다 크게 우수하며 대부분의 작업에서 최신 기술(SOTA)을 초과합니다. 이는 아래 그림 13에서 보여집니다:\n\n![Figure 13](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_8.png)\n\n그러나, 그림 13에 표시된 작업들은 앞서 우리가 정의한 PDF 구문 분석 작업과는 다릅니다. 이 부분에서 누가(Nougat)가 더 전문적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n누가트는 마크다운의 전체 생산 과정에 초점을 맞추고 있습니다. 그래서 그 평가 체계는 Figure 14에 나와 있는 편집 거리, BLEU, METEOR 및 F-측정에 의존합니다.\n\n![이미지](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_9.png)\n\n게다가, 누가트는 다른 도구보다 수식과 테이블과 같은 복잡한 요소를 LaTeX 소스 코드로 더 정확하게 파싱할 수 있습니다. 이를 Figures 15와 16에서 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_10.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_11.png)\n\nFurthermore, Nougat can conveniently acquire table captions and associate them with corresponding tables.\n\n## Pipeline-Based vs. OCR-Free\n\nFigure 17 compares the overall architecture and performance of two methods. The upper left illustrates the pipeline-based method, while Donut model is represented on the lower left.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_12.png)\n\nFigure 17의 오른쪽에 나타난 것처럼, 도넛은 파이프라인 기반 방법에 비해 저장 공간을 적게 사용하고 더 높은 정확성을 제공합니다. 그러나 느린 속도로 작동합니다. 다른 OCR 무료 솔루션이 도넛과 유사합니다.\n\n## OCR-Free Small Model-Based Method의 제한사항\n\n- 파이프라인 기반 방법은 여러 모델을 사용하지만 각 모델은 가벼워요. 총 매개변수 수는 OCR 무료 모델보다 중요하게 적을 수 있습니다. 이 요소는 대규모 배포에 대해 도전을 제공할 수 있으며 OCR 무료 모델의 느린 구문 분석 속도로 이어질 수 있습니다. 예를 들어, 작은 모델이지만 Nougat의 매개변수 양은 250MB 또는 350MB입니다. 그러나 Nougat 논문에 명시된대로 생성 속도가 느립니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_13.png)\n\n- 이 방법론을 위한 훈련 데이터셋을 구축하는 것은 비용이 많이 듭니다. 큰 규모의 이미지-텍스트 쌍을 구축해야하기 때문입니다. 더구나 더 많은 GPU와 더 오랜 훈련 기간이 필요해 기계 비용이 증가합니다.\n- 게다가 엔드 투 엔드 방법은 특정한 나쁜 케이스를 최적화하는 데 어려움이 있어 최적화 비용이 높아집니다. 파이프라인 기반 솔루션에서는 테이블 처리 모듈이 성능을 발휘하지 못할 경우 이 모듈만 최적화가 필요합니다. 그러나 엔드 투 엔드 솔루션에서는 모델 구조를 변경하지 않고 새로운 파인튜닝 데이터를 만들어야 합니다. 이로 인해 다른 시나리오에서 새로운 나쁜 케이스가 발생할 수 있습니다.\n\n# 결론\n\n본 글은 PDF 파싱에서의 OCR을 사용하지 않는 소형 모델 기반 방법에 대한 개요를 제공했습니다. 세 가지 대표적인 모델을 사용해 이 접근 방식을 탐구하며 상세한 소개와 도출된 통찰을 제공했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적으로 OCR을 사용하지 않는 작은 모델 기반 PDF 구문 분석 방법의 장점 중 하나는 중간 단계에서 발생할 수 있는 잠재적인 손상을 피할 수 있는 일괄 처리 과정입니다. 그러나 그 효과는 다중 모달 모델의 구조와 훈련 데이터의 품질에 크게 의존합니다. 또한 훈련 및 추론 속도가 느려 파이프라인 기반 방법보다는 실용적이지 않습니다. 이 방법의 해석 가능성 역시 파이프라인 기반 방법만큼 강하게 나타나지는 않습니다.\n\n개선이 필요하지만 OCR을 사용하지 않는 접근 방식은 표 및 수식 인식과 같은 영역에서 잘 수행됩니다. 이러한 강점은 우리가 자체 PDF 구문 분석 도구를 구축하는 데 유용한 통찰력을 제공합니다.\n\nPDF 구문 분석이나 문서 인텔리전스에 관심이 있다면 다른 기사를 확인해 보세요.\n\n그리고 최신 기사는 뉴스레터에서 찾을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 문서에 오류나 빠진 점이 있거나 공유하고 싶은 생각이 있다면 댓글 섹션에서 언급해 주세요.","ogImage":{"url":"/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_0.png"},"coverImage":"/assets/img/2024-06-19-DemystifyingPDFParsing03OCR-FreeSmallModel-BasedMethod_0.png","tag":["Tech"],"readingTime":27},{"title":"문서챗 데이터를 손쉽게 탐색하고 이해하는 데 도움이 되는 방법  파트 1","description":"","date":"2024-06-19 19:14","slug":"2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1","content":"\n\n# 소개:\n\n대형 언어 모델(LLMs)의 가장 혁신적인 사용 사례 중 하나는 정교한 질의응답(Q\u0026A) 챗봇을 개발하는 데 있습니다. 이러한 지능적인 시스템은 \"검색 증강 생성\"이라는 기술 덕분에 특정 데이터셋을 이용하여 질문에 대답하고 해석할 수 있습니다.\n\n본 기사는 기업용 챗봇을 구축하는 시리즈의 일환입니다. 우리는 기초적인 개념부터 시작하여 점차적으로 더 복잡한 주제로 나아갈 것입니다. 이 시리즈를 통해 다음과 같은 내용을 배우게 될 것입니다:\n\n- 메모리 인식 챗봇 구축을 위한 기초적인 개념: RAG, LangChain, LlamaIndex 등의 기초 개념부터 시작하여 챗봇이 맥락을 유지하고 일관된 장기적 상호작용을 제공할 수 있도록 합니다.\n- 고급 데이터 전처리 및 멀티모달 검색: 이미지나 테이블이 포함된 문서를 처리하여 챗봇이 이러한 데이터를 효과적으로 해석하고 활용할 수 있도록 합니다.\n- 기업용 데이터 수집: 기업 환경에 맞게 데이터 수집, 저장 및 조정을 위한 강력한 전략입니다.\n- 에이전트 전략: 기존 RAG 파이프라인 상에 에이전트를 구축하여 자동화된 의사결정 능력을 부여합니다.\n- 보안 및 거버넌스: 챗봇을 안전하게 보호하고 데이터 거버넌스 정책을 준수하는 데 필요한 모범 사례입니다.\n- 가시성: 챗봇의 건강과 성능을 유지하기 위해 모니터링 및 가시성을 구현합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_0.png\" /\u003e\n\n이 시리즈가 끝나면, 데이터 탐색과 이해를 쉽게 능력을 향상시킬 수 있는 강력한 기업급 챗봇을 구축하는 데 필요한 지식과 도구를 갖게 될 것입니다.\n\n## RAG란 무엇인가요?\n\nRAG는 LLM의 기능을 확장하여 추가 데이터를 통합하는 강력한 방법입니다. LLM은 다양한 주제를 토론할 수 있지만, 그들의 지식은 일정한 시점까지 공개 정보로 제한됩니다. 개인 정보나 보다 최근 데이터를 처리할 수 있는 AI 애플리케이션을 만들기 위해서는 모델의 지식을 관련 정보로 보충하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG은 필요한 데이터를 검색하여 모델의 프롬프트에 삽입함으로써 이를 달성합니다. LangChain, LlamaIndex와 같은 프레임워크는 Q\u0026A 애플리케이션 및 RAG 구현을 용이하게 하는 컴포넌트 스위트를 제공합니다. 전형적인 RAG 애플리케이션은 두 가지 주요 컴포넌트로 구성됩니다:\n\n- 색인화: 이는 여러 소스에서 데이터를 수집하고 색인화하는 파이프라인을 설정하는 과정입니다.\n\n- 데이터 로딩: 첫 번째 단계는 데이터를 로드하는 것인데, 여기서는 LangChain의 `PyPDFLoader`, `WebBaseLoader` 또는 LLamaIndex의 `SimpleDirectoryReader`와 같은 DocumentLoader를 사용합니다.\n- 텍스트 분할: 텍스트 분할기는 큰 문서를 작은 청크로 분할하여 검색이 쉽고 모델의 컨텍스트 창에 맞는 데이터로 만듭니다.\n- 데이터 저장: 분할된 데이터 청크는 추후 검색을 위해 저장되고 색인화됩니다. 이때 ChromaDB, Azure Search, AWS ElasticSearch와 같은 VectorStores(벡터 스토어)를 Embeddings 모델과 결합하여 종종 사용합니다.\n\n2. 검색 및 생성: 이 컴포넌트는 사용자 쿼리를 실시간으로 처리하고 색인에서 중요한 데이터를 검색하여 모델을 사용하여 응답을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 데이터 검색: 사용자가 쿼리를 입력하면, 관련 청크는 리트리버를 사용하여 저장소에서 검색됩니다.\n- 답변 생성: ChatModel 또는 LLM은 사용자의 질문과 검색된 데이터를 포함하여 답변을 생성합니다.\n\n## RAG 아키텍처\n\n![RAG 아키텍처](/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_1.png)\n\n```js\ndef process_pdf_simple(self, file_content):\n    # 문서 로드\n    loader = PyPDFLoader(file_content)\n    docs = loader.load()\n    \n    # 문서 분할\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000, \n        chunk_overlap=200\n    )\n    splits = text_splitter.split_documents(docs)\n    \n    # 문서 색인화\n    vectorstore = Chroma.from_documents(splits, self.embeddings)\n    \n    # 리트리버 정의\n    retriever = vectorstore.as_retriever()\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 스니펫에서는 PyPDFLoader를 사용하여 PDF 콘텐츠를 초기화하고 문서를 로드합니다. 그런 다음 Chroma 클래스를 사용하여 문서 청크에서 벡터 저장소를 생성합니다. Chroma의 `from_documents` 메서드는 임베딩 모델을 사용하여 문서 분할에서 인덱스를 생성합니다. `as_retriever` 메서드는 벡터 저장소를 검색기 객체로 변환하여 챗봇이 인덱싱된 문서 청크를 검색하고 가장 관련성 높은 정보를 빠르게 찾을 수 있도록 합니다.\n\n# Q\u0026A 챗봇의 주요 구성 요소:\n\n1. 챗 모델: 텍스트 기반 LLM과 달리 메시지 기반 상호작용에 최적화되어 더 자연스러운 대화 응답을 제공합니다.\n\n2. 프롬프트 템플릿: 이러한 템플릿은 기본 메시지, 사용자 입력, 채팅 기록 및 선택적으로 다른 소스에서 검색한 추가 컨텍스트를 결합하여 프롬프트를 만드는 데 도움이 됩니다. 이는 예를 들어, 금융 자문가로 챗봇을 가정하는 특정 페르소나를 만들어낼 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 채팅 기록: 이 기능을 통해 챗봇은 과거 상호작용을 기억할 수 있어 후속 질문에 맥락을 제공하여 응답할 수 있습니다. Q\u0026A 애플리케이션에서는 과거 질문과 답변을 기억하는 것이 일관된 대화를 위해 중요합니다.\n\n## 기록 인식 검색 구현:\n\n우리는 역사적 메시지와 최신 사용자 질문을 가져와 질문을 재정렬하여 이전 맥락없이도 이해할 수 있도록 할 서브-체인을 정의할 것입니다. 이를 위해 우리의 프롬프트에서 \"chat_history\"라는 `MessagesPlaceholder` 변수를 사용합니다. `create_history_aware_retriever`라는 도우미 함수를 사용하여 채팅 기록을 포함하고 시퀀스를 적용할 것입니다: `prompt | lIm | StrOutputParser | retriever`.\n\n```js\n####\n# 질문 맥락화\n####\ncontextualize_q_system_prompt = (\n    \"과거 채팅 기록과 최신 사용자 질문이 주어졌을 때, 채팅 기록에서 맥락을 참조할 수 있는 문제를 독립적으로 이해할 수 있는 혼자서도 이해할 수 있는 질문으로 재평가하세요. 질문에 대답하지 말고, 필요하다면 다시 정리하고 그렇지 않으면 그대로 반환하세요.\"\n)\n\ncontextualize_q_prompt = ChatPromptTemplate.from_messages(\n    (\"system\", contextualize_q_system_prompt),\n    MessagesPlaceholder(\"chat_history\"),\n    (\"human\", \"{input}\")\n)\n\nhistory_aware_retriever = create_history_aware_retriever(\n    self.llm, retriever, contextualize_q_prompt\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 전체 QA 체인 구축하기:\n\n마침내, 우리는 리트리버를 히스토리 인식 리트리버로 업데이트하고 `create_stuff_documents_chain`을 사용하여 질문-답변 체인을 구축할 것입니다. 이 체인은 검색된 컨텍스트, 채팅 기록 및 사용자 쿼리를 받아 답변을 생성합니다. 그런 다음 `create_retrieval_chain`을 사용하여 최종 RAG 체인을 구성합니다. 이 체인은 히스토리 인식 리트리버와 질문-답변 체인을 순차적으로 적용하여 검색된 컨텍스트와 같은 중간 출력을 유지합니다. 이러한 단계를 통해 과거 상호작용을 인식하고 기억하는 강력한 챗봇을 구축했습니다. 이는 사용자와의 원활하고 일관된 대화를 보장합니다.\n\n```js\n### 채팅 기록 상태 관리하기 ###\nstore = {}\n\n# 채팅 기록을 영속적으로 저장하고 있지 않지만, redis에 저장할 수도 있습니다\ndef get_session_history(session_id: str) -\u003e BaseChatMessageHistory:\n    if session_id not in store:\n        store[session_id] = ChatMessageHistory()\n    return store[session_id]\n\nconversational_rag_chain = RunnableWithMessageHistory(\n    rag_chain,\n    get_session_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n    output_messages_key=\"answer\"\n)\n\nreturn conversational_rag_chain\n```\n\n마지막으로, 입력 쿼리를 처리하고 색인된 문서 청크에서 관련 정보를 검색하는 conversational_rag_chain inbuilt 메서드 invoke를 호출할 수 있습니다. 결합된 질문, 컨텍스트 및 프롬프트는 LLM에 전송되어 응답을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfile_path = 'amazon_2024_10q.pdf'\nuser_query = \"Amazon의 2024년 Q1 10-Q SEC 보고서에서 보고된 주요 재무 하이라이트 및 중요한 변화는 무엇입니까?\"\nobj = ConversationRetrieverAgent()\nchain = obj.process_pdf_simple(file_path)\nresult = chain.invoke({\"input\": user_query})\nprint(result[\"answer\"])\n```\n\n# 결론\n\nDocuChat 앱은 LangChain 및 검색 확장 생성 (RAG)과 같은 고급 기술을 활용하여 사용자가 데이터를 탐색하고 이해하는 데 편리하게 도와줍니다. 문서를 효율적으로 로드, 분리 및 색인화하고 정교한 검색 및 생성 기술을 활용하여, DocuChat은 사용자 쿼리에 정확하고 컨텍스트에 민감한 답변을 제공할 수 있습니다. 채팅 모델, 프롬프트 템플릿 및 채팅 기록을 통합함으로써 자연스럽고 일관된 대화를 보장합니다. 히스토리 인식 검색 및 견고한 세션 관리를 구현함으로써, DocuChat은 데이터를 더 접근 가능하고 실행 가능하게 만들어 스마트하고 원활한 상호 작용 경험을 제공합니다.\n\n# 다음 단계?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이번 시리즈의 다음 부분을 기대해주세요. 다음에는 고급 데이터 전처리와 멀티모달 검색에 대해 자세히 알아볼 것입니다. 이미지와 테이블을 포함한 문서를 어떻게 처리하는지, 이 데이터를 챗봇이 효과적으로 해석하고 활용하는 방법을 다룰 예정입니다. 이는 금융 서비스용 봇을 만들 때 특히 유용하며, SEC와 Bloomberg과 같은 출처에서 받은 금융 시장 데이터를 분석할 수 있게 해줍니다. 이 데이터는 종종 그래프, 지표, 테이블을 포함하고 있습니다. 이러한 통찰력을 놓치지 마시고 챗봇 역량을 향상시키세요!\n\n# 저자 정보\n\n이 기사를 읽어주셔서 감사합니다! 만약 여기서 논의된 전체 코드베이스를 보거나 완전히 기능하는 챗 앱을 사용해보고 싶다면, 아래 링크를 방문해 주세요:\n\n- LinkedIn: LinkedIn 프로필\n- GitHub: 이 기사의 전체 코드를 제 GitHub 프로필에서 확인하세요.\n- Streamlit: Streamlit 앱에서 완전히 기능하는 앱과 상호 작용해보세요. 기능을 탐색하고, 질문을 하며, DocuChat이 실시간으로 쿼리에 응답하는 방식을 확인해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLinkedIn에서 업데이트, 토론 및 지적 응용 프로그램 구축에 대한 자세한 통찰력을 얻으세요. 피드백 및 기여는 언제나 환영합니다!\n\n참고 자료:\n\n- https://platform.openai.com/docs/quickstart\n- https://python.langchain.com/v0.2/docs/tutorials/chatbot/\n- https://blog.langchain.dev/semi-structured-multi-modal-rag/\n- https://docs.llamaindex.ai/en/stable/getting_started/concepts/","ogImage":{"url":"/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_0.png"},"coverImage":"/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_0.png","tag":["Tech"],"readingTime":7},{"title":"주식 예측을 위한 심층 강화학습","description":"","date":"2024-06-19 19:04","slug":"2024-06-19-ForecastingStockUsingDeepReinforcementLearning","content":"\n\n깊은 강화 학습은 딥 러닝의 능력과 강화 학습의 강점을 결합합니다. 딥 러닝은 raw 데이터로부터 복잡한 표현을 학습하는 데 뛰어나며, 강화 학습은 에이전트가 시행착오를 통해 주어진 환경에서 최적의 조치를 학습할 수 있게 합니다. DRL을 통해 연구자와 투자자들은 역사적 데이터를 분석하고 복잡한 시장 역학을 이해하여 주식 매수, 매도 또는 보유에 대한 판단을 내릴 수 있는 모델을 개발할 수 있습니다.\n\n## 코딩을 시작해봅시다!\n\n```python\n# 이 Python 3 환경에는 많은 유용한 분석 라이브러리가 설치되어 있습니다\n# kaggle/python 도커 이미지로 정의됩니다: https://github.com/kaggle/docker-python\n# 예를 들어, 몇 가지 유용한 패키지를 로드하는 방법을 보여드리겠습니다 \n```\n\n```python\nimport numpy as np # 선형 대수\nimport pandas as pd # 데이터 처리, CSV 파일 입력 및 출력 (예: pd.read_csv)\n# 입력 데이터는 \"../input/\" 디렉토리에 있습니다.\n# 예를 들어, 실행하면 (실행 단축키를 누르거나 Shift+Enter를 누릅니다) input 디렉토리의 파일을 나열합니다\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# 현재 디렉토리에 기록된 결과는 출력으로 저장됩니다.\nimport time\nimport copy\nimport numpy as np\nimport chainer\nimport chainer.functions as F\nimport chainer.links as L\nfrom plotly import tools\nfrom plotly.graph_objs import *\nfrom plotly.offline import init_notebook_mode, iplot, iplot_mpl\nfrom tqdm import tqdm_notebook as tqdm\ninit_notebook_mode()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬 코드에는 데이터 분석 및 처리를 위한 여러 패키지 가져 오기 및 환경 설정이 포함되어 있습니다. 선형 대수 연산 및 데이터 처리를 위해 코드는 NumPy 및 Pandas 라이브러리를 가져옵니다. 또한 신경망을 정의하고 훈련하기 위한 심층 학습 프레임워크 인 Chainer를 가져옵니다. 또한 시각화 및 진행률 표시 막대를 위해 각각 plotly 및 tqdm 라이브러리를 가져옵니다.\n\n주석 처리된 코드에서 이것은 사전 설치된 분석 라이브러리가 포함된 Python 3 환경임을 설명합니다. 이 기사는 또한 Kaggle/docker-python 이미지를 사용하여 지정된 디렉토리에서 입력 데이터 파일을로드하는 방법을 설명합니다. 또한 코드는 오프라인 시각화를위한 plotly를 설정하고 Jupyter 노트북 내에서 시각화를 표시하기위한 노트북 모드를 사용합니다.\n\n```js\n# Kaggle 데이터 세트에서 \"huge stock market\"라는 데이터 가져 오기\n```\n\n```js\ntry:\n    data = pd.read_csv('../input/Data/Stocks/goog.us.txt')\n    data['Date'] = pd.to_datetime(data['Date'])\n    data = data.set_index('Date')\nexcept (FileNotFoundError):\n    import datetime\n    import pandas_datareader as pdr\n    from pandas import Series, DataFrame\n    start = datetime.datetime(2010, 1, 1)\n    end = datetime.datetime(2017, 1, 11)\n    data = pdr.get_data_yahoo(\"AAPL\", start, end)\nprint(data.index.min(), data.index.max())\nsplit_index = int(len(data)/2)\ndate_split = data.index[split_index]\ntrain = data[:split_index]\ntest = data[split_index:]\n#date_split = '2016-01-01'\n#train = data[:date_split]\n#test = data[date_split:]\nprint(len(data), len(train), len(test))\ndisplay(data)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Forecasting Stock Using Deep Reinforcement Learning - 0](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_0.png)\n\n![Forecasting Stock Using Deep Reinforcement Learning - 1](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_1.png)\n\n이 코드는 Python으로 작성된 'huge stock market'이라는 Kaggle 데이터 세트에서 데이터를 가져옵니다. 초기에 코드는 데이터 세트 내 'goog.us.txt'라는 CSV 파일에서 데이터를 읽습니다. 코드는 CSV 파일을 읽은 후 'Date' 열을 Pandas 라이브러리를 사용하여 Pandas datetime 객체로 변환합니다. 데이터는 'Date' 열로 인덱싱됩니다. 'AAPL' 주식에 대한 데이터는 지정된 파일이 발견되지 않을 경우 Pandas DataReader를 사용하여 Yahoo Finance로부터 얻습니다.\n\n그런 다음 코드는 가져온 데이터의 최소 날짜와 최대 날짜를 표시합니다. Pandas의 슬라이싱 기능을 사용하여 데이터를 교육 및 테스트 두 부분으로 분할합니다. 분할 인덱스는 데이터의 길이의 절반으로 계산되고 해당 날짜가 'date_split'으로 저장됩니다. 'train' 변수에는 분할 인덱스까지의 데이터가 포함되고, 'test' 변수에는 분할 인덱스 이후의 데이터가 포함됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼 코드는 전체 데이터 세트, 훈련 세트 및 테스트 세트의 길이를 출력합니다. 'display' 함수를 사용하여 코드는 Jupyter 노트북에서 가져온 데이터를 표시합니다.\n\n코드에는 주어진 날짜가 아닌 분할 인덱스를 기반으로 데이터를 분할하는 주석 처리된 행이 포함되어 있습니다.\n\n```js\ndef plot_train_test(train, test, date_split):\n    \n    data = [\n        Candlestick(x=train.index, open=train['Open'], high=train['High'], low=train['Low'], close=train['Close'], name='train'),\n        Candlestick(x=test.index, open=test['Open'], high=test['High'], low=test['Low'], close=test['Close'], name='test')\n    ]\n    layout = {\n         'shapes': [\n             {'x0': date_split, 'x1': date_split, 'y0': 0, 'y1': 1, 'xref': 'x', 'yref': 'paper', 'line': {'color': 'rgb(0,0,0)', 'width': 1}\n         ],\n        'annotations': [\n            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'left', 'text': ' test data'},\n            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'right', 'text': 'train data '}\n        ]\n    }\n    figure = Figure(data=data, layout=layout)\n    iplot(figure)\n```\n\n이 코드는 Plotly라는 Python 그래프 라이브러리를 사용하여 상호 작용형 캔들스틱 차트를 만드는 plot_train_test라는 함수를 정의합니다. 지정된 날짜를 기준으로 차트는 주식 데이터를 훈련 세트와 테스트 세트로 분할합니다. 입력 매개변수에는 train, test 및 date_split이 포함됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n함수의 첫 부분은 훈련 데이터 세트와 테스트 데이터 세트 각각에 대한 Candlestick 객체를 생성합니다. 각 객체에는 해당 데이터 세트의 인덱스(데이터의 x축 역할)와 주식 가격의 Open, High, Low, Close 값을 나타내는 캔들스틱이 포함됩니다. 데이터 세트를 레이블하려면 name 속성이 'train' 또는 'test'로 설정됩니다.\n\n다음으로 차트의 모양을 사용자 정의하기 위해 레이아웃 딕셔너리를 정의합니다. Shapes 키는 훈련 데이터와 테스트 데이터를 분리하는 수직선을 나타내는 단일 딕셔너리가 포함됩니다. 선의 좌표는 'x0', 'x1', 'y0', 'y1'로 정의되며, 'xref' 및 'yref'는 각각 'x' 및 'paper'로 설정됩니다. 'line' 키를 사용하여 선의 색상과 너비를 지정할 수 있습니다.\n\nAnnotations 키에는 각각 분리 선 위에 위치한 텍스트 레이블을 나타내는 두 개의 딕셔너리가 포함됩니다. 'Test data'는 선의 왼쪽에 고정되고, 'train data'는 오른쪽에 고정됩니다. 두 레이블 모두 'showarrow' 키가 False로 설정되어 있어 텍스트를 가리키는 화살표를 방지합니다.\n\n이전에 정의된 데이터 및 레이아웃 객체를 사용하여 Figure 객체를 생성합니다. Figure 객체를 인수로 사용하여 iplot() 함수를 사용하면 훈련 및 테스트 데이터 세트가 수직선으로 분리된 대화형 캔들스틱 차트가 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nplot_train_test(train, test, date_split)\n```\n\n![Stock Forecasting](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_2.png)\n\n위 코드는 \"plot_train_test\"라는 사용자 정의 함수를 호출하는 것으로 보입니다. 이 함수의 세 가지 인수는 'train', 'test', 'date_split'입니다. 'train'과 'test'는 각각 훈련 및 테스트 데이터를 포함하는 Pandas 데이터프레임입니다. 'date_split'은 데이터가 훈련 및 테스트로 분리된 날짜를 나타냅니다.\n\n'plot_train_test' 함수는 훈련 및 테스트 데이터를 시각화하는 플롯을 생성합니다. 코드가 가져온 주식 시장 데이터를 플롯하여 Jupyter 노트북에 표시하는 데 이 함수를 사용할 수 있습니다. 이 함수의 구현이 제공되지 않았으므로 플롯을 생성하는 방법에 대한 자세한 내용을 제공하기 어렵습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport matplotlib.pyplot as plt\n```\n\n```js\ndata['Close'].plot(figsize=(23,8))\nplt.legend()\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_3.png\" /\u003e\n\nMatplotlib 라이브러리를 사용하여 이 Python 코드는 가져온 주식 시장 데이터의 'Close' 가격을 그립니다. 먼저 코드는 Matplotlib 라이브러리에서 'pyplot' 모듈을 가져오고 'plt'로 이름을 바꿉니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPandas 색인(indexing)을 사용하여 코드는 import된 데이터의 'Close' 열에 액세스하고, Pandas 데이터프레임의 'plot' 메서드를 사용하여 그래프를 그립니다. 'figsize' 매개변수는 그래프의 크기를 가로 23인치, 세로 8인치로 설정합니다. 이렇게 하면 크고 명확한 쉽게 볼 수 있는 그래프가 만들어집니다.\n\n그런 다음 'pyplot' 모듈의 'legend' 메서드를 사용하여 그래프에 범례를 추가합니다. 동일한 그림에 여러 데이터 시리즈가 표시될 때, 범례는 플롯에 대한 추가 정보를 제공합니다.\n\n마지막으로 'pyplot' 모듈의 'show' 메서드를 사용하여 그래프를 표시합니다. 별도의 창에 그래프가 표시되며 사용자가 이를 닫을 수 있습니다. 시간이 지남에 따른 'Close' 가격의 그래프는 주식 시장의 행동에 대한 통찰을 제공합니다.\n\n```python\nclass Environment:\n    \n    def __init__(self, data, history_t=90):\n        self.data = data\n        self.history_t = history_t\n        self.reset()\n        \n    def reset(self):\n        self.t = 0\n        self.done = False\n        self.profits = 0\n        self.positions = []\n        self.position_value = 0\n        self.history = [0 for _ in range(self.history_t)]\n        return [self.position_value] + self.history # obs\n    \n    def step(self, act):\n        reward = 0\n        \n        # act = 0: stay, 1: buy, 2: sell\n        if act == 1:\n            self.positions.append(self.data.iloc[self.t, :]['Close'])\n        elif act == 2: # sell\n            if len(self.positions) == 0:\n                reward = -1\n            else:\n                profits = 0\n                for p in self.positions:\n                    profits += (self.data.iloc[self.t, :]['Close'] - p)\n                reward += profits\n                self.profits += profits\n                self.positions = []\n        \n        # set next time\n        self.t += 1\n        self.position_value = 0\n        for p in self.positions:\n            self.position_value += (self.data.iloc[self.t, :]['Close'] - p)\n        self.history.pop(0)\n        self.history.append(self.data.iloc[self.t, :]['Close'] - self.data.iloc[(self.t-1), :]['Close'])\n        \n        # clipping reward\n        if reward \u003e 0:\n            reward = 1\n        elif reward \u003c 0:\n            reward = -1\n        \n        return [self.position_value] + self.history, reward, self.done, self.profits # obs, reward, done, profits\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제공된 코드에서 에이전트는 단순한 거래 환경을 시뮬레이션하는 Environment라는 클래스와 상호 작용할 수 있습니다. 먼저 시장 주식 가격 데이터를 활용하여 데이터에 기반해 주식을 매수하거나 매도하거나 보유할지를 결정할 수 있습니다.\n\n__init__() 함수는 두 개의 인자를 받습니다. 데이터는 주식 가격 데이터를 나타내고, history_t는 환경이 유지해야 하는 시간 단계를 정의합니다. 데이터와 history_t 값을 설정하고 reset()을 호출하면 클래스가 초기화됩니다.\n\nReset() 함수는 환경의 내부 상태 변수를 초기화하거나 재설정합니다. 현재 시간 단계 (self.t), 완료 플래그, 총 이익, 보유 중인 포지션, 포지션 가치 및 가격 이력을 초기화합니다. 포지션 가치와 가격 이력으로 이루어진 관측값이 해당 메서드에 의해 반환됩니다.\n\nstep() 메서드를 사용하여 환경의 상태를 행위 (act)에 기반해 업데이트할 수 있습니다. 행위는 정수로 나타낼 수 있으며, 0은 보유, 1은 매수, 2는 매도를 의미합니다. 에이전트가 매수하기로 결정하면 주식의 현재 종가가 포지션 목록에 추가됩니다. 에이전트가 판매하기로 결정하면 해당 메서드는 각 오픈 포지션에 대해 이익 또는 손실을 계산하고 수익 변수를 업데이트합니다. 그런 다음, 모든 오픈 포지션이 종료됩니다. 판매 행위 중 발생한 이익 또는 손실에 따라 보상이 -1, 0 또는 1로 클리핑됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위치가 업데이트되면 메서드는 현재 시간 단계를 증가시키고 위치 값을 다시 계산합니다. 또한 가격 기록은 가장 오래된 데이터 포인트를 제거하고 현재 및 이전 종가 사이의 차이를 추가하여 업데이트됩니다. 업데이트된 관측, 보상, 완료 플래그 및 총 이익 외에도 메서드는 업데이트된 관측과 보상을 반환합니다.\n\n환경 클래스를 사용하여 주식 가격 데이터를 기반으로 학습하고 결정을 내릴 수 있는 에이전트를 만들 수 있습니다. 환경 클래스는 주식 거래 환경을 시뮬레이션합니다. 통제된 환경에서 강화 학습 에이전트는 거래 전략을 개발하는 데 훈련될 수 있습니다.\n\n```python\nenv = Environment(train)\nprint(env.reset())\nfor _ in range(3):\n    pact = np.random.randint(3)\n    print(env.step(pact))\n```\n\n![Stock Image](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 Python 코드는 \"Environment\"이라는 사용자 정의 클래스를 사용하여 환경을 모의하는 방법을 보여줍니다. 이 코드는 'train' 변수를 인수로 사용하여 Environment 클래스의 인스턴스를 생성합니다. 환경을 초기화하기 위해 'train' 변수에는 훈련 데이터를 포함한 Pandas 데이터프레임이 들어 있습니다.\n\n그런 다음 코드는 환경의 'reset' 메서드를 호출하는데, 이는 환경을 초기 상태로 재설정한 후의 환경 관측값을 반환합니다. 'print' 함수를 사용하여 관측값을 출력합니다.\n\n그런 다음 코드는 세 번 반복하는 루프에 들어갑니다. 루프 내에서 NumPy의 randomint 함수를 사용하여 0부터 2 사이의 랜덤한 액션을 선택합니다. 이 랜덤 액션을 환경의 'step' 메서드에 전달하고, 이는 단일 액션을 취하고 환경의 상태를 업데이트합니다. 'print' 함수를 사용하여 'step' 메서드가 환경의 새로운 상태와 보상 값을 반환합니다.\n\n이 코드는 'Environment' 클래스를 사용하여 환경을 모의하고 'reset' 및 'step' 메서드를 사용하여 상호 작용하는 방법을 보여줍니다. 코드의 세부 사항과 'Environment' 클래스의 성질, 그리고 액션 및 보상의 세부 내용이 제공되지 않았기 때문에 코드의 기능에 대한 더 자세한 설명은 어렵습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# DQN\n```\n\n```js\ndef train_dqn(env, epoch_num=50):\n    class Q_Network(chainer.Chain):\n        def __init__(self, input_size, hidden_size, output_size):\n            super(Q_Network, self).__init__(\n                fc1 = L.Linear(input_size, hidden_size),\n                fc2 = L.Linear(hidden_size, hidden_size),\n                fc3 = L.Linear(hidden_size, output_size)\n            )\n        def __call__(self, x):\n            h = F.relu(self.fc1(x))\n            h = F.relu(self.fc2(h))\n            y = self.fc3(h)\n            return y\n        def reset(self):\n            self.zerograds()\n    Q = Q_Network(input_size=env.history_t+1, hidden_size=100, output_size=3)\n    Q_ast = copy.deepcopy(Q)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(Q)\n    step_max = len(env.data)-1\n    memory_size = 200\n    batch_size = 20\n    epsilon = 1.0\n    epsilon_decrease = 1e-3\n    epsilon_min = 0.1\n    start_reduce_epsilon = 200\n    train_freq = 10\n    update_q_freq = 20\n    gamma = 0.97\n    show_log_freq = 5\n    memory = []\n    total_step = 0\n    total_rewards = []\n    total_losses = []\n    start = time.time()\n    for epoch in range(epoch_num):\n        pobs = env.reset()\n        step = 0\n        done = False\n        total_reward = 0\n        total_loss = 0\n        while not done and step \u003c step_max:\n            # select act\n            pact = np.random.randint(3)\n            if np.random.rand() \u003e epsilon:\n                pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))\n                pact = np.argmax(pact.data)\n            # act\n            obs, reward, done, profit = env.step(pact)\n            # add memory\n            memory.append((pobs, pact, reward, obs, done))\n            if len(memory) \u003e memory_size:\n                memory.pop(0)\n            # train or update q\n            if len(memory) == memory_size:\n                if total_step % train_freq == 0:\n                    shuffled_memory = np.random.permutation(memory)\n                    memory_idx = range(len(shuffled_memory))\n                    for i in memory_idx[::batch_size]:\n                        batch = np.array(shuffled_memory[i:i+batch_size])\n                        b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)\n                        b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)\n                        b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n                        b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)\n                        b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)\n                        q = Q(b_pobs)\n                        maxq = np.max(Q_ast(b_obs).data, axis=1)\n                        target = copy.deepcopy(q.data)\n                        for j in range(batch_size):\n                            target[j, b_pact[j]] = b_reward[j]+gamma*maxq[j]*(not b_done[j])\n                        Q.reset()\n                        loss = F.mean_squared_error(q, target)\n                        total_loss += loss.data\n                        loss.backward()\n                        optimizer.update()\n                if total_step % update_q_freq == 0:\n                    Q_ast = copy.deepcopy(Q)\n            # epsilon\n            if epsilon \u003e epsilon_min and total_step \u003e start_reduce_epsilon:\n                epsilon -= epsilon_decrease\n            # next step\n            total_reward += reward\n            pobs = obs\n            step += 1\n            total_step += 1\n        total_rewards.append(total_reward)\n        total_losses.append(total_loss)\n        if (epoch+1) % show_log_freq == 0:\n            log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq\n            log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq\n            elapsed_time = time.time()-start\n            print('\\t'.join(map(str, [epoch+1, epsilon, total_step, log_reward, log_loss, elapsed_time])))\n            start = time.time()\n            \n    return Q, total_losses, total_rewards\n```\n\n이 코드는 간단한 주식 거래 환경을 위해 Deep Q-Network(DQN)을 훈련하는 train_dqn() 함수를 정의합니다. 이 함수는 두 개의 매개변수를 사용합니다: 거래 환경을 나타내는 env 매개변수와 몇 번의 에포크를 훈련할지를 지정하는 epoch_num 매개변수입니다.\n\n코드는 Chainer의 Chain 클래스의 하위 클래스인 Q_Network 클래스를 정의합니다. Q-Network에는 첫 번째 두 레이어에 ReLU 활성화 함수가 있는 세 개의 완전 연결 레이어가 있습니다. 모델 그래디언트는 reset() 메서드에 의해 초기화됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이후에 Q-Network의 두 인스턴스, Q와 Q_ast가 생성되며, 모델의 매개변수를 업데이트하는 Adam 옵티마이저가 함께 생성됩니다. DQN 학습을 위해 메모리 크기, 배치 크기, 엡실론, 감마 및 업데이트 빈도를 포함한 여러 하이퍼파라미터가 정의됩니다.\n\n트레이닝 중 모델의 성능을 추적하기 위해 총 보상 및 총 손실 목록이 메모리 목록에 생성됩니다. 각 에포크의 시작 시에 환경이 재설정되고 일부 변수가 초기화됩니다.\n\n에이전트는 현재 상태 및 엡실론 탐색 전략에 기반하여 '보유', '구매' 또는 '판매' 중 하나의 행동을 선택합니다. 그런 다음 에이전트는 환경에서 행동을 수행하고 보상을받으며 새로운 상태를 관찰합니다. 메모리에는 경험 튜플(이전 상태, 행동, 보상, 새로운 상태 및 종료 플래그)이 저장됩니다.\n\nDQN을 훈련하기 위해 메모리가 가득 찼을 때 메모리에서 일괄 경험을 샘플링합니다. Q_ast 네트워크와 벨만 방정식을 사용하여 대상 Q값을 계산합니다. 손실은 예측된 Q값과 대상 Q값 사이의 평균 제곱 오차로 계산됩니다. 그라디언트가 계산되고 옵티마이저가 모델의 매개변수를 업데이트합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n타겟 네트워크 Q_ast는 메인 네트워크 Q의 가중치로 주기적으로 업데이트됩니다. 에이전트가 학습함에 따라 엡실론 값이 선형적으로 감소하여 더 많은 이용을 촉진합니다. 매 에포크마다 총 보상과 손실이 누적되고 결과가 기록됩니다.\n\n훈련을 마치면 train_dqn()은 훈련된 Q-네트워크, 총 손실 및 총 보상을 반환합니다. DQN 모델은 입력 주식 가격 데이터와 시뮬레이션된 거래 환경을 기반으로 거래 전략을 개발하는 데 사용할 수 있습니다.\n\n```js\ndqn, total_losses, total_rewards = train_dqn(Environment(train), epoch_num=25)\n```\n\n![Stock Forecasting](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDeep Q-Network (DQN) 알고리즘을 사용하여 이 Python 코드는 깊은 강화학습 모델을 훈련합니다. ‘train_dqn’은 ‘Environment’ 클래스의 인스턴스와 ‘epoch_num’ 매개변수 값 25를 인수로 받습니다. 이 함수는 지정된 환경의 훈련 데이터를 사용하여 25개의 에포크 동안 DQN 모델을 훈련시키고, 훈련된 DQN 모델, 총 손실 및 총 보상을 반환합니다.\n\n‘dqn’은 ‘train_dqn’에 의해 반환된 훈련된 DQN 모델을 받습니다. 환경의 상태에 따라, 이 모델은 결정 순서에 따른 누적 보상을 극대화하기 위해 훈련되었을 것으로 예상됩니다.\n\n총 손실 값은 각 훈련 에포크마다 'total_losses' 변수에 저장됩니다. 훈련 중에 손실 값을 최소화함으로써 예측된 Q값과 실제 Q값 사이의 차이를 최소화하여 모델의 정확도를 향상시킵니다.\n\n‘total_rewards’ 변수는 각 훈련 에포크에서의 총 보상 값 목록을 받습니다. 보상 값은 모델이 일련의 작업에서 얻은 누적 보상을 나타내며, 성능을 평가하는 데 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n총 손실 및 보상값을 나타내는 그래프를 그려주는 \"plot_loss_reward\"라는 사용자 정의 함수를 Python으로 작성한 코드입니다. 'total_losses'와 'total_rewards'는 각 훈련 에포크별 총 손실 값과 총 보상 값의 리스트입니다.Markdown의 표를 변경한 형식이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 이 함수는 Plotly 라이브러리의 ‘make_subplots’ 함수를 사용하여 두 개의 서브플롯이 있는 그림을 생성합니다. 두 서브플롯은 'loss'와 'reward'라는 제목이 달린 행 하나에 배치됩니다. 그림에서 그리드 라인을 숨기기 위해 'print_grid' 매개변수가 False로 설정됩니다.\n\n다음으로, 이 함수는 'append_trace' 메서드를 사용하여 그림에 두 개의 트레이스를 추가합니다. 첫 번째 트레이스는 'total_losses' 값들의 스카이블루로 색칠된 산점도 플롯입니다. 두 번째 트레이스는 주황색 선으로 'total_rewards' 값들의 산점도 플롯을 보여줍니다.\n\n서브플롯의 x축 제목은 'epoch'로 설정되며, 'layout' 객체의 'update' 메서드를 사용하여 그림의 높이와 너비를 각각 400픽셀과 900픽셀로 설정합니다. 그림에서 범례를 숨기기 위해 'showlegend' 매개변수가 False로 설정됩니다.\n\nJupyter 노트북에서 그림을 표시하려면 Plotly 라이브러리에서 'iplot' 함수를 사용합니다. 훈련 epoch 동안, 이 플롯은 손실과 보상 값의 추이를 보여주어 DQN 모델의 성능에 대한 통찰을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nplot_loss_reward(total_losses, total_rewards)\n```\n\n![이미지](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_6.png)\n\n이 코드는 \"plot_loss_reward\"라는 사용자 정의 함수를 호출합니다. 'total_losses'와 'total_rewards'라는 두 인자를 허용합니다. 이는 각 훈련 에폭마다 총 손실 값과 총 보상 값의 목록입니다.\n\nPlot_loss_reward는 훈련 에폭을 통해 손실 및 보상 값의 추세를 시각화하는 플롯을 생성합니다. 주식 시장 예측에 사용되는 DQN 모델의 훈련 중에는 코드가 이 함수를 사용하여 손실 및 보상 값을 플롯합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef plot_train_test_by_q(train_env, test_env, Q, algorithm_name):\n    \n    # train\n    pobs = train_env.reset()\n    train_acts = []\n    train_rewards = []\n    train_ongoing_profits = []\n\n```\n\n```js\n    for _ in range(len(train_env.data)-1):\n        \n        pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))\n        pact = np.argmax(pact.data)\n        train_acts.append(pact)\n            \n        obs, reward, done, profit = train_env.step(pact)\n        train_rewards.append(reward)\n        train_ongoing_profits.append(profit)\n        pobs = obs\n        \n    train_profits = train_env.profits\n    \n    # test\n    pobs = test_env.reset()\n    test_acts = []\n    test_rewards = []\n    test_ongoing_profits = []\n    for _ in range(len(test_env.data)-1):\n    \n        pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))\n        pact = np.argmax(pact.data)\n        test_acts.append(pact)\n            \n        obs, reward, done, profit = test_env.step(pact)\n        test_rewards.append(reward)\n        test_ongoing_profits.append(profit)\n        pobs = obs\n        \n    test_profits = test_env.profits\n    \n    # plot\n    train_copy = train_env.data.copy()\n    test_copy = test_env.data.copy()\n    train_copy['act'] = train_acts + [np.nan]\n    train_copy['reward'] = train_rewards + [np.nan]\n    test_copy['act'] = test_acts + [np.nan]\n    test_copy['reward'] = test_rewards + [np.nan]\n    train0 = train_copy[train_copy['act'] == 0]\n    train1 = train_copy[train_copy['act'] == 1]\n    train2 = train_copy[train_copy['act'] == 2]\n    test0 = test_copy[test_copy['act'] == 0]\n    test1 = test_copy[test_copy['act'] == 1]\n    test2 = test_copy[test_copy['act'] == 2]\n    act_color0, act_color1, act_color2 = 'gray', 'cyan', 'magenta'\n    data = [\n        Candlestick(x=train0.index, open=train0['Open'], high=train0['High'], low=train0['Low'], close=train0['Close'], increasing=dict(line=dict(color=act_color0)), decreasing=dict(line=dict(color=act_color0))),\n        Candlestick(x=train1.index, open=train1['Open'], high=train1['High'], low=train1['Low'], close=train1['Close'], increasing=dict(line=dict(color=act_color1)), decreasing=dict(line=dict(color=act_color1))),\n        Candlestick(x=train2.index, open=train2['Open'], high=train2['High'], low=train2['Low'], close=train2['Close'], increasing=dict(line=dict(color=act_color2)), decreasing=dict(line=dict(color=act_color2))),\n        Candlestick(x=test0.index, open=test0['Open'], high=test0['High'], low=test0['Low'], close=test0['Close'], increasing=dict(line=dict(color=act_color0)), decreasing=dict(line=dict(color=act_color0))),\n        Candlestick(x=test1.index, open=test1['Open'], high=test1['High'], low=test1['Low'], close=test1['Close'], increasing=dict(line=dict(color=act_color1)), decreasing=dict(line=dict(color=act_color1))),\n        Candlestick(x=test2.index, open=test2['Open'], high=test2['High'], low=test2['Low'], close=test2['Close'], increasing=dict(line=dict(color=act_color2)), decreasing=dict(line=dict(color=act_color2)))\n    ]\n    title = '{}: train s-reward {}, profits {}, test s-reward {}, profits {}'.format(\n        algorithm_name,\n        int(sum(train_rewards)),\n        int(train_profits),\n        int(sum(test_rewards)),\n        int(test_profits)\n    )\n    layout = {\n        'title': title,\n        'showlegend': False,\n         'shapes': [\n             {'x0': date_split, 'x1': date_split, 'y0': 0, 'y1': 1, 'xref': 'x', 'yref': 'paper', 'line': {'color': 'rgb(0,0,0)', 'width': 1}\n         ],\n        'annotations': [\n            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'left', 'text': ' test data'},\n            {'x': date_split, 'y': 1.0, 'xref': 'x', 'yref': 'paper', 'showarrow': False, 'xanchor': 'right', 'text': 'train data '}\n        ]\n    }\n    figure = Figure(data=data, layout=layout)\n    iplot(figure)\n    \n    return train_ongoing_profits, test_ongoing_profits\n```\n\nplot_train_test_by_q()는 훈련된 DQN 모델의 거래 행동과 성능을 훈련 및 테스트 데이터 세트에서 시각화합니다. 이 알고리즘은 train_env와 test_env(훈련 및 테스트 환경), Q(훈련된 Q-Network), algorithm_name(알고리즘 이름) 네 가지 인수를 사용합니다.\n\n훈련된 Q-Network를 사용하여 함수는 환경을 초기화하고 훈련 및 테스트 데이터를 반복합니다. 두 데이터 세트 모두에서 조치, 보상 및 지속적인 이윤을 누적합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 단계에서 함수는 훈련 및 테스트 데이터의 사본을 생성하고, 행동과 보상을 새 열로 추가합니다. 훈련 및 테스트 데이터 모두는 이후 행동(0: stay, 1: buy, 2: sell)에 따라 분할됩니다.\n\n훈련 또는 테스트 데이터 및 행동의 각 조합에 대해 함수는 서로 다른 색상으로 다른 행동을 나타내는 캔들스틱 플롯 목록을 만듭니다. 플롯 제목에는 훈련 및 테스트 데이터뿐만 아니라 총 보상과 이익도 포함됩니다.\n\n플롯은 훈련 및 테스트 데이터를 구분하는 수직선이 설정되고, 훈련 및 테스트 데이터 섹션을 나타내는 주석이 포함됩니다. 데이터와 레이아웃이 생성된 후 iplot()을 사용하여 플롯을 표시합니다.\n\n알고리즘 성능의 분석이나 비교를 위해, 함수는 훈련 및 테스트 데이터 모두에 대한 지속적인 이익을 반환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntrain_profits, test_profits = plot_train_test_by_q(Environment(train), Environment(test), dqn, 'DQN')\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_7.png\" /\u003e\n\n파이썬을 사용하여, 이 코드는 훈련된 DQN 모델의 성능을 훈련 및 테스트 데이터로 평가합니다. 'plot_train_test_by_q' 함수는 'Environment' 클래스의 인스턴스(훈련 데이터용과 테스트 데이터용)와 훈련된 DQN 모델 'dqn'을 인자로 전달받아 호출됩니다. 모델의 예측 결과를 기반으로, plot_train_test_by_q 함수는 훈련 및 테스트 데이터에서 얻은 수익을 반환합니다.\n\nDQN 모델의 예측에 따라, 'train_profits' 변수에는 훈련 데이터에서 얻은 수익이 저장되고, 'test_profits'에는 DQN 모델의 예측에 따라 얻은 테스트 데이터 수익이 저장됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련된 DQN 모델을 훈련 및 테스트 데이터에 대해 평가하고 각 데이터셋에서 얻은 이익을 계산하는 코드입니다. 이 평가는 DQN 모델의 정확성과 효과를 결정하는 데 유용할 수 있습니다.\n\n```js\nplt.figure(figsize=(23,8))\nplt.plot(data.index,((data['Close']-data['Close'][0])/data['Close'][-1]), label='buy and hold')\nplt.plot(train.index, ([0] + train_profits)/data['Close'][-1], label='rl (train)')\nplt.plot(test.index, (([0] + test_profits) + train_profits[-1])/data['Close'][-1], label='rl (test)')\nplt.ylabel('relative gain')\nplt.legend()\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_8.png\" /\u003e\n\nPython 코드는 주식 시장 예측을 위한 DQN 모델의 성능을 '매수 및 보유' 전략과 비교하는 플롯을 생성합니다. Matplotlib의 'plt' 모듈을 사용하여 플롯을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMatplotlib 라이브러리의 'figure' 함수를 사용하여 플롯의 크기를 설정하는 코드입니다. 'figsize' 매개변수를 인수로 취합니다. 마지막에 플롯의 크기는 폭 23인치, 높이 8인치입니다.\n\nMatplotlib의 plot 함수를 사용하여 '매수 보유' 전략을 플롯하는 코드입니다. 플롯의 x 축은 가져온 데이터의 인덱스를 나타내며, y 축은 주식을 매수하여 보유한 결과로 얻은 이익의 상대적 증가량을 나타냅니다. 이 플롯에는 '매수 보유'라는 레이블이 지정됩니다.\n\nDQN 모델을 사용하여 훈련 데이터에서 얻은 이익을 플롯하는 코드입니다. 이 플롯의 x 축은 훈련 데이터의 인덱스를 나타내며, y 축은 DQN 모델의 예측으로부터 얻은 이익의 상대적 증가량을 나타냅니다. 상대적 이득은 이익을 가져온 데이터의 마지막 종가로 나누어 계산됩니다. 이 플롯의 레이블은 'rl(train)'로 설정됩니다.\n\nDQN 모델을 사용하여 테스트 데이터에서 얻은 이익을 플롯하는 코드입니다. x 축은 테스트 데이터의 인덱스를 나타내며, y 축은 DQN 모델의 예측으로부터 얻은 상대적인 수익 증가를 나타냅니다. 상대적 이득은 훈련 이익을 추가하고 가져온 데이터의 마지막 종가로 나누어 계산됩니다. 이 플롯의 레이블은 'rl(test)'로 지정됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n맷플롯립의 'ylabel' 함수는 플롯의 y-축 레이블을 '상대 이익'으로 설정합니다. 맷플롯립의 'legend' 함수는 플롯 범례에 그려진 세 개의 선의 레이블을 표시합니다.\n\n플롯은 맷플롯립 라이브러리의 'show' 함수를 사용하여 표시됩니다. 훈련 및 테스트 데이터 모두에서 플롯은 '매수 및 보유' 전략 및 DQN 모델의 예측으로부터의 상대적 이익 획득을 보여줍니다. DQN 모델을 '매수 및 보유'와 같은 간단한 전략과 비교함으로써 효과를 파악할 수 있습니다.\n\n```js\n# 더블 DQN\n```\n\n```js\ndef train_ddqn(env, epoch_num=50):\n    class Q_Network(chainer.Chain):\n        def __init__(self, input_size, hidden_size, output_size):\n            super(Q_Network, self).__init__(\n                fc1 = L.Linear(input_size, hidden_size),\n                fc2 = L.Linear(hidden_size, hidden_size),\n                fc3 = L.Linear(hidden_size, output_size)\n            )\n        def __call__(self, x):\n            h = F.relu(self.fc1(x))\n            h = F.relu(self.fc2(h))\n            y = self.fc3(h)\n            return y\n        def reset(self):\n            self.zerograds()\n    Q = Q_Network(input_size=env.history_t+1, hidden_size=100, output_size=3)\n    Q_ast = copy.deepcopy(Q)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(Q)\n    step_max = len(env.data)-1\n    memory_size = 200\n    batch_size = 50\n    epsilon = 1.0\n    epsilon_decrease = 1e-3\n    epsilon_min = 0.1\n    start_reduce_epsilon = 200\n    train_freq = 10\n    update_q_freq = 20\n    gamma = 0.97\n    show_log_freq = 5\n    memory = []\n    total_step = 0\n    total_rewards = []\n    total_losses = []\n    start = time.time()\n    for epoch in range(epoch_num):\n        pobs = env.reset()\n        step = 0\n        done = False\n        total_reward = 0\n        total_loss = 0\n        while not done and step \u003c step_max:\n            # select act\n            pact = np.random.randint(3)\n            if np.random.rand() \u003e epsilon:\n                pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))\n                pact = np.argmax(pact.data)\n            # act\n            obs, reward, done, profit = env.step(pact)\n            # add memory\n            memory.append((pobs, pact, reward, obs, done))\n            if len(memory) \u003e memory_size:\n                memory.pop(0)\n            # train or update q\n            if len(memory) == memory_size:\n                if total_step % train_freq == 0:\n                    shuffled_memory = np.random.permutation(memory)\n                    memory_idx = range(len(shuffled_memory))\n                    for i in memory_idx[::batch_size]:\n                        batch = np.array(shuffled_memory[i:i+batch_size])\n                        b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)\n                        b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)\n                        b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n                        b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)\n                        b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)\n                        q = Q(b_pobs)\n                        \"\"\" \u003c\u003c\u003c DQN -\u003e Double DQN\n                        maxq = np.max(Q_ast(b_obs).data, axis=1)\n                        === \"\"\"\n                        indices = np.argmax(q.data, axis=1)\n                        maxqs = Q_ast(b_obs).data\n                        \"\"\" \u003e\u003e\u003e \"\"\"\n                        target = copy.deepcopy(q.data)\n                        for j in range(batch_size):\n                            \"\"\" \u003c\u003c\u003c DQN -\u003e Double DQN\n                            target[j, b_pact[j]] = b_reward[j]+gamma*maxq[j]*(not b_done[j])\n                            === \"\"\"\n                            target[j, b_pact[j]] = b_reward[j]+gamma*maxqs[j, indices[j]]*(not b_done[j])\n                            \"\"\" \u003e\u003e\u003e \"\"\"\n                        Q.reset()\n                        loss = F.mean_squared_error(q, target)\n                        total_loss += loss.data\n                        loss.backward()\n                        optimizer.update()\n                if total_step % update_q_freq == 0:\n                    Q_ast = copy.deepcopy(Q)\n            # epsilon\n            if epsilon \u003e epsilon_min and total_step \u003e start_reduce_epsilon:\n                epsilon -= epsilon_decrease\n            # next step\n            total_reward += reward\n            pobs = obs\n            step += 1\n            total_step += 1\n        total_rewards.append(total_reward)\n        total_losses.append(total_loss)\n        if (epoch+1) % show_log_freq == 0:\n            log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq\n            log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq\n            elapsed_time = time.time()-start\n            print('\\t'.join(map(str, [epoch+1, epsilon, total_step, log_reward, log_loss, elapsed_time])))\n            start = time.time()\n            \n    return Q, total_losses, total_rewards\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제공된 코드는 거래 환경을 해결하기 위해 더블 딥 Q-네트워크(DDQN)를 훈련하는 train_ddqn() 함수를 정의합니다. 기본값이 50인 선택적인 epoch_num 매개변수는 훈련 에포크의 수와 환경 env를 나타냅니다.\n\nQ_Network는 chainer.Chain의 하위 클래스로 정의되며, Chainer에 특화된 신경망 모델입니다. __call__ 메서드는 첫 두 레이어에 ReLU 활성화 함수를 적용하고 세 번째 레이어의 출력을 반환합니다.\n\n훈련 함수는 Q-네트워크 Q와 대상 네트워크 Q_ast를 초기화하고 옵티마이저를 설정하며, 메모리 크기, 배치 크기 및 엡실론과 같은 학습 프로세스의 하이퍼파라미터를 정의합니다.\n\n훈련 과정에서 함수는 여러 에포크를 반복합니다. 각 에포크에서 다음 단계가 수행됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 환경을 초기화하고 초기 관측값을 얻는 것은 첫 단계입니다.\n- 현재 엡실론 탐욕 전략에 따라, 에이전트가 어떤 행동을 취할지 결정합니다.\n- 에이전트는 환경에서 행동을 수행하고 결과적인 관측값, 보상 및 완료 플래그를 수집합니다.\n- 경험 튜플 (상태, 행동, 보상, 다음 상태, 완료)은 메모리 버퍼에 저장됩니다.\n- 메모리 버퍼가 가득 차면, 에이전트는 미니 배치를 샘플링하고 더블 DQN 업데이트 규칙을 사용하여 가중치를 업데이트합니다.\n- 주요 Q-네트워크의 가중치는 주기적으로 타겟 네트워크 Q_ast에 업데이트됩니다.\n- 엡실론이 최솟값에 도달할 때까지 선형적으로 감소됩니다.\n- 에이전트는 총 보상, 현재 상태 및 단계 수를 업데이트하면서 다음 단계로 이동합니다.\n\n훈련 과정이 완료되면 함수는 훈련된 Q-네트워크, 총 손실 및 각 에포크별 총 보상을 반환합니다. 훈련된 DDQN 모델은 테스트 환경에서 에이전트의 성능을 평가하거나 실제 주식 거래 시나리오에서 예측을 수행하는 데 사용할 수 있습니다.\n\n```js\nddqn, total_losses, total_rewards = train_ddqn(Environment(train), epoch_num=50)\n```\n\n![Stock Forecasting](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 Python 코드는 Double Deep Q-Network (DDQN) 알고리즘을 사용하여 강화 학습 모델을 훈련합니다. 'Environment' 인스턴스가 'train_ddqn' 함수에 전달되며 'epoch_num' 매개변수 값으로 50이 전달됩니다. 'train_ddqn' 함수는 지정된 환경에서 제공된 훈련 데이터를 사용하여 50개의 에포크 동안 DDQN 모델을 훈련하고, 훈련된 모델, 총 손실 및 총 보상을 반환합니다.\n\n'train_ddqn' 함수에서 반환된 훈련 된 DDQN 모델은 'ddqn' 변수에 저장됩니다. 이 모델은 환경의 상태를 기반으로 결정을 내리고 연속적인 작업을 통해 누적 보상을 극대화하도록 훈련될 가능성이 높습니다.\n\n총 손실 값은 각 훈련 에포크마다 'total_losses' 변수에 저장됩니다. 훈련 중에 손실 값은 예측된 Q-값과 실제 Q-값 간의 차이를 최소화하여 모델의 정확도를 향상시키기 위해 최소화됩니다.\n\n'total_rewards' 변수는 각 훈련 에포크마다 총 보상 값 목록을 수신합니다. 보상 값은 모델이 연속적인 작업을 통해 획득한 누적 보상을 나타내며 모델의 성능을 평가하는 데 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 지정된 환경에서 훈련 데이터를 사용하여 DDQN 모델을 훈련하고 'train_ddqn' 함수를 사용하여 훈련된 모델과 각 훈련 에포크별 총 손실 및 보상을 얻습니다. 주식 시장 예측이나 DDQN 모델을 사용하여 강화 학습이 필요한 다른 의사 결정 작업을 수행할 수 있습니다.\n\n```js\nplot_loss_reward(total_losses, total_rewards)\n```\n\n![stock_prediction_graph](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_10.png)\n\n이는 \"plot_loss_reward\"라는 사용자 정의 함수를 호출합니다. 이 함수는 총 손실 값 및 각 훈련 에포크별 총 보상 값의 목록인 'total_losses'와 'total_rewards'라는 두 인수를 받습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nplot_loss_reward 함수는 손실 및 보상 값의 추세를 시각화하는 플롯을 생성합니다. DDQN 모델을 훈련하는 동안, 이 함수는 손실 및 보상 값의 그래픽을 생성합니다.\n\n이 함수의 구현 내용이 제공되지 않았기 때문에 플롯이 어떻게 표시되는지 또는 무엇을 표시하는지에 대한 자세한 내용을 제공하기 어렵습니다. 그러나 함수는 아마도 Plotly 또는 Matplotlib과 같은 그래픽 라이브러리를 사용하여 각 훈련 에포크에 걸쳐 손실 및 보상 값이 표시되는 플롯을 생성할 것으로 예상됩니다. DDQN 모델의 성능을 파악하는 데 도움이 될 수 있습니다.\n\n```js\ntrain_profits, test_profits = plot_train_test_by_q(Environment(train), Environment(test), ddqn, 'Double DQN')\n```\n\n![그림](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬으로 작성된 코드는 훈련된 더블 딥 Q-네트워크(DDQN) 모델의 성능을 훈련 및 테스트 데이터에서 평가합니다. plot_train_test_by_q 함수에는 세 가지 인수가 전달됩니다: 훈련 데이터용 'Environment' 클래스의 인스턴스, 테스트 데이터용 'Environment' 클래스의 인스턴스, 그리고 훈련된 DDQN 모델입니다. plot_train_test_by_q 함수는 DDQN 모델을 테스트 데이터에 대해 평가하고 모델 예측에 따른 이익을 반환합니다.\n\nDDQN 모델 예측의 결과로 'train_profits'는 훈련 데이터에서 얻은 이익을 받습니다. DDQN 모델 예측에 따라 'test_profits' 변수는 테스트 데이터에서 얻은 이익을 받습니다.\n\n이 코드는 훈련 및 테스트 데이터에서 훈련된 DDQN 모델의 성능을 평가하고 각 데이터셋에 대한 이익을 얻습니다. 주식 시장 예측이나 강화 학습을 필요로 하는 기타 의사 결정 작업에는 이 평가 결과가 유용할 수 있습니다.\n\n```js\nplt.figure(figsize=(23,8))\nplt.plot(data.index,((data['Close']-data['Close'][0])/data['Close'][-1]), label='buy and hold')\nplt.plot(train.index, ([0] + train_profits)/data['Close'][-1], label='rl (train)')\nplt.plot(test.index, (([0] + test_profits) + train_profits[-1])/data['Close'][-1], label='rl (test)')\nplt.ylabel('relative gain')\nplt.legend()\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_12.png)\n\n이 코드는 Python으로 작성되었으며 주식 시장 예측을 위해 DDQN 모델과 '매수 및 보유' 전략의 성능을 비교하는 플롯을 생성하는 데 사용됩니다. Matplotlib 라이브러리의 'plt' 모듈을 사용하여 플롯을 생성합니다.\n\n코드는 먼저 Matplotlib 라이브러리의 'figure' 함수를 사용하여 플롯의 크기를 설정하며 'figsize' 매개변수를 인수로 취합니다. 결과 플롯은 너비 23인치, 높이 8인치입니다.\n\n그런 다음 코드는 Matplotlib 라이브러리의 'plot' 함수를 사용하여 '매수 및 보유' 전략을 플롯합니다. 플롯의 x 축은 가져온 데이터의 색인으로 설정되고 y 축은 주식을 사고 보유함으로써 얻는 이윤의 상대적 이득을 나타냅니다. 이 플롯의 레이블은 '매수 및 보유'로 설정됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 코드는 DDQN 모델을 사용하여 훈련 데이터에서 얻은 이익을 플롯합니다. 이 그래프의 x축은 훈련 데이터의 인덱스로 설정되고, y축은 DDQN 모델의 예측에 따른 이익 상대적인 이득을 나타냅니다. 이익은 가져온 데이터의 마지막 종가로 나누어 상대적인 이득을 얻기 위해 조정됩니다. 이 그래프의 레이블은 'rl (train)'로 설정됩니다.\n\n그 다음, 코드는 DDQN 모델을 사용하여 테스트 데이터에서 얻은 이익을 플롯합니다. 이 그래프의 x축은 테스트 데이터의 인덱스로 설정되고, y축은 DDQN 모델의 예측에 따른 이익 상대적인 이득을 나타냅니다. 이익은 훈련 이익을 더한 다음 가져온 데이터의 마지막 종가로 나누어 상대적인 이득을 얻기 위해 조정됩니다. 이 그래프의 레이블은 'rl (test)'로 설정됩니다.\n\n플롯의 y축 레이블은 Matplotlib 라이브러리의 'ylabel' 함수를 사용하여 '상대적인 이익'으로 설정됩니다. 플롯 범례는 Matplotlib 라이브러리의 'legend' 함수를 사용하여 표시되며, 플롯된 세 가지 선의 레이블을 보여줍니다.\n\n마지막으로, Matplotlib 라이브러리의 'show' 함수를 사용하여 플롯이 표시됩니다. 결과 그래프는 '매수 및 보유' 전략과 DDQN 모델의 예측으로 얻은 이익의 상대적인 이득을 훈련 및 테스트 데이터 모두에서 보여줍니다. 이를 통해 DDQN 모델의 효과를 '매수 및 보유'와 같은 간단한 전략과 비교하는 통찰력을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 경쟁 두 번째 배럴 DQN\n```\n\n```js\ndef train_dddqn(env, epoch_num=50):\n    \"\"\" \u003c\u003c\u003c 더블 DQN -\u003e Dueling Double DQN\n    class Q_Network(chainer.Chain):\n        def __init__(self, input_size, hidden_size, output_size):\n            super(Q_Network, self).__init__(\n                fc1 = L.Linear(input_size, hidden_size),\n                fc2 = L.Linear(hidden_size, hidden_size),\n                fc3 = L.Linear(hidden_size, output_size)\n            )\n        def __call__(self, x):\n            h = F.relu(self.fc1(x))\n            h = F.relu(self.fc2(h))\n            y = self.fc3(h)\n            return y\n        def reset(self):\n            self.zerograds()\n    === \"\"\"\n    class Q_Network(chainer.Chain):\n        def __init__(self, input_size, hidden_size, output_size):\n            super(Q_Network, self).__init__(\n                fc1 = L.Linear(input_size, hidden_size),\n                fc2 = L.Linear(hidden_size, hidden_size),\n                fc3 = L.Linear(hidden_size, hidden_size//2),\n                fc4 = L.Linear(hidden_size, hidden_size//2),\n                state_value = L.Linear(hidden_size//2, 1),\n                advantage_value = L.Linear(hidden_size//2, output_size)\n            )\n            self.input_size = input_size\n            self.hidden_size = hidden_size\n            self.output_size = output_size\n        def __call__(self, x):\n            h = F.relu(self.fc1(x))\n            h = F.relu(self.fc2(h))\n            hs = F.relu(self.fc3(h))\n            ha = F.relu(self.fc4(h))\n            state_value = self.state_value(hs)\n            advantage_value = self.advantage_value(ha)\n            advantage_mean = (F.sum(advantage_value, axis=1)/float(self.output_size)).reshape(-1, 1)\n            q_value = F.concat([state_value for _ in range(self.output_size)], axis=1) + (advantage_value - F.concat([advantage_mean for _ in range(self.output_size)], axis=1))\n            return q_value\n        def reset(self):\n            self.zerograds()\n    \"\"\" \u003e\u003e\u003e \"\"\"\n    Q = Q_Network(input_size=env.history_t+1, hidden_size=100, output_size=3)\n    Q_ast = copy.deepcopy(Q)\n    optimizer = chainer.optimizers.Adam()\n    optimizer.setup(Q)\n    step_max = len(env.data)-1\n    memory_size = 200\n    batch_size = 50\n    epsilon = 1.0\n    epsilon_decrease = 1e-3\n    epsilon_min = 0.1\n    start_reduce_epsilon = 200\n    train_freq = 10\n    update_q_freq = 20\n    gamma = 0.97\n    show_log_freq = 5\n    memory = []\n    total_step = 0\n    total_rewards = []\n    total_losses = []\n    start = time.time()\n    for epoch in range(epoch_num):\n        pobs = env.reset()\n        step = 0\n        done = False\n        total_reward = 0\n        total_loss = 0\n        while not done and step \u003c step_max:\n            # select act\n            pact = np.random.randint(3)\n            if np.random.rand() \u003e epsilon:\n                pact = Q(np.array(pobs, dtype=np.float32).reshape(1, -1))\n                pact = np.argmax(pact.data)\n            # act\n            obs, reward, done, profit = env.step(pact)\n            # add memory\n            memory.append((pobs, pact, reward, obs, done))\n            if len(memory) \u003e memory_size:\n                memory.pop(0)\n            # train or update q\n            if len(memory) == memory_size:\n                if total_step % train_freq == 0:\n                    shuffled_memory = np.random.permutation(memory)\n                    memory_idx = range(len(shuffled_memory))\n                    for i in memory_idx[::batch_size]:\n                        batch = np.array(shuffled_memory[i:i+batch_size])\n                        b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)\n                        b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)\n                        b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n                        b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)\n                        b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)\n                        q = Q(b_pobs)\n                        \"\"\" \u003c\u003c\u003c DQN -\u003e Double DQN\n                        maxq = np.max(Q_ast(b_obs).data, axis=1)\n                        === \"\"\"\n                        indices = np.argmax(q.data, axis=1)\n                        maxqs = Q_ast(b_obs).data\n                        \"\"\" \u003e\u003e\u003e \"\"\"\n                        target = copy.deepcopy(q.data)\n                        for j in range(batch_size):\n                            \"\"\" \u003c\u003c\u003c DQN -\u003e Double DQN\n                            target[j, b_pact[j]] = b_reward[j]+gamma*maxq[j]*(not b_done[j])\n                            === \"\"\"\n                            target[j, b_pact[j]] = b_reward[j]+gamma*maxqs[j, indices[j]]*(not b_done[j])\n                            \"\"\" \u003e\u003e\u003e \"\"\"\n                        Q.reset()\n                        loss = F.mean_squared_error(q, target)\n                        total_loss += loss.data\n                        loss.backward()\n                        optimizer.update()\n                if total_step % update_q_freq == 0:\n                    Q_ast = copy.deepcopy(Q)\n            # epsilon\n            if epsilon \u003e epsilon_min and total_step \u003e start_reduce_epsilon:\n                epsilon -= epsilon_decrease\n            # next step\n            total_reward += reward\n            pobs = obs\n            step += 1\n            total_step += 1\n        total_rewards.append(total_reward)\n        total_losses.append(total_loss)\n        if (epoch+1) % show_log_freq == 0:\n            log_reward = sum(total_rewards[((epoch+1)-show_log_freq):])/show_log_freq\n            log_loss = sum(total_losses[((epoch+1)-show_log_freq):])/show_log_freq\n            elapsed_time = time.time()-start\n            print('\\t'.join(map(str, [epoch+1, epsilon, total_step, log_reward, log_loss, elapsed_time])))\n            start = time.time()\n            \n    return Q, total_losses, total_rewards\n```\n\n제공된 코드는 트레이딩 환경을 해결하기 위해 Dueling Double Deep Q-Network (Dueling DDQN)을 훈련하는 train_dddqn() 함수를 정의합니다. 이 함수는 환경 env를 인수로 받고 선택적인 epoch_num 매개변수를 취하며 기본값은 50입니다. epoch_num은 훈련 에포크 수를 나타냅니다.\n\n이 코드와 이전의 더블 DQN 구현 간의 주요 차이점은 Q_Network 클래스의 정의입니다. Dueling DDQN은 Q-Network 아키텍처를 수정하여 상태 가치를 추정하는 스트림과 각 작업의 어드밴티지 값을 추정하는 또 다른 스트림을 포함합니다. 두 스트림이 결합되어 최종 Q-값을 계산합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nQ_Network 클래스는 chainer.Chain의 하위 클래스이며, 다섯 개의 완전 연결 레이어 (Linear 레이어)를 포함하고 있어요. __call__ 메서드에서 처음 두 개 레이어는 두 스트림 간에 공유되며, 그 다음에는 두 개의 별도 스트림으로 분리돼요. 상태 값 스트림은 추가 Linear 레이어 (state_value)를 가지고 있어요. 이 레이어는 단일 값 출력하고, 이에 반해 어드밴티지 값 스트림은 각 행동에 대한 값을 출력하기 위한 추가 Linear 레이어 (advantage_value)를 가지고 있어요. 최종 Q-값은 상태 값과 어드밴티지 값의 조합으로 계산되며, 안정성을 위해 평균 어드밴티지 값이 빼져요.\n\n나머지 코드는 더블 DQN 구현과 매우 유사해요. Q-Network Q와 대상 네트워크인 Q_ast를 초기화하고, 옵티마이저를 설정하며, 훈련 과정을 위한 하이퍼파라미터를 정의해요. 훈련 루프는 여러 에포크를 반복하며, 입실론-그리디 전략을 사용하여 행동을 선택하고, 메모리 버퍼를 업데이트하며, Dueling DDQN 업데이트 규칙을 사용하여 Q-Network를 훈련시키고 있어요. 대상 네트워크 Q_ast는 기본 Q-Network의 가중치로 주기적으로 업데이트되며, 입실론은 최솟값에 도달할 때까지 선형적으로 감소해요.\n\n훈련 과정을 마치면, 함수는 훈련된 Dueling DDQN 모델, 총 손실 및 각 에포크별 총 보상을 반환해요. 이 훈련된 모델은 테스트 환경에서 에이전트의 성능을 평가하거나 실제 세계의 거래 시나리오에서 예측을 수행하는 데 사용할 수 있어요.\n\n```js\ndddqn, total_losses, total_rewards = train_dddqn(Environment(train), epoch_num=25)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_13.png)\n\n이 코드 라인은 훈련 데이터셋을 사용하여 거래 환경에서 Dueling Double Deep Q-Network (Dueling DDQN)을 훈련하는 train_dddqn() 함수를 호출합니다. 이 함수는 두 개의 인수를 사용합니다:\n\n- 환경(train): 훈련 데이터를 사용하여 새로운 거래 환경의 인스턴스를 생성합니다. 이 환경은 환경을 초기화하거나 시간 단계를 걸어가는 등의 데이터와 상호 작용하는 방법을 제공합니다.\n- epoch_num=25: 이는 실행될 훈련 epochs의 수를 지정합니다. 이 경우, 25번의 epochs를 의미합니다. 각 epoch은 훈련 데이터셋을 완전히 통과하는 것을 의미하며, 에이전트가 환경과 상호 작용하고 Q-Network을 업데이트하며 경험으로부터 학습하는 것을 포함합니다.\n\ntrain_dddqn() 함수는 세 가지 값을 반환합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- dddqn: 훈련된 Dueling DDQN 모델로, 테스트 환경이나 실제 시나리오에서 거래 결정을 내릴 때 사용할 수 있습니다.\n- total_losses: 각 epoch별 총 손실값 목록입니다. 손실은 훈련 중 예측된 Q값과 대상 Q값 사이의 평균 제곱 오차로 계산됩니다. 이는 모델의 훈련 성능을 평가하고, 에이전트가 효과적으로 학습하는지를 평가하는 데 사용할 수 있습니다.\n- total_rewards: 각 epoch별 총 보상값 목록입니다. 보상은 각 epoch 동안 에이전트의 성능을 측정한 것으로, 일반적으로 거래 중 발생한 이익이나 손실에 기반합니다. 이는 훈련 과정 전체에서 수익성 있는 거래 결정을 내리는 에이전트의 능력을 평가하는 데 사용될 수 있습니다.\n\n이러한 반환 값을 변수에 할당함으로써, 훈련 결과를 추가로 분석하거나, 시간이 지남에 따라 손실과 보상을 플로팅하거나, 테스트 환경에서 훈련된 모델의 성능을 평가할 수 있습니다.\n\n```js\nplot_loss_reward(total_losses, total_rewards)\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_14.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nplot_loss_reward(total_losses, total_rewards) 함수를 사용하면 모델의 손실과 보상을 시간에 따라 그래픽으로 나타낼 수 있어요. 이 함수는 두 개의 인수를 사용합니다:\n\n- total_losses: 훈련 과정 중 각 에포크의 총 손실 목록입니다. 이러한 손실은 예측된 Q-값과 타겟 Q-값 사이의 차이로, 평균 제곱 오차로 계산됩니다. 시간이 지남에 따라 손실을 추적하면 학습 과정의 효과를 평가하고 모델이 최적 해결책으로 수렴하는지 여부를 판단하는 데 도움이 됩니다.\n- total_rewards: 훈련 과정 중 각 에포크의 총 보상 목록입니다. 보상은 거래 환경에서 에이전트의 성능을 나타내는데, 일반적으로 거래 중 발생한 이익이나 손실에 기반합니다. 시간이 지남에 따라 보상을 모니터링하면 에이전트가 이윤을 창출하는 거래 결정을 내리는 능력을 평가하고 경험을 통해 결정력을 향상하는 데 도움이 됩니다.\n\n이 함수는 두 개의 플롯을 생성합니다: 하나는 손실에 대한 것이고 다른 하나는 보상에 대한 것입니다. 각 플롯에는 x-축에 에포크 수가, y-축에는 해당 손실 또는 보상 값이 표시됩니다. 이러한 플롯은 훈련 진행 상황에 대한 시각적인 통찰력을 제공하여 학습 과정에서 트렌드나 문제를 식별하는 데 도움이 됩니다. 예를 들어, 감소하는 손실 트렌드는 모델이 효과적으로 학습하고 있음을 나타내며, 증가하는 보상 트렌드는 에이전트가 시간이 지남에 따라 이윤 창출하는 거래 결정에 능숙해지고 있는 것을 시사합니다.\n\n```js\ntrain_profits, test_profits = plot_train_test_by_q(Environment(train), Environment(test), dddqn, 'Dueling Double DQN')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![plot_train_test_by_q](/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_15.png)\n\n\"plot_train_test_by_q\" 함수 호출은 훈련된 Dueling Double DQN(DDDQN) 모델의 성능을 훈련 및 테스트 데이터에 대해 평가하고, 거래 과정에서 에이전트가 생성한 이익을 시각화하는 데 사용됩니다.\n\n이 함수는 네 가지 인수를 사용합니다:\n\n- Environment(train): 훈련 데이터셋을 사용하여 초기화 된 거래 환경의 인스턴스입니다.\n- Environment(test): 테스트 데이터셋을 사용하여 초기화 된 거래 환경의 인스턴스입니다.\n- dddqn: 환경에서 거래 결정을 내리는 데 사용되는 훈련된 DDDQN 모델입니다.\n- `Dueling Double DQN`: DDDQN 모델을 사용하고 있음을 나타내는 생성된 플롯의 제목 역할을 하는 문자열입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDDDQN 모델의 성능을 평가하는 함수입니다. 해당 함수는 에이전트의 거래 활동을 시뮬레이션하고 각 거래 세션에서 생성된 이익을 수집하여 훈련 및 테스트 환경에서 모델의 성과를 평가합니다. 이익은 훈련 및 테스트 데이터셋에서 생성된 이익을 각각 나타내는 train_profits 및 test_profits 두 개의 별도 리스트에 저장됩니다.\n\n마지막으로, 해당 함수는 훈련 및 테스트 데이터에 대한 거래 이익의 시간에 따른 시각화를 생성합니다. 이 그래프는 y-축에 에이전트가 생성한 누적 이익을, x-축에 거래 스텝을 나타냅니다. 훈련 및 테스트 데이터셋 상에서 에이전트의 성능을 비교함으로써 모델의 일반화 능력과 새로운, 보이지 않는 시장 데이터에 대한 적응 능력을 평가할 수 있습니다. 또한 시각화를 통해 훈련 데이터에서 뛰어난 성과를 보일지라도 테스트 데이터에서 어려움을 겪는 과적합 문제를 식별하는 데 도움이 됩니다.\n\nMarkdown 형식으로 변경된 코드를 참고해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드 스니펫은 DDDQN 기반 거래 에이전트의 성능을 \"매수 및 보유\" 전략과 비교하는 시각화를 생성하는 역할을 합니다. 이를 위해 각 접근 방식이 달성한 상대 이익을 동일한 그래프 상에 시각화합니다. 시각화는 Matplotlib 라이브러리를 사용하여 생성되며, 다음 단계로 구성됩니다:\n\n- plt.figure(figsize=(23,8)): 지정된 너비와 높이(23인치 × 8인치)로 새로운 Matplotlib 피규어를 생성합니다.\n- plt.plot(data.index,((data[`Close`]-data[`Close`][0])/data[`Close`][-1]), label=`buy and hold`): 현재 종가와 초기 종가의 차이를 최종 종가로 나눈 것으로 계산된 \"매수 및 보유\" 전략의 상대적 이익을 플롯합니다. x축은 시간 인덱스를, y축은 상대적 이익을 나타냅니다.\n- plt.plot(train.index, ([0] + train_profits)/data[`Close`][-1], label=`rl (train)`): 학습 데이터셋에서 DDDQN 에이전트의 상대적 이익을 플롯합니다. x축은 학습 데이터셋의 시간 인덱스이며, y축은 누적 수익을 최종 종가로 나눈 상대적 이익을 나타냅니다.\n- plt.plot(test.index, (([0] + test_profits) + train_profits[-1])/data[`Close`][-1], label=`rl (test)`): 테스트 데이터셋에서 DDDQN 에이전트의 상대적 이익을 플롯합니다. x축은 테스트 데이터셋의 시간 인덱스를, y축은 누적 수익과 학습 데이터셋의 최종 이익을 더한 것을 최종 종가로 나눈 상대적 이익을 보여줍니다.\n- plt.plot(test.index, (([0] + test_profits) - data[`Close`][0] + data[`Close`][len(train_profits)])/data[`Close`][-1], label=`rl (test)`): 테스트 데이터셋에서 DDDQN 에이전트의 상대적 이익의 대체 버전을 플롯합니다. 누적 수익에서 초기 종가를 뺀 후 학습 데이터셋의 끝에서의 종가를 더한 것을 최종 종가로 나눈 것으로 계산됩니다.\n- plt.ylabel(`relative gain`): y축 레이블을 \"상대적 이익\"으로 설정합니다.\n- plt.legend(): 플롯에 라인의 레이블을 보여주는 범례를 추가합니다.\n- plt.show(): 생성된 플롯을 표시합니다.\n\n이 시각화는 DDDQN 거래 에이전트의 성능과 간단한 \"매수 및 보유\" 전략의 비교를 제공하여 특정 거래 문제에 대한 강화 학습 접근 방식의 효과를 평가할 수 있게 해줍니다.\n\n# 상대적 신호 강도\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRSI는 추세 모멘텀을 나타내는 데 사용됩니다. 상단 영역은 매수 과다 상태를 나타내고, 하단 영역은 매도 과다 상태를 나타냅니다. RSI가 매수 과다 또는 매도 과다 영역에 도달하면 각각 추세가 강하게 하락하거나 상승하는 것을 의미하지만, 영역을 벗어나면 추세 반전이 발생할 수 있습니다.\n\n```js\ndef calcRsi(series, period):\n    \"\"\"\n    데이터 시리즈의 RSI 계산\n    \n    Parameters\n    ----------\n    series : 판다스 시리즈\n        캔들스틱 데이터셋\n    period : int\n        각 계산의 기간\n        \n    Returns\n    -------\n    rsi : float\n        계산된 rsi값\n    \"\"\"\n    try:\n        delta = series.diff().dropna()\n        u = delta * 0\n        d = u.copy()\n        u[delta \u003e 0] = delta[delta \u003e 0]\n        d[delta \u003c 0] = -delta[delta \u003c 0]\n        u[u.index[period-1]] = np.mean( u[:period] ) # 첫 번째 값은 평균 이익의 합\n        u = u.drop(u.index[:(period-1)])\n        d[d.index[period-1]] = np.mean( d[:period] ) # 첫 번째 값은 평균 손실의 합\n        d = d.drop(d.index[:(period-1)])\n```\n\n```js\n        rs = u.ewm(com=period-1, adjust=False).mean() \\\n            / d.ewm(com=period-1, adjust=False).mean()\n        \n        rsi = 100 - 100 / (1 + rs)\n    except IndexError:\n        rsi = 0\n        \n    return rsi\ncolumn_value='Close'\ncolumn_index='Date'\ndata['RSI'] = calcRsi(data[column_value], 14)\n#RSI\nfig, ax = plt.subplots(figsize=(15,12))\nax.plot(data.index, data['RSI'])\nax.plot(data.index, data[column_value]/data[column_value][0]*100.0)\nax.axhline(y=70,color='r')\nax.axhline(y=30,color='r')\nplt.text(s='매수 과다', x=data.index[0], y=70, fontsize=14)\nplt.text(s='매도 과다', x=data.index[0], y=30, fontsize=14)\nplt.legend()\n#p = plt.setp(ax.xaxis.get_majorticklabels(), rotation=90, fontsize=8)\nxmin, xmax = ax.get_xlim()\nax.set_xticks(np.linspace(xmin, xmax, 6))\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_17.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 상대강도지수(Relative Strength Index, RSI)를 계산하는 calcRsi 함수를 정의하고 주식 시장 데이터를 포함하는 데이터 집합에 이 함수를 적용합니다. RSI는 상승장이나 하락장인지 판단하는 데 사용되는 인기 있는 기술적 지표입니다. RSI를 계산한 후 코드는 RSI와 주식의 정규화된 종가를 시각화하는 플롯을 생성합니다.\n\n여기 코드의 상세한 설명입니다:\n\n- calcRsi 함수는 두 개의 인자, 즉 가격 데이터를 포함하는 팬더 Series인 series와 RSI 계산에 사용되는 기간을 나타내는 period를 사용합니다.\n- calcRsi 함수 내부에서 가격 시리즈의 첫 번째 차이를 계산하고 delta 변수에 저장합니다. 이는 한 기간에서 다음 기간까지의 가격 변동을 나타냅니다.\n- u와 d라는 두 개의 새로운 Series가 생성됩니다. 이는 양수 가격 변동과 음수 가격 변동을 각각 나타냅니다. 양수 가격 변동은 u에 저장되고 음수 가격 변동(음수으로 곱한 값)은 d에 저장됩니다.\n- 초기 기간의 평균 이익과 손실이 u와 d Series에 저장됩니다.\n- u와 d의 지수 이동 평균(EMA)이 지정된 감쇠 계수를 사용하여 ewm 메서드를 통해 계산됩니다. 감쇠 계수는 초기 값인 u와 d의 평균 값을 고려하도록 기간 - 1로 설정되고 adjust=False로 설정됩니다.\n- 상대강도(RS)는 u의 EMA를 d의 EMA로 나누어 계산됩니다. RSI는 그 후 100 - 100 / (1 + RS)로 계산됩니다.\n- RSI는 데이터 DataFrame에 새 열로 추가됩니다.\n- plt.subplots()를 사용하여 새로운 그림과 축이 생성됩니다. RSI와 정규화된 종가(0에서 100 범위로 스케일링)가 동일한 그래프에 플로팅됩니다.\n- y축 값 70과 30에 오버보트(과매수)와 오버솔드(과매도) 임계값을 나타내는 수평선이 추가됩니다. 이러한 임계값을 표시하는 텍스트 레이블이 추가됩니다.\n- x축 눈금을 동일하게 간격으로 설정하려면 np.linspace()를 사용합니다.\n- 마지막으로 plt.show()를 사용하여 그래프가 표시됩니다.\n\n이 코드는 주식의 RSI와 정규화된 종가를 동일한 그래프에 시각화함으로써 거래자가 상승장 및 하락장에 대한 주식의 가격 변동을 해당 RSI 값과의 관련성에 대해 분석하여 정보를 얻을 수 있도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 볼린저 밴드\n\n볼린저 밴드는 가능한 추세 반전을 나타내는 데 사용됩니다. 추세선이 상단 밴드 또는 하단 밴드 중 하나를 통과하면 반전이 발생할 수 있다는 것을 의미합니다.\n\n```js\ndef addBollinger(df, period=20, col='Close'):\n    \"\"\"\n    데이터 프레임에 간단한 이동 평균 열 추가\n```\n\n```js\n    Parameters\n    ----------\n    df : 판다 데이터프레임\n        캔들스틱 데이터셋\n    period : 정수\n        각 계산의 기간\n    Returns\n    -------\n    없음\n    \"\"\"\n    bbmid_series = df[col].rolling(window=period).mean()\n    series_stdev = df[col].rolling(window=period).std()\n    df['BBUpperBand'] = bbmid_series + 2*series_stdev\n    df['BBLowerBand'] = bbmid_series - 2*series_stdev\n    df['BBBandwidth'] = df['BBUpperBand'] - df['BBLowerBand']  \n    df['BBMiddleBand'] = bbmid_series\n    \n    return df\n\ndata = addBollinger(data)\ncolumn_value='Close'\ncolumn_index='Date'\n#볼린저 밴드\nfig, ax = plt.subplots(figsize=(15,12))\nax.plot(data.index, data[column_value], label='Close')\nax.plot(data.index, data['BBUpperBand'], c='orange', label='Upper Band')\nax.plot(data.index, data['BBLowerBand'], c='orange', label='Lower Band')\nax.plot(data.index, data['BBMiddleBand'], c='black', label='Middle Band')\nplt.legend()\n#p = plt.setp(ax.xaxis.get_majorticklabels(), rotation=90, fontsize=8)\nxmin, xmax = ax.get_xlim()\nax.set_xticks(np.linspace(xmin, xmax, 6))\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_18.png\" /\u003e\n\n이 코드는 Bollinger Bands를 계산하고 제공된 주식 시장 데이터를 포함하는 팬더스 DataFrame에 추가하는 addBollinger 함수를 정의합니다. Bollinger Bands는 거래에서 가격 변동성을 측정하고 잠재적으로 매수 과잉 또는 매도 과잉 상태를 식별하는 데 사용되는 기술적분석 도구입니다. Bollinger Bands를 계산한 후에 코드는 종가 및 상한, 중간, 하한 Bollinger Bands를 시각화하는 플롯을 생성합니다.\n\n다음은 코드의 상세한 설명입니다:\n\n- addBollinger 함수는 세 가지 인수를 사용합니다: 주식 시장 데이터가 포함된 팬더스 DataFrame인 df; Bollinger Bands 계산에 사용되는 기간인 period; 그리고 가격 데이터를 포함하는 열인 col (기본값은 `Close`로 설정됨).\n- addBollinger 함수 내에서 지정된 기간 동안의 가격 데이터의 단순 이동 평균(SMA)이 rolling 및 mean 메서드를 사용하여 계산되고 변수 bbmid_series에 저장됩니다.\n- 지정된 기간 동안의 가격 데이터의 표준 편차가 rolling 및 std 메서드를 사용하여 계산되고 series_stdev 변수에 저장됩니다.\n- 상하한 Bollinger Bands는 중간 밴드(SMA)에 표준 편차를 두 배 더하거나 빼서 계산됩니다. 이러한 값들은 데이터 DataFrame에 새 열 ‘BBUpperBand’ 및 ‘BBLowerBand’로 추가됩니다.\n- 상하한 밴드 간의 차이인 Bollinger Bands 대역폭이 계산되어 데이터 DataFrame에 새 열 ‘BBBandwidth’로 추가됩니다.\n- 중간 밴드 (SMA)도 데이터 DataFrame에 새 열 'BBMiddleBand'로 추가됩니다.\n- 이제 Bollinger Bands를 포함하는 수정된 DataFrame이 반환됩니다.\n- addBollinger 함수가 데이터 DataFrame에 Bollinger Bands를 추가하도록 호출됩니다.\n- plt.subplots()를 사용하여 새로운 figure 및 axis가 작성됩니다. 종가, 상한 Bollinger Band, 하한 Bollinger Band, 그리고 중간 Bollinger Band가 동일한 그래프에 플로팅됩니다.\n- 플롯을 구분하기 위해 범례가 추가됩니다.\n- np.linspace()를 사용하여 x-축 틱을 균일 간격으로 설정합니다.\n- 마지막으로 plt.show()를 사용하여 플롯을 표시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 Bollinger Bands를 시각화하여 종가를 함께 표시함으로써 주식의 가격 움직임을 Bollinger Bands와 비교 분석하여 신중한 거래 결정을 내릴 수 있는 방법을 제공합니다.\n\n# 이동평균 수렴 발산\n\nMACD는 현재 트렌드에서 시장이 힘을 잃고 있다는 것을 알려주는 다른 모멘텀 지표로, 시그널 선과 MACD 선이 교차하는 지점에서 주로 트렌드 반전이 예상됩니다.\n\n```js\ndef addMACD(df, column_value='Close'):\n    ema_fast = df[column_value].ewm(span=12).mean()\n    ema_slow = df[column_value].ewm(span=26).mean()\n    signal_line = df[column_value].ewm(span=9).mean()\n    df['ema_fast'] = ema_fast\n    df['ema_slow'] = ema_slow\n    df['macd'] = ema_fast - ema_slow\n    df['macd_signal'] = df.macd.ewm(span=9, adjust=False).mean()\n    df['macdh'] = df['macd'] - df['macd_signal']\n    return df\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndata = addMACD(data)\nfig, ax = plt.subplots(figsize=(15,12))\nax.plot(data.index, data['ema_fast'], c='orange', label='빠른 EMA')\nax.plot(data.index, data['ema_slow'], c='blue', label='느린 EMA')\nplt.legend()\np = plt.setp(ax.xaxis.get_majorticklabels(), rotation=90, fontsize=8)\nplt.show()\nfig, ax = plt.subplots(figsize=(15,12))\nax.plot(data.index, data['macd'], c='green')\n# ax.bar(, height=)\nax.plot(data.index, data['macd_signal'], c='blue')\nax.axhline(y=0,color='black')\nax.fill_between(data.index, data['macdh'], color = 'gray', alpha=0.5, label='MACD 히스토그램')\n#ax.set_xticklabels(data.index.reindex(ax.get_xticks()))\nplt.legend()\np = plt.setp(ax.xaxis.get_majorticklabels(), rotation=90, fontsize=8)\nplt.show()\n```\n\n이 코드는 MACD(Moving Average Convergence Divergence) 및 관련 지표를 계산하는 addMACD 함수를 정의합니다. 이 함수는 주식 시장 데이터를 포함한 pandas DataFrame에 대해 사용됩니다. MACD는 트레이더들이 잠재적인 추세 반전, 매수/매도 과열 상태, 거래 진입 또는 종료 지점을 식별하는 데 사용되는 인기 있는 모멘텀 기반 기술적 분석 도구입니다. 이 코드는 빠른/느린 지수 이동 평균(EMA) 및 MACD 라인, 시그널 라인, MACD 히스토그램을 시각화하는 두 개의 플롯을 생성합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드에 대한 자세한 설명입니다:\n\n- addMACD 함수는 DataFrame df와 계산에 사용될 가격 데이터를 나타내는 선택적인 column_value 인수(기본값은 `Close`)를 가져옵니다.\n- 12기간과 26기간의 지수이동평균(EMA)은 ewm 및 mean 메소드를 사용하여 계산되어 각각 ema_fast 및 ema_slow 변수에 저장됩니다.\n- 9기간 EMA인 시그널 라인은 계산되어 signal_line 변수에 저장됩니다.\n- 계산된 빠른 및 느린 EMAs는 데이터 DataFrame에 'ema_fast'와 'ema_slow'라는 새 열로 추가됩니다.\n- MACD 라인은 빠른 및 느린 EMAs 간의 차이로 계산되어 데이터 DataFrame에 'macd'라는 새 열로 추가됩니다.\n- MACD 시그널 라인은 MACD 라인의 9기간 EMA로 계산되고 데이터 DataFrame에 'macd_signal'이라는 새 열로 추가됩니다.\n- MACD 히스토그램(MACDH)은 MACD 라인과 MACD 시그널 라인 간의 차이로 계산되어 데이터 DataFrame에 'macdh'라는 새 열로 추가됩니다.\n- 이제 MACD 및 관련 지표를 포함하는 수정된 DataFrame이 반환됩니다.\n- addMACD 함수를 사용하여 데이터 DataFrame에 MACD와 관련 지표를 추가합니다.\n- 첫 번째 플롯은 빠른(12기간) 및 느린(26기간) EMAs를 나타냅니다. x축 레이블은 90도로 회전되고 글꼴 크기는 8로 설정됩니다.\n- 두 번째 플롯은 MACD 라인, MACD 시그널 라인 및 MACD 히스토그램을 나타냅니다. MACD 라인은 초록색으로, 시그널 라인은 파란색으로 플롯됩니다. 또한 ax.axhline(y=0, color=`black`)를 사용하여 제로 라인도 플롯됩니다.\n- MACD 히스토그램은 fill_between 메소드를 사용하여 MACD 라인과 시그널 라인 사이의 채워진 영역으로 시각화됩니다. x축 레이블은 90도로 회전되고 글꼴 크기는 8로 설정됩니다.\n- 마지막으로, plt.show()를 사용하여 두 플롯을 모두 표시합니다.\n\n이 코드는 MACD 및 관련 지표를 시각화하는 방법을 제공하여 트레이더가 주식의 가격 움직임을 MACD 지표와 관련하여 분석하여 정보에 기반한 거래 결정을 내릴 수 있도록 합니다.\n\n```js\n# 짧은 창과 긴 창 초기화\nshort_window = 40\nlong_window = 100\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\n# `signals` DataFrame을 `signal` 열과 함께 초기화합니다\nsignals = pd.DataFrame(index=data.index)\nsignals['signal'] = 0.0\n# 짧은 기간의 이동평균을 만듭니다\nsignals['short_mavg'] = data['Close'].rolling(window=short_window, min_periods=1, center=False).mean()\n# 긴 기간의 이동평균을 만듭니다\nsignals['long_mavg'] = data['Close'].rolling(window=long_window, min_periods=1, center=False).mean()\n# 트레이딩 신호 생성\nsignals['signal'][short_window:] = np.where(signals['short_mavg'][short_window:] \n                                            \u003e signals['long_mavg'][short_window:], 1.0, 0.0)  \n# 트레이딩 주문 생성\nsignals['positions'] = signals['signal'].diff()\n```\n\n이 코드는 데이터 DataFrame의 주식 데이터를 사용하여 간단한 이동평균 교차 트레이딩 전략을 만드는 내용입니다. 코드는 주어진 짧은 기간과 긴 기간을 사용하여 계산된 이동평균값과 이를 기반으로 하는 트레이딩 신호를 저장할 `signals` DataFrame을 초기화하고, 이를 기반으로 트레이딩 주문을 생성합니다.\n\n다음은 각 단계에 대한 설명입니다:\n\n- 짧은 기간과 긴 기간의 창 크기는 각각 40과 100으로 설정됩니다.\n- 데이터 DataFrame과 동일한 인덱스를 가지는 새 DataFrame인 `signals`가 만들어지며, `signal` 열이 0.0으로 초기화됩니다.\n- 'Close' 가격 데이터에 대해 짧은 이동평균(SMA)을 `short_window` (40) 크기의 창을 사용하여 계산합니다. 계산된 SMA는 `signals` DataFrame의 새 열인 `short_mavg`에 저장됩니다.\n- 'Close' 가격 데이터에 대해 긴 이동평균(SMA)을 `long_window` (100) 크기의 창을 사용하여 계산합니다. 계산된 SMA는 `signals` DataFrame의 새 열인 `long_mavg`에 저장됩니다.\n- 짧은 이동평균이 긴 이동평균보다 큰 경우, 40번째 데이터 이후부터 각 데이터 포인트에 대해 트레이딩 신호가 생성됩니다. 짧은 이평선이 더 길면 신호는 1.0 (매수 신호)로 설정되고, 그렇지 않으면 0.0 (수행 없음)으로 설정됩니다.\n- 연속하는 트레이딩 신호 간의 차이를 계산하여 트레이딩 주문을 생성합니다. 생성된 주문은 `signals` DataFrame의 새 열 'positions'에 저장됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 기본 이동평균 크로스오버 거래 전략을 설정합니다. 짧은 이동평균이 긴 이동평균 위에 있을 때 전략은 \"매수\" 신호를 생성합니다. 짧은 이동평균이 긴 이동평균 아래에 있을 때는 어떠한 조치도 취하지 않습니다. signals DataFrame의 'positions' 열을 검토함으로써 거래 전략이 주식에 대한 포지션 진입 또는 청산을 제안하는 지점을 결정할 수 있습니다.\n\n```js\nfig = plt.figure(figsize=(10, 8))\n```\n\n```js\n# 부분 그래프와 y-축 레이블 추가\nax1 = fig.add_subplot(111, ylabel='달러 가격')\n# 종가 플로팅\ndata['Close'].plot(ax=ax1, color='회색', lw=2.)\n# 짧은 이동평균과 긴 이동평균 플로팅\nsignals[['short_mavg', 'long_mavg']].plot(ax=ax1, lw=2.)\n# 매수 신호 플로팅\nax1.plot(signals.loc[signals.positions == 1.0].index, \n         signals.short_mavg[signals.positions == 1.0],\n         '^', markersize=10, color='자홍')\n         \n# 매도 신호 플로팅\nax1.plot(signals.loc[signals.positions == -1.0].index, \n         signals.short_mavg[signals.positions == -1.0],\n         'v', markersize=10, color='검정')\n         \n# 그래프 표시\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_21.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 이전에 생성한 signals DataFrame을 사용하여 이동평균 교차 거래 전략과 전략에서 생성된 매수/매도 신호를 시각화하는 플롯을 생성합니다.\n\n다음은 코드가 하는 일입니다:\n\n- plt.figure()를 사용하여 크기가 (10, 8)인 새로운 그림을 생성합니다.\n- fig.add_subplot()을 사용하여 y-축 레이블을 'Price in $'로 하는 서브플롯을 그림에 추가합니다. 서브플롯은 ax1 변수에 할당됩니다.\n- 데이터 DataFrame의 종가를 회색으로 그림과 두께가 2인 선으로 ax1에 플로팅합니다.\n- signals DataFrame에서 장기 이동평균(short) 와 단기 이동평균(long)을 두께가 2인 선으로 동일한 서브플롯(ax1)에 플로팅합니다.\n- positions이 1.0인 signals DataFrame의 데이터 포인트를 선택하여 매수 신호를 ax1에 플로팅합니다. 이러한 포인트는 크기가 10이고 자홍색(magenta)인 업워드 삼각형(^)으로 표시됩니다.\n- positions이 -1.0인 signals DataFrame의 데이터 포인트를 선택하여 매도 신호를 ax1에 플로팅합니다. 이러한 포인트는 크기가 10이고 검정색(black)인 다운워드 삼각형(v)으로 표시됩니다.\n- plt.show()를 사용하여 플롯을 표시합니다.\n\n결과 플롯은 주가의 종가와 단기 및 장기 이동평균, 그리고 이동평균 교차 전략에서 생성된 매수 및 매도 신호를 시각화합니다. 이를 통해 전략의 성능을 더 잘 이해하고 주식 포지션 진입 또는 청산 지점을 식별하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 초기 자본 설정\ninitial_capital = 100 * data['Close'][0] #float(0.0)\n```\n\n```js\n# DataFrame `positions` 생성\npositions = pd.DataFrame(index=signals.index).fillna(0.0)\n# 100주를 사기\npositions['AAPL'] = 100 * signals['signal']\n\n# 보유한 가치로 포트폴리오 초기화\nportfolio = positions.multiply(data['Close'], axis=0)\n# 소유 주식 수의 차이 저장\npos_diff = positions.diff()\n# `holdings`를 포트폴리오에 추가\nportfolio['holdings'] = (positions.multiply(data['Close'], axis=0)).sum(axis=1)\n# `cash`를 포트폴리오에 추가\nportfolio['cash'] = initial_capital - (pos_diff.multiply(data['Close'], axis=0)).sum(axis=1).cumsum()\n# `total`을 포트폴리오에 추가\nportfolio['total'] = portfolio['cash'] + portfolio['holdings']\n# `returns`를 포트폴리오에 추가\nportfolio['returns'] = portfolio['total'].pct_change()\nfig = plt.figure(figsize=(10, 8))\nax1 = fig.add_subplot(111, ylabel='포트폴리오 가치($)')\n# 달러로 된 자산 곡선 그리기\nportfolio['total'].plot(ax=ax1, lw=2.)\n# `buy` 거래를 자산 곡선에 그리기\nax1.plot(portfolio.loc[signals.positions == 1.0].index, \n         portfolio.total[signals.positions == 1.0],\n         '^', markersize=10, color='m')\n# `sell` 거래를 자산 곡선에 그리기\nax1.plot(portfolio.loc[signals.positions == -1.0].index, \n         portfolio.total[signals.positions == -1.0],\n         'v', markersize=10, color='k')\n# 그래프 보이기\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_22.png\" /\u003e\n\n해당 코드는 이동평균 교차 전략에서 생성된 거래 신호를 사용하여 시간 경과에 따른 포트폴리오 가치를 계산하고 자산 곡선과 매수/매도 신호를 시각화합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 코드는 다음을 수행합니다:\n\n- 초기 자본을 주식의 첫 번째 종가의 100배로 설정합니다.\n- 동일한 인덱스를 가진 positions DataFrame이 생성되고 0으로 채워집니다.\n- positions DataFrame에서 'AAPL' 열을 업데이트하여 거래 신호를 100주로 곱합니다.\n- 포지션과 주식의 종가를 요소별로 곱하여 포트폴리오 DataFrame을 초기화합니다.\n- 연속된 시간 간격 사이의 소유 주식의 차이를 계산하고 pos_diff DataFrame에 저장합니다.\n- 포트폴리오 DataFrame에 총 보유 주식 가치를 나타내는 'holdings' 열을 추가합니다.\n- 포트폴리오 DataFrame에 주식을 매수/매도한 후의 사용 가능 현금을 나타내는 'cash' 열을 추가합니다.\n- 포트폴리오 DataFrame에 각 시간 단계에서 총 포트폴리오 가치(cash + holdings)를 나타내는 'total' 열을 추가합니다.\n- 포트폴리오 DataFrame에 이전 시간 단계에서의 총 포트폴리오 가치의 백분율 변경을 나타내는 'returns' 열을 추가합니다.\n\n나머지 코드는 자산 곡선(총 포트폴리오 가치)과 매수/매도 신호를 시각화합니다:\n\n- plt.figure()를 사용하여 크기가 (10, 8)인 새로운 그림을 생성합니다.\n- 'Portfolio value in $'로 y축에 레이블이 지정된 서브플롯이 생성되고 ax1 변수에 할당됩니다.\n- 포트폴리오 DataFrame에서 총 포트폴리오 가치를 2의 선 두께로 ax1에 플롯합니다.\n- positions이 1.0인 데이터 포인트를 선택하여 signals DataFrame에서 ax1에 매수 신호를 표시합니다. 이 지점은 크기가 10이고 자홍색(magenta)인 위로 향하는 삼각형(^)으로 표시됩니다.\n- positions이 -1.0인 데이터 포인트를 선택하여 signals DataFrame에서 ax1에 매도 신호를 표시합니다. 이 지점은 크기가 10이고 검은색(k)인 아래로 향하는 삼각형(v)으로 표시됩니다.\n- plt.show()를 사용하여 플롯을 표시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n플롯 결과는 포트폴리오의 자본 곡선을 시간에 따라 시각화하며, 이동 평균 교차 전략에 의해 생성된 매수 및 매도 신호를 함께 보여줍니다. 이는 전략의 성능과 포트폴리오 가치에 미치는 영향을 더 잘 이해하는 데 도움이 됩니다.\n\n```js\nenv = Environment(data)\nenv.reset()\nongoing_profits = []\nfor i in range(1,len(signals['positions']-1)):\n    a = signals['positions'][i]\n    if a == -1:\n        a = 2\n    elif a == float('NaN'):\n        a = 0\n    obs, reward, done, profit = env.step(a)\n    ongoing_profits.append(profit)\n    \nplt.figure(figsize=(23,8))\nplt.plot(data.index,((data['Close']-data['Close'][0])/data['Close'][-1]), label='buy and hold')\nplt.plot(data.index, ([0] + ongoing_profits)/data['Close'][-1], label='crossing strategy')\nplt.ylabel('relative gain')\nplt.legend()\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_23.png\" /\u003e\n\n이 코드는 이동 평균 교차 전략의 성능을 시뮬레이션하고 지속적인 이익을 계산하며, 단순한 매수 및 보유 전략과 비교하여 상대 이익을 플롯합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드는 다음과 같은 작업을 수행합니다:\n\n- Environment 클래스의 인스턴스를 생성하여 주식 데이터를 입력값으로 사용합니다.\n- reset() 메서드를 사용하여 환경을 재설정합니다.\n- 진행 중인 이익을 저장하기 위해 빈 리스트인 ongoing_profits를 초기화합니다.\n- 코드는 signals[`positions`] 시리즈를 두 번째 요소부터 뒤에서 두 번째 요소까지 반복합니다.\n- signals[`positions`] 시리즈의 각 요소에 대해 값에 따라 action 변수 a를 업데이트합니다:\n\n  - a가 -1이면 a를 2로 설정합니다.\n  - a가 NaN이면 a를 0으로 설정합니다.\n\n- step() 메서드를 사용하여 작업 a로 환경을 업데이트하고, 새 관측값, 보상, 환경이 종료되었는지 여부(done), 이익을 반환합니다.\n- 이익을 ongoing_profits 리스트에 추가합니다.\n- plt.figure()를 사용하여 크기가 (23, 8)인 새 그림을 생성합니다.\n- 매수 및 보유 전략의 상대적 이득을 나타내는 데이터를 플롯합니다. 이는 종가 차이를 마지막 종가로 나눈 비율입니다.\n- 교차 전략의 상대적 이득을 플롯합니다. 이는 마지막 종가로의 이익 비율입니다.\n- y축을 ‘상대적 이득’이라고 레이블을 지정합니다.\n- 플롯에 범례를 추가합니다.\n- plt.show()를 사용하여 플롯을 표시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과 플롯은 이동평균 교차 전략의 성능을 간단한 매수 보유 전략과 비교한 것을 보여줍니다. 이를 통해 이동평균 교차 전략의 효과를 이해하고 수동 투자 접근법과 비교할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_0.png"},"coverImage":"/assets/img/2024-06-19-ForecastingStockUsingDeepReinforcementLearning_0.png","tag":["Tech"],"readingTime":62},{"title":"다중 헤드 어텐션  공식적으로 설명하고 정의하기","description":"","date":"2024-06-19 19:01","slug":"2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined","content":"\n\n![이미지](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_0.png)\n\n다중 헤드 어텐션은 자연어 처리를 혁신적으로 바꾼 트랜스포머에서 중요한 역할을 합니다. 이 메커니즘을 이해하는 것은 현재 최첨단 언어 모델의 명확한 그림을 그리는 데 필수적인 단계입니다.\n\n몇 년 전에 소개되었고 그 후 널리 사용되고 논의되었음에도 불구하고 모호한 표기법과 형식적인 정의의 부족으로 인해 새로운 이들이 빠르게 다중 헤드 어텐션 메커니즘을 해소할 수 없었습니다.\n\n이 기사에서는 다중 헤드 어텐션의 포관적이고 모호하지 않은 형식화를 제시하여 이 메커니즘을 쉽게 이해할 수 있도록하는 것이 목표입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새로운 개념을 더 잘 이해하기 위해서는 스스로 사용하는 것이 중요합니다. 이 기사에는 다중 헤드 어텐션에 대해 정확히 이해하기 위한 여러 연습 문제/질문과 해결책이 함께 제시됩니다.\n\n참고: 다중 헤드 어텐션의 정의와 설명을 시작하기 전에, 라텍스 지원 부족으로 수식을 이미지로 변환하여 수학적 객체를 표시했습니다.\n\n## 입력\n\n먼저, 다중 헤드 어텐션 메커니즘의 입력이 무엇인지 명확히 합시다. 우리는 다중 헤드 어텐션 레이어의 입력을 다음과 같이 정의합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이곳이 있어요! \n\nX는 n개의 행과 d개의 열로 이루어진 행렬이에요. 그 두 차원은 다음과 같이 대응되어요:\n\n- n: 입력 시퀀스의 길이 (토큰 수)\n- d: 토큰 벡터의 차원.\n\n## 시퀀스 길이\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적으로 모든 시퀀스에 대해 기본 고정 길이 n을 설정합니다. 일반적으로 \"Attention Is All You Need\" (Vaswani et al., 2017에서 사용된 값과 같은) 256 또는 512와 같은 값이 사용됩니다. 그런 다음, 모든 입력 시퀀스는 정확히 n개의 토큰을 가지도록 패딩되거나 자르게됩니다.\n\n이것은 시퀀스의 단어 수로 볼 수 있습니다.\n\n따라서 X의 각 행은 입력 시퀀스의 토큰에 해당합니다.\n\n## 토큰 차원\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n텍스트를 토큰화하면 각각의 토큰이 특성 벡터로 표현된 시퀀스로 변환됩니다.\n\n토큰 벡터의 가장 간단한 예시는 원핫 인코딩입니다. 예를 들어, 1,000개의 가능한 토큰 세트가 있다면, 각 토큰은 1,000차원의 이진 벡터로 모델링될 수 있습니다. 여기서 각 토큰은 0으로 설정된 999개의 구성 요소와 주어진 토큰에 연결된 구성 요소에 1로 설정된 1개를 가지게 됩니다. 여기서 d는 1,000입니다.\n\n따라서 입력 시퀀스의 n개의 각 토큰은 X의 행으로 표시되며 d개의 열이 있습니다.\n\n## 연습문제 1 — 입력 시퀀스 모델링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래의 가정에 따라 문장 \"attention is all you need\"을 모델링하고자 합니다:\n\n- 입력 시퀀스의 고정된 길이는 n = 8입니다.\n- 모델링될 수 있는 토큰의 집합 T = '“all”, “attention”, “cat”, “is”, “need”, “transformer”, “you”'입니다.\n- 토큰 벡터는 가능한 토큰 집합 T를 기반으로 한 원핫 인코딩 표현입니다.\n- \"End-of-Sequence\" 토큰과 같은 특수 토큰은 고려하지 않습니다. (만약 이 가정을 이해하지 못한다면, 괜찮습니다.)\n\nQ1: 여기서 토큰 벡터의 차원 d는 무엇인가요?\n\nQ2: 방금 전에 한 가정에 따라 \"attention is all you need\"의 입력 행렬 X를 제시해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 요약\n\n## 해결책 — 연습 문제 1\n\nQ1: 여기서 가능한 토큰 집합 T에는 일곱 개의 토큰이 있고, 토큰을 원핫 인코딩으로 모델링한다고 가정했습니다. 따라서 d = 7 (T에있는 토큰 수).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nQ2: 먼저, n = 8이고 d = 7인 것을 알았기 때문에, 여덟 개의 행과 일곱 개의 열을 가진 행렬 X를 얻어야 한다는 것을 알 수 있습니다.\n\n각 행은 입력 문장의 토큰에 대응해야 합니다. 그러나 알 수 있듯이, “attention is all you need”에는 다섯 개의 토큰만 포함되어 있습니다. 행렬 X에 여덟 개의 행을 어떻게 채울 수 있을까요?\n\n한 가지 옵션은 입력 시퀀스를 빈 토큰으로 채우는 것입니다. 이렇게 하면 X의 맨 아래에 세 개의 빈 행이 생기게 됩니다.\n\n참고: 또 다른 접근 방식은 빈 토큰을 가능한 토큰 집합에 포함하는 것입니다. 즉, T = '“all”, “attention”, “cat”, “is”, need”, “transformer”, “you”, ∅'와 같이 ∅가 빈 토큰을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_2.png\" /\u003e\n\n이제 한-hot 벡터를 올바르게 작성하여 X를 완료했습니다. 최종적으로 다음 행렬이 나와야 합니다:\n\n\u003cimg src=\"/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_3.png\" /\u003e\n\n# Query, Key, Value\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"다중 헤드 어텐션”에서는 “다중 헤드”가 있습니다. 이는 이러한 메커니즘을 사용하는 레이어가 여러 개의 헤드를 사용한다는 것을 의미합니다.\n\n만일 “헤드”라는 용어가 이해되지 않는다면, 이를 “매핑”이나 “레이어”로 생각하실 수 있습니다.\n\nh를 다중 헤드 어텐션 레이어에서 사용될 어텐션 헤드의 수로 정의해봅시다.\n\n이제 쿼리(질의), 키(검색어), 값에 대해 정의해보겠습니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_4.png)\n\n서로 다른 이름을 가지고 있지만, 쿼리, 키, 값은 본질적으로 동일한 정의를 가지고 있습니다: 입력 행렬과 가중치 행렬의 곱입니다.\n\n여기서 k와 v가 양의 정수일 때, 가중치 행렬은 다음 행렬 공간에 있습니다:\n\n![image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_5.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가중 행렬은 h 개의 헤드 간에 다릅니다. 따라서 아래 첨자는 i이며, i는 1에서 h까지 범위입니다.\n\n쿼리, 키 및 값 사이에는 가중 행렬이 다르므로 \"Q\", \"K\" 및 \"V\"의 지수가 있어서 이들을 구별합니다.\n\n논문 \"Attention Is All You Need\" (Vaswani et al., 2017)에서는 일반적으로 k 및 v가 k = v = d / h로 설정됩니다.\n\n## 문제 2 — 쿼리, 키 및 값\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n쿼리 Q의 차원은 무엇인가요? 키 K의 차원은 무엇인가요? 값 V의 차원은 무엇인가요?\n\n(아래 \"요약\" 이후에 솔루션 있음.)\n\n## 요약\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 해결책 — 연습문제 2\n\n행렬 곱셈을 주의 깊게 읽은 후, 쿼리, 키, 밸류 행렬의 다음 차원을 얻어야 합니다:\n\n![Matrix Dimensions](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_6.png)\n\n# 어텐션\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주의는 다음 매핑으로 정의될 수 있습니다:\n\n![매핑](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_7.png)\n\n여기서 softmax 함수가 행을 따라 실행됩니다:\n\n![softmax](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알림으로써, 소프트맥스 함수는 벡터의 값을 정규화하는 방법입니다. 이 함수를 사용하면 합이 1이 되도록 벡터를 변환하여 소프트맥스의 출력이 확률 분포를 나타낼 수 있게 합니다.\n\n## Exercise 3 — 어텐션과 행렬의 차원\n\n다음 행렬들의 차원은 무엇인가요?\n\n![행렬 이미지](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Exercise 4 — 주의 집중 해석\n\n다음 구절을 해당 수식과 일치시키세요. 주어진 구절은 이전에 소개된 적은 없지만, 수학적 표현을 해석함으로써 여기서 추측할 수 있습니다.\n\n이미지 태그를 Markdown 형식으로 변경하세요.\n\n## Exercise 5 — 행렬 해석\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nQ1: 주어진 쿼리 Q에 대해,\n\n- Q의 한 행은 무엇을 나타내나요?\n- Q의 한 열은 무엇을 나타내나요?\n\n(동일한 해석은 키 K 및 값 V에 대해서도 가능합니다.)\n\nQ2: 주어진 쿼리 Q와 주어진 키 K, 행 i, 열 j에 대해, 아래와 같은 계수가 나타내는 것은 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_11.png)\n\nQ3: 특정 쿼리 Q와 주어진 키 K에 대해 다음 매트릭스의 한 행을 어떻게 해석할 수 있나요?\n\n![Image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_12.png)\n\n(아래 \"Recap\" 이후에 해답이 있습니다.)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 요약\n\n![image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_13.png)\n\n## 해결책 — 연습 문제 3\n\n아래 행렬들에 대한 차원을 순차적으로 얻습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_14.png)\n\n## Solution — Exercise 4\n\n![Image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_15.png)\n\nThe (scaled) attention scores are the dot products between the projections of the input tokens both in the query space and the key space. They provide a raw score of “how much each input token attends to each input token”.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 균도 가중치는 이전에 언급한 주의 점수에서 확률 분포를 만듭니다.\n\n스케일링 닷-프로덕트 주의는 값 공간에서 주의 가중치와 입력 투영을 기반으로 입력 시퀀스의 새로운 잠재 표현을 제공합니다.\n\n## 해결책 — 연습 문제 5\n\n질문 1: 쿼리 Q가 쿼리 공간에서 입력 X의 투영이며, Q의 치수에 기초하여 추론할 수 있는 내용은 무엇입니까?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Q의 한 행은 질의 공간에서 표현된 입력 토큰 벡터를 나타냅니다.\n- Q의 한 열은 질의 공간의 잠재적 차원을 나타냅니다.\n\nQ2: Q와 K의 전치(Transpose)의 곱셈에서 i번째 행과 j번째 열의 계수는 입력 시퀀스의 i번째 토큰이 j번째 토큰과 얼마나 관련되어 있는지를 나타냅니다.\n\n이 계수가 높을수록, i번째 토큰과 j번째 토큰이 더 연관되어(~유사하게) 있습니다.\n\nQ3: 먼저, 어텐션 가중치 행렬의 각 행에 대한 합이 1과 같아집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 행렬의 i행은 입력 시퀀스 토큰이 시퀀스 의미에 기여하는 정도를 모델링한 확률 분포로 해석할 수 있습니다. 토큰 i를 살펴보는 경우 시퀀스 의미에 어떤 기여를 하는지를 나타냅니다.\n\n# 다중 헤드 어텐션\n\n이제, 다중 헤드 어텐션 메커니즘에서 각 헤드들은 어떻게 작용할까요?\n\n## 연결\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n서로 다른 헤드의 출력은 행을 따라 연결되고 출력 가중치 행렬과 곱해집니다:\n\n![image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_16.png)\n\n다시 말해, 이것은 기술적인 내용이 아니며, 가장 어려운 부분은 여러 행렬의 차원을 명심하는 것입니다.\n\n## Exercise 6 — Multi-head dimensions\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 행렬의 차원은 무엇입니까?\n\n![image](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_17.png)\n\n## Exercise 7 — 결과 해석\n\n여러 헤드 어텐션은 처음에 기계 번역에 적용되어 영어와 독일어 간의 문장을 번역했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n입력 X와 출력 Y = MultiHead(X)의 차원을 주석으로 남겨주세요.\n\n## 연습 8 — 왜 여러 개?\n\n왜 여러 개의 어텐션 헤드가 필요할까요? 특히, 서로 다른 헤드가 어디에서 상호 작용하는지 확인할 수 있나요?\n\n(아래의 \"요약\" 이후 답안이 제시됩니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 요약\n\n## 해결책 — 연습문제 6\n\n다중 헤드 어텐션에 개입하는 이 행렬들의 차원은 다음과 같습니다:\n\n![이미지](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_18.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 해결 방법 — 연습문제 7\n\n입력 X의 차원과 출력 Y = MultiHead(X)의 차원이 일치하는 것을 알아채셨을 것입니다. 둘 다 n x d입니다.\n\n따라서, 다중 헤드 어텐션의 출력은 입력의 재구성으로 해석될 수 있거나, 적어도 동일한 고정 길이의 다른 시퀀스로 해석될 수 있습니다.\n\n다중 헤드 어텐션이 머신 번역을 위해 처음에 소개되었기 때문에, 출력은 다음과 같이 해석할 수 있습니다: 영어로 모델링된 입력 시퀀스에 대한 입력이 주어지면, 다중 헤드 어텐션 레이어는 독일어(또는 다른 어떤 언어든)로의 입력 시퀀스 번역을 모델링하는 행렬 Y를 출력합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 해결책 — 연습문제 8\n\n먼저, 여러 다른 헤드를 사용하는 아이디어는 토큰 간에 다른 관계에 대해 여러 헤드가 참석하도록하는 것입니다.\n\n실제로, 다양한 헤드들은 다중 헤드 어텐션의 매우 끝에서 함께 상호작용합니다:\n\n![다중 헤드 어텐션](/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_19.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 토큰에 대해 모든 헤드의 출력 값을 합산합니다. 이는 서로 다른 헤드가 상호 작용하는 곳입니다.\n\n# 결론\n\n종합하면, 다중 헤드 어텐션은 입력 시퀀스 X를 출력 시퀀스 Y로 변환하기 위해 두 가지를 활용하는 구성 요소로 이루어져 있습니다:\n\n- 어텐션 메커니즘\n- 여러 어텐션 헤드의 연결\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 메커니즘을 올바르게 이해하기 위해서는 계산 중 사용된 모든 행렬의 차원을 명확히 확인하는 것이 가장 중요합니다.","ogImage":{"url":"/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_0.png"},"coverImage":"/assets/img/2024-06-19-Multi-HeadAttentionFormallyExplainedandDefined_0.png","tag":["Tech"],"readingTime":9},{"title":"N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법","description":"","date":"2024-06-19 18:57","slug":"2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient","content":"\n\n\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png\" /\u003e\n\n2020년에 N-BEATS는 시계열 예측에서 통계적 및 혼합 모델보다 뛰어난 성과를 보인 첫 딥러닝 모델이었습니다.\n\n그 후 2년 뒤인 2022년에 새로운 모델이 N-BEATS를 제쳐놓았습니다. Challu와 Olivares 등이 딥 러닝 모델 N-HiTS를 발표했습니다. 이들은 N-BEATS의 긴 예측 지표에 대한 두 가지 단점을 해결했습니다:\n\n- 정확도의 감소 및\n- 계산량의 증가.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS는 시계열 예측을 위한 Neural Hierarchical Interpolation의 약자입니다.\n\n이 모델은 N-BEATS 및 그 신경 기반 확장 아이디어에 기반을 두고 있습니다. 신경 기반 확장은 계층화된 스택을 통해 여러 블록에서 이루어집니다.\n\n이 글에서는 N-HiTS 뒤에 숨겨진 구조, 특히 N-BEATS와의 차이에 대해 살펴볼 것입니다. 하지만 너무 걱정하지 마세요, 깊이 파고들기가 이해하기 쉬울 거에요. 하지만 N-HiTS 작동 방식을 이해하는 것만으로 충분하지 않습니다. 따라서 Python에서 어떻게 N-HiTS 모델을 쉽게 구현하고 하이퍼파라미터를 튜닝할 수 있는지 보여드릴 거에요.\n\n# 핵심 아이디어가 같다면, N-BEATS와 N-HiTS의 차이는 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 모델이 각 스택의 입력과 출력을 처리하는 방식에 차이가 있습니다. N-HiTS의 주요 아이디어는 서로 다른 시간 스케일의 예측을 결합하는 것입니다.\n\n이를 위해 N-HiTS는\n\n- 입력의 다중 속도 데이터 샘플링 및\n- 출력의 계층적 보간\n\n을 적용합니다.\n\n이 방법으로 N-HiTS는 더 긴 시계열에 대해 더 나은 정확도와 낮은 계산 비용을 달성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다중 비율 데이터 샘플링은 스택이 단기 또는 장기적 영향에 특화되도록 만듭니다. 이러한 스택이 각각의 구성 요소를 학습하기 쉬워집니다. 장기적 행동에 중점을 둔 것은 N-BEATS에 비해 향상된 장기적 시계열 예측을 이끌어냅니다.\n\n계층적 보간은 각 블록이 서로 다른 시간 단위로 예측하도록 허용합니다. 그런 다음 모델은 각 블록의 시간 단위에 맞게 예측을 보간하여 최종 예측과 일치시킵니다. 재샘플링과 보간은 학습 가능한 매개변수의 수를 줄입니다. 이는 훈련 시간이 더 짧고 가벼운 모델로 이어집니다.\n\n이제 N-HiTS가 어떤 점에서 다르게 작동하는지 알았으니, 이러한 변화가 아키텍처에 어떻게 포함되어 있는지 살펴보겠습니다.\n\n# N-HiTS는 자세히 어떻게 작동하나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS 모델은 다음과 같은 아키텍처를 가지고 있어요:\n\n![N-HiTS 모델](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_1.png)\n\n우리가 볼 수 있듯이, N-BEATS와 많은 유사성을 가지고 있어요.\n\n첫째, N-HiTS는 시계열을 lookback 및 forecast 기간으로 분리해요. 둘째, 해당 모델은 다층 스택과 블록으로 구성되어 있어요, backcast와 forecast를 생성해요. 각 블록에서 다층 퍼셉트론은 backcast와 forecast를 위한 기저 확장 계수를 생성해요. backcast는 블록이 포착한 시계열의 일부를 보여줘요. 우리는 이전 블록의 backcast를 제거하고 시계열을 블록에 전달하기 전에요. 이를 통해 각 블록은 서로 다른 패턴을 학습하게 되어요, 블록 간에 잔차만 전달하기 때문이에요. 해당 모델은 모든 블록의 forecast를 합하여 최종 예측을 생성해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n유사한 부분에 대해서는 이 정도로 설명을 유지하겠습니다. 더 자세한 정보는 제 N-BEATS 글을 참조하시기 바랍니다.\n\n하지만 차이점에 대해서는 더 깊이 파헤쳐 보겠습니다: 다중 속도 데이터 샘플링과 계층적 보간.\n\n## 입력의 다중 속도 신호 샘플링\n\nN-HiTS는 MaxPool 레이어를 통해 블록 수준에서 다중 속도 샘플링을 수행합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMaxPool 레이어는 선택된 커널 크기 내에서 가장 큰 값을 취함으로써 입력을 평활화합니다. 따라서 커널 크기가 샘플링 속도를 결정합니다. 커널 크기가 클수록 평활화가 더 강해집니다.\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_2.png)\n\nMaxPool 레이어의 커널 크기는 스택 레벨에서 정의합니다. 따라서 동일한 스택 내의 각 블록은 동일한 커널 크기를 갖습니다.\n\nN-HiTS는 리샘플링을 위해 위에서 아래로 접근하는 방식을 사용합니다. 첫 번째 스택은 큰 커널 크기를 통해 장기적인 효과에 초점을 맞춥니다. 후속 스택은 작은 커널 크기를 통해 단기적인 효과에 초점을 맞춥니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 출력의 계층 적 보간\n\nN-HiTS는 각 스택의 예측 수, 즉 기수를 줄이기 위해 계층 적 보간을 사용합니다. 더 작은 기수는 장기 예측을 위한 계산 요구 사항을 줄여줍니다.\n\n이게 무슨 말인가요?\n\n시계열의 다음 24시간을 예측하려고 한다고 가정해 봅시다. 우리는 우리 모델이 24개의 예측을 출력할 것을 기대합니다(각 시간당 하나). 시간당 데이터의 다음 두 주를 예측하려면 336개의 예측이 필요합니다(14 * 24). 그게 맞죠?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이것이 문제가 되는 곳입니다. N-BEATS 모델을 예를 들어봅시다. 최종 예측은 각 스택의 부분 예측을 결합한 것입니다. 따라서 각 스택은 336개의 값을 예측해야 하며, 이는 계산 비용이 많이 듭니다. N-BEATS는 더 긴 예측 범위에서 같은 문제를 겪는 모델 중 하나에 불과합니다. 다른 딥러닝 접근 방식인 트랜스포머나 순환 신경망과 같은 모델들도 같은 문제에 직면하게 됩니다.\n\nN-HiTS는 각 스택이 서로 다른 시간 스케일에서 예측하도록하여 이 도전을 극복합니다. N-HiTS는 각 스택의 시간 스케일을 내삽을 사용하여 최종 출력에 일치시킵니다.\n\n이를 위해 N-HiTS는 표현 간격 비율 개념을 사용합니다. 이 비율은 예측 기간 내의 예측 수를 결정합니다. 작은 표현 간격 비율은 스택이 더 적은 예측을 하도록 만듭니다. 따라서 스택의 기수가 작아집니다. 예를 들어, 1/2의 표현 간격 비율을 선택합니다. 이는 스택이 최종 예측에서 원하는 매 두 번째 값을 예측하게 만듭니다.\n\n표현 간격 비율은 출력을 입력의 재샘플링과 관련시킵니다. 입력의 재샘플링과 결합되어, 각 스택은 서로 다른 주파수에서 작동합니다. 따라서 각 스택은 서로 다른 속도로 시계열을 처리하는 데 전문화될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS의 저자들은 입력에 가까운 스택은 장기적 효과에 초점을 맞춰야 한다고 제안합니다. 따라서 이러한 스택은 표현 비율이 작아야 합니다. 예를 들어, 세 개의 스택을 가질 수 있습니다. 첫 번째 스택은 주간 행동에 특화되어 있고, 두 번째는 일일 행동에 특화되어 있으며, 세 번째는 시간당 행동에 특화되어 있습니다.\n\n![N-HiTS](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_3.png)\n\n하지만 표현 비율에 대한 합리적인 선택은 무엇인가요?\n\n그것은 시계열에 따라 다릅니다. 저자들은 두 가지 옵션을 권장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 다양한 주파수 범위를 다룰 때 매개변수의 수를 줄이기 위해 스택 간 지수적으로 증가하는 표현 비율을 사용합니다.\n- 일간, 주간 등의 시계열 주기를 활용합니다.\n\n# N-HiTS를 활용한 예측 예시\n\nN-HiTS가 어떻게 작동하는지 알게 되었으니, 모델을 예측 작업에 적용해 보겠습니다.\n\nN-BEATS 글에서와 마찬가지로, 우리는 독일의 도매 전기 가격을 다음 두 주 예측할 것입니다. 우리는 CC-BY-4.0 라이선스로 제공되는 \"유럽 도매 전기 가격\" 데이터를 사용할 것입니다. Nixtla의 neuralforecast 라이브러리에서 N-HiTS 구현을 사용할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_4.png)\n\n상세한 데이터 탐색을 하지 않아도 두 가지 계절성 구성 요소를 확인할 수 있습니다:\n\n- 일별: 전기 소비량이 이 시간대에 보통 높기 때문에 아침과 저녁 시간에 가격이 더 높습니다.\n- 주간별: 전기 소비량이 평일에 더 높기 때문에 주말보다 평일에 가격이 높습니다.\n\nN-BEATS 논문에서 동일한 데이터 집합을 사용했기 때문에 데이터 준비, 훈련-테스트 분할, 결과 시각화 및 기준 모델에 대한 모든 코드를 재사용할 수 있습니다. 따라서 이곳에 코드 조각을 표시하지 않겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드 작성에 들어가기 전에 가능한 정확한 예측을 얻으려는 것이 아니라 어떻게 N-HiTS를 적용할 수 있는지를 보여주는 것입니다.\n\n## 베이스라인 모델\n\n하지만, 베이스라인으로 간단한 모델부터 시작해 보겠습니다.\n\n이곳에서는 이전에 N-BEATS 기사에서 사용한 계절성이 있는 단순 모델을 사용할 것입니다. 따라서 자세한 내용은 다루지 않고 결과만 보여드리겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 세트의 마지막 주 데이터를 사용하여 예측하면 MAE가 17.84로 나옵니다. 이미 상당히 좋은 성적입니다.\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_5.png)\n\n## N-HiTS 모델 훈련\n\n첫 번째 N-HiTS 모델을 훈련해 봅시다. Nixtla의 neuralforecast 라이브러리를 사용하므로 구현은 간단합니다. 예측과 과거 기간을 정의하는 N-HiTS 모델을 초기화합니다. 이 경우, 과거 기간을 1주로 설정했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러면 몇 가지 사용자 정의 옵션이 있습니다.\n\n- 모델을 선택하여 스택 및 블록 수, MLP 레이어 크기, 활성화 함수, MaxPooling을 위한 커널 크기, 풀링 유형 등을 사용자 정의할 수 있습니다.\n- 손실 함수, 학습률, 배치 크기 등을 선택하여 학습을 사용자 정의할 수 있습니다.\n- 입력 데이터의 스케일링을 할 수 있습니다.\n\nNixtla의 문서 전체 설명을 보십시오.\n\nN-BEATS 모델과 대조적으로 몇 가지 차이점을 볼 수 있습니다. 우리는 모델을 사용자 정의하기 위해 더 많은 매개변수를 가지고 있습니다. 커널 크기 및 풀링 유형을 선택하여 다중 속도 데이터 샘플링을 사용자 정의할 수 있습니다. 계층적 보간은 보간 유형 및 표현성 비율을 통해 사용자 정의할 수 있습니다. 코드 스니펫에서 이미 일부 하이퍼파라미터를 조정해 보았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델을 초기화한 후에는 neuralforecast 클래스로 래핑하고 모델을 적합시킵니다. N-BEATS 기사를 읽으셨다면 이 단계에 익숙할 것입니다.\n\n결과는 기준선보다 더 좋아졌습니다. MAE는 17.84에서 17.01로 낮아졌습니다.\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_6.png)\n\n## N-HiTS 모델의 하이퍼파라미터 튜닝\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n좋은 하이퍼파라미터를 찾기 위해 시간을 쓰지 말고 최적화를 실행할 수 있어요.\n\n이것은 복잡하지 않아요. 많은 코드 줄을 추가할 필요가 없습니다. NHITS 모델을 Nixtla의 AutoNHITS 모델로 교체하기만 하면 돼요. AutoNHITS 모델이 하이퍼파라미터 튜닝을 대신 해줍니다. 우리는 백엔드(ray 또는 optuna)와 하이퍼파라미터의 탐색 범위를 선택하기만 하면 돼요.\n\n이 두 가지 선택은 NHITS 모델을 실행하는 것과 달리 유일한 차이점입니다. 다른 모든 단계는 동일합니다.\n\nOptuna를 선택하고 사용자 정의 구성 파일을 사용해 시작해봐요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"우리는 '최적화된' N-HiTS 모델이 베이스라인과 N-HiTS 모델에 비해 정확도가 더 낮다는 것을 알 수 있습니다 (MAE는 22.63입니다).\n\n![](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_7.png)\n\n아마도 저의 검색 공간 선택이 좋지 않았을 수도 있습니다. 따라서 더 많은 시도를 해보거나 더 나은 결과를 얻기 위해 다른 검색 공간을 사용할 수 있습니다. 또는 AutoNHITS의 기본 설정을 사용할 수도 있습니다. 모델에 구성을 전달하지 않고 바로 사용하거나 기본 설정을 약간 변경하여 사용할 수 있습니다.\n\n## 외생 변수가 포함된 N-HiTS\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사를 마치기 전에 마지막으로 보여드릴것이 있습니다. N-HiTS 모델에서 외생 변수를 사용할 수도 있습니다. 이를 위해 초기화 동안 futr_exog_list로 외생 변수를 NHITS 모델에 전달하기만 하면 됩니다. 예를 들어, 주간 계절성이 있는 경우 모델에 요일을 전달할 수 있습니다.\n\n요일을 외생 변수로 추가한 결과 MAE는 21.62가 나왔습니다. 다양한 외생 변수나 다양한 하이퍼파라미터를 시도하면 정확도를 향상시킬 수 있을 것입니다.\n\n![마지막에 관해](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_8.png)\n\n# N-HiTS에 대한 마지막 메모\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS는 논문에서 다양한 데이터 세트에서 매우 좋은 성능을 보였습니다. 그러나 이것은 모든 문제와 데이터 세트에 대해 N-HiTS가 최적의 해결책이 될 것을 의미하지는 않습니다. 특히 당신의 경우에는요.\n\n예시에서 보듯이, N-HiTS가 단순한 계절성 naive baseline 모델을 거의 이길 수 있었습니다. 하지만 그것에 도달하는 데 시간이 걸렸습니다. 먼저, 모델을 설정하고 좋은 하이퍼파라미터 세트를 찾는 데 더 많은 시간을 소비했습니다. 둘째, 훈련은 기준 모델보다 30배가 넘는 시간이 걸렸습니다.\n\n그래서 이것이 회사 프로젝트였다면, 나는 기준 모델을 선택했을 것입니다. 비록 N-HiTS가 약간의 정확도 향상을 제공하지만, 추가 복잡성은 고생할 가치가 없습니다.\n\n따라서, N-HiTS가 사용하기 쉽고 유망한 모델처럼 보여도, 해당 모델로 프로젝트를 시작하지 마십시오. 간단한 기준 모델로 시작하십시오. 기준을 토대로하여, N-HiTS가 문제에 대한 좋은 선택인지를 결정할 수 있습니다. 예를 들어, N-HiTS가 추가된 복잡성에 비해 얼마나 가치를 더하는지를 고려할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n이 기사는 매우 길었지만 다뤄야 할 내용이 많았습니다. 여기까지 함께 지켜주셨다면, 이제 다음 내용을 이해하실 수 있을 것입니다.\n\n- N-HiTS 모델이 어떻게 작동하는지에 대해 매우 좋은 이해를 갖게 되었을 것이고,\n- N-HiTS가 N-BEATS와 어떻게 다른지를 알게 되었을 것이며,\n- 실전에서 N-HiTS 모델을 사용할 수 있을 것이며,\n- 하이퍼파라미터 튜닝 중에 모델의 내부 동작을 변경할 수 있을 것입니다.\n\nN-HiTS 모델에 대해 더 깊이 알아보고 싶다면 N-HiTS 논문을 확인해보세요. 그렇지 않다면, 댓글을 남기거나 다음 기사에서 만나요!","ogImage":{"url":"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png"},"coverImage":"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png","tag":["Tech"],"readingTime":9},{"title":"시계열 분할 기술 정확한 모델 유효성 검증 보장하기","description":"","date":"2024-06-19 18:56","slug":"2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation","content":"\n\n시계열 데이터 작업 중이시군요. 멋지네요! 그러나 모델 훈련에 들어가기 전에 데이터를 나누는 방법에 대해 이야기해보죠. 시계열 데이터를 나눌 때는 날짜 순서를 유지하고 데이터 누수를 피하는 것이 중요합니다. 모델이 정확하고 신뢰할 수 있도록 유지하는 효과적인 시계열 분할 기술을 살펴봅시다.\n\n# 1. TimeSeriesSplit\n\n`TimeSeriesSplit`을 데이터 분할의 믿음직한 타임키퍼로 생각해보세요. 이는 데이터를 연속적인 폴드로 나누어, 각 훈련 세트가 과거 데이터에서 형성되고 각 테스트 세트가 미래 데이터에서 형성되도록 보장합니다.\n\n![Time Series Splitting Techniques Ensuring Accurate Model Validation](/assets/img/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom sklearn.model_selection import TimeSeriesSplit\ntscv = TimeSeriesSplit(n_splits=5)\nfor train_index, test_index in tscv.split(X):\n X_train, X_test = X[train_index], X[test_index]\n y_train, y_test = y[train_index], y[test_index}\n```\n\n# 2. Sliding/Rolling Window Split\n\nIn the rolling window approach, your model moves forward in time with a fixed-size training window that slides along your dataset. It’s like taking steps into the future while always keeping an eye on the past.\n\n![TimeSeriesSplittingTechniques](/assets/img/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation_1.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n파이썬 코드:\n\n```python\nfor date in pd.date_range('2021-01-01', '2021-12-31', freq='M'):\n    delta = date - pd.offsets.MonthBegin(1)\n    train = series.loc[delta:date-pd.offsets.Day(1)]\n    valid = series.loc[date:date+pd.offsets.MonthEnd(1)]\n```\n\n## 3. 확장 창 분할\n\n확장 창 분할을 사용하면 모델은 오래된 학습 세트로 시작하여 점차적으로 더 많은 관측 값을 포함하게 됩니다. 시간이 흐름에 따라 더 많은 데이터를 통합하여 지식을 축적하는 것과 같습니다.\n\n\n![시각](/assets/img/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation_2.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfor date in pd.date_range('2021-01-01', '2021-12-31', freq='M'):\n train = series.loc[:date-pd.offsets.Day(1)]\n valid = series.loc[date:date+pd.offsets.MonthEnd(1)]\n```\n\n# 4. Sliding Window with Gap Split\n\nThe sliding window with a gap introduces a buffer zone between your training and validation sets, ensuring no information from the future leaks into your model’s training. It’s like building a fence to keep your model focused on the present.\n\n![TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation](/assets/img/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfor date in pd.date_range('2021–01–01', '2021–12–31', freq='M'):\n delta = date - pd.offsets.MonthBegin(1)\n train = series.loc[delta:date-pd.offsets.Day(1)]\n valid = series.loc[date+pd.offsets.MonthEnd(1)+pd.offsets.Day(1):date+pd.offsets.MonthEnd(2)]\n```\n\n# 결론\n\n내 경험상, 시계열 데이터의 올바른 분할 기술을 선택하는 것은 견고하고 신뢰할 수 있는 모델을 구축하는 데 중요합니다. 개인적으로 증가하는 창 분할이 장기적인 추세를 포착하는 데 특히 효과적이라고 생각합니다. 이는 모델이 점차적으로 더 많은 데이터 포인트로부터 배울 수 있기 때문입니다. 그러나 계산 리소스를 관리하기 위해 고정 크기의 학습 세트를 유지하고 싶은 경우, 슬라이딩 창 접근 방식이 잘 작동합니다. 궁극적으로, 최적의 기술은 특정 사례와 데이터의 특성에 따라 다릅니다. 시계열 예측 요구 사항에 가장 적합한 방법을 찾기 위해 다양한 방법을 실험해보세요.\n\n# 참고 자료:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://robjhyndman.com/hyndsight/tscv/\nhttps://otexts.com/fpp3/tscv.html\nhttps://forecastegy.com/posts/time-series-cross-validation-python/","ogImage":{"url":"/assets/img/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation_0.png"},"coverImage":"/assets/img/2024-06-19-TimeSeriesSplittingTechniquesEnsuringAccurateModelValidation_0.png","tag":["Tech"],"readingTime":4},{"title":"죄를 사과하지 않는 일로 상처 받은 모든 것에 대해 치유되길 바라요","description":"","date":"2024-06-19 18:55","slug":"2024-06-19-ihopeyouhealfromthethingsthatnooneeverapologizedfor","content":"\n\n\n![image](/assets/img/2024-06-19-ihopeyouhealfromthethingsthatnooneeverapologizedfor_0.png)\n\n이런 경험 해 본 적 있나요? 앞으로 나아가고 상처를 극복하려는 마음을 느끼지만, 아직 미해결된 상처와 배신의 무게로 인해 막혀 있는 느낌이 들 때가 있지 않나요? 진짜 지칠 때가 있죠.\n\n\"당신을 깨뜨린 사람들의 발 밑에서 치유를 찾지 마세요\".\n\n우리 모두 인정합시다, 조용히 우리를 부순 모든 것으로부터 회복하는 게 힘들어요. 용서하기 어려워요. 부서진 후에 다시 완전해지는 게 어려워요. 다른 사람들이 당신을 쳐다보는 곳에서 숨쉬기 힘들어요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n왜 그들에게 상처 주는 말을 그렇게 쉽게 하는 걸까요? 그들이 그들이 하는 말을 알고 있는 걸까요? 아니면 나는 너무 많은 의미를 부여하고 있는 걸까요?\n\n나는 너희들을 절대 잊지 않을 거에요.\n\n매일 밤 울었던 모든 일들을 위해. 너에게 새겨진 모든 말들을 위해. 너를 상처 입힌 모든 흔적들을 위해. 너가 무시했던 것들을 위해. 모든 것이 조용히 너를 파괴했던 것들을 위해.\n\n너가 모든 것에서 치유되기를 바래요, 비록 그들 중 아무도 사과하지 않아도요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n너가 머릿속을 맴도는 많은 생각 속에서 평화롭게 자는 게 얼마나 어려운지 알아. \"괜찮아, 선택할 수 있는 게 없어\" 라고 스스로 위로하는 것이 얼마나 어려운지 알아. 조용히 울기가 얼마나 힘든지 알아. 자신의 울음소리를 듣는 것이 얼마나 아픈지 알아.\n\n그들을 용서하기를 바란다.\n\n그리고 또한,\n\n네 자신을 용서하기를 바란다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n치유에는 많은 시간이 걸리지만, 당신은 여기서 벗어날 수 있을 거에요. 산이 높아도 오를 수 있다는 걸 알아요. 바다가 깊어도 헤쳐나갈 수 있다는 걸 알아요.\n\n그들이 한 말이 마음을 찌르는 듯해도, 언제나 내가 여기 있다는 걸 기억해주길 바래요. 모든 고통을 없애주지는 못하지만, 나는 당신과 함께할 준비가 돼 있어요.\n\n당신과 마찬가지로, 나도 당신의 경험의 피해자에요.\n\n어떤 면에서 우리 모두는 이 경험들의 피해자에요. 우리는 어둠을 헤치며 길을 찾기 위해 같이 힘겨워하고 있어요. 함께 이겨내요.","ogImage":{"url":"/assets/img/2024-06-19-ihopeyouhealfromthethingsthatnooneeverapologizedfor_0.png"},"coverImage":"/assets/img/2024-06-19-ihopeyouhealfromthethingsthatnooneeverapologizedfor_0.png","tag":["Tech"],"readingTime":2},{"title":"장기 단기 메모리 LSTM  RNN 개선하기","description":"","date":"2024-06-19 18:53","slug":"2024-06-19-LongShortTermMemoryLSTMImprovingRNNs","content":"\n\n\n![그림](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_0.png)\n\n이 글에서는 Long-Short-Term Memory Networks (LSTM)에 대해 소개하겠습니다. 이는 일반적인 바닐라 순환 신경망(RNN)의 변형으로서 장기 의존성을 처리하는 데 능숙합니다.\n\n이들은 의사결정에 필요하거나 중요하지 않다고 판단되는 특정 정보를 기억하거나 잊는 서로 다른 \"게이트\"를 사용합니다.\n\nLSTM은 RNN의 최신 버전으로, 산업 내에서 폭넓게 사용되며 우리가 오늘날 보는 모든 멋진 대형 언어 모델 (LLMs)의 기반이 됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRNN 개요\n\nRecurrent Neural Networks(RNN)은 일반적인 피드포워드 신경망의 변형으로, 자연어나 시계열 데이터와 같은 순차 데이터를 더 잘 처리할 수 있도록 합니다.\n\n이는 이전 입력과 출력을 다음 레이어로 전달하는 숨겨진 순환 뉴런을 가지고 수행됩니다. 아래는 예시입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_1.png)\n\n네트워크를 통해 전달되는 벡터 h를 주목해보세요. 이것이 순환 신경망(RNNs) 뒤에 숨겨진 주요 기능인 은닉 상태입니다. 이것이 시퀀스 데이터에 대해 잘 작동하는 이유입니다.\n\n은닉 상태는 이전에 계산된 은닉 상태와 해당 시간 단계에서의 새 입력을 결합합니다. 그런 다음 해당 시간 단계의 최종 출력을 계산하기 위해 시그모이드 활성화 함수가 적용됩니다. 수학적으로 표현하면:\n\n![image](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_2.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래에서:\n\n- Y: 출력 벡터\n- X: 기능의 입력 벡터\n- h: 숨겨진 상태\n- V: 출력을 위한 가중 행렬\n- U: 입력을 위한 가중 행렬\n- W: 숨겨진 상태를 위한 가중 행렬\n\nV, U 및 W의 가중 행렬은 시간에 걸쳐 백프로파게이션을 통해 찾아집니다. 이는 백프로파게이션 알고리즘의 한 변형에 불과합니다.\n시각적으로는 이렇게 보입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_3.png)\n\nFor example, when predicting Y_1, the RNN would use the inputs of X_1 plus the output from the previous time step from Y_0. As Y_0 influences Y_1, we can then see that Y_0 will also indirectly influence Y_2, demonstrating the recurrent nature.\n\nIf you want a full intro to RNNs then check out my previous blog.\n\n# Vanishing \u0026 Exploding Problem\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRNN의 긍정적인 측면 중 하나는 각 계층이 U, W 및 V의 가중 행렬을 공유하지만, 정규 피드포워드 신경망은 각 계층마다 자체 가중 행렬을 갖는다는 것입니다. 이로 인해 RNN은 더 메모리를 효율적으로 사용할 수 있습니다.\n\n그러나 이 가중 행렬 공유는 그들의 중요한 결함 중 하나인 사라지는 그래디언트와 폭주하는 그래디언트 문제를 야기합니다.\n\nRNN은 backpropagation through time (BPTT)라는 backpropagation 알고리즘의 변형을 사용하여 학습합니다. 이 알고리즘은 일반적인 backpropagation과 유사하지만, 각 시간 단계에서 업데이트해야 하는 계층 간의 공유 가중 행렬로 인해 더 '중첩된' 계산이 필요합니다.\n\nBPTT의 일반적인 공식은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image 1](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_4.png)\n\nRNN에서 J는 임의의 가중치 행렬이며 U, W 또는 V일 수 있으며 E는 총 오차입니다.\n\nRNN은 일반적인 신경망보다 더 깊은 경향이 있습니다(각 시간 단계는 하나의 레이어입니다). 따라서 그래디언트가 1보다 작거나 큰 경우에는 역방향으로 전파될 때 그래디언트가 소멸되거나 폭발될 수 있습니다.\n\n![image 2](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_5.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n관심 있는 독자를 위해, 왜 이런 일이 발생하는지의 수학적인 전체 분석은 여기서 찾을 수 있어요. 이것은 고유값과 야코비안 행렬과 같은 재미있는 것들이 관련돼 있습니다!\n\n만약 역전파를 통한 시간 알고리즘 (BTTP)과 그라디언트가 사라지거나 폭발하는 문제의 전체적인 분석을 원한다면, 제 이전 게시물을 확인해보세요.\n\n사라지는 그라디언트와 폭발하는 그라디언트 문제를 잘 보여주는 좋은 예시는 Stanford의 CS224D 수업에서 제시되었습니다. 두 개의 문장을 생각해보세요:\n\n- \"제인이 방으로 들어갔어요. 존도 들어왔어요. 제인이 ___에게 안녕했어요.\"\n- \"제인이 방으로 들어갔어요. 존도 들어왔어요. 늦었고, 모두가 긴 하루 일과를 마치고 집으로 향했어요. 제인이 ___에게 안녕했어요.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어떤 경우에도 빈 공간은 아마도 존을 가리키는 것입니다. RNN은 이 맥락을 학습하여 두 문장 모두 출력이 존임을 이해해야 합니다.\n\n그러나 실험 결과, 문장 1이 문장 2보다 정확하게 예측되는 경향이 있었습니다. 이는 문장 2에서 그래디언트가 소멸되어 예측을 할 때 먼 맥락을 효율적으로 인식하지 못하기 때문입니다.\n\n이것은 분명히 문제입니다. RNN은 이와 같은 시나리오에 대한 \"기억\"을 갖도록 설계되었기 때문입니다.\n\n그래서, 이 문제에 대해 어떻게 해결할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 롱-숏텀 메모리\n\n## 개요\n\nLSTMs는 1997년 Hochreiter \u0026 Schmidhuber에 의해 소개되었으며, 그 기본 아이디어는 순환 셀 내부에 \"게이트\"가 있다는 것입니다. 이러한 게이트는 순환 셀이 장기 기억을 구축할 때 무엇을 기억하고 잊어야 하는지를 제어합니다.\n\n일반적인 RNN에서는 순환 셀이 다음과 같이 보입니다:\n\n\n|  Table  |  Tag   |\n|---------|--------|\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Long Short Term Memory - LSTM Improving RNNs](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_6.png)\n\nHowever, the LSTM cell is a lot more complicated:\n\n![LSTM Cell](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_7.png)\n\nI appreciate there is a lot going on here, but lets break it down step by step.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 셀 상태\n\n핵심적인 차이 중 하나는 셀 상태 C의 도입입니다. 이 셀 상태에는 컨텍스트 및 과거 패턴과 같이 기본적인 정보가 포함되어 있습니다. 바로 메모리입니다. 이 셀 상태는 셀을 통과하며 선형 상호 작용을 하는 여러 개의 게이트에 의해 조정될 수 있습니다.\n\n셀 상태와 은닉 상태를 혼동하기 쉽지만, 일반적으로 셀 상태는 네트워크의 전체 메모리를 포함하도록 설계되었으며, 은닉 상태는 단기 의존성을 위해 사용되고 실제로 최근 정보만을 가지고 있습니다. 또한 예측을 위해 셀의 출력에 사용됩니다.\n\n## 잊기 게이트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLSTM의 첫 번째 단계는 forget gate입니다. 이 게이트는 이전 셀 상태 C_'t-1'에서 어떤 이전 정보를 삭제할지 결정하는 역할을 합니다.\n\n![이미지](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_8.png)\n\n여기서:\n\n- σ: 시그모이드 활성화 함수.\n- W_f: forget gate의 가중치 행렬.\n- h_'t−1': 이전 시간 단계의 출력.\n- x_t: 시간 단계 t의 입력.\n- b_f: forget gate의 편향.\n- f_t: 0과 1 사이의 값을 가지는 forget gate 출력.\n- X_t: 현재 입력.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n출력 f_t는 이전 셀 상태 C_'t-1'에 곱해져 어떤 요소를 잊어야 하는지 수정합니다. 시그모이드 함수 덕분에 값은 0과 1 사이에 있으며, 0은 잊기를 의미하고 1은 기억에 추가됩니다.\n\nW_f 행렬에서 올바른 값을 찾아 역전파를 통해 이 정보를 학습합니다. 이를 통해 우리는 기억할지 잊을지를 결정할 수 있습니다.\n\n## 입력 게이트 및 후보 셀 상태\n\n입력 게이트 i_t는 다음 단계이지만 현재 시간 단계에서 셀 상태에 추가할 새로운 기억을 결정합니다. 후보 셀 상태 C*_t는 셀 상태에 추가할 가능한 모든 정보를 보유합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_9.png)\n\nWhere:\n\n- σ: 시그모이드 활성화 함수.\n- tanh⁡: 쌍곡 탄젠트 활성화 함수.\n- W_i: 입력 게이트용 가중치 행렬.\n- W_c: 후보 셀 상태용 가중치 행렬.\n- b_i: 입력 게이트용 편향\n- b_c: 후보 셀 상태용 편향.\n- C*_t: 후보 셀 상태, -1과 1 사이의 출력 값.\n- i_t: 0과 1 사이의 입력 게이트 출력.\n- h_'t-1': 이전 숨은 상태.\n- X_t: 현재 입력.\n\ntanh을 사용하면 셀 상태를 증가시키거나 감소시킬 수 있습니다. tanh는 출력을 -1과 1 사이로 압축하기 때문입니다. 시그모이드는 기억에 새로운 것을 추가하기 위해 이전 게이트와 유사한 이유로 사용됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n입력 게이트는 특히 이전 셀 상태C_'t-1'입니다.\n\n## 셀 상태 업데이트\n\n우리는 후보 셀 상태 C*_t 에서 새로운 셀 상태 C_t로 관련 정보만 추가하려고 합니다. 이를 위해 후보 셀 상태를 입력 게이트 i_t 와 곱하고 이를 잊어버린 게이트 f_t 와 이전 셀 상태 C_'t-1' 의 곱과 더할 수 있습니다.\n\n![image](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_10.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 작업은 좀 더 친숙한 느낌을 주려고 세포 상태를 갱신했습니다. 관련 없는 정보는 잊어버리고 필요한 새로운 정보를 추가했어요.\n\n## 출력 게이트\n\n마지막 단계는 셀에서 어떤 것을 예측으로 출력할지 결정하는 것이었지요. 먼저 출력 게이트 o_t를 계산하고, 이는 우리가 출력할 셀 상태의 어느 부분을 결정하는데 사용됩니다. 이는 기본적으로 일반 RNN의 일반적인 숨겨진 상태 반복 셀과 비슷한 역할을 해요.\n\n그 출력값은 새로운 셀 상태의 tanh 값과 곱해져서 원하는 값만을 출력합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_11.png)\n\nWhere:\n\n- σ: 시그모이드 함수.\n- tanh: 쌍곡선 탄젠트 활성화 함수.\n- W_o: 가중치 행렬.\n- b_o: 편향.\n- o_t: 출력 상태.\n- h_t: 새로운 은닉 상태.\n- h_'t-1': 이전 은닉 상태.\n- X_t: 현재 입력.\n- C_t: 새로운 셀 상태.\n\n그게 전부에요! 언급할 중요한 점은 모든 가중치 행렬이 BPTT를 사용하여 어떤 요소를 잊고 기억할지 학습해야 한다는 것입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 변형\n\n이것은 표준 LSTM일 뿐이고 다른 변형들이 있습니다. 그중 가장 흔한 것은 다음과 같습니다:\n\n- 양방향\n- 합성곱\n- 쌓인\n- 청구 접속\n- 게이트 순환 유닛\n\n이 글에서 이러한 모두를 다루는 것은 범위를 벗어나지만, 관심 있는 독자는 위에 제공된 링크에서 자세히 알아볼 수 있습니다. 다음 글에서는 게이트 순환 유닛에 대해 다룰 예정입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 요약 및 더 깊은 생각\n\nLSTMs는 처음에는 무서워 보일 수 있지만, 이 글을 통해 조금 더 친숙해졌으면 좋겠어요! 다양한 계산이 있지만, 이 모든 것들은 매우 유사합니다. 잊어버릴 것을 결정하는 forget gate와 기억에 추가할 새로운 정보를 결정하는 input gate 두 가지 기본 구성 요소가 있습니다. LSTMs의 장점은 이러한 gate들 덕분에 장기 기억력이 더 나은 것입니다.\n\n# 추가로!\n\n저는 '데이터 소스 공유', 매주 공유하는 더 나은 데이터 과학자가 되는 팁, 업계에서의 일반적인 경험, 지난 주에 한 생각들을 나누는 무료 뉴스레터를 운영하고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 나와 소통해요!\n\n- 링크드인, 트위터, 또는 인스타그램에서 연락해요.\n- 내 YouTube 채널에서는 기술적인 데이터 과학과 머신러닝 개념을 배우세요!\n\n# 참고 자료\n\n- LSTM에 대한 훌륭한 블로그 포스트\n- 스탠포드 RNN 체트시트\n- Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. Aurélien Géron. 2019년 9월. 출판사: O'Reilly Media, Inc. ISBN: 9781492032649.","ogImage":{"url":"/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_0.png"},"coverImage":"/assets/img/2024-06-19-LongShortTermMemoryLSTMImprovingRNNs_0.png","tag":["Tech"],"readingTime":8},{"title":"왜 나는 글쓰기를 그만두지 않을 것인지 이유","description":"","date":"2024-06-19 18:52","slug":"2024-06-19-ThisIsWhyIWillNotStopWriting","content":"\n\n과거 작품들을 훑어보면 낯선 사람처럼 느껴지기도 해요. 마치 박물관에서 유물을 뒤적이는 손님 같아요. 예전에 썼던 것들이 다시 유용하게 쓰일 때가 있어서 더욱 놀랍네요. 마치 필요성을 예견하고 미리 해결책을 준비한 것 같아요.\n\n가끔 써본 말들이 당시 느꼈던 감정을 상기하려고 노력해요. 때로는 성공도 해보지만, 때로는 그렇지 못할 때도 있어요. 때로는 한 마디로 당시의 감정과 머릿 속 상태를 정확히 떠올릴 수도 있고, 다른 때에는 여러 단어를 반복해도 당시의 감정과 연관을 찾지 못할 때도 있어요.\n\n![image](/assets/img/2024-06-19-ThisIsWhyIWillNotStopWriting_0.png)\n\n저는 강력히 믿어요. 우주는 현재의 관점을 통해 우리의 과거를 다시 방문하는 것 같아요. 그래서 어떤 경험이 새롭긴 하지만, 과거 어느 때와도 전혀 무관한 것은 아니에요. 감정은 마치 그릇처럼 앞뒤로 흔들리면서, 과거의 감정을 혀끝으로 맛 볼 수 있을 정도로 순간순간 변하기도 해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 난 글쓰기를 멈추지 않을 거야. 우주가 다른 이들을 위해 썼다는 핑계로 나에게 미래 편지를 쓰라고 요청하는 것처럼. 오늘 썼던 이 말들이 다음 10년 후에 도움이 될지도 몰라. 이것은 내 감정을 담는 창고이며, 반복되는 패턴을 발견했기 때문이다.","ogImage":{"url":"/assets/img/2024-06-19-ThisIsWhyIWillNotStopWriting_0.png"},"coverImage":"/assets/img/2024-06-19-ThisIsWhyIWillNotStopWriting_0.png","tag":["Tech"],"readingTime":1},{"title":"위성 이미지에서 GANs적대적 생성 신경망을 사용하여 구름 제거하기","description":"","date":"2024-06-19 18:49","slug":"2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks","content":"\n\n## 파이썬으로부터 GAN(Generative Adversarial Networks) 만들어 보기\n\n![이미지](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png)\n\nGAN(Generative Adversarial Networks)이라는 아이디어는 2014년 Goodfellow와 그 동료들에 의해 소개되었고, 곧 그 이후에 컴퓨터 비전 및 이미지 생성 분야에서 극도로 인기를 끌게 되었습니다. 인공지능 분야에서의 급속한 발전과 새로운 알고리즘의 수가 늘어나는 것을 고려하더라도, 이 개념의 단순함과 창의성은 여전히 매우 인상적입니다. 그래서 오늘은 이러한 네트워크가 얼마나 강력할 수 있는지를 보여주기 위해 위성 RGB(빨강, 녹색, 파랑) 이미지에서 구름을 제거하는 시도를 해보려고 합니다.\n\n적절히 균형 잡히고 충분히 크며 올바르게 전처리된 컴퓨터 비전 데이터셋을 준비하는 데에는 상당한 시간이 소요되므로, 저는 Kaggle에 어떤 것이 있는지 살펴보기로 결정했습니다. 이 작업에 가장 적합하다고 생각한 데이터셋은 EuroSat이며, 이는 오픈 라이선스를 가지고 있습니다. 이 데이터셋은 Sentinel-2에서 64x64 픽셀의 27000개의 레이블이 지정된 RGB 이미지로 구성되어 있고, 다중 클래스 분류 문제를 해결하기 위해 만들어졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_1.png)\n\n우리는 분류 자체에 흥미가 없지만 EuroSat 데이터셋의 주요 기능 중 하나는 모든 이미지에 맑은 하늘이 있습니다. 그것이 정확히 우리가 필요한 것입니다. [3]에서 이 접근법을 채택하여, 우리는 이 Sentinel-2 샷을 대상으로 사용하고 입력을 추가하여 (구름) 노이즈를 생성할 것입니다.\n\n그래서 우리가 GANs에 대해 실제로 이야기하기 전에 데이터를 준비해 봅시다. 우선, 데이터를 다운로드하고 모든 클래스를 하나의 디렉토리로 병합해야 합니다.\n\n🐍전체 Python 코드: GitHub.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom os import listdir, mkdir, rename\nfrom os.path import join, exists\nimport shutil\nimport datetime\n\nimport matplotlib.pyplot as plt\nfrom highlight_text import ax_text, fig_text\nfrom PIL import Image\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n```\n\n```js\nclasses = listdir('./EuroSat')\npath_target = './EuroSat/all_targets'\npath_input = './EuroSat/all_inputs'\n\n\"\"\"UNPACK한 아카이브 파일의 파일 이름을 변경하기 위해 단 한 번만 실행하세요\"\"\"\nmkdir(path_input)\nmkdir(path_target)\nk = 1\nfor kind in classes:\n  path = join('./EuroSat', str(kind))\n  for i, f in enumerate(listdir(path)):\n    shutil.copyfile(join(path, f),\n                  join(path_target, f))\n    rename(join(path_target, f), join(path_target, f'{k}.jpg'))\n    k += 1\n```\n\n중요한 두 번째 단계는 노이즈 생성입니다. 다양한 방법을 사용할 수 있지만, 예를 들어 일부 픽셀을 무작위로 마스킹하거나 가우시안 노이즈를 추가하는 등의 방법이 있습니다. 그러나 이 글에서는 저는 새로운 방식인 Perlin 노이즈를 시도해 보고 싶습니다. Perlin 노이즈는 80년대에 Ken Perlin이 영화 연기 효과를 개발할 때 발명했습니다. 이 종류의 노이즈는 일반적인 랜덤 노이즈에 비해 더 유기적인 외관을 가지고 있습니다. 저에게 이를 증명하는 기회를 주세요.\n\n```js\ndef generate_perlin_noise(width, height, scale, octaves, persistence, lacunarity):\n    noise = np.zeros((height, width))\n    for i in range(height):\n        for j in range(width):\n            noise[i][j] = pnoise2(i / scale,\n                                  j / scale,\n                                  octaves=octaves,\n                                  persistence=persistence,\n                                  lacunarity=lacunarity,\n                                  repeatx=width,\n                                  repeaty=height,\n                                  base=0)\n    return noise\n\ndef normalize_noise(noise):\n    min_val = noise.min()\n    max_val = noise.max()\n    return (noise - min_val) / (max_val - min_val)\n\ndef generate_clouds(width, height, base_scale, octaves, persistence, lacunarity):\n    clouds = np.zeros((height, width))\n    for octave in range(1, octaves + 1):\n        scale = base_scale / octave\n        layer = generate_perlin_noise(width, height, scale, 1, persistence, lacunarity)\n        clouds += layer * (persistence ** octave)\n\n    clouds = normalize_noise(clouds)\n    return clouds\n\ndef overlay_clouds(image, clouds, alpha=0.5):\n\n    clouds_rgb = np.stack([clouds] * 3, axis=-1)\n\n    image = image.astype(float) / 255.0\n    clouds_rgb = clouds_rgb.astype(float)\n\n    blended = image * (1 - alpha) + clouds_rgb * alpha\n\n    blended = (blended * 255).astype(np.uint8)\n    return blended\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n가로, 세로 = 64, 64\n옥타브 = 12  # 합쳐지는 잡음 레이어의 수\n지속성 = 0.5  # 낮은 지속성은 높은 주파수 옥타브의 진폭을 줄입니다.\n라쿠나리티 = 2  # 높은 라쿠나리티는 높은 주파수 옥타브의 주파수를 늘립니다.\nfor i in range(len(listdir(path_target))):\n  기본_스케일 = random.uniform(5, 120)  # 잡음 주파수\n  알파 = random.uniform(0, 1)  # 투명도\n\n  구름 = generate_clouds(가로, 세로, 기본_스케일, 옥타브, 지속성, 라쿠나리티)\n\n  이미지 = np.asarray(Image.open(join(path_target, f'{i+1}.jpg')))\n  이미지 = Image.fromarray(overlay_clouds(이미지, 구름, 알파))\n  이미지.save(join(path_input, f'{i+1}.jpg'))\n  print(f'{i+1}/{len(listdir(path_target))}번째 처리 완료')\n```\n\n```js\n인덱스 = np.random.randint(27000)\nfig, ax = plt.subplots(1,2)\nax[0].imshow(np.asarray(Image.open(join(path_target, f'{인덱스}.jpg')))\nax[1].imshow(np.asarray(Image.open(join(path_input, f'{인덱스}.jpg')))\nax[0].set_title(\"원본\")\nax[0].axis('off')\nax[1].set_title(\"입력\")\nax[1].axis('off')\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_2.png\" /\u003e\n\n위에서 볼 수 있듯이 이미지의 구름은 매우 현실적이며 다양한 \"밀도\"와 질감을 가지며 실제 구름과 유사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 저처럼 Perlin 소음에 흥미를 느낀다면, 게임 개발 산업에서 이 소음이 어떻게 적용될 수 있는지에 대한 정말 멋진 비디오가 있어요!\n\n이제 우리가 사용할 준비가 된 데이터셋이 있으니, GANs에 대해 이야기해 보겠습니다.\n\n# 생성적 적대 신경망\n\n이 아이디어를 더 잘 설명하기 위해, 동남아시아를 여행하다가 밖이 너무 춥다고 느낄 때 후디가 절실하게 필요하다고 상상해 보세요. 가장 가까운 거리 시장에 가보니, 몇 가지 브랜드 의류가 있는 작은 가게를 발견했어요. 판매자가 유명한 브랜드 ExpensiveButNotWorthIt의 후디를 시도해보라며 괜찮은 후디를 가져다줍니다. 더 자세히 살펴보고 분명히 가짜라고 결론 내리게 됩니다. 판매자가 말합니다: '잠시만요, 진짜 것이 있어요.' 그가 다른 후디를 가져오는데, 브랜드 제품과 더 닮았지만 여전히 가짜입니다. 이와 같은 반복 작업을 몇 번 거친 후, 판매자가 전설적인 ExpensiveButNotWorthIt의 구별이 어려운 사본을 가져와 여러분은 기꺼이 구매하게 됩니다. 이것이 바로 GANs가 작동하는 방식입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nGAN의 경우, 당신은 판별자(D)라고 불립니다. 판별자의 목표는 진짜 물체와 가짜 물체를 구별하거나 이진 분류 작업을 수행하는 것입니다. 이에 반해, 생성자(G)는 높은 품질의 가짜를 생성하려고 하는 판매자라고 불립니다. 판별자와 생성자는 서로 능가하기 위해 독립적으로 훈련됩니다. 따라서 최종적으로 우리는 높은 품질의 가짜를 얻습니다.\n\n![이미지](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_3.png)\n\n훈련 과정은 일반적으로 다음과 같이 진행됩니다:\n\n- 입력 노이즈를 샘플링합니다 (우리의 경우 구름이 있는 이미지).\n- 노이즈를 생성자(G)에 공급하고 예측을 수집합니다.\n- D 손실을 계산합니다. G의 출력에 대한 하나와 실제 데이터에 대한 다른 예측을 얻어서 이루어집니다.\n- D의 가중치를 업데이트합니다.\n- 다시 입력 노이즈를 샘플링합니다.\n- 노이즈를 생성자(G)에 공급하고 예측을 수집합니다.\n- G 손실을 계산합니다. G의 예측을 D에 공급하여 이루어집니다.\n- G의 가중치를 업데이트합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Erasing Clouds from Satellite Imagery Using GANs](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_4.png)\n\nIn other words, we can define a value function V(G,D):\n\n![Value function V(G,D)](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_5.png)\n\nwhere we want to minimize the term log(1-D(G(z))) to train G and maximize log D(x) to train D (in this notation x — real data sample and z — noise).\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 파이토치에서 구현해 봅시다!\n\n원본 논문에서 저자들은 Multilayer Perceptron (MLP)을 사용하는 것에 대해 언급합니다; 이것은 ANN으로 간단히도 불립니다만, 저는 미세한 접근을 시도하고 싶습니다 — Generator로 UNet [5] 아키텍처를 사용하고, Discriminator로는 ResNet [6]을 사용하고 싶습니다. 이들은 둘 다 잘 알려진 CNN 아키텍처이기 때문에 여기서 설명하지는 않겠습니다 (댓글에서 별도의 글을 쓸지 여부를 알려주세요).\n\n이제 구축해 봅시다. Discriminator:\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.utils.data import Subset\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n                        nn.BatchNorm2d(out_channels),\n                        nn.ReLU())\n        self.conv2 = nn.Sequential(\n                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n                        nn.BatchNorm2d(out_channels))\n        self.downsample = downsample\n        self.relu = nn.ReLU()\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.conv2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block=ResidualBlock, all_connections=[3,4,6,3]):\n        super(ResNet, self).__init__()\n        self.inputs = 16\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1),\n                        nn.BatchNorm2d(16),\n                        nn.ReLU()) #16x64x64\n        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2) #16x32x32\n\n\n        self.layer0 = self.makeLayer(block, 16, all_connections[0], stride = 1) #connections = 3, shape: 16x32x32\n        self.layer1 = self.makeLayer(block, 32, all_connections[1], stride = 2)#connections = 4, shape: 32x16x16\n        self.layer2 = self.makeLayer(block, 128, all_connections[2], stride = 2)#connections = 6, shape: 1281x8x8\n        self.layer3 = self.makeLayer(block, 256, all_connections[3], stride = 2)#connections = 3, shape: 256x4x4\n        self.avgpool = nn.AvgPool2d(4, stride=1)\n        self.fc = nn.Linear(256, 1)\n\n    def makeLayer(self, block, outputs, connections, stride=1):\n        downsample = None\n        if stride != 1 or self.inputs != outputs:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inputs, outputs, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(outputs),\n            )\n        layers = []\n        layers.append(block(self.inputs, outputs, stride, downsample))\n        self.inputs = outputs\n        for i in range(1, connections):\n            layers.append(block(self.inputs, outputs))\n\n        return nn.Sequential(*layers)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(-1, 256)\n        x = self.fc(x).flatten()\n        return F.sigmoid(x)\n```\n\nGenerator:\n\n```js\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self):\n      super().__init__()\n      self.conv_1 = DoubleConv(3, 32) # 32x64x64\n      self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32x32\n\n      self.conv_2 = DoubleConv(32, 64)  #64x32x32\n      self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2) #64x16x16\n\n      self.conv_3 = DoubleConv(64, 128)  #128x16x16\n      self.pool_3 = nn.MaxPool2d(kernel_size=2, stride=2) #128x8x8\n\n      self.conv_4 = DoubleConv(128, 256)  #256x8x8\n      self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2) #256x4x4\n\n      self.conv_5 = DoubleConv(256, 512)  #512x2x2\n\n      #DECODER\n      self.upconv_1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) #256x4x4\n      self.conv_6 = DoubleConv(512, 256) #256x4x4\n\n\n      self.upconv_2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) #128x8x8\n      self.conv_7 = DoubleConv(256, 128)  #128x8x8\n\n      self.upconv_3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2) #64x16x16\n      self.conv_8 = DoubleConv(128, 64)  #64x16x16\n\n      self.upconv_4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2) #32x32x32\n      self.conv_9 = DoubleConv(64, 32)  #32x32x32\n\n      self.output = nn.Conv2d(32, 3, kernel_size = 3, stride = 1, padding = 1) #3x64x64\n\n    def forward(self, batch):\n\n      conv_1_out = self.conv_1(batch)\n      conv_2_out = self.conv_2(self.pool_1(conv_1_out))\n      conv_3_out = self.conv_3(self.pool_2(conv_2_out))\n      conv_4_out = self.conv_4(self.pool_3(conv_3_out))\n      conv_5_out = self.conv_5(self.pool_4(conv_4_out))\n\n      conv_6_out = self.conv_6(torch.cat([self.upconv_1(conv_5_out), conv_4_out], dim=1))\n      conv_7_out = self.conv_7(torch.cat([self.upconv_2(conv_6_out), conv_3_out], dim=1))\n      conv_8_out = self.conv_8(torch.cat([self.upconv_3(conv_7_out), conv_2_out], dim=1))\n      conv_9_out = self.conv_9(torch.cat([self.upconv_4(conv_8_out), conv_1_out], dim=1))\n\n      output = self.output(conv_9_out)\n\n\n      return F.sigmoid(output)\n```\n\n이제 데이터를 훈련/테스트 세트로 분할하고 torch 데이터 세트로 래핑해야합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nclass dataset(Dataset):\n    def __init__(self, batch_size, images_paths, targets, img_size=64):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.images_paths = images_paths\n        self.targets = targets\n        self.len = len(self.images_paths) // batch_size\n\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n        ])\n\n        self.batch_im = [self.images_paths[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]\n        self.batch_t = [self.targets[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]\n\n    def __getitem__(self, idx):\n        pred = torch.stack([\n            self.transform(Image.open(join(path_input, file_name)))\n            for file_name in self.batch_im[idx]\n        ])\n        target = torch.stack([\n            self.transform(Image.open(join(path_target, file_name)))\n            for file_name in self.batch_im[idx]\n        ])\n        return pred, target\n\n    def __len__(self):\n        return self.len\n```\n\n멋져요. 이제 훈련 루프를 작성할 시간입니다. 그 전에 손실 함수와 옵티마이저를 정의해 봅시다:\n\n```python\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size = 64\nnum_epochs = 15\nlearning_rate_D = 1e-5\nlearning_rate_G = 1e-4\n\ndiscriminator = ResNet()\ngenerator = UNet()\n\nbce = nn.BCEWithLogitsLoss()\nl1loss = nn.L1Loss()\n\noptimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate_D)\noptimizer_G = optim.Adam(generator.parameters(), lr=learning_rate_G)\n\nscheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.1)\nscheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)\n```\n\n이전 GAN 알고리즘 그림의 손실 함수와는 다른 것을 볼 수 있습니다. 특히 L1 손실을 추가했습니다. 이 아이디어는 우리가 무작위로 이미지를 생성하는 것이 아니라 입력에서 대부분의 정보를 유지하고 노이즈만 제거하려고 한다는 것입니다. 따라서 G 손실은 다음과 같을 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nG_loss = log(1 − D(G(z))) + 𝝀 |G(z)-y|\n\ninstead of just\n\nG_loss = log(1 − D(G(z)))\n\n𝝀 is an arbitrary coefficient, which balances two components of the losses.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 데이터를 분할하여 훈련 과정을 시작해봅시다:\n\n```js\ntest_ratio, train_ratio = 0.3, 0.7\nnum_test = int(len(listdir(path_target)) * test_ratio)\nnum_train = int((int(len(listdir(path_target))) - num_test))\n\nimg_size = (64, 64)\n\nprint(\"훈련 샘플 수:\", num_train)\nprint(\"테스트 샘플 수:\", num_test)\n\nrandom.seed(231)\ntrain_idxs = np.array(random.sample(range(num_test + num_train), num_train))\nmask = np.ones(num_train + num_test, dtype=bool)\nmask[train_idxs] = False\n\nimages = {}\nfeatures = random.sample(listdir(path_input), num_test + num_train)\ntargets = random.sample(listdir(path_target), num_test + num_train)\n\nrandom.Random(231).shuffle(features)\nrandom.Random(231).shuffle(targets)\n\ntrain_input_img_paths = np.array(features)[train_idxs]\ntrain_target_img_path = np.array(targets)[train_idxs]\ntest_input_img_paths = np.array(features)[mask]\ntest_target_img_path = np.array(targets)[mask]\n\ntrain_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=train_input_img_paths, targets=train_target_img_path)\ntest_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=test_input_img_paths, targets=test_target_img_path)\n```\n\n이제 훈련 루프를 실행해봅시다:\n\n```js\ntrain_loss_G, train_loss_D, val_loss_G, val_loss_D = [], [], [], []\nall_loss_G, all_loss_D = [], []\nbest_generator_epoch_val_loss, best_discriminator_epoch_val_loss = -np.inf, -np.inf\nfor epoch in range(num_epochs):\n\n    discriminator.train()\n    generator.train()\n\n    discriminator_epoch_loss, generator_epoch_loss = 0, 0\n\n    for inputs, targets in train_loader:\n        inputs, true = inputs, targets\n\n        '''1. 판별자 (ResNet) 훈련하기'''\n        optimizer_D.zero_grad()\n\n        fake = generator(inputs).detach()\n\n        pred_fake = discriminator(fake).to(device)\n        loss_fake = bce(pred_fake, torch.zeros(batch_size, device=device))\n\n        pred_real = discriminator(true).to(device)\n        loss_real = bce(pred_real, torch.ones(batch_size, device=device))\n\n        loss_D = (loss_fake + loss_real) / 2\n\n        loss_D.backward()\n        optimizer_D.step()\n\n        discriminator_epoch_loss += loss_D.item()\n        all_loss_D.append(loss_D.item())\n\n        '''2. 생성자 (UNet) 훈련하기'''\n        optimizer_G.zero_grad()\n\n        fake = generator(inputs)\n        pred_fake = discriminator(fake).to(device)\n\n        loss_G_bce = bce(pred_fake, torch.ones_like(pred_fake, device=device))\n        loss_G_l1 = l1loss(fake, targets) * 100\n        loss_G = loss_G_bce + loss_G_l1\n        loss_G.backward()\n        optimizer_G.step()\n\n        generator_epoch_loss += loss_G.item()\n        all_loss_G.append(loss_G.item())\n\n    discriminator_epoch_loss /= len(train_loader)\n    generator_epoch_loss /= len(train_loader)\n    train_loss_D.append(discriminator_epoch_loss)\n    train_loss_G.append(generator_epoch_loss)\n\n    discriminator.eval()\n    generator.eval()\n\n    discriminator_epoch_val_loss, generator_epoch_val_loss = 0, 0\n\n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs, targets\n\n            fake = generator(inputs)\n            pred = discriminator(fake).to(device)\n\n            loss_G_bce = bce(fake, torch.ones_like(fake, device=device))\n            loss_G_l1 = l1loss(fake, targets) * 100\n            loss_G = loss_G_bce + loss_G_l1\n            loss_D = bce(pred.to(device), torch.zeros(batch_size, device=device))\n\n            discriminator_epoch_val_loss += loss_D.item()\n            generator_epoch_val_loss += loss_G.item()\n\n    discriminator_epoch_val_loss /= len(test_loader)\n    generator_epoch_val_loss /= len(test_loader)\n\n    val_loss_D.append(discriminator_epoch_val_loss)\n    val_loss_G.append(generator_epoch_val_loss)\n\n    print(f\"------에포크 [{epoch+1}/{num_epochs}]------\\n훈련 손실 D: {discriminator_epoch_loss:.4f}, 검증 손실 D: {discriminator_epoch_val_loss:.4f}\")\n    print(f'훈련 손실 G: {generator_epoch_loss:.4f}, 검증 손실 G: {generator_epoch_val_loss:.4f}')\n\n    if discriminator_epoch_val_loss \u003e best_discriminator_epoch_val_loss:\n        discriminator_epoch_val_loss = best_discriminator_epoch_val_loss\n        torch.save(discriminator.state_dict(), \"discriminator.pth\")\n    if generator_epoch_val_loss \u003e best_generator_epoch_val_loss:\n        generator_epoch_val_loss = best_generator_epoch_val_loss\n        torch.save(generator.state_dict(), \"generator.pth\")\n\n    fig, ax = plt.subplots(1,3)\n    ax[0].imshow(np.transpose(inputs.numpy()[7], (1,2,0)))\n    ax[1].imshow(np.transpose(targets.numpy()[7], (1,2,0)))\n    ax[2].imshow(np.transpose(fake.detach().numpy()[7], (1,2,0)))\n    plt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드가 끝나면 손실을 그래프로 그려볼 수 있어요. 이 코드는 이 멋진 웹사이트에서 일부 채택되었어요:\n\n```js\nfrom matplotlib.font_manager import FontProperties\n\nbackground_color = '#001219'\nfont = FontProperties(fname='LexendDeca-VariableFont_wght.ttf')\nfig, ax = plt.subplots(1, 2, figsize=(16, 9))\nfig.set_facecolor(background_color)\nax[0].set_facecolor(background_color)\nax[1].set_facecolor(background_color)\n\nax[0].plot(range(len(all_loss_G)), all_loss_G, color='#bc6c25', lw=0.5) \nax[1].plot(range(len(all_loss_D)), all_loss_D, color='#00b4d8', lw=0.5)\n\nax[0].scatter(\n      [np.array(all_loss_G).argmax(), np.array(all_loss_G).argmin()],\n      [np.array(all_loss_G).max(), np.array(all_loss_G).min()],\n      s=30, color='#bc6c25',\n   )\nax[1].scatter(\n      [np.array(all_loss_D).argmax(), np.array(all_loss_D).argmin()],\n      [np.array(all_loss_D).max(), np.array(all_loss_D).min()],\n      s=30, color='#00b4d8',\n   )\n\nax.text(\n      np.array(all_loss_G).argmax()+60, np.array(all_loss_G).max()+0.1,\n      f'{round(np.array(all_loss_G).max(),1)}',\n      fontsize=13, color='#bc6c25',\n      font=font,\n      ax=ax[0]\n   )\nax.text(\n      np.array(all_loss_G).argmin()+60, np.array(all_loss_G).min()-0.1,\n      f'{round(np.array(all_loss_G).min(),1)}',\n      fontsize=13, color='#bc6c25',\n      font=font,\n      ax=ax[0]\n   )\n\nax.text(\n      np.array(all_loss_D).argmax()+60, np.array(all_loss_D).max()+0.01,\n      f'{round(np.array(all_loss_D).max(),1)}',\n      fontsize=13, color='#00b4d8',\n      font=font,\n      ax=ax[1]\n   )\nax.text(\n      np.array(all_loss_D).argmin()+60, np.array(all_loss_D).min()-0.005,\n      f'{round(np.array(all_loss_D).min(),1)}',\n      fontsize=13, color='#00b4d8',\n      font=font,\n      ax=ax[1]\n   )\nfor i in range(2):\n    ax[i].tick_params(axis='x', colors='white')\n    ax[i].tick_params(axis='y', colors='white')\n    ax[i].spines['left'].set_color('white') \n    ax[i].spines['bottom'].set_color('white') \n    ax[i].set_xlabel('Epoch', color='white', fontproperties=font, fontsize=13)\n    ax[i].set_ylabel('Loss', color='white', fontproperties=font, fontsize=13)\n\nax[0].set_title('Generator', color='white', fontproperties=font, fontsize=18)\nax[1].set_title('Discriminator', color='white', fontproperties=font, fontsize=18)\nplt.savefig('Loss.jpg')\nplt.show()\n# ax[0].set_axis_off()\n# ax[1].set_axis_off()\n```\n\n또한 테스트 데이터셋에서 임의의 샘플을 시각화할게요:\n\n```js\nrandom.Random(2).shuffle(test_target_img_path)\nrandom.Random(2).shuffle(test_input_img_paths)\nsubset_loader = dataset(batch_size=5, img_size=img_size, images_paths=test_input_img_paths,\n                        targets=test_target_img_path)\ngenerator = UNet()\ngenerator.load_state_dict(torch.load('generator.pth'))\n\ngenerator.eval()\nfor X, y in subset_loader:\n    fig, axes = plt.subplots(5, 3, figsize=(9, 9))\n\n    for i in range(5):\n        axes[i, 0].imshow(np.transpose(X.numpy()[i], (1, 2, 0)))\n        axes[i, 0].set_title(\"Input\")\n        axes[i, 0].axis('off')\n        \n        axes[i, 1].imshow(np.transpose(y.numpy()[i], (1, 2, 0)))\n        axes[i, 1].set_title(\"Target\")\n        axes[i, 1].axis('off')\n        \n        generated_image = generator(X[i].unsqueeze(0)).detach().numpy()[0]\n        axes[i, 2].imshow(np.transpose(generated_image, (1, 2, 0)))\n        axes[i, 2].set_title(\"Generated\")\n        axes[i, 2].axis('off')\n    \n    # 레이아웃 조정\n    plt.tight_layout()\n    plt.savefig('Test.jpg')\n    plt.show()\n    break \n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_6.png\" /\u003e\n\n여기서 보시다시피, 결과는 완벽하지 않고 땅커버 유형에 매우 의존합니다. 그럼에도 불구하고, 구축된 모델은 이미지에서 구름을 제거하며, G 및 D 깊이를 늘리는 것으로 성능을 향상시킬 수 있습니다. 다른 유망한 전략은 서로 다른 땅커버 유형을 위해 별도의 모델을 훈련시키는 것입니다. 예를 들어, 작물밭과 물 투구는 분명히 다른 공간적 특징을 가지고 있기 때문에 일반화 모델의 능력에 영향을 주는 경우가 있습니다.\n\n이 기사가 지리정보 도메인에서 심층 학습 알고리즘을 적용하는 데 새로운 시각을 제공해 드렸기를 바랍니다. 내 생각에는, GANs는 데이터 과학자가 활용할 수 있는 가장 강력한 도구 중 하나이며, 여러분의 도구 상자의 필수적인 부분이 되길 희망합니다!\n\n===========================================\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참고문헌:\n\n1. Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville 및 Yoshua Bengio. “Generative adversarial nets.” Advances in neural information processing systems 27 (2014). [논문 링크](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)\n\n2. Helber, Patrick, Benjamin Bischke, Andreas Dengel 및 Damian Borth. “Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 12, no. 7 (2019): 2217–2226. [논문 링크](https://arxiv.org/pdf/1709.00029)\n\n3. Wen, Xue, Zongxu Pan, Yuxin Hu 및 Jiayin Liu. “Generative adversarial learning in YUV color space for thin cloud removal on satellite imagery.” Remote Sensing 13, no. 6 (2021): 1079. [논문 링크](https://www.mdpi.com/2072-4292/13/6/1079)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. “U-net: Convolutional networks for biomedical image segmentation.” In Medical image computing and computer-assisted intervention–MICCAI 2015: 18th international conference, Munich, Germany, October 5–9, 2015, proceedings, part III 18, pp. 234–241. Springer International Publishing, 2015. [Link](https://arxiv.org/pdf/1505.04597)\n\n6. He, Kaiming, et al. “Deep residual learning for image recognition.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [Link](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n\n===========================================\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제 Medium의 모든 게시물은 무료이며 공개되어 있습니다. 그래서 여기서 저를 팔로우해 주시면 정말 감사하겠습니다!\n\nP.s. 저는 (지리)데이터 과학, 머신 러닝/인공지능, 기후 변화에 대해 열정적으로 관심을 가지고 있습니다. 그래서 어떤 프로젝트에서 함께 작업하고 싶다면 LinkedIn에서 연락 주세요.\n\n🛰️더 많은 소식을 받아보려면 팔로우하세요!🛰️","ogImage":{"url":"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png"},"coverImage":"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png","tag":["Tech"],"readingTime":25}],"page":"25","totalPageCount":71,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"25"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>