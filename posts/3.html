<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/3" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/3" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="절대 초보자를 위한 신경망 직접 코딩 기초부터 구현까지" href="/post/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="절대 초보자를 위한 신경망 직접 코딩 기초부터 구현까지" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="절대 초보자를 위한 신경망 직접 코딩 기초부터 구현까지" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">절대 초보자를 위한 신경망 직접 코딩 기초부터 구현까지</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT에 대한 2024년 최신 진실" href="/post/2024-06-30-ChatGPTisBullshit"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT에 대한 2024년 최신 진실" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-ChatGPTisBullshit_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT에 대한 2024년 최신 진실" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">ChatGPT에 대한 2024년 최신 진실</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="5분 안에 알아보는 비전 트랜스포머와 마스크드 오토인코더" href="/post/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="5분 안에 알아보는 비전 트랜스포머와 마스크드 오토인코더" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="5분 안에 알아보는 비전 트랜스포머와 마스크드 오토인코더" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">5분 안에 알아보는 비전 트랜스포머와 마스크드 오토인코더</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="라즈베리파이에서 x86_64부터 ARM64까지 크로스 아키텍처 도커 배포 방법" href="/post/2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="라즈베리파이에서 x86_64부터 ARM64까지 크로스 아키텍처 도커 배포 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="라즈베리파이에서 x86_64부터 ARM64까지 크로스 아키텍처 도커 배포 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">라즈베리파이에서 x86_64부터 ARM64까지 크로스 아키텍처 도커 배포 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="슈퍼휴먼의 시대 AI와 로봇이 우리의 생산성을 폭발적으로 향상시키는 방법" href="/post/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="슈퍼휴먼의 시대 AI와 로봇이 우리의 생산성을 폭발적으로 향상시키는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="슈퍼휴먼의 시대 AI와 로봇이 우리의 생산성을 폭발적으로 향상시키는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">슈퍼휴먼의 시대 AI와 로봇이 우리의 생산성을 폭발적으로 향상시키는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="직접 해보는 학습의 힘 DIY 교육의 효과" href="/post/2024-06-30-Hands-OnLearningThePowerofDIYinEducation"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="직접 해보는 학습의 힘 DIY 교육의 효과" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="직접 해보는 학습의 힘 DIY 교육의 효과" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">직접 해보는 학습의 힘 DIY 교육의 효과</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Arduino로 퀀텀 컴퓨팅 구현하기 가이드 및 팁" href="/post/2024-06-30-QuantumComputingonArduino"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Arduino로 퀀텀 컴퓨팅 구현하기 가이드 및 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-QuantumComputingonArduino_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Arduino로 퀀텀 컴퓨팅 구현하기 가이드 및 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Arduino로 퀀텀 컴퓨팅 구현하기 가이드 및 팁</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="배 만들기 - VI 제6편" href="/post/2024-06-30-BuildingaShipVI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="배 만들기 - VI 제6편" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-BuildingaShipVI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="배 만들기 - VI 제6편" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">배 만들기 - VI 제6편</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="API로 전기 사용량 추적하는 방법" href="/post/2024-06-30-TrackingelectricityusagethroughanAPI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="API로 전기 사용량 추적하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-TrackingelectricityusagethroughanAPI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="API로 전기 사용량 추적하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">API로 전기 사용량 추적하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="비트코인에서 중요한 변화 2024년 최신 업데이트 분석" href="/post/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="비트코인에서 중요한 변화 2024년 최신 업데이트 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="비트코인에서 중요한 변화 2024년 최신 업데이트 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">비트코인에서 중요한 변화 2024년 최신 업데이트 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 30, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link posts_-active__YVJEi" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"절대 초보자를 위한 신경망 직접 코딩 기초부터 구현까지","description":"","date":"2024-06-30 19:11","slug":"2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners","content":"\n\n쌀선별기에 대해 알고 계신가요? 여기에 그 이미지가 있어요-\n\n![img](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_0.png)\n\n이 기사는 꽤 길어요. 하지만 여러분의 시간을 낭비하게 하려는 것이 아니에요. 이 긴 글은 사실 직관적으로 이해하기 쉽고 학습 속도를 높이기 위해 여기 있는 거예요. 또한 기술 용어와 수학은 피해서 더 간단하게 소화하도록 할게요.\n\n멋져요! 이제 쌀선별기로 돌아가보죠. 이 기계는 벼를 받아들이고 그 후에 어떤 처리(탈곡)를 해요. 마지막에 쌀과 견과가 출력으로 나와요-\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Coding a Neural Network from Scratch for Absolute Beginners](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_1.png)\n\n신경망이나 일반적으로 모든 AI 모델은 일종의 처리 기계와 같습니다. 데이터를 입력으로 받아들이고 어떤 형태의 변환을 실행한 후 변환된 결과를 출력합니다. 예를 들어, 모델에 염소 이미지를 제공하면 이미지를 \"염소\"라는 단어로 변환합니다. 이렇게 생각하는 것이 매우 도움이 됩니다 - 분류, 분할, 생성과 같은 어떤 유형의 작업을 수행하더라도 모델은 단순히 하나의 데이터를 다른 데이터로 변환하는 것뿐입니다.\n\n간단한 문제인 폭풍 예측으로 넘어가 봅시다. 어두운 구름과 온도의 급격한 하락이 있다면, 우리는 폭풍이 온다고 예측할 수 있습니다. 아래는 데이터의 테이블 형식 표현입니다-\n\n![Coding a Neural Network from Scratch for Absolute Beginners](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실생활에서는 날씨 예측이 복잡한 과정입니다. 여기서는 어두운 구름과 온도 감소가 모두 있는 경우에만 폭풍이 발생한다고 예측할 것입니다. 이 문제를 간단한 'if/else' 문으로 해결할 수 있습니다. 아래는 파이썬 코드입니다-\n\n```js\ndef predict(dark_clouds, temperature_drop):\n    storm = 0\n    if dark_clouds == 1 and temperature_drop == 1:\n        storm = 1\n    return storm\n\nprint(predict(1, 1))\nprint(predict(1, 0))\nprint(predict(0, 1))\nprint(predict(0, 0))\n```\n\n그러나 여기서는 머신러닝을 다루고 있으므로 문제를 명시적으로 해결하길 원하지 않습니다. (\"왜냐하면?\"이라고 물어볼 수 있습니다. 실제로 프로그래밍하기 매우 어려운 문제들이 있습니다. 그런 문제들을 해결하기 위해 머신러닝을 사용합니다.). 대신, 주어진 솔루션을 평가하고 더 나은 솔루션을 제안할 수 있는 코드를 작성해야 합니다-\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*itmi_oBBInInevageKOOxw.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실전에서는 무작위 예측으로 시작하여 그것을 점진적으로 개선해나갑니다. 모든 것이 괜찮은데, 그럼 뉴런이 무엇인가요?! 뉴런은 여러 입력을 받아들이고, 일종의 마법을 부리며 결과물을 출력하는 함수와 같습니다.\n\n```js\ndef predict(dark_clouds, temperature_drop):\n    storm = 마법!\n    return storm\n```\n\n마법이 커질수록, 비밀이 어리석어집니다!! 뉴런은 단순히 각 입력에 대해 출력에 미치는 영향에 따라 가중치를 부여합니다. 그런 다음, 가중 입력을 모두 누적합니다. 합계가 1보다 크면 1을 출력하고, 그렇지 않으면 0을 출력합니다.\n\n![이미지](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 두 개의 입력이 있기 때문에 각각에 대한 두 개의 가중치를 유지해야 합니다. 따라서, 필요한 가중치와 predict() 함수를 가진 neuron 클래스를 생성할 수 있습니다.\n\n```js\nclass Neuron:\n    def __init__(self):\n        self.w1 = 2\n        self.w2 = 0.5\n\n    def predict(self, dark_clouds, temperature_drop):\n        storm = 0\n        if (dark_clouds*self.w1 + temperature_drop*self.w2) \u003e 1:\n            storm = 1\n        return storm\n\nneuron = Neuron()\nprint(neuron.predict(1, 1))\nprint(neuron.predict(1, 0))\nprint(neuron.predict(0, 1))\nprint(neuron.predict(0, 0))\n```\n\n기다려 주세요! 가중치 값을 어디서 가져오는 건가요? 그것이 바로 머신러닝이죠 :)\n\n제발, 그냥 글을 읽지 말아주세요. 읽기만으로는 깊은 직관력을 갖출 수 없습니다; 연습이 필요합니다. 아직 하지 않으셨다면, Python 편집기나 GoogleColab을 열고 코드를 직접 실행해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금은 w1을 2로 설정하고 w2를 0.5로 설정해 봅시다. 코드를 실행하면 다음 결과가 나올 것입니다-\n\n```js\n1\n1\n0\n0\n```\n\n여기서 오직 한 가지 실수가 있는 것을 알 수 있습니다- 2번째 예측값은 0이어야 합니다. 이제 두 가중치를 모두 3으로 설정해 봅시다. 그러면, w1=3이고 w2=3이 됩니다. 이제 우리는 다음 결과를 얻습니다-\n\n```js\n1\n1\n1\n0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUps! 지금 두 가지 오류가 있어요 - 2번째와 3번째 예측이 틀렸어요. w1=0.6, w2=0.8로 설정해보겠습니다 -\n\n```js\n1\n0\n0\n0\n```\n\n와우! 이제 모든 정답을 맞췄어요. 다른 가중치 값을 사용해서 정확한 결과를 얻을 수 있는지 확인해보세요.\n\n지금까지 알게 된 것은 - 가중치를 변경함으로써 입력-출력 패턴에 맞게 예측 함수를 조정할 수 있습니다. 따라서, 두 입력과 출력값을 받아 가중치를 조정하기 위해 어떤 매직(다시 한번)을 하는 학습 함수가 필요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 일부 무작위 값으로 가중치를 초기화하겠습니다 (여기서 예측 함수는 다음과 같이 최소화됩니다 [...])-\n\n```js\nimport random\n\nclass Neuron:\n    def __init__(self):\n        self.w1 = random.random()\n        self.w2 = random.random()\n\n    def predict(self, dark_clouds, temperature_drop): [...]\n\n    def learn(self, dark_clouds, temperature_drop, storm):\n        self.w1 = 마법!\n        self.w2 = 마법!\n```\n\n그래서 여기서의 마법은 먼저 우리가 가진 무작위 가중치로 결과를 예측해보는 것입니다. 그런 다음 예측값을 실제 결과에서 뺌으로써 오차를 계산합니다. 마지막으로, 오차와 관련 입력(가중치로 곱해진 값)에 의해 가중치를 업데이트합니다. 이것은 가중치가 오차에 미치는 영향(관련 입력)에 기초하여 가중치에 벌을 부과하는 것과 같습니다. 이것을 생각해볼 수도 있는데, 에러를 생성하는 데 가중치의 부분에 따라 가중치에 에러를 분배하는 것과 같습니다.\n\n```js\nimport random\n\nclass Neuron:\n    def __init__(self): [...]\n\n    def predict(self, dark_clouds, temperature_drop): [...]\n\n    def learn(self, dark_clouds, temperature_drop, storm):\n        오차 = self.predict(dark_clouds, temperature_drop) - storm\n        self.w1 -= 오차 * dark_clouds / 100\n        self.w2 -= 오차 * temperature_drop / 100\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n너무 많은 변화를 원하지 않아요. 솔루션으로 나아가기 위해 작은 단계를 나아갈 거예요 (큰 단계는 종종 발산을 일으킵니다). 그래서 가중치를 업데이트할 때 에러를 100으로 나눠줘요.\n\n이제 훈련 및 테스트 코드를 추가할 수 있어요-\n\n```js\nimport random\n\nclass Neuron: [...]\n\nneuron = Neuron()\n\nwhile True:\n    # 테스트\n    if (neuron.predict(1, 1) == 1 and\n            neuron.predict(1, 0) == 0 and\n            neuron.predict(0, 1) == 0 and\n            neuron.predict(0, 0) == 0):\n        break\n\n    # 훈련\n    neuron.learn(1, 1, 1)\n    neuron.learn(1, 0, 0)\n    neuron.learn(0, 1, 0)\n    neuron.learn(0, 0, 0)\n\n# 출력\nprint(neuron.predict(1, 1))\nprint(neuron.predict(1, 0))\nprint(neuron.predict(0, 1))\nprint(neuron.predict(0, 0))\n```\n\n알 수 있듯이, 모든 올바른 출력을 얻을 때까지 훈련을 실행하고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_4.png\" /\u003e\n\n이렇게 까지 오신 것을 축하드립니다! 당신은 제로베이스에서 인공 신경세포를 직접 코딩하고 훈련시켰습니다!! 멋지세요!!!\n\n훈련 및 테스트를 위한 함수를 만들어 봅시다 -\n\n```js\nimport random\n\nclass Neuron: [...]\n\n\ndata = [[1, 1, 1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 0]]\n\ndef runTraining(neuron):\n    for row in data:\n        neuron.learn(row[0], row[1], row[2])\n\ndef runTesting(neuron):\n    return [neuron.predict(row[0], row[1]) for row in data]\n\nneuron = Neuron()\nwhile True:\n    output = runTesting(neuron)\n    print(output)\n    if output == [row[2] for row in data]:\n        break\n\n    runTraining(neuron)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드를 여러 번 실행하면 매번 해결책에 도달하기 위해 필요한 단계가 다를 수 있어요. 이는 가중치를 초기화하는 데 사용되는 랜덤 값 때문입니다. 때로는 한 단계만으로도 해결에 도달할 수 있을 수도 있어요.\n\n자, 이제 다른 출력값들과 놀아볼까요? 두 번째 출력값을 1로 변경하고 코드를 여러 번 실행해보세요 -\n\n```js\ndata = [[1, 1, 1],\n        [1, 0, 1],\n        [0, 1, 0],\n        [0, 0, 0]]\n```\n\n이번에는 해결책에 도달하기 위해 더 많은 단계가 소요되나요? 그런 이유가 무엇일까요? 시간을 내서 곰곰히 생각해보세요. 각 훈련 단계 이후에 가중치를 출력하여 변화를 분석해볼 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제, 첫 번째 출력을 0으로 설정하고 다시 실행해보겠습니다.\n\n```js\ndata = [[1, 1, 0],\n        [1, 0, 1],\n        [0, 1, 0],\n        [0, 0, 0]]\n```\n\n해결책에 도달하는 데 더 적은 단계가 필요한가요? 아니면 더 많은 단계가 필요한가요? 이해하는 것은 인공 뉴런의 기본 메커니즘을 이해하는 데 매우 유용합니다.\n\n이제, 모든 출력을 1로 설정해보겠습니다 -\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\n데이터 = [[1, 1, 1],\r\n        [1, 0, 1],\r\n        [0, 1, 1],\r\n        [0, 0, 1]]\r\n```\r\n\r\n무슨 일이 일어나고 있나요? 컴퓨터가 다운되었나요? 아니면 응답하지 않는 건가요? 사실, while 루프에 갇혔습니다. 모든 올바른 출력을 얻지 못하기 때문입니다. 문제는 4번째 행인 [0, 0, 1]에 발생합니다. 그리고 그 이유를 이해하는 것은 쉽습니다 - 입력 값이 둘 다 0(영)이기 때문입니다. 그렇기 때문에 어떤 가중치를 곱해도 0이 됩니다. 따라서, predict() 함수의 조건인 `(dark_clouds*self.w1 + temperature_drop*self.w2) ` 1`은 절대 충족되지 않을 것입니다.\n\n여기서 멈춰주세요. 이 기발한 문제에 대해 생각해보세요. 이를 해결하기 위해 무엇을 할 것인지 고민해보세요. 계속 읽기 전에 뇌에 충분한 시간을 주세요.\n\n여기서 문제가 되는 것은 조건에서의 임계점인 1(하나)입니다. 1 대신 -1(음수 1)을 임계점으로 사용할 수 있습니다- `(dark_clouds*self.w1 + temperature_drop*self.w2) ` -1` . 이렇게 하면 문제가 해결됩니다. 그러나 그렇게 되면 모든 0(영) 출력에 대한 문제가 발생할 것입니다-\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n데이터 = [[1, 1, 0],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 0]]\n```\n\n따라서 해당 임계값을 조정해야 합니다. 임계값에 랜덤 값을 설정하고 가중치를 학습한 방식과 동일한 방법으로 학습할 수 있습니다. 여기에 코드 전체가 있습니다-\n\n```js\nimport random\n\nclass Neuron:\n    def __init__(self):\n        self.w1 = random.random()\n        self.w2 = random.random()\n        self.t = random.random()\n\n    def predict(self, dark_clouds, temperature_drop):\n        storm = 0\n        if (dark_clouds*self.w1 + temperature_drop*self.w2) \u003e self.t:\n            storm = 1\n        return storm\n\n    def learn(self, dark_clouds, temperature_drop, storm):\n        error = self.predict(dark_clouds, temperature_drop) - storm\n        self.w1 -= error * dark_clouds / 100\n        self.w2 -= error * temperature_drop / 100\n        self.t += error / 100\n\ndata = [[1, 1, 1],\n        [1, 0, 1],\n        [0, 1, 1],\n        [0, 0, 1]]\n\ndef runTraining(neuron):\n    for row in data:\n        neuron.learn(row[0], row[1], row[2])\n\ndef runTesting(neuron):\n    return [neuron.predict(row[0], row[1]) for row in data]\n\nneuron = Neuron()\nwhile True:\n    output = runTesting(neuron)\n    print(output)\n    if output == [row[2] for row in data]:\n        break\n\n    runTraining(neuron)\n```\n\n와우! 놀랄만한 여정이었어요! 기계 학습(ML)의 세계에 오신 것을 환영합니다. 이제 어떤 어려운 ML 용어를 알아보도록 하죠-\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n편향: 머신 러닝에서 임계값 t를 단순히 편향이라고 부릅니다.\n\n매개변수: w1, w2 및 t(가중치와 편향)는 학습을 통해 배우는 변수인 매개변수로 불립니다. 매개변수를 선택하는 행위를 매개변수화라고 합니다.\n\n모델: 학습 후에는 올바른 출력을 생성하는 좋은 w1, w2 및 t (가중치와 편향) 값들이 있게 됩니다. 이러한 매개변수 값의 집합을 모델이라고 부릅니다.\n\n학습률: 함수 learn()에서 매개변수를 조정하는 동안 값들을 100으로 나눕니다. 이를 0.01로 곱하는 것으로 생각할 수 있습니다. 이 0.01을 학습률이라고 부르며, 종종 알파(α)로 표시됩니다. 학습률은 매우 중요한 하이퍼파라미터입니다(사람이 설정하는 값으로, 학습을 통해 학습되지 않는 값).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그레디언트 디센트: 우리가 learn() 함수에서 실행한 알고리즘은 매개변수(가중치와 편향)를 조정하기 위한 그레디언트 디센트라고 합니다. 더 구체적으로는 확률적 경사 하강법(SGD)입니다.\n\n회귀: 예측, 오차 계산 및 매개변수 조정의 전체 반복 과정을 회귀라고 합니다. 여기서 사용한 변형은 선형 회귀입니다.\n\n에포크: 올바른 출력값에 도달하기 위해 회귀에서 필요한 반복 수입니다.\n\n위 코드는 두 가지 입력만을 고려했습니다. 그러나 배열을 사용하여 어떤 수의 입력이라도 쉽게 업그레이드할 수 있습니다. 전체 코드는 여기에서 찾을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리에게는 마지막 테스트가 하나 더 있어요 :D\n\n```js\ndata = [[1, 1, 0],\n        [1, 0, 1],\n        [0, 1, 1],\n        [0, 0, 0]]\n```\n\n이곳에는 하나의 뉴런만 있어요. 그리고 이 문제를 해결할 수 있는 뉴런이 한 개만 있다는 것이 증명되었어요. 이 문제를 해결하기 위해 여러 개의 뉴런(또는 신경망)이 필요할 거예요. [곧 연속되는 파트가 나올 거에요...]","ogImage":{"url":"/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_0.png"},"coverImage":"/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_0.png","tag":["Tech"],"readingTime":10},{"title":"ChatGPT에 대한 2024년 최신 진실","description":"","date":"2024-06-30 19:09","slug":"2024-06-30-ChatGPTisBullshit","content":"\n\n원페이지가 하나의 이유로 산업계에서 큰 화제를 일으키고 있어요:\n\n그 이유가 뭔지, 그리고 그게 무슨 의미를 갖는지 알고 싶나요?\n\n# 인공지능의 진정한 본성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대형 언어 모델(Large Language Model, LLM)이 실수를 할 때, 우리는 그 모델이 '환각을 일으켰다'고 말합니다.\n\nLLM은 확률론적(의사 난수 생성) 단어 생성기이기 때문에, 모델이 진실에서 벗어난 예상치 못한 결과물을 출력할 확률이 항상 있는 것입니다.\n\n그리고 분명히 말하자면, 이것은 일부러 이루어지는 것입니다.\n\n자연어로 같은 생각이나 감정을 표현하는 다양한 방법이 있기 때문에, 우리는 모델에 불확실성을 모델링하도록 훈련시킵니다. 이를 위해 우리는 새로운 예측마다 정확한 단어를 결정하도록 하지 않고, 모든 단어 어휘에 대한 확률 분포를 출력하도록 강제합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다시 말해, 아래에서 볼 수 있듯이, 모델은 입력 시퀀스에 대한 계속으로 통계적으로 합리적인 단어 (어휘)를 순위별로 나열합니다.\n\n![image](/assets/img/2024-06-30-ChatGPTisBullshit_1.png)\n\n하지만 역설적으로, 우리는 항상 가장 확률이 높은 단어를 선택하지는 않습니다. 사실, 상위 k개 단어 중 하나를 무작위로 샘플링하며, 모두가 아마도 합리적인 계속으로 판단됩니다 (위 이미지에서 5개의 옵션은 모두 의미론적으로 유효합니다).\n\n이는 모델의 창의력을 향상시키기 위해 수행되며, 때로는 이것이 바람직하며 모델의 언어 모델링 능력을 향상시키는 데 도움이 된다고 여겨집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 모델이 잘못된 가정을 내어놓고 어색한 주장을 하는 경우, 그것이 정말로 인간이 하는 것처럼 '환각'을 하는 것일까요?\n\n## 로봇에 의인화를 부여하다\n\n연구자들은 이겍이 명백히 잘못되었다고 말합니다.\n\n환각은 세상을 잘못 인식하여 현실과 어긋난 주장을 만들어내는 것을 의미합니다. 그러나 이것이 바로 그 차이점입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n---\n새로운 데이터\n\nChatGPT와 친숙해지기 위해 몇 가지 텍스트를 입력해보세요. 이것은 머신러닝 모델을 더 재미있고 유용하게 만들 수 있습니다.\n---\n\nLLM은 현실을 인식할 수 없어요.\n\n그들은 텍스트의 렌즈를 통해 현실을 보기 때문에 실제로 경험할 수 없어요.\n\n그 이유로 '환각'이라고 부르는 것은 도움이 되기보다 오히려 해를 끼치죠. 하지만 왜 거짓이라고 부르지 않는 건 어떨까요?\n\n# ChatGPT의 목표 이해하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n연구자들은 'ChatGPT가 거짓말을 했다'고 말하는 것이 LLMs의 실제 본성을 왜곡한다고 주장합니다. 거짓말을 하려면 누군가가 어떤 것에 대한 진실을 알고 의도적으로 대체로 부정확한 주장을 해야 합니다.\n\n사실, 팀은 모델이 진실을 말하려고 하는 것이 아니기 때문에 진실과 거짓을 알 수 없다고 주장합니다. 모델은 단순히 인간의 언어를 모방하려고 하는 것뿐입니다.\n\n그래서 LLMs에 더 적용되는 용어인 '허풍을 떨다' 또는 부정확한 주장을 퍼뜨리지만 그 부정확함을 인식하지 못하는 것입니다.\n\n그런데 왜 그럴까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델이 '진실을 말한다'는 점에서, 그 모델은 훈련 데이터의 진실성만큼 정확합니다.\n\n모델은 각 단어와 문장의 진실성을 평가하지 않습니다. 대신, 통계적 패턴과 확률에 기반하여 응답을 생성합니다. 이는 진실이나 거짓 여부와 독립적으로 이루어집니다.\n\n결국, 모델이 마치 답변을 찾기 위해 노력하는 것처럼 보일지라도, 실제로 하는 일은 제공된 입력 순서에 따라 자체 지식에서 해답을 검색하고 있습니다. 모델이 진실을 찾고 있는 것이 아니라, 주어진 순서의 다음으로 가장 통계적으로 타당한 후속 조치를 찾고 있는 것입니다.\n\n하지만 모델을 더 정확하게 만들 방법이 있을까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 진실을 찾아 나서며\n\n우리가 추론이 올바른 해결책을 찾을 때까지 가능한 해결책의 공간을 탐색하는 한 형태의 탐색인 것으로 가정한다면 (나의 연구 결과에 따르면 이는 LLMs가 효과적으로 추론할 수 있는지 여부와는 별개의 논점이며 동의하는 견해인 것으로 보여집니다), LLMs와 런타임 탐색을 결합함으로써 그들의 추론 능력을 향상시키고, 따라서 부정확성을 감소시킬 수 있습니다.\n\n그러나 이 모델에서도 여전히 진실을 찾는 것이 아니며, 목표는 여전히 인간의 언어를 모방하는 것입니다.\n\n그렇다면, 아마도 진실성을 암묵적으로 향상시키는 방법이 있을 수 있습니다. 이는 연구자들이 엔트로피 최소화와, 최근에는 테스트 시 점진적인 미세 조정을 통해 오랫동안 조사해온 두 가지 방법입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 엔트로피 최소화에서는 모델이 엔트로피가 낮은 응답을 선호하는 귀납편향을 갖고 있습니다. 다시 말해, 여러 응답을 생성하고, 차별화 방법으로, 가능한 가정의 수가 가장 적은(즉, 가장 간단한) 응답을 가장 좋은 답이라고 취하는 가설을 적용합니다. 일부 분들께는 Ockham의 면도날과 유사하게 느껴질 것입니다.\n\n- 테스트 시간 미세조정에서 Jack Cole과 Mohamed Osman은 推論에 대한 모델을 세밀 조정하여 유명한 ARC-AGI 벤치마크(대규모 언어 모델에 대한 가장 어려운 벤치마크)의 해법을 활발히 탐색하고 있습니다.\n\n그러나 저의 겸손한 견해에 따르면(제가 틀릴 수도 있습니다), 이러한 검색과 LLM을 결합하는 매우 흥미로운 방법이 모델의 정확성을 향상시킬 수 있다는 점에도 불구하고, 본질적으로 모델은 여전히 진실을 탐색하는 것이 아니라 이전에 메모리화한 해결 경로와 유사한 최상의 통계적으로 타당한 응답을 제공하고 있지 않는다는 문제를 해결하지 못하는 것 같습니다.\n\n다시 말해, 더 똑똑한 검색 방법과 LLM은 더 나은, 더 사실적인 응답으로 이어질 수 있지만, 모델은 여전히 단순히 통계적으로 최적의 답변을 제공하는 목표를 실현하고 있으며, 거기에 반드시 응답의 진실성을 고려하지는 않습니다. 비록 논의된 귀납편향이 내제적으로 진실성을 향상시킬 수 있다고 하더라도요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앞서 설명한 바와 같이 모델들이 더 나은 품질의 데이터를 소화하고 압축 능력을 향상시키면, '참'이라고 할 수 있는 주장이 '거짓'이라고 할 때보다 모델에게 통계적으로 더 합리적일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 모델이 진실을 찾을 수 없는 한(그 존재를 모르기 때문에), 학습 데이터에서 미대표적인 진실은 모델이 가짜로 답변하게 유도하거나, 더 정확히 말하면 '헛소리로' 오도록 할 수 있습니다.\n\n나는 몰라. 당신은 알고 있나요?","ogImage":{"url":"/assets/img/2024-06-30-ChatGPTisBullshit_0.png"},"coverImage":"/assets/img/2024-06-30-ChatGPTisBullshit_0.png","tag":["Tech"],"readingTime":4},{"title":"5분 안에 알아보는 비전 트랜스포머와 마스크드 오토인코더","description":"","date":"2024-06-30 19:07","slug":"2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes","content":"\n\n## 컴퓨터 비전으로 일반화된 NLP 작업을 안내하는 간단한 가이드\n\n2017년 transformer 아키텍처가 등장하면서 언어 모델링, 가려진 단어 예측, 번역 및 질의 응답과 같은 대부분의 자연어 처리 작업들이 혁신을 이루었습니다. Transformers가 컴퓨터 비전 작업에서도 뛰어난 성과를 거뒀다는 데는 2~3년이 걸리지 않았습니다. 이 이야기에서는 transformers가 컴퓨터 비전 분야로 진출할 수 있게 된 두 가지 기본 아키텍처를 탐구합니다.\n\n## 목차\n\n- Vision Transformer\n  - 주요 아이디어\n  - 운영\n  - 혼합 아키텍처\n  - 구조의 손실\n  - 결과\n  - 가려진 자가 반복 학습\n- 가려진 오토인코더 비전 Transformer\n  - 주요 아이디어\n  - 아키텍처\n  - 최종 결론 및 예제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 비전 트랜스포머\n\n![이미지](/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_0.png)\n\n## 주요 아이디어\n\n비전 트랜스포머는 단순히 표준 트랜스포머 구조를 이미지 입력을 처리하고 학습하기 위해 일반화하는 것을 의미합니다. 저자들이 강조한 아키텍처에 대한 중요한 아이디어가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 동작\n\n“가능한 수정을 가장 적게 하는 것”을 말 그대로 받아들이는 것은 옳습니다. 사실 그들은 거의 수정을 하지 않습니다. 그들이 실제로 수정하는 것은 입력 구조입니다:\n\n- NLP의 transformer encoder는 입력 문장/문단을 나타내는 원핫 벡터 시퀀스(또는 동등한 토큰 인덱스)를 가져와 문맥 임베딩 벡터 시퀀스를 반환합니다. 이는 나중에 사용될 수 있는 벡터들이며(예: 분류)\n- CV를 일반화하기 위해, vision transformer는 입력 이미지를 나타내는 패치 벡터 시퀀스를 가져와 문맥 임베딩 벡터 시퀀스를 반환합니다. 이는 나중에 사용될 수 있는 벡터들입니다(예: 분류)\n\n특히, 입력 이미지의 차원이 (n, n, 3)이라고 가정할 때, 이를 transformer에 입력으로 전달하기 위해 vision transformer가 수행하는 작업은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 위의 그림과 같이 k (예: k=3)로 k² 패치로 나눕니다.\n- 이제 각 패치는 (n/k, n/k, 3)이고, 다음 단계는 각 패치를 벡터로 평평하게 만드는 것입니다.\n\n패치 벡터는 3*(n/k)*(n/k) 차원입니다. 예를 들어, 이미지가 (900,900,3)이고 k=3을 사용한다면, 패치 벡터는 평평화된 패치의 픽셀 값을 나타내는 300*300*3 차원이 될 것입니다. 논문에서는 k=16을 사용하고 있습니다. 따라서, 제목에 \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\"이라고 표시됩니다. 단어를 나타내는 one-hot 벡터를 주지 않고 이미지의 패치를 나타내는 픽셀 벡터로 대신합니다.\n\n나머지 작업은 원래 트랜스포머 인코더와 동일합니다:\n\n- 이러한 패치 벡터는 훈련 가능한 임베딩 레이어를 통과합니다.\n- 각 벡터에 위치 임베딩이 추가되어 이미지의 공간 정보를 유지합니다.\n- 출력은 각 패치에 대한 인코더 표현 (패치 또는 이미지 수준의 분류에 사용 가능)이 될 수 있습니다.\n- 더 자주 (및 논문에서처럼), CLS 토큰이 전단에 추가되고 해당 표현을 사용하여 전체 이미지에 대한 예측을 수행합니다 (BERT와 유사).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTransformer Decoder에 대해 어떻게 생각하시나요?\n\n기억해두세요, Transformer Encoder와 마찬가지로 Transformer Decoder도 마찬가지로 작동합니다; 차이점은 self-attention 대신 masked self-attention을 사용한다는 것입니다 (하지만 동일한 입력 signature를 유지합니다). 어쨌든, 단순히 다음 패치를 예측하는 것은 큰 흥미를 불러일으키는 작업이 아닐 수 있으므로 대부분의 경우 decoder-only Transformer 아키텍처를 드물게 사용할 것으로 기대됩니다.\n\n## 하이브리드 아키텍처\n\n작가들은 또한 이미지 자체 대신 CNN feature map으로 시작하여 하이브리드 아키텍처를 형성하는 것이 가능하다고 언급합니다 (CNN이 비전 Transformer에 출력을 전달). 이 경우 입력을 일반적인 (n,n,p) feature map으로 생각하고 패치 벡터는 차원이 (n/k)*(n/k)*p로 생각합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 구조 손실\n\n당신이 생각할 수도 있겠지만, 이미지를 선형 구조로 처리하는 것이 아니기 때문에 이 아키텍처가 그리 좋지 않다고 생각할 수 있습니다. 저자가 의도적으로 이를 언급하여 이 구조가 의도적임을 나타내려고 노력한 것을 알 수 있습니다.\n\n저희는 이를 증명하기 위해 transformer가 이를 학습할 수 있는 능력을 가지고 있음을 그들의 실험에서 좋은 성능을 보여줌으로써, 그리고 더 중요한 것은 다음 논문의 아키텍처를 통해 확인할 것입니다.\n\n## 결과\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과에서 주요 결론은 비전 트랜스포머가 작은 데이터셋에서 CNN 기반 모델보다 우월한 성능을 내지 않지만, 큰 데이터셋에서는 접근하거나 능가할 수 있으며 어느 쪽이든 상당히 적은 계산량이 필요하다는 것입니다:\n\n![이미지](/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_1.png)\n\n여기서 JFT-300M 데이터셋(300M개의 이미지)을 사용한 경우, 해당 데이터셋에서 사전 훈련된 ViT 모델들이 ResNet 기반 베이스라인보다 우수한 성능을 보이면서 훈련에 필요한 계산 자원이 상당히 적다는 것을 볼 수 있었습니다. 사용된 큰 비전 트랜스포머인 ViT-Huge(632M 개의 매개변수 및 k=16)는 ResNet 기반 모델에 사용된 계산량의 약 25%만을 사용하고 여전히 우수한 성능을 발휘했습니다. 계산량의 6.8%만을 사용하는 ViT-Large를 사용했을 때에도 성능이 크게 저하되지 않았습니다.\n\n한편, ImageNet-1K(단 1.3M개의 이미지)에서 훈련된 경우 ResNet이 더 우수한 성과를 냈다는 결과도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 마스킹에 의한 자가-지도학습\n\n저자들은 자가-지도학습을 위해 가리기된 패치 예측에 대한 예비 탐구를 수행했습니다. 이는 BERT에서 사용된 가리기된 언어 모델링 작업을 모방하며 (즉, 패치를 가리고 예측하는 것), 자가-지도학습을 위한 것입니다.\n\n자가-지도 사전 훈련을 통해, 작은 ViT-Base/16 모델은 ImageNet에서 79.9%의 정확도를 달성했습니다. 이는 처음부터 훈련하는 것보다 2%의 중요한 향상을 보입니다. 그러나 여전히 지도된 사전 훈련보다 4% 뒤에 있습니다.\n\n# 가리기된 오토인코더 비전 트랜스포머\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_2.png\" /\u003e\n\n## 주요 아이디어\n\n비전 트랜스포머 논문에서 볼 수 있듯이, 입력 이미지의 패치를 마스킹하여 사전 훈련의 이득은 일반적인 NLP와 비교했을 때 그다지 중요하지 않았습니다. 반면 일부 파인튜닝 작업에서 마스킹 전 사전 훈련이 우수한 결과를 낼 수 있는 일반 NLP와는 다르게 이득이 크게 나타나지 않았습니다.\n\n본 논문에서는 인코더와 디코더를 포함한 비전 트랜스포머 아키텍처를 제안하며, 이를 마스킹하여 사전 훈련하면 기본 비전 트랜스포머 모델 대비 상당한 개선이 나타납니다(기본 크기의 비전 트랜스포머를 지도 학습하는 것과 비교하여 최대 6%의 향상을 보임).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_3.png)\n\n다음은 샘플(입력, 출력, 실제 레이블)입니다. 입력을 재구성하면서 누락된 패치를 채우려고 시도한 오토인코더입니다.\n\n## 아키텍처\n\n그들의 인코더는 이전에 설명한 일반적인 비전 트랜스포머 인코더입니다. 교육 및 추론에서는 \"관측된\" 패치만 사용합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한편, 그들의 디코더는 보통 비전 트랜스포머 인코더와 동일하지만 다음을 사용합니다:\n\n- 누락된 패치를 위한 마스크된 토큰 벡터\n- 알려진 패치를 위한 인코더 출력 벡터\n\n따라서 누락된 패치가 있는 이미지 [ [ A, B, X], [C, X, X], [X, D, E]]에서 X는 누락된 패치를 나타냅니다. 디코더는 패치 벡터 시퀀스를 가져와야 합니다 [Enc(A), Enc(B), Vec(X), Vec(X), Vec(X), Enc(D), Enc(E)]. Enc는 패치 벡터가 주어졌을 때 인코더 출력 벡터를 반환하고 X는 누락된 토큰을 나타내는 벡터입니다.\n\n디코더의 마지막 레이어는 비전 트랜스포머 인코더에서 생성된 문맥 임베딩을 패치 크기와 동일한 길이의 벡터로 매핑하는 선형 레이어입니다. 손실 함수는 오차 제곱을 사용하는 평균 제곱 오차입니다. 이 손실 함수에서 우리는 마스크된 토큰으로 인한 디코더 예측만 고려하며 현재 존재하는 토큰에 해당하는 예측은 무시합니다 (예: Dec(A), Dec(B), Dec(C) 등).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 최종 설명 및 예시\n\n저자들이 이미지의 패치 중 약 75%를 가리는 것을 제안한다는 것이 놀라울 수도 있습니다. 반면 BERT는 단어의 약 15%만 가리게 됩니다. 그들은 다음과 같이 이를 정당화합니다:\n\n스스로 해보고 싶으신가요? NielsRogge의 데모 노트북을 확인해보세요.\n\n여기까지 입니다. 우리는 컴퓨터 비전 세계로 일반화되는 기본 트랜스포머 모델을 이해하기 위한 여정을 함께해 왔습니다. 이 내용이 명확하고 통찰력 있으며 여러분의 시간을 가치 있게 보내게 되었기를 바랍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참고 자료:\n\n[1] Dosovitskiy, A. et al. (2021) 'An image is worth 16x16 words: Transformers for image recognition at scale', arXiv.org. [온라인] Available at: https://arxiv.org/abs/2010.11929 (방문 날짜: 2024년 6월 28일).\n\n[2] He, K. et al. (2021) 'Masked autoencoders are scalable vision learners', arXiv.org. [온라인] Available at: https://arxiv.org/abs/2111.06377 (방문 날짜: 2024년 6월 28일).","ogImage":{"url":"/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_0.png"},"coverImage":"/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_0.png","tag":["Tech"],"readingTime":6},{"title":"라즈베리파이에서 x86_64부터 ARM64까지 크로스 아키텍처 도커 배포 방법","description":"","date":"2024-06-30 19:06","slug":"2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi","content":"\n\n애플리케이션을 일관된 환경에서 다양한 아키텍처로 배포하는 것은 컨테이너화에서 처음으로 겪은 중요한 도전 중 하나였어요. 이 글에서는 x86_64 머신에서 Docker 이미지를 빌드하고 ARM64 라즈베리 파이에서 실행하는 경험을 공유하려고 해요. 이 여정은 Docker Buildx를 사용하고 이미지를 전송하며 cron과 함께 Python 스크립트를 실행하도록 컨테이너를 구성하는 과정을 포함하고 있답니다.\n\n여기서는 KISS 원리(Keep It Simple, Stupid)를 준수하고자 하며 관련된 코드에 집중하기로 하고 불필요한 설명은 건너뛸 거예요. 시스템과 필수 구성 요소가 최신 상태임을 전제로 하고 업데이트는 생략할 거에요.\n\n# 1. Docker Buildx 설정\n\n```js\ndocker buildx install\ndocker buildx create --use\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2. ARM64용 도커 이미지 빌드하기\n\n```js\ndocker buildx build --platform linux/arm64 -t \u003cmy-python-app\u003e --load .\n```\n\n# 3. 이미지 내보내고 전송하기\n\n```js\ndocker save \u003cmy-python-app\u003e -o \u003cmy-python-app\u003e.tar\nsudo scp \u003cmy-python-app\u003e.tar pi@raspberrypi:/home/pi/\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예시에서 사용자 이름은 pi입니다. 여러분의 자격 증명으로 교체해 주세요\n\n## 4. 라즈베리 파이에 이미지 로드하기\n\n```js\ndocker load -i \u003c나의-파이썬-앱\u003e.tar\n```\n\n## 5. 특권 플래그를 사용하여 컨테이너 실행하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨테이너를 실행하려면 여러 속성을 지정해야 했어요. 예를 들어, 환경 변수를 포함시키고 호스트와 컨테이너 간 데이터 공유를 위해 폴더를 마운트했어요. 또한 반드시 --privileged 플래그를 설정해야 했어요. 그렇지 않으면 컨테이너가 제대로 작동하지 않았어요.\n\n```js\ndocker run -d \\\n  --name \u003cname\u003e \\\n  --platform linux/arm64 \\\n  -e MY_ENV_VAR=value\\\n  --privileged \\\n  --mount type=bind,source=\u003cpath on raspberry\u003e,target=\u003cpath inside container\u003e \\\n  \u003cmy-python-app\u003e\n```\n\n# 6. 크론 작업 설정\n\n크론 작업이 제대로 실행되려면 환경 변수가 crontab 파일에 정의되어 있고 Python 인터프리터의 전체 경로가 지정되어 있어야 했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 환경 변수 정의\nMY_ENV_VAR=value\n\n# m h  dom mon dow   command\n* * * * * /usr/local/bin/python /app/my_script.py \u003e\u003e /var/log/cron.log 2\u003e\u00261\n```\n\n주된 문제는 플랫폼을 (--platform) 지정하는 것, --privileged 플래그를 설정하는 것, 그리고 환경 변수가 cron 파일에 올바르게 정의되는 것이었습니다. 이 기사가 누군가에게 도움이 되어 도커와 라즈베리 파이를 사용해 실험하는 데 시간을 절약할 수 있기를 바랍니다. 즐거운 하루 되세요! :)","ogImage":{"url":"/assets/img/2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi_0.png","tag":["Tech"],"readingTime":2},{"title":"슈퍼휴먼의 시대 AI와 로봇이 우리의 생산성을 폭발적으로 향상시키는 방법","description":"","date":"2024-06-30 19:06","slug":"2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity","content":"\n\n안녕하세요, 저는 미래를 모습을 만들어가는 최신 기술을 탐험하는 것에 열정을 가진 소프트웨어 엔지니어인 야쉬입니다. 웹3과 인공지능의 흥미로운 영역을 탐험하는 호기심 많은 마음으로, 인간-인공지능 협력의 변혁적인 힘에 대한 제 생각을 나누어 주는 것에 기쁨을 느낍니다.\n\n그럼 시작해볼까요?\n\n우리가 이 여정을 시작함에 따라, 인공지능과 로봇공학은 우리의 능력을 증강시키고 전례없는 생산성과 효율성을 끌어올릴 준비가 되어 있습니다. 그들의 잠재력을 활용하여 우리는 더 적은 시간에 더 많은 것을 더 정확하게 달성할 수 있을 것입니다. 정밀함과 정확성을 갖춘 상태로 두 배 많은 것을 절반의 시간에 달성할 수 있는 능력을 상상해보세요. 생산성의 미래가 여기 있으며, 이는 인간의 창의력과 기술적 발전의 융합에 의해 이루어졌습니다.\n\n![이미지](/assets/img/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인간의 잠재력 향상:\n인간과 AI의 협업 미래는 엄청난 약속을 품고 있습니다. 두 가지의 강점을 활용하여 우리는 다음을 달성할 수 있습니다:\n\n- 생산성과 효율성을 증가시키다\n- 의사 결정 및 문제 해결 능력 강화\n- 건강 결과와 삶의 질 향상\n- 혁신과 기업가 정신 육성\n- 교육 및 기술 개발을 위한 새로운 길 만들기\n\n미래를 항해하며:\n이 여정에 착수할 때, 이러한 기술적 발전과 함께 오는 도전과 책임을 인식하는 것이 중요합니다. 우리는 다음 사항을 우선적으로 고려해야 합니다:\n\n- 윤리적 AI 개발 및 배포\n- 데이터 개인 정보 보호와 보안\n- 노동 인력 재훈련과 업스킬링\n- 기술 및 그 혜택에 대한 포용적 접근\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대화에 참여해 주셔서 감사합니다 - 아래 댓글에 생산성의 미래에 대한 생각을 공유해주세요. 인간과 AI의 협업 가능성을 함께 탐험해봐요!\n\n계속해서 주목해 주세요 - 저의 블로그를 구독하시면 Web3, AI 및 기술의 미래에 대한 더 많은 통찰력을 얻을 수 있습니다. 함께 미래를 만들어 나가요!\n\n- 야시 파틸","ogImage":{"url":"/assets/img/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity_0.png"},"coverImage":"/assets/img/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity_0.png","tag":["Tech"],"readingTime":2},{"title":"직접 해보는 학습의 힘 DIY 교육의 효과","description":"","date":"2024-06-30 19:05","slug":"2024-06-30-Hands-OnLearningThePowerofDIYinEducation","content":"\n\n\u003cimg src=\"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_0.png\" /\u003e\n\n교과서와 강의가 교육 분야를 지배하는 시대에 조용한 변화가 일고 있습니다. DIY (스스로 해보기) 정신에 힘입어 손으로 배우는 것이 학생들이 정보를 학습하고 유지하는 방식을 변화시키고 있습니다. 이 방식은 단순히 매료되는 것뿐만 아니라, 빠르게 변화하는 세계에 대비하여 학생들을 준비시켜줍니다.\n\n화면 뒤에서 : 과학\n\n연구 결과에 따르면, 손으로 배우는 경험은 여러 뇌 영역을 활성화시켜 신경 연결을 강화하고 학습 능력을 향상시킵니다. 학생들이 DIY 프로젝트에 참여하면 문제 해결 능력, 비판적 사고, 창의력을 발전시키는데, 이는 21세기 성공에 필수적인 능력들입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_1.png\" /\u003e\n\n다음 몇 가지를 소개해 드립니다:\n\n- STEM 교육: 다리 건설, 보조 장치 디자인, 또는 태양열 자동차 제작과 같은 DIY 프로젝트를 통해 학생들은 물리학, 공학 및 수학의 복잡한 개념을 이해할 수 있습니다.\n- 언어 예술: 학생들은 자신만의 책, 만화, 또는 대본을 만들면서 글쓰기, 편집, 그리고 스토리텔링 기술을 발전시킬 수 있습니다.\n- 환경 과학: 조랑말집 건설, 테라리움 제작, 또는 재활용 시스템 디자인과 같은 DIY 프로젝트는 지속가능성과 보전에 대한 감사心을 육성합니다.\n\n\"왜\" : 교육에서 DIY의 혜택\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n교육과정에 DIY 프로젝트를 통합함으로써 학생들은 교실 밖으로 계속 이어지는 다양한 혜택을 누릴 수 있습니다. 학업 성취도 향상부터 창의력과 비판적 사고 능력 향상까지, 교육 분야에서 DIY의 장점은 다양하고 유효합니다. 학생들이 실습 학습을 채택함으로써, 학업, 직업, 그리고 삶에서 성공을 위해 준비가 되는 중요한 기술을 개발할 수 있습니다.\n\n어떻게?\n\n- 참여 증가: 실습 학습은 학생 참여와 동기부여를 촉진합니다.\n- 기억력 향상: DIY 프로젝트는 학생들이 개념을 더 효과적으로 기억하게 도와줍니다.\n- 소프트 스킬 개발: 협력, 커뮤니케이션, 문제 해결 능력은 DIY 활동을 통해 향상됩니다.\n- 창의성 강화: 학생들은 창의적인 해결책을 개발하기 위해 상상력을 발휘합니다.\n- 미래를 위한 준비: DIY 교육은 지속 가능한 에너지, 로봇공학, 생명공학과 같은 떠오르는 분야에서의 경력을 위한 학생들을 준비합니다.\n\n![Hands-On Learning: The Power of DIY in Education](/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오오... 증거들! 성공 스토리\n\n- 메이커 운동: 이 세계적인 현상은 학교와 지역사회가 DIY 교육을 채택하도록 영감을 주어 학생들의 참여와 혁신이 증가하도록 이끌었습니다.\n- 프로젝트 기반 학습: 뉴욕시 교육부의 iSchool과 같은 학교들은 DIY 프로젝트를 도입하여 학업 성취 및 학생 만족도가 향상되었습니다.\n- MIT의 Fab Lab: 이 유명한 프로그램은 학생들이 혁신적인 프로젝트를 설계하고 구축할 수 있게 하여 창의성과 기업가정신을 육성했습니다.\n- DIY Girls' 프로그램: 이 이니셔티브는 손잡이 프로젝트를 통해 과학, 기술, 공학, 수학(STEM) 분야를 추구하도록 젊은 여자 아이들을 격려하여 자신감과 학업 성취도가 증가했습니다.\n- Cardboard Challenge: 이 세계적인 대회는 카드보드를 사용하여 혁신적인 프로젝트를 만들도록 학생들에 영감을 주어 창의력, 비판적 사고, 문제 해결 능력을 촉진했습니다.\n- STEM 아카데미: 이 프로그램은 DIY 프로젝트를 교육과정에 통합하여 학생 성과가 향상되고 STEM 분야에 대한 관심이 증가했습니다.\n\n교육자이자 혁신가인 Sugata Mitra는 “학습의 미래는 정보 전달이 아니라 발견을 촉진하는 것이다”라고 말합니다. DIY 프로젝트를 통한 실습 학습은 교육을 혁신하는 강력한 방법을 제공합니다. 이 방법을 수용함으로써, 학생들이 창의적인 문제 해결사, 비판적 사고가 필요한 사람, 혁신가가 되도록 돕을 수 있습니다.\n\nDIY 세계를 탐험하려면 TinQ를 다운로드하세요 🏹","ogImage":{"url":"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_0.png"},"coverImage":"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_0.png","tag":["Tech"],"readingTime":3},{"title":"Arduino로 퀀텀 컴퓨팅 구현하기 가이드 및 팁","description":"","date":"2024-06-30 19:04","slug":"2024-06-30-QuantumComputingonArduino","content":"\n\n![이미지](https://miro.medium.com/v2/resize:fit:1000/0*fA_-0zuJ81UEVDTs.gif)\n\n테크 자이언트들이 수십억 달러를 양자 컴퓨팅에 투자하고 초전도 회로와 저온 냉각 시스템에 거액을 쓰는 세상에서, 나는 약간 다른 방법을 택했습니다. Arduino Uno(실제로 훨씬 저렴한 Elegoo Uno), 손에 꼽을만큼의 LED, 그리고 양자 지배력에 대한 끝없는 열망으로 무장한 채, 저는 고급스러운 양자 컴퓨터를 부러워할 Arduino 양자 에뮬레이터를 만들었습니다.\n\n여기, Arduino 양자 컴퓨터를 소개합니다. 7개의 큐빗으로 무장한 본격적인 양자 계산의 강자이며, 손바닥에 들어맞는 크기로 실내 온도에서 작동합니다. 저기, 희석 냉동고야, 너도 이거 같아라!\n\n![이미지](/assets/img/2024-06-30-QuantumComputingonArduino_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금, 아마 “그런데 구글의 Sycamore 프로세서는 53큐빗을 가지고 있지 않나요? IBM의 최신 양자 컴퓨터는 433큐빗을 자랑하지 않나요?” 라고 생각하실 수도 있습니다. 물론, 만약에 기술적으로 모든 것에 대해 깊이 이해하고 싶다면 말이죠. 하지만 여기 한 가지 묻고 싶은 게 있어요: 그들의 양자 컴퓨터가 LED를 깜박일 수 있나요? 제 생각에는 안 될 것 같네요.\n\n우리의 활기찬 아두이노 양자 에뮬레이터는 여러분이 즐겨 사용하는 모든 양자 게이트를 지원해요: Hadamard, CNOT, X, Y, S, T 그리고 Z. 심지어 GHZ 상태를 “양자 얽힘” 이라고 매우 느리게 말할 때보다 빠르게 준비할 수 있답니다.\n\n```js\nH(0);  \nfor(int i = 0; i \u003c NUM_QUBITS - 1; i++) {\n  CX(i,i+1);\n}\n```\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1000/0*U2A8oH-Ril25vd52.gif\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장 멋진 부분은 뭘까요? 다른 양자 컴퓨터들은 박사 학위를 가진 물리학자 팀이 운영해야하는 반면, 우리의 아두이노 양자 에뮬레이터는 C++의 기본 이해와 실제 양자 역학에 대한 완전한 무관심만 있으면 누구나 프로그래밍할 수 있습니다.\n\n그치만, 더할 나위 없이 좋은 소식이 있습니다! 다른 양자 컴퓨터들과 달리, 외부 간섭으로부터 격리되어야 하는 다른 양자 컴퓨터와 달리, 우리의 아두이노 양자 컴퓨터는 잡음을 필요로 합니다. 사실, 그것은 연결되지 않은 핀에서 발생하는 아날로그 잡음을 사용하여 난수 생성기를 시작합니다. 이것은 결함이 아니라 기능입니다!\n\n```js\nrandomSeed(analogRead(0));\n```\n\n지금, 여러분이 생각할 수 있는 것을 알아요. \"이것은 혁명적이네요! 비용은 얼마나 드나요?\" 잘 준비되세요. 다른 양자 컴퓨터가 수백만 달러에 이르는 반면, 여러분은 저렴한 가격으로 이 양자 파워하우스를 약 25달러(또는 더 저렴한 Elegoo 포함 시 10달러)에 제작할 수 있습니다. 네, 좋은 식사 비용으로 양자 컴퓨팅 혁명에 함께 참여할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약하자면, 다른 연구자들이 대수적으로 큰 숫자를 인수분해하거나 복잡한 양자 시스템을 시뮬레이션하는 등의 사소한 문제에 시간을 낭비하는 도중에 우리는 여기서 5볼트로 동작하는 LED를 중첩시킬 것입니다. 양자 컴퓨팅의 미래는 이미 여기에 있고, 그것은 5볼트로 운영됩니다.\n\n코드는 오픈 소스이며 아파치 라이선스(https://github.com/)하에 제공됩니다.\n\n또한 내 커모도어64 양자 에뮬레이터도 확인해보세요.\n\n면책사항: 이 양자 에뮬레이터는 실제로 클래식 컴퓨터보다 빠르게 어떤 실제 세계 문제를 해결할 수 없을 수도 있습니다. 그러나, 다른 대부분의 양자 컴퓨터도 여전히 그렇지 않으니 걱정하지 마세요!","ogImage":{"url":"/assets/img/2024-06-30-QuantumComputingonArduino_0.png"},"coverImage":"/assets/img/2024-06-30-QuantumComputingonArduino_0.png","tag":["Tech"],"readingTime":2},{"title":"배 만들기 - VI 제6편","description":"","date":"2024-06-30 19:02","slug":"2024-06-30-BuildingaShipVI","content":"\n\n우리가 선체를 건설하기로 한 모델은 CA Thayer입니다. 여기에서 선도도와 오프셋 표를 찾을 수 있습니다. 이 페이지에서 발표 자료를 찾을 수 있습니다. 2, 3, 4페이지의 슬라이드를 살펴보세요. 편한 포맷으로 다운로드하세요. 이 세 가지 자료는 선체를 건설하는 데 필요하지만, 나머지 자료도 유용할 수 있습니다(만약 전체 선박을 건설할 계획이 있다면). 이미지를 출력하고, 2와 3번 이미지를 가운데에서 합치세요(수직적인 간격 없이 - 아래 참조).\n\n![이미지1](/assets/img/2024-06-30-BuildingaShipVI_0.png)\n![이미지2](/assets/img/2024-06-30-BuildingaShipVI_1.png)\n\n이렇게 합치세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-30-BuildingaShipVI_2.png\" /\u003e\n\n[팁: 이 작업은 두 이미지를 인쇄하면 훨씬 쉬워집니다. 또한 인쇄하면 물리적인 계획을 확인할 수 있습니다]. 이제 이 컬렉션에 stationlines 플롯 + 오프셋 테이블을 추가하고 시작할 수 있습니다. 오프셋 테이블을 (물론 수동으로) Excel과 같은 편집 가능 / 조작 가능한 형식으로 복사하세요. 추가 단계와 스케일링에 대한 가치 있는 자료가 될 것입니다.\n\n\u003cimg src=\"/assets/img/2024-06-30-BuildingaShipVI_3.png\" /\u003e\n\nFigure 4에 있는 오프셋 테이블에 주의를 기울이면: 최상단 행 (STATIONS로 레이블이 지정됨)은 앞부터 뒤로의 스테이션 라인 번호를 매깁니다. 가장 왼쪽 열은 킬(kiel)로부터의 워터라인의 높이를 나타냅니다. Figure 3에 제시된 프로필에서 배를 보면, 선체가 X-Z 평면(화면이 X-Z 평면인)의 X축을 따라 배치됩니다. 이 경우, 선체는 Y축으로 돌출됩니다(화면 평면 내부와 외부로). 이를 염두에 둔 채로 오프셋 테이블을 살펴보세요. 각 행은 Z값에 해당합니다. 각 열은 X값에 해당합니다. 각 셀의 숫자는 피트-인치-8분의 1인치 (17-5-2는 17ft + 5인치 + 2/8 또는 1/4인치를 의미)의 Y 오프셋(돌출)입니다. 모형 제작 목적으로는 피트-인치 숫자만 채용해도 충분합니다. 세 번째 숫자가 4라면 인치를 하나 더 올립니다(또는 하지 않고 완전히 무시합니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 내가 만든 엑셀 시트로 갑니다. 다섯 개의 숫자 그룹이 있습니다 - 즉, 서투르게 서식이 되어 있는 다섯 개의 테이블이 있습니다. 첫 번째 테이블은 소수점을 건너뛰고 오프셋 테이블의 복사본입니다. 두 번째는 피트만, 그리고 세 번째는 인치만 포함합니다. 네 번째는 사실상 Y 오프셋이 센티미터로 변환된 것입니다 [저는 인도인이고 메트릭 시스템으로 일하기 때문에요].\n\n마지막은 우리가 스케일을 설정하는 곳입니다. 그 전에 선체의 총 길이를 결정해야 합니다. 제 경우에는 600mm(60cm / 약 2ft)를 선택했습니다. 당신의 배의 총 길이가 M 센티미터이고, 선체의 최종 크기가 N 센티미터인 경우 [제 경우, N = 60], 스케일링 인자 = N / M 입니다. 예를 들면:\n\n선체 길이 (M) = 54 미터\n\n모형 선체의 최종 길이 (N) = 60 센티미터\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**스케일 요소 (SF) = N / M = 0.6 / 50 = 0.012 (12 / 100)**\n\n원본 크기에서 거리(d)가 60cm이라면, 모형에서의 거리는 d x SF로 계산됩니다. 60 x 12 / 100 = 7.2cm이 됩니다.\n\n**테이블 5 단계 1:** 테이블 4에서 모든 값을 선호하는 전체 선체 길이로 줄여주세요.\n\n**테이블 5 단계 2:** 동일한 변환 + 스케일링 요소를 사용하여 Z 값을 모형의 cm로 변환해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5번 테이블의 3단계: X축 값을 추론합니다. 이를 위해 먼저 선 데칼을 측정합니다. 이전 단계(2)에서 계산한 원래 높이가 있습니다. 모델의 인쇄된 길이를 Z 높이로 변경한 다음, 원하는 길이에 도달하도록 두 번째 스케일링을 수행합니다. 예를 들어, 출력물의 높이가 5cm이고 원래 높이가 약 20 ft (600cm)이면, 각 cm이 약 4ft (120 cm)이 되고, 각 mm이 원본에서 12cm임을 알 수 있습니다. 다음으로 역으로 변환하고자 하는 원래 길이를 cm 단위로 표시하는 역염 단면 사이 간격을 측정합니다. 이것이 X축을 따라 이동하는 거리/길이입니다. 위에서 계산된 스케일 인수를 사용하여 이 원래 길이에서 원하는 길이로의 두 번째 변환/스케일링을 수행합니다(Y축에 대한). 참조된 엑셀 시트의 5번 테이블에는 이러한 모든 계산이 이미 수행되어 있습니다. 그러나 정밀도와 신뢰의 성향에 따라 직접 수학을 해야 합니다.\n\n이것은 작업의 역량 부분입니다. 다음은 키를 설치합니다(VII부).\n\n그때까지 안녕!","ogImage":{"url":"/assets/img/2024-06-30-BuildingaShipVI_0.png"},"coverImage":"/assets/img/2024-06-30-BuildingaShipVI_0.png","tag":["Tech"],"readingTime":3},{"title":"API로 전기 사용량 추적하는 방법","description":"","date":"2024-06-30 19:01","slug":"2024-06-30-TrackingelectricityusagethroughanAPI","content":"\n\nTL;DR: 코드로 건너뛰려면 여기를 클릭하세요.\n\n몇 년 전, 에너지 위기 기간 동안 전기 사용량을 보고하기 위해 추적기를 만들어서 내 사용 습관을 더 잘 이해하고 낭비를 줄일 수 있기를 희망했습니다. 당시 공급업체인 EON이 설치한 스마트 미터가 정확한 통계를 IHD(인 홈 디바이스)로 보내지만 그 정보들은 항상 켜져 있는 디스플레이 안으로 갇혀 있었어요. 이 정도만으로는 충분하지 않았죠.\n\n영국 전체 주택에 스마트 미터를 설치하는 노력은 절대 영향력을 제로화하는 목표의 일환입니다. 스마트 미터는 소비자들이 사용량을 더 잘 인식하도록 돕고, 필요 없는 것을 끄는 것을 장려하여 전력(그리고 돈!)을 절약할 수 있도록 돕습니다. 보는 것과 측정하는 것을 통제하는 것이 훨씬 쉽습니다. 데이터 통신 회사(DCC)의 등장입니다.\n\n요약하면, DCC는 스마트 미터를 에너지 공급업체에 연결하여 특정 간격(일반적으로 매 30분마다)에 사용된 에너지 양을 추적합니다. 이 데이터는 대규모 에너지 공급업체에게 제공되지만 중개업체들을 통해 광범위하게 공개되며, 그 가운데 하나인 glowmarkt가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n글로마켓의 Bright 앱을 사용하면 DCC에 연결하여 미터 데이터를 다운로드할 수 있습니다. 이 과정은 앱을 다운로드하고 스마트 미터 일련 번호와 소유권 증명을 제공하는 것만큼 쉽습니다 (이 데이터를 아무나에게 제공할 수는 없습니다).\n\n등록은 몇 영업일이 걸릴 수 있지만, 등록되면 앱을 통해 미터가 캡처한 세부 정보를 볼 수 있습니다(보통 30분마다). 이것은 정말 좋습니다. 이제 우리는 IHD에서 볼 수 있는 것과 동일한 데이터에 폰에서 액세스할 수 있습니다. 한 걸음 더 나아가서 API에서 직접 원시 데이터를 가져올 수도 있습니다.\n\n# Bright API\n\n여기에 Postman 컬렉션이 있습니다. 아래에서 Postman을 통한 호출 방법과 타입스크립트 애플리케이션 일부를 자동화하는 방법을 보여드리겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 인증하기\n\n먼저 정적 bright 애플리케이션 id를 사용하여 사용자 이름/비밀번호로 인증하려면 https://api.glowmarkt.com/api/v0-1/auth 로 POST를 통해 인증합니다.\n\n![이미지](/assets/img/2024-06-30-TrackingelectricityusagethroughanAPI_0.png)\n\n```js\nasync function getLoginToken() {\n  const body = {\n    \"username\": process.env.BRIGHT_USERNAME,\n    \"password\": process.env.BRIGHT_PASSWORD,\n    \"applicationId\": \"b0f1b774-a586-4f72-9edd-27ead8aa7a8d\"\n  }\n\n  const res = await fetch('https://api.glowmarkt.com/api/v0-1/auth', {\n    method: 'POST',\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(body)\n  })\n\n  if (res.status !== 200) {\n    throw new Error(`인증에서 200을 기대했으나 ${res.status}을 받음`)\n  }\n\n  const json = await res.json()\n  return json.token\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가상 엔티티 가져오기\n\n접근 토큰을 사용하여 가상 엔티티를 요청하려면 https://api.glowmarkt.com/api/v0-1/virtualentity/ 로 GET을 보내세요.\n\n![이미지](/assets/img/2024-06-30-TrackingelectricityusagethroughanAPI_1.png)\n\n```js\nasync function getVirtualEntities(token: string) {\n  const res = await fetch('https://api.glowmarkt.com/api/v0-1/virtualentity/', {\n    headers: {\n      token,\n      applicationId: 'b0f1b774-a586-4f72-9edd-27ead8aa7a8d'\n    }\n  })\n\n  if (res.status !== 200) {\n    throw new Error(`GET VEs에서 200을 기대했지만, ${res.status}를 받았습니다`)\n  }\n\n  const json: VirtualEntitiesResponse = await res.json()\n  return json\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 응답에서는 각 연료 유형을 나타내는 여러 Virtual Entities를 볼 수 있습니다(예: 가스 및 전기), 그리고 태양열판이나 배터리 등이 있는 경우 수출 미터가 포함될 수도 있습니다. 이 예제에서는 \"전기 소비\"에 관심이 있습니다. resourceId를 가져와서 소비를 조회해 보겠습니다.\n\n## 소비 조회\n\n쿼리 매개변수를 사용하여 세밀도와 시간 범위를 정의한 상태에서 https://api.glowmarkt.com/api/v0-1/resource/`id`/readings 로 GET을 수행하십시오. 예를 들어, 2023년 1월 1일부터 2023년 1월 7일까지 30분 간격으로 조회하려면 다음과 같이 호출하면 됩니다.\n\n```js\nGET https://api.glowmarkt.com/api/v0-1/resource/447c88f4-c99d-44c4-9f1d-03a767b084a6/readings?period=PT30M\u0026function=sum\u0026from=2023-01-01T00:00:00\u0026to=2023-01-07T23:59:59\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nasync function getThirtyMinuteIntervalUsage(token: string, resourceId: string, from: Date, to: Date) {\n  const fromStr = dateToApiFormat(from)\n  const toStr = dateToApiFormat(to)\n  const res = await fetch(`https://api.glowmarkt.com/api/v0-1/resource/${resourceId}/readings?period=PT30M\u0026function=sum\u0026from=${fromStr}\u0026to=${toStr}`, {\n    headers: {\n      token,\n      applicationId: 'b0f1b774-a586-4f72-9edd-27ead8aa7a8d'\n    }\n  })\n\n  if (res.status !== 200) {\n    throw new Error(`Expected 200 from GET Readings. Got ${res.status}`)\n  }\n\n  return await res.json() as ResourceReadingsResponse\n}\n\nfunction dateToApiFormat(date: Date) {\n  const pad = (num: number) =\u003e num.toString().padStart(2, '0')\n  return `${date.getFullYear()}-${pad(date.getMonth() + 1)}-${pad(date.getDate())}T${pad(date.getHours())}:${pad(date.getMinutes())}:${pad(date.getSeconds())}`\n}\n\nasync function getCompleteHistoryReadings(token: string, resourceId: string, earliestTime = 0) {\n  const startTo = new Date(Date.now() + (1000 * 60))\n  const readingsByTime: Record\u003cnumber, number\u003e = {}\n\n  let i = 0\n  while (true) {\n    const to = new Date(startTo.getTime() - ((MILLI_IN_DAY * 10) * i++))\n    const from = new Date(to.getTime() - (MILLI_IN_DAY * 10) - 1)\n    const response = await getThirtyMinuteIntervalUsage(token, resourceId, from, to)\n\n    // If ALL readings are 0 then either we haven't used anything for 10 days or we're out of data\n    if (!response.data.some(o =\u003e o[1] \u003e 0)) {\n      return readingsByTime\n    }\n\n    // Should already be sorted in response - but for sanity sake\n    response.data.sort((a, b) =\u003e a[0] \u003e b[0] ? -1 : 1)\n\n    for (const [epoch, kwh] of response.data) {\n      readingsByTime[epoch] = kwh\n\n      if (epoch \u003c earliestTime) {\n        return readingsByTime\n      }\n    }\n  }\n}\n\n// Tie it altogether\nexport async function getMeterReadings(since?: number) {\n  const token = await getLoginToken()\n  const entities = await getVirtualEntities(token)\n  const resource = entities[1].resources.find(o =\u003e o.name === \"electricity consumption\")\n\n  if (!resource) {\n    throw new Error('Failed to find electricity consumption resource')\n  }\n\n  return await getCompleteHistoryReadings(token, resource?.resourceId, since ? (since / 1000) || 0 : 0)\n}\n```\n\nWe get an array of arrays representing the start time of that period and its usage. In the above screenshot, I used 0 kWh between 12am — 1am and then 0.211 kWh between 1:30am — 2:00am. In the TypeScript code, we are converting this array of arrays to a key/value object by time.\n\n## Using this data\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 Discord에서의 일일 사용량을 멋지게 포맷된 그래프로 보고하고 있어요.\n\n![이미지](/assets/img/2024-06-30-TrackingelectricityusagethroughanAPI_3.png)\n\n저는 Octopus의 Agile 요금제를 사용하고 있어요. 이 요금제는 30분마다 변경되는 가격을 가지고 있어요. 이 가격을 30분 단위 사용량에 매핑하여 하루 내내 전기 요금이 얼마나 드는지 정확하게 파악할 수 있어요. 이를 통해 Agile 요금제가 가격 상한선보다 돈을 절약하는지 추적하고 평가하고 있어요. 에너지 위기 때는 가격 상한선이 33펜스였던 때가 참으로 그랬지만 시간이 지남에 따라 그렇지 않아지고 있어요. 여기서 봇이 얼마나 절약하거나 손해를 봤는지, 그리고 예상 월간 비용을 알려줘요.\n\n![이미지](/assets/img/2024-06-30-TrackingelectricityusagethroughanAPI_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\nDCC를 통해 데이터에 쉽게 접근할 수 있어서 투명성이 증대되고 소비자가 에너지 사용을 이해하고 제어하는데 더 많은 권한을 부여받습니다. 아마도 여러분에게 자신의 데이터를 얻는 것이 얼마나 쉬운지 보여줬을 텐데요. 사용 가능한 데이터로 무엇이 더 가능한지에 대해 많이 할 수 있습니다. 향후 포스트에서 이에 대해 더 탐구할 예정입니다. 이제 멋진 것을 만들러 가세요!","ogImage":{"url":"/assets/img/2024-06-30-TrackingelectricityusagethroughanAPI_0.png"},"coverImage":"/assets/img/2024-06-30-TrackingelectricityusagethroughanAPI_0.png","tag":["Tech"],"readingTime":7},{"title":"비트코인에서 중요한 변화 2024년 최신 업데이트 분석","description":"","date":"2024-06-30 19:00","slug":"2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN","content":"\n\n2024년에 대단한 성과를 거둘 암호 프로젝트에 대해 모두가 이야기하고 있어요. 하지만 우리의 데이터에 따르면 매우 중요한 변화가 일어났답니다. 맞아요, 10월에 저점을 부를 때부터 엄청난 수익을 봤지만, 이제 앞으로 나타날 큰 추악한 진실이 있어요. 우리는 이 패턴을 이전에도 본 적이 있어요.\n\n그래서 이 비디오에서는 그 패턴에 대해 자세히 살펴보고 추악한 진실을 밝혀내어 그게 위험할 수 있는지 확인해 볼 거예요.\n\n또한, 현재 대부분의 암호 트레이더들이 활용하지 않는 것에 대해 이야기할 거예요. 그런 다음 저는 이번 주 SimpleFX에서 벌어들인 수 pass받는 임을 업데이트하고 구매한 암호통화에 대해 얘기할 거예요. 이것은 내 돈을 두 배 이상 벌어들일 것으로 기대하고 있어요.\n\n만약 도와주시면 끝까지 따라와 주신다면, 매우 적은 금액으로 시작하여 놀라운 것으로 성장시킨 영감을 주는 이야기가 있는데요. 안녕하세요, 다시 오신 것을 환영합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 이름은 디지털화폐거래자 매체의 더그입니다. 이 매체에서는 암호화폐에 관해 글을 쓰면서 돈을 벌 수 있어요.\n\n여기서 12시간 차트를 보면 거의 그대로 유지되고 있어요. 4시간 차트로 확대해 보면 여전히 매우 좁은 범위에 머물고 있어요. 이번에는 지난 업데이트 때보다 조금 더 자세히 살펴볼게요. 고래 거래는 지금 가격에 매우 가까워요. 어떤 움직임이든 의심스러울 수 있어요; 어느 방향으로의 이탈인 척할 수도 있어요. 1시간 차트도 마찬가지에요. 움직임이 계속적으로 발생하며, 큰 포지션을 취하기가 정말 속이 상해요.\n\n긴 시간 차트로 이동해서 비트코인이 123 탑 형성을 크로스해 온 것을 볼 수 있어야 해요.\n\n![중요한비트코인변화](/assets/img/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 우리 상슨 추세선을 돌파했고, 그것은 주관적입니다 — 어디서 추세선을 그리고 싶은지에 따라 달라집니다. 4시간 봉의 EMA가 교차했으므로, 우리는 매매 상태가 다가오고 있다는 것을 알 수 있어요.\n\n미국 달러 지수를 살펴보고 싶어요. 왜냐하면 미국 달러 지수가 여기서 상승한다면, 금, 은, 비트코인 가격이 내려가게 될거거든요.\n\nDXY의 Bollinger Bands를 살펴보면 이 평행 채널을 탈출했음을 볼 수 있어요. 굉장히 중요한 부분이에요. 그래서, 더욱 가까운 시간대로 확대하여 살펴보고 싶어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n15분 타임 프레임으로 들어가면 상승 트렌드 선이 하나, 두 개, 세 개의 정점 형성을 뚫는 것을 볼 수 있어요. 여기서 수평선을 그린다는 생각이 들어요. 이 수평선으로부터 확대해서 이 레벨이 얼마나 중요할지 보고 싶어요. 12시간 타임 프레임으로 돌아오면, 이 레벨이 역사 전반에 걸쳐 중요함을 볼 수 있어요.\n\n하지만, 주간 타임 프레임으로 돌아가면, 이 레벨이 더 중요하다는 것을 알 수 있어요. 역사적 레벨을 통해 보면, 이 달러 인덱스 레벨이 15분 타임 프레임에서 하나, 두 개, 세 개의 정점 형성 중인 지금 매우 중요하다는 것을 볼 수 있어요.\n\n즉, 이 레벨을 넘어선다면, 무시할 수 없어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이 수준에서 튕기고 123 패턴 하방으로 돌파하면, 미 달러 지수가 정말로 약화하기 시작하는 순간일 수 있고, 비트코인이 이곳에 자리를 유지할 것이라고 예상할 수 있습니다.\n\n금과 은이 자리를 유지하고 이곳에서 상승을 시작할 것으로 예상됩니다. 그래서, 지금은 비트코인과 달러 지수에 대해 살펴볼 시간입니다. 이것이 확대된 시간대입니다.\n\n그런데 이제 알트 시즌의 상황에 대해 알아보겠습니다. 알트 시즌은 매우 적은 트레이더가 이용하고 있는 것이기 때문입니다.\n\n비트코인 지배력을 들여다보는 이 데이터는 지금 정말 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 데이터를 통해 가짜 상승이 어디에서 발생했는지 식별할 수 있습니다. 알림 상태 코인의 수가 급증하고 홀드 상태 코인의 수가 따라오지 않는 상황이죠. 어떤 코인이 강세를 유지하고 있는지, 어떤 코인이 그렇지 않은지 정확히 파악하는 것은 돈을 보호하느냐, 잃느냐의 차이를 만들어냅니다. \n\n이러한 데이터는 이른 상승 현상에 속지 않도록 도와주고 동시에 그에 대한 조치를 취할 수 있도록 도와줍니다. \n\nAlex Hormozi가 수익의 장밋빛 분포에 대해 가르치듯이 대담해지고 다양성을 유지하는 것이 중요합니다. 대박을 친 승자들이 다양한 실험을 지원해주기 때문이죠.\n\n그러니 알림 상태를 만나면 포지션을 취하는 것이 중요하지만, 리스크 관리도 중요합니다. 그렇지 않으면 계속 보유하고만 있을 뿐입니다.\n\n그럼 이제 비디오의 수익 창출 부분으로 넘어가서, 이번 주 SimpleFX로부터 얼마의 패시브 소득을 올렸는지에 대해 이야기해보도록 하죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 표를 마크다운 형식으로 변경했어요.\n\n25달러의 수익을 올렸고, 대부분의 돈을 도지코인에 투자했어요. 매주 발생하는 수입으로 다른 암호화폐를 구입할 수 있다는 것을 깨달았을 때, 와우! 지금까지 98개의 도지코인을 모았어요. 이건 거의 천연가스 계약 하나를 제어할 수 있는 양이에요.\n\n이 정말 멋있고, 거래를 하지 않더라도 사랑합니다. 도지코인을 그냥 보유하는 것만으로 돈을 10배 이상 벌 수 있을 거라고 생각해요.\n\n그래서 이번 주에 벌어들인 그 작은 금액은, 내가 보유 중인 암호화폐 덕분에 정말로 크게 성장시킬 수 있을 것 같아요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비디오 시작할 때 너에게 말했던 대로, 매우 작은 돈으로 시작하는 사람들에게 영감을 주는 것이 있어.\n\n장기적으로 볼 때, 나는 2016년에 한 실험을 보여줄게. 그 해, 나는 수도꼭지 플랫폼 계정을 가지고 다양한 수도꼭지를 방문하여 Bitcoin을 모아 다른 암호화폐를 사고 그에 대한 영상을 제작했어.\n\n그 후, 이 포트폴리오를 설정하고 잊어버렸어. 이것은 실제 포트폴리오가 아니고, 데이터를 수동으로 입력한 것일 뿐이야. 그리고 그대로 두었더니, 이제 이 값은 47,00을 기록했어. 나는 $600 미만을 투자했는데, 실제로 최고점에서 $91,000까지 올랐었어. 그래서, 네가 주의를 기울이고 작은 금액을 투자하며 상승 패턴을 따르고 적절히 나올 때 나오면, 이것은 나에게 정말 영감적이야.\n\n얼마나 빨리 백만장자가 될 수 있는지에 대한 글을 썼어.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 Medium 프로필 맨 위에 있으니 찾아보세요. 많은 클랩을 받고 있어요. 어떻게 백만장자가 될 수 있는지 수학적으로 보여줘요. $1,000으로 시작해서 매년 딱 한 번씩 2배씩 했다면, 10년 안에 백만장자가 되고 $1,000을 투자한 게 전부였어요.\n\n그래서 이 예시를 보고, 수익을 얻고 다시 투자하면, 짧은 기간에 얼마나 많은 돈을 벌 수 있는지 알 수 있다고 생각해요.\n\n재정적으로 독립할 수 있을 거에요.\n\n![이미지](/assets/img/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 여기서 비디오를 마무리 짓겠습니다. 함께 해 주셔서 정말 감사합니다; 흥미로운 것이나 유익한 정보를 발견했으면 좋겠어요. 댓글로 의견을 꼭 남겨주세요.\n\n![이미지](/assets/img/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN_5.png)\n\n안전한 거래를 유지하고 손실을 최소화하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN_6.png)","ogImage":{"url":"/assets/img/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN_0.png"},"coverImage":"/assets/img/2024-06-30-SomethingIMPORTANThasCHANGEDinBITCOIN_0.png","tag":["Tech"],"readingTime":4}],"page":"3","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"3"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>