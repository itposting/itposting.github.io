<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/11" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/11" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="파이썬으로 감성 분석 모델 만드는 방법" href="/post/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이썬으로 감성 분석 모델 만드는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이썬으로 감성 분석 모델 만드는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">파이썬으로 감성 분석 모델 만드는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="경량 GPU를 위한 실시간 고정확도 객체 탐지  YOLO-ReT 상세 리뷰" href="/post/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="경량 GPU를 위한 실시간 고정확도 객체 탐지  YOLO-ReT 상세 리뷰" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="경량 GPU를 위한 실시간 고정확도 객체 탐지  YOLO-ReT 상세 리뷰" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">경량 GPU를 위한 실시간 고정확도 객체 탐지  YOLO-ReT 상세 리뷰</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AVP의 GrayMatter Robotics 투자에 대해 알아야 할 5가지 사항" href="/post/2024-06-23-AVPsInvestmentinGrayMatterRobotics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AVP의 GrayMatter Robotics 투자에 대해 알아야 할 5가지 사항" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-AVPsInvestmentinGrayMatterRobotics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AVP의 GrayMatter Robotics 투자에 대해 알아야 할 5가지 사항" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AVP의 GrayMatter Robotics 투자에 대해 알아야 할 5가지 사항</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="차동 구동 로봇을 위한 Wheel Odometry 모델 분석" href="/post/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="차동 구동 로봇을 위한 Wheel Odometry 모델 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="차동 구동 로봇을 위한 Wheel Odometry 모델 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">차동 구동 로봇을 위한 Wheel Odometry 모델 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">16<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="로봇 공학 적용의 시대" href="/post/2024-06-23-Theageofappliedrobotics"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="로봇 공학 적용의 시대" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-Theageofappliedrobotics_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="로봇 공학 적용의 시대" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">로봇 공학 적용의 시대</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="소설에서 영화까지 블레이드 러너의 모든 것" href="/post/2024-06-23-BooktoLifeBladeRunner"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="소설에서 영화까지 블레이드 러너의 모든 것" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-BooktoLifeBladeRunner_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="소설에서 영화까지 블레이드 러너의 모든 것" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">소설에서 영화까지 블레이드 러너의 모든 것</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Gradient Descent 알고리즘과 맞춤형 웨이포인트로 AWS DeepRacer 성능 향상시키는 방법" href="/post/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Gradient Descent 알고리즘과 맞춤형 웨이포인트로 AWS DeepRacer 성능 향상시키는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Gradient Descent 알고리즘과 맞춤형 웨이포인트로 AWS DeepRacer 성능 향상시키는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Gradient Descent 알고리즘과 맞춤형 웨이포인트로 AWS DeepRacer 성능 향상시키는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파스칼의 삼각형을 간단하고 빠르게 이해하는 방법" href="/post/2024-06-23-AShortandDirectWalkwithPascalsTriangle"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파스칼의 삼각형을 간단하고 빠르게 이해하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-AShortandDirectWalkwithPascalsTriangle_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파스칼의 삼각형을 간단하고 빠르게 이해하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">파스칼의 삼각형을 간단하고 빠르게 이해하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="애플의 부활부터 교황의 봇에 대한 생각까지 기술과 AI의 현재 트렌드 분석" href="/post/2024-06-23-FromApplesRevivaltothePopesThoughtsonBots"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="애플의 부활부터 교황의 봇에 대한 생각까지 기술과 AI의 현재 트렌드 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-FromApplesRevivaltothePopesThoughtsonBots_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="애플의 부활부터 교황의 봇에 대한 생각까지 기술과 AI의 현재 트렌드 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">애플의 부활부터 교황의 봇에 대한 생각까지 기술과 AI의 현재 트렌드 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="28살에 수학 배우기" href="/post/2024-06-23-Learningmathat28"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="28살에 수학 배우기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-Learningmathat28_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="28살에 수학 배우기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">28살에 수학 배우기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link posts_-active__YVJEi" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"파이썬으로 감성 분석 모델 만드는 방법","description":"","date":"2024-06-23 18:40","slug":"2024-06-23-HowtoCreateaSentimentAnalysisModelinPython","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_0.png\" /\u003e\n\n이 글에서는 예측 분석의 영역에 대해 탐구하며, COT 보고서에서 제공되는 다양한 통찰력을 활용하여 기계 학습 모델의 기능을 향상시킬 수 있는 방법을 살펴봅니다. 트레이더 포지션 내의 패턴을 해석함으로써, 우리는 금융 세계에서 더 정확하고 데이터 기반의 의사 결정을 내릴 수 있는 잠재력을 발견할 수 있습니다.\n\n# KNN 알고리즘과 COT 보고서 소개\n\nK-Nearest Neighbors (KNN)은 분류 및 회귀 작업에 모두 사용되는 간단하고 직관적인 기계 학습 알고리즘입니다. 하지만 먼저, 분류와 회귀가 무엇을 의미하는지 알아야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 분류(Classification)는 지도 학습의 한 유형으로, 데이터 포인트를 미리 정의된 클래스나 레이블로 분류하는 것을 목표로 합니다. 분류에서 모델은 입력의 특징에 기반하여 클래스나 범주를 지정하는 방법을 학습합니다. 분류의 출력은 이산적이며 범주나 클래스 레이블을 나타냅니다. 예를 들어, 이메일을 스팸 또는 비스팸으로 분류하는 것입니다.\n- 반면에 회귀(Regression)는 지도 학습의 한 유형으로, 연속적인 수치 값을 예측하는 것을 목표로 합니다. 회귀에서 모델은 입력 특징과 출력 간의 관계를 수립하는 것을 학습하며, 출력은 연속적인 범위의 값이며 양이나 수치 값을 나타냅니다. 예를 들어, 집의 가격을 예측하거나 주가를 예측하는 것입니다.\n\nKNN은 게으른 학습(lazy learning)의 한 유형으로, 훈련 중에 모델을 구축하지 않고 대신 전체 훈련 데이터 집합을 기억하고 새 데이터 포인트와 기존 데이터 포인트 간의 유사성을 바탕으로 예측합니다.\n\n그래서 KNN의 핵심 아이디어는 유사한 특징을 가진 객체(데이터 포인트)이 특징 공간에서 서로 가깝다는 것입니다. KNN은 특징 공간에서 특정 테스트 데이터 포인트와 가장 가까운 K개의 훈련 예제를 찾아서 그 주변 이웃들의 레이블이나 값에 따라 테스트 포인트에 레이블이나 값을 할당합니다. 이는 K가 훈련 단계에서 조절할 수 있는 변수라는 것을 의미합니다.\n\n다음 그림을 살펴보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_1.png\" /\u003e\n\n두 가지 클래스가 있습니다. 클래스 A(바나나)와 클래스 B(사과)입니다. 우리는 파란색 물체의 클래스(또는 레이블)를 식별하려고 합니다. 가장 가까운 이웃은 바나나로 보이기 때문에 클래스 A입니다. 이것이 KNN 알고리즘의 작동 방식입니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_2.png\" /\u003e\n\nKNN은 회귀 작업에도 사용될 수 있습니다. KNN 회귀에서 목표는 새로운 데이터 포인트의 연속 값을 예측하는 것입니다. 이 값은 이웃 K개의 값에 기반하여 예측됩니다. KNN 회귀의 단계는 KNN 분류와 유사하지만 클래스 레이블을 세는 대신, K개 이웃의 대상 값들의 평균 또는 가중 평균을 계산하여 테스트 포인트의 값을 예측합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n커밋먼츠 오브 트레이더스(COT) 보고서는 미국 상품 선물 거래위원회(CFTC)가 매주 발간하는 보고서로, 선물 시장의 다양한 참여자들의 포지션에 대한 통찰을 제공합니다. 이러한 참여자들에는 상업 헤지거들, 대형 투기자들, 그리고 소규모 거래자들이 포함됩니다.\n\n보고서는 이러한 그룹들의 순 포지션을 보여주어 그들이 상승을 기대하고 있는지(매수 포지션) 또는 하락을 예상하고 있는지(매도 포지션)를 나타냅니다. 순 COT 값은 각 그룹의 총 매수 및 매도 포지션의 차이를 통해 계산됩니다.\n\n순 COT 값을 분석하면 잠재적인 미래 가격 움직임에 대한 어떤 단서를 제공할 수 있습니다. 예를 들어, 대형 투기자들이 상당히 많은 순 매수 포지션을 보유하고 있다면 시장에서 매수 센티먼트가 있다는 것을 시사할 수 있습니다. 그러나 다른 요소들을 고려하고 COT 보고서를 예측의 여러 도구 중 하나로 활용하는 것이 중요합니다. 트렌드는 변할 수 있고, 시장 역학은 COT 데이터 이상의 다양한 요인에 영향을 받습니다.\n\n간단히 말하면, COT 보고서는 시장에서 어떤 그룹들의 거래자들이 어떻게 베팅을 하고 있는지 요약해줍니다. 그들의 포지션에 주목할 만한 변화가 있다면, 시장 트렌드의 가능성 있는 변화를 나타낼 수 있습니다. 그러나 이것이 마법구슬은 아니며, 더 포괄적인 분석을 위해 다른 요소들을 고려해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Sentiment Analysis Model in Python](/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_3.png)\n\nIf you want to see more of my work, you can visit my website for the books catalogue by simply following the link attached the picture:\n\n![Books Catalogue](/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_4.png)\n\n# Creating the Algorithm\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nKNN 회귀 예제 코드를 시도해봅시다. 주요 작업은 GBP의 순 COT 값 변화를 예측하는 것입니다. 아래 코드를 사용하여 작업을 수행해보세요:\n\n```js\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsRegressor\n\ndata = pd.read_excel('COT_GBP.xlsx')\ndata = np.reshape(np.array(data), (-1))\ndata = np.diff(data)\n\ndef data_preprocessing(data, num_lags, train_test_split):\n    # 훈련용 데이터 준비\n    x = []\n    y = []\n    for i in range(len(data) - num_lags):\n        x.append(data[i:i + num_lags])\n        y.append(data[i + num_lags])\n    x = np.array(x)\n    y = np.array(y)\n\n    split_index = int(train_test_split * len(x))\n    x_train = x[:split_index]\n    y_train = y[:split_index]\n    x_test = x[split_index:]\n    y_test = y[split_index:]\n\n    return x_train, y_train, x_test, y_test\n\nnum_lags = 20\ntrain_test_split = 0.80\nx_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, 0.85)\n\nmodel = KNeighborsRegressor(n_neighbors=2)\nmodel.fit(x_train, y_train)\ny_pred = model.predict(x_test)\n\nplt.plot(y_pred[-100:], label='예측 데이터', linestyle='--', marker='.', color='red')\nplt.plot(y_test[-100:], label='실제 데이터', marker='.', alpha=0.7, color='blue')\nplt.legend()\nplt.grid()\nplt.axhline(y=0, color='black', linestyle='--')\nsame_sign_count = np.sum(np.sign(y_pred) == np.sign(y_test)) / len(y_test) * 100\nprint('일치율 =', same_sign_count, '%')\n```\n\nCFTC 웹사이트에서 COT GBP 데이터를 찾을 수 있습니다. 다음 차트는 실제 데이터와 예측 데이터를 비교한 것입니다:\n\nK 값이 2이고 입력값으로 20개의 래그 값을 사용한 알고리즘의 일치율(정확도)은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nHit Ratio =  67.92 %\n\n![Image](/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_5.png)\n","ogImage":{"url":"/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_0.png"},"coverImage":"/assets/img/2024-06-23-HowtoCreateaSentimentAnalysisModelinPython_0.png","tag":["Tech"],"readingTime":5},{"title":"경량 GPU를 위한 실시간 고정확도 객체 탐지  YOLO-ReT 상세 리뷰","description":"","date":"2024-06-23 18:39","slug":"2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs","content":"\n\n## YOLO-Ret, Jetson Nano 및 Jetson Xavier NX에서 실시간으로 작동하는 Jetson Xavier NGX\n\n- 최신 기술의 다양한 특징 규모 간의 결합적 연결 부족을 활용하여 새로운 다중 규모 특징 상호 작용을 제안합니다.\n- 또한 새로운 전이 학습 백본 절단도 제안됩니다.\n\n# 개요\n\n- YOLO-Ret\n- 결과\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1. YOLO-Ret\n\n![Image](/assets/img/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs_0.png)\n\n## 1.1. Raw Feature Collection and Redistribution (RFCR) Module\n\n- 기존의 다중 스케일 피처 상호 작용 방식은 한 번에 두 개의 인접한 피처 스케일에만 초점을 맞추고 있습니다.\n- 게다가 상하 방향의 반복 사용 시, 모델의 감지 정확도가 포화될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이러한 레이어에는 무거운 계산이나 매개변수가 포함되지 않지만, 각 특성 스케일의 모든 쌍 사이에 직접적인 링크를 가능하게 합니다.\n- YOLOv3 탐지 헤드에 3개의 출력 스케일이 있지만, RFCR은 네 가지 다른 백본 피처를 사용하여 모델 성능을 향상시킬 수 있는 보다 세분된 저수준 피처를 활용할 수 있습니다.\n\n## 1.2. 백본 Truncation\n\n![image](/assets/img/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs_1.png)\n\n- 실험에는 MobileNetV2 (×0.75 및 ×1.4) 및 EfficientNet-B3와 같이 3가지 일반적으로 사용되는 백본이 사용되며, 이들 백본은 다양한 블록으로 나뉩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 위의 도표 2에서 결과를 기반으로 하면, MobileNetV2 버전의 마지막 두 블록과 EfficientNet의 마지막 세 블록을 백본으로 채택할 때 잘려진다.\n\n## 2. 결과\n\n### 2.1. 제거 연구\n\n![도표 2](/assets/img/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 제안된 RFCR 모듈에는 추가로 ’shortcut’ 연결이 도입되었습니다. 이 추가된 ‘shortcut’은 백본의 더 얇은 레이어에서 비롯되어 정확성을 더 향상시키며, 정확한 탐지 작업에 대한 낮은 수준의 기능의 중요성을 강조합니다.\n\n## 2.2. SOTA 비교\n\n![이미지](/assets/img/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs_3.png)\n\n- 모델은 Jetson Nano, Jetson Xavier NX, Jetson Xavier NGX에 배포됩니다.","ogImage":{"url":"/assets/img/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs_0.png"},"coverImage":"/assets/img/2024-06-23-BriefReviewYOLO-ReTTowardsHighAccuracyReal-timeObjectDetectiononEdgeGPUs_0.png","tag":["Tech"],"readingTime":2},{"title":"AVP의 GrayMatter Robotics 투자에 대해 알아야 할 5가지 사항","description":"","date":"2024-06-23 18:38","slug":"2024-06-23-AVPsInvestmentinGrayMatterRobotics","content":"\n\n![AVP's Investment in Gray Matter Robotics](/assets/img/2024-06-23-AVPsInvestmentinGrayMatterRobotics_0.png)\n\n저희는 제조업, 농업, 의료 및 호텔업 등 물리적 산업 전반에서 AI 기반 로봇 플랫폼이 대규모 인간 노동을 보강할 기술적 역량에 도달하면서 혁명을 이루는 과정의 첫 이닝에서 있습니다. 로봇 플랫폼은 과거에는 환경의 실시간 변화, 높은 공정 또는 제품 변이성, 복잡한 제조 공정에서 흔한 다른 요인에 대한 반응 불가능으로 인해 간단하고 반복적인 프로세스로 제약되어 왔습니다. 그러나 처리 능력의 발전, 대규모 데이터 집합을 처리, 저장 및 분석할 수 있는 능력, 그리고 생성적 인공지능의 지수 함수적인 발전을 통해 로봇 기술은 인간 노동과 동등하거나 그 이상의 속도, 정확도, 품질로 고복잡도, 고변이성 작업을 완료할 수 있는 수준에 이르렀습니다. 하드웨어의 가격 하락과 기능 향상이 결합되어, 로봇 솔루션이 기업에게 경제적으로 실용적인 수준에서 마침내 솔루션이 되어, 대규모 채택을 위한 길을 열고 있습니다.\n\n이러한 주장을 추구하는 동안, 저희는 차기 투자 사실을 기쁘게 알려드립니다. Advance Venture Partners(AVP)는 GrayMatter Robotics의 시리즈 B 자금 조달에 투자하고 있습니다. 이 투자는 공장 마감 처리 및 처리를 포함한 갠능한 제조 과제를 수행하는 로봇 솔루션을 구축하는 공동 창업자 Ariyan Kabir, Brual Shah 및 SK Gupta를 지원합니다.\n\nAriyan, Brual 및 SK와 처음 만나보았을 때, 그들은 혁신적인 로봇 기업을 설립할 수 있는 고급 기술 지식을 보유할 뿐만 아니라 고객 요구에 부합하는 플랫폼을 설계하고 GrayMatter를 포함한 모든 이해 관계자에게 매력적인 경제를 창출하는 비즈니스 마인드를 지닌 것을 즉시 알아챘습니다. USC 고급 제조업 센터에서 활동했을 때, Ariyan과 Brual은 제조 업계를 기반으로 한 AI 기반 로봇 플랫폼을 구축하여 생산 과정에서 가장 흔한 표면 마감 및 처리 작업을 시작점으로 삼을 수 있는 기회를 발견했습니다. 표면 마무리 및 처리는 기타 것들로 기타 제품까지 $2.5조 규모의 미국 제조 산업에서 중요한 단계로, 이 업무는 유해하고 힘든 성격 및 필요로 하는 방대한 훈련 때문에 심각한 인력 부족을 겪는 여러 작업 중 하나이며, 이것들은 특히 청년 세대들이 매력적인 직업 기회로 보지 않는 무거운 일과 위험한 역할입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n거대한 산업에 중립적인 문제를 염두에 두고 GrayMatter 팀은 샌딩, 버핑, 그라인딩, 폴리싱과 같은 표면 마무리 및 처리를 자동화하는 전체 스택 AI 솔루션을 구축했습니다. 기업 플랫폼은 현재까지의 로봇 플랫폼의 주요 문제를 극복했습니다 - 동적이고 변화가 빈번한 환경에서 사람들과 마찬가지로 복잡한 작업을 동일한 처리량과 품질로 수행하지 못하는 점입니다. GrayMatter의 로봇들은 심지어 시스템이 아직 보지 못한 물체에 대해서도 본 시간에 복잡한 작업을 자율적으로 처리할 수 있습니다. 결과적으로 고객들은 GrayMatter를 활용함으로써 다면적인 투자수익을 누릴 수 있습니다. 로봇들은 수동 작업보다 2~4배 빠르게 작업할 뿐만 아니라 사람이 6개월이 걸릴 작업을 머신러능이 1일 이내에 훈련받을 수 있어서 인건비(임금, 고용, 훈련, 노동자 보상)의 직간접 비용을 줄이며, 고객의 매출을 증가시킴으로써 공정 처리량을 개선하고 백로그를 감소시키며, 재작업과 폐기물이 줄어드는 고품질 결과물을 만듭니다. 로봇들은 또한 소비하는 소모품 비용(샌드페이퍼, 페인트 등)을 수동작업보다 30% 이상 절약할 수 있어서 고객이 지속가능성 목표를 달성하는데 도움이 됩니다. 많은 산업에서 심각한 노동력 부족 문제에 추가되어, 고객이 인식한 구체적인 투자수익은 GrayMatter를 선택해야 하는 단계로 만듭니다.\n\n우수한 기술과 명확한 제품-시장 적합성을 바탕으로 GrayMatter는 중요하게 로봇서비스 비즈니스 모델을 통해 자체적으로 매력적인 경제를 창출할 수 있는 능력을 입증했습니다. 많은 로봇 기업들이 우수한 기술을 개발했지만 확장 가능한 흥미로운 비즈니스 모델을 구축하지 못했습니다. Ariyan과 Brual은 GrayMatter와 고객을 위해 초기에 강력한 경제를 창출할 필요성을 이해했습니다. 회사는 이미 항공우주 및 국방, 조선업, 특수 차량, 레크리에이션과 소비재, 기타 제조업을 포함한 다양한 산업의 인상적인 고객 목록을 구축했으며, 해당 고객 기반은 시간이 지남에 따라 제품 기능을 추가하여 계속 성장할 것입니다.\n\n기술 발전과 광범위한 노동시장 역동성은 산업 전반에 걸쳐 로봇 플랫폼의 대규모 채택 기회를 열어두었다고 믿습니다. AVP 팀은 GrayMatter Robotics에 백업하고 Ariyan, Brual, SK와 함께 제조업체에 장기간 자동화 요구를 해결할 수 있는 AI 기반 로봇 솔루션을 제공합니다.\n\nGrayMatter Robotics 또는 AVP 웹사이트를 방문하여 자세한 정보를 확인해주세요. 로봇 투자에 대해 더 심층적으로 논의하고 싶다면 언제든지 AVP 팀에 연락해주세요!","ogImage":{"url":"/assets/img/2024-06-23-AVPsInvestmentinGrayMatterRobotics_0.png"},"coverImage":"/assets/img/2024-06-23-AVPsInvestmentinGrayMatterRobotics_0.png","tag":["Tech"],"readingTime":3},{"title":"차동 구동 로봇을 위한 Wheel Odometry 모델 분석","description":"","date":"2024-06-23 18:35","slug":"2024-06-23-WheelOdometryModelforDifferentialDriveRobotics","content":"\n\n휠 오도메트리란 바퀴의 움직임과 위치를 추정하는 것을 의미합니다. 이는 회전 엔코더(즉, 바퀴의 모터에 부착되어 회전을 측정하는 센서)를 사용하여 이루어집니다. 바퀴로봇이나 자율 주행 차량의 위치 추정에 유용한 기술입니다.\n\n이 글에서는 바퀴 오도메트리 모델에 대해 깊이 다루어 보겠습니다.\n\n# 시나리오 정의\n\n바퀴로봇 기술의 세계는 복잡하고 광활합니다. 마찬가지로, 회전 엔코더 센서에는 다양한 옵션이 있습니다. 따라서 휠 오도메트리 모델을 만들기 전에 우리가 모델링할 시나리오를 정의해 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 두 개의 바퀴로 이루어진 로봇에 초점을 맞출 것입니다. 우리의 모델에서 로봇의 모양과 실루엣은 중요하지 않습니다. 로봇을 공간에서 한 점으로 취급할 것이기 때문에 이렇게 간단히 모델링할 수 있습니다. 다이어그램에서 우리는 로봇을 간단히 사각형으로 표현할 것입니다. 우리의 로봇에 강제할 유일한 물리적 제약은 두 바퀴가 평행하다는 것입니다. 두 바퀴 사이에 동일한 거리에 위치한 기준점을 정의할 것입니다. 이는 모델의 동력을 간단하게 만들어 줄 것입니다. 또한, 시각화를 위해 로봇의 전방 방향은 삼각형 모양으로 나타낼 것입니다. 따라서, 우리 다이어그램에서 로봇은 다음과 같이 보일 것입니다:\n\n\u003cimg src=\"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_0.png\" /\u003e\n\n이 기사에서는 차동 구동 로봇에 초점을 맞출 것입니다. 차동 구동이란 각각의 바퀴가 독립된 모터를 가지고 있고 서로 독립적으로 작동할 수 있다는 것을 의미합니다. 차동 구동 로봇에서 각 바퀴를 제어하는 모터는 별도로 있으며 각 모터는 서로 다른 속도와 방향(즉, 전진 또는 후진)으로 바퀴를 회전시킬 수 있습니다. 두 바퀴의 속도에 따라 다른 로봇 동작을 볼 수 있습니다. 두 바퀴 모터가 동일한 속도로 동일한 방향으로 움직이면, 로봇은 해당 방향으로 직진할 것입니다 (예: 두 모터가 동일한 속도로 전진 회전 중이면, 로봇은 직진 경로로 전진할 것입니다). 한쪽 바퀴 모터의 속도가 더 빠르면 로봇은 더 빠른 모터 쪽의 반대 방향으로 회전할 것입니다 (예: 오른쪽 모터가 왼쪽 보다 더 빠르게 후진 회전 중이면, 로봇은 후진하고 왼쪽으로 회전할 것입니다).\n\n\u003cimg src=\"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로봇이 앞으로도 뒤로도 움직일 수 있고, 좌우 방향은 로봇의 방향에 따라 반전될 수 있으므로 로봇의 방향 움직임을 논의하는 것이 혼란스러울 수 있습니다. 이 잠재적인 혼동을 해소하기 위해 우리는 컴퍼스가 참 북쪽을 가지고 있는 것처럼, 방향을 절대적인 용어로 정의할 것입니다. 이 글에서는 로봇과의 방향을 상대로 설명할 때 고정된 기준 프레임으로 설정해, 로봇의 전방이 항상 앞쪽을 가리키도록 합니다. 이렇게 설정하면 로봇의 방향에 상관없이 앞, 뒤, 좌, 우가 항상 로봇의 전면을 기준으로 동일하게 유지됩니다. 위 다이어그램에서 보듯, 로봇의 방향이 어디를 향하고 있건, 방향은 항상 전방이 향하고 있는 곳을 기준으로 조정됩니다.\n\n우리 오도메트리 모델의 데이터/측정은 로터리 엔코더에서 나옵니다. 일반적으로 로터리 엔코더는 모터에 부착되어 회전에 대한 데이터를 수집합니다. 이 상황에서는 왼쪽 바퀴의 모터에 부착된 하나와 오른쪽 바퀴의 모터에 부착된 다른 하나, 즉 두 개의 로터리 엔코더가 있습니다. 그리고 이러한 로터리 엔코더의 속성을 이용해 각 바퀴가 이동한 거리 등의 정보를 결정할 수 있습니다. 로터리 엔코더가 어떻게 작동하는지 보여주기 위해 예제에 중점을 둘 것입니다.\n\n이 글에서 중점을 둘 로터리 엔코더는 증분식 광학 엔코더입니다. 증분식 광학 엔코더는 발광 다이오드(LED), 슬릿이 있는 디스크, 그리고 포토 센서가 있는 회로를 활용하는 엔코더로, 디스크는 LED와 포토 센서가 있는 회로를 슬릿으로 분리합니다. 모터가 회전할 때, 디스크는 LED에서 빛을 슬릿을 통해 포토 센서로 보내는 방식으로 회전하며, 이는 회로의 전압을 변화시킵니다. 전압이 변하는 횟수는 슬릿을 통과한 횟수에 해당하며, 이는 회전 각도에 대한 정보를 제공합니다 (각 슬릿은 일정량의 회전에 대응됩니다). 이는 각 측정마다 이전 시간 단계에서 얼마나 회전했는지를 알게 해주는 증분식 엔코더가 될 것인데, 이는 절대식 엔코더와 대조적입니다. 절대식 엔코더는 각 측정마다 모터의 정확한 방향이 결정됩니다.\n\n![다이어그램](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n회전 데이터와 함께 엔코더의 정보, 예를 들어 반지름이나 둘레와 같은 정보를 함께 사용하여 바퀴가 이동한 거리를 추정할 수 있습니다. 각 홈은 회전 각도를 나타내며, 특정 시간 간격 사이의 회전량을 알 수 있도록 통과한 홈의 수를 알면 됩니다. 광학 엔코더의 경우, 모든 홈이 동일한 간격으로 배치되어 있으므로, 통과한 홈의 수를 단일 홈이 나타내는 회전량으로 곱하면 시간 간격 사이의 총 회전 각도를 얻을 수 있습니다. 회전 각도를 결정한 후에는 엔코더의 둘레와 곱하여 바퀴가 이동한 거리를 구할 수 있습니다.\n\n저희의 측정 모델은 사용하는 엔코더에 의존하지 않습니다. 사실, 거리를 결정할 수 있다면 어떤 유형의 엔코더도 작동할 것입니다. 점진적 광학 엔코더의 경우, 엔코더 (즉, 그 차원)의 특성과 함께 수집된 회전 데이터를 사용하여 엔코더 측정치를 거리로 변환할 수 있습니다. 저희는 이 문서에 직관적인 성질을 갖고 있는 점진적 광학 엔코더를 선택했습니다. 그러나 다른 유형의 엔코더에서 거리를 추출할 수도 있지만, 절차가 다를 수 있고, 이러한 엔코더는 이 문서의 측정 모델에 적합할 것입니다.\n\n요약하면, 이 문서의 바퀴 측정 모델은 두 바퀴가 평행하게 배치되고 로봇이 두 바퀴 중간에 위치한 단일 참조점으로 나타내는 차동 구동 로봇을 위한 것입니다. 로봇을 점으로 취급하고 로봇의 물리적 특성을 무시하며 로봇의 전방 방향과 관련하여 방향을 정의할 것입니다. 엔코더의 경우, 각 시간 간격마다 바퀴가 이동한 거리를 추출할 수 있다면 어떤 것이든 작동할 것입니다. 엔코더의 직관을 구축하기 위해 임의적으로 점진적 광학 엔코더를 살펴봤습니다.\n\n# 바퀴 측정 모델\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 오도메트리 모델의 목표는 로봇의 위치와 방향을 추정하는 것입니다. 이를 달성하기 위해 회전 엔코더에서 얻는 데이터, 로봇의 치수, 그리고 기하학을 활용할 것입니다. 이전에 설명한대로, 엔코더는 각 바퀴가 각 시간 단계에서 이동한 거리에 대한 정보를 제공할 것입니다. 로봇의 치수를 사용할 때, 로봇을 한 점으로 표현하기 때문에 많이 필요하지 않습니다. 필요한 유일한 치수는 좌우 바퀴로부터 점까지의 거리입니다. 두 바퀴 사이의 거리를 절반으로 나누어 점이 두 바퀴로부터 동일한 거리에 위치하도록 하였으므로, 하나의 숫자만 추적하면 됩니다.\n\n이제 이러한 아이디어를 추적하기 위해 몇 가지 변수를 정의해 봅시다:\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_3.png)\n\n첫 두 변수는 특정 시간 단계에서 각 바퀴가 이동한 거리를 대응합니다. 이 정보는 회전 엔코더에서 얻을 것입니다. 세 번째 변수는 두 바퀴 사이의 거리를 측정하고, 점이 두 바퀴로부터 동일한 거리에 위치하므로 해당 거리를 반으로 나누어 파생될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_4](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_4.png)\n\n로봇의 운동 모델을 정의해 봅시다. 로봇의 운동은 항상 어느 호를 따라 이동한다고 가정합니다. 수학적으로, 이것은 어떤 반지름의 원 위를 이동하는 것을 의미합니다.\n\n![2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_5](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_5.png)\n\n원 위의 곡선으로 운동을 모델링하는 동기는 거리와 방향 각도를 해결하기 위해 다양한 기하학적 속성을 사용할 수 있기 때문입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 다이어그램에서 모델은 왼쪽으로 전진하는 모습을 보여줍니다. 그럼 직진, 오른쪽, 그리고 후진은 어떨까요? 다행히도, 우리 모델은 여전히 유효합니다 - 그 이유를 살펴봅시다.\n\n우리 모델에서 직진은 매우 작은 각도와/또는 매우 큰 반지름을 가진 곡선에 해당할 것입니다. 각도가 더 작아지거나 반지름이 증가함에 따라 곡선의 곡률이 감소하고 곡선은 더 평평해집니다. 매우 작은 각도와/또는 큰 반지름에서는 그 곡선이 직선처럼 보일 것입니다. 따라서 이 모델로 직진 운동을 포괄할 수 있습니다.\n\n오른쪽 운동의 경우, 위 다이어그램을 수평으로 뒤집어 모델링할 수 있다는 점에 주목해보세요. 이는 대칭성을 보여줍니다 - 실제로, 뒤집힌 버전을 유도한다면, 왼쪽 바퀴에 관련된 변수/값이 오른쪽 바퀴에 관련된 변수/값으로 뒤바뀌지만 동일한 방정식을 얻을 것입니다. 결과적으로, 모델에서의 방향성 추정값은 부호가 뒤바뀔 것이지만 (즉, 양수에서 음수로, 음수에서 양수로), 거리 추정값은 동일하게 유지될 것입니다. 각도는 양 방향으로 정의되며 부호 뒤집파와 유사한 대칭성을 나타내므로 실제로 이 모델로 오른쪽 운동을 포괄할 수 있습니다.\n\n후진 운동을 포함하는 논의는 비슷한 형태입니다. 후진 운동은 단순히 음의 방향으로 이동하는 거리입니다. 따라서 우리는 음의 거리값을 통해 후진 운동을 포괄할 수 있을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금 이렇게 곡선/호를 사용하여 로봇 움직임을 포착하는 것이 합리적임을 확인했으니, 이제 모델 뒤에 있는 기하학을 살펴봅시다. \n\n첫 번째 기하학적 개념은 각도에 대한 단위입니다. 각도는 일반적으로 도(degrees) 또는 래디언(radians)으로 측정됩니다. 도의 경우, 원을 360개의 동일한 부분으로 나누고 각 잘린 부분의 각도가 1도의 크기입니다. 래디언의 경우, 호의 길이로 정의되며, 단위 원(반지름이 1인 원)의 곡선에 대한 호의 길이와 각도를 관계짓는다 - 바로 호의 길이에 해당하는 각도를 나타내는 1 래디안입니다.\n\n래디언과 각도 간 변환하는 공식과 표가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_6.png)\n\n삼각함수 및 기하학 속성 정의에는 각도의 단위로 라디안과 도를 모두 사용할 수 있습니다. 이 글에서는 라디안과 도를 모두 활용할 것입니다. 각도의 기본 단위는 라디안이며, 다르게 명시되지 않는 한 항상 라디안이 사용됩니다.\n\n이제 각도의 단위에 대한 우리의 맥락을 알게 되었으므로, 휠 오도메트리 모델에서 핵심 공식 중 하나는 호의 길이 공식(라디안 사용)일 것입니다:\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_7.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_8.png)\n\nThe last few geometric ideas we’ll state are:\n\n- The sum of all angles on a straight line is 180°\n\n![Image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_9.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 삼각형의 모든 각의 합은 180°입니다\n\n![Triangle](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_10.png)\n\n- 원에 대한 접선은 원과 접촉점에서 수직이며(즉, 90° 각도), 접선과 현의 각도는 현이 만드는 호의 각도의 절반입니다\n\n![Circle](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금은 우리의 오도메트리 모델을 알려진 변수와 관심 변수로 주석 달기를 시작해 봅시다. 혼잡을 피하기 위해 현재 시간 아래 첨자를 삭제하고 오도메트리 모델의 핵심 관계를 찾아가는 동안 작업해 보겠습니다. 나중에는 흐름 분석에 중요해지는 변수들로 알아봅시다.\n\n![이미지1](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_12.png)\n\n![이미지2](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_13.png)\n\n첫 세 가지 변수는 직접 측정할 수 있습니다(첫 두 변수는 엔코더를 사용하고 세 번째 변수는 자를 이용할 수 있습니다). 마지막 세 변수는 직접 측정할 수 없지만, 대신 이러한 변수들을 측정 가능한 양과 관련시키기 위해 기하학을 사용해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 호 길이 공식을 사용하여 시작해 보겠습니다. 왼쪽 바퀴, 오른쪽 바퀴 및 참조점의 경로는 호입니다. 이들은 모두 같은 각도를 공유하며, 각각의 반지름은 참조점을 포함하는 곡선의 반지름과 참조점과 바퀴 사이의 거리와 관련하여 표현할 수 있습니다.\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_14.png)\n\n이제 소거법을 사용하여 방정식 체계를 풀어 회전 각도의 변화를 해결해 봅시다.\n\n- 곱셈 분배\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003ctable\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cimg src=\"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_15.png\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/table\u003e\n\n- 좌측 바퀴 거리 방정식의 양쪽을 음수로 곱하기\n\n\u003ctable\u003e\n\u003ctr\u003e\n\u003ctd\u003e\u003cimg src=\"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_16.png\" /\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/table\u003e\n\n- 변수 소거와 대수학\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_17.png\" /\u003e\n\n그래서, 우리는 측정 가능한 양에 대한 회전 각도의 변화를 해결할 수 있었고 다음의 관계를 얻었습니다:\n\n\u003cimg src=\"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_18.png\" /\u003e\n\n이제 방정식을 재배열하고 우리가 알고 있는 것을 대입하여 참조점을 포함하는 곡선의 반지름을 구해 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 참조점을 포함하는 곡선의 반지름이 한 쪽에 있는 방정식을 재배열하세요\n\n![그림](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_19.png)\n\n- 우리는 방정식을 뒤집어서 원하는 해를 풀고자 하는 관심 대상의 양이 자연스럽게 읽히도록 오른쪽에 오도록 할 것입니다\n\n![그림](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_20.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n곡선의 반지름을 측정 가능한 양의 관점에서 구했습니다. 이제 참조점이 이동한 거리로 넘어가봅시다. 우리가 한 결과를 대입하고 간단히 정리하기만 하면 됩니다.\n\n![이미지](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_21.png)\n\n측정 가능한 양의 관점에서 모든 변수를 구했습니다. 로봇의 위치와 방향에 관심을 가지고 있으므로, 주요 변수는 참조점이 이동한 거리와 회전 각도의 변화일 것입니다. 참조점이 이동한 거리는 위치를 알려주고, 회전 각도의 변화는 방향을 알려줍니다. 참조점을 포함하는 곡선의 반지름은 유도에 유용하지만 더 이상 필요하지 않습니다. 그래서 지금까지 우리 모델에서 중요한 결과는 다음과 같습니다:\n\n![이미지](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_22.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금까지의 결과를 통해 한 시간 단계에서 다음 시간 단계로의 거리 및 방향 변화를 결정할 수 있습니다. 결과는 시간 간의 상대적인 운동을 설명합니다.\n\n그러나 로봇의 방향이나 새로운 방향을 알고 싶다면 해당 정보가 누락되어 있습니다. 우리는 이동한 거리를 알고 있지만 방향은 알지 못 합니다. 우리는 방향 각도가 얼마나 바뀌었는지 알고 있지만 새로운 방향 각도는 알 수 없습니다. 이는 우리 오도메트리 모델의 다음 부분을 동기부여할 것입니다.\n\n이동 거리의 방향을 결정하려고 시작해봅시다. 우리 모델을 단순화하기 위해 참조점이 이동한 거리를 곡선이 아닌 선으로 표현할 것입니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_23.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적으로 휠 엔코더를 사용한 휠 오도미터에서 데이터 샘플링이 매우 높기 때문에 이러한 단순화를 할 수 있습니다. 이는 엔코더가 데이터를 매우 자주 수집할 수 있어 측정 간의 시간 창이 매우 작다는 것을 의미합니다. 시간 창이 매우 작기 때문에 각 시간 단계에서 캡처된 운동량도 매우 작을 것입니다. 모델링할 때 이는 호의 곡률이 매우 작아져 직선과 유사하다는 것을 의미합니다. 따라서 거리를 이제 직선으로 나타내는 것은 안전한 가정이며 단순화입니다.\n\n이 거리가 이동하는 각도에 관심이 있습니다.\n\n![image 1](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_24.png)\n\n![image 2](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_25.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 각도는 삼각형의 속성, 즉 삼각형의 각이 180°가 되고, 원에 대한 접선의 성질, 즉 선분과 원이 직교하기 때문에 접하는 지점에서 각이 90°가 된다는 것을 활용하여 구할 수 있어요. 참고: 로봇 몸체를 제거하여 혼란을 줄였어요.\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_26.png)\n\n방정식을 세우고 문제를 해결할 수 있어요. 참고: 이 각도는 도입니다(일반 대중이 각도를 더 익숙하게 다루기 때문에), 하지만 라디안으로 문제를 해결할 수도 있었어요 - 정답이 달라지지는 않았을 거예요.\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_27.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n좋아요 — 이제 거리의 각도를 이전에 해결한 변수로 풀었어요.\n\n이제 새로운 로봇의 방향을 풀기 위해 주목해봐요.\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_28.png)\n\n이전과 마찬가지로 기하학 원리를 사용해서 새로운 방향의 각도를 풀어볼거에요. 이것이 바로 우리 다이어그램이에요 (로봇 본문은 제거해서 혼란을 줄였어요):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMarkdown 형식으로 테이블 태그를 변경하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_31.png)\n\n이제 직선 위의 각도들은 180°가 되어야 한다는 사실을 이용하여 문제를 해결할 수 있습니다.\n\n![이미지](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_32.png)\n\n따라서, 우리의 현재 오도메트리 모델은 다음과 같이 보입니다 (덜 중요하거나 중간 변수들을 걸러냄):\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_33.png)\n\n로봇이 얼마나 멀리 이동했는지, 이동한 각도, 회전 각도의 변화 및 서로 다른 시간 단계 간의 방향 각도를 알게 되었습니다.\n\n# 휠 오도메트리 절대 운동\n\n이전 섹션의 결과를 토대로 상대 운동(즉, 한 시간 단계에서 다음으로 이동하는 것)을 추정할 수 있습니다. 그러나 절대 운동을 설명하는 오도메트리 모델을 확장할 수 있습니다. 절대 운동에서는 로봇이 탐색하는 환경을 좌표 평면 시스템(일반적으로 x 및 y 방향으로)으로 정의할 것입니다. 이 좌표 시스템에서 로봇의 운동은 로봇의 절대 위치를 나타내는 좌표에 의해 포착될 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n방위에 대해 정의할 수 있는 것은 x-축에서의 각도입니다. 로봇이 양의 x-축 방향을 향할 때, 방위 각도는 0°입니다. 로봇이 돌아서 제1 사분면 어딘가를 향할 때 방위 각도는 0°에서 90°까지입니다. 로봇이 제2 사분면 어딘가를 향할 때 방위 각도는 90°에서 180°까지입니다. 로봇이 제3 사분면 어딘가를 향할 때 방위 각도는 180°에서 270°까지입니다. 그리고 로봇이 제4 사분면 어딘가를 향할 때 방위 각도는 270°에서 360°까지입니다. 이는 주변에 도(도 및 라디안을 가지고 있고 중앙에 사분면 레이블이 있는)을 가진 그래픽을 통해 시각화할 수 있습니다:\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_34.png)\n\n상대적 방향과의 주요 차이점은 절대 방위가 항상 동일한 기준 프레임, 즉 고정된 좌표 평면의 양의 x-축에서의 각도에서 오는 것이라는 것입니다. 반면에 상대적 방향은 관점 / 기준 프레임에 따라 달라질 수 있습니다.\n\n지금까지 저희의 오도메트리 모델은 초기 위치가 왼쪽을 향하도록 그려져 있었습니다. 이는 현재까지 저희의 오도메트리 모델에서 로봇이 항상 제로 라디안의 절대 방위로 시작했다는 의미입니다(기존 방향을 고려할 필요가 없었습니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로봇이 다른 방향에서 시작할 때 어떻게 되는지 궁금하셨군요? 상대 운동에 대한 모든 작업은 그대로 유지되지만, 초기 방향을 고려하여 완전한 위치와 방향을 올바르게 계산할 수 있도록 조정해야 합니다.\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_35.png)\n\n왜 초기 방향이 변경되더라도 모든 상대 운동이 여전히 유지되는지 궁금할 수 있습니다. 그 이유는 관점 때문입니다. 위 예시를 들어보겠습니다. 이미 존재하는 좌표계를 회전시켜 초기 방향을 제로 라디안(즉, x축이 로봇의 현재 방향과 평행하도록)으로 만들면 어떻게 될까요? 이전에 논의한 상대 운동에 대한 모든 작업을 적용할 수 있을 것입니다. 좌표계를 회전시키는 것은 기본적으로 아무것도 변경하지 않습니다. 단지 관점을 바꿔서 볼 뿐입니다.\n\n사실, 절대 운동 모델을 얻는 한 가지 전략은 회전하고 다시 원래 좌표계로 변환하는 등 각각의 새로운 좌표계를 계속 생성하는 것입니다. 이러한 좌표 변환 방법은 좌표계를 회전시키는 (회전) 행렬을 사용하여 더 복잡하며 고급 기술입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이것은 기하학에 대한 멋진 관점을 제공합니다. 우리의 로봇은 일부 절대 방향으로 시작합니다. 로봇이 방향이 0 라디안이되도록 좌표계를 수정하기로 결정하면, 기존 좌표 평면을 절대 방향 각도만큼 회전해야 합니다. 이는 우리가 절대 방향을 양의 x축에서의 각도로 정의했기 때문입니다. 기본적으로 우리는 절대 방향 각도로 좌표 평면을 조정하고 있습니다. 전체 좌표 평면을 이동하는 대신, 아래에서 설명하는 대로 상대적 방향 계산에 이를 추가할 수 있습니다:\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_36.png)\n\n이 다이어그램에서 시간 t에서의 오도메트리 모델은 이전 시간 단계의 절대 방향 각도를 추가할 것입니다. 이전 시간 단계의 방향을 추가해도 기준점의 이동 거리나 회전 각도 변경에는 영향을 미치지 않습니다. 왜냐하면 이전에 유도한 공식이 방향 각도에 의존하지 않고 (이동한 바퀴 거리에만 의존하기 때문에)입니다. 변경되는 것은 로봇의 방향입니다. 시간 단계 간에 상대적인 것에서 좌표 평면 상의 절대 방향으로 변경됩니다. 따라서 어떤 시간 단계에서도 절대 방향 각도는 다음과 같이 정의될 수 있습니다:\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_37.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n절대 운동을 다룰 때, 로봇이 각 시간 단계마다 좌표점을 가지게 됩니다. 좌표 위치가 업데이트되는 방법은 삼각함수의 특성을 사용하는 것인데, 즉 각의 코싸인이 이웃변을 가각변으로 나눈 값이고 사인이 이웃변을 빗변으로 나눈 값이라는 것입니다. 참조점이 이동한 거리를 빗변으로 하고 이전 시간 단계의 방향 각도 및 이동으로 인한 각도를 더하여 x와 y 방향으로 이동한 거리를 계산할 수 있습니다.\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_38.png)\n\n이전 시간 단계의 좌표에 x와 y 거리를 더함으로써 로봇의 새로운 좌표 위치를 결정할 수 있습니다. 이러한 방정식을 사용하여 역학을 설명할 수 있습니다:\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_39.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현재 시간의 위치는 이전 시간 단계의 위치와 각도에 따라 결정되며 현재 시간 단계에서 회전 각도의 변화에 기반합니다. 하나의 방정식에서 두 가지 다른 시간 단계의 양을 사용하는 것을 감안하면 차이를 명확히 하기 위해 다시 시간 첨자를 사용하는 것이 좋습니다.\n\n# 결론\n\n우리의 인코더는 각 바퀴가 이동한 거리를 수집하고, 바퀴와 참조점 사이의 거리를 측정할 수 있습니다. 호의 길이 공식을 사용하여, 시스템의 방정식을 얻었고, 우리는 거리 이동 및 시간 단계 사이의 회전 각도 변화(라디안)를 구하기 위해 이를 해결했습니다.\n\n![image](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_40.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 휠 인코더로 데이터를 빈번하게 수집하기 때문에 우리의 이동 거리를 호선 대신 선으로 나타낼 수 있다는 것을 깨달았어요. 높은 데이터 수집 빈도로 인해 곡선이 더 직선처럼 동작하고 보이게 됩니다. 그런 다음, 각도의 기하학을 사용하여 우리는 움직임에 의해 발생하는 방향 각도(라디안 단위)와 최종적인 상대적 방향을 찾았어요.\n\n그 후에, 우리는 절대 위치 및 방향에 대한 모델을 확장했어요. 여기서 우리는 정의된 좌표 평면이 있는 절대 시스템에서 우리의 오도메트리 모델을 조정해야 해요. 절대 시스템에서는 이전 시간 단계의 절대 방향 각도를 고려하여 오도메트리 모델을 조정해야 해요. 그런 다음, 우리는 삼각함수 관계식을 사용하여 새로운 절대 방향 각도(라디안)와 좌표 위치를 결정할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n절대 운동에 대해, x 및 y 구성 요소로 이뤄진 좌표 위치와 절대 방향 각도(라디안 단위)가 있습니다. 절대 운동에 대한 오도메트리 모델을 정의하는 세 가지 방정식은 다음과 같습니다:\n\n![equation 1](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_43.png)\n\n또한 일반적으로 방정식을 벡터 형태로 표현하는 것이 일반적입니다:\n\n![equation 2](/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_44.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글에서 우리는 두 바퀴 차동 구동 로봇을 위한 오도메트리 모델을 개발했습니다. 이 모델을 사용하면 로터리 엔코더에서 수집한 데이터를 사용하여 위치와 방향을 추적할 수 있습니다. 로터리 엔코더는 매우 저렴하고 데이터 샘플링이 높기 때문에 휠 로보틱스에서 센서로 자주 사용됩니다. 그러나 엔코더를 사용하는 데 있어서의 한 가지 어려움은 잡음과 측정 오차입니다. 우리 모델을 계속 개발하려면 다음 단계로 우리의 측정 값과 함께 통계적 불확실성과 오차를 고려하는 것이 좋은 방향입니다.","ogImage":{"url":"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_0.png"},"coverImage":"/assets/img/2024-06-23-WheelOdometryModelforDifferentialDriveRobotics_0.png","tag":["Tech"],"readingTime":16},{"title":"로봇 공학 적용의 시대","description":"","date":"2024-06-23 18:32","slug":"2024-06-23-Theageofappliedrobotics","content":"\n\n![Amazon Sparrow](/assets/img/2024-06-23-Theageofappliedrobotics_0.png)\n\n안녕하세요! 아마존이 새로운 창고 로봇인 Amazon Sparrow를 발표했어요. 이 로봇은 패커들의 역할을 대체하기 위해 디자인된 것인데, 패커들은 주로 피커들이 가져온 아이템을 패킹하는 일을 하는 분들이죠. 피커들 자체가 로봇들에 의해 대체되고 있어요. 로봇들은 창고 외곽의 위치에 해당하는 선반을 가져다놓는 로봇인데요.\n\nSparrow는 창고에서 두 가지 가장 중요한 기능을 자동화하는 것을 가능하게 했어요. 제품을 이동시키는 것과 출고 배포를 위해 제품을 포장하는 것인데요. 제품의 이동은 오랫동안 선반을 들어들고 이동시키는 로봇에 의해 수행되어 왔는데, 이로 인해 인간들이 접근할 수 없는 미래적인 환경들이 만들어졌어요.\n\n그리고 다루고 포장하는 일은 매우 복잡했어요. 왜냐하면 매우 다양한 치수, 재료 등을 다루기 위해서 적응적 능력이 필요했기 때문이죠. 그러므로 그 기술적 요소들을 제어할 수 있는 로봇 팔을 디자인하는 방법은 무엇인가요? 그에 대한 답은 하나뿐이에요: 기계 학습이죠. 창고의 모든 제품에 대한 참조가 있는 거대한 카탈로그에서 물체를 인식할 수 있는 알고리즘을 사용하여, 제품의 특성에 따라 올바른 흡입컵, 부품 및 필요한 힘으로 제품을 조작할 수 있게 되는 거죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기계 학습은 로봇 공학을 새로운 수준으로 끌어올리고 있습니다. 동시에 전 세계적으로 수백만 개의 직업이 위험에 처해 있다는 것도 사실입니다. 아마존은 이에 대해 걱정할 필요가 없다고 말하며, 자사의 역사를 통해 자동화를 지속해왔고 거대한 기계화된 군대를 구축하면서 동시에 사람을 고용해왔다는 주장을 펼치고 있습니다(팬데믹 이후를 제외하고). 동시에, 우리는 인간들이 더 이상 편안하게 수행하기를 원치 않는 작업들의 기계화에 대해 이야기하고 있으며, 이로 인해 불만족한 직원들이 자신의 급여와 근무 조건에 반발하기도 합니다.\n\n최근 연구에 따르면 로봇화가 일자리에 미치는 위협은 우려할 필요가 없을 뿐만 아니라, 사실은 인간에게 더 큰 부가 가치를 제공하는 다른 유형의 직업에 대한 필요로 상쇄될 수도 있다고 합니다. 실제로, 우리는 아마존이 정의한 '응용 로봇공학 시대'에 진입하게 됩니다: 반복적인 작업만 수행하는 것이 아니라 다양한 가능성을 선택할 수 있는 로봇들이 등장함으로써 훨씬 더 발전된 자동화가 이루어지고 있습니다.\n\n앞으로 더 많은 공장들이 로봇을 이용하여 인간이 해서는 안 되는 더러운, 위험한, 단조롭고, 멸시받는 작업에 대해 책임하게 될 것인가요? 고급 자동화는 노동의 존엄성을 높일 것인가요, 아니면 많은 직업의 상실과 더 심화된 불평등을 야기할 것인가요? 아무튼, 로보틱스와 기계 학습을 결합한 고급 자동화는 경쟁력의 핵심 요소이며, 따라서 결과에 관계없이 필요에 의해 채택될 것입니다. 그렇다면 우리가 이에 대해 탐구하고 가능성을 이해할수록 좋을 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-Theageofappliedrobotics_0.png"},"coverImage":"/assets/img/2024-06-23-Theageofappliedrobotics_0.png","tag":["Tech"],"readingTime":2},{"title":"소설에서 영화까지 블레이드 러너의 모든 것","description":"","date":"2024-06-23 18:31","slug":"2024-06-23-BooktoLifeBladeRunner","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-BooktoLifeBladeRunner_0.png\" /\u003e\n\n영화 전공 학생으로서, 내가 본 영화의 수가 상대적으로 적다는 비판을 받아왔어. 이번 여름에는 이를 바꾸기 위해 영화/TV 시청과 독서를 일상에 편입할 예정이야. 수업으로 인한 바쁜 시간이 없기 때문에 평론을 쓰면서 더 많이 배우고 발견할 수 있을 거라 믿어.\n\n어릴 적에는 판타지, 신화, 미스터리 책에 몰입했었어. 이런 장르들이 내 창의력과 문제 해결 능력에 크게 기여한 것 같아. 오랜 기간 동안 내 맥락 형성에 이른 나의 메이어스-브릭스 성격 유형은 ENFJ였는데, 이는 이러한 초기 영향들 때문이라고 생각해.\n\n내가 성숙해지면서, 흥미는 디스토피아와 과학 소설로 옮겼어. 이제 “1984”, “Dune”, “Blade Runner”와 같은 책들에서 삶의 교훈을 찾고 있어.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDenis Villeneuve의 \"블레이드 러너 2049\"는 아직 보지 않았지만, 다가오는 몇 주 안에는 계획 중에 있습니다. Philip K. Dick의 공상 과학 소설 \"블레이드 러너: 안드로이드는 전기양을 꿈꾸는가?\"는 특히 정신적으로 자극적이었습니다. 과학 소설을 읽을 때, 세계를 생생하게 상상하며, 단 3일 안에 완독한 후 완전히 몰입했어요. 이 소설은 250쪽 미만으로 짧지만 의미가 풍부하여 결말은 예측 가능하지만 만족스럽다고 느꼈어요. 약 한 달 전에 완독한 \"1984\" 이후 처음으로 완독한 책이에요.\n\n지난 추수감사절에는 친구와 신앙과 생물학의 공존에 대해 3시간 간의 논쟁 끝에(나는 회의론자였고, 그는 지지자였어요), 인간이 무엇인지에 대해 고찰하기 시작했어요. 인공지능과 로봇이 주도하는 새로운 시대에 접어들면서, 이러한 주제에 더 깊이 고민하고 있어요. 졸업을 앞둔 지금, 현재 일하고 있는 스타트업은 전통적인 소상공인이 현금 흐름 문제를 피할 수 있도록 중점을 두고 있는데, 이는 인공지능과 로봇의 직접적인 영향에서 나를 보호해 줄 거라고 믿어요. 스타트업 여정은 길지만, 회사 내에서 배우게 될 교훈들에 설레고 있어요.\n\n7~8년 후, 회사를 떠날 때 깊은 기술 기반 회사를 창업하고 싶어요. \"블레이드 러너: 안드로이드는 전기양을 꿈꾸는가?\"의 세계에서 영감을 받은 깊은 과학 기술 회사를 시작하고 싶어 해요. Elon Musk와 같은 선구자적인 창업자들을 존경하는데, 그들은 공상 과학에 집착하고 있어요. Musk가 경고하는 AI의 발전은 블레이드 러너 이야기에서 명확하게 표현되고 있어요. 인간들이 화성에 콜로니를 창설하기 전에 넥서스-6와 유사한 안드로이드를 개발할 수도 있다고 믿어요. Musk의 Optimus - Gen 2는 이미 테슬라 공장에서 많은 노동을 대체할 수 있는 흥미로운 작업들을 하고 있어요.\n\nPhilip K. Dick이 창조한 세계는 매혹적입니다. 이 디스토피아에서는 세계 전쟁 종말(WWT)로 인해 대부분의 생명체가 위험에 처하거나 멸종됐습니다. Kipple, 방사능 물질과 먼지로 지구를 덮어 애완동물이 귀한 보물이 되었어요. 많은 사람들은 일정한 사회적 지위를 투영하기 위해 전자 동물을 소유하게 되었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 과학 소설 우주에서 Dick이 상상하는 것들:\n\n- 자동차를 없애기 위해 레이저 건을 든 현상금 사냥꾼들\n- 사용자 제어 키보드를 통해 감정 상태를 수정하는 Penfield 감정 장기\n- 먼지로 가득한 이 세계에서 전통적인 도로가 쓸모 없어서 비행 자동차\n- 로켓을 이용한 교통수단으로, 시애틀에서 LA까지 1시간 만에 도착\n- 물론 안드로이드들\n\n저는 실생활에서 경찰관들이 레이저를 더 자주 사용하지 않는 이유를 의문합니다. 일부 파장은 인간 눈에 보이지 않기 때문입니다. 레이저 스타트업에서 일한 경험으로 그런 환경에서 안전 고글의 중요성을 알고 있습니다. 또한 비행 자동차가 과학 소설의 상징이지만 실용적인 구현은 아직 멀어보입니다. 규제와 개발 비용만 놓고 봐도 전통적인 차량에 비해 비행 자동차는 실용적인 투자가 아닙니다.\n\nPenfield 감정 장기는 흥미롭게 느껴지지만, 인간 감정 조작에 대한 제 도덕적 입장과 상충됩니다. 정신 질환을 가진 사람들에게 도움이 될 수 있지만 소설에서는 Rick의 우울증을 앓는 아내에게 효과적이지 않다고 나옵니다. 이것은 정신 질환을 치료할 수 없다는 것을 시사할 수 있으며, 기계는 일시적인 안위만 제공합니다. 경제적인 관점에서는 그런 장치의 퇴보하는 한계 효용에 대해 의문을 품고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로켓 기반 교통 수단은 현실적이면서도 현실적이지 않습니다. 긴급 여행에 유용할 수 있지만, 필요한 훈련과 비용은 일등급 비행기 표와 비교했을 때 비싼 만큼 실용적이지 않습니다. 파이콘 9 좌석에 드는 5500만 달러의 우주 관광 비용(파이콘 9의 페이로드 당 1,200달러)은 이러한 모험의 금전적으로 방해되는 비용을 강조합니다.\n\n안드로이드는 매혹적이면서 무서운 요소도 있어, 로봇공학이랑 인간의 윤리적 질문을 자극합니다. Rick이 Rachel Rosen과 \"잠을 자는\" 것이 사기인가요? 의식 있는 안드로이드를 죽이는 것은 불법인가요? 소설 제목이 시사하는 것처럼, 안드로이드는 꿈을 꾸는 걸까요? 이런 질문들은 이 새로운 산업시대에 접어들기 전에 답할 필요가 있습니다, 세계전쟁 황폐한 경계선이 먼저 일어나는 경우를 제외하고는요...\n\n그럼에도 불구하고, 저는 미래에 대해 낙관적입니다. 이 기술적 발전과 \"블레이드 러너\" 세계에 관련성 있는 무언가를 30대 초반쯤에 창조할 것입니다. 그러나 가장 짜증나는 것은 내가 이해하려는 개념에 대해 항공우주/기계공학자가 수업에서 배운 것을 이해하기 위해 10개의 질문을 해야 한다는 지식 장벽입니다.\n\n무언가를 만들고 싶다면, 가장 똑똑한 사람들을 주변에 둘러싸고, 위대한 일을 이루기 위해 그들을 하나로 모으는 단일한 비전을 가져야 합니다.","ogImage":{"url":"/assets/img/2024-06-23-BooktoLifeBladeRunner_0.png"},"coverImage":"/assets/img/2024-06-23-BooktoLifeBladeRunner_0.png","tag":["Tech"],"readingTime":3},{"title":"Gradient Descent 알고리즘과 맞춤형 웨이포인트로 AWS DeepRacer 성능 향상시키는 방법","description":"","date":"2024-06-23 18:29","slug":"2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints","content":"\n\n# AWS DeepRacer에 대해\n\nAWS DeepRacer는 Amazon Web Services (AWS)의 흥미로운 프로젝트로, 자율 주행 레이싱의 즐거움과 강화 학습 (RL)의 힘을 시원하게 결합한 것이죠. DeepRacer의 핵심은 RL 분야를 분석하고 민주화하는 데 중점을 둔 포괄적이고 인터랙티브한 플랫폼입니다. 이를 통해 숙련된 개발자부터 초보자까지 RL 분야에 대한 접근성을 높일 수 있습니다.\n\n# 커뮤니티 레이스\n\nDeepRacer 커뮤니티 레이스는 AWS DeepRacer 생태계 내에서 참여자들 간의 커뮤니티와 경쟁 의식을 촉진하기 위해 디자인된 매력적이고 협업적인 프로그램입니다. 이 흥미진진한 프로젝트는 모든 수준의 참가자들을 초대하여 그들의 AI 레이싱 스킬을 겨룰 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![DeepRacer Performance](/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_0.png)\n\n우리 회사의 DeepRacer 경주에 참여한 기회를 가졌는데, 이 경험은 즐겁고 교육적이었습니다. 이 여정을 통해 강화 학습의 세계에 심취하며 자율 주행 레이싱 카를 훈련하는 데 중추적인 역할을 하는 보상 함수(RF)에 대한 깊은 이해를 얻을 수 있었습니다.\n\n저는 경사하강 알고리즘과 코딩을 통해 3바퀴를 24.58초로 완주한 경험을 공유할 예정입니다.\n\n![DeepRacer GIF](https://miro.medium.com/v2/resize:fit:1200/1*7vcRCVvk4TG3Hy_9AzB9KQ.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 최적 경로 계획\n\nAWS Invent:2018 트랙 레이스를 위한 나의 모델 훈련은 핵심 작업인 최적 레이싱 경로 계획으로 시작되었습니다. 이 노력에서는 GitHub Repository에서 제시된 방법론에서 영감을 받았습니다. 이 방법론은 경사 하강 알고리즘의 힘을 이용하고 있습니다. 먼저, 저는 아래와 같이 빨간색으로 표시된 상한선과 하한선을 설정하는 데 집중했습니다:\n\n![그림](/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_1.png)\n\n그 후 알고리즘의 목표는 자동차의 최적 경로를 계산하는 것이었습니다. 이때의 주요 목표는 트랙의 직선 구간을 최대화하는 것이었습니다. 이 전략적인 접근 방식은 급한 회전을 줄여주어 자동차가 장기간 최대 속도를 유지할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, AWS에서 제공한 미리 정의된 웨이포인트를 계획된 경로 위에 겹쳤습니다.\n\n그로 인해 차량이 가속해야 하는 최적 구간과 회전을 준비하기 위해 감속해야 하는 지역을 명확히 식별할 수 있었습니다. 이 포괄적인 이해는 내 보상 함수 개발의 기초가 되었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 경로 계획에 이어 트랙상의 각 인덱스에 적합한 속도를 결정하는 과정이 집중적으로 다루어졌습니다. 최적의 성능을 보장하기 위해 속도 범위는 1.5에서 4.0 사이로 제한했습니다. 특히, U턴 및 중요 지점 근처에서 계산된 속도가 낮아지는 것을 관찰할 수 있는데, 이는 차량이 정밀하게 이 도전적인 섹션을 운행할 수 있도록 도와줍니다.\n\n이 방식을 활용하여 차량의 속도를 다양한 트랙 구간에 맞게 섬세하게 조절할 수 있는 폭넓은 속도 값 범위를 포착했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_6.png\" /\u003e\n\n이 속도 범위는 모델 훈련 과정을 가속화하고 향상시키는 데 중요한 역할을 합니다. 당연히 이러한 범위를 조정하여 여러분의 구체적인 트랙과 목표에 맞출 수 있는 유연성이 있습니다. 이렇게 하면 성능을 더욱 향상시킬 수 있습니다.\n\n앞으로 계획된 작업 공간에 대해 자세히 살펴볼 수 있습니다. 각 행은 예상 작업을 나타내며 각 인덱스에 해당합니다 (웨이포인트와 동일함). 이 작업 공간은 [x, y, speed, time]로 표시됩니다. 훈련 중에 \"시간\" 구성 요소는 안정성이 다소 일관되지 않았기 때문에 크게 사용하지 않았습니다.\n\n이 트랙에 118개의 인덱스가 존재하지만 할당할 수 있는 작업은 단 30개뿐이므로, 속도와 작업 가능성을 더 관리할 수 있는 집합으로 압축하기 위해 클러스터링 접근 방법이 필요했습니다. 이를 위해 K-means 클러스터링 방법을 선택하여 작업을 13개의 구분된 클러스터로 효과적으로 줄였습니다. 이 접근 방법을 통해 모델이 학습하고 레이싱 결정 중에 적용할 수 있는 보다 간결하고 실용적인 작업 집합이 보장되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_7.png)\n\n그리고 이것이 이산적인 액션들입니다:\n\n![이미지](/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_8.png)\n\n# 모델 훈련\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n강화 학습을 탐험하면서, 상대적으로 새로운 개념인데도 불구하고, 그 근본적인 원리에 대해 파고들어 내 나름대로의 이해로 정리했습니다:\n\n모델 훈련 측면에서, 제 개인적인 경험은 큰 학습 속도 및 작은 배치 크기로 시작하는 것이 효과적이라는 것을 알려 주었습니다. 이 전략은 모델이 일반적인 경로와 속도 경향을 빠르게 파악하는 데 도움이 됩니다. 점진적으로, 모델이 진행됨에 따라 이러한 초매개변수를 점차 감소시키는 것을 권장하며, 더 구체적이고 정교한 훈련 요구에 적응하도록 합니다. 대부분의 훈련에 사용된 하이퍼파라미터는 다음과 같습니다:\n\n[하이퍼파라미터 테이블](/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_9.png)\n\n총 30시간 정도의 시간을 들여, 모델을 복제하고 훈련하여 비교적 안정된 상태에 이르렀습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_10.png\" /\u003e\n\n열정적이고 철저한 훈련 노력 끝에, 나는 리더보드에서 선두를 차지했습니다.\n\n이 보상 함수가 효과적인 면에서 이점을 제공하지만, 간단한 보상 함수보다 수렴하는 데 더 많은 시간이 걸릴 수 있다는 점을 인지하는 것이 중요합니다. 이 요소로 인해 마지막 제출이 레이스 마감 시간을 넘어섰고 두 번째 위치를 확보한 타이밍이었습니다. 이것은 강화 학습과 레이싱의 동적 세계에서 복잡성과 수렴 속도 사이의 적절한 균형을 찾는 것이 중요한 도전임을 상기시켜줍니다. 그러나 이는 DeepRacer 여정을 풍부하게 하는 귀중한 학습 경험이기도 합니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_11.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 데이터 분석으로 보상 기능 향상하기\n\n매 훈련 세션 이후, 훈련 로그를 다운로드하고 분석하는 과정은 여정 중 중추적인 단계가 됩니다. 저는 주로 세 가지 필수 플롯을 분석하여 가치 있는 통찰을 얻습니다:\n\n- 에피소드 진행 플롯 (왼쪽): 이 플롯은 각 에피소드에서 이루어진 진행을 시각적으로 나타내며 학습 곡선을 명확하게 보여줍니다.\n- 완주 당 총 단계 플롯 (가운데): 여기서 나는 자동차가 각 랩을 완주하기 위해 필요한 총 단계 수를 평가합니다. 이 통찰은 효율성과 전반적인 성능을 평가하는 데 중요합니다.\n- 보상 플롯 (오른쪽): 보상 그래프는 매우 중요한데, 보상 함수의 효과적인지를 시험하는 역할을 합니다. 이 그래프는 함수가 자동차가 더 짧은 걸음으로 최적의 경로를 따르도록 적절하게 장려하는지를 강조합니다.\n\n이러한 플롯들은 훈련 진행 상황에 대한 종합적인 시각을 제공하며 최적의 결과를 위해 모델 수정을 도와줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같이 Markdown 형식으로 수정하세요.\n\n\n![이미지](/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_12.png)\n\n실제로 리워드 대 웨이포인트 그래프는 특정 웨이포인트를 찾아내는 데 매우 유용한 도구입니다. 이 그래프를 면밀히 살펴보면, 리워드가 낮은 웨이포인트를 식별하여 자동차가 코스를 이탈하게 하는 요인을 찾아낼 수 있습니다. 이러한 특정 통찰력은 리워드 기능을 정밀하게 조정하여 자동차의 전반적인 성능을 향상시키고, 더 일관되게 코스를 유지할 수 있도록 하는 데 도움이 됩니다.\n\n![이미지](/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_13.png)\n\n당연히, 훈련 트랙을 시각화할 수 있는 능력은 최적 경로를 설계하는 데만 있는 것이 아니라, 훈련 과정에 대한 보다 깊은 통찰력을 얻을 수 있는 귀중한 자원입니다. \"Training_analysis.ipynb\"를 탐험하는 것을 강력히 권장합니다. 이 파일은 이러한 유용한 플롯 생성을 자동화하여 분석을 단순화하고, 모델을 더욱 개선하기 위한 데이터 기반 의사결정을 도와줍니다. DeepRacer 여정에서 귀하의 성공에 크게 기여할 수 있는 강력한 도구입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 코드 세부 정보\n\n보상 함수는 다음과 같습니다:\n\n```js\n# 속도 범위: 1.5 - 4\nimport math\n\n\nclass Reward:\n    def __init__(self):\n        self.first_racingpoint_index = 0\n\n    def reward_function(self, params):\n\n        ################## 도우미 함수 ###################\n\n        def dist_2_points(x1, x2, y1, y2):\n            return abs(abs(x1-x2)**2 + abs(y1-y2)**2)**0.5\n\n        def closest_2_racing_points_index(racing_coords, car_coords):\n\n            # 모든 레이싱 포인트까지의 거리 계산\n            distances = []\n            for i in range(len(racing_coords)):\n                distance = dist_2_points(x1=racing_coords[i][0], x2=car_coords[0],\n                                         y1=racing_coords[i][1], y2=car_coords[1])\n                distances.append(distance)\n\n            # 가장 가까운 레이싱 포인트의 인덱스 가져오기\n            closest_index = distances.index(min(distances))\n\n            # 두 번째로 가까운 레이싱 포인트의 인덱스 가져오기\n            distances_no_closest = distances.copy()\n            distances_no_closest[closest_index] = 999\n            second_closest_index = distances_no_closest.index(\n                min(distances_no_closest))\n\n            return [closest_index, second_closest_index]\n\n        def dist_to_racing_line(closest_coords, second_closest_coords, car_coords):\n\n            # 가장 가까운 2개 레이싱 포인트 사이의 거리 계산\n            a = abs(dist_2_points(x1=closest_coords[0],\n                                  x2=second_closest_coords[0],\n                                  y1=closest_coords[1],\n                                  y2=second_closest_coords[1]))\n\n            # 차와 가장 가까운 레이싱 포인트 사이의 거리와 두 번째로 가까운 레이싱 포인트 사이의 거리\n            b = abs(dist_2_points(x1=car_coords[0],\n                                  x2=closest_coords[0],\n                                  y1=car_coords[1],\n                                  y2=closest_coords[1]))\n            c = abs(dist_2_points(x1=car_coords[0],\n                                  x2=second_closest_coords[0],\n                                  y1=car_coords[1],\n                                  y2=second_closest_coords[1]))\n\n            # 차와 레이싱 라인 사이의 거리 계산 (가장 가까운 2개의 레이싱 포인트를 통과)\n            # DeepRacer에서 드문 버그인 경우를 위해 try-except 사용\n            try:\n                distance = abs(-(a**4) + 2*(a**2)*(b**2) + 2*(a**2)*(c**2) -\n                               (b**4) + 2*(b**2)*(c**2) - (c**4))**0.5 / (2*a)\n            except:\n                distance = b\n\n            return distance\n\n        # 다음인 레이싱 포인트 및 이전 레이싱 포인트 계산\n        def next_prev_racing_point(closest_coords, second_closest_coords, car_coords, heading):\n\n            # 차를 더 많이 향하도록 설정\n            heading_vector = [math.cos(math.radians(\n                heading)), math.sin(math.radians(heading))]\n            new_car_coords = [car_coords[0]+heading_vector[0],\n                              car_coords[1]+heading_vector[1]]\n\n            # 새로운 차 좌표와 두 가장 가까운 레이싱 포인트까지의 거리 계산\n            distance_closest_coords_new = dist_2_points(x1=new_car_coords[0],\n                                                        x2=closest_coords[0],\n                                                        y1=new_car_coords[1],\n                                                        y2=closest_coords[1])\n            distance_second_closest_coords_new = dist_2_points(x1=new_car_coords[0],\n                                                               x2=second_closest_coords[0],\n                                                               y1=new_car_coords[1],\n                                                               y2=second_closest_coords[1])\n\n            if distance_closest_coords_new \u003c= distance_second_closest_coords_new:\n                next_point_coords = closest_coords\n                prev_point_coords = second_closest_coords\n            else:\n                next_point_coords = second_closest_coords\n                prev_point_coords = closest_coords\n\n            return [next_point_coords, prev_point_coords]\n\n        def racing_direction_diff(closest_coords, second_closest_coords, car_coords, heading):\n\n            # 가장 가까운 웨이포인트를 기반으로 센터 라인의 방향 계산\n            next_point, prev_point = next_prev_racing_point(closest_coords,\n                                                            second_closest_coords,\n                                                            car_coords,\n                                                            heading)\n\n            # 방향 계산(radian 값, arctan2(dy, dx), 결과는 라디안 단위로 (-pi, pi))\n            track_direction = math.atan2(\n                next_point[1] - prev_point[1], next_point[0] - prev_point[0])\n\n            # 도수로 변환\n            track_direction = math.degrees(track_direction)\n\n            # 트랙 방향과 차량의 진행 방향 간의 차이 계산\n            direction_diff = abs(track_direction - heading)\n            if direction_diff \u003e 180:\n                direction_diff = 360 - direction_diff\n\n            return direction_diff\n\n        #################### 레이싱 라인 ######################\n\n        # Spain 트랙을 위한 최적의 레이싱 라인\n        # 각 행: [x,y,speed,timeFromPreviousPoint]\n        racing_track = [\n            [3.06664, 0.69989, 4.0, 0.03654],\n            ...\n            [2.77639, 0.72086, 4.0, 0.03581],\n            [2.92074, 0.70874, 4.0, 0.03621]]\n\n        ...\n\nreward_object = Reward()\n\n\ndef reward_function(params):\n    return reward_object.reward_function(params)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드 구현의 세부 사항에 관심이 있는 분들을 위해, 제 GitHub 저장소를 살펴보실 것을 초대합니다:\n\n# 감사의 말\n\n이 모델을 교육하는 경험은 절대적으로 즐거웠으며 가치 있는 학습 여정이었습니다. 강화 학습에 대한 실용적인 통찰을 얻을 뿐만 아니라, 즐거운 레이싱 게임 측면 때문에 이를 수행하는 데 즐거움을 느꼈습니다. 이 경험을 가능하게 해 준 주최자들께 감사의 말씀을 전하고 싶습니다 (교육 시간은 싸지 않습니다)!\n\n이 GitHub 저장소를 완성하는 데 중요한 참고 자료로 사용된 두 명의 저자 dgnzlz 및 GitHub 사용자 oscarYCL의 역할에 감사의 의미를 표합니다. Capstone_AWS_DeepRacer 및 deepracer-waypoints-workshop이라는 저장소는 그들의 창의성과 기여가 귀중했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 이겪은 것은 팀워크입니다. 제 동료들과 함께 이 모델을 개발하는 과정을 즐겼습니다.\n\n# 참고\n\n- https://github.com/dgnzlz/Capstone_AWS_DeepRacer\n- https://github.com/oscarYCL/deepracer-waypoints-workshop\n- https://docs.aws.amazon.com/deepracer/latest/developerguide/deepracer-reward-function-input.html","ogImage":{"url":"/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_0.png"},"coverImage":"/assets/img/2024-06-23-EnhancingYourAWSDeepRacerPerformancewithGradientDescentAlgorithmandPersonalizedWaypoints_0.png","tag":["Tech"],"readingTime":12},{"title":"파스칼의 삼각형을 간단하고 빠르게 이해하는 방법","description":"","date":"2024-06-23 18:26","slug":"2024-06-23-AShortandDirectWalkwithPascalsTriangle","content":"\n\n## 경로 탐색 알고리즘을 세는 것으로 개선할 수 있다면?\n\n![이미지](/assets/img/2024-06-23-AShortandDirectWalkwithPascalsTriangle_0.png)\n\n다익스트라(Dijkstra) 알고리즘과 A*와 같은 고전적인 경로 탐색 알고리즘은 비디오 게임, 모바일 로봇공학 및 건축 설계와 같은 응용 프로그램에서 여행 경로를 생성하는 데 사용됩니다. 이러한 알고리즘의 인기에도 불구하고, 그들이 생성하는 경로는 거의 직선으로 이어지지 않습니다. 이 문서에서는 Pascal의 삼각형에서 영감을 받은 계산 기술을 사용하여 매우 직접적인 경로를 계산하는 방법에 대해 배울 수 있습니다. 이는 제 동료들과 제가 개발한 아이디어로, 최근 인공지능 연구 저널에 발표되었습니다. 전통적인 경로 탐색의 오래된 문제를 극복할 수 있는 쉬운 경로 수 세기 단계를 통해 경로를 계산할 수 있습니다.\n\n# 미관코의 경로 문제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 분야에서 짧고 직접적인 경로를 계산해야 하는 필요성이 발생합니다. 건물 설계자들은 길찾기 도구를 사용하여 사람들이 가장 가까운 비상구에 도달하기 위해 얼마나 걷어야 하는지 분석합니다. 일부 건축가들은 한 걸음 더 나아가 건물을 대피하는 사람들의 군중을 시뮬레이션하며, 이는 모든 건물 거주자를 위한 대피 경로를 생성해야 합니다. 비디오 게임 개발자들은 AI가 제어하는 에이전트가 맵 상에서 어떻게 이동해야 하는지 결정하기 위해 경로 탐색 알고리즘을 활용합니다.\n\n경로 찾기를 구현하는 가장 간단하고 인기 있는 방법 중 하나는 맵을 그리드 형식으로 표현한 다음, Dijkstra's Algorithm이나 A*와 같은 고전적인 검색 방법을 적용하여 가능한 최단 거리의 그리드 경로를 찾는 것입니다. 아래 애니메이션은 시작 위치 A에서 목적지 B까지의 최단 그리드 경로의 예시를 보여줍니다. 그림자가 있는 그리드 셀은 피해야 할 벽 또는 다른 장애물을 나타냅니다. 일단은 그리드 경로를 따라 이동할 때 각 이동이 북쪽, 남쪽, 동쪽 또는 서쪽 중 하나의 방향으로 한 걸음이라고 가정하겠습니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*L-is8Tk78R2rCC1vOPsc7g.gif)\n\n위 경로는 A에서 B로 가는 400개의 최단 그리드 경로 중 하나입니다. 또한 매우 간접적인 경로입니다. 명백한 직선 최단거리를 활용하지 않습니다. 만약 그리드에 따라 걷어야 하는 의무가 없는 경우 실제로 사람이 따르는 직접적인 경로와는 크게 다릅니다. Amit Patel의 Red Blob Games 튜토리얼에서 A*를 구현하는 방법에 대해 설명한 내용에 따르면 이러한 \"못생긴 경로\"는 널리 발생하는 문제라고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nThe ugly path problem can be tackled in a brute force manner by testing up to hundreds of thousands of possible straight-line shortcuts during an A* path search. An algorithm called Theta*, which was published in 2010, uses this approach. In order to avoid all these line-of-sight tests, our strategy is to select a shortest grid path that happens to approximate a direct route. Of the 400 shortest grid paths in our example, the path below is the one we would select.\n\n![Image](https://miro.medium.com/v2/resize:fit:1400/1*82ROrH4W04_B9M5apco4Jg.gif)\n\nThis central grid path isn’t actually shorter than the indirect grid path we saw previously. Both paths require 15 grid moves, and each move is one grid spacing in length. However, the central path is a better approximation of the smooth path a person would take in real life. One way to solve the ugly path problem is to find a simple and efficient method for producing central grid paths. Enter Pascal’s Triangle.\n\n# Pascal’s Triangle\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1655년에 프랑스 수학자 블레즈 파스칼이 '삼각수열에 관한 논문'을 발표했습니다. 이후 이 수열은 파스칼의 삼각형으로 알려지게 되었습니다.\n\n파스칼의 삼각형에 대한 분석은 니윗의 이항정리에 대한 기여뿐만 아니라 라이프니츠의 미적분학에도 영감을 주었습니다. 그러나 이 패턴을 처음 발견한 사람은 파스칼이 아니었습니다. 오리엔트(페르시아 및 중국), 인도에서 1000년 넘게 전 발견되었습니다.\n\n파스칼의 삼각형은 정점과 두 변이 다른 위치에 1을 둠으로써 형성됩니다. 나머지 숫자는 이전 두 숫자를 더하여 생성됩니다. 아래 애니메이션은 처음 5행에 대한 작업을 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-AShortandDirectWalkwithPascalsTriangle_2.png\" /\u003e\n\n파스칼의 삼각형은 매력적인 여러 성질로 유명합니다. 그 중 하나는 파스칼의 삼각형의 각 숫자를 경로 수로 해석할 수 있다는 점입니다: 삼각형 정점에서 해당 숫자의 위치까지의 가장 짧은 격자 경로 수입니다. 예를 들어, 애니메이션의 중앙 하단에 있는 육각형 격자 셀에는 숫자 6이 있으며, 삼각형의 맨 위 셀에서 해당 중앙 하단 셀까지의 정확히 6개의 가장 짧은 격자 경로가 있습니다. 이 애니메이션은 육각 격자를 보여줍니다만, 파스칼의 삼각형이 블레즈 파스칼의 이전 다이어그램처럼 사각 격자에 그려져 있을 때에도 이 성질은 유지됩니다.\n\n파스칼의 삼각형을 사용하여 격자 상의 경로 수를 세는 방법을 설명하는 온라인 기사와 비디오들이 많이 있습니다. 놀랍게도 우리는 한 단계 더 나아갈 수 있습니다. 파스칼의 삼각형은 우리에게 모든 가능한 경로 수를 세는 방법 뿐만 아니라 이러한 경로 중에서 가장 직접적인 경로 중 하나를 선택하는 방법도 보여줍니다.\n\n# Counting을 통한 Pathfinding\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새로운 경로 탐색 접근 방식은 각 그리드 셀을 통과하는 최단 경로의 수를 세고, 그 중 가장 높은 수를 가진 그리드 셀을 선택합니다.\n\n첫 번째 단계는 순방향으로 경로를 세는 것입니다. 아래 그림에서 보듯이 시작 위치 A에 숫자 1을 할당하는 것부터 시작합니다. 그리드 셀에 숫자가 할당되면, 해당 숫자는 최단 그리드 경로를 따라 다음 셀로 복사됩니다. 여러 경로가 만나는 경우, 숫자가 추가됩니다. Pascal의 삼각형과 유사하게, 결과적으로 각 그리드 셀은 A에서 해당 셀로의 최단 그리드 경로 수를 포함하게 됩니다. 예를 들어, 애니메이션에서 A와 12로 표시된 셀 사이에는 12개의 최단 그리드 경로가 있습니다. A와 B 사이에는 400개의 최단 그리드 경로가 있다는 사실에 주목해주세요.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*1rFU420fm5kfktpcMJigvQ.gif)\n\n그런 다음, 역방향으로 절차를 반복합니다. 이제 B에 숫자 1을 할당하고, A에 도달할 때까지 숫자를 복사하고 추가합니다. 결과적으로 모든 그리드 셀은 B에서 해당 셀로의 최단 그리드 경로 수를 포함하게 됩니다. 방향을 반전했지만 두 끝점 사이에 여전히 400개의 최단 그리드 경로가 있다는 점에 주목해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*pX75tvt6Iu0HdwlRIdvP7w.gif)\n\n다음 단계는 이 두 개의 경로 수 세트를 가져와 곱하여 단일 탐색 횟수 세트를 만드는 것입니다. 이 개념을 이해하려면 위의 애니메이션을 보고 A로부터 12개의 경로 수와 B로부터 20개의 경로 수를 가진 고유한 그리드 셀을 찾으십시오. 한 쪽에서의 12개 경로와 다른 쪽에서의 20개 경로는 12×20 개의 서로 다른 조합으로 결합될 수 있어서 A에서 B로 가는 도중에 이 그리드 셀을 통해 통과하는 경로가 240개 있다는 것을 의미합니다. 아래에서 볼 수 있듯이 이 셀의 탐색 횟수는 240입니다. 이 애니메이션은 각 그리드 셀에 대해 탐색 횟수가 계산되는 과정을 보여줍니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*PpM5hzKpMgrcwQk1M5Of6Q.gif)\n\n마지막 단계는 A에서 시작한 다음 B로 향하는 다음 그리드 셀을 반복해서 선택하고 가장 높은 탐색 횟수를 갖는 그리드 셀을 선택하는 것입니다. 아래의 애니메이션은 탐색 횟수를 표시하고 경로가 생성되는 과정을 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*bd3lyPgJHvHpT0Gsbp8w-w.gif)\n\n특정 방식으로 접근한 결과는 중심 그리드 경로입니다. 이는 사람이 걸어다닐 것으로 예상되는 경로를 근사한 직접적인 최단 그리드 경로입니다.\n\n# 경로 계산의 장점\n\n경로 계산이 미치는 영향을 살펴보려면, 아래에 일반적인 A* 구현체에 의해 생성된 임의 또는 \"추악한\" 최단 그리드 경로를 보면 됩니다. 이 맵은 Dragon Age: Origins 벤치마크 데이터셋에서 가져왔습니다. 이 그리드 경로는 큰 불필요한 지그재그를 보이며, 경로의 부드럽게 만든 버전조차 명백한 결함을 가지고 있습니다. 이미지를 클릭하여 자세히 살펴보세요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-AShortandDirectWalkwithPascalsTriangle_3.png\" /\u003e\n\nA*가 경로 카운팅과 함께 확장되면, 중심 그리드 경로가 지도의 빈 영역을 가로지를 때 시야선을 따라가게 됩니다. 아래 그림에서 보듯이, 지그재그가 가능한 한 작아졌으며, 부드럽게 만들 수 있습니다. 중심 그리드 경로를 계산하는 데 평균적으로 임의의 그리드 경로보다 약 40% 더 오래 걸립니다. 반면, A*에서 Theta*로 전환하면 계산 시간이 세 배로 증가할 것입니다. 본문에서 보는 것처럼, 경로를 계산하는 단계를 추가함으로써 결과 품질이 크게 향상됩니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-AShortandDirectWalkwithPascalsTriangle_4.png\" /\u003e\n\n위의 중심 경로는 가까운 평행한 경로를 근사하고 있는 것을 알 수 있습니다. 이러한 관찰은 중심 그리드 경로의 이론적 특성과 일치합니다. 같은 끝 점 사이에서 중심 경로를 계속해서 계산하지만 그리드 해상도를 점점 세밀하게 해본다고 상상해보십시오. 중심 극한 정리에 따르면, 이 중심 경로가 최종적으로는 어떠한 직선 단축을 활용하고 있다고 재경로화되며 다크한 경로에 수렴할 것입니다. 다시 말해, 중심 그리드 경로는 궁극적으로 완벽하게 직접적이게됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 실용적인 고려사항\n\n새로운 접근 방식은 중앙 그리드 경로 계획, 중앙 그리드 기반 경로 탐색 또는 카운팅에 의한 경로 탐색으로 언급될 수 있습니다. 이 기술을 구현에 관심이 있다면, 아래에 주의해야 할 몇 가지 실용적인 고려사항이 있습니다. 더 자세한 안내사항은 오픈 액세스 저널 논문 \"그리드 기반 네비게이션을 위한 경로 카운팅\" [1]에서 확인할 수 있습니다.\n\n- 먼저 Dijkstra 또는 A* 알고리즘을 사용한 후에 경로를 계산합니다. 이 논문의 애니메이션 예시는 모든 도달 가능한 그리드 셀이 최단 그리드 경로의 일부인 특수한 경우입니다. 일반적으로 Dijkstra 알고리즘 또는 A*를 사용하여 최단 그리드 경로의 방향성 비순환 그래프(DAG)를 생성하는 것이 좋습니다. 이 작업이 완료되면 경로 카운팅 작업은 원래 맵이 아닌 DAG에서 수행됩니다. 자세한 내용은 논문의 3.1 및 3.2절에서 확인할 수 있습니다. 결론적으로, 경로 계산은 Dijkstra 또는 A* 대안이 아니라 이러한 고전적인 경로 탐색 방법을 개선하는 방법입니다.\n- 큰 경로 횟수를 계산하기 위해 로그를 사용하세요. 경로 횟수는 그리드의 크기와 기하학적으로 증가합니다. 따라서 애니메이션 예시에서는 400개의 최단 그리드 경로가 있지만, 실제 응용 프로그램에서는 10의 400승 이상의 경로가 있을 수 있습니다. 이는 경로 횟수를 직접 나타내기 위해 64비트 부동 소수점 숫자를 사용하면 오버플로우할 수 있음을 의미합니다. 다행히 로그를 사용하여 간접적으로 경로 횟수를 처리할 수 있습니다. 논문의 3.2절은 이 접근 방식의 작은 것이지만 극도로 중요한 세부 조정을 설명합니다.\n- 가능한 경우 대각선 이동을 허용하세요. 애니메이션 예시에서 그리드 이동은 4개의 주요 이동(north, south, east, west)으로 제한됩니다. 더 나은 결과를 위해 4개의 대각선 이동(ne)으로도 허용하는 것이 최선입니다. 이 경우, 대각선 이동은 주이동보다 대략 40% 길다는 것을 기억해야 합니다. 또한 대각선 이동을 허용하는 경우, 두 그리드 셀 간의 등장 수에 따라 약간의 차이가 나타날 수 있는 반올림 오차에 주의해야 합니다. 논문의 예시에서는 주요 및 대각선 이동이 허용된 경우를 가정합니다.\n- 원하는 경우 최종 경로를 부드럽게 만드세요. 그리드 경로를 후처리 단계에서 부드럽게 만들어 원치 않는 지그재그를 제거하고 경로를 줄이는 것이 일반적인 방법입니다. 경로 계산과 경로 부드러움이 잘 결합된다는 것이 밝혀졌습니다. 논문의 3.3절은 중앙 그리드 경로를 부드럽게 만드는 것이 임의의 최단 그리드 경로를 부드럽게 만드는 것보다 더 짧은 이동 경로를 생성한다는 것을 보여줍니다.\n- 기존의 구현과 결과를 비교하세요. 작성 시점에서 중앙 그리드 기반 경로 찾기 도구가 하나 이상 존재합니다. SpaceAnalysis라는 저와 동료들이 개발한 건축 설계 도구가 그 예입니다. 더 많은 사람들이 이 기술에 대해 배우면 다른 구현이 나타날 것입니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n경로 계산은 파스칼의 삼각형의 핵심에서 잘 알려진 절차입니다. 또한 클래식한 경로 탐색 알고리즘에서 더 직접적이고 직선적인 이동 경로를 얻는 실용적인 방법입니다. 비디오 게임, 분석 도구 또는 심지어 모바일 로봇을 위한 간단한 내비게이션 방법이 필요하다면 논문을 확인하고 경로 계산을 시작해보세요!\n\n업데이트: 본문이 이제 3부작 시리즈의 첫 번째 글이 되었습니다. Grid-Based Visibility에서 볼 수 있는 영역을 계산하는 데 경로 계산을 어떻게 활용할 수 있는지 알아보세요. 그런 다음 배운 내용을 적용하여 3D 그리드 이웃을 다루는 A Sharp and Solid Outline of 3D Grid Neighborhoods를 확인하세요. 또한 이제 중앙 그리드 기반 경로 탐색의 오픈 소스 구현체가 있어 여러분의 프로젝트에서 사용할 수 있습니다. GitHub의 Central64 C++ 라이브러리를 확인해보세요.\n\n# 참고 자료\n\n[1] R. Goldstein, K. Walmsley, J. Bibliowicz, A. Tessier, S. Breslav, A. Khan, Path Counting for Grid-Based Navigation (2022), 인공지능 연구 저널, vol. 74, pp. 917–955\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[2] K. Daniel, A. Nash, S. Koenig, A. Felner, Theta*: Any-Angle Path Planning on Grids (2010), 인공 지능 연구 저널, 제39권, 553–579쪽\n\n[3] C. Cobeli, A. Zaharescu, Pascal의 삼각형을 따라 산책 — 숫자 동기 (2013) [PDF], 루마니아 수학 과학 협회 보고서, 제56권, 제104호, 73–98쪽\n\n[4] N. R. Sturtevant, 그리드 기반 경로 탐색을 위한 벤치마크 (2012) [PDF], 게임에서의 계산 지능과 AI에 관한 Transactions, 제4권, 제2호, 144–148쪽","ogImage":{"url":"/assets/img/2024-06-23-AShortandDirectWalkwithPascalsTriangle_0.png"},"coverImage":"/assets/img/2024-06-23-AShortandDirectWalkwithPascalsTriangle_0.png","tag":["Tech"],"readingTime":9},{"title":"애플의 부활부터 교황의 봇에 대한 생각까지 기술과 AI의 현재 트렌드 분석","description":"","date":"2024-06-23 18:26","slug":"2024-06-23-FromApplesRevivaltothePopesThoughtsonBots","content":"\n\n- 애플은 세계에서 가장 가치 있는 회사로 자리를 다시 차지했어요. 마이크로소프트와 엔비디아를 능가했답니다.\n- 이 테크 자이언트의 부활은 주로 ChatGPT를 다양한 제품에 통합한 데 기인합니다.\n- 이러한 움직임으로 애플의 생태계 전반에 걸쳐 사용자 경험을 혁신하고 생산성을 높이는 것으로 예상됩니다.\n\n## AI가 안드로이드에게 인간적인 느낌을 불어넣다\n\n- 중국에서 X Robots은 안드로이드의 현실적인 얼굴 표정을 보여주는 능력을 향상시킴으로써 안드로이드의 진보를 이끌고 있어요.\n- 이 로봇들은 주변 환경을 감지하고 인간다운 방식으로 반응하는 것이 설계되었어요.\n- 목표는 더 생동감 있고 반응성이 뛰어난 로봇을 만들어, 인간-로봇 상호작용을 혁신적으로 바꾸는 것입니다.\n\n## 교황의 AI에 대한 관점\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- G7 정상 회의 도중 교황은 인공지능에 대한 우려를 표명했습니다.\n- 그는 기술에 대한 인간의 통제를 유지하는 중요성을 강조했습니다.\n- 교황은 기계가 인간의 선택을 지배하는 미래에 대해 경고하며, AI의 윤리적 거버넌스 필요성을 강조했습니다.\n\n## 일론 머스크의 법적 후퇴\n\n- 일론 머스크가 ChatGPT 창조자인 OpenAI에 대한 소송을 의외로 철회했습니다.\n- 머스크는 이전에 OpenAI를 인류의 이익을 위해 AI를 개발하는 미션에서 벗어나 이윤에 집중하고 있다고 비난했습니다.\n- 머스크의 철회 이유는 공개되지 않았으며, 추측의 여지를 남겨 두었습니다.\n\n## 고양이 건강 관리의 AI\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 일본에서는 \"Cats Me\"라는 AI 기반 앱이 애완동물 건강 관리 분야에서 큰 반향을 일으키고 있습니다.\n- 이 앱은 수천 개의 고양이 이미지를 분석하여 고양이의 통증을 감지할 수 있습니다.\n- \"Cats Me\"은 출시 이후 23만 명 이상의 사용자를 확보하여 인기와 효과적임을 반영하고 있습니다.\n\n## 결론\n\nAI 기술은 Apple과 같은 주요 기술 기업부터 일본의 애완동물 건강 관리 분야에 이르기까지 다양한 분야에서 큰 발전을 이루고 있습니다. 이러한 발전은 흥미로운 가능성을 제시하지만 중요한 윤리적 문제도 제기합니다. AI를 받아들이는 동안 기술이 인류의 이익을 위해 봉사할 수 있도록 하는 것이 중요하며, 교황의 경고적인 말이 강조한 바와 같습니다. 누가 알았겠습니까, AI가 심지어 우리의 고양이 친구들에게도 도움을 줄 수 있다는 것을? 이것은 미래를 위한 혁신과 조심이 완벽하게 균형 잡힌 조화입니다.","ogImage":{"url":"/assets/img/2024-06-23-FromApplesRevivaltothePopesThoughtsonBots_0.png"},"coverImage":"/assets/img/2024-06-23-FromApplesRevivaltothePopesThoughtsonBots_0.png","tag":["Tech"],"readingTime":2},{"title":"28살에 수학 배우기","description":"","date":"2024-06-23 18:25","slug":"2024-06-23-Learningmathat28","content":"\n\n3학년 수학부터 시작하면 되겠네요. 두려워하고 흥분되는 일에 도전하는 건 시기를 놓친 일이 아닙니다.\n\n안녕하세요!\n\n저는 두려움과 흥분 속에서 당신에게 글을 씁니다. 지난 10년 동안 제게 잠재웠던 두려움에 마주하고 있습니다.\n\n5월에 소프트웨어 회사의 기술 컨설팅 직을 그만 두고 인생을 돌아보는 시간을 가졌어요. 지금 28살이고 한 가지 삶의 목표를 완수한 것 같아요. 저는 항상 컨설턴트가 되길 원했고 기술적으로 말하자면 그렇게 된 적이 있어요. 저는 기술 컨설턴트로 일하며 병원이 전자 건강 기록 소프트웨어를 도입하는 데 도움을 주었습니다. 그런데 그것이 제가 생각했던 컨설턴트의 이미지와는 조금 달랐어요. 저는 경영 컨설턴트가 되길 원했었죠. 그래서 어떻게 된 걸까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 지난 10년 동안의 경력 발전 소개.\n\n우리는 원점으로 돌아가야 해요. 대학교에 지원할 때, 경제학 전공을 희망했어요. 첫 경제학 수업을 듣고 학기를 끝내면 성적표에 큰 C가 있어 놀랐어요. 장학생으로서 저는 공포에 사로잡혔고 급히 더 편안한 심리학 전공으로 전과 했죠. 그 후 10년간의 경력 동안 수학을 피해왔어요. 졸업 이후부터 7개의 직장을 경험했는데, 언제나 내 전문 기술을 최대한 발휘하지 못하는 느낌이 들었어요. 승진을 시도하거나 부서 이동을 하려 할 때마다 수학과 데이터 분석 능력을 요구해서 현재의 역할에 갇히게 되었죠.\n\n삶의 궤적을 바꾸려던 다른 시도로 2년 전 MBA 프로그램에 지원했어요. 수학 실력이 좋지 않은 저에게도 놀랍게도 두 프로그램에 합격했어요. 저는 UNC Keanan-Flagler의 온라인 MBA와 University of Miami의 이중 학위 MBA 및 지속가능성 석사과정에 합격했어요. 아무도 놀랄 일이 아니겠지만 부분 장학금만 받았고 프로그램 시작 전에 수학 수업을 들어야 하는 보충 수학 트랙에 배정되었어요. 하지만 수업료를 감당할 수 없어서 거절하고 평범한 경력을 이어나가게 되었어요.\n\n지난 10년을 돌아보면, 다양한 산업과 직업에 흥미를 가졌지만 그 어느 것도 할 수 없었던 이유를 생각해봐요. 대학 시절에는 경영 컨설턴트가 되길 희망했고 졸업 한 해 뒤에는 소프트웨어 엔지니어가 되고 나중에는 데이터 과학자가 되길 원했어요. 졸업 6년 후에는 항공우주 공학을 시도하고 생명공학과 로보틱스를 거쳐했어요. 추세를 보이죠? 모든 분야에서 좋은 수학 실력이 도움이 되는 것 같아요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼 이제 어떻게 하면 좋을까요?\n\n## 계획을 실행에 옮겨봅시다.\n\n저는 28살이고 일자리가 없어요. 앞으로 1년 9개월 정도는 시간이 있어요. 제 계획은 수학을 배우는 것이에요. 저는 3학년부터 시작해서 수학을 배우고 있어요. 네, 맞아요. 28살인 저는 3학년 수학 문제집과 칸 아카데미로 수학을 공부하고 있어요. 목표는 대학 수준의 미적분학을 배울 때까지 이어가는 것이고, 그 후에 잠시 중단하고 반성할 거에요.\n\n왜 3학년 수학부터 시작하느냐구요? 저는 쿠바에서 미국으로 이사와서 5학년 때 ESOL 수업을 받았어요. 그 당시에 배운 내용은 기억도 안나요. 해야 할 일이 참 많아졌네요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로봇 공학과 전자에 대한 관심이 여전히 많아요. 우주 과학과 여성 건강을 위한 웨어러블 기기 내의 전자기기에 관심이 많아합니다. 수학에 자신감을 갖게 되면, 이러한 분야를 깊게 탐구할 수 있을 것 같아요.\n\n## 내 독자들에 대한 희망 ♥︎\n\n내 이야기를 따라가고 관심 있는 분들께, 당신들이 두렵고 흥분되는 일에 대처하는 데 영감을 받길 바래요. 두려워하는 건 너무 늦은 일이 아니에요. 오랫동안 하고 싶었지만, 두려움 때문에 기회를 놓친다고 믿거나, 더 이상 필요하지 않다고 생각하거나, 더 나쁜 경우에는 더 이상 관심이 없다고 생각한 일에 대해 생각해보세요. 그런 다음, 시작해야 할 단계가 무엇이든 두려움을 극복할 수 있는 행동 계획을 세워보세요.\n\n행복한 하루 보내세요 🌙,\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\ndataprincess\n\n![Learning Math at 28](/assets/img/2024-06-23-Learningmathat28_0.png)","ogImage":{"url":"/assets/img/2024-06-23-Learningmathat28_0.png"},"coverImage":"/assets/img/2024-06-23-Learningmathat28_0.png","tag":["Tech"],"readingTime":3}],"page":"11","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"11"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>