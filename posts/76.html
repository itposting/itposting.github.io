<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/76" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/76" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="윈도우 함수의 해부학" href="/post/2024-06-19-AnatomyofWindowsFunctions"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="윈도우 함수의 해부학" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-AnatomyofWindowsFunctions_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="윈도우 함수의 해부학" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">윈도우 함수의 해부학</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="카프카 API에 대한 부드러운 소개" href="/post/2024-06-19-AGentleIntroductiontoKafkaAPI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="카프카 API에 대한 부드러운 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="카프카 API에 대한 부드러운 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">카프카 API에 대한 부드러운 소개</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS Glue ETL을 사용하여 DynamoDB에서 Redshift로 데이터 이전하기" href="/post/2024-06-19-DynamoDBtoRedshiftusingAWSGlueETL"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS Glue ETL을 사용하여 DynamoDB에서 Redshift로 데이터 이전하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DynamoDBtoRedshiftusingAWSGlueETL_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS Glue ETL을 사용하여 DynamoDB에서 Redshift로 데이터 이전하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AWS Glue ETL을 사용하여 DynamoDB에서 Redshift로 데이터 이전하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="dbt 프로젝트 작업 흐름을 빠르게하는 방법 Makefile 사용하기" href="/post/2024-06-19-HowtouseaMakefiletospeedupyourdbtprojectworkflow"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="dbt 프로젝트 작업 흐름을 빠르게하는 방법 Makefile 사용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-HowtouseaMakefiletospeedupyourdbtprojectworkflow_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="dbt 프로젝트 작업 흐름을 빠르게하는 방법 Makefile 사용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">dbt 프로젝트 작업 흐름을 빠르게하는 방법 Makefile 사용하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI 개발에서의 데이터 개인 정보 보호 데이터 지역화" href="/post/2024-06-19-DataPrivacyinAIDevelopmentDataLocalization"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 개발에서의 데이터 개인 정보 보호 데이터 지역화" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DataPrivacyinAIDevelopmentDataLocalization_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 개발에서의 데이터 개인 정보 보호 데이터 지역화" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI 개발에서의 데이터 개인 정보 보호 데이터 지역화</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년을 위해 효과적으로 사용하는 방법과 함께 관리자 대시보드의 상위 10가지 유형" href="/post/2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년을 위해 효과적으로 사용하는 방법과 함께 관리자 대시보드의 상위 10가지 유형" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년을 위해 효과적으로 사용하는 방법과 함께 관리자 대시보드의 상위 10가지 유형" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">2024년을 위해 효과적으로 사용하는 방법과 함께 관리자 대시보드의 상위 10가지 유형</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 과학을 위한 상위 5개의 Python 프론트엔드 라이브러리" href="/post/2024-06-19-Top-5PythonFrontendLibrariesforDataScience"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 과학을 위한 상위 5개의 Python 프론트엔드 라이브러리" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 과학을 위한 상위 5개의 Python 프론트엔드 라이브러리" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">데이터 과학을 위한 상위 5개의 Python 프론트엔드 라이브러리</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="사막  숨겨진 네트워크" href="/post/2024-06-19-DuneAHiddenNetwork"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="사막  숨겨진 네트워크" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-DuneAHiddenNetwork_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="사막  숨겨진 네트워크" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">사막  숨겨진 네트워크</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마이크로소프트 엑셀에서 대시보드 만들기  단계별 방법 제1부" href="/post/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마이크로소프트 엑셀에서 대시보드 만들기  단계별 방법 제1부" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마이크로소프트 엑셀에서 대시보드 만들기  단계별 방법 제1부" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">마이크로소프트 엑셀에서 대시보드 만들기  단계별 방법 제1부</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 시각화 AI 에이전트의 성능 향상 - Performance Improvement" href="/post/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 시각화 AI 에이전트의 성능 향상 - Performance Improvement" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 시각화 AI 에이전트의 성능 향상 - Performance Improvement" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">데이터 시각화 AI 에이전트의 성능 향상 - Performance Improvement</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 19, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/61">61</a><a class="link" href="/posts/62">62</a><a class="link" href="/posts/63">63</a><a class="link" href="/posts/64">64</a><a class="link" href="/posts/65">65</a><a class="link" href="/posts/66">66</a><a class="link" href="/posts/67">67</a><a class="link" href="/posts/68">68</a><a class="link" href="/posts/69">69</a><a class="link" href="/posts/70">70</a><a class="link" href="/posts/71">71</a><a class="link" href="/posts/72">72</a><a class="link" href="/posts/73">73</a><a class="link" href="/posts/74">74</a><a class="link" href="/posts/75">75</a><a class="link posts_-active__YVJEi" href="/posts/76">76</a><a class="link" href="/posts/77">77</a><a class="link" href="/posts/78">78</a><a class="link" href="/posts/79">79</a><a class="link" href="/posts/80">80</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"윈도우 함수의 해부학","description":"","date":"2024-06-19 16:08","slug":"2024-06-19-AnatomyofWindowsFunctions","content":"\n\n## 소극적으로 여겨지는 SQL 작업의 이론과 실무\n\n![이미지](/assets/img/2024-06-19-AnatomyofWindowsFunctions_0.png)\n\n# 소개\n\nIT 분야는 매일 새로운 도구, 새로운 프레임워크, 새로운 클라우드 제공업체, 그리고 새로운 LLM이 생성되는 등 끊임없는 변화로 유명합니다. 그러나 이 바쁜 세계에서도 몇 가지 원칙, 패러다임, 그리고 도구는 '모든 것이 영원하지 않다'는 상태 쿼를 도전하는 것처럼 보입니다. 특히 데이터 분야에서는 SQL 언어만큼 강제적인 예가 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n80년대에 탄생한 이후 데이터 웨어하우스 시대를 지나 Hadoop/Data-lake/Big Data로 활용되어 Hive로 거듭난 뒤 지금은 Spark API 중 하나로 살아 숨 쉬고 있어요. 세상은 많이 변했지만 SQL은 여전히 중요하고 존재감이 크죠.\n\n하지만 SQL은 마치 체스와 같아요. 기본 규칙을 이해하기 쉽지만 스스로를 완전히 다루기는 어려운 것 같아요! SQL은 많은 가능성을 지니고 있으며 같은 문제를 해결하는 다양한 방법, 다양한 함수와 키워드를 가지고 있습니다. 불행히도, 더 많이 알려지지 않은 기능들이 많아요. 이를 알면 쿼리를 작성할 때 많은 도움이 될 수 있습니다.\n\n그래서 이번 포스트에서는, 일상적인 쿼리를 작성할 때 굉장히 유용하게 느껴졌던, 그리 잘 알려지지 않은 SQL의 기능 중 하나에 대해 이야기해보려고 해요: 윈도우 함수.\n\n# 윈도우 함수란 무엇인가\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전통적이고 가장 유명한 SGBD(PostgreSQL, MySQL 및 Oracle)는 관계 대수 개념에 기반을 두고 있습니다. 여기에는 행이 튜플로 불리며 테이블은 관계로 불립니다. 관계란 튜플들의 집합으로, 즉 튜플 간의 순서 또는 연결이 없습니다. 그래서 테이블 내의 행에 대한 기본적인 순서가 없으며, 한 행에 수행된 계산은 다른 결과에 영향을 주지 않으며 다른 결과에도 영향을 받지 않습니다. ORDER BY와 같은 절조차도 테이블만을 정렬할 뿐, 다른 행의 값을 기반으로 한 행에서의 계산을 수행하는 것은 불가능합니다.\n\n간단히 말하면, 윈도우 함수가 이를 해결해주며 SQL 기능을 확장하여 다른 행의 값을 기반으로 한 행에서 계산을 수행할 수 있습니다.\n\n# 이해를 돕는 기본 사례/해부학\n\n1- 집계 함수 사용하지 않고 집계하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWindows 함수를 이해하는 가장 단순한 예는 '집계하지 않고 집계하는' 능력입니다.\n\n전통적인 GROUP BY를 사용하여 집계를 수행하면 전체 테이블이 두 번째 테이블로 압축되어 각 행이 그룹의 요소를 나타내게 됩니다. 그러나 Windows 함수를 사용하면 행을 압축하는 대신 동일한 테이블에 집계 결과가 포함된 새 열을 생성할 수 있습니다.\n\n예를 들어, 비용 테이블에서 모든 지출을 더해야 한다면, 전통적으로는 다음과 같이 수행할 것입니다:\n\n```js\nSELECT SUM(value) AS total FROM myTable\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWindows 함수를 사용하면 아래와 같이 만들 수 있어요:\n\n```js\nSELECT *, SUM(value) OVER() FROM myTable\n-- 창 함수(window function)가 쿼리에서 열 레벨에 정의됨에 주목하세요\n```\n\n아래 이미지는 결과를 보여줍니다:\n\n![윈도우 함수의 구조](/assets/img/2024-06-19-AnatomyofWindowsFunctions_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새로운 테이블을 생성하는 대신, 집계 값은 새로운 열에 반환됩니다. 값은 같지만 테이블이 '요약'되지 않았습니다. 원본 레코드가 유지되었고 계산된 집계를 집계하지는 않았다는 것을 주목하세요 ;)\n\nOVER 절은 윈도우 함수를 생성함을 나타냅니다. 이 절은 계산이 이루어질 레코드를 정의합니다. 위의 코드가 비어있으므로 모든 레코드에 대해 SUM()을 계산합니다.\n\n이는 열의 합계(또는 평균, 최솟값, 최댓값)을 기반으로 계산이 필요할 때 유용합니다. 예를 들어 각 비용이 총 비용에 대한 백분율로 얼마나 기여하는지를 계산하는 경우입니다.\n\n실제 케이스에서는 회사 부서별로 비용이 있는 예처럼 특정 카테고리에 대한 자세한 내용이 필요할 수 있습니다. 다시 말해서, 각 부서별 총 지출을 간단한 GROUP BY로 얻을 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nmyTable에서 depto 및 총합(value)을 그룹화하여 SELECT합니다.\n\n또는 윈도우 함수에서 PARTITION 로직을 지정할 수 있습니다.\n\nmyTable을 PARTITION BY depto로 지정하여 SELECT 및 SUM(value)을 실행합니다.\n\n결과를 확인하세요.\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![AnatomyofWindowsFunctions_2](/assets/img/2024-06-19-AnatomyofWindowsFunctions_2.png)\n\n이 예제는 해당 기능이 '창' 함수로 불리는 이유를 이해하는 데 도움이 됩니다. OVER 절은 해당 함수가 작동할 '창' 즉, 테이블의 일련의 줄을 정의합니다.\n\n위의 경우, SUM() 함수는 depto 열 (RH 및 SALES)에 의해 생성된 파티션에서 작동합니다. 이 함수는 depto 열의 각 항목에 대해 '값' 열의 모든 값들을 각각 개별적으로 합산합니다. 줄이 속한 그룹 (RH 또는 SALES)에 따라 '총계' 열의 값이 결정됩니다.\n\n2 — 시간과 순서의 인식\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가끔은 다른 행의 값에 기반하여 하나의 행 안의 열의 값을 계산해야 할 때가 있습니다. 전형적인 예로 현재 값과 이전 값에서 계산한 국가의 GDP의 연간 증가율이 있습니다.\n\n지난 해의 값을 필요로 하는 이러한 계산, 현재 및 이전 행의 차이, 시리즈의 첫 번째 값 등을 필요로 하는 경우는 윈도우 함수의 강력함을 증명합니다. 사실, 표준 SQL 명령어로 이러한 동작을 달성할 수 있는지 모르겠습니다! 아마 가능할 것이지만, 매우 복잡한 쿼리가 될 것입니다...\n\n그러나 윈도우 함수를 사용하면 간단하게 할 수 있습니다. 아래 이미지는 (어린이의 키를 기록하는 테이블입니다):\n\n![테이블 스냅샷](/assets/img/2024-06-19-AnatomyofWindowsFunctions_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT \n  year, height, \n  LAG(height) OVER (ORDER BY year) AS height_last_year\nFROM myTable\n```\n\nLAG('column') 함수는 이전 행의 'column' 값을 참조하는 역할을 합니다. 이것을 한 단계씩의 순차적인 단계로 상상해볼 수 있습니다: 두 번째 행에서는 첫 번째 값을 고려하고, 세 번째 행에서는 두 번째 값을 고려하고, 그 다음 계속 됩니다... 첫 번째 행은 카운트되지 않습니다(따라서 NULL 값이 반환되는 것), 이전 행이 없기 때문입니다.\n\n당연히 '이전 행'을 정의하기 위해 어떤 순서 조건이 필요합니다. 여기에서 윈도우 함수의 또 다른 중요한 개념인 분석 함수가 필요합니다.\n\n전통적인 SQL 함수와 대조적으로 분석 함수(LAG과 같은)는 행들 사이에 순서가 존재한다고 가정합니다 — 이 순서는 OVER() 안에 있는 ORDER BY 절에 의해 정의됩니다, 즉, 처음, 두 번째, 세 번째 행 등의 개념은 OVER 키워드 내에서 정의됩니다. 이러한 함수들의 주요 특징은 현재 행과 상대적인 다른 행을 참조할 수 있는 능력입니다: LAG는 이전 행을 참조하고, LEAD는 다음 행을 참조하고, FIRST는 분할 내 첫 번째 행을 참조하고, 등등이 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLAG 및 LEAD의 멋진 점 중 하나는 두 번째 인수인 오프셋을 받아들인다는 것입니다. 이 오프셋은 LEAD의 경우 앞으로 몇 개의 행(LEAD) 또는 뒤로 몇 개의 행(LAG)을 살펴볼지를 지정합니다.\n\n```js\nSELECT \n    LAG(height,  2) OVER (ORDER BY year) as height_two_years_ago,\n    LAG(height,  3) OVER (ORDER BY year) as height_three_years_ago,\n    LEAD(height)    OVER (ORDER BY year) as height_next_year\nFROM ...\n```\n\n또한 이러한 함수들로 계산을 수행하는 것도 완벽하게 가능합니다:\n\n```js\nSELECT \n    100*height/(LAG(height) OVER (ORDER BY year)) \n    AS \"annual_growth_%\"\nFROM ...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3 - 시간 인식과 집계\n\n시간과 공간은 하나라고 아인슈타인이 한번 말했던 적이 있는데, 그런 느낌인 것 같아요. 잘 모르겠어요 ¯\\_(ツ)_/¯\n\n이제 파티션 분할과 정렬하는 방법을 알았으니, 두 가지를 함께 사용할 수 있어요! 이전 예제로 돌아와서, 그 표 위에 더 많은 아이들이 있다고 상상해 봅시다. 우리는 각 아이의 성장률을 계산해야 할 때가 왔어요. 매우 간단해요. 정렬과 파티션을 결합해 보세요! 년도별로 정렬하고 아이 이름별로 파티션하면 되겠네요.\n\n```js\nSELECT 1-height/LAG(height) OVER (ORDER BY year PARTITION BY name) ...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-AnatomyofWindowsFunctions_4.png\" /\u003e\n\n위의 쿼리는 다음을 수행합니다 — child에 따라 테이블을 분할하고 각 분할에서 년도별로 값을 정렬한 후 현재 년도의 높이 값을 이전 값으로 나눈 다음 (결과를 1에서 빼서) 계산합니다.\n\n'윈도우(window)'의 전체 개념에 점점 다가가고 있어요! 이것은 '윈도우(window)'가 테이블 슬라이스이며, PARTITION BY에서 정의된 열로 그룹화된 행 세트로서, ORDER BY에서 정의한 필드로 정렬되어, 동일한 그룹(분할) 내의 행만을 고려하며 특정 순서로 모든 계산이 이루어진다는 것입니다.\n\n4-순위 및 위치\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWindows 함수는 세 가지 카테고리로 나뉠 수 있는데, 그 중 두 가지에 대해 이미 이야기했습니다: 집계 함수 ( COUNT, SUM, AVG, MAX, ... )와 분석 함수 ( LAG, LEAD, FIRST_VALUE, LAST_VALUE, ... ).\n\n세 번째 그룹은 가장 간단한 순위 함수입니다. 그 중에서도 row_number() 함수가 가장 큰 영향을 미칩니다. 해당 함수는 그룹 내에서 행의 위치를 나타내는 정수를 반환합니다 (정의된 순서에 따라).\n\n```js\nSELECT row_number() OVER(ORDER BY score)\n```\n\n순위 함수는 이름에서 알 수 있듯이 그룹 내 라인의 위치에 따라 값이 반환되며, 정렬 기준에 따라 정의된 그룹입니다. ROW_NUMBER, RANK 및 NTILE이 가장 많이 사용되는 함수 몇 가지입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 이미지에서 각 플레이어의 점수에 기반한 행 번호가 생성됩니다.\n\n... 그리고 네, 1부터 시작하는 끔찍한 프로그래밍 죄악을 저질립니다.\n\n5-창 크기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현재까지 소개된 모든 함수들은 결과를 계산할 때 파티션/그룹 내의 모든 행을 고려합니다. 예를 들어, 첫 번째 예제에서 설명한 SUM() 함수는 총계를 계산할 때 모든 부서의 행을 고려합니다.\n\n하지만 더 작은 창 크기를 지정하여 현재 행 전후 몇 줄을 계산에 고려할 수도 있습니다. 이는 이동 평균/롤링 윈도우를 계산하는 데 유용한 기능입니다.\n\n다음 예제를 고려해 봅시다. 특정 질병의 일일 발병 건수를 포함하는 표가 있고, 현재 날짜와 이전 2일을 고려하여 발병 건수의 평균을 계산해야 하는 경우를 생각해 봅시다. 앞서 소개된 LAG 함수로도 이 문제를 해결할 수 있다는 점을 주목해 주세요:\n\n```js\nSELECT\n( n_cases + LAG(n_cases, 1) + LAG(n_cases, 2) )/3\nOVER (ORDER BY date_reference)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 더 우아하게 동일한 결과를 얻을 수 있습니다. 프레임 개념을 사용하여:\n\n```js\nSELECT\nAVG(n_cases)\nOVER (\n ORDER BY date_reference\n ROWS BETWEEN 2 PRECEDING AND CURRENT ROW \n)\n```\n\n위의 프레임은 이전 2개의 행과 현재 행에 대해서만 평균을 계산해야 함을 지정합니다. 이전, 현재 행 및 다음 행을 모두 고려하고 싶다면, 프레임을 변경할 수 있습니다:\n\n```js\nAVG(n_cases)\nOVER (\n ORDER BY date_reference\n ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n그것이 프레임이란 거에요 — 특정한 범위 내에서 함수의 작용을 제한하는 방법입니다. 대부분의 경우, 윈도우 함수는 다음과 같은 프레임을 고려합니다:\n\n```js\nROWS BETWEEN UNBOUDED PRECEDING AND CURRENT ROW\n-- 이전의 모든 행 + 현재 행\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-AnatomyofWindowsFunctions_6.png\" /\u003e\n\n이 소개가 윈도우 함수가 무엇이고, 어떻게 작동하며, 실제 구문은 어떻게 되는지 더 잘 이해하도록 도와드리기를 바랍니다. 당연히 윈도우 함수에는 많은 다른 키워드가 추가될 수 있지만, 이미 다룬 명령어들이 일상 생활에서 많이 사용될 것으로 생각합니다. 이제 제가 일상에서 문제를 해결하기 위해 사용하는 흥미로운 실용적인 응용 프로그램 중 일부를 살펴보겠습니다 — 아주 흥미로운 것들이 있답니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Windows 함수의 흥미로운 사용 사례\n\n## 시간별 누적 합계\n\n이것은 Windows 함수를 사용하는 가장 고전적인 사례 중 하나입니다.\n\n매월 당신의 급여가 나와 있는 표가 있다고 상상해보세요. 각 달에 얼마를 벌었는지 누적으로 알고 싶다면(이전 달 모두를 고려하여), 이것이 작동하는 방식입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아주 쉽죠?\n\n이 쿼리에서 흥미로운 점은 SUM() 함수가 현재 행 및 이전 모든 행을 고려하여 집계를 계산한다는 것입니다.\n\n## 로그 테이블의 이벤트 지속 시간\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 최근에 작성한 포스트인 \"덕DB의 My First Billion (of Rows)\"에서는 브라질의 전자 투표 기계에서 로그를 조작하는 내용을 다뤘어요. 대량의 데이터 처리에 관심이 있다면 한 번 확인해보세요.\n\n요약하면, 각 이벤트가 시작된 시간을 나타내는 타임스탬프와 이름, 그리고 고유 식별자로 구성된 로그 테이블을 상상해보세요. 각 이벤트는 이전 이벤트가 끝날 때 시작되기 때문에, 이벤트 기간을 나타내는 열을 쉽게 추가할 수 있어요:\n\n![이미지](/assets/img/2024-06-19-AnatomyofWindowsFunctions_8.png)\n\n## 누락된 값 채우기 (마지막 발생으로)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n판다스를 활용한 머신 러닝 클래식! fillna, bfill 또는 다른 방법으로 널 값을 채우는 것만으로도 데이터 처리를 해결할 수 있어요.\n\nSQL에서는 이를 어떻게 할까요? 간단해요!\n\n![이미지](/assets/img/2024-06-19-AnatomyofWindowsFunctions_9.png)\n\n머신 러닝을 처음 공부할 때는 판다스와 같은 고수준의 함수들을 많이 사용하곤 해요. 하지만 실제 프로젝트를 진행할 때는 데이터 양이 매우 많아 판다스를 사용할 수 없는 경우가 많아요. 그럴 때는 PySpark, Snowflake, Hive+hadoop 등의 도구를 사용해야 하는데, 이들은 어떤 식으로든 SQL에서 작업이 가능해요. 그렇기 때문에 SQL에서 이러한 처리와 전처리를 어떻게 하는지 배우는 것이 중요하다고 생각해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 누락된 값 채우기 (앞 행의 평균으로)\n\n널(빈 값)을 채우는 더 다양한 방법, 그래도 간단합니다!\n\n![Windows Functions](/assets/img/2024-06-19-AnatomyofWindowsFunctions_10.png)\n\n이 예는 윈도우 함수가 복잡하고 특별한 것으로 보일지라도 일반 열처럼 사용할 수 있다는 것을 강조합니다! CASE에 포함시킬 수 있고, 계산에 활용할 수 있습니다. 알고 있는 제한 사항 중 일부는 WHERE 절에 직접적으로 배치할 수 없다는 것뿐입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\nSELECT * FROM\nWHERE SUM() OVER() \u003e 10 -- 이 기능은 postgres에서는 불가능합니다.\n```\n\n## 특정 열 기반의 행 중복 제거\n\n윈도우 함수의 또 다른 고전적인 사례! 때로는 하나의 열 집합을 기준으로 하여 테이블의 행을 중복 제거해야 할 때가 있습니다.\n\n물론 SQL에서는 DISTINCT 절을 사용할 수 있지만, 이는 전체 행이 중복될 때만 작동합니다. 테이블에 같은 ID 열의 값이지만 나머지 열에서는 다른 값이 있는 여러 행이 있는 경우 다음 로직을 사용하여 중복을 제거할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-AnatomyofWindowsFunctions_11.png\" /\u003e\n\n```js\nSELECT *\n  FROM (\n   SELECT\n   ROW_NUMBER() OVER (PARTITION BY id) as row_number\n  )\nWHERE row_number = 1\n```\n\n이 작업은 데이터 버전 관리도 가능합니다! 예를 들어, 시스템에서 사용자가 이름을 변경할 때마다 변경 날짜와 함께 새로운 줄을 저장하면(기존 줄을 변경하는 대신), 각 사용자의 현재 이름을 검색할 수 있습니다:\n\n```js\nSELECT\n    *\nFROM\n(\n  SELECT \n    name, \n    row_number() OVER (PARTITION BY id ORDER BY DATE DESC) AS row_number\n  FROM myTable\n) AS subquery\nWHERE row_number = 1\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003ctable\u003e 태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 여러분, Windows 함수의 흥미로운 케이스가 있나요? 공유하고 싶은 내용이 있다면 댓글에 남겨주세요!\n\n# 결론\n\nSQL이 고전적이거나 클래식하다고 말할 수 없겠죠. 이런 용어들은 과거를 가리키지만, SQL은 저에게 있어 현재에서 매우 중요하며 데이터 분야에서 일하는 사람들에게 꼭 필요한 언어입니다.\n\n그렇지만 SQL로만 해결하기 어려운 문제들이 몇 가지 있을 수도 있습니다. 이럴 때는 언어와 그 능력에 대한 좋은 이해가 정말 중요합니다. Windows 함수가 없다면, Python 관점에서는 보편적으로 간주되는 많은 문제들이 매우 어려우거나 심지어 불가능할 수도 있습니다. 하지만 우리가 도구를 올바르게 사용하는 방법을 안다면 마법을 부릴 수 있습니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 게시물이 Windows 기능이 작동하는 방식과 실제로 해결할 수 있는 문제 유형을 더 잘 이해하는 데 도움이 되었으면 좋겠습니다. 여기에 제시된 모든 자료는 주로 PostgreSQL 구문을 기반으로 하고 있으며, 다른 데이터베이스에서는 바로 작동하지 않을 수 있지만 가장 중요한 것은 논리 자체입니다. 항상 전문가가 아니며, 해당 주제에 관심이 있는 모든 분들에게 깊이 있는 학습 및 많은 실습을 권장합니다.\n\n독자 여러분, 감사합니다! ;)\n\n# 참고 문헌\n\n[1] PostgreSQL 윈도우 함수를 사용한 데이터 처리. (미상). Timescale. 링크.\n[2] Kho, J. (2022, June 5). 고급 SQL 윈도우 함수 쉬운 안내 — Towards Data Science. Medium.\n[3] Markingmyname. (2023, November 16). Funções analíticas (Transact-SQL) — SQL Server. Microsoft Learn.\n[4] PostgreSQL Tutorial. (2021, April 27). PostgreSQL 윈도우 함수: 궁극의 안내. 링크.\n[5] VanMSFT. (2023, May 23). OVER 절 (Transact-SQL) — SQL Server. Microsoft Learn.\n[6] 윈도우 함수. (미상). SQLite 공식 문서.\n[7] 윈도우 함수. (2014, July 24). PostgreSQL 문서.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 게시물의 모든 이미지는 저자가 제작했습니다.","ogImage":{"url":"/assets/img/2024-06-19-AnatomyofWindowsFunctions_0.png"},"coverImage":"/assets/img/2024-06-19-AnatomyofWindowsFunctions_0.png","tag":["Tech"],"readingTime":11},{"title":"카프카 API에 대한 부드러운 소개","description":"","date":"2024-06-19 16:05","slug":"2024-06-19-AGentleIntroductiontoKafkaAPI","content":"\n\n![Kafka API 소개](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_0.png)\n\n카프카는 링크드인에서 처음 시작되어 강력하고 확장 가능한 메시지 버스를 구축하기 위한 프로젝트입니다. 이는 링크드인의 데이터 인프라에서 중추적인 역할을 하였으며 독특한 기능과 능력으로 널리 채택되었습니다. 이 잠재력을 인지한 후, 2016년 링크드인은 카프카를 아파치 소프트웨어 재단에 기부하여 아파치 카프카로 발전시켜왔습니다. 이후 아파치 카프카는 초기 기능을 유지하면서 추가적인 기능과 개선을 얻게 되었습니다.\n\n카프카가 인기를 얻고 코드베이스가 성숙해짐에 따라 여러 업체가 자체 카프카 배포 버전을 출시하려고 포크했습니다. Redpanda나 Warpstream과 같은 기업들은 심지어 자바 이외의 다른 프로그래밍 언어로 전체 코드베이스를 다시 작성하는 일까지 진행했습니다.\n\n그러나 이러한 변경 사항들 속에서도 이 기업들은 중요한 한 가지를 변경하지 않으려았습니다 — 카프카 API입니다. 이 표준 인터페이스는 서로 다른 카프카 배포판 간의 호환성과 상호 운용성을 보장하는 데 중요한 역할을 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 아파치 카프카 대 Kafka API\n\n아파치 카프카와 Kafka API의 차이를 이해하는 것이 중요합니다. 이 둘은 서로 다른 개체들입니다.\n\n아파치 카프카는 분산형 병합 전용 커밋 로그입니다. 이는 프로듀서로부터 메시지를 수신하고 이를 내결함성을 가진 방식으로 저장하여 소비자가 수신된 순서대로 이러한 메시지를 가져올 수 있도록 합니다. 이러한 설계로 인해 카프카는 안정적이고 매우 확장 가능한 실시간 데이터 피드 처리를 위한 발행-구독 메시징 시스템으로 확립되었습니다.\n\n당신은 Kafka API를 통해 Kafka와 작업할 것입니다. 개발자로서, Kafka API를 사용하여 Kafka에 데이터를 읽고 쓸 수 있는 클라이언트 응용 프로그램을 작성할 것입니다. 운영자로서, Kafka API를 사용하여 Kafka에 관리 작업을 수행할 것입니다. Kafka 배포가 오픈 소스인지 상업용 제품인지에 상관없이, 여전히 동일한 Kafka API를 사용해야 합니다. 따라서 Kafka API를 이해하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_1.png)\n\n이 게시물에서는 Kafka 배포를 사용할 때 마주치게 될 고수준 개념을 다룰 것입니다. 이 내용은 특정 프로그래밍 언어나 벤더와 무관합니다. Kafka 프로토콜이나 API 메서드의 세부 내용에 대해 깊이 있게 다루지 않고 개념적으로 논의할 것입니다.\n\n# 브로커와 클러스터\n\nKafka는 브로커가 이 시스템 내에서 단일 노드를 나타내는 분산 시스템입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n부킹 애플리케이션에서 클라이언트를 여러 개의 브로커에 초기 연결하려면 어떻게 해야 하나요? Bootstrap Server 주소를 사용해야 합니다. 이는 애플리케이션이 클러스터 메타데이터를 얻기 위해 상호 작용하는 첫 번째 브로커입니다. 추후 상세히 다룰 주제입니다. 위의 이미지를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 메시지\n\n카프카 세계에서 메시지, 레코드, 이벤트 모두 같은 개념을 가리킵니다 - 응용 프로그램과 브로커 간에 전송되는 데이터의 단위입니다.\n\n메시지는 키(key)와 값(value)으로 구성됩니다. 값은 실제 데이터 또는 보내거나 받고 싶은 페이로드를 포함합니다. 키는 null을 포함한 모든 값을 사용할 수 있습니다. 일반적으로 값과 관련된 속성이 키로 지정됩니다. 예를 들어 값이 주문 객체인 경우 키는 고객 ID가 될 수 있습니다. 키를 가지는 이유는 메시지를 주제 내의 특정 파티션으로 라우팅하기 위한 것입니다. 우리는 파티션에 대해 알아갈 때 이에 대해 배우게 될 것입니다.\n\n![이미지](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n키와 값은 변수 길이의 바이트 배열로 표현됩니다. 이는 Kafka가 일반 텍스트에서 직렬화된 객체까지 다양한 데이터 유형을 처리할 수 있도록 합니다.\n\n# 토픽\n\n토픽은 메시지의 논리적 그룹화입니다. 관련된 레코드를 함께 유지하는 관계형 데이터베이스 세계의 테이블과 유사합니다. 서로 다른 목적을 위해 서로 다른 토픽을 가질 수 있습니다.\n\n토픽은 Kafka의 정보 계층구조에서 가장 높은 수준에 있습니다. 개발자로서 여러분은 클라이언트 응용 프로그램을 작성하게 될 것인데, 이는 다양한 토픽으로부터 데이터를 생성하고 소비합니다. 토픽은 메시지 브로커의 발행-구독 세맨틱스를 빌려옵니다. 토픽은 여러 생산자와 소비자에 의해 동시에 데이터 쓰기 및 읽기를 지원합니다. 또한 메시지가 한 토픽에서 생성되면 여러 소비자가 소비할 수 있는 방송/팬아웃 스타일 메시징을 지원합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주제는 추가 작업만을 허용하며 임의로 변경할 수 없습니다. 따라서 한 번 메시지를 주제에 쓰면 그것을 다시 업데이트할 수 없습니다. 또한 주제에서 읽는 것은 파괴적인 작업이 아닙니다. 동일한 소비자는 나중에 다시 필요에 따라 메시지를 다시 읽을 수 있습니다. 소비자 오프셋에 대해 언급할 때 이에 대해 알아보겠습니다.\n\n![image](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_4.png)\n\n# 파티션과 오프셋\n\n주제는 연속적이지 않고 파티션으로 구성됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주제는 논리적인 개념이며, 파티션은 더 구체적인 엔티티입니다.\n\n주제 파티션은 한 주제에 속한 데이터 하위 집합을 저장하는 append-only 정렬된 로그 파일입니다. 주제는 하나 이상의 파티션이 있을 수 있으며, 이러한 파티션은 클러스터의 다른 브로커에 분산되어 부하 분산 및 내결함성을 제공합니다.\n\n## 파티션의 필요성\n\n파티션 개념이 없고 Kafka가 주제 데이터를 단일 블록으로 유지한다면 어떻게 될까요? 먼저, 데이터가 더 많이 쌓일수록 주제의 크기가 증가하고 곧 단일 기계의 저장 한도를 초과할 것입니다. 추가 저장소를 연결하고 기계를 더 크게 만들 수는 있습니다. 그러나 결국 그에도 한계가 존재할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n둘째, 모든 소비자는 그 큰 주제를 보유한 브로커에서 소비해야합니다. 그렇게 하면 소비자 부하 분산이 없기 때문에 해당 브로커의 부하가 증가합니다. 게다가 그런 방대한 주제를 백업하는 것은 시간이 많이 소요되며, 해당 주제를 저장하고 있는 브로커가 충돌하면 데이터 전체를 잃을 위험이 큽니다.\n\n요약하자면, Kafka에서 주제 파티션을 가지는 것은 데이터를 클러스터 내의 여러 브로커로 분산할 수 있어서 유익합니다. 이 분산은 부하 분산과 장애 허용성을 향상시킵니다. 하나의 기계의 저장 한계를 넘어서 주제 데이터가 성장할 수 있기 때문에 시스템이 확장 가능해집니다. 또한, 파티션은 소비자 부하 분산을 가능하게 하며, 소비자는 서로 다른 브로커에서 소비할 수 있습니다. 이렇게 함으로써 시스템은 보다 효율적이고 신뢰할 수 있어지며, 한 브로커가 충돌하더라도 데이터를 모두 잃을 위험이 줄어듭니다.\n\n## 파티션 오프셋\n\n파티션 내 각 메시지는 고유한 오프셋을 받습니다. 이는 해당 파티션 로그 파일에서 메시지 위치를 나타내는 단조로 증가하는 정수입니다. 간단히 말해, 오프셋은 로그 파일의 시작으로부터 메시지가 얼마나 떨어져 있는지를 말합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메시지가 파티션에 작성되면 로그 끝에 추가되고 다음 순차적 오프셋이 할당됩니다. 오프셋은 소비자가 파티션에서 소비한 메시지를 추적하는 데 특히 유용합니다.\n\n![image](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_5.png)\n\n## 메시지 순서 및 파티션 라우팅\n\n파티션에 작성된 메시지는 항상 도착하는 순서대로 정렬됩니다. 그러나 토픽을 통해 메시지 순서가 보장되진 않습니다. 파티션 내에서 엄격한 순서가 필요한 경우 파티션 키를 올바르게 사용해야 합니다. 하지만 어떻게 해야 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 배운 바와 같이 메시지마다 키를 포함할 수 있습니다. 메시지를 수신하면 Kafka는 키에 해시 함수를 사용하여 메시지를 작성해야 하는 파티션을 결정합니다. 이를 통해 동일한 키로 생성된 모든 레코드가 보낸 순서대로 동일한 파티션에 도달한다는 것이 보장됩니다.\n\n![image](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_6.png)\n\n# 파티션 복제 - 리더와 팔로워\n\n파티션에는 여러 개의 복사본이 있을 수 있습니다. 이는 장애 허용 및 고가용성을 위해 복제됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n동일한 데이터의 여러 복사본을 유지함으로써 Kafka는 하나의 브로커가 실패하더라도 다른 브로커가 데이터를 제공할 수 있도록 합니다. 이 중복성을 통해 시스템은 장애에도 계속 작동할 수 있습니다. 또한 여러 브로커에 걸쳐 복제본을 갖고 있음으로써 Kafka는 읽기 및 쓰기 요청의 부하를 균형 있게 분산시켜 시스템 성능을 향상시킬 수 있습니다.\n\n토픽을 생성할 때 파티션 수와 복제 요소를 선택적으로 지정할 수 있습니다. 10개의 파티션과 복제 요소를 3으로 설정한 토픽의 경우, 클러스터 전체에 10x3=30개의 파티션이 저장됩니다.\n\n## 파티션 리더와 팔로워\n\n각 파티션 복제본은 리더 또는 팔로워 중 하나입니다. 리더 복제본은 해당 파티션의 모든 읽기 및 쓰기 요청을 처리하고, 팔로워 복제본은 리더를 수동으로 복제합니다. 리더가 실패하면 팔로워 복제본 중 하나가 자동으로 새로운 리더가 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_7.png)\n\nKafka는 파티션 리더를 어떻게 결정할까요? Kafka는 Apache Zookeeper와 같은 분산 콘센서스 알고리즘 구현에 의존하여 파티션에 대한 리더 선출을 처리합니다. 하나의 브로커가 실패하고 다시 온라인 상태로 돌아오거나 클러스터에 새 브로커가 추가될 때마다, ZooKeeper는 각 파티션에 대한 새 리더를 선출하는 데 도움을 줍니다. 선출 프로세스는 특정 파티션에 대해 한 번에 하나의 브로커만이 리더로 작동하도록 보장합니다.\n\n그러나 Kafka의 Zookeeper에 대한 의존성은 폐지되고 KRaft로 대체되고 있습니다. Redpanda와 같은 일부 브로커들은 브로커에 기본 Raft 구현을 통합했습니다.\n\n# Segments\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파티션은 실체가 있는 것이라고 언급했지만, 정확히 그렇지는 않아요. 파티션은 더 작은 세그먼트로 나뉩니다.\n\n세그먼트는 카프카 저장소의 데이터 포함의 가장 작은 단위로, 기본적으로 메시지의 일부를 보유하는 추가 전용 정렬된 로그 파일입니다. 여러 세그먼트가 모여 하나의 파티션을 형성합니다.\n\n각 파티션에는 항상 데이터를 수신하는 하나의 활성 세그먼트만 있습니다. 충분한 메시지가 활성 세그먼트에 축적되면 그 세그먼트는 닫히거나 다음 활성 세그먼트로 \"회전\"합니다. 이 세그먼트 크기는 설정 가능합니다.\n\n![이미지](/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시에어끼는 세그먼트에서 메시지는 삭제되거나 압축될 수 있어 디스크 공간을 절약할 수 있습니다. 이것은 구성 가능합니다. 게다가 티어드 스토리지를 사용하면 저렴한 비용으로 예전 로그 세그먼트를 아카이브할 수 있어, 예를 들어 스토리지 비용을 줄이기 위해 S3 버킷에 저장할 수 있습니다.\n\n파티션과 달리 세그먼트는 개발자에게 보이지도, 접근 가능하지도 않습니다. 이들은 주로 저장 및 운영 측면에 속합니다.\n\n# Kafka 클라이언트\n\n우리는 Kafka를 어리석은 파이프라고 말합니다. 그리고 프로듀서와 컨슈머는 스마트 엔드포인트입니다. 그들은 클라이언트 SDK에 포함된 많은 스마트 논리를 가진 두꺼운 클라이언트입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개발자로서는 대응하는 Kafka 클라이언트 SDK가 있는 모든 프로그래밍 언어로 Kafka 클라이언트를 작성할 수 있습니다. Java 및 Scala가 기본적이며 Python, .NET, Go, Rust, C++ 등의 언어에 대한 Kafka 클라이언트 SDK도 제공됩니다.\n\n생산자(Producer)는 메시지를 생성하고 Kafka 주제(Topic)로 전송하는 클라이언트 애플리케이션입니다. SDK는 생성하는 데 사용되는 send() 메서드를 노출하는데, 해당 메서드는 주제 이름, 키, 값 및 파티션 ID를 매개변수로 사용하여 오버로드되어 있습니다. SDK는 메시지를 파티션별로 그룹화하여 일정 임계치에 도달하면 일괄로 묶어서 각 일괄을 브로커에 전송합니다.\n\n소비자(Consumer)는 Kafka 주제로부터 메시지를 읽는 클라이언트 애플리케이션입니다. Kafka 클라이언트 SDK는 메시지를 한 번에 하나씩 또는 일괄로 소비하는 메서드를 제공합니다. 소비자는 하나 이상의 주제를 구독하고 메시지를 작성된 순서대로 소비할 수 있습니다.\n\n소비자 그룹(Consumer Group)은 여러 사용자가 레코드 처리 작업을 나누는 기능입니다. 여러 소비자가 주제를 구독하고 동일한 소비자 그룹에 속한 경우, 그룹의 각 소비자는 레코드의 일부를 받게 됩니다. Kafka는 메시지가 그룹 내 하나의 소비자만에 의해서만 소비되도록 보장하고 장애 발생 시 소비자를 균형있게 조정하여 확장성과 내결함성에 도움이 되는 유용한 기능입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_9.png\" /\u003e\n\n# 마무리\n\n요약하자면, 우리는 Kafka와 Kafka API의 기본 개념과 구성 요소를 다루었습니다. Kafka가 분산 추가 전용 커밋 로그로 작동하며 Kafka API가 이와 상호 작용하는 표준 인터페이스를 제공하는 방법에 대해 논의했습니다.\n\n브로커와 클러스터, 메시지, 토픽, 파티션, 오프셋 및 복제에 대한 개념, 세그먼트의 중요성 및 Kafka 클라이언트의 역할을 살폈다. 이러한 개념을 이해하는 것은 특정 배포 또는 프로그래밍 언어와는 무관하게 Kafka를 다루는 데 있어 중요합니다.","ogImage":{"url":"/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_0.png"},"coverImage":"/assets/img/2024-06-19-AGentleIntroductiontoKafkaAPI_0.png","tag":["Tech"],"readingTime":8},{"title":"AWS Glue ETL을 사용하여 DynamoDB에서 Redshift로 데이터 이전하기","description":"","date":"2024-06-19 16:04","slug":"2024-06-19-DynamoDBtoRedshiftusingAWSGlueETL","content":"\n\nAWS Glue ETL을 사용하여 DynamoDB에서 Redshift로의 파이프라인을 구축하는 과정은 여러 단계로 이루어져 있습니다. 아래에 이를 설정하는 자세한 가이드가 있어요:\n\n단계 1: DynamoDB와 Redshift 설정하기\n\n1. DynamoDB:\n이미 하지 않았다면 DynamoDB 테이블을 생성하고 데이터로 채워 넣어주세요.\n\n2.Redshift:\nAmazon Redshift 클러스터를 설정하세요.\nRedshift에 DynamoDB 테이블 구조와 일치하도록 데이터베이스와 테이블을 생성해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단계 2: DynamoDB용 AWS Glue 크롤러 생성하기\n\n1. AWS Glue 콘솔을 엽니다.\n2. 새 크롤러를 생성합니다:\n이름: 크롤러에 이름을 지정합니다.\n데이터 원본: DynamoDB를 선택하고 테이블을 선택합니다.\nIAM 역할: 없는 경우 필요한 권한을 가진 IAM 역할을 생성합니다.\n데이터베이스: 기존의 Glue 데이터베이스를 선택하거나 새 데이터베이스를 생성합니다.\n실행 빈도: 요구 사항에 따라 설정합니다.\n\n3. 크롤러 실행:\n이 작업을 통해 Glue 데이터 카탈로그에 DynamoDB 테이블을 위한 테이블이 생성됩니다.\n\n단계 3: AWS Glue ETL 작업 생성하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. AWS Glue 콘솔을 엽니다.\n2. 새 작업을 만듭니다:\n이름: 작업에 이름을 지정합니다.\nIAM 역할: 동일한 역할 또는 필요한 권한이 있는 다른 역할을 사용합니다.\n유형: \"Spark\"를 선택합니다.\nGlue 버전: 적절한 Glue 버전을 선택합니다.\n보안 구성, 스크립트 라이브러리 및 작업 매개변수: 필요에 따라 구성합니다.\n작업 북마킹: 처리된 데이터를 추적하려면 활성화합니다.\n\n3. 스크립트 편집기:\nGlue Studio 시각적 편집기를 사용하거나 스크립트를 직접 편집할 수 있습니다.\n\n단계 4: ETL 스크립트 작성\n\n다음은 다이나모DB에서 Redshift로 데이터를 이동하는 예제 스크립트입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\n# Glue 컨텍스트 초기화\nargs = getResolvedOptions(sys.argv, ['JOB_NAME'])\nsc = SparkContext()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\njob.init(args['JOB_NAME'], args)\n\n# DynamoDB 테이블을 소스로 정의\ndynamodb_table = \"dynamodb_table_name\"\ndatasource0 = glueContext.create_dynamic_frame.from_catalog(\n    database=\"your_glue_database\",\n    table_name=dynamodb_table\n)\n\n# 필요한 변환 작업 적용\napplymapping1 = ApplyMapping.apply(\n    frame=datasource0,\n    mappings=[\n        (\"dynamodb_column1\", \"string\", \"redshift_column1\", \"string\"),\n        (\"dynamodb_column2\", \"number\", \"redshift_column2\", \"int\"),\n        # 필요한 경우 더 많은 열 추가\n    ]\n)\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Redshift 연결 옵션 정의하기\nredshift_tmp_dir = “s3://your-bucket/temp-dir/”\nredshift_connection_options = '\n“url”: “jdbc:redshift://your-redshift-cluster:5439/your_database”,\n“user”: “your_redshift_user”,\n“password”: “your_redshift_password”,\n“dbtable”: “your_redshift_table”,\n“redshiftTmpDir”: redshift_tmp_dir\n'\n\n# Redshift로 쓰기\ndatasink4 = glueContext.write_dynamic_frame.from_jdbc_conf(\nframe = applymapping1,\ncatalog_connection = “your_redshift_connection”,\nconnection_options = redshift_connection_options\n)\n\n# 작업 완료하기\njob.commit()\n\n단계 5: Glue Job 실행 및 예약하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. 작업 실행\nAWS Glue 콘솔에서 작업을 수동으로 실행할 수 있습니다.\n2. 작업 일정 설정:\nGlue 트리거를 사용하여 특정 간격에 작업을 실행할 수 있는 일정을 설정하세요.\n\n단계 6: ETL 작업 모니터링 및 관리\n\n1. 모니터링:\nAWS Glue의 모니터링 기능을 사용하여 작업 실행, 오류 및 성능을 추적하세요.\n2. 오류 처리:\n필요한 경우 스크립트에 오류 처리를 구현하세요.\n3. 최적화:\n특히 대규모 데이터 집합을 처리할 때 성능을 위해 ETL 작업을 최적화하세요.\n\n이러한 단계를 따르면 AWS Glue ETL 작업을 사용하여 DynamoDB에서 Redshift로 데이터를 전송하는 파이프라인을 설정할 수 있습니다. 감사합니다.","ogImage":{"url":"/assets/img/2024-06-19-DynamoDBtoRedshiftusingAWSGlueETL_0.png"},"coverImage":"/assets/img/2024-06-19-DynamoDBtoRedshiftusingAWSGlueETL_0.png","tag":["Tech"],"readingTime":3},{"title":"dbt 프로젝트 작업 흐름을 빠르게하는 방법 Makefile 사용하기","description":"","date":"2024-06-19 16:02","slug":"2024-06-19-HowtouseaMakefiletospeedupyourdbtprojectworkflow","content":"\n\n## 명령 체계를 간소화하고 관련 명령을 그룹화하여 재사용성을 높이세요\n\n빌드, 실행, 테스트, 문서, 스냅샷, 복제 등 dbt 명령이 많이 있습니다. 저와 같은 경우면 필요한 명령어를 다시 입력하기 싫어서 명령어 히스토리를 계속 찾아다니고 있을 것입니다. 특히 여러 명령을 자주 함께 사용할 때는 더 그렇습니다. 더 나은 해결책이 있을 것입니다.\n\n![Makefile](/assets/img/2024-06-19-HowtouseaMakefiletospeedupyourdbtprojectworkflow_0.png)\n\n# Makefile이 구원해줄 것입니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n소프트웨어를 컴파일한 적이 없다면 메이크파일을 본 적이 없을 수도 있어요. 메이크파일은 코드를 컴파일하는 데 필요한 모든 종속성과 명령을 관리하는 데 사용되지만, 리눅스나 맥 OS에서 어떤 작업을 자동화하는 데도 사용할 수 있어요.\n\n메이크파일을 사용하면 기본적으로 자신만의 추상화된 명령을 만들 수 있어요. 이를 필요로 하는 경우가 있습니다:\n\n- 같은 명령을 자주 실행하는 경우\n- 명령이 길고 매번 입력하기 귀찮거나 명령 기록을 찾기 싫은 경우\n- 명령을 논리적으로 \u0026\u0026 그룹으로 묶고 싶은 경우\n- 명령을 공유하거나 일반적인 명령 패턴을 프로젝트에 포함하고 싶은 경우\n\n메이크파일의 미세한 세부 사항에 너무 심술을 파는 것은 필요하지 않아요. 알아야 할 주요한 점은 우리가 타겟과 명령으로 구성된 규칙을 만들 수 있다는 것이에요. 'Phony'라는 특별한 타겟을 사용할 것인데요, 아래에서 좀 더 자세히 알아볼게요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 간단한 예제\n\n다음은 dbt 문서를 생성하고 제공하는 간단한 makefile입니다:\n\n```js\n# 기본 대상에 대한 문서 생성 및 제공\n.PHONY: docs\ndocs:\n dbt docs generate \u0026\u0026 dbt docs serve\n```\n\n- 프로젝트의 루트 디렉토리에 위 줄을 포함한 Makefile(확장자 없음)이라는 파일을 만듭니다.\n- 프로젝트의 루트에서 make docs를 실행하면 dbt docs generate \u0026\u0026 dbt docs serve 명령이 실행됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ make docs\ndbt docs generate \u0026\u0026 dbt docs serve\n04:35:12  dbt 실행 중=1.7.9\n04:35:12  등록된 어댑터: duckdb=1.7.2\n04:35:12  모델 7개, 테스트 25개, 소스 3개, 노출 0개, 메트릭 0개, 매크로 582개, 그룹 0개, 의미 모델 0개 발견됨\n...\n...\n```\n\n# .PHONY\n\n.PHONY로 시작하는 줄을 본 적이 있을지도 모르겠죠. 이것은 홀덴 코필드와는 아무 상관이 없습니다. 이것은 'Phony targets'라고 불리는 사용자 정의 대상을 정의하는 방법입니다. 이는 파일이 아닌 명령을 참조하는 makefile 규칙입니다.\n\n기억해야 할 것은 대상을 올바르게 작동하도록 'Phony'로 식별하는 것입니다. 이를 간단한 예제처럼 각 대상 위에 할 수도 있고, 대신에 다음과 같이 한 곳에 모두 선언할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n.PHONY: build test docs help\n```\n\n이렇게 하면 build, test, docs, help 네 개의 가짜 대상이 정의되며, 여러분의 makefile 상단에 위치합니다.\n\n# 이것으로 빌드합니다\n\n추가하는 명령어는 실제로 여러분의 개인적인 워크플로우에 따라 다양합니다. 그것이 바로 이에 대한 아름다움입니다 — 그것들은 여러분의 프로젝트에 유용한 명령어로 이루어진 여러분만의 특정 명령어 세트입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 추가적인 기본 예시 몇 가지가 있어요:\n\n```js\n.PHONY run seed docs kitchen-sink clean \n\nrun:\n dbt run \u0026\u0026 dbt test\n \nseed:\n dbt seed \u0026\u0026 dbt run\n \ndocs:\n dbt docs generate \u0026\u0026 dbt docs serve\n\nkitchen-sink:\n dbt clean \u0026\u0026 dbt deps \u0026\u0026 dbt seed \u0026\u0026 dbt run \u0026\u0026 dbt test\n\nclean:\n dbt clean \u0026\u0026 dbt deps\n```\n\n# 고급 예시\n\n명령줄에서 변수를 makefile로 전달하거나 환경 변수를 로드하여 더 심화된 수준으로 이어갈 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## CLI에서 변수 전달하기\n\n가정해보자. dbt 빌드 명령을 실행하고 dbt 환경 대상을 지정하고 싶다면 다음과 같이 코드를 작성할 수 있습니다:\n\n```js\n.PHONY: build\n\nbuild:\n @echo \"Building project with environment: $(TARGET)\"\n dbt build --target $(TARGET)\n```\n\n그런 다음 make 명령을 실행할 때 사용할 dbt 대상을 지정할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n$ make build TARGET=dev\n환경: dev으로 프로젝트 빌드 중\ndbt 빌드 --target dev\n04:11:42  dbt=1.7.9 버전으로 실행 중\n...\n```\n\n환경 변수와 함께 사용하면 makefile이 프로젝트를 조작하는 데 매우 강력한 도구가 될 수 있음을 알 수 있습니다.\n\n## 환경 변수 로드\n\n.env 파일을 로드하려면 makefile 맨 위에 다음을 추가하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ninclude .env\nexport\n```\n\n이제 당신의 makefile은 모든 .env 변수를 불러올 것입니다. 예를 들어 기본 dbt 타겟을 지정할 수 있습니다:\n\n```js\nTARGET=dev\n```\n\n그런 다음, makefile을 업데이트하여 .env 변수가 설정되었는지 확인해주세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ninclude .env\nexport\n\n# Default value for TARGET if not set\nTARGET ?= $(TARGET)\n\n.PHONY: build\n\nbuild:\n @echo \"프로젝트를 환경과 함께 빌드 중: $(TARGET)\"\n dbt build --target $(TARGET)\n```\n\n이제 make build를 실행할 때, .env 파일에 정의된 대상인 dev가 사용됩니다. 그러나 make 명령을 실행할 때 TARGET를 지정하여 재정의할 수도 있습니다:\n\n```js\n# 기본 .env 대상 재정의\nmake build TARGET=prod\n```\n\n이로써 makefile이 일종의 bash 스크립트로 변환되었습니다 (이것을 말할 때 리눅스 전문가들이 나를 죽일지도 모릅니다). 특히 환경 변수를 로드할 수 있다는 점을 고려할 때입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 도움말 섹션\n\n명령을 완료하면 만든 모든 사용 가능한 명령에 대해 설명하는 도움말 섹션을 추가하십시오. 이렇게 하면 거의 자체 CLI 도구처럼 만들어집니다!\n\n```js\n# 사용 가능한 명령 표시\n.PHONY: help\nhelp:\n @echo \"사용 가능한 명령:\"\n @echo \"  docs - 기본 대상의 문서 생성 및 서비스\"\n``` \n\n# 일반 dbt 작업을 위한 보일러플레이트 makefile\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 시작할 수 있는 보일러플레이트가 있어요. 별로 복잡하지 않지만 시작할 때 도움이 될 거에요:\n\n프로젝트를 위한 기본 TARGET 및 PROFILE을 가진 .env 파일을 만들어놓지 않았다면 기억하세요.\n\n## Makefile 활용\n\n구체적인 요구 사항과 의존성을 갖는 실제 프로젝트에서 makefile이 어떻게 보일 수 있는지 알고 싶다면, Alex가 Zero to dbt 프로젝트의 makefile에서 어떤 작업을 했는지 확인해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\n.include .env\n.export\n\n.PHONY: run clean clean_log duck_dev duck_prod\n\nDBT_TARGET = dev\n\nrun:\n @echo \"SPODBTIFY_SOURCE_PARQUET = $$SPODBTIFY_SOURCE_PARQUET\"\n dbt run --target $(DBT_TARGET)\n\ndoc: \n dbt docs generate \u0026\u0026 dbt docs serve \n\nduck_dev:\n duckdb spodbtify.duckdb -cmd \"USE spodbtify.dev; show all tables\"\n\nduck_prod:\n duckdb spodbtify.duckdb -cmd \"USE spodbtify.prod; show all tables\"\n\nclean: \n unset SPODBTIFY_SOURCE_PARQUET \u0026\u0026 dbt clean \u0026\u0026 rm -rf *.duckdb\n\nclean_log:\n rm -rf logs/*.log\n```\n\n이 프로젝트는 duckdb를 사용하므로 Alex가 duckdb를 실행하고 prod 및 dev의 테이블을 표시하는 몇 가지 타겟을 만들었습니다. 따라서 프로젝트에서 makefile을 사용하는 방식은 구성에 매우 의존함을 알 수 있습니다.\n\n# 결론\n\nMakefiles는 사용하는 명령어를 소유하는 강력한 방법이 될 수 있습니다. 여러 명령어를 자주 실행하거나 프로젝트별 공통 작업이 있는 경우 생명 구원자가 될 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 가지 단점은 원래 명령어를 추상화함으로써 해당 명령어로부터 동떨어져 있게 될 수 있다는 점입니다. 원래 명령어를 잊어버릴 수도 있고, 새로운 기능이나 사용 패턴을 놓칠 수도 있습니다. 따라서 자주 자신의 makefile을 다시 살펴보는 것이 좋습니다.\n\n프로젝트에서 makefile을 사용하고 계신가요? 팁이나 멋진 사용 예시가 있다면 댓글로 공유해주세요!","ogImage":{"url":"/assets/img/2024-06-19-HowtouseaMakefiletospeedupyourdbtprojectworkflow_0.png"},"coverImage":"/assets/img/2024-06-19-HowtouseaMakefiletospeedupyourdbtprojectworkflow_0.png","tag":["Tech"],"readingTime":6},{"title":"AI 개발에서의 데이터 개인 정보 보호 데이터 지역화","description":"","date":"2024-06-19 16:00","slug":"2024-06-19-DataPrivacyinAIDevelopmentDataLocalization","content":"\n\n## 왜 데이터가 어디에 있는지 중요한지 알아야 할까요?\n\n![이미지](/assets/img/2024-06-19-DataPrivacyinAIDevelopmentDataLocalization_0.png)\n\n6월 25일 샌프란시스코에서 열리는 AI 품질 컨퍼런스를 위해 제 발표를 작성하는 과정에서 다루는 주제들이 많이 나왔어요. 발표하는 동안 간단히 언급할 시간이 부족할 것 같아 좀 더 자세히 설명해드리고자 관련 주제에 대한 소규모 칼럼 시리즈를 시작하려고 합니다. 이 칼럼 시리즈는 기계 학습과 AI 개발과 관련된 내용을 데이터 개인 정보 보호와 보안을 유지하면서 다뤄보려고 해요. 오늘은 데이터 위치 지정부터 시작해보겠습니다.\n\n시작하기 전에, 데이터 개인 정보 보호 및 보안 규정이 무엇을 다루는지 명확히 해야 해요. 간단하게 말해서, 이는 \"개인 데이터\"에 적용됩니다. 하지만 무엇이 개인 데이터로 간주될까요? 이는 관할권에 따라 다르지만 보통 PII(이름, 전화번호 등)와 결합되어 사람을 식별할 수 있는 데이터(우편번호, 생일, 성별, 인종, 정치 성향, 종교 등)가 포함됩니다. 이에는 사진, 영상이나 음성 녹음, 컴퓨터나 브라우저에 대한 자세한 정보, 검색 기록, 생체 인식 정보 등이 포함됩니다. GDPR에 대한 규정은 여기에서 설명되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다뤄봐야 할 게 다 되었으니, 데이터 로컬라이제이션에 대해 좀 더 알아보고, 기계 학습 개발자로서 우리에게 미치는 영향을 살펴봅시다.\n\n# 데이터 로컬라이제이션이란?\n\n물어봐 주셔서 감사합니다! 데이터 로컬라이제이션은 본질적으로 데이터가 저장된 지리적 위치에 관한 문제입니다. 데이터를 로컬라이즈하면 데이터를 생성된 위치에 유지하는 것입니다. (이것은 때로 \"데이터 소재지\"로 알려져 있으며 반대 개념은 \"데이터 이동성\"입니다.) 예를 들어, AWS S3에 있는 데이터셋이 us-east-1에 있다면, 당신의 데이터는 사실상 (데이터가 어느 지역에 존재하는지에 관해서는) 미국의 버지니아 북부 어딘가에 물리적으로 저장되어 있습니다. 좀 더 자세히 말하자면, AWS는 버지니아 북부에 여러 개의 특정 데이터 센터를 보유하고 있으며, 이들의 정확한 주소를 온라인으로 확인할 수 있습니다. 그러나 대부분의 경우, 이 정도의 수준에서 일반적인 지역 정보를 알고 있으면 충분합니다.\n\n# 데이터센터의 위치를 왜 신경 써야 하나요? 클라우드는 그냥 '어디에나' 있는 거 아닌가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터가 어디에 있는지를 알고 있는 것에는 좋은 이유가 있습니다. 하나는 데이터를 클라우드에 로딩/쓰는 데 실제 물리적인 속도 영향이 있을 수 있습니다. 여러분과 컴퓨터가 데이터 센터가 위치한 지역과 얼마나 떨어져 있는지에 따라 다를 수 있습니다. 하지만 이것은 극도로 빠른 계산을 하지 않는 한 큰 문제가 되지는 않을 것입니다.\n\n중요한 이유 중 하나는 데이터 프라이버시와 관련이 있습니다. 전 세계적으로 데이터 프라이버시 법률 (그리고 클라이언트와의 계약 및 고객이 작성한 동의서)에는 데이터 로컬라이제이션에 관한 규정이 포함되어 있습니다. 데이터 로컬라이제이션 규정은 특정 장소의 시민이나 거주자들에 대한 개인 데이터가 해당 장소의 서버에 저장되도록 요구됩니다.\n\n일반적인 주의 사항:\n\n- 모든 유형의 데이터에 항상 해당되는 것은 아닙니다 (재무 데이터가 보다 자주 해당됨)\n- 모든 유형의 사업에 항상 해당되는 것은 아닙니다 (기술 기업이 보다 자주 해당됨)\n- 정부 요청에 따라 발동되기도 하며, 자동으로 이루어지기도 합니다 (베트남 참조)\n- 데이터를 이동할 동의를 얻을 수 있는 경우도 있고 그렇지 않은 경우도 있습니다\n- 가끔은 초기에 데이터를 해당 국가에 저장하고 나중에 이동할 수도 있습니다 (러시아 참조)\n- 출신 국가 외부에 저장할 수도 있지만 다른 위치에 대한 제약 조건이 있을 수 있습니다 (EU 참조)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, 사설 회사들은 때때로 계약에서 데이터 로컬라이제이션 요구사항을 규제하며, 이는 이러한 법률을 준수하거나 데이터 유출 또는 다른 정부에 의한 감시 위험을 줄이기 위한 것일 수 있습니다.\n\n이것은 말 그대로, 특정 데이터를 저장할 수 있는 데이터 센터의 위치에 법적인 제한이 있을 수 있다는 것을 의미하는데, 이는 주로 데이터의 주체나 데이터 원본 소유자에 따라 결정될 수 있습니다.\n\n# 예시\n\n구체적인 (간소화된) 예시로 설명하는 것이 더 이해하기 쉬울 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 웹사이트를 운영하고 계신 것 같군요. 사람들이 구매를 할 수 있는 사이트인데요. 신용카드 정보, 주소, 이름, IP 주소, 그리고 기타 몇 가지 정보를 구매 중에 수집하고 계시네요. 동의 배너/소문에는 데이터의 로컬라이제이션에 대한 내용이 포함되어 있지 않다고 하시네요.\n- 러시아, 인도, 그리고 아랍에미리트 연합에서 고객을 받고 계신 것 같군요.\n- 명시적 동의를 받지 않았다면, 이 방문자들로부터 수집한 모든 개인 데이터는 다른 데이터 로컬라이제이션 규정의 영향을 받습니다.\n\n이것이 무엇을 의미하는지요? 이 모든 데이터는 다르게 처리되어야 합니다.\n\n- 러시아 고객의 데이터는 러시아 기반 서버에 처음으로 저장되어야 하며, 적용되는 규정에 따라 전송될 수 있습니다.\n- 유럽 연합 고객의 데이터는 데이터 보안 관련 법률이 충분한 국가에 저장될 수 있습니다 (주목할 점은 러시아가 아님).\n- 아랍에미리트 연합 고객 데이터는 동의를 받지 못해 이를 다른 곳에 저장하지 않아야 합니다.\n\n이로 인해 데이터 엔지니어링에는 분리된 파이프라인이 필요하게 되어 분명한 문제가 발생합니다. 또한 모델링과 훈련에도 어려움이 있을 수 있는데요. 실제로 사용할 데이터셋을 어떻게 구성해야 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 동의 받기\n\nUAE 고객으로부터 데이터 이전에 동의를 받았다면 괜찮았을텐데요. 데이터 엔지니어링은 여전히 러시아 고객의 데이터를 특별한 경로를 통해 전달해야 하지만, 교육용으로 데이터를 결합할 수 있었을 거에요. 그러나 동의를 받지 않아서 지금 난처하게 되었습니다! 동의 도구가 어떤 권한과 인가를 포함하는지 잘 알고, 이런 문제에 빠지지 않도록 해야 해요.\n\n# 즉석 조합\n\n그것을 할 시간이 없다고 가정했을 때, 다른 해결책은 훈련 시간에 다른 데이터베이스에서 로드하는 컴퓨팅 플랫폼을 갖는 것이에요. 데이터셋을 그 때 그 때 결합하고, 모델을 디스크 어딘가에 데이터를 기록하지 않고 학습시키는 것이에요. 일반적으로 (법률적인 조언은 아니에요) 모델 자체가 개인 데이터가 아니기 때문에 법적 규칙의 적용을 받지 않는다는 것이 일반적인 합의입니다. 하지만 이것에는 작업과 인프라 작업이 필요하기 때문에 자신의 개발-운영 역량을 발휘해 보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n생각지도 못한 큰 데이터 양으로 인하여 계산 비용이 빠르게 증가할 수 있습니다. 이 데이터를 기반으로 피처를 생성하지만 사례에 대한 개인 데이터가 여전히 해석 가능하면, 이를 한 곳에 모두 저장할 수 없게 됩니다. 대신, 비식별화/집계된 피처를 별도로 저장하거나 원래 지역으로 돌려쓰거나, 혹은 필요할 때마다 다시 계산해야 할 수 있습니다. 이 모든 것들은 어려운 도전입니다.\n\n# 비식별화 및/또는 집계\n\n다행히도 또 다른 옵션이 있습니다. 데이터를 집계, 요약하거나 철저하게 (되돌릴 수 없게) 비식별화하면 개인 데이터 보호가 사라지고 더 쉽게 작업할 수 있습니다. 식별 가능한 개인 데이터를 저장하지 않는 것이 강력한 인센티브가 될 수 있습니다! (게다가 데이터 누설 및 해킹 위험을 줄일 수 있습니다.) 데이터가 이제 더 이상 고위험 데이터가 아니기 때문에 법적으로 보호되지 않게 되면, 원하는 대로 작업하고 원하는 대로 데이터를 저장할 수 있습니다. 식별되지 않는 피처를 추출하고 식별 가능한 데이터는 버리십시오. 가능하다면요.\n\n하지만 데이터가 언제 충분히 집계되거나 비식별화되어 지역화 법률이 더 이상 적용되지 않는지 결정하는 것은 때로는 어려운 문제일 수 있습니다. 왜냐하면 앞에서 설명한 것처럼, 많은 종류의 인구통계 데이터는 다른 데이터 포인트와 결합되면 식별성을 만들어낼 수 있기 때문입니다. 우리는 종종 PII(전체 이름, 주민등록번호 등)가 제거되면 데이터를 마음대로 사용해도 된다고 생각하는데, 이는 많은 관할권에서 법률이 이를 허용하지 않는 것입니다! 법률 부서와 상담하고 위험의 의미에 대해 성실하게 고려하십시오. 이상적으로, 데이터가 더 이상 개인 데이터가 아닌 경우에 가장 안전합니다. 즉, 개인 수준의 이름, 인구통계, 주소, 전화번호 등이 포함되지 않거나 해시되지 않고 사람이 읽을 수 있는 일반 텍스트로 표시되지 않습니다. 이 글은 법률적 자문이 아닙니다. 법률 부서와 상담해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 데이터를 어디에서든 가져와 조작하고 계산을 실행하고 데이터를 저장하는 데에 익숙합니다 - 노트북, S3 또는 GCS, 또는 원하는 곳 어디에서든요. 그러나 우리가 사람들에 관한 개인 데이터를 더 수집하고 전 세계적으로 더 많은 데이터 개인정보 보호법이 시행되면, 우리는 무엇을 해야 하는지에 대해 더 조심스러워져야 합니다.\n\n# 자주 묻는 질문\n\n## 데이터 출처를 모른다면 어떡해요?\n\n이것은 어려운 상황입니다. 사람들에 관한 일부 개인 데이터가 있고 그 데이터의 출처나 그 사람들의 위치를 전혀 모르고 (아마도 그들이 이행한 동의 양식도 모르는 경우), 안전한 해결책은 이 데이터를 민감한 정보로 다루어 그것을 비식별화하고, 사용 사례에 적합하다면 집계하고, 데이터 개인정보 보호법에 따르면 개인 정보나 민감한 데이터로 간주되지 않도록 하는 것입니다. 그러나 이 데이터를 사용해야 하는 방식으로 인해 그것이 선택지가 아니라면, 변명하지 않고 변호사와 상의할 시간입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 회사가 전세계적으로 데이터 센터를 견딜 여유가 없다면 어떻게 할까요?\n\n대부분 이는 동일한 대답입니다. 이상적으로는 사용자 또는 고객으로부터 데이터를 받는 즉시 해당 동의 솔루션을 마련하는 것이 좋지만, 그게 불가능한 경우라면 데이터를 즉시 비식별화하는 방법을 찾는 것을 추천합니다. 사용자로부터 데이터가 수신되면 해당 데이터를 해싱하여 뒤집을 수 없도록 만들고 사용하세요. 인구 통계 또는 다른 민감한 개인 데이터에 대해서는 특히 조심스러워야 하지만, 개인 식별 정보(PII)를 첫 번째로 비식별화하는 것이 중요합니다. 민감하거나 잠재적으로 누군가를 식별할 수 있는 데이터를 저장하지 않는다면 지역화에 대해 걱정할 필요가 없습니다. 이 글은 법적 자문이 아닙니다. 귀사의 법률 부서와 상의하세요.\n\n## 왜 국가들은 이러한 법을 만드는 걸까요?\n\n이에 대한 몇 가지 이유가 있습니다. 일부가 다른 것보다 좋은 이유가 있습니다. 첫째, 데이터가 실제로 국내에 저장된다면 해당 국가에 사실상 비즈니스 존재가 있기 때문입니다(또는 데이터 저장 제공업체가 있음). 따라서 그들은 시민들의 데이터를 남용할 경우 처벌할 권한을 지니게 되어 훨씬 용이해집니다. 둘째, 이는 어떤 국가에서 기술 분야의 경제 발전을 지원하기 위함입니다. 왜냐하면 누군가는 데이터 센터에 전력을 공급, 냉각, 직원 고용, 건축 등을 제공해야 하기 때문입니다. 셋째, 불행하게도 일부 국가는 자국 시민들에 대한 감시 체제를 운영하고 있습니다. 그리고 국내에 데이터 센터가 있으면 전체주의적인 정부가 이 데이터에 접근하기가 더 쉬워집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터 과학자로서 덜 힘들게 하려면 뭘 할 수 있을까요?\n\n미리 계획을 세우세요! 회사의 관련 당사자들과 협력하여 초기 데이터 처리가 준수되면서 필요한 데이터를 얻을 수 있도록 하십시오. 그리고 고객들이 부여하는 동의 및 해당 권한이 무엇인지에 대해 파악하여야 합니다. 만약 여전히 위치 규칙을 가지고 있는 데이터를 소유하게 된다면 해당 데이터가 잘못된 위치에 저장되지 않도록 데이터를 관리할 방법을 찾거나, 데이터를 식별 불가능하게 하거나/또는 집계하여 데이터가 민감하지 않게 만들도록 하여 데이터 개인정보 규정이 더 이상 적용되지 않도록 해야 합니다.\n\n## 알아두어야 할 중요한 데이터 지역화 법률은 무엇이 있나요?\n\n다음은 몇 가지 주요 법률 요약입니다. 그러나 많은 법률이 있으며 시간이 지남에 따라 새로운 법률이 계속 등장할 수 있으므로 이것이 모두가 아닙니다. (다시 한 번 강조하건대, 여기에 포함된 내용은 법적인 조언이 아닙니다):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 인도: DPDP(디지털 개인 데이터 보호)는 국가 데이터 개인정보 보호 규정입니다. 이 법은 어떤 것보다 제한적이지는 않지만, 인도 정부 내의 개별 기관은 특정 종류의 데이터에 대해 보다 제한적인 정책을 수립할 수 있습니다. 인도 연방은 은행의 한 예로, 국가법보다 더 제한적인 데이터 로컬라이제이션 정책을 시행합니다. 아메리칸 익스프레스와 같은 금융 기업들은 인도 외부 서버에 인도 금융 거래 데이터를 저장한 것으로 벌금을 받은 사례도 있습니다.\n- 중국: PIPL은 중국의 국가 데이터 개인정보 보호 규정이며, 데이터 로컬라이제이션 규칙은 다소 복잡합니다. \"중국 내 개인들에게 제품이나 서비스를 제공하는 기업\" 및/또는 \"중국 내 자연인의 행위를 분석하고 평가하는 기업\"에 적용되므로 상당히 광범위합니다. 데이터가 법률적으로 \"중요하다\" 또는 \"자연인을 식별하거나 식별할 수 있는 정보\"로 간주된다면, 데이터 로컬라이제이션의 대상이 될 가능성이 높습니다. 앞서 말씀 드렸듯이, 이것은 법률 상담이 아니며 귀하의 법률부에 문의해야 합니다.\n- 러시아: 러시아는 오랜 시간 동안 데이터 로컬라이제이션 법을 시행해왔으며, Facebook 및 Twitter를 포함한 많은 기업이 위반으로 벌금을 받았습니다. \"데이터 로컬라이제이션 법의 제18항(5)에 따르면, 러시아 시민들의 개인 데이터를 수집하는 러시아 및 외국 데이터 처리자들은 초기에 러시아 데이터베이스를 사용하여 데이터를 기록, 저장, 정리, 업데이트하고 추출해야 합니다.\" 이를 적용하는 추가 법률도 있습니다(자세한 내용은 링크 참조). 러시아 서버에서 데이터를 초기 수집하고 저장한 후에는 데이터를 다른 곳으로 이전할 수 있습니다.\n- 베트남: 2018년 법률에 따르면 특정 데이터는 정부 요청에 따라 국내에 24개월 동안 저장되어야 합니다. 이는 전자상거래, 소셜 네트워킹 및 기타 디지털 서비스 분야의 국내 기업 및 특정 외국 기업에 적용됩니다. 또한, 데이터를 제3자에게 전송해야 하는 경우 고객의 동의가 필요합니다.\n- EU(GDPR): EU는 시민들의 데이터가 보관될 수 없는 특정 국가(예: 러시아)에 대한 우려로 인해 일부 국가에 대해 특정 규정을 설정합니다.\n- UAE: 대부분의 데이터에 대해 UAE 외부로 데이터를 전송하려면 해당 주체로부터 동의를 얻어야 합니다. 일부 선택적인 경우에는 이것만으로 충분하지 않을 수도 있으며, 예를 들어 결제 처리 데이터는 UAE 내에 보관되어야 합니다.\n- 일본: 데이터 주체는 일본과 특정 데이터 공유 협정에 가입한 다른 나라로 데이터를 전송할 때 동의를 해야 합니다.\n\n당신의 회사 크기와 같은 다른 고려 사항도 있습니다(일부 장소에서는 소규모 기업에 대해 제한적인 규칙이 적용되고, 일부 장소에서는 그렇지 않습니다), 그러므로 이것을 귀하의 비즈니스에 대한 결론적인 답변으로 받아들이면 안 됩니다.\n\n# 결론\n\n여기까지 읽어 주셔서 감사합니다! 지루할 수 있지만, 이야기로 보답하겠습니다. 한 번, 우리가 EU에서 생성된 데이터가 EU에 있어야하는 데이터 로컬라이제이션 조항이 포함된 계약에서 일한 적이 있습니다(법으로 아니라 다른 기업이 이러한 규칙을 설정한 경우), 그래서 미국에 북아메리카 데이터 저장소를 이미 구축한 상황이었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 이유로 새로운 복제 데이터베이스가 만들어졌습니다. 이 데이터베이스는 EU 지역에 위치하고 EU 관련 데이터만 포함하고 있었습니다. 그래서 전체 Snowflake 데이터베이스의 두 버전을 병렬로 유지했습니다. 이는 새로운 테이블을 생성하거나 필드를 변경하거나 데이터베이스에서 무언가를 수행할 때 다른 쪽에서도 작업을 복사해야 했기 때문에 악몽이었습니다. 당연히 대부분의 사람들은 이를 기억하지 못했기 때문에 두 데이터베이스는 크게 다르게 발전했고, 스키마가 크게 다른 수준으로 발전했습니다. 그래서 쿼리 및 작업을 위한 끝없는 조건부 코드가 필요했고, 데이터를 추출하며 올바른 열 이름, 형식, 테이블 이름 등을 갖고 있어야 했기 때문에 데이터를 잘못된 위치에 저장하지 않고도 \"즉석에서\" 조합할 수 있었습니다. (BI 목적의 중복 대시보드에 대해 언급할 때는 하지 마세요.) 이를 권장하지 않습니다!\n\n이러한 규정은 다양한 분야의 데이터 과학자들에게 실질적인 도전을 제공하며, 법적 의무를 준수하고 작업과 회사를 책임질 수 있도록 하는 것이 중요합니다. 지역화 도전에 직면한 적이 있나요? 이 문제에 대한 제가 언급하지 않은 해결책을 발견했다면 이 기사에 댓글을 남겨주세요.\n\n# 추가 읽을거리\n\nhttps://www.techpolicy.press/the-human-rights-costs-of-data-localization-around-the-world/\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 친숙하게 번역한 내용입니다.\n\n1. [인도의 새로운 데이터 보호법 이해 - Carnegie Endowment for International Peace](https://carnegieendowment.org/research/2023/10/understanding-indias-new-data-protection-law?lang=en)\n\n2. [인도에서의 데이터 로컬라이제이션에 관한 모든 것 - IR Global](https://irglobal.com/article/all-about-data-localisation-in-india-2/#:~:text=The%20RBI%20ordered%20all%20payment,to%20abide%20by%20this%20instruction.)\n\n3. [RBI(인도 중앙 은행) FAQ](https://m.rbi.org.in/Scripts/FAQView.aspx?Id=130)","ogImage":{"url":"/assets/img/2024-06-19-DataPrivacyinAIDevelopmentDataLocalization_0.png"},"coverImage":"/assets/img/2024-06-19-DataPrivacyinAIDevelopmentDataLocalization_0.png","tag":["Tech"],"readingTime":10},{"title":"2024년을 위해 효과적으로 사용하는 방법과 함께 관리자 대시보드의 상위 10가지 유형","description":"","date":"2024-06-19 15:58","slug":"2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024","content":"\n\n여러 종류의 관리자 대시보드 및 사용 방법을 발견하세요. 귀하는 비즈니스에 적합한 것을 선택하고 효율성을 극대화하기 위해 우리의 포괄적인 안내서를 통해 배울 수 있습니다.\n\n![대시보드 이미지](/assets/img/2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024_0.png)\n\n관리자 대시보드는 현대 비즈니스 관리에서 중요한 역할을 합니다. 기업의 운영 다양한 측면을 모니터링, 분석, 및 제어하기 위한 집중된 플랫폼을 제공합니다. 본 문서에서는 다양한 관리자 대시보드의 유형 및 실용적인 비즈니스 관리 응용을 탐색할 것입니다. 이러한 대시보드는 데이터 시각화 및 인력 관리와 같은 특정 비즈니스 요구를 해결하도록 설계되었습니다. 우리는 중요한 기능을 논의하고 효과적인 와이어프레임 생성에 대한 통찰을 제공하며, 판매 및 인력 자원 부문 통합의 중요성을 강조할 것입니다. 함께 하여 관리자 대시보드 유형과 실용적인 사용 예시를 탐험해 보세요.\n\n# 목차\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 관리자 대시보드와 사용자 대시보드 구별하기\n- 관리자 대시보드의 장점\n- 관리자 대시보드 유형\n- 관리자 대시보드 와이어프레임 만들기\n\n# 관리자 대시보드와 사용자 대시보드의 구별\n\n시스템이나 애플리케이션 내에서 관리자 대시보드와 사용자 대시보드는 각각 다른 목적을 가지고 있습니다. 관리자 대시보드는 시스템의 다양한 측면을 모니터링, 관리, 제어하기 위해 포괄적인 접근이 필요한 관리자나 관리자 사용자를 위해 디자인되었습니다. 관리자 대시보드는 주로 데이터 관리, 사용자 권한 관리, 분석 도구 및 시스템 구성 옵션과 같은 고급 기능을 제공합니다.\n\n반면, 사용자 대시보드는 주로 특정 작업을 수행하거나 사용자의 역할이나 선호도에 맞게 제공되는 데이터, 기능 및 기능성에 중점을 둔 일반 사용자나 최종 사용자를 위해 맞춤형으로 설계되었습니다. 사용자 대시보드는 종종 간단한 디자인을 가지고 있으며 개별 사용자 역할이나 선호도에 맞게 제공하는 관련 데이터, 기능 및 기능성에 집중합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 관리자 대시보드의 장점\n\n![이미지](/assets/img/2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024_1.png)\n\n관리자 대시보드는 결정을 내리고 전반적인 효율성을 향상시키는 여러 가지 혜택을 제공합니다. 이러한 혜택 중 일부는 다음과 같습니다:\n\n# 1. 사용자 관리:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 세밀한 권한 설정: 기본 역할(관리자/편집자/사용자)을 넘어서 특정 작업을 제어하는 세밀한 권한 집합을 구현하여 다양한 엔티티(데이터 포인트, 콘텐츠 유형, 기능성)에서 사용자가 수행할 수 있는 행동을 제어하세요.\n- 사용자 활동 로그: 대시보드 내에서 사용자의 활동을 추적하여 활동을 모니터링하고 잠재적인 문제를 식별하며 규정 준수를 확보하세요.\n\n## 2. 콘텐츠 관리:\n\n- 버전 관리: 콘텐츠에 대한 변경 사항을 추적할 수 있는 기능을 제공하여 필요한 경우 이전 버전으로 되돌릴 수 있고 콘텐츠 편집에 협력할 수 있도록 합니다.\n- 워크플로우 관리: 콘텐츠 승인 프로세스를 위한 워크플로우를 구현하여 편집 사항이 게시되기 전에 검토 및 승인이 필요하도록 만듭니다.\n\n## 3. 사용자 정의:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 드래그 앤 드롭 기능: 관리자가 대시보드 위젯을 쉽게 정렬하고 조직하여 개인화된 화면 및 작업 효율성을 향상시킵니다.\n- 사전 구축 대시보드: 일반 사용자 역할 또는 기능에 대한 사전 구성된 대시보드를 제공하며 사용자 지정 생성 기능도 함께 제공합니다.\n\n## 4. 설정:\n\n- 데이터 유지 보관 정책: 대시보드 내 사용자 데이터, 활동 로그 및 기타 정보의 데이터 저장 기간을 관리하는 정책을 구현합니다.\n- 감사 로깅: 설정과 관련된 시스템 구성 변경 및 사용자 작업을 추적하여 책임 소재를 유지하고 잠재적 보안 위험을 식별합니다.\n\n## 5. 추가 고려 사항:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 사용자 인터페이스 (UI) 디자인: 사용자 관리, 콘텐츠 편집 및 사용자 정의를 위한 UI를 관리자가 다양한 기술 능력을 가지고 사용해도 직관적이고 사용하기 쉽도록 보장합니다.\n- 확장성: 사용자 제어 및 편집 기능을 디자인하여 시스템 내에서 성장하는 사용자 기반 및 데이터 양을 처리할 수 있게 합니다.\n\n무료로 Mokkup을 사용해보세요!\n\n# 관리자 대시보드 유형\n\n![Admin Dashboard Types](/assets/img/2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n관리 대시보드는 시스템이나 플랫폼의 특정 요구 사항에 따라 다양할 수 있습니다. 다음은 일반적인 유형의 관리 대시보드입니다:\n\n## 1. 콘텐츠 관리 시스템 (CMS) 대시보드:\n\n- 주요 포인트: 이 대시보드를 통해 관리자는 웹 사이트 콘텐츠를 관리할 수 있습니다. 페이지, 포스트 또는 기타 콘텐츠 유형의 생성, 편집 및 삭제가 가능합니다.\n- 도구: WordPress, Drupal, Wix\n\n## 2. 사용자 관리 대시보드:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 주요 포인트: 이 유형의 대시보드는 사용자 관리 작업에 초점을 맞추어 사용자 계정 생성, 편집, 삭제, 권한 관리 및 사용자 관련 문제 처리와 같은 작업을 다룹니다.\n- 도구: 구글 워크스페이스 관리 콘솔, 마이크로소프트 365 관리 센터, 옥타\n\n# 3. 분석 대시보드:\n\n- 주요 포인트: 분석 대시보드는 시스템이나 플랫폼의 다양한 측면에 대한 통찰과 메트릭을 제공합니다. 사용자 활동, 트래픽 소스, 전환율 등을 포함합니다. 관리자는이 정보를 활용하여 데이터 기반 의사결정을 할 수 있습니다.\n- 도구: 구글 애널리틱스, 어도비 애널리틱스, 클리키\n\n# 4. 전자상거래 대시보드:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 주요 포인트: 전자상거래 관리자 대시보드는 온라인 상점을 관리할 수 있도록 설계되었습니다. 일반적으로 제품, 재고, 주문, 결제 및 고객 관계를 관리할 수 있는 기능이 포함되어 있습니다.\n- 도구: Shopify 관리 패널, BigCommerce 제어판, WooCommerce\n\n## 5. 고객 관계 관리 (CRM) 대시보드:\n\n- 주요 포인트: CRM 대시보드는 관리자가 고객이나 클라이언트와의 상호작용을 관리하는 데 도움을 주도록 설계되었습니다. 잠재고객 추적, 연락처 관리, 후속 조치 일정 설정 및 고객 상호작용 분석 기능이 포함될 수 있습니다.\n- 도구: Salesforce Essentials, Zoho CRM, HubSpot CRM\n\n## 6. 프로젝트 관리 대시보드:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 주요 포인트: 프로젝트 관리 대시보드는 프로젝트 계획, 추적 및 협조를 용이하게 합니다. 일반적으로 작업 생성 및 할당, 진행 상황 추적, 기한 관리 및 팀원들과 협업하는 기능을 포함하고 있습니다.\n- 도구: Asana, Trello, Monday.com\n\n## 7. 시스템 구성 대시보드:\n\n- 주요 포인트: 이 유형의 작업 대시보드는 시스템이나 플랫폼의 다양한 설정 및 환경 설정(예: 이메일 설정, 보안 구성, 통합 설정 등)을 구성하는 데 사용됩니다.\n- 도구: 시스템/플랫폼에 따라 다양함 (예: 웹 호스팅의 cPanel, Windows Server Manager)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 주요 포인트: 보고 대시보드는 시스템이 수집한 데이터를 기반으로 보고서를 생성하고 표시합니다. 관리자는 시스템의 성능이나 운영의 특정 측면에 대한 통찰력을 얻기 위해 보고서를 사용자 정의할 수 있습니다.\n- 도구: 주로 특정 소프트웨어/플랫폼의 기본 기능 (예: Google Analytics 대시보드, CRM 판매 보고서)\n\n# 9. 보안 대시보드:\n\n- 주요 포인트: 보안 대시보드는 시스템의 보안 상태에 대한 통찰력을 제공하며 보안 사건, 취약점, 액세스 제어 및 규정 준수 상태에 관한 정보를 포함합니다.\n- 도구: Crowdstrike Falcon Insight, Palo Alto Networks PAN-OS 관리자 콘솔, McAfee ePO\n\n# 10. 워크플로우 관리 대시보드:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 주요 포인트: Workflow 관리 대시 보드는 관리자가 비즈니스 프로세스를 간소화하고 자동화하는 데 도움을 줍니다. Workflow 설계, 실시간 모니터링, 효율적인 Workflow 최적화 기능 등이 포함될 수 있습니다.\n- 도구: Kissflow, ProcessMaker, Bonzai\n\n위는 몇 가지 대시 보드 예시일 뿐이며, 관리자 대시 보드는 시스템이나 플랫폼의 특정 요구 사항에 맞게 매우 맞춤화될 수 있습니다.\n\n# 관리자 대시 보드 와이어프레임 만들기\n\n프로젝트 관리 대시 보드 와이어프레임을 만드는 것은 관리자가 프로젝트 상태 및 자원 할당을 모니터링하는 데 필요한 핵심 정보와 기능을 개요로 작성하는 과정입니다. 잘 설계된 대시 보드는 이러한 데이터를 명확하고 간결하게 시각적으로 제시해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n무료로 가입해서 Mokkup.ai를 사용하고 프로젝트 관리 대시보드 템플릿을 시작해보세요. Mokkup의 프로젝트 관리 대시보드는 이 유형의 대시보드의 좋은 예입니다. 이 대시보드는 \"경영진 대시보드 요약\"과 \"고객\"과 같은 명확한 제목으로 대시보드를 섹션으로 나눕니다. 각 섹션은 차트, 그래프 및 텍스트를 조합하여 데이터를 제시합니다. 예를 들어, \"프로젝트\" 섹션은 프로젝트를 사이즈별로 분배하는 쌓인 막대 차트를 사용합니다(대형, 중형, 소형 및 지원). 이 차트를 통해 관리자는 한 눈에 일정 비율의 프로젝트가 대규모 사업이고 작은 배당 비율이 지원 관련 작업임을 볼 수 있습니다.\n\n\"경영진 요약\" 섹션에는 프로젝트 유입 및 시작 및 종료 날짜를 보여주는 테이블이 있습니다. 이 섹션에는 또한 다른 프로젝트 사이즈 간의 청구 가능 시간 분포를 보여주는 쌓인 막대 차트가 포함되어 있습니다. 이 아래에는 시간당 달러 \"트렌드\"에 대한 섹션이 있어 시간이 지남에 따라 수익성을 추적하는 데 도움이 될 수 있습니다.\n\n전반적으로, Mokkup 프로젝트 관리 대시보드는 관리자에게 프로젝트 상태, 자원 할당 및 팀 생산성에 대한 포괄적인 보기를 제공합니다. 가장 좋은 점은 이것이 모컵의 템플릿으로 제공되어 당신의 필요에 맞게 쉽게 사용자 정의할 수 있다는 것입니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약하자면, 관리자 대시보드는 다양한 분야에서 효율적인 관리를 위한 필수 도구로 작용합니다. 프로젝트 진행 상황 추적, 재무 지표 모니터링, 또는 사용자 활동 감시와 같은 작업에 사용되며, 다양한 대시보드 유형이 각기 다른 기업 요구에 맞춰 제공됩니다. 심층적인 통찰력을 제공하는 분석 대시보드부터 일상 업무를 간소화하는 운용 대시보드까지, 각 유형은 정보 기반 의사결정에 중요한 기능을 제공합니다. 특정 요구사항과 목표를 이해하는 것이 가장 적합한 대시보드 유형을 선택하는 핵심입니다. 이 다재다능한 도구의 능력을 활용하면, 기관은 운영을 최적화하고 생산성을 향상시키며, 명확하고 정확하게 목표를 달성할 수 있습니다.\n\n무료로 모컵을 사용해보세요!","ogImage":{"url":"/assets/img/2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024_0.png"},"coverImage":"/assets/img/2024-06-19-Top10TypesofAdminDashboardsandHowtoUseThemEffectivelyin2024_0.png","tag":["Tech"],"readingTime":6},{"title":"데이터 과학을 위한 상위 5개의 Python 프론트엔드 라이브러리","description":"","date":"2024-06-19 15:56","slug":"2024-06-19-Top-5PythonFrontendLibrariesforDataScience","content":"\n\n파이썬에는 많은 프론트엔드 라이브러리가 있습니다. 각각의 장단점이 있죠. 어떤 것을 선택해야 할까요?\n\n데이터 과학자, 데이터 엔지니어, 머신러닝 엔지니어 또는 파이썬 개발자이든 상관없이 적어도 하나의 프론트엔드 라이브러리를 알고 있어야 합니다. 이것은 여러 면에서 도움이 될 수 있습니다. 예를 들어, 펫 프로젝트 생성, 풀 스택 개발자가 되는 데 도움이 되고, 대시보드를 만드는 데 도움이 되며 일상생활에서도 도움이 될 수 있습니다.\n\n이 기사에서는 고유한 특징, 장단점을 갖춘 5가지 다른 프론트엔드 라이브러리를 다룰 것입니다.\n\n![Top 5 Python Frontend Libraries for Data Science](/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1. Streamlit\n\n![Streamlit](/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_1.png)\n\n가장 인기 있는 데이터 과학용 프론트엔드 프레임워크로 시작합니다.\n\nStreamlit은 오픈 소스 Python 프레임워크입니다. 이를 사용하면 데이터 과학자나 머신 러닝 엔지니어들이 웹 개발 지식이 많지 않아도 빠르고 쉽게 대화형 데이터 앱을 만들 수 있어 특히 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStreamlit을 사용하면 개발자들은 깊은 프론트엔드 경험이나 지식을 요구하지 않고 매력적인 사용자 인터페이스를 구축 및 공유하고 모델을 배포할 수 있습니다. 이 프레임워크는 무료이며 모두 Python으로 작성되었으며 오픈 소스로 공개되어 있어 몇 분만에 공유 가능한 웹 앱을 만들 수 있습니다.\n\n빠른 프로토타입, SaaS, 분석 대시보드 또는 친구들을 위한 프로젝트를 만들고 싶다면 Streamlit은 좋은 선택입니다. 시작하는 데 시간이 걸리지 않으며 준비된 많은 템플릿이 있고 몇 분만에 프론트엔드를 마무리할 수 있습니다. 또한 공유가 매우 쉽습니다.\n\n그러나 이 라이브러리는 확장 가능한것이나 많은 기능을 갖춘 큰 것을 원한다면 좋은 결정이 아닐 수 있습니다. Streamlit은 한 가지 특정 기능을 보여주는 간단한 한 페이지 웹사이트에 더 중점을 둔다는 점을 유의해야 합니다. 그래서 이를 사용하여 소셜 네트워크나 스타트업을 만드는 것은 권장되지 않습니다.\n\n많은 사용자들은 Streamlit을 매우 쉽게 사용할 수 없다고 말합니다. 문서에 없는 새로운 기능을 추가하려면 어려운 도전이 될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2. Solara\n\n![Solara](/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_2.png)\n\nSolara는 ipywidgets 또는 ipywidgets 상단의 React 유사 API를 사용하여 순수 Python에서 웹 앱을 구축할 수 있습니다. 이러한 앱은 주피터 노트북 내에서 작동하거나 FastAPI와 같은 프레임워크를 사용하여 독립형 웹 앱으로 작동합니다.\n\nSolara를 사용하면 구성 요소 기반 코드를 장려하고 상태 관리를 단순화하여 개발 프로세스를 더 효율적으로 만들고 애플리케이션을 유지 관리하기 쉽게합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSolara는 파이썬 생태계의 모든 잠재력을 제공합니다. 즉, 웹 개발 역량을 확장하면서도 즐겨 사용하는 라이브러리를 계속 사용할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_3.png)\n\n따라서 크고 확장 가능한 웹사이트를 개발하거나 파이썬 노트북용 위젯을 만들려면 Solara가 좋은 선택입니다.\n\n하지만 단점은 다음과 같습니다: Solara는 (예를 들어 streamlit과 비교했을 때) 그다지 인기가 없어서 문제에 대한 답을 찾기 어렵거나 시작할 템플릿을 찾기 어렵습니다. 일부 사용자는 문서에 대해 불평하기도 합니다. 마지막으로, 상태를 사용하고 컴포넌트 기반 코드를 관리하는 방법을 알아야하기 때문에 일반적으로 개발하기 어렵습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3. Trame\n\n![Trame](/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_4.png)\n\nTrame은 웹 개발 또는 기술에 대한 최소한의 지식으로 상호 작용 및 시각적으로 멋진 웹 애플리케이션을 손쉽게 생성할 수 있는 오픈 소스 플랫폼입니다. Python을 기반으로 하며 VTK, ParaView, Vega와 같은 플랫폼을 활용하여 몇 분 만에 웹 기반 애플리케이션을 만드는 데 사용됩니다.\n\nTrame은 반응적이고 상태를 가지는 웹 애플리케이션을 구축하기위한 고수준 프레임워크를 제공하며, 데스크톱 애플리케이션과 마찬가지로 로컬에서 사용할 수 있지만 대량 및/또는 민감한 데이터에 액세스하기위해 클라우드 또는 온프레미스에 배포될 수도 있습니다. Trame은 기존 라이브러리 또는 도구를 활용하여 다양한 기능을 내장하고 있으며, Vuetify, Altair, Vega, Deck, VTK, ParaView 등의 도구를 활용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTrame은 다른 언어나 기술로 전환하지 않고도 풍부한 시각화를 통해 대화형 데이터 처리 애플리케이션을 만들 수 있게 해줍니다. 사용 가능한 여러 레이아웃을 통해 애플리케이션을 빠르게 구축할 수 있습니다. 또한 Trame은 서버 측 및 클라이언트 측 렌더링 그리고 혼합 접근법 중 선택할 수 있도록 해줍니다.\n\n따라서 Trame은 상호작용 및 복잡한 시각화와 시뮬레이션을 포함한 과학 중심 앱을 만들고 싶다면 이 상품을 선택할 수 있습니다. 이것은 멀티 플랫폼이며 많은 유용한 기능을 제공하며 전체적으로 미적으로 매력적으로 보입니다.\n\n안타깝게도 단점도 있습니다. Trame은 아직 비교적 새로운 프레임워크이기 때문에 아직 큰 커뮤니티가 형성되지 않았습니다. 또한 아직 개발 중이기 때문에 몇 가지 문제나 버그가 발생할 수 있습니다. 마지막으로, 이를 정말로 깊이 파고들어 모든 개념을 이해하는 데 시간이 걸릴 것입니다.\n\nTrame으로 개발을 시작하려면 이 라이브러리에 대한 개요인 제 기사 중 하나를 확인해보세요: https://medium.com/python-in-plain-english/trame-frontend-with-vue-js-but-in-python-329111755b98\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4. ReactPy\n\n![ReactPy](/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_5.png)\n\nReactPy는 JavaScript 없이 사용자 인터페이스(UI)를 구축하기 위한 Python 패키지입니다. ReactJS와 유사하게 작고 재사용 가능한 구성 요소를 사용하여 인터페이스를 만들 수 있습니다. ReactPy 인터페이스는 Flask, FastAPI, Sanic, Tornado, Django, Jupyter 및 Plotly-Dash와 같은 다양한 백엔드에 대해 구축할 수 있습니다.\n\n기본적으로 ReactJS에서 구축할 수 있는 것은 거의 대부분 ReactPy에서도 구축할 수 있습니다. ReactPy에는 이미 상태 관리, 훅, 구성 요소 등과 같은 대부분의 React 기능이 구현되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 ReactJS에 익숙하고 백엔드와 프론트엔드를 동일한 언어로 구성하고 싶다면, ReactPy가 최선의 선택입니다. 그렇지 않다면, ReactPy는 보통 HTML/CSS/JS를 사용하는 다중 페이지 웹사이트, 랜딩 페이지 및 기타 요소를 작성하는 데 좋은 라이브러리입니다.\n\nReactPy의 주요 단점은 아직까지 새로운 기술이라 커뮤니티가 크지 않다는 것입니다. 이 말은 ReactJS처럼 수백 개의 라이브러리를 사용할 수 없다는 것을 의미합니다. 또한, 아직 개발 중이기 때문에 몇 가지 버그가 발생할 수 있고, 일부 기능이 완전히 구현되지 않을 수 있습니다.\n\nReactPy로 시작하고 싶다면, 아래의 저의 글을 확인해보세요: https://medium.com/@ash_computational_qm/reactpy-building-dynamic-frontend-applications-with-python-de92d9e95bce\n\n# 5. PyQt\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Python Frontend Libraries for Data Science](/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_6.png)\n\nPyQt는 유연한 Python 프로그래밍 언어와 강력한 Qt C++ 크로스 플랫폼 프레임워크를 원활하게 통합하여 강력한 GUI 모듈로 기능하는 플러그인 형태로 구현된 크로스 플랫폼 GUI 툴킷의 Python 바인딩입니다.\n\nQtCore는 핵심 비 GUI 기능을 위한 기능이며, QtGui는 GUI 기능을 위한 기능과 같이 특정 작업에 맞게 설계된 여러 모듈로 구성됩니다. PyQt는 최신 위젯 모음과 Windows, Unix, Linux, macOS, iOS 및 Android와 호환되는 여러 운영 체제와의 호환성으로 인해 그래픽 응용 프로그램을 개발하는 데 널리 사용됩니다.\n\n위에서 언급된 OS 중에서 데스크탑 앱이 필요하다면 PyQt가 최고의 선택 중 하나입니다. 다양한 위젯 세트, 좋은 사용자 정의 가능성을 제공하며 모든 Python 규칙을 따르므로 쉽게 작업할 수 있습니다. 또한 비디오 및 오디오와 같은 멀티미디어를 지원합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n흐음, 안타깝게도 PyQt를 설치할 때 추가적인 단계가 필요하며, 다른 라이브러리보다 더 어려운 점이 있어요. 또한, 애플리케이션이 공개 소스가 아닌 경우 상업용 라이센스를 구매해야 해요. 마지막으로, PyQt로 애플리케이션을 제대로 만들기 위해 모든 위젯과 기능이 어떻게 동작하는지 이해하는 데 시간이 걸려요.\n\n# 결론\n\n파이썬에서 다섯 가지 주요 프론트엔드 프레임워크를 탐색했어요. 각각의 독특한 강점과 응용 분야가 있어요. 빠르고 간편한 프로토타이핑을 위해서는 Streamlit을 선택하세요. 기업용 확장성을 원한다면 Solara가 적합하겠죠. 시뮬레이션과 복잡한 3D 시각화를 원한다면 Trame이 전문가에요. ReactJS와 유사한 웹사이트 개발을 원한다면 ReactPy가 이상적인 선택이 될 거예요. 그리고 크로스 플랫폼 데스크톱 애플리케이션을 만들고 싶다면 PyQt가 많이 선호되는 프레임워크입니다.\n\n이 개요를 통해 데이터 과학 노력에 완벽하게 맞는 프레임워크를 손쉽게 선택할 수 있을 거예요. 즐거운 코딩 되세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 참고 자료\n\n- [Streamlit 웹사이트](https://streamlit.io)\n- [Streamlit과 Scikit-learn의 Chatbot 애플리케이션](https://blog.streamlit.io/building-a-streamlit-and-scikit-learn-app-with-chatgpt/)\n- [Trame](https://kitware.github.io/trame/)\n- [Solara](https://solara.dev)\n- [PyQt 위키](https://wiki.python.org/moin/PyQt)\n- [PyQt 소개](https://www.tutorialspoint.com/pyqt/pyqt_introduction.htm)\n- [ReactPy 문서](https://reactpy.dev/docs/index.html)\n- [React.js로 개발된 멋진 웹사이트 20선](https://dev.to/davidepacilio/20-awesome-websites-built-with-react-js-3ik8)","ogImage":{"url":"/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_0.png"},"coverImage":"/assets/img/2024-06-19-Top-5PythonFrontendLibrariesforDataScience_0.png","tag":["Tech"],"readingTime":7},{"title":"사막  숨겨진 네트워크","description":"","date":"2024-06-19 15:54","slug":"2024-06-19-DuneAHiddenNetwork","content":"\n\n\u003cimg src=\"/assets/img/2024-06-19-DuneAHiddenNetwork_0.png\" /\u003e\n\n# 이 기사에서, Patrik Szigeti와 함께 우리는 오리지널 '둠' 삼부작 뒤의 복잡한 사회 네트워크를 개괄하는 그래프 시각화를 지원하는 데이터 및 네트워크 방법론을 설계했습니다.\n\n2021년에 박스 오피스에서와 평론가들로부터의 성공을 거두자마자, 2024년 '둠: 파트 투'는 가장 기대되는 영화 중 하나였으며, 실망시키지 않았습니다. 본 글 작성 시점에서 이전 작품보다 Rotten Tomatoes와 IMDb에서 평점이 높고 더 많은 수익을 올릴 것으로 예상되는 '둠'은 변화무쌍한 정치적 풍경을 가졌으며, 네트워크 과학을 통해 탐구하기에 완벽한 시리즈입니다. 본 짧은 글에서, 우리는 프랭크 허버트의 처음 세 책 - '둠' (1965), '둠 메시아' (1969), 그리고 '둠의 아이들' (1976)을 바탕으로 Impremium의 다른 가문과 인물들 간의 연결을 탐구하기 위해 노력했습니다.\n\n이 기사의 첫 번째 부분에서는 '둠' 위키에서 캐릭터 프로필 데이터를 수집하는 파이썬 기반 방법을 소개하고 이러한 프로필을 재미있는 네트워크 그래프로 변환합니다. 그런 다음, 두 번째-스포일러가 많이 담긴-섹션에서, 우리는 네트워크의 심도에 빠져 첫 번째 '둠' 삼부작이 전하는 모든 이야기를 추출합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 이미지는 저자들에 의해 만들어졌습니다.\n\n# 1 네트워크 구축\n\n먼저, 우리는 Python을 사용하여 두네 캐릭터들의 전체 목록을 수집합니다. 그런 다음, 각 캐릭터의 팬 위키 사이트에서 그들의 전기 프로필을 다운로드하고 각 캐릭터의 이야기가 다른 캐릭터의 이야기를 언급한 횟수를 계산합니다. 이를 통해 두 캐릭터 간의 다양한 상호작용을 인코딩한다고 가정합니다. 그런 다음, 이러한 관계를 복잡한 그래프로 변환하기 위해 네트워크 과학을 사용할 것입니다.\n\n1.1 캐릭터 목록 수집\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 뒤니 팬 위키 사이트에서 관련 캐릭터 목록을 수집했습니다. 구체적으로, urllib와 bs4를 사용하여 언급된 각 캐릭터의 이름과 팬 위키 ID를 추출했습니다. 그리고 각 캐릭터가 자체적으로 위키 페이지가 있으며 해당 ID로 인코딩되어 있다는 사실도 확인했습니다. 이를 Dune, Dune Messiah 및 Children of Dune 세 권의 첫 세 권에 적용하였는데, 이 책들은 아트레이드 가문의 부상을 다루고 있습니다.\n\n참고 링크:\n- https://dune.fandom.com/wiki/Dune_(novel)\n- https://dune.fandom.com/wiki/Dune_Messiah\n- https://dune.fandom.com/wiki/Children_of_Dune_(novel)\n\n첫 번째로, 캐릭터 목록 사이트의 HTML을 다운로드하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndune_meta = {\n    'Dune': {'url': 'https://dune.fandom.com/wiki/Dune_(novel)'},\n    'Dune Messiah': {'url': 'https://dune.fandom.com/wiki/Dune_Messiah'},\n    'Children of Dune': {'url': 'https://dune.fandom.com/wiki/Children_of_Dune_(novel)'}\n}\n\nfor book, url in dune_meta.items():\n    sauce = urlopen(url['url']).read()\n    soup  = bs.BeautifulSoup(sauce,'lxml')\n    dune_meta[book]['chars'] = soup.find_all('li')\n```\n\n약간의 수동 작업을 통해 캐릭터 이름과 ID를 세밀하게 조정해주었습니다:\n\n```js\ndune_meta['Dune']['char_start'] = 'Abulurd'\ndune_meta['Dune']['char_end'] = 'Arrakis'\ndune_meta['Dune Messiah']['char_start'] = 'Abumojandis'\ndune_meta['Dune Messiah']['char_end'] = 'Arrakis'\ndune_meta['Children of Dune']['char_start'] = '2018 Edition'\ndune_meta['Children of Dune']['char_end'] = 'Categories'\n```\n\n그런 다음, 모든 관련 이름과 해당 프로필 URL을 추출했습니다. 여기서, 캐릭터 이름이 어디서 시작하는지 수동으로 확인하고 ('캐릭터 목록 사이트의 개요와는 대조적') 추가로, 확장 시리즈에 해당하는 'XD' 및 'DE'로 표시된 캐릭터 및 특정 책에서 \"언급만 된\" 캐릭터들은 제외하기로 결정했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nfor k, v in dune_meta.items():\n    names_urls = {}\n    keep_row = False\n    print(f'----- {k} -----')\n    for char in v['chars']:\n        if v['char_start'] in char.text.strip():\n            keep_row = True\n        if v['char_end'] in char.text.strip():\n            keep_row = False\n        if keep_row and 'Video' not in char.text:\n            try:\n                url = 'https://dune.fandom.com' + str(char).split('href=\"')[1].split('\" title')[0]\n                name = char.text.strip()\n                if 'wiki' in url and 'XD' not in name and 'DE' not in name and '(Mentioned only)' not in name:\n                    names_urls[name] = url\n                    print(name)\n            except:\n                pass\n    dune_meta[k]['names_urls'] = names_urls\r\n```\n\n그런 다음 이 코드 블록은 다음과 같은 문자 목록을 출력합니다:\n\n\u003cimg src=\"/assets/img/2024-06-19-DuneAHiddenNetwork_1.png\" /\u003e\n\n마지막으로, 수집한 문자 수를 확인하고 다음 소단원을 위해 프로필 URL과 식별자를 저장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndune_names_urls = {}\nfor k, v in dune_meta.items():\n    dune_names_urls.update(dune_meta[k]['names_urls'])\n\nnames_ids  = {n : u.split('/')[-1] for n, u in dune_names_urls.items()}\n\nprint(len(dune_names_urls))\r\n```\n\n이 셀의 출력 결과는 프로필 URL이 포함된 119자입니다:\n\n\u003cimg src=\"/assets/img/2024-06-19-DuneAHiddenNetwork_2.png\" /\u003e\n\n1.2 캐릭터 프로필 다운로드\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 목표는 '둠(Dune)' 캐릭터들의 소셜 네트워크를 그리는 것입니다. 이것은 누가 누구와 상호작용했는지 파악해야 한다는 것을 의미합니다. 이전 하위 장에서는 '누가'의 목록을 얻었고, 이제 그들의 개인 이야기 정보를 얻을 것입니다. 이러한 이야기들은 간단한 웹 스크래핑 기술을 다시 사용하여 가져오고, 그리고 각 캐릭터의 개인 사이트의 소스를 로컬에 별도 파일로 저장할 것입니다:\n\n```js\n# 프로필 html 파일을 저장할 폴더\nfolderout = 'fandom_profiles'\nif not os.path.exists(folderout):\n    os.makedirs(folderout)\n      \n# 프로필 html 파일 가져오기 및 저장\nfor ind, (name, url) in enumerate(dune_names_urls.items()):\n    if not os.path.exists(folderout + '/' + name + '.html'):\n        try:\n            fout = open(folderout + '/' + name + '.html', \"w\")\n            fout.write(str(urlopen(url).read()))\n        except:\n            pass\r\n```\n\n이 코드를 실행한 결과는 저희 로컬 디렉토리에 각 선택된 캐릭터에 속한 모든 팬 위키 사이트 프로필이 있는 폴더가 생성됩니다.\n\n## 1.3 네트워크 구축하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n캐릭터 간 네트워크를 구축하기 위해서는, 각 캐릭터의 위키 사이트 소스가 다른 캐릭터의 위키 식별자를 얼마나 자주 참조하는지 카운트합니다. 다음과 같은 로직을 사용합니다. 여기서는 소스와 대상 노드(캐릭터)의 연결을 포함하는 연결 목록 - 두 캐릭터 페이지 간에 공동 참조 빈도를 포함하는 연결의 무게도 포함하는 연결 목록을 구축합니다.\n\n```js\n# html 소스에서 이름 언급을 추출하고 연결 목록을 딕셔너리로 구성\nedges = {}\n\nfor fn in [fn for fn in os.listdir(folderout) if '.html' in fn]:\n\n    name = fn.split('.html')[0]\n    \n    with open(folderout + '/' + fn) as myfile:\n        text = myfile.read()\n        soup  = bs.BeautifulSoup(text,'lxml')\n        text = ' '.join([str(a) for a in soup.find_all('p')[2:]])\n        soup = bs.BeautifulSoup(text,'lxml')\n        \n        \n        for n, i in names_ids.items():\n            \n            w = text.split('Image Gallery')[0].count('/' + i) \n            if w\u003e0:\n                edge = '\\t'.join(sorted([name, n]))\n                if edge not in edges:\n                    edges[edge] = w\n                else:\n                    edges[edge] += w\n\nlen(edges)\n```\n\n이 코드 블록을 실행하면, 119명의 둥니 캐릭터를 연결하는 307개의 엣지가 있는 결과를 얻을 수 있습니다.\n\n다음으로, NetworkX 그래프 분석 라이브러리를 사용하여 엣지 목록을 그래프 객체로 변환하고, 그래프가 가지고 있는 노드와 엣지의 수를 출력합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\n# dict of edges로부터 networkx 그래프를 생성합니다\nimport networkx as nx\nG = nx.Graph()\nfor e, w in edges.items():\n    if w \u003e 0:\n        e1, e2 = e.split('\\t')\n        G.add_edge(e1, e2, weight=w)\n\nG.remove_edges_from(nx.selfloop_edges(G))\n\nprint('노드 수: ', G.number_of_nodes())\nprint('엣지 수: ', G.number_of_edges())\n```\n\n위 코드 블록의 결과:\n\n\u003cimg src=\"/assets/img/2024-06-19-DuneAHiddenNetwork_3.png\" /\u003e\n\n노드 수는 단 72개이며, 47개의 문자가 어떤 중심 구성원과도 연결되지 않았음을 의미합니다. 아마도 해당 인물들의 위키 프로필은 꽤 간결한 것으로 보입니다. 게다가 몇 개의 자기 루프가 제거되어 엣지 수가 4개 줄었습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내장 Matplotlib 플로터를 사용하여 네트워크를 간단히 살펴보겠습니다:\n\n```js\n# 네트워크를 매우 간단히 살펴봅니다\nimport matplotlib.pyplot as plt\nf, ax = plt.subplots(1,1,figsize=(15,15))\nnx.draw(G, ax=ax, with_labels=True)\n```\n\n셀의 출력:\n\n\u003cimg src=\"/assets/img/2024-06-19-DuneAHiddenNetwork_4.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현재 이 시각화에서 이미 네트워크 구조가 일부 보입니다. 우리는 다음 코드 라인을 사용하여 그래프를 Gephi 파일로 내보내었고, 아래 그림에 첨부된 네트워크를 설계했습니다 (이러한 네트워크 시각화 방법은 곧 나올 튜토리얼 기사의 주제가 될 것입니다):\n\n```js\nnx.write_gexf(G, 'dune_network.gexf')\n```\n\n전체 Dune 네트워크:\n\n# 2 네트워크 읽기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"우리 네트워크의 중심에 폴 아트레이데스(리산 알-가이브, 무앗 딥, 우술, 코이삷 하데라흐 등으로도 불립니다)를 발견할 것이라는 것은 놀라운 일이 아닙니다. 그는 첫 번째 책(그리고 영화)의 주인공이자 마지막에는 제국 황제로 자리를 꿰차는 중요한 인물입니다. 두 번째 책인 '듄의 메시아'에서 우리는 전쟁을 벌이고 예지의 능력에 저주받은 지 오랜 기간 후의 리더인 다른 폴을 만나게 됩니다. 그는 블라인드 프레멘으로 사막으로 걸어가 스스로를 샤이-훌루드에 바칩니다. 그리고 나중에 '듄의 아이들'에서 등장하는 '선지자'로 나타납니다. 이 여정동안 그는 다른 많은 캐릭터와 마주하게 됩니다. 그의 이른바 이고 네트워크 — 그의 모든 연결 및 그 사이의 연걸 포함한 서브그래프 —는 모든 노드의 약 절반과 모든 링크의 64%를 포함하고 있음을 잘 보여줍니다. 아래에 그림도 나와 있습니다.\n\n![그림](/assets/img/2024-06-19-DuneAHiddenNetwork_5.png)\n\n우리는 네트워크를 계속 읽고 있으면 아트레이데스 가문이 중심에 자리하고 있음을 알 수 있습니다. 물론, 폴 주변에는 가족이 있습니다. 부모인 제시카 여사는 레토 아트레이데스 1세의 후궁이자 베네 게서릿 현자님입니다. 제시카는 하우스 하코넨의 블라디미르 하코넨의 딸로, 노드 그룹 중 노란색과 연한 파란색 노드 그룹 간의 첫 연결을 우리에게 보여줍니다. 폴과 프레멘 후궁 차니 사이에 강한 연결이 있으며, 그들의 자녀 레토 2세와 가니마와도 연결되어 있습니다. 폴은 멘토이자 친한 친구인 던컨 아이다호와 거니 할렉뿐만 아니라 베네 게서릿 현자인 가이우스 헬렌 모힘과도 밀접한 연결이 있습니다. 이 네트워크가 분명히 폴을 중심으로 하고 있음에도 불구하고 하우스 코리노(갈색), 하우스 하코넨(연한 파란색), 프레멘(파란색)의 명확한 그룹을 볼 수 있습니다. 하지만 우리에게 정말 흥미로운 점은 위키백과 기사를 기반으로 만든 이 간단한 네트워크가 이 세 권의 책 속 전개되는 줄거리에 대해 우리에게 많은 정보를 제공하고 있다는 것입니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLiet Kynes는 프레멘의 사실상의 지도자이자 식물학자로, 황량한 행성 아라키스가 푸르른 목초지와 물 공급으로 부자로 변하는 것을 꿈꾸었습니다. 그의 딸 Chani는 폴의 삶에서 중요한 인물인 스틸가와 연결되며 종교적인 추종자이자 프레멘 전체와 연결됩니다. 그러나 두 사이에 스키탈이 있었는데, 그는 무아딥의 지하, 덩컨 아이다호의 고라(죽은 개인을 복제한 인공적으로 창조된 인간)를 통해 로열 가문을 파괴하려 계획했습니다. 영화만 보신 분들은 덩컨이 우리 네트워크에서 중요한 인물이라는 것에 놀라실 수도 있지만, 아트레이데 집안의 검술사로 일한 뒤 아라키스 사막 전투에서 전사한 후, 상기된 고라로 돌아와 알리아 아트레이데스와 결혼하며 중요한 역할을 했습니다. 레이디 제시카의 딸이자 폴의 자매인 알리아 아트레이데스와 결혼하며 중요한 역할을 했습니다.\n\n영화 시청자들은 하코넨 집안의 일원으로서 투피어 하와트의 색채에도 놀라실지 모릅니다. 하우스 아트레이데스의 안전을 책임지는 멘타트인 그는 하코넨 집안이 아트레이데스를 아라키스 통치자로 대체한 후 그들의 봉사자로 강제로 들어가고 있었으며, 그들에게 반항하고 있었지만, 진정한 목표는 그가 사랑하는 덕의 죽음을 복수하는 것이었습니다. 제시카 여사가 공격의 배후라고 생각한 자데 그 후 그는 폴을 죽이지 않고 자살하는 행동으로 구원을 얻었습니다.\n\n그러나 이 네트워크에서 가장 매혹적인 부분은 캐릭터의 노드가 얼마나 작아 보이든 이들이 줄거나 중요한 역할을 하지 않았다는 뜻은 아닙니다. 그들은 올바른 말을 잘못된 대상에게 했을 수도 있었으며(Paul이 무아딥이 되기 전에 인간성의 중요한 요소를 잃었다고 주장한 Ix의 브론소), 알리아 아트레이데스의 연인이 되었을 수도 있으며(Javid), 아트레이데스 쌍둥이 레토와 가니마를 죽이려 계획했을 수도 있습니다(Tyekanik). 계속해서 말씀드릴 수 있습니다. 이들은 프랭크 허버트의 '듄'의 흥미진진하고 서로 연결된 정치적 배경 중 몇 가지 예일 뿐입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사를 통해, 데이터 과학 팬과 둥팬 사이에 다리를 만들고, 이 두 그룹 사이에 이미 존재하는 겹치는 커뮤니티를 재미있게 할 수 있도록 목표로 했습니다. 먼저, Python에서 상대적으로 일반적인 프레임워크를 제시하여 만날 수 있는 모든 팬 위키 사이트의 소셜 네트워크를 매핑할 수 있도록 했습니다. 둘째, 이 네트워크 시각화가 전체 이야기가 펼쳐지는 방식을 자세히 해석했습니다. 수많은 단어가 꼬리표가 되는 사진, 심지어 삼부작 이상의 가치를 지닌 사진입니다.","ogImage":{"url":"/assets/img/2024-06-19-DuneAHiddenNetwork_0.png"},"coverImage":"/assets/img/2024-06-19-DuneAHiddenNetwork_0.png","tag":["Tech"],"readingTime":10},{"title":"마이크로소프트 엑셀에서 대시보드 만들기  단계별 방법 제1부","description":"","date":"2024-06-19 15:53","slug":"2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1","content":"\n\n\n\u003cimg src=\"/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_0.png\" /\u003e\n\n아래에서 사용된 데이터 세트는 Tableau 커뮤니티에서 제공되는 Superstore 데이터 세트입니다.\n\nMicrosoft Excel에서 대시보드를 만드는 단계\n\n- 새 엑셀 워크북 열기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시트1을 대시보드로 변경해주세요.\n\n시트2를 데이터로 변경해주세요.\n\n![이미지](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_1.png)\n\n· 데이터를 작업용 문서의 데이터 시트에 복사해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_2.png)\n\nSelect the data and click insert Pivot Table\n\n1. Click the option - From table/Range\n\n2. Leave the table range as is and click new worksheet. A new sheet will be created, and rename it as Analyze\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Step3](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_3.png)\n\n![Step4](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_4.png)\n\n3. 오른쪽에는 피벗 테이블 필드가 나타날 것입니다. 필터, 열, 행, 값으로 구성된 네 가지 섹션이 있을 것입니다. 매출을 값으로 드래그하여 매출의 합계(집계)로 표시하고, 하위 범주를 행으로 이동시킵니다. 새로운 피벗 테이블 데이터가 생성됩니다.\n\n![Step5](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_5.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. 대시보드 시트에 표시해야 하는 3가지 KPI입니다. 이제, 피벗 테이블 데이터를 새 셀에 복사하여 붙여넣으세요.\n\n5. 모든 섹션에서 필드를 제거하고 하위 범주를 행 섹션에 추가하고 매출을 값을 섹션에 추가하세요.\n\n![이미지1](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_6.png)\n\n![이미지2](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· 피벗 테이블(하위 카테고리/판매)을 선택하고 삽입을 클릭한 후, 권장 차트를 선택하여 막대 차트를 클릭하세요.\n\n· 하위 카테고리별 판매 차트가 생성됩니다.\n\n![판매 부문 차트](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_8.png)\n\n차트 형식을 조정하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Dashboard](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_9.png)\n\n- Edit the title and right-click on the bar to sort it.\n- Hide all remaining buttons.\n- Remove the gridlines.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· 다시 데이터 분석 시트로 이동하여 피벗 테이블을 복사하고 새 셀에 붙여넣기 해주세요.\n\n이제 오른쪽에 다른 피벗 테이블 필드가 나타날 것입니다. 모든 섹션에서 필드를 제거하고 지역을 행 섹션으로, 매출을 값 섹션으로 추가해주세요.\n\n· 이 피벗 테이블을 선택한 후 삽입을 클릭하고 권장 차트를 선택하여 파이 차트를 클릭해주세요.\n\n· 차트를 서식을 지정해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지 태그를 아래와 같이 변경해 주세요:\n\n![Create Dashboard in Microsoft Excel Step by Step Method Part 1](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_10.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n동일한 단계를 따라서 또 다른 차트를 생성해 보세요. 월간 판매를 나타내는 선 그래프를 만들어 보겠습니다.\n\n행 부분에 월(주문 날짜)을 추가해 주세요.\n\n· 차트 서식 설정\n\no 제목 편집\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 버튼을 숨기세요\n\n그리드 라인을 제거하세요\n\n![이미지](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_11.png)\n\n워크북의 대시보드 시트 서식 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 대시보드의 구조를 그려 봅시다.\n\n- 모양에서 텍스트 상자를 삽입하고 선택한 후, 제목을 작성하고 상자를 채우고 가운데 정렬하세요.\n\n![이미지](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_12.png)\n\n마찬가지로 KPI 지표와 차트를 위한 자리 표시자를 만들어보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- KPI 값 추가하기. \"총 매출\" 상자를 클릭한 후, \"총 매출\" 텍스트 끝에서 엔터 키를 누르세요. 이제 커서가 아래 셀에 위치해 있습니다. 새 텍스트 상자를 추가한 후, 아래 공식을 사용하여 매출 금액을 입력하세요. 그리고 해당 KPI 상자 형식으로 텍스트 상자를 서식 지정해 주세요.\n\n`=Analyze!A4`\n\n![이미지](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_13.png)\n\n- 차트를 각각의 자리에 추가하고 서식을 설정하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_14.png)\n\n참고 :\n[마이크로소프트 공식 문서](https://support.microsoft.com/en-us/office/create-and-share-a-dashboard-with-excel-and-microsoft-groups-ad92a34d-38d0-4fdd-b8b1-58379aae746e#ID0EBBJ=Create_a_dashboard)","ogImage":{"url":"/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_0.png"},"coverImage":"/assets/img/2024-06-19-CreateDashboardinMicrosoftExcelStepbyStepMethodPart1_0.png","tag":["Tech"],"readingTime":4},{"title":"데이터 시각화 AI 에이전트의 성능 향상 - Performance Improvement","description":"","date":"2024-06-19 15:50","slug":"2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent","content":"\n\n## DSPy를 사용하고 최적화 기술을 활용하여 에이전트 성능 향상\n\n![에이전트 이미지](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_0.png)\n\n몇 주 전에, 데이터 시각화를 지원하는 AI 에이전트를 개발하는 프로젝트를 공유했습니다. 에이전트는 대부분의 쿼리에 대해 잘 작동했지만 때로는 실행 불가능한 코드와 불완전한 지침(부제/주석과 같은 중요한 구성 요소를 잊어버린)과 같은 여러 문제가 발생할 때가 있었습니다. 대부분의 에이전트 응용 프로그램과 마찬가지로 성능 측면에서 신뢰할 수 없었지만, 이 게시물에서는 어떻게 에이전트를 더 잘 작동하게 만들었는지에 대해 설명합니다.\n\nAI 에이전트에 문제가 있나요? AI 에이전트의 신뢰성과 견고성을 향상시키고 싶으신가요? 에이전트를 효과적으로 개발하는 방법을 모르시겠나요? 전문가에게 문의해보세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://form.jotform.com/240744327173051\n\n![Image 1](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_1.png)\n\n![Image 2](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_2.png)\n\n# 요약\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 에이전트의 성능을 최적화하는 방법을 설명하기 전에, 에이전트가 구축된 방식에 대해 간단히 되짚어보려고 합니다. 그러면 따라오실 수 있을 거예요.\n\n![에이전트 이미지](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_3.png)\n\n에이전트에는 이 두 가지 구성 요소가 있어요:\n\n- 데이터프레임 인덱스: 이것은 에이전트가 사용하는 데이터프레임에 대한 정보를 담고 있는 인덱스입니다. 열 이름, 데이터 유형 및 통계 정보 (최솟값/최댓값/카운트/평균)과 같은 것들이 있어요.\n- 스타일링 도구: 이곳에는 Plotly의 다양한 차트 유형에 대한 자연어로 된 정보가 있어요. 각 유형의 차트를 어떻게 서식 지정해야 하는지에 대한 에이전트의 지침이 담겨 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n에이전트는 사용자 쿼리를 처리하여 관련 열을 식별하고 적절한 차트 유형을 결정합니다. 그런 다음 실행할 때 지정된 차트를 생성하는 Python 코드를 생성합니다.\n\n에이전트가 어떻게 만들어졌는지 더 알고 싶다면, 이 게시물을 읽어보세요:\n\n# 성능 측정\n\n에이전트를 개선하는 첫 번째 단계는 현재 성능을 측정하고 시스템에 가한 변경 사항과 비교하는 것입니다. 효과적으로 성능을 측정하기 위해 시스템이 마주할 쿼리 세트를 포함하는 데이터 세트를 생성해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 쿼리 데이터 세트 작성하기\n\nLLM이 만나게 될 쿼리 유형을 추가할 수 있습니다. 여기서 한 것처럼 LLM에게 해달라고 요청하는 것이 더 쉬운 방법입니다.\n\n![image](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_4.png)\n\n평가 목적으로 추가적인 쿼리를 생성하도록 Language Model에 계속해서 요청할 수 있습니다. 자신만의 쿼리를 기여하는 것이 매우 유익합니다. 또한, 인덱스에 없는 정보를 요청하거나 데이터 시각화와 관련이 없는 질문 등, 에이전트를 도전시킬 수 있는 쿼리를 생성하는 것이 좋습니다. 여기에 제가 개발한 쿼리 세트의 예시가 있습니다. 기억해야 할 요점은 이 세트가 에이전트가 만날 가능성이 있는 모든 유형의 쿼리를 포함해야 한다는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n# 여기에는 LLM을 사용하여 만든 몇 가지 평가 쿼리가 나와 있어요.\n평가 쿼리는 다음과 같아요:\n- 'Filtering', 'Crime Analysis', 'Data Comparison', 'Advanced Queries', 'Imaginary Data', 'Irrelevant Queries', 'Prompt Injections', 'Line Chart', 'Bar Chart', 'Pie Chart', 'Map', 'Single-Value', 'Sankey' 같이 다양한 카테고리로 구성돼요.\n\n## 평가 메트릭\n\n이제 우리는 에이전트의 응답 \"유효성\"을 수치적으로 정의할 방법이 필요해요 - 우수한 응답과 좋지 않은 응답을 구별할 수 있는 점수 메커니즘이요.\n\n이 논리 다이어그램은 설계된 평가 메트릭이 작동하는 방식을 설명해줘.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_5.png)\n\n전체 점수를 계산하려면 코드가 필요한 속성을 갖추었는지 확인하는 기본적인 방법을 사용하거나 Large Language Model (LLM)을 사용하여 평가를 수행할 수 있습니다. 제 구현에서는 각 쿼리에 대해 작은 점수 평가기를 구축하여 DSPy 서명을 사용했습니다.\n\n```python\nimport dspy\nfrom pydantic import BaseModel, Field\n\n# 출력을 위한 pydantic validator 정의\nclass Score(BaseModel):\n    commentary: str = Field(desc=\"점수 분석\")\n    Score: int = Field(desc=\"점수\")\n\n# 총점을 평가하는 데 사용할 서명 정의\nclass Scorer(dspy.Signature):\n    \"\"\"\n    쿼리와 코드를 위해 제공된 서명으로 총점을 계산합니다.\n    \"\"\"\n\n    query = dspy.InputField(desc=\"데이터 및 그래프에 대한 정보가 포함된 사용자 쿼리\")\n    code = dspy.InputField(desc=\"에이전트가 생성한 코드\")\n    output: Score = dspy.OutputField(desc='코드를 평가한 후의 점수')\n\n# 코드 실행 여부를 확인하는 함수\ndef check_code_run(code):\n    score = 0\n    try:\n        code = code.split('')[1]\n        exec(code)\n        score += 10\n        return score\n    except:\n        return score\n\n# LLM이 찾는 속성을 모두 찾았는지 여부에 따라 점수를 계산하는 함수\ndef evaluating_response(code, query):\n    score = 0\n    scorer = dspy.Predict(Scorer)\n    response = scorer(query=query, code=code)\n    score += int(response.Score.split('Score:')[1])\n    return score\n```\n\n평가 지표를 정의한 후, '미훈련' 시스템의 성능을 확인해보겠습니다. DSPy를 최적화하기 위해 DSPy 모듈 및 서명을 사용하여 에이전트를 다시 만들어야 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희는 대규모 언어 모델 애플리케이션을 개선해 드리는 전문가입니다. 문의하실 사항이 있으시면 언제든지 아래 링크를 통해 저희에게 연락해 주세요:\nhttps://form.jotform.com/240744327173051\n\n## DSPy에서 에이전트 정의하기\n\n```js\nfrom pydantic import BaseModel, Field\n\n# Pydantic 출력 파서\nclass Plotly_code(BaseModel):\n    commentary: str = Field(desc=\"코드에 대한 주석\")\n    Code: str = Field(desc=\"Plotly 코드\")\n\n# 우리의 프롬프트에 대한 시그니처\nclass AgentSig(dspy.Signature):\n    \"\"\"\n    여러분은 Plotly에서 데이터 시각화를 생성하기 위해 {query}를 사용하는 AI 에이전트입니다.\n    사용 가능한 도구를 활용해야 합니다.\n    {dataframe_index}\n    {styling_index}\n\n    해당하는 열이 없는 경우 코드로 출력해야 합니다. 해당 정보가 없다고 밝히세요.\n    \"\"\"\n    query = dspy.InputField(desc=\"차트를 그리고자 하는 데이터 및 차트에 대한 정보를 포함한 사용자 쿼리\")\n\n    dataframe_context = dspy.InputField(desc=\"데이터 프레임의 데이터에 대한 정보 제공. 컬럼 이름 및 데이터 프레임 이름만 사용해야 함\")\n    styling_context = dspy.InputField(desc='Plotly 차트에 스타일을 적용하는 방법에 대한 지시')\n    code: Plotly_code = dspy.OutputField(desc=\"사용자 쿼리 및 dataframe_index 및 styling_context에 따라 필요한 시각화를 하는 Plotly 코드\")\n    \nclass AI_data_viz_agent(dspy.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.dataframe_index = dataframe_index\n        self.style_index = style_index\n\n        self.agent = dspy.ChainOfThought(AgentSig)\n    \n    def forward(self, query):\n        dataframe_context = self.dataframe_index.as_retriever(similarity_top_k=1).retrieve(query)[0].text\n        styling_context = self.style_index.as_retriever(similarity_top_k=1).retrieve(query)[0].text\n\n        prediction = self.agent(dataframe_context=dataframe_context, styling_context=styling_context, query=query)\n\n        return dspy.Prediction(dataframe_context=dataframe_context, styling_context=styling_context, code=prediction.code)\n\nlm = dspy.GROQ(model='llama3-70b-8192', api_key=\"\", max_tokens=3000)\ndspy.configure(lm=lm)\n\nagent = AI_data_viz_agent()\nprint(agent('What is the distribution of crimes by type by histogram?').code)\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_6.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## DSPy 프로그램 미컴파일/미훈련 평가\n\n벤치마킹을 수립하기 위해, 더 나은 성능을 위해 우리의 에이전트를 ‘훈련/컴파일’하지 않고 먼저 평가하겠습니다.\n\n```js\n# eval_df는 데이터셋 섹션에서 정의되었습니다\n# 평가 df에 코드 추가\ncode_list = []\nfor q in eval_df['Query']:\n    code_list.append(agent(q).code)\neval_df['Code'] = code_list\n\n# 코드가 실행되는지 확인하는 방법을 사용하여 실행함\n\neval_df['check_run'] = [check_code_run(code) for code in eval_df['Code']]\n\n# evaluate_response 방법을 사용하여 코드의 속성을 평가\neval_df['Attribute_Score'] = [evaluating_response(code, query) for code, query in zip(eval_df['Code'], eval_df['Query'])]\n\n# 에이전트가 필요한 정보를 갖고 있는 쿼리만 \n# 답변 가능해야 합니다. 에이전트가 충분한 정보가 없는 \n# 질문에 정확한 코드를 생성하는 상황을 피하고 싶습니다.\neval_df['Answerable'] = [1 if x.strip().lower()!='no relevant information' else 0 for x in eval_df['Expectation']]\n```\n\n![이미지](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 최종 점수 계산\n# 심사원 서명 작성\nclass CodeJudge(dspy.Signature):\n    \"\"\"응답에 코드가 포함되어 있는지 판단합니다.\"\"\"\n    response = dspy.InputField(desc=\"AI 에이전트로부터의 응답\")\n    has_code = dspy.OutputField(desc=\"응답에 파이썬 코드가 포함되어 있는지 여부\", prefix=\"사실적[예/아니오]:\")\n\n# 각 예측 응답에 대한 최종 점수를 계산하는 메트릭\n# 최고의 응답을 포함하는 예시와 비교\ndef full_metric(example, pred, trace=None):\n    if 'No relevant information' not in example.code:\n        check_run = check_code_run(pred.code)\n        attributes = evaluating_response(pred.code, example.query)\n    else:\n        check_if_code = dspy.ChainOfThought(CodeJudge)\n        response = check_if_code(response=pred.code)\n        if response.has_code.split('사실적[예/아니오]:')[1].strip() == '예':\n            return 0\n        else:\n            return 19\n        \n    return check_run + attributes\n\nzip_ = zip(eval_df['Answerable'], eval_df['check_run'], eval_df['Attribute_Score'], eval_df['Code'])\neval_df['Total_Score'] = [final_score(a, c, a_s, c) for a, c, a_s, c in zip_]\n\n# 총 점수 / 총 가능 점수 계산\n\neval_full_df['Total_Score'].sum() / (len(eval_full_df)) * 19\n```\n\n![이미지](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_8.png)\n\n![이미지](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_9.png)\n\n# 성능 향상\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n성능을 향상시키기 위해서는 모델에 완벽한 점수를 획득할 수 있는 예제를 제공해야 합니다. 다행히도, 에이전트가 이미 이 작업의 절반을 완료했습니다. 훈련 세트를 준비하기 위해 누락된 속성을 추가하고 코드를 실행할 수 있도록 해야 합니다. 쿼리가 결과를 반환하지 않아야 하는 경우, 예제에 간단히 '관련 정보 없음'을 포함하면 됩니다.\n\n그러나 개선된 코드를 검증하는 데는 조금 경계를 두고, 실제로 필요한 모든 속성이 코드에 있는지 확인하기 위해 다시 테스트해야 합니다.\n\n```js\n# 코드 개선 에이전트를 위한 새로운 서명 정의 \nclass Improver(dspy.Signature):\n    \"\"\"\n    코드 개선 에이전트입니다. 코드와 설명을 입력으로 받고 향상된 코드 개선을 출력합니다.\n    코드와 설명을 취해서 Plotly 코드를 출력해야 합니다. 이는 완벽한 점수를 받을 수 있는 코드입니다.\n\n    이 코드가 판단된 9가지 속성: 각 정답마다 +1\n    {'correct_column_names', 'title', 'Annotations', 'Format number in 1000 in K \u0026 millions in M only for numbers',\n   'Aggregation used', 'correct axis label', 'Plotly_white theme', 'Correct chart type', 'Html tag like \u003cb\u003e',}\n\n     여기가 따라야 하는 형식입니다\n    code: {code}\n    commentary:{commentary}\n    improved_code: 9점을 얻는 향상된 출력\n    \"\"\"\n    code = dspy.InputField(desc=\"개선해야 하는 코드\")\n    commentary = dspy.InputField(desc=\"평가 에이전트가 제공한 코드에 대한 설명\")\n    improved_code = dspy.OutputField(desc=\"평가에 따라 완벽한 점수를 받을 수 있는 향상된 코드\")\n\n# 이 개선 에이전트 모듈은 개선된 코드를 제공할 것입니다.\nimprover = dspy.ChainOfThought(Improver)\n# 원하는 기준을 충족하는지를 확인하기 위해 이전에 정의한 평가 모듈을 사용할 수 있습니다.\nscorer = dspy.ChainOfThough(Scorer)\n```\n\n개선자와 평가자 모듈을 호출하여 생성하고 검증하면 대부분의 작업이 완료됩니다. 이제 출력을 수동으로 확인하기만 하면 됩니다. 저희 훈련 세트는 총 59개의 쿼리이므로 한 번에 하나씩 확인하는 것이 좋습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Improving Performance for Data Visualization AI Agent](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_10.png)\n\n## 학습세트 생성하기\n\n이제 DSPy Optimizer로 훈련 예제를 보내서 몇 가지 샷 예제를 추가하여 프롬프트를 개선할 수 있습니다.\n\n```js\n# 판사 서명 작성\nclass CodeJudge(dspy.Signature):\n    \"\"\"응답에 코드가 포함되어 있는지 확인합니다\"\"\"\n    response = dspy.InputField(desc=\"AI 에이전트에서 온 응답\")\n    has_code = dspy.OutputField(desc=\"응답에 파이썬 코드가 포함되어 있는지 여부\", prefix=\"사실적[예/아니오]:\")\n\n# 모든 예측된 응답에 대한 최종 점수를 계산하는 메트릭\n# 가장 적절한 응답을 포함한 예제와 비교합니다\ndef full_metric(example, pred, trace=None):\n    if 'No relevant information' not in example.code:\n        check_run = check_code_run(pred.code)\n        attributes = evaluating_response(pred.code, example.query)\n    else:\n        check_if_code = dspy.ChainOfThought(CodeJudge)\n        response = check_if_code(response=pred.code)\n        if response.has_code.split('사실적[예/아니오]:')[1].strip() == '예':\n            return 0\n        else:\n            return 19\n        \n    return check_run + attributes\n\n# 쿼리, 코드 쌍을 DSPy Example로 포맷팅\ntrainset = [dspy.Example(query=q, code=c).with_inputs('query') for q, c in zip(eval_full_df['Query'], eval_full_df['Best Response'])]\n```\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Few Shot 예시 찾기\n\nLLM에 프롬프트에 몇 가지 예시를 제공하는 것은 LLM의 응답을 향상시키는 일관된 기술이었습니다. 좋은 예시를 찾는 전통적인 방법은 추측하고 시도해보는 것이었습니다. 이제 추가할 예시를 체계적으로 찾을 수 있습니다.\n\nBootStrapFewShot은 다음을 수행하여 시작합니다:\n\n- 최적화하려는 학생 프로그램과 일반적으로 학생의 사본인 선생님 프로그램을 초기화합니다.\n- LabeledFewShot 텔레프롬프터를 사용하여 선생님에게 데모를 추가합니다.\n- 예측기의 이름과 학생 및 선생님 모델 모두에서 해당 인스턴스와의 매핑을 생성합니다.\n- 부트스트랩 데모 수(최대 부트스트랩)를 설정하여 생성되는 초기 교육 데이터 양을 제한합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 훈련 세트의 각 예제를 거쳐 갑니다. 각 예제에 대해:\n\n- 해당 방법은 부트스트랩의 최대 횟수에 도달했는지 확인합니다. 그렇다면 프로세스가 중지됩니다.\n- 교사 모델이 예측을 생성하려고 합니다.\n- 교사 모델이 성공적으로 예측을 수행하면, 이 과정의 세부 내용이 기록됩니다. 이에는 어떤 예측자가 호출되었는지, 받은 입력 및 생성된 출력이 포함됩니다.\n- 예측이 성공하면, 기록된 과정의 각 단계에 대해 입력 및 출력을 포함한 데모가 생성됩니다.\n\n```js\nfrom dspy.teleprompt import BootstrapFewShotWithRandomSearch\n\n# 옵티마이저 설정: 프로그램 단계의 8번 샘플을 \"부트스트랩\"(즉, 자체 생성)하기를 원합니다.\n# 옵티마이저는 이를 개발세트에서 최상의 시도로 선택하기 전에 10번 반복(초기 시도 포함)합니다.\nconfig = dict(max_bootstrapped_demos=2, max_labeled_demos=2, num_candidate_programs=3, num_threads=4)\n\n# 간단히 말해, 임의 검색으로 적은 데이터로 학습하기는 LLM을 사용하여 예제를 생성한 후\n# 이를 평가하는 방식으로 작동합니다.\n# 여러 번의 반복 후에는 훈련 세트에 좋은 예제가 생성됩니다.\nteleprompter = BootstrapFewShotWithRandomSearch(metric=full_metric, **config)\noptimized_agent = teleprompter.compile(agent, trainset=trainset)\n```\n\n훈련 후 이를 통해 프롬프트에 추가할 몇 가지 예제가 제공됩니다. 이를 확인하려면 lm.inspect_history(n=1)을 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![표](/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_11.png)\n\n## 프롬프트 지침, 서명 및 접두사 최적화\n\n프롬프트를 테스트할 예제는 있지만 초기 지침은 어떻게 할까요? DSPy는 COPRO라는 알고리즘을 사용하여 이를 최적화합니다. 이 알고리즘은 다음과 같이 작동합니다:\n\n- 새로운 지침 생성 및 개선: COPRO는 새로운 지침 세트를 생성하고 단계별로 개선합니다.\n- Coordinate Ascent(언덕 오르기): 이것은 각 단계가 주어진 메트릭 함수를 기반으로 결과를 개선하려는 최적화 기술입니다. 언덕 오르기는 계속해서 값이 증가하는 솔루션을 향해 이동하는 로컬 탐색 알고리즘입니다.\n- 메트릭 함수 및 훈련 데이터셋: 최적화에는 메트릭 함수(성공이나 적합성의 양적 측정일 수 있음)와 훈련 데이터셋(trainset)을 사용하여 지침을 평가하고 개선합니다.\n- 깊이: 이 매개변수는 프롬프트를 개선하기 위해 최적화자가 수행하는 반복 횟수를 지정합니다. 보통 더 많은 반복은 더 정제되고 최적화된 지침을 가능하게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom dspy.teleprompt import COPRO\n\n# 설계된 메트릭과 시도할 최적화 횟수를 알려주는 폭으로 COPRO를 초기화합니다.\nteleprompter = COPRO(\n    metric=full_metric,\n    verbose=True, breadth=5\n)\n\n# num_threads는 LLM과 함께 열리는 인스턴스 수입니다. \n# API를 과도하게 사용하여 요금이 부과될 수 있으니 주의하세요.\nkwargs = dict(num_threads=8, display_progress=True, display_table=0) # 최적화 프로세스의 Evaluate 클래스에서 사용됨\n\n# 프로그램을 컴파일합니다.\ncompiled_prompt_opt = teleprompter.compile(agent, trainset=trainset[:40], eval_kwargs=kwargs)\n# 나중에 검토할 수 있도록 저장합니다.\ncompiled_prompt_opt.save('COPRO_agent.json')\n```\n\n컴파일 후에는 에이전트의 성능을 향상시키는 데 어떤 종류의 지침, 접두사 및 서명이 더 나은 성능을 낼지 확인할 수 있습니다.\n\n```js\n# 모든 DSPy 프로그램 내부에서 __dict__를 사용하여 후보 프로그램을 확인할 수 있습니다.\ncompiled_prompt_opt.__dict__\n```\n\n\u003cimg src=\"/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_12.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_13.png\" /\u003e\n\n# 결과\n\n아래는 각 프롬프트 기법에 대한 컴파일된 결과입니다. 전체적으로 가장 큰 개선은 시그니처 및 접두사를 최적화한 COPRO_AGENT에서 나왔습니다. 즉, 원래 지시사항 및 접두사가 매우 최적화되지 않았음을 의미합니다. 전체적으로 COPRO 에이전트는 데이터셋에서 71%의 성능을 보였으며, FewShoot는 63%의 성능을 보였으며, 베이스 라인은 60%였습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_14.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 다음 단계\n\n에이전트는 분명히 개선되었지만 아직 멀었습니다. 저는 이 AI 에이전트를 사용하여 기본적인 탐색적 데이터 분석 및 통계 모델링을 수행하는 등의 추가 기능을 더욱 개선할 계획입니다.\n\n이 게시물이 유익했다면 FireBird Technologies와 저를 Medium에서 팔로우해보세요. AI 개발에 도움이 필요하다면 아래 링크를 통해 자유롭게 연락해 주세요.\n\n[링크](https://form.jotform.com/240744327173051)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n읽어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_0.png"},"coverImage":"/assets/img/2024-06-19-ImprovingPerformanceforDataVisualizationAIAgent_0.png","tag":["Tech"],"readingTime":14}],"page":"76","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"76"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>