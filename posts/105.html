<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/105" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/105" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="질문-응답 시스템 주요 아키텍처 개요" href="/post/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="질문-응답 시스템 주요 아키텍처 개요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="질문-응답 시스템 주요 아키텍처 개요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">질문-응답 시스템 주요 아키텍처 개요</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="성의 기초" href="/post/2024-05-27-TheVeryFoundationofSex"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="성의 기초" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-TheVeryFoundationofSex_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="성의 기초" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">성의 기초</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대용량 데이터셋 특성 선택을 혁신하는 강화 학습" href="/post/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대용량 데이터셋 특성 선택을 혁신하는 강화 학습" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대용량 데이터셋 특성 선택을 혁신하는 강화 학습" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">대용량 데이터셋 특성 선택을 혁신하는 강화 학습</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="이해할 수 있는 이상 탐지 Frequent Patterns Outlier Factor FPOF" href="/post/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="이해할 수 있는 이상 탐지 Frequent Patterns Outlier Factor FPOF" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="이해할 수 있는 이상 탐지 Frequent Patterns Outlier Factor FPOF" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">이해할 수 있는 이상 탐지 Frequent Patterns Outlier Factor FPOF</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="시계열 데이터에서 이상치를 찾는 궁극의 안내서 파트 1" href="/post/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="시계열 데이터에서 이상치를 찾는 궁극의 안내서 파트 1" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="시계열 데이터에서 이상치를 찾는 궁극의 안내서 파트 1" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">시계열 데이터에서 이상치를 찾는 궁극의 안내서 파트 1</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">20<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="임베딩 크기를 줄이고 RAG 검색 속도 높이는 방법" href="/post/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="임베딩 크기를 줄이고 RAG 검색 속도 높이는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="임베딩 크기를 줄이고 RAG 검색 속도 높이는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">임베딩 크기를 줄이고 RAG 검색 속도 높이는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="차이인차이 101" href="/post/2024-05-27-Difference-in-Difference101"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="차이인차이 101" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-Difference-in-Difference101_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="차이인차이 101" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">차이인차이 101</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Ollama를 사용하여 모델 실행하기 단계별 안내" href="/post/2024-05-27-RunningmodelswithOllamastep-by-step"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Ollama를 사용하여 모델 실행하기 단계별 안내" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Ollama를 사용하여 모델 실행하기 단계별 안내" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Ollama를 사용하여 모델 실행하기 단계별 안내</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI가 다물고 보니 연기와 거울일까요" href="/post/2024-05-27-HowDoWeKnowifAIIsSmokeandMirrors"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI가 다물고 보니 연기와 거울일까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-HowDoWeKnowifAIIsSmokeandMirrors_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI가 다물고 보니 연기와 거울일까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI가 다물고 보니 연기와 거울일까요</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="약물 발견을 위한 지식 그래프" href="/post/2024-05-27-KnowledgeGraphsforDrugDiscovery"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="약물 발견을 위한 지식 그래프" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-27-KnowledgeGraphsforDrugDiscovery_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="약물 발견을 위한 지식 그래프" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">약물 발견을 위한 지식 그래프</strong><div class="PostList_meta__VCFLX"><span class="date">May 27, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/101">101</a><a class="link" href="/posts/102">102</a><a class="link" href="/posts/103">103</a><a class="link" href="/posts/104">104</a><a class="link posts_-active__YVJEi" href="/posts/105">105</a><a class="link" href="/posts/106">106</a><a class="link" href="/posts/107">107</a><a class="link" href="/posts/108">108</a><a class="link" href="/posts/109">109</a><a class="link" href="/posts/110">110</a><a class="link" href="/posts/111">111</a><a class="link" href="/posts/112">112</a><a class="link" href="/posts/113">113</a></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"질문-응답 시스템 주요 아키텍처 개요","description":"","date":"2024-05-27 15:08","slug":"2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures","content":"\n## 확장 가능한 정보 검색 시스템을 구축하는 디자인 방식 탐색\n\n![Question-AnsweringSystemsOverviewofMainArchitectures](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_0.png)\n\n# 소개\n\n최근 몇 년 동안 질문-응답 애플리케이션이 강력하게 등장했습니다. 현대적인 검색 엔진, 챗봇 또는 단순히 대량의 테마 데이터에서 관련 정보를 검색하는 애플리케이션 등 어디에서나 찾을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이름에서 알 수 있듯이 QA 응용 프로그램의 목적은 텍스트 단락에서 주어진 질문에 대한 가장 적합한 답변을 검색하는 것입니다. 처음 몇 가지 방법은 키워드 또는 정규 표현식을 사용한 단순한 검색으로 이뤄졌습니다. 당연히 이러한 접근 방식은 최적이 아닙니다: 질문이나 텍스트에 오타가 있을 수 있습니다. 게다가, 정규 표현식은 쿼리에서 주어진 단어와 관련이 높은 유의어를 감지할 수 없습니다. 이러한 접근 방식은 결과적으로, 트랜스포머와 벡터 데이터베이스 시대에 특히 강력한 새로운 방법론으로 대체되었습니다.\n\n이 기사에서는 현대적이고 확장 가능한 QA 응용 프로그램을 구축하기 위한 세 가지 주요 설계 접근 방식을 다룹니다.\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_1.png)\n\n# 추출형 QA\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n추출형 QA 시스템은 세 가지 구성 요소로 구성되어 있습니다:\n\n- 검색기 (Retriever)\n- 데이터베이스 (Database)\n- 리더 (Reader)\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_2.png)\n\n먼저, 질문이 검색기에 입력됩니다. 검색기의 목표는 질문에 해당하는 임베딩을 반환하는 것입니다. 간단한 벡터화 방법인 TF-IDF, BM-25부터 더 복잡한 모델까지 다양한 구현이 있을 수 있습니다. 대부분의 경우 트랜스포머와 같은 모델 (BERT)이 검색기에 통합됩니다. 단순한 단어 빈도수만을 의존하는 날것한 접근 방식과는 달리, 언어 모델은 텍스트의 의미를 캡처할 수 있는 밀집된 임베딩을 구축할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n질문에서 쿼리 벡터를 얻은 후, 외부 문서 모음에서 가장 유사한 벡터를 찾는 데 사용됩니다. 각 문서에는 질문에 대한 답변이 포함될 확률이 있습니다. 보통 문서 모음은 학습 단계에서 처리되어 리트리버에 전달되어 해당 문서에 대한 임베딩을 출력합니다. 이러한 임베딩은 일반적으로 효과적인 검색을 제공할 수 있는 데이터베이스에 저장됩니다.\n\n쿼리 벡터와 가장 유사한 상위 k개의 데이터베이스 벡터를 검색함으로써, 원래 텍스트 표현을 사용하여 다른 구성 요소인 리더가 답변을 찾습니다. 리더는 초기 질문을 취하고 k개의 검색된 문서 각각에서 텍스트 단락에서 답변을 추출하고 이 답변이 올바른 확률을 반환합니다. 가장 높은 확률을 갖는 답변이 마지막으로 독점 QA 시스템에서 반환됩니다.\n\n# 오픈 생성형 QA\n\n오픈 생성형 QA는 추출형 QA와 정확히 동일한 프레임워크를 따릅니다. 단, 리더 대신 제너레이터를 사용한다는 점에서 차이가 있습니다. 리더와 달리 제너레이터는 텍스트 단락에서 답변을 추출하지 않습니다. 대신, 질문과 텍스트 단락에서 제공된 정보를 사용하여 답변이 생성됩니다. 추출형 QA의 경우와 마찬가지로 가장 높은 확률을 갖는 답변이 최종 답변으로 선택됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Question-Answering Systems Overview of Main Architectures](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_3.png)\n\n비슷한 구조를 가지고 있기 때문에, 추출형 또는 개방적 생성 구조를 사용하는 것이 더 나은 시점에 대한 질문이 생길 수 있습니다. 독자 모델이 상대적 정보를 포함한 텍스트 단락에 직접 액세스할 수 있는 경우, 일반적으로 정확하고 간결한 답변을 검색하는 데 충분히 똑똑합니다. 반면에, 대부분의 경우 생생 생성 모델은 주어진 맥락에 대해 더 긴 범용 정보를 생성하는 경향이 있습니다. 이는 질문이 개방형 형태로 제시될 때 유익할 수 있지만, 짧거나 정확한 답변이 예상되는 상황에는 해당되지 않을 수 있습니다.\n\n## 검색 보조 생성\n\n최근 기계 학습에서 \"검색 보조 생성\" 또는 \"RAG\"라는 용어의 인기가 급증했습니다. 간단히 말하면, 이는 개방형 생성 QA 시스템에 기반을 둔 LLM 응용 프로그램을 생성하는 프레임워크입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n경우에 따라서, LLM 응용 프로그램이 여러 지식 도메인과 작동하는 경우, RAG 검색기는 주어진 쿼리에 가장 관련있는 지식 도메인을 식별하려는 보조 단계를 추가할 수 있습니다. 식별된 도메인에 따라 검색기는 다양한 작업을 수행할 수 있습니다. 예를 들어, 특정 도메인에 속하는 쿼리의 경우 해당 도메인의 벡터 데이터베이스를 사용하여 쿼리에 가장 관련있는 정보를 검색할 수 있습니다.\n\n이 기술은 모든 문서가 아닌 특정 문서 하위 집합을 통해 검색하기 때문에 검색 프로세스를 더 빠르게 만듭니다. 게다가, 검색을 더 신뢰할 수 있게 만들 수 있습니다. 왜냐하면 최종 검색된 컨텍스트가 더 많은 관련 문서에서 구성되기 때문입니다.\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_4.png)\n\n## 닫힌 생성 QA\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n닫힌 생성형 QA 시스템은 외부 정보에 액세스할 수 없으며 질문에서 제공된 정보만 사용하여 답변을 생성합니다.\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_5.png)\n\n닫힌 QA 시스템의 명백한 이점은 대규모 외부 문서 집합을 검색할 필요가 없어지므로 파이프라인 시간을 줄일 수 있다는 점입니다. 그러나 교육 및 정확도 측면에서는 비용이 발생합니다: 생성기는 충분히 강력하고 적절한 답변을 생성할 수 있도록 충분한 학습 지식을 갖추어야 합니다.\n\n닫힌 생성형 QA 파이프라인은 다른 단점도 있습니다. 생성기는 교육을 받은 데이터에 후에 나타난 정보를 알지 못합니다. 이 문제를 해결하기 위해 생성기는 최신 데이터셋에 다시 교육을 받을 수 있습니다. 그러나 생성기는 일반적으로 수백만 또는 수십억 개의 매개변수를 가지고 있기 때문에 이러한 교육은 매우 많은 자원을 필요로 합니다. 이와 비교하여 추출형 QA 및 개방형 생성형 QA 시스템으로 동일한 문제를 다루는 것은 훨씬 간단합니다. 벡터 데이터베이스에 새로운 콘텍스트 데이터를 추가하는 것만으로 충분합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대부분의 경우 일반적인 질문이 있는 애플리케이션에서는 폐쇄형 생성 접근 방식이 사용됩니다. 매우 구체적인 도메인의 경우, 폐쇄형 생성 모델의 성능이 저하되는 경향이 있습니다.\n\n# 결론\n\n본 문서에서 QA 시스템 구축을 위한 세 가지 주요 접근 방법을 발견했습니다. 이들 중에서 절대적인 승자는 없습니다. 각각이 각자의 장단점을 갖고 있습니다. 그러므로 먼저 입력 문제를 분석하고 올바른 QA 아키텍처 유형을 선택하여 더 나은 성능을 내도록 하는 것이 선행되어야 합니다.\n\n머신 러닝 분야에서 Open Generative QA 아키텍처가 현재 트렌드로 떠오르고 있으며, 특히 최근에 등장한 혁신적인 RAG 기술들과 함께 그 인기가 높아지고 있습니다. NLP 엔지니어라면 지금 당장 RAG 시스템에 주목하는 것이 좋습니다. 이 시스템들은 최근에 엄청난 속도로 발전하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 자료\n\n- 질의 응답 | Hugging Face\n\n모든 이미지는 특별히 언급되지 않는 한 저자에 의해 제공됩니다.\n","ogImage":{"url":"/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_0.png"},"coverImage":"/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_0.png","tag":["Tech"],"readingTime":5},{"title":"성의 기초","description":"","date":"2024-05-27 15:07","slug":"2024-05-27-TheVeryFoundationofSex","content":"\n\n![image](/assets/img/2024-05-27-TheVeryFoundationofSex_0.png)\n\n나의 남자친구는 정말 질투심이 많은 사람인데, 그게 맘에 든다. 최근에 그는 약물을 먹여 적나라하게 만지작거리며 자국들을 즐기던 야한 이야기를 나눠주었다. 그 결과로 그는 세로필름으로 감싸져 있고 누군가에 의해 최면을 걸리게 된 것이었다. 그는 몇 년간 에로틱 탐험의 세계에 발을 들인 적이 있었는데, 아마도 나와 같은 기간 동안 활동했던 것 같다.\n\n매우 섹시한 최면 비디오를 보려면 여기를 클릭해주세요: [영상 링크](https://youtu.be/mkcTmNe6kQU?si=LktapkZGHkdnbZFW)\n\n특히 격렬한 세션 끝에 하룻밤, 그의 품에서 잠이 들었다. 그가 부드럽게 내 등을 쓸어 주며, 나는 몸을 돌리고 그가 속삭였다. \"너는 완전 훌륭한 사람이 됐어.\" 그 말에 오싹함이 느껴졌다. 왜냐하면 그가 몇 년 동안 내 블로그를 열심히 읽고 있었다는 것을 알고 있었기 때문이다. 몇 년 동안! 그리고 나는 보통 그저 내 이중 인생에 관해 아무것도 모르는 무술에서 만나는 바보들의 성적 유혹과 데이트 제의를 무시하곤 했다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 여기 있을 때 그는 내 마음을 자극하고, 왜 그가 일찍이 연락을 한 때 나에게 더 빨리 손을 내밀지 않았는지 궁금하게 만들고 있습니다. 몇 년 전에 그가 처음 연락했을 때 응답했다면 어떠했을까요? 그러나 그 시절에는 준비가 되지 않았습니다. 제가 박사과정 첫 해에 있었고, 뇌졸중 회복 중이었으며, Peter가 남긴 상처를 극복하고 있었습니다. 그것은 복합적인 외상의 시기였습니다.\n\n그렇다면 여성과 남성, 그들이 어떻게 흥분되는지와 어떤 관련이 있을까요? 여성은 일반적으로 남성에 비해 정서적 관련에서 흥분하는 경향이 더 있습니다. 남성은 주로 신체적 자극에 더 많이 반응할 수 있지만, 여성은 정서적 연결과 강도를 통해 흥분하는 경향이 있습니다.\n\n여성은 감정적인 강도에 끌리는데, 그것이 전체 경험을 높여주기 때문입니다. 신체적 쾌락뿐만 아니라, 원하는 대로 느껴지고 소중하게 여기며, 더 깊은 수준에서 이해받는 경험에 관련이 있습니다. 남성이 감정을 섬세하게 성적 애착으로 연결할 수 있을 때, 그는 단순한 신체성을 초월하는 강력한 연결을 만들어냅니다.\n\nNLP(신경 언어 프로그래밍)를 사용하여 이러한 감정적 강도를 만들려면, 이 단계를 따르세요 (기본으로 돌아가 보겠습니다):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 소통을 조절해요\n\n그녀의 몸짓, 목소리 톤, 말의 속도를 반영하여 깊은 연결을 형성하세요. 이렇게 하면 그녀가 이해받고 편안해 집니다.\n\n- 앵커링 활용\n\n일부 접촉, 말, 또는 제스처를 긍정적인 감정과 흥분과 연관짓습니다. 예를 들어, 센슈얼한 말을 속삭이는 동안 부드럽게 그녀의 손목에 손을 대어 접촉과 그녀의 흥분 사이에 강한 연결을 만들어 보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 감각을 자극하는 표현 사용\n\n흥분을 증폭시키는 상황을 묘사하는 데 생동감과 감각이 풍부한 언어를 사용하세요. 그녀의 피부가 느껴지는 방법, 숨을 가쁘게 하게 되는 것, 그녀의 몸이 어떻게 반응하는지 이야기해 보세요.\n\n4. 절제와 리딩\n\n그녀의 감정 상태에 맞추어 시작한 후 서서히 그녀를 흥분하고 강렬한 상태로 이끌어보세요. 스토리텔링, 판타지 묘사 또는 자신의 욕망을 공유하는 것으로도 가능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 언어 패턴 활용하기\n\n임베디드 명령, 비유, 이중 굴레와 같은 최면적인 언어 패턴을 사용하여 그녀의 생각과 감정을 이끌어보세요. 예를 들어, \"당신이 편안해질수록, 더욱 흥분하고 있는 자신을 발견할 수도 있습니다.\"\n\n6. 기대감 조성하기\n\n조금씩 강도를 높이며 만지작거리고 긴장감을 쌓아가며 기대감을 조성하세요. 그녀가 더 바라게 만들어 강력한 감정적, 신체적 반응을 일으키게 하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 기술을 숙달함으로써 여러분은 그녀를 매혹시키고 격렬한 감정의 매듭을 만들어 흥분시키며, 잊지 못할 만족스러운 경험을 창출할 수 있습니다.\n\n저희는 다가오는 60일간의 NLP 훈련에서 이 기본적인 방법들을 가르치는 것에 열정적입니다. 여러분이 함께해 주시기를 강력하게 추천드리며, 저희는 이를 접근하기 쉽게 슬라이딩 스케일로 제공하고 있습니다.\n\n제 소개를 조금 드리자면, 저는 Robert Dilts 밑에서의 NLP 트레이너 자격증을 소지하고 있으며, 제 마스터 프랙티셔너 및 프랙티셔너 자격증은 NLPCA(팀 할볼름과 로버트 해리슨에 의해 양성된)에서 받았습니다. 저는 2003년부터 NLP를 실천해 오고 있습니다. 저의 최면 자격증은 National Guild를 통해 받았으며, 저의 박사 학위는 아리조나 대학과 프레스코트 대학에 인정받았습니다.\n\n거기에 더하여, 저는 kink 씬에서 20년 이상의 경험을 갖고 있습니다. 여러분이 저희와 함께 훈련할 수 있는 이 기회를 강력하게 추천드립니다.\n","ogImage":{"url":"/assets/img/2024-05-27-TheVeryFoundationofSex_0.png"},"coverImage":"/assets/img/2024-05-27-TheVeryFoundationofSex_0.png","tag":["Tech"],"readingTime":3},{"title":"대용량 데이터셋 특성 선택을 혁신하는 강화 학습","description":"","date":"2024-05-27 15:05","slug":"2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning","content":"\n## 아주 큰 데이터셋을 다룰 때 특성 선택에 강화 학습의 힘을 활용해 보세요\n\n기계 학습 모델에 대한 특성 선택을 변화시키는 강화 학습의 힘을 경험해보세요. 실용적인 예시와 전용 Python 라이브러리를 활용하여 이 혁신적인 접근 방식의 과정, 구현, 그리고 혜택에 대해 알아보세요.\n\n[이미지](/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_0.png)\n\n특성 선택은 기계 학습 모델을 구축하는 과정에서 결정적인 단계입니다. 모델에 좋은 특성을 선택하면 원하는 작업에 대한 결과를 향상시킬 수 있습니다. 실제로 특성은 노이즈를 추가하여 모델을 방해할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기능을 선택하는 것은 특히 고차원 데이터 세트를 다룰 때 더 중요합니다. 이는 모델이 더 빨리 그리고 더 잘 배울 수 있게 합니다. 그 아이디어는 최적의 기능 수와 가장 의미 있는 것들을 찾는 데 있습니다.\n\n이 글에서는 이 문제를 다루고 새롭게 구현된 기능 선택 방법을 소개할 것입니다. 다양한 기능 선택 프로세스가 있지만 이미 다뤄진 글들이 많기 때문에 여기서 소개하지 않겠습니다. 저는 강화 학습 전략을 사용한 기능 선택에 초점을 맞출 것입니다.\n\n먼저, 강화 학습과 특히 Markov Decision Process에 대해 다룰 것입니다. 이는 데이터 과학 분야에서 매우 새로운 접근법이며 특히 기능 선택 목적으로 사용됩니다. 그 다음으로, 이를 구현하고 파이썬 라이브러리(FSRLearning)를 설치하고 사용하는 방법을 소개할 것입니다. 마지막으로, 이 구현의 효율성을 검증할 것입니다. 래퍼나 필터링과 같은 가능한 기능 선택 접근법 중에서, 강화 학습이 가장 강력하고 효율적입니다.\n\n이 글의 목표는 구체적이고 실제 문제를 위한 구현에 중점을 두는 것입니다. 이 문제의 이론적 측면은 예제를 통해 간단히 설명되지만 참고 자료가 끝에 제공될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 강화 학습: 특성 선택을 위한 마르코프 의사 결정 문제\n\n강화 학습 (RL) 기법이 게임 해결과 같은 문제에 매우 효율적일 수 있다는 것이 입증되었습니다. RL의 개념은 마르코프 의사 결정 과정 (MDP)에 기반을 두고 있습니다. 여기서 중요한 것은 MDP를 깊이 이해하는 것이 아니라 그 작동 방식과 어떻게 우리 문제에 유용할지에 대한 일반적인 개념을 이해하는 것입니다.\n\nRL 뒤에 숨겨진 단순한 아이디어는 에이전트가 알 수 없는 환경에서 시작한다는 것입니다. 이 에이전트는 작업을 완료하기 위해 조치를 취해야 합니다. 에이전트의 현재 상태 및 이전에 선택한 조치에 따라, 에이전트는 일부 조치를 선택하기 쉬울 것입니다. 도달한 각 새로운 상태와 취한 조치에 대해, 에이전트는 보상을 받게 됩니다. 그래서 여기 특성 선택을 위해 정의해야 할 주요 파라미터들이 있습니다:\n\n- 상태란 무엇인가요?\n- 조치란 무엇인가요?\n- 보상은 무엇인가요?\n- 어떻게 조치를 선택하나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫째, 상태는 데이터 세트에 존재하는 기능들 중의 하위 집합에 불과합니다. 예를 들어, 데이터 세트에 세 가지 기능 (나이, 성별, 키)와 하나의 레이블이 있다면, 가능한 상태는 다음과 같습니다:\n\n```js\n[]                                              --\u003e 빈 집합\n[나이], [성별], [키]                             --\u003e 1개 기능 집합\n[나이, 성별], [성별, 키], [나이, 키]             --\u003e 2개 기능 집합\n[나이, 성별, 키]                                --\u003e 모든 기능 집합\n```\n\n상태에서는 기능의 순서가 중요하지 않으며, 이를 뒤쪽에서 조금 더 설명하겠습니다. 우리는 이를 세트로 간주하고 특징들의 목록으로 간주해서는 안 됩니다.\n\n행동에 대해서는, 하위 집합으로부터 현재 상태보다 한 가지 미탐색 기능이 더 추가된 다른 하위 집합으로 이동할 수 있습니다. 기능 선택 문제에서, 한 행동은 현재 상태에서 이미 탐색되지 않은 기능을 선택하고 다음 상태에 추가하는 것입니다. 여기에 가능한 행동의 예시가 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n[나이] -\u003e [나이, 성별]\n[성별, 키] -\u003e [나이, 성별, 키]\n\n\n이제 불가능한 행동의 예를 살펴봅시다:\n\n\n[나이] -\u003e [나이, 성별, 키]\n[나이, 성별] -\u003e [나이]\n[성별] -\u003e [성별, 성별]\n\n\n우리는 상태와 행동을 정의했지만 보상은 정의하지 않았습니다. 보상은 상태의 품질을 평가하는 데 사용되는 실수입니다. 예를 들어 로봇이 미로의 출구에 도달하려고 노력하고 다음 행동으로 출구로 가기로 결정한다면, 이 행동에 대한 보상은 \"좋음\"이 될 것입니다. 만일 함정으로 가기로 다음 행동을 선택하면 보상은 \"나쁨\"이 될 것입니다. 보상은 이전 조치에 대한 정보를 제공하는 값입니다.\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기능 선택 문제에서 흥미로운 보상은 새로운 기능을 추가함으로써 모델에 추가되는 정확도 값일 수 있습니다. 다음은 보상이 계산되는 방법의 예시입니다:\n\n```js\n[나이] --\u003e 정확도 = 0.65\n[나이, 성별] --\u003e 정확도 = 0.76\n보상(성별) = 0.76 - 0.65 = 0.11\n```\n\n첫 방문한 각 상태마다 분류기가 해당 기능 집합으로 훈련됩니다. 이 값은 상태에 저장되며 분류기의 훈련은 상태가 나중에 다시 방문되더라도 한 번만 발생합니다. 분류기는 기능의 순서를 고려하지 않습니다. 이것이 우리가 이 문제를 트리가 아닌 그래프로 볼 수 있는 이유입니다. 이 예시에서 모델에 새로운 기능으로 성별 선택 작업의 보상은 현재 상태와 다음 상태의 정확도 차이입니다.\n\n\u003cimg src=\"/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 그래픽에서 각 기능이 숫자에 매핑되었습니다 (예: \"나이\"는 1, \"성별\"은 2이고 \"키\"는 3입니다). 최적의 세트를 찾기 위해 다른 메트릭을 사용하는 것이 완전히 가능합니다. 많은 비즈니스 응용 프로그램에서 정확도보다 재현율이 더 중요하게 여겨집니다.\n\n다음 중요한 질문은 현재 상태에서 다음 상태를 선택하는 방법이거나 환경을 어떻게 탐사하는지입니다. 매우 복잡한 문제가 될 수 있기 때문에 가장 최적의 방법을 찾아야 합니다. 실제로, 문제에서 10개의 기능이 있는 경우 모든 가능한 기능 세트를 단순히 탐색하면 상태의 수가\n\n```js\n10! + 2 = 3,628,802개의 가능한 상태\n```\n\n입니다.\n\n+2는 빈 상태와 모든 가능한 기능을 포함하는 상태를 고려했기 때문입니다. 이 문제에서는 정확도를 극대화하는 기능 세트를 얻기 위해 모든 상태에서 동일한 모델을 교육해야 할 것입니다. 강화 학습 접근 방식에서는 모든 상태를 방문할 필요가 없고 이미 방문한 상태로 이동할 때마다 모델을 교육할 필요가 없을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 문제에 대한 몇 가지 중지 조건을 결정해야 했고, 이를 나중에 자세히 설명할 것입니다. 현재 epsilon-탐욕 상태 선택이 선택되었습니다. 이것은 현재 상태에서 epsilon(0과 1 사이, 주로 0.2 정도)의 확률로 다음 동작을 무작위로 선택하고, 그렇지 않은 경우에는 함수를 최대화하는 동작을 선택하는 아이디어입니다. 특징 선택에 대한 함수는 각 특징이 모델의 정확도에 기여한 보상의 평균입니다.\n\nEpsilon-탐욕 알고리즘에는 두 단계가 포함됩니다:\n\n- 무작위 단계: epsilon의 확률로, 현재 상태의 가능한 이웃 중에서 다음 상태를 무작위로 선택합니다 (균일하게 또는 소프트맥스 선택이라고 상상할 수 있음)\n- 탐욕 단계: 현재 상태에 추가된 기능이 모델의 정확도에 대한 최대 기여를 갖도록 다음 상태를 선택합니다. 시간 복잡성을 줄이기 위해, 각 특징에 대한 이러한 값을 포함하는 목록을 초기화했습니다. 이 목록은 특징이 선택될 때마다 업데이트됩니다. 업데이트는 다음 공식 덕분에 매우 최적화되었습니다:\n\n\n\u003cimg src=\"/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_2.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- AORf: 기능 \"f\"가 가져온 보상의 평균\n- k: \"f\"가 선택된 횟수\n- V(F): 특징 집합 F의 상태 값 (이 기사에서는 상세히 설명되지 않음)\n\n전체 아이디어는 어떤 기능이 모델에 가장 높은 정확도를 제공했는지 찾는 것입니다. 이것이 바로 우리가 여러 다른 환경에서 여러 상태를 검토하여 모델에 대한 가장 전반적인 정확도 값을 평가해야 하는 이유입니다.\n\n마지막으로 두 가지 중지 조건을 설명하겠습니다. 알고리즘이 방문하는 상태의 수를 최소화하는 것이 목표이기 때문에 이를 주의 깊게 살펴봐야 합니다. 방문한 상태가 적을수록 서로 다른 기능 집합으로 학습해야 할 모델의 양이 줄어듭니다. 정확도를 얻기 위해 모델을 학습하는 것은 시간과 계산 능력면에서 가장 비용이 많이 드는 단계입니다.\n\n- 알고리즘은 모든 기능을 포함하는 집합인 최종 상태에서 반드시 중지됩니다. 이 상태에 도달하는 것을 피하기 위해 모델을 학습하는 데 가장 비용이 많이든다.\n- 또한, 연속적으로 값이 감소하는 방문된 상태들의 시퀀스가 발생하면 그래프를 조회하는 것을 중지합니다. 데이터 세트의 총 기능 수의 제곱근 이후에는 계속 탐색을 중단하는 임계값이 설정되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문제의 모델링이 설명되었으므로, 이제 파이썬에서의 구현에 대해 자세히 설명하겠습니다.\n\n## 강화 학습을 사용한 특성 선택을 위한 파이썬 라이브러리\n\n이 문제를 해결하는 파이썬 라이브러리가 있습니다. 이 부분에서 그 동작 방식을 설명하고 그것이 효율적인 전략임을 입증하겠습니다. 또한, 이 문서는 설명서로 작용하여 해당 부분이 끝나면 이 라이브러리를 여러분의 프로젝트에 사용할 수 있을 것입니다.\n\n## 1. 데이터 전처리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n방문한 상태의 정확도를 평가해야 하기 때문에, 해당 기능 및 이 기능 선택 작업에 사용된 데이터를 모델에 제공해야 합니다. 데이터는 정규화되어야 하며 범주형 변수는 인코딩되어야 하며 가능한 적은 행을 가지고 있어야 합니다 (행이 적을수록 알고리즘은 더 빠릅니다). 또한, 기능과 일부 정수 사이의 매핑을 생성하는 것이 매우 중요합니다. 이 단계는 필수는 아니지만 매우 권장됩니다. 이 단계의 최종 결과는 예측할 수 있는 라벨과 함께 모든 기능이 포함된 DataFrame을 얻는 것입니다. 아래는 기준으로 사용된 데이터셋 예시입니다 (UCI Irvine Machine Learning Repository에서 확인할 수 있습니다).\n\n## 2. FSRLearning 라이브러리 설치 및 가져오기\n\n두 번째 단계는 라이브러리를 pip을 사용하여 설치하는 것입니다. 여기에 설치 명령어가 있습니다:\n\n```js\npip install FSRLearning\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이브러리를 가져오려면 아래 코드를 사용합니다:\n\n단순히 Feature_Selector_RL 객체를 만들어서 기능 선택기를 만들 수 있을 겁니다. 몇 가지 매개변수를 채워야 합니다.\n\n- feature_number (정수): DataFrame X에 있는 피처 수\n- feature_structure (사전): 그래프 구현을 위한 사전\n- eps (부동 소수 [0; 1]): 무작위 다음 상태를 선택할 확률, 0은 오직 탐욕 알고리즘이고 1은 오직 무작위입니다.\n- alpha (부동 소수 [0; 1]): 업데이트 속도를 제어합니다, 0은 거의 업데이트하지 않는 상태이고 1은 매우 업데이트됩니다.\n- gamma (부동 소수 (0, 1]): 다음 상태의 관찰을 조절하는 요소, 0은 근시적인 상태이고 1은 장기적인 행동을 나타냅니다.\n- nb_iter (정수): 그래프를 통해 이동할 수열의 수\n- starting_state (\"empty\" 또는 \"random\"): \"empty\"인 경우 알고리즘은 빈 상태에서 시작하고, \"random\"인 경우 그래프의 무작위 상태에서 시작합니다.\n\n모든 매개변수가 튜닝될 수 있지만 대부분의 문제에 대해 일부 이터레이션만으로 충분합니다 (대략 100회) 그리고 epsilon 값이 0.2 정도면 충분합니다. 시작 상태는 그래프를 효율적으로 더 탐색하는 데 유용하지만 데이터셋에 매우 의존적일 수 있고 두 값 모두 테스트할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마침내 다음 코드로 선택기를 매우 간단하게 초기화할 수 있습니다.\n\n알고리즘을 훈련하는 것은 대부분의 머신 러닝 라이브러리와 동일한 기초에 따라 매우 쉽습니다.\n\n다음은 출력 예시입니다:\n\n\n![Output Example](/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 5-튜플 출력입니다:\n\n- 데이터프레임 X 내 특성의 인덱스(마치 맵핑처럼)\n- 특성이 관측된 횟수\n- 반복이 끝난 후 특성에 의해 가져온 보상의 평균\n- 특성의 중요도를 가장 적은 것부터 가장 중요한 것까지 순위로 나타낸 것(여기서 2는 가장 적은 중요도이고 7은 가장 중요한 특성입니다)\n- 전역적으로 방문된 상태의 수\n\n이 선택기의 또 다른 중요한 방법은 Scikit-Learn의 RFE 선택기와 비교하는 것입니다. X, y 및 선택기의 결과를 입력으로 사용합니다.\n\n선택 과정마다 RFE와 FSRLearning의 전역 측정 지표를 출력합니다. 또한 모델의 정확도에 대한 시각적 비교를 출력합니다. x축에는 선택된 특성 수가 있고 y축에는 정확도가 있습니다. 두 개의 수평 선은 각 방법의 정확도 중앙값입니다. 다음은 예시입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n평균 기준 정확도: 0.854251012145749, 강화학습 정확도: 0.8674089068825909\n중간 기준 정확도: 0.8552631578947368, 강화학습 정확도: 0.868421052631579\nRFE보다 더 좋은 메트릭을 가진 변수 세트를 얻을 확률: 1.0\n두 곡선 사이의 면적: 0.17105263157894512\n```\n\n이 예시에서는 강화학습 방법이 항상 RFE보다 모델을 위한 더 좋은 특성 집합을 제공했습니다. 따라서 우리는 정렬된 특성 집합 중에서 확실히 선택할 수 있으며, 그것은 모델에 더 높은 정확도를 제공할 것입니다. 여러 번 모델과 비교자를 실행하여 매우 정확한 평가를 얻을 수 있지만 강화학습 방법이 항상 더 좋습니다.\n\n또 다른 흥미로운 방법은 get_plot_ratio_exploration입니다. 이는 지정된 이터레이션에 대해 이미 방문한 노드 수와 순서대로 방문한 노드 수를 비교하는 그래프를 그립니다.\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\n![그림1](/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_5.png)\n\n또한, 두 번째 중지 조건 덕분에 알고리즘의 시간 복잡도가 지수적으로 감소합니다. 따라서 기능의 수가 많더라도 수렴이 빨리 이루어질 것입니다. 아래 그림은 특정 크기의 집합이 방문된 횟수를 나타냅니다.\n\n![그림2](/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_6.png)\n\n모든 반복에서 알고리즘이 6개 이하의 변수를 포함하는 상태를 방문했습니다. 6개 이상의 변수를 넘어가면 도달한 상태의 수가 줄어드는 것을 볼 수 있습니다. 이는 작은 기능 집합으로 모델을 훈련하는 것이 큰 기능 집합보다 빠르기 때문에 좋은 동작입니다.\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론 및 참고 자료\n\n전반적으로 RL 방법은 모델의 지표를 극대화하는 데 매우 효율적임을 알 수 있습니다. 항상 흥미로운 특성 하위 집합으로 빠르게 수렴합니다. 또한 FSRLearning 라이브러리를 사용하면 ML 프로젝트에서 이 방법을 매우 쉽고 빠르게 구현할 수 있습니다.\n\n프로젝트의 Github 저장소와 완벽한 문서는 여기에서 확인할 수 있습니다.\n\n문의 사항이 있으시면 직접 링크드인에서 연락하실 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 라이브러리는 다음 두 논문을 참고하여 구현되었습니다:\n\n- Sali Rasoul, Sodiq Adewole, 및 Alphonse Akakpo, FEATURE SELECTION USING REINFORCEMENT LEARNING (2021), ArXiv\n- Seyed Mehdin Hazrati Fard, Ali Hamzeh, 및 Sattar Hashemi, Using reinforcement  learning to find an optimal set of features (2013), ScienceDirect\n\n","ogImage":{"url":"/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_0.png"},"coverImage":"/assets/img/2024-05-27-RevolutionizingLargeDatasetFeatureSelectionwithReinforcementLearning_0.png","tag":["Tech"],"readingTime":9},{"title":"이해할 수 있는 이상 탐지 Frequent Patterns Outlier Factor FPOF","description":"","date":"2024-05-27 15:02","slug":"2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF","content":"\n## 범주형 데이터를 지원하며 이상치를 감지하고, 이상치에 대한 설명을 제공하는 감지 방법\n\n이상치 탐지는 기계 학습에서 흔한 작업입니다. 구체적으로, 이는 지도 레이블이 없는 데이터를 분석하는 비지도학습의 한 형태입니다. 데이터 집합에서 다른 항목에 비해 이례적인 항목을 찾는 작업입니다.\n\n데이터에서 이상치를 식별하려는 이유는 여러 가지가 있을 수 있습니다. 분석 중인 데이터가 회계 기록이고 오류 또는 사기를 찾고자 한다면, 데이터에는 수동으로 각 거래를 검토하기에는 너무 많은 거래가 포함되어 있어서 소수의 거래를 조사해야 합니다. 가장 이상한 레코드를 찾아 이를 조사하는 것이 좋은 시작점일 수 있습니다. 이는 오류와 사기가 모두 드물어서 이상치로 드러날 것이라는 생각으로 이루어진 것입니다.\n\n다시 말하지만, 모든 이상치가 흥미로운 것은 아니지만, 오류와 사기는 아마도 이상치가 될 가능성이 있으므로 이를 찾을 때 이상치를 식별하는 것은 매우 실용적인 기술일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또는 데이터에는 신용 카드 거래, 센서 읽기, 기상 측정, 생물학적 데이터 또는 웹 사이트 로그가 포함될 수 있습니다. 모든 경우에, 오류나 다른 문제를 시사하는 레코드를 식별하는 것이 유용할 수 있으며, 가장 흥미로운 레코드를 찾는 것도 도움이 될 수 있습니다.\n\n또한 이상값 탐지는 비즈니스나 과학적 발견의 일부로 사용되어 데이터와 데이터에 설명된 프로세스를 더 잘 이해하는 데 도움이 될 수 있습니다. 과학적 데이터의 경우, 가장 이례적인 레코드를 찾는 것이 종종 가장 과학적으로 흥미로울 수 있습니다.\n\n## 이상값 탐지에서 해석 가능성의 필요성\n\n분류 및 회귀 문제의 경우 해석 가능한 모델을 사용하는 것이 종종 바람직합니다. 이는 정확도가 낮아질 수 있지만(탭화면 데이터의 경우 가장 높은 정확도는 일반적으로 해석하기 어려운 부스트 모델에서 얻어집니다), 안전성이 높아집니다. 우리는 모델이 보지 못한 데이터를 어떻게 다루게 될지 알고 있습니다. 그러나 분류 및 회귀 문제의 경우에는 개별 예측이 이루어지는 이유를 이해할 필요가 없는 경우도 흔합니다. 모델이 상당히 정확하다면, 모델이 예측을 만들도록만 하는 것만으로 충분할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이상치 탐지를 수행하면 해석 가능성이 훨씬 더 높아집니다. 이상치 탐지기가 레코드를 매우 이상하다고 예측하는 경우, 왜 이렇게 예측되었는지 명확하지 않으면 해당 항목을 처리하는 방법을 알 수 없을 수도 있고, 그것이 이상할 수도 있는지 여부조차 알 수 없습니다.\n\n사실, 상황에 따라 이상치 탐지를 수행해도, 왜 이상치로 표시된 항목이 표시되었는지를 잘 이해하지 못하면 그 가치가 제한될 수 있습니다. 신용 카드 거래 데이터 세트를 확인하는 경우 이상치 탐지 루틴이 매우 이례적인 것으로 보이는 일련의 구매를 식별하고, 따라서 의심스럽다고 식별할 경우, 이것들을 효과적으로 조사할 수 있는 방법은 무엇인지 알고 있어야만 합니다. 경우에 따라 이것이 명백하거나, 시간을 들여 조사한 후에 분명해질 수도 있지만, 발견된 시점에서 이상 점의 특성이 명확하다면 훨씬 효율적입니다.\n\n분류 및 회귀와 마찬가지로 해석 가능성이 불가능한 경우, 사후 해설이라고 하는 것을 사용하여 예측을 이해하려는 시도를 하는 것이 종종 가능합니다. Feature importances, proxy models, ALE plots 등을 사용하는 XAI(Explainable AI) 기법을 사용합니다. 이들은 아주 유용하며 앞으로의 기사에서도 다룰 것입니다. 그러나, 처음부터 결과가 명확한 것의 장점도 아주 큽니다.\n\n이 기사에서는 특히 표 형식의 데이터에 초점을 맞추지만, 이후의 기사에서 다른 형식을 살펴볼 것입니다. 오늘날 흔히 사용되는 탭 데이터를위한 이상치 검출 알고리즘 중에는 Isolation Forests, Local Outlier Factor (LOF), KNNs, One-Class SVM 등 여러 가지가 있습니다. 이들은 종종 매우 잘 작동하지만, 불행히도 대부분의 경우 이상치를 찾은 이유에 대한 설명을 제공하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대부분의 이상치 탐지 방법은 알고리즘 수준에서 이해하기 쉽지만, 그래도 어떤 레코드가 탐지기에 의해 높은 점수를 받았고 다른 레코드가 그렇지 않았는지를 결정하는 것은 어렵습니다. 예를 들어 금융 거래 데이터 세트를 Isolation Forest와 같은 방법으로 처리하면 가장 이롭은 레코드를 볼 수 있지만, 특히 테이블에 많은 특성이 있는 경우, 이상치가 드문 조합의 다중 특성을 포함하거나 이상치가 특성이 높지만 다중 특성이 다소 이상한 경우에는 왜 그런지 이해하는 것이 어려울 수 있습니다.\n\n## FPOF(Frequent Patterns Outlier Factor)\n\n지금은 최소한 빠르게라도 이상치 탐지와 해석에 대해 살펴보았습니다. 이 기사의 나머지는 저의 책인 파이썬에서의 이상치 탐지(https://www.manning.com/books/outlier-detection-in-python)에서 다루는 FPOF에 대한 발췌문입니다.\n\nFPOF(FP-outlier: Frequent pattern based outlier detection)은 이상치 탐지에 어느 정도의 해석 가능성을 제공할 수 있는 소수의 탐지기 중 하나이며, 이상치 탐지에서 더 많이 사용되어야 할 가치가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n카테고리 데이터와 함께 작동하도록 설계된 매력적인 속성을 갖고 있습니다. 대부분의 현실 세계의 표 데이터는 숫자 및 범주형 열을 모두 포함하는 혼합된 형태입니다. 그러나 대부분의 검출기는 모든 열이 숫자인 것으로 가정하며, 모든 범주형 열을 숫자로 인코딩해야 합니다(원핫, 서수 또는 다른 인코딩을 사용하여).\n\nFPOF와 같은 검출기가 데이터가 범주형이라고 가정하는 경우, 우리는 반대의 문제를 겪습니다: 모든 숫자 특성은 범주형 형식으로 변환되어야 합니다. 둘 중 어느 것이라도 사용 가능하지만, 데이터가 주로 범주형인 경우 FPOF와 같은 검출기를 사용할 수 있는 것이 편리합니다.\n\n그리고 이상 탐지를 수행할 때 일부 숫자 검출기와 일부 범주형 검출기를 함께 사용할 때 혜택이 있습니다. 불행히도, 비교적 적은 수의 범주형 검출기가 있기 때문에 FPOF는 이런 면에서도 유용하며, 해석력이 필요하지 않은 경우에도 유용합니다.\n\n## FPOF 알고리즘\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nFPOF는 테이블에서 빈발 아이템 세트(Frequent Item Sets, FISs)를 식별하여 작동합니다. 이것들은 하나의 특성에서 매우 흔한 값이거나 함께 자주 나타나는 여러 열에 걸친 값의 세트일 수 있습니다.\n\n거의 모든 테이블에는 상당수의 FIS가 포함되어 있습니다. 단일 값에 기초한 FIS는 한 열의 일부 값이 다른 값보다 매우 흔하기 때문에 항상 발생하며, 이는 거의 항상 사실입니다. 그리고 여러 열에 걸친 FIS는 열 사이에 연관성이 있을 때 발생합니다: 특정 값(또는 숫자 값의 범위)이 다른 열에서 다른 값(또는 다시 말해 숫자 값의 범위)과 연관이 있을 때 발생합니다.\n\nFPOF는 데이터셋에 많은 빈발 아이템 세트를 포함하고 있다는 아이디어에 기반을 두고 있습니다(거의 모든 데이터셋이 해당됩니다). 그러므로 대부분의 행에는 여러 빈발 아이템 세트가 포함되며, 정상 레코드에는 이상 값(이상치) 행보다 훨씬 더 빈발한 아이템 세트가 포함됩니다. 이를 활용하여 대부분의 행보다 훨씬 적고 훨씬 덜 빈발한 FIS를 포함하는 행을 이상치로 식별할 수 있습니다.\n\n## 실제 데이터 예시\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실제로 FPOF를 사용하는 실제 예제를 살펴보면 OpenML의 SpeedDating 세트를 살펴봅니다 (https://www.openml.org/search?type=data\u0026sort=nr_of_likes\u0026status=active\u0026id=40536, CC BY 4.0 DEED 라이선스).\n\nFPOF를 실행하는 것은 먼저 데이터 집합에서 FIS를 채굴하는 것으로 시작합니다. 이를 지원하기 위해 Python에서 사용할 수 있는 여러 라이브러리가 있습니다. 이 예제에서는 머신러닝을 위한 범용 라이브러리 인 mlxtend (https://rasbt.github.io/mlxtend/)를 사용합니다. 빈발 항목 집합을 식별하는 여러 알고리즘을 제공하며, 여기서는 apriori라는 알고리즘을 사용합니다.\n\n먼저 OpenML에서 데이터를 수집합니다. 보통 범주형 및 (binned) 숫자형 특성을 모두 사용할 것이지만, 여기서는 간단하게 일부 특성만 사용할 것입니다.\n\n언급했듯이 FPOF는 숫자형 특성의 binning을 필요로 합니다. 일반적으로 각 숫자 열에 대해 작은 수의 (5에서 20개 정도) 폭이 동일한 bin을 사용합니다. 이를 위해 pandas의 cut() 메서드가 편리합니다. 이 예제는 더 간단합니다. 여기서는 범주형 열만 다룹니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom mlxtend.frequent_patterns import apriori\nimport pandas as pd\nfrom sklearn.datasets import fetch_openml\nimport warnings\n\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)\n\ndata = fetch_openml('SpeedDating', version=1, parser='auto')\ndata_df = pd.DataFrame(data.data, columns=data.feature_names)\n\ndata_df = data_df[['d_pref_o_attractive', 'd_pref_o_sincere',\n                   'd_pref_o_intelligence', 'd_pref_o_funny',\n                   'd_pref_o_ambitious', 'd_pref_o_shared_interests']]\ndata_df = pd.get_dummies(data_df)\nfor col_name in data_df.columns:\n    data_df[col_name] = data_df[col_name].map({0: False, 1: True})\n\nfrequent_itemsets = apriori(data_df, min_support=0.3, use_colnames=True)\n\ndata_df['FPOF_Score'] = 0\n\nfor fis_idx in frequent_itemsets.index:\n    fis = frequent_itemsets.loc[fis_idx, 'itemsets']\n    support = frequent_itemsets.loc[fis_idx, 'support']\n    col_list = (list(fis))\n    cond = True\n    for col_name in col_list:\n        cond = cond \u0026 (data_df[col_name])\n\n    data_df.loc[data_df[cond].index, 'FPOF_Score'] += support\n\nmin_score = data_df['FPOF_Score'].min()\nmax_score = data_df['FPOF_Score'].max()\ndata_df['FPOF_Score'] = [(max_score - x) / (max_score - min_score)\n                         for x in data_df['FPOF_Score']]\n```\n\n아프리오리 알고리즘은 모든 기능이 원-핫 인코딩되어 있어야합니다. 이를 위해 판다의 get_dummies() 메서드를 사용합니다.\n\n그런 다음 apriori 메서드를 호출하여 빈번한 항목 집합을 결정합니다. 이를 수행하기 위해 FIS가 나타나는 행의 최소 분수 인 최소 지원을 지정해야합니다. 이 값을 너무 높게 설정하면 강한 이상값도 FIS를 포함 시키지 않으며 FIS가 적게 포함 된 레코드를 어렵게 구별하게됩니다. 그리고 이 값을 너무 낮게 설정하면 FIS가 의미없을 수 있으며 이상값도 이니셜과 동일한 수의 FIS를 포함 할 수 있습니다. 낮은 최소 지원으로 apriori를 사용하면 매우 많은 수의 FIS를 생성 할 수 있으며 실행 속도가 느려지고 해석 가능성이 낮아질 수 있습니다. 이 예에서는 0.3을 사용합니다.\n\nFIS의 크기에 제한을 둘 수도 있고 때로는 그렇게합니다. 최소 및 최대 열 수 사이에 관련되도록 요구하는 여러 항목 집합의 크기에 제한을 둘 수 있으며 가장 관심 있는 이상값의 형태를 좁히는 데 도움이 될 수 있습니다.\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빈도가 높은 항목 집합은 지원과 열 값을 나타내는 팬더 데이터프레임에서 반환됩니다. 이 값은 원-핫 인코딩된 열 형식으로 표시되며 원본 열과 값을 나타냅니다.\n\n결과를 해석하기 위해 먼저 자주 등장하는 항목 집합(frequent_itemsets)을 확인할 수 있습니다. 각 FIS의 길이를 포함하려면:\n\n```js\nfrequent_itemsets['length'] = \\\n    frequent_itemsets['itemsets'].apply(lambda x: len(x))\n```\n\n총 24개의 FIS가 발견되었으며, 가장 긴 것은 세 가지 특징을 포함하고 있습니다. 다음 표는 지원에 따라 정렬된 처음 열 개의 행을 표시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF_0.png)\n\n그런 다음 각 빈번한 항목 집합을 루프하고 지원하는 빈번한 항목 집합을 포함하는 각 행에 대해 점수를 증가시킵니다. 이는 선택적으로 길이가 더 큰 빈번한 항목 집합을 선호하도록 조정할 수 있습니다(예를 들어, 지원이 0.4이고 5개 열을 포함하는 FIS는, 그 외의 조건이 동일한 경우, 2개 열을 포함하는 지원이 0.4인 FIS보다 관련성이 더 높습니다), 하지만 여기서는 각 행의 FIS 수 및 지원을 간단히 사용합니다.\n\n실제로 이것은 정상성에 대한 점수를 생성하고 이상값이 아닙니다. 따라서 점수를 0.0과 1.0 사이로 정규화할 때 순서를 뒤집습니다. 이제 가장 높은 점수를 가진 행이 가장 강한 이상값입니다: 가장 적고 가장 일반적인 빈번한 항목 집합을 가진 행입니다.\n\n원래 데이터프레임에 점수 열을 추가하고 점수별로 정렬하면 가장 정상적인 행을 확인할 수 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF_1.png)\n\n이 행의 값들이 FISs와 잘 일치하는 것을 볼 수 있습니다. d_pref_o_attractive의 값은 [21-100]이며 이는 FIS(지원 0.36)와 일치합니다. d_pref_o_ambitious와 d_pref_o_shared_interests의 값은 각각 [0-15]로, 이 또한 FIS(지원 0.59)와 일치합니다. 다른 값들도 대부분 FIS들과 일치합니다.\n\n가장 이상한 행은 다음과 같이 표시됩니다. 이는 식별된 FIS들과 일치하지 않습니다.\n\n![이미지](/assets/img/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF_2.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자주 나오는 항목 집합 자체가 꽤 이해하기 쉬우므로,이 방법은 상당히 해석 가능한 결과를 얻는 장점이 있습니다. 다만, 자주 나오는 항목 집합이 많이 사용되는 경우에는 이러한 장점이 적을 수 있습니다.\n\n![image](/assets/img/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF_3.png)\n\n해석력은 향상될 수 있지만, 이상치는 \"포함하지 않는다\"는 방식으로 식별되기 때문에, 각 이상치의 점수를 설명하는 것은 해당 이상치에 포함되지 않는 모든 항목 집합을 나열하는 것을 의미합니다. 그러나 각 이상치를 설명하기 위해 모든 누락된 항목 집합을 나열하는 것이 반드시 필요한 것은 아닙니다. 누락된 가장 일반적인 항목 집합을 나열하는 것은 대부분의 목적에 충분할 것입니다. 행에 나타나는 항목 집합과 있는 항목 집합의 통계와 빈도를 비교하는 것은 좋은 컨텍스트를 제공합니다.\n\n이 방법의 변형 중 하나는 자주 나오는 것이 아닌 드문 항목 집합을 사용하는 것인데, 각 행의 드문 항목 집합의 수와 희귀성에 따라 각 행을 점수 매깁니다. 이 방법도 유용한 결과를 얻을 수 있지만, 계산 비용이 상당히 많이 소요되며, 더 많은 항목 집합이 채굴되어야 하고, 각 행은 많은 항목 집합과 테스트되어야 합니다. 그러나 최종 점수는 각 행에 누락된 대신 발견된 항목 집합을 기반으로 하므로 더 해석하기 쉬울 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결론\n\n여기에 나와 있는 코드 외에는 파이썬에서 FPOF를 구현한 것을 알지 못합니다. 그러나 R에서는 구현된 것이 있습니다. FPOF 작업의 주요 부분은 FISs를 채굴하는 것이며, 여기에서 사용된 mlxtend 라이브러리를 포함하여 이를 수행할 수 있는 다양한 파이썬 도구가 있습니다. 위에서 본 FPOP의 나머지 코드는 꽤 간단합니다.\n\n이상 탐지에서 해석 가능성의 중요성을 고려할 때, FPOF는 매우 유용할 수 있습니다.\n\n향후 기사에서는 이상 탐지를 위한 다른 해석 가능한 방법에 대해 알아볼 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 그림은 저자에 의해 생성되었습니다.\n","ogImage":{"url":"/assets/img/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF_0.png"},"coverImage":"/assets/img/2024-05-27-InterpretableOutlierDetectionFrequentPatternsOutlierFactorFPOF_0.png","tag":["Tech"],"readingTime":9},{"title":"시계열 데이터에서 이상치를 찾는 궁극의 안내서 파트 1","description":"","date":"2024-05-27 14:58","slug":"2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1","content":"\n\n![Outliers](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_0.png)\n\n이상치: 통계 모델을 왜곡하고 예측을 왜곡시키며 의사 결정 프로세스를 약화시키는 문제가 되는 데이터 포인트들입니다.\n\n그들이 데이터 분석에서 특별히 좋아지지 않는 것은 놀라운 일이 아닙니다.\n\n제 이름은 Sara이며, 물리학 석사 학위를 가지고 있습니다. 현재는 글로벌 에너지 회사에서 데이터 과학자로 일하고 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사는 시계열 데이터에서 이상치를 식별하고 관리하는데 전념한 세 개의 시리즈를 시작합니다. 만약 이 시리즈를 계속해서 따르고 싶다면, 저를 팔로우하고 다음 부분이 발행될 때 업데이트를 받을 수 있도록 구독하세요!\n\n이 첫 번째 글에서는 시계열 데이터에서 이상치를 효과적으로 식별하기 위한 시각적 및 통계적 방법을 탐구합니다. 이 기초적인 지식은 분석 정확도를 향상시키려는 모든 사람에게 중요합니다.\n\n다음 기사에서는 기계 학습 방법에만 집중하여, 그 중요성과 복잡성에 비추어, 전용 논의가 필요합니다.\n\n그 후 세 번째 기사에서는 이상치를 관리하는 다양한 전략을 탐색할 것입니다. 우리는 변형 기술에 집중하여, 그 영향을 완화하는 실용적인 해결책을 제시할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시작해 봅시다!\n\n컨텐츠:\n\nPart I (이 기사):\n\n- 왜 중요한가요?\n- Outliers vs Anomalies\n- 올바른 이상 탐지 방법 선택하기\n- 단변량 vs 다변량 시계열 데이터\n- 이상치 식별\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 시각 검사\n- 통계적 방법\n\n5. 평가 지표\n\nPart II (다음):\n\n3. 이상값 식별\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 기계 학습 방법\n- 평가 지표\n\n다음 장 (예정):\n\n4. 이상값 처리\n\n- 무시하거나 제거하거나?\n- 변환 기술\n- 대치\n- 상한 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어째서 신경 써야 할까요?\n\n만약 여러분이 이 글을 읽고 있다면, 아마도 모델링을 수행하기 전에 이상치를 처리하는 것이 얼마나 중요한지 이미 알고 계실 것입니다.\n\n시계열 데이터에서 이상치에 대해 신경 써야 하는 몇 가지 이유는 다음과 같습니다:\n\n- 이상치는 데이터 집합의 평균, 분산, 상관 계수 등과 같은 주요 통계치를 심각하게 왜곡하고 잘못 표현할 수 있습니다.\n- 이상치는 예측 모델의 성능을 훼손시킬 수 있습니다.\n- 이상치는 시계열 데이터에서 진정한 추세와 주기적인 행동을 가리고 숨길 수 있습니다.\n- 이상치를 철저히 검토하지 않은 데이터에 기반한 결정은 부적절한 전략적 결정으로 이어질 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시계열 데이터에서 이상 값 처리가 효과적인 분석에 중요한 이유가 더 많이 있지만, 이것들은 우리가 시작하기를 원하는 충분한 이유일 것입니다.\n\n## Outliers vs Anomalies\n\n\"이상 값\"과 \"이상 값\"이라는 용어를 번갈아 사용할 것이지만, 그들의 정의에는 미묘한 차이가 있습니다. 이상 값은 정상에서 벗어나는 모든 데이터 포인트를 가리킬 수 있지만, 이상 값은 특히 대부분의 데이터 포인트로부터 크게 벗어난 극단적인 값이라는 것을 명시적으로 나타냅니다. 많은 방법이 이상 값과 이상 값 모두에 적용될 수 있습니다.\n\n# 시계열 데이터에 적합한 이상 값 탐지 방법을 선택하는 방법?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![The Ultimate Guide to Finding Outliers in Your Time-Series Data Part 1](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_1.png)\n\n시계열 데이터의 이상 탐지 방법을 선택하기 위해서는 데이터셋과 예상되는 이상과 깊이 이해가 필요합니다.\n\n그렇다면, 데이터셋의 크기와 사용 가능한 계산 리소스를 고려해보세요.\n\n해석 가능성이 중요한 데이터셋의 경우 Z-Score와 이동 평균과 같은 간단한 방법이 이상적일 수 있습니다. 그러나 섬세한 패턴을 감지해야 하는 복잡한 시나리오와 같은 경우에는 LSTM 네트워크와 같은 고급 기법이 유용할 수 있습니다(이에 대한 자세한 내용은 이 시리즈의 두 번째 부분에서 다룰 예정이며, 상당한 데이터와 계산 능력이 필요합니다).\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 기억하세요: 데이터셋 크기, 계산 자원, 해석 가능성, 그리고 작업의 성격은 적절한 이상점 탐지 방법을 선택하는 데 중요합니다.\n\n정확한 성능 평가를 위해 다양한 방법과 지표를 실험해 보는 것이 유익할 수 있습니다. 가능하다면 정확도를 향상시키기 위해 여러 방법의 앙상블을 사용하는 것을 고려해보세요. 또한 분야에 대해 알고 있는 사학자나 전문가의 의견을 활용하여 방법을 선택할 수 있습니다.\n\n사기 탐지와 같이 이상치가 드물지만 중요한 경우와 같이 이상치 탐지 방법을 평가하는 것은 특히 어려울 수 있습니다.\n\n정밀도, 재현율, F1 점수와 같은 지표는 사기 활동을 포착하면서 거짓 양성을 줄이는 이러한 방법의 효과를 평가하는 데 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예측 유지보수와 같은 맥락에서 ROC 곡선과 AUC 지표는 잠재적인 기계 고장을 적시에 식별하는 데 매우 유용합니다.\n\n건강 관리와 같은 산업에서는 시각화가 환자의 중요 생리 신호를 모니터링하는 데 자주 사용되지만, 이러한 방법의 정확성은 올바른 해석을 위해 도메인 전문 지식에 매우 의존합니다.\n\n# 단변량 vs 다변량 데이터\n\n이상치 분석을 시작하기 전에 데이터가 단변량인지 다변량인지 고려하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단변량 시계열 데이터는 시간에 따라 기록된 단일 관측값 순서로 구성됩니다. 전형적인 예시로는 일일 주식 가격, 월간 판매 수치 또는 연간 기상 데이터가 있습니다.\n\n![image](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_2.png)\n\n반면, 다변량 시계열 데이터는 동일한 시간 간격에서 관찰되고 기록된 여러 변수 또는 순서로 구성됩니다.\n\n이 유형의 데이터는 서로 다른 변수 간의 관계 및 상호작용을 포착하며 개별적인 추세 및 계절적 변동도 포함합니다. 예를 들어, 다변량 시계열에는 온도, 습도 및 풍속의 일일 측정치가 동시에 기록된 것이 포함될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_3.png)\n\n이 기사에서 설명된 몇 가지 방법은 일변량 데이터에 더 적합하며 다른 몇 가지는 여러 변수를 처리하는 데 특화되어 있습니다.\n\n그러나 일부는 두 가지에 모두 적용할 수 있습니다. 방법에 깊이 들어가기 전에 두 종류의 데이터에 대한 일반적인 방법을 소개하겠습니다.\n\n일변량 데이터에 대해 시계열 플롯 및 상자 그림과 같은 시각적 검사 방법이 일반적으로 사용되며 한 번에 한 변수에 초점을 맞춥니다. 또한 일변량 설정에서 STL 분해가 전통적으로 사용됩니다. Z-점수, 수정된 Z-점수 방법 및 Grubbs' 검정도 이 유형의 데이터에 사용됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기계 학습 방법 중 Isolation Forest, LOF 및 Autoencoders와 같은 방법들은 일반적으로 다변량 데이터에서 차원 축소와 이상 탐지에 사용되지만, 단일 시계열 데이터를 압축하고 복원하여 재구성 오류를 기반으로 이상을 식별하는 데도 사용됩니다.\n\n![이미지](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_4.png)\n\n팁: 이 정신 지도에 나열된 방법 이외에도 더 많은 이상치 탐지 방법이 있습니다.\n\n여러 변수가 포함된 데이터의 경우 산점도 분석이 일반적으로 여러 변수 간의 관계를 조사하는 데 사용됩니다. Isolation Forests, LOF 및 Autoencoders는 고차원 데이터를 처리하는 데 자연스럽게 적합합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다중 변수 데이터에도 여러 가지 일변량 방법을 적용할 수 있습니다. 예를 들어, Z-점수 방법은 각 변수에 대해 독립적으로 Z-점수를 계산하여 다중 변수 상황에서도 사용할 수 있습니다.\n\n상자 도표는 다차원 데이터셋 내 각 변수에 대해 별도로 사용될 수 있어 각 차원에서 이상치를 식별하는 데 도움이 됩니다. 다차원 시나리오에서는 산점도를 사용하여 변수 쌍을 플롯할 수 있습니다. STL 분해는 전통적으로 일변량이지만 각 시리즈를 독립적으로 분해하여 다중 변수 시리즈를 분석하는 데 적용할 수 있습니다.\n\n# 데이터에서 이상치를 탐지하기 위한 최상의 방법은 무엇입니까?\n\n# 시각적 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시각 검사는 시계열 데이터에서 이상치를 식별하는 데 중요한 방법입니다. 데이터의 특성에 따라 시각적 검사를 어떻게 수행할지가 영향을 받습니다.\n\n시계열 플롯\n\n시계열 데이터에 대한 가장 간단한 플롯입니다. 시간 경향, 패턴, 계절 변동 및 잠재적 이상치를 시간에 따라 확인할 수 있습니다. 다른 데이터에서 크게 벗어난 지점은 종종 쉽게 발견할 수 있습니다.\n\n```js\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\ndef plot_temporal_trends(df, columns):\n\n    num_plots = len(columns)\n    fig, axes = plt.subplots(num_plots, 1, figsize=(10, num_plots * 3), sharex=False)  # sharex=False로 x축을 공유하지 않음\n    fig.suptitle(f'시간 트렌드', fontsize=16, y=1.02 + 0.01 * num_plots)\n\n    if num_plots == 1:  # axes가 반복 가능한지 확인\n        axes = [axes]\n\n    for ax, col in zip(axes, columns):\n        ax.plot(df.index, df[col], marker='o', markersize=4, linestyle='-', label=col)\n        ax.set_title(f'{col} - {title}')\n        ax.set_ylabel('값')\n\n        # 각 subplot의 x축에 대한 날짜 포매터 설정\n        ax.xaxis.set_major_locator(mdates.YearLocator(base=2))\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n        # 틱 라벨을 더 잘 보이도록 회전 및 정렬\n        ax.tick_params(axis='x', rotation=45)\n\n        ax.legend()\n\n    plt.tight_layout(rect=[0, 0, 1, 0.97])  # 제목을 위한 공간을 만들기 위해 레이아웃 조정\n    plt.show()\n\ncolumns = df.columns.tolist()\nplot_temporal_trends(df, columns)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_5.png\" /\u003e\n\n이상값을 발견할 수 있나요? 🤔 이 시각화는 이상값을 쉽게 드러낼 수도 있고, 데이터의 복잡성에 따라 더 자세한 분석이 필요할 수도 있습니다. 대부분의 경우, 추가 시각화가 필요할 수도 있습니다.\n\n## 이상값 분석에서 계절 고려 사항\n\n이상값을 계절별로 처리하는 것은 매우 중요할 수 있습니다, 특히 계절 변동을 나타내는 데이터를 다룰 때입니다. 많은 시계열 데이터 세트는 특정 시기에 명확한 패턴을 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사실 이상값으로 보였던 데이터 포인트가 계절에 따라 처리되면 이상값으로 간주되지 않을 수도 있습니다. 다시 말해 데이터와 문제의 성겁에 따라 다릅니다!\n\n예를 들어, 저는 최근 댐에서의 수질 측정 데이터를 다루는 프로젝트에 참여했습니다. 여기서 이상값은 계절별로 분석해야 한다는 것이 빠르게 명확해졌습니다. 각 계절은 고유한 특성과 추세를 가지고 있으며, 이는 파라미터에 독특한 방식으로 영향을 미칩니다. 계절별로 데이터를 분할하여, 각 하위 그룹에 효과적인 특정 이상값 탐지 방법을 적용할 수 있었습니다.\n\n예를 들어, 비가 많이 오는 계절의 수질 이상값은 유출 때문에 일반적일 수 있지만, 건조한 계절에는 비정상적일 수 있습니다.\n\n게다가, 계절별 분석은 계절적 영향을 고려하여 예측 모델을 개선할 수 있습니다. 이것은 농업, 관광 및 소매업과 같은 계절적 변화에 크게 영향을 받는 산업에 중요할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n박스 플롯\n\n데이터 집합이나 데이터 하위 집합에서 이상 징후를 정적으로 식별하는 데 유용합니다. 상자 외부의 점들(일반적으로 사분위수에서 1.5배의 사분위 범위로 설정)은 잠재적인 이상값입니다.\n\n```js\ndef plot_outliers(param_dfs):\n    for key, df in param_dfs.items():\n        plt.figure(figsize=(10, 6))\n        df.boxplot()\n        plt.title(f'{key}의 박스 플롯')\n        plt.xticks(rotation=45)\n        plt.show()\n\n# 이상값을 플롯하는 함수 호출\nplot_outliers(param_dfs)\n```\n\n![Boxplot image](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상기 그림에서는 특정 매개변수를 다른 수심별로 분석하여 이들을 옆에 비교했습니다. 플롯 상의 작은 검은 원은 잠재적 이상점을 나타냅니다. 이러한 시각적 단서는 각 하위 집합 내에서 근본적으로 벗어난 데이터 포인트를 신속하게 식별하는 데 중요합니다.\n\n산포도\n\n시계열 데이터가 다른 변수와 관련이 있다면, 산포도는 두 변수의 맥락에서 이상점을 식별하는 데 도움이 될 수 있습니다.\n\n```js\n# 플로팅\nplt.figure(figsize=(10, 6))\n# 정상 데이터\nplt.scatter(df['연간 소득'][:-5], df['신용카드 지출'][:-5], color='blue')\nplt.title('연간 소득 대 신용카드 지출')\nplt.xlabel('연간 소득 ($)')\nplt.ylabel('신용카드 지출 ($)')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_7.png\" /\u003e\n\n# 통계적 방법\n\n## STL 분해\n\n시계열 데이터는 추세, 계절성 및 잔류로 분할될 수 있다는 것을 이미 알고 계시다시피,\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSTL 분해는 LOESS(Locally Estimated Scatterplot Smoothing)를 사용하여 시계열 신호를 이 세 가지 구분된 구성 요소로 효과적으로 분리하는 데 유용합니다. 이를 통해 데이터의 기본적인 행동에 대한 명확한 통찰력을 얻어 분석하고 예측할 수 있는 능력이 향상됩니다.\n\n참고: STL은 데이터 포인트가 시간 순서대로 배열되어 있다고 가정합니다. STL 분해는 데이터 포인트들이 자연적인 시간 순서로 서로 뒤이어 따라 오는 시리즈를 예상합니다. 이는 추세 및 계절 변동을 정확하게 추정하기 위한 중요한 요소로, 각 포인트가 이어지는 포인트를 이해하는 데 기여합니다.\n\n![이미지](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_8.png)\n\nSTL은 이상치를 식별하는 데 어떻게 도움을 줄까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSTL 분해의 잔여 구성 요소는 계절성 및 추이 구성 요소로 설명할 수 없는 데이터 부분을 나타냅니다.\n\n이상적으로는 잔여는 무작위 잡음이어야 합니다. 이상점은 종종 잔여 시리즈에서 일반적인 잡음 수준에서 현저하게 벗어나는 이상한 돌출이나 패딩으로 감지될 수 있습니다. 따라서 잔여에서 극단적인 값들을 찾아보세요. 잔여는 이상적으로 무작위 잡음을 나타내므로 어떠한 중요한 이탈도 이상점을 나타낼 수 있습니다.\n\n잔여의 표준 편차를 분석하여 평균 잔여로부터 일반적으로 분류되는 이상한 거리에 있는 점들을 식별할 수 있습니다. 예를 들어, 평균 잔여에서 2 또는 3 표준 편차 이상 떨어진 데이터 포인트는 이상점으로 간주될 수 있습니다.\n\n추이 구성 요소는 단기 변동을 완화시키고 데이터 집합의 폭넓은 움직임을 강조합니다. 이상점은 추이에 예상치 못한 변동이나 대부분의 데이터가 설정한 부드러운 패턴과 어울리지 않는 급격한 변화를 일으킬 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 1: 잔차 플롯 검토\n\n먼저 STL 분해에서 얻은 잔차 플롯을 살펴봅니다. 이 플롯은 추세나 계절성 구성 요소로 설명할 수 없는 데이터 포인트를 보여줍니다.\n\n## 단계 2: 통계 지표 계산\n\n잔차의 평균과 표준 편차를 계산합니다. 이는 정규 분포된 잡음 패턴에서 기대하는 것과 유의미하게 다른 데이터 포인트를 결정하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 3: 이상치에 대한 임계값 정의\n\n일반적으로, 평균으로부터 2 또는 3 표준 편차 이상 떨어진 데이터 포인트는 이상치로 간주됩니다. 이상치에 얼마나 민감하게 대응할지에 따라 임계값을 선택할 수 있습니다. 많은 경우, 3 표준 편차를 사용하는 것이 일반적입니다.\n\n## 단계 4: 이상치 식별\n\n잔차 구성 요소에서 이 임계값을 초과하는 데이터 포인트를 식별합니다. 이것들이 당신의 잠재적인 이상치입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 5: 시각적 검사 및 상호 확인\n\n원래 시계열 플롯과 추세 및 계절성 구성 요소의 플롯을 다시 살펴보세요. 식별된 이상점이 이러한 구성 요소와 어떤 관련이 있는지 살펴보세요.\n\n이상점이 단순히 유례 없는 변동이거나 오류 또는 이상 현상을 나타낼 가능성이 있는지 확인하세요. 이는 데이터에 대한 문맥적 지식을 포함할 수 있습니다.\n\n```js\nimport numpy as np\n#예시\n\n# 잔차의 평균과 표준 편차 계산\nresiduals = result.resid\nmean_resid = np.mean(residuals)\nstd_resid = np.std(residuals)\n\n# 이상점 감지를 위한 임계값 정의\nthreshold = 3 * std_resid\n\n# 잠재적인 이상점 식별\noutliers = residuals[np.abs(residuals - mean_resid) \u003e threshold]\n\n# 이상점의 날짜 및 값 출력\nprint(outliers)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nZ-점수와 수정된 Z-점수 방법\n\nZ-점수는 표준 점수로도 알려져 있으며, 데이터 포인트가 데이터 집합의 평균으로부터 몇 표준 편차 떨어져 있는지를 측정합니다. 이는 아래 공식을 사용하여 계산됩니다:\n\n\nZ = (X - μ) / σ\n\n\n- X는 개별 데이터 포인트를 나타냅니다.\n- μ는 데이터 집합의 평균을 나타냅니다.\n- σ는 데이터 집합의 표준 편차를 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일정 임계값(일반적으로 2 또는 3)보다 높은 Z-점수를 가진 데이터 포인트는 이상값으로 간주됩니다.\n\n참고: Z-점수 방법은 데이터가 정규 분포를 따른다고 가정하거나 적어도 대략적으로 정규 분포를 따른다고 가정합니다. 또한, 특이값이 평균과 표준 편차에 비해 극단적인 값을 가질 것이라고 가정합니다.\n\n```js\nimport numpy as np\n\ndef identify_outliers_with_z_score(df, z_thresh=z_thresh):\n    print(\"Z-점수 방법을 사용하여 이상값 식별:\")\n    for col in df.columns:\n        if np.issubdtype(df[col].dtype, np.number):  # 숫자 데이터만\n            df_col = df[col].dropna()  # NaN 값 제거\n            z_scores = np.abs((df_col - df_col.mean()) / df_col.std(ddof=0))\n            outliers = df_col[z_scores \u003e z_thresh]\n            print(f\"{col} - 이상값: {len(outliers)}\")\n            print(outliers, \"\\n\")\n\nz_thresh = 3\nidentify_outliers_with_z_score(df)\n```\n\n데이터 세트에서 이상값을 식별하기 위해 Z-점수 임계값을 선택하는 것은 데이터 분석 결과에 상당한 영향을 줄 수 있는 중요한 결정임을 기억해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 일반 분포 하에서의 z-점수에 대한 설명입니다: z-점수 1은 곡선 아래 약 68%를, z-점수 2는 약 95%를, z-점수 3는 약 99.7%를 포함합니다.\n\n만약 다양한 임계값을 사용하여 데이터의 이상치 개수를 궁금해 한다면, 그것을 플로팅하여 비교할 수도 있습니다:\n\n```js\ndef count_outliers_by_z_threshold(series, z_thresholds=[1, 2, 3]):\n    \"\"\"주어진 Z-점수 임계값에 대해 이상치 개수를 반환합니다.\"\"\"\n    mean = series.mean()\n    std = series.std()\n    z_scores = np.abs((series - mean) / std)\n\n    # 각 Z-점수 임계값에 대한 이상치 개수 계산\n    counts = {}\n    for z_thresh in z_thresholds:\n        counts[z_thresh] = (z_scores \u003e z_thresh).sum()\n    return counts\n\n# 'param_dfs'가 DataFrame의 딕셔너리인 것을 가정합니다\nz_thresholds = [1, 2, 3]\noutlier_counts_by_threshold = {z: 0 for z in z_thresholds}\n\nfor df in param_dfs.values():\n    for column in df.columns:\n        series = df[column].dropna()  # NaN 값 제거\n        counts = count_outliers_by_z_threshold(series, z_thresholds)\n        for z_thresh, count in counts.items():\n            outlier_counts_by_threshold[z_thresh] += count\n\n# 플로팅을 위해 이상치 개수를 리스트로 변환\ncounts = [outlier_counts_by_threshold[z] for z in z_thresholds]\n\n# 플로팅\nplt.figure(figsize=(8, 6))\nbars = plt.bar(z_thresholds, counts, color=['blue', 'orange', 'green'])\n\nplt.xlabel('Z-점수 임계값')\nplt.ylabel('이상치 개수')\nplt.title('Z-점수 임계값에 따른 이상치 수')\nplt.xticks(z_thresholds)\n\n# 각 막대에 높이 값으로 주석 달기\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.05 * max(counts), int(yval), ha='center', va='bottom')\n\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_11.png)\n\n시계열 데이터를 다루고 있기 때문에 연도별 이상치 분포를 시각화하는 것이 유용할 수 있습니다:\n\n```js\ndf['Z-Score'] = zscore(df['Value'])\n\n# Z-score가 3보다 크거나 -3보다 작은 경우를 이상치로 정의\ndf['Outlier'] = (df['Z-Score'] \u003e 3) | (df['Z-Score'] \u003c -3)\n\n# 연도별 이상치 개수 계산\noutlier_counts = df.resample('Y')['Outlier'].sum().astype(int)\n\n# 연도를 별도 열로 얻기 위해 인덱스 재설정 및 플로팅 준비\noutlier_counts = outlier_counts.reset_index()\noutlier_counts['Year'] = outlier_counts['index'].dt.year\noutlier_counts.drop('index', axis=1, inplace=True)\n\nplt.figure(figsize=(10, 6))\ncolors = plt.cm.viridis(np.linspace(0, 1, len(outlier_counts)))\nplt.bar(outlier_counts['Year'], outlier_counts['Outlier'], color=colors)\nplt.title('Distribution of Outliers Per Year')\nplt.xlabel('Year')\nplt.ylabel('Number of Outliers')\nplt.xticks(outlier_counts['Year'])  # 모든 연도가 표시되도록\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.show()\n```\n\n![image](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_12.png)\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 계절 당:\n\n![image](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_13.png)\n\nRobust Z-Score\n\n수정된 Z-점수 방법으로도 알려진 이 기술은 일반적인 Z-점수를 개선하기 위해 평균 대신 중앙값(M)을 사용합니다. 평균은 가장 신뢰할 수있는 통계적 측정 방법이 아니기 때문에 중앙값을 사용합니다. 또한 표준 편차 대신 중앙값의 절대 편차(MAD)를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_14.png)\n\n수정된 Z-점수 공식의 0.6745 배수는 중앙값 절대편차(MAD)를 표준 편차와 비교 가능하게 만들기 위해 사용됩니다.\n\n이 조정이 필요한 이유는 정의에 따라 MAD가 동일한 데이터 집합에 대해 표준 편차보다 작기 때문입니다. 따라서 이런 스케일링을 고려하여 임계값을 조정해야 합니다.\n\n참고: 중앙값과 MAD는 평균과 표준 편차보다 이상값에 강인한 특성을 가집니다. 때로는, 이 강인성으로 인해 MAD 값이 작아질 수 있으며, 특히 이상값이 극단적인 경우에 그렇습니다. 따라서, 가장 극단적인 관측치만 이상값으로 표시되도록 하기 위해 약간 더 높은 임계값이 필요할 수 있습니다 (문맥에 따라 3.5, 4 또는 5).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom scipy.stats import median_absolute_deviation\n\n# 중앙값 및 중앙값 절대 편차(MAD)를 사용하여 수정된 Z-점수 계산\ndf['Median'] = df['Value'].median()\ndf['MAD'] = median_absolute_deviation(df['Value'])\ndf['Modified_Z-Score'] = 0.6745 * (df['Value'] - df['Median']) / df['MAD']\n\n# 수정된 Z-점수가 3보다 크거나 -3보다 작은 경우 이상값으로 정의\ndf['Outlier'] = (df['Modified_Z-Score'] \u003e 3.5) | (df['Modified_Z-Score'] \u003c -3.5)\n\n# 연도별 이상값 수 계산\noutlier_counts = df.resample('Y')['Outlier'].sum().astype(int)\n\n# 인덱스 재설정하여 연도를 별도의 열로 가져오고 플로팅을 위해 준비\noutlier_counts = outlier_counts.reset_index()\noutlier_counts['Year'] = outlier_counts['index'].dt.year\noutlier_counts.drop('index', axis=1, inplace=True)\n\n# 연도별 그래픽 플로팅\nplt.figure(figsize=(10, 6))\ncolors = plt.cm.viridis(np.linspace(0, 1, len(outlier_counts)))\nplt.bar(outlier_counts['Year'], outlier_counts['Outlier'], color=colors)\nplt.title('연도별 이상값 분포')\nplt.xlabel('연도')\nplt.ylabel('이상값 수')\nplt.xticks(outlier_counts['Year'])  # 모든 연도를 표시하도록 설정\nplt.grid(True, which='both', linestyle='--', linewidth=0.5)\nplt.show()\n```\n\n![이미지](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_15.png)\n\n## 통계 및 시각적 방법 통합\n\nZ-점수 방법(임계값 3)으로 감지된 이상값을 시계열 도표로 시각화합시다.\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n#여기서 이상치는 사전입니다.\ndef plot_outliers(df, outliers_dict):\n    #한 stage마다 이상치가 있는 column의 수만큼 subplot의 행 수가 됩니다.\n    for stage, columns_outliers in outliers_dict.items():\n        #플롯 수 결정\n        num_plots = len(columns_outliers)\n        if num_plots == 0:\n            continue  # 이 stage에 이상치가 없으면 건너뜁니다.\n\n        #서브플롯 만들기\n        fig, axes = plt.subplots(nrows=num_plots, figsize=(15, num_plots * 5), sharex=True)\n        fig.suptitle(f'{stage} Stage의 이상치 시각화', fontsize=16)\n\n        if num_plots == 1:  # 플롯이 하나뿐이면 iterable로 만들기\n            axes = [axes]\n\n        for ax, (column, outliers) in zip(axes, columns_outliers.items()):\n            #전체 데이터 시리즈 플롯\n            ax.plot(df.index, df[column], label=f'{column} (전체 시리즈)', color='black', linestyle='-', marker='', alpha=0.5)\n\n            #이상치 강조\n            if not outliers.empty:\n                ax.scatter(outliers.index, outliers, color='red', label='이상치', marker='o', s=50)\n\n            ax.set_title(f'{column}의 이상치')\n            ax.set_ylabel('값')\n            ax.legend()\n\n            #x축 주요 로케이터와 포매터 설정\n            ax.xaxis.set_major_locator(mdates.YearLocator())\n            ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n            plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n\n        plt.tight_layout(rect=[0, 0, 1, 0.96])  # 레이아웃 조정\n        plt.show()\n```\n\n![2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_16.png](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_16.png)\n\nGrubb의 Test\n\nGrubb의 테스트, 최대 또는 최소값을 데이터셋의 평균 및 표준편차와 비교하여 잠재적인 이상치를 식별하는 최대 표준화 잔차 테스트로 알려져 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참고: 데이터가 1차원 정규 분포를 따르고 이상치는 평균과 표준편차에 비해 극단적인 값을 가질 것으로 가정합니다.\n\n중요한 점은 그럽스 검정이 일반적으로 데이터 집합에서 최댓값 또는 최솟값 중 하나를 포함해 한 번에 한 데이터 포인트씩 수행됩니다.\n\n![image](/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_17.png)\n\nG는 그럽스 검정 통계량, X는 의심스러운 이상치 값(데이터 집합에서 최대값 또는 최소값), X(바로 위에 bar가 있는)는 데이터 집합의 평균이며, s는 데이터 집합의 표준 편차입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n의심되는 이상값이 유의한지 여부를 결정하기 위해 계산된 검정 통계량 G를 적절한 통계 분포(일반적으로 T-분포)의 임계값과 비교합니다.\n\nG가 임계값을 초과하는 경우, 의심되는 이상값은 통계적으로 유의하다고 간주되며, 이는 이상값일 가능성이 높음을 나타냅니다.\n\n```js\nfrom pyod.models.grubbs import grubbs_test\n\n# PyOD를 사용하여 Grubbs' 테스트 적용\noutliers_grubbs = []\nfor col in df.columns:\n    outliers = grubbs_test(df[col])\n    outliers_grubbs.extend([(idx, col) for idx in outliers])\nprint(\"Grubbs' 테스트에 의해 감지된 이상값:\")\nprint(outliers_grubbs)\n```\n\n# 평가 메트릭\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 이에 대해 전체 블로그 글을 쓸 수도 있을 거예요.\n\n하지만 간단히 하기 위해, 주요 평가 지표를 언급하며 몇 가지 예시를 드릴게요.\n\n적절한 평가 지표를 선택하는 것은 시계열 분석에서 이상 탐지 방법의 효과를 평가하는 데 매우 중요한 요소에요.\n\n## 최적의 지표는 데이터의 성격, 해당 이상값의 특성 및 거짓 긍정과 거짓 부정 사이에서 필요한 균형에 따라 다를 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시: 사기 탐지\n\n사기 탐지에서 이상 징후는 드물지만 중요합니다. 여기서 핵심적인 지표는 정밀도, 재현율, 그리고 F1 점수입니다. 정밀도는 실제로 이상 징후인 것들 중에 몇 개를 올바르게 식별했는지 측정합니다. 재현율은 방법으로 올바르게 식별된 실제 이상 징후의 수를 측정합니다. F1 점수는 정밀도와 재현율을 균형 있게 고려해 방법의 성능을 종합적으로 평가하는 데 도움을 줍니다.\n\n예시: 예측 유지보수\n\n예측 유지보수에서는 이상을 적시에 식별하는 것이 중요합니다. 여기서 수신기 조작 특성 (ROC) 곡선과 곡선 아래 영역 (AUC)은 주요 지표입니다. 이러한 지표들은 참 양성 비율과 거짓 양성 비율 사이의 균형을 이해하는 데 도움을 줍니다. 이는 서로 다른 운영 요구 사항을 충족시키기 위해 감지 임계값을 최적화하는 데 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시: 의료\n\n의료 분야에서 해석 가능성은 매우 중요하기 때문에 시각화 역시 매우 중요합니다. 이들은 전문가들이 감지된 이상 현상을 확인하고 의사 결정에 미치는 영향을 이해할 수 있도록 돕습니다. 도메인 지식을 통합함으로써, 이러한 시각 도구들은 결과물의 타당성과 해석 가능성을 향상시켜 미래에 적용 가능하고 중요한 이상 현상임을 보장합니다.\n\n적절한 지표를 선택하는 것은 시계열 데이터에서 이상 현상을 효과적으로 감지하고 관리하는 데 상당한 영향을 미칠 수 있습니다.\n\n이상 현상 관리에 어떤 지표를 선택해야 하는지 알아보았습니다.\n\n지금까지입니다! 이 글이 마음에 든다면 반드시 클랩을 눌러주세요 😋. 비슷한 기사를 원하신다면 제 팔로우도 환영합니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 시계열 분석에서 주로 사용하는 통계적 방법은 무엇인가요?\n\n## 그 밖에 어떤 방법을 알고 계신가요? 댓글로 알려주세요 :)\n\n저는 물리학과 천문학 배경을 가진 데이터 과학자인 사라 노브레가입니다. 인공지능, MLOps, 스마트 시티, 지속가능성, 우주학, 그리고 인권에 관심이 많습니다.\n\n참고 문헌\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시계열 데이터에서 이상 감지를 어떻게 수행하나요?\n","ogImage":{"url":"/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_0.png"},"coverImage":"/assets/img/2024-05-27-TheUltimateGuidetoFindingOutliersinYourTime-SeriesDataPart1_0.png","tag":["Tech"],"readingTime":20},{"title":"임베딩 크기를 줄이고 RAG 검색 속도 높이는 방법","description":"","date":"2024-05-27 14:56","slug":"2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed","content":"\n\u003cimg src=\"/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_0.png\" /\u003e\n\n# 소개\n\n텍스트 임베딩은 단일 단어나 전체 문장의 고차원 벡터 표현입니다.\n\n이 숫자 배열로 이루어진 벡터는 기본 텍스트에 대한 풍부한 정보를 포착함으로써 의미 이해, 분류, 군집화, 정보 검색 (RAG), 재정렬 및 더 많은 하류 작업에 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n보통 임베딩 벡터의 차원 d는 고정됩니다. 임베딩 차원은 일반적으로 64에서 4096까지의 2의 제곱수로 구성됩니다.\n\n매트료시카 임베딩을 사용하면 응용 프로그램에 따라 임베딩의 차원을 변경할 수 있습니다. 이를 통해 저장 공간을 줄이고 비용을 절약하며 검색 속도를 높일 수 있습니다.\n\n# 텍스트 임베딩이란?\n\n![이미지](/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희는 모든 가능한 입력 문자를 정수 값으로 매핑하는 어휘를 정의하여 시작합니다. 이 어휘에는 알파벳 문자 뿐만 아니라 특수 문자, 짧은 단어 및 하위 단어도 포함됩니다:\n\n```js\n{\n  \"a\": 1,\n  \"b\": 2,\n  \"c\": 3,\n  ...\n  \"z\": 26,\n  \"the\": 27,\n  \" \": 28\n}\n```\n\n토큰화 후에는 토큰 목록을 인코더 모델에 전달할 수 있습니다. 인코더는 대량의 훈련 데이터로부터 학습하여 각 토큰을 고차원 숫자 벡터 임베딩으로 변환합니다.\n\n예를 들어, OpenAI의 text-embedding-3-large 모델의 임베딩의 출력 차원 d는 3072입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단일 문장 임베딩을 얻으려면 여러 토큰 임베딩에서 정보를 압축해야 합니다. 이를 위한 한 가지 방법은 단순히 모든 토큰 임베딩을 평균내는 것입니다.\n\n# 마트료시카 임베딩\n\n마트료시카 임베딩은 워싱턴 대학, 구글 리서치, 하버드 대학의 연구자들에 의해 2022년에 발표된 \"Matryoshka Representation Learning\" 논문에서 소개되었습니다.\n\n마트료시카 임베딩은 서로 다른 세기의 정보를 하나의 임베딩 벡터에 인코딩하는 데 훈련되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, MRL을 사용하여 단순히 크기 d = 1024의 전체 임베딩 벡터를 학습하는 대신, 우리는 동일한 시간에 최적화하려는 손실 함수를 위해 matryoshka_dims = [1024,512,256,128,64] 차원 목록을 사용합니다[2].\n\n이렇게 하면 처음 몇 차원에 가장 덜 구체적인 정보가 저장되고 나중 차원에는 점점 더 많은 세부 정보가 저장된 임베딩 벡터가 생성됩니다.\n\n![이미지](/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_2.png)\n\n이는 우리가 원하는 곳에서 임베딩 벡터를 잘라도 성능을 너무 많이 희생하지 않고 사용할 수 있다는 효과가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 왜 중요한가요?\n\n만약 우리가 텍스트 임베딩 벡터를 벡터 데이터베이스에 저장하려고 한다고 가정해봅시다. 각 임베딩은 d 차원을 가지고 있습니다. 그리고 각 숫자는 일반적으로 32비트 부동 소수점 수입니다. 그래서 우리는 저장을 위해 n _ d _ 4 바이트가 필요합니다.\n\n그리고 만약 우리가 점곱이나 코사인 유사성과 같은 유사성 지표를 계산하려고 한다면 (코사인 유사성은 단지 정규화된 점곱일 뿐입니다), 차원 d가 클수록 수학적 계산을 더 많이 해야 합니다.\n\n![image](/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMRL을 사용하면 작은 메모리 공간, 빠른 처리 속도 및 따라서 비용 절약에 관심이 있다면, 첫 64차원만 사용할 수도 있습니다. 최상의 하류 성능을 원한다면 모든 차원을 사용합니다. 그리고 그 중간을 선택할 수도 있습니다.\n\n따라서, MRL은 LLM 사용자들에게 내려보기 성능의 작은 저하에 대한 임베딩 크기(비용)의 대가를 거래할 수 있는 능력을 제공합니다.\n\n# Nomic AI에서 MRL 사용하기\n\nNomic의 Matryoshka 텍스트 임베딩 모델 nomic-embed-text-v1.5은 matryoshka_dims = [768,512,256,128,64]로 훈련되었습니다. 해당 모델은 Hugging Face에서 공개적으로 사용할 수 있습니다 [3].\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또 다른 이 인코더 모델의 멋진 기능은 다른 접두사를 지원한다는 것입니다. 이 모델은 [search_query, search_document, classification, clustering] 접두사를 지원하여 각 특정 하류 작업에 대해 더 나은 임베딩을 얻을 수 있습니다.\n\nnomic-embed-text-v1.5 모델이 Massive Text Embedding Benchmark (MTEB)에서 어떻게 수행되는지 살펴보겠습니다:\n\n![image](/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_4.png)\n\nPython에서 PyTorch와 Sentence Transformers 라이브러리를 사용하여 모델을 구현해 봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n!pip install torch sentence_transformers einops\n\n\n\nimport torch\nfrom sentence_transformers import SentenceTransformer\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n\nmodel = SentenceTransformer(\n    \"nomic-ai/nomic-embed-text-v1.5\",\n    device=device,\n    trust_remote_code=True,\n    prompts={\n        \"search_query\": \"search_query: \",\n        \"search_document\": \"search_document: \",\n        \"classification\": \"classification: \",\n        \"clustering\": \"clustering: \",\n    },\n)\n\n\ndef embed_sentences(\n    model: SentenceTransformer,\n    sentences: list[str],\n    prompt_name: str,\n    matryoshka_dim: int,\n    device: str,\n):\n    assert matryoshka_dim \u003c= 768, \"maximum dimension for nomic-embed-text-v1.5 is 768\"\n    embeddings = model.encode(\n        sentences, prompt_name=prompt_name, device=device, convert_to_tensor=True\n    )\n    embeddings = torch.nn.functional.layer_norm(\n        embeddings, normalized_shape=(embeddings.shape[1],)\n    )\n    embeddings = embeddings[:, :matryoshka_dim]\n    embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n    return embeddings.cpu()\n\n\nmatryoshka_dim 매개변수를 사용하여 768차원 임베딩 벡터를 자릅니다. 그런 다음 새로운 임베딩 벡터를 정규화합니다.\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 원하는 차원을 설정하고 위키피디아 텍스트와 RAG(검색 증강 생성)용 쿼리를 인코딩할 수 있습니다.\n\n```js\nmatryoshka_dim = 64\n\nwikipedia_texts = [\n    \"개(Canis familiaris 또는 Canis lupus familiaris)는 늑대의 길들여진 후손입니다.\",\n    \"알베르트 아인슈타인은 1879년 3월 14일 독일 제국의 뷔르템베르크 왕국 울름에서 태어났습니다.\",\n    \"아인슈타인은 어린 시절부터 물리학과 수학에서 뛰어나며, 곧 같은 나이의 아이들만이 보유한 수학적 전문 지식을 습득했습니다.\",\n    \"베르너 칼 하이젠베르크는 독일의 이론 물리학자로 양자역학 이론의 주요 선구자 중 한 명이며, 제2차 세계대전 중 나치 핵무기 프로그램의 주요 과학자였습니다.\",\n    \"스티븐 폴 잡스(1955년 2월 24일 - 2011년 10월 5일)는 기술 거장 애플 주식회사를 공동 창업하여 가장 잘 알려진 미국 사업가, 발명가, 투자가였습니다.\",\n    \"고양이(Felis catus), 일반적으로 가정 고양이 또는 집고양이로 불리는 것은 고양이과에서 유일하게 길들인 종입니다.\",\n]\n\nquestion = [\"알베르트 아인슈타인은 어디에서 태어났나요?\"]\n\nquestion_embedding = embed_sentences(\n    model,\n    sentences=question,\n    prompt_name=\"search_query\",\n    matryoshka_dim=matryoshka_dim,\n    device=device,\n)\n\ndocument_embeddings = embed_sentences(\n    model,\n    sentences=wikipedia_texts,\n    prompt_name=\"search_document\",\n    matryoshka_dim=matryoshka_dim,\n    device=device,\n)\n```\n\n```js\nprint(f\"document_embeddings.shape: {document_embeddings.shape}\")\nprint(f\"question_embedding.shape:  {question_embedding.shape}\")\n\u003e\u003e document_embeddings.shape: torch.Size([6, 64])\n\u003e\u003e question_embedding.shape:  torch.Size([1, 64])\n```\n\n우리는 Matryoshka 텍스트 임베딩의 첫 번째 두 차원을 산포도로 시각화할 수 있습니다. 그러나 이 임베딩 모델은 명시적으로 2차원의 Matryoshka 차원에 최적화되지는 않았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nmd\n![image](/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_5.png)\n\n다음으로, 문서 임베딩을 벡터 데이터베이스에 저장할 수 있습니다. 저는 Faiss를 사용하고 있어요. Faiss는 밀집 벡터의 효율적인 유사성 검색 및 클러스터링을 위한 Meta Research의 오픈 소스 라이브러리입니다 [4].\n\n```bash\n!pip install faiss-cpu\n```\n\n\n\n\n```python\nimport faiss\n\nindex = faiss.IndexFlatIP(matryoshka_dim)\nindex.add(document_embeddings)\n```\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 내적 제품을 사용하여 \"정확한 검색\"을 통해 벡터 데이터베이스를 만듭니다. 이때 IndexFlatIP를 사용하는데, 이는 내적 유사도 측정 방법입니다. 정규화된 임베딩을 사용하고 있기 때문에, 내적과 코사인 유사도는 동일합니다.\n\n이제 index는 여섯 개의 텍스트 임베딩으로 구성된 벡터 데이터베이스입니다:\n\n```js\nprint(index.ntotal)\n\u003e\u003e 6\n```\n\n질문과 가장 유사한 임베딩을 검색하고 상위 k개 결과를 검색해보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndistances, indices = index.search(question_embedding, k=6)\nprint(indices)\nprint(distances)\n\u003e\u003e [[1 2 3 4 0 5]]\n\u003e\u003e [[0.9633528  0.729192   0.63353264 0.62068397 0.512541   0.43155164]]\n```\n\n저희 데이터베이스에서 가장 유사한 텍스트는 인덱스 1이며 유사도 점수는 0.96입니다 (최대 점수는 1.0입니다).\n\n```js\n# d=64인 결과\nprint(question)\nprint(wikipedia_texts[1])\n\u003e\u003e ['알버트 아인슈타인은 어디에서 태어났나요?']\n\u003e\u003e '알버트 아인슈타인은 독일 제국의 퀴르템베르크 왕국 울름에서 1879년 3월 14일에 태어났습니다.'\n```\n\n저는 matryoshka_dim=768로 코드를 다시 실행했고 유사한 결과를 얻었습니다. 그러나 더 높은 차원은 더 많은 메모리와 계산이 필요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\n# 결과 d=768일 때\nprint(indices)\nprint(distances)\n\u003e\u003e [[1 2 4 3 0 5]]\n\u003e\u003e [[0.92466116 0.645744   0.54405797 0.54004824 0.39331824 0.37972206]]\n```\n\n# MRL 및 양자화\n\n더욱 압축된 임베딩을 원한다면, MRL과 이진 벡터 양자화를 함께 사용할 수 있습니다. 이진 양자화는 임베딩 벡터에서 0보다 큰 모든 숫자를 1로 변환하고 그 외의 숫자를 0으로 변환합니다 [5].\n\n\u003cimg src=\"/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_6.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이진 양자화를 사용하면 d 차원의 임베딩 벡터는 오직 d / 8 바이트의 메모리만 필요합니다. 이는 float32 형식의 d \\* 4 바이트와 비교해 크기가 32배로 줄어든 것을 의미합니다 [4]. 그러나 이 축소는 성능 저하와 함께 발생합니다.\n\n# 결론\n\nMatryoshka 손실을 사용하는 임베딩 모델은 훈련 중에 동시에 여러 임베딩 차원에 최적화되어 있습니다.\n\nMatryoshka 표현 학습을 사용하면 LLM 사용자가 텍스트 임베딩 크기를 작게 조정하여 성능 저하를 감수할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 작은 임베딩은 더 적은 메모리와 계산을 필요로하며, 이는 장기적으로 많은 비용을 절약할 수 있습니다. 또한 계산이 빨라져서 검색 속도가 빨라지기 때문에, 예를 들어 RAG 애플리케이션에 적합합니다.\n\n# 참고 자료\n\n[1] A. Kusupati 등. (2022), Matryoshka Representation Learning, arXiv:2205.13147\n\n[2] MatryoshkaLoss: https://www.sbert.net/docs/package_reference/losses.html#matryoshkaloss (접근일: 2024년 04월 05일)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[3] Hugging Face의 nomic-embed-text-v1.5: https://huggingface.co/nomic-ai/nomic-embed-text-v1.5 (접속일: 2024년 04월 05일)\n\n[4] Faiss 문서: https://github.com/facebookresearch/faiss/wiki/Getting-started (접속일: 2024년 04월 05일)\n\n[5] A. Shakir, T. Aarsen, S. Lee (2024), 바이너리 및 스칼라 임베딩 양자화로 훨씬 빠르고 저렴한 검색, Hugging Face 블로그\n","ogImage":{"url":"/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_0.png"},"coverImage":"/assets/img/2024-05-27-HowtoReduceEmbeddingSizeandIncreaseRAGRetrievalSpeed_0.png","tag":["Tech"],"readingTime":9},{"title":"차이인차이 101","description":"","date":"2024-05-27 14:54","slug":"2024-05-27-Difference-in-Difference101","content":"\n차이인차이(DiD 또는 DD 또는 diff-in-diff)는 무엇인가요? 왜 차이인차이에 관심이 있나요? 오늘은 정책 효과를 연구하는 경제학에서 가장 인기 있는 방법 중 하나에 대한 모든 질문에 답할 거예요.\n\nDiD는 처리 그룹과 대조 그룹 간의 시간에 따른 결과 변화를 비교하여 인과 관계를 추정하는 널리 사용되는 경제학 기법입니다. 처리 그룹과 대조 그룹이 무엇인지에 대한 문제가 있어요. 처리는 정책 또는 변경로 인해 특정 그룹에 영향을 미치는 정책 개입을 말해요. 대조는 개입을 받지 않은 그룹을 말해요. 인과 관계란 원인과 결과의 관계를 의미해요.\n\n우리는 이 방법에 관심을 갖는 이유는 무작위 실험이 불가능한 경우에 정책 변경이나 개입의 효과를 평가하는 데 유용하기 때문이에요. 즉, 때때로 실험은 특정 그룹에 집중되므로 처리를 받은 사람들이 무작위가 아니라는 것을 의미해요. DiD는 무작위화 없이도 개입의 영향을 분리하는 데 도움이 될 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사는 개념, 가정, 구현 및 예시 등에 대해 다룰 것입니다.\n\n# DiD란\n\n우리의 연구 질문은: 치료 D가 결과 y에 미치는 영향이 무엇인가요? DiD는 우리에게 치료 그룹이 개입되지 않았다면 치료 그룹에 무슨 일이 일어났을지를 추정할 수 있도록 해줍니다. 이 대역사적 시나리오는 치료의 실제 효과를 이해하는 데 중요합니다. 모든 직업이나 업무는 경제적 성장과 관련하여 세금 인하의 영향을 평가합니다. 또한 공공 정책 분야에서는 새 교통 법규가 사고 발생률에 미치는 영향을 평가합니다. 마케팅에서 DiD는 광고 캠페인이 매출에 미치는 영향을 분석합니다.\n\n![이미지](/assets/img/2024-05-27-Difference-in-Difference101_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 다이어그램을 예로 들어보면 샘플에서 인구 데이터가 있습니다. 여기서는 처리군과 대조군으로 데이터를 나누고 처리군은 개입을 받았습니다. 두 그룹 모두 후기와 전기 변수를 관찰할 수 있습니다.\n\n# DiD 방법\n\n## 간단한 처리/대조 차이 추정기\n\n![DiD 다이어그램](/assets/img/2024-05-27-Difference-in-Difference101_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방정식은 치료와 대조 그룹 간의 시간 경과에 따른 결과 변화를 비교하여 치료 효과를 계산할 것입니다.\n\n수학을 이해하는 데 도움이 되기 위해 가짜 예제를 만들었습니다.\n\n![다면적 효과](/assets/img/2024-05-27-Difference-in-Difference101_3.png)\n\n위에서 언급한 공식을 사용하면 DiD 계수는 9가 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## DiD Estimator: 회귀분석을 사용한 계산\n\nDiD는 처리 효과의 추정을 편향시킬 수 있는 시간 불변 특성을 제어하는 데 도움을 줍니다. 이는 시간이 지남에 따라 일정한 변수(예: 지리적 위치, 성별, 인종, 타고난 능력 등)의 영향을 제거한다는 것을 의미합니다. 그 이유는 이러한 특성이 각 그룹에 대해 전·후 처리 기간 모두 동일하게 영향을 미치기 때문입니다.\n\n기본 DiD 모델의 핵심 방정식은 다음과 같습니다:\n\n![DiD equation](/assets/img/2024-05-27-Difference-in-Difference101_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서:\n\n- y는 𝑡시간에 그룹 j의 개인 i의 결과 변수입니다.\n- 𝐴𝑓𝑡𝑒𝑟은 관측이 사후 처리 기간에 속하는 경우 1과 같은 더미 변수입니다.\n- 𝑇𝑟𝑒𝑎𝑡𝑚𝑒𝑛𝑡은 관측이 처리 그룹에 속하는 경우 1과 같은 더미 변수입니다.\n- 𝐴𝑓𝑡𝑒𝑟 × 𝑇𝑟𝑒𝑎𝑡𝑚𝑒𝑛𝑡은 상호 작용 항이며, 계수 β는 DiD 추정량을 캡처합니다.\n\n상호 작용 항의 계수는 y에서 DiD 추정량입니다. 회귀 분석은 추가 변수의 표준 오차를 제공하고 제어하는 데 도움이 되기 때문에 연구자들 사이에서 더 인기가 있습니다.\n\n# 평행 추세 가정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDiD에 대한 주요 가정 중 하나입니다. 이것은 치료가 없을 때 치료 그룹과 대조 그룹 간의 차이가 시간이 지남에 따라 일정하게 유지될 것이라는 생각에 기반을 두고 있습니다. 다시 말해, 치료가 없을 때 β (DiD 추정치)=0입니다.\n\n형식적으로, 이는 다음을 의미합니다:\n\n\n| Time        | Treatment Group | Control Group  | Difference   |\n|-------------|-----------------|----------------|--------------|\n| Before      | Y1              | Y0             | Y1 - Y0      |\n| After       | Y3              | Y2             | Y3 - Y2      |\n| DiD Estimate| (Y1 - Y0) - (Y3 - Y2)                    |\n\n\n또 다른 관점은 정책 변경이 없었을 때 두 그룹 간의 차이가 정책 변경 없이도 시간이 지남에 따라 동일하게 유지되었을 것이라는 것입니다. 치료 전에 추세가 평행하지 않으면 DiD 추정치가 편향될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 이 가정을 확인하는 방법\n\n그렇다면 다음 질문은: 어떻게 확인하는 걸까요? 평행 추세 가정의 타당성은 그래픽 분석과 플라시보 테스트를 통해 평가할 수 있습니다.\n\n![그림](/assets/img/2024-05-27-Difference-in-Difference101_6.png)\n\n이 가정은 치료가 적용되지 않은 경우 치료 그룹(주황색 선)과 대조 그룹(파란 점선)이 시간이 지남에 따라 평행한 경로를 따를 것이라는 것입니다. 치료(수직 선)는 치료가 적용되는 지점을 나타내며, 치료 전후에 두 그룹 간의 추세 차이를 비교하여 치료 효과를 추정할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 평행 추세 가정을 위반하는 예시\n\n간단히 말해서, 우리는 치료에서 두 가지를 찾습니다:\n\n- 기울기의 변화\n\n![image](/assets/img/2024-05-27-Difference-in-Difference101_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-27-Difference-in-Difference101_8.png)\n\n위 두 경우 모두 평행한 추세 가정이 만족되지 않습니다. 치료 그룹 결과는 통제 그룹 결과보다 더 빨리 성장하거나(part a) 더 느리게 성장합니다(part b). 이를 수학적으로 표현하면 다음과 같습니다:\n\nDiD = 실제 효과 + 차이 추세 (차이 추세는 0이어야 함)\n\n차이 추세는 양수 (part a) 또는 음수 (part b)일 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDiD는 우리가 그것에 대한 차별적인 경향을 가지고 있기 때문에 개입의 영향을 분리할 수 없을 것입니다.\n\n2. 개입 이후의 치료 라인에서의 점프(상승 또는 하락)\n\n![image](/assets/img/2024-05-27-Difference-in-Difference101_9.png)\n\n위의 이미지에서 처리 그룹의 경향이 통제 그룹의 경향과 다르게 변경되어, 개입 없이 일정하게 유지되어야 했던 것과 다릅니다. DiD 연구에서는 점프가 허용되지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Placebo Tests\n\nPlacebo 테스트는 관측된 치료 효과가 실제로 치료로 인한 것이 아니라 다른 혼재 요소로 인한 것인지 확인하는 데 사용됩니다. 이는 치료 효과가 예상되지 않는 기간이나 그룹에 동일한 분석을 적용하는 것을 포함합니다. 이러한 플레이스보 테스트에서 유의한 효과가 발견되면, 원래 결과가 잘못된 것일 가능성이 있습니다.\n\n예를 들어, 2019년에 고등학교에 알약을 제공하는 개입 연구가 수행되었습니다. 우리는 플레이스보 테스트를 수행할 수 있어서 2017년이라는 가짜 개입 연도를 만들 수 있습니다. 여기서는 정책 변경이 발생하지 않았다는 것을 알고 있습니다. 플레이스보 날짜 (2017년)에 치료 효과 분석을 적용해도 유의미한 변화가 없는 경우, 2019년에 관측된 효과가 (있는 경우) 실제 정책 개입으로 인한 것일 가능성이 높습니다.\n\n# Extensions and Variations of DiD\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이벤트 스터디 DiD: 연도별 처리 효과를 추정하여 처리 효과의 타이밍을 평가하고 사전 추세를 확인하는 데 유용합니다. 이 모델은 연도별 처리 효과를 다양하게 설정할 수 있습니다. 우리는 t+1, t+2, ..., t+n 시점에서 효과를 연구할 수 있습니다.\n- 합성 대조법(SCM): SCM은 여러 비치료 단위에 가중치를 부여하여 치료 전 특성을 근사하는 합성 대조 그룹을 구성합니다. 이 방법은 단일 처리 단위와 비치료 단위 집단을 비교할 때 특히 유용합니다. 여러 단위의 정보를 결합하여 믿을 수 있는 대조 사실을 제시합니다.\n\n이외에도 많은 방법이 있지만, 여기서는 두 가지만 소개하겠습니다. 나중에 더 자세히 설명하는 글을 쓸 수도 있겠네요.\n\n# 결론\n\n본 글에서는 평균 처리 효과를 추정하는 인기 있는 방법인 Difference-in-Differences (DiD) 추정기법을 분석했습니다. DiD는 처리 및 통제 그룹 간 시간 경과에 따른 변화를 비교함으로써 정책 효과를 연구하는 데 널리 사용됩니다. DiD의 주요 장점은 시간이 지남에 따라 일정하게 유지되는 관측되지 않은 혼입변수를 통제하여 개입의 실제 영향을 분리할 수 있는 능력입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 평행 추세 가정, 전처리 데이터의 중요성, 그리고 시각적 분석과 장소보 테스트를 사용하여 가정 위반을 확인하는 방법과 같은 주요 개념을 탐구했습니다. 게다가, 이원차 차이-DiD의 확장과 변형인 이벤트 스터디 DiD 및 합성 통제 방법에 대해 이야기했는데, 이는 다양한 시나리오에서 추가 통찰력과 견고성을 제공합니다.\n\n# 참고문헌 및 추가 자료\n\n[1] Wing, C., Simon, K., \u0026 Bello-Gomez, R. A. (2018). 차이-DiD 연구 설계: 공공 보건 정책 연구를 위한 모범 사례. 공공 보건 연례 보고서, 39, 453–469.\n\n[2] Callaway, B., \u0026 Sant’Anna, P. H. (2021). 다중 시간 기간을 갖는 차이-차이 방법. 계량경제학 잡지, 225(2), 200–230.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[3] Donald, S. G., \u0026 Lang, K. (2007). Inference with difference-in-differences and other panel data. The review of Economics and Statistics, 89(2), 221–233.\n\n## 읽어 주셔서 감사합니다!\n\n읽어 주셔서 감사합니다! 🤗 만약 이 게시물을 즐겼고 더 많은 것을 보고 싶다면 팔로우해주세요. 또한 LinkedIn에서도 팔로우할 수 있습니다. 인과 추론 및 데이터 분석에 관한 블로그를 쓸 계획이며, 항상 단순하게 유지하려고 노력합니다.\n\n소소한 주의: 학습을 위해 쓰기 때문에 최선을 다하겠지만 실수가 발생할 수 있습니다. 오류를 발견하시면 알려주세요. 또한 새로운 주제에 대한 제안을 환영합니다!\n","ogImage":{"url":"/assets/img/2024-05-27-Difference-in-Difference101_0.png"},"coverImage":"/assets/img/2024-05-27-Difference-in-Difference101_0.png","tag":["Tech"],"readingTime":6},{"title":"Ollama를 사용하여 모델 실행하기 단계별 안내","description":"","date":"2024-05-27 14:51","slug":"2024-05-27-RunningmodelswithOllamastep-by-step","content":"\n\nLLM을 빠르게 테스트할 수 있는 방법을 찾고 계신가요? 전체 인프라를 설정할 필요 없이 테스트할 수 있는 방법이 있다면 정말 훌륭하죠. 이 짧은 기사에서 우리가 할 일이 바로 그거에요.\n\n![이미지](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_0.png)\n\nOllama에 관해 경험이 있는 경우에는 특정 단락으로 이동해도 됩니다. 이 기사에서 찾을 수 있는 내용은 다음과 같아요:\n\n- Ollama가 무엇인가요?\n- Windows에 Ollama 설치하기.\n- Ollama [cmd] 실행하기.\n- 로컬로 모델 다운로드하기.\n- 다양한 용도에 맞는 다른 모델.\n- 모델 실행하기 [cmd].\n- CPU에 친화적인 양자화된 모델.\n- 다른 소스에서 모델 통합하기.\n- Ollama-파워드 (Python) 앱으로 개발자들의 삶을 더 쉽게 만들기.\n- 요약.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1. Ollama이란?\n\nOllama는 오픈 소스 코드로, 로컬에서 또는 본인의 서버에서 언어 모델과의 원활한 통합을 가능하게 하는 사용 준비 도구입니다. 이를 통해 상업용 API의 유료 버전을 사용하지 않아도 되므로, 특히 이제 Meta가 Llama2 모델을 상용으로 사용 가능하게 한 것을 고려하면, 자신의 데이터셋에서 추가 학습에 적합합니다.\n\n➡️ GitHub 저장소: https://github.com/ollama/ollama\n\n➡️ Ollama 공식 웹페이지: https://ollama.com\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_1.png)\n\n# 2. Windows에서 Ollama 설치하기\n\nOllama는 Windows, Mac 및 Linux에서도 원활하게 작동합니다. 이 간단한 자습서는 특히 Windows 10용 설치 단계를 안내합니다. 설치 후 프로그램은 약 384MB를 차지합니다. 그러나 다운로드한 모델이 가벼운 것은 아닐 수 있습니다.\n\n만약 도커 컨테이너에서 Ollama를 실행하길 원한다면, 아래 설명을 건너뛰고 \n\n감십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n➡️ https://ollama.com/blog/ollama-is-now-available-as-an-official-docker-image\n\n![Running Models with Ollama](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_2.png)\n\n➡️ Ollama 홈페이지로 이동하여 .exe 파일을 다운로드하세요: https://ollama.com\n\n![Running Models with Ollama](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOllama를 다운로드하고 Windows에 설치하세요. 보통 다음 경로에 위치한 기본 모델 저장 경로를 사용할 수 있습니다:\n\n```js\nC:\\Users\\your_user\\.ollama\n```\n\n그러나 C: 파티션에 공간이 제한적이라면, 대안 디렉토리로 전환하는 것이 권장됩니다. D:\\와 같은 다른 파티션이 있는 경우, 간단하게:\n\n- 데스크탑의 컴퓨터 아이콘을 마우스 오른쪽 클릭합니다.\n- 속성을 선택한 후 \"고급 시스템 설정\"으로 이동합니다.\n- 환경 변수를 클릭합니다.\n- ...을 위한 사용자 변수에서 모델을 저장할 디렉토리의 절대 경로를 삽입하십시오. 예를 들면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n변수: OLLAMA_MODELS\n값: D:\\your_directory\\models\n```\n\nOLLAMA_MODELS 변수의 이름을 변경하지 마십시오. 이 변수는 Ollama가 정확히 아래와 같이 검색할 것입니다.\n\nWindows의 하단 표시줄에 Ollama 아이콘이 나타납니다. 프로그램이 시작되지 않으면 Windows 프로그램에서 찾아서 거기서 시작하십시오.\n\n\u003cimg src=\"/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_4.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 Ollama를 실행하고 모델을 다운로드할 준비가 되었어요 :)\n\n# 3. Ollama 실행하기 [cmd]\n\n![image](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_5.png)\n\nOllama를 설정하고 나면 윈도우에서 cmd(명령줄)를 열고 로컬로 일부 모델을 다운로드할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOllama 로컬 대시보드를 사용하려면 웹 브라우저에서 다음 URL을 입력하세요:\n\n```js\nhttp://localhost:11434/api/\n```\n\nOllama를 실행하는 것은 그렇게 어렵지 않습니다. 나중에 CMD 및 Python 코드를 통해 어떻게 활용하는지 알아보겠습니다.\n\n중요한 몇 가지 명령어:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로컬로 사용 가능한 모델을 확인하려면 다음을 cmd에 입력하세요:\n\n```js\nollama list\n```\n\n특정 모델에 해당하는 SHA 파일을 확인하려면 cmd에 입력하세요 (예: llama2:7b 모델 확인을 위한 예시):\n\n```js\nollama show --modelfile llama2:7b\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델을 제거하려면:\n\n```js\nollama rm llama2:7b\n```\n\n모델을 서버에 올리려면:\n\n```js\nollama serve\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4. 모델을 로컬로 다운로드하기\n\n웹사이트 ➡️ https://ollama.com/library 에서는 여러 다양한 파라미터 크기로 제공되는 다수의 모델을 다운로드할 수 있습니다.\n\n로컬로 모델을 다운로드하기 전에, 해당 모델을 로딩할 충분한 메모리를 가지고 있는지 확인해주세요. 테스트할 때는 애플리케이션에 통합하기에 적합한 작은 모델인 '7B'로 레이블이 지정된 모델을 사용하는 것이 좋습니다.\n\n⚠️ 부드러운 모델 작동을 위해 적어도 하나의 GPU를 보유하는 것이 강력하게 권장됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래에는 내가 테스트하고 추천하는 여러 모델이 있습니다. 명령을 복사하여 명령 프롬프트에 붙여넣어 지정된 모델을 로컬로 가져올 수 있습니다.\n\n👉Meta에서의 Llama2 모델\n\n대화 시나리오를 위해 최적화된 생성 텍스트 모델 세트입니다. Ollama의 많은 모델과 마찬가지로 Llama2는 다양한 구성으로 제공됩니다:\n\n![image](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 해당 모델을 가져오는 몇 가지 예시입니다:\n\n표준 모델:\n\n```js\nollama pull llama2\n```\n\n검열되지 않은 버전:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nollama pull llama2-비겁하지 않은:7b\n```\n\n채팅 7B 모델:\n\n```js\nollama pull llama2:7b-채팅\n```\n\n➡️ 더 읽기: https://llama.meta.com/llama2\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n👉 구글의 젬마\n\n주요 7B 크기 모델과 유사한 견고한 성능을 제공하는 오픈 소스 모델입니다.\n\n```js\nollama pull gemma:7b\n```\n\n➡️ 자세히 보기: https://blog.google/technology/developers/gemma-open-models/\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n👉 Haotian Liu 등의 LLava.\n\n이미지에서 텍스트 설명을 다루는 데 뛰어나며 시각 및 언어 모델 모두에 대한 견고한 지원을 제공하는 멀티모달 모델입니다.\n\n```js\nollama pull llava\n```\n\n➡️ 자세히 알아보기: https://llava-vl.github.io/\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 서로 다른 목적을 위한 다양한 모델\n\n![이미지](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_7.png)\n\n일부 모델은 특정 데이터셋에서 훈련되어 코드 완성, 대화 또는 이미지에서 텍스트로 변환과 같은 특정 작업에 더 적합합니다. Ollama에서는 다양한 목적을 위해 설계된 모델을 찾을 수 있습니다.\n\n첫 번째 그룹은 대화, 텍스트 완성, 요약 등을 용이하게 하는 데 초점을 맞춘 모델을 포함하고 있습니다. Gemma, Llama2, Falcon 또는 OpenChat과 같은 모델이 포함됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일부 예시:\n\n- [Falcon](https://ollama.com/library/falcon)\n\n- [Gemma](https://ollama.com/library/gemma)\n\n- [Openchat](https://ollama.com/library/openchat)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 그룹은 대화를 나누거나 챗봇 역할을 하는 다중 모달 모델과 이미지 설명(시각 모델), 텍스트 요약, 질문-답변(Q/A) 애플리케이션을 구동할 수 있는 모델들로 구성됩니다.\n\n일부 예시:\n\n➡️ https://ollama.com/library/llava\n\n➡️ https://ollama.com/library/bakllava\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 매우 전문화된 그룹은 Ollama에서 이용 가능한 모델을 활용하여 개발자의 작업을 지원합니다. 코델라마, 돌핀-미스트랄, 돌핀-믹스트랄(코딩 작업에 능숙한 Mixtral 전문가 모델을 기반으로 세밀하게 조정된 모델)과 같은 모델들이 있으며, 계속해서 크리에이터들이 추가하고 있습니다.\n\n몇 가지 예시:\n\n➡️ https://ollama.com/library/codellama\n\n➡️ https://ollama.com/library/dolphin-mistral\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n➡️ https://ollama.com/library/dolphin-mixtral\n\n# 6. 모델 실행하기 [cmd]\n\n다운로드한 모델을 실행하려면, ollama run 모델이름:파라미터 \"당신의 프롬프트\"를 입력하세요. 예를 들어:\n\n```js\nollama run llama2:7b \"당신의 프롬프트\"\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다중 모달 모델을 사용하면 기본 프롬프트를 벗어난 파일, 로컬 이미지 경로 등을 포함할 수 있어 더 많은 기능을 확장할 수 있습니다.\n\n# 6. CPU 친화적 양자화 모델\n\n양자화는 모델의 정밀도를 유지하는 비용을 줄이는 것으로 관련 비용을 줄이는 것입니다. 이 과정 뒤에 숨은 직관력을 구축하는 데 도움이 되는 이 크고 훌륭한 기사에서 자세한 설명을 찾아볼 수 있습니다:\n\n📃 양자화 LLMs란 무엇인가? (Miguel Carreira Neves의 글):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n➡️ https://www.tensorops.ai/post/what-are-quantized-llms\n\n추가 자료:\n\n📃 Extreme Compression of Large Language Models via Additive Quantization:\n\n➡️ https://arxiv.org/html/2401.06118v2\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n📃 SmoothQuant: 대형 언어 모델을 위한 정확하고 효율적인 사후 훈련 양자화:\n\n➡️ [논문 링크](https://arxiv.org/pdf/2211.10438.pdf)\n\n📃 BiLLM: LLMs를 위한 사후 훈련 양자화 한계 돌파:\n\n➡️ [논문 링크](https://arxiv.org/pdf/2402.04291.pdf)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단하게 말하면, 양자화는 가중치 정밀도를 조정하여 모델 크기를 줄이고 중요한 정확도 하락 없이 성능을 쉽게 감소시킬 수 있는 하드웨어에서 실행할 수 있게 해줍니다.\n\n이 글과 함께 제공된 이미지를 통해 양자화 후에 모델이 원래 버전보다 상당히 적은 공간을 차지하는 것을 확인할 수 있습니다:\n\n![Quantized Models](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_8.png)\n\nOllama는 양자화된 모델을 지원하여 별도로 처리하는 부담을 덜어줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 7. 다른 소스에서 모델 통합하기\n\n![Running Models With Ollama Step-by-Step](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_9.png)\n\nOllama의 모델은 다양성을 제공하지만 현재 모든 모델에 액세스할 수 있는 것은 아닙니다. 그러나 로컬에 직접 모델을 통합하는 것은 간단한 프로세스입니다. 새로운 모델을 지역 Ollama에 통합하는 방법을 알아봅시다.\n\nThe Bloke의 HuggingFace 계정에서 많은 양자화된 모델을 사용할 수 있습니다. 의학 논문을 위해서 우리는 편리하게 medicine-chat-GGUF 모델을 선택할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n➡️ https://huggingface.co/TheBloke/medicine-chat-GGUF\n\n해당 링크를 열고 파일 및 버전을 클릭하세요.\n\n![Files and versions](/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_10.png)\n\nOllama 모델에 포함하고 싶은 모델을 다운로드하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_11.png\" /\u003e\n\nModelfile이라는 빈 파일을 생성하고 아래 지정된 데이터를 삽입하세요 (저장된 모델의 절대 경로로 경로를 대체하십시오). 이 예제는 기본적이며, 모델의 온도, 시스템 메시지 등과 같은 여러 옵션을 포함하여 확장될 수 있습니다. 필요한 경우 파일에서 '#'를 제거하여 해당 옵션을 활성화하세요.\n\n```js\nFROM D:\\...\\medicine-chat.Q4_0.gguf\n# PARAMETER 온도 0.6\n# SYSTEM \"\"\"도움이 되는 의학 조수입니다.\"\"\"\n```\n\nModelfile을 저장한 후, cmd에 다음을 입력하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```bash\nollama create 모델_이름 -f 모델_파일\n```\n\n# 9. Ollama를 활용한 (Python) 앱으로 개발자의 삶을 더 쉽게 만들기\n\n백그라운드에서 실행되는 Ollama는 일반적인 REST API와 같이 접근할 수 있습니다. 따라서 requests와 같은 라이브러리 또는 조금 더 발전된 FastAPI, Flask 또는 Django와 같은 프레임워크를 사용하여 응용 프로그램에 쉽게 통합할 수 있습니다.\n\nOllama python 패키지를 쉽게 pip를 통해 설치하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n⬆️ https://pypi.org/project/ollama/0.1.3:\n\n```js\npip install ollama\n```\n\nPython 코드를 통해 임베딩을 생성하는 방법:\n\n```js\nimport ollama\n\nembedding = ollama.embeddings(model=\"llama2:7b\", prompt=\"Hello Ollama!\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단히 CURL을 사용하여:\n\n```js\ncurl http://localhost:11434/api/embeddings -d '{\n  \"model\": \"llama2:7b\",\n  \"prompt\": \"Here is an article about llamas...\"\n}'\n```\n\nOllama 엔드포인트에 대해 더 알아보려면 다음 링크를 방문해주세요:\n\n➡️ https://github.com/ollama/ollama/blob/main/docs/api.md\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOllama가 Langchain 프레임워크에 원활하게 통합되어 개발 노력을 최적화하고 기술 측면의 작업을 더욱 간편하게 만들었습니다:\n\n➡️ https://python.langchain.com/docs/integrations/llms/ollama\n\n임베딩을 만드는 간단함을 감상해보세요:\n\n```js\n# pip install langchain_community\nfrom langchain_community.embeddings import OllamaEmbeddings\n\n\nembed = OllamaEmbeddings(model=\"llama2:7b\")\nembedding = embed.embed_query(\"Hello Ollama!\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 10. 요약\n\n본 기사는 당신을 Ollama를 사용하여 모델을 실행하는 과정을 단계별로 안내하여, 전체 인프라 구성 없이 LLM을 테스트할 수 있는 원활한 방법을 제공합니다.\n\n올라마는 오픈 소스 도구로, Meta의 Llama2 모델을 무료로 사용할 수 있게 해주는 로컬 또는 서버 기반의 언어 모델 통합을 용이하게 합니다. 윈도우에서의 설치 과정과 명령줄을 통해 Ollama를 실행하는 방법에 대해 설명되어 있습니다.\n\n이 기사에서는 모델 다운로드, 특정 작업을 위한 다양한 모델 옵션, 다양한 명령어를 사용하여 모델 실행, CPU 친화적인 양자화된 모델, 그리고 외부 모델 통합에 대해 탐구합니다. 또한, 개발자들을 위해 Ollama를 활용한 파이썬 애플리케이션을 강조하고 있습니다.","ogImage":{"url":"/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_0.png"},"coverImage":"/assets/img/2024-05-27-RunningmodelswithOllamastep-by-step_0.png","tag":["Tech"],"readingTime":10},{"title":"AI가 다물고 보니 연기와 거울일까요","description":"","date":"2024-05-27 14:49","slug":"2024-05-27-HowDoWeKnowifAIIsSmokeandMirrors","content":"\n\n## \"AI 혁명\"이 인쇄 기계인지, 암호폐인지에 대한 사려 (스포일러: 둘 다 아님)\n\n![image](/assets/img/2024-05-27-HowDoWeKnowifAIIsSmokeandMirrors_0.png)\n\n나는 AI의 출현이 우리 세계에 미치는 의미에 대해 진지하게 고민한 첫 번째 사람은 아닙니다. 하지만 아직도 이 질문이 계속해서 제기되고 토론되고 있다는 것은 알 수 있습니다. 그러나 대부분의 이런 대화들은 관련 핵심 요인들을 빼먹는 것으로 보입니다.\n\n시작하기 전에, 최근에 나의 사고를 형성시킨 이 문제의 다양한 측면을 보여주는 3가지 일화를 알려드리겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 최근 금융 컨설턴트와 대화를 나누었어요. 그는 그의 기관의 임원들이 AI가 경제 장면에서 실질적인 변화라고 말하며, 투자 전략은 혁명적으로 취급해야 한다는 조언을 전했다고 언급했어요. 그는 머신러닝 산업의 실무자로서 내 생각을 알고 싶어했죠. 나는 친구들과 독자들에게 이전에 말해왔던 대로, 지나치게 과대 퍼징된 혹은 진짜 가치를 알아보려고 기다리고 있다고 말했어요. 혹은 단지 허무주의 사이클이나 순식간의 현상이 아니다. 이 혹은 사이클은 아직도 진행 중이에요.\n\n- 이번 주에는 'Tech Won’t Save Us'의 에피소드를 듣았어요. 거기서는 기술 저널리즘과 Kara Swisher에 관한 이야기가 있었어요. 게스트인 Edward Ongweso Jr.는 Swisher가 새로운 기술에 대해 신중하지 않고, 그 새로운 기술이 약속한 것만큼 인상적이거나 혁명적이 아니라는 것이 입증되면 태도를 변경한다고 말했죠(자율 주행 자동차, 암호화폐 등을 참조). 그는 이번에도 그녀와 같은 현상이 AI에 대해 일어나고 있다고 생각했어요.\n\n- 제 동반자와 저는 둘 다 기술 분야에서 일하고 있어서 주기적으로 기술 뉴스에 대해 이야기를 나눠요. 그는 한 번 어떤 전문가나 기술 사상가가 자신이 잘 알지 못하는 주제에 대해 매우 현명한 통찰을 보여주면서 멋지다고 한 적이 있다고 언급했어요. 그러나 그들이 자신의 전문 분야에 대해 이야기하기 시작하면 갑자기 그들의 판단이 틀렸다는 것을 깨닫게 된다고 했어요. 그때 \"이 부분에 대해 틀렸다는 것을 알고 있어요. 그들이 저것에 대해서도 틀렸을까요?\"라고 고민할 때가 있다고 해요. 요즘 가끔씩 머신러닝에 관한 이런 경험을 하고 있어요.\n\n새로운 기술들이 어떻게 안착할지, 그리고 그들이 우리 사회에 미칠 장기적인 영향이 어떻게 될지 정말 어려워요. 역사학자들은 \"이 이벤트가 발생할 수 있는 유일한 방법이 '이것'이었을 것이다\"라고 가정하고 돌이킬 수 없이 계속 나아간 것처럼 보이지만, 실제로는 현재에는 누구도 그 다음에 무슨 일이 일어날지 알지 못하며, 일어날 수 있는 많은 사건이 있었으며, 그것이 최종적으로 실제로 일어난 것보다 더 나거나 덜 가능한 변화를 가져올 수 있었어요.\n\n# 요약\n\nAI는 완전한 사기가 아니에요. 머신러닝은 정말 복잡한 작업을 자동화하고 효과적으로 확장할 수 있는 기회를 제공해줘요. AI가 우리 세계와 경제 전반에 모든 것을 바꿀 것이라는 것은 아니에요. 그것은 도구이지만, 대부분의 경우 인간 노동을 대체하지는 않을 거에요. 그리고 AGI가 현실적인 전망이 아니에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n왜 말하느냐면, 설명해 드릴게요.\n\n먼저, 기계 학습은 정말 대단한 기술이에요. 사람들이 직접 파악하기에 너무 복잡한 패턴의 미묘한 점들을 기계에 가르치는 것은 매력적이라고 생각해요. 그리고 이를 통해 컴퓨터가 문제를 해결할 수 있는 다양한 기회가 열리는 것을 만들어내는데 도움이 된다고 생각해요. 기계 학습은 이미 우리 삶에 다양한 방식으로 영향을 미치고 있으며, 수년간 그 영향을 주고 있어요. 사람에겐 지루하거나 거의 불가능한 작업을 완료할 수 있는 모델을 개발하고, 그것이 동료들의 문제를 해결하는 데 사용될 때, 정말 만족스러워요. 이것은 생성적 인공지능 영역에서 이루어지는 혁신적인 일들 중 한 가지 아주 작은 단위에 불과하지만, 넓은 우산 아래에서 이루어지고 있어요.\n\n# 기대\n\n일반 대중과 기계 학습 전문가들에게 AI가 의미하는 것에 대해 이야기하면 두 그림이 매우 다르게 나올 거에요. 이에 대해 이전에 글을 썼지만, 여기서 다시 언급할 필요가 있어요. 우리는 AI에 어떤 것을 기대하고 있나요? 우리가 \"인공지능\"이라는 용어를 사용할 때 어떤 의미를 부여하고 있나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n나에게 있어 인공지능은 기본적으로 \"머신 러닝 모델을 사용하여 작업을 자동화하는 것\"입니다. 그 이상도 이하도 아냐. 머신 러닝 모델이 매우 복잡하다면 어떤 복잡한 작업을 자동화할 수 있지만, 비교적 한정된 작업을 하는 작은 모델들도 여전히 이에 포함됩니다. 머신 럽엥 모델이 정말 무엇을 하는지에 대해 길게 쓰긴 했지만, 간단히 말하면: 데이터에서 패턴을 수학적으로 분석하고 재현하는 것이죠. 그러니까, 우리는 데이터의 패턴을 수학적으로 나타낸 것을 사용하여 작업을 자동화하는 것입니다. 인공지능은 우리가 기록된 역사의 사건 패턴을 바탕으로 다음 단계를 선택하는 것이다, 사람들이 쓴 텍스트의 역사, 주택 가격의 역사 또는 그 외 다른 모든 것의 역사일지라도 말이에요.\n\n그러나 많은 사람들에게는 인공지능은 더 복잡한 것을 의미하는 경우가 많아요, 약간과학 판타지 수준에서 이해될 때도 있어요. 경우에 따라서 인공지능과 AGI(인공일반지능) 사이의 선을 흐리게 만들기도 하는데, 이것은 우리의 대화에서도 제대로 정의되지 않은 부분이 있죠. 종종 사람들 스스로도 이 용어가 정확히 무엇을 의미하는지 모르겠다고 생각하지만, 현실이 제공하는 것보다 훨씬 더 정교하고 보편적인 것을 예상하는 느낌을 받아요.\n\n예를 들어, LLM은 인간 언어의 구문과 문법을 이해하지만 실질적인 의미 개념은 갖고 있지 않아요. LLM이 아는 모든 것은 내부적 연관성에 의해 정해져요 — \"왕\"은 LLM에게는 \"여왕\"이나 \"남자\"와 같은 다른 단어와의 관계에 의해 정의됩니다. 그래서 언어나 의미 문제를 돕기 위한 모델이 필요하다면 그건 괜찮아요. 동의어를 요구하거나 특정 주제와 관련된 단어들로 가득한 단락을 축적하도록 요청하더라도, 그런 모델은 잘 할 거예요.\n\n하지만 이것과 \"지식\" 사이에는 뚜렷한 차이가 있어요. 바위를 던져보면 ChatGPT가 사실을 제대로 이해하지 못하고 항상 환각한다고 하는 소셜 미디어 쓰레드를 찾을 수 있어요. ChatGPT는 결코 \"사실을 생산하는 로봇\"이 아니에요. 그저 큰 언어 모델일 뿐이에요. 언어를 다룹니다. 지식은 실제 사실 이상의 것이며, 사실이 무엇을 의미하는지 이해하는 엔티티를 의미하며 더 많은 것을 포함하고 있어요. 현재의 방법론과 우리에게 제공되는 기술을 사용해서 머신 러닝 모델이 이 수준에 이르는 것에 대한 위험은 없어요. 몇몇 사람들이 현재의 방법과 기술을 사용하면 \"AGI\"라고 불리는 것에 도달할 것이라 지적하는 것들이 있지만 말이죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 사람들이 ChatGPT를 보고 AGI를 원한다면, 정보나 현실에 대한 이해력이 사람들과 동등하거나 더 뛰어난 기계 학습 모델 형태를 원하는 것은 완전히 현실적이지 않은 기대일 것입니다. (참고: 이 산업 분야에서는 AGI의 임박한 도래를 허세 부리며 PR에 강조하지만, 압박 당하면 AGI의 정의를 현실적인 것으로 크게 변경하여 자신들의 과대광고에 대한 책임을 피하려고 할 것입니다.)\n\nAI가 혁명적일 것이라는 나의 회의에 직면해서, 나의 금융 자문가는 fast food 레스토랑이 차 드라이브스루에서 음성 인식 AI로 전환하여 고객들이 자동차 안에서 하는 말을 이해하지 못하는 인간 작업자로 인한 문제를 줄이는 사례를 언급했습니다. 이것은 흥미로울 수 있지만, 전혀 깨달음적인 것은 아닙니다. 이것은 사람들이 일을 조금 더 잘할 수 있도록 도와주는 도구로써의 기계 학습 모델입니다. 이것은 생성적 AI 세계에만 해당되는 것은 아닙니다! 우리는 10년 이상 동안 기계 학습을 사용하여 작업을 자동화하고 인간 노동을 줄이고 있으며, LLMs를 추가하는 것은 정도의 차이이며, 급격한 변화가 아닙니다.\n\n내가 말하려는 바는 기계 학습을 사용함으로써 우리가 많은 일을 수행하는 속도와 효율성에서 점진적인 개선을 얻을 수 있다는 것이며, 우리의 기대는 이러한 모델이 무엇인지와 그들이 아닌 것을 실제로 이해하고 그에 따라 형성되어야 합니다.\n\n# 실용적인 한계\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아마 여러분은 내 첫 번째 주장이 현재 모델 훈련을 위한 기술 능력과 오늘 사용되는 방법에 기반한다는 것을 생각하실 수도 있고, 그것은 합리적인 의견입니다. 훈련과 기술을 계속 발전시켜 더 복잡한 생성 모델을 만들어내는 경우, 아주 새로운 것이 만들어질 수 있는 시점에 도달할까요? 우리가 더 이상 \"AGI\"라고 말하는 것이 만들어질 수 있는 시점에 도달할까요? 하늘은 끝이 없는 범위가 아니라고요?\n\n문제에 대한 솔루션으로 기계 학습의 잠재력은 그 잠재력을 실현할 수 있는 능력과 매우 다릅니다. 무한한 자원 (돈, 전기, 칩용 희귀 희토류, 훈련을 위한 인간 생성 콘텐츠 등)이 있다면, 기계 학습으로부터 얻을 수 있는 한 가지 수준의 패턴 표현이 있을 수 있습니다. 그러나 실제로 우리가 살고 있는 현실 세계에서 이러한 모든 자원은 상당히 한정적이며, 이들의 한계에 마주치고 있습니다.\n\n우리는 이미 수 년간 LLM을 훈련할 품질 데이터가 부족하다는 것을 알고 있으며, 생성된 데이터를 훈련 데이터로 다시 사용하는 시도는 매우 문제가 많습니다. (생성된 다른 AI의 출력에서 심각히 훈련받은 \"하브스부르크 AI\" 또는 \"비정상적이고 기이한 특징을 갖춘 근원적인 돌연변이와 같이 될 수 있는 시스템을 발명한 Jathan Sadowski에게 감사를 표합니다) 경우에 따라 생성된 데이터와 유기적 데이터를 구별하는 역량이 부족하다는 점을 언급하는 것도 중요하다고 생각합니다. 이러한 이유로 우리가 하브스부르크 AI를 만들고 있다는 것을 알 수도 없을 수 있으며, 그렇게 되는 과정에서 나타나는 퇴화 현상은 우리에게 점진적으로 다가올 수 있습니다.\n\n오늘은 돈/에너지/금속의 제약 사항에 대해 논의하는 것을 건너뛸 것이며 AI의 자연 자원 및 에너지 영향에 대해 다른 글을 계획 중이기 때문입니다. 하지만 전력 소비에 대한 논의를 위해 Verge로 이동해보세요. 우리는 모두 에너지가 무한한 자원이 아님을 알고 있습니다, 심지어 재생 가능 에너지도 마찬가지이며, 우리는 이미 소규모 국가에 해당하는 전기 소비를 기계 모델 훈련에 투입하고 있습니다 - AI 거래꾼들이 과대 광고한 것에 접근하지 못하는 모델입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n나는 AI 기업들이 직면하는 규제 및 법적 도전들이 가능성이 있다고 생각해요. 이전에도 썼었지만, 이 문제는 그들이 할 수 있는 일에 제한을 둘 수밖에 없을 거에요. 어떤 기관도 법 위에 있어서나 제한 없이 존재해서는 안 되고, 지구의 자연 자원을 모두 낭비하여 AGI를 만들려고 하는 것은 혐오스럽다고 생각해요.\n\n내 의견은 이론적으로 어떤 일을 할 수 있다는 것과 실제로 우리가 할 수 있는 일이 같다는 건 아니다라는 거에요. 무한한 은행 계좌, 광물 광산 및 데이터 소스가 있다고 해도 머신 러닝이 이러한 제약 없이 AGI를 달성할 수 있다고 믿지 않아요. 일부는 훈련을 수행하는 방식 때문에, 실제 세계의 조건하에서는 저런 것을 이루기 어려울 것이라는 건 잘 알고 있어요.\n\n만약 AGI에 대해 걱정하지 않고 우리가 실제로 가진 모델에 집중한다면, 자원 할당은 여전히 실질적인 문제에요. 인기 문화에서 AI라고 하는 것이 정말로 “기계 학습 모델을 사용하여 작업을 자동화하는“ 것 뿐이라는 걸 언급했듯이, 그렇게 들리진 않죠. 더 중요한 건, 이 작업이 단일체가 아니라는 것을 드러내주죠. AI는 하나의 것이 아니라, 모든 곳에 흩어져 있는 수백만 개의 작은 모델들이며, 이들은 자원을 소비하여 작업을 완료하기 위해 사용하는 워크플로 및 파이프라인에 삽입되는 거에요. 우리는 이러한 작업에 삽입하기 위해 잠재적인 선택지인 LLMs를 추가하고 있지만, 이것이 프로세스를 다르게 만드는 것은 아니에요.\n\n비즈니스를 설득하고, 자원을 확보하고, 모델을 구축하고 유지하는 데 필요한 일을 경험해본 사람으로서, 이 작업이 “할 수 있는 건가?”보다는 실제로는 “우선순위와 제한된 자원과 경쟁 속에서 이것을 하는 게 옳은 일인가?”라는 게 진짜 문제에요. 종종, 모델을 구축하고 작업을 자동화하는 데 구현하는 것은 회사의 시간과 돈을 쓸 가치 있는 방법이 아니라서 프로젝트가 쓰여질 수도 있다는 거죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n기계 학습과 그 결과물은 정말 멋지고, 잘 활용된다면 문제 해결과 인간 삶의 개선에 큰 잠재력을 제공합니다. 그러나 이것은 새로운 것이 아니며, 공짜는 없다는 것을 명심해야 합니다. 우리 사회의 다양한 분야에서 기계 학습의 적용이 계속해서 확대될 것으로 보입니다. 이것은 지난 10년 이상 동안 계속된 것처럼 더 이상 놀라운 일이 아닙니다. AI 생성 기술을 도구상자에 추가하는 것은 차이의 문제에 불과합니다.\n\nAGI는 현재 완전히 다른 상상 속의 존재입니다. AGI가 존재한다면 우리가 원할지에 대해 전혀 탐구해보지 않았으며, 이것은 그저 흥미로운 철학적 주제일 뿐 위험한 상황은 아닙니다. (다른 날에 다시 논의할 주제입니다.) 그렇기 때문에 누군가가 AI가 우리 세계를 완전히 변화시키리라고 말할 때, 특히 즉각적인 미래에 그렇게 믿는다면 저는 회의적입니다. 기계 학습은 우리를 크게 도와주었고, 이미 많은 해 동안 그 역할을 하고 있습니다. 생성 AI 개발에 사용되는 새로운 기술은 몇몇 경우에 흥미롭고 유용하지만, 우리가 믿기로 생각하는 만큼 깊은 변화를 가져다주지는 못할 것입니다.\n\n더 많은 저의 작품은 www.stephaniekirmer.com에서 확인하실 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 참고 자료\n\nhttps://arxiv.org/pdf/2211.04325.pdf","ogImage":{"url":"/assets/img/2024-05-27-HowDoWeKnowifAIIsSmokeandMirrors_0.png"},"coverImage":"/assets/img/2024-05-27-HowDoWeKnowifAIIsSmokeandMirrors_0.png","tag":["Tech"],"readingTime":8},{"title":"약물 발견을 위한 지식 그래프","description":"","date":"2024-05-27 14:48","slug":"2024-05-27-KnowledgeGraphsforDrugDiscovery","content":"\n\n![Knowledge Graphs for Drug Discovery](/assets/img/2024-05-27-KnowledgeGraphsforDrugDiscovery_0.png)\n\n약물 발견 분야의 급변하는 분야에서, 지식 그래프는 새로운 약물을 식별하고 개발하는 방식을 변형하는 강력한 인실리코 도구로 발전하고 있습니다. 방대하고 다양한 데이터셋을 통합함으로써, 지식 그래프는 생물 엔티티간의 숨겨진 관계를 발견하고, 약물 발견 분야에서 더 정확한 예측과 효율적인 프로세스를 가능하게 합니다. 이 기사는 이 분야에서 지식 그래프가 가져온 다양한 최근 응용 및 혁신에 대해 탐구합니다.\n\n## 타겟 우선 순위 지정\n\n약물 발견 분야에서 지식 그래프의 주요 응용 중 하나는 타겟 우선 순위 지정입니다. 다양한 데이터셋을 통합함으로써, 지식 그래프는 연구자들이 약물 개발을 위해 생물학적 타겟을 식별하고 우선 순위를 지정할 수 있도록 합니다. 데이터의 상호 연결된 특성은 유전자, 단백질, 경로 및 질병 사이의 복잡한 관계를 이해하는 데 도움이 되어, 추구해야 할 타겟에 대해 보다 정보에 기초한 결정을 내릴 수 있게 합니다. [더 읽기]\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 약물 재포지셔닝\n\n지식 그래프는 기존 약물에 대한 새로운 치료용도를 찾는 약물 재포지셔닝에도 중요한 역할을 합니다. 약물과 질병 간 복잡한 관계를 매핑하여, 지식 그래프는 전통적인 방법으로는 분명히 눈에 띄지 않을 수 있는 재포지셔닝 기회를 발견할 수 있습니다. 데이터의 통합을 통해 다양한 약물이 어떻게 다양한 생물학적 요소와 상호 작용하는지 종합적으로 파악할 수 있으며, 이를 통해 약물 재포지셔닝 프로세스를 간소화할 수 있습니다. [더 읽기]\n\n# 인공지능 통합\n\n지식 그래프와 인공지능(AI)의 통합은 그들의 능력을 더욱 향상시킵니다. AI 알고리즘은 지식 그래프 내 복잡한 관계를 분석하여 예측과 데이터 분석의 정확성을 향상시킵니다. AI와 지식 그래프 사이의 시너지는 연구자들이 새로운 통찰을 발견하고 약물 발견에서 더 나은 결정을 내릴 수 있도록 도와줍니다. [더 읽기]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# TransR Model for Enhanced Link Prediction\n\nTransR 모델은 지식 그래프에서의 사용으로 약물 발견 분야에서 혁신적인 응용 사례 중 하나입니다. TransR은 유전자, 약물 및 질병간의 관계를 더 잘 포착하는 지식 그래프 임베딩 모델로, 이 모델은 지식 그래프 내의 링크 예측 정확도를 향상시켜 기존 약물에 대한 새로운 치료적 사용 사례를 식별하는 데 도움을 줍니다. [더 읽기]\n\n# Large Language Models Integration\n\n지식 그래프와 대형 언어 모델 (LLMs)의 결합이 다양한 약물 발견 작업에서 기존 방법을 능가하는 것으로 입증되었습니다. 지식 그래프의 구조화된 표현은 LLM의 고급 자연어 처리 기능과 결합되어 더 나은 데이터 통합, 패턴 인식 및 가설 생성이 가능하게 합니다. 이 통합은 복잡한 생물의학적 질문을 효과적으로 다루며, 약물 발견 파이프라인을 간소화합니다. [더 읽기]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Drug Repurposing을 위한 설명 가능한 AI\n\n지식 그래프를 활용한 설명 가능한 AI 프레임워크를 구현하는 것은 Drug Repurposing 예측에 대한 투명하고 해석 가능한 설명을 제공하는 데 중요합니다. 다양한 생명 과학 데이터 소스를 통합하여, 이러한 프레임워크는 인간이 이해할 수 있는 설명을 생성하여, 약물 발견에서의 AI 주도 예측의 신뢰성과 사용 가능성을 향상시킵니다. [더 알아보기]\n\n# AIDTox 모델을 위한 독성 예측\n\nAIDTox 모델은 인간이 이해할 수 있는 딥러닝 모델로, 지식 그래프를 활용하여 약물 및 화학 물질의 독성에 대한 포괄적인 설명을 제공합니다. 화학물질-유전자 연결 및 유전자-경로 관계의 편집된 지식을 통합함으로써, AIDTox는 해석 가능한 예측을 생성하여 연구자들이 부작용 약물 반응과 화학물질의 독성을 이해하는 데 도움이 됩니다. [더 알아보기]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 생체 의학 지식 그래프 학습\n\n생체 의학 지식 그래프는 고처리 데이터를 통합하고 기계 학습 기술을 활용하여 상호 연결된 데이터를 분석하여 계산적인 약물 재활용을 용이하게 합니다. 이러한 그래프는 의미론적 관계의 중요성을 강조하여 전통적인 방법으로는 알아내기 어려운 잠재적인 약물-질병 관계를 발견하는 데 도움을 줍니다.\n\n# 지식 그래프에 자연어 처리 통합\n\n교차적인 생체 의학 지식 그래프에 자연어 처리(NLP) 파이프라인을 통합함으로써 복잡한 생체 의학 데이터를 대표하고 분석하는 능력을 향상시킵니다. 이 통합은 구조화되지 않은 생체 의학 문헌으로부터 가치 있는 통찰을 추출하므로 지식 그래프의 정확성과 포괄성을 향상시키고, 이로써 더 효과적인 약물 발견과 재활용을 가능하게 합니다. [더 읽기]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 의약품 발견 애플리케이션\n\n지식 그래프는 다양한 생물의학 데이터를 통합하고 분석하여 새로운 약품 후보를 식별하고 질병 메커니즘을 이해하며 약물 개발 파이프라인을 최적화하는 구조화된 플랫폼을 제공합니다. 연구자들이 생물학적 개체 간의 복잡한 관계를 탐색할 수 있도록 함으로써, 지식 그래프는 새로운 치료제를 발견하고 개발하는 속도를 가속화합니다. [자세히 보기]\n\n# 결론\n\n의약품 발견에서 지식 그래프의 사용은 다양한 데이터 세트를 통합하고 AI 능력을 향상시키며 투명하고 설명 가능한 예측을 제공함으로써 분야를 혁신하고 있습니다. 타깃 우선 순위 설정 및 약물 재활용부터 AI 및 NLP 기술 통합에 이르기까지, 지식 그래프는 혁신적인 응용 방법을 통해 신규 통찰력을 발견하고 의약품 발견 프로세스를 가속화하기 위한 과학적이고 효율적인 접근 방법을 제공합니다. 본 문서에서 논의된 혁신적인 응용 프로그램은 의료 연구에서 지식 그래프의 혁신적 잠재력을 강조하며, 더욱 효과적이고 효율적인 의약품 발견 및 개발을 위한 길을 열고 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-27-KnowledgeGraphsforDrugDiscovery_0.png"},"coverImage":"/assets/img/2024-05-27-KnowledgeGraphsforDrugDiscovery_0.png","tag":["Tech"],"readingTime":4}],"page":"105","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":13,"currentPageGroup":5},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"105"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>