<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/23" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/23" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="AI 예술은 진짜 예술인가" href="/post/2024-06-22-IsAIArtRealArt"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 예술은 진짜 예술인가" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-IsAIArtRealArt_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 예술은 진짜 예술인가" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI 예술은 진짜 예술인가</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Stylar AI의 새로운 스타일 학습기 소개" href="/post/2024-06-22-StylarAIhasanewStyleLearner"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Stylar AI의 새로운 스타일 학습기 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-StylarAIhasanewStyleLearner_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Stylar AI의 새로운 스타일 학습기 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Stylar AI의 새로운 스타일 학습기 소개</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Hugging Face 탐구 조건 없는 이미지 생성 방법" href="/post/2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Hugging Face 탐구 조건 없는 이미지 생성 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Hugging Face 탐구 조건 없는 이미지 생성 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Hugging Face 탐구 조건 없는 이미지 생성 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="지속 가능한 생성형 AI 혁명을 위한 방법들" href="/post/2024-06-22-TowardsaSustainableGenerativeAIRevolution"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="지속 가능한 생성형 AI 혁명을 위한 방법들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="지속 가능한 생성형 AI 혁명을 위한 방법들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">지속 가능한 생성형 AI 혁명을 위한 방법들</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">26<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Artvyai로 당신의 내면 예술가를 펼치세요  최고의 무료 AI 아트 플랫폼" href="/post/2024-06-22-UnleashYourInnerArtistwithArtvyaiTheUltimateFreeAIArtPlatform"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Artvyai로 당신의 내면 예술가를 펼치세요  최고의 무료 AI 아트 플랫폼" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-UnleashYourInnerArtistwithArtvyaiTheUltimateFreeAIArtPlatform_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Artvyai로 당신의 내면 예술가를 펼치세요  최고의 무료 AI 아트 플랫폼" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Artvyai로 당신의 내면 예술가를 펼치세요  최고의 무료 AI 아트 플랫폼</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">1<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ComfyUI 설치 가이드 Linux, Windows" href="/post/2024-06-22-InstallingComfyUILinuxWindows"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ComfyUI 설치 가이드 Linux, Windows" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-InstallingComfyUILinuxWindows_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ComfyUI 설치 가이드 Linux, Windows" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">ComfyUI 설치 가이드 Linux, Windows</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI 아트 프롬프트의 구성 요소 분석" href="/post/2024-06-22-TheAnatomyofanAIArtPrompt"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 아트 프롬프트의 구성 요소 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 아트 프롬프트의 구성 요소 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI 아트 프롬프트의 구성 요소 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI 얼굴 스왑 배틀 PuLID vs InstantID vs FaceID" href="/post/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 얼굴 스왑 배틀 PuLID vs InstantID vs FaceID" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 얼굴 스왑 배틀 PuLID vs InstantID vs FaceID" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI 얼굴 스왑 배틀 PuLID vs InstantID vs FaceID</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이썬을 사용한 신호처리를 위한 생성적 적대 신경망GAN 실습 가이드" href="/post/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이썬을 사용한 신호처리를 위한 생성적 적대 신경망GAN 실습 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이썬을 사용한 신호처리를 위한 생성적 적대 신경망GAN 실습 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">파이썬을 사용한 신호처리를 위한 생성적 적대 신경망GAN 실습 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="초보자를 위한 디스코드에서 Midjourney 시작하기 단계별 가이드" href="/post/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="초보자를 위한 디스코드에서 Midjourney 시작하기 단계별 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="초보자를 위한 디스코드에서 Midjourney 시작하기 단계별 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">초보자를 위한 디스코드에서 Midjourney 시작하기 단계별 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link posts_-active__YVJEi" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"AI 예술은 진짜 예술인가","description":"","date":"2024-06-22 21:58","slug":"2024-06-22-IsAIArtRealArt","content":"\n\n## 코드로 생성된 수백만 장의 이미지가 새로운 경제 엔진을 가속화시켰습니다. 그러나 현대 예술은 여러 해 동안 여러 물꼬를 일으켜 온 것으로 알려져 있습니다. AI 예술은 새 시대의 도래일까요, 아니면 예술 세계의 최신 장난일까요?\n\n![image](/assets/img/2024-06-22-IsAIArtRealArt_0.png)\n\n생성 예술은 기계 학습과 기계 비전 기술을 사용하여 이미지를 생성합니다. 그리고 이것은 무엇이 진짜 예술이고 아닌지에 대해 주제를 이루며 많은 헤드라인을 생산하고 있습니다.\n\n저에게는 답이 명확합니다: AI 생성 예술은 예술입니다. 물론 그렇습니다. 그것은 레시피를 따르고 입력과 출력이 있습니다. 레시피를 개발하는 것도 예술이고, 레시피를 사용하여 새로운 것을 세상에 내놓는 것도 예술입니다. 둘 다 예술입니다. 이게 왜 논란이 되는 걸까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n온라인 리소스와 문서를 공유하려면 가장 흔하게 사용되는 **Markdown** 양식을 사용하는 것이 좋습니다. 간단하고 사용하기 쉬우며 거의 모든 플랫폼에서 지원됩니다. Markdown으로 테이블을 변경해 보겠습니다:\n\n\n| Topic          | Translation                                    |\n|----------------|------------------------------------------------|\n| Language       | 언어                                           |\n| Translation    | 번역                                           |\n| Developer      | 개발자                                         |\n| Friendly       | 친절한                                        |\n\n\n위와 같이 Markdown 형식으로 테이블을 작성할 수 있습니다. 종이와 필기구 없이도 코드를 깔끔하게 구성할 수 있어서 편리합니다. 어떤 테이블 형식이 필요한지 주시면 도와드리겠습니다!\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Artwork](/assets/img/2024-06-22-IsAIArtRealArt_1.png)\n\n아티스트들은 최소한 세기 동안 같은 질문을 탐구해 왔습니다. 여론은 다음과 같습니다: 우리는 예술의 정의를 제한해서는 안 되며, 오히려 확장해야 합니다. 예술은 심지어 물리적 형태를 가져야 할 필요도 없습니다. 중요한 것은 아티스트의 결정, 대중과의 상호 작용, 그리고 이것이 어떤 의미를 지니는지가 있습니다. 그것이 아이디어가 얼마나 새롭고 독특한지와는 상관이 없습니다.\n\nAI로 생성된 예술에서 컴퓨터가 모든 결정을 내리는 것처럼 보일 수 있습니다. 아티스트가 알고리즘의 모든 과정을 이해하지 못할 수도 있습니다. (그것을 작성한 개발자들조차도 이러한 프로세스 내에서 일어나는 모든 일을 이해한다고 말할 수 없을 것입니다.) 그러나 한 사람의 입력 없이는 아무것도 일어나지 않을 것입니다. 그것이 예술을 찾는 지점입니다. 어떻게 자신의 기계학습 모델에 가중치를 줄 것인지 계산하는 지점이나, 교육 데이터에 대해 어떤 결정을 내리는지 같은 과정을 시작하는 방법에 대해 어떠한 선택을 하고 있는지 등입니다.\n\n언뜻 보기에 이러한 종류의 작업을 만들기 위해 사용하는 도구는 \"모든 일을 한다\"는 반대 의겢입니다. 그들의 출력물은 예측하기 어렵고 자체적인 마음을 지니는 것처럼 보입니다. 이러한 도구를 통해 흥미로운 결정을 내리기 전에 아티스트는 새로운 기술에서 수년간의 공부와 숙련도를 쌓아야 합니다. 비평가, 큐레이터, 예술을 감상하는 대중 등이 작품과 상호작용하는 새로운 방식을 개발하고 그것을 찾기 위한 새로운 기준을 정립해야 할 것입니다. 새로운 예술 형태가 새로운 예술을 형성할 것입니다. 그런 상황이 언제나 다를 수 있었겠습니까?\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 많은 창조적인 '아트'를 보려면 https://studioamelia.com에 있는 포트폴리오나 메타버스에서 https:/oncyber.io/studioamelia를 확인해보세요!","ogImage":{"url":"/assets/img/2024-06-22-IsAIArtRealArt_0.png"},"coverImage":"/assets/img/2024-06-22-IsAIArtRealArt_0.png","tag":["Tech"],"readingTime":3},{"title":"Stylar AI의 새로운 스타일 학습기 소개","description":"","date":"2024-06-22 21:57","slug":"2024-06-22-StylarAIhasanewStyleLearner","content":"\n\n저는 생성적 AI 앱 내 스타일 프리셋의 열렬한 팬입니다. 이에는 좋은 이유가 있죠.\n\n전통적인 예술에서 스타일은 작가나 디자이너의 시각적인 서명으로 작용하며, 그들의 독특한 관점과 창의적인 정체성을 담아냅니다. 이미지는 스타일을 통해 즉각적인 소재뿐만 아니라 표면 아래 감정적이고 개념적인 층도 전달합니다.\n\n독특한 스타일은 간단한 이미지도 강력한 커뮤니케이션 도구로 변화시킬 수 있어, 관객으로부터 특정한 감정, 생각, 반응을 유도합니다. 작가의 비전을 관람객에게 전달하는 차량으로, 예술을 기억에 남고 영향력 있게 만듭니다.\n\n스타일은 생성적 예술에서 다른 어떤 예술 형태에서나 중요합니다. 네, 프롬프트 자체에서 스타일을 설명하는 것이 가능하고 흔합니다. 대다수 생성적 AI 사용자들이 그렇게 하죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![StylarAI new Style Learner](/assets/img/2024-06-22-StylarAIhasanewStyleLearner_0.png)\n\nBut prompts are not unlimited. Generative AI apps have limited capacity to interpret long and complicated prompts. Sooner or later, it becomes really difficult, or even impossible, to describe everything that is needed in one single prompt.\n\nIt becomes an even more complex task if the creator wants to remain consistent in style and have their own visual signature.\n\nThat is where style presets and style references come in. Giving AI a reference to the style and leaving a prompt to describe your scene, subjects, and composition is the most effective way to work.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStylar AI는 이미 멋진 스타일 프리셋을 제공하고 있어요. 하지만 프리셋은 각 개별 창작자의 스타일과는 조금 다를 수 있죠.\n\n이제 Stylar AI에게 하나의 이미지를 제공하여 스타일 참조 이미지를 줄 수 있었고, 그 이미지에서 스타일을 잘 이해하는 일을 했습니다.\n\n그러나 이제는 여러 이미지로 Stylar AI를 훈련시켜 내가 원하는 스타일을 더 잘 이해할 수 있게 된 것이 가능해졌고, 정말 좋아요. 사용하기도 쉬워요.\n\n이 새로운 도구는 텍스트에서 이미지로 또는 이미지에서 이미지로 도구 중 스타일 옵션 창 옆의 “+” 기호를 클릭하여 액세스할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-22-StylarAIhasanewStyleLearner_1.png\" /\u003e\n\n\"스타일 생성” 팝업 창에는 “스타일 스왑”과 “스타일 학습” 두 가지 옵션이 있어요. “스타일 스워퍼”는 과거 버전으로, 하나의 스타일 참조 이미지만 필요해요.\n\n“스타일 학습”은 지속적인 스타일을 가진 3-10개의 이미지를 학습시켜 새로운 스타일 프리셋을 만들 수 있어요.\n\n사용 과정은 직관적이고 간단해요: “스타일 학습” 버튼을 클릭하면 새 창이 열려 이미지를 업로드하고 새 스타일에 이름을 지정할 수 있어요. 필요한 정보가 모두 담긴 “학습 가이드” 링크도 있어요. 읽어보는 걸 추천해요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![2024-06-22-StylarAIhasanewStyleLearner_2](/assets/img/2024-06-22-StylarAIhasanewStyleLearner_2.png)\n\n이미지를 업로드하고 스타일을 지정한 후 \"학습\" 버튼을 클릭하세요.\n\n학습 과정에는 시간이 소요됩니다. Stylar AI는 카운트다운 타이머를 제공할 것입니다. 제가 시행한 경우, 10개의 이미지를 기반으로 20~30분이 소요되었습니다. 작은 이미지 세트에 대해 학습하는 것이 빠를 것으로 예상되지만, 이 경우 더 많이 하는 것이 더 나은 결과를 가져다주고 기다릴 가치가 있다고 생각합니다.\n\n제가 생성한 이미지를 \"텍스트-이미지\" 및 \"이미지-이미지\" 도구로 테스트했고 결과가 인상적이었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여러 이미지 스타일 프리셋에서 훈련을 받은 것은 단일 이미지 스타일 참조와 비교하여 훨씬 다양한 경우에 더 잘 작동합니다.\n\n여기 몇 가지 새로운 스타일 프리셋으로 테스트한 컴필레이션이 있습니다. 각 이미지 행은 프롬프트 없이 이미지-이미지 도구에 적용된 스타일을 보여주며, 간단한 프롬프트 \"춤을 추는 여자\"로 텍스트-이미지에 적용된 스타일을 보여줍니다. 마지막 이미지는 \"귀여운 뛰는 긴 모발 강아지\"라는 프롬프트와 함께 표시됩니다.\n\n![이미지](/assets/img/2024-06-22-StylarAIhasanewStyleLearner_3.png)\n\n![이미지](/assets/img/2024-06-22-StylarAIhasanewStyleLearner_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Stylar AI](/assets/img/2024-06-22-StylarAIhasanewStyleLearner_5.png)\n\n결과는 정말 멋지다고 생각해요. 하지만 가장 마음에 들었던 건 여러 도구들과 다양한 프롬프트를 사용해도 달성할 수 있는 일관성이었어요.\n\n이런 일관성은 개인적인 스타일과 브랜드를 구축하기 위해 필요한 요소에요. 이 도구는 전문가들을 위한 것이며 전문적인 결과를 만들어냅니다.\n\nStylar AI는 이미 높은 품질의 작업을 위한 도구로 잘 갖추어져 있어요. 이 새로운 애드온은 그 철학을 더욱 발전시키고 있답니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아이바라스 그라우지니스","ogImage":{"url":"/assets/img/2024-06-22-StylarAIhasanewStyleLearner_0.png"},"coverImage":"/assets/img/2024-06-22-StylarAIhasanewStyleLearner_0.png","tag":["Tech"],"readingTime":4},{"title":"Hugging Face 탐구 조건 없는 이미지 생성 방법","description":"","date":"2024-06-22 21:56","slug":"2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration","content":"\n\n## 무조건적 이미지 생성\n\n![이미지](/assets/img/2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration_0.png)\n\n무조건적 이미지 생성은 특정 가이드나 입력 없이 완전히 새로운 이미지를 생성하는 과정을 의미합니다. 조건적 이미지 생성과는 달리 텍스트 프롬프트나 참조 이미지를 사용하여 출력물을 유도하는 것과 달리, 무조건적 생성은 훈련 데이터로부터 학습된 통계적 패턴만을 기반으로 이미지를 생성합니다.\n\n```python\n# !pip install diffusers\nfrom diffusers import DDPMPipeline, DDIMPipeline, PNDMPipeline\n\nmodel_id = \"google/ddpm-cifar10-32\"\n\n# 모델 및 스케줄러 로드\nddpm = DDPMPipeline.from_pretrained(model_id)  # 빠른 추론을 위해 DDPMPipeline 대신 DDIMPipeline 또는 PNDMPipeline으로 대체할 수 있습니다.\n\n# 추론 파이프라인 실행 (랜덤 노이즈 샘플링 및 노이즈 제거)\nimage = ddpm().images[0]\n\n# 이미지 저장\nimage.save(\"ddpm_generated_image.png\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```MD\n![Exploring HuggingFace Unconditional Image Generation](/assets/img/2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration_1.png)\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom huggingface_hub import from_pretrained_keras\n\nseed = 42\nn_images = 36\ncodings_size = 100\ngenerator = from_pretrained_keras(\"huggan/crypto-gan\")\n\ndef generate(generator, seed):\n    noise = tf.random.normal(shape=[n_images, codings_size], seed=seed)\n    generated_images = generator(noise, training=False)\n\n    fig = plt.figure(figsize=(10, 10))\n    for i in range(generated_images.shape[0]):\n        plt.subplot(6, 6, i+1)\n        plt.imshow(generated_images[i, :, :, :])\n        plt.axis('off')\n    plt.savefig(\"samples.png\")\n    \ngenerate(generator, seed)\n\n![Exploring HuggingFace Unconditional Image Generation](/assets/img/2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration_2.png)\n\n## 추가 정보\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 참고 자료\n\n- [huggingface.co - 무조건 이미지 생성](https://huggingface.co/tasks/unconditional-image-generation)\n- [huggingface.co - 디퓨저(en) 문서 - 무조건 훈련](https://huggingface.co/docs/diffusers/en/training/unconditional_training)\n- [huggingface.co - 구글/ddpm-cifar10-32](https://huggingface.co/google/ddpm-cifar10-32)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://huggingface.co/huggan/crypto-gan","ogImage":{"url":"/assets/img/2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration_0.png"},"coverImage":"/assets/img/2024-06-22-ExploringHuggingFaceUnconditionalImageGeneration_0.png","tag":["Tech"],"readingTime":3},{"title":"지속 가능한 생성형 AI 혁명을 위한 방법들","description":"","date":"2024-06-22 21:51","slug":"2024-06-22-TowardsaSustainableGenerativeAIRevolution","content":"\n\n\u003cimg src=\"/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_0.png\" /\u003e\n\n인류의 창의적인 역량은 멈출 수 없는 생성적 AI 혁명에 의해 늘어나고 있습니다. 텍스트 및 다른 종류의 프롬프트를 사용하여 사람들은 이 기술을 활용하여 멋진 이미지, 비디오, 3D 형상, VR 환경 등을 생성합니다. 그러나, AI 세대가 예술 대회, 예술 플랫폼, 주식 라이브러리 등과 같은 여러 문제와 관련하여 발생하는 성장 고통이 나타나기 시작했습니다.\n\n저는 이 혁명의 시작부터 출범한 최초의 생성적 AI 플랫폼 중 하나인 Geniverse의 공동 창업자입니다. 나는 오랜 시간 다분야 예술가로 활동해왔습니다.\n\n(생성적 AI와 예술 두 분야에서 매우 활발한 사람으로) 이러한 문제에 관여된 다양한 각도와 관점들을 고찰할 예정입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 함께 재미있는 여정을 떠나 이 흥미진진한 기술의 본질을 처음부터 다시 살펴보게 될 거에요. 우리는 모든 것을 인간의 창의력, 예술가들의 마음과 연결하여 탐구할 거예요.\n\n그리고 이제, 혁명의 현재 상태에서 나타나는 좋은 점, 까다로운 점, 그리고 가장 중요한 문제에 대해 알아볼 거에요. 마지막으로, 우리가 어떻게 함께 나아가서 초기 단계를 넘어서 보다 지속 가능한 상황으로 나아갈 수 있는지에 대해 고찰할 거에요.\n\n준비됐나요? 이 글에서는 AI에 관한 비유에서부터 잠재 공간, 예술가의 마음, 스마트 생성 환경, 그리고 다양한 미래 시나리오, 창작자의 권리, 콘텐츠 인증 이니셔티브(CAI) 표준 등을 다룰 거예요. 시작해봅시다.\n\n# 집에 오다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단한 은유를 사용하여 창조적 AI 혁명이 제시하는 것과 창작가, 예술가, 그리고 모든 인류에게 미치는 영향을 탐구해 봅시다.\n\n옛날 어느 날, 당신은 인생의 바다에 떨어졌습니다. 이는 상당히 광대한 바다이며, 정보의 바다입니다.\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_1.png)\n\n무의식과 의식이라는 두 관점 또는 부분으로 이뤄진 당신으로 상상해 봅시다. 그리고 무의식을 정보의 바다 위에 떠다니는 부엌 냄비로 상징화해 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 테이블 태그를 Markdown 형식으로 변경해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 여기 계시네요. 인생의 바다를 떠다니며, 가끔은 무의식 속 솥 안에서 일어나는 요리 과정을 위한 방향을 제공해 주는 신비로운 의식을 가지고 있습니다.\n\n그 동안, 그 무의식은 계속해서 감각을 통해 도착하는 갖가지 재료(정보)들을 결합, 혼합, 그리고 재조합하고 있습니다.\n\n가끔, 그러한 결합은 새로운 아이디어의 씨앗이 될 수도 있습니다. 비유적으로 말하면, 우리는 무의식에서 의식으로 상승하는 연약하고 섬세한 거품들을 상상할 수 있습니다. 그리고 마음 속에 여유가 있다면, 소음으로 가득 차 있지 않다면, 그 연약한 거품들을 인지할 수 있을 것이고, 그리고: 유레카! 아이디어가 떠오를 수도 있습니다!\n\n![2024-06-22-TowardsaSustainableGenerativeAIRevolution_4.png](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_5.png)\n\n하지만 여기 문제가 있어요. 이 바다에는 너무 많은 정보가 있고, 너무 많은 복잡성이 있어요. 그리고 우리의 무의식은 한정된 크기를 갖고 있어요. 뻣뻣하지 않아요. 어느 정도로는 유연하고 가느다랗습니다. 하지만 그 크기는 여전히 제한되어 있어요.\n\n따라서 자연은 삶의 바다의 엄청난 복잡성에 대처하기 위한 문제를 해결하기 위한 메커니즘을 진화했어요: 압축 및 압축 해제 과정.\n\n우리 뇌는 우리의 감각을 통해 도착하는 정보를 가져와서 더 적은 세부사항과 더 많은 추상화를 갖는 형태로 압축시킬 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_6.png)\n\n이 매우 중요한 축, 세부-추상 축을 시각화해 봅시다. 우리가 인생의 복잡성을 압축할 때, 고 세부 정보(고 차원 공간)에서 고 추상화(낮은 차원 공간 내)로 이동합니다.\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_7.png)\n\n그래서, 우리의 잠재의식 속에서, 우리는 때로 latent spaces라고도 하는 세계의 복잡성을 압축한 표현들을 모아둡니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_8.png)\n\n이러한 잠재 공간은 서로 다른 정보 도메인의 추상적 본질을 담고 있습니다. 우리는 무의미한 세부 정보를 제거하고 줄어든 차원의 수를 유지합니다. 각각은 데이터가 속한 정보 도메인과 관련된 중요하고 유용한 요인을 기록합니다.\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_9.png)\n\n우리의 두뇌는 반대과정도 수행할 수 있습니다. 그것은 압축 해제를 수행하고 높은 요약 수준에서 높은 세부 사항으로 전환할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"코딩을 즐기고 계신가요? 그렇다면, 여기 코드를 Markdown 형식으로 변경해 보세요. 함께 코딩하는 것을 즐기실 거예요!\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_11.png)\n\n복잡한 생성 AI 시스템을 탐색할 때, DALLE-2(OpenAI)에서 Imagen(Google)로, Stable Diffusion(Stability.ai) 및 그 이상으로 진행하면, 각기 다른 중간 단계가 발견됩니다. 이 중간 단계는 예를 들어 모드 간 변환, 확산 프로세스 수행, 입력 및 출력 확장 등 여러 작업을 수행할 수 있지만, 모든 시스템의 초기 기본은 고해상도와 고추상화 사이를 양방향으로 이동할 수 있게 해주는 압축 및 압축 해제 프로세스입니다.\n\nAI 시스템의 구체적인 내용은 우리가 가진 목적에 따라 달라집니다. 이미지를 확대하거나 선명하게 만들거나, 텍스트 프롬프트에 따라 새로운 이미지를 생성하거나, 이러한 것들을 함께 수행하거나 또는 완전히 다른 작업을 수행할 수도 있습니다. 이는 우리가 사용하는 훈련 목표 및 데이터셋을 결정하며 최종 아키텍처의 각 부분의 구체적인 세부 정보를 결정할 것입니다.\n\n현재 주요 생성 AI 시스템에서 사용되는 주요 전략은 확산(diffusion, 브러시한 의미)에 기반합니다. 예를들어, Stable diffusion 시스템은 이미지에 추가된 소음을 예측하기 위해 대규모 데이터셋으로 훈련된 U-Net과 유사한 아키텍처를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 번 훈련을 받은 네트워크는 이미지+노이즈의 다양한 조합(랜덤 노이즈 포함)으로부터 고품질 이미지로 여러 단계를 거쳐 돌아갈 수 있습니다.\n\n또한 초기 이미지에 일부 노이즈를 추가한 다음 이전과 같은 프로세스를 수행하여 이미지에서 다른 이미지로 이동할 수도 있습니다.\n\n이러한 생성물들이 올바른 방향으로 이동하려면 우리가 입력한 텍스트 프롬프트의 압축된 표현에 의존합니다(U-Net 아키텍처의 다양한 부분에 주입됩니다).\n\n기술적인 세부 사항은 여기까지. 계속해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AI가 집으로 오고 있어요\n\n그래서, 생성적 AI 혁명과 함께, 우리는 수렴과 발산(압축과 해제)의 보완적인 과정을 수행할 수 있는 존재로서의 본질에 더 가까워지고 있습니다. 이는 우리의 분석적이고 창의적인 능력을 통해 표현됩니다.\n\n깊은 학습 AI 시스템의 수렴 능력(예측, 추천, 분류, 식별 등의 능력)을 서서히 확장하고 발전시킨 지 10년 후에, 생성적 AI 혁명은 초인적인 발산 능력(창조와 생성 능력)을 추가함으로써 순환을 완성합니다. AI가 집으로 오고 있어요.\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_12.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 잠재 공간의 마법\n\n하지만 우리가 잠재 공간이나 추상적인 압축된 표현에 대해 얘기할 때 정확히 무엇을 의미하는지 궁금해할 때가 있습니다. 답은 우리 안에 있습니다. 우리는 매우 간단한 예시를 통해 대답을 찾을 수 있습니다.\n\n자연 속을 산책하다 돌아옵니다. 돌아오자마자 친구가 산책이 어땠는지 묻습니다. \"너무 좋았어요, 아름다운 매미를 봤어요!\"라고 말합니다. 그럼 친구가 물어봅니다. \"매미는 어땠나요?\"\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_13.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그때 나는 마음 속으로 매미를 시각화합니다. 나의 시각화가 1000 x 1000개의 조도 점으로 표현된 그리드에 있다고 상상해 봅시다. 이것은 100만 차원의 공간입니다. 점이 색을 갖고 있다면, 각각은 빨간색, 녹색 및 파란색 구성 요소가 있을 것입니다(3배 더 많은 차원).\n\n따라서 나는 친구에게 매미를 설명하기 시작할 수 있습니다. \"음, 내 시각화의 왼쪽 상단에 있는 첫 번째 조도 점은 빨간 강도가 15, 녹색 강도가 25, 파란 강도가 77입니다. 그 옆에 있는 다음 점은 빨간 강도가 145, 녹색 강도가 55... 그 다음 점은..., 등\"이라고 말하는 것으로 시작할 수 있습니다. 그리고 나는 100만 개의 조도 점을 통해 계속 진행할 수 있습니다. 이 방식의 문제점은 명백합니다.\n\n매미를 설명하는 데 한 달이 걸릴 수 있으며 그 사이에 친구는 이미 멀리 떠날 수 있습니다. 효율성이 전혀 없습니다. 하지만 본질적인 문제는 심지어 그것도 아닙니다.\n\n100만 개 중 하나의 점이 빨간 강도가 155임을 알아도 큰 도움이 되지 않습니다. 세세한 부분은 종종 관련 정보를 제공하지 않습니다. 그래서 나는 다른 방식으로 해보려고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시끄러운 소리를 내는 해충의 복잡함과 섬세함을 그저 몇 가지 요소인 30, 50, 100 가지 요소(아무튼 적은 수)로 압축할 거야. 내가 본 것의 본질을 설명하는 핵심적인 것들을 설명할 거야.\n\n![이미지 파일](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_14.png)\n\n그리고 나는 내 친구에게 말할 거야: \"봐봐, 그 해충은 넓은 머리, 튼튼한 녹색 몸과 투명한 뿌리난 날개를 가지고 있었어. 날개가 네 개 있었고, 날개에는 이런 종류의 무늬가 있었어. 그리고 큰 홍저안을 가졌으며 눈의 수는 이만큼이었고, 여섯 다리와 이런 모양의 다리가 있었어. 등등.\" 상세한 표현을 중대요소 몇 가지로 압축해서 중요하고 관련 있는 정보를 전달할 거야.\n\n그리고 이제, 내 친구가 이를 듣고 반대로 하는 과정, 압축 해제를 하게 될 거야.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그녀는 내가 본 것을 표현하는 몇 가지 압축된 차원을 변형하여 그 본질을 시각화하기 위해 그것들을 부풀려 마음속에서 세밀한 세부 사항 표현을 만들어 냅니다. 그 점에 대응하는 이미지는 매미입니다 (나와는 다를 수 있습니다. 압축-해제 과정과 관련 시나리오에 대한 각자의 이전 지식을 비롯한 시스템 간의 차이로 인해).\n\n![DALLE-2 작동 방식 및 인간 뇌와의 비교](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_15.png)\n\n그래서 어떤 면에서는, 우리가 어떤 것을 회상할 때마다, 우리는 그것을 재건축하고, 재상상하고, 그 본질에서 재생성하는 것과 같습니다 (이 프로세스의 정확도는 관련 잠재 공간의 풍부성과 창조에 관여하는 감각 모달리티의 수 등 여러 요소에 많이 달려 있습니다).\n\n다음은 DALLE-2의 작동 방식을 인간 뇌와 비교한 인포그래픽입니다. 저는 몇 달 전에 만들었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_16.png)\n\n# 작은 냄비, 거대한 냄비\n\n우리 두뇌 안과 이 AI 네트워크 안에서 벌어지는 일에는 많은 차이가 있지만, 이 글에서 특히 중요한 하나의 차이는 상징적으로 말할 때의 무의식적인 냄비의 크기입니다.\n\n우리의 무의식적인 냄비는 삶에서 경험하는 것에 의해 먹여지는 것이죠. 사람들과 이야기할 때, 세상을 경험할 때, 그 내용물을 풍부하게 합니다. 결국 그 요리 과정은 우리의 마음 속에서 새로운 아이디어, 시각화, 소리 등을 만들어 냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 네트워크는 (학습 시기에) 거대한 데이터 세트로 공급됩니다. 생성적 AI 시스템에서 사용되는 데이터 세트는 인터넷에서 수집된 정보로 구성됩니다. 우리는 엄청난 양의 데이터에 대해 이야기하고 있습니다.\n\n그렇기에 한쪽에는 우리 인간들이 있고, 우리는 우리의 작은 잠재의식적 용기를 가지고 있습니다.\n\n다른 한편에는, 우리는 인터넷에서 수집한 데이터로 공급되는 거대한 AI 용기를 가지고 있습니다. 그 데이터 중 일부는 공개 도메인에 있습니다. 하지만 전부는 아닙니다. 이것이 무엇을 의미하고 함축하는지는 나중에 조금 더 논의할 것입니다.\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_17.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_18.png)\n\n# The depth elevator\n\nIt’s time to connect all the previous sections with art and human artists. Now, defining what makes an artist is an impossible task. Instead, I will focus on exploring something that has been common to many of the great creatives in history.\n\nRemember that axis (detail to abstraction) that I was discussing above? In a book I published years ago, I wrote about another metaphor I came up with, which I call “The depth elevator”.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수직선으로 상상해보세요. 상승기내에서 움직이는 엘리베이터가 있습니다. 선의 맨 아래에는 고차원 및 상세한 영역이 있습니다. 이곳은 생명의 바다의 복잡성이 완전히 표현되는 곳입니다.\n\n선의 맨 위에는 낮은 차원의 압축된 잠재 공간의 영역이 있습니다. 이곳은 아래 영역의 추상적 본질을 보존하는 곳입니다 (여기에는 우리의 언어가 살고 있습니다).\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_19.png)\n\n예술가들은 이 깊이 엘리베이터를 민첩하고 유연하며 동적인 방식으로 탐험하는 일에 능숙합니다. 이에 대해 더 깊이 들어가 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어린이로 낳아져서 나중에 어린이 때, 우리는 주로 깊이 엘리베이터의 바닥에서 우주의 풍부함과 디테일과 상호작용하면서 대부분의 시간을 보냅니다. 우리의 분석적 사고 모듈은 아직 완전히 발달되지 않았습니다. 이것은 우리의 탐험 단계입니다.\n\n한편, 대부분의 성인들은 이미 자신들의 머릿속에 정립된 정신적 패턴을 재사용하여 효율에 중점을 두는 경향이 있습니다 (이는 또한 우리의 뇌를 구동하는 소중한 연료인 포도당을 낭비하지 않도록 도와줍니다). 이것은 우리의 활용 단계입니다. 따라서 성인들은 깊이 엘리베이터의 꼭대기에 있는 좁은 아이보리 탑에서 많은 시간을 보냅니다.\n\n깊이 엘리베이터의 양쪽 반의 시간을 보내는 것 사이의 좋은 균형을 이루는 것은 건강한 목표입니다. 수렴과 발산, 압축과 확장, 추상화와 디테일 사이의 좋은 균형.\n\n이 극성들 사이의 균형 부족(어느 방향이든)은 성인들에게 다양한 문제를 초래합니다. 이에 대해 제가 상세히 썼지만, 이 글의 주제는 아닙니다. 예술가들에 대해 다시 이야기하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_20.png)\n\n많은 위대한 예술가들이 공통적으로 갖고 있는 것이 있습니다. 그들은 이 심도 엘리베이터를 민첩하고 유연하게 탐험할 수 있습니다. 그들은 우주의 풍요함이 기다리는 첫 번째 엘리베이터 아래로 내려갈 수 있습니다.\n\n그리고 필수적인 점은, 그들이 그냥 발가락만 담그지 않고 떠나지 않는다는 것입니다. 대신에, 그들은 아래 아래 오래도록 시간을 보내며 진흙 같고 야생적이며 불안한 물 속을 탐험할 수 있습니다.\n\n또한, 그들은 그 풍부함을 다양한 해석과 표현으로 결정할 수 있습니다. 이들은 세부사항에서 추상화로 이어지는 축 전체를 통해 서로 다른 수준에서 표현될 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 표현 자체나 그 설명이나 전달 방식이 상당히 엘리베이터 깊이의 맨 위에 위치하고 있습니다.\n\n이 모든 것은 일반적인 어른들이 대부분의 시간을 엘리베이터의 맨 위층이나 맨 꼭대기 부근에 보내는 것과 대조적입니다. 그리고 당신은 그 이유를 알 수 있습니다.\n\n추상화의 상역터인 엘리베이터의 꼭대기에 있다는 것은 우주의 복잡한 세부 사항을 포함한 축의 진흙바닥을 탐험하는 것보다 더 편리하며(비유적으로 얘기하면, 우리는 엘리베이터의 바닥에 위치한 야생 놀이터를 탐험해 손을 더럽히는 것보다 훨씬 더 편리하다고 할 수도 있습니다) 더 적은 연료를 필요로 합니다.\n\n여기서 또 다른 중요한 점에 도착합니다. 역사상 가장 훌륭한 예술가들이 할 수 있었던 것처럼 그 깊이 엘리베이터를 탐험하는 것은 노력을 필요로 합니다. 시간이 필요하며 인내가 필요합니다. 그리고, 어른의 마음이 효율적이고 소중한 연료를 낭비하지 않도록 하는 천성에 반항해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![table](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_21.png)\n\n그에 관련하여, 현재 일부 플랫폼들이 제너레이티브 AI 아트를 금지하거나 별도의 범주나 카테고리에 넣고 있습니다. 그 이유는 이를 \"노력이 전혀 들어가지 않은\" 예술로 간주하기 때문입니다.\n\n네, 제너레이티브 AI 아키텍처를 이끄는 적절한 프롬프트를 찾는 데에는 일정한 노력이 필요합니다. 하지만 이 프로세스에 필요한 노력과 시간이 이전에 설명한 과정을 마스터하는 데 몇 년 또는 때로는 수십 년이 걸리는 것과 비교될 수 없습니다. 이러한 점을 좀 더 깊게 살펴보고, 근본적인 해결책에 대해 이 글의 뒷부분에서 다룰 것입니다. 그 때, 이러한 난제에 대한 잠재적인 해결책에 대해 고찰할 것입니다.\n\n따라서, 이 유연한 항해를 통해 위대한 예술가들과 창조자들은 우주의 풍부함을 새롭고 독특한 방식으로 표현할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n삶 속에서 아무 것이나 선택해보세요, 예를 들어, 나무. 나무를 매우 이성적이고 추상적인 방식으로 경험할 수도 있습니다. 아니면 나무의 모든 복잡성을 매우 심층적이고 자세한 수준에서 탐험할 수도 있습니다. 두 극단 사이를 유연하게 이동할 수 있다면, 그 우주 원소와 관련된 새롭고 다른 것을 창조하기에 훨씬 좋은 위치에 있습니다.\n\n![Image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_22.png)\n\n위대한 창조자들 또한 축의 맨 아래에 위치한 그 거대한 바다의 다양한 영역들을 서로 연결하는 여러 방법을 이해할 수 있습니다. 그 바다의 다양한 층들을 통과하며 깊이 엘리베이터의 가장자리를 통해 이어진다.\n\n예를 들어, 위대한 창조자가 리듬을 경험할 때, 그녀는 학문, 기술, 도구와 눈부신 용어를 넘어설 수 있습니다. 위대한 창조자는 리듬을 어디서나 보고 느낍니다. 커튼에 의해 투사된 빛과 그림자 속에서, 떨어지는 눈물의 소리와 움직임에서, 별들의 춤과 우리 생각들 사이의 간격에서, 그 이상을 본다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_23.png)\n\n여러 해와 십년 동안 위대한 창작가들은 잠재적 무의식의 공간을 확장하고 결합합니다.\n\n또한 그들은 심층 엘리베이터를 탐험하는 방식을 정제하여 세부 사항과 추상을 연결하는 강력한 방법으로 창조적 과정을 풍부하게 합니다.\n\n게다가 예술가들과 창작가들은 종종 다른 사람들과 협력합니다. 그렇게 함으로써 서로 다른 무의식의 공간이 서로를 풍요롭게 할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image1](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_24.png)\n\n![Image2](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_25.png)\n\n![Image3](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_26.png)\n\n그래서, 역사상 가장 위대한 창조자들과 예술가들을 연구해 보면, 그들 모두가 말하고자 하는 것, 메시지, 비전이 있었다는 것을 알 수 있습니다. 또한 그러한 비전과 그들이 표현한 방식이, 수십 년 동안 발전시킨 자신의 역량과 밀접하게 연결되어 있었는데, 그들은 순발력 있게 이 심층 엘레베이터를 탐험하면서 우주의 풍요함의 심미함과 추상화의 상공을 탐험하며 두 극지 사이의 다양한 영역을 탐험하였습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마침내, 그 깊이 엘리베이터에 관해, 다음 단계는 그것들을 고립된 개체로 보는 것이 아니라, 다차원 공간 내에서 상호 연결된 여러 퍼널로 시각화하는 것입니다.\n\n다음 오리가미 이미지는 비유의 그 확장의 작은 조각을 나타내기 위해 노력했습니다.\n\n그러나 이제는 엘리베이터를 멈추고 나아가서, 생성적 AI 혁명의 현재 상황을 검토하고 그 성장 과정에 대처하는 방법에 초점을 맞추는 시간입니다.\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_27.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 살펴본 내용을 활용해 오늘 상황과 앞으로 올 가능성을 고려해보고, 이에 대해 어떻게 대응할지 살펴봅시다.\n\n## 좋은 점, 복잡한 점 그리고 방에 있는 코끼리\n\n이 창조적인 AI 혁명 초기 단계에서 파생된 여러 결과를 탐색해 봅시다.\n\n## 좋은 점\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Generative AI는 인간의 창의력을 대체하지 않을 것입니다. 그것은 강화할 것입니다.\n- 이 기술은 창의성을 풀어줍니다. 에디슨이 말한 것을 생각해보세요: 천재는 땀 흘리기의 99% (조합, 재조합, 생산적 작업 및 실험)와 영감의 1% (씨앗을 정립하는 것, 깎아내기 등)입니다. 이 새로운 기술 덕분에 우리는 이제 창조적 과정의 상당 부분을 자동화할 수 있다는 것을 깨닫게 됩니다. 이 과정은 우리 마음 속에서 무의식적으로 일어나는 부분입니다.\n- 인간의 의사결정에 관한 연구에 따르면, 우리는 하루에 3만 번 이상의 결정을 내립니다. 그러나 우리는 그 중 약 0.26%만을 자각합니다(Huawei의 연구 참고). 생각보다 우리 삶의 많은 부분이 무의식적으로 이루어지고 있다는 걸 깨닫게 됩니다. AI 기술을 사용하여 우리의 무의식적인 요리 과정을 자동화함으로써, 우리는 우리 존재의 상당 부분에 긍정적인 영향을 줄 수 있습니다.\n- 사실, 저는 이 새로운 시대를 \"슈퍼 무의의 시대\"라고 부르고 있습니다.\n\n[이미지 바로가기](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_28.png)\n\n- 이 기술을 다양한 아이언맨 수트 시리즈로 생각해보세요. 이것들은 당신의 무의식적 잠재력을 증폭시키고 창의적인 능력을 강화할 것입니다.\n- 각각의 아이언맨 수트는 다른 스타일, 특성 및 성격을 가졌습니다.\n- 프롬프트 엔지니어는 이러한 아이언맨 수트에서 최상의 결과물을 얻는 전문가가 될 것입니다. 그들은 각각의 장단점과 특성을 잘 파악할 것입니다.\n- 그들은 또한 원하는 결과를 얻기 위해 이러한 강력한 증폭기와 상호작용할 때 인간적 경험과 직관을 사용하는 마스터가 될 것입니다.\n- 따라서 이러한 프롬프트 전문가들은 앞으로 매우 존경받을 것입니다. 그들의 역할은 취업 시장에서 권위 있는 것이 될 것입니다. 그리고 이런 기술을 교육하고 역량을 키우는 수업, 출판물 및 시스템이 많이 등장할 것입니다.\n- 오늘날, 우리의 프롬프트는 자연어와 이미지입니다. 하지만 멀티모달 구조를 통해, 프롬프트는 이러한 구조를 이끌어 줄 수 있는 다양한 종류의 데이터가 될 것입니다(다양한 시스템이 여러 유형의 안내 입력을 수용하도록 설계될 것입니다).\n- 초기 텍스트에서 이미지로의 단계가 이제 텍스트에서 비디오 및 3D 능력으로 전환되었습니다. 결국 우리는 특정 수직분야의 필요에 맞는 커스텀 시스템으로 다양한 종류의 데이터를 출력할 수 있게 될 것입니다.\n- 다음으로, 우리는 멀티모달 출력 기능을 목격할 것이며, 이를 통해 시각, 대화, 음악 등을 포함한 완전한 영화를 제작할 수 있는 시대가 올 것입니다.\n- 이 기술은 아직 상상하지 못한 새로운 예술 형태를 영감을 받을 것입니다. 멀티모달 생성 AI는 탐구된 영역과 탐험되지 않은 영역을 결합하는 새로운 형태의 예술 표현이 매우 존경받을 것이라는 시기로 넘어서게 될 것입니다.\n- 생성 AI는 매우 많은 분야에 영향을 줄 것입니다. 합성 세대로 과학적 데이터 세트를 확장하고, 브레인스토밍 프로세스를 혁신하며, 몇 달 전에는 상상할 수 없었던 방식으로 브랜딩을 개인화하며, 실시간 동적인 “당신만을 위한” 마케팅 및 광고의 봉사 시대를 가속화하며, 모든 종류의 발표를 둘러싸는 미디어를 그것들의 내용과 인상적인 방식으로 일치시킬 것입니다. 주식 라이브러리부터 디자인 부티크까지, 미디어 산업의 많은 부분이 이 기술을 채택하고 경쟁적으로 활용할 것입니다.\n- VR 및 AR과 같은 최첨단 기술(일반적인 XR의 모든 형태를 포함하여)은 이 기술을 통합할 것입니다(실험은 이미 진행 중입니다). 결국 우리는 사용자의 시선을 추적하여 스마트하게 재생하는 몰입형 공간을 실시간 생성하는 것을 목격하게 될 것입니다(이러한 실험과 Donald Hoffman의 이론 사이의 연결을 고려하는 것이 흥미롭습니다).\n- 이 기술은 많은 창의적 프로세스의 탐구와 실험 단계를 가속화할 것입니다. 컨셉 디자인, 제품 디자인, 캐릭터 디자인 및 다양한 분야의 프로토타이핑 단계에서, 생성 AI를 통해 우리는 시간을 더 적게 들이고 새로운 방향을 시험하며, 모든 수준의 탐구에 깊이 빠져들 수 있을 것입니다.\n- 많은 사람들에게는 \"메타버스\"는 여전히 유토피아이며, 그것을 적절히 구현하는 데는 꽤 오랜 시간이 걸릴 것으로 보입니다. 만약 메타버스가 유용한 현실로 이루어질 경우, 이는 아마도 생성 AI 기술의 노력으로 이뤄질 것이며, 이 기술이 구현을 가속화하는 핵심 요소가 될 것입니다.\n- 미래에는 우리의 요구나 감정 상태에 따라 변화하는 스마트 생성 환경(SGE)의 부상을 목격할 것입니다. 집, 이벤트 장소 및 기타 환경은\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 우리, 인간들은 한정된 상대적으로 작은 잠재의식적 인재를 가지고 있습니다. 생성적 AI 시스템은 인터넷 지식의 상당 부분을 포함하는 거대한 재료를 가지고 훈련됩니다.\n- 그래서, 인간 창작자들이 생성적 AI 시스템과 경쟁해야 하는 것은 공정하지 않고 도덕적으로 옳지 않다고 생각되지 않습니다.\n- 기계가 체스에서 인간을 이기는 것을 넘어선 경우 (이것보다 더 중요하지 않은 사건), 아무도 그것이 인류 대 기계 체스 대회를 계속 즐길 가치가 있다고 생각하지 않았습니다 (우리가 패배했다는 점을 보여 준 대회를 넘어서). 우리는 그들이 우리보다 더 잘한다고 인정했습니다. 그리고 우리는 각자의 길을 가기로 했습니다.\n- 인간 체스 선수들은 자신을 훈련시키고 더 나아지기 위해 AI를 사용합니다 (이는 생성적 AI 시스템이 제공하는 비유적 철 인형 수트의 능력 증가와 증폭과 유사합니다).\n- 체스나 바둑을 하는 AI 시스템은 때로 사람이 생각지 못할 정말 아름다운 수를 만들어냅니다. 그들만의 특별한 시각을 가지고 있습니다 (물론 시간을 멀리 앞서다 봄이라는 엄청난 능력에 기반합니다). 그럼에도, 기계 대 기계 대회를 따라가는 사람은 매우 적습니다. 인간들은 다른 불완벽한 인간들이 경기하는 것을 더 선호합니다.\n- 어쨌든, 가장 중요한 것은 그들이 두 영역을 분리한다는 것입니다. 기계가 인간 체스 선수들을 훈련시키고 더 나아지도록 돕고, 그들끼리 대결도 할 수 있습니다. 인간들은 별도로 자신들의 대회에서 경기를 합니다.\n- 생성적 AI에 대해서도 결국 비슷한 일이 일어날 것이라고 믿습니다 (물론 매우 다른 영역이기 때문에 몇 가지 차이점이 있을 것입니다).\n- 고려해야 할 또 다른 까다로운 문제는 이 기술에 대한 현재 흥미 때문에 발생한 핵심 요인입니다. 이에 대해 제가 이 기사의 마지막 부분에서 자세히 다룰 것입니다. 일단 지금은 소개하겠습니다.\n- 그렉 루코우스키(Greg Rutkowski)는 많은 사람들이 판타지 아트 분야에서 최고인지 아니면 최고인 것으로 여기는 생각입니다. 그리고 그의 이름은 최근 몇 차례에 걸쳐 가장 인상적인 생성적 AI 아트를 만드는 데 사용된 많은 프롬프트들 중에 등장합니다.\n- 그래서, 그렉 루코우스키가 그린 것 같은 놀라운 아트를 생산함으로써 유발된 도파민 분비가 끝나면, 그 도파민 분비가 꺾일 때, 많은 사람들이 AI가 생성한 이미지나 비디오 수백 개 혹은 수천 개를 가지고 \"그럼, 이제 어떡하지?\"라고 자신에게 물을 것입니다.\n- 대부분의 경우 \"아무것도\"가 대답이 될 것입니다. 왜냐하면 그들 대부분이 어떤 심오한 의미 있는 내재적 동기에 따라 창의력을 발휘한 것이 아니었기 때문입니다; 그들은 이 기술을 사람이 새 iPhone를 사는 사람처럼 본능적인 방식으로 사용했기 때문입니다. 빛나는 최신 기술을 따라가기 위해.\n- 그 본능이 가라앉으면, 그들은 어떤 면에서 빈 공허함을 느낄 것입니다. 왜냐하면 남아 있는 것 대부분은 그들의 것이 아니라, 그렉 루코우스키와 그의 스타일에 속한 몇십 년간의 열심히 한 결과인데, 이것이 유감스러운 일입니다 (많은 다른 활동 중인 아티스트들의 작품이 이러한 네트워크를 이끄는 것입니다). \n- 어쨌든, 현실적으로 생각해보죠. 일들이 너무 빨리 움직이고 있고, 사람들이 따라잡는 시간이 필요하다는 것이 이해됩니다. 현재 시나리오에 대해 해결책이 많을 수 있습니다. 이에 대해 다음 섹션의 끝에서 몇 가지 논의하도록 하겠습니다.\n\n# 룸 안의 코끼리\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_29.png)\n\n- AI 생성 시스템은 훈련에 사용되는 거대한 데이터 세트 덕분에 가능합니다.\n- AI 생성 아키텍처는 이미지, 비디오, 텍스트로 구성된 거대한 데이터 세트로 훈련됩니다.\n- 이 데이터는 일반적으로 이러한 데이터 세트를 만드는 그룹에 의해 인터넷에서 추출됩니다.\n- 이러한 데이터 세트에 사용된 일부 데이터는 공공 도메인 데이터입니다. 이러한 데이터를 사용하여 데이터 세트를 만드는 것은 공정하다고 생각됩니다.\n- 하지만 이러한 데이터 세트에 사용된 많은 데이터는 공개 도메인 데이터로 선언하지 않은 활동 중인 예술가들의 소유입니다. 이러한 활동 중인 예술가들은 특정 스타일과 일련의 작품을 만들어내기 위해 수십 년간 노력하고 이를 판매함으로써 생계를 유지합니다.\n- 이러한 예술가들이 이 혁명이 급부상하는 데 기반으로 삼고 있습니다.\n- 그래서, 점점 더 많은 활동 중인 예술가들이 이에 대해 불평하고 있습니다. 그 중 일부는 활동 중인 예술가들의 작품은 이러한 데이터 세트에 포함해서는 안 된다고 주장합니다. 일부에 따르면, 그들의 불평이 무시당하고 있다고 말합니다. 그들은 대부분 무시당하고 있는 것입니다 (적어도 지금까지는).\n- 이러한 활동 중인 예술가들의 불평을 무시한다면, 우리 자신을 무시하는 것입니다. 오늘은 시각 예\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 인류에 많은 혜택을 가져다줄 멋진 혁명입니다. 그러나 우리가 볼 수 있듯이, 이 초기 단계에서 고려해야 할 까다로운 면도 있습니다. 어떻게 대처할 수 있는지 논의해 보겠습니다.\n\n![이미지](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_30.png)\n\n## 혁명을 이끌어가기\n\n나는 도덕적이고 윤리적인 입장에서 이 마지막 섹션을 다루고자 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결국, 다양한 규제 형태를 도입할 것으로 예상되며 기업들도 자체 보호장치와 통제를 도입할 것입니다. 하지만 이러한 법적 시각을 포함한 것들이 확립되기까지는 시간이 필요할 것입니다.\n\n하지만 우리가 기대하는 것보다는 그렇게 오랜 시간이 걸리지 않을 것 같아요. 다음 섹션에서는 Adobe가 설립한 오픈 표준인 콘텐츠 신뢰성 이니셔티브 (CAI)에 대해 논평할 거에요. CAI에는 이미 수백 개의 기업이 참여했고, 그 중 일부는 이미 자사 플랫폼에 이를 구현할 계획을 세우고 있습니다.\n\n이를 통해 디지털 콘텐츠의 출처를 추적하고, 생성 AI가 사용되었는지 여부, 창작자의 권리 보호와 관련된 다른 요소들을 파악할 수 있게 될 거에요.\n\n이제 이 혁명을 더 지속 가능하게 만드는 방법에 대해 고민해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데카드를 자랑하는 거대한 생성적 AI 데이터 세트 중에 이 작가의 작품이 포함되려면 이 작가만의 저작권을 보유하고 있으며 수십 년 동안 스타일과 작품집을 개발해 온 살아있는 예술가는 의견을 내거나 보상을 받아야 합니다.\n\n그렇지 않으면, 예를 들어 갤러리 안에 작품을 전시하고 누군가가 와서 가져가서 이익을 취하는 것과 마찬가지입니다. 생성적 AI 혁명이 시작될 때 마술처럼 사라지지 않은 저작권이라는 보편적으로 인지되는 것이 있습니다.\n\n어떤 사람들은 YouTube의 예를 들어 이 문제들을 손대던 초기에 YouTube가 이 문제들을 손대지 않았다면 결코 성과를 거두지 못했을 것이라고 말합니다. 우리가 다 아는 것처럼 요즘은 YouTube가 플랫폼 내에서 저작권을 보호하기 위한 매우 엄격한 메커니즘을 가지고 있습니다. 사실, 생성적 AI는 이미 엄청난 방식으로 폭발적으로 성장했습니다. 따라서 초기의 이상한 단계는 이해할 수 있지만, 그 단계는 이미 뒤에 남아 있습니다. 그러므로 YouTube나 다른 유사한 플랫폼이 행한 것처럼, 지금은 창작자의 권리를 보호하기 시작할 때입니다.\n\n마지막으로, 회색 지대에 대해 논의할 필요가 있습니다. 이를 이해하기 위해 이전 절에서 제기한 한 가지를 빨리 되짚어 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인간과 기계가 동일한 예술 대회, 예술 플랫폼 등에서 경쟁하는 것은 공정하지 않습니다. 사람은 무의식적인 팟을 가지고 있어요. 반면 AI 시스템은 엄청나죠. 인간의 무의식적인 팟은 그들의 삶, 단 하나의 삶의 한정된 경험을 담고 있어요. 반면 AI 시스템은 수백만 또는 수십억 명의 인간의 지식을 보유하고 있어요. 우리가 현실적으로 생각해 봅시다. 그들끼리 서로 경쟁하는 것은 공정하지 않고 도덕적이지 않아요.\n\n대신, 체스에서 일어난 것처럼 예술 대회와 예술 플랫폼에서 별도의 부문을 상상할 수 있어요. 인간이 만든 예술과 AI가 만든 예술. 이미 세계의 많은 플랫폼에서 이러한 현상이 일어나고 있어요. 하지만 이러한 점은 결국 그레이 존으로 우리를 이끌어가요.\n\n# 그레이 존\n\n\"잠깐, 이 작품은 AI만으로 완전히 제작된 것이 아니에요. 네 알아요, 제가 일부를 AI를 사용해서 만들었지만, 그 후에 저는 그것을 연마하고 더해나갔기 때문에 합법적이지 않나요?\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 이를 많이 듣게 될 것입니다. 그래서 이런 종류의 시나리오에 대해 주의를 기울이는 것이 중요합니다.\n\n미국 저작권 사무소의 최근 판결에 따르면, AI가 생성한 작품을 등록하려는 요청과 관련하여 \"미국에서는 저작권 보호에는 인간의 저작자가 선행되어야 하며, 따라서 해당 작품은 등록될 수 없다\"고 밝혔습니다. 이 판결에 대한 자세한 토론은 여기에서 확인할 수 있습니다.\n\n하지만 우리가 직면하게 될 것 (이미 발생하고 있는 일들)은 회색 영역입니다. 중간 지대입니다. 그리고 이에 대한 답은 공공 도메인 대 비공공 도메인에 대한 토론에서 찾을 수 있다고 생각합니다.\n\n왜냐하면 어느 정도로 모든 것이 바뀌었지만, 아무것도 바뀌지 않은 것 같습니다. 이제 시작합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Generative AI가 급격하게 발전하기 전에는 구글 검색을 통해 공개 도메인 이미지, 비디오 또는 어떠한 종류의 데이터를 찾아 창의적인 프로세스에 통합할 수 있었고, 모든 것이 공정하고 좋았습니다.\n- Generative AI가 급격하게 발전하기 전에는 구글 검색을 이용하여 일부 활동 중인 예술가의 비공개 도메인 이미지, 비디오 또는 어떠한 종류의 데이터를 찾아 그 작품과 본인의 작품이 결합된 결과물로 이윤을 추구할 때 허가를 받지 않고 가져다 사용하거나 통합할 수 없었습니다 (당연히 자신의 작품과 결합된 결과물로 이익을 취하려고 할 때 말입니다. 단지 온라인 작품을 이용해 단순 실험을 하고자 하는 경우, 이익을 얻지 않고 개인적으로 사용하는 경우는 토론의 대상이 아닙니다).\n\n이것이 바로 답이에요. 아무것도 새로운 게 없습니다. 동일한 기준이 계속 적용될 수 있다는 거죠.\n\n- 우리가 이 Generative AI 혁명 속에서 항해하면서, 공개 도메인 데이터만 사용하는 데이터셋에 연결된 기술을 사용하는 것은 괜찮을 것입니다 (또는 이러한 데이터셋 내에서 사용되는 예술가들로부터 명시적으로 허가를 받은 데이터). 다시 말하지만, 이 기술을 사용하여 이익을 얻기 위해 만들어진 시나리오에 대해 이야기하고 있습니다.\n- 상업적 목적으로 결과물을 사용하고자 하는 경우, 비공개 도메인 데이터를 포함하는 데이터셋을 완전히 또는 일부 사용하는 것은 적합하지 않을 것입니다. 유명한 활동 중인 예술가의 작품을 다운로드하는 현재의 상황을 예로 들어 자신의 개인적 사용 목적으로 실험해 볼 수는 있지만, 반드시 상업적 목적으로 사용하면 안 됩니다.\n\n이것은 제 생각으로는 상식에 기반한 생각입니다. 하지만 다른 사람들은 예술가들에게 보상을 제공하는 새로운 방법을 찾아서 이러한 위기를 해결하는 새로운 길을 제시할 수 있습니다. YouTube는 이러한 문제를 해결하기 위한 대안적인 방법에 대한 단서를 다시 제공합니다 (아래에서 더 자세히 설명하겠습니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 예술 대회, 예술 플랫폼, 스톡 이미지 플랫폼 등은 참가자들에게 다음을 공개할 것을 요청할 수 있습니다:\n\n- 생성 데이터 AI 기술을 사용했는지 여부.\n- 사용한 경우, 어떤 것을 사용했는지와 그 기술을 구동하는 데이터셋이 무엇인지.\n- 해당 기술을 구동하는 데이터셋이 공공 도메인 데이터만 포함하는지, 그렇다면 해당 작품을 수용할 수 있습니다.\n- 관련 데이터셋이 공공 도메인 이외의 데이터도 포함하는 경우, 해당 작품을 거절하거나 따로 구분해서 전시할 수 있습니다.\n- 물론 사람들이 거짓말을 할 수 있습니다. 때문에 작업의 일부가 저작권으로 보호받는 활동 중 일치할 경우를 인식할 수 있는 자동화 시스템이 늘어날 것입니다.\n\n예를 들어, 오늘날 YouTube와 같은 플랫폼에서는 사용자가 업로드하는 비디오 음악에 관련하여 사용하고 있습니다. 오류가 많이 발생할 것이고 같은 일이 발생할 것입니다. YouTube가 현재 사용하는 시스템과 같습니다. 살아있는 창작자와 예술가들의 권리를 보호하기 위한 대가입니다.\n\n이러한 메커니즘을 모든 종류의 데이터와 음압보다 복잡하고 고차원의 데이터까지 모두 포함하도록 확장하는 것은 쉽지 않을 것입니다. 하지만 이미 이와 같은 문제에 대해 연구하고 있는 사람들이 분명히 이미 존재합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n유튜브를 다시 살펴보면, 플랫폼이 공개 도메인 데이터 위에 구축된 새로운 AI 아트에 대처하는 다양한 방식들을 볼 수 있습니다 (사용자가 선언하거나 자동 시스템이 감지하거나 CAI 표준이 제안하는 기술 같은 것들이 감지에 도움을 줄 것으로 예상됩니다).\n\n플랫폼은 이러한 작품에 광고를 넣고 영향을 받는 아티스트들과 수익을 나눌 수 있습니다. 또는 아티스트나 창작 그룹과 관련된 저작권이 적용된 지역에서 해당 작품의 일부 또는 전체를 차단할 수 있습니다. 또는 이러한 시나리오가 더 명확해질 때까지 휴먼 크리에이션에서 따로 특별한 범주에 넣을 수도 있습니다. 우리는 공개 도메인 데이터를 활용한 휴먼+AI 시스템에 의해 생산된 창작물들에 대한 처리 방법의 다양성을 눈여겨봐야 합니다. 요약하자면, 탐지 시스템이 충분히 발전하게 되면, 이러한 회색 지대를 다루는 다양한 방법들이 등장할 것입니다.\n\n해당 탐지 시스템에 대한 작업은 이미 시작되었습니다. 스마트 메타데이터 및 기타 도구를 활용한 CAI 표준은 곧 전 세계의 회사와 플랫폼에서 시행될 것입니다. 이것이 무엇을 하는지 간단히 살펴보겠습니다.\n\n# 책임 있는 AI와 콘텐츠 신뢰성 이니셔티브 (CAI)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수많은 회사들과 그룹들이 이미 회색 영역과 잘못된 정보를 다룰 수 있는 시스템을 설계하는 연구를 진행하고 있습니다.\n\n이러한 시스템 중 하나는 Adobe가 시작한 콘텐츠 신뢰성 이니셔티브 프로젝트(CAI)입니다. CAI는 실제로 2019년에 시작되었는데, Adobe와 같은 회사들이 AI 도구가 잘못된 정보를 생산할 수 있는 가능성에 대비하는 표준의 필요성을 예견했기 때문입니다.\n\n그들의 말에 따르면, CAI 회원들은 \"미디어 및 기술 회사, 비정부 기관, 학자 및 기타 이해관계자로 구성된 커뮤니티로, 콘텐츠 신뢰성과 근원에 대한 개방형 산업 표준 채택을 촉진하는 데 일했습니다.\" 그룹은 무료로 가입할 수 있으며, 디지털 콘텐츠의 근원 및 소유권을 캡처부터 배포까지의 전체 파이프라인에서 추적할 수 있는 오픈 소스 도구를 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n창의적인 작업을 한 사람들이 그들의 노력을 인정받을 수 있고, 사람들과 플랫폼이 다루고 있는 콘텐츠의 원본과 제작 방법을 이해할 수 있는 것이 최종 목표입니다.\n\nCAI 표준이 특정 콘텐츠를 만들 때 생성 AI가 사용되었는지, 그 방법에 대해서 사람들이 알 수 있게 될 것이라는 것을 강조해야 합니다.\n\n대기업들이 \"책임 있는 AI\"라고 부르는 것을 촉진하려고 노력하고 있다는 것은 좋은 신호입니다. 또한, 디지털 콘텐츠의 각 부분이 어디에서 왔는지, 생성 AI가 제작에 관여했는지 여부, 콘텐츠에 부착된 저작권 등을 알 수 있는 시스템이 구축되고 있다는 것도 중요합니다.\n\n사진 기자 및 다른 창작자들의 개인 정보 보호와 보안을 위해, 이러한 시스템을 사용할 때 창작자들은 속성을 보존할지 익명을 유지할지 선택할 수 있는 옵션이 있다는 것을 강조하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n세계는 지켜보고 있어요. 최근 Visual 1st 컨퍼런스(이미징 에코시스템을 위한 주요 컨퍼런스로, 샌프란시스코에서 개최되며 Hans Hartman과 Alexis Gerard가 주도)에서 generative AI가 큰 화제였어요. 저는 이번 행사에서 열린 파이어사이드 챗을 통해 Hans와 Alexis와 멋진 대화를 나누는 기회를 가졌어요.\n\nPaul Melcher와 같은 시각 기술 전문가들은 generative AI의 최신 기술을 전 세계 관객들에게 소개하는 데 큰 역할을 하고 있어요.\n\nfast.ai와 같은 기관에서 AI 마스터 프로그램까지 전 세계의 교육자, 수백만 명의 팔로워를 가진 유튜버, 그리고 prompt engineering 전문가들이 이 혁명의 모든 과정을 문서화하고 설명하고 있어요.\n\n데이터셋 분야에서는 datasetshop.com과 같은 매우 흥미로운 기업과 프로젝트도 찾아볼 수 있어요. vAIsual의 기술을 이용하는 이들은 합법적으로 깨끗한 합성 재고 미디어를 생성하는 선구적인 기업들로, 세계 최대의 라이선스 취득 가능한 생체 측정 방출 실제 데이터셋을 만들어내고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다시 \"Responsible AI\"와 \"Legally Clean\" 데이터셋 같은 용어가 등장하고 있다는 것은 좋은 소식입니다.\n\n이 두 분야에서 활발하게 활동하는 하나의 인간으로서, 생성적 AI와 예술에 대해서 다뤄보려고 노력했습니다. 이 글을 통해 이러한 역동적인 초기 단계에 관련된 여러 관점을 개략적으로 살펴볼 수 있도록 했습니다.\n\n우리에게 꼭 상기시켜야 할 것은 이러한 것들이 실제로 급속하게 발전 중인 맥락에서 이루어지고 있다는 사실입니다. 그러므로 우리 모두는 인류에게 많은 혜택을 가져다줄 기술을 촉진하고, 창조적인 사람들과 예술가들의 권리를 지키는 것 사이에서 올바른 균형을 찾으려 최선을 다할 때 서로 최대한 부드럽도록 하는 것이 중요합니다.\n\n# 미래가 가지고 있는 것\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다가오는 시대에 대해 내 의견은 다음과 같고, 간단히 말하자면:\n\n- 예술가들은 계속해서 예술가로 남을 것입니다. 이 기사는 명확하게 설명했듯이, 예술가인지 아닌지는 특정 도구나 기술과 관련이 있는 것이 아닙니다. 그 대신, 과거에 탐구한 깊이 높은 것들과 상호작용하는 방법과 많은 연관이 있습니다.\n- 엔지니어들은 계속해서 엔지니어로 남을 것입니다.\n- 연구원들은 계속해서 연구원으로 남을 것입니다.\n- 신속 엔지니어(새로운 세그먼트)은 그냥 신속 엔지니어가 되리라.\n- 그리고 AI 기술과 신속 엔지니어링을 자신의 과정에 통합하는 예술가 및 창작가들, 전문가든 아니든(다음 내용은 전문 창작가나 자신의 창작력을 발휘하려는 자연스러운 성향을 가진 사람들에게도 동일하게 적용됨)은 자신들의 분야를 주도할 기회를 더욱 높일 수 있을 뿐만 아니라, 이 강력한 아이언맨 슈트(거대한 무의식의 냄비)를 통해 아이디어를 숙성시키고, 창의적 생산과정을 가속화하기 위해 그와 동일한 기술을 사용함으로써 더욱 뛰어난 예술가와 창작가가 될 수도 있습니다.\n- 마지막으로, 게으른 사람들은 계속해서 게으른 사람으로 남을 것입니다.\n\n# 함께 만들어봐요\n\nAI는 분명히 우리 곁으로 오고 있습니다. 우리는 모두 함께 최선을 다해 이 혁명에서 최대한 인류에 이롭게 작용할 수 있도록 협력해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사를 완성하고 꽤 복잡한 문제들을 탐구한 후 가벼운 분위기로 마무리 지어 봅시다. 이 멋진 기술에 대한 음악적 헌사를 들으며 마무리합시다.\n\n다음은 소프라노 코바동가 곤잘레스 베르나르도의 공연 조각입니다. 다양한 AI 시스템과 제가 함께 작곡한 곡을 연주하고 있습니다. 가사에는 GPT 아키텍처가 사용되었고, 멜로디와 코드에는 음악 변형기가 사용되었으며 시각적인 부분에는 VQGAN이 사용되었습니다. (이 작은 조각에는 시각적 요소가 나타나지 않습니다). 이 프로젝트는 몇 차례 강연을 한 Instituto of Inteligencia Artificial @ iia.es에서 제안하고 조직했습니다.\n\n그다음으로, 인공지능 생성주의 주제에 바탕을 둔 간단한 피아노 연주가 나옵니다. 인간의 잠재력에 더 가까워진 인공지능에 대한 곡입니다.\n\n마지막으로, 시간 여행 재미 요소가 포함되어 있습니다. 우리 모두가 오늘날의 인공지능 생성과정을 몇 십 년 전에는 기적으로 해석했을 것이라는 것을 감사히 여길 수 있을까요? 1950년에 스페인으로 시간을 되돌려 봅시다 :)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여러분 모두 건강하게 지내세요. 그리고 무엇보다도 인간 다운 모습을 유지해주세요.\n\n# 에필로그\n\n제 마지막 문구에 대해, \"인간 다운 모습을 유지해주세요\".\n\n가끔 사람들이 묻습니다: 30, 40, 또는 50년 후에 인공지능이 시스템 2 능력(추론, 계획 등)에서 뛰어날 때 어떤 일이 일어날 것이라고 생각합니까?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템 1과 2는 우리 마음 속의 다른 종류의 사고 모드입니다.\n\n시스템 1은 빠르고 무의식적이며 동시에 직감적인 프로세스를 의미하며, 이곳이 AI가 초인적 능력에 도달하고 있는 영역입니다.\n\n시스템 2는 천천히, 논리적으로, 합리적으로, 체계적으로, 정확하고 연속적인 종류의 사고를 의미합니다. 이 두 번째 모드를 숙달하는 것은 아직 우리의 AI 시스템이 능숙히 할 수 있는 것을 넘어섰습니다. (시스템 1 대 시스템 2 사고에 대해 더 알고 싶다면 다니엘 카네먼의 책 \"사고, 빠르게 하고 천천히\"를 참고하세요).\n\nAI와 관련하여 현재와 미래에 시스템 2의 능력에 대한 토의는 이 정도와 더 큰 분량의 기사를 채울 정도입니다. 그래서 그에 대한 논의는 다른 시간에 남겨두겠습니다. 이 자막의 시작에서 제시된 질문으로 돌아가 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수십 년 후에는 이 질문이 더 이상 의미가 없을 수 있다고 일반적으로 대답합니다. 왜냐하면 오늘날에는 인공 지능과 인간 사이에 구분이 있기 때문이죠. 인공 지능이 존재하고, 우리는 여기 있습니다.\n\n그러나 몇 십 년 후에는 그 구분이 더 이상 존재하지 않을 것입니다. 이미 회사 Neuralink가 현재 진행 중인 일들을 생각해보세요. 그것은 앞으로 올 것 중에 매우 일부에 불과합니다.\n\n몇 십 년 후에는 우리의 기술과 인간생물학을 포함한 우리의 생물학이 여러 면에서 결합될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 새로운 질문이 있을 수도 있어요: \"우리가 함께 있으니, 다음으로 어디로 갈까요?\"\n\n읽어 주셔서 감사합니다.\n\n![image](/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_31.png)","ogImage":{"url":"/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_0.png"},"coverImage":"/assets/img/2024-06-22-TowardsaSustainableGenerativeAIRevolution_0.png","tag":["Tech"],"readingTime":26},{"title":"Artvyai로 당신의 내면 예술가를 펼치세요  최고의 무료 AI 아트 플랫폼","description":"","date":"2024-06-22 21:49","slug":"2024-06-22-UnleashYourInnerArtistwithArtvyaiTheUltimateFreeAIArtPlatform","content":"\n\n혁신적인 AI로 생성된 예술 세계를 탐험할 준비가 되셨나요? Artvy로 가보세요! 최고의 무료 AI 예술 플랫폼입니다. 첨단 DeepArt 기술과 놀라운 스티커로 AI 작품을 개인화할 수 있는 기능을 통해 창의성을 발휘할 수 있습니다.\n\nArtvy의 활기찬 AI 예술 커뮤니티에 가입하여 Stable Diffusion 및 Midjourney 알고리즘을 활용하여 아이디어를 독특한 디지털 걸작으로 변환하는 방법을 배워보세요. 무료 생성기를 통해 각 작품을 자유롭게 만들어내고 비용 없이 창의력을 발휘하세요!\n\nAI로 생성된 예술의 힘을 발견하고 artvy.ai에서 디지털 창작의 즐거움을 느껴보세요. \n\n![이미지](/assets/img/2024-06-22-UnleashYourInnerArtistwithArtvyaiTheUltimateFreeAIArtPlatform_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n진짜 예술가들의 작품도 참고하는 것을 잊지 마세요! AI 예술은 혁신적이고 흥미로운 것이지만 전통적인 예술가들의 재능을 지지하고 감상하는 것도 중요합니다.\n\n시작할 준비가 되셨나요? 오늘 Artvy.ai에서 AI 생성 예술의 세계에 뛰어들어 창의력을 펼쳐보세요.\n\nArtvy에 대해 더 알아보세요:\n\n- Artvy 웹사이트\n- DeepArt 기술\n- 생성적 예술\n- 알고리즘 예술","ogImage":{"url":"/assets/img/2024-06-22-UnleashYourInnerArtistwithArtvyaiTheUltimateFreeAIArtPlatform_0.png"},"coverImage":"/assets/img/2024-06-22-UnleashYourInnerArtistwithArtvyaiTheUltimateFreeAIArtPlatform_0.png","tag":["Tech"],"readingTime":1},{"title":"ComfyUI 설치 가이드 Linux, Windows","description":"","date":"2024-06-22 21:48","slug":"2024-06-22-InstallingComfyUILinuxWindows","content":"\n\n친절한 마음으로 설치 방법 알려드립니다.\n\nLinux 또는 Windows에 ComfyUI를 수동으로 설치하세요.\n\n![이미지](/assets/img/2024-06-22-InstallingComfyUILinuxWindows_0.png)\n\n오랫동안 미게시 상태로 남아있었기 때문에 이를 새로 공유하려 합니다. 쉽게 설치할 수 있는 휴대용 Windows 버전이 있지만, 이 가이드에서는 수동 설치 방법을 다룹니다.\n\n## 전제조건\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPython 3.10\nGit\n\n## 단계 1: 레포지토리 복제하기\n\n명령 프롬프트(Windows)나 터미널(Linux)을 열고 레포지토리를 설치할 위치로 이동합니다. 윈도우의 C 드라이브 루트 디렉토리에 ai라는 폴더를 생성하고, 리눅스에서는 사용자의 홈 디렉토리에 해당 폴더를 생성합니다.\n\n![이미지](/assets/img/2024-06-22-InstallingComfyUILinuxWindows_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 Markdown 형식으로 표태그를 변경해주세요.\n\n\n\u003cimg src=\"/assets/img/2024-06-22-InstallingComfyUILinuxWindows_2.png\" /\u003e\n\n\nGit을 사용하여 레포지토리를 클론해주세요. 클론이 완료되면 현재 작업 디렉토리를 ComfyUI로 설정해주세요.\n\n```js\ngit clone https://github.com/comfyanonymous/ComfyUI.git\n```\n\n```js\ncd ComfyUI\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-22-InstallingComfyUILinuxWindows_3.png)\n\n![이미지](/assets/img/2024-06-22-InstallingComfyUILinuxWindows_4.png)\n\n## 단계 2: 가상 환경 만들기\n\n이제 가상 환경(venv)을 생성할 것입니다. 이 저장소의 설치 지침은 시스템 전역 수준에서 종속성을 설치하는 것을 제안하지만, 종속성 같은 것들은 다른 프로젝트들과 겹치는 영역을 피하기 위해 자체 venv 내에서 격리시키는 것이 더 나은 것 같아요. 다음 명령어를 사용할 거에요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\npython -m venv을 사용하여 새로운 가상 환경을 만들 수 있어요. 가상 환경의 이름을 venv로 지정할게요. 가장 간단하게 설정하기 위해요.\n\n```js\nREM: Windows용\n\nREM: 가상 환경 생성\npython -m venv venv\n\nREM: 가상 환경 활성화\nvenv\\Scripts\\activate.bat\n```\n\n```js\n# Linux용\n\n# 가상 환경 생성 (참고: python3 사용)\npython3 -m venv venv\n\n# 가상 환경 활성화\nsource venv/bin/activate\n```\n\n![이미지](/assets/img/2024-06-22-InstallingComfyUILinuxWindows_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-22-InstallingComfyUILinuxWindows_6.png)\n\n(venv)가 접두어로 있는 프롬프트를 볼 때, 활성화되었음을 의미합니다.\n\nvenv가 활성화된 상태에서는 설치된 파이썬 패키지가 venv 내에서만 작동합니다.\n\n## 단계 3: 의존성 설치\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 Torch를 설치해 주세요. 몇 분 정도 소요될 거에요.\n\n```js\npip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121\n```\n\n다음으로 requirements.txt 파일에 나열된 나머지 종속성을 설치해 주세요:\n\n```js\npip install -r requirements.txt\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 4: ComfyUI 실행하기\n\nComfyUI를 실행하려면 먼저 venv가 활성화되어 있는지 확인해야 합니다.\n\n```js\nREM: Windows\n\nREM: venv를 활성화합니다.\nvenv\\Scripts\\activate.bat\n\nREM: comfyui 시작\npython main.py\n```\n\n```js\n# Linux\n\n# venv를 활성화합니다.\nsource venv/bin/activate\n\n# comfyui 시작\npython3 main.py\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작업을 간편하게 하기 위해 위 두 가지를 배치 파일(Windows)이나 셸 스크립트(Linux) 안에 넣을 수 있습니다.\n\nWindows에서: 새 텍스트 파일을 만들고 launch.bat로 이름을 지정하십시오. 그 안에 다음과 같이 작성하십시오:\n\n```js\nREM: venv 활성화\ncall venv\\Scripts\\activate.bat\n\nREM: comfyui 시작\npython main.py --listen\n```\n\n파일을 저장한 후, launch.bat 파일을 더블 클릭하여 ComfyUI를 간편하게 시작할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리눅스용: 새 텍스트 파일을 만들어 launch.sh라는 이름을 지어주세요. 그 안에 다음 내용을 넣어주세요:\n\n```bash\n#!/bin/bash\n\n# 가상 환경 활성화\nsource venv/bin/activate\n\n# comfyui 시작\npython3 main.py\n```\n\n파일을 저장해주세요. 다음으로 해당 파일을 실행 가능하게 만들기 위해 아래 명령어를 입력해주세요:\n\n```bash\nchmod +x launch.sh\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같이 입력하여 실행하세요:\n\n```js\n./launch.sh\n```\n\n또는 GUI에서 직접 실행할 수도 있지만, 파일 관리자에 따라 다를 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-22-InstallingComfyUILinuxWindows_0.png"},"coverImage":"/assets/img/2024-06-22-InstallingComfyUILinuxWindows_0.png","tag":["Tech"],"readingTime":4},{"title":"AI 아트 프롬프트의 구성 요소 분석","description":"","date":"2024-06-22 21:46","slug":"2024-06-22-TheAnatomyofanAIArtPrompt","content":"\n\n![이미지](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_0.png)\n\n좋은 프롬프트를 작성하는 방법을 이해하면 찾고 있는 결과물을 얻는 데 도움이 됩니다.\n\nUI 도구를 사용하여 프롬프트를 작성할 수 있지만, 자신의 프롬프트를 변경, 세밀 조정하고 만드는 능력은 매우 중요합니다. 이러한 기술을 설명하는 용어가 심지어 있습니다 – 때로는 \"프롬프트 제작\" 또는 \"프롬프트 엔지니어링\"이라고도 합니다.\n\n물론 모든 지침을 따르지 않고도 놀라운 결과물을 얻을 수 있습니다. 단순한 단어나 구절에서 생성된 멋진 이미지를 보았습니다. 그러나 일관성을 원하고 결과물을 향상시키려면 AI가 언어 패턴에 어떻게 응답하는지 배워야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n나는 커뮤니티 포럼과 디스코드 채널에서 팔로우하는 AI 아티스트들이 이 기술을 숙달했으며, 그들이 어떻게 프롬프트를 작성하는지 공부하는 것이 나의 프롬프트 작성 능력 향상에 도움이 되었습니다.\n\n이 글에서 제가 하고 싶은 것은 제가 프롬프트를 작성할 때 사용하는 사고 과정을 보여드리고 싶습니다. 이를 특정 AI 아트 도구와 무관하게 작성 중이며, 다양한 도구들 사이에 문법 차이가 있을 수 있지만, 작성 방식은 대체로 비슷합니다. 아래 예시에서는 Midjourney에서 생성된 아트를 보여드리겠습니다.\n\n# 프롬프트 만들기\n\n나는 프롬프트의 해부학을 네 가지 구분으로 생각하고 특정한 순서로 배치하는 것을 좋아합니다 (순서가 출력물의 AI 우선 순위에 영향을 미침을 주의하세요).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 콘텐츠 유형\n- 설명\n- 스타일\n- 구성\n\n작업 절차에서 각각을 자세히 살펴보겠습니다.\n\n## 1. 콘텐츠 유형\n\n미술 작품을 만드는 방식을 고려할 때, 먼저 생각해야 할 것은 어떤 유형의 작품을 만들고 싶은지입니다. 사진, 드로잉, 스케치 또는 3D 렌더 중 어느 것인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네 아래와 같이 시작하시면 됩니다.\n\n```js\n...사진\n```\n\n## 2. 설명\n\n설명은 주제, 주제 특성 및 환경/장면을 정의하는 것을 의미합니다. 형용사를 사용하여 더 구체적으로 설명할수록 결과물이 더 좋아집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단한 설명은 이렇게 생겼을 거에요…\n\n```js\n늑대 사진\n```\n\n결과물은 이렇게 나올 거에요…\n\n![image](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 나은 설명은 환경/장면 설명과 함께 주제 속성을 추가하는 것입니다.\n\n```js\n안개 낀 숲 속에서 화난 전신 늑대 사진\n```\n\n그리고 이렇게 됩니다…\n\n![이미지](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 이미지 URL과 함께 텍스트 설명을 포함하여 시각적 영감으로 활용할 수 있습니다.\n\n```js\n![Photograph of an angry full-bodied wolf in the foggy woods](http://www.wolfsite.com/wolf.jpg)\n```\n\n이 예시에서는 적용되지 않지만, 설명에 중요한 측면 중 하나는 포착하려는 시대나 역사적 시기입니다. 따라서 해당 이미지에 사람이나 건물이 있는 경우 \"언제\"라는 맥락이 중요할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\n원시 사회, 고대, 중세, 르네상스, 현대 세계, 현대, 미래\r\n```\r\n\r\n## 3. 스타일\r\n\r\n미술 스타일은 표현에 큰 영향을 미치는데, 스타일을 세 가지 하위 카테고리로 생각합니다:\r\n\r\n조명, 디테일 및 아트 스타일.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 조명에 사용할 수 있는 단어 몇 가지가 있어요:\n\n```js\n액센트 조명, 백라이트, 블랙라이트, 눈부신 빛, 양초 빛, 콘서트 조명, 황혼 광선, 직사광선, 황혼, 에디슨 전구, 전자 아크, 불, 형광등, 빛나는, 방사성 빛나는, 발광스틱, 용암 빛, 달빛, 자연 조명, 네온 램프, 나이트클럽 조명, 핵폐기물 빛나는, 양자 점 디스플레이, 스포트라이트, 스트로브, 햇빛, 자외선, 드라마틱 조명, 어두운 조명, 부드러운 조명\n```\n\n아트워크의 세부사항은 날카로움뿐만 아니라 특정 카메라 렌즈 또는 디지털 렌더링 엔진에서도 나타날 수 있어요.\n\n여기 세부사항에 사용할 수 있는 몇 가지 단어가 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n고도로 세밀하고 질감이 풍부한, 현실적인, 언리얼 엔진, 옥타네 랜더, 보케, Vray, 후디니 랜더, 퀵셀 메가스캔, 초점 깊이(또는 DoF), 아놀드 랜더, 8K UHD, 광선 추적, CGI, 루멘 반사, CGSociety, 초 현실적인, 부피적 안개, 오버글라즈, 아날로그 사진, 폴라로이드, 100mm, 필름 사진술, DSLR, Cinema4D, 스튜디오 품질\n\n\n미술 양식은 다른 기술들의 설명일 수도 있고, 역사적인 미술 장르로 정의될 수도 있어요.\n\n다음은 역사적 미술 양식을 위한 단어들입니다:\n\n\n추상, 중세 미술, 르네상스, 바로크, 로코코, 신고전주의, 낭만주의, 인상파, 후기 표현주의, 쿠비즘, 퓨처리즘, 아르트 데코, 추상표현주의, 현대, 팝 아트, 초현실주의, 판타지\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아름다운 기술과 자료에 관한 몇 가지 용어들입니다:\n\n```js\n디지털 아트, 디지털 페인팅, 컬러 페이지, 픽시브(애니메이션/만화 사이트) 주목 받은 작품, 아트스테이션에서 트렌드를 이끌고 있는 작품, 정밀한 선 화법, 타로 카드, 캐릭터 디자인, 컨셉 아트, 대칭, 황금비, 감동적인, 수상 경력, 반짝이는, 부드러운, 초현실주의, 신성한, 천상의, 우아한, 유화, 부드러운, 매혹적인, 미술\n```\n\n이제, 우리 늑대 프롬프트에 일부 스타일을 추가해보겠습니다.\n\n```js\n안개 낀 숲 속에서 분노한 전신 늑대의 사진, 황혼, 언리얼 엔진, 8K\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_3.png)\n\n8k 품질로 우드들이 매우 자세히 보이는 것을 확인할 수 있습니다. 셋인해 생산된 썩은 저녁 태양으로부터 발한 어둠 속에 밝기가 빛납니다. 늑대는 Epic 게임에서 모델링된 것처럼 보입니다.\n\n다음은 몇 가지 역사적 예술 스타일을 추가한 예시입니다:\n아래 프롬프트는 팝 아트의 역사적인 스타일을 포함하고 있습니다.\n\n```js\n안개 낀 숲 속에서 성난 전신 통통한 늑대의 사진, 팝 아트\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스타일이 결과물에 미치는 영향을 확인할 수 있습니다:\n\n![Style Influence](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_4.png)\n\n## 아티스트 이름을 스타일로\n\n미술 스타일에 관한 가장 인기 있는 형태는 AI가 정말 좋아하는 아티스트 이름의 사용입니다. 스타일 변화를 탐구하기 위해 둘 이상의 아티스트 이름을 사용하는 것도 일반적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기를 클릭하면 Midjourney 커뮤니티가 유지하는 놀라운 예술가와 스타일 자원이 나옵니다.\n\n그래서 우리의 늑대 프롬프트를 확장해보자면, 자원 시트에서 2명의 아티스트를 선택했고, 포토그래픽 스타일로 돌아가기 위해 Unreal Engine을 제거했으며, 'sepia'를 색상으로 추가했습니다.\n\n보시다시피... 프롬프트 제작은 텍스트 입력을 계속 바꿔가며 결과물을 정제하고 다시 만드는 것이죠.\n\n```js\n알렉스 홀리-오를란델리에 의한 안개 낀 숲 속의 화난 늑대 사진, 바스티앙 르쿠프-드하름, 황혼, 세피아,\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 이것이 결과입니다:\n\n![image](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_5.png)\n\n## 4. 구성\n\n남은 요소는 구성이며 이는 ...\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n화면 비율, 카메라 뷰 및 해상도.\n\n특정 목적을 지정할 때 화면 비율은 정말 중요합니다. 배너를 만들고 있다면, 화면 보호기를 만들 때와는 다른 화면 비율을 사용해야 합니다.\n\n다양한 크기에 적용되는 다양한 화면 비율을 보여주는 훌륭한 자료입니다.\n\n![이미지](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n카메라 시점은 이미지의 관점에 관한 것입니다. 여러분의 작품은 가까이서 찍은 사진이나 광각 사진, 피시아이, 등과 같이 어떤 시점을 선택할 건가요?\n\n중요한 질문은 시청자 시각이 무엇인가에 대한 것입니다.\n\n다음은 카메라 시점에 사용할 수 있는 몇 가지 단어입니다.\n\n\n울트라 광각, 광각, 항공 시점, 대규모 규모, 길거리 수준, 풍경, 파노라마, 보케, 피시아이, 네덜란드각, 저각도, 초장거리 샷, 장거리 샷, 가까이서 촬영, 극한 가까이서 촬영\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상세, 품질 및 원하는 크기에 대한 해상도를 적용할 것입니다. 해상도에 사용할 수 있는 단어는 다음과 같습니다:\n\n```js\n높은 상세 정도, 초점 깊이 (또는 DoF), 4k, 8k UHD, 초실감적, 스튜디오 품질.\n```\n\n## 추가 도구 기반 매개변수\n\nMidJourney, Stable Diffusion 및 DALL-E 2와 같은 각 AI 생성기는 결과물을 더욱 정교하게 만들기 위한 추가 명령 매개변수를 갖게 됩니다. 예를 들어, Midjourney는 다음과 같은 추가 매개변수를 가지고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n--beta = 더 높은 품질의 출력을 위한 실험 알고리즘\n--no = 특정 객체를 포함하지 않도록 하는 부정적인 프롬프팅\n--s = stylize 인수는 스타일화 강도를 설정합니다\n--q = 출력물의 품질을 설정합니다\n--chaos = 출력물에 랜덤성을 추가하는 옵션을 포함합니다\n--seed = 특정 이미지에서 시작점을 설정합니다 (각 이미지에는 고유한 ID가 있음), 일관된 관점을 원하는 경우에 좋습니다\n```\n\n앞으로 이 도구 기반 명령어들을 사용하는 방법에 대해 더 많이 다룰 예정이니, 반드시 제를 팔로우해주세요.\n\n## 마치며\n\n이 프롬프트 생성 과정을 통해 도움이 되었기를 바랍니다. 프롬프트를 배열하는 방법을 이해하고 나면 정말 재미있을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요청 내용의 해부학 분석을 여기 안내해 드리겠어요:\n\n![The Anatomy of an AIArt Prompt](/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_7.png)\n\n제가 사용하는 프롬프트 기술과 차이를 알아들을 수 있다면 흥미롭게 생각하겠어요.\n\n프롬프트 작성은 계속 발전하는 기술이지만, 반드시 필요한 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이 기사를 좋아하셨다면, 조금의 Medium 사랑을 표현해 주세요... 박수를 치거나 댓글을 달아 주시고, 반드시 팔로우해 주세요.\n\n또한, 제 추천 링크를 사용하여 회원이 되어 Medium에서 제 작품을 지원하고 무제한 액세스를 받을 수도 있습니다.","ogImage":{"url":"/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_0.png"},"coverImage":"/assets/img/2024-06-22-TheAnatomyofanAIArtPrompt_0.png","tag":["Tech"],"readingTime":6},{"title":"AI 얼굴 스왑 배틀 PuLID vs InstantID vs FaceID","description":"","date":"2024-06-22 21:45","slug":"2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID","content":"\n\n오늘은 ComfyUI 워크플로우를 사용하여 PuLID, InstantID 및 IP-Adapter의 FaceID-V2와 같은 세 가지 AI 얼굴 교체 기술을 비교해보려고 해요. 이러한 기술은 얼굴 인식, 얼굴 감지 및 얼굴 정렬을 위해 설계된 깊은 얼굴 분석 라이브러리 인 InsightFace를 기반으로 합니다. InsightFace는 상업적 라이센스가 필요하다는 점을 유의해 주세요.\n\nIP-Adapter FaceID는 이러한 기술 중에서 처음에 소개되었고, 그 뒤를 이어 InstantID가 나왔으며, 가장 최근에 PuLID가 나왔어요.\n\n각각의 프로그램은 얼굴 참조 이미지가 필요하기 때문에 교체된 얼굴의 효과는 제공하는 참조 이미지의 품질과 적합성에 크게 의존합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 세 가지 얼굴 교체 방법의 결과를 ComfyUI 워크플로우를 사용하여 비교할 것입니다. 여기서 다운로드할 수 있어요.\n\n먼저, 이 워크플로우의 사용 방법을 보여드리겠습니다. 그런 다음, 효과를 평가하기 위해 4 세트의 이미지를 생성하고 평가할 것입니다.\n\n![이미지](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_1.png)\n\n비디오 콘텐츠와 함께 Stable Diffusion에 더 자세히 파고들고 싶은 분들을 위해 이 글에 부가된 매력적인 비디오 튜토리얼을 확인하실 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# ComfyUI Workflow 설정하기\n\n1️⃣ 노드 다운로드 및 불러오기:\n\n- 필요한 모든 노드가 있는지 확인해주세요. 누락된 노드는 ComfyUI 관리자를 통해 설치한 후 ComfyUI를 재시작하면 됩니다.\n- 노드를 설치하기 전에 ComfyUI를 업그레이드하여 누락된 노드로 인한 문제를 피해주세요.\n\n![이미지](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2️⃣ 필요한 모델 설치하기:\n\n모델의 다운로드 주소와 저장 경로는 각 노드의 GitHub 홈페이지에 자세히 나와 있습니다.\n\n- PuLID: [GitHub 링크](GitHub Link)\n- InstantID: [GitHub 링크](GitHub Link)\n- IP-Adapter: [GitHub 링크](GitHub Link)\n\n예를 들어 PuLID의 경우, 미리 학습된 모델을 다운로드하여 ComfyUI/models/pulid/ 폴더에 위치시킵니다. 첫 실행 시 추가 모델을 자동으로 다운로드합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Workflow Structure\n\n1️⃣ Shared Nodes:\n\nAt the bottom, these nodes are common to PuLID, InstantID, and FaceID. They use identical dimensions for checkpoint, prompt, latent image, and fixed seed, facilitating easy comparison.\n\n![Image](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2️⃣ 모델 노드 그룹:\n\n더 위에, 세 개의 노드 그룹이 있습니다. 왼쪽부터 오른쪽으로: PuLID, InstantID, 그리고 IP-Adapter-FaceID입니다. 저자들은 이를 직관적으로 조직했습니다.\n\n![이미지](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_4.png)\n\n3️⃣ 참조 이미지 노드:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에 있는 \"Face\" 노드(\"Load Image\" 노드)는 세 기술 모두에 사용되는 참조 사진을 로드합니다.\n\n![이미지](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_5.png)\n\n# Workflow 실행 및 결과 비교\n\n## 진행 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 모든 노드 및 모델이 올바르게 설치되고 구성되었는지 확인하십시오.\n- 워크플로를 가져오고 노드 연결 및 구성을 확인하십시오.\n- 참조 이미지를 로드하여 이미지 경로와 형식을 확인하십시오.\n- 워크플로를 실행하여 세 가지 기술을 위한 효과 이미지를 생성하십시오.\n- PuLID, InstantID 및 IP-Adapter FaceID의 차이, 장단점을 평가하기 위해 생성된 이미지를 비교하십시오.\n\n## 평가 기준\n\n다음 차원에 따라 네 개의 이미지 세트를 생성하고 다음과 같이 점수를 매기세요 (각각 1-3점):\n\n- 빠른 적합성: 이미지가 프롬프트 설명과 얼마나 잘 일치하는지.\n- 얼굴 밝기: 얼굴의 빛과 그림자의 자연스러움.\n- 얼굴 유사성: 생성된 이미지와 참조 이미지 사이의 닮은 정도.\n- 얼굴 세부 사항: 얼굴의 질감과 세부 풍부함.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 비교 분석\n\n💠 첫 번째 이미지 세트\n\n![First set of pictures](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_6.png)\n\n💠 두 번째 이미지 세트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_7.png)\n\n💠Third set of pictures\n\n![Image 2](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_8.png)\n\n💠Fourth set of pictures\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_9.png)\n\nFinally, let’s calculate the total score:\n\nFrom my observations:\n\n- InstantID scores the highest overall, followed closely by FaceID.\n- PuLID lags behind the other two.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nInstantID는 최고의 결과를 제공하지만, 가장 많은 자원을 사용합니다. 최종적으로 최선의 선택은 귀하의 특정한 요구 사항에 달렸습니다.\n\n귀하는 직접 테스트를 수행하고 결과를 댓글 섹션에서 공유하는 것을 장려합니다.\n\n💡 더 깊은 탐구를 원하십니까? 제 스테이블 디퓨전 컬렉션이 기다리고 있습니다.\n\n## 기사가 마음에 드셨나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그렇다면:\n\n- 댓글 남기기\n- 업데이트 팔로우하기\n- 무료 이메일 알림","ogImage":{"url":"/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_0.png"},"coverImage":"/assets/img/2024-06-22-AIfaceswapbattlePuLIDvsInstantIDvsFaceID_0.png","tag":["Tech"],"readingTime":4},{"title":"파이썬을 사용한 신호처리를 위한 생성적 적대 신경망GAN 실습 가이드","description":"","date":"2024-06-22 21:43","slug":"2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython","content":"\n\n## 몇 줄의 코드로 신호 처리를 위한 생성형 딥러닝 모델을 만드는 방법\n\n![이미지](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_0.png)\n\n저는 연구에서 머신(딥)러닝을 많이 사용합니다. 이틀 전에, 생성적 적대 신경망(GAN)에 대해 작업하고 제 작업에 어떻게 적용할 수 있는지 살펴보았습니다.\n\n코드가 완성되면, 제가 Medium에 이 기사를 쓰기 시작했고, 항상 하는 것처럼 적절한 소개로 시작하는 최상의 문구를 찾으려 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자, 이제부터 질문을 스스로에게 던지기 시작합니다:\n\n물론, 저는 내가 쓰는 것이 의미 있고 재미있기 때문에 독자들이 이것을 읽어야 한다고 믿습니다.\n\n하지만 사실은, 저는 시그널 처리를 사랑하고, 시그널 처리에 대해 글을 쓰는 것을 사랑하기 때문에 그렇게 합니다. 이 글은 제가 가장 사랑하는 두 가지에 대한 것입니다: 시그널 처리와 인공지능. 이 두 가지에 제 모든 사랑, 에너지, 열정을 쏟았으며 (사실 한 바다를 건너가서 연구까지 했습니다), 여러분이 이 주제를 흥미롭게 생각해주길 바랍니다.\n\n제목에서 짐작하실 수 있듯이, 우리는 시그널 처리를 위해 생성적 적대 신경망(Generative Adversarial Networks)을 사용할 것입니다. 이번에 할 게임은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 실험을 진행하고 있다고 상상해보세요. 이 실험의 설치는 생성기에 의해 이루어집니다. 이 생성기의 출력물은 시계열 데이터(즉, 신호)입니다.\n\n![이미지](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_1.png)\n\n이 실험이 비싸고 많은 에너지와 계산 노력이 필요하다고 상상해보세요. 우리는 결국 이 실험을 중단하고 싶습니다. 이를 위해서 생성기를 대리 생성기(surrogate)로 바꿔야 합니다.\n\n![이미지](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 대리 모델인 연핑크 뇌를 보십시오. 특히, 이 대리 모델은 기계 학습 모델입니다. 이름에서 알 수 있듯이, 이 기계 학습 모델은 적대적 생성 신경망(GAN)입니다.\n\n이 글은 이런 내용을 담고 있을 거에요:\n\n- 실험 구축하기: 우리는 통제된 데이터셋을 생성하고 설명할 거에요.\n- 기계 학습 모델 정의하기: 우리 GAN 모델의 특정 기능을 설명할 거에요.\n- 결과 탐색하기: 우리 생성 모델을 실행하고, 대리 모델을 사용하여 신호를 추출할 거에요.\n\n제가 기대되는 만큼 당신도 신나길 바라요. 함께해요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1. 실험에 관하여\n\n전기/기계 공학자가 설정한 대부분의 신호는 사인 파형 신호입니다.*\n\n즉, 출력 신호는 이렇게 어떤 모양인 것입니다:\n\n![image](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위와 같은 표를 Markdown 형식으로 변경합니다.\n\n| Variable | Description                              |\n|----------|------------------------------------------|\n| A        | 신호의 진폭                               |\n| omega    | 주파수                                   |\n| b        | 편향                                    |\n\n실제 세계 실험에서는 노이즈 요소가 있습니다.\n지금은 다양한 종류의 노이즈가 있으며, 각각 색상이 지정되어 있습니다(white noise, pink noise, blue noise, green noise 등). 가장 전형적인 노이즈 중 하나는 가우시안 백색 소음으로, 모든 주파수에서 존재하며 가우시안 분포를 갖는 노이즈입니다.\n\n따라서 대상 신호는 다음과 같이 보입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_4.png)\n\nNow, in practice:\n\n- The mean is usually 0\n- The standard deviation can vary, but it is safe to assume it is 1 and fixed for our experiment.\n- Another constant can be considered to be in front of the noise factor as a sort of amplitude of the noise\n\nSo at the end of the day, it looks more like this:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_5.png\" /\u003e\n\n이것이 바로 우리의 완벽한 세계, 아바타에서 말하는 대로 우리의 판도라입니다 😄\n\n현실에서는 상황이 조금 다를 수 있습니다.\n예를 들어, 우리가 진폭을 고정했다고 해봅시다. 그러나 그 진폭은 많이 변할 수 있습니다.\n예를 들어, 다음과 같이 말씀드릴 수 있습니다:\n\n- 진폭은 0.1부터 10까지의 범위 내에서 0.1씩 증가합니다.\n- 편향은 0.1부터 10까지의 범위 내에서 0.1씩 증가합니다.\n- 주파수는 1부터 2까지의 범위 내에서 0.001씩 증가합니다.\n- 잡음의 진폭은 고정되어 있으며 0.3입니다 (잡음의 랜덤성은 그 확률 분포에 있습니다)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 이러한 무작위성을 통합하려면 다음 코드 라인을 사용할 수 있습니다:\n\n다음은 일부 출력입니다:\n\n이 시점에서 목표가 충분히 명확해야 합니다:\n\n그러면 머신 러닝부터 시작합시다 🤗\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2. 머신 러닝에 대해\n\n저희가 사용하는 머신 러닝 모델은 Generative Adversarial Network (GAN)입니다.\n\nGAN에 대한 설명과 함께 신호 처리에 관한 이 기사를 정말 원합니다. 간단히 소개해보겠습니다. 주의: 어떤 사람들은 저보다 훨씬 잘 설명합니다 (이번에 Joseph Rocca에게 큰 찬사를 드립니다: Understanding Generative Adversarial Networks (GANs))\n\nGAN이 Deepfake에 사용되는 모델이라고 생각해보세요.\n이것은 이름에서 느낄 수 있듯이 생성 모델로, 생성 부분과 구별자를 훈련시켜 구현됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n생성 부분은 실제 모델과 가능한 가까운 모델을 생성하려고 노력합니다. 그게 전부라면 일반적인 인코더-디코더와 다르지 않을 것입니다. \"진짜 거래\"는 식별 부분의 존재입니다.\n\n식별 부분은 실제와 \"가짜\" (생성된 생성 모델에서 생성된) 인스턴스를 구분하려고 시도하는 분류기입니다.\n\n따라서 게임은 훈련 데이터 객체와 유사한 가짜 객체를 구축하려고 하는 생성 모델과 훈련 데이터 객체와 가짜 객체를 구분하려고 하는 식별 모델 사이의 경쟁입니다. 이 \"게임\"은 최소-최대 손실 함수와 Ian J. Goodfellow의 뛰어난 마음에 의해 만들어진 우아하면서 간단한 알고리즘으로 실현됩니다 (Generative Adversarial Nets 논문).\n\n지금, GAN의 매우 흔한 사용은 조건부 GAN입니다. 조건부 GAN은 특정 입력과 관련된 생성 모델입니다.\n입력이 문자열이라고 말해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 출력물은 다음 이미지입니다:\n\n![Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_6](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_6.png)\n\n이 예에서 모델은 더 단순하며 생성 모델은 특정 입력과 관련이 없습니다.\n이 생성 모델의 입력은 지금 잡음이므로 모델은 잡음에서 소스에서 생성된 것으로 추정되는 신호로 가려고 합니다.\n\n생성 모델의 구조는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 식별 모델의 아키텍처입니다:\n\n![discriminative model](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_8.png)\n\n생성 모델은 다음과 같이 설명할 수 있습니다:\nLSTM 모델은 무작위 잡음 벡터(3차원 벡터)를 입력으로 받고, 이상적으로는 원하는 신호인 300개의 요소로 이루어진 벡터를 출력합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image1](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_9.png)\n\nThe discriminative model distinguishes a real (from the training data) and a fake (generated by the generative model) output:\n\n![image2](/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_10.png)\n\nThe hands-on implementation of this GAN is the following:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 입력의 길이는 모델의 매개변수입니다:\n\n```js\nLENGHT_INPUT = 300\n```\n\n그리고 노이즈 벡터의 차원은 latent_dim 매개변수입니다.\n\n이제 데이터셋을 생성해야 합니다. 이는 n개의 신호를 생성하는 함수를 작성하는 것을 의미합니다. 또한 주어진 차원의 n개의 무작위 노이즈 입력을 생성해야 하며, n개의 무작위 노이즈 신호를 사용하여 가짜 신호를 생성하는 코드를 작성해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 저희는 기차 함수를 구축해야 합니다.\n\n이 코드는 우리의 생성 모델을 훈련할 것입니다. 또한 n_eval 단계마다 생성 모델의 진행 상황을 보여줄 것이고, 진짜 데이터와 가짜 데이터(여기서 가짜란 \"우리 모델에 의해 생성된\" 것을 말합니다)를 플로팅할 것입니다.\n\n# 3. 전체 코드\n\n전체 스크립트입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 데이터셋을 생성합니다\n- GAN 모델을 구축합니다\n- GAN을 학습합니다\n\n다음과 같습니다:\n\n진행 상황을 보여드릴게요:\n\n이제 100,000개의 랜덤 신호를 생성해볼게요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대박이에요. 각 실험이 0.5달러 든다고 가정해보세요. 그러면 50,000달러를 \"절약\"한 셈이에요. 또한 각 실험이 1분이 걸린다고 가정해보세요. 그러면 70일을 \"절약\"한 셈이죠. 이것이 GANs 모델을 사용하는 목적입니다: \"시간과 노력을 절약하기 위해\".\n\n이제 100,000개의 실제 신호를 생성합시다.\n\n결과를 몇 개 그래프로 나타내 보겠습니다:\n\n## 4. 요약\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는:\n\n- 인공 지능과 신호 처리가 멋지다는 것을 확인하고, 그래서 이 둘을 합치기로 결정했습니다.\n- 우리는 신호 처리 시나리오를 만들었습니다. 여기서는 소음이 있는 사인 발생기가 있습니다. 이 사인에는 다른 진폭, 다른 주파수 및 다른 바이어스가 있을 수 있습니다.\n- 우리는 GAN 모델에 대해 간단히 설명했습니다. 모델의 생성 부분, 식별 부분 및 손실이 무엇인지 설명했습니다. 생성 모델의 입력은 3차원 노이즈이며, 출력은 학습 데이터 중 하나와 비슷한 신호입니다.\n- 우리는 GAN 모델을 훈련시키고 일부 무작위 신호를 생성했습니다.\n\n이 모델의 핵심 부분은 생성 능력이며, 훈련된 생성 모델은 시간, 비용 및 에너지를 절약할 수 있습니다. 이는 실험을 진행하는 대신 파이썬 환경에서 \"실행\" 버튼만 누르면 되기 때문입니다 🚀\n\n# 5. 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이 기사를 좋아하셨고 머신 러닝에 대해 더 알고 싶거나, 단순히 저에게 질문을 하고 싶다면 아래 방법으로 연락해 주세요:\n\n1. LinkedIn에서 팔로우하기 - 모든 이야기를 공개하고 있습니다.\n2. 뉴스레터 구독하기 - 새로운 이야기에 대한 최신 정보를 받을 수 있으며, 궁금한 사항 또는 수정 사항을 받아 볼 수 있습니다.\n3. 추천 회원 가입하기 - 월별 \"이야기의 최대 개수\" 제한 없이 읽을 수 있으며, 최신 기술에 관한 저와 수천 명의 다른 머신 러닝 및 데이터 과학 최고의 작가들이 쓴 내용을 읽을 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_0.png"},"coverImage":"/assets/img/2024-06-22-Hands-onGenerativeAdversarialNetworksGANforSignalProcessingwithPython_0.png","tag":["Tech"],"readingTime":7},{"title":"초보자를 위한 디스코드에서 Midjourney 시작하기 단계별 가이드","description":"","date":"2024-06-22 21:41","slug":"2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners","content":"\n\n## Midjourney는 텍스트 프롬프트에서 AI가 생성한 이미지를 생성하는 흥미로운 도구이지만, Discord와 AI 이미지 생성에 처음 접하는 경우 과정이 다소 어렵게 느껴질 수 있습니다. 이 안내서는 Discord 설정부터 Midjourney를 사용하여 첫 AI 이미지를 생성하는 단계까지 안내해 드립니다.\n\n![이미지](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_0.png)\n\n안녕하세요! AI 이미지를 생성하는 데 관심이 있는 많은 분들이 시작하기에 어려움, 혼란 또는 불확실함을 느낀다는 피드백을 받았습니다. 대부분의 사람들이 AI 이미지 생성에 대해 들어본 적이 있고 결과물을 본 적이 있어, 그 능력과 활용 방법에 궁금해하고 있습니다.\n\nAI 생성 이미지의 잠재적인 사용 범위는 매우 넓습니다. 개인 프로젝트에서부터 창의적 영감, 비즈니스 그래픽, 웹사이트 디자인 및 수동 소득 창출까지 가능성은 무한합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작가로서 AI 도구를 자주 활용하는 저는 Midjourney AI를 가장 사용하기 편리하고 효율적인 이미지 생성기로 발견했습니다. Midjourney나 다른 AI 응용 프로그램과는 관련이 없으며 이들로부터 어떠한 보상도 받지 않지만, 여전히 제가 가장 선호하는 이 제품에 대한 초보자를 위한 안내서를 공유하고 싶었습니다. 게다가 Night Cafe AI를 사용하는 것도 좋아하는데, 이미지 생성을 위한 매일 무료 크레딧을 제공하기 때문입니다.\n\nMidjourney를 사용해보고 싶다면, 시작하는 방법에 대한 안내서가 여기 있습니다. Midjourney에서 discord를 통해 100개의 이미지를 생성한 후에 웹사이트 애플리케이션에 접근할 수 있다는 것을 기억해 주세요.\n\n이 글은 누구나 무료로 읽을 수 있습니다. AI가 생성한 글 내용이 포함되어 있어요. 자세한 안내서를 직접 작성하고 싶지만, ChatGPT의 도움을 받아 명확하고 유용한 안내서를 만드는 것이 더 효율적입니다. 유료 콘텐츠는 제가 직접 작성한 것이며 AI로 생성된 것이 아니라는 점을 참고해 주세요.\n\n## 초보자를 위한 Midjourney Discord 시작 가이드: 단계별 안내법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 1: 디스코드 설정\n\n- 디스코드 계정 만들기:\n\n- 디스코드 웹사이트에 가서 오른쪽 상단의 \"로그인\"을 클릭합니다.\n- \"등록\"을 선택하고 필요한 세부 정보를 입력합니다(이메일, 사용자 이름, 비밀번호 및 생년월일).\n- 이메일 주소를 확인하려면 이메일로 전송된 링크를 따릅니다.\n\n2. 디스코드 앱 다운로드 (선택 사항):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 웹 브라우저를 통해 디스코드를 사용할 수 있지만 더 나은 경험을 위해 디스코드의 다운로드 페이지에서 컴퓨터나 휴대폰용 앱을 다운로드하세요.\n\n3. 디스코드에 로그인하기:\n\n- 디스코드 앱이나 웹사이트를 열고 새 계정 자격 증명을 사용하여 로그인하세요.\n\n## 단계 2: Midjourney 디스코드 서버 가입하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 초대 링크 받기: [여기를 클릭하여 Discord 초대 링크를 받아보세요](https://discord.com/invite/midjourney)\n\n- Midjourney 웹사이트를 방문하고 \"Beta 참여\" 버튼을 클릭하거나 위 링크를 사용해주세요.\n\n2. 서버에 참여하기:\n\n- 초대 링크를 클릭한 후 \"초대 수락\"을 클릭해주세요. 이렇게 하면 Midjourney Discord 서버로 이동됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Getting Started with Midjourney on Discord: A Step-by-Step Guide for Beginners](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_1.png)\n\n## Step 3: Understanding the Server Layout\n\n- Familiarize Yourself with Channels:\n\n- On the left sidebar, you’ll see various channels. Channels are like rooms where specific topics are discussed.\n- Look for channels like #newbies, #announcements, and #rules to get started.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Getting Started with Midjourney on Discord - A Step-by-Step Guide for Beginners](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_2.png)\n\n2. Read the Rules\n\n- In the #rules channel, read through the guidelines to understand what is expected of members.\n\n![Getting Started with Midjourney on Discord - A Step-by-Step Guide for Beginners](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 4: 첫 번째 AI 이미지 생성하기\n\n- 뉴비 채널 찾기:\n\n- #newbies(예: #newbies-1, #newbies-2)라고 레이블된 채널을 찾아 클릭하세요.\n\n![이미지](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. 봇 사용하기:\n\n화면 하단의 텍스트 입력 상자에 /imagine 명령어를 입력한 다음 생성하고 싶은 이미지에 대한 설명을 추가하세요.\n예를 들어, /imagine 일몰 시 산과 호수가 있는 고요한 풍경을 입력하세요.\n명령을 보내려면 \"Enter\" 키를 누르세요.\n\n3. 결과 기다리기:\n\nMidjourney 봇이 요청을 처리하고 프롬프트에 기반한 네 개의 이미지를 생성합니다. 이는 일반적으로 1분 이내에 완료됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Upscaling Images](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_5.png)\n\n4. Upscaling Images:\n\n- Once the images are generated, you can choose to upscale (enhance) any of them for better quality. Click on the button under the image you like labeled “U1”, “U2”, “U3”, or “U4” (corresponding to the first, second, third, and fourth images).\n\n![Another Image](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_6.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 다양성:\n\n- \"V1\", \"V2\", \"V3\", 또는 \"V4\"를 클릭하여 이미지의 변형을 만들 수도 있습니다.\n\n![Variations](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_7.png)\n\n6. 이미지 저장하기:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 최종 확대된 이미지를 클릭한 후, 확대된 이미지를 오른쪽 클릭하여 \"이미지 다른 이름으로 저장...\"을 선택하여 디바이스에 다운로드하세요.\n\n![이미지](/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_8.png)\n\n## 단계 5: 커뮤니티 참여\n\n- 여러분의 작품 공유하기:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 적절한 채널에서 이미지를 공유하고 다른 사람들이 무엇을 만들고 있는지 확인해보세요.\n\n2. 도움 요청하기:\n\n- 궁금한 점이 있으면 #help 또는 #support 채널에서 질문할 수 있어요. 커뮤니티와 모더레이터들은 일반적으로 매우 지원적입니다.\n- 탐험하고 실험하기:\n- 다양한 프롬프트를 시도해보고, 여러 채널을 탐험하며, Midjourney의 가치를 극대화하기 위해 커뮤니티 이벤트에 참여해보세요.\n\n## 이러한 단계를 따라가면, Midjourney로 멋진 AI 생성 이미지를 만드는 길에 잘 진행될 거예요! 궁금한 점이 있다면 이 게시물에 댓글을 남겨주세요. 저가 답변해 드릴게요!","ogImage":{"url":"/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_0.png"},"coverImage":"/assets/img/2024-06-22-GettingStartedwithMidjourneyonDiscordAStep-by-StepGuideforBeginners_0.png","tag":["Tech"],"readingTime":5}],"page":"23","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"23"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>