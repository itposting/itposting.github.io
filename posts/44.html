<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/44" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/44" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="대형 언어 모델을 활용한 자동 지식 그래프 구축" href="/post/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대형 언어 모델을 활용한 자동 지식 그래프 구축" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대형 언어 모델을 활용한 자동 지식 그래프 구축" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">대형 언어 모델을 활용한 자동 지식 그래프 구축</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLM의 행동을 바꾸는 것은 GPU를 바꾸는 것입니다" href="/post/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLM의 행동을 바꾸는 것은 GPU를 바꾸는 것입니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLM의 행동을 바꾸는 것은 GPU를 바꾸는 것입니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">LLM의 행동을 바꾸는 것은 GPU를 바꾸는 것입니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="탐사 분류기를 사용하여 연락 센터 LLMs의 학습 내용을 밝힐 수 있을까요 아니요, 불가능합니다" href="/post/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="탐사 분류기를 사용하여 연락 센터 LLMs의 학습 내용을 밝힐 수 있을까요 아니요, 불가능합니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="탐사 분류기를 사용하여 연락 센터 LLMs의 학습 내용을 밝힐 수 있을까요 아니요, 불가능합니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">탐사 분류기를 사용하여 연락 센터 LLMs의 학습 내용을 밝힐 수 있을까요 아니요, 불가능합니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="다중 에이전트 시스템    LangGraph" href="/post/2024-06-20-Multi-AgentSystemsLangGraph"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="다중 에이전트 시스템    LangGraph" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="다중 에이전트 시스템    LangGraph" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">다중 에이전트 시스템    LangGraph</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="GPT-4 - 우리는 속고 있는 걸까요" href="/post/2024-06-20-GPT-4oAreWebeingLIEDto"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="GPT-4 - 우리는 속고 있는 걸까요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-GPT-4oAreWebeingLIEDto_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="GPT-4 - 우리는 속고 있는 걸까요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">GPT-4 - 우리는 속고 있는 걸까요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI 이해력을 높이는 방법" href="/post/2024-06-20-HowtoJumpstartYourAILiteracy"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 이해력을 높이는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-HowtoJumpstartYourAILiteracy_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 이해력을 높이는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI 이해력을 높이는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI Agents in a GPT" href="/post/2024-06-20-AIAgentsinaGPT"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI Agents in a GPT" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-AIAgentsinaGPT_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI Agents in a GPT" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI Agents in a GPT</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="지식 그래프로 RAG 어플리케이션의 정확성 향상하기" href="/post/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="지식 그래프로 RAG 어플리케이션의 정확성 향상하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="지식 그래프로 RAG 어플리케이션의 정확성 향상하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">지식 그래프로 RAG 어플리케이션의 정확성 향상하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="컴퓨터 프로그래머이자 15년간 ChatGPT에 대해 전문적으로 썼어요 - 전문 작가들이 괜찮다는 법을 이야기해 드릴게요" href="/post/2024-06-20-ImaComputerProgrammerandWroteProfessionallyaboutChatGPTfor15YearsHeresHowProWritersCanBeOkay"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="컴퓨터 프로그래머이자 15년간 ChatGPT에 대해 전문적으로 썼어요 - 전문 작가들이 괜찮다는 법을 이야기해 드릴게요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-ImaComputerProgrammerandWroteProfessionallyaboutChatGPTfor15YearsHeresHowProWritersCanBeOkay_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="컴퓨터 프로그래머이자 15년간 ChatGPT에 대해 전문적으로 썼어요 - 전문 작가들이 괜찮다는 법을 이야기해 드릴게요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">컴퓨터 프로그래머이자 15년간 ChatGPT에 대해 전문적으로 썼어요 - 전문 작가들이 괜찮다는 법을 이야기해 드릴게요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">13<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="합리적인 AI 프롬프트의 비밀 데이터와 함께 프롬프팅" href="/post/2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="합리적인 AI 프롬프트의 비밀 데이터와 함께 프롬프팅" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="합리적인 AI 프롬프트의 비밀 데이터와 함께 프롬프팅" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">합리적인 AI 프롬프트의 비밀 데이터와 함께 프롬프팅</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link posts_-active__YVJEi" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"대형 언어 모델을 활용한 자동 지식 그래프 구축","description":"","date":"2024-06-20 18:48","slug":"2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels","content":"\n\n## 대형 언어 모델의 파워와 지식 채집하기\n\n![이미지](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_0.png)\n\n# 작성자\n\n- Amanda Kau (ORCID: 0009-0004-4949-9284)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 소개\n\n지식 그래프는 데이터를 그래픽 형식으로 나타내는 네트워크입니다. 지식 그래프의 장점은 개념, 이벤트 및 엔티티를 노드로, 이들 사이의 관계를 엣지로 나타낸다는 데 있습니다. 이러한 관계는 노드의 맥락을 결정하고, 결과적으로 단어의 의미를 이해하고 여러 가능한 의미를 구별할 수 있도록 합니다. 예를 들어, Google의 지식 그래프는 구글 검색을 지원하여 \"Apple\" 브랜드와 \"사과\" 과일을 구별할 수 있습니다. 지식 그래프는 소매업에서 제품 추천, 검색 엔진 최적화, 자금세탁 방지 이니셔티브, 그리고 의료 분야를 포함한 다양한 분야 및 응용 프로그램에서 적용될 수 있습니다.\n\n그러나 지식 그래프의 활용은 그들의 어렵고 비용이 많이 드는 건설 과정 때문에 제약을 받습니다. 이러한 과제는 자동 지식 그래프 구축을 탐구하는 새로운 연구의 열풍을 격려했습니다. 특히, GPT-4와 같은 대형 언어 모델(LLMs)을 건설 프로세스에 통합하는 데 관심이 늘어나고 있습니다. 이 글에서는 먼저 지식 그래프 구축과 관련된 어려움을 간단히 살펴볼 것입니다. 그런 다음, 지식 그래프와 LLMs를 지식 베이스로 비교할 것입니다. 마지막으로, LLMs를 활용한 자동 지식 그래프 구축에 대한 기존 방법들을 검토할 것입니다.\n\n# 지식 그래프 구축의 어려움\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전의 지식 그래프 구축 방법은 크라우드소싱 또는 텍스트 마이닝에 기반합니다. WordNet 및 ConceptNet과 같은 인기 있는 크라우드소싱 기반 지식 그래프는 상당한 인적 노동으로 구축되었지만 미리 정의된 관계 집합에 한정됩니다. 한편, 텍스트 마이닝 기반 접근 방식은 문서에서 지식을 추출하지만 텍스트 내 명시적으로 명시된 추출된 관계에만 한정됩니다. 이 접근 방식은 대용어 해소, 명명 개체 인식 등 많은 단계를 포함합니다. 이 문서에서 지식 그래프 구축 프로세스에 대해 더 읽어보시기 바랍니다.\n\n다양한 개념 및 용어가 각 분야에서 사용되기 때문에 각 분야 또는 응용 분야마다 별도의 지식 그래프가 구축되는 어려움이 있습니다. 특정 도메인은 고유한 도전 과제를 제시하기도 합니다. 예를 들어, 지식 그래프는 서비스 컴퓨팅 커뮤니티에서 매우 유용하며 자원 관리, 맞춤형 추천 및 고객 이해에 도움이 됩니다. 그러나 이 맥락에서의 지식 그래프는 다양한 분야의 지식과 개념이 필요하며, 지식 그래프를 구축하는 데 필요한 데이터는 매우 분산되어 있고 주로 주석이 없습니다. 이러한 요소들은 지식 그래프를 생성하는 데 필요한 시간, 노력 및 비용을 크게 증가시킵니다.\n\n# 지식 그래프 대 대형 언어 모델\n\n지식 그래프와 LLM (Large Language Models)은 모두 지식을 검색하는 데 쿼리될 수 있습니다. 아래 그림에서 지식 그래프는 관련된 연결된 노드를 찾아 답을 찾지만, LLM은 문장을 완성하기 위해 [MASK] 토큰을 채우도록 유도됩니다. GPT-4 및 BERT와 같은 LLM은 최근에 언어를 이해하는 놀라운 능력으로 많은 주목을 받았습니다. LLM은 매년 크기가 계속 커지고 방대한 양의 데이터로 훈련되어 광범위한 지식을 소유할 수 있게 됩니다. 많은 사람들은 구글에서 검색하는 대신 ChatGPT에 질문을 할 수도 있습니다. 연구 커뮤니티에게 다음 질문은 LLM (예: GPT)이 지식 그래프 (예: Google 지식 그래프)를 지식의 주요 소스로 대체할 수 있는지를 탐구하는 것이었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Automated Knowledge Graph Construction with Large Language Models](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_1.png)\n\nFurther research revealed that despite possessing more fundamental world knowledge, LLMs struggled to recall relational facts and deduce relationships between actions and events. Despite possessing numerous advantages, LLMs also suffer from challenges such as:\n\n- Hallucinations: LLMs occasionally produce convincing but incorrect information. Conversely, Knowledge Graphs provide structured and explicit knowledge grounded in its factual data sources.\n- Limited reasoning abilities: LLMs struggle to comprehend and use supporting evidence to draw conclusions, especially in numerical computation or symbolic reasoning. The relationships captured in Knowledge Graphs allow for better reasoning capabilities.\n- Lack of domain knowledge: While LLMs are trained on vast amounts of general data, they lack knowledge from domain-specific data like medical or scientific reports with specific technical terms. Meanwhile, Knowledge Graphs can be constructed for specific domains.\n- Knowledge obsolescence: LLMs are expensive to train and are not regularly updated, causing their knowledge to become outdated over time. Knowledge Graphs, on the other hand, have a more straightforward update process that does not require retraining.\n- Bias, privacy and toxicity: LLMs may give biassed or offensive responses, whereas Knowledge Graphs are typically built from reliable data sources devoid of these biases.\n\nKnowledge Graphs do not encounter these same issues and exhibit better consistency, reasoning ability, and interpretability, though they do have their own set of limitations. Aside from those discussed previously, Knowledge Graphs also lack the flexibility that LLMs enjoy from their unsupervised training process.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 지식 그래프와 대형 언어 모델 통합\n\n결과적으로, 대형 언어 모델(대형 LLM)과 지식 그래프를 합치는 데 많은 연구 노력이 기울어져 왔습니다. 지식 그래프는 대형 LLM을 정확성 향상으로 이끌 수 있는 능력을 갖추고 있지만, 대형 LLM은 지식 그래프의 구축 중 지식 추출에 도움을 주고 지식 그래프의 품질을 개선할 수 있습니다. 이 두 개념을 통합하는 몇 가지 접근 방식이 있습니다:\n\n- 대형 LLM을 활용하여 자동 지식 그래프 구축 지원: LLM은 데이터로부터 지식을 추출하여 지식 그래프를 채워넣을 수 있습니다. 이 방법에 대한 자세한 내용은 아래에서 논의될 것입니다.\n- LLM에게 지식 그래프에서 지식 검색 방법 가르치기: 아래 이미지에서 보여지는 것처럼, 지식 그래프는 LLM의 추론 과정을 향상시켜 LLM이 더 정확한 답변을 도출할 수 있습니다.\n- 지식 그래프를 통합한 사전 훈련된 언어 모델(KGPLMs)로 결합: 이러한 방법들은 지식 그래프를 대형 LLM 훈련 과정에 통합하기 위해 노력합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 대형 언어 모델을 활용한 지식 그래프 자동 생성\n\n## 이전 방법\n\n2019년 제안된 초기 방법 중 하나는 COMET(또는 COMmonsEnse Transformers)이었는데, 이 방법은 미세 조정된 생성형 LLM인 GPT를 사용하여 지식 그래프를 구축했습니다. 이는 헤드 엔티티와 관계가 주어졌을 때 테일 엔티티를 생성함으로써 구성되었습니다. 아래 이미지에 나와 있는 \"시드\"와 \"관계\"를 고려할 때, COMET은 \"완성\" 응답을 생성했고, 이 응답의 타당성을 평가하기 위해 사람들에 의해 평가되었습니다. 이러한 시드-관계-완성 쌍은 지식 그래프를 형성하는 데 사용될 수 있습니다. 예를 들어, \"조각\"과 \"기계\"는 \"의 일부\"관계로 연결된 두 노드를 형성할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## ChatGPT를 정보 추출기로 활용하기\n\n특정 서비스 도메인을 위해 구축된 지식 그래프인 BEAR는 수동 데이터 주석 작업에 필요한 노력과 비용을 피하기 위해 ChatGPT를 활용하여 개발되었습니다. 이를 위해 도메인에 특화된 온톨로지가 작성되었는데, 이는 후에 지식 그래프를 채울 개념과 특성을 식별하는 기반이 되었습니다. ChatGPT는 그 후에 아래 이미지처럼 비구조적 텍스트 데이터에서 관련 내용과 관계를 추출하도록 유도되었습니다. 자동으로 추출된 정보는 이후에 지식 그래프에 통합되어 구축되었습니다.\n\n![이미지](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_4.png)\n\n## LLMs를 활용한 반자동 지식 그래프 구축\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한번 더 ChatGPT를 정보 추출기로 사용하여, Kommineni 등이 최근 Knowledge Graph 구축 방법으로 ChatGPT-3.5를 제안했습니다. 이 과정에서 인간 도메인 전문가들이 결과물을 두 단계로 확인하였습니다. 이 방법과 이전 방법의 차이는 여기서 LLMs가 보다 더 활발한 역할을 한다는 점입니다. 특정 데이터셋을 시작으로, ChatGPT가 데이터에 대한 추상 수준의 문제인 역량 질문(CQs)을 생성하도록 유도되었습니다. 역량 질문(CQs)은 데이터에 관한 추상 수준의 질문이었습니다. ChatGPT에 프롬프트하여, CQs에서 개념 및 관계를 추출하여 온톨로지를 생성했습니다. CQs에 대한 답변은 데이터에서 검색되어 ChatGPT에 제공되었으며, ChatGPT는 지식 그래프를 구성하기 위해 중요 엔터티, 관계 및 개념을 추출하고 이를 온톨로지에 매핑하도록 지시되었습니다.\n\n![그림](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_5.png)\n\n## LLMs에서 지식 그래프 수확\n\n본 문서에서 논의된 최종 방법은 LLMs에서 직접 정보를 추출하는 것이었습니다. Hao 등은 초기 훈련 단계에서 LLMs에 저장된 방대한 양의 지식을 활용할 수 있다고 인지했습니다. 아래 이미지는 LLM의 지식을 수확하기 위한 단계를 보여줍니다. 프로세스는 초기 프롬프트와 두 개의 예시 entity 쌍으로 시작되었고, 텍스트 패러프레이즈 모델이 초기 프롬프트를 패러프레이즈하고 원본에서 수정된 프롬프트를 유도하기 위해 사용되었습니다. 그 후, 해당 프롬프트 세트에 해당하는 entity pair를 검색하였습니다. 검색 및 재점수화 방법을 사용하여, 가장 관련성 있는 쌍을 추출하여 지식 그래프를 형성하였고, 해당 쌍의 entity를 노드, 프롬프트를 관계로 사용하였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방식을 통해 파생 관계가 전통적으로 구성된 지식 그래프에는 보이지 않는 여러 특성을 가지고 있어서 결과적으로 그래프 간에 더 나은 관계 품질을 제공했습니다:\n\n- 관계는 복잡할 수 있습니다. 예를 들면 \"A는 B를 할 수 있지만 잘하지는 않다\"와 같이.\n- 관계는 두 개체 이상을 포함할 수 있습니다. 예를 들면 \"A는 C에서 B를 할 수 있다\"와 같이.\n\n또한 LLMs를 사용하여 지식 그래프를 형성하는 것은 LLM 내에서 포착된 지식을 시각화하고 양적으로 표현하는 새로운 방법을 제시했습니다.\n\n![그림](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n요약하자면, 우리는 지식 그래프와 대형 언어 모델(LLMs)이 지식 베이스로서 갖는 잠재력에 대해 논의했습니다. 지식 그래프는 관계를 포착하는 능력이 뛰어나며 추론 능력이 크지만 구축하기 어렵고 비용이 많이 듭니다. 반면, LLMs는 방대한 지식을 포함하고 있지만 편향, 환각 및 기타 문제에 노출될 수 있습니다. 특정 도메인에 맞게 세밀하게 조정하거나 적응시키는 데도 계산적으로 비용이 많이 듭니다. 두 방법의 장점을 활용하기 위해 지식 그래프와 LLMs를 여러 방법으로 통합할 수 있습니다.\n\n본 문서에서는 LLMs를 사용하여 자동 지식 그래프 구축을 지원하는 데 초점을 맞추었습니다. 특히, 과거의 COMET 모델을 포함한 ChatGPT를 사용하여 BEAR에서 정보 추출기로 사용하고 LLMs로부터 지식을 직접 수확하는 네 가지 예시를 검토했습니다. 이러한 방법들은 지식 그래프와 LLMs의 강점을 결합하여 지식 표현을 향상시키는 방향으로 유망한 발전을 나타냅니다.\n\n# 참고 문헌\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 지식 그래프란 무엇인가요? | IBM. (연도 미상). [Www.ibm.com](https://www.ibm.com/topics/knowledge-graph)\n- 양, 루이 등. (2023). 사실을 우리에게 제시하세요: 사실인식 언어 모델에 지식 그래프를 통합하여 개선하기 (버전 2). arXiv. [https://doi.org/10.48550/ARXIV.2306.11489](https://doi.org/10.48550/ARXIV.2306.11489)\n- 펑, 창 등. (2023). Knowledge Solver: 지식 그래프에서 도메인 지식 검색을 위한 LLM 교육 (버전 1). arXiv. [https://doi.org/10.48550/ARXIV.2309.03118](https://doi.org/10.48550/ARXIV.2309.03118)\n- 보स슬룻, 알렉스 등. (2019). COMMONET: 자동 지식 그래프 구축을 위한 상식 트랜스포머 (버전 2). arXiv. [https://doi.org/10.48550/ARXIV.1906.05317](https://doi.org/10.48550/ARXIV.1906.05317)\n- 유, 성 등. (2023). BEAR: LLM을 활용한 서비스 도메인 지식 그래프 구축 혁신. Service-Oriented Computing (페이지 339-346). Springer Nature Switzerland. [https://doi.org/10.1007/978-3-031-48421-6_23](https://doi.org/10.1007/978-3-031-48421-6_23)\n- 코미네니, 빅라브 카시 등. (2024). 인간 전문가로부터 기계로: 온톨로지 및 지식 그래프 구축을 위한 LLM 지원 접근 방식 (버전 1). arXiv. [https://doi.org/10.48550/ARXIV.2403.08345](https://doi.org/10.48550/ARXIV.2403.08345)\n- 하오, 순영 등. (2022). BertNet: 사전 훈련된 언어 모델에서 임의 관계를 가진 지식 그래프 수집하기 (버전 3). arXiv. [https://doi.org/10.48550/ARXIV.2206.14268](https://doi.org/10.48550/ARXIV.2206.14268)","ogImage":{"url":"/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_0.png","tag":["Tech"],"readingTime":9},{"title":"LLM의 행동을 바꾸는 것은 GPU를 바꾸는 것입니다","description":"","date":"2024-06-20 18:45","slug":"2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_0.png\" /\u003e\n\n대부분의 기술인들은 의존성의 다양한 버전이 다른 동작으로 이어질 수 있다는 것을 알고 있습니다. 그러나 대규모 언어 모델의 영역에서는 우리가 많은 계산을 필요로 하기 때문에 훈련과 추론 작업 양쪽에서 GPU에 크게 의존합니다. 그럼에도 불구하고 몇몇은 GPU를 변경하면 여러분의 LLM 출력에도 영향을 줄 수 있다는 것을 실제로 인식하고 있지 않습니다.\n\n그래서 똑같은 환경을 만들려고 하고 계신가요?\n의존성 버전을 설정할 수 있습니다.\n도커화를 사용할 수 있습니다.\nLLM 온도를 0으로 설정할 수 있습니다.\n원하는 시드를 설정할 수 있습니다.\n결국 여러분이 똑같은 GPU 모델을 사용하지 않았다면 이 모든 것이 작동하지 않을 것입니다.\n\n본 기사에서는 차이점이 발생하는 위치와 그 이유를 보여주는 실험을 통해 이 현상을 강조하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참고: 실험을 재현하거나 코드에 관심이 없다면 코드 스니펫을 건너 뛸 수 있습니다 (바로 \"7. 두 개의 GPU에서 동일한 입력과 동일한 LLM에서 생성된 답변이 왜 다를까요?\" 섹션으로 이동하여도 이해에 도움이 되는 결론을 얻을 수 있습니다.\n\n# 1. 이 기사를 읽는 이유는?\n\n어느 날, OpenAI와 Anthropic 모델이 설계상 결정론적이지 않은 이유에 대해 몇 분들과 토론하고 있었습니다. MoE (Mixture of Experts) 방식을 사용할 수 있어 토큰을 최적의 전문가에 경로 지정하지 못할 수도 있다고 설명했습니다. 왜냐하면 해당 전문가들이 다른 토큰 처리에 너무 바쁘기 때문에 이로 인해 일관성 없는 답변이 나오기도 합니다.\n\n또 다른 요인은 OpenAI가 효율성을 위해 쿼리를 배치하는 것일 수 있습니다. 이러한 배치의 크기는 들어오는 쿼리의 양에 따라 달라질 수 있으며 GPU 계산 전략을 변경하여 다른 결과를 이끌어낼 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어떤 사람이 \"다른 GPU도 서로 다른 결과로 이어질 수 있지 않을까요?\" 라고 말하자 대화가 흥미로워졌어요.\n\n생각해보세요... OpenAI API를 사용할 때, 여러분을 대신하여 계산을 실행하고 결과를 반환해주는 원격 기기가 있어요. 만약 그 기기가 항상 동일한 하드웨어에서 작동하지 않는다면, 결국 동일한 출력을 받지 못할 수도 있어요.\n\n이를 염두에 두고 다른 고려 사항들이 발생할 수 있어요:\n\n- 만약 제가 운영중인 LLM 앱을 다른 GPU를 가진 다른 인스턴스로 확장해야 한다면, 큰 문제가 될까요?\n- 개발 환경에 사용된 GPU가 운영 환경과 다를 경우 어떻게 될까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 이러한 질문들은 현상을 강조하고 그 영향이 얼마나 중요한지 확인하기 위해 실험을 설정하고 싶다는 생각을 들게 했어요.\n\n## 2. 실험 설정하기\n\n현상을 강조하기 위해 두 개의 동일한 환경을 설정하겠습니다. 그 환경들은 GPU만 다를 것입니다: 첫 번째는 Nvidia Tesla T4이고 두 번째는 Nvidia A10G일 것입니다. 그런 다음 Mistral-7b-v0.1을 사용하여 조금씩 실험을 해보겠습니다.\n\n노트북에서 실험을 실행하기 위해 다음 단계를 따라주시면 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 환경 설정하기\n\n- CUDA 버전 설정하기.\n\n```js\n!pip uninstall torchvision torchtext torchaudio torch -y\n!pip install torchvision==0.16.0 torch==2.1.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html\n```\n\n2. Transformers 및 관련 모듈 버전 설정하기.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n!pip3 어클리러레이트 비츠엔바이츠 트랜스포머 데이터셋을 각각 제거합니다.\n!pip3 어클리러레이트==0.28.0 비츠엔바이츠==0.43.0 트랜스포머==4.39.3 데이터셋==2.18.0를 설치합니다.\n```\n\n3. 랜덤 시드 설정:\n\n```js\n# 시드 값을 설정하면 일관된, 재현 가능한 결과를 얻을 수 있습니다.\nimport random\nimport numpy as np\nimport torch\nfrom transformers import set_seed\n\n# 재현성을 위해 시드 설정\nrandom_seed = 42\nnp_seed = 42\ntorch_seed = 42\ntransformers_seed = 42\n\nrandom.seed(random_seed)\nnp.random.seed(np_seed)\ntorch.manual_seed(torch_seed)\nset_seed(transformers_seed)\n```\n\n참고: transformers.set_seed만 설정해도 충분하지만 보다 안전하게 하기 위해 추가적으로 설정하였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**참고 2:** 이 예시에서는 Python 3.10을 사용합니다.\n\n## Mistral 불러오기\n\nHugging Face로부터 Mistral-7B-v0.1 모델을 불러오려면, 환경 변수 HF_TOKEN에 Hugging Face 토큰을 설정해야 합니다.\n모델의 양자화된 버전을 사용할 것이며, 이는 계산의 정밀도를 줄여 GPU의 메모리 사용량을 줄이는 것을 의미합니다.\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\nfrom time import time\nimport os\n\nmodel_name = \"mistralai/Mistral-7B-v0.1\"\ndevice = \"cuda\" # 모델을 불러올 장치\n\n# 단순성을 위해 이렇게 유지하지만, Hugging Face 토큰은 .env 파일에 넣고, 'python-dotenv' 라이브러리의 load_dotenv 함수를 사용하여 불러오는 것이 좋습니다.\nos.environ[\"HF_TOKEN\"] = \"\u003c여기에 Hugging Face 토큰을 입력하세요\u003e\"\n\ndouble_quant_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype = \"float16\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    padding_side=\"right\",\n    add_eos_token=False,\n    add_bos_token=False,\n    trust_remote_code=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=double_quant_config)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 트랜스포머 파이프라인 사용\n\n우리는 트랜스포머 라이브러리의 pipeline을 사용하여 LLM(Large Language Model)에서 출력을 생성하는 것을 간단하게할 것입니다.\n\n결정론적인 이유로, LLM의 어휘 중에서 가장 가능성 있는 토큰을 일관되게 예측하고 싶으므로, top_k=1 또는 0에 가까운 값으로 온도를 구성할 수 있습니다.\n\n또한, 간편함을 위해 max_new_tokens 매개변수를 1로 설정하여 LLM이 우리의 프롬프트를 하나의 토큰으로 완료하도록 할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom transformers import pipeline\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    add_special_tokens=False,\n    max_new_tokens=1,\n    temperature=0.00000000001,\n    repetition_penalty=1.4\n)\n\nsentence = \"I enjoy walking in the\"\n\nresponse = pipe(sentence)[0]['generated_text']\nprint(response)\n\n# \u003e\u003e\u003e I enjoy walking in the woods\n```\n\n만약 LLM이 \"I enjoy walking in the\"라는 시퀀스에 대해 \"woods\"라는 한 단어만 출력하면, 올바른 결과를 돌려주었다고 볼 수 있습니다. 그럼 실험을 진행해도 좋을 것 같아요.\n\n# 3. 실험 결과: T4 대 A10G\n\n이 두 개의 GPU에 접근하기 위해, AWS SageMaker를 통해 ml.g4dn.xlarge (T4) 및 ml.g5.xlarge (A10G) 인스턴스를 론칭했습니다. \n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단한 쿼리를 시도해 봅시다:\n\n```js\n# 프롬프트\n매우 간결하게 질문에 대답하세요\n질문: 대형 언어 모델의 특별한 점은 무엇인가요?\n답변:\n```\n\n```js\nprompt = \"\u003cs\u003e[INST]매우 간결하게 질문에 대답하세요[/INST] \\n질문: 대형 언어 모델의 특별한 점은 무엇인가요? \\n답변:\"\nresponse = pipe(prompt)[0]['generated_text']\nprint(response)\n```\n\nT4와 A10G에서 얻은 답변이 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n질문: 대형 언어 모델에 대해 무엇이 특별한가요?\n대답: 그들은 인간이 쓴 것처럼 보이는 텍스트를 생성할 수 있습니다. 이는 번역이나 텍스트 요약과 같은 여러 작업에 사용될 수 있음을 의미합니다(한 언어에서 다른 언어로 또는 반대로). 모델 자체는 교육 데이터가 필요하지 않지만 입력 문장을 기반으로 새로운 문장을 생성할 때 어떻게 동작해야 하는지 몇 가지 예시만 필요로 하므로 다른 모델들보다 훨씬 쉬워집니다. 더 이상 사전에 여러 데이터 세트를 사전에 가지고 있을 필요가 없다는 것을 의미합니다!\n\n지금까지 좋습니다. 그러나 이것은 짧은 쿼리였습니다. RAG 사용 사례의 경우, 통상 수천 개의 토큰을 전송합니다. Hugging Face에서 호스팅되는 llama-2-arxiv-papers-chunked 데이터 세트를 사용하여 더 큰 쿼리로 테스트해 봅시다.\n\n다음 코드에서는 데이터 세트의 인덱스 0, 4518, 4519 및 799에서 검색된 청크를 사용하여 RAG가 어떻게 작동하는지 모방할 것입니다. 청크 4518과 4519는 Llama 2에 대해 설명하지만 다른 청크는 아닙니다. 이 문맥을 사용하여 LLM이 이 질문에 대한 답변인 'Llama 2에 대해 무엇이 특별한가요?'을 예상합니다. 이 프롬프트는 약 1,400개의 토큰입니다.\n\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nT4의 결과:\n\n```js\nLlama 2와 블룸 또는 친치아와 같은 대형 언어 모델 세부 튜닝 사이의 주요 차이점은 그들의 훈련 방법입니다. 이 두 가지 방법은 인터넷에서 스크랩된 데이터로 모델을 훈련하지만, Llama 2는 훈련 시 자체에서 생성된 텍스트만 사용하여 시스템에 편향이 외부 소스(소셜 미디어 게시물 등)로 인해 도입되는 가능성을 낮춥니다. 또한 이는 내부의 모든 것이 다른 실행에서도 일관되게 유지되므로 나온 결과물을 더 신뢰할 수 있게 합니다! 또한 각 단어 토큰이 문장 당 전역 점수 한 개가 아니라 개별 가중치 값을 ​​할당받기 때문에 특정 작업 시 사용자가 더 좋은 제어를 얻을 수 있어서 현재 경쟁하는 시스템들이 부족한 기능입니다. 마지막으로 중요한 것은, 비용이 비싼 하드웨어 리소스에 크게 의존하는 다른 시스템과 달리 스스로 업데이트해야 하는 시기가 예상보다 빠르지 않는 한 수개월마다 상수적으로 업데이트해야 하는 시스템 등...\n```\n\nA10G의 결과:\n\n```js\nLlama 2와 블룸 또는 친치아와 같은 대형 언어 모델 세부 튜닝 사이의 주요 차이점은 그들의 훈련 방법입니다. 이 두 가지 방법은 인터넷에서 스크랩된 데이터로 모델을 훈련하지만, Llama 2는 훈련 시 자체에서 생성된 텍스트만 사용하여 시스템에 편향이 외부 소스(소셜 미디어 게시물 등)로 인해 도입되는 가능성을 낮춥니다. 또한 이는 이 텍스트 내에서 다루는 주제에 대한 질문을 할 때 더 자신감을 갖도록 하기 때문에, 잠재적인 편향은 이미 사전에 제거되어 있을 것입니다! 또한 여기서 사용된 각 단어는 다른 단어 뒤에 직접 올기기 때문에 문장 내에 무작위 단어가 무작위로 삽입되는 것보다 오류가 적은 것을 의미하며, 전통적인 기계 학습 접근법들과 비교할 때 매 문장이 자체 내부에 일종의 오류 교정 메커니즘을 가져야 하는 경우가 적습니다. 마지막으로 중요한 것은, 어떤 유형의 질문이든 누군가 질문을 해도 중요하지 않습니다. 트위터 DM 메시지를 통해 친구나 가족 구성원 사이에 개인적으로 보낸 짧은 쿼리든, 손으로 종이에 수기로 쓴 장문의 글이나 나중에 디지털적으로 스캔된 문서든 내 무엇이 어떤 질문을 하든 언제든지 모든 것이 신뢰할 수 있게 된다는 사실 덕분에 하드의 모든 것이 AI 기술에 의해 일어나는 세계 밑바닥에서 발생하는 모든 것에 크게 기여합니다!!!\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참 흥미로운 내용이에요. 처음 보면 두 답변이 같은 내용으로 시작하기 때문에 눈에 띄지 않을 수 있어요. 하지만 \"etc...\" 다음에는 차이가 있어요.\n\nT4 쪽에서는: \"etc... 이는 내부의 모든 것이 다른 실행에서도 일관되게 유지되므로 출력에 더 신뢰를 할 수 있다는 것을 의미합니다!...\"\n\nA10G 쪽에서는: \"etc... 이는 이 텍스트 내에서 다루는 주제에 관련된 질문을 할 때 더 자신감을 가질 수 있게 될 거에요...\"\n\n# 4. T4 Colab vs T4 SageMaker.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n동일한 GPU를 사용하는 두 환경이 동일한 결과를 낳는지 궁금한 분을 위해, 무료 버전의 Colab 노트북과 T4를 장착한 것이 특징인 ml.g4dn.xlarge (T4) SageMaker 노트북 인스턴스를 구동하여 테스트를 실시해 보았습니다. 결과는 실제로 동일함을 확인했습니다.\n\n# 5. 왜 두 개의 GPU에서 동일한 입력과 동일한 LLM으로 생성되는 답변이 완전히 다른가요?\n\n동일한 입력으로 생성되는 답변이 매우 다른 이유는 LLM의 자기회귀적인 성질 때문입니다. 다음 토큰은 이전 토큰에 의해 선택되므로, 아주작은 변경이 연쇄 반응을 일으켜 나비 효과를 초래합니다.\n\n주어진 맥락을 기반으로 한 답변은 아니라는 점을 유의하세요. LLM은 지시에 완전히 따르지 않았지만, 그것은 중요하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM을 항상 가장 가능성 높은 토큰으로 선택하도록 설정했기 때문에, GPU 간에 확률을 계산하는 방법을 살펴볼 수 있습니다. 이러한 확률을 조사해 보겠습니다.\n\n# 6. 확률 탐색\n\n각 선택된 토큰의 확률을 인쇄하려면, 파이프라인을 우회하고 tokenizer와 model.generate 메소드를 직접 사용하여 출력_dict_in_generate=True 및 output_scores=True를 설정할 수 있습니다. 그런 다음 전이 점수를 확률로 계산, 정규화 및 변환할 수 있습니다.\n\n```js\ninputs = tokenizer([prompt], return_tensors=\"pt\")\n\noutputs = model.generate(**inputs, max_new_tokens=300, temperature=0.00000000001, repetition_penalty=1.4, return_dict_in_generate=True, output_scores=True)\ntransition_scores = model.compute_transition_scores(\n    outputs.sequences, outputs.scores, normalize_logits=True\n)\n\ninput_length = inputs.input_ids.shape[1]\ngenerated_tokens = outputs.sequences[:, input_length:]\nfor tok, score in zip(generated_tokens[0], transition_scores[0]):\n    // | 토큰 | 토큰 문자열  | 확률\n    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {np.exp(score.numpy()):.2}\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드는 각 토큰의 ID, 디코딩된 토큰 및 확률을 출력할 것입니다. 출력의 전체 내용이 상당히 길기 때문에 중요한 부분만 포함하겠습니다.\n\nT4 출력:\n\n```js\n# T4\n토큰 ID | 토큰 문자열 | 확률\n----------------------------------\n...\n|  4345 | etc       | 35.28%\n|   568 | ..        | 44.56%\n|   851 | This      | 36.57%\n|   835 | also      | 30.27%\n|  2825 | means     | 38.98%\n|   368 | you       | 24.24%\n|   541 | can       | 46.44%\n|  4893 | trust     | 18.74%\n|   767 | what      | 29.62%\n|  3435 | comes     | 44.17%\n|   575 | out       | 40.51%\n...\n```\n\nA10G 출력:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# A10G \n토큰 id| 토큰 문자열 | 확률\n----------------------------------\n...\n| 4345 | 등등      | 35.48%\n| 568  | ..        | 44.38%\n| 851  | 이것      | 36.40%\n| 835  | 또한      | 30.22%\n| 2825 | 의미       | 39.42%\n| 368  | 당신       | 24.29%\n| 541  | 할 수 있다 | 46.42%\n| 347  | 되다      | 18.62%\n| 680  | 더        | 49.45%\n| 10689| 자신감      | 57.50%\n...\n```\n\n오케이, 이제 흥미로워지고 있네요. T4와 A10G의 확률이 정확히 일치하지 않습니다. 보통 이것은 토큰 순위에 영향을 미치지 않습니다(생성된 시퀀스에서 아무것도 알아차리지 못할 것입니다), 하지만 때로는 그렇지 않을 수도 있습니다.\n\n예를 들어, T4에서 \"신뢰\"는 18.74%의 확률을 가지고 있지만, A10G에서는 \"되다\"가 18.62%로 선호됩니다. 이 시점부터 LLM의 자기회귀적 성질로 인해 생성이 분기될 것입니다.\n\n참고: LLM의 양자화는 계산 정밀도를 줄이기 때문에 이러한 차이가 더 자주 발생합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당신에게 한 가지 합리적인 질문은 \"GPU에 따라 계산이 왜 다를까요?\"입니다.\n\n## 7. GPU에 따라 계산이 다르게 나타나는 이유는 무엇인가요?\n\n저는 CUDA 전문가는 아니지만 연구를 했습니다. GPU 간의 차이는 여러 요인과 관련이 있습니다:\n\n병렬 계산 처리:\nGPU는 병렬로 많은 계산을 효율적으로 처리하는 데 관심이 있습니다. 그러나 서로 다른 GPU는 병렬 작업을 처리하는 방식에 차이가 있을 수 있으며, 이는 연산 순서와 메모리 접근에 영향을 줄 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 중요합니다. 프로그래밍에서 크기가 크게 다른 숫자를 더하는 것조차 연관성이 없을 수 있기 때문입니다. 이는 정교한 계산에서 정확도에 영향을 줄 수 있습니다. 비연관성은 다음과 같은 경우에 발생합니다.\n\n(a + b) + c ≠ a + (b + c).\n\n![이미지](/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_1.png)\n\n그래서 이러한 계산은 분할되어 독립적으로 처리되고, 그 후 비연관적으로 결합됩니다. 결과적으로, 이러한 부분들이 다시 결합되는 방식이 최종 결과에 영향을 줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 연관되지 않은 계산의 간단한 예시입니다:\n\n```js\nimport torch\n# 크기 차이가 큰 bfloat16 형식의 세 개의 부동 소수점 수를 정의합니다.\na = torch.tensor(1e10, dtype=torch.bfloat16)\nb = torch.tensor(-1e10, dtype=torch.bfloat16)\nc = torch.tensor(1.0, dtype=torch.bfloat16)\n\n# 서로 다른 순서로 합을 계산합니다.\nsum1 = (a + b) + c\nsum2 = a + (b + c)\n# 계산 결과를 bfloat16로 출력합니다.\nprint(f\"(a + b) + c in bfloat16: {sum1}\")\n# \u003e\u003e\u003e 1.0\nprint(f\"a + (b + c) in bfloat16: {sum2}\")\n# \u003e\u003e\u003e 0.0\n```\n\nLLM을 사용하면 수백만 개의 계산이 소수점 오차로 인해 발산할 수 있으며, 이는 시퀀스 생성 중 단어 선택에 영향을 미칠 수 있습니다.\n\n하드웨어 아키텍처:\nNvidia Tesla T4 및 Nvidia A10G와 같은 다양한 GPU 모델은 다른 하드웨어 아키텍처를 가지고 있습니다. 이러한 아키텍처는 병렬 처리 능력, 메모리 대역폭 및 계산 유닛과 같은 성능의 다양한 측면을 최적화하기 위해 설계되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, T4는 Turing 아키텍처를 사용하는 반면 A10G는 Ampere 아키텍처를 기반으로 합니다.\n\n다른 아키텍처는 부동 소수점 산술, 메모리 액세스 패턴 및 기타 저수준 작업에 대한 다른 구현을 의미합니다. 이러한 구현의 미묘한 차이도 계산 결과의 차이를 초래할 수 있습니다.\n\n예를 들어, 높은 정밀도에 최적화된 아키텍처는 속도에 최적화된 아키텍처와 비교하여 동일한 부동 소수점 작업을 수행하더라도 다른 결과를 제공할 수 있습니다.\n\n양자화 효과:\n모델을 양자화하면 메모리 및 계산 리소스를 저장하기 위해 정밀도를 줄이지만 추가적인 오류 소스를 도입합니다. 이러한 오류의 영향은 GPU가 낮은 정밀도 산술을 처리하는 방식에 따라 다를 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n양자화는 숫자를 근사화하는 과정이 포함되어 있기 때문에 다양한 GPU가 이러한 근사화를 다르게 처리할 수 있으며, 토큰 예측의 확률에 변화를 일으킬 수 있습니다.\n\n## 8. 여러 GPU를 사용하여 LLM을 수평적으로 확장하는 것에 대해 걱정해야 할까요?\n\n그 질문 정말 훌륭한 질문이네요, 질문해 주셔서 감사합니다! :)\n동일한 GPU의 여러 인스턴스를 추가하는 경우(예: A10G GPU 1대에서 4개의 A10G GPU가 포함된 인스턴스로 확장) 걱정해야 할 필요가 있을까요?\n\n여러 GPU를 사용하여 추론 작업에 접근하는 여러 전략이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델이 하나의 GPU에 맞는 경우 첫 번째 전략은 각 GPU에 모델 사본을 로드하는 것입니다. 예를 들어, pipeline으로 네 개의 쿼리 목록을 보내면 각 쿼리가 다른 GPU에서 처리될 수 있습니다. 이렇게 하면 한 GPU만 사용하는 것과 같은 결과를 볼 수 있지만 처리량이 향상됩니다.\n\n두 번째 전략은 모델이 하나의 GPU에 맞지 않는 경우 일반적으로 사용되며, 이는 샤딩(sharding)으로 그 모델의 가중치를 GPU들 간에 분산하는 것입니다. 이론적으로는 연산 분배와 실행 차이로 인한 변화가 발생할 수 있지만, 실제로는 적어도 제가 한 테스트에서는 샤딩 사용 시 단일 GPU에서의 시퀀스와 확률과 동일한 결과를 얻었습니다. 파이토치는 결정론적 연산을 위해 노력한다고 생각됩니다.\n\n# 결론:\n\n다른 GPU를 사용하면 동일한 환경, 설정 및 시드를 사용해도 LLM이 서로 다른 결과를 출력할 수 있음을 보여줬습니다. 이러한 변동성은 보다 긴 프롬프트에서 더 많은 계산이 필요하기 때문에 증가하며, 부정확성의 전파가 증가하고 두 GPU 간의 차이가 완화됩니다. 게다가 양자화를 사용할 경우 이 효과가 더 두드러집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과가 항상 재앙적인 것은 아니라는 것을 말하고 싶은 게 아니에요, 하지만 LLM 배포 시 고려해야 할 사항이에요.\n\n만약 제품에서 사용하는 GPU와 다른 GPU로 개발한다면, 성능이 적절한지 확인하기 위한 테스트를 설정해주세요. 또한, 다른 GPU가 장착된 새로운 인스턴스에 LLM을 확장할 계획이 있다면 이 역시 중요해요.\n\n끝까지 읽으셨다면, 축하드려요! 이 게시물을 즐겨주셨으면 좋겠어요. 제가 Medium에서 처음으로 쓴 글이라서요. 재미있게 보셨다면 더 많이 쓰도록 격려해 주시기를 바라요. 댓글에서 의견을 자유롭게 공유해주세요.","ogImage":{"url":"/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_0.png"},"coverImage":"/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_0.png","tag":["Tech"],"readingTime":13},{"title":"탐사 분류기를 사용하여 연락 센터 LLMs의 학습 내용을 밝힐 수 있을까요 아니요, 불가능합니다","description":"","date":"2024-06-20 18:44","slug":"2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt","content":"\n\n이 블로그는 2024년 NAACL에서 수락된 기술 논문에 대한 참조입니다. 이 논문은 멕시코시티에서 개최된 5번째 맞춤형 결과로부터의 통찰력 워크샵(NLP@NAACL)에서 발표되었습니다.\n\n![이미지](/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png)\n\n## 소개\n\n고객 서비스의 빠른 세상에서, 연락 센터는 기술 지원부터 청구 문의까지 모든 분야의 고객 상호 작용의 최전선으로 기능합니다. 기술이 발전함에 따라 대규모 언어 모델(LLMs)이 연락 센터에 통합되면 고객 지원의 제공 방식을 혁신화할 수 있습니다. 다만, 이러한 모델의 효과는 연락 센터 상호 작용의 특정 세부 사항을 이해하고 처리할 수 있는 능력에 크게 의존합니다. 저희 논문인 \"프로빙 분류기가 연락 센터 대규모 언어 모델의 학습을 밝혀 줄까요?: 아니요, 그렇지 않습니다!\"에서는 연락 센터 도메인을 위해 특별히 선별된 LLMs의 학습을 프로빙 분류기가 밝혀낼 수 있는지 조사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 동기\n\n본 연구의 동기는 접촉 센터를 포함한 다양한 영역에서 LLMs에 대한 의존도가 점점 증가하고 있다는 점에서 비롯됩니다. 접촉 센터는 고객 지원 및 서비스에 중요한 역할을 하며 기술적 문제부터 청구 관련 문제까지 다양한 쿼리를 처리합니다. 그러나 이러한 상호 작용의 즉흥적이고 소음이 많은 특성은 LLMs에게 중요한 도전 요소가 됩니다. 도메인별 데이터로 LLMs를 세밀하게 조정하면 성능을 향상시킬 수 있지만, 이 과정에서 이러한 모델이 실제로 무엇을 배우는지 이해하는 것이 중요합니다. 기존에는 탐사 분류기가 LLMs의 내부 표현을 해석하고 이해하는 데 사용되어 왔지만, 이들이 도메인별 학습의 세부 사항을 밝히는 데 얼마나 효과적인지는 여전히 불분명합니다. 본 연구는 접촉 센터 응용 프로그램을 위해 세밀하게 조정된 LLMs가 습득하는 핵심적인 특성을 평가함으로써 이 갭을 메우고자 합니다.\n\n## 도메인별 세밀한 조정의 중요성\n\nOpenAI 및 Google과 같은 대규모 언어 모델은 인간과 유사한 텍스트를 생성하는 놀라운 능력을 보여주고 있습니다. 이러한 모델의 성능을 재정 및 생명공학과 같은 특정 도메인에서 더욱 향상시키기 위해 이러한 모델은 종종 도메인별 데이터로 세밀하게 조정됩니다. 이 방법은 다양한 분야에서 성공적인 것으로 입증되었지만, 접촉 센터 도메인에는 소음이 많은 쿼리, 즉흥 대화 및 특정 용어와 같은 독특한 도전 요소가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 방법론\n\n본 연구에서는 30억부터 130억 개 파라미터까지 다양한 크기의 두 가지 인기 있는 LLM 아키텍처인 Flan-T5와 Llama에 중점을 두었습니다. 저희는 내선 작업에서의 효과를 측정하기 위해 연락센터 대화의 독점 데이터셋으로 이러한 모델들을 세밀하게 조정합니다. 또한 이 연락센터(CC) 도메인 특화 지시 LLM들이 기본 설정 버전과 비교했을 때 배운 근본적 특성을 평가합니다. 이를 위해 저희는 대화, 채널, 자동 음성 인식(ASR) 속성을 평가하는 점검 작업을 정의하여 무엇을 배우고 그것이 연락센터 도메인에서 실제 성능으로 어떻게 변환되는지 알아봅니다.\n\n## 주요 발견\n\n- 내선 작업에서의 성능 향상: CC-LLMs는 내선 작업에서 상당한 성능 향상을 보였습니다. 특히, OOB 모델과 비교하여 응답 수용성이 48% 이상 향상되었습니다. 이는 도메인 특화 세밀 조정이 연락센터에서 LLM의 실용성을 향상시키는 데 효과적임을 강조합니다.\n- 점검 분류기의 차이 미미: 내선 작업에서의 성능 향상에도 불구하고, 점검 분류기는 세세한 차이를 보이지 않았습니다. 이는 전통적인 점검 작업이 모델 내에서 발생하는 미묘한 학습을 효과적으로 포착하지 못할 수 있다는 것을 시사합니다.\n- 아키텍처와 크기의 중요성: 시험한 모델 중에서 T5 모델이 다양한 설정에서 일반적으로 Llama 모델보다 우수한 성능을 보였습니다. 흥미로운 점은 작은 CC-Flan-T5(110억) 모델이 종종 큰 CC-Llama(130억)보다 우수한 성능을 보인다는 것인데, 이는 모델 아키텍처가 모델 크기보다 더 중요할 수 있다는 것을 시사합니다.\n- 일반 언어 특성: 세밀 조정 이후, CC-Flan-T5와 CC-Llama 모델은 SentEval suite의 일반 언어 점검 작업에서 점수가 낮아졌으며, 일반 언어 특성에서 도메인 특화 능력으로의 초점 이동을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 함의 및 향후 방향\n\n연구 결과는 LLMs가 학습한 근본적인 특성들을 신뢰할 수 있는 방식으로 드러낼 수 있는 것이라는 가정에 도전하고 있습니다. 세부적으로 조정된 모델들은 특정 작업에서 우수한 성과를 보이지만, 기존의 조사 메커니즘은 모델의 학습에서 변경된 기본적인 특성을 발견하는 데 충분하지 않아 보입니다.\n\n이는 우리가 어떻게 조사 작업을 설계하고 활용하는지 재검토할 필요가 있음을 시사합니다. 컨택 센터의 대화의 동적이고 맥락 의존적인 성격은 보다 정교하고 맥락을 인지하는 조사 전략이 필요할 수도 있습니다. 게다가, 연구는 언어 생성 중의 디코딩 전략이 중요한 역할을 하며 향후 연구의 중점이 되어야 함을 제안합니다.\n\n마무리로, 컨택 센터와 같은 특정 도메인에 LLMs를 세부 조정함으로써 실용적 작업에서 성능을 크게 향상시킬 수 있지만, 기존의 조사 분류기는 이러한 개선 사항을 밝히는 데 한계가 있습니다. 이 연구는 더 효과적인 조사 방법에 대한 연구를 위한 새로운 방향을 제시하며, 높은 성과를 내는 LLMs 개발 시 아키텍처와 세부 조정 전략을 모두 고려하는 중요성을 강조합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n세계 곳곳의 연락센터를 위해 대화 인텔리전스를 변화시키는 Observe.AI에서 더 많은 정보를 확인해보세요.","ogImage":{"url":"/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png"},"coverImage":"/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png","tag":["Tech"],"readingTime":3},{"title":"다중 에이전트 시스템    LangGraph","description":"","date":"2024-06-20 18:42","slug":"2024-06-20-Multi-AgentSystemsLangGraph","content":"\n\n응, 맞아, Smiths가 여기 있어! 내 이전 게시물이 꽤 오래되었네. 처음 보는 사람이라면, 안녕. 이 게시물에서는 LangGraph에 대해 이야기하고, LangSmith에 대해서도 조금 언급하고 싶어. 최근에 우리는 에이전트 감독자를 구현하기 시작했어; 이것은 다중 에이전트 시스템을 구현하는 방법이야.\n\n그러나 너무 기술적으로 들어가기 전에, 잠시만 기다려 줄 수 있을까? 이것은 매트릭스의 Smith 에이전트야. 매트릭스에서 '질서'를 유지하기 위해 만들어진 코드 일부였다는 걸 기억해봐, 사람들을 시뮬레이션에 유지하는 시스템 내에서. (시스템이 붕괴해도, 네오에게 한 큰 박수). Smiths는 계층 구조였지; 다른 Smiths에게 일을 시키는 'the Smith'가 있었어. (그는 나중에 시뮬레이션 내에서 자신의 존재를 복제할 수 있었지. 사실, 많은 요청이 있는 시스템을 다루는 매우 멋진 방법이라고 할 수 있어, 아마 LangChain의 다음 움직임이 될지도 ;))\n\n![Smith Image](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_0.png)\n\n내 농담 세션 이후, LangGraph는 정말 멋진 라이브러리야; LangChain이 감당할 수 없는 경우에 매우 유용해. 복잡한 문제, 사용 사례 또는 흐름을 나누는 해결책을 제공해줘. 이전에 언급한 대로, 다중 에이전트 시스템에 대해 이야기할 테니, 주로 감독자 구현에 대해 이야기할 거야, 왜냐하면 이러한 에이전트를 결합하는 다양한 방법이 있거든. 그리고 우리가 챗봇을 구현하려고 노력하고 있기 때문에, 고객 지원 봇 튜토리얼에서 많은 도움을 받았어. 채팅에서 무엇을 할 수 있고, 에이전트를 제어하여 올바른 일을 수행하는 방법에 대해 매우 명확한 아이디어를 제공해줘.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# LangGraph 소개\n\nLangGraph는 LangChain 위에 구축되어 있으며 LangChain 생태계와 완전히 호환됩니다. 그것은 기본적으로 그래프 기반 상태 머신을 사용하여 복잡하고 확장 가능한 AI 에이전트를 구축하는 Python 라이브러리입니다. LangChain을 시도해 본 적이 있다면, 에이전트를 프로덕션 환경에서 실행하려고 할 때 그 부족함을 느낄 것입니다. 프로덕션에서는 종종 더 많은 제어가 필요합니다. 특정 도구를 항상 호출하도록 강제하고 싶을 수 있습니다. 도구를 호출하는 방법을 더 많이 제어하고 싶을 수 있습니다. 상태에 따라 에이전트에 대한 서로 다른 프롬프트를 사용하고 싶을 수 있습니다.\n\n그렇다면, 이 “상태 머신”이란 무엇일까요? 이를 통해 인간 상호작용을 순환하며 LLM(Lang Language Model)을 통해 작업을 수행할 수 있는 권한을 얻게 됩니다. 이는 어떤 에이전트가 실행되었는지, 어떤 도구를 사용했는지, 그리고 원한다면 메모리까지 추적합니다. 현재 메모리에 대해 자세히 알아볼 필요는 없지만, LangChain에서 본 것과는 조금 다릅니다. Checkpointer는 상태를 영속화하여 에이전트에게 \"메모리\"를 제공합니다.\n\n## StateGraph\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStateGraph은 그래프를 나타내는 클래스입니다. 상태 정의를 전달하여이 클래스를 초기화합니다. 그래프 내의 노드가 상태를 업데이트하고, 이는 키-값 저장소 형식의 작업을 반환합니다.\n\n```js\nfrom langgraph.graph import StateGraph\nfrom typing import TypedDict, List, Annotated\nimport Operator\nfrom langchain_core.messages import BaseMessage\n\nclass State(TypedDict):\n    input: str\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n\ngraph = StateGraph(State)\n```\n\n## 노드\n\nStateGraph를 만든 후 graph.add_node(name, value) 구문을 사용하여 노드를 추가합니다. value 매개변수는 호출 될 함수 또는 LCEL 실행 가능이어야 합니다. (즉 실행 가능한 도구 또는 LLM)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ngraph.add_node(\"model\", model)\ngraph.add_node(\"tools\", tool_executor)\n```\n\n그래프를 순환할 것이기 때문에 프로세스 중 어딘가에서 종료하는 것이 중요합니다. 그래프의 끝을 나타내는 END 노드를 사용하세요.\n\n```js\nfrom langgraph.graph import END\n\ngraph.add_node(\"end\", END)\n```\n\n## 엣지\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노드를 추가한 후에 그래프를 만들기 위해 엣지를 추가할 수 있습니다. 현재는 세 가지 유형의 엣지가 있습니다:\n\n1 - 시작 엣지: 이 엣지는 그래프의 시작점을 특정 노드에 연결하는 엣지입니다. 아래 코드는 우리의 그래프가 'model' 노드에서 시작한다는 것을 의미합니다.\n\n```js\ngraph.set_entry_point(\"model\")\n```\n\n2 - 일반 엣지: 이러한 엣지는 한 노드가 항상 다른 노드 뒤에 호출되도록합니다. 아래 코드는 'tools' 노드를 호출할 때 'model' 노드가 항상 그 뒤에 호출된다는 것을 의미합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ngraph.add_edge(\"tools\", \"model\")\n```\n\n3 - 조건부 엣지: 이는 LLM이 첫 번째로 이동할 노드를 결정하는 데 사용하는 엣지입니다. 엄격히 어디로 이동할지를 지정하지 않습니다. LLM은 상태와 사용자 입력을 확인하여 목적지를 결정합니다.\n\n조건부 엣지에는 세 가지 매개변수가 있습니다. 첫 번째 매개변수는 다음에 할 일을 결정할 노드입니다. 두 번째 매개변수는 다음으로 호출할 노드를 결정하는 함수입니다. 세 번째 매개변수는 함수(2)가 반환할 수 있는 가능한 값이어야 합니다. 그리고 값은 이동할 노드의 이름이어야 합니다.\n\n```js\ngraph.add_conditional_edge(\n    \"model\",\n    should_continue,\n    {\n        \"end\": END,\n        \"continue\": \"tools\"\n    }\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 컴파일\n\n우리가 그래프를 정의한 후, 그것을 실행 가능한 형태로 컴파일할 수 있습니다. 이 실행 가능한 형태는 LangChain 러너블과 똑같은 메소드를 가지고 있습니다 (.invoke, .stream, .astream_log 등).\n\n```js\napp = graph.compile()\n```\n\n# Multi-Agent Systems\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단일 에이전트는 순차적으로 실행해야 할 너무 많은 도구가 있을 때 실패할 수 있습니다. 그래서 다중 에이전트 시스템에서는 문제를 분할하여 각 단계를 다른 에이전트로 정복하고 적절한 전문가에게 업무를 라우팅합니다.\n\n## 에이전트 감독\n\n에이전트 그룹을 만들 것입니다. 각 에이전트는 작업을 완료하는 데 필요한 특정 도구를 갖게 됩니다. 에이전트 감독은 작업을 위임하는 데 도움을 줄 것입니다.\n\n![에이전트 감독](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예제에서는 2명의 에이전트와 1명의 감독관이 있습니다. 첫 번째 에이전트는 무작위 숫자를 생성하고, 다른 에이전트는 해당 무작위 숫자에 대한 다이어그램을 그립니다. 기대한 대로, 감독관이 작업을 위임하며, 무작위 숫자 생성 에이전트가 작업을 마치면 다른 에이전트에게 바퀴를 넘깁니다.\n\n우리는 기초를 정의하며 시작합니다.\n\n```js\nfrom langchain_openai import ChatOpenAI\nfrom typing import Annotated, List, Tuple, Union\nfrom langchain.tools import BaseTool, StructuredTool, Tool\nfrom langchain_experimental.tools import PythonREPLTool\nfrom langchain_core.tools import tool\nimport random\n\n\n#Model\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n\n#Tools\n\n#다이어그램 그리기용\npython_repl_tool = PythonREPLTool()\n\n#무작위 숫자 생성용\n@tool(\"random_number\", return_direct=False)\ndef random_number(input:str) -\u003e str:\n    \"\"\"0-100 사이의 무작위 숫자를 반환합니다. 'random'이라는 단어를 입력하세요.\"\"\"\n    return random.randint(0, 100)\n\ntools = [random_number,python_repl_tool]\n```\n\n도우미 함수로 계속하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent\nfrom langchain_core.messages import BaseMessage, HumanMessage\nfrom langchain_openai import ChatOpenAI\n\n# 주어진 도구와 프롬프트로 AgentExecutor를 반환하는 함수\ndef create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\n                \"system\",\n                system_prompt,\n            ),\n            MessagesPlaceholder(variable_name=\"messages\"),\n            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n        ]\n    )\n    agent = create_openai_tools_agent(llm, tools, prompt)\n    executor = AgentExecutor(agent=agent, tools=tools)\n    return executor\n\n# 에이전트 노드, 그래프에서 에이전트를 호출하는 데 사용할 함수\ndef agent_node(state, agent, name):\n    result = agent.invoke(state)\n    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n```\n\n이제 그래프를 만들어 이 2개의 에이전트를 노드로 추가하겠습니다 :\n\n```js\nimport operator\nfrom typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\nimport functools\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langgraph.graph import StateGraph, END\n\n# 난수 생성기를 노드로 설정\nrandom_agent = create_agent(llm, [random_number], \"You get random numbers\")\nrandom_node = functools.partial(agent_node, agent=random_agent, name=\"Random_Number_Generator\")\n\n# 코더를 노드로 설정\ncode_agent = create_agent(llm, [python_repl_tool], \"You generate charts using matplotlib.\")\ncode_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n```\n\n이제 슈퍼바이저를 생성해 봅시다!\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n\nmembers = [\"Random_Number_Generator\", \"Coder\"]\nsystem_prompt = (\n    \"안녕하세요! 대화를 관리하는 감독관으로 지정되었습니다. {members}와(과) 같은 작업자들 간의 대화 관리를 맡았습니다. 아래 사용자 요청이 제시된 경우, 다음에 행동할 작업자를 응답하세요. 각 작업자는 작업을 수행하고 결과 및 상태에 회신합니다. 작업이 완료되면 FINISH로 회신해주세요.\"\n)\n# 다음 작업자 노드를 선택하거나 처리를 종료하기 위해 함수 호출을 사용합니다.\noptions = [\"FINISH\"] + members\n# openai 함수 호출\nfunction_def = {\n    \"name\": \"route\",\n    \"description\": \"다음 역할을 선택합니다.\",\n    \"parameters\": {\n        \"title\": \"routeSchema\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"next\": {\n                \"title\": \"Next\",\n                \"anyOf\": [\n                    {\"enum\": options},\n                ],\n            }\n        },\n        \"required\": [\"next\"],\n    },\n}\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"messages\"),\n        (\n            \"system\",\n            \"위 대화를 참고하여, 다음에 누가 행동해야 할까요? 아니면 FINISH로 종료해야 할까요? 다음 중 하나를 선택해주세요: {options}\",\n        ),\n    ]\n).partial(options=str(options), members=\", \".join(members))\n\n\n# 라우팅 함수 및 시스템 프롬프트와 결합된 LLM으로 체인 생성\nsupervisor_chain = (\n    prompt\n    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n    | JsonOutputFunctionsParser()\n)\n```\n\n그래프를 생성해봅시다! (코멘트를 참고해주세요)\n\n먼저 상태를 정의하고 에이전트 노드와 감독관 노드를 추가합니다.\n\n```js\n# 메시지를 보유하고 어디로 이동할지를 나타내는 AgentState 정의\nclass AgentState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    # 'next' 필드는 다음으로 라우팅할 위치를 나타냅니다\n    next: str\n\n# 상태 그래프(StateGraph) 정의\nworkflow = StateGraph(AgentState)\n\n# 에이전트를 노드로 추가, 감독관 체인을 노드로 추가\nworkflow.add_node(\"Random_Number_Generator\", random_node)\nworkflow.add_node(\"Coder\", code_node)\nworkflow.add_node(\"Supervisor\", supervisor_chain)\n\n# 에이전트가 작업을 완료하면 다음은 항상 감독관이어야 합니다\nworkflow.add_edge(\"Random_Number_Generator\", \"supervisor\") \nworkflow.add_edge(\"Coder\", \"supervisor\")\n\n# 감독관이 그래프 상태의 \"next\" 필드를 결정하여 노드 또는 종료로 라우팅합니다. (위의 END 특수 노드를 기억하세요)\nworkflow.add_conditional_edges(\n    \"supervisor\", \n    lambda x: x[\"next\"], \n    {\n        \"Random_Number_Generator\": \"Random_Number_Generator\",\n        \"Coder\": \"Coder\",\n        \"FINISH\": END \n    })\n\n# 시작점은 항상 감독관이어야 합니다\nworkflow.set_entry_point(\"supervisor\")\n\ngraph = workflow.compile()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 번 해 보세요, 그래프를 스트리밍하거나 직접 실행할 수 있습니다.\n\n```js\nfor s in graph.stream(\n    {\n        \"messages\": [\n            HumanMessage(content=\"10개의 무작위 숫자를 가져와 히스토그램을 생성합니다.\")\n        ]\n    }, config={\"recursion_limit\": 20}\n):\n    if \"__end__\" not in s:\n        print(s)\n        print(\"----\")\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_2.png\" /\u003e\n\n출력에서 보듯이, 우리는 선언된 Supervisor로 시작합니다. Supervisor는 우리를 Random_Number_Generator로 경로 설정합니다. Random_Number_Generator가 작업을 완료한 후에는 엣지를 추가했기 때문에 Supervisor로 돌아갑니다. 그런 다음 Supervisor는 Coder로 경로를 설정하며 Coder가 완료되어 Supervisor로 돌아옵니다. 작업이 완료되면 Supervisor가 처리를 완료합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n🥳\n\n# LangSmith\n\nLangSmith은 LLM 애플리케이션 개발, 모니터링 및 테스트를 위한 플랫폼입니다. 저는 주로 모니터링에 사용하고 있어서 해당 측면만 언급할 예정이에요. LangSmith 추적을 활성화하면 LLM을 디버깅할 수 있어요.\n\n문서를 보려면 여기를 클릭하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 실행한 예제는 아래와 같이 보입니다:\n\n![image1](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_3.png)\n\n더 자세한 정보를 원하신다면:\n\n![image2](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n많은 도구를 가진 에이전트를 사용할 때 매우 유용합니다. 우리 경우에는 하나의 도구만 가지고 있었지만, 문제가 더 복잡해지고 내부에서 무슨 일이 일어나고 있는지 이해하고 싶을 때, LangSmith가 당신이 그 과정을 따라가는 데 정말 도움이 될 것입니다. 디버그 콘솔로도 할 수 있지만, 왜 이 도구가 있는데 불편하게 해야 하나요?\n\n환경 변수를 추가하여 추적 기능을 활성화할 수 있습니다:\n\n```js\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n```\n\n추가 링크:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- [https://blog.langchain.dev/langgraph/](https://blog.langchain.dev/langgraph/)\n- [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)\n\n즐겁게 즐겼다면 좋겠어요! 다음에 또 만나요 :)","ogImage":{"url":"/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_0.png"},"coverImage":"/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_0.png","tag":["Tech"],"readingTime":11},{"title":"GPT-4 - 우리는 속고 있는 걸까요","description":"","date":"2024-06-20 18:41","slug":"2024-06-20-GPT-4oAreWebeingLIEDto","content":"\n\n오늘날 열풍을 일으키는 인공지능(AI) 기술이 얼마나 빠르게 발전하고 있는지에 대해 Open AI 및 기타 기업들로부터 거짓 정보를 받고 있는 걸까요?\n\n![image](/assets/img/2024-06-20-GPT-4oAreWebeingLIEDto_0.png)\n\n또는 이것이 또 다른 \"NFT 순간\"인지, 즉 과대포장 이후 큰 폭락이 일어날 것인지 궁금할 수도 있겠네요.\n\n그런데 제 생각에 이번에는 그렇게 되지 않을 것 같아요. 저는 NFT 열풍 주기에는 믿음을 안 했지만, 인스턴스적으로는 인공지능 열풍에는 믿음이 많이 드네요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 매일 인공지능(AI)의 최신 정보를 읽어요.\n\n만약 당신이 유료 Medium 회원이 아니라면, 여기서 무료로 읽을 수 있어요.\n\n저는 우리가 인공 일반 지능(AGI)에 빠르게 다가가고 있다고 생각하는 것과 LLM(Large Language Model)의 능력 면에서 플랫폼에 다다르고 있는 것 중 어디에 더 가까운지 계속 변해요.\n\n양쪽에 대한 좋은 주장들이 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 AI가 지나치게 과대포장되고 있는 가능성을 살펴보고 싶습니다.\n\n내 AI 뉴스레터에 관심이 있을지도 몰라요 👉\n\n매일 GPT-4o를 사용하고 있어요.\n\n내 동생이자 비즈니스 파트너 인 Addison Best와 저는 GPT-4o의 역량이 감소하고 있다는 점에 주목하고 있어요. 네, 이것은 주관적인 견해이지만 감소가 상당히 명백해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 내가 GPT-4o에게 기사의 특정 부분에 제 제휴 링크를 넣도록 요청하면, 이런 간단한 작업에 엉망징창으로 처리할 수도 있어요.\n\n(이전에는 더 잘 작동했는데, 어떻게든 모델의 능력이 시간이 지남에 따라 변화하는 것 같아요)\n\nGPT-4o는 정말 빠르긴 하지만, 제가 무엇을 요청했는지에 대한 정확성과 이해력은 심지어 GPT-4보다 나빠 보이네요.\n\n그들이 얼마나 빠르고 능숙한지 알려줄 수 있다면, 아마 우리는 '빠른' 부분에 만족하고 '능숙한' 부분은 신경도 쓰지 않을 지 모를 거에요. (또는 '능숙한' 부분으로 인해 플러스 멤버십을 해지할 정도로 신경 쓰지도 않을 거에요.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 왜 내가 AI가 과대포장되었다고 생각하는지\n\n- 기업들은 더 많은 관심과 자금을 얻기 위해 AI에 대해 거짓말을 하고 과장하는 경제적 인센티브가 엄청나다.\n- 회사들은 실제로 AI 데모 중에 주장을 과장했다가 발각된 적이 있습니다 (Google, OpenAI, Amazon 등).\n- 모델은 점점 느려지는 것 같습니다 (개인적 경험).\n- 모델 파라미터의 수가 기하급수적으로 늘어남에도 성능은 그렇지 않습니다. (더 세게 짜도 한 송이 레몬에서 무한한 주스를 짤 수는 없습니다)\n- 어떤 사람들은 OpenAI가 음성을 더 인간적으로(예를 들어 애교있게 껄껄대면서) 만들어 \"가짜\" 지능을 만들고 있다고 주장합니다. — 이는 내가 생각하지 못한 흥미로운 포인트입니다.\n\n내가 개인적으로 믿는 바는 최고의 AI가 우리에게 주어진 것보다 훨씬 강력하다는 것입니다. 문제는 최고의 모델이 월 20달러에 제공하기에 충분히 에너지 효율적이지 않다는 것입니다.\n\n그래서 그들은 모델의 능력을 계속해서 억제하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n의견을 궁금해요.\n\n- 웹사이트 방문 - AI Growth Guys\n- 👉 AI 뉴스레터 👈 구독\n- 이메일 마케팅에 Beehiiv를 추천하는 이유 확인\n- AI Growth Guys YouTube 채널 확인\n- AI 전문가 Andrew Best의 소개 읽기\n\n# 쉽게 설명하면 🚀\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 떠나시기 전에:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 작가를 박수 치고 팔로우하기 잊지 마세요! 👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문하기: CoFeed | Differ\n- PlainEnglish.io에서 더 많은 콘텐츠 확인하기","ogImage":{"url":"/assets/img/2024-06-20-GPT-4oAreWebeingLIEDto_0.png"},"coverImage":"/assets/img/2024-06-20-GPT-4oAreWebeingLIEDto_0.png","tag":["Tech"],"readingTime":3},{"title":"AI 이해력을 높이는 방법","description":"","date":"2024-06-20 18:39","slug":"2024-06-20-HowtoJumpstartYourAILiteracy","content":"\n\nAI 열풍이 시작된 지 벌써 1년이 넘었어요. AI는 글쓰기, 예술, 기술, 소셜 미디어 그리고 업무에 영향을 미쳤어요. 이제 거의 모든 회사, 정부, 그리고 기관이 AI 열풍에 참여하고 있습니다. 인공 지능은 여기에 남아 있고, 버블이던 아니던 사회에 지속적인 영향을 미칠 거예요.\n\n하지만 당신은 어떤가요?\n\n내가 추측해 보면, 당신은 아래 중 하나에 해당할 것입니다:\n\n- AI에 정통하고 호기심이 많아서 더 알고 싶어 하는 분\n- AI를 꺼리며 그 열풍에 동참하지 않는 분\n- 이 모든 AI에 대해 뒤처지고 시작해볼 방법을 모르는 분\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당신의 위치와 관계없이 AI 지식을 늘리는 것이 중요합니다. 앞으로 AI는 우리가 일하는 방식을 항상 보완할 것입니다. 만약 당신이 화이트 칼라 직업을 가졌는데 인공지능 모델과 상호 작용하는 방법을 이해하지 못한다면 뒤처질 것입니다.\n\n충분한 공포를 조장하는 건 그만두고요... 저는 AI 지식 베이스를 확장하여 미래로 나아갈 방법과 새로운 사용 사례에 적용하기 위해 어떻게 준비할 수 있는지 말하려고 합니다.\n\n# AI 직감력을 개발하기\n\nAI에 능숙해지려면 다양한 용도에서 AI 모델의 응용 가능성을 인식하는 자연스러운 능력을 개발하는 것이 중요합니다. 좋은 소식은 모든 AI의 각 면을 이해할 필요는 없다는 것입니다. 이것을 발전시키는 것은 쉬운 일이라고 주장합니다. 오직 이러한 핵심 단계를 따르기만 한다면요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 매일 생활 속에서 AI 적용하기\n\n그냥 사용하세요. 많이요.\n\n![AI 이미지](/assets/img/2024-06-20-HowtoJumpstartYourAILiteracy_0.png)\n\nChatGPT와 대화를 나누어 문제를 해결해보세요. 집안에서 생산성을 높이는 데 활용하거나, 새로운 취미를 찾고, 예술을 향상시키거나, 요리할 새로운 아이디어를 고민해보세요. 어이 없는 일을 시키도록 해보세요. 다양한 아이디어와 컨셉을 실험해보세요. AI처럼 복잡한 것을 이해하는 가장 좋은 방법은 시행착오를 통해 시작하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 ChatGPT를 제 개인 상담대로 사용하여 대부분의 아이디어와 프로세스를 떠올리고 발전시키는 습관을 들였어요. 이미 시작하지 않은 경우, 이는 AI 흐름에 쉽게 진입하는 방법입니다. 그리고 가능한 빨리 GPT Pro를 구입해야 합니다. 최첨단 모델과 상호 작용하는 것은 가치가 있어요.\n\n매일 AI를 사용하는 데 어려움을 겪고 있다면, 창의적인 아이디어를 떠올릴 수 있는 ChatGPT의 과소평가된 사용 사례에 대해 쓴 기사가 있어요.\n\n## AI 발전 상황을 따라가기\n\nAI의 최신 동향을 계속해서 따라갈 수 있는 신뢰할 수 있는 출처를 찾아보세요. 뉴스 매체, 온라인 포럼 또는 뉴스 집계기가 될 수 있어요. 현재 최첨단 기술의 상태를 이해하면(즉, 현재 현대 AI 시스템의 정의를 결정하고 있는 특성과 제한을 이해하게 됩니다), AI 발전에 대한 깊은 이해를 위한 기준으로 활용할 수 있게 될 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 대형 언어 모델 AI에 익숙하지 않은 사람은 Anthropic의 최신 모델 세트인 Claude 3에 대해 들어본 적이 없을 수도 있어요. 그런데 이 모델은 GPT-4를 꺾고 1년 만에 최고를 차지한 첫 번째 모델이에요. 더군다나 작은 \"하이쿠\" 모델도 가장 \"성능 대비 가격이 좋은\" LLM으로 엄청난 발전을 이루었어요. AI는 너무 빨리 발전하기 때문에 이러한 매우 중요한 발전들이 종종 주목받지 못할 수 있으니, 미래를 이해하기 위해서는 현재 상황을 알고 있어야 해요.\n\n다음은 저가 자주 방문하는 몇 가지 좋은 소스입니다:\n\n- MIT Technology Review\n- David Shapiro (Youtube)\n- Google News (지능적인 필터링 및 검색 기능 포함)\n- Reddit (토론 및 새로운 소식을 얻기 좋은 곳)\n\n## AI의 특수 응용 프로그램에 대해 알아보세요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 단계는 당신의 연상 능력을 활성화하는 데 중요합니다. 회사들이 AI를 어떻게 독특한 용례에 활용하는지 연구하고 배우는 데 집중하면, 일부 패턴 인식과 연상 능력을 개발할 수 있습니다. 예를 들어, 공장을 운영한다고 가정해 봅시다. 어떤 회사들이 AI를 활용하여 제조 문제를 해결하는 방법을 살펴본다면, 당신이 직면한 일부 문제를 어떻게 해결할 수 있을지에 대한 아이디어를 얻을 수 있습니다.\n\n이는 여러분이 자체 AI 모델을 구축하는 방법을 알아내야 한다는 것을 의미하는 것은 아닙니다. 오히려, AI의 진보에 대한 심층적인 탐구를 위해 무엇을 찾아야 하는지 알 수 있으며 여러분의 업무 효율성을 높일 수 있습니다.\n\n## AI 사용 방법을 배우세요\n\n저는 ChatGPT를 어떻게 사용하지 말아야 하는지에 대한 전체 기사를 썼습니다. 사람들이 그것을 오용하는 모든 방법을 종합하는 것은 깨달음을 줬으며, 몇 달 동안 그 이후로도 더 많은 오용 사례를 보았습니다. 그들을 모두 통합하는 한 가지는 무엇일까요? 그들은 그 한계를 모르고 AI가 \"아무것도 제대로 못한다\"고 좌절해 하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이건 사실이 아니에요. 그냥 그것이 만들어진 목적과는 다른 작업에서 실패할 뿐이에요. 당신이 정비공에게 미적분 증명을 요청하지 않듯이, 당신의 망치가 당신을 직장으로 데려다 주기를 기대하지 않을 것입니다.\n\nChatGPT는 언어 작업에 아주 뛰어나기 때문에 그 강점을 알 필요가 없다는 점이에요; 오히려 그것이 할 수 없는 것에 대해 알아보는 데 집중해야 해요. 실은 저는 ChatGPT를 사용하는 중요한 원칙 몇 가지만 알고 있다면 빠르게 전문가로 성장할 수 있다고 확신합니다.\n\n## AI 모델 식별 방법 배우기\n\n여러 가지 유형의 AI가 있어요. 회사가 \"AI를 사용중이다\"라고 언급할 때, 그것이 어디에서, 어떻게, 왜 사용되는지를 구별하기가 점점 어려워지고 있어요. 다양한 종류의 AI 모델을 이해하면 그들의 사용 사례를 빠르게 식별하고 그것이 마케팅 발언인지 아니면 기술의 실제로 흥미로운 적용인지 알아낼 수 있어요. 이 지식은 또한 자신의 일이나 개인 생활에 AI를 어떻게 적용할 수 있는지를 알아내는 데 도움이 돼요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 예측 AI — 예측 AI는 대규모의 과거 데이터를 학습하여 대량의 복잡한 데이터셋에서 추세, 패턴 및 이상점을 찾습니다. 이들은 상품 가격, 시장 변동성 및 물류 분석과 같은 동적 요소의 움직임을 예측하는 데 유용합니다.\n- 분석 AI — 이들은 예측 모델과 유사하지만 입력을 분류하고 새로운 유용한 데이터로 조작하는 데 초점을 맞춥니다. 예를 들어, 분석 모델은 오디오를 분석하여 텍스트로 변환할 수 있습니다. 또 다른 사용 사례는 컴퓨터 비전으로, 입력 이미지나 비디오를 가져와 영상 내의 특정 요소를 분류할 수 있습니다. 예를 들어, 인간 얼굴을 인식하고 기록하는 보안 카메라 시스템과 같은 사례가 있습니다.\n- 생성 AI — 여기서 여러분이 들어본 큰 주제입니다. ChatGPT, Gemini, Claude, Midjourney, Runway, Sora 등 많은 예시들이 있는 생성 AI는 주로 간단한 사용자 입력에서 새로운 콘텐츠를 생성하는 데 초점을 맞춥니다. 이들은 작년에 인공지능에 대한 관심 폭증의 가장 큰 책임자이며, 그 이유는 비밀이 없습니다. 그들은 정말 멋지고 즉각적으로 유용합니다.\n\n이 주제에 대해 더 알고 싶다면, 인공지능/머신러닝이 높은 수준에서 무엇인지 이해하는 데 더 깊은 시작점을 제공하는 이 기사를 강력히 추천합니다.\n\n앞으로 몇 년 동안은 예측이나 분석 AI보다는 일상 생활에서 생성 AI와 상호 작용할 가능성이 더 높기 때문에, 이 기사의 주요 초점은 ChatGPT와 같은 생성 모델에 맞춰져 있습니다.\n\n## AI 작동 방식 이해하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장 마지막 단계로 이것을 배치했는데, 아마도 여기서 가장 밀집되고 열정적인 학습 곡선일 것입니다. 그러나 여전히 AI를 효과적으로 활용하는 데 필수적이라고 생각합니다. 특히 ChatGPT를 이해하는 데 좋은 두 가지 자료가 있습니다:\n\n- ChatGPT가 무엇을 하고 있으며 어떻게 작동하는가? 이 우수한 스티븐 월프람의 기사는 ChatGPT의 내부 작업에 대해 깊이 파고들어 설명합니다. 주의: 이 기사는 1시간 이상 소요되며 가벼운 소비자에게는 부적합할 수 있습니다. 그러나 ChatGPT를 이해하는 데 가장 좋은 입문 자료라고 생각합니다.\n- LLM Visualizer — 이 웹사이트는 LLM의 과정을 임베딩에서 출력까지 모든 단계마다 따라갈 수 있는 정말 멋진 기능이 있습니다. 이는 상당히 기술적이지만 매우 눈부신 경험입니다. 이 기능을 사용하기 전에 먼저 스티펜 월프람의 기사를 읽어보세요!\n\n이러한 모델들은 정보를 연결하여 입력과 일치하는 \"새로운\" 정보를 생성하려고 합니다. 사용자로서 여러분을 만족시키기 위해 가능한 최대한 신뢰할 만하고 관련성 있는 출력을 생성하려고 노력합니다. AI가 실제로 \"자신만의 마음\"을 가지지 않는다는 사실(적어도 현재로서)과 실제로 예측 가능하고 일관성있게 작동한다는 것을 깨달을 때 많은 이점을 얻게 될 것입니다:\n\n- 어떤 요청이 동작하고 어떤 것이 동작하지 않는지 직관적으로 파악할 수 있습니다. AI의 한계를 알고 있는 것이 강점을 알고 있는 것보다 훨씬 중요합니다.\n- 빠르고 쉽게 그것을 다룰 수 있습니다. AI와 함께 작업하기 어려울 수 있지만, 상자 속에 있는 도구들을 이해하면 원하는 결과물을 보다 빠르고 반복 횟수를 줄이며 달성할 수 있습니다.\n- 다른 사람들이 AI를 더 효과적으로 활용하는 방법을 가르칠 수 있습니다. 말해두지 않아도, AI의 기초를 더 많이 알 것이므로 그 정보를 다른 사람들과 공유하기가 더 쉬워집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 지식에 확신이 없거나 따라잡기 힘들다고 느끼시는 분들께 이 자료가 유용하길 바랍니다. AI는 방대하고 복잡한 주제지만, 작은 조각으로 쪼개면 어려울 게 없어요.\n\n읽어 주셔서 감사합니다! 즐거운 코딩하세요!\n\n- Jordan","ogImage":{"url":"/assets/img/2024-06-20-HowtoJumpstartYourAILiteracy_0.png"},"coverImage":"/assets/img/2024-06-20-HowtoJumpstartYourAILiteracy_0.png","tag":["Tech"],"readingTime":6},{"title":"AI Agents in a GPT","description":"","date":"2024-06-20 18:38","slug":"2024-06-20-AIAgentsinaGPT","content":"\n\n## GPT에 AI 에이전트를 내장하는 방법\n\n이것은 GPT-5에 에이전트가 곧 출시될 수도 있다는 힌트일까요?\n\n![이미지](/assets/img/2024-06-20-AIAgentsinaGPT_0.png)\n\n오늘은 여러분에게 멋진 것을 보여드릴 거예요 — 직접 AI 에이전트를 만들고 GPT에서 사용하는 방법을 알려 드릴 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예시는 간단하지만, AI 에이전트의 힘을 보여줍니다.\n\n아마도 AI 에이전트에 대해 들어본 적이 있을 것입니다. 그리고 그들이 미래라는 것도 들었을 겁니다.\n\n아마도 이미 GitHub에서 찾을 수 있는 몇 가지 기존 AI 에이전트 프레임워크를 시도해 보았을지도 모릅니다. 그러나 이들 중 많은 것들은 설정하기가 꽤 복잡하고 높은 코딩 지식이 필요합니다 — 이들은 일반인을 위한 것은 아니며, 많은 프로젝트에는 필요하지 않습니다.\n\n이 튜토리얼은 AI 에이전트를 간단한 용어로 설명하고, 코드 없이 시작하는 법을 알려줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 안내서는 AI 에이전트 사용에 대한 소개입니다.\n\n코더이고 다른 AI 에이전트를 시도해본 적이 있다면 - 이것이 비교 가능하다고 말하고 싶지는 않습니다.\n\n하지만 GPT에서 AI 에이전트를 사용해 보려는 것은 GPT의 매우 흥미로운 사용 사례를 만들어줄 수 있습니다.\n\n여기 제가 만든 비디오가 있어요. AI 에이전트를 GPT에서 직접 확인할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AI 에이전트와 ChatGPT의 차이점은 무엇인가요?\n\nAI 에이전트는 특정 작업을 자체적으로 수행할 수 있습니다. 당신이 필요한 것을 이해하고, 결정을 내릴 수 있으며, 당신을 돕기 위해 행동할 수 있습니다.\n\nAI 에이전트는 또한 각각이 특정 역할을 가지고 팀으로 작동할 수 있으며, 심지어 인간의 개입 없이 공통의 목표를 달성하기 위해 협력할 수 있습니다.\n\nChatGPT는 대화를 나누는 것과 비슷합니다. 당신이 계속해서 질문하면, LLM을 사용하여 답변하고 질문에 답변하는 데 도움을 줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n질문하거나 무언가를 시키면 그에 따라 답변합니다. 질문하거나 요청하면 텍스트를 생성하는 데 탁월한데요, AI 에이전트처럼 자동으로 작업을 수행하지는 않습니다.\n\nAI 에이전트는 여러 단계의 작업을 자체적으로 수행하는 반면, ChatGPT는 대화를 시작하고 무엇을 해야 할지 말해줘야 합니다. 모든 단계에 참여해야 합니다.\n\n간단한 예시로 차이를 살펴보는 것이 매우 도움이 됩니다.\n\n저의 👉 AI 뉴스레터 👈에 관심이 있을 수도 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# ChatGPT를 사용하여 여러 단계에서 기사 작성하기\n\n예를 들어, 작가라면, ChatGPT를 사용하여 기사를 여러 단계로 만들 수 있습니다. 다음은 ChatGPT에서 기사를 만드는 단계별 작업 및 상호 작용 방법입니다:\n\n- 기사 제목 생성: ChatGPT에게 현재 AI 연구를 기반으로 하는 다섯 가지 기사 제목을 요청하십시오.\n- 개요 작성: 그 다음, 기사 개요를 요청합니다.\n- 기사 초안 작성: 그런 다음, 기사 초안을 작성하도록 합니다.\n- 기사 편집: 마지막으로, 편집자에게 기사를 개선하고 제안을 받도록 요청합니다.\n- 최종 초고: 편집자의 제안을 기반으로 새로운 기사를 작성하도록 ChatGPT에게 요청합니다.\n\nChatGPT는 이러한 작업을 수행할 수 있지만, 각 단계를 수동으로 요청해야 합니다. 이 프로세스는 오랜 시간이 걸리고 지루할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 예시에서는 ChatGPT에게 5개의 별도 질문을 하고 매번 대답을 기다려야 합니다.\n\n# AI 에이전트를 사용하여 동일한 기사 생성\n\n저는 AI 에이전트를 활용한 간단한 GPT를 만들었습니다. 이를 사용하여 위의 예시와 동일한 방식으로 동일한 기사를 생성합니다.\n\n하지만 에이전트끼리 대화하면서 전체 기사와 아웃라인, 초안, 편집 등을 하나의 프롬프트만으로 처리할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nGPT를 사용한 AI 에이전트를 만들었어요. 이 GPT는 다음을 할 거예요:\n\n- 다섯 개의 기사 주제에 대한 연구\n- 기사 개요 작성\n- 기사 초고 작성\n- 기사 편집, 개선 제안 및 완성까지 정제\n\n# 에이전트 역할\n\n이 에이전트 프레임워크를 포함한 모든 AI 에이전트의 첫 번째 단계는 각 에이전트의 역할을 정의하고 원하는 능력을 결정하는 것이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# GPT 지침서의 에이전트 역할 정의\n\n- 연구자 에이전트: 다섯 개의 기사 주제를 생성합니다.\n- 개요 작성자 에이전트: 주제를 선택하고 개요를 작성합니다.\n- 작가 에이전트: 개요를 기반으로 기사를 초안 작성합니다.\n- 편집자 에이전트: 초안을 검토하고 개선 제안을 하여 작가에게 개정을 요청합니다.\n\nGPT에서 에이전트 역할 외에, 다음을 말했습니다:\n\nGPT에서 에이전트를 시작하려면 \"주제\"에 대한 단 한 가지 프롬프트만 필요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼 요원들이 소통하여 제가 더 이상 개입하지 않고 기사를 완성할 거예요.\n\nAI 에이전트 GPT가 작동하는 것을 보고 싶다면, 이 기사 맨 위의 동영상을 확인해보세요.\n\n# AI 에이전트의 장점\n\nAI 에이전트는 작업을 독립적이고 효율적으로 처리하여 시간을 절약해줍니다. 특히 기사 작성 및 소프트웨어 개발과 같은 여러 단계를 포함하는 작업에 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n에이전트마다 특정 역할을 정의하여 원활하게 함께 작업할 수 있습니다.\n\n더 발전된 에이전트 역할을 만들 수도 있고, API에 액세스하거나 다른 LLM 모델에 접근하거나 코드를 설치하고 실행할 수 있게 할 수도 있습니다.\n\nGPT 안의 AI 에이전트는 GPT 환경 내에서 실행되기 때문에 제한됩니다. 이는 로컬호스트나 서버와 같지 않습니다.\n\n하지만 흥미로운 사용 사례를 만들기 위해 해킹되어 일부 사용 사례를 만들어낼 수는 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 ChatGPT, 인공지능, GPT 등을 활용하여 온라인 비즈니스를 키우는 방법에 대해 가르치고 있어요.\n\n제 👉 AI Growth Guys Newsletter 👈를 확인해보세요.\n\n아래의 다른 채널들도 확인해보세요.\n\n저희 YouTube 채널도 놀러오세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 웹 사이트에서 팔로우해 주세요: AI Growth Guys","ogImage":{"url":"/assets/img/2024-06-20-AIAgentsinaGPT_0.png"},"coverImage":"/assets/img/2024-06-20-AIAgentsinaGPT_0.png","tag":["Tech"],"readingTime":4},{"title":"지식 그래프로 RAG 어플리케이션의 정확성 향상하기","description":"","date":"2024-06-20 18:36","slug":"2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs","content":"\n\n## 네오포스트 및 LangChain을 사용하여 RAG 애플리케이션에서 지식 그래프를 구축하고 정보를 검색하는 실용적 가이드\n\n![Enhancing the Accuracy of RAG Applications With Knowledge Graphs](/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_0.png)\n\n그래프 검색 보강 생성 (GraphRAG)은 전통적인 벡터 검색 검색 방법에 강력한 보충으로 인기를 얻고 있습니다. 이 접근 방식은 그래프 데이터베이스의 구조화된 성격을 활용하여 데이터를 노드와 관계로 구성함으로써 회수된 정보의 깊이와 맥락을 향상시킵니다.\n\n![Enhancing the Accuracy of RAG Applications With Knowledge Graphs](/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래프는 다양하고 서로 연결된 정보를 체계적으로 표현하고 저장하는 데 탁월합니다. 복잡한 관계와 속성을 다양한 데이터 유형에 걸쳐 손쉽게 캡처할 수 있습니다. 반면에 벡터 데이터베이스는 고차원 벡터를 통해 비구조화된 데이터를 처리하는 데 강점을 가지고 있어서 구조화된 정보에 어려움을 겪을 수 있습니다. RAG 애플리케이션에서는 구조화된 그래프 데이터와 비구조화된 텍스트를 통한 벡터 검색을 결합하여 양쪽의 장점을 모두 활용할 수 있습니다. 이것이 이 블로그 포스트에서 증명할 내용입니다.\n\n## 지식 그래프가 훌륭하지만, 그것을 어떻게 만들까요?\n\n지식 그래프를 구축하는 것은 보통 가장 어려운 단계입니다. 이 작업에는 데이터 수집과 구조화가 필요하며, 해당 도메인과 그래프 모델링에 대한 심층적인 이해가 필요합니다.\n\n이 프로세스를 간소화하기 위해 우리는 LLM(Large Language Models)을 실험해오고 있습니다. 언어와 맥락에 대한 깊은 이해력을 갖춘 LLM은 지식 그래프 생성 프로세스의 중요한 부분을 자동화할 수 있습니다. 이 모델들은 텍스트 데이터를 분석하여 엔티티를 식별하고, 그들의 관계를 이해하며, 어떻게 그들을 최상의 그래프 구조로 표현할 지 제안할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 실험의 결과로 LangChain에 그래프 구성 모듈의 첫 번째 버전을 추가했습니다. 이 블로그 게시물에서 이를 시연할 예정입니다.\n\n해당 코드는 GitHub에서 확인할 수 있습니다.\n\n## Neo4j 환경 설정\n\nNeo4j 인스턴스를 설정해야 합니다. 이 블로그 게시물의 예제를 따라 진행하십시오. 가장 쉬운 방법은 Neo4j Aura에서 무료 인스턴스를 시작하는 것입니다. 이는 Neo4j 데이터베이스의 클라우드 인스턴스를 제공합니다. 다른 방법으로는 Neo4j 데스크톱 애플리케이션을 다운로드하고 로컬 데이터베이스 인스턴스를 생성하여 로컬 Neo4j 데이터베이스를 설정할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nos.environ[\"OPENAI_API_KEY\"] = \"sk-\"\nos.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\nos.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\nos.environ[\"NEO4J_PASSWORD\"] = \"password\"\n\ngraph = Neo4jGraph()\n```\n\n또한, 이 블로그 게시물에서 OpenAI 모델을 사용할 예정이므로 OpenAI 키를 제공해야 합니다.\n\n# 데이터 수집\n\n이 데모에서는 엘리자베스 1세의 위키백과 페이지를 사용할 것입니다. LangChain 로더를 사용하여 위키백과 문서를 손쉽게 가져와 분할할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\n# 위키백과 항목 읽기\r\nraw_documents = WikipediaLoader(query=\"Elizabeth I\").load()\r\n# 청킹 전략 정의\r\ntext_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\r\ndocuments = text_splitter.split_documents(raw_documents[:3)\r\n```\r\n\r\n이제 검색된 문서를 기반으로 그래프를 구성할 시간입니다. 이를 위해 그래프 데이터베이스에 지식 그래프를 구축하고 저장하는 데 큰 도움이 되는 LLMGraphTransformermodule을 구현했습니다.\r\n\r\n```js\r\nllm=ChatOpenAI(temperature=0, model_name=\"gpt-4-0125-preview\")\r\nllm_transformer = LLMGraphTransformer(llm=llm)\r\n\r\n# 그래프 데이터 추출\r\ngraph_documents = llm_transformer.convert_to_graph_documents(documents)\r\n# Neo4j에 저장\r\ngraph.add_graph_documents(\r\n  graph_documents, \r\n  baseEntityLabel=True, \r\n  include_source=True\r\n)\r\n```\r\n\r\n지식 그래프 생성 체인이 사용할 LLM을 정의할 수 있습니다. 현재 OpenAI 및 Mistral에서 함수 호출 모델만 지원하고 있지만, 향후 LLM 선택을 확장할 계획입니다. 이 예시에서는 최신 GPT-4을 사용합니다. 생성된 그래프의 품질은 사용하는 모델에 크게 의존하는 것을 주의해야 합니다. 이론적으로는 항상 능력 있는 모델을 사용하는 것이 좋습니다. LLM 그래프 트랜스포머는 그래프 문서를 반환하며, 이를 add_graph_documents 메서드를 통해 Neo4j로 가져올 수 있습니다. baseEntityLabel 매개변수는 각 노드에 추가적인 __Entity__ 라벨을 할당하여 색인화 및 쿼리 성능을 향상시킵니다. include_source 매개변수는 노드를 원본 문서에 연결하여 데이터 추적 및 문맥 이해를 용이하게 합니다.\r\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네오4j 브라우저에서 생성된 그래프를 확인할 수 있습니다.\n\n![그래프](/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_2.png)\n\n이 이미지는 생성된 그래프의 일부분을 나타냅니다.\n\n# RAG를 위한 혼합 검색\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래프 생성 후, 우리는 RAG 애플리케이션을 위한 벡터 및 키워드 색인과 그래프 검색을 결합한 하이브리드 검색 접근 방식을 사용할 것입니다.\n\n![이미지](/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_3.png)\n\n이 다이어그램은 사용자가 질문을 제기하면 RAG 검색기로 이어지는 검색 프로세스를 보여줍니다. 이 검색기는 키워드 및 벡터 검색을 사용하여 구조화되지 않은 텍스트 데이터를 검색하고 이를 지식 그래프에서 수집한 정보와 결합합니다. Neo4j는 키워드 및 벡터 색인이 모두 있는 기능을 제공하기 때문에 단일 데이터베이스 시스템으로 세 가지 검색 옵션을 구현할 수 있습니다. 이러한 소스에서 수집된 데이터는 LLM(언어 모델)에 공급되어 최종 답변을 생성하고 전달합니다.\n\n## 구조화되지 않은 데이터 검색기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"Neo4jVector.from_existing_graph\" 메서드를 사용하여 문서에 키워드 및 벡터 검색을 추가할 수 있어요. 이 방법은 \"Document\"로 레이블이 지정된 노드를 대상으로 하는 하이브리드 검색 접근 방식을 위해 키워드 및 벡터 검색 인덱스를 구성합니다. 또한, 누락된 경우 텍스트 임베딩 값을 계산합니다.\n\n```js\nvector_index = Neo4jVector.from_existing_graph(\n    OpenAIEmbeddings(),\n    search_type=\"hybrid\",\n    node_label=\"Document\",\n    text_node_properties=[\"text\"],\n    embedding_node_property=\"embedding\"\n)\n```\n\n그런 다음에 유사성 검색 방법을 사용하여 벡터 인덱스를 호출할 수 있어요.\n\n## Graph Retriever\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한편, 그래프 검색을 구성하는 것은 좀 더 복잡하지만 더 많은 자유를 제공합니다. 이 예제에서는 전체 텍스트 색인을 사용하여 관련 노드를 식별하고 해당 직접 이웃들을 반환할 것입니다.\n\n![image](/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_4.png)\n\n그래프 검색기는 입력에서 관련 엔티티를 식별하여 시작합니다. 단순화를 위해, 우리는 LLM에 개인, 조직 및 위치를 식별하도록 지시합니다. 이를 달성하기 위해 새롭게 추가된 with_structured_output 방법을 사용한 LCEL을 사용할 것입니다.\n\n```js\n# 텍스트에서 엔터티 추출\nclass Entities(BaseModel):\n    \"\"\"엔터티에 대한 정보 식별.\"\"\"\n\n    names: List[str] = Field(\n        ...,\n        description=\"텍스트에 나타나는 모든 사람, 조직 또는 비즈니스 엔터티들\",\n    )\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\n            \"시스템\",\n            \"텍스트에서 조직 및 개인 엔터티를 추출 중입니다.\",\n        ),\n        (\n            \"사용자\",\n            \"다음 입력에서 정보를 추출하기 위해 주어진 형식을 사용하세요: {질문}\",\n        ),\n    ]\n)\n\nentity_chain = prompt | llm.with_structured_output(Entities)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테스트해 봅시다:\n\n```js\nentity_chain.invoke({\"question\": \"Amelia Earhart가 어디에서 태어났나요?\"}).names\n# ['Amelia Earhart']\n```\n\n좋아요, 이제 질문에서 엔티티를 감지할 수 있게 되었으니, 전체 텍스트 인덱스를 사용하여 그들을 지식 그래프에 매핑해 봅시다. 먼저, 전체 텍스트 인덱스를 정의하고 약간의 철자 오류를 허용하는 전체 텍스트 쿼리를 생성하는 함수를 만들어야 합니다. 이 과정에 대해서는 자세히 다루지 않겠습니다.\n\n```js\ngraph.query(\n    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n\ndef generate_full_text_query(input: str) -\u003e str:\n    \"\"\"\n    주어진 입력 문자열에 대한 전체 텍스트 검색 쿼리를 생성합니다.\n\n    이 함수는 전체 텍스트 검색에 적합한 쿼리 문자열을 생성합니다.\n    입력 문자열을 단어로 분할하고 각 단어에 유사성 임계값(~2개의 변경된 문자)을 추가한 후, AND 연산자를 사용하여 결합합니다.\n    사용자 질문에서 엔티티를 데이터베이스 값에 매핑하는 데 유용하며, 일부 철자 오류를 허용합니다.\n    \"\"\"\n    full_text_query = \"\"\n    words = [el for el in remove_lucene_chars(input).split() if el]\n    for word in words[:-1]:\n        full_text_query += f\" {word}~2 AND\"\n    full_text_query += f\" {words[-1]}~2\"\n    return full_text_query.strip()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 모든 것을 함께 적용해 봅시다.\n\n```js\n# Fulltext index query\ndef structured_retriever(question: str) -\u003e str:\n    \"\"\"\n    질문에 언급된 엔터티의 인근 엔터티를 수집합니다.\n    \"\"\"\n    result = \"\"\n    entities = entity_chain.invoke({\"question\": question})\n    for entity in entities.names:\n        response = graph.query(\n            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n            YIELD node,score\n            CALL {\n              MATCH (node)-[r:!MENTIONS]-\u003e(neighbor)\n              RETURN node.id + ' - ' + type(r) + ' -\u003e ' + neighbor.id AS output\n              UNION\n              MATCH (node)\u003c-[r:!MENTIONS]-(neighbor)\n              RETURN neighbor.id + ' - ' + type(r) + ' -\u003e ' +  node.id AS output\n            }\n            RETURN output LIMIT 50\n            \"\"\",\n            {\"query\": generate_full_text_query(entity)},\n        )\n        result += \"\\n\".join([el['output'] for el in response])\n    return result\n```\n\nstructured_retriever 함수는 사용자 질문에서 엔터티를 감지하여 시작합니다. 그런 다음 감지된 엔터티를 반복하고 해당 노드의 인근을 검색하기 위해 Cypher 템플릿을 사용합니다. 이제 테스트해 봅시다!\n\n```js\nprint(structured_retriever(\"Who is Elizabeth I?\"))\n# Elizabeth I - BORN_ON -\u003e 7 September 1533\n# Elizabeth I - DIED_ON -\u003e 24 March 1603\n# Elizabeth I - TITLE_HELD_FROM -\u003e Queen Of England And Ireland\n# Elizabeth I - TITLE_HELD_UNTIL -\u003e 17 November 1558\n# Elizabeth I - MEMBER_OF -\u003e House Of Tudor\n# Elizabeth I - CHILD_OF -\u003e Henry Viii\n# 그리고 더 많은 정보가 출력됩니다...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 최종 검색기\n\n처음에 언급했던대로, 우리는 비구조화 및 그래프 검색기를 결합하여 LLM에 전달할 최종 컨텍스트를 생성할 것입니다.\n\n```js\ndef retriever(question: str):\n    print(f\"검색 쿼리: {question}\")\n    structured_data = structured_retriever(question)\n    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n    final_data = f\"\"\"구조화된 데이터:\n{structured_data}\n비구조화된 데이터:\n{\"#문서 \". join(unstructured_data)}\n    \"\"\"\n    return final_data\n```\n\n우리는 Python을 다루고 있으므로, 간단하게 f-string을 사용하여 출력을 연결할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# RAG Chain 정의\n\nRAG의 검색 구성 요소를 성공적으로 구현했습니다. 이제, 통합된 하이브리드 검색기가 제공하는 컨텍스트를 활용하여 응답을 생성하는 프롬프트를 소개하여 RAG 체인의 구현을 완료합니다.\n\n```js\ntemplate = \"\"\"다음 컨텍스트만을 기반으로 질문에 답해보세요:\n{context}\n\n질문: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\nchain = (\n    RunnableParallel(\n        {\n            \"context\": _search_query | retriever,\n            \"question\": RunnablePassthrough(),\n        }\n    )\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n마지막으로, 하이브리드 RAG 구현을 테스트해볼 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nchain.invoke({\"question\": \"엘리자베스 1세가 속한 집은 무엇인가요?\"})\n# 검색 쿼리: 엘리자베스 1세는 어떤 집에 속했나요?\n# '엘리자베스 1세는 Tudor 왕조에 속했습니다.'\n\n```\n\n또한 질의 재작성 기능을 적용하여 RAG 체인이 대화 형태에 적응하도록 했습니다. 후속 질문을 효율적으로 검색하기 위해 벡터 및 키워드 검색 방법을 사용하기 때문에 후속 질문을 재작성하여 검색 프로세스를 최적화해야 합니다.\n\n```js\nchain.invoke(\n    {\n        \"question\": \"언제 태어났나요?\",\n        \"chat_history\": [(\"엘리자베스 1세가 어떤 집에 속했나요?\", \"Tudor 왕조\")],\n    }\n)\n# 검색 쿼리: 엘리자베스 1세는 언제 태어났나요?\n# '엘리자베스 1세는 1533년 9월 7일에 태어났습니다.'\n\n```\n\n질문이 언제 태어났나요?가 처음에 언제 엘리자베스 1세가 태어났나요?로 재작성된 것을 관찰할 수 있습니다. 재작성된 쿼리가 관련 context를 검색하여 질문에 대답하는 데 사용되었습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# RAG 애플리케이션을 쉽게 개선하기\n\nLLMGraphTransformer의 도입으로 지식 그래프를 생성하는 과정이 더 매끄럽고 접근하기 쉬워졌습니다. 지식 그래프가 제공하는 심층성과 맥락으로 여러분의 RAG 애플리케이션을 향상시키려는 누구에게나 이제 보다 쉬워졌습니다. 이것은 시작에 불과하며 앞으로 많은 개선 사항이 계획되어 있습니다.\n\nLLMs로 그래프를 생성하는 데 대한 통찰, 제안 또는 질문이 있으시다면 망설이지 말고 연락해 주세요.\n\n코드는 GitHub에서 확인할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_0.png"},"coverImage":"/assets/img/2024-06-20-EnhancingtheAccuracyofRAGApplicationsWithKnowledgeGraphs_0.png","tag":["Tech"],"readingTime":10},{"title":"컴퓨터 프로그래머이자 15년간 ChatGPT에 대해 전문적으로 썼어요 - 전문 작가들이 괜찮다는 법을 이야기해 드릴게요","description":"","date":"2024-06-20 18:32","slug":"2024-06-20-ImaComputerProgrammerandWroteProfessionallyaboutChatGPTfor15YearsHeresHowProWritersCanBeOkay","content":"\n\n![alt text](/assets/img/2024-06-20-ImaComputerProgrammerandWroteProfessionallyaboutChatGPTfor15YearsHeresHowProWritersCanBeOkay_0.png)\n\n2023년 1월에 ChatGPT가 공개 된 지 세 달 후에는 이미 기업들이 작가들을 불필요하다고 생각하고 있음을 알 수 있었습니다. 몇몇 클라이언트들이 사라졌는데, 그 중 아무도 ChatGPT를 사용 중이라고 말해 주지 않았습니다.\n\n또한 내가 작가로 일을 찾는 데 꾸준히 신뢰할 수 있는 방법 중 하나인 나의 차가운 아웃리치에 대한 직접적이고 모욕적인 댓글들도 있었어요. \"오, ChatGPT가 이제 그런 걸 할 수 있어.\"\n\n그 후로, 나는 내가 판매하는 프리랜싱 플랫폼에서 ChatGPT의 훌륭함에 대해 글을 쓰도록 제안을 받았습니다. 이 회사는 세계적으로 프리랜서 일을 타격할 것으로 예상되었던 \"AI-파멸\"에 대응하여 콘텐츠 전략을 강화하기로 결정했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그들의 전략 중 일부는 ChatGPT 및 다양한 GenAI 도구에 대해 수많은 기사를 쓰는 것이 포함되어 있었고, 이로 인해 이러한 주제에 대한 SEO 트래픽을 이용하여 방문자들을 자신들의 프리랜서 서비스로 유도했습니다.\n\n기술 작성에 특화된 제가 17년 동안 코더였기 때문에 전문가로서 특히 고급 기술 내용에 대한 주요 AI 작성자가 되었습니다.\n\n# 작가로서, 뭔가를 알고 있는 척하지 마세요\n\n2019년, 저는 프리랜서 작가로서 성공을 꿈꾸는 절박한 소설 작가였습니다. 저는 성공을 이루기 위해 무엇을 해야 하는지 배울 수 있도록 Writing Cooperative라는 출판물을 꾸준히 참고했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수익이 많은 작가들로부터 가장 흔히 본 조언 중 하나는 전문화하는 것이었습니다. 저는 $0.25/단어 이상을 받는 프로 작가들의 기사에서 반복해서 읽었습니다. 그 당시에는 사랑하는 일을 하면서 $0.25/단어를 받는다는 것이 꿈 같았습니다. 하지만 오늘날에는 당연한 수준입니다.\n\n나는 '테크 작가'가 되기를 의도한 적이 없었습니다. 어쩌다 보니 그 방향으로 빠져들었습니다. 사람들이 나의 글을 발견하면서 나의 기술적 배경도 알게 되었고, 나에게 기술 주제에 대해 글을 쓰라는 요청을 했습니다. 나는 그 주제들 중 많은 것에 익숙하지 않았지만, 나의 고객들은 기술 분야 사람들이 작문이 서툰 경향이 있다는 걸 알아주었기 때문에 나에게 투자해 주었습니다. 나는 그 간극을 메워주었고, 기술적인 개념을 비전문가들에게도 전달할 수 있는 기술적인 사람이었습니다.\n\n그러한 요청들은 나를 안드로이드 개발, 메타버스, 핀테크, 암호화폐(심오한 주제들이 실린 곳이었습니다), 다양한 SaaS 도구, 스타트업, 백엔드 기술, 여러 프로그래밍 언어(중에는 전에 들어본 적도 없는 것이 있었습니다) 등에 대해 글을 쓰게 이끌었습니다.\n\n또한 AI에 대해 글을 써보게 되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n고스트라이터로 일찍 배운 것은 뭔가를 알고 있다고 속이는 것은 좋지 않은 글을 쓰도록 이끈다는 것이었습니다. 전문가가 글을 쓰면 사람들은 글쓰기보다는 전문성을 더 감상합니다. 고스트라이터가 하는 주요 실수 중 하나는 그들의 화려한 문장이 정확도보다 중요하다고 생각하는 것입니다. 하지만 그렇지 않습니다.\n\n테크니컬 라이터로써, 정확성은 당신의 생명줄입니다.\n\n고객들이 종종 내가 하는 말 중 하나는, \"나는 글을 쓸 때 뭔가를 알고 있다고 속이지 않으므로 멍청한 질문을 많이 할 거야. 당신이 전문가입니다. 난 그저 작가일 뿐이죠\" 라는 것입니다.\n\n사람들은 그것을 존중합니다. 이 태도로 몇 년 동안 일을 유지해 왔습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AI의 내부를 배우기\n\n같은 태도는 나를 AI의 내부로 이끌었어요 — 현재 AI로 간주되는 것이 무엇인지에 대해 모두가 동의하지 않기 때문에.\n\n테크니컬 라이터로, 저는 무언가의 섬세하고 궁극적인 부분, 그것이 어떻게 작동하는지, 그리고 왜 그것이 작동하는지를 알고 싶어해요. 누군가가 GPT에 대해 쓰라고 부탁했을 때, 제가 스스로에게 묻는 첫 번째 질문은 \"GPT가 무엇을 의미하는지?\" 였어요.\n\n그것이 AI, 머신 러닝, 그리고 모델 아키텍처에 대해 배우는 멋진 토끼굴로 이끈거든요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nChatGPT이 \"작동\"하는 방식을 완전히 이해하게 되어서, 그것의 응답에 대한 신비를 풀어주고, 이 기계가 이유할 능력이 전혀 없다는 것이 밝혀졌어요. 그렇죠.\n\n여기에 전체 논문에 대해 자세히 다루진 않겠습니다(어차피 자격이 없어서요), 그리고 아래 정의들은 간결함을 위해 어느 정도 부정확할 수 있습니다.\n\nGPT란 다음을 의미합니다:\n\n- Generative: 것을 \"생성\"합니다.\n- Pretrained: 야생으로 방출되기 전에 데이터에서 패턴을 찾아 \"학습\"하는 \"훈련\" 과정을 거칩니다. 이 \"사전 훈련\" 이후, 수많은(수백만?) 답변 중에서 사람들이 \"올바른\" 답변인지 틀린 답변인지를 \"미세 조정\"합니다. 전체 교육 과정은 답변에 \"가중치\"를 더하여, 시스템이 통계 분석을 기반으로 더 정확하게 올바른 답변을 예측할 수 있도록 합니다. 다시 말해, 만약 사람이 90%의 정확도로 한 답변을 올바르다고 표시했다면, 시스템은 그것이 \"정답\"이라 \"배웠다\"는 것입니다. 만약 사전 훈련 데이터가 90%의 시간을 같은 부정확성을 가졌다면, AI 시스템은 그 답변을 \"정답\"으로 고려할 것입니다. 바보 같죠?\n- Transformer: 시스템이 데이터를 순차적으로 처리하는 대신 병렬로 처리할 수 있는 AI 아키텍처를 가리킵니다. (Transformer 아키텍처는 구글 엔지니어들에 의해 만들어진 시대의 획기였는데 지금 보고 있는 금 러시로 이끌었습니다.) 예를 들어, \"bat\"이라는 단어는 포유류나 막대기를 의미할 수 있습니다. \"The bat was hungry\"라는 맥락에서 \"bat\"이 \"포유류\"라는 것을 추론할 수 있습니다. Transformer 아키텍처는 데이터를 동시에(\"병렬로\") 처리하여, 순차적으로 처리할 때보다 훨씬 더 맥락을 추출할 수 있습니다. 이것이 Transformer 아키텍처가 (그리고 ChatGPT뿐만 아니라 다른 Transformer 아키텍처들도 있습니다) 일반적으로 맥락을 올바르게 이해하는 이유입니다. (IBM Technology 유튜브 채널이 지금까지 발견한 것 중에 Transformer와 다른 AI 개념에 대한 가장 좋은 설명을 제공합니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앞서 말한 것만으로도 몇 가지 경고 신호를 눈치채셨을지도 모르겠어요. ChatGPT에 대해 더 많은 기사를 쓰면서 저는 느끼기 시작한 몇 가지를 여기서 설명해 드릴게요:\n\n- 모든 것은 확률 공식에 따라 작동합니다. 무수히 많은 데이터에 기반하여 \"사전 훈련된\" 시스템은 통계 분석을 사용하여 문장에서 다음으로 가장 가능성이 높은 단어를 결정합니다. 많은 사람들이 ChatGPT가 마치 감각이 있는 것처럼 느껴졌을 정도로 '사운드'가 믿음직스럽다고 생각했을 거에요. 하지만 사실은 수학적 공식을 바탕으로 동작하고 있는 거예요. 여기서 경고 신호는 바로 이겁니다. 아무것도 진정한 창작물이 아니다. 전부 유도물이에요. (그리고, 말그대로, 대규모 언어 모델의 '채팅' 버전은 더 '수다스러운' 소리를 내도록 특별히 훈련되었습니다. 이 모든 것은 매우 교묘하고 매우 신선하다.)\n\n- 이러한 시스템의 본능적 편견이 생성된 콘텐츠에서 나타나기 시작하는 데 오래 걸리지 않았어요. 이미지 생성 도구는 대개 다른 아키텍처를 사용하지만, 확률 공식의 개념은 비슷하며, 편향적인 심지를 일관되게 생성했고, 때로는 인종 차별적이고 성 차별적인 이미지를 생성하기도 했어요. 다시 한 번 강조하지만: 아무것도 창작된 게 없어요. 전부 유도물이죠.\n\n- OpenAI - ChatGPT 뒤에 있는 회사 - 는 열린 것이 아니라는 것을 드러냈어요. Microsoft는 최초 출시 이후 100억 달러를 투자하여 OpenAI에 깊이 뛰어들었습니다. 20년간의 경쟁 끝에 구글을 마침내 이길 것을 갈망하는 Microsoft의 절박함이 분명합니다. ChatGPT 출시 이후 Microsoft는 구글의 검색 엔진 시장 점유율을 정복할 것이라고 확신했어요. 그렇지는 않았죠.\n\n저는 Microsoft/Google의 경쟁을 여러 해간 지켜봤어요. ChatGPT 이후 Microsoft CEO 사티아 나델라의 행동은 사회의 이익보다는 개인적 복수심과 우월함에 기반한 충동적인 행동이라고 생각해요.\n\n요점은요: 폐쇄적인 회사가 사람들을 직접 훈련하여 언어 모델을 만든 다음, 그 언어 모델이 통계적으로 가능성 높은 방식으로 답변을 건진다는 점입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n변환된 표를 Markdown 형식으로 바꿔주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 작가들이 이해해야 할 중요한 측면은 AI가 사고할 수없다는 것입니다. 이것을 이해해야 합니다. AI는 생각하지 않습니다. 데이터셋과 \"미세 조정\"에 기반한 통계적으로 가능성이 높은 답변을 반복합니다.\n\n우리가 ChatGPT에 공급한 방대한 양의 데이터는 대부분의 시간 정확해 보이게끔 만듭니다. 이 방대한 양의 데이터를 분석하는 것은 실제로 유용한 진전이며 그에는 활용 방법이 있습니다.\n\n# 잘못 정의된 단어가 혹평을 일으키기도 합니다\n\nAI와 ChatGPT를 이해하기 위해 하는 작업 중, AI를 높은 위치에 두고 있는, 그러나 부정확한 단어를 반복해서 만나게 되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n“신경망”과 “뉴런”: 이 단어들은 조심스럽게 다뤄야 하는 가장 위험한 용어 중 하나입니다. 왜냐하면 인공지능을 인간 사고와 관련된 것으로 위치시킨다는 점에서 그렇습니다 — 하지만 그렇지 않습니다.\n\n옥스퍼드는 “신경망”을 “인간 뇌와 신경계를 모방한 컴퓨터 시스템”으로 잘못 정의하고 있습니다.\n\n이 정의는 놀라울 정도로 어렵습니다. 왜냐하면 뇌에 대해 전문가들조차 뇌가 어떻게 작동하는지에 대해 의견이 분분합니다. 빠른 구글 검색만으로도 인정받는 전문가들 간에 얼마나 많은 논란이 있는지 쉽게 확인할 수 있습니다. 신경과학자, 심리학자, 정신과의사들 사이에 상반되는 의견을 찾을 수 있습니다.\n\n만약 뇌를 연구하는 사람들이 인간 뇌가 어떻게 작동하는지 명확하고 확실하게 설명할 수 없다면, 대기업 기술 회사들은 어떻게 할 수 있을까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 번역해 드리겠습니다.\n\n그것은 불가능합니다.\n\n하지만 이해해야 했습니다. 그래서 더 심층적으로 파고들어가 보니, 다른 정의와 부딪혔습니다. 신경망은 \"뉴런(neurons)\"으로 구성되어 있다고 합니다. 놀랍게도 이 \"뉴런(neurons)\"은 \"뇌 속 뉴런을 모방한 것\"이었습니다.\n\n토끼굴에서 벗어나는 데 얼마나 오랜 시간이 걸렸는지 모르겠습니다. 하지만 마침내 벗어났습니다.\n\n저는 기술에 흥미를 갖는 사람입니다. 회로 기판을 분해하며 자랐습니다. 누군가 기계에 대해 이야기할 때, 제게는 그것을 어떻게 만들 것인지 알고 싶습니다. 이러한 정의들은 어떻게 신경망을 만들지에 대해 말해 주지 않았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n많은 연구 끝에 제가 개발한 정의는 다음과 같습니다:\n\n- 컴퓨터 과학에서의 뉴런은 여러 개의 가중치 입력을 처리하여 비선형 변환을 통해 하나의 출력을 생성하는 계산 단위입니다.\n\n- 비선형 변환이란 출력이 입력의 변화에 직접 비례하지 않고, 입력 매개변수가 변경될 때 출력의 복잡한 수정이 가능한 것을 의미합니다.\n\n- 신경망은 상호 연결된 인공 뉴런으로 구성된 계산 모델로, 각 뉴런은 여러 개의 가중치 입력을 처리하여 비선형 변환을 통해 하나의 출력을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그게 더 좋아 보이죠? 실행 가능하니까요. 한정된 내용이고요. 수수께끼가 없어요. \n\n그리고 사실적입니다.\n\nAI와 ML에 관한 글을 쓸 때 원래 위의 정의들을 사용했었지만 미래에 다른 사람들에 의해 수정될 수 있으니 위와 같이 붙여 놓았어요.\n\n신경망과 뉴런을 그들의 계산적 의미로 정의하면 그들을 이상한, 페라오의 의미에서 벗어나게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI는 가중 입력을 처리하고 단일 출력을 생성하는 도구인 'AI'를 올바른 위치에 배치합니다.\n\n\"가중 입력\"에 대해 말하자면, 가중치는 사전 훈련, 편향 등에서 나옵니다.\n\n# '환각'은 환각이 아닙니다. 버그입니다.\n\n'환각'이라는 용어가 잘못 정의되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nGenAI의 환각 성향은 잘 알려져 있습니다. 그 환각은 법정 문서에서 가짜 사례를 사용해 벌금을 부과받은 변호사들이 여러 명 생겼습니다.\n\n\"환각\"이란 단어는 AI가 실제로 가진 창의력을 강조하기 위한 것입니다.\n\n환각은 환각이 아닙니다. 그것들은 소프트웨어 버그입니다. 그리고 그것들은 고칠 수 없습니다. 그 이유는 다음과 같습니다:\n\n소프트웨어를 작성할 때, 개발자들은 일반적으로 \"제어 구조\"라고 하는 일련의 프로세스를 논리적으로 따릅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n만약 입력값이 \"1\"이면\n  ' 사용자가 \"1\"을 입력한 경우에만 이 코드가 실행됩니다.\n  Print(\"1을 입력했습니다\")\n그렇지 않으면\n  ' 사용자가 \"1\" 이외의 다른 값을 입력한 경우에 이 코드가 실행됩니다.\n  Print(\"1을 입력하지 않았습니다\")\n끝\n```\n\n위 예제에서 \"if...then...else\" 구조는 프로그램의 흐름을 제어하기 때문에 \"제어 구조\"라고 합니다. 누군가 \"1\"을 입력하면 첫 번째 코드 섹션이 실행됩니다. 다른 값을 입력하면 두 번째 섹션이 실행됩니다.\n\n휴대폰과 컴퓨터에 설치된 멋진 앱들의 기반이 되는 다른 제어 구조들도 있습니다.\n\n다층 신경망은 다르게 작동합니다. 제가 너무 단순하게 설명했다면 죄송합니다. 프로그래밍에 대한 논문을 쓰는 것이 목적이 아니라 고수준 개념을 설명하여 이해하는 데 도움을 주는 것이 목표입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n생성적 AI에서는 무수히 많은 입력이 동시에 처리되기 때문에 신경망 내부에서 무슨 일이 일어나고 있는지의 흐름을 포착하는 것이 불가능합니다. 이를 늦추면 AI의 기본 구조가 맥락을 포착하지 못하게 되어 정확한 답변을 제공하는 능력이 감소합니다.\n\n\"한꺼번에 일어나는 모든 것\"이라는 문제로, 아무도 AI의 내부를 해체해서 고쳐야 하는 부분을 파악할 수 없습니다.\n\n왜 고장났는지 아무도 모릅니다. 그리고 아무도 디버깅할 수 없습니다.\n\n널리 알려진 대로, 생성적 AI는 재정과 같이 높은 정확도를 요구하는 상황에서는 전혀 사용할 수 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 정말? 그가 진짜 마법이라고 말했다고요? 어머나요.\n\n# 정확도가 필요한 작업에서는 ChatGPT를 피하십시오 — 특히 수학 관련 작업\n\n비코더들을 당황하게 만드는 또 다른 주요 개념은 언어 모델과 수학입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대형 언어 모델은 수학 계산을 수행할 수 없어요. 물리적으로 불가능한 일인데, 그 이유는 컴퓨터의 특정 부분에 입력 값을 연산할 수 있는 곳으로 보내지 않기 때문이에요.\n\n컴퓨터에서 \"숫자\"와 \"텍스트\"는 핵심 개념이에요. 컴퓨터 프로세서에는 수학 계산을 처리하는 특정 섹션이 존재하는데, 그것이 산술 논리 장치(ALU)라고 불려요.\n\nOpenAI의 대표 Greg Brockman이 ChatGPT 4를 시연할 때, \"TaxGPT\"라는 귀여운 예제를 보여줬어요. 그는 누군가의 세금 계산을 하도록 요청하고, 이후 \"계산기에 연결되어 있지 않다\"며 \"머리 계산\"을 하고 있는 것이라고 언급했어요.\n\n실례지만 - 뭐라구요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앞서 언급한 대로, ChatGPT는 문장에서 다음 단어를 예측합니다. 이 단어들을 이해하지는 않습니다. ChatGPT는 1, \"1\" 또는 \"one\" 사이의 차이를 이해하지 못합니다. 만약 인터넷에 \"1 + 1 = 2\"와 같은 패턴을 따르는 충분한 텍스트가 있다면, ChatGPT는 \"1 + 1 =\"으로 시작하는 텍스트 라인 끝에 \"2\"를 출력할 가능성이 높습니다.\n\n아마도.\n\n확실하지는 않습니다.\n\n\"정신적인 계산\"은 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n계산기가 없어요.\n\n여러분, 세금 계산에는 챗지피티(ChatGPT)가 아니라 회계 도구를 사용해주세요. 세금 당국은 챗지피티 데모를 믿었다고 해도 관대해주지 않을 거에요.\n\n# 더 나은 프롬프트는 아무런 영향을 미치지 않았어요 — 결국 챗지피티 사용을 그만뒀어요\n\n챗지피티에 대해 기사를 쓰는 일을 받았던 때에는 대략적인 구상을 만들거나 질문에 답변하는 데 널리 사용했었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n초반에는 열정 가득했지만, 그 결과물을 거의 사용하지 않게 되었다. 사용했을 때도 많이 편집했다.\n\n내가 글을 쓸 때 프로그래밍 주제를 배우는 데 도움이 되었다. 그래도 그 결과물을 확인하고, 가끔 비현실적인 부분이 있어서, 직접 튜토리얼을 참고하느니 ChatGPT를 사용하는 것이 시간을 절약할 수 있는지 의문이 들었다.\n\n전문 작가로서 나의 작업에 부정확함이 들어갈 수 없었다. 그래서 ChatGPT가 생성한 모든 것을 구글링했다. 그것은 종종 틀렸다.\n\n전문가들의 조언을 따라 \"더 나은 프롬프트 만들기\"를 시도했다. JSON(JavaScript Object Notation)이라 불리는 \"프로그래밍 스타일\" 언어를 사용한 프롬프트를 작성하기도 했는데, ChatGPT가 이해하기 쉬울 것이라 생각했다. (JSON은 텍스트를 구조화된 방식으로 작성할 수 있게 해주어 프로그래밍 작업에 더 적합하다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n변동이 거의 없었네요.\n\n어떤 경우에도 ChatGPT는 저가 누구나 제한을 넘을 수 없었어요.\n\n결국, 덜 사용하기 시작했고, 몇 달 전에 프로 구독을 취소하고 나서부터 거의 사용하지 않았어요.\n\n한편으로 Claude.ai를 발견했는데, OpenAI보다 윤리적인 면에서 높게 평가되는 회사가 만들었어요. 그럼에도 결국에는 동일하게 실망스러웠고, 저도 그 도구를 거의 사용하지 않게 되었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# ChatGPT은 비작가들에게 유용하며, Canva와 CapCut은 비디자이너들에게 유용합니다.\n\n만약 ChatGPT의 글쓰기가 너무 형편없었다면 — 정말 그랬습니다 — 제게는 이 질문이 들떴어요, \"왜 글쓰기를 판매하기가 더 어려운 느낌일까?\" 2023년은 비즈니스 측면에서는 그리 나쁘지 않았습니다 — 대부분은 AI에 대해 쓰기로 그만큼 많은 돈을 받았기 때문이죠 (이것도 아이러니하죠) — 그러나 정말로 몇몇 클라이언트를 잃었고, 새로운 클라이언트를 확보하는 것이 어려워진 느낌이었습니다.\n\n내 자신을 클라이언트의 입장에 두고 몇 가지를 깨달았습니다. 스스로에게 물었죠, \"SEO 기사를 위해 글쓰기 작업에 $250을 지불할 의사가 있을까?\"\n\n그 대답은 명확했습니다. 아니에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그것은 깨워주는 순간이었어요. 내가 내 작업에 대해 지불하길 원하지 않았다면, 내 고객들은 왜 할 것이라고 생각할까?\n\n답은 간단했어요: 돈을 지불한 가치.\n\nChatGPT는 지루하고 단조로운 반복적이고 지루한 글쓰기를 테이블에서 제외했어요. 그리고 많은 작가들 - 나 자신 포함 - 그런 종류의 콘텐츠를 작성하고, 아마도 과금하고 있었을 수도 있어요.\n\n많은 회사들이 필사적으로 만들고 싶어하는 “SEO 목적 콘텐츠”들은 바로 ChatGPT가 제공하는 것이에요. 그리고 이건 무료로 제공돼요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아무도 그런 것을 읽는 것을 좋아하지 않는다고 생각해요. 하지만 Google 순위를 성스럽게 여기는 절박한 많은 CEO들과 대화를 나눈 적이 있어요. 그들은 그 순위를 위해 모든 것을 쓸 것이라고 말해요. 그들에게는 트래픽을 가져다줄 뿐인 기사 내용이 무엇이든 상관이 없어요.\n\n사실, 클라이언트 중 한 명이 그렇게 말한 적이 있어요. (그들은 아직도 ChatGPT가 아닌 저에게 글쓰기 요금을 지불하고 있어요.)\n\n\"SEO 목적용 콘텐츠\"는 또한 낮게 매달린 열매예요. 그것을 원하는 기업들은 사고리더십에 크게 신경을 쓰지 않으며 콘텐츠에 많은 돈을 지불하고 싶어하지 않아요.\n\n저에게 글쓰기 요금을 지불하는 일에 대해서는 — SEO 콘텐츠로 통하는 쓰레기에 대해 $250를 지불하지 않을 테지만, 제 분야에서 리더로서의 위치를 강조하고 비즈니스 문을 여는 기사라면 두 배나 네 배의 금액을 지불할 의향이 충분해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 품질의 콘텐츠입니다.\n\n나는 ChatGPT를 사랑하는 Canva와 CapCut 두 도구를 비교합니다. 나는 프로 디자이너가 아니며 확실히 비디오 편집자도 아닙니다(아직은). 이러한 도구들은 나의 소셜 미디어 프로필을 위해 \"냄새나지 않는\" 빠르고 조잡한 콘텐츠를 만들 수 있게 해줍니다— 그리고 돈을 크게 쓰지 않아도 됩니다. 나는 내 브랜드를 구축하는 초기 단계에 있습니다. 나에게는 정량이 정직합니다. 매일 비디오를 만들면 비디오 편집이 비십니다.\n\n그래서 나는 Canva를 그래픽용으로, CapCut을 비디오 편집용으로 사용합니다.\n\n프로 디자이너와 비디오 편집자는 아마도 내 소셜 미디어 콘텐츠를 보고 싫어할 것입니다. 그러나 그것은 우리 모두가 공존할 수 있는 행복한 중간지대입니다. 언젠가 부유하고 돈이 많이 번 다면, 누군가에게 일을 맡기겠지요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금은 프로급 디자인 및 비디오 편집 작업을 제공하는 사람들의 올바른 타깃 시장이 아닙니다.\n\n# 혹평은 문제가 아니에요 — 문장의 퀄리티만큼 중요해요\n\n저급한, 대량생산, 대량콘텐츠를 제공하는 클라이언트들을 살릴 수 없어요. 솔직히 그런 고객들과 관련된 일을 하는 게 귀찮아요.\n\n그런 종류의 글을 쓰는 게 싫고, 제가 하는 글은 훨씬 더 즐겁답니다. 퀄리티가 훨씬 높아서 도전적이지만 보람도 커요. 그리고 더 많이 벌어들일 수 있죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"나는 '싼 가격' 경쟁을 그만뒀어. 그건 그냥 맨 밑바닥으로 달려가는 경주라고 생각해.\n\n최고의 고객은 이상적이지만 더 어렵게 찾을 수 있어. 그러나 그런 고객은 존재해. 그런 고객을 만나기 위한 방법은 자신의 품질을 면밀히 살펴보고, 탁월하지 않다면 개선하는 것이다.\n\n그런 다음 사이에 있는 사람들 — 중상위 고객들이 있어: 그들은 괜찮은 콘텐츠를 존중하지만 여전히 ChatGPT가 그들을 위해 만들어 줄 수 있다고 바라는 사람들이다. 왜냐면 사람들의 후기로 그렇게 들었기 때문이야.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n과장된 혹평으로 인해 잠재적 고객에게 제품을 판매하기 어려워졌어요. 하지만 매출 사이클이 어렵게 되는 건 이 과장이라는 것을 알아야 해요. 품질 때문은 아니에요. 만약 매출 사이클을 개선한다면 여전히 중간 계층 고객을 끌어들일 수 있는 기회가 있어요.\n\n네, 이 새로운 생태계에서 우리는 더욱 열심히 팔아야 합니다.\n\nAI가 전문 작가의 작품과 비슷할 리 없다는 걸 확신할 수 있어요. 저는 이것에 한푼의 의심도 없어요. 이걸 확실히 믿게 되는 데는 1년 반이 걸렸죠. 확신을 갖게 되면, 제 판매 능력도 향상되었어요. 누군가 앞에 서서 \"챗지피티로는 그 퀄리티를 얻을 수 없어요\" 혹은 \"챗지피티 콘텐츠로 브랜드를 훼손하게 될 거라고 절대적으로 확신해요\" 라고 확신을 갖고 전할 수 있게 되었거든요.\n\n다른 사람들에게 이것들을 설득하기 위해선 이런 사실에 대해 개인적 확신을 얻어야 했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제 목표는 예술가와 작가들을 위해 힘을 실어주는 것입니다. 매일 올라오는 격려가 담긴 콘텐츠를 받고 싶다면, 즐겨 사용하는 소셜 미디어 채널에서 저를 팔로우해주세요.","ogImage":{"url":"/assets/img/2024-06-20-ImaComputerProgrammerandWroteProfessionallyaboutChatGPTfor15YearsHeresHowProWritersCanBeOkay_0.png"},"coverImage":"/assets/img/2024-06-20-ImaComputerProgrammerandWroteProfessionallyaboutChatGPTfor15YearsHeresHowProWritersCanBeOkay_0.png","tag":["Tech"],"readingTime":13},{"title":"합리적인 AI 프롬프트의 비밀 데이터와 함께 프롬프팅","description":"","date":"2024-06-20 18:31","slug":"2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData_0.png\" /\u003e\n\n맞아요. 환각이나 가짜 증거는 더 이상 없어요. 이젠 순수한 사실들뿐이에요.\n\n그리고 제일 좋은 점은 무엇이냐면, 많이 변화시킬 필요가 없다는 거예요. 프롬프트하는 방식을 약간 바꾸는 것만으로 충분했어요.\n\n이게 뭔지 궁금하시다면, 이제 알아보도록 하죠. 함께 파헤쳐봐요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 데이터 기반 프롬프팅\n\n여기서는 \"데이터를 활용한 프롬프팅\"이라고 부르겠어요. 이것에 대해 처음 들어보신다면, 기본 아이디어를 알려드리겠습니다:\n\n- 템플릿 사용: 당신의 작업을 설명하는 대신, ChatGPT에 응답 템플릿을 제공하세요.\n- 데이터 포함: 관련 데이터를 직접 프롬프트에 첨부하세요. URL, PDF 또는 간단한 텍스트일 수 있습니다.\n- 지시 추가: 연결된 데이터를 사용하여 AI에게 템플릿을 작성하도록 요청하세요.\n\n여기에 이 기술을 사용한 프롬프트의 예시가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData_1.png\" /\u003e\n\n이제 우리가 기초를 알았으니까 이 프롬프트를 만드는 방법을 알아볼까요? (예를 들어 사용해서) 간단한 트윗을 학술 에세이로 바꾸려고 해요.\n\n## 1/ 데이터 찾기\n\n첫 번째 단계는 첫걸음을 내는 것입니다. 내 경우에는 데이터를 찾는 것이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 블로그 게시물, PDF, 이미지 또는 ChatGPT에서 받아들일 수 있는 다른 형식일 수 있어요.\n\n나에게는 트윗이에요.\n\n## 2/ 데이터로 프롬프트를 제시해보세요\n\n다음 단계는 프롬프트를 작성하는 것이에요. 채워야 할 중요한 두 부분이 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 템플릿: 이것은 AI의 출력 형식을 안내합니다.\n- 데이터: 이것은 필요한 맥락과 제약을 제공합니다.\n\n원하는 경우 작업을 명확히 설명할 수 있습니다. 제 경우에는 트윗을 글로 변환하라고 언급했어요.\n\n![이미지](/assets/img/2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData_2.png)\n\n한 번 시도해보고 싶다면 전체 프롬프트는 여기에 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 텍스트를 친절하게 한국어로 번역해 드리겠습니다.\n\n\n| 파일 이름                                            | 설명                              |\n|-------------------------------------------------|--------------------------------|\n| 2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData_3.png | AIPrompt 데이터 사용 방법을 보여주는 이미지 |\n\n정말 멋지죠? 간단하면서도 마법처럼 잘 작동합니다.\n\n## 3/ 직접 해보기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 코드로 표를 마크다운 형식으로 바꿔보세요.\n\n즐거운 코딩 되세요!","ogImage":{"url":"/assets/img/2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData_0.png"},"coverImage":"/assets/img/2024-06-20-TheSecrettoFoolproofAIPromptsPromptingWithData_0.png","tag":["Tech"],"readingTime":2}],"page":"44","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"44"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>