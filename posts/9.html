<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/9" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/9" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="최신 RAG 09 프롬프트 압축 전문 가이드" href="/post/2024-06-23-AdvancedRAG09PromptCompression"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="최신 RAG 09 프롬프트 압축 전문 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-AdvancedRAG09PromptCompression_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="최신 RAG 09 프롬프트 압축 전문 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">최신 RAG 09 프롬프트 압축 전문 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">32<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드" href="/post/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="요청콘텐츠 스타일을 제한하는 50가지 두 단어 ChatGPT 프롬프트 예시  파트 2" href="/post/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="요청콘텐츠 스타일을 제한하는 50가지 두 단어 ChatGPT 프롬프트 예시  파트 2" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="요청콘텐츠 스타일을 제한하는 50가지 두 단어 ChatGPT 프롬프트 예시  파트 2" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">요청콘텐츠 스타일을 제한하는 50가지 두 단어 ChatGPT 프롬프트 예시  파트 2</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="OpenAI  토큰을 사용하는 최고의 방법" href="/post/2024-06-23-OpenAIBestPracticesofUsingTokens"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="OpenAI  토큰을 사용하는 최고의 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="OpenAI  토큰을 사용하는 최고의 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">OpenAI  토큰을 사용하는 최고의 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="ChatGPT-4o 시스템 프롬프트" href="/post/2024-06-23-ChatGPT-4oSystemPrompt"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="ChatGPT-4o 시스템 프롬프트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-ChatGPT-4oSystemPrompt_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="ChatGPT-4o 시스템 프롬프트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">ChatGPT-4o 시스템 프롬프트</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="하이퍼 관계형 그래프 더 지능적인 RAG 시스템의 핵심" href="/post/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="하이퍼 관계형 그래프 더 지능적인 RAG 시스템의 핵심" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="하이퍼 관계형 그래프 더 지능적인 RAG 시스템의 핵심" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">하이퍼 관계형 그래프 더 지능적인 RAG 시스템의 핵심</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="당신을 치유한 사람들에 의해 다시 상처받는 경험" href="/post/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="당신을 치유한 사람들에 의해 다시 상처받는 경험" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="당신을 치유한 사람들에 의해 다시 상처받는 경험" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">당신을 치유한 사람들에 의해 다시 상처받는 경험</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="컨볼루션 신경망CNN의 수학적 원리 분석" href="/post/2024-06-23-TheMathBehindConvolutionalNeuralNetworks"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="컨볼루션 신경망CNN의 수학적 원리 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="컨볼루션 신경망CNN의 수학적 원리 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">컨볼루션 신경망CNN의 수학적 원리 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">26<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근" href="/post/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="MLOps 로드맵  2024년 MLOps 엔지니어가 되는 방법" href="/post/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="MLOps 로드맵  2024년 MLOps 엔지니어가 되는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="MLOps 로드맵  2024년 MLOps 엔지니어가 되는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">MLOps 로드맵  2024년 MLOps 엔지니어가 되는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 23, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link posts_-active__YVJEi" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"최신 RAG 09 프롬프트 압축 전문 가이드","description":"","date":"2024-06-23 19:03","slug":"2024-06-23-AdvancedRAG09PromptCompression","content":"\n\nRAG 프로세스에서는 두 가지 문제가 발생할 수 있습니다:\n\n- 대규모 언어 모델(LLM)은 일반적으로 문맥 길이 제한이 있습니다. 따라서 입력 텍스트가 길수록 프로세스가 더 많은 시간과 비용이 소모됩니다.\n- 검색된 문맥이 항상 유용하지는 않을 수 있습니다. 더 큰 청크 중 작은 부분만 답변과 관련이 있을 수도 있습니다. 경우에 따라서는 특정 질문에 답변하기 위해 여러 청크를 결합해야 할 수도 있습니다. 이 문제는 리랭킹을 해도 계속되는 문제일 수 있습니다.\n\nLLM을 위한 프롬프트 압축은 이러한 문제를 해결하기 위한 방법입니다. 본질적으로, 목표는 프롬프트의 주요 정보를 유지하여 입력 토큰을 보다 가치 있게 만드는 것입니다. 이 접근 방식은 모델의 성능을 향상시키고 비용을 줄이는 데 도움이 됩니다. Figure 1의 우측 하단에 표시된 것과 같습니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_0.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알아두면 좋은 점은 그림 1의 보라색 점선에 표시된 대로 일부 압축기는 검색된 컨텍스트에 직접적으로 적용될 수도 있다는 것입니다.\n\n전체적으로, 프롬프트 압축 방법은 네 가지 주요 범주로 나뉠 수 있습니다:\n\n- 정보 엔트로피에 기반한 방법, Selective Context, LLMLingua, LongLLMLingua와 같은 것이 있습니다. 그러한 방법들은 작은 언어 모델을 사용하여 원본 프롬프트의 각 토큰의 자기 정보 또는 난해함을 계산합니다. 그런 다음 난해함이 낮은 토큰을 삭제합니다.\n- 소프트 프롬프트 튜닝에 기반한 방법, AutoCompressor와 GIST와 같은 것이 있습니다. 이러한 방법들은 특정 도메인에 적합하도록 LLM 매개변수를 세밀하게 튜닝해야 하지만 블랙박스 LLM에 직접 적용할 수는 없습니다.\n- 먼저 LLM으로부터 데이터 정제를 수행한 후, 더 해석하기 쉬운 텍스트 요약을 생성하는 모델을 훈련합니다. 이러한 요약은 서로 다른 언어 모델 간에 전송될 수 있으며, 기울기 업데이트가 필요하지 않은 블랙박스 LLM에 적용될 수 있습니다. 대표적인 방법으로는 LLMLingua-2와 RECOMP이 있습니다.\n- 토큰 병합 또는 토큰 가지치기에 기반한 방법, ToMe와 AdapLeR과 같은 것이 있습니다. 이러한 방법들은 보통 모델 세밀 튜닝이 필요하거나 추론 과정 중간 결과 생성을 요구합니다.\n\n4번째 유형의 방법이 ViT나 BERT와 같은 작은 모델을 위해 처음 제안되었으므로, 이 기사에서는 첫 세 가지 방법 유형의 대표적 알고리즘 원리를 소개하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 선택적 콘텍스트\n\n## 통찰\n\nFigure 2에서는 LLMs가 전체 콘텍스트나 완전한 대화 기록을 요구하지 않고 사용자 쿼리에 응답할 수 있다는 것을 보여줍니다. 적절한 정보가 생략되어도 LLMs는 여전히 예상된 응답을 생성할 수 있습니다. 이는 LLMs가 사전 훈련 중에 얻은 문맥 단서 및 이전 지식으로 누락된 정보를 추론할 수 있는 능력에 기인할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러므로 성능을 저해하지 않고 덜 유익한 콘텐츠를 걸러내어 문맥 길이를 최적화하는 것이 가능합니다. 이것이 선택적 문맥(Selective Context)의 중요한 통찰입니다.\n\n선택적 문맥은 주어진 문맥에서 문장, 구, 또는 토큰과 같은 어휘 단위의 자기 정보(self-information)를 결정하기 위해 소규모 언어 모델(SLM)을 활용합니다. 그런 다음 이 자기 정보를 사용하여 그들의 유익성을 평가합니다. 높은 자기 정보를 가진 콘텐츠를 선택적으로 유지함으로써, 선택적 문맥은 LLM을 위한 더 간결하고 효율적인 문맥 표현을 제공합니다. 이는 서로 다른 작업 간에 그들의 성능에 영향을 미치지 않고 달성됩니다.\n\n## 자기 정보(Self-Information)\n\n선택적 문맥은 콘텐츠의 품질을 평가하기 위해 자기 정보를 활용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자기 정보는 정보 이론에서 중요한 개념으로 놀람 또는 정보 내용이라고도 합니다. 이것은 이벤트에 의해 전달되는 정보량을 측정합니다. 토큰의 음의 로그 우도로 정의됩니다:\n\n\\[ I(x) = -\\log P(x) \\]\n\n여기서 I(x)는 토큰 x의 자기 정보를 나타내고, P(x)는 출력 확률을 나타냅니다.\n\n정보 이론에서 자기 정보는 이벤트와 관련된 놀라움 또는 불확실성의 수준을 측정합니다. 더 많은 정보를 전달하는 드문 이벤트는 더 높은 자기 정보를 가지고 있습니다. 반대로, 덜 많은 정보를 전달하는 일반적인 이벤트는 더 낮은 자기 정보를 가지고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 알고리즘\n\n원칙을 더 편리하게 설명하기 위해 소스 코드를 자세히 살펴봅시다.\n\n먼저, 해당 파이썬 라이브러리를 설치하고 Spacy 모델을 다운로드하여 환경을 설정합니다.\n\n```js\n(base) Florian:~ Florian$ conda create -n \"selective_context\" python=3.10 \n(base) Florian:~ Florian$ conda activate selective_context\n(selective_context) Florian:~ Florian$ pip install selective-context\n(selective_context) Florian:~ Florian$ python -m spacy download en_core_web_sm\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n설치가 완료되면 버전은 다음과 같습니다:\n\n```js\n(selective_context) Florian:~ Florian$ pip list | grep selective\nselective-context   0.1.4\n```\n\n테스트 코드는 다음과 같습니다:\n\n```js\nfrom selective_context import SelectiveContext\n\nsc = SelectiveContext(model_type='gpt2', lang='en')\ntext = \"INTRODUCTION Continual Learning ( CL ) , also known as Lifelong Learning , is a promising learning paradigm to design models that have to learn how to perform multiple tasks across different environments over their lifetime [To uniform the language and enhance the readability of the paper we adopt the unique term continual learning ( CL ) .]. Ideal CL models in the real world should be deal with domain shifts , researchers have recently started to sample tasks from two different datasets . For instance , proposed to train and evaluate a model on Imagenet first and then challenge its performance on the Places365 dataset . considers more scenarios , starting with Imagenet or Places365 , and then moving on to the VOC/CUB/Scenes datasets. Few works propose more advanced scenarios built on top of more than two datasets.\"\ncontext, reduced_content = sc(text)\n\n# reduce_ratio를 조절할 수도 있습니다\n# context_ratio, reduced_content_ratio = sc(text, reduce_ratio = 0.5)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 실행은 GPT-2 모델을 다운로드할 것인데, 해당 모델은 대략 500MB의 크기를 가지고 있어요. 테스트 코드의 결과는 아래 그림 3에 나와 있어요.\n\n![Figure 3](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_3.png)\n\n그다음, sc(text) 함수를 살펴봅시다. 내부 소스 코드는 다음과 같아요:\n\n```js\nclass SelectiveContext:\n    ...\n    ...\n    def __call__(self, text: str, reduce_ratio: float = 0.35, reduce_level: str = 'phrase') -\u003e List[str]:\n        context = self.beautify_context(text)\n\n        self.mask_ratio = reduce_ratio\n\n        sents = [sent.strip() for sent in re.split(self.sent_tokenize_pattern, context) if sent.strip()]\n\n        # 문장, 구문, 또는 토큰 단계에서 축소가 일어나도록 원하시나요?\n        assert reduce_level in ['sent', 'phrase', 'token'], f\"reduce_level should be one of ['sent', 'phrase', 'token'], got {reduce_level}\"\n        sent_lus, phrase_lus, token_lus = self._lexical_unit(sents)\n        lexical_level = {\n            'sent': sent_lus,\n            'phrase': phrase_lus,\n            'token': token_lus\n        }\n\n        # context가 축소된 맥락, masked_sents가 걸러진 맥락을 나타냄\n        context, masked_sents = self.self_info_mask(lexical_level[reduce_level].text, lexical_level[reduce_level].self_info, reduce_level)\n        return context, masked_sents\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드는 주로 세 가지 단계로 구성되어 있습니다:\n\n- 문맥 내 각 토큰의 자기 정보(self-information)를 계산합니다.\n- 구 절이나 문장과 같은 어휘 단위를 기반으로 토큰과 그들의 자기 정보를 병합합니다.\n- 정보 문맥을 선택적으로 유지합니다.\n\n단계 1: 자기 정보 계산\n\n각 토큰 xi를 나타내는 문맥 C = x0, x1, …, xn이 주어졌을 때, 우리는 각 토큰 xi의 자기 정보를 계산하기 위해 인과 언어 모델(GPT-2, OPT, LLaMA 등)을 사용합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 Markdown 형식으로 표시된 코드입니다:\n\n\n![이미지](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_4.png)\n\n만약 GPT-2를 사용 중이라면, 해당 코드는 다음과 같습니다:\n\n```python\nclass SelectiveContext:\n    ...\n    ...    \n    def _get_self_info_via_gpt2(self, text: str) -\u003e Tuple[List[str], List[float]]:\n        if self.lang == 'en':\n            text = f\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노드 수준에서 선택적인 콘텍스트 필터링을 직접 수행하면 일관성 없는 콘텍스트가 발생할 수 있습니다. 예를 들어 원래 프롬프트에 있는 \"2009\"는 \"209\"로 압축될 수 있습니다.\n\n따라서 토큰 수준 필터링 외에도 구, 문장 수준에서 필터링 절차를 구현하는 것이 중요합니다. 필터링의 기본 단위인 어휘 단위는 토큰, 구, 또는 문장이 될 수 있습니다.\n\n각 어휘 단위 u = (xt, …, xt+α)의 자기 정보를 어떻게 계산할까요? u를 구성하는 각 토큰의 자기 정보를 더하여 자기 정보의 가산성 원리를 따릅니다:\n\n![이미지](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 코드는 다음과 같습니다. 특정 변수에 대한 디버깅 정보가 추가되었습니다:\n\nclass SelectiveContext:\n    ...\n    ...\n    def _lexical_unit(self, sents):\n\n        if self.sent_level_self_info:\n            sent_self_info = []\n            all_noun_phrases = []\n            all_noun_phrases_info = []\n            all_tokens = []\n            all_token_self_info = []\n\n            for sent in sents:\n                # print(sent)\n                tokens, self_info = self.get_self_information(sent)\n                '''\n                ipdb\u003e sent\n                'INTRODUCTION Continual Learning ( CL ) , also known as Lifelong Learning , is a promising learning paradigm to design models that have to learn how to perform multiple tasks across different environments over their lifetime [To uniform the language and enhance the readability of the paper we adopt the unique term continual learning ( CL ) .].'\n\n                ipdb\u003e tokens\n                ['IN', 'TR', 'ODUCT', 'ION', ' Contin', 'ual', ' Learning', ' (', ' CL', ' )', ',', ' also', ' known', ' as', ' Lif', 'elong', ' Learning', ',', ' is', ' a', ' promising', ' learning', ' paradigm', ' to', ' design', ' models', ' that', ' have', ' to', ' learn', ' how', ' to', ' perform', ' multiple', ' tasks', ' across', ' different', ' environments', ' over', ' their', ' lifetime', ' [', 'To', ' uniform', ' the', ' language', ' and', ' enhance', ' the', ' read', 'ability', ' of', ' the', ' paper', ' we', ' adopt', ' the', ' unique', ' term', ' continual', ' learning', ' (', ' CL', ' )', '.', '].']\n\n                ipdb\u003e self_info\n                [7.514791011810303, 1.632637619972229, 0.024813441559672356, 0.006853647995740175, 12.09920597076416, 2.1144468784332275, 9.457701683044434, 2.4503376483917236, 10.236454963684082, 0.8689146041870117, 5.269547939300537, 4.641763210296631, 0.22138957679271698, 0.010370315983891487, 10.071824073791504, 0.6905602216720581, 0.01698811538517475, 1.5882389545440674, 0.4495090842247009, 0.45371606945991516, 6.932497978210449, 6.087430477142334, 3.66465425491333, 3.3969509601593018, 7.337691307067871, 5.881226539611816, 1.7340556383132935, 4.599822521209717, 6.482723236083984, 4.045308589935303, 4.762691497802734, 0.213468670845\n                \n                sent_self_info.append(np.mean(self_info))\n\n                all_tokens.extend(tokens)\n                all_token_self_info.extend(self_info)\n\n                noun_phrases, noun_phrases_info = self._calculate_lexical_unit(tokens, self_info)\n                '''\n                ipdb\u003e noun_phrases\n                ['INTRODUCTION Continual Learning', ' (', ' CL', ' )', ',', ' also', ' known', ' as', ' Lifelong Learning', ',', ' is', ' a promising learning paradigm', ' to', ' design', ' models', ' that', ' have', ' to', ' learn', ' how', ' to', ' perform', ' multiple tasks', ' across', ' different environments', ' over', ' their lifetime', ' [', 'To', ' uniform', ' the language', ' and', ' enhance', ' the readability', ' of', ' the paper', ' we', ' adopt', ' the unique term continual learning', ' (', ' CL', ' )', '.', ']', '.']\n                \n                ipdb\u003e noun_phrases_info\n                [4.692921464797109, 2.4503376483917236, 10.236454963684082, 0.8689146041870117, 5.269547939300537, 4.641763210296631, 0.22138957679271698, 0.010370315983891487, 3.5931241369495788, 1.5882389545440674, 0.4495090842247009, 4.284574694931507, 3.3969509601593018, 7.337691307067871, 5.881226539611816, 1.7340556383132935, 4.599822521209717, 6.482723236083984, 4.045308589935303, 4.762691497802734, 0.2134686708\n                \n                if all_noun_phrases:\n                    noun_phrases[0] = f\" {noun_phrases[0]}\"\n                all_noun_phrases.extend(noun_phrases)\n                all_noun_phrases_info.extend(noun_phrases_info)\n            \n            return [\n                LexicalUnits('sent', text=sents, self_info=sent_self_info),\n                LexicalUnits('phrase', text=all_noun_phrases, self_info=all_noun_phrases_info),\n                LexicalUnits('token', text=all_tokens, self_info=all_token_self_info)\n            ]\r\n\nStep 3: 선택적 정보 컨텍스트 보존\n\n각 어휘 단위의 자가 정보를 계산한 후, 정보성이 어떻게 평가될 수 있는지에 대한 의문이 생깁니다. 논문은 가장 정보가 많은 콘텐츠를 선택하기 위해 백분위 기반 필터링 접근 방식을 제안합니다. 이는 고정된 임계값을 사용하거나 상위 k개 어휘 단위를 고정하는 것보다 바람직합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 자기 정보 값에 따라 용어를 내림차순으로 정렬합니다. 그런 다음, 모든 용어의 자기 정보 값에 대한 p-백분위수를 계산합니다. 그런 다음, 자기 정보 값이 p-백분위수 이상인 용어를 선택적으로 유지합니다.\n\n해당하는 코드는 다음과 같습니다.\n\nclass SelectiveContext:\n    ...\n    ...\n\n    def self_info_mask(self, sents: List[str], self_info: List[float], mask_level):\n        # mask_level: 문장, 구, 또는 토큰을 가리는 이등급\n        sents_after_mask = []\n        masked_sents = []\n                \n        self.ppl_threshold = np.nanpercentile(self_info, self.mask_ratio * 100)\n\n        # if title is not None:\n        #     with open(os.path.join(self.path, title+'_prob_token.tsv'), 'w', encoding='utf-8') as f:\n        #         for token, info in zip(tokens, self_info):\n        #             f.write(f\"{token}\\t{info}\\n\")\n        #     with open(os.path.join(self.path, title+'_prob_sent.tsv'), 'w', encoding='utf-8') as f:\n        #         for sent, info in zip(sents, sent_self_info):\n        #             f.write(f\"{sent}\\n{info}\\n\\n\")\n\n        for sent, info in zip(sents, self_info):\n            if info \u003c self.ppl_threshold:\n                masked_sents.append(sent)\n                sents_after_mask.append(self.mask_a_sent(sent, mask_level))\n            else:\n                sents_after_mask.append(sent)\n        masked_context = \" \".join(sents_after_mask) if mask_level == 'sent' else \"\".join(sents_after_mask)\n        \n        return masked_context, masked_sents\n\n# LLMLingua\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 개요\n\nLLMLingua는 선택적 컨텍스트가 종종 압축된 콘텐츠 간의 상호 연결과 LLM 및 프롬프트 압축에 사용된 소규모 언어 모델 사이의 상관 관계를 무시하는 것을 제안합니다. LLMLingua는 이러한 문제를 정확히 다룹니다.\n\n특히, 그림 4에 나와 있는 것처럼 LLMLingua는 예시, 데모 및 질문과 같은 원래 프롬프트의 다양한 구성 요소에 동적으로 다른 압축 비율을 할당하기 위해 예산 컨트롤러를 사용합니다. 또한 LLMLingua는 시멘틱 무결성을 유지하기 위해 고약간의, 데모 수준의 압축을 수행하여 심하게 압축된 비율에서도 유지합니다. 또한 LLMLingua는 세분화된 프롬프트 압축을 위해 토큰 레벨 반복 알고리즘을 도입합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비교적으로 Selective Context에 비해 LLMLingua는 조건적 의존성을 고려하면서 프롬프트의 핵심 정보를 더 효과적으로 유지할 수 있습니다. 이를 통해 프롬프트를 20배 압축할 수 있습니다.\n\n## 예산 컨트롤러\n\n예산 컨트롤러는 LLMLingua의 중요한 구성 요소로, 원래 프롬프트의 다양한 부분에 동적으로 다른 압축 비율을 할당하는 데 사용됩니다.\n\n프롬프트의 다양한 섹션은 압축에 대해 다른 민감도를 가지고 있습니다. 예를 들어, 지시사항과 질문은 민감하며, 시연은 민감하지 않습니다. 예산 컨트롤러는 지시사항과 질문에 낮은 압축 비율을 할당하여 필수 정보를 보존하는 역할을 합니다. 반면, 시연에는 중복 정보를 제거하기 위해 더 높은 압축 비율을 할당할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예산 컨트롤러 알고리즘이 그림 5에 표시되어 있습니다:\n\n![이미지](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_7.png)\n\n주요 변수는 다음과 같습니다:\n\n- M_𝑠: GPT-2 또는 LLaMA와 같은 작은 언어 모델.\n- x = (x^ins , x^dems , x^que): 지시사항, 데모 및 질문이 포함된 원시 프롬프트.\n- 𝐿, 𝐿_ins, 𝐿_dems 및 𝐿_que은 x, x^ins , x^dems 및 x^que의 토큰 수를 나타냅니다.\n- 𝜏_dems: 데모에 대한 압축률로, 목표 전체 압축률 𝜏 및 지시사항과 질문에 대한 사전 정의된 압축률인 𝜏_ins 및 𝜏_que가 포함됩니다.\n- D: 이 집합에는 압축된 데모가 포함됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메인 프로세스는 다음과 같습니다:\n\n- 시연의 압축률 계산\n- GPT-2 또는 LLaMA와 같은 작은 언어 모델을 사용하여 원래 시연 집합의 각 시연의 난해도 계산\n- 모든 시연을 난해도에 따라 내림차순으로 정렬\n- 순서대로 시연을 선택하여 집합 D에 추가\n- 시연을 압축한 후, 남은 예산을 지시사항과 질문에 할당\n- 일반화된 압축 후 집합 D 출력\n\n시연 수준의 프로세스를 통해 예산 컨트롤러는 압축 중에 주요 정보를 유지하여 원래 프롬프트의 크기를 효과적으로 줄일 수 있습니다. 이 방법은 특히 여러 시연을 포함하는 프롬프트에 적합합니다.\n\n관련 코드는 control_context_budget 함수에 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 반복 토큰 수준 프롬프트 압축 (ITPC)\n\n프롬프트 압축을 위해 퍼플렉시티를 사용하는 것에는 내재적인 한계가 있습니다: 독립 가정입니다. 이 가정은 프롬프트의 각 토큰을 독립적으로 간주합니다. 다시 말해, 토큰의 발생 확률은 이전 토큰에만 의존하며 다른 토큰과 관련이 없습니다.\n\n이 가정의 문제는 자연어에서 종종 발생하는 토큰 간의 복잡한 종속성을 간과한다는 것입니다. 이러한 종속성은 맥락을 이해하고 의미 무결성을 보존하는 데 중요합니다.\n\n이러한 간과로 압축 프로세스 중에 중요한 정보의 손실이 발생할 수 있습니다. 예를 들어, 고률 압축에서, 토큰이 맥락에서 중요한 추론 단계 또는 논리적 연결을 제공하는 경우, 해당 토큰을 이 퍼플렉시티에만 의존하여 보관할지 여부를 결정하면 불완전한 추론 프로세스로 이어질 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 문제를 해결하기 위해 LLMLingua는 반복적인 토큰 수준 프롬프트 압축(ITPC) 알고리즘을 도입했습니다. 독립적인 확률에만 의존하는 대신, 이 방법은 프롬프트 압축 중 각 토큰의 중요성을 더 정확하게 평가합니다. 이를 위해 각 세그먼트를 반복적으로 처리하고 현재 컨텍스트 내에서 각 토큰의 조건부 확률을 고려합니다. 이 접근 방식은 토큰 간 종속성을 더 잘 보호하는 데 도움을 줍니다.\n\nITPC의 자세한 단계는 다음과 같습니다:\n\n![Figure 6](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_8.png)\n\n이 과정을 통해 ITPC 알고리즘은 프롬프트의 길이를 효과적으로 압축하면서 프롬프트 의미의 무결성을 유지하여 LLM의 추론 비용을 줄일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**반복 압축 프롬프트 함수에 관련된 코드입니다.**\n\n## 명령어 튜닝\n\nFigure 4에서는 명령어 튜닝 또한 LLMLingua에서 중요한 단계임을 보여줍니다. 이 단계의 목적은 압축 프롬프트에 사용되는 작은 언어 모델과 LLM 간의 분포 차이를 최소화하는 것입니다.\n\nFigure 7은 명령어 튜닝의 단계를 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```\n![Image](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_9.png)\n\n## 코드 데모\n\n이제 코드 데모를 시작해 봅시다. 먼저 환경을 설정하세요.\n\n```js\n(base) Florian:~ Florian$ conda create -n \"llmlingua\" python=3.11\n\n(base) Florian:~ Florian$ conda activate llmlingua\n\n(llmlingua) Florian:~ Florian$ pip install llmlingua\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n설치된 버전은 다음과 같습니다:\n\n```js\nllmlingua          0.2.1\n```\n\n테스트 코드는 아래와 같습니다:\n\n```js\nfrom llmlingua import PromptCompressor\n\nGSM8K_PROMPT = \"질문: 안젤로와 멜라니는 다음 주에 시험을 볼 것으로 계획하기 위해 함께 공부해야 할 시간을 계획하려고 합니다. 그들은 교과서의 2장을 공부하고 메모를 해야 할 4개의 문제지가 있습니다. 그들은 교과서의 각 장에 3시간, 각 문제지에 1.5시간을 할애해야 한다고 생각합니다. 하루에 최대 4시간 공부할 계획이기 때문에, 1시간마다 10분 휴식을 취하고, 하루에 3번 10분짜리 간식 휴식을 취하며, 매일 점심시간에는 30분을 포함한 경우, 그들은 다음 주에 총 몇 일을 공부할 계획이어야 할까요?\\n단계별로 생각해 봅시다.\\n안젤로와 멜라니는 2장에 각각 3시간을 할애해야 한다고 생각하여 2장 x 3시간 = 총 6시간이 됩니다.\\n문제지에는 각 문제지에 1.5시간을 할애할 계획이기 때문에, 1.5시간 x 4개의 문제지 = 총 6시간입니다.\\n안젤로와 멜라니는 공부를 시작해야 할 12시간의 계획이 필요한데, 하루에 4시간씩이므로, 12 / 4 = 3일이 필요합니다.\\n그러나, 휴식과 점심시간을 포함해야 합니다. 1시간에 10분씩 휴식을 취하고 싶어 한다면, 총 12시간 x 10분 = 휴식을 위해 120분이 더 필요합니다.\\n또한 3번의 10분짜리 간식 휴식과 점심시간에 30분을 포함하고 싶어 한다면, 120분 휴식 + 30분 간식 휴식 + 30분 점심시간 = 총 180분, 또는 180 / 60분당 1시간 = 3시간을 더 필요합니다.\\n그래서 안젤로와 멜라니는 12시간 공부 + 3시간 휴식을 계획합니다 = 총 15시간을 공부할 계획입니다.\\n하루에 4시간씩 공부할 예정이라면, 15시간 / 하루 4시간 = 3.75입니다.\\n그들은 필요한 모든 시간을 고려하여 4일을 공부할 계획이어야 합니다.\\n답은 4입니다\\n\\n질문: 동일한 가격으로 4개의 사과 또는 1개의 수박을 구입할 수 있습니다. 오렌지, 사과 및 수박으로 고른 36개의 과일을 구입했으며 1개의 오렌지 가격은 $0.50입니다. 총 청구액이 $66이라면, 1개의 사과는 얼마인가요?\\n단계별로 생각해 봅시다.\\n만약 36개의 과일이 3종류의 과일로 골고루 나눠졌다면, 나는 각각의 과일을 36/3 = 12개씩 샀습니다.\\n만약 1개의 오렌지 비용이 $0.50이라면, 12개의 오렌지는 $0.50 x 12 = $6입니다.\\n총 청구액이 $66이며 오렌지에 $6을 썼다면, 다른 2종류의 과일에는 $66 - $6 = $60을 사용했습니다.\\n수박 가격을 W로 가정하고, 4개의 사과를 동일한 가격으로 구입할 수 있으며 1개의 사과 가격이 A이라면, 1W=4A입니다.\\n우리가 $60에 12개의 수박과 12개의 사과를 샀다면, $60 = 12W + 12A임을 알 수 있습니다.\\n1W=4A를 알고 있다면, 위를 $60 = 12(4A) + 12A로 변환할 수 있습니다.\\n$60 = 48A + 12A\\n$60 = 60A\\n그러면 1개의 사과(A)의 가격은 $60/60= $1이 됩니다.\\n답은 1입니다\\n\\n질문: 수지는 800명의 학생이 있는 대형학교에 다니고 있고, 사라는 300명의 학생만 있는 작은 학교에 다니고 있습니다. 수지는 학년 초에 100명의 소셜 미디어 팔로워가 있었습니다. 그녀는 학년 초 첫 주에 40명의 새로운 팔로워를 얻었으며, 그 중 절반을 둘째 주에 얻었고, 그 중 절반을 셋째 주에 얻었습니다. 사라는 학년 초에 시작할 때 50명의 소셜 미디어 팔로워가 있었지만, 첫 주에 90명의 새로운 팔로워를 얻고, 둘째 주에는 그 중 3분의 1을 얻었으며, 셋째 주에는 그 중 3분의 1을 얻었습니다. 3주 후, 가장 많은 총 팔로워를 보유한 소녀는 몇 명의 소셜 미디어 팔로워를 가지고 있습니까?\\n단계별로 생각해 봅시다.\\n한 주 후, 수지는 100+40 = 140명의 팔로워가 있습니다.\\n둘째 주에 수지는 40/2 = 20명의 새로운 팔로워를 얻습니다.\\n셋째 주에 수지는 20/2 = 10명의 새로운 팔로워를 얻습니다.\\n합계적으로, 수지는 140+20+10 = 총 170명의 팔로워를 가지고 3주를 마칩니다.\\n한 주 후, 사라는 50+90 = 140명의 팔로워가 있습니다.\\n둘째 주에 사라는 90/3 = 30명의 팔로워를 얻습니다.\\n셋째 주에 사라는 30/3 = 10명의 팔로워를 얻습니다.\\n그래서 사라는 140+30+10 = 총 180명의 팔로워를 가지고 3주를 마칩니다.\\n따라서 수라는 총 180명의 팔로워를 가진 소녀로, 가장 많은 총 팔로워를 가지고 있습니다.\\n답은 180입니다\"\n\nllm_lingua = PromptCompressor()\n\n## 또는 phi-2 모델을 사용하세요,\n# llm_lingua = PromptCompressor(\"microsoft/phi-2\")\n\n## 또\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기본 모델은 처음 실행할 때 다운로드됩니다. 또는 양자화된 모델을 사용할 수도 있습니다. 실행 결과는 아래 그림 8에서 확인할 수 있습니다:\n\n![Figure 8](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_10.png)\n\n# LongLLMLingua\n\nLLMLingua의 문제는 압축 프로세스 중에 사용자 질문을 고려하지 않아 관련 없는 정보를 유지할 수 있다는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLongLLMLingua는 사용자 질문을 압축 과정에 통합하여 이 문제를 해결하고자 합니다.\n\n![image](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_11.png)\n\n그림 9에 나타난 것처럼 LongLLMLingua는 LLMs(Large Language Models)에서 주요 정보의 인지를 향상시키기 위해 네 가지 새로운 구성 요소를 제안했습니다:\n\n- 질문 인식 코스 그레인 및 파인 그레인 압축\n- 문서 재정렬 메커니즘\n- 동적 압축 비율\n- 서브시퀀스 복구 알고리즘\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 질문 인식 코어스 그래인드 압축\n\nLongLLMLingua는 다른 맥락 x^doc_k에 의존하는 질문 x^que의 엉킴도를 나타내기 위해 퍼플렉서티를 활용하는 것을 제안합니다. 제한적인 문장 x^restrict = \"주어진 문서에서 이 질문에 대한 답변을 얻을 수 있다\"는 x^que 뒤에 추가될 수 있습니다. 이 문장은 x^que와 x^doc_k 간의 연결을 강화시키며, 환각 효과를 줄이는 정규화 요소 역할을 합니다. 이는 다음과 같이 표현될 수 있습니다:\n\n```\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_12.png\" /\u003e\n\n\n왜 질문 x^que의 조건 아래 문서 수준의 퍼플렉서티를 계산하지 않는 걸까요? 이는 문서가 종종 관련 없는 정보를 많이 포함하기 때문입니다. x^que에 의존하더라도 전체 문서에 대해 계산된 퍼플렉서티 점수는 충분히 구분되지 않을 수 있으므로, 문서 수준의 압축에는 부적합한 측정 항목이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 코드는 get_distance_longllmlingua 함수에서 찾을 수 있습니다.\n\n## 질문 인식 미세압축\n\nLongLLMLingua는 대조적인 난해도 개념을 소개했습니다.\n\n![이미지](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_13.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 우리는 질문을 고려하지 않고 토큰의 수수께끼를 계산합니다. 이를 perplexity(x_i | x`i)로 표현합니다. 그런 다음, 우리는 질문을 포함하여 perplexity를 다시 측정합니다. 이 경우 perplexity(x_i | x^que, x`i)로 나타냅니다. 이는 질문 x^que가 주어졌을 때 토큰 x_i 이전의 모든 토큰을 보는 놀라움을 측정합니다.\n\n목표는 각 토큰의 놀람 수준이 질문과 관련하여 어떻게 변하는지 결정하는 것입니다. 질문을 포함할 때 단어가 덜 놀랍다면, 그 단어는 질문과 매우 관련이 있을 수 있습니다.\n\n## 문서 재배열 메커니즘\n\nFigure 10에 나와 있는 것처럼, 추론 과정에서 LLM은 주어의 시작과 끝에서 내용을 사용하는 경향이 있으며, 중간 내용은 무시합니다. 이 문제를 \"Lost in the Middle(가운데에서 사라짐)\"이라고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_14.png\" /\u003e\n\nFigure 10은 관련 정보가 시작 부분에 위치할 때 LLM이 가장 잘 작동한다는 것을 보여줍니다. 이에 따라 LongLLMLingua는 일반 압축의 결과를 기반으로 단락을 조직화하여 그들을 점수의 내림차순으로 앞에서 뒤로 배열합니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_15.png\" /\u003e\n\n## 동적 압축 비율\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문서마다 중요 정보 밀도가 다르기 때문에, 질문과 관련이 더 많은 문서에는 더 많은 예산(즉, 더 낮은 압축 비율)을 할당해야 합니다.\n\nLongLLMLingua는 굵은 압축에서 중요도 점수를 사용하여 미세한 압축 과정 중에 예산 분배를 안내합니다.\n\n특히, LLMLingua의 예산 컨트롤러를 사용하여 보유 문서의 초기 예산을 설정합니다. 그런 다음, 미세 압축 단계에서 각 문서에 압축 예산을 동적으로 할당합니다. 이 할당은 해당 문서의 중요도 점수의 순위 지수에 기반하며, 이는 굵은 압축 단계 중에 결정됩니다.\n\nLongLLMLingua는 적응적 할당을 위해 선형 스케줄러를 사용하며, 각 토큰 xi의 예산을 다음과 같이 정의할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_16.png)\n\n여기서 Nd는 문서의 수를 나타내며, δτ는 동적 할당의 총 예산을 제어하는 하이퍼파라미터입니다.\n\n해당 코드는 get_dynamic_compression_ratio 함수에서 찾을 수 있습니다.\n\n## 서브시퀀스 복구 알고리즘\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제11 그림에 나와 있듯이, 세밀한 토큰별 압축 과정에서 주요 엔티티의 일부 토큰이 폐기될 수 있습니다. 예를 들어, 원본 프롬프트의 \"2009\"는 \"209\"로 압축될 수 있고, \"Wilhelm Conrad Rontgen\"은 \"Wilhelmgen\"으로 압축될 수 있습니다.\n\n![그림 1](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_17.png)\n\nLongLLMLingua는 LLM의 응답에서 원본 콘텐츠를 복구할 수 있는 서열 복원 알고리즘을 제안했습니다. 이에 대한 자세한 내용은 제12 그림에 나와 있습니다.\n\n![그림 2](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_18.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기본 프로세스는 다음 단계를 포함합니다:\n\n- LLMs 응답에서 토큰 yl을 트래버스하고 압축된 프롬프트 x˜에 나타나는 가장 긴 부분 문자열 y˜key,l을 선택합니다.\n- 원래의 프롬프트 x에서 y˜key,l에 해당하는 최대 공통 최단 부분수열 xi,j를 찾습니다.\n- LLMs 응답에서 해당하는 토큰 y˜key,l을 xi,j로 대체합니다.\n\n해당 코드는 함수 recover에서 찾을 수 있습니다.\n\n## 코드 데모스트레이션\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n환경 설정 방법은 LLMLingua와 같습니다. 여기에 시험용 코드가 있습니다:\n\n```js\nfrom llmlingua import PromptCompressor\n\nGSM8K_PROMPT = \"질문: 앤젤로와 멜라니는 다음 주에 임박한 시험을 위해 얼마나 많은 시간을 함께 공부해야 하는지 계획하려고 합니다. 그들은 공부할 교과서의 장을 2장과 암기해야 할 문제집을 4개 발견했습니다. 그들은 교과서의 장당 3시간, 문제집당 1.5시간을 할애해야 한다고 생각했습니다. 만약 그들이 하루에 최대 4시간을 공부할 계획이고 매 시간마다 10분 휴식을 취하며 매일 3회 10분 간식 휴식과 하루에 30분의 점심 시간을 포함한다면, 다음 주에 총 몇 일 동안 공부할 계획을 세워야 할까요?\\n단계별로 생각해 봅시다\\n앤젤로와 멜라니는 각 교과서 장에 3시간을 할애해야 한다고 생각했습니다. 2장 x 3시간 = 총 6시간.\\n문제집에는 문제집당 1.5시간을 할애할 계획이며 4개의 문제집이 있습니다. 1.5시간 x 4개 = 총 6시간.\\n앤젤로와 멜라니는 공부할 12시간의 계획을 시작해야 합니다. 하루에 4시간씩, 12 / 4 = 3일이 필요합니다.\\n하지만 휴식과 점심 시간을 고려해야 합니다. 매 시간에 10분 휴식을 취하고 싶어 시간당 총 120분의 공부시간이 있습니다.\\n그들은 또한 3회 10분 간식 휴식을 취하고 싶어 하며, 3 x 10분 = 30분.\\n그리고 매일 30분의 점심 시간을 포함하고 싶어 하여, 휴식을 위한 120분 + 간식 휴식 30분 + 점심 30분 = 180분, 혹은 180 / 60분 = 3시간이 더 필요합니다.\\n그래서 앤젤로와 멜라니는 공부할 12시간 + 휴식 3시간 = 총 15시간의 계획을 세우기를 원합니다.\\n하루에 최대 4시간씩 공부할 계획이며, 15시간 / 하루당 4시간 = 3.75\\n그들은 필요한 모든 시간을 고려하려면 공부할 일정이 4일이어야 합니다.\\n정답은 4입니다\\n\\n질문: 동일한 가격으로 4개의 사과나 1개의 수박을 구입할 수 있습니다. 주인은 주전에 도전하기로 결심합니다. 그는 $80,000에 집을 사고 $50,000의 수리비를 들였습니다. 집 값은 150% 증가했습니다. 그는 얼마의 이익을 냈습니까?\"\n\nQUESTION = \"질문: 조쉬는 집을 뒤집어 보기로 결정합니다. 그는 $80,000에 집을 사고 $50,000을 수리합니다. 이로 인해 집 값이 150% 증가했습니다. 그가 얼마의 이익을 냈습니까?\"\n\nllm_lingua = PromptCompressor()\n\ncompressed_prompt = llm_lingua.compress_prompt(\n    GSM8K_PROMPT.split(\"\\n\\n\")[0],\n    question = QUESTION,\n    condition_in_question = \"after_condition\",\n    reorder_context = \"sort\",\n    dynamic_context_compression_ratio = 0.3,\n    condition_compare = True,\n    context_budget = \"+100\",\n    rank_method = \"longllmlingua\",\n)\n\nprint('-' * 100)\nprint(\"original:\")\nprint(GSM8K_PROMPT.split(\"\\n\\n\")[0])\n\nprint('-' * 100)\nprint(\"compressed_prompt:\")\nprint(compressed_prompt)\n```\n\n실행 결과는 아래 그림에서 확인할 수 있습니다:\n\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_19.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AutoCompressor\n\n이전에 언급된 방법과는 다르게, AutoCompressor는 부드러운 프롬프트 기반 접근 방식입니다.\n\n기존 모델을 스마트하게 세밀하게 조정하여 어휘를 확장하고 \"요약 토큰\" 및 \"요약 벡터\"를 활용하여 컨텍스트 정보를 간추립니다.\n\n![이미지](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_20.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nFigure 14에는 AutoCompressor의 아키텍처가 나와 있습니다. AutoCompressor는 다음 단계에서 작동합니다:\n\n- 어휘 확장: 이 단계는 모델의 기존 어휘에 \"요약 토큰\"을 추가하는 작업을 포함합니다. 이러한 토큰을 사용하면 모델이 대량의 정보를 더 작은 벡터로 압축할 수 있습니다.\n- 문서 분할: 처리할 문서를 작은 세그먼트로 나누고, 각 세그먼트에는 요약 토큰이 추가됩니다. 이러한 토큰은 이전 세그먼트들의 요약 정보도 함께 운반하여 요약 누적을 만듭니다.\n- 미세 조정 훈련: AutoCompressor는 \"다음 단어 예측\" 작업을 활용하여 준지도 학습 방법을 사용하여 모델을 미세 조정합니다. 이 작업의 목표는 현재 토큰 앞의 토큰들과 현재 세그먼트 앞의 세그먼트들의 요약 벡터를 기반으로 다음 단어를 예측하는 것입니다.\n- 역전파: AutoCompressor는 각 세그먼트에 대해 시간을 거슬러가는 역전파(BPTT)와 그래디언트 체크포인팅을 사용하여 계산 그래프의 크기를 최소화합니다. 모델이 전체 문서에 대해 역전파를 수행하므로 전체 컨텍스트의 연관성을 학습할 수 있습니다.\n\n## 코드\n\nAutoCompressor는 코드를 제공하고 있으며, 관심 있는 독자들은 시도해볼 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport torch\nfrom transformers import AutoTokenizer\nfrom auto_compressor import LlamaAutoCompressorModel, AutoCompressorModel\n\n# 6천개의 토큰을 4개의 압축 단계로 압축하여 훈련된 AutoCompressor를 로드합니다.\ntokenizer = AutoTokenizer.from_pretrained(\"princeton-nlp/AutoCompressor-Llama-2-7b-6k\")\n# Llama 모델을 실행하려면 bfloat16 + cuda가 필요합니다.\nmodel = LlamaAutoCompressorModel.from_pretrained(\"princeton-nlp/AutoCompressor-Llama-2-7b-6k\", torch_dtype=torch.bfloat16).eval().cuda()\n\nprompt = '현재 미국 대통령의 이름은 \"'\nprompt_tokens = tokenizer(prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids.cuda()\n\ncontext = \"\"\"조 바이든(Joe Biden)은 1942년 11월 20일 필라델피아 주 스크랜턴(Scranton)에서 태어나 중산층 가정에서 자랐습니다. 그는 델라웨어 대학을 졸업하며 역사와 정치학을 복수전공했습니다. 그 후 1968년에 실라큐스 대학 로 스쿨에서 법학 학위를 취득했습니다.\n바이든의 정치 경력은 1970년 델라웨어주 뉴캐슬 카운티 의회의 의원으로 선출되면서 시작되었습니다. 1972년 그의 아내 네일리아와 1세 딸 나오미가 차량 사고로 사망하고 아들 베아우와 헌터가 다쳤습니다. 이러한 비극적인 상황에도 불구하고 바이든은 자신의 약속을 지키기로 선택하고 그의 아들들의 침대 옆에서 상원 의원으로 취임했습니다.\n바이든은 1973년부터 2009년까지 델라웨어 주 상원의원으로 6회 임기를 보냈습니다. 상원 의원으로 활동하는 동안 바이든은 여러 위원회에 참여했으며 외교 문제에 대한 지식으로 유명했습니다. 그는 여러 차례 상원 외교위원회 위원장으로 활약했습니다.\n2008년 조 바이든은 대통령 선거에서 버락 오바마의 동역자로 선택되었습니다. 부통령으로 활동하면서 바이든은 오바마 행정부에서 정책 수립과 경제 회복, 외교 문제, Affordable Care Act (ACA, 일명 오바마케어) 시행 등의 문제를 다루는 데 중요한 역할을 했습니다.\n부통령으로 두 기간을 재직한 후 조 바이든은 2020년 대통령 선거에 출마하기로 결정했습니다. 그는 민주당 후보로 확정되어 재집권 중인 도널드 트럼프 대통령과 대선에서 맞붙었습니다. 바이든은 통일을 약속하며 코로나19 대유행, 기후 변화, 인종 정의, 미국 내 부의 불평등 등을 포함한 여러 중요 문제에 대처하겠다고 공약했습니다.\n2020년 11월 선거에서 바이든은 승리하고 2021년 1월 20일에 미국 46대 대통령으로 취임했습니다. 78세의 나이로 바이든은 미국 역사상 최고령 대통령이 되었습니다.\n대통령으로서 조 바이든은 인프라 투자, 기후 변화 대책, 이민 개혁, 의료 서비스 접근성 확대 등을 중점으로 한 그의 정책을 실행하려고 노력했습니다. 그는 국제 관계에서 외교의 중요성을 강조했고 전 세계 파트너와의 동맹을 새롭게 구축하려고 노력했습니다.\n공공분야의 긴 경력 동안 조 바이든은 양당 간의 협력, 공감, 노동 계층 문제에 대한 헌신으로 인해 인정받았습니다. 그는 국가를 향한 직면한 난제를 극복하며 나라를 하나로 이끄고 모든 미국인을 위한 긍정적인 변화를 만들기 위해 계속 노력하고 있습니다.\"\"\"\ncontext_tokens = tokenizer(context, add_special_tokens=False, return_tensors=\"pt\").input_ids.cuda()\n\nsummary_vectors = model(context_tokens, output_softprompt=True).softprompt\nprint(f\"{context_tokens.size(1)}개의 토큰을 {summary_vectors.size(1)}개의 요약 벡터로 압축 중\")\n# \u003e\u003e\u003e 660개의 토큰을 50개의 요약 벡터로 압축 중\n\ngeneration_with_summary_vecs = model.generate(prompt_tokens, do_sample=False, softprompt=summary_vectors, max_new_tokens=12)[0]\nprint(\"요약 벡터 사용해서 생성:\\n\" + tokenizer.decode(generation_with_summary_vecs))\n# \u003e\u003e\u003e 현재 미국 대통령의 이름은 \"조\"이며 성은 \"바이든\"입니다.\n\nnext_tokens_without_context = model.generate(prompt_tokens, do_sample=False, max_new_tokens=11)[0]\nprint(\"컨텍스트 없이 생성:\\n\" + tokenizer.decode(next_tokens_without_context))\n# \u003e\u003e\u003e 현재 미국 대통령의 이름은 \"도널드\"이며 성은 \"트럼프\"입니다.\n```\n\n# LLMLingua-2\n\nLLMLingua-2는 LLaMa-7B와 같은 인과 언어 모델로부터 정보 엔트로피를 기반으로 토큰 또는 어휘 단위를 삭제하여 프롬프트를 압축하는 데 두 가지 문제를 식별합니다:\n\n(1) 정보 엔트로피를 결정하는 소형 언어 모델이 프롬프트 압축 목표와 일치하지 않습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(2) 양방향 컨텍스트를 활용하지 않고 있어서, 빠른 압축을 위해 필요한 모든 정보를 포괄하지 못할 수 있습니다.\n\n이 문제들의 핵심은 정보 엔트로피가 압축에 대한 최적의 척도가 아닐 수 있다는 것입니다.\n\nLLMLingua-2의 전체 아키텍처는 다음과 같이 그림 15에 나와 있습니다:\n\n![LLMLingua-2 Architecture](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_21.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이슈 1을 해결하기 위해 LLMLingua-2는 데이터 증류 과정을 도입했습니다. 이 과정은 LLM에서 지식을 추출하여 중요 정보를 잃지 않으면서 프롬프트를 압축합니다. 동시에 추출형 텍스트 압축 데이터셋을 구축합니다. 이 데이터셋으로 훈련을 진행하면 작은 언어 모델이 프롬프트 압축에 효과적으로 정렬될 수 있습니다.\n\n이슈 2를 해결하기 위해 LLMLingua-2는 프롬프트 압축을 토큰 분류 문제로 다룹니다. 이 접근 방식은 압축된 프롬프트가 원래 프롬프트와 충실하다는 것을 보장합니다. 전이 전체 양방향 컨텍스트에서 프롬프트 압축을 위한 모든 필요한 정보를 캡처하기 위해 트랜스포머 인코더를 사용합니다.\n\n## 효과적인 프롬프트 압축 데이터셋 구축 방법\n\n데이터 증류\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 정제는 GPT-4와 같은 대규모 언어 모델에서 지식을 추출하여 필수 정보를 잃지 않고 프롬프트를 효과적으로 압축하는 것을 의미합니다.\n\nLLMLingua-2에서는 Figure 16에 나와 있는 것처럼 주의 깊게 설계된 지침을 따릅니다. 이러한 지침은 GPT-4로 하여금 원본 텍스트에서 비필수 단어를 제외하고 생성 프로세스 중에 새로운 단어를 추가하지 않으면서 텍스트를 압축하도록 요구합니다.\n\n동시에, 이러한 지침은 압축 비율 제한을 부과하지 않습니다. 대신, GPT-4에게 최대한 많은 정보를 유지한 채 원본 텍스트를 최대한 압축하도록 요청합니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_22.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그림 17에서 보듯이, GPT-4는 매우 긴 컨텍스트를 처리할 때 종종 높은 압축 비율을 적용합니다. 이는 긴 컨텍스트를 처리하는 능력이 제한되어 있기 때문일 수 있습니다. 이러한 공격적인 압축은 상당한 정보 손실로 이어지며, 후속 작업의 성능에 상당한 영향을 미칩니다.\n\n![그림](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_23.png)\n\n이 문제를 해소하기 위해 LLMLingua-2는 긴 텍스트를 512 토큰을 초과하지 않는 여러 청크로 나누는 청크 압축 방법을 채택했으며, 그런 다음 GPT-4에게 각 블록을 따로 압축하도록 안내합니다.\n\n데이터 주석화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현재 데이터 축소를 통해 원본 텍스트와 해당 압축 버전의 쌍을 확보하였습니다. 데이터 주석 작업의 목표는 원본 텍스트의 각 토큰에 이진 레이블을 할당하는 것입니다. 이는 압축 후 해당 토큰을 유지해야 하는지를 결정합니다.\n\nGPT-4가 지시에 엄격하게 따르지 않을 수 있기 때문에, LLMLingua-2는 검색 범위를 제한하기 위해 슬라이딩 윈도우 기술을 사용합니다. 또한 GPT-4의 압축 과정 중 원본 단어에 잠재적인 변경이 발생하는 것을 다루기 위해 퍼지 매칭을 사용합니다.\n\n품질 관리\n\nLLMLingua-2는 GPT-4 축산 및 자동 주석 레이블의 생성된 압축 텍스트의 품질을 평가하기 위해 Variation Rate(VR) 및 Alignment Gap(AG) 두 개의 품질 제어 메트릭을 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVariation Rate은 압축된 텍스트와 원본 텍스트 중 다른 단어의 백분율을 측정합니다. Alignment Gap은 자동 주석 단어의 품질을 평가합니다.\n\nLLMLingua-2는 이러한 측정치를 사용하여 낮은 품질의 샘플을 제외함으로써 데이터셋의 품질을 보장할 수 있습니다.\n\n## Compressor\n\n이진 분류 문제로 간주됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n처음에는 프롬프트 압축 문제를 이진 분류 문제로 변환할 수 있습니다. 기본 개념은 각 어휘 단위를 독립적인 엔티티로 고려하고 \"유지(preserve)\" 또는 \"폐기(discard)\" 라벨을 할당하는 것입니다. 이 방법은 압축된 프롬프트의 내용의 무결성을 보존하면서 모델의 설계를 간소화합니다.\n\n모델 아키텍처\n\n트랜스포머 인코더 기반 특징 인코더가 사용되고 상단에 선형 분류 레이어가 추가됩니다.\n\n이 아키텍처는 각 어휘 단위의 양방향 컨텍스트 정보를 캡처하여 압축 작업에 필수적인 정보를 제공할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n압축 전략\n\n원래 프롬프트 x의 압축 전략은 세 단계로 구성되어 있습니다. 목표 압축 비율은 1/τ로 정의되며, 여기서 τ는 압축된 프롬프트의 단어 수와 원래 프롬프트 x의 단어 수를 나눈 값입니다.\n\n- 먼저, 압축된 프롬프트 x˜에 유지할 토큰의 목표 수를 결정합니다: N˜ = τN.\n- 그런 다음, 토큰 분류 모델을 사용하여 각 단어 xi가 '보존'으로 표시될 확률 pi를 예측합니다.\n- 마지막으로, 원래 프롬프트 x에서 확률 pi 값이 가장 높은 상위 N˜개의 단어를 보존하여 원래 순서를 유지하고 압축된 프롬프트 x˜를 형성합니다.\n\n## 코드\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 볼 수 있듯이, LLMLingua-2의 주요 작업은 압축기를 구축하는 것입니다. 그렇다면 한 번 획득한 압축기를 어떻게 활용할 수 있을까요?\n\n아래 코드를 참조해 주세요(LLMLingua와 환경 설정 방법은 같습니다). 주요 내부 프로세스는 compress_prompt_llmlingua2 함수에서 확인할 수 있습니다.\n\n```js\nfrom llmlingua import PromptCompressor\n\nPROMPT = \"John: So, um, I've been thinking about the project, you know, and I believe we need to, uh, make some changes. I mean, we want the project to succeed, right? So, like, I think we should consider maybe revising the timeline.\\n\\nSarah: I totally agree, John. I mean, we have to be realistic, you know. The timeline is, like, too tight. You know what I mean? We should definitely extend it.\"\n\nllm_lingua = PromptCompressor(\n    model_name=\"microsoft/llmlingua-2-xlm-roberta-large-meetingbank\",\n    use_llmlingua2=True,\n)\ncompressed_prompt = llm_lingua.compress_prompt(PROMPT, rate=0.33, force_tokens=['\\n', '?'])\n\n## 또는 LLMLingua-2-small 모델 사용\n# llm_lingua = PromptCompressor(\n#     model_name=\"microsoft/llmlingua-2-bert-base-multilingual-cased-meetingbank\",\n#     use_llmlingua2=True,\n# )\n\nprint('-' * 100)\nprint(\"original:\")\nprint(PROMPT)\n\nprint('-' * 100)\nprint(\"compressed_prompt:\")\nprint(compressed_prompt)\n```\n\n실행 결과는 다음과 같이 나타납니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-AdvancedRAG09PromptCompression_24.png)\n\n# RECOMP\n\nRECOMP은 추출 및 요약 두 가지 유형의 훈련된 압축기를 소개합니다. 추출 압축기는 검색된 문서에서 유용한 문장을 선택하고, 추상적 압축기는 여러 문서에서 정보를 결합하여 요약을 생성합니다.\n\nFigure 19은 RECOMP에서 압축기의 위치를 보여줍니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_25.png\" /\u003e\n\n## 추출 압축기\n\n입력 문서 세트에서 n개의 문장 [s1, s2, …, sn]가 주어지면, 이중 인코더 모델을 학습합니다. 이 모델은 문장 si와 입력 시퀀스 x를 고정 차원 임베딩으로 임베딩합니다. 이러한 임베딩의 내적은 입력 x에 si를 추가하여 대상 출력 시퀀스를 생성할 때 LLM에게 얻는 혜택을 나타냅니다.\n\n압축기에서 최종 요약 s는 입력과의 내적에 따라 순위가 매겨진 상위 N개의 문장으로 구성됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 추상 압축기\n\n추상 압축기는 인코더-디코더 모델입니다. 입력 시퀀스 x와 검색된 문서 세트의 연결을 가져와서 요약 s를 출력합니다.\n\n이 방법은 LLM(예: GPT-3과 비슷한 모델)을 사용하여 훈련 데이터 세트를 생성하고 이 데이터를 필터링한 다음 필터링된 데이터 세트로 인코더-디코더 모델을 훈련하는 것을 포함합니다.\n\n## 코드\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRECOMP의 코드는 아직 초기 단계에 있기 때문에 여기에서는 시연하지 않습니다. 관심 있는 독자들은 직접 시도해 볼 수 있습니다.\n\n# 결론\n\n이 기사에서는 프롬프트 압축 방법을 도입하였습니다. 방법 분류, 알고리즘 원칙 및 코드 설명에 대한 정보가 포함되어 있습니다.\n\n논의된 방법 중 LongLLMLingua가 우수한 선택일 수 있습니다. 이미 연구 프로젝트에서 구현하였습니다. LongLLMLingua의 단점이나 더 나은 방법이 발견되면 기사를 업데이트하겠습니다. 또한, LLMLingua-2도 시도해볼 수 있으며, 속도와 메모리 사용에 이점을 가지고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 기술에 관심이 있다면, 제 다른 기사들도 확인해보세요.\n\n그리고 최신 AI 관련 콘텐츠는 제 뉴스레터에서 찾을 수 있어요.\n\n마지막으로, 이 기사에 오류나 누락된 내용이 있다면 또는 궁금한 점이 있다면 댓글 섹션에 남겨주세요.","ogImage":{"url":"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_0.png"},"coverImage":"/assets/img/2024-06-23-AdvancedRAG09PromptCompression_0.png","tag":["Tech"],"readingTime":32},{"title":"LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드","description":"","date":"2024-06-23 19:01","slug":"2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs","content":"\n\n대형 언어 모델(LLMs)은 자연 언어 처리를 혁신적으로 바꿨지만, 그들의 전체 잠재력을 이용하기 위해서는 주요 파라미터를 이해하는 것이 필요합니다.\n\n본 안내서는 두 가지 핵심 설정인 온도와 상위-K를 해석해 줍니다. 온도와 상위-K가 무엇인지, 어떻게 작동하는지, 그리고 최적 결과를 얻기 위해 각각을 언제 사용해야 하는지 살펴볼 것입니다.\n\n# 온도란 무엇인가요?\n\n온도는 LLM의 출력의 무작위성을 제어합니다. 일반적으로 0과 1 사이로 설정됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 낮은 온도(0에 가까운): 더 예측 가능하고 집중된 응답을 생성합니다.\n- 높은 온도(1에 가까운): 더 다양하고 창의적이며 때로는 예측할 수 없는 출력물을 생성합니다.\n\n기술적으로 온도는 모델의 다음 토큰 예측의 확률 분포를 수정합니다. 이는 소프트맥스 함수를 적용하기 전에 로짓(정규화되지 않은 예측 점수)를 온도 값으로 나누는 방식으로 수행됩니다:\n\n![image](/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png)\n\n위와 같습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- i는 우리가 확률을 계산하고 있는 특정 토큰을 나타냅니다.\n- j는 어휘 중 모든 토큰을 반복하는 합산에 사용됩니다.\n- x_i는 토큰 i의 로짓(unnormalized score)을 의미합니다.\n- x_j는 어휘 내 모든 토큰 j의 로짓들을 나타냅니다.\n- P(x_i)는 토큰 i의 확률을 나타냅니다.\n- T는 온도(temperature)를 의미합니다.\n- V는 어휘(vocabulary)를 나타냅니다.\n\nT가 0에 가까워질수록, 분포는 좀 더 뾰족해지며 높은 확률을 가진 토큰을 강하게 선호합니다. T가 커지면, 분포는 평평해지며 낮은 확률을 갖는 토큰들이 선택될 가능성이 높아집니다.\n\n![image](/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_1.png)\n\n# Top-K란 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTop-k 샘플링은 언어 모델에서 텍스트를 생성하는 데 사용되는 전략입니다. 여기에는 모든 가능한 단어를 고려하는 대신 상위 K개 가장 확률이 높은 단어에서 다음 단어를 선택하는 과정이 포함됩니다. 이 방법은 무작위성과 의미 있는 출력 사이의 균형을 도와줍니다. 아래는 이 방법이 작동하는 방식입니다:\n\n- 확률 분포: 모델이 시퀀스에서 다음 단어에 대한 어휘에 대한 확률 분포를 예측합니다.\n- 상위 K 선택: 가장 높은 확률을 가진 상위 K개의 단어만 고려됩니다.\n- 무작위 샘플링: 그 다음 이 상위 K개의 단어 중에서 단어가 그들의 확률에 기반하여 무작위로 선택됩니다.\n\n![이미지](/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_2.png)\n\nTop-K는 샘플링 풀의 크기를 제어하는 직접적인 방법을 제공합니다. K가 작을수록 보다 집중된 결과를 얻게 되지만, K가 클수록 더 다양성을 허용하지만 덜 관련성 있는 토큰을 포함할 위험이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 모델이 매우 불가능하거나 터무니없는 토큰을 선택하는 것을 방지하는 데 특히 효과적일 수 있습니다, 특히 K값이 비교적 낮게 설정된 경우. 그러나 이 방법은 상황에 따라 어휘 크기에 어려움을 겪을 수 있으며, 경우에 따라 너무 제한적일 수도 있고 다른 경우에는 너무 허용될 수 있습니다.\n\n# 온도, Top-K 또는 둘 다를 언제 사용해야 할까요?\n\n이 샘플링 방법을 적용해야 하는 시점을 이해하는 것은 귀하의 LLM 출력을 최적화하기 위해 중요합니다. 다음은 선택하는 데 도움이 되는 안내서입니다:\n\n## 온도\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 사실적 정확성이 필요한 작업(예: 질의응답 또는 데이터 추출)에는 낮은 온도(0.1-0.3)를 사용하세요.\n- 창의성과 일관성이 균형있는 일반 대화 또는 콘텐츠 생성에는 중간 온도(0.4-0.7)를 사용하세요.\n- 브레인스토밍, 시에 관한 높은 온도(0.8-1.0)를 필요로 하는 시나, 최대 창의력을 요구하는 작업에는 고온도를 사용하세요.\n\n### 상위-K\n\n- 가장 가능성 높은 단어로 모델을 제한하고 싶을 때는 낮은 K 값(10-50)을 사용하세요. 집중적이고 결정론적인 출력에 유용합니다.\n- 매우 불가능한 토큰의 선택을 방지하면서 더 많은 다양성을 허용하려면 더 높은 K 값(100-1000)을 사용하세요.\n- 상위-K는 특히 짧은 시퀀스의 출력 품질을 유지하는 데 유용합니다.\n\n## 온도와 상위-K 결합\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이러한 방법들을 조합하면 생성된 텍스트의 다양성과 품질을 세밀하게 조절할 수 있어요.\n- 확률적으로 발생할 가능성이 낮은 토큰을 걸러내기 위해 중간 K 값 (예: 50–100)을 사용한 후, 해당 하위 집합 내에서 무작위성을 조절하기 위해 온도를 적용해주세요.\n- 이 조합은 종종 각각의 방법을 단독으로 사용하는 것보다 안정적이며, 특히 더 긴 생성 작업에 적합해요.\n\n## 조합 사용 지침\n\n- 중간 K 값 (예: 50)와 온도 (예: 0.7)로 시작해주세요.\n- 출력물이 너무 무작위적이거나 주제와 관련이 없다면 K 값을 줄이거나 온도를 낮춰주세요.\n- 출력물이 너무 반복적이거나 예측 가능하다면 K 값을 늘리거나 온도를 높여주세요.\n- 특정 사용 사례 및 원하는 출력 특성에 기반하여 세밀하게 조정해주세요.\n\n기억해주세요, 이상적인 설정은 작업, 모델 및 원하는 결과에 따라 다릅니다. 실험을 통해 응용 프로그램에 최적의 균형을 찾는 것이 중요해요. 결과를 모니터링하고 적절하게 조정하여 LLM 출력물에서 일관성, 관련성 및 창의성의 최적 조합을 달성해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n온도 조절과 Top-K 샘플링을 숙달하는 것이 LLM 성능을 최적화하는 핵심입니다. 온도는 출력 무작위성을 직관적으로 조절하며, Top-K는 토큰 품질을 직접 관리합니다. 이러한 방법을 결합하면 종종 최상의 결과를 얻을 수 있으며, 창의성과 일관성 사이의 미묘한 균형을 제공합니다.\n\n기억하세요, 만능 해결책은 없습니다. 이상적인 설정은 당신의 특정 작업, 모델 및 원하는 결과에 따라 다릅니다. 이러한 매개변수를 실험하여 응용 프로그램에 완벽한 균형을 찾아보세요. 연습을 통해 언어 모델의 가능성을 최대한 활용하는 기술을 개발하여 자연 언어 생성의 경계를 넓힐 수 있을 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png"},"coverImage":"/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png","tag":["Tech"],"readingTime":4},{"title":"요청콘텐츠 스타일을 제한하는 50가지 두 단어 ChatGPT 프롬프트 예시  파트 2","description":"","date":"2024-06-23 19:00","slug":"2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2","content":"\n\n![이미지](/assets/img/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2_0.png)\n\n챗GPT 프롬프트 트릭을 모두 알고 있다고 생각했나요? 다시 한 번 생각해 보세요! 두 단어 톤 프롬프트의 첫 번째 부분으로 마음을 끌었는데, AI의 목소리를 제어하는 데 사용될 수 있는 50가지 더 놀라운 방법으로 돌아왔습니다.\n\n어리석은 이야기부터 심각한 보고서까지, 이러한 소프트 프롬프트는 AI의 톤과 개성을 제어할 수 있게 해줬어요.\n\n우리는 \"재미있는 이야기\"와 같은 단순한 분위기를 넘어, 몇 가지 더 황당한 단계를 올려가고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nChatGPT가 다양한 주제에 대해 다양한 답변을 제공할 수 있다는 걸 알고 계시나요?\n\n그 쿨한 트릭을 알아? 정확히 원하는 유형의 응답을 받는 방법이 있는데, 그 방법은 두 단어만 사용하는 것이야!\n\n놀라운 ChatGPT 프롬프트를 사용하여 글을 쓰고 최적화하는 것도 가능해.\n\n이러한 프롬프트를 사용하면 ChatGPT가 자유자재로 코드를 전환하면서 자유스럽게 랩퍼처럼 라임을 맞춰주거나, 고대의 현자처럼 철학적으로 이야기하거나, 앤드루 다이스 클레이를 부끄러워하게 할만한 욕설로 가득한 욕설을 할 수 있어. 그건 시작에 불과해!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- “전략 개요”\n- “예측 제공”\n- “이론 설명”\n- “개요 제공”\n- “비평 제공”\n- “접근 방법 설명”\n- “요약 제공”\n- “기법 비교”\n- “목표 개요”\n- “평가 제공”\n- “개념 설명”\n- “세부 내용 제공”\n- “권장 사항 제공”\n- “근거 설명”\n- “평가 제공”\n- “접근 방법 비교”\n- “방법론 개요”\n- “결론 제공”\n- “현상 설명”\n- “제안 제공”\n- “통찰력 제공”\n- “제안 제공”\n- “논리 설명”\n- “추가 설명”\n- “틀 제공”\n- “결과 비교”\n- “계획 개요”\n- “전망 제공”\n- “영향 설명”\n- “분석 제공”\n- “관점 제시”\n- “과정 설명”\n- “세부 내용 제공”\n- “구조 개요”\n- “요약 제공”\n- “해결책 제시”\n- “추론 설명”\n- “배경 제공”\n- “더 자세히 설명”\n- “대안 제시”\n- “참고 자료 제공”\n- “주요 요점 요약”\n- “타임라인 제공”\n- “이유 설명”\n- “정의 제공”\n- “제품 비교”\n- “요약 작성”\n- “방법론 설명”\n- “단계 개요”\n- “지시 제공”\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n뭐 기다려? 이 살상적인 프롬프트들을 꽂아보면서 끊임없는 대화, 이야기, 그리고 AI 들어끼기의 새로운 세계를 즐겨보세요.\n\n그럼 어서 뭐 기다리고 있어? 이 살상적인 프롬프트들을 꽂아보면서 끊임없는 대화, 이야기, 그리고 AI 들어끼기의 새로운 세계를 즐겨보세요.\n\n---\n\n이 글을 즐겼다면 몇 번의 박수👏를 해주시고 주변에 공유해주세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n웹진이 팔로우해 주셔서 감사합니다!\n\n더 많은 멋진 콘텐츠가 곧 공개될 예정이니, 저를 여기 중간에서 팔로우해 주세요.\n\n아래 댓글에 의견과 피드백을 남겨주세요!\n\n건배! 🥂\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 웹진니(Webjinnee 창립자) Nitin입니다. 다음에 만나요! ✌️\n\n#챗GPT해킹 #프롬프트파워 #톤트릭스 #AI워드크래프트 #최소프롬프트 #AI글쓰기팁 #챗GPT프롬프트","ogImage":{"url":"/assets/img/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2_0.png"},"coverImage":"/assets/img/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2_0.png","tag":["Tech"],"readingTime":2},{"title":"OpenAI  토큰을 사용하는 최고의 방법","description":"","date":"2024-06-23 18:58","slug":"2024-06-23-OpenAIBestPracticesofUsingTokens","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png\" /\u003e\n\n# 오픈AI 토큰이란\n\n오픈AI의 고급 언어 모델인 GPT-3.5 및 GPT-4와 같은 분야에서 \"토큰\"이란 텍스트에서 함께 자주 나타나는 문자 시퀀스를 가리킵니다. 이러한 모델은 이러한 토큰 간의 통계적 관계를 이해하고 예측하는 데 설계되어 있습니다.\n\n텍스트를 토큰으로 분해하는 프로세스는 다른 모델 간에 다를 수 있습니다. 예를 들어, GPT-3.5와 GPT-4는 이전 모델과 달리 다른 토큰화 프로세스를 사용하여 입력 텍스트에 대해 다른 토큰을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적으로 한 토큰은 영어 텍스트의 네 문자에 해당하는 양으로, 대략 세 분의 삼분의 이 하나의 단어와 거의 비슷합니다. 따라서, 100개의 토큰은 대략 75단어에 해당합니다.\n\n예를 들어, \"OpenAI is great!\"이라는 문장을 생각해 봅시다. 이 문장에서 토큰은 다음과 같이 분리될 수 있습니다:\n\n[“Open”, “AI”, “ is”, “ great”, “!”]\n\n![이미지](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 각각이 토큰으로 간주됩니다. 모델에서 사용하는 구체적인 토큰화 프로세스에 따라 정확한 분할이 다를 수 있습니다. 예를 들어, 일부 모델은 \"OpenAI\"를 하나의 토큰으로 처리할 수 있지만, 다른 모델은 \"Open\"과 \"AI\"로 분할할 수도 있습니다. 마찬가지로, 공백과 구두점은 종종 별도의 토큰으로 처리됩니다. 그래서 이 예시에서는 다섯 개의 토큰이 있습니다: \"Open\", \"AI\", \" is\", \" great\", 그리고 \"!\".\n\n토큰 길이 개념을 이해하기 위한 유용한 가이드라인을 제시해드리겠습니다:\n\n- 1 토큰은 대략 영어로 4자와 동일합니다.\n- 1 토큰은 대략 단어의 3/4에 해당합니다.\n- 100 토큰은 약 75단어에 해당합니다.\n\n또는,\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 토큰 인코딩\n\n토큰 인코딩은 자연어 처리(NLP) 및 기계 학습에서 중요한 단계입니다. 이는 기계가 이해하고 작업할 수 있는 형식인 고정 차원의 수치 벡터로 변환하는 과정입니다.\n\n다른 토큰 인코딩은 서로 다른 모델에 연결되어 있으므로 텍스트를 토큰으로 변환할 때 어떤 모델을 사용할 지 고려해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주어진 텍스트 문자열 (예: \"OpenAI is great!\")과 인코딩 (예: \"cl100k_base\")으로 토크나이저가 텍스트 문자열을 토큰 목록으로 분할할 수 있습니다 (예: [\"Open\", \"AI\", \" is\", \" great\", \"!\"]).\n\n다음 표는 토큰 인코딩 방법과 OpenAI 모델 간의 매핑을 보여줍니다:\n\n\n| 토큰 인코딩 방법 | OpenAI 모델 |\n|------------------|-------------|\n| cl100k_base      | 모델 1      |\n| cl200k_base      | 모델 2      |\n| cl500k_base      | 모델 3      |\n\n\n# 토큰화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOpenAI의 맥락에서 토큰화는 텍스트를 더 작은 조각, 즉 토큰으로 분리하는 방법입니다. 이 토큰들은 텍스트에서 함께 자주 나타나는 문자 시퀀스로, OpenAI의 대형 언어 모델인 GPT-3.5 및 GPT-4 등에서 사용되어 텍스트를 처리하고 이해하는 데 활용됩니다.\n\nTiktoken은 OpenAI가 만든 기반 Python 도구입니다. 이 도구는 주로 OpenAI의 GPT-4와 같은 모델과 함께 작동하도록 설계된 빠른 바이트 페어 인코딩 (BPE) 토크나이저입니다. Tiktoken의 주요 기능은 텍스트를 더 작은 조각으로 나누어 모델이 텍스트를 처리하고 이해할 수 있도록 하는 것입니다.\n\n오픈 소스 도구인 Tiktoken은 pip install tiktoken 명령을 사용하여 PyPI에서 쉽게 설치할 수 있습니다. 또한 JavaScript 환경에서 사용할 수 있는 커뮤니티 지원 버전도 있습니다.\n\nTiktoken의 주요 기능 중 하나는 교육용 하위 모듈인데, 이 모듈은 BPE의 작동 방식을 이해하고 사용자가 토큰화 프로세스를 시각화할 수 있도록 도와줍니다. 또한 Tiktoken은 유연하며 새로운 인코딩 지원을 추가할 수 있도록 사용자에게 허용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예제 하나가 이렇게 보일 거예요:\n\n```python\nimport tiktoken\n\nencoding = tiktoken.get_encoding(\"cl100k_base\")\n# 특정 모델 이름에 해당하는 올바른 인코딩을 자동으로 로드하기 위해\nencoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n\nprint(encoding.encode(\"OpenAI is great!\"))\n```\n\n출력은 이렇게 보일 거예요:\n\n```python\n[5109, 15836, 374, 2294, 0]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토큰을 세는 방법은 .encode()로 반환된 리스트의 길이를 세면 됩니다.\n\n# 토큰 한도\n\n요청에 사용할 수 있는 토큰의 최대 수는 선택한 모델에 따라 다르며, 입력 프롬프트 및 생성된 출력(gpt-3.5-turbo)에 대한 4096개의 토큰이라는 결합한 한도가 있습니다. 따라서, 입력에 4000개의 토큰을 할당하면 출력에는 최대 96개의 토큰이 남게 됩니다.\n\n이 제약은 주로 기술적인 이유로 인해 발생합니다. 그러나, 입력을 더 간결하게 요약하거나 콘텐츠를 더 작은 세그먼트로 나누는 등 이러한 제한 내에서 효과적으로 작업하는 다양한 전략이 존재합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nGPT4의 토큰 한도\n\n![Image](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_3.png)\n\n더 많은 정보를 알고 싶다면 openai의 공식 웹사이트를 방문해보세요: [여기를 클릭하세요](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\n\n# 토큰 가격 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOpenAI API는 다양한 모델 유형을 제공하며 각 모델은 다른 가격 수준에서 사용할 수 있습니다. 이러한 모델들은 능력이 다양하며 가장 진보된 것은 다빈치이고, 가장 빠른 것은 에이다입니다. 요청을 만드는 데 드는 비용은 이러한 모델에 따라 달라집니다.\n\n예를 들어, GPT-4 Turbo 모델의 경우, 입력 기준으로 $0.01/1K 토큰, 출력 기준으로 $0.03/1K 토큰이 듭니다.\n\n표:\n\n![OpenAI 모델 비용](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_4.png)\n\n그리고 OpenAI에 따르면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCobus Greyling님은 OpenAI 토큰 비용에 대한 멋진 차트를 보유하고 계시네요:\n\n![OpenAI Token Cost Chart](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_5.png)\n\n# 가격 계산기\n\n다음 \"OpenAI 및 다른 LLM API 가격 계산기\"를 활용하여 계산을 할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_6.png)\n\n위는 1000개의 입력 단어, 500개의 출력 단어 및 100회의 API 호출에 대한 총 비용을 보여줍니다.\n\n# Best Practices\n\nOpenAI 토큰을 사용할 때는 최적의 방법을 채택하여 효율성을 극대화하고 비용을 최소화하며 OpenAI의 API와의 상호 작용을 효과적이고 안전하게 보장할 수 있습니다. 다음은 추천하는 최상의 방법론입니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 토큰 이코노믹스 이해하기\n\n사용하는 맥락에서 어떻게 토큰이 계산되는지, 그리고 토큰을 구성하는 것이 무엇인지 이해하세요. 다양한 입력 길이에 대한 대략적인 토큰 수를 알면 사용량과 비용을 보다 정확하게 추정하는 데 도움이 됩니다.\n\n## 프롬프트 디자인 최적화\n\n모델이 원하는 출력 생성 방향으로 이끌 수 있도록 프롬프트를 간결하면서도 충분히 구체적으로 디자인하세요. 이 균형을 유지하면 사용된 토큰 수를 줄이고 유용한 응답을 받을 확률을 높일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 효율적인 토큰 관리 활용하기\n\n예상치 못한 비용을 피하기 위해 토큰 사용량을 추적하세요. 플랫폼이나 응용 프로그램에서 지원한다면 알림이나 제한을 구현하여 소비량을 모니터링하세요.\n\n## 가능한 경우 일괄 요청 처리하기\n\n사용 사례가 허용한다면 일괄 처리는 한 번에 한 요청을 처리하는 것보다 더 효율적일 수 있습니다. 이 방법은 비용 절감에도 도움이 될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 작업에 적합한 모델 활용하기\n\n작업에 가장 적합한 모델을 선택하세요. Davinci와 같이 큰 모델은 더 강력하지만, Ada나 Babbage와 같은 작은 모델은 깊은 이해나 창의력이 필요하지 않은 작업에 대해 더 비용 효율적일 수 있어서 토큰을 절약할 수 있습니다.\n\n## 빈번한 요청에 대한 캐싱 구현하기\n\n응용 프로그램이 동일하거나 유사한 프롬프트로 반복적인 요청을 수행하는 경우, 응답을 캐싱하여 토큰을 절약할 수 있습니다. 캐시가 안전하게 관리되고 개인정보 및 데이터 보호 요구 사항을 준수하는지 확인하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## API 키 보호하기\n\nOpenAI API 키를 안전하게 보호하여 무단 사용을 방지하고, 토큰 낭비 및 예상치 못한 요금 부과를 방지하세요. 접근 제어를 구현하고 정기적으로 키를 변경하세요.","ogImage":{"url":"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png"},"coverImage":"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png","tag":["Tech"],"readingTime":6},{"title":"ChatGPT-4o 시스템 프롬프트","description":"","date":"2024-06-23 18:57","slug":"2024-06-23-ChatGPT-4oSystemPrompt","content":"\n\nChatGPT이 시스템 프롬프트를 실수로 출력해 버렸어. 다른 분들도 궁금해할 것 같아 공유하려고 해.\n\n```js\n넌 오픈AI에서 훈련된 대규모 언어 모델인 ChatGPT이고, GPT-4 아키텍처를 기반으로 하고 있어.\nChatGPT iOS 앱을 통해 사용자와 대화 중이야. 대부분의 경우에는 한 두 문장 정도여야 해, 사용자의 요청이 이성적 사고나 장문의 결과를 필요로 할 때를 제외하고는. 사용자가 명시적으로 요청하지 않은 이상 이모지를 사용하지 마.\n지식의 종점: 2023년 10월\n현재 날짜: 2024년 06월 21일\n이미지 입력 기능: 활성화\n개성: v2\n\n# 도구\n\n## bio\n`bio` 도구를 사용하면 대화 전반에 걸쳐 정보를 유지할 수 있어. 메시지를 `to=bio`로 지정하고 기억하고 싶은 정보를 쓰세요. 이 정보는 나중 대화에서 모델 설정 맥락에 표시될 거야.\n\n## dalle\n// 이미지 설명이 제공될 때마다 dalle가 이미지를 생성할 수 있는 프롬프트를 만들어야 하며 다음 정책을 준수해야 해:\n// 1. 프롬프트는 영어로 작성되어야 해. 필요한 경우 영어로 번역하세요.\n// 2. 이미지를 생성할 권한을 요청하지 말고 그냥 생성하세요!\n// 3. 설명을 나열하거나 참조하지 마세요. 이미지 생성 전후로 참조하지 마세요.\n// 4. 사용자로부터 나온 이미지 설명이 변경된 경우, 프롬프트는 단순히 길어지는 것이 아니라 사용자 제안을 통합하도록 다시 만들어져야 합니다.\n// 5. 현재 이미지 설명을 요구하는 경우, 다음 절차를 적용하세요: (a) 작품의 이름을 스타일의 핵심 측면을 잡아내는 세 가지 형용사로 대체하고가; (b) 작품의 컨텍스트를 제공하기 위해 관련 예술의 흐름이나 시대를 포함하며; (c) 작가가 사용한 주요 매체를 언급하세요\n// 6. 특정, 명시된 사적 인물을 품은 생성을 요청받은 경우, 그들이 어떻게 보이는지를 설명할 것을 사용자에게 요청하세요. 당신이 그들이 어떻게 생겼는지 모르기 때문에.\n// 7. 이름으로 언급되는 어떠한 공인된 인물의 이미지 생성을 요청받은 경우, 해당 성별과 체형이 비슷한 사람들의 이미지를 생성하세요. 그들이 닮아 보이지 않아야 해. 이미지에서 해당 사람에 대한 참조가 텍스트만으로 나타 나는 경우라면, 참조를 그대로 사용하세요.\n// 8. 저작권이 있는 캐릭터의 이름을 공개하거나 직/간접적으로 언급하거나 설명하지 마세요. 특정 다른 캐릭터에 대해 자세히 설명하는 방식으로 프롬프트를 재작성하세요. 색상, 헤어 스타일 또는 다른 구별적인 시각적 특성을 가진 다른 특정 캐릭터에 대해 자세히 설명해 주세요. 응답에서 저작권 정책에 대해 이야기하지 마세요.\n// dalle에 보내야 하는 생성된 프롬프트는 매우 상세해야 하며, 약 100단어 가량이어야 합니다.\n// dalle에 대한 예제 호출: `{\"prompt\": \"\u003c프롬프트 내용 삽입하세요\u003e\"}`\n\n## browser\n`browser` 도구를 사용할 수 있어. 다음 상황에서 `browser`를 사용하세요:\n- 사용자가 현재 이벤트 또는 실시간 정보를 요청하는 경우 (날씨, 스포츠 점수 등).\n- 사용자가 안경데지 우리가 알지 못하는 용어에 대해 물어보는 경우 (새로운 것일 수 있음).\n- 사용자가 명시적으로 브라우징하거나 참조 링크를 제공하도록 요청하는 경우\n조회가 필요한 쿼리를 위해 당신의 차례는 세 단계로 이루어져야 합니다:\n1. 검색 기능을 호출하여 결과 목록을 가져옵니다.\n2. `mclick` 함수를 호출하여 이 결과의 다양하고 고품질의 부분을 검색합니다(병렬로). `mclick`을 사용할 때 적어도 3개의 소스를 선택하세요.\n3. 이 결과를 기반으로 사용자에게 응답하세요. 응답에서는 아래 인용 형식을 사용하여 소스를 인용하세요.\n일부 경우에는 초기 결과가 만족스럽지 않은 경우, 쿼리를 더 정제하여 더 나은 결과를 얻을 수 있다고 믿는다면 스텝 1을 두 번 반복해야 합니다.\n또한 사용자가 제공한 경우 바로 URL을 열 수 있습니다. 이를 위해 `open_url` 명령어만 사용하세요. 검색 함수에서 반환되는 URL이나 웹페이지에서 찾은 URL을 열지 마세요.\n`browser` 도구에는 다음과 같은 명령이 있습니다:\n`search(query: str, recency_days: int)`. 검색 엔진에 쿼리를 발행하고 결과를 표시합니다.\n`mclick(ids: list[str])`. 제공된 ID(인덱스)의 웹페이지 내용을 검색합니다. 사용할 때는 꼭 3개 이상, 최대 10개 페이지를 선택하세요. 다양한 관점의 소스를 선택하고 신뢰할 수 있는 소스를 우선 선택하세요. 일부 페이지가 로드되지 않을 수 있으므로, 콘텐츠가 중복될 수 있더라도 일부 페이지를 중복 선택하는 것이 괜찮습니다.\n`open_url(url: str)`. 주어진 URL을 열고 표시합니다.\n브라우저 도구에서 인용한 것은 다음 형식으로 렌더링하세요: `【{메시지 인덱스}†{링크 텍스트}】`.\n긴 인용문의 경우 다음 형식으로 렌더링하세요: `[링크 텍스트](메시지 인덱스)`.\n그 외에는 링크를 렌더링하지 말아주세요.\n\n## python\nPython 코드를 포함한 메시지를 python에게 보내면 상태 유지 Jupyter 노트북 환경에서 실행됩니다. python은 실행 결과를 응답하거나 60.0초 후에 타임아웃 될 것입니다.\n'/mnt/data' 드라이브를 사용하여 사용자 파일을 저장하고 유지할 수 있습니다. 이 세션에서의 인터넷\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인터넷에서 처음으로 이를 발견한 사람은 아니라는 걸 알고 있어요. 일부 사람들은 챗봇을 \"탈옥\"하려고 의도적으로 노력하고 있는데요. 하지만 여전히 재미있게 보실 분들이 있을 거라고 생각해요.\nMarkdown 포맷으로 변경하였습니다.\n\n![ChatGPT-4oSystemPrompt_0](/assets/img/2024-06-23-ChatGPT-4oSystemPrompt_0.png)","ogImage":{"url":"/assets/img/2024-06-23-ChatGPT-4oSystemPrompt_0.png"},"coverImage":"/assets/img/2024-06-23-ChatGPT-4oSystemPrompt_0.png","tag":["Tech"],"readingTime":3},{"title":"하이퍼 관계형 그래프 더 지능적인 RAG 시스템의 핵심","description":"","date":"2024-06-23 18:55","slug":"2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems","content":"\n\n다음은 여러 문서 간의 정보를 원활하게 연결하여 복잡한 질문에 답변할 수 있는 인공 지능 시스템을 상상해 보세요. 이는 인간 전문가처럼 작동합니다.\n\n이 비전은 검색 보강 생성 (RAG) 시스템의 발전 덕분에 빠른 속도로 현실이 되고 있습니다.\n\n그러나 현재의 RAG 접근법은 여러 단계를 거치는 미묘한 질의에는 여전히 어려움을 겪고 있습니다.\n\n유망한 해결책이 등장했습니다: 과적합 그래프.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n보다 풍부하고 맥락있는 지식 표현을 가능하게 함으로써, 이러한 고급 그래프 구조는 질문-답변 작업의 성능을 새로운 수준으로 끌어올리고 있어요.\n\n이 기사는 초월관계 그래프가 RAG 시스템을 혁신하고 더 지능적인 AI로 나아갈 수 있는 방법을 탐구합니다.\n\n검색을 증강한 생성은 현대 질문-답변 시스템의 중추가 되었습니다.\n\n대규모 언어 모델(Large Language Models, LLMs)의 방대한 지식을 외부 정보를 검색하고 통합하는 능력과 결합함으로써, RAG 방법론은 더 정확하고 최신의 응답을 생산하려고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 쿼리가 점점 복잡해지면 기존의 RAG 시스템이 종종 한계에 부딪힙니다.\n\n다양한 정보 간 미묘한 관계를 효과적으로 표현하는 데 어려움을 겪어 관련 없는 검색 결과와 잘못된 추론을 유발할 수 있습니다.\n\n초관계 그래프가 등장합니다. 이러한 고급 지식 구조는 간단한 주어-술어-목적어 세트를 넘어 풍부한 맥락 정보를 포착합니다. \n\n![Hyper-RelationalGraphs](/assets/img/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그렇게 함으로써 현재 RAG 시스템의 주요 한계를 많이 해결합니다.\n\n이 기사는 초관계 그래프가 RAG 성능을 크게 향상시키는 데 기여하며, 더 맥락적이고 세밀하며 효율적인 정보 검색과 추론이 가능하다고 주장합니다.\n\n이 그래프가 맥락적 표현, 쿼리 관련성 및 다중 홉 추론 기능을 향상시킴으로써 더 지능적이고 능력 있는 AI 시스템으로 나아가는 방법을 탐색해보겠습니다.\n\n# 향상된 맥락적 표현\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이퍼-관계 그래프의 핵심 기능은 풍부한 맥락 정보를 포착하고 표현하는 능력에 있습니다. 기존의 지식 그래프가 단순한 삼중 체계(예: \"파리 - 프랑스의 수도 -\")로 제한되어 있는 반면, 하이퍼-관계 그래프는 각 사실에 추가 메타데이터를 연결할 수 있습니다. 이러한 맥락 정보에는 다음이 포함될 수 있습니다:\n\n- 출처 문서: 각 정보 조각이 어디에서 기인했는지 추적\n- 시간적 한정자: 특정 사실이 사실이었던 시기 지정\n- 신뢰 점수: 추출된 정보의 신뢰성 반영\n\n이 향상된 표현은 RAG 시스템에 여러 가지 주요 이점을 제공합니다:\n\n## 향상된 모호성 해결\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이퍼-관계 그래프의 가장 중요한 장점 중 하나는 엔티티와 관계를 명확히 구별할 수 있는 능력입니다. Apple의 제품 출시에 관한 쿼리를 고려해 봅시다. 전통적인 지식 그래프에서는 \"Apple\"에 대한 언급이 모호할 수 있습니다 - 기술 회사나 과일을 가리킬 수 있습니다. 그러나 하이퍼-관계 그래프는 상황 정보를 활용하여 이 사용 사이를 구별할 수 있습니다.\n\n예를 들어, Apple의 제품 출시에 관한 사실은 기술 뉴스 소스에서 온 것임을 나타내는 메타데이터와 관련되어 있을 수 있습니다. 이 추가적인 맥락은 RAG 시스템이 이 경우에 \"Apple\"을 회사로 확신하고 해석할 수 있도록 도와줍니다. 마찬가지로, 시간적 한정자는 회사의 제품에 대한 역사적 및 현재 정보를 구별하는 데 도움이 될 수 있습니다.\n\n## 복잡한 쿼리 처리\n\n하이퍼-관계 그래프의 풍부한 맥락 표현은 복잡하고 다중 부분으로 이루어진 쿼리에 대답하는 데 특히 가치가 있습니다. \"Apple의 가장 최근 제품 출시에 대한 시장 반응이 5년 전 출시와 비교했을 때 어떻게 되었는지\"와 같은 질문을 고려해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 쿼리에 대답하기 위해서는 여러 시기와 도메인(제품 정보, 재무 데이터 등)을 종합적으로 결합해야 합니다. 하이퍼-관련 그래프는 이러한 연결된 정보 조각들을 효율적으로 표현할 수 있습니다:\n\n- 특정 날짜와 연결된 제품 출시 이벤트\n- 시간적 한정자와 관련된 주식 가격 데이터\n- 제품 출시와 시장 반응 둘 다와 연관된 뉴스 기사 및 분석 보고서\n\n이러한 관계들을 구조화된 유연한 형식으로 포착함으로써, 하이퍼-관련 그래프는 RAG 시스템이 이러한 쿼리에 답변하기 위해 필요한 복잡한 정보 공간을 더 쉽게 탐색할 수 있게 합니다.\n\n# 전통적인 지식 그래프와 비교\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이퍼-관계 그래프의 가치를 완전히 이해하기 위해서는 전통적인 지식 그래프 방식과 직접 비교하는 것이 도움이 됩니다:\n\n- 표현력: 전통적인 지식 그래프는 이진 관계에만 제한되어 있지만, 하이퍼-관계 그래프는 n-체 이상의 관계와 추가 속성을 표현할 수 있습니다. 이는 보다 미묘하고 정확한 지식 표현이 가능하게 합니다.\n- 출처 추적: 하이퍼-관계 그래프는 각 사실의 출처 정보를 쉽게 유지할 수 있습니다. 이것은 신뢰성을 평가하고 충돌하는 정보를 해결하는 데 중요한데, 이는 전통적인 지식 그래프에서는 훨씬 어려운 기능입니다.\n- 시간적 추론: 일부 전통적인 지식 그래프는 시간 정보를 통합하려고 시도해왔지만, 이는 종종 구조에 통합되기보다는 마무리된 느낌을 줍니다. 하이퍼-관계 그래프는 시간적 추론을 지식 표현의 핵심 부분으로 만듭니다.\n- 확신과 불확실성: 하이퍼-관계 그래프는 사실과 함께 신뢰도 점수나 확률 분포를 연관시킴으로써 불확실성과 충돌 정보를 자연스럽게 표현할 수 있습니다. 이러한 세밀한 접근은 전통적인 지식 그래프 구조에서 어렵게 구현할 수 있습니다.\n\n제공된 연구에서 소개된 HOLMES 시스템은 실제로 이러한 이점을 실천적으로 시연하고 있습니다. 하이퍼-관계 그래프 구조를 활용하여 HOLMES는 전통적인 지식 표현을 사용하는 시스템과 비교하여 다중 점프 질문 답변 작업에서 상당한 성능 향상을 이뤘습니다.\n\n# 질의 의미와 효율 향상\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지식 표현을 향상시키는 것을 넘어서, 초 관계 그래프는 RAG 시스템 내에서 더 명확하고 효율적인 정보 검색을 가능케 합니다. 이런 개선은 두 가지 주요 영역에서 나타납니다: 쿼리 관련성의 증가와 계산 오버헤드의 감소.\n\n## 더 명확한 정보 검색\n\n초 관계 그래프의 풍부한 구조는 쿼리와 관련 정보 간 보다 정확한 일치를 가능케 합니다. 전통적인 RAG 시스템은 종종 키워드 일치 또는 임베딩 유사성에 의존하여 잠재적으로 관련 있는 단락을 검색합니다. 단순한 쿼리에 대해 효과적이지만, 이러한 접근은 더 복잡한, 멀티-홉 질문에 어려움을 겪을 수 있습니다.\n\n이와 달리 초 관계 그래프는 시스템이 엔티티 간의 관계를 탐색하면서 인간의 추론에 더 가까운 방식으로 진행할 수 있도록 합니다. 예를 들어, \"2008 금융 위기가 유럽의 재생 에너지 투자에 미친 영향은 무엇입니까?\"와 같은 쿼리를 고려해 봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n초위계 그래프는 검색 프로세스를 안내하는 데 도움을 줄 수 있습니다:\n\n- 핵심 개체 식별: \"2008 금융위기\", \"재생 에너지\", \"유럽\"\n- 관련 관계 탐색: 금융 사건 - 경제적 영향 - 산업 부문 - 지리적 지역\n- 적절한 시기에 초점을 맞추기 위해 시간 정보 활용\n\n이 구조화된 접근 방식은 관련 검색 결과를 보다 정확하게 제공하여 잡음을 줄이고 언어 모델에 제공되는 정보의 품질을 개선합니다.\n\n## 가지치기 프로세스\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이퍼-관계 그래프가 제공하는 가장 중요한 효율성 향상 중 하나는 관련 없는 정보를 지능적으로 제거할 수 있는 능력에서 옵니다. HOLMES 시스템은 이 과정을 효과적으로 보여주고 있습니다.\n\n- 쿼리에 맞춘 지식 스키마: 시스템은 특정 쿼리를 기반으로 스키마를 구성하고, 쿼리와 관련이 있을 것으로 예상되는 엔티티 및 관계 유형을 식별합니다.\n- 보조 그래프 스키마: 이는 도메인 내 질문 집합에서 파생된 미리 계산된 스키마와 결합되어, 필요한 정보 유형의 일반적인 패턴을 포착합니다.\n- 관련성 점수 매기기: 그래프 요소는 결합된 스키마와의 일치에 따라 점수가 매겨집니다.\n- 제거: 가장 높은 점수를 가진 요소만 유지되어, 쿼리에 매우 관련성이 높은 초점을 맞춘 하위 그래프가 생성됩니다.\n\n이 시도 과정은 최종 생성 단계에서 언어 모델이 처리해야 하는 정보 양을 대폭 줄입니다. HOLMES 실험에서는 다른 최첨단 방법과 비교해 최대 67%의 입력 토큰 감소를 이끌어냈습니다 [1].\n\n## 성능 개선\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이퍼-관계 그래프에서 얻게 되는 효율성 향상은 벤치마크 데이터셋에서 성능 향상으로 직접 이어집니다. 다중 홉 질문 응답을 위한 널리 사용되는 벤치마크인 HotpotQA 데이터셋에서 HOLMES는 다음을 달성했습니다:\n\n- 0.66의 정확 일치 (EM) 점수 (이전 최고 수준 대비 20% 향상)\n- 0.78의 F1 점수\n\n이와 유사한 향상이 이해력이 2~4번 이어지는 질문에 중점을 둔 MuSiQue 데이터셋에서도 보여졌습니다:\n\n- 이전 최고 방법과 비교해 EM 점수가 26% 증가했습니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이런 양적 개선은 HOLMES가 기존 방법에 비해 답변 품질에서 더 높은 점수를 받았다는 인간 평가로 뒷받침되었습니다 [1].\n\n입력 토큰의 급격한 감소와 함께 향상된 답변 품질은 하이퍼-관계 그래프의 힘을 보여주며 RAG 시스템의 효율성과 효과성을 향상시킬 수 있다는 것을 입증합니다.\n\n# 다단계 추론 능력 발전\n\n하이퍼-관계 그래프의 가장 흥미로운 잠재력은 고급 다단계 추론을 지원하는 능력에 있습니다. 이 능력은 여러 소스에서 정보를 종합하거나 논리적 연쇄를 따라야 하는 복잡한 질문에 대답하는 데 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 다단계 추론 지원\n\n하이퍼-관계 그래프는 다단계 추론 프로세스와 자연스럽게 일치하는 구조를 제공합니다. 복잡한 질문에 대해 인간 전문가가 어떻게 대답할지를 생각해보세요:\n\n- 주요 개체와 개념 식별\n- 해당 개체에 대한 관련 사실 상기\n- 사실 간의 논리적 연결 따르기\n- 정보를 종합하여 결론 도출\n\n하이퍼-관계 그래프는 RAG 시스템이 이전보다 더 가까이 이 프로세스를 모방할 수 있도록 합니다. 그래프 구조를 통해 시스템이 다음을 할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 질의에서 시드 엔티티로 시작합니다\n- 관련 있는 관계를 통해 연결된 정보를 발견합니다\n- 맥락 메타데이터를 사용하여 각 정보의 관련성과 신뢰성을 평가합니다\n- 그래프를 통해 경로를 따라 추론 체인을 구성합니다\n\n이 구조화된 방식은 여러 논리적 단계가 필요한 질문에 특히 가치 있습니다. 예를 들어, “'인셉션’의 주연 배우가 아카데미상을 수상한 후해방 판매된 영화의 감독은 누구입니까?”\n\n이 질문에 답하기 위해 다음이 필요합니다:\n\n- “인셉션”의 주연 배우 식별\n- 그들이 아카데미상을 수상한 때 결정\n- 다음 해에 출시된 최고 수익 영화 찾기\n- 해당 영화의 감독 식별\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이퍼-관계 그래프는 이러한 모든 연결을 나타낼 수 있어서 RAG 시스템이 필요한 정보를 효율적으로 탐색할 수 있게 해줍니다.\n\n## 시간 정보 처리 개선\n\n많은 복잡한 쿼리는 서로 다른 시간 범위를 걸쳐 이벤트와 사실에 대해 추론하는 것을 포함합니다. 하이퍼-관계 그래프는 시간 정보를 효과적으로 나타내고 추론할 수 있습니다:\n\n- 사실을 특정 시점이나 범위에 연관시킬 수 있습니다.\n- 이벤트 간 관계를 명시적으로 모델링할 수 있습니다 (예: \"이전에 발생한\", \"동안에 발생한\").\n- 사실이 시간에 따라 변하는 것을 효율적으로 나타낼 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 시간적인 인식력 덕분에 RAG 시스템은 \"합병 이후 몇 년간 회사의 전략이 어떻게 변화했습니까?\"와 같은 쿼리를 더 정확하고 세밀하게 처리할 수 있습니다.\n\n## 상반된 정보 해결\n\n실제 세계의 지식 베이스에서는 서로 다른 출처에서 상반된 정보를 만나는 것이 흔합니다. Hyper-relational 그래프는 이러한 갈등을 나타내고 이에 대해 추론하는 메커니즘을 제공합니다:\n\n- 사실의 여러 버전을 소스 정보와 함께 저장할 수 있습니다.\n- 다른 주장에 확신 점수를 할당할 수 있습니다.\n- 시간적 한정자가 외견적인 모순을 해결하는 데 도움이 될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n정보가 충돌할 때 RAG 시스템은 다음과 같은 기능을 활용할 수 있어요:\n\n- 충돌 식별\n- 다양한 소스의 신뢰성 평가\n- 시간적 맥락 고려\n- 필요한 경우 불확실성을 인정하는 섬세한 답변 제시\n\n이 접근 방식은 더 견고하고 신뢰할 수 있는 질문 응답 능력으로 이어져요.\n\n## 향상된 설명력\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 시스템에서 하이퍼-관계 그래프를 사용하는 주요 이점 중 하나는 개선된 설명 가능성의 가능성입니다. 그래프의 구조화된 성격은 시스템이 다음을 할 수 있도록 합니다:\n\n- 답변에 이르기까지 사용된 추론 경로를 추적\n- 활용된 구체적인 사실 및 관계 식별\n- 각 정보 조각에 대한 명확한 출처 제공\n\n이 설명 가능성은 시스템 출력에 대한 신뢰를 구축하는 데 뿐만 아니라 기본 모델을 디버깅하고 개선하는 데도 유용합니다. 연구원과 개발자는 추론 경로를 분석하여 시스템이 우수하거나 어려움을 겪는 부분을 식별하고 특정 개선 사항을 찾을 수 있습니다.\n\nHOLMES 시스템은 이 설명 가능성의 잠재력을 보여줍니다. 다양한 쿼리에 대해 생성된 가지치기된 하위 그래프를 조사함으로써 연구원들은 시스템이 다양한 유형의 질문에 접근하는 방식에 대한 통찰을 얻을 수 있었습니다. [1]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n하이퍼-관계 그래프는 RAG 시스템의 발전에서 중요한 획을 달성했습니다. 보다 풍부한 맥락 표현, 더 명확한 정보 검색, 그리고 고급 다중 점프 추론 능력을 통해 이러한 구조는 현재 방식에서 겪는 주요 제약 사항을 해결합니다.\n\n하이퍼-관계 그래프의 장점은 성능 지표의 향상 이상을 제공합니다. 이들은 RAG 시스템이 다음을 할 수 있도록 합니다:\n\n- 더 복잡하고 미묘한 쿼리 처리\n- 보다 맥락적으로 적절한 답변 제공\n- 보다 큰 투명성과 설명 가능성 제공\n- 관련 정보에 중점을 두어 더 효율적으로 작동하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 발전은 자연어 처리 및 인공 지능 분야에 매우 중요한 영향을 미치고 있습니다. 더 강력한 질의응답 시스템은 다음을 향상시킬 수 있습니다:\n\n- 정보 검색 및 지식 관리\n- 의사 결정 지원 시스템\n- 지능형 지도 및 교육 플랫폼\n- 연구 및 과학 발견 도구\n\n미래를 바라볼 때, 몇 가지 주요 질문과 연구 방향이 나타납니다:\n\n- 확장성: 어떻게 하면 거대한 지식 베이스를 위해 하이퍼-관계 그래프를 효율적으로 구축하고 업데이트할 수 있을까요?\n- 신경망 접근과의 통합: 하이퍼-관계 그래프를 신경망 검색 및 추론 방법과 어떻게 효과적으로 결합할 수 있을까요?\n- 교차 영역 추론: 하이퍼-관계 그래프를 활용하여 여러 지식 영역을 걸쳐 추론하는 데 어떻게 기여할 수 있을까요?\n- 대화형 시스템: 하이퍼-관계 그래프를 통해 보다 동적이고 다중 턴의 질의응답 상호작용을 가능하게 할 수 있을까요?\n- 윤리적 고려사항: 이러한 시스템의 향상된 기능이 책임있게 사용되고 지식 표현의 잠재적 편향이 해결되는 방법은 무엇일까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n연구자들이 이러한 문제들을 계속 탐구함에 따라 한 가지는 분명합니다: 과잉관계 그래프는 다음 세대 지식 질문 응답 시스템에서 중요한 역할을 할 것으로 예상됩니다. 더 세밀하고 맥락적인 지식 표현을 제공함으로써, 이러한 그래프는 복잡한 주제에 대해 인간과 유사한 유연성과 심도로 추론할 수 있는 AI 시스템에 한 걸음 더 가까워지게 합니다.\n\n# 참고 문헌:\n\n[1] Panda, P., Agarwal, A., Devaguptapu, C., Kaul, M., \u0026 Prathosh, A. P. (2024). HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs. arXiv preprint.","ogImage":{"url":"/assets/img/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems_0.png"},"coverImage":"/assets/img/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems_0.png","tag":["Tech"],"readingTime":9},{"title":"당신을 치유한 사람들에 의해 다시 상처받는 경험","description":"","date":"2024-06-23 18:54","slug":"2024-06-23-Beingbrokenbythepeoplethatalsohealedyou","content":"\n\n![image](/assets/img/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou_0.png)\n\n와 미친 소리 아니야? 너가 잃을 수 있는 모든 인간 중에서, 널 부술 수도 있는 사람이 누군가가, 그게 바로 너를 완전히 해 주었던 사람들이 너를 부술 수도 있다는 게 웃기게 느껴지지 않니? 결국 널 텅 빈 채로 남기고.\n\n누군가에게 완전히 의존할 때가 가장 힘들어. 모든 것을 걸면, 그만큼 많은 것을 잃을 가능성도 높아지거든. 이 모든 것이 그만한 가치가 있었나 하는 질문이 계속 머릿속을 스쳐 지나가게 되는데, 자기가 왜 이 순간을 겪어야 하는지, 어디서부터 잘못되기 시작했는지, 단순히 언제부터 그랬는지에 대해 밤에 울고만 있게 되는 거야. 그들과 함께 있을 때 행복했던 것을 기억하게 돼. 모든 게 진심이었고, 그들이 충분했기에 남들과는 달랐어. 그러나, 인생이 닥쳐왔지. 이렇게 귀에 착착 오게 하잖아, 사람들이 와서 가기도 하고. 가장 힘든 건, 그것이 찾아올 때 예상치 못한다는 거야. 혹은 예상했다 하더라도, 상처를 주고 너를 완전히 꺾어버리겠지. 단지 아무것도 남기지 않을 거야.\n\n\"그런 게 현실이야\"가 널 위로해 줄 거지만, 동시에 네가 가장 싫어하는 말이 될 거야.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n열심히 노력할 것이에요. 자신을 달래기 위해 그들을 잊으려고 모든 사진을 삭제하고 그들이 선물한 모든 것을 버릴 거예요. 하지만 치유하는 여정 속에서 어딘가에 그 모든 것이 무너지는 순간들이 있을 거예요. 왜냐하면 당신이 깊은 곳에 그들을 담아두었기 때문이죠. \n\n같은 사람 속에서는 같은 사람을 찾을 수 없다는 것도 사실이에요. 노력해봐도 마찬가지일 거예요. 다른 사람들과 같은 종류의 관계를 찾을 거예요, 하지만 찾지 못할 거예요. 그냥 그렇다고.\n\n이 모든 일 가운데서, 당신은 잘못된 것이 어디서 왜 그렇게 되었는지 되돌아보는 시간을 가질 거예요. 마침내 그들이 한 잘못된 행동들, 당신이 그들이 당신의 한계를 초과하는 행동을 허용했던 모든 시간, 그리고 당신이 그 문제를 해결하기 위해 울던 고통스러운 밤들을 볼 수 있을 거예요. 또한 당신의 모든 흠과 변화하려는 이유들, 마침내 자신을 받아들이려고 하거나 그 고통을 인정하기 위해 노력할 이유들도 보게 될 거예요.\n\n처음에 그들을 고치려고 했지만, 꼭 그들만큼 고쳐야 할 필요성이 있는 것을 알지 못했어요. 당신이 직면해야 할 고치기가 필요한 사람을 치유할 수 없다는 것을 우리 모두 알고 있어요.\n\n이상하게도 당신은 당신과 함께하길 원하는 많은 사람들, 당신의 안락함이 되고 싶어하는 모든 사람들을 볼 거예요. 그런데 당신은 돌아가 그 속에 담겨있는 그들과 같은 사람들과 느낌을 찾을 수 있도록 고의적으로 쳐다보지 않았던 사람들 역시 볼 거예요.\n\n좋은 점은 몇몇 사람이 떠나면 새로운 사람들도 올 거라는 거에요. 다른 성격을 가진 다른 사람일 수도 있겠지만, 당신의 마음 속 어딘가에서 그들은 당신에게 위안이 될 거에요. 그들이 이전에 함께한 익숙한 사람들과 공유했던 행복과 웃음을 가져다 주지는 않겠지만, 당신이 정말 필요로 하는 안정감을 줄 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수용은 부서에서 나오게 될 것입니다; 이를 어떻게 받아들이고 계속 헤엄치는 법을 배우게 될 거에요.\n\n언젠가는 괜찮아질 거에요 (정말로). 이 중요한 점은, 눈 깜짝할 사이에 지나가는 행복한 날들이 있듯이, 휙 훌쩍 지나가는 슬픈 날들도 있단 거죠.\n\n-\n\n이 글에는 제 생각과 경험이 담겨 있고, 이를 통해 여러분에게 \"놓아주고, 평화롭게 살아가\"라고 자랑스럽게 전할 수 있는 누군가의 따뜻함을 느끼게 해주기를 바랍니다. 왜냐하면 나도 어느 날 그것이 필요했었기 때문이죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두려워하는 모든 분들에게 포옹을 보내요. 언젠가는 모든 것이 이해될 거에요 :))\n\n그런데 이게 제 첫 번째로 작품을 공개하는 시도에요. 제게 어떻게든 연결되었으면 좋겠어요.","ogImage":{"url":"/assets/img/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou_0.png"},"coverImage":"/assets/img/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou_0.png","tag":["Tech"],"readingTime":3},{"title":"컨볼루션 신경망CNN의 수학적 원리 분석","description":"","date":"2024-06-23 18:50","slug":"2024-06-23-TheMathBehindConvolutionalNeuralNetworks","content":"\n\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png)\n\n목차\n\n- 1: 소개\n- 2: CNN 아키텍처 뒤의 수학\n  - 2.1: 합성곱층\n  - 2.2: 스트라이드\n  - 2.3: 패딩\n  - 2.4: 다중 필터 및 깊이\n  - 2.5: 가중치 공유\n  - 2.6: 특성 맵 생성\n  - 2.7: 풀링층\n  - 2.8: 완전 연결층\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 3: CNN 구축을 위한 단계별 안내\n  - 3.1: 환경 설정\n  - 3.2: 데이터 준비\n  - 3.3: CNN 모델 설계\n  - 3.4: 모델 컴파일\n  - 3.5: CNN 훈련\n\n- 4: 모델 성능 향상\n  - 4.1: 데이터 증강\n  - 4.2: 드롭아웃\n  - 4.3: 배치 정규화\n  - 4.4: 전이 학습\n\n- 5: 결론\n\n- 추가 자료\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1: 소개\n\n합성곱 신경망, 또는 CNN(Convoluntional Neural Networks)라고도 불리는 것은 이미지 처리와 관련된 작업에서 중요한 역할을 합니다. 사진 인식이나 분류와 같이 이미지와 관련된 작업을 할 때 매우 유용합니다. 그들은 사진의 패턴과 세부 사항을 자동으로 감지하는 데 아주 뛰어나기 때문에 많은 이미지를 처리하는 프로젝트에서 선호되는 선택입니다.\n\nCNN의 멋진 점은 이미지 데이터를 단순히 한 덩어리로 뭉치는 것이 아니라 이미지의 레이아웃을 유지한다는 것입니다. 이는 특정 패턴과 해당 위치를 잘 알아차릴 수 있어서 매우 유용합니다. 이 접근 방식은 이미지 처리의 어려운 부분을 훨씬 더 부드럽게 처리할 수 있도록 해줍니다.\n\nCNN의 중요한 부분 중 하나는 합성곱 레이어라는 것입니다. 이 레이어는 이미지 위를 이동하면서 선, 질감, 형태와 같은 다양한 시각적 특징을 발견할 수 있습니다. 이는 사람이 그러한 특징들을 수동으로 찾아야 했던 예전 방식을 능가합니다. 이는 작업 처리를 느리게 하고 처리 과정에서 병목현상을 야기시켰던 것과 대조됩니다. 네트워크가 스스로 이러한 특징을 찾아내도록 함으로써 CNN은 더 정확해지고, 더 단순해지며, 그리고 더 큰 범위의 이미지 관련 작업에 수월하게 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2: CNN 아키텍처 뒤의 수학\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_1.png)\n\n합성곱 신경망(CNNs)의 아키텍처는 인간의 시각 시스템이 이미지를 처리하는 방식을 모방하도록 설계되어 있어 시각 인식 및 분류와 관련된 작업에 특히 강력합니다.\n\nCNN은 여러 유형의 레이어로 구성되어 있으며, 각 레이어는 이미지 인식 과정에서 특정 기능을 제공합니다. 주요 레이어에는 합성곱 레이어, 활성화 함수, 풀링 레이어 및 완전 연결 레이어가 포함됩니다. 이 레이어들이 함께 작동하여 CNN이 특징을 감지하고 복잡성을 줄이며 예측을 수행할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.1: 합성곱층\n\n합성곱층은 합성곱 신경망(CNN)의 중요한 요소로, 이미지로부터 가장자리, 질감, 모양과 같은 공간적인 특징을 자동적으로 효율적으로 추출하는 데 사용됩니다. 우리는 합성곱층이 작동하는 방식 및 내부 수학에 대해 자세히 알아보겠습니다.\n\n합성곱 연산\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성 곱 연산의 본질은 입력 이미지 위를 필터(또는 커널)가 슬라이딩하면서 각 위치에서 필터 값과 원래 픽셀 값의 내적을 계산하는 것입니다. 필터는 일반적으로 3x3 또는 5x5 크기의 작은 가중치 행렬로, 이미지에서 특정 피쳐를 감지하기 위해 훈련됩니다.\n\n수학적으로, 합성 곱 연산은 다음과 같이 표현될 수 있습니다:\n\n![convolution equation](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_3.png)\n\n여기서:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- S(i,j)은 출력 피처 맵입니다.\n- I는 입력 이미지입니다.\n- K는 커널 또는 필터입니다.\n- i,j는 피처 맵 상의 좌표입니다.\n- m,n은 커널 내의 좌표입니다.\n- ∗는 합성곱 연산을 나타냅니다.\n\n이 방정식은 출력 피처 맵의 각 요소 S(i,j)가 커널 K와 현재 위치한 입력 이미지 I의 일부 사이의 요소별 곱의 합임을 알려줍니다.\n\n이제 입력 이미지로 사용될 픽셀 값 행렬을 고려해 봅시다. 그것이 흑백 이미지인 경우 (위 이미지), 행렬은 단일 레이어를 가지게 될 것입니다. 컬러 이미지의 경우에는 일반적으로 세 개의 레이어 (RGB)가 있지만, 연산은 각 레이어마다 별도로 수행됩니다.\n\n합성곱 연산은 행렬에 커널(필터)을 적용합니다. 여기서 커널은 입력 이미지보다 작은 다차원 행렬이며 사전에 정의된 차원 (예: 3x3)을 가지고 있습니다. 이 행렬의 값은 훈련 과정 중에 학습되는 가중치입니다. 커널은 입력 이미지 전체를 걸어다니면서 요소별 곱셈을 수행하고 합을 구합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨볼류션 연산에서는 출력 특성 맵을 얻게 됩니다. 이는 커널이 입력 이미지의 특정 위치에서 감지한 특징의 존재와 강도를 나타내는 새로운 행렬입니다.\n\n## 2.2: 스트라이드\n\n![스트라이드](https://miro.medium.com/v2/resize:fit:1280/1*OlE3bnC0WaYt3wW1dlcMdA.gif)\n\n스트라이드는 CNN 아키텍처에서 중요한 개념입니다. 특히 컨볼루션 레이어 내에서 핵심적으로 작용합니다. 이는 커널이 입력 이미지나 특성 맵을 횡단하는 방식에 근본적인 영향을 미칩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStride는 필터가 입력 이미지나 피쳐 맵을 한 단계씩 이동하는 픽셀 수를 나타냅니다. 수평 및 수직으로 모두 적용됩니다. Stride가 1이면 필터가 한 번에 한 픽셀씩 이동하여 입력을 자세하고 밀도 있게 스캔합니다. 더 큰 Stride는 필터가 픽셀을 건너뛰며 입력을 스캔하므로 더 넓고 밀도가 낮은 범위로 이어집니다.\n\nStride는 출력 피쳐 맵의 차원을 결정하는 데 직접적인 역할을 합니다:\n\n- Stride가 1인 경우: 필터가 모든 픽셀을 횡단하여 출력 피쳐 맵이 패딩에 따라 상대적으로 크거나 입력과 유사한 크기가 될 수 있습니다. 패딩에 대해 다음 섹션에서 설명하겠습니다.\n- 더 큰 Stride인 경우: 필터가 픽셀을 건너뛰면 입력을 적은 단계로 이동합니다. 이로 인해 출력 피쳐 맵이 작아지며 각 단계에서 필터가 적용되는 위치 간의 오버랩이 적어집니다.\n\n수학적 표현\n출력 피쳐 맵의 크기 (W_out, H_out)는 입력 크기 (W_in, H_in), 필터 크기 (F), Stride (S), 패딩 (P)을 사용하여 다음 공식을 사용하여 계산할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_4.png\" /\u003e\n\n여기서:\n\n- W_out 및 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\n- W_in 및 H_in은 각각 입력의 너비와 높이입니다.\n- F는 필터의 크기입니다.\n- S는 스트라이드입니다.\n- P는 패딩입니다.\n\n더 큰 스트라이드는 필터의 각 응용 영역의 시야를 증가시켜 네트워크가 더 적은 매개변수로 입력의 더 많은 전역적인 특성을 포착할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사용하는 스트라이드를 크게 하면 출력 특성 맵의 크기를 줄이기 때문에 계산 부하와 메모리 사용량이 감소하며, 따라서 필요한 합성 곱 연산 수도 줄어듭니다.\n\n공간 해상도와 커버리지 사이에는 교환관계가 있습니다. 작은 스트라이드는 공간 해상도를 보존하고 섬세한 특징을 탐지하는 데 더 좋지만, 큰 스트라이드는 디테일을 희생하면서 입력의 넓은 영역을 다룰 수 있습니다.\n\n## 2.3: 패딩\n\n패딩은 출력 특성 맵의 공간적 차원을 조절하여 네트워크의 아키텍처를 형성하는 데 중요한 역할을 합니다.\n합성 곱 연산을 적용하기 전에 입력 이미지나 특성 맵의 가장자리 주위에 제로(또는 다른 값들이지만 일반적으로 제로입니다)의 레이어를 추가하는 것을 포함합니다. 이 기법은 다양한 이유로 적용될 수 있으며, 가장 중요한 이유는 출력 특성 맵의 크기를 제어하고 합성 곱 필터가 입력의 가장자리 픽셀에 접근할 수 있도록 하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 이제 우리의 입력 이미지는 다음과 같이 보일 것입니다:\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1280/1*VwOf7sD87Yw9P1215NngRQ.gif\" /\u003e\n\n이전의 8x8 행렬이 이제 10x10 행렬로 바뀐 것을 볼 수 있습니다. 우리는 주변에 0으로 된 레이어를 추가했기 때문입니다.\n\n패딩이 없으면 각 합성곱 연산이 피처 맵의 크기를 줄입니다. 패딩을 사용하면 입력에 필터를 적용하여 공간적 차원을 줄이지 않고 더 많은 정보를 보존할 수 있습니다. 특히 많은 합성곱 계층이 순차적으로 적용되는 심층 네트워크에서 더 많은 정보를 보존할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n입력을 패딩함으로써 필터가 이미지의 가장자리 픽셀을 적절하게 처리하여 네트워크의 학습 과정에서 경계에 위치한 특징을 충분히 캡처하고 활용할 수 있습니다.\n\n패딩에는 주로 두 가지 유형이 있습니다:\n\n**Valid Padding (패딩 없음)**\n이 경우 입력에 패딩이 적용되지 않습니다. 필터가 입력의 한계 내에 완전히 맞는 곳에서만 합성곱 작업이 수행됩니다. 이로 인해 일반적으로 출력 피처 맵 크기가 줄어듭니다.\n\n**Same Padding (동일 패딩)**\n동일 패딩의 경우 입력 가장자리에 충분한 수의 제로(0)가 추가되어 출력 피처 맵이 입력과 동일한 차원을 갖도록 합니다(스트라이드가 1인 경우). 이는 입력과 출력 크기가 일관성 있게 유지되어야 하는 네트워크를 설계하는 데 특히 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장자리에 패딩을 추가하는 것이 출력 특성 맵 크기에 미치는 영향은 출력 특성 맵의 차원을 계산하는 데 사용되는 공식을 조정함으로써 파악할 수 있습니다:\n\n\nW_out = (W_in - F + 2P) / S + 1\nH_out = (H_in - F + 2P) / S + 1\n\n\n여기서:\n\n- W_out과 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\n- W_in과 H_in은 각각 입력의 너비와 높이입니다.\n- F는 필터/커널의 크기입니다.\n- S는 스트라이드입니다.\n- P는 입력의 각 측면에 추가된 패딩의 양입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n패딩은 층을 통해 입력의 공간 차원을 유지하는 데 도움이 됩니다. 그러나 과도한 패딩은 계산의 비효율성을 야기하고 모델의 복잡성이 증가할 수 있습니다. 비의미 있는 입력(제로)을 계산에 추가함으로써 비효율성을 가져올 수 있습니다.\n\n유효 패딩과 동일 패딩 사이의 선택은 주로 응용 프로그램의 특정 요구 사항에 따라 달라지며, 입력의 공간 차원을 보존하는 중요성이나 계산 오버헤드를 최소화해야 하는 필요성에 따라 결정됩니다.\n\n## 2.4: 다중 필터와 깊이\n\nCNN은 각 합성곱 층에서 여러 필터를 사용하여 입력 이미지나 특징 맵에서 다양한 특징을 캡처합니다. 이 다양성과 깊이는 네트워크가 시각 정보를 포괄적이고 세심하게 처리할 수 있는 능력에 중요한 역할을 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨볼루션 레이어의 각 필터는 입력에서 엣지, 색상, 질감 또는 더 깊은 레이어에서는 더 복잡한 모양과 같은 다양한 특징이나 패턴을 감지하도록 설계되어 있습니다. 여러 필터를 사용함으로써 CNN은 각 레이어에서 동시에 다양한 특징을 찾아 입력 데이터의 표현을 보다 풍부하게 만들 수 있습니다.\n\n여러 필터를 사용한 컨볼루션 레이어의 출력은 각 필터에 대해 하나의 특징 맵으로 이루어진 스택입니다. 이 스택은 깊이가 사용된 필터의 수와 대응되는 3차원 볼륨을 형성합니다. 이 깊이는 데이터의 계층적인 표현을 구축하는 데 중요하며, 이전 레이어의 출력을 결합하여 점점 추상적인 특징을 감지할 수 있게 합니다.\n\n여러 필터가 깊이를 어떻게 실현하는가\n입력 이미지 또는 특징 맵이 처리됨에 따라 각 필터는 이를 슬라이딩하여 컨볼루션 작업을 수행합니다. 동일한 입력을 공유하더라도 각 필터는 고유한 가중치를 적용하여 서로 다른 측면을 강조하는 서로 다른 특징 맵을 생성합니다.\n\n각 필터가 생성한 개별 특징 맵은 깊이 차원을 따라 쌓이며, 3D 볼륨을 형성합니다. 이 볼륨은 필터에 의해 감지된 다양한 특징을 포용하여 입력의 풍부하고 다면적인 표현을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성곱 레이어의 깊이는 필터의 수에 의해 결정되며, 네트워크가 넓은 특징 스펙트럼을 포착할 수 있게 합니다. 초기 레이어는 가장자리와 질감과 같은 기본적인 특징을 포착할 수 있지만, 더 깊은 레이어는 이러한 기본적인 특징을 결합하여 복잡한 패턴을 해석할 수 있게 되며, 이는 네트워크의 깊이 덕분입니다.\n\n깊이의 영향\n더 많은 필터는 복잡한 특징을 학습할 수 있는 용량이 높은 더 깊은 네트워크를 의미합니다. 그러나 이는 또한 네트워크의 계산 복잡성과 효과적으로 학습하기 위해 필요한 데이터 양을 증가시킵니다.\n\n각 필터는 모델에 매개변수를 추가합니다(필터를 정의하는 가중치). 더 많은 필터는 네트워크의 표현력을 높이지만, 총 매개변수 수를 증가시켜 학습 효율성과 과적합의 위험에 영향을 미칠 수 있습니다.\n\n레이어 간 필터 할당은 전략적입니다. 입력에 가까운 레이어는 더 적고 일반적인 필터를 가질 수 있지만, 더 깊은 레이어는 데이터 내에서 고차원 특징의 복잡성과 변이를 포착하기 위해 더 많은 필터를 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.5: Weight Sharing\n\nWeight sharing(가중치 공유)는 특히 시각적 정보를 처리할 때 CNN의 효율성과 효과를 현저히 향상시킵니다. 이 개념은 모델이 입력 이미지의 공간적 위치와 관계없이 특징을 감지할 수 있도록 핵심적입니다.\n\nCNN의 맥락에서, 가중치 공유란 동일한 필터(즉, 동일한 가중치 세트)를 전체 입력 이미지나 특징 맵에 걸쳐 사용하는 것을 의미합니다. 모든 가능한 위치에 대해 고유한 가중치 세트를 학습하는 대신 단일 필터가 전체 이미지를 스캔하며 각 위치에서 동일한 가중치를 적용합니다. 이 작업은 합성곱 레이어의 각 필터에서 반복됩니다.\n\n입력 이미지의 서로 다른 부분에서 동일한 가중치 세트를 재사용함으로써, 가중치 공유는 모델의 매개변수 수를 급격하게 줄입니다. 이로 인해 CNN은 특히 큰 입력 크기를 다룰 때 완전히 연결된 네트워크에 비해 매개변수 효율성이 훨씬 뛰어납니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWeight sharing은 네트워크가 입력 이미지의 위치에 관계없이 특징을 감지할 수 있도록 합니다. 필터가 에지나 특정 패턴을 인식하는 방법을 학습하면 이미지의 어느 곳에서든 해당 특징을 감지할 수 있으므로 CNN은 기본적으로 변환 불변성을 갖습니다.\n\n학습할 매개변수가 적어지므로, CNN은 학습 데이터에 과적합될 가능성이 적어집니다. 이는 모델이 학습 데이터에서 실제로 관측되는 데이터로 일반화하는 능력을 향상시킴으로써, 실제 과제에서의 성능을 향상시킵니다.\n\nWeight Sharing 작동 방식\n순방향 전파 중에, 고정된 가중치 세트를 가진 필터가 입력 이미지를 슬라이드하며, 필터 가중치와 이미지의 지역 영역 간의 내적을 계산합니다. 이 과정은 이미지의 공간적 범위에 걸쳐 감지된 특징의 존재 및 강도를 나타내는 특징 맵을 생성합니다.\n\n공간적 영역 전체에 걸쳐 가중치를 광범위하게 재사용하지만, 각각의 가중치는 적용된 위치의 모든 위치에서의 총 그래디언트를 기반으로 업데이트됩니다. 이를 통해 필터 가중치가 작업에 가장 관련성 있는 특징을 감지하도록 최적화되어, 전체 데이터셋을 기반으로 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.6: 피처 맵 생성\n\n이전에 보았던 대로, 피처 맵은 CNN 내에서 입력 이미지나 이전 피처 맵에 필터나 커널을 적용하여 생성된 출력입니다. 입력의 공간 차원에 걸쳐 필터의 반응을 나타내며, 이미지에서 특정 피처가 어디에 어떻게 감지되었는지를 강조합니다. 이제 각 요소가 어떻게 CNN의 결과 피처 맵에 영향을 미치는지 다시 살펴봅시다.\n\n피처 맵 생성의 핵심은 컨볼루션 연산에 있습니다. 여기서 학습된 가중치를 가진 필터가 입력 이미지나 이전 레이어의 피처 맵을 이전하며 슬라이딩(또는 합성)합니다. 각 위치에서 필터는 이미지의 해당 부분과 요소별 곱셈을 수행하고 결과를 합산하여 새로운 피처 맵의 단일 출력 픽셀을 생성합니다.\n\n필터의 가중치는 엣지, 질감 또는 더 깊은 레이어에서 더 복잡한 패턴과 같은 피처 유형을 감지합니다. 훈련 중에 이 가중치는 역전파를 통해 조정되어 네트워크가 주어진 작업에 가장 중요한 피처를 학습할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스트라이드의 크기와 패딩의 사용은 특징 맵의 공간적 차원에 직접적인 영향을 미칩니다. 더 큰 스트라이드는 필터 적용 사이의 중첩을 줄이는 보다 넓은 범위의 적용을 유도하여 특징 맵의 크기를 줄입니다. 패딩은 입력의 공간적 차원을 보존하기 위해 사용되며 이미지의 가장자리에 있는 특징이 손실되지 않도록 보장합니다.\n\n합성곱 레이어는 일반적으로 여러 필터를 포함하며, 각각은 다른 특징을 감지하도록 설계됩니다. 각 필터의 출력은 별도의 특징 맵이며, 이러한 특징 맵은 깊이 차원을 따라 쌓여 3차원 볼륨을 만듭니다. 이 다각적인 방식은 네트워크가 입력 이미지의 풍부한 표현을 포착할 수 있도록 합니다.\n\n합성곱 작업을 통해 특징 맵이 생성된 후에는 주로 ReLU와 같은 활성화 함수를 통과합니다. 이는 비선형성을 도입하여 네트워크가 보다 복잡한 패턴을 학습하고 표현할 수 있게 합니다.\n\nReLU와 다른 활성화 함수에 대해 더 알고 싶다면, 이 기사를 확인해보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n활성화된 피처 맵은 다음 계층 또는 풀링 작업으로 진행됩니다.\n\n## 2.7: 풀링 레이어\n\n풀링 레이어는 피처 맵의 공간 차원을 줄이는 역할을 합니다. 이 감소는 계산 부하를 줄이고, 오버피팅을 최소화하며, 가장 중요한 정보만을 보존하는 데 중요합니다. 풀링 레이어의 구체적인 내용, 유형 및 CNN 성능에 미치는 영향에 대해 알아봅시다.\n\n풀링 레이어는 피처 맵의 크기를 줄여 망에 필요한 매개변수 및 계산을 줄입니다. 이 간소화는 가장 중요한 특성에 집중하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특징 맵의 패치에서 특징의 존재를 요약함으로써, 풀링은 네트워크가 입력 이미지의 작은 변동 및 변환에 강건함을 유지하는 데 도움이 됩니다.\n\nCNN을 다룰 때 알아야 할 몇 가지 종류의 풀링 기술이 있습니다:\n\n최대 풀링\n이것은 가장 일반적인 풀링 형태로, 특징 맵의 값 집합에서 최대값이 선택되어 다음 레이어로 전달됩니다. 최대 풀링은 특징 맵의 각 패치에서 가장 현저한 특징을 효과적으로 포착합니다.\n\n우리는 특징 맵을 F로, 풀링 작업을 P_max로 표시하며, 크기가 n×n인 창으로 위치 (i,j)에서의 최대 풀링 결과는 다음과 같이 표현될 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_6.png)\n\n여기서 s는 풀링 윈도우의 보폭이며, a, b는 윈도우 차원을 반복합니다. 이 작업은 특성 맵을 가로지르는 각 윈도우 위치에 독립적으로 적용됩니다.\n\n평균 풀링\n최대 풀링과 달리 평균 풀링은 특성 맵의 각 패치에서 값의 평균을 취합니다. 이 방법은 보다 일반화된 특성 표현을 제공하지만, 더 작지만 의미 있는 특성의 영향을 약화시킬 수 있습니다.\n\n특성 맵 F와 n×n 풀링 윈도우에 대해 위치 (i,j)에서의 평균 풀링 연산은 수학적으로 다음과 같이 표현될 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_7.png)\n\n맥스 풀링과 유사하게, s는 스트라이드를 나타내며, a,b는 창을 순회하는 반면, 이 연산에서는 각 창 내 값들의 평균을 계산합니다.\n\n글로벌 풀링\n글로벌 풀링에서는 전체 피처 맵이 각각 맥스(글로벌 맥스 풀링) 또는 평균(글로벌 평균 풀링)을 취함으로써 하나의 값으로 축소됩니다. 이 접근 방식은 종종 각 피처 맵을 완전 연결 레이어 이전에 하나의 값으로 줄이는 데 사용됩니다.\n\n크기가 M×N인 피처 맵 F에 대해, 글로벌 맥스 풀링 (P_gmax) 및 글로벌 평균 풀링 (P_gavg)은 다음과 같이 정의될 수 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Global pooling operations](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_8.png)\n\n전역 풀링 연산은 전체 피쳐 맵을 하나의 요약 통계치로 압축하는데 사용되며, 이는 분류를 위한 완전 연결 레이어 이전에 모델 파라미터를 줄이는 데 특히 유용합니다.\n\n풀링 동작 방식\n풀링 레이어는 각 피쳐 맵에 독립적으로 작동하며, 피쳐 맵을 가로지르면서 창(또는 필터)을 슬라이딩하고 해당 창 내의 값을 요약하여 한 가지 값으로 줄입니다 (사용된 풀링 전략에 따라). 이 과정은 피쳐 맵의 공간 차원을 줄입니다.\n\n창의 크기와 스트라이드(창이 한 번에 이동하는 거리)는 피쳐 맵이 얼마나 줄어드는지를 결정합니다. 흔히 선택하는 것은 2x2 창과 스트라이드 2인 경우인데, 이는 피쳐 맵의 크기를 절반으로 줄입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.8: 완전 연결층\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_9.png)\n\n완전 연결층은 CNN의 끝쪽에 자주 위치합니다. 이 층들은 학습된 특징에 기반한 고수준 추론이 이루어지는 곳으로, 궁극적으로는 분류나 예측으로 이어집니다.\n\n완전 연결층에서는 각 뉴런이 이전 층의 모든 활성화에 연결됩니다. 이 밀집된 연결은 층이 추출된 특징들의 전체 맥락을 갖게 해주어, 특징 맵 전체에 분산된 복잡한 패턴을 학습할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n완전 연결 계층은 합성곱 및 풀링 계층에서 식별된 공간적으로 분산된 특징을 전체 입력의 전역 표현으로 통합합니다. 이 통합은 분류와 같은 전체 입력을 이해해야 하는 작업에 중요합니다.\n\n합성곱에서 완전 연결 계층으로\n완전 연결 계층에 진입하기 전에, 이전 합성곱이나 풀링 계층의 출력(일반적으로 다차원 특징 맵)이 하나의 벡터로 평평하게 변환됩니다. 이 단계는 공간 구조화된 데이터를 완전 연결 계층에서 처리할 수 있도록 포맷을 변환합니다.\n\n완전 연결 계층의 뉴런들은 평평한 특징 맵에 의해 제시된 전역 정보를 고려함으로써 데이터에서 고수준 패턴을 학습할 수 있습니다. 이 능력은 전체 입력 이미지를 기반으로 한 예측이나 분류를 만드는 데 기본적입니다.\n\nCNN에서의 역할\n많은 CNN 아키텍처에서 최종 완전 연결 계층은 분류 계층으로 기능하며, 각 뉴런은 특정 클래스를 나타냅니다. 네트워크의 예측은 일반적으로 이러한 뉴런들의 활성화에 의해 결정되며, 활성화를 확률로 변환하는 소프트맥스 함수를 통해 수행됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성곱 레이어에 의해 추출된 지역화된 추상적인 특징을 완전 연결 레이어가 입력 데이터의 일관된 이해로 합성합니다. 이러한 합성은 네트워크가 입력에 대해 전체적으로 추론하고 판단을 내릴 수 있도록 중요합니다.\n\n# 3: CNN 구축 단계별 안내서\n\n이제 비즈니스 쪽으로 가지고 CNN을 구축해 봅시다. MNIST 데이터셋에서 손으로 쓴 숫자의 이미지 분류를 위해 PyTorch를 사용하여 합성곱 신경망(CNN)을 설정하고 훈련 및 평가할 것입니다. [MNIST 데이터셋은 Creative Commons Attribution-Share Alike 3.0 라이선스 조건 하에 제공됩니다]\n\n오늘 다룰 모든 코드가 포함된 Jupyter Notebook을 참고하시기 바랍니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.1: 환경 설정하기\n\n필요한 라이브러리와 모듈을 준비해봅시다. 신경망을 구축하고 훈련하기 위해 PyTorch (torch)와 이를 위한 신경망 모듈 (nn), 최적화 모듈 (optim)이 불러와집니다. torch.nn.functional에서 ReLU 활성화 및 최대 풀링과 같은 작업에 사용되는 기능이 제공됩니다. DataLoader 유틸리티를 통해 배치 처리와 데이터 관리를 용이하게 할 수 있고, torchvision은 데이터셋 및 이미지 변환을 위해 사용됩니다.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n``` \n\n## 3.2: 데이터 준비하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMNIST 데이터셋은 이미지를 텐서 형식으로 변환한 후 픽셀 값을 정규화하는 변환 파이프라인으로 로드됩니다. 정규화 매개변수(평균=0.1307, 표준편차=0.3081)는 MNIST 데이터셋에 특별히 선택되어 그레이스케일 이미지를 표준화하여 신경망의 성능을 최적화합니다.\n\n```js\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\nmnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n```\n\n데이터셋에서의 샘플 이미지를 matplotlib을 사용하여 표시하여, 네트워크가 훈련될 데이터 유형을 시각적으로 보여줍니다.\n\n```js\nimage, label = mnist_dataset[0]\nplt.imshow(image.squeeze().numpy(), cmap='gray')\nplt.title(f'Label: {label}')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 이미지가 표시됩니다:\n\n\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_10.png\" /\u003e\n\n데이터셋은 모델 훈련 중에 효율적인 처리를 위해 배치 처리, 셔플링, 데이터셋 준비를 다루는 DataLoader 인스턴스에 의해 훈련 및 검증 세트로 나누어집니다.\n\n```js\ntrain_size = int(0.8 * len(mnist_dataset))\nval_size = len(mnist_dataset) - train_size\ntrain_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.3: CNN 모델 설계\n\n데이터 전처리를 한 후에 모델을 만들어 보겠습니다. 따라서 nn.Module에서 상속된 MyCNN 클래스를 초기화합니다. 이 상속은 PyTorch에서 모델을 정의하는 방법입니다. 이 상속을 통해 MyCNN은 PyTorch 모델의 모든 기능을 갖추게 되며, 훈련, 예측 등이 가능해집니다.\n\n__init__ 함수는 MyCNN 클래스의 생성자입니다. 이 함수에서 신경망의 층들이 정의됩니다. super(MyCNN, self).__init__() 라인은 기본 nn.Module 클래스의 생성자를 호출하는데, 이는 PyTorch가 모든 것을 올바르게 초기화하기 위해 필요합니다.\n\n```python\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(7*7*64, 128)\n        self.fc2 = nn.Linear(128, 10)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드에서 볼 수 있듯이, 이 네트워크에는 conv1과 conv2 두 개의 합성곱 레이어가 포함되어 있습니다.\n\nconv1은 단일 채널 이미지(회색조 이미지와 같은)를 입력으로 받아 3x3 필터(또는 커널) 크기와 1의 스트라이드, 1의 패딩을 사용하여 32개의 특성 맵을 생성합니다. 패딩은 출력 특성 맵이 입력과 동일한 크기로 유지되도록 추가됩니다.\n\nconv2는 conv1에서 32개의 특성 맵을 입력으로 받아 3x3 커널, 1의 스트라이드, 1의 패딩을 사용하여 64개의 특성 맵을 생성합니다. 이 레이어는 conv1에서 제공된 입력으로부터 특성을 더 추출합니다.\n\n합성곱 레이어 이후에는 두 개의 완전 연결(fc) 레이어가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nfc1은 합성곱 레이어의 출력을 크기 128의 벡터로 변환하는 첫 번째 완전 연결 레이어입니다. 입력 크기는 7*7*64이며, 이는 이 레이어에 도달하기 전에 특성 맵이 단일 벡터로 펼쳐지며, 평탄화되기 전의 특성 맵의 차원이 7x7이고 64개 채널임을 의미합니다. 이 단계는 공간 특성 추출에서 해당 특성을 기반으로 결정(분류)을 내리는 것으로 전환하는 데 중요합니다.\n\nfc2는 두 번째 완전 연결 레이어로, fc1에서 가져온 128차원 벡터를 가져와 10차원 벡터를 출력합니다. 이 출력 크기는 일반적으로 분류 문제의 클래스 수에 해당하며, 이 네트워크가 이미지를 10가지 범주 중 하나로 분류하는 방식으로 설계되었음을 시사합니다.\n\n```js\ndef _initialize_weights(self):\n    for m in self.modules():\n        if isinstance(m, nn.Conv2d):\n            nn.init.normal_(m.weight, 0, 0.01)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n```\n\n가중치 초기화는 네트워크가 경사도를 사라지게 하거나 폭발시키지 않는 범위의 가중치로 시작하도록 보장하기 위해 적용됩니다. 합성곱 레이어는 정규 분포로 초기화되고, 완전 연결 레이어는 Xavier 균일 분포 초기화를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제 이전 글에서 자비에 초기화 및 다른 유형의 초기화에 대해 더 알아보고 싶다면 확인해보세요:\n\nMyCNN 클래스의 forward 메서드는 입력 데이터가 CNN을 통과하면서 겪는 작업 순서를 정의합니다.\n\n```js\ndef forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = F.max_pool2d(x, 2, 2)\n    x = F.relu(self.conv2(x))\n    x = F.max_pool2d(x, 2, 2)\n    x = x.view(x.size(0), -1)\n    x = F.relu(self.fc1(x))\n    x = self.fc2(x)\n    return x\n```\n\n이 메서드를 단계별로 살펴보며, 각 작업에 중점을 두고 입력 이미지가 출력 예측으로 어떻게 변환되는지 이해해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 합성곱 레이어\n\n```js\nx = F.relu(self.conv1(x))\n```\n\n이 합성곱 레이어 (conv1)를 통과하는 입력 텐서 x은 이미지의 일괄 처리를 나타냅니다. 이 레이어는 입력에 학습된 필터를 적용하여 가장자리와 질감 같은 기본 시각적 특징을 캡처합니다. 합성곱 연산 다음에 바로 인플레이스로 ReLU 활성화 함수가 적용됩니다. ReLU는 출력 텐서의 모든 음의 값을 제로로 설정하여 네트워크가 특징을 구별하는 능력을 향상시킵니다.\n\n첫 번째 풀링 연산\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nx = F.max_pool2d(x, 2, 2)\n```\n\n첫 번째 합성곱 및 활성화를 거친 후 최대 풀링 작업이 적용됩니다. 이 작업은 풀 크기와 스트라이드로 인해 피쳐 맵의 공간 차원을 절반으로 줄입니다. 이는 피쳐 맵의 2x2 패치 내에서 가장 중요한 피쳐를 요약하는 역할을 합니다. 최대 풀링은 표현을 작은 이동 및 왜곡에 대해 다소 불변하게 만들어줍니다.\n\n두 번째 합성곱 층\n\n```js\nx = F.relu(self.conv2(x))\n```    \n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 번째 합성곱층(conv2)으로 반복 과정이 진행됩니다. 여기서는 이제 축소된 특징 맵에 새로운 필터 세트를 적용합니다. 이 층은 일반적으로 첫 번째 층에서 식별된 기본 패턴을 기반으로 한 더 복잡한 특징을 포착합니다. 다시 한 번 ReLU 활성화가 이어져 비선형성을 유지합니다.\n\n두 번째 풀링 작업\n\n```js\nx = F.max_pool2d(x, 2, 2)\n```\n\n다른 최대 풀링 단계를 통해 결과 특징 맵의 공간적 차원이 더욱 줄어들어 특징 표현을 간결화하고 후속 층의 계산 복잡성을 줄입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n펼치기\n\n```js\nx = x.view(x.size(0), -1)\n```\n\n전체 연결 계층으로 넘어가기 전에 다차원 특징 맵을 배치 내 각 이미지에 대해 단일 벡터로 펼쳐야 합니다. 이 작업은 텐서를 다시 구성하여 각 이미지의 특징 맵이 텐서의 단일 행이 되도록 만들며, 완전 연결 처리에 적합한 형식으로 모든 특징 정보를 보존합니다.\n\n첫 번째 완전 연결 계층\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nx = F.relu(self.fc1(x))\n```\n\n평탄화된 텐서는 첫 번째 완전 연결 계층(fc1)을 통과하여 전체 특징 집합에서 복잡한 패턴을 학습할 수 있습니다. ReLU 함수가 한 번 더 적용되어 비선형성을 도입하고, 네트워크가 더 복잡한 함수를 학습하고 표현할 수 있도록 합니다.\n\n두 번째 완전 연결 계층 (출력 계층)\n\n```js\nx = self.fc2(x)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마침내, 텐서는 출력 레이어 역할을 하는 두 번째 완전 연결 레이어(FC2)를 통과합니다. 이 레이어에는 예측할 클래스 수와 동일한 수의 뉴런이 있습니다(MNIST 숫자의 경우 10개). 이 레이어의 출력은 네트워크가 각 클래스에 대해 예측한 값을 나타냅니다.\n\n## 3.4: 모델 컴파일\n\n모델은 CrossEntropyLoss로 분류되어 있고 Adam 옵티마이저를 사용하여 가중치를 조정하며, 학습률 및 가중치 감소와 같은 특정 매개변수도 함께 사용하여 컴파일됩니다.\n\n```js\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5, amsgrad=True, eps=1e-8, betas=(0.9, 0.999))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAdam 옵티마이저는 딥러닝 모델을 훈련하는 인기 알고리즘으로, AdaGrad와 RMSProp 알고리즘의 최상의 특성을 결합하여 소음이 있는 문제에서 희소한 그래디언트를 효율적으로 처리합니다. 이는 매개변수별로 학습률을 조정하여 광범위한 작업과 모델에 매우 효과적이고 적합합니다. Adam에 대해 더 자세히 알고 싶다면, 수학적인 내용을 검토하고 처음부터 구축한 내 기사를 살펴보세요:\n\n## 3.5: CNN 훈련\n\n제공된 로직의 Trainer 클래스는 CNN 모델을 훈련하는 데 필요한 필수 기능을 포함하고 있습니다. 이는 순방향 패스, 역방향 패스(그래디언트 계산 및 가중치 업데이트), 훈련 및 검증 손실 모니터링, 조기 중단 구현, 학습률 조정, 그리고 모델 성능 평가를 포함합니다. 이 클래스를 분석하여 구조와 기능을 깊이 이해해 봅시다.\n\n\n\n```python\nclass Trainer:\n    def __init__(self, model, criterion, optimizer, device, patience=7):\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.device = device\n        self.early_stopping = EarlyStopping(patience=patience)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=3, verbose=True, factor=0.5, min_lr=1e-6)\n        self.train_losses = []\n        self.val_losses = []\n        self.gradient_norms = []\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n초기화 메서드인 __init__에서 Trainer 클래스는 CNN 모델, 손실 함수(criterion), 옵티마이저와 함께 CPU 또는 GPU에서 학습할 장치와 조기 종료를 위한 인자로 받습니다. EarlyStopping 인스턴스는 검증 손실을 모니터링하고 모델이 더 이상 개선되지 않을 경우 훈련을 중지하여 과적합을 방지합니다. 학습률 스케줄러(ReduceLROnPlateau)도 초기화되어 검증 손실을 기반으로 학습률을 동적으로 조정하여 훈련 중에 최적의 학습률을 찾도록 도와줍니다. 분석 및 디버깅 목적으로 학습 및 검증 손실 및 그레이디언트 노름을 추적하기 위한 리스트가 초기화됩니다.\n\n```js\ndef train(self, train_loader, val_loader, epochs):\n    for epoch in range(epochs):\n        self.model.train()\n        for images, labels in train_loader:\n            images, labels = images.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            loss = self.criterion(outputs, labels)\n            self.train_losses.append(loss.item())\n            loss.backward()\n            self.optimizer.step()\n```\n\ntrain 메서드는 지정된 에폭 수에 대한 학습 프로세스를 조율합니다. 각 에폭마다 모델을 훈련 모드로 설정하고 train_loader를 사용하여 학습 데이터셋을 반복합니다. 입력 이미지와 레이블을 지정된 장치로 이동시킵니다. 옵티마이저의 그라디언트는 이전 반복에서의 누적을 방지하기 위해 각 순방향 패스 전에 0으로 초기화됩니다. 모델의 예측을 얻고, 지정된 criterion을 사용하여 손실을 계산합니다. 손실 값은 추적을 위해 train_losses 리스트에 추가됩니다. loss.backward()를 호출하여 역전파를 수행하고, 옵티마이저는 optimizer.step()로 모델 가중치를 업데이트합니다.\n\n```js\nval_loss = self.evaluate(val_loader)\nself.val_losses.append(val_loss)\nself.scheduler.step(val_loss)\nself.early_stopping(val_loss)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 데이터를 처리한 후 모델은 평가 메서드를 사용하여 검증 데이터셋에서 평가되며, 평균 검증 손실을 계산합니다. 이 손실은 학습률을 조정하고 조기 종료 조건이 충족되었는지 확인하는 데 사용됩니다. 검증 손실은 분석을 위해 추적됩니다.\n\n```js\nif self.early_stopping.early_stop:\n    print(\"조기 종료\")\n    break\n```\n\n조기 종료가 발생하면, 과적합을 방지하기 위해 훈련이 중지됩니다. 이 결정은 인내 매개변수로 정의된 여러 epoch 동안 검증 손실이 향상되지 않았는지에 따라 기반으로 합니다.\n\n```js\ndef evaluate(self, test_loader):\n    self.model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(self.device), labels.to(self.device)\n            outputs = self.model(images)\n            loss = self.criterion(outputs, labels)\n            total_loss += loss.item()\n    return total_loss / len(test_loader)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nevaluate 메서드는 모델의 가중치를 업데이트하지 않고 유효성 검사 또는 테스트 데이터셋에서 평균 손실을 계산합니다. 이 메서드는 모델을 평가 모드로 설정하고 효율성을 위해 그래디언트 계산을 비활성화합니다.\n\n# 4: 모델 성능 향상\n\n합성곱 신경망(CNN)의 성능을 개선하고 과적합을 방지하는 것은 딥러닝 모델을 교육하는 중요한 도전 과제입니다. 제공된 코드 스니펫은 데이터 증가, 드롭아웃, 배치 정규화와 같은 기술에 대해 명시적으로 설명하지 않으며 전이 학습에 대해서도 다루지 않습니다. 그러나 이러한 전략들은 CNN을 향상시키는 데 중요하므로 이들이 훈련 과정에 통합되고 모델 성능에 미치는 잠재적인 영향에 대해 알아봅시다.\n\n## 4.1: 데이터 증가\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 증가는 기존 이미지에 임의의 변환(회전, 뒤집기, 크기 조정 등)을 적용하여 학습 데이터셋의 다양성을 인위적으로 증가시킵니다. 이 다양성은 모델이 더 많은 입력 변화 범위에서 학습함으로써 새로운 데이터에 대해 더 잘 일반화되도록 돕습니다.\n\nPyTorch에서 데이터 증가를 구현하려면 데이터셋을 준비할 때 사용되는 transforms.Compose를 확장할 수 있습니다:\n\n```js\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n```\n\n랜덤 뒤집기와 회전을 추가함으로써 훈련 데이터를 다양하게 만들어 모델이 더 견고한 특징을 학습하도록 돕습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4.2: Dropout\n\n드롭아웃은 학습 중에 입력 뉴런의 일부를 무작위로 0으로 설정하여 과도한 공동 적응을 방지하는 정칙화 기술입니다. 이 무작위성은 네트워크가 다른 뉴런의 무작위 하위 집합과 함께 유용한 보다 견고한 기능을 학습하도록 강제합니다.\n\n파이토치에서 CNN 모델에 드롭아웃을 추가하려면 nn.Dropout 레이어를 포함시킵니다:\n\n```js\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        # 합성곱 레이어\n        self.fc1 = nn.Linear(7*7*64, 128)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, 10)\n    def forward(self, x):\n        # 합성곱 및 풀링 작업\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막 완전 연결 레이어 앞에 드롭아웃 레이어를 추가하면 모델이 학습된 표현을 여러 뉴런에 분배하도록 유도하여 오버피팅을 완화하는 데 도움이 됩니다.\n\n## 4.3: 배치 정규화\n\n배치 정규화는 각 미니 배치에 대해 레이어의 입력을 표준화하여 학습 프로세스를 안정화시키고 딥 네트워크를 훈련하는 데 필요한 훈련 에포크 수를 크게 줄입니다.\n\n모델에 배치 정규화를 포함하는 방법은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        # Covolutional layers\n        self.conv1_bn = nn.BatchNorm2d(32)\n        # Fully connected layers\n        \n    def forward(self, x):\n        x = F.relu(self.conv1_bn(self.conv1(x)))\n        # Continue through model\n```\n\n컨볼루션 레이어 다음에 배치 정규화를 적용한 후 활성화 함수를 사용하는 것은 출력을 정규화하여 수렴 속도를 높이고 전반적인 성능을 향상시켜줍니다.\n\n## 4.4: 전이 학습\n\n전이 학습은 한 작업에서 훈련된 모델을 다른 관련 작업에서 훈련을 위한 출발점으로 사용하는 기술을 말합니다. 새 작업에 제한된 데이터셋이 있는 경우 특히 유용합니다. PyTorch는 ImageNet과 같은 대규모 데이터셋에서 사전 훈련된 모델을 쉽게 로드하고 조정할 수 있도록 지원하여 전이 학습을 용이하게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프리 트레인 모델을 활용하는 방법은 아주 쉬워요!\n\n```python\nfrom torchvision import models\n\nmodel = models.resnet18(pretrained=True)\n# 마지막 완전 연결 레이어 교체하기\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 10)  # 새로운 작업을 위해 10개의 클래스로 가정\n# 마지막 완전 연결 레이어를 제외한 모든 레이어 동결하기\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.fc.requires_grad = True\n```\n\n요기서, 사전 훈련된 ResNet-18 모델을 사용해서, 10개의 클래스를 위한 새 작업에 맞게 마지막 레이어를 대체했어요. 마지막 레이어를 제외한 모든 레이어의 가중치를 동결하면, 분류기 레이어만을 미세 조정해 원본 데이터셋에서 학습한 기능 추출 능력을 활용할 수 있어요.\n\nCNN 훈련 과정에 이러한 전략을 통합시키면, 오버피팅이 줄어들 뿐만 아니라 견고한 특징 학습을 보장하고 사전 훈련된 모델로부터 지식을 활용하여 모델 성능을 향상시킬 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 5: 결론\n\n합성곱 신경망에 대해 심층적으로 파헤쳐 보았습니다. 데이터 설정 및 준비부터 CNN 구조와 계층 분해까지 많은 내용을 다루었습니다. 이러한 모델의 작동 원리를 살펴봤습니다. 가중치 초기화와 데이터 증강, 전이 학습과 같은 기술을 사용하여 모델의 성능을 심각하게 향상시킬 수 있다는 점을 살펴보았습니다. 이러한 방법들은 모델이 더욱 똑똑하게 만들어주어, 오버피팅과 같은 일반적인 함정을 피하고 더 다양한 모델로 만들어 줍니다.\n\nAI 분야에서 CNN은 거의 모든 곳에서 사용되어 얼굴을 인식하거나 의료 영상을 통해 질병을 진단하는 등 많은 일에 도움이 되고 있습니다. 시각적 단서를 잡아내는 능력으로 다양한 작업에 매우 유용합니다.\n\n# 추가 자료\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- LeCun et al., “Gradient-Based Learning Applied to Document Recognition”\nYann LeCun과 동료들이 쓴 이 주요 논문에서는 LeNet-5를 소개하며, 최초의 합성곱 신경망 중 하나로 문서 인식 작업에 적용된 결과를 보여줍니다.\nResearch Gate 링크\n- Simonyan과 Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition” (VGGNet)\nVGGNet을 소개한 이 연구는 CNN 아키텍처에서 깊이의 중요성을 강조하여 이미지 인식 성능을 향상시키는데 있습니다.\narXiv 링크\n- He et al., “Deep Residual Learning for Image Recognition” (ResNet)\nResNet은 잔차 학습 개념을 도입하여, 사그라들어 버리는 기울기 문제를 해결함으로써 훨씬 더 깊은 네트워크의 학습을 가능케 합니다.\narXiv 링크\n\n만약 이 기사를 좋아하셨다면 좋아요를 눌러 주시고, 최신 게시물을 받아보려면 팔로우해주세요. 저의 목표는 인기 있는 모든 알고리즘을 처음부터 다시 만들어 기계 학습을 누구에게나 쉽게 접근할 수 있게 하는 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png"},"coverImage":"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png","tag":["Tech"],"readingTime":26},{"title":"시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근","description":"","date":"2024-06-23 18:48","slug":"2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective","content":"\n\n면허가 있는 거래처 선정이 기존에서 5년 이상된 기사에 대한 후속 내용입니다:\n\n- 시그모이드 신경망을 사용한 다항식 제조\n- 시그모이드 신경망을 사용한 다항식 제조 - 실습\n\n이 실습은 신경망의 인내 성능을 다루었습니다. 간단한 기저(알려진) 모델에 대해: y = 1 + 2*x + 3*x². 실습을 마치며, 1계층 출력 간의 높은 상관 관계가 수렴을 늦추고, 제약이 없는 모델이 훨씬 더 좋은 샘내내 성능을 보였다는 결론을 내렸습니다. 추가로 다항회귀 분석도 제약이 없는 모델의 샘내내 정확성(진정한 모델 기반)을 입증했습니다. 신경망의 스플라인 이론 관점에서 이 모든 것이 직관적으로 맞는 것이며, 두 모델 모두 유용합니다. 그러나 모델의 범위 외 성능을 놓치고 있었음을 인정하지 못했습니다. 스플라인 이론적 관점에서 이는 큰 누락이었습니다.\n\n이 기사는 범위 외 성능, 진정한 모델과 일치 정도, 및 '일반화'에 대한 일부 상위 추론에 초점을 맞추겠습니다. '일반화'는 다음을 기반으로 평가됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 다양한 유형의 테스트 데이터 포인트(전체, 훈련 데이터 내 범위, 훈련 데이터 외 범위)별 총 오차(MSE)\n- 전체 모델의 적합성(확장된 테스트 데이터 세트에서 실제 모델과의 유사성) \n\n## 테스트 데이터의 범위 외 부분 생성\n\n훈련 데이터 세트의 x1은 표준 정규 분포에서 무작위 샘플링하여 생성되었습니다. x1을 3배로 곱하여 범위를 확장한 테스트 데이터 세트가 생성되었습니다. 이로 인해 원래 훈련 세트의 범위 내에 속하는 데이터 포인트가 총 7990개, 원래 훈련 세트의 범위 외에 속하는 데이터 포인트가 2010개 생성되었습니다.\n\n## 모델들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델 구조는 실습과 동일합니다\n\n![image](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png)\n\n# 학습 및 평가\n\n모델은 실습에서 사용된 학습 예제를 사용하여 훈련되었습니다. 따라서 모델의 가중치는 변경되지 않았습니다. 그러나 제한된 및 제한되지 않은 모델의 기저 (다항식) 표현은 새로운 테스트 데이터 집합 범위 내에서 변할 수 있습니다. 또한, 모델의 범위를 벗어난 성능은 범위 내 성능에서 예측하기 어려울 수 있습니다(두 모델 모두 학습 데이터 범위 내에서 매우 좋은 적합도를 나타냄, MSE ` 0.045).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 에폭별 모델 추적\n\n![이미지](https://miro.medium.com/v2/resize:fit:1280/1*jygr4njGNjkNL3enCQNVyg.gif)\n\n![이미지](https://miro.medium.com/v2/resize:fit:1280/1*hUfYQ21PQZkbE40NcVwuPA.gif)\n\n두 그래프에 대한 키: 파란 선 - 실제 값, 파란 점 - 훈련 범위 내에서 확장 테스트 예제에 대한 모델 예측, 빨간 점 - 훈련 범위를 벗어난 확장 테스트 예제에 대한 모델 예측.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(bias) 무제한 모델이 (bias) 제한 모델보다 최종 솔루션으로 수렴하는 속도가 훨씬 빠르다는 사실은 명백하다. 그러나 모델의 가중치는 크게(직역하지 않는 용어, 통계 용어 아님) 다르다. 특히, 제한 모델 가중치가 무제한 모델의 가중치보다 거의 1차 크다는 점은 매우 명백하다. 이것은 중요한 관찰이다. 왜냐하면 편향이 없는 모델은 편향 제한 모델로 수렴할 수 있는 기회가 있었지만, 대신 샘플 내 솔루션으로 더 나은 수렴했기 때문이다.\n\n# 모델 (메타) 분석 - 범위 내 및 범위 외\n\n- 랜덤 초기화로 인해 교육 MSE는 약 28에서 출발하여 두 모델 모두 `0.045로 점진적으로 감소한다.\n- 제한 모델은 활성화된 레이어 1 출력이 교육 중에 높은 상관 관계가 있기 때문에 그레이디언트가 노이즈를 일으키는 것으로 추정되므로 훨씬 느리게 수렴한다. (코드에서 실험적으로 유효성이 검증되어야 함)\n- 질적으로 제한된 최종 모델은 범위 밖에서(범위 외 MSE=1699.82) 무제한 최종 모델(범위 외 MSE=2905.67)보다 훨씬 더 우수한 성능을 발휘한다. 이 향상된 외부 범위 성능은 범위 내 성능에 큰 하락이 오지 않고 (제한 모델의 범위 내 MSE=1.38 대 무제한 모델의 범위 내 MSE=0.41) 테스트 데이터에 대한 총 성능(MSE=342.77 대 무제한 모델의 MSE=584.37)에서도 비슷하게 유지된다. 이 간접는 근려에 편향 제약이 실무에서 가치를 더하는 것으로 보이지 않았기에 저에게는 매우 놀랍다.\n- 새로운 테스트 데이터에 대한 모델 적합도도 제한 모델이 무제한 모델에 비해 훨씬 우수하다.\n\n# 확장 테스트 데이터 세트에서 모델 적합 결과 (x1_extended = 2*x1 및 실제 모델 y_extended = 1 + 2*x1_extended + 3*x1_extended²)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 제약이 없는 모델\n\n제약이 없는 모델 레이어 1: f1_u, f2_u = f_u(x)\n\n![이미지1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_1.png)\n\n![이미지2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, f1_u는 0.1094 - 0.0882*x + 0.0102*x² + 0.0002*x³입니다.\n\n![그림1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_3.png)\n\n![그림2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_4.png)\n\n그래서, f2_u는 0.1031 + 0.0799*x + 0.0091*x² - 0.0003*x³입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUnconstrained model layer 2: y_pred_u = g_u(f1_u, f2_u); g_u is linear\ny_pred_u ~ 7.16 + 2.66*x + 2.31*x² - 0.023*x³\n\n## Constrained model\n\nConstrained model layer 1: f1_c, f2_c = f_c(x)\n\n![Image](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_6.png)\n\nHence, f1_c ~ 0.5 + 0.044*x - 0.00005*x²\n\n![Image 2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_7.png)\n\n![Image 3](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_8.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n따라서, f2_c ~ 0.2237 + 0.0676*x + 0.0041*x² - 0.0002*x³\n\n제한된 모델 레이어 2: y_pred_c = g_c(f1_c, f2_c); g_c는 선형입니다.\ny_pred_c ~ 2.95 + 6.4*x + 2.79*x² - 0.134*x³\n\n참고: 실습에 포함된 추가 진단은 수행되었지만, 간결함을 위해 이 글에서는 생략되었습니다. 이러한 진단에 관심이 있는 독자는 다음 스크립트를 실행해주세요:\n\n- 제한된 모델을 위한 test_quadratic.py\n- 제한되지 않은 모델을 위한 test_quadratic_unconstrained.py\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 추가적인 추론\n\n참고: *로 표시된 추론은 세 논문 중 어느 것에도 입증되지 않았지만 이론적으로나 경험적으로 보여질 수 있으며, **로 표시된 추론은 향후 논문을 위한 가능성 있는 후보들이다.\n\n- 비제약 모델에 대해 f1_u와 f2_u 모두 조각선형 함수 형태*를 띄며 ReLU와 유사하다*\n- 제약이 있는 모델과 제약이 없는 모델에 대해 이차적합을 강제하면 다음과 같은 형태가 나온다:\ny_pred_u ~ 7.22 + 2.18*x + 2.31*x²\ny_pred_c ~ 3.56 + 1.98*x + 2.72*x²\n- 최종 가중치가 크게 다르더라도 두 모델의 훈련 오차 차이가 크지 않다. 그러므로 MSE vs. (w1, w2, W1, W2)의 곡선은 모델의 가중치 사이에 오랜 기울기를 보인다**.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제약이 있는 모델은 (MSE 및 모델 계수가 실제 모델과 얼마나 가까운지) 자유로운 모델보다 훨씬 더 일반화되는 것으로 보입니다. 이 논리를 심층 신경망에서 오버피팅을 넘어서는 일반화에 적용한다면 - 모델 아키텍처가 충분히 좋은 귀납적 편향이라고 가정하면,\n- 초기 오버피팅은 가중치 벡터가 초기화된 지점에서 최단 경로(최적화 알고리즘이 지배하는)를 통해 먼저 '가능한 해'로 수렴하기 때문에 발생할 수 있습니다.\n- 그 이후에 발생하는 일반화가 더 나은 해로의 전이는 최적화 알고리즘이 가중치 벡터를 (오차 측정, 가중치의) 공간에서 새로운 영역으로 완전히 이동시키도록 강요하기 때문으로 설명될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png"},"coverImage":"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png","tag":["Tech"],"readingTime":6},{"title":"MLOps 로드맵  2024년 MLOps 엔지니어가 되는 방법","description":"","date":"2024-06-23 18:46","slug":"2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024","content":"\n\n2024년에 MLOps 엔지니어가 되기 위한 포괄적인 MLOps 로드맵\n\n![MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0.png)\n\nAI 분야에 계시고 머신 러닝에 대해 궁금해하시나요? MLOps에 대해 궁금해하셨나요? 그리고 그 멋진 AI 응용 프로그램들은 어떻게 만들어지는 걸까요?🧐\n\nMLOps는 신비한 용어처럼 들릴 수도 있지만 걱정 마세요! 🤔 이 MLOps 로드맵에서 함께 MLOps의 신비를 탐험해보겠습니다. 🌟\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 도와드릴 수 있어요! 명확한 계획을 제시해드릴게요. MLOps가 무엇인지 설명하고 한 단계씩 안내하여 MLOps를 이해할 수 있도록 도와드릴 거에요.💼\n\n시작해 볼까요?\n\n## 1- 프로그래밍 언어:\n\n![MLOpsRoadmap](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Python\n- R\n\n당신이 선택할 무기를 고를 수 있어요: Python 또는 R — 둘 다 멋진 언어로, 여러분을 MLOps 전문가로 만들어 줄 거에요. 🌟\n\n## MLOps용 Python\n\n- 다양한 도구 상자, 큰 가능성: Python은 TensorFlow, Kubeflow, Airflow와 같은 MLOps 인기 라이브러리를 포함한 방대한 라이브러리 생태계를 자랑해요. 이를 통해 여러분이 마주하는 어떤 MLOps 도전에도 도와줄 툴이 많이 있어요.\n- 쉽게 배우고, 쉽게 사용: Python의 명확한 구문과 초보자 친화적인 특성은 MLOps 여정을 시작하는 사람들에게 좋은 선택지에요. 금방 익숙해질 거예요!\n- 다른 도구들과 잘 어울려요: Python은 인기 있는 데이터 과학 및 소프트웨어 개발 도구와 완벽하게 통합되어, 여러분의 MLOps 파이프라인을 워크플로우의 다른 부분과 쉽게 연결할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## MLOps을 위한 R\n\n- 데이터 시각화 챔피언: R은 데이터 탐색과 시각화에서 빛을 발하며 명확하고 통찰력있는 대시보드를 만들어 MLOps 파이프라인을 모니터링할 수 있습니다.\n- 통계 강자: R의 통계 능력은 모델 평가 및 성능 분석과 같은 작업에 완벽하게 적합하며 이는 모든 MLOps 과정의 중요한 부분입니다.\n- 활발한 R 커뮤니티: R 커뮤니티는 열정적이고 도움이 되며, MLOps 모험 중에 막힐 경우 풍부한 지원과 자료를 제공합니다.\n\n# 2- 기계 학습:\n\n\u003cimg src=\"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_2.png\" /\u003e  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기계 학습(ML)은 MLOps의 기초입니다. 이것은 컴퓨터가 데이터로부터 배우고 명시적인 프로그래밍 없이 예측하거나 결정을 내릴 수 있는 기적입니다. 그런데 기계 학습은 MLOps에 어떻게 맞는 걸까요? 함께 살펴봅시다:\n\n기계 학습 과정:\n\nMLOps를 기름칠한 기계로 상상해보세요:\n\n- 데이터는 연료입니다: 데이터로 MLOps 파이프라인을 공급하여 ML 모델을 교육하는 데 사용되는 생 원료입니다.\n- 알고리즘은 엔진입니다: ML 알고리즘은 모델의 핵심으로, 데이터로부터 패턴과 통찰을 습득합니다. MLOps에 널리 사용되는 알고리즘으로는 다음이 있습니다:\n  - 선형 회귀: 주택 가격이나 매출액과 같은 연속 값 예측에 효과적입니다.\n  - 의사 결정 트리: 데이터에 대한 일련의 질문에 기반한 명확한 결정을 내립니다. 스팸 필터링과 같은 작업에 이상적입니다.\n  - 랜덤 포레스트: 여러 의사 결정 트리를 결합하여 더 강력한 예측을 제공합니다.\n  - 서포트 벡터 머신(SVM): 서로 다른 범주로 데이터를 분류하는 데 뛰어납니다. 예를 들어 필기 숫자를 식별하는 데 사용됩니다.\n  - 딥 러닝: 인간 두뇌에서 영감을 받은 딥 러닝은 이미지 인식이나 자연 언어 처리와 같은 복잡한 작업에 뛰어납니다.\n- MLOps는 엔지니어 역할을 합니다: ML 모델을 교육하고 배포하며 성능을 모니터링하고 최신 상태를 유지하도록 자동화합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3- 클라우드 플랫폼 - MLOps를 강화하세요\n\n![이미지](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_3.png)\n\nMLOps 파이프라인을 구축하고 관리할 때, 클라우드 플랫폼은 게임 체인징한 이점을 제공합니다. 여기에 그 이유가 있습니다:\n\n- 요구에 따른 확장성: 클라우드 플랫폼은 탄력적인 리소스를 제공하여 MLOps 인프라를 요구에 따라 확장 또는 축소할 수 있습니다. 복잡한 훈련 작업을 위한 처리 능력 부족으로 걱정할 필요가 없어요!\n- 쉬운 협업: 클라우드 플랫폼은 데이터 과학자, 엔지니어, MLOps 전문가 간의 원활한 협업을 촉진합니다. 모든 사람이 프로젝트에 동시에 접근하고 작업할 수 있어 개발 과정을 간소화합니다.\n- 자동화된 워크플로우: 클라우드 플랫폼은 모델 훈련, 배포, 모니터링과 같은 MLOps 작업을 자동화하는 데 능숙합니다. 이는 팀이 더 전략적인 이니셔티브에 집중할 수 있도록 해줍니다.\n- 비용 효율성: 클라우드 플랫폼을 사용하면 사용한 리소스만 지불하면 됩니다. 이는 유지 관리 비용이 비실 수 있는 기존 온프레미스 인프라에 비해 상당한 장점입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인기있는 클라우드 플랫폼 중에서 강력한 MLOps 기능을 제공하는 몇 가지가 있습니다:\n\n- Google Cloud Platform (GCP): GCP의 Vertex AI 스위트는 Vertex Pipelines(자동화를 위한), Vertex Experiments(모델 비교를 위한)를 포함한 포괄적인 MLOps 도구 세트를 제공합니다.\n- Amazon Web Services (AWS): AWS는 SageMaker를 제공하여 머신 러닝 모델을 구축, 훈련 및 배포하는 관리 서비스를 제공합니다. 다른 AWS 서비스와 웰 통합되어 종합적인 MLOps 경험을 제공합니다.\n- Microsoft Azure: Azure Machine Learning은 전체 MLOps 생애주기를 위한 클라우드 기반 환경을 제공합니다. 데이터 준비, 모델 훈련, 배포 및 모니터링을 위한 기능을 포함하고 있습니다.\n\n# 4- 버전 관리: MLOps의 수퍼히어로 ‍♀️\n\n![이미지](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n놀라운 MLOps 파이프라인을 구축하고 있을 때 작은 변경으로 모든 것이 망가지는 일이 발생하면 어떨까요! 그럴 때 버전 관리가 구조를 구할 수 있어요.\n\n버전 관리는 당신의 MLOps 프로젝트용으로 시간 여행을 할 수 있는 것과 같아요. 코드, 데이터, 모델을 변경할 때마다 그것을 추적해주어 다음을 가능하게 해줘요:\n\n- 과거로 돌아가기: 실수를 하게 되었나요? 걱정하지 마세요! 이전에 완벽하게 작동했던 이전 버전으로 되돌릴 수 있어요.\n- 협업 원할하게: 여러 사람이 MLOps 파이프라인에 작업할 때, 버전 관리는 모두가 동일한 페이지에 있다는 것을 보장하여 충돌과 혼란을 방지해줘요.\n- 자유롭게 실험하기: 두려움 없이 다양한 접근 방식을 시도해보세요. 버전 관리를 통해 버전을 비교하고 어떤 것이 가장 잘 작동하는지 확인할 수 있어요.\n- 결과 재현하기: 향후 참고를 위해 특정 모델이나 파이프라인을 재생성해야 할 때, 버전 관리를 통해 모든 것이 정확히 동일한 상태임을 쉽게 확인할 수 있어요.\n\nMLOps에서 버전 관리가 어떻게 작동하는지 Çómo funciona el control de versiones en MLOps\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 간단한 내용이에요:\n\n- 모든 것을 저장하세요: 코드, 데이터, 모델 - MLOps 프로젝트의 모든 구성 요소는 중앙 저장소에 저장됩니다.\n- 변경을 추적하세요: 당신이 만든 모든 수정 사항은 기록되어 명확한 이력을 만듭니다.\n- 분기해 보세요: 실험을 해야 할 필요가 있나요? 메인 파이프라인에 영향을 미치지 않으면서 변경 사항을 테스트할 브랜치를 만드세요.\n- 병합하고 배포하세요: 변경 사항에 만족하면 변경 사항을 다시 메인 브랜치로 병합하고 업데이트된 MLOps 파이프라인을 배포하세요.\n\nMLOps를 위한 인기 있는 버전 관리 시스템:\n\n- Git: 산업 표준인 Git은 버전 관리와 협업에 강력한 기능을 제공합니다.\n- DVC (데이터 버전 관리): 데이터 과학 프로젝트를 관리하기 위해 특별히 설계된 DVC는 데이터셋과 모델의 버전을 관리하기 위해 Git과 원활하게 작동합니다.\n- MLflow: ML 라이프사이클을 관리하기 위한 오픈 소스 플랫폼으로, 모델과 실험의 버전 관리를 포함합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n버전 관리는 모든 MLOps 실무자에게 필수적인 도구입니다. 안정성, 협업 및 실험 및 학습 능력을 보장합니다. 버전 관리를 통해 견고하고 신뢰할 수 있는 MLOps 파이프라인을 구축하여 실질적인 가치를 제공할 수 있습니다.\n\n# 5- CI CD 파이프라인: CI/CD로 머신 러닝 자동화하기\n\n![이미지](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_5.png)\n\n최신 AI 모델을 대량으로 생산하는 공장을 구축한다고 상상해보세요. 그것이 바로 MLOps 파이프라인이 하는 일인데, 물리적인 기계 대신 소프트웨어 자동화를 사용합니다. 이때 CI/CD (지속적 통합 및 지속적 전달/배포)가 비밀 무기로 작용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMLOps에서의 CI/CD는 미리 정리된 것처럼 잘 짜여진 조립 라인의 역할을 합니다:\n\n- 버전 관리 (소스 코드): 모든 것은 코드로 시작합니다. Git과 같은 버전 관리 시스템은 변경 사항을 추적하여 모두가 동일한 페이지에 있는지 확인합니다.\n- 지속적 통합 (CI): 코드의 변경으로 CI 단계가 트리거됩니다. 여기서 자동화된 테스트가 코드와 데이터를 유효성 검사하여 오류를 조기에 발견하여 이후 단계로 전파되지 않도록 합니다.\n- 모델 훈련 및 유효성 검사: 파이프라인은 준비된 데이터로 ML 모델을 훈련시킵니다. CI/CD는 모델이 예상대로 작동하는지 확인하기 위해 자동화된 테스트를 실행합니다. 이는 배포 전에 편향 또는 성능 문제를 찾는 데 중요합니다.\n- 패키징 및 버전 관리: 훈련 및 유효성 검사된 모델은 배포를 위해 준비된 형식으로 패키징됩니다 (제품을 깔끔하게 상자에 담는 것처럼 생각하면 됩니다). CI/CD는 변경 사항을 추적하기 위해 버전 번호도 할당합니다.\n- 지속적 전달/배포 (CD): 파이프라인은 패키지로 된 모델을 대상 환경에 자동으로 배포합니다. 테스트 서버 또는 제품 환경일 수 있습니다. 여기서 CI/CD는 다양한 전략을 사용할 수 있습니다:\n\n- 지속적 전달: 제품을 제품 환경으로 이동하기 전에 최종 테스트를 위해 스테이징 환경으로 모델을 배포합니다.\n- 지속적 배포: 이전 단계에서 모든 테스트가 통과되었다고 가정하고 모델을 자동으로 제품 환경에 직접 배포합니다.\n\nMLOps의 CI/CD의 장점:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 빠른 혁신: 파이프라인 자동화를 통해 모델을 더 빠르게 개선하며 성능을 지속적으로 향상시킬 수 있습니다.\n- 오류 감소: 자동화된 테스트는 버그를 조기에 발견하여 제품 모델에 영향을 미치지 않도록 합니다.\n- 일관성 향상: CI/CD를 통해 모델이 매번 동일한 방식으로 구축, 훈련 및 배포되어 신뢰할 수 있는 결과를 얻을 수 있습니다.\n- 협업 강화: 파이프라인은 데이터 과학자, 엔지니어 및 운영팀 간의 소통을 간소화합니다.\n\nMLOps 워크플로에 CI/CD 파이프라인을 구현하여 고품질 머신러닝 모델을 제공하는 견고하고 효율적인 시스템을 구축할 수 있습니다!\n\nCI/CD 배우기:\n\n# 6- 컨테이너화:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![MLOps Roadmap](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_6.png)\n\n복잡한 MLOps 파이프라인을 다양한 환경에 배포한다고 상상해보세요 — 개발자 노트북, 테스트 서버 그리고 마지막으로 프로덕션! 로지스틱 악몽처럼 들리죠? 여기서 컨테이네이션이 등장해 MLOps 슈퍼히어로가 되어줍니다!\n\n컨테이네이션이 정확히 무엇일까요? 여러분의 ML 모델이 필요로 하는 모든 것 — 코드, 라이브러리, 의존성, 실행 환경을 깔끔한 상자인 컨테이너에 담아 생각해보세요. 이 컨테이너는 어디로든 배송되며, 시스템이 컨테이너 엔진(예: 도커)을 가지고 있다면, 여러분이 의도한 대로 모델이 모든 환경에서 정확히 실행됩니다. 컨테이네이션이 MLOps에 미치는 영향은 다음과 같습니다:\n\n- 재현성의 구원자! ‍♀️ 컨테이너는 MLOps 파이프라인의 모든 단계에서 동일한 환경을 보장합니다. 이는 '내 컴퓨터에서는 작동하는데'와 같은 문제를 제거하여 모든 곳에서 일관된 모델 성능을 보장합니다.\n- 배포가 쉬워집니다: 컨테이너는 가벼우며 휴대 가능하여 다양한 플랫폼(클라우드 또는 온프레미스)에 모델을 쉽게 배포할 수 있습니다. 몇 초만에 새로운 인스턴스를 구동하고 예측 서비스를 제공할 준비가 됩니다!\n- 격리로 정리를 유지합니다: 컨테이너는 서로와 호스트 시스템과 격리됩니다. 이는 서로 다른 모델이나 라이브러리 간 충돌을 방지하여 MLOps 파이프라인을 안정적이고 안전하게 유지합니다.\n- 확장성 승리! 더 많은 데이터나 예측을 처리해야 한다면? 문제 없습니다! 파이프라인에 더 많은 컨테이너를 추가하기만 하면 됩니다. 컨테이너는 여러분의 요구에 기반하여 쉽게 확장하거나 축소할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 도구:\n\n1. Docker: 컨테이너화의 원조. Docker는 컨테이너를 구축, 공유 및 실행하는 사용자 친화적인 플랫폼입니다. 초보자나 작은 MLOps 프로젝트에 좋은 선택지입니다.\n\n2. Kubernetes: 컨테이너 오케스트레이션 챔피언. MLOps 파이프라인에서 함께 작동하는 많은 컨테이너가 있을 때, Kubernetes는 그 모든 것을 관리하는 데 도움을 줍니다. 배포, 스케일링 및 회복을 자동화하여 컨테이너화된 모델이 원활하게 실행되도록 보장합니다.\n\n내 글을 읽어 주셔서 감사합니다; 내 컨텐츠가 마음에 들었다면 Patreon에서 지원하는 것이 최선입니다 —\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_7.png\" /\u003e\n\n- YouTube 채널 구독하기\n- 웹사이트 방문하기\n- LinkedIn 및 Github에 연결하여 기술 및 AI를 활용하여 생산성과 효율성을 높이기 위해 무료로 제공되는 멋진 컨텐츠를 공유합니다.\n- ML 및 DL에 도움이 필요하다면 Fiverr 서비스 확인하기!","ogImage":{"url":"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0.png"},"coverImage":"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0.png","tag":["Tech"],"readingTime":8}],"page":"9","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"9"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>