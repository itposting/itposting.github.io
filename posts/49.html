<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/49" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/49" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="프록시목스Proxmox LXC에 포토프리즘Photoprism 설치하기" href="/post/2024-06-20-ProxmoxInstallingPhotoprisminLXC"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="프록시목스Proxmox LXC에 포토프리즘Photoprism 설치하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="프록시목스Proxmox LXC에 포토프리즘Photoprism 설치하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">프록시목스Proxmox LXC에 포토프리즘Photoprism 설치하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="여행가방 이야기" href="/post/2024-06-20-TheStoryoftheTravelingBag"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="여행가방 이야기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-TheStoryoftheTravelingBag_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="여행가방 이야기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">여행가방 이야기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="유기농 아몬드버터 종교" href="/post/2024-06-20-OrganicAlmondButterReligion"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="유기농 아몬드버터 종교" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-OrganicAlmondButterReligion_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="유기농 아몬드버터 종교" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">유기농 아몬드버터 종교</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="하드웨어 패스키로 안드로이드 장치 잠금 해제하기 Digispark Attiny85 사용 가이드" href="/post/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="하드웨어 패스키로 안드로이드 장치 잠금 해제하기 Digispark Attiny85 사용 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="하드웨어 패스키로 안드로이드 장치 잠금 해제하기 Digispark Attiny85 사용 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">하드웨어 패스키로 안드로이드 장치 잠금 해제하기 Digispark Attiny85 사용 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Niels, 러스트를 배우다 4 - VM을 모듈화하는 세 가지 다른 방법" href="/post/2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Niels, 러스트를 배우다 4 - VM을 모듈화하는 세 가지 다른 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Niels, 러스트를 배우다 4 - VM을 모듈화하는 세 가지 다른 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">Niels, 러스트를 배우다 4 - VM을 모듈화하는 세 가지 다른 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="IoT ESP32가 MQTT Broker에 연결하기 위해 SSL TLS 인증서를 사용하는 방법 파트 2" href="/post/2024-06-20-IoTESP32usingssltlscertificatetoconnectwidthMQTTBrokerPart2"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="IoT ESP32가 MQTT Broker에 연결하기 위해 SSL TLS 인증서를 사용하는 방법 파트 2" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-IoTESP32usingssltlscertificatetoconnectwidthMQTTBrokerPart2_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="IoT ESP32가 MQTT Broker에 연결하기 위해 SSL TLS 인증서를 사용하는 방법 파트 2" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">IoT ESP32가 MQTT Broker에 연결하기 위해 SSL TLS 인증서를 사용하는 방법 파트 2</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="짝커 - 아두이노로 박수 감지 스위치를 만드는 방법" href="/post/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="짝커 - 아두이노로 박수 감지 스위치를 만드는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="짝커 - 아두이노로 박수 감지 스위치를 만드는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">짝커 - 아두이노로 박수 감지 스위치를 만드는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="소형 머신 러닝 - 주성분 분석" href="/post/2024-06-20-TinyMLPrincipalComponentAnalysis"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="소형 머신 러닝 - 주성분 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="소형 머신 러닝 - 주성분 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">소형 머신 러닝 - 주성분 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마이크로 머신러닝  합성곱 신경망 CNN" href="/post/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마이크로 머신러닝  합성곱 신경망 CNN" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마이크로 머신러닝  합성곱 신경망 CNN" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">마이크로 머신러닝  합성곱 신경망 CNN</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">23<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="시리얼 통신 마스터하기 아두이노 메가 2560 마스터와 우노 슬레이브 UART 튜토리얼" href="/post/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="시리얼 통신 마스터하기 아두이노 메가 2560 마스터와 우노 슬레이브 UART 튜토리얼" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="시리얼 통신 마스터하기 아두이노 메가 2560 마스터와 우노 슬레이브 UART 튜토리얼" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">시리얼 통신 마스터하기 아두이노 메가 2560 마스터와 우노 슬레이브 UART 튜토리얼</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link posts_-active__YVJEi" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"프록시목스Proxmox LXC에 포토프리즘Photoprism 설치하기","description":"","date":"2024-06-20 17:14","slug":"2024-06-20-ProxmoxInstallingPhotoprisminLXC","content":"\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_0.png)\n\nPhotoprism은 AI 기반의 멋진 사진 관리 서비스로, 여러분의 사진을 색인화, 보기 및 공유할 수 있습니다. 해당 기능에 대해 자세히 알아볼 수 있는 공식 웹사이트가 있습니다. 오늘은 가정 환경에서 Proxmox의 LXC 컨테이너에 이를 설치해 보겠습니다.\n\n## 요구 사항:\n\n- Proxmox가 완전히 설치되고 구성되어 있으며 GUI에 액세스할 수 있어야 합니다.\n- 정적 IP 주소를 설정하고 정적 IP, DHCP 범위에 대한 기본적인 지식이 있는 라우터 제어 패널에 액세스해야 합니다.\n- 사진 및 섬네일에 충분한 스토리지 공간이 있어야 합니다. (대부분의 컬렉션은 총 200GB까지 용량을 차지할 수 있다고 알려져 있습니다. 이 강좌에서는 NAS의 네트워크 공유를 사용할 것이지만, 원하는 경우 로컬 디스크의 폴더를 사용할 수도 있습니다.)\n- 터미널에 대한 기본 지식이 필요합니다. (파일을 열고 저장하는 등)\n- Proxmox 컨테이너에 대한 기본 지식이 필요합니다. (LXC 템플릿 다운로드, 컨테이너 설정 등)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 컨테이너 생성:\n\n다음 리소스를 사용하여 컨테이너를 생성하세요:\n\n- 선택한 호스트 이름 (컨테이너 이름)을 가진 관리자 권한이 있는 컨테이너를 만듭니다.\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n-  당신이 좋아하는 리눅스 플레이버는 무엇인가요? 저는 여기서 Debian 11을 사용했어요.\n- ~16GB의 루트 저장공간입니다. (사진을 저장하기에는 절대 충분하지 않아요. 외부 저장공간을 꼭 사용하시길 강력히 추천드려요. 제 개인 NAS에서 저장 공간을 사용하겠습니다.)\n\n![첨부된 이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_2.png)\n\n- 시스템의 모든 코어를 사용하세요 (4~8개가 좋습니다).\n\n![첨부된 이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 8GB RAM 이상, 4GB 스왑 이상이 필요합니다.\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_4.png)\n\n- DHCP IPv4 주소를 선택하시고, 나중에 라우터에서 설정할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 나머지는 기본값으로 둔 채로 컨테이너를 시작하지 마세요.\n- 컨테이너 측면 표시줄의 옵션으로 이동하여 다음을 활성화하세요:\n\n```js\nnesting=1\nSMB/CIFS=1 # 외부 공유를 사용하는 경우에만 선택적으로 필요\n```\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_6.png)\n\n- 이제 컨테이너를 시작하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## IP 주소 설정하기:\n\n정적 IP 주소를 설정하면 서비스에 더 쉽게 액세스할 수 있습니다.\n\n이 단계는 라우터마다 다를 수 있습니다. 제어 패널에 로그인해야 합니다. 일반적으로 192.168.xxx.1을 통해 액세스할 수 있습니다. 그리고 컨테이너에 정적 IP 주소를 추가하셔야 합니다. 정적 IP 할당이 DHCP 할당 범위와 겹치지 않도록 주의하셔야 합니다. 일반적으로 정적 IP에는 192.168.xxx.1~192.168.xxx.50을 추천합니다.\n\n참고: 만약 컨테이너가 라우터 장치 목록에 나타나지 않으면, 컨테이너로 돌아가 apt update를 실행하고 라우터 화면을 새로고침하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대부분 인기있는 라우터에 대해 이 작업을 하는 방법을 다루는 YouTube 동영상이 많이 있습니다. 이 작업을 완료한 후 컨테이너를 다시 부팅하십시오. Proxmox를 다시 부팅할 필요는 없습니다.\n\n## 스토리지 설정:\n\n이전에 언급했던 대로 16Gb의 부팅 디스크 공간은 대량의 섬네일이나 사진을 저장하기에 부족합니다. Proxmox 호스트 디스크에 충분한 공간이 있고 lvm 스토리지로 적절히 구성된 경우, 부팅 디스크에 200-300GB의 스토리지를 추가하고 계속 진행할 수 있습니다.\n\n저는 컨테이너 부팅 디스크에 파일을 저장하는 것을 좋아하지 않으며 가능한 한 작게 유지합니다. Proxmox 호스트 디스크가 가득 차는 경우... 복구는 가능하지만 절대로 처지고 싶지 않은 상황입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 경우에는 NAS가 있어서 192.168.xxx.yy에 위치한 appdata라는 SMB 공유 폴더를 노출시킵니다.\n\n필요한 패키지를 설치하십시오:\n\n```js\napt install cifs-utils\n```\n\n마운트 폴더를 생성하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\n/media/appdata를 만들기\r\n```\n\nSMB 자격 증명 파일을 만들기:\n\n```js\r\n/root/.smb에 nano 사용\r\n```\n\n다음과 같이 자격 증명을 파일에 추가하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n사용자 이름=당신의_사용자_이름\n비밀번호=당신의_비밀번호\n```\n\nfstab 설정하기:\n\n```js\nnano /etc/fstab\n```\n\n다음 줄을 추가하십시오:\n설정에 맞게 192.168.xxx.yy/appdata를 변경하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n//192.168.xxx.yy/appdata /media/appdata cifs credentials=/root/.smb,uid=0,gid=0,dir_mode=0777,file_mode=0777,users,rw,iocharset=utf8,noperm 0 0\n```\n\n이제 `mount -a`를 실행하여 공유를 마운트하세요.\n\n## Photoprism 설치:\n\n이제 컨테이너와 저장소가 설정되었으므로 Photoprism을 설치할 준비가 되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기존 패키지를 업데이트하세요:\n\n```bash\napt update \u0026\u0026 apt upgrade\n```\n\n필요한 패키지를 설치하세요:\n\n```bash\napt install -y gcc g++ git gnupg make zip unzip ffmpeg exiftool darktable libpng-dev libjpeg-dev libtiff-dev imagemagick libheif-examples\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNode.js 설치하기:\n\n```js\nwget https://deb.nodesource.com/setup_18.x -O node_setup.sh\nchmod +x node_setup.sh\n./node_setup.sh\napt install -y nodejs\nrm node_setup.sh\n```\n\nGoLang 설치하기:\n본 안내서 작성 시점에서 1.20.6 버전이 최신입니다. 최신 버전을 확인하려면 웹 사이트를 방문하여 URL을 변경해 주세요.\n\n```js\nwget https://golang.org/dl/go1.20.6.linux-amd64.tar.gz\nrm -rf /usr/local/go\ntar -C /usr/local -xzf go1.20.6.linux-amd64.tar.gz\nln -s /usr/local/go/bin/go /usr/local/bin/go\nrm go1.20.6.linux-amd64.tar.gz\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n텐서플로우 설치:\n이 버전은 AVX2 호환 CPU용입니다 (현대적인 CPU 대부분이 해당됩니다). Photoprism 웹사이트에서 단순히 AVX 용이나 AVX를 지원하지 않는 CPU 용 버전을 찾을 수 있습니다.\n\n```js\nwget https://dl.photoprism.org/tensorflow/linux/libtensorflow-linux-avx2-1.15.2.tar.gz\nsudo tar -C /usr/local -xzf libtensorflow-linux-avx2-1.15.2.tar.gz\nsudo ldconfig\nrm libtensorflow-linux-avx2-1.15.2.tar.gz\n```\n\nPhotoprism 다운로드 및 설치:\nPhotoprism을 빌드하는 과정에서 많은 메모리가 사용될 수 있습니다. 여기서처럼 컨테이너를 구성한 경우 오류가 발생하지 않아야 합니다. 메모리 부족(OOM) 오류가 발생하면 이를 확인하고 각 make 단계를 개별적으로 실행하세요.\n\n```js\nmkdir -p /opt/photoprism/bin\ngit clone https://github.com/photoprism/photoprism.git\ncd photoprism\ngit checkout release\nmake all\n./scripts/build.sh prod /opt/photoprism/bin/photoprism\ncp -a assets/ /opt/photoprism/assets/\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 구성:\n\nPhotoprism의 작업 디렉토리를 만들고 구성 파일을 추가하세요.\n전체 구성 옵션은 여기를 참조하세요.\n\n```js\nmkdir /var/lib/photoprism\nnano /var/lib/photoprism/.env\n```\n\n다음을 구성 파일에 추가하세요:\n기본 SQLite 데이터베이스를 작은 컬렉션 이외의 것에는 권장하지 않습니다. 이를 위해 MariaDB를 사용하는 것을 고려해보세요. MariaDB를 설치하는 방법에 대한 별도 가이드가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저장 요소를 변경하려면 Photoprism 저장 경로를 마운트된 폴더로 변경해야 합니다. 저의 경우에는 /media/appdata가 될 것입니다.\n\n```js\n# 초기 admin 사용자의 비밀번호\nPHOTOPRISM_AUTH_MODE=\"password\"\nPHOTOPRISM_ADMIN_PASSWORD=\"photoprism\"\n\n# Photoprism 저장 디렉터리\nPHOTOPRISM_STORAGE_PATH=\"/var/lib/photoprism\"\nPHOTOPRISM_ORIGINALS_PATH=\"/var/lib/photoprism/photos/Originals\"\nPHOTOPRISM_IMPORT_PATH=\"/var/lib/photoprism/photos/Import\"\n\n# SQLite 대신 MariaDB/MySQL을 사용하는 경우 아래 주석 해제 (기본 설정값)\n# PHOTOPRISM_DATABASE_DRIVER=\"mysql\"\n# PHOTOPRISM_DATABASE_SERVER=\"MYSQL_IP_HERE:PORT\"\n# PHOTOPRISM_DATABASE_NAME=\"DB_NAME\"\n# PHOTOPRISM_DATABASE_USER=\"USER_NAME\"\n# PHOTOPRISM_DATABASE_PASSWORD=\"PASSWORD\"\n```\n\nPhotoprism 서비스 설정:\nPhotoprism이 부팅될 때 시작되도록 설정합니다.\n\n서비스 정의 파일 생성:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnano /etc/systemd/system/photoprism.service\n```\n\n서비스 파일에 다음을 추가하세요:\n\n```js\n[Unit]\nDescription=PhotoPrism 서비스\nAfter=network.target\nStartLimitIntervalSec=500\nStartLimitBurst=5\n\n[Service]\nType=simple\nRestart=on-failure\nRestartSec=5s\nWorkingDirectory=/opt/photoprism\nEnvironmentFile=/var/lib/photoprism/.env\nExecStart=/opt/photoprism/bin/photoprism up\nExecStop=/opt/photoprism/bin/photoprism down\n\n[Install]\nWantedBy=multi-user.target\n```\n\n이제 데몬을 다시로드하고 서비스를 시작하세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nsystemctl daemon-reload\nsystemctl start photoprism\nsystemctl enable photoprism\n```\n\n서비스 상태를 확인하세요:\n\n```js\nsystemctl status photoprism\n```\n\n모든 것이 잘 실행됐다면 (활성화된 상태는 녹색으로 표시됩니다):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_7.png)\n\n지금은 이전에 설정한 IP 주소와 포트 2342를 통해 서버에 액세스할 수 있어야 합니다.\n\n```js\nhttp://YOUR-IP:2342\n```\n\n## 크레딧:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n포토프리즘 설치는 아래 안내서를 기반으로 진행되었고, 제게는 너무나 귀중한 정보입니다. 문제 해결이 필요할 때 대비하여 읽어보는 것을 고려해보세요.\n\n고지사항:\n\n이 문서는 프로덕션 또는 비즈니스 환경에서의 설정을 위한 안내서가 아니며, 공개 인터넷에 노출할 준비가 된 상태가 아닙니다.\n\n저는 IT 전문가가 아닙니다. 기술 지원도 제공하지 않습니다. 서버를 가진 대학생입니다. 시스템에서 실행하는 모든 명령어에 대한 최종 책임은 여러분에게 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n질문이 있으면 댓글을 남겨주세요. 즐거운 시간 보내세요!","ogImage":{"url":"/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_0.png"},"coverImage":"/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_0.png","tag":["Tech"],"readingTime":8},{"title":"여행가방 이야기","description":"","date":"2024-06-20 17:12","slug":"2024-06-20-TheStoryoftheTravelingBag","content":"\n\n## 예술 | 창의력 | 공예 | 바느질\n\n![여행가방](/assets/img/2024-06-20-TheStoryoftheTravelingBag_0.png)\n\n이 가방이 있는데, 이건 그냥 평범한 가방이 아니에요. 이 세상 많은 것을 경험했어요.\n\n나는 이를 여행가방이라고 부르죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 정확히 어디서 구매했는지는 정확히 기억이 나지 않지만 쇼핑을 한 곳은 쇼핑몰이었고 부모님과 함께 여행 중이었습니다. 제가 반드시 16세에서 19세 사이에 있었을 때였고, 백화점에서 옷걸이에 걸려 있는 것을 아직도 기억합니다.\n\n왜 그 가방을 선택했는지 정확히는 모르겠습니다. 멋진 패턴이나 안쪽에 반전할 수 있는 다른 패턴이 있어서 그랬을 수도 있습니다. 아니면 그냥 제 돈을 쓸 수 있는 즐거움이 크게 작용했을 수도 있습니다.\n\n어떤 이유에서든, 그 가방에 매료되었고, 이 가방은 분명히 제 가장 소중한 소유물 중 하나입니다. 거의 30년이 지난 지금까지도 함께 있습니다! 우리가 2017년에 모든 것을 판매해서 만큼을 전 세계를 여행하는 큰 변화를 겪을 때도 살아남았고, 제 파트너와 함께 많은 나라를 여행하기도 했습니다.\n\n![여행가방 이야기](/assets/img/2024-06-20-TheStoryoftheTravelingBag_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한동안 지나면서 가방이 부패하기 시작했습니다. 우리는 절대적으로 모든 것에 사용하고 있는데, 평범한 면으로 만들어진 것이기 때문에 그럴 만하죠. 먼저, 스트랩이 풀어지기 시작했어요 - 그건 쉽게 해결할 수 있었어요. 어느 날 시장에서 스트랩 소재를 발견하고 새로운 것을 손으로 봉제할 수 있었습니다. 기존 스트랩을 바로 끊기보다는 짧게 잘랐다가 새로운 스트랩에 봉제했어요. 또한 카라비너으로 가방에 뭔가를 걸고 싶을 때 루프를 추가했어요, 예를 들어 물병 등.\n\n저는 스트랩을 가방에 직접 봉합함으로써 스트랩과 가방이 만나는 부분이 약해진 지점을 보강했습니다.\n\n우리가 터키 이스탄불에 있을 때, 저희는 꿈같은 수공예 상점을 우연히 만났어요. 그 상점에서 본 물건들은 정말 대단했고, 그날 찍은 영상을 공유하고 싶었어요. 어떤 창의적인 사람이라도 천국에 갔다온 듯한 느낌을 받았을 거예요.\n\n안타깝게도 우리에겐 많은 돈이 없어서 심각하게 쇼핑은 안 하고 둘러보기만 했지만, 눈여겨본 것 중 하나는 패치들이었어요. 그때쯤이면 내 사랑하는 가방에 구멍이 나기 시작했고, 사용하는 데 조심해야 했어요. 언젠가는 수리할 수 없을 정도로 찢어질까 걱정하는데, 무엇보다도 채소나 운반품 등이 바닥으로 떨어질까 걱정했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 순간 나는 패치들이 가방의 구멍들을 메울 수 있는 필요한 것이라는 것을 깨달았어요. 그 가방을 어떻게든 구할 수 있기를 간절히 바랬죠.\n\n우리는 주로 같은 패치들로 이뤄진 10개 패치 세트만 구매할 수 있었어요. 그래도 패키지는 저렴했어요. 한 세트에 대략 $2-3 정도였죠. 나는 멋진 버섯, 설탕 두개골, 그리고 벌 한 마리 패키지를 사게 되었어요. 나는 벌 패치만 따로 사진이 있고, 다른 패치들은 가방에 붙어 있을 거에요.\n\n![bee](/assets/img/2024-06-20-TheStoryoftheTravelingBag_2.png)\n\n또한 그 날에 자수실을 구입해서 가방 상단을 강화하는 데 사용했고, 장식적으로 나선 모양을 만드는 데도 사용했어요. 그 때는 결국 전체 가방을 자수할 것이라고 생각했어요. 하지만, 얼마나 많은 노력이 필요한지 깨달은 후에, 그 꿈은 길지 않게 사라지게 되었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 아래에서 확인할 수 있듯이 몇 가지 자수 작업을 한 것 같아요. 가방의 약한 부분을 강화하는 데 효과가 있었어요.\n\n![image](/assets/img/2024-06-20-TheStoryoftheTravelingBag_3.png)\n\n이제는 가방에 다른 부분들을 봉제하기도 시작했어요. 네팔에서 얻은 낡은 티셔츠가 있었는데, 그것을 가방에 있는 원하는 부분을 자르고, 그것을 봉았어요. 우리가 2019년에 카리브해의 식물원에서 봉사를 한 봉사복도 있었는데, 그옷에서 패치를 자르고, 가방에 봉았어요.\n\n저는 이 가방을 우리의 여행과 경험의 대표로 만들고 싶다는 것을 깨달았어요. 그래서 우리가 방문한 나라들에서 패치를 찾아 추가하기 시작했어요. 또한 캐나다 패치를 가지고 다니고 있었는데, 봉제할 곳이 필요했고, 마침 이제 그 곳이 생겼어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n조금씩, 시간을 들여 가며, 다가오는 멸망으로부터 가방을 살리기 위해 필사적인 노력을 했습니다.\n\n2022년에 만든 가방을 보세요. 가장자리 주위에 자수 실이 더 잘 보이고, 또한 티셔츠의 다른 조각들을 이어 붙이는 데도 사용했어요. 맞아요, 1996년 네팔에서 받은 티를 입었던 거죠. 나를 향수로 그리게 만들어.\n\n지금 가방에 있는 파란색이 어디서 왔는지 궁금할 텐데, 그것은 우간다에서 도색을 하다 우리가 가방을 들고 작업하고 있을 때 직원 중 한 명이 가방 옆에 컨테이너에 파란색 페인트를 엎었을 때 생긴 것이에요. 우리는 바로 알아차리지 못했는데, 알아차린 때에는 이미 절반 정도 말랐더라고요.\n\n그래, 결정했습니다. 결국 이 가방은 창의적인 가방이니까요, 우리는 벽화 화가니까 말이죠. 테마에 딱 맞는 가방인 거 같네요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 가방은 꽤 오랫동안 이런 식으로 존재했어요. 하지만 상상할 수 있겠지만, 벌어진 곳들이 점점 더 더러워지고 얇아지고 있다는 걸 알았어요. 이 가방을 완전히 살리고 싶다면 더 많은 패치를 구하고 생산량을 늘려야 한다는 걸 알았죠.\n\n그리고 2023년 캐나다로 돌아왔을 때, 가족과 친구를 만나고 재정 문제를 정리하러 다시 방문했어요. 몇 달 동안만 돌아올 계획이었는데, 여행에서 좀 더 긴 휴식이 필요하다고 깨달았어요. 이제 거의 1년 동안 돌아와 있다는 사실에 놀라고 있어요.\n\n어느 날, 크리스의 엄마를 만나러 갔는데 갑자기 영감이 떠올랐어요. 그녀는 바느질을 잘하시고 다양한 것들을 만드시는데요 — 퀼트, 앞치마 등이죠. 그녀가 패브릭 조각이 좀 있을 거라고 생각했고, 그걸 이용해서 가방에 덧대면 더 견고해질 수 있지 않을까 생각했어요.\n\n패브릭을 다룬다면, 얼마나 어처구니 없는 질문인지 아실 거예요. 그녀는 나를 바느질 방으로 데려가 데스크 서랍 가득한 패브릭 조각을 보여주었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 황야에 있었어요.\n\n서랍을 헤집어서 원하는 패턴을 골라내고, 가방에 원하는 부분을 자르고, 그리고 바쁘게 그것들을 바느질로 달았어요. 지그재그 스티치를 사용해서 가방에 직접 달았는데, 모양이 어떻게 되었는지는 크게 신경쓰지 않았어요. 제 주요 목표는 가방을 강화하는 것이었기 때문에 완벽함에 대해서는 걱정하지 않았어요.\n\n몇 시간 후, 지하실에서 나와서 제 작품을 보여주었어요. 그녀가 바느질에서 얼마나 정교한지 알고 있기 때문에, 정말로 무엇을 생각했을지 궁금하기도 해요 — 하지만 그녀는 그것을 좋아했다고 말했어요.\n\n하나 또는 두 개의 장점은 분명히 더 다채롭게 보이긴 해요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여러분들도 보시다시피, 우리가 방문한 장소들의 다른 패치들을 발견하여 믹스에 추가했습니다. 시간이 흐를수록 이를 계속 추가하고, 우리의 여행 이야기를 담은 패치워크가 되길 바랍니다.\n\n![이미지](/assets/img/2024-06-20-TheStoryoftheTravelingBag_4.png)\n\n요즘 가방은 훨씬 더 강해 졌고, 시간의 시험을 견디리라는 것을 알게 되었습니다. 어떻게 그리고 왜 나에게 가장 소중한 소지품 중 하나가 되었는지는 아직도 잘 모르지만, 앞으로도 많은 해 동안 사용할 기대가 되네요.\n\n이 이야기는 다른 'Share Your Creativity' 작가, Chloe ~ Calendula Craft와 그녀의 기억을 담은 퀼트를 만드는 기사에서 영감을 받았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n창의력을 공유하고 싶다면, 제 출판물에 창의적인 글을 제출해보는 것을 고려해보세요:\n\n![TheStoryoftheTravelingBag](/assets/img/2024-06-20-TheStoryoftheTravelingBag_5.png)\n\n제 글이 마음에 들고 더 읽고 싶다면, 저를 팔로우하고 여기에서 이메일로 제 글을 받아보실 수 있도록 가입해주세요. 또한 Patreon이나 Ko-Fi 링크를 통해 팁을 보내주시면 저희가 매우 기쁠 것입니다:)\n\n2017년부터 우리는 유목민의 삶을 살아왔어요! 아래 링크를 클릭해 우리의 여정에 동행해보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n웹사이트 | 인스타그램 | 페이스북 | 링크드인 | 패트리언 | 유튜브 | 미디엄 | 트위터 | 코-피 | 언스플래시","ogImage":{"url":"/assets/img/2024-06-20-TheStoryoftheTravelingBag_0.png"},"coverImage":"/assets/img/2024-06-20-TheStoryoftheTravelingBag_0.png","tag":["Tech"],"readingTime":5},{"title":"유기농 아몬드버터 종교","description":"","date":"2024-06-20 17:11","slug":"2024-06-20-OrganicAlmondButterReligion","content":"\n\n\n![Organic Almond Butter](/assets/img/2024-06-20-OrganicAlmondButterReligion_0.png)\n\n우리는 아몬드를 믿고, 아몬드 버터를 땅콩 버터보다 더 좋아해요. 아몬드 버터는 유기농이 아니어도 꽤 비싸요. 유기농 라벨에 대한 프리미엄이 더 높아져요.\n\n## 직접 만들어요\n\n우리는 유기농 아몬드로부터 직접 우리만의 유기농 아몬드 버터를 만들어요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아몬드는 아몬드 버터보다 파운드당 훨씬 싸요. 대량 구매로 가격을 매우 합리적으로 만들 수 있어요!\n\n직접 아몬드 버터를 만들면 같은 유리 캐닝 병을 계속해서 재사용할 수 있어요. 모든 면에서 폐기물이 줄어들어요.\n\n아몬드 + 전기 + 시간 = 아몬드 버터\n\n우리는 유기농 아몬드 한 쿼트로 시작해요. 350도 F의 오븐에서 쿠키 시트에 로스팅해서 10~15분간 굽고 식힌 후, 푹 갈라 놓기 위해 음식 가공기에 넣어서 칼날로 약 20분간 갈아요. 원하는 조직감에 도달할 때까지요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그들이 갈고 있는 동안, 우리는 맛을 내기 위해 소금을 1/4 티스푼 넣습니다. 아몬드 1쿼트는 약 절반의 양으로 아몬드 버터를 만들어 냅니다.\n\n## 배운 교훈\n\n우리는 머신이 매우 뜨거워지고 아몬드 버터를 만드는 데 최대 한 시간이 걸렸던 생 아몬드로 시작했습니다. 아몬드를 볶음으로 만들 때, 가공 속도가 빨라지며 기계에 더 적은 감손을 줍니다. 더 짧은 가동 주기로 전기를 절약하고, 귀에 덜 무리가 갑니다.\n\n푹푹 끓일 때 소금을 넣으세요. 이렇게 하면 푸레터에 소금 뭉치가 생기는 것을 방지할 수 있습니다. 어떤 사람들은 이것을 좋아할 수도 있지만, 우리는 싫습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-20-OrganicAlmondButterReligion_1.png)\n\nStory enjoyed? Join Sweet Publications!\n\nSweet.pub is a family of three — 💚 Short, 💙 Long, and 🧡 Deep.\nExplore stories that will make your 🤍 beat!\n\nThis article was published on June 19th, 2024 in the Short. Sweet. Valuable. publication.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Organic Almond Butter Religion](/assets/img/2024-06-20-OrganicAlmondButterReligion_2.png)\n","ogImage":{"url":"/assets/img/2024-06-20-OrganicAlmondButterReligion_0.png"},"coverImage":"/assets/img/2024-06-20-OrganicAlmondButterReligion_0.png","tag":["Tech"],"readingTime":2},{"title":"하드웨어 패스키로 안드로이드 장치 잠금 해제하기 Digispark Attiny85 사용 가이드","description":"","date":"2024-06-20 17:09","slug":"2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85","content":"\n\n우리 모두 한 번쯤은 그 순간을 겪어봤죠—핸드폰 잠금 상태에서 핀 코드를 기억하지 못하는 그 순간. 무수히 입력했지만 이제 손가락이 주저하는 그 순간. 근육 기억에 의지하지만 그것조차 실망스러운 것 같아요. 이런 순간들이 우리에게 이 중요한 보안 코드를 잊어버리기 쉬운지 상기시켜 줍니다.\n\n다행히도 이 문제에 대한 혁신적인 해결책이 즉시 사용 가능한 것 같아요. 이 해결책은 보통의 비밀번호 알림과는 다릅니다. 하드웨어 패스키입니다—당신의 핸드폰이나 컴퓨터에 연결되면 핀 코드를 자동으로 입력해주는 소형 회로입니다. 이 기술적인 놀라움은 주로 10달러 미만으로 구할 수 있는 저렴한 Digispark Attiny85 보드로 구현할 수 있어요.\n\n본 기사에서는 직접 하드웨어 패스키를 만드는 단계별 가이드를 안내해 드릴게요.\n\n![이미지](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 요구 사항:\n\n- Windows 컴퓨터\n- Digispark Attiny85 보드\n- 안드로이드 폰\n- 아두이노 소프트웨어\n\n# 아두이노 설정\n\n- 공식 웹사이트에서 아두이노 다운로드\n- 파일 -` 기본 설정 -` 설정 -` 추가 보드 관리자 URL로 이동\n- 다음 URL을 목록에 추가하고 저장: https://raw.githubusercontent.com/digistump/arduino-boards-index/master/package_digistump_index.json\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Step 1](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_1.png)\n\n- Go to Tools -\u003e Board -\u003e Boards Manager..., search for “digistump”, and install “Digistump’s AVR Boards”.\n\n![Step 2](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_2.png)\n\n![Step 3](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Windows 10 사용자들은 usbser 드라이버 설치 중 실패할 수 있습니다. 그런 경우에는 여기서 직접 다운로드할 수 있습니다: [https://github.com/digistump/DigistumpArduino/releases/download/1.6.7/Digistump.Drivers.zip](https://github.com/digistump/DigistumpArduino/releases/download/1.6.7/Digistump.Drivers.zip) 다운로드한 파일을 압축 해제하고 DPinst64.exe를 실행하여 드라이버를 설치하세요.\n- 아두이노 인터페이스에서 Tools -` Board -` Digistump AVR Boards -` Digispark (Default 16.5 MHz)를 선택하세요.\n\n![이미지](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_4.png)\n\n설정이 완료되었습니다! 이제 스케치 코드를 작성할 준비가 되었습니다!!\n\n# 페이로드 코딩\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 스케치에는 두 가지 미리 정의된 함수가 있습니다: setup()과 loop(). 이 튜토리얼에서는 PIN 코드가 '1234'라고 가정해봅시다. 우리의 코드는 다음과 같이 보일 것입니다:\n\n```js\n#include \"DigiKeyboard.h\"\n\nvoid setup() {\n  // setup에서 할 일이 없습니다.\n}\n\nvoid loop() {\n  // 이 지연은 컴퓨터가 DigiSpark를 인식하는 데 시간을 주기 위한 것입니다.\n  // 연결 후 2000밀리초는 2초입니다.\n  DigiKeyboard.delay(2000);\n\n  // 이제 PIN에 대한 키 입력을 보낼 것입니다.\n  DigiKeyboard.println(\"1234\");\n\n  // PIN을 입력한 후, 다시 입력하기 전에 오랜 지연을 할 것입니다.\n  // 이는 DigiSpark가 플러그를 꽂은 채로 있는 경우 계속해서 PIN을 입력하지 않도록 방지하기 위한 것입니다.\n  DigiKeyboard.delay(60000);\n}\n```\n\n이 코드를 입력한 후, \"Verify\" 버튼을 클릭하여 컴파일 및 오류 확인을 실행해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지 태그를 Markdown 형식으로 변경하세요.\n\n\n![Unlocking Your Android Device with a Hardware Passkey - A Guide to Using Digispark Attiny85](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_6.png)\n\n![Unlocking Your Android Device with a Hardware Passkey - A Guide to Using Digispark Attiny85](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_7.png)\n\n# 페이로드 업로드\n\nAttiny85 보드에 코드를 업로드하는 중:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 아두이노 인터페이스에서 업로드 버튼을 클릭하세요.\n\n![이미지](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_8.png)\n\n- \"지금 장치를 연결하세요... (60초 후 타임아웃)\"라는 메시지가 나오면 Attiny85 보드를 컴퓨터의 USB 포트에 연결하세요.\n\n![이미지](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- \"Micronucleus done. Thank you!\" 메시지가 표시될 때까지 기다렸다가 USB 포트에서 보드를 제거해주세요.\n\n![이미지](/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_10.png)\n\n축하합니다! 이제 하드웨어 패스키를 사용할 준비가 되었습니다.\n\n# 패스키 테스트:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWindows에서는 메모장을 열고 패스키를 연결하세요. 자동으로 PIN 코드를 입력해줄 것입니다.\n\n## 온라인 PIN 저장소 또는 비밀번호 관리자보다 하드웨어 패스키의 장점:\n\n- 오프라인 저장: 하드웨어 패스키는 오프라인이므로 온라인 해킹에 취약성이 낮습니다. 당신의 PIN은 인터넷 서버에 저장되지 않아 보안이 향상됩니다.\n- 타사 신뢰 불필요: 비밀번호 관리 애플리케이션과는 달리, 하드웨어 패스키는 데이터를 보호하기 위해 제3자에게 신뢰를 두지 않아도 됩니다.\n- 마스터 비밀번호 필요 없음: 비밀번호 관리자는 마스터 비밀번호가 필요한데, 이를 잊어버리면 잠금 상태가 될 수 있습니다. 하드웨어 패스키는 PIN을 자동 입력하여 이 문제를 피할 수 있습니다.\n\n기억하세요, 완벽한 해결책은 없습니다. 하드웨어 패스키에는 잠재적인 보안 문제도 있으니 아래 섹션에서 자세히 설명하겠습니다. 당신의 디지털 보안 요구 및 편안함에 맞는 최상의 솔루션을 선택하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 하드웨어 패스키에 대한 잠재적 보안 위험:\n\n하드웨어 패스키는 기기 접근을 간단하게 만들지만, 관련된 보안 문제를 고려하는 것이 중요합니다:\n\n- 물리적 보안: 분실되거나 도난당하면 패스키를 사용하여 당신의 기기에 무단 접근할 수 있습니다. 안전하게 보관하세요.\n- 악성 소프트웨어: 프로그래밍 기기가 감염되면 악성 소프트웨어가 패스키에 감염될 수 있습니다. 최신 백신 소프트웨어로 기기를 보호하세요.\n- 하드코딩된 PIN: 숙련된 개인이 패스키에서 하드코딩된 PIN을 추출할 수 있습니다. 안전하게 다루세요.\n\n편리하더라도, 이러한 잠재적 보안 위험을 고려하여 하드웨어 패스키를 책임있게 사용하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 마무리 글\n\n저렴한 Digispark Attiny85 보드로 구동되는 하드웨어 패스키는 잊혀진 PIN에 대한 일반적인 문제에 효과적이고 오프라인 솔루션을 제공합니다. 온라인 저장소나 비밀번호 관리 앱 대안으로 사용자 친화적이며 편리함과 통제를 동시에 제공합니다.\n\n그러나 이 도구를 사용하는 동안 물리적 보안 및 악성 소프트웨어 위협과 같은 잠재적인 위험을 인식하는 것이 중요합니다. 안드로이드용 하드웨어 패스키를 만드는 가이드이지만 기술 책임성의 보다 넓은 맥락을 무시할 수는 없습니다.\n\n본질적으로, 하드웨어 패스키는 기술이 우리 삶을 간편하게 만들 수 있는 잠재력을 상징합니다. 이러한 솔루션을 계속 탐구할 때 우리는 편의와 안전한 사용을 균형있게 고려해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제 Medium 계정을 팔로우하여 제 기술 여정을 계속 지켜보세요. 그리고 만약 함께 힘을 합쳐 기술 세계를 정복하고 싶다면, LinkedIn에서 연결해요!","ogImage":{"url":"/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_0.png"},"coverImage":"/assets/img/2024-06-20-UnlockingYourAndroidDevicewithaHardwarePasskeyAGuidetoUsingDigisparkAttiny85_0.png","tag":["Tech"],"readingTime":6},{"title":"Niels, 러스트를 배우다 4 - VM을 모듈화하는 세 가지 다른 방법","description":"","date":"2024-06-20 17:07","slug":"2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular","content":"\n\n이 문서는 '루스트(Rust)'를 배우면서 내장형 자바 가상 머신을 이식하는 과정의 네 번째 단골입니다. 전체 시리즈를 보려면 여기를 클릭하세요.\n\n이전 VM 버전은 Darjeeling 가상 머신의 변경 버전이었습니다. 모듈식으로 설정되어 다양한 구성 요소 세트로 쉽게 컴파일할 수 있었습니다.\n\n이러한 구성 요소는 무선 프로그래밍, 장치 UART 액세스, Java 기본 라이브러리 등과 같은 다양한 기능을 제공했습니다. 이를 사용한 연구 프로젝트는 이종적인 사물 인터넷(IoT) 장치 네트워크를 조정하는 데 사용되었습니다. 이 프로젝트에서는 심지어 자바 가상 머신 자체를 선택적 구성 요소로 만들어 가장 작은 장치용 버전을 작성할 수 있었으므로 자바 코드를 실행할 수 없어도 네트워크에 참여할 수 있었습니다.\n\n# 프로젝트 레이아웃\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVM을 빌드하기 전에 프로젝트 레이아웃을 먼저 설정해 봅시다. 목표는 VM을 구축할 때 설정 옵션에 따라 선택적으로 포함될 수 있는 구성 요소를 갖는 것입니다. 각 구성 요소는 코어 VM에서 노출된 여러 훅에 대한 콜백을 등록할 수 있어야 합니다. 이를 통해 구성 요소를 초기화하고 가비지 컬렉터와 상호 작용하게 하며 네트워크 메시지를 수신할 수 있어야 합니다. 이 단계에서 우리는 init()라는 훅을 정의할 것입니다. 이 훅은 시작할 때 호출됩니다.\n\n다양한 옵션을 설명하기 위해 두 개의 구성 요소로 시작해 봅시다.\n\n- jvm : 실제 Java 가상 머신을 포함할 것입니다.\n- uart : CPU의 UART(유니버설 비동기 수신기/발신기)를 제어하는 코드를 포함할 것입니다.\n\n프로젝트 레이아웃은 이렇게 보일 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```rust\n.\n├── avrora.rs\n├── main.rs\n└── components\n    ├── mod.rs\n    ├── jvm\n    │   └── mod.rs\n    └── uart\n        └── mod.rs\n\n4 directories, 5 files\n```\n\n러스트는 세 가지 방법으로 모듈을 정의하여 계층적으로 범위를 지정합니다:\n\n- mod modname ' ... ' 블록,\n- modname.rs 파일로, 이 프로젝트에는 avrora라는 모듈이 있습니다,\n- 그리고 mod.rs가 포함된 하위 디렉토리로, 해당 하위 디렉토리의 이름을 따르는 모듈이 정의됩니다. 여기에서는 components, components::jvm, 그리고 components::uart 모듈이 있습니다.\n\n컴파일은 main.rs 또는 라이브러리의 경우 lib.rs에서 시작됩니다. 다른 파일이나 디렉토리의 모듈은 명시적으로 프로젝트에 포함되어야 합니다. 그렇지 않을 경우 무시됩니다. 이 경우 mod avrora;와 mod components; 라인은 avrora 및 components 모듈을 가져와서 전체 크레이트에서 사용할 수 있도록 만듭니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n목표는 구성 설정에 따라 components::uart 및 components::vm을 선택적으로 포함하고, 활성화되어 있는 경우 init() 함수를 호출하는 것입니다.\n\n이를 수행하는 세 가지 방법을 고려해 보았는데, 각각이 저에게 몇 가지 흥미로운 Rust 기능을 가르쳐 주었습니다. 따라서 모두 살펴보도록 하겠습니다:\n\n# 옵션 A: build.rs\n\nCargo에는 코드를 빌드하기 전에 Rust 스크립트를 실행할 수 있는 옵션이 있습니다. 스크립트는 build.rs로 불리며 프로젝트의 루트 디렉토리에 배치되어야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n선택한 구성 요소를 가져오는 데 필요한 코드를 생성하는 데 사용할 수 있습니다. 구성 요소가 활성화되는 설정을 따로 저장할 것이며, 이는 프로젝트 루트에 있는 vm-config.toml 파일에 저장됩니다:\n\n```js\n[capevm]\ncomponents = [\"jvm\"]\n```\n\n이 예에서는 jvm이 활성화되었지만 uart 구성 요소는 비활성화되었습니다. 그럼 우리의 빌드 스크립트는 다음 코드를 포함한 파일을 생성해야 합니다:\n\n```js\n#[path = \"/home/niels/git/capevm-rust/capevm/src/components/jvm/mod.rs\"]\nmod jvm;\n\npub fn init() {\n    jvm::init();\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n러스트는 프로젝트에 명시적으로 임포트되지 않는 코드를 무시하므로 최종 빌드에는 jvm 모듈만 포함되고 uart 모듈은 건너뛰게 됩니다.\n\n생성된 코드는 일시적인 파일이며 소스 제어에 포함되지 않아야 합니다. 따라서 Cargo의 출력 디렉토리에 생성하고 components/mod.rs에서 포함시키겠습니다. 이 파일은 이제 다음과 같이 한 줄만 포함하고 있습니다:\n\n```js\ninclude!(concat!(env!(\"OUT_DIR\"), \"/enabled_components.rs\"));\n```\n\n생성된 코드의 #[path] 속성이 필요한 이유는 모듈 임포트가 가져오는 파일의 위치를 기준으로 상대적이기 때문입니다. 그러나 Rust의 include! 매크로는 C의 #include 전처리기 지시문과 다르게 작동합니다. 포함된 코드는 단순히 파일에 붙여넣는 것이 아니라 해당 소스 위치에 따라 구문 분석되는데, 이 경우에는 Cargo 출력 디렉토리입니다. 만약 #[path] 속성을 사용하지 않고 Rust에게 해당 컴포넌트가 다른 위치에 있다고 알리지 않으면 아래와 같은 오류가 발생할 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular_0.png\" /\u003e\n\n다음은 완전한 빌드 스크립트입니다:\n\n```js\nextern crate toml;\n\nuse std::fs;\nuse std::path::Path;\nuse toml::Value;\n\nfn main() {\n    println!(\"cargo:rerun-if-changed=build.rs\");\n    println!(\"cargo:rerun-if-changed=vm-config.toml\");\n\n    let manifest_dir = std::env::var(\"CARGO_MANIFEST_DIR\").unwrap();\n    let out_dir = std::env::var(\"OUT_DIR\").unwrap();\n    let dest_path = Path::new(\u0026out_dir).join(\"enabled_components.rs\");\n\n    let contents: String = fs::read_to_string(\"vm-config.toml\").unwrap();\n    let cargo_toml = contents.parse::\u003cValue\u003e().unwrap();\n\n    let vm_components =\n        if let Some(capevm_components) = cargo_toml.get(\"capevm\")\n                                        .and_then(Value::as_table)\n                                        .and_then(|table| table.get(\"components\"))\n                                        .and_then(Value::as_array) {\n            capevm_components.iter().filter_map(|v| v.as_str()).collect::\u003cVec\u003c\u0026str\u003e\u003e()\n        } else {\n            Vec::\u003c\u0026str\u003e::default()\n        };\n\n    let mod_imports =\n        vm_components.iter()\n            .map(|name| format!(r#\"\n                #[path = \"{manifest_dir}/src/components/{name}/mod.rs\"]\n                mod {name};\"#, manifest_dir=manifest_dir, name=name))\n            .collect::\u003cVec\u003c_\u003e\u003e().join(\"\\n\");\n    let mod_inits =\n        vm_components.iter()\n            .map(|name| format!(\"\n                {}::init();\", name))\n            .collect::\u003cVec\u003c_\u003e\u003e().join(\"\\n\");\n\n    let generated_code =\n        format!(\"{}\n            \n            pub fn init() {\n                {}\n            }\", mod_imports, mod_inits);\n\n    fs::write(dest_path, generated_code.as_bytes()).unwrap();\n}\n```\n\n조금 주목해야 할 사항이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- extern crate toml; 메인 애플리케이션과 마찬가지로 build.rs 스크립트는 외부 크레이트를 사용할 수 있습니다. 다른 크레이트와 마찬가지로 Cargo.toml에 선언해야 하지만, [dependencies] 대신 [build-dependencies] 섹션에 선언해야 합니다.\n- println!(\"cargo:rerun-if-changed=...\"); 표준 출력에 쓰는 것으로 Cargo가 빌드 스크립트를 실행하는 시점(그리고 다른 여러 가지 것들)을 제어할 수 있습니다. 여기서 두 줄은 Cargo에게 build.rs 또는 vm-config.toml이 변경되면 빌드 스크립트를 다시 실행하도록 지시합니다.\n- std::env::var(\"CARGO_MANIFEST_DIR\"): Cargo는 환경 변수를 통해 빌드 프로세스의 여러 매개변수를 스크립트에 노출시킵니다. 이 경우 OUT_DIR을 사용하여 생성된 파일이 위치해야 하는 곳을 결정하고, CARGO_MANIFEST_DIR을 사용하여 구성 요소의 위치를 파악합니다.\n- unwrap(): Rust의 주요 오류 처리 방식은 Result\u003cT, E\u003e를 반환하는 것입니다. 이는 T 값이나 E 오류 중 하나를 포함할 수 있습니다. 일반적으로 오류를 처리하거나 전달해야 하지만, 오류가 발생할 가능성이 없거나 코드가 패닉 상황이라고 생각하면 unwrap을 사용하여 Result에서 값을 가져올 수 있습니다.\n- .and_then(): toml 크레이트는 toml 파일의 내용을 나타내는 Value 객체를 제공합니다. 이는 이름으로 검색할 수 있습니다. 이는 Option\u003c\u0026Value\u003e를 반환하며, 이름을 찾지 못하면 None일 수 있습니다. .and_then() 호출을 사용하면 값을 포함하는 경우에는 Option에서 작업을 연결하고, 그렇지 않은 경우에는 None을 유지할 수 있습니다. 다른 언어에서는 이를 flatmap 또는 bind라고도 부르기도 합니다.\n\n# 옵션 B: Cargo 피쳐\n\n두 번째 옵션은 Rust 피쳐를 사용하는 것입니다. 이 방법은 훨씬 간단하지만 한계가 있습니다. 먼저 다음과 같이 Cargo.toml에 [features] 섹션을 선언합니다:\n\n```js\n[features]\ndefault = [\"jvm\"]\njvm = []\nuart = []\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 기능은 종속성 목록이 포함된 이름에 해당합니다. 기본 기능은 기본적으로 포함됩니다. 예를 들어 이 예시에서 기본 기능은 jvm에 의존하므로 해당 기능은 활성화되지만 uart는 활성화되지 않습니다.\n\n그런 다음 조건부 컴파일에 사용할 수 있는 이름이 지정된 기능이 있습니다. #[cfg(feature = \"...\")] 속성을 사용하여 구성요소/mod.rs를 다음과 같이 구현할 수 있습니다:\n\n```js\n#[cfg(feature = \"jvm\")]\nmod jvm;\n#[cfg(feature = \"uart\")]\nmod uart;\n\npub fn init() {\n    #[cfg(feature = \"jvm\")]\n    jvm::init();\n    #[cfg(feature = \"uart\")]\n    uart::init();\n}\n```\n\n이 접근 방식의 장점은 빌드 스크립트보다 훨씬 간단하다는 것입니다. 또한 명령줄에서 선택된 기능을 제어할 수 있습니다. 예를 들어, --features=\"uart\"은 uart 기능을 활성화하며, --no-default-features는 기본 기능을 무시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단점 중 하나는 해당 기능이 활성화되어 있는 경우 그 모든 컴포넌트를 가져오기 위해 components/mod.rs에 수동으로 목록을 작성해야 한다는 것입니다. 게다가, 현재 init() 함수만 있어야 하는데 이 함수는 모든 활성화된 기능을 위해 호출되어야 합니다. 그러나 쓰레기 수집 및 네트워킹과 같은 항목을 추가할 때 가능한 후크 목록이 늘어나게 됩니다. 그래서 일부 컴포넌트는 수신 메시지를 듣거나 힙에 자체 객체를 등록하려는 것일 수 있습니다.\n\n이것은 꽤 강한 결합이며, 모듈 및/또는 후크의 수가 계속해서 늘어난다면 이 접근법은 유지하기 어려워질 수 있습니다.\n\n# 옵션 C: 기능 + 인벤토리 크레이트\n\n이제 옵션 C로 넘어가봅시다: 인벤토리 크레이트입니다. 이를 통해 컴포넌트와 코어 VM 간의 강한 결합을 줄일 수 있습니다. 안타깝게도 AVR에서는 작동하지 않지만, 학습할 가치가 있는 내용입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n크레이트를 사용하면 데이터 형식을 정의하고 해당 데이터 형식의 인스턴스를 코드의 한 부분에서 등록하고 다른 곳에서 수집할 수 있습니다. 저희 경우에는 데이터 형식이 init() 함수 포인터를 포함하는 구조체일 수 있습니다:\n\n```rust\npub struct Component {\n    init: fn()\n}\n```\n\n이제 컴포넌트의 구현은 아래와 같습니다:\n\n```rust\npub fn init() {\n    println!(\"jvm 초기화 중...\");\n}\n\ninventory::submit! {\n    crate::components::Component { init }\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n구성 요소/components/mod.rs의 구현부는 다음과 같습니다:\n\n```js\n#[cfg(feature = \"jvm\")]\nmod jvm;\n#[cfg(feature = \"uart\")]\nmod uart;\n\npub struct Component {\n    init: fn()\n}\n\ninventory::collect!(Component);\n\npub fn init() {\n    for component in inventory::iter::\u003cComponent\u003e {\n        (component.init)();\n    }\n}\n```\n\ncollect! 매크로는 submit!()를 통해 등록된 모든 Component 객체를 순회할 수 있는 반복자를 생성합니다. 이 반복자는 main() 함수에 진입하기 전에 초기화되며, 우리가 수동으로 초기화 코드를 실행할 필요가 없습니다.\n\n이 동작이 가능하게 하는 핵심은 submit! 매크로에 있습니다. 매크로가 어떻게 확장되는지 볼 수 있다는 점은 종종 유용하거나 그냥 재미있을 수 있습니다. cargo-expand라는 Cargo 확장 프로그램을 사용하여 확장된 소스를 표시할 수 있습니다. 설치한 후(cargo install cargo-expand), cargo expand components::jvm: 명령을 통해 확장된 소스를 확인할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular_1.png)\n\n특정 링크된 섹션에 코드를 배치하여 마법이 일어납니다. 인벤토리 크레이트의 소스를 살펴보면(조밀하지만 500줄 미만이고 그 중 절반은 주석입니다), 생성될 링커 섹션이 운영 체제에 따라 다르다는 것을 알 수 있습니다. 리눅스의 경우 .init_array가 되고, 윈도우의 경우 .CRT$XCU가 되며 macOS의 경우 __DATA,__mod_init_func가 됩니다. 각각은 main() 함수에 진입하기 전에 실행될 코드를 포함하고 있습니다.\n\nAVR의 경우 이러한 종류의 코드가 .initN 섹션으로 들어가지만, 안타깝게도 인벤토리 크레이트는 AVR에서 작동하지 않습니다:\n\n![이미지](/assets/img/2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular_2.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n에러 메시지가 약간 암호화되어 있어서 이 문제는 조금 어렵게 느껴질 수도 있어요. 특히 `ptr` 피처 부분이 숨겨져 있는 것이요. 이 크레이트는 core::sync::atomic::AtomicPtr라는 유형을 사용하는데, 어떤 이유 때문에 사용할 수 없네요. 이 유형의 구현을 살펴보면 플랫폼이 원자 포인터 작업을 지원하는 경우에만 설정되는 #[cfg(target_has_atomic_load_store = \"ptr\")]라는 조건부 컴파일 속성이 있다는 것을 알게 됩니다.\n\nAVR은 그 작업을 지원하지 않아요. 이는 8비트 CPU이며 포인터는 16비트이기 때문에 포인터 조작은 항상 여러 번의 읽기 또는 쓰기가 필요해요.\n\n# 비교와 결정\n\n우리는 아마도 인벤토리 크레이트가 하는 것을 AtomicPtr이 없이도 일부 코드를 복사하고 수정하여 재생산할 수 있을 거예요. 그러나 여기서 최종적으로 가장 좋은 선택이 아닌 이유가 하나 더 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방식은 iterator가 루프를 돌 수 있는 정적 inventory::Node 객체의 링크드 리스트를 만들어 작동합니다. 이것은 RAM을 사용하므로, 객체당 4바이트가 필요한 경우에도 RAM이 단 4KB만 있는 장치에서 정적 목록에 낭비하고 싶지 않습니다.\n\n그러므로 옵션 A와 B 중에서 선택해야 합니다. 옵션 A는 핵심 vm 코드가 구성 요소에 대해 알 필요가 없어 보이지만, 옵션 B는 각 구성 요소를 해당 기능 플래그와 등록해야 한다는 점이 필요합니다.\n\n옵션 A의 단점은 각 구성 요소가 초기화할 것이 없더라도 init()에 대한 구현을 정의해야 한다는 것입니다. 빌드 스크립트는 항상 호출을 생성하므로 말입니다. 러스트 컴파일러는 죽은 코드를 제거하는 데 매우 뛰어나기 때문에, 컴파일 시간에 이 코드들이 제거될 가능성이 높지만, 나중에 사용할 쓰레기 수집기를 위해 비슷한 후크를 추가할 때마다, 적어도 빈 구현을 제공해야 하는데 이는 추가 작업이 필요합니다.\n\n구성 요소와 후크의 수가 제한될 것이므로, 두 옵션 모두 잘 작동할 것으로 보입니다. 옵션 A는 더 많은 요소가 움직이며, 마법이 적으면 항상 좋은 것이므로, 일단 옵션 B를 선택하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n보통 이번 단계의 코드 상태는 Github에서 확인하실 수 있어요. 세 가지 옵션을 업로드했어요:\n\n- 옵션 A: build.rs\n- 옵션 B: features\n- 옵션 C: features + inventory (AVR에서 컴파일되지 않아요)\n- 데스크탑에서 작동하는 옵션 C의 최소 예제.\n\n2024년 5월 23일에 https://nielsreijers.com에서 최초로 게시되었어요.","ogImage":{"url":"/assets/img/2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular_0.png"},"coverImage":"/assets/img/2024-06-20-NielslearnsRust4ThreedifferentwaysmaketheVMmodular_0.png","tag":["Tech"],"readingTime":10},{"title":"IoT ESP32가 MQTT Broker에 연결하기 위해 SSL TLS 인증서를 사용하는 방법 파트 2","description":"","date":"2024-06-20 17:06","slug":"2024-06-20-IoTESP32usingssltlscertificatetoconnectwidthMQTTBrokerPart2","content":"\n\n시작부터 따라오고 싶다면 다음 링크를 확인하세요 (Part 1)\n\n[Part 1](/assets/img/2024-06-20-IoTESP32usingssltlscertificatetoconnectwidthMQTTBrokerPart2_0.png)\n\n## 개요\n\n이 기사에서는 ESP32를 사용하여 SSL/TLS 프로토콜에서 MQTT 통신을 하는 방법을 보여줍니다. 암호화된 메시지를 발행하고 주제를 구독하는 방법에 대해 설명합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 똑같은 Raspberry Pi 3에 설치된 Mosquitto 브로커를 사용할 것입니다. 이 브로커는 모든 메시지를 수신하고, 메시지를 필터링하며, 누가 관심이 있는지 결정하고 구독한 모든 클라이언트에게 메시지를 게시하는 역할을 합니다.\n\n# 준비 사항\n\n- Raspberry Pi에 익숙해야 합니다 — Getting Started with Raspberry Pi와 Arduino IDE를 읽어보세요.\n- Raspberry Pi에 Raspbian 운영 체제가 설치되어 있어야 합니다 — Raspbian Lite 설치와 SSH로 연결하는 방법에 대한 유튜브 비디오를 시청하세요.\n- esp32 컨트롤러가 필요합니다.\n- MQTT가 무엇이고 어떻게 작동하는지 배워보세요.\n\n여기가 전체 코드입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```json\n#include \"WiFiClientSecure.h\"\n#include \u003cPubSubClient.h\u003e\n#include \"credentials.h\"\n\n// WiFi credentials\nconst char* ssid = \"\u003c와이파이 라우터 이름\u003e\";\nconst char* password = \"\u003c와이파이 비밀번호\u003e\";\n\n// MQTT Broker credentials\nconst char* mqtt_broker = \"\u003c브로커의 IP 주소\u003e\";\nconst char* topic = \"test\";\nconst int mqtt_port = 8883 ;\n\n// SSL 인증서 설정\nconst char* root_ca =  CA_CRT;\nconst char* server_cert = SERVER_CERT;\nconst char* server_key  = SERVER_KEY;\n\n// WiFiClient espClient;\nWiFiClientSecure espClient;\nPubSubClient client(espClient);\n\nvoid setup() {\n  // 소프트웨어 시리얼 보드레이트 설정: 115200\n  Serial.begin(115200);\n  // WiFi 네트워크에 연결\n  WiFi.begin(ssid, password);\n  while (WiFi.status() != WL_CONNECTED) {\n    delay(500);\n    Serial.println(\"WiFi에 연결 중..\");\n  }\n  Serial.println(\"WiFi 네트워크에 연결되었습니다.\");\n  // SSL을 사용하여 MQTT 브로커에 연결\n  espClient.setCACert(root_ca);\n  espClient.setCertificate(server_cert);  // 클라이언트 확인을 위해\n  espClient.setPrivateKey(server_key);    // 클라이언트 확인을 위해\n\n  // 원격 MQTT 브로커에 연결\n  client.setServer(mqtt_broker, mqtt_port);\n  client.setCallback(callback);\n\n  while (!client.connected()) {\n    // 클라이언트 ID 생성\n    String client_id = \"esp32-client\";\n    client_id += String(WiFi.macAddress());\n    // esp32 컨트롤러의 이름과 ID 출력\n    Serial.printf(\"클라이언트 %s가 공개 MQTT 브로커에 연결합니다\\n\", client_id.c_str());\n    if (client.connect( client_id.c_str())) {\n      Serial.println(\"Public emqx mqtt 브로커에 연결되었습니다\");\n    } else {\n      Serial.print(\"연결 실패, 상태: \");\n      Serial.print(client.state());\n      delay(2000);\n    }\n  }\n  // 게시 및 구독\n  client.publish(topic, \"안녕, 나는 ESP32^^\");\n  client.subscribe(topic);\n}\n\nvoid callback(char* topic, byte* payload, unsigned int length) {\n  Serial.print(\"주제에서 메시지 도착: \");\n  Serial.println(topic);\n  Serial.print(\"메시지:\");\n  for (int i = 0; i \u003c length; i++) {\n    Serial.print((char)payload[i]);\n  }\n  Serial.println();\n  Serial.println(\"-----------------------\");\n}\n\nvoid loop() {\n  client.loop();\n\n  client.publish(topic, \"ESP32가 MQTT 브로커로 암호화된 메시지를 보냅니다\");\n\n  // 10초마다 메시지 전송\n  delay(10000);\n}\n```\n\nSSL 인증서를 설정하려면 credentials.h 파일을 작성해야 합니다.\n\n아래와 같은 형태여야 합니다:\n\n```js\n#define CA_CRT                                                           \\\n    \"-----BEGIN CERTIFICATE-----\\n\"                                      \\\n    \"MIIDVzCCAj+gAwIBAgIUIwOnfZCxwCKrQXHpbI0rVksEcaMwDQYJKoZIhvcNAQEL\\n\" \\\n    // 중략\n#define SERVER_CERT                                                      \\\n    \"-----BEGIN CERTIFICATE-----\\n\"                                      \\\n    \"MIIDBTCCAe0CFHjJN1GNHVnqXiMyngV3yvLg/70FMA0GCSqGSIb3DQEBCwUAMDsx\\n\" \\\n    // 중략\n#define SERVER_KEY                                                       \\\n    \"-----BEGIN RSA PRIVATE KEY-----\\n\"                                  \\\n    \"MIIEpQIBAAKCAQEAvsxvL0H8M9HjGplper2/oRtQQTFfBYLX3JfBrTJIXD6A5HFJ\\n\" \\\n    // 중략\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그런 다음 자격 증명 파일을 업로드하려는 메인 파일에 자격 증명.h 파일을 가져와서 사용할 수 있습니다.\n\n## 마지막으로 MQTT 브로커에서 나타나는 다음 메시지를 확인해야합니다.\n\n![이미지](/assets/img/2024-06-20-IoTESP32usingssltlscertificatetoconnectwidthMQTTBrokerPart2_1.png)\n\n# 정리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요약하면, 저는 브로커 부분과 컨트롤러 부분을 포함한 가정용 IOT 시스템의 기본 개념을 보여드렸습니다.","ogImage":{"url":"/assets/img/2024-06-20-IoTESP32usingssltlscertificatetoconnectwidthMQTTBrokerPart2_0.png"},"coverImage":"/assets/img/2024-06-20-IoTESP32usingssltlscertificatetoconnectwidthMQTTBrokerPart2_0.png","tag":["Tech"],"readingTime":4},{"title":"짝커 - 아두이노로 박수 감지 스위치를 만드는 방법","description":"","date":"2024-06-20 17:03","slug":"2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino","content":"\n\n당신이 말한 코딩에 관한 책이 필요하다면 언제든지 물어보세요! 저는 여러가지 책과 자료를 추천해드릴 수 있어요. 요즘 프로그래밍을 배우는 것은 정말 뜻깊은 경험이 될거에요. 함께 열심히 공부해서 좋은 개발자가 되어봐요!😊\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n필요한 것이 있을까요? 하드웨어부터 시작해봅시다. 이러한 프로젝트를 위해서는 하드웨어가 필수입니다. 사용된 구성 요소 목록은 다음과 같습니다:\n\n- 브레드보드 (1개)\n- LED (1개)\n- 아두이노 Me 마이크로컨트롤러 (거의 모든 마이크로컨트롤러를 사용할 수 있습니다) (1개)\n- 소리 센서 (1개)\n- 1000R 저항 (1개)\n- M-F 점퍼 케이블 (3개)\n- M-M 점퍼 케이블 (5개)\n- 전원 공급원 (1개)\n\n## 핀 매칭\n\n![핀 매칭](/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 코드\n\n가장 기본적인 구현부터 시작해서 원하는 대로 가보자. 우리의 사운드 센서로부터 신호를 수신하고, 신호를 \"임계값\"과 비교하는 코드를 구현해보자. 만약 신호가 임계값을 초과하면 LED 라이트를 토글한다.\n\n```js\n // sound-sensitive-switch-v1.ino\n\nconst int micPin = A0; // 마이크가 연결된 아날로그 입력 핀\nconst int ledPin = 2;\nconst int threshold = 60;\n\nint sensorValue = 0;\nbool ledState = false;\n\nvoid setup() {\n Serial.begin(9600);\n \n pinMode(micPin, INPUT);\n pinMode(ledPin, OUTPUT);\n}\n\nvoid loop() {\n sensorValue = analogRead(micPin);\n \n // 박수 감지 로직\n if (sensorValue \u003e threshold) {\n  // 박수 감지!\n  digitalWrite(ledPin, ledState ? LOW : HIGH);\n  ledState = !ledState;\n  \n  delay(500); // 여러 번 트리거를 방지하기 위한 디바운스 딜레이\n }\n\n delay(10); // 샘플링 딜레이\n}\n```\n\n연결이 제대로 되어있다면 주어진 임계값을 초과하는 모든 소리로 라이트를 트리거할 수 있어야 합니다. 그러나 이 설정과 코드에 대한 또 다른 문제로 우리를 이끌어간다면, 마이크 민감도입니다. 나의 실험에서, 마이크를 낮은 민감도로 설정하면 회로 내의 소리 센서에서의 잡음을 더 잘 관리할 수 있었습니다. 이것은 완벽하지 않았으며, 조용한 환경에서도 0-45 사이의 신호값을 가지고 있었습니다. 이 레벨의 침묵을 달성하기 위해 소리 센서 부품의 기록용 가변저항을 사용했습니다. 이것은 3326 모델이며, 회로에서 잡음 신호를 줄이기 위해 회전시킬 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_2.png)\n\n여기에는 포트 튜닝 전후의 신호 데이터가 표시되어 있습니다. Y축에서 볼 수 있듯이, 튜닝 전에는 40 이상의 값이 나타나는 반면, 튜닝 후에는 10 미만으로 감소된 것을 확인할 수 있습니다.\n\n포트 튜닝 전.\n\n![image](/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그 후, 마이크 민감도를 더 줄일 수 있다는 것을 발견했습니다. 더 부드러운 파형을 강제하는데 그러나 다른 제약 사항이 있었습니다. 클랩하면 스위치가 활성화되는 매우 높은 수준의 소음이 있어야 했습니다.\n\n![이미지](/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_4.png)\n\n참고: 마이크로컨트롤러에 따라 다른 베이스라인 읽기가 있는 것을 알았습니다. 내 아두이노 Uno Mini가 소음 수준에서 나의 아두이노 메가보다 더 나은 성능을 발휘했습니다.\n\n위의 조정을 하고 나서, 라이트 스위치가 작동하지만 우리의 진폭 임계값을 초과하는 모든 소리에 의해 트리거됩니다. 이와 같은 문제에 직면했을 때는 전략 재고가 필요합니다. 그래서 다시 기본부터 시작하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n손뼉 소리는 복잡한 소리 파형을 생성하지 않는다는 것을 알아봅시다. 마이크가 고품질이 아닌 것이 이를 강조합니다. 더 복잡한 파형은 분석을 위한 더 명확한 신호를 제공할 수 있을지 모르지만, 여전히 간단한 손뼉에서 유용한 통찰을 얻을 수 있습니다. 나는 아두이노를 연결하여 손뼉의 특성을 나타내는 그래프를 그리는 데이터를 캡처했습니다. 여기에 결과가 있습니다.\n\n![TheClapper](/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_5.png)\n\n손뼉은 소리 파동의 진폭이 급격하게 증가한 후 급격히 감소하는 것으로 특징 지어집니다. 그러나, 이 정의는 한 가지 문제점을 강조합니다: 비슷한 특성은 문을 세게 닫거나 탁을 치거나 책을 떨어뜨릴 때와 같은 다양한 소리로도 나타낼 수 있습니다.\n\n이를 해결하기 위해 이러한 제한을 극복할 전략을 개발해 보겠습니다. 여기 잠재적인 접근 방식이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 소리를 캡처합니다.\n- 녹음된 소음 레벨이 미리 정의된 진폭 임계값을 초과하는지 확인합니다.\n- 특정 시간 창 내에서 추가 소음을 청취합니다.\n- 박수의 빠르게 감소하는 특성과 일치하는지 확인하기 위해 소리의 감쇠 속도를 분석합니다. 그렇다면 원하는 작업(예: 조명 켜기/끄기)을 계속 진행합니다.\n\n이 프로그램의 핵심은 명백히 소리 인식이므로, 박수의 소리파를 어떻게 인식할 수 있는지 궁금해집니다.\n\n변화를 분석하고 감지하기 위해 ML 모델을 사용하는 것이 떠올랐기 때문에, 이러한 특성을 찾기 위한 모델을 개발했습니다. 그러나 이에 대해 다른 글에서 자세히 다루겠습니다. tinyML과 같은 기술의 계산 요구 사항에 따라, 소리파 신호를 깨끗하고 부드럽게 만들기 위한 물리학과 수학의 방법을 먼저 조사하기로 결정했습니다. 일부 연구를 거친 후, 그리고 FFT를 시도한 후, 고역통과 필터라는 좀 더 \"기본적\"인 접근 방법으로 결정했습니다.\n\n고역통과 필터\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이 패스 필터는 일정한 차단 주파수보다 높은 주파수를 가진 신호를 통과시키고, 차단 주파수보다 낮은 주파수를 가진 신호를 약화시키는 전자 필터입니다. 이 필터는 낮은 주파수 신호를 통과시키지 않고, 대신 필터 설계에 따라 일관되게 차단합니다.\n\n우리 필터는 어떻게 생겼을까요?\n\n```js\n// 낮은 주파수 잡음을 제거하는 간단한 하이 패스 필터\nhighPass = alpha * (highPass + sample - lastSample);\nlastSample = sample;\n\n// 획득기 - 절대값 취하고 평활화\nenvelope *= release;\nenvelope = max(envelope, abs(highPass));\n```\n\nhighPass: 필터의 현재 값\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알파: 알파는 일반적으로 0에서 1 사이의 값으로 범위하며, 필터의 차단 주파수를 결정하는 계수입니다. 알파 값이 낮을수록 차단이 더 뚜렷해지며, 이는 필터가 이전 상태를 더 오래 유지하게 한다는 것을 의미합니다. 그 반대로 높은 값은 값을 더 많이 변경하며 알파가 클수록 부드러운 차단이 이뤄집니다.\n\n샘플: 이것은 마이크로폰에서의 현재 입력 샘플입니다.\n\nlastSample: 이것은 마이크로폰에서 이전에 입력한 샘플입니다.\n\nEnvelope Detector: 엔벨롭 디텍터는 소리 처리 도구로, 소리 파형의 바깥쪽 한계를 캡처하는 데 사용됩니다. 이는 신호의 급격한 변화가 아닌 파형의 진폭의 느린 변화를 캡처하는 것을 의미합니다. 아래는 디지털 하이 패스 필터를 통과한 후의 파형의 결과입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 코드를 Markdown 형식으로 변경했습니다:\n\n![이미지](/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_6.png)\n\n변경된 코드는 다음과 같습니다:\n\n```js\n// sound-sensitive-switch-v2.ino\n\nconst int micPin = A0; // 마이크가 연결된 아날로그 입력 핀\nconst float alpha = 0.9; // 고주파 필터용 계수\n\nint sample;\nfloat filtered, highPass;\nfloat lastSample = 0;\nfloat envelope = 0;\nfloat release = 0.9; // 엔벨롭 감지기 용 해제 계수\nint threshold = 30; // 박수 감지 임계값\n\nbool ledState = false;\nint ledPin = 2;\n\nvoid setup() {\n Serial.begin(9600);\n pinMode(micPin, INPUT);\n pinMode(ledPin, OUTPUT);\n}\n\nvoid loop() {\n sample = analogRead(micPin);\n // 단순 고주파 필터를 사용하여 저주파 노이즈 제거\n highPass = alpha * (highPass + sample - lastSample);\n lastSample = sample;\n \n // 엔벨롭 감지기 - 정류하고 부드럽게\n envelope *= release;\n envelope = max(envelope, abs(highPass));\n \n // 박수 감지 논리\n if (envelope \u003e threshold) {\n  unsigned long timeStart = millis();\n  \n  while (millis() - timeStart \u003c 100) { // 100ms 내에 빠른 감쇠 확인\n   sample = analogRead(micPin);\n   highPass = alpha * (highPass + sample - lastSample);\n   lastSample = sample;\n   envelope *= release;\n   envelope = max(envelope, abs(highPass));\n  }\n  \n  if (envelope \u003c threshold / 2) { // 엔벨롭이 감쇠해야 함\n   // 박수 감지!\n   digitalWrite(ledPin, ledState ? LOW : HIGH);\n   ledState = !ledState;\n  }\n  \n  delay(500); // 다중 트리거 방지를 위한 디바운스 지연\n }\n\n delay(10); // 샘플링 지연\n}\n```\n\n이 코드는 상당히 잘 작동합니다. 소음이 큰 음악으로 테스트했을 때, 원하는 특성을 가진 짧은 소리 폭발 이외에는 스위치를 트리거할 수 없었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 시스템이 잘 작동하는 것을 확인했으니 강화를 시도해 볼 수 있을 것 같아요. 이를 위한 한 가지 방법은 트리거 소리의 파형을 더 복잡하게 만드는 것입니다. 우리는 박수 그 자체를 바꿀 수 없지만, 대신 1번의 박수 대신 2번 연속된 박수를 트리거로 인식할 수 있습니다. 이렇게 하면 책이 탁 탁하는 소리나 문이 쾅 하고 닫혀도 스위치가 작동하지 않을 가능성이 높아집니다. 이것은 간단한 선택이죠.\n\n이를 실행하기 위해 대부분의 코드는 동일하게 유지되지만, 여기에 변경 사항이 있습니다:\n\n```js\n// 박수를 마지막으로 감지한 타임스탬프를 추적\nunsigned long lastClapTime = 0;\n// 발견한 박수의 횟수\nint clapCount = 0;\n// 더블 박수를 감지할 시간 창문 (1초)\nconst unsigned long clapDelay = 1000;\n```\n\n우리의 \"박수 감지 로직\" 안에서, 연속된 박수가 세어질 수 있는 시간 창문을 고려하면서 발견한 박수 횟수를 세는 이 코드 조각을 추가할 것입니다. 이는 500ms의 시간 창문 내에서 연속된 박수가 카운트될 수 있음을 의미하는데요. 이것은 특정한 박수 패턴을 갖게끔 하기 위해 연속된 박수를 계산하는 상한선을 여기에 표시하고 있음을 기억해 주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nif (timeNow - lastClapTime \u003e 500) { // 클랩이 너무 가깝지 않게 500밀리초 간격 확인\n clapCount++;\n lastClapTime = timeNow;\n}\n```\n\n여기서 중요한 점은 코드에서 clapCount가 이 시점에서 1만큼 증가했음에도 실제로 클랩으로 간주하려면 신호 읽기가 신속한 감쇠 테스트를 통과해야 한다는 것입니다. 따라서 그 코드를 구현해 보겠습니다.\n\n```js\nif (clapCount == 2 \u0026\u0026 (millis() - lastClapTime \u003c= clapDelay)) {\n digitalWrite(ledPin, ledState ? LOW : HIGH);\n ledState = !ledState;\n clapCount = 0; // 작업 후 클랩 횟수 카운터 재설정\n}\n```\n\n여기서, 스위치를 토글하기 전에 클랩 횟수가 2이고 연이어 발생한 클랩이 clapDelay 시간 내에 있는지 확인합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막 코드 부분은 가정정리용입니다. 여기서 clapCount가 0보다 크고 현재 시간과 박수가 발생한 시간 간의 차이 (lastClapTime)가 clapDelay 시간 프레임을 벗어나는 경우 clapCount를 재설정합니다. 즉, clap이 clapDelay 시간 프레임을 벗어나 늙었으면 그 clap을 무시합니다. 이때 clapDelay는 lastClapTime 이후 1000ms입니다.\n\n```js\nif (millis() - lastClapTime \u003e clapDelay \u0026\u0026 clapCount \u003e 0) {\n  clapCount = 0;\n}\n```\n\n이제 2개 clap을 고려한 최종 코드는 다음과 같습니다:\n\n```js\nconst int micPin = A0; // 초음파가 연결된 아날로그 입력 핀\nconst float alpha = 0.9; // 하이패스 필터용 계수\nint sample;\nfloat highPass;\nfloat lastSample = 0;\nfloat envelope = 0;\nfloat release = 0.9; // 엔벨로프 감지기의 릴리스 계수\nint threshold = 20; // 박수 감지 임계값\n\nbool ledState = false;\nint ledPin = 2;\nunsigned long lastClapTime = 0;\nint clapCount = 0;\nconst unsigned long clapDelay = 1000; // 이중 박수 감지 시간 창문 (1초)\n\nvoid setup() {\n  Serial.begin(9600);\n  pinMode(micPin, INPUT);\n  pinMode(ledPin, OUTPUT);\n}\n\nvoid loop() {\n  sample = analogRead(micPin);\n  // 저주파 노이즈 제거를 위한 하이패스 필터\n  highPass = alpha * (highPass + sample - lastSample);\n  lastSample = sample;\n\n  // 엔벨로프 감지기 - 정류 및 평활화\n  envelope *= release;\n  envelope = max(envelope, abs(highPass));\n\n  Serial.println(sample);\n  // 박수 감지 논리\n  if (envelope \u003e threshold) {\n    unsigned long timeNow = millis();\n    if (timeNow - lastClapTime \u003e 500) {  // 박수가 너무 가깝지 않도록, 500ms 간격 확인\n      clapCount++;\n      lastClapTime = timeNow;\n    }\n\n    // 100ms 내에 빠르게 감소하는 경우 확인\n    while (millis() - timeNow \u003c 100) {\n      sample = analogRead(micPin);\n      highPass = alpha * (highPass + sample - lastSample);\n      lastSample = sample;\n      envelope *= release;\n      envelope = max(envelope, abs(highPass));\n    }\n\n    if (envelope \u003c threshold / 2) { // 엔벨로프가 감소해야 함\n      if (clapCount == 2 \u0026\u0026 (millis() - lastClapTime \u003c= clapDelay)) {\n        digitalWrite(ledPin, ledState ? LOW : HIGH);\n        ledState = !ledState;\n        clapCount = 0; // 동작 후 clap 카운터 재설정\n      }\n    }\n  }\n\n  // 시간 창문 내에 두 번째 clap이 없을 경우 clap 수를 재설정\n  if (millis() - lastClapTime \u003e clapDelay \u0026\u0026 clapCount \u003e 0) {\n    clapCount = 0;\n  }\n\n  delay(10); // 샘플링 지연\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 다음 수준으로 업그레이드해 보세요\n\n이제 우리에게 완전히 작동하는 시스템과 코드가 준비되었으니, 실제 기기에 연결하여 회로를 더 개선해 보는 것이 좋겠죠. 이를 위해 아이디어를 고민해 오셨다면, 여기에 답이 있습니다!\n\n계속 진행하려면 몇 가지 추가 구성품이 필요합니다:\n\n- 아두이노 보드, 브레드보드 및 마이크로폰을 포함할 하우징\n- 5V 단일 채널 릴레이와 함께 선택한 릴레이\n- 전원 케이블이 연장된 플러그\n- 고전압 기기에 연결할 여성 AC 전원 소켓\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 핀 재매핑\n\n우선 배선을 변경해보세요. 이 기사의 첫 부분에서는 LED 전구를 켰었습니다. 이번에는 LED를 제거하지만 동일한 배선을 사용하고, 우리의 램프가 도입한 추가 연결을 더할 것입니다.\n\n새로운 연결은 다음과 같습니다:\n\n마이크 연결은 그대로 유지됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_7.png\" /\u003e\n\n만약 모든 연결이 올바르게 되어 있다면, 램프를 전원에 연결하고 아두이노를 5V 전원에 연결하십시오. 이제 당신의 램프는 박수로 제어될 수 있습니다 👏.\n\n자신에게 박수를 쳐주시겠어요? 😅","ogImage":{"url":"/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_0.png"},"coverImage":"/assets/img/2024-06-20-TheClapperHowtomakeaclapsensitiveswitchwithArduino_0.png","tag":["Tech"],"readingTime":10},{"title":"소형 머신 러닝 - 주성분 분석","description":"","date":"2024-06-20 17:00","slug":"2024-06-20-TinyMLPrincipalComponentAnalysis","content":"\n\nFrom mathematical foundations to edge implementation\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 Research group: Conecta.ai (ufrn.br)\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1 — PCA 알고리즘 이론\n\n주성분 분석 (PCA)은 데이터 분석에서 널리 사용되는 강력한 기술로, 데이터 세트의 차원을 줄이면서 중요한 정보를 유지하는 데 특히 유용합니다. 이는 원래 변수를 주성분이라고 불리는 새로운, 상관관계가 없는 변수 세트로 변환하여 달성됩니다. PCA의 주요 측면을 자세히 살펴봅시다:\n\n- 차원 축소: PCA는 고차원 데이터 세트를 처리하는 데 중요합니다. 중요한 정보를 추출하고 관련성이 낮은 특징을 제거하여 분석 프로세스를 단순화합니다.\n- 데이터 탐색 및 시각화: PCA는 데이터 탐색 및 시각화에 중요한 역할을 합니다. 숨겨진 패턴과 통찰을 찾아내는 데 기여합니다.\n- 선형 변환: PCA는 데이터의 선형 변환을 수행하며, 분산의 방향을 식별하는 데 목적을 두고 있습니다. 이를 통해 데이터 세트의 더 간결한 표현이 가능해집니다.\n- 특성 선택: 주성분은 설명하는 분산에 기반하여 순위가 매겨집니다. 이 순위는 데이터의 가장 중요한 측면을 강조하는 효과적인 특성 선택을 용이하게 합니다.\n- 데이터 압축: PCA는 데이터를 압축하는 데 뛰어납니다. 큰 데이터 세트의 효율적인 저장 및 처리를 위해 원본 정보의 상당 부분을 유지합니다.\n- 클러스터링 및 분류: PCA는 클러스터링 및 분류 작업에서 실용적으로 활용됩니다. 잡음을 줄이고 기존 구조를 강조함으로써 알고리즘의 성능을 향상시킵니다.\n\n## 1.1 — 데이터 적합성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"Adequacy of Data\" 또는 \"Data Suitability\"는 일반적으로 사용 가능한 데이터가 특정 목적이나 분석에 적합하고 충분하며 관련성 있는지 여부를 나타냅니다. 그것은 손에 있는 데이터가 의도된 사용 또는 연구에 필요한 요구 사항과 기준을 충족하는지를 평가합니다.\n\n1.1.1 — Kaiser-Meyer-Olkin(KMO)\n\nKaiser-Meyer-Olkin 측정치는 분석을 위한 표본의 적절성을 평가하며, 고려중인 변수가 구분된 신뢰성 있는 요인을 얻을 것으로 예상되는지 여부를 나타냅니다. KMO 통계치는 0에서 1 사이의 범위 내에 있으며, 더 높은 값은 요인 분석에 더 적합함을 나타냅니다.\n\n- KMO가 0.5 이상일 경우: 주로 허용 가능하다고 간주되며, 데이터 집합이 요인 분석에 적합함을 나타냅니다.\n- KMO가 0.5 미만일 경우: 데이터 집합이 요인 분석에 적합하지 않을 수 있다는 것을 시사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_1.png\" /\u003e\n\n1.1.2 — Bartlett의 구형성 검정\n\nBartlett의 구형성 검정은 요인 분석의 맥락에서 사용되는 통계적 검정으로, 관측된 변수들의 상관 행렬이 항등 행렬과 유의하게 다른지를 결정하기 위해 사용됩니다. 간단히 말하면, 이는 변수들 사이에 충분한 상관관계가 있는지를 평가하여 요인 분석을 계속 진행할 수 있는지 여부를 파악하는 데 도움이 됩니다.\n\n다음은 Bartlett의 구형성 검정의 자세한 단계와 수학적 공식입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단계 1: 가설 설정\n\n- 귀무가설 (H0): 관찰된 상관 행렬은 독립 행렬이며 변수 간 상관 관계가 없음을 나타냅니다.\n- 대립가설 (H1): 관찰된 상관 행렬은 독립 행렬이 아니며 변수 간 유의한 상관 관계가 있다는 것을 시사합니다.\n\n단계 2: 바트렛의 구형성 검정 통계량 계산\n\n바트렛의 구형성 검정 통계량은 카이제곱 (χ2) 분포를 따릅니다. 검정 통계량의 공식은 다음과 같습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_2.png\" /\u003e\n\n여기서:\n\n- n은 관찰값의 수입니다.\n- p는 변수의 수입니다.\n- det(R)은 관찰된 상관 행렬의 행렬식입니다.\n- det(I)은 항등 행렬의 행렬식입니다.\n\n단계 3: 자유도 결정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자유도(df)는 카이 제곱 분포의 경우 다음과 같이 계산됩니다:\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_3.png)\n\n단계 4: 임계값과 비교\n\n계산된 χ² 통계량을 선택한 유의 수준 (예: 0.05)에서 카이 제곱 분포 표의 임계값과 비교합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n### 단계 5: 결정 내리기\n\n만약 계산된 χ2 값이 임계값보다 크다면, 귀무가설을 기각해야 합니다. 이는 변수들 간에 상관 관계가 유의미하며 요인 분석이 적절할 수 있다는 것을 시사합니다.\n\n### 1.2 — 상관계수 행렬\n\n변수 집합에 대한 Pearson 상관계수 행렬은 행렬 형태로 표현될 수 있습니다. n개의 변수를 X1,X2,…,Xn으로 표시한다고 가정해 봅시다. 이러한 변수에 대한 Pearson 상관계수 행렬 R은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_4.png)\n\nHere:\n\n- The diagonal elements (main diagonal) are all 1 because each variable perfectly correlates with itself.\n- The off-diagonal elements (rij) represent the Pearson correlation coefficient between variables Xi and Xj.\n- The matrix is symmetric (rij=rji) because the correlation between Xi and Xj is the same as the correlation between Xj and Xi.\n\nThe formula to compute rij (Pearson correlation coefficient between Xi and Xj) is given by:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_5.png)\n\n이 공식에는 평균 (Xˉi 및 Xˉj) 및 제곱 차이의 합이 포함되어 있습니다. 두 변수에 대한 이전에 설명한 쌍별 계산과 유사합니다.\n\n피어슨 상관 관계는 선형 관계만을 측정하므로 비선형 관계는 포착하지 못할 수 있습니다. 피어슨 상관 계수는 -1에서 1 사이의 범위를 가집니다:\n\n- r=1: 완벽한 양의 상관 관계;\n- r=−1: 완벽한 음의 상관 관계;\n- r=0: 선형 상관 관계 없음.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 1.3 — 고유값과 고유벡터\n\n1.3.1 — 고유값 (λ)\n\n고유값은 데이터의 최대 변이성을 포착하는, 정사각 행렬에서 유도된 독립적인 벡터들입니다. 고유값은 따라서 연구된 변수들에 의해 포착된 총 분산의 부분으로 이해될 수 있습니다.\n\n- 고유값은 식 Av=λv이 비제로 해 v를 가지는 스칼라 λ입니다.\n- 종종 λ로 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n고윳값을 찾는 방정식은 A를 원래 행렬에서 λI(단위 행렬)을 뺀 후 Determinant를 구하여 얻는 특성 방정식을 풀어야 합니다:\n\ndet(A−λI)=0\n\nλ에 대한 이 방정식을 해결하면 행렬 A의 고윳값을 얻게 됩니다.\n\n1.3.2 —고유벡터 (v)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 고유벡터는 방정식 Av=λv를 만족하는 0이 아닌 벡터 v입니다.\n- 종종 v로 표기됩니다.\n\n- 고유값을 구했다면, 각 고유값을 방정식 Av=λv에 대입하여 v에 대해 풀어서 해당하는 고유벡터를 찾을 수 있습니다. 이 솔루션들이 고유벡터를 형성합니다.\n\n이 과정은 아래와 같이 요약될 수 있습니다:\n\n- 고유문자식: det(A−λI)=0;\n- 고유값(λ) 구하기: 고유문자식을 해결하여 고유값 λ를 찾습니다.\n- 고유벡터(v) 찾기: 각 고유값 λ에 대해, (A−λI)v=0인 선형 방정식을 풀어 해당하는 고유벡터 v를 찾습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 1.4 — 요인들\n\nPCA는 식별된 직교 기저의 새로운 축을 나타내는 요인의 집합입니다. 첫 번째 요인은 샘플의 분산을 가장 잘 설명하는 조합입니다. 두 번째 요인은 두 번째로 높은 분산을 설명하며 첫 번째 요인과 관련이 없습니다. 이와 같이 계속됩니다. 따라서 PCA 알고리즘의 출력은 초관련 변수 집합으로부터 유도된 상관관계가 없는 변수 집합입니다.\n\nPCA에서 주성분(요인)을 형성하기 위해 원래 변수들의 선형 조합을 행렬 형태로 표현할 수 있습니다. 표준화된 데이터 행렬을 Z로 표시하고(열은 표준화된 변수를 나타냄), 고유벡터 행렬을 V로 표시합니다(열은 고유벡터를 나타냄). k번째 주성분(Fk)을 얻기 위한 선형 조합은 다음과 같이 표현될 수 있습니다:\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기에는 Z가 표준화된 데이터 행렬이고, Vk는 k번째 고유값에 해당하는 고유벡터 행렬의 k번째 열입니다. Fk의 개별 요소는 다음과 같이 표현될 수 있습니다:\n\n\n| Fk1 |\n| Fk2 |\n| ... |\n| Fkn |\n\n\n이 식에서 Fki는 k번째 주성분의 i번째 관측값, Zij는 j번째 표준화된 변수의 i번째 관측값, Vjk는 j번째 고유벡터의 k번째 요소입니다.\n\n이 선형 결합을 사용하여 k번째 주성분을 원래 표준화된 변수들의 가중 합으로 표현할 수 있습니다. 가중치는 k번째 고유벡터의 요소로 제공됩니다. 각 주성분은 원래 변수들의 다른 선형 결합을 나타내며, 데이터의 최대 분산을 포착합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1.4.1 — 요인 수\n\n- 카이저의 규칙: 이 방법은 각각의 고유값이 1보다 큰 값을 가지는 요인을 선택하는 방법으로 구성되어 있습니다. 다시 말해서, 우리는 1 이상의 분산을 설명하는 요인들만 사용하고 싶습니다.\n- 공유 분산 분석: 이 방법은 누적된 공유 분산의 합을 분석하는 주관적인 방법입니다. 이 방법을 통해 우리는 가능한 한 적은 수의 요인을 유지하면서 가장 많은 분산을 설명하는 요인의 수를 선택하려고 합니다. 이를 위해, 비즈니스 문제에 따라 70~90%의 공유 분산이 설명되면 충분할 수 있으므로, 공유 분산의 70~90%를 합한 요인이 정의될 것입니다.\n\n## 1.5— 요인 부하\n\n요인 부하는 특정 요인에 대한 각 원본 변수에 할당된 가중치를 의미합니다. 이러한 부하는 각 변수와 해당 요인간의 관계의 강도와 방향을 나타냅니다. 요인 부하의 수학적 설명을 살펴봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPCA에서 요인 적재량은 표준화된 데이터의 공분산 행렬 또는 상관 행렬의 고유벡터에서 유도됩니다. Vk가 k번째 고유값에 연결된 고유벡터라고 가정해 봅시다. j번째 변수와 k번째 요인의 요인 적재량(λjk)은 Vk의 요소에서 얻어집니다.\n\n요인 적재량은 원래 변수 Xj가 k번째 요인에 얼마나 기여하는지를 나타냅니다. λjk가 양수이면, Xj와 k번째 요인 사이에 긍정적 상관 관계가 있다는 것을 시사하며, 음수이면 음적 상관 관계를 시사합니다. 요인 적재량의 크기는 관계의 강도를 나타냅니다.\n\n요인 모델에서 요인 적재량(λjk)은 원래 변수와 잠재적인 요인 사이의 관계를 나타내는 매개변수입니다. 이 모델은 다음과 같이 표현됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같은 테이블을 Markdown 포맷으로 바꿔주세요.\n\n\n| 변수 | 설명 |\n|------|------|\n| Xj   | j번째 원본 변수 |\n| λjk  | Xj와 k번째 요인 간의 관계를 나타내는 요인 로딩 |\n| Fk   | k번째 잠재 요인 |\n| εj   | j번째 변수와 연관된 오차 |\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기존 변수에서 잠재 요인으로 설명되는 분산의 비율을 의미합니다. \"공용성\"의 수학적 설명을 살펴보겠습니다.\n\n만약 p개의 원래 변수 X1,X2,…,Xp가 있다면, j번째 변수 (Hj)의 공용성은 다음과 같이 계산됩니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- m은 인자의 수입니다.\n- λjk는 j번째 변수의 k번째 인자에 대한 인자 적재입니다.\n\n공통 분산은 잠재적 요인에 의해 설명된 Xj 변수의 분산의 총량을 나타냅니다. 합계에서 각 항목 2λjk^2은 공통 분산에 기여하며, k번째 인자에 의해 설명된 변수 Xj의 분산의 비율을 나타냅니다.\n\n실용적으로, Hj가 1에 가까우면 변수 Xj가 잠재적 요인에 의해 잘 설명된다는 것을 나타냅니다. 0에 가까우면 변수는 모델의 요인들에 의해 잘 표현되지 않습니다.\n\n모든 변수의 공통성의 합계는 모델의 요인들에 의해 설명된 총 분산의 전반적인 지표입니다. 변수가 p개인 경우, 총 분산은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 요인에 의해 설명된 분산이며:\n\n![image2](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_12.png)\n\n요인에 의해 설명된 분산의 비율은 요인에 의해 설명된 분산을 총 분산으로 나누어 계산할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2— TinyML 구현\n\n이 예시를 통해 ESP32, 아두이노, 라즈베리파이 및 다른 다양한 마이크로컨트롤러 또는 IoT 장치에 기계 학습 알고리즘 (PCA)을 구현할 수 있습니다.\n\n1 — 다음 명령으로 micromlgen 패키지를 설치하세요:\n\n```js\n!pip install micromlgen\n!pip install factor_analyzer\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2 — 라이브러리 가져오기\n\n```python\nfrom micromlgen import port\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport numpy as np\n\nfrom factor_analyzer.factor_analyzer import calculate_kmo\nfrom factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nfrom factor_analyzer import FactorAnalyzer\n```\n\n3 — 데이터셋 로드\n\nDecathlon\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n41행 13열로 구성된 데이터베이스가 있습니다. 첫 10개 열은 각 선수의 10종목 경기 성적에 해당합니다. 열 11과 12는 각각 선수의 등급과 획득한 점수를 나타냅니다. 마지막 열은 2004년 올림픽 게임 또는 2004년 데카스론과 같은 종목에 해당하는 범주형 변수입니다.\n\n다음은 변수입니다.\n\n- 100m (100m 달리기)\n- long.jump (멀리뛰기)\n- shot.put (역도)\n- High.jump (높이뛰기)\n- 400m (400m 달리기)\n- 110m.hurdle (110m 허들)\n- Discus (원반 던지기)\n- Pole.vault (양봉)\n- Javeline (투창)\n- 1500m (1500m 달리기)\n\n\npatch = './data/decathlon.csv'\ndf = pd.read_csv(patch, index_col=0)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 아래는 Markdown 형식으로 테이블의 변경 내용이 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_13.png\" /\u003e\n\n4 — 데이터셋 시각화\n\n```js\nsns.pairplot(df)\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_14.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5- 데이터 표준화하기\n\n```js\ncolumns_selected = ['100m', 'Long.jump', 'Shot.put', 'High.jump', '400m', '110m.hurdle',\n       'Discus', 'Pole.vault', 'Javeline']\n\nX = df[columns_selected]\n```\n\n```js\nX_standardized = StandardScaler().fit_transform(X)\ndf_X_standardized = pd.DataFrame(X_standardized, columns=columns_selected)\n```\n\n6- 데이터의 상관 행렬 분석하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n6.1- 상관 행렬\n\n```js\ncorr = X.corr()\ncorr\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_15.png\" /\u003e\n\n```js\n# 그림 크기 조정\nplt.figure(figsize=(10, 8))\n\n# 히트맵 생성을 위한 기존 코드\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n\n# 히트맵에 값 추가\nfor i in range(len(corr.columns)):\n    for j in range(len(corr.columns)):\n        plt.text(j + 0.5, i + 0.5, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', color='w')\n\n# 히트맵 표시\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_16.png)\n\n6.2 — 고유값과 고유벡터\n\n```js\nX = np.matrix(X)\ncov_matrix =  np.cov(np.transpose(X))\n```\n\n```js\nnp.diagonal(cov_matrix)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_17.png\" /\u003e\n\n```js\neigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\nsorted_indices = np.argsort(eigenvalues)[::-1]\neigenvalues = eigenvalues[sorted_indices]\neigenvectors = eigenvectors[:, sorted_indices]\n```\n\n```js\neigenvalues\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_18.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n고유벡터\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_19.png)\n\n7— 데이터 적합성\n\n7.1 — 카이저-마이어-올킨 (KMO)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# KMO 값 계산\nkmo_score, kmo_model = calculate_kmo(X)\n\n# KMO 점수 표시\nprint(f'카이저-마이어-올킨 (KMO) 점수: {kmo_model}')\n```\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_20.png)\n\n```js\n# 변수별로 KMO를 시각화하는 막대 차트 생성\nplt.figure(figsize=(12, 6))\nplt.bar(df_X_standardized.columns, kmo_score, color='blue')\nplt.title('변수별 KMO')\nplt.xlabel('변수')\nplt.ylabel('KMO 값')\nplt.grid()\nplt.xticks(rotation=45, ha='right')  # 더 잘 보이도록 x축 레이블 회전\n```\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_21.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n7.2 — 바틀렛의 구 구형성 검정\n\n```js\n# 바틀렛의 구 구형성 검정 계산\nchi_square, p_value = calculate_bartlett_sphericity(X)\n\n# 검정 통계량 표시\nprint(f'카이제곱 값: {chi_square}')\nprint(f'P-value: {p_value}')\n```\n\n![Image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_22.png)\n\n```js\n# 바틀렛의 구 구형성 검정 시각화\nplt.figure(figsize=(6, 4))\nplt.bar(['카이제곱 값', 'P-value'], [chi_square, p_value], color=['blue', 'green'])\nplt.title(\"바틀렛의 구 구형성 검정\")\nplt.ylabel('값')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_23.png\" /\u003e\n\n### 8 - 주성분 분석\n\n```js\nX = np.asarray(X)\n```\n\n```js\npca = PCA()\npca.fit(X)\nautovalores = pca.explained_variance_\nautovetores = pca.components_\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n8.1 — 카이젤의 법칙\n\n```js\n# 관련 요인 분석 객체를 생성하고 데이터에 적합화합니다\nfa = FactorAnalyzer()\nfa.fit(X)\n\n# 고유값을 가져옵니다\neigenvalues, _ = fa.get_eigenvalues()\n```\n\n```js\n# 고유값을 요인 번호에 대해 그려봅니다\nplt.figure(figsize=(10, 8))\nplt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o')\nplt.title(\"Scree Plot\")\nplt.xlabel(\"요인 번호\")\nplt.ylabel(\"고유값\")\nplt.axhline(1, color='red', linestyle='dashed', linewidth=2, label=\"카이젤의 기준 (고유값 = 1)\")\nplt.legend()\nplt.grid()\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_24.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n8.2 — 공유 분산의 분석\n\n```js\nexp_var_cumul = np.cumsum(pca.explained_variance_ratio_)\n```\n\n```js\n# 공분산 설명 비율 시각화\nplt.figure(figsize=(10, 8))\n# 각 요인으로 설명되는 누적 분산 플롯\nplt.plot(exp_var_cumul )\nplt.title('요인별 공분산 설명 비율')\nplt.xlabel('요인 수')\nplt.ylabel('누적 설명 분산 (%)')\nplt.grid()\nplt.show()\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_25.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n8.3 — Plot Components\n\n```python\nmodel = PCA(n_components=2)\nX_pca = model.fit(X)\n```\n\n```python\ncomponents = model.fit_transform(X)\ncomponents \n```\n\n```python\nloadings = model.components_.T * np.sqrt(model.explained_variance_)\n\nfig = px.scatter(components, x=0, y=1)\n\nfor i, feature in enumerate(columns_selected):\n    fig.add_shape(\n        type='line',\n        x0=0, y0=0,\n        x1=loadings[i, 0],\n        y1=loadings[i, 1]\n    )\n    fig.add_annotation(\n        x=loadings[i, 0],\n        y=loadings[i, 1],\n        ax=0, ay=0,\n        xanchor=\"center\",\n        yanchor=\"bottom\",\n        text=feature,\n    )\nfig.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_26.png)\n\n9 - Inverse Transform\n\n```js\nX_reconstructed = model.inverse_transform(components)\nX_reconstructed\n```\n\n![Image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_27.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n10— 마이크로콘트롤러에 구현할 모델 획득\n\n```js\nprint(port(model))\n```\n\n```js\n#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class PCA {\n                public:\n                    /**\n                    * 차원 축소 적용\n                    * @warn 목적지 벡터가 제공되지 않으면 원본 벡터를 덮어씁니다!\n                    */\n                    void transform(float *x, float *dest = NULL) {\n                        static float u[2] = {0};\n                        u[0] = dot(x, -0.010208828727, 0.009522664636, 0.07801034572, 0.004103495259, -0.003935853874, -0.004232033634, 0.21088426957, -0.00282519103, 0.974263356619);\n                        u[1] = dot(x, -0.015215508318, 0.016476395215, 0.128355383147, 0.008750586985, -0.049637455695, -0.049172415055, 0.964175225747, -0.0112017847, -0.219782142624);\n                        memcpy(dest != NULL ? dest : x, u, sizeof(float) * 2);\n                    }\n\n                protected:\n                    /**\n                    * 가변 길이 인수로 점곱 계산\n                    */\n                    float dot(float *x, ...) {\n                        va_list w;\n                        va_start(w, 9);\n                        static float mean[] = {10.998048780488, 7.26, 14.477073170732, 1.976829268293, 49.616341463415, 14.605853658537, 44.325609756098, 4.76243902439, 58.316585365854};\n                        float dot = 0.0;\n\n                        for (uint16_t i = 0; i \u003c 9; i++) {\n                            dot += (x[i] - mean[i]) * va_arg(w, double);\n                        }\n\n                        return dot;\n                    }\n                };\n            }\n        }\n    }\n```\n\n11— 템플릿을 .h 파일에 저장\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nwith open('./PCA/PCA.h', 'w') as file:\n    file.write(port(model))\n```\n\n12- 완성된 아두이노 스케치\n\n아래에 표시된 대로 아두이노 스케치에 \"PCA.h\" 파일을 포함시키세요:\n\n```js\n#include \"PCA.h\"\n\nEloquent::ML::Port::PCA pca;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    float X_1[9] = {11.04,  7.58, 14.83,  2.07, 49.81, 14.69, 43.75,  5.02, 63.19};\n    float result_1[2];\n    pca.transform(X_1, result_1);\n    Serial.print(\"입력 X1로 예측한 결과:\");\n    for (int i = 0; i \u003c 2; i++) {\n        Serial.print(\" \");\n        Serial.print(result_1[i]);\n    }\n    Serial.println();  // 맨 끝에 새 줄 추가\n    delay(2000);\n\n    float X_2[9] = {10.76,  7.4 , 14.26,  1.86, 49.37, 14.05, 50.72,  4.92, 60.15};\n    float result_2[2];\n    pca.transform(X_2,  result_2);\n    Serial.print(\"입력 X2로 예측한 결과:\");\n    for (int i = 0; i \u003c 2; i++) {\n        Serial.print(\" \");\n        Serial.print(result_2[i]);\n    }\n    Serial.println();  // 맨 끝에 새 줄 추가\n    delay(2000);\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과:\n\n구성요소 X1: [ 4.65528953, -1.59196422]\n\n역변환 X1: [10.97474627, 7.27810093, 14.63589674, 1.98200161, 49.67703998, 14.66443304, 43.77240463, 4.76711978, 63.20194867]\n\n구성요소 X2: [ 3.12393184, 5.77720022]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n역변환 된 X2: [10.87825406, 7.38493559, 15.46230692, 2.0402022, 49.3172806, 14.30855419, 50.55463117, 4.68889837, 60.09039224]\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_28.png)\n\n전체 프로젝트는 다음에서 확인할 수 있어요: [TinyML/07_principal_components_analysis at main · thommaskevin/TinyML](github.com)\n\n## 만약 마음에 드신다면, 제게 커피한 잔 ⚡️💰(Bitcoin)을 사주실래요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 Markdown 형식으로 변경된 코드입니다:\n\n\ncode: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_29.png)\n","ogImage":{"url":"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_0.png"},"coverImage":"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_0.png","tag":["Tech"],"readingTime":17},{"title":"마이크로 머신러닝  합성곱 신경망 CNN","description":"","date":"2024-06-20 16:55","slug":"2024-06-20-TinyMLConvolutionalNeuralNetworksCNN","content":"\n\n수학적 기초부터 엣지 구현까지\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 연구 그룹: Conecta.ai (ufrn.br)\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 요약\n\n# 1 — 컨볼루션 신경망 역사\n\n컨볼루션 신경망(CNN)의 개념은 1980년대 금사이 후코시마의 연구로 형성되기 시작했습니다. 그는 Neocognitron을 개발했는데, 이는 동물의 시각 시스템 구조에서 영감을 받아 자가 조직화 과정을 통해 시각적 패턴을 인식할 수 있는 학습이 가능한 계층적 구조를 가졌습니다. 이 작업은 현대 CNN의 개발을 위한 중요한 선행 연구였습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCNN의 현대 아키텍처는 얀 르쿤과 그의 동료들에 의해 1980년대 후반과 1990년대 초에 제안되었습니다. 그들은 MNIST 데이터셋에서 손으로 쓴 숫자를 인식하기 위해 설계된 컨볼루션 신경망인 LeNet-5를 개발했습니다. LeNet-5는 여러 개의 컨볼루션 레이어를 거친 후 pooling 레이어와 완전 연결 레이어로 이어지는 구조로, 오늘날 사용되는 CNN의 아키텍처의 기초를 구축했습니다.\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_2.png)\n\n초기 성공에도 불구하고 CNN의 활용은 계산 제약과 대규모 레이블 데이터셋의 부족으로 제한되었습니다. 그러나 컴퓨팅 파워가 증가하고 GPU(그래픽 처리 장치)를 사용해 딥 네트워크를 훈련하는 기술이 실현 가능해지면서 CNN은 더 많은 관심을 끌게 되었습니다. 게다가 ImageNet과 같은 대규모 레이블 이미지 데이터베이스의 개발은 딥 네트워크를 효과적으로 훈련하기 위한 필수 자료를 제공했습니다.\n\n2012년에 Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton이 개발한 AlexNet이 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 경쟁 상대들보다 큰 폭으로 우승하면서 전환점이 찾아왔습니다. AlexNet은 여러 컨볼루션 레이어, ReLU 활성화 함수, 그리고 dropout과 같은 정규화 기법을 활용하여 시각 인식 작업에 CNN의 성능을 입증했습니다. 이후로 CNN은 다양한 응용 분야에 대한 주요 도구가 되어 지속적인 혁신을 이끌어내는 데 이르렀습니다. VGGNet, GoogLeNet(Inception), ResNet과 같은 모델들은 네트워크의 깊이, 효율성, 정확도를 향상시키기 위한 새로운 아키텍처와 기법들을 소개했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_3.png\" /\u003e\n\n지금은 CNN이 많은 인공지능 시스템의 필수 구성 요소입니다. 이미지 인식 뿐만 아니라 비디오 분석, 자연어 처리, 의학 진단, 자율 주행차 등 다양한 분야에서 사용됩니다. 연구는 계속해서 발전하고 있으며, 효율적인 합성곱 신경망, 깊은 신경망(DNNs), 생성적 적대 신경망(GANs) 등의 혁신이 이루어지고 있습니다.\n\n# 2— 합성곱 신경망 이론\n\n수학에서 \"합성곱\"은 한 함수가 다른 함수에 의해 변환되는 통합 연산을 나타냅니다. 그러나 신경망의 맥락에서는 이 개념이 전통적인 통계적 해석과 다릅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기본적으로 우리는 입력 함수로 시작합니다. 우리의 경우에는 주로 이미지입니다. 또한, 필터(커널이라고도 함)를 소개합니다. 이미지는 점곱 연산을 통해 변환되는 함수로, 일반적으로 \"합성곱(convolution)\"이라고 합니다. 그 다음, 이러한 필터를 입력 이미지에 적용하면 \"특성 맵(feature maps)\"이라고 하는 출력 이미지를 얻게 됩니다.\n\n## 2.1 — 합성곱 계층\n\n합성곱 계층은 패턴을 감지하고 필터(커널)를 통해 특성 맵을 생성하기 위해 이미지가 처리되는 곳입니다. 이러한 특성 맵은 필터가 식별하려는 각 속성을 나타냅니다. 필터는 일반적으로 (3x3) 또는 (5x5) 행렬로 구성되어 있으며, 각 필터는 입력 이미지에서 동일한 크기의 필드를 차지합니다. 그런 다음, 필터가 한 칸씩 가로로 이동하고 같은 프로세스가 반복됩니다. 가로 끝에 도달하면 필터가 한 칸 아래로 이동하고 점곱 프로세스가 다시 수평으로 적용됩니다. 그 결과는 순서대로 출력에 추가되어 특성 맵을 생성합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/0*4UZXfXs7eQ3TT02M.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n입력 이미지를 나타내는 텐서 I의 차원이 m1 x m2 x mc인 경우를 가정해 봅시다. 이 텐서에서,\n\n![image1](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_4.png)\n\n우리는 입력 이미지와 일치하는 채널 수를 가진 (n1 x n2 x nc) 차원을 가지는 필터를 적용합니다. 이 필터는 이미지를 왼쪽에서 오른쪽으로 움직이면서, 입력 텐서 I의 해당 영역과 요소별 곱셈을 수행하고 이러한 곱셈 결과를 합산합니다. 스트라이드 매개변수는 필터가 이미지를 횡단하는 단계 크기를 결정합니다. I와 K 사이의 이 작업의 결과는 다른 차원 (m1 - n1 + 1) x (m2 - n2 + 1) x 1을 가진 또 다른 텐서를 생성합니다.\n\n![image2](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요,\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_6.png\" /\u003e\n\n특징 맵의 (i, j)번째 항목은 다음과 같이 계산됩니다:\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 예를 선택했습니다. 5x5x1 차원 이미지가 3x3x1 커널로 합성되고 s=1 스트라이드가 적용됩니다.\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_8.png)\n\n특징 맵의 (i, j)-번째 항목은 단일 채널에 대한 다음 일반 공식으로 주어집니다:\n\n![formula](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 예에서 feature map의 (1, 1)번 째 항목을 계산해 봅시다:\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_10.png)\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_11.png)\n\n사용할 수 없는 항목은 0으로 대체되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_12.png)\n\n마찬가지로, 남은 항목들은 동일한 공식을 사용하여 계산할 수 있습니다. 이 과정은 서로 다른 유형의 필터를 적용함으로써 반복되며, 각각이 이미지의 다른 특징을 캡처하는 것을 보여줍니다. 예를 들어, 필터 개수가 하나 이상이 될 수 있어서 스트라이드 개념이 도입됩니다.\n\n## 2.2— 패딩 레이어\n\n기본 CNN은 (n x n) 크기의 흑백 이미지와 (f x f) 크기의 필터/커널을 사용하여 결과를 제공하며, 출력 크기는 (n - f + 1) x (n - f + 1)이 됩니다. 예를 들어, (8 x 8) 이미지와 (3 x 3) 필터를 사용한 어떤 합성 곱 작업의 경우, 출력 이미지 크기는 (6 x 6)이 됩니다. 이러한 크기의 감소는 이미지 처리 중 일관적으로 발생하며, 레이어의 출력이 일반적으로 입력보다 작습니다. 또한, 합성 곱 작업에서 사용되는 필터는 픽셀을 횡단하면서 항상 모서리에 초점을 두지 않습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![TinyML CNN](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_13.png)\n\n머신 러닝에서 일반적으로 사용되는 여러 유형의 패딩이 있습니다:\n\n- Same 패딩: Same 패딩은 원본 이미지의 외부 프레임에 일반적으로 0과 같은 추가 요소를 추가하는 것을 포함합니다. 이 방식으로 입력을 확장함으로써, 필터가 더 넓은 영역을 스캔할 수 있게 되어 출력 이미지가 원본과 동일한 크기를 유지할 수 있습니다. 이것은 컨볼루션 작업 중 공간적 차원을 유지하는 데 유용합니다.\n- Valid 패딩: Same 패딩과는 달리, Valid 패딩은 이미지에 추가 요소를 추가하는 것을 포함하지 않습니다. 필터는 추가 요소 없이 원본 이미지를 훑어갑니다. 이것은 간격으로 인한 일부 데이터 손실이 발생할 수 있지만, valid 패딩은 출력 피쳐 맵의 크기를 줄이고자 할 때 사용됩니다. 이러한 축소는 모델의 매개변수 수를 줄이고 계산 효율성을 향상시킬 수 있습니다.\n- Causal 패딩: Causal 패딩은 주로 시퀀스-투-시퀀스 모델 및 시계열 예측에 사용되며, 특히 1차원 컨볼루션 레이어에서 사용됩니다. 이 유형의 패딩은 데이터 시퀀스의 시작 부분에 요소를 추가하여 알고리즘이 초기 시간 단계에 대한 값을 예측할 수 있게 합니다. 과거 및 현재 데이터를 예측에 포함시킴으로써, causal 패딩은 모델이 추론 중에 사용할 수 없는 미래 데이터를 활용하지 않도록 보장합니다.\n- Full 패딩: 이 유형의 패딩은 입력의 테두리 주위에 여러 레이어의 0을 추가하여 원본 이미지 크기보다 큰 출력 피쳐 맵을 생성합니다. Full 패딩은 덜 일반적이지만 더 큰 출력 크기가 필요한 특정 시나리오에서 사용할 수 있습니다.\n\n## 2.3 —Pooling Layer\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n풀링 레이어에서는 컨볼루션된 특징의 공간 차원이 일반적으로 축소되어 입력 이미지에서 주요한 특징을 추출하는 데 도움이 됩니다. 이 크기의 축소는 컨볼루션 레이어에서 얻은 출력에 풀링 함수를 적용하여 달성됩니다. 이렇게 가정해 봅시다:\n\n![그림 1](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_14.png)\n\n풀링된 부분의 차원은 다음과 같습니다:\n\n![그림 2](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_15.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n딥러닝에서는 3가지 종류의 풀링이 있어요:\n\n평균 풀링: 커버된 영역 내 픽셀 값의 평균이 출력 매트릭스로 전달됩니다.\n\n최대 풀링: 커버된 영역 내 픽셀 값 중 가장 높은 값이 출력 매트릭스로 전달됩니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_16.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전역 최대 풀링(Global Max Pooling) : 모든 입력 크기의 픽셀 값 중 가장 높은 값이 출력 행렬로 전달됩니다. 이 유형의 풀링에서 풀 크기는 입력 크기와 동일합니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_17.png)\n\nsum pooling, average pooling, max pooling과 같은 다양한 유형의 풀링이 있습니다. 최대 풀링의 예는 아래에 제공됩니다. 최대 풀링은 2x2 패치에 수행됩니다. 각 패치에서 최댓값이 선택됩니다.\n\n## 2.4 — 플래튼 레이어\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n플래튼 레이어는 신경망 아키텍처에서 중요한 구성 요소이며, 특히 합성곱 레이어에서 완전히 연결된 레이어로의 전환 시에 중요합니다. 이 레이어는 합성곱 및 풀링 레이어에서 생성된 다차원 피쳐 맵을 일차원 벡터로 변환하여, 분류 또는 회귀 작업을 위해 후속 완전히 연결된 레이어로 전달할 수 있습니다.\n\n![이미지 설명](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_18.png)\n\n다음은 플래튼 레이어의 작동 방식입니다:\n\n- 입력: 플래튼 레이어의 입력은 일반적으로 이전 합성곱 또는 풀링 레이어에서 생성된 피쳐 맵을 나타내는 다차원 텐서입니다. 예를 들어, 마지막 합성곱 또는 풀링 레이어가 높이, 너비, 깊이의 피쳐 맵을 생성한다면 입력 텐서는 (배치 크기, 높이, 너비, 깊이) 형태를 가질 것입니다.\n- 플래팅: 플래팅 레이어는 단순히 피쳐 맵의 모든 요소를 하나의 차원을 따라 연결하여 입력 텐서를 일차원 벡터로 다시 형태화합니다. 예를 들어, 피쳐 맵이 높이, 너비, 깊이의 차원을 가진다면 플래팅 레이어는 이를 높이 * 너비 * 깊이의 길이를 가진 벡터로 변환합니다.\n- 출력: 플래팅 레이어의 출력은 피쳐 맵을 플래팅한 일차원 벡터입니다. 이 벡터는 이후의 완전히 연결된 레이어의 입력으로 전달될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n평탄화 레이어의 목적은 특성 맵에서 캡처된 공간 정보를 완전 연결 레이어에서 처리할 수 있는 형식으로 변환하는 것입니다. 완전 연결 레이어는 일차원 입력 벡터를 필요로하므로 특성 맵을 평탄화함으로써 신경망이 데이터의 다양한 공간 위치에 걸쳐 복잡한 패턴과 관계를 효과적으로 학습할 수 있습니다. 이를 통해 더 정확한 예측을 할 수 있습니다.\n\n이전의 합성곱 또는 풀링 레이어에 의해 생성된 특성 맵 𝐹 집합이 있다고 가정해봅시다. 이러한 특성 맵의 차원을 다음과 같이 표기해 봅시다:\n\n- 𝐻: 특성 맵의 높이\n- 𝑊: 특성 맵의 너비\n- 𝐷: 특성 맵의 깊이 (채널 수)\n- 𝐵: 배치 크기 (배치에 포함된 샘플 수)\n\n그러면 특성 맵 𝐹의 형태는 (B,H,W,D)가 됩니다. 여기서 𝐵은 배치 크기를 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 피처 맵을 일차원 벡터로 평탄화하기 위해, 단순히 이를 길이 𝐻×𝑊×𝐷의 벡터로 재구성합니다. 수학적으로 표현하면 다음과 같습니다:\n\nFlatten(𝐹)=reshape(𝐹, (𝐵, 𝐻×𝑊×𝐷))\n\n이 경우, 재구성 연산은 (𝐵, 𝐻, 𝑊, 𝐷) 텐서를 (𝐵, 𝐻×𝑊×𝐷) 텐서로 재구성하여 공간 차원을 하나의 차원으로 펼치게 됩니다.\n\n예를 들어, 만약 𝐹가 차원이 (4,5,5,3)인 경우 (배치 크기가 4, 높이가 5, 너비가 5, 깊이가 3인 피처 맵), 그러면 평탄화된 출력은 (4,75) 차원을 갖게 되며, 각 행은 배치의 한 샘플에 대한 평탄화된 피처 맵을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 평탄화된 벡터는 신경망의 후속 완전 연결 레이어에 입력으로 전달될 수 있습니다.\n\n# 3 — TinyML 구현\n\n이 예제를 통해 ESP32, 아두이노, 라즈베리 파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에서 머신러닝 알고리즘을 구현할 수 있습니다.\n\n3.0 — requirements.txt 파일에 나열된 라이브러리를 설치합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\n!pip install -r requirements.txt\n```\n\n3.1 — 라이브러리 가져오기\n\n```python\nimport numpy as np\nfrom sklearn.datasets import load_digits\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport time\nimport seaborn as sns\nimport os\n```\n\n3.2 — 데이터셋 불러오기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMNIST은 Modified National Institute of Standards and Technology database의 줄임말로, 기공 학습 및 컴퓨터 비전 분야에서 널리 사용되는 데이터셋입니다. 이 데이터셋은 0에서 9까지의 손으로 쓴 숫자들의 모음으로, 각 숫자는 28x28 픽셀 크기의 회색 음영 이미지로 표현됩니다. 이 데이터셋에는 총 70,000개의 이미지가 포함되어 있으며, 이 중 60,000개의 이미지는 훈련에 사용되고 10,000개의 이미지는 테스트에 사용됩니다.\n\n링크: [https://www.nist.gov/itl/products-and-services/emnist-dataset](https://www.nist.gov/itl/products-and-services/emnist-dataset)\n\n```python\ndef get_data():\n    np.random.seed(1337)\n    x_values, y_values = load_digits(return_X_y=True)\n    x_values /= x_values.max()\n    # reshape to (8 x 8 x 1)\n    x_values = x_values.reshape((len(x_values), 8, 8, 1))\n    # split into train, validation, test\n    TRAIN_SPLIT = int(0.6 * len(x_values))\n    TEST_SPLIT = int(0.2 * len(x_values) + TRAIN_SPLIT)\n    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n\n    return x_train, x_test, x_validate, y_train, y_test, y_validate\n```\n\n3.3 — 데이터 분할\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nX_train, X_test, X_validate, y_train, y_test, y_validate = get_data()\n```\n\n3.4 — 탐색적 데이터 분석\n\n```js\nX_train__ = X_train.reshape(X_train.shape[0], 8, 8)\n\nfig, axis = plt.subplots(1, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train__[i], cmap='binary')\n    digit = y_train[i]\n    ax.set(title = f\"실제 숫자는 {digit}입니다.\")\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_19.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.5— 모델 정의하기\n\n```js\nmodel = tf.keras.Sequential()\nmodel.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(8, 8, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(len(np.unique(y_train))))\n```\n\n```js\nmodel.summary()\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_20.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nplot_model(model, to_file='./figures/model.png')\n```\n\n![Plot](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_21.png)\n\n3.6—모델 컴파일하기\n\n```js\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.7 — 모델 훈련\n\n```js\nhistory = model.fit(X_train, y_train,\n                    epochs=50,\n                    batch_size=16,\n                    validation_data=(X_validate, y_validate))\n```\n\n```js\nmodel.save('.\\models\\model.keras')\n```\n\n```js\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'r.', label='훈련 손실')\nplt.plot(epochs, val_loss, 'y', label='검증 손실')\nplt.title('훈련 및 검증 손실')\nplt.xlabel('에포크')\nplt.ylabel('손실')\nplt.grid()\nplt.legend()\nplt.savefig('.\\\\figures\\\\history_traing.png', dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_22.png\" /\u003e\n\n모델 평가\n\n테스트 데이터\n\n```js\ndef test_model(model, x_test, y_test):\n    x_test = (x_test / x_test.max()).reshape((len(x_test), 8, 8, 1))\n    y_pred = model.predict(x_test).argmax(axis=1)\n    print('정확도', ((y_pred == y_test).sum() / len(y_test))*100, \"%\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\ntest_model(model, X_test, y_test)\n```\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_23.png)\n\n3.8.2 — Confusion matrix\n\n```js\nfig = plt.figure(figsize=(10, 10)) # Set Figure\n\ny_pred = model.predict(X_test) # Predict class probabilities as 2 =\u003e [0.1, 0, 0.9, 0, 0, 0, 0, 0, 0, 0]\nY_pred = np.argmax(y_pred, 1) # Decode Predicted labels\nmat = confusion_matrix(y_test, Y_pred) # Confusion matrix\n\n# Plot Confusion matrix\nsns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues, fmt='.0f', \n            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test), \n            annot_kws={\"fontsize\": 14}, linewidths=1, linecolor='white')\n\nplt.xlabel('Predicted Values', fontsize=14)\nplt.ylabel('True Values', fontsize=14)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.savefig('.\\\\figures\\\\confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_24.png)\n\n3.8.3— 예측 유효성 검사 결과\n\n```js\ny_pred = model.predict(X_test)\nX_test__ = X_test\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test__[i], cmap='binary')\n    ax.set(title = f\"실제 숫자: {y_test[i]}\\n예측 숫자: {y_pred[i].argmax()}\")\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_25.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.9 — 마이크로컨트롤러에 구현할 모델을 얻기\n\n3.9.1 — C 프로그래밍을 위해 일부 16진수 값을 배열로 변환하기\n\n```js\n# 함수: C 프로그래밍을 위해 일부 16진수 값을 배열로 변환\ndef hex_to_c_array(hex_data, var_name):\n\n  c_str = ''\n\n  # 헤더 가드 생성\n  c_str += '#ifdef __has_attribute\\n'\n  c_str += '#define HAVE_ATTRIBUTE(x) __has_attribute(x)\\n'\n  c_str += '#else\\n'\n  c_str += '#define HAVE_ATTRIBUTE(x) 0\\n'\n  c_str += '#endif\\n'\n  c_str += '#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) \u0026\u0026 !defined(__clang__))\\n'\n  c_str += '#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\\n'\n  c_str += '#else\\n'\n  c_str += '#define DATA_ALIGN_ATTRIBUTE\\n'\n  c_str += '#endif\\n\\n'\n\n  # C 변수 선언\n  c_str += 'const unsigned char ' + var_name + '[]  DATA_ALIGN_ATTRIBUTE = {'\n  hex_array = []\n  for i, val in enumerate(hex_data) :\n\n    # 16진수에서 문자열로 변환\n    hex_str = format(val, '#04x')\n\n    # 각 줄이 80자 이내로 유지되도록 서식 지정 추가\n    if (i + 1) \u003c len(hex_data):\n      hex_str += ','\n    if (i + 1) % 12 == 0:\n      hex_str += '\\n '\n    hex_array.append(hex_str)\n\n  # 마지막 중괄호 추가\n  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n\n  # 헤더 가드 종료\n  c_str += 'const int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n\n  return c_str\n```\n\n3.9.2—모델을 Float32와 Int8형식으로 변환하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef representative_dataset():\n    for i in range(len(X_train)):\n        input_data = np.array([X_train[i]], dtype=np.float32)\n        yield [input_data]\n\ndef converter_quantization_model(model, model_name):\n\n    # Convert the model to float32\n    converter_float32 = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_float32.optimizations = [tf.lite.Optimize.DEFAULT]\n    converter_float32.target_spec.supported_types = [tf.float32]\n    converter_float32._experimental_lower_tensor_list_ops = False\n    converter_float32.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n    converter_float32.representative_dataset = representative_dataset\n    tflite_model_float32 = converter_float32.convert()\n    print(tflite_model_float32)\n    with open(model_name+'_quant_float32' + '.h', 'w') as file:\n        file.write(hex_to_c_array(tflite_model_float32, model_name+'_quant_float32'))\n    with open(model_name+'_quant_float32.tflite', 'wb') as f:\n        f.write(tflite_model_float32)\n    size_model_tflite_float32 = os.path.getsize(model_name+'_quant_float32.tflite')\n    print(model_name+f'_quant_float32.tflite: {size_model_tflite_float32} Bytes')\n\n    # Convert the model to Int8\n    converter_int8 = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]\n    converter_int8.target_spec.supported_types = [tf.int8]\n    converter_int8.representative_dataset = representative_dataset\n    converter_int8.target_spec.supported_ops = [\n        tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n        tf.lite.OpsSet.SELECT_TF_OPS,\n    ]\n    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n    converter_int8.experimental_new_converter = True\n    converter_int8.experimental_new_quantizer = True\n    converter_int8.experimental_new_calibrator = True\n    tflite_model_int8 = converter_int8.convert()\n    with open(model_name+'_quant_int8' + '.h', 'w') as file:\n        file.write(hex_to_c_array(tflite_model_int8, model_name+'_quant_int8'))\n    with open(model_name+'_quant_int8.tflite', 'wb') as f:\n        f.write(tflite_model_int8)\n    size_model_tflite_int8 = os.path.getsize(model_name+'_quant_int8.tflite')\n    print(model_name+f'_quant_int8.tflite: {size_model_tflite_int8} Bytes')\n\n    return None\n```\n\n```js\nmodel_name='.\\models\\model'\nconverter_quantization_model(model, model_name)\n```\n\n3.10 — Quantized Model Evaluation\n\n```js\ndef evaluate_quantization(model_path, X_test, y_test, quantization_type):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Evaluate the quantized model\n    input_index = interpreter.get_input_details()[0]['index']\n    output_index = interpreter.get_output_details()[0]['index']\n    predictions = []\n    processing_times = []\n\n    X_test = np.array(X_test, dtype=np.float32)\n    \n    for X in X_test:\n        interpreter.set_tensor(input_index, [X])       \n        start_time = time.time()\n        interpreter.invoke()\n        end_time = time.time()\n        processing_time = end_time - start_time\n        processing_times.append(processing_time)\n        output = interpreter.get_tensor(output_index).argmax(axis=1)\n        predictions.append(output[0])\n\n    acc = accuracy_score(y_test, predictions)\n   \n    # Calculate the average and standard deviation of differences\n    result = { \"Accuracy (%): \":acc*100,\n                \"Process time (s): \": np.mean(processing_times)\n            }\n\n    return result\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nmodel_name = '.\\models\\model'\n```\n\n```js\neval_quant_float32 = evaluate_quantization(model_name + '_quant_float32.tflite', X_test, y_test, 'float32')\neval_quant_float32\n```\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_26.png)\n\n```js\neval_quant_int8 = evaluate_quantization(model_name + '_quant_int8.tflite', X_test, y_test, 'int8')\neval_quant_int8 \n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_27.png\" /\u003e\n\n## 3.11 — 모델 배포\n\n이 예제를 통해 ESP32, 아두이노, 아두이노 Portenta H7 with Vision Shield, 라즈베리파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에 머신러닝 알고리즘을 구현할 수 있습니다.\n\n3.11.1 — EloquentTinyML 라이브러리 설치\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도서관 폴더로 이동하여 EloquentTinyML-main을 설치해주세요.\n\n3.11.2 — 완전한 아두이노 스케치\n\nmodel_quant_float32.h 또는 model_quant_int8.h 파일을 열어서 다음에서 모든 16진수 값을 복사하세요:\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_28.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같이 변경해주세요:\n\n\nand model len\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_29.png)\n\nand cut in model.h:\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_30.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nand\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_31.png)\n\n3.11.2 — 완성된 아두이노 스케치\n\n```js\n#include \u003cEloquentTinyML.h\u003e\n#include \u003celoquent_tinyml/tensorflow.h\u003e\n\n// sine_model.h contains the array you exported from Python with xxd or tinymlgen\n#include \"model.h\"\n\n#define N_INPUTS 64\n#define N_OUTPUTS 10\n// in future projects you may need to tweak this value: it's a trial and error process\n#define TENSOR_ARENA_SIZE 6*1024\n\nEloquent::TinyML::TensorFlow::TensorFlow\u003cN_INPUTS, N_OUTPUTS, TENSOR_ARENA_SIZE\u003e tf;\n\nfloat input[64] = {0.00000000000f, 0.12500000000f, 0.00000000000f, 0.50000000000f, 0.56250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.81250000000f, 0.31250000000f, 0.87500000000f, 0.50000000000f, 0.43750000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.75000000000f, 0.31250000000f, 0.12500000000f, 0.00000000000f, 0.56250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.43750000000f, 0.31250000000f, 0.00000000000f, 0.00000000000f, 0.18750000000f, 0.31250000000f, 0.00000000000f, 0.00000000000f, 0.18750000000f, 0.62500000000f, 0.00000000000f, 0.00000000000f, 0.12500000000f, 0.62500000000f, 0.00000000000f, 0.00000000000f, 0.06250000000f, 0.81250000000f, 0.00000000000f, 0.00000000000f, 0.06250000000f, 0.75000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.31250000000f, 0.81250000000f, 0.31250000000f, 0.56250000000f, 0.81250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.56250000000f, 1.00000000000f, 1.00000000000f, 0.43750000000f, 0.00000000000f};\n\nfloat y_pred[10] = {0};\n\nvoid setup() {\n    Serial.begin(9600);\n    delay(4000);\n    tf.begin(model);\n\n    // check if model loaded fine\n    if (!tf.isOk()) {\n      Serial.print(\"ERROR: \");\n      Serial.println(tf.getErrorMessage());\n\n      while (true) delay(1000);\n    }\n}\n\nvoid loop() {\n\n        tf.predict(input, y_pred);\n        for (int i = 0; i \u003c 10; i++) {\n            Serial.print(y_pred[i]);\n            Serial.print(i == 9 ? '\\n' : ',');\n        }\n    Serial.print(\"Predicted class is: \");\n      Serial.println(tf.probaToClass(y_pred));\n      // or you can skip the predict() method and call directly predictClass()\n      Serial.print(\"Sanity check: \");\n      Serial.println(tf.predictClass(input));\n      delay(2000);\n\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.12 — 결과\n\n3.12.1 — 양자화된 모델 Float32\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_32.png)\n\n3.12.1 — 양자화된 모델 Int8\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_33.png)\n\nFull project in: [TinyML/13_CNN at main · thommaskevin/TinyML](https://github.com/thommaskevin/TinyML)\n\n## If you like it, consider buying my coffee ☕️💰 (Bitcoin)\n\ncode: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n`\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_34.png\" /\u003e`","ogImage":{"url":"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png"},"coverImage":"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png","tag":["Tech"],"readingTime":23},{"title":"시리얼 통신 마스터하기 아두이노 메가 2560 마스터와 우노 슬레이브 UART 튜토리얼","description":"","date":"2024-06-20 16:52","slug":"2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial","content":"\n\n\n![이미지](/assets/img/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial_0.png)\n\n# 소개\n\n아두이노 프로젝트의 영역에서 시리얼 통신은 기본적인 기술입니다. 이것은 새로운 언어로 대화하는 것을 배우는 것과 같습니다. 하지만 단어 대신에 전기 신호를 사용합니다. 이 튜토리얼에서는 두 가지 인기 있는 아두이노 보드인 메가 2560을 마스터로, 그리고 우노를 슬레이브로하여 UART (Universal Asynchronous Receiver-Transmitter) 통신을 설정하는 방법을 알아볼 것입니다. 이 안내서를 끝까지 따라오면 이 두 보드가 서로 '대화'할 수 있는 방법에 대해 명확히 이해하게 될 것입니다.\n\n# 필요한 것\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 1 x 아두이노 메가 2560\n- 1 x 아두이노 우노\n- 점퍼 와이어\n- 아두이노 IDE\n\n# 마스터 이해하기: 아두이노 메가 2560\n\n# 설정\n\n시리얼 포트 초기화: 우리의 메가 2560은 두 개의 시리얼 포트를 사용합니다. 디버깅용으로 Serial을 사용하고 Uno와 통신하기 위해 Serial1을 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSerial.begin(9600);\nSerial1.begin(9600);\n```\n\nLED로 표시기 사용: 내장 LED를 사용하여 받은 데이터를 시각적으로 표현합니다.\n\n```js\npinMode(LED_BUILTIN, OUTPUT);\ndigitalWrite(LED_BUILTIN, HIGH);\n```\n\n# 루프\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 수신: Mega는 시리얼 포트에서 데이터를 기다립니다.\n\n```js\nif (Serial.available() \u003e 0) {\n   char received = Serial.read();\n   ...\n}\n```\n\n데이터 전달: 데이터를 수신하면 Mega는 동일한 데이터를 Serial1을 통해 Uno로 전달합니다.\n\n```js\nSerial1.write(received);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터에 따른 조치: 받은 데이터가 '1'이면 LED가 꺼지고, '2'이면 켜집니다.\n\n```js\nif (received == '1') {\n   digitalWrite(LED_BUILTIN, LOW);\n} else if (received == '2') {\n   digitalWrite(LED_BUILTIN, HIGH);\n}\n```\n\n# 슬레이브 이해하기: 아두이노 우노\n\n# 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n소프트웨어 시리얼: Uno는 하드웨어 시리얼 포트가 하나뿐이기 때문에, 우리는 SoftwareSerial을 사용하여 가상 시리얼 포트를 생성합니다.\n\n```js\nSoftwareSerial Serial1(10, 9); // RX, TX\n```\n\n시리얼 포트 초기화: 하드웨어 및 소프트웨어 시리얼 포트가 모두 초기화됩니다.\n\n```js\nSerial.begin(9600);\nSerial1.begin(9600);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 루프\n\n데이터 수신: Uno는 Mega로부터 소프트웨어 시리얼 포트에서 데이터를 수신합니다.\n\n```js\nif (Serial1.available() \u003e 0) {\n   char received = Serial1.read();\n   ...\n}\n```\n\n데이터 응답: Mega와 유사하게, Uno는 수신한 데이터를 사용하여 LED를 제어합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nif (received == '1') {\n   digitalWrite(LED_BUILTIN, LOW);\n} else if (received == '2') {\n   digitalWrite(LED_BUILTIN, HIGH);\n}\n```\n\n# 함께 모두 넣어봅시다\n\n# 아두이노 메가 2560 (마스터)\n\n```js\n#include \u003cSoftwareSerial.h\u003e\n\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);\n    digitalWrite(LED_BUILTIN, HIGH);\n    Serial.begin(9600);\n    Serial1.begin(9600);\n}\n\nvoid loop() {\n    if (Serial.available() \u003e 0) {\n        char received = Serial.read();\n        Serial1.write(received);\n\n        if (received == '1') {\n            digitalWrite(LED_BUILTIN, LOW);\n        } else if (received == '2') {\n            digitalWrite(LED_BUILTIN, HIGH);\n        }\n    }\n}\n```\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 아두이노 Uno (슬레이브)\n\n```js\n#include \u003cSoftwareSerial.h\u003e\n\nSoftwareSerial Serial1(10, 9); // RX, TX\n\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);\n    digitalWrite(LED_BUILTIN, HIGH);\n    Serial.begin(9600);\n    Serial1.begin(9600);\n}\n\nvoid loop() {\n    if (Serial1.available() \u003e 0) {\n        char received = Serial1.read();\n\n        if (received == '1') {\n            digitalWrite(LED_BUILTIN, LOW);\n        } else if (received == '2') {\n            digitalWrite(LED_BUILTIN, HIGH);\n        }\n    }\n}\n```\n\n# 배선\n\n5V to 5V 연결:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 아두이노 메가의 5V 핀을 아두이노 우노의 5V 핀에 연결하십시오. 이 단계에서 우노를 메가로부터 전원을 공급합니다.\n\n그라운드 연결:\n\n- 아두이노 메가의 GND(그라운드) 핀을 아두이노 우노의 GND 핀에 연결하십시오. 이 공통 그라운드는 올바른 통신을 위해 중요합니다.\n\nTX에서 RX로 연결:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 아두이노 메가의 TX1 (송신) 핀을 아두이노 우노의 10번 핀에 연결하세요. 코드에서 우노의 SoftwareSerial에서 10번 핀을 RX (수신) 핀으로 설정해주세요.\n\n컴퓨터 연결 및 시리얼 모니터:\n\n- USB 케이블을 사용하여 아두이노 메가를 컴퓨터에 연결하세요.\n- 아두이노 IDE를 열고 메가에 대한 올바른 COM 포트를 선택하세요.\n- 아두이노 IDE에서 시리얼 모니터를 열어주세요. 이것은 메가에서 우노로 데이터를 보내는 데 사용될 것입니다.\n\n이제 실험을 위한 설정이 완료되었습니다. 아두이노 IDE의 시리얼 모니터에 '1' 또는 '2'를 입력하면 (메가를 선택한 상태에서), 메가는 TX1을 통해 10번 핀에 데이터를 보내고, 우노는 수신된 데이터에 따라 LED를 켜거나 끌 것입니다.","ogImage":{"url":"/assets/img/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial_0.png"},"coverImage":"/assets/img/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial_0.png","tag":["Tech"],"readingTime":4}],"page":"49","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"49"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>