<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/54" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/54" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="MySQL에서의 고급 데이터 분석 통계 함수" href="/post/2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="MySQL에서의 고급 데이터 분석 통계 함수" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="MySQL에서의 고급 데이터 분석 통계 함수" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">MySQL에서의 고급 데이터 분석 통계 함수</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="데이터 분석가가 되기 전 알았으면 하는 것들" href="/post/2024-06-20-ThingsIwishIknewbeforebecomingaDataAnalyst"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="데이터 분석가가 되기 전 알았으면 하는 것들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-ThingsIwishIknewbeforebecomingaDataAnalyst_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="데이터 분석가가 되기 전 알았으면 하는 것들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">데이터 분석가가 되기 전 알았으면 하는 것들</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커를 사용하여 PostgreSQL 및 pgAdmin 4 설치하기" href="/post/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커를 사용하여 PostgreSQL 및 pgAdmin 4 설치하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커를 사용하여 PostgreSQL 및 pgAdmin 4 설치하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">도커를 사용하여 PostgreSQL 및 pgAdmin 4 설치하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="판다 라이브러리가 할 수 있는 5가지를 소개합니다" href="/post/2024-06-20-5ThingsIWishthePandasLibraryCouldDo"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="판다 라이브러리가 할 수 있는 5가지를 소개합니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="판다 라이브러리가 할 수 있는 5가지를 소개합니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">판다 라이브러리가 할 수 있는 5가지를 소개합니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="SQL 집계 함수 마스터하기 예제와 함께 다루는 포괄적 가이드" href="/post/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="SQL 집계 함수 마스터하기 예제와 함께 다루는 포괄적 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="SQL 집계 함수 마스터하기 예제와 함께 다루는 포괄적 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">SQL 집계 함수 마스터하기 예제와 함께 다루는 포괄적 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="여러분이 배워야 할 6가지 DuckDB SQL 향상 기능" href="/post/2024-06-20-SixDuckDBSQLenhancementsyoushouldlearn"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="여러분이 배워야 할 6가지 DuckDB SQL 향상 기능" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-SixDuckDBSQLenhancementsyoushouldlearn_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="여러분이 배워야 할 6가지 DuckDB SQL 향상 기능" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">여러분이 배워야 할 6가지 DuckDB SQL 향상 기능</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="SQLAlchemy MissingGreenletError" href="/post/2024-06-20-SQLAlchemyMissingGreenletError"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="SQLAlchemy MissingGreenletError" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-SQLAlchemyMissingGreenletError_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="SQLAlchemy MissingGreenletError" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">SQLAlchemy MissingGreenletError</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이썬과 SQL을 통합하여 견고한 데이터 솔루션 구축하기" href="/post/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이썬과 SQL을 통합하여 견고한 데이터 솔루션 구축하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이썬과 SQL을 통합하여 견고한 데이터 솔루션 구축하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">파이썬과 SQL을 통합하여 견고한 데이터 솔루션 구축하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년을 위한 SQL에서 재귀 CTE 사용 방법 알아야 할 모든 것" href="/post/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년을 위한 SQL에서 재귀 CTE 사용 방법 알아야 할 모든 것" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년을 위한 SQL에서 재귀 CTE 사용 방법 알아야 할 모든 것" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">2024년을 위한 SQL에서 재귀 CTE 사용 방법 알아야 할 모든 것</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="마법같은 메이지 글로벌 후크의 마법을 풀어보세요" href="/post/2024-06-20-UnleashtheMagicofMageGlobalHooks"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="마법같은 메이지 글로벌 후크의 마법을 풀어보세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="마법같은 메이지 글로벌 후크의 마법을 풀어보세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">마법같은 메이지 글로벌 후크의 마법을 풀어보세요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/41">41</a><a class="link" href="/posts/42">42</a><a class="link" href="/posts/43">43</a><a class="link" href="/posts/44">44</a><a class="link" href="/posts/45">45</a><a class="link" href="/posts/46">46</a><a class="link" href="/posts/47">47</a><a class="link" href="/posts/48">48</a><a class="link" href="/posts/49">49</a><a class="link" href="/posts/50">50</a><a class="link" href="/posts/51">51</a><a class="link" href="/posts/52">52</a><a class="link" href="/posts/53">53</a><a class="link posts_-active__YVJEi" href="/posts/54">54</a><a class="link" href="/posts/55">55</a><a class="link" href="/posts/56">56</a><a class="link" href="/posts/57">57</a><a class="link" href="/posts/58">58</a><a class="link" href="/posts/59">59</a><a class="link" href="/posts/60">60</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"MySQL에서의 고급 데이터 분석 통계 함수","description":"","date":"2024-06-20 15:57","slug":"2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions","content":"\n\n\n![Advanced Data Analysis in MySQL - Statistical Functions 0](/assets/img/2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions_0.png)\n\n![Advanced Data Analysis in MySQL - Statistical Functions 1](/assets/img/2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions_1.png)\n\n각 데이터 세트의 분석 중요한 부분은 통계 속성을 분석하는 것입니다. 특히 기계 학습에 사용하려면 데이터에 대한 적절한 통찰력을 갖고 사전 처리 및 특성 추출을 수행해야 합니다.\n\n데이터베이스에 대규모 데이터 집합이 있는 경우 데이터베이스에서 이러한 분석을 직접 실행하는 것이 도움이 됩니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 일부 데이터베이스의 내장 통계 함수는 매우 포괄적이지 않을 수 있습니다. MySQL 데이터베이스도 그러한 경우 중 하나입니다.\n\n본 기사에서는 MySQL 인스턴스에 더 고급 통계 함수를 가져오고 대규모 데이터를 분석하는 방법을 안내해 드리겠습니다.\n\n# 준비 사항\n\n통계와 SQL 쿼리 언어에 대한 기본적인 이해가 있다고 가정합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## MySQL 인스턴스 + 샘플 데이터 세트\n\n또한 MySQL 데이터베이스의 실행 중인 인스턴스가 설치되어 특권 사용자가 있는 상태로, MySQL 웹 사이트에서 '표준' 직원 샘플 데이터베이스를 가져와 샘플 데이터 세트로 가져오셨다고 가정합니다.\n\n그렇지 않은 경우, 먼저 다음 기사를 참고하시기 바랍니다: \"MySQL에서 데이터 분석을 위한 첫 걸음: 기본 함수\".\n\n이 기사에서 작업할 기존 데이터베이스 스키마는 다음과 같아야 합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions_2.png)\n\nThe fields are mostly self-explanatory, but to be on the safe side, we list the descriptions of the non-obvious fields for the tables employees and salaries below:\n\n- employees.emp_no: The primary key of the employees table.\n- employees.hire_date: The hire date of the employee.\n- salaries.emp_no: The foreign key to the employees table.\n- salaries.salary: The salary paid in a given period.\n- salaries.from_date: The date from which the salary was paid.\n- salaries.to_date: The date by which the salary was paid.\n\n## Install the statistics extension\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMySQL은 통계 함수가 제한적이기 때문에 고급 기능을 위한 '확장 프로그램'이 필요합니다. 이 기사에서는 다음과 같은 통계 함수를 사용합니다: Statistics for MySQL.\n\n이 확장 프로그램에는 Gini 계수, 중앙값, Mersenne Twister 난수 생성기, Pearson 상관 계수, 행 번호 및 왜도 등 여러 통계 함수가 포함되어 있습니다.\n\nWindows 사용자는 다음을 직접 다운로드하고(32비트 또는 64비트 맞춤 libsqlstat.dll을 MySQL 설치 디렉토리의 lib\\plugin 디렉토리로 복사하고) 루트 사용자로 확장 프로그램을 설치할 수 있습니다:\n\n```js\nmysql -u root -p -f \u003c examples\\install.sql\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLinux 또는 MacOS 사용자는 INSTALL 파일의 지침을 따라 프로젝트를 컴파일해야 합니다.\n\n#의사 난수 생성\n\n통계 함수를 살펴보기 전에 무작위 숫자나 분포를 생성하는 방법에 대해 먼저 살펴보겠습니다.\n\n명확히 말하자면, 우리는 '통계적' 무작위성 또는 의사 난수성에 대해 이야기하고 있으며 이는 어떠한 인식 가능한 패턴이나 규칙성을 포함하지 않습니다. 많은 통계 사용 사례에 도움이 되며 충분합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이는 '진정한' 무작위성, 즉 객관적으로 예측할 수 없음을 의미하는 것은 아닙니다.\n\n## 간단한 난수\n\n다음 쿼리를 사용하여 Mersenne Twister 알고리즘(rand_mt)을 이용하여 0 이상의 임의의 숫자를 생성할 수 있습니다.\n\n```js\nSELECT rand_mt();\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 샘플 데이터셋의 각 급여 항목에 대해 무작위 '가중치'를 생성하여 쇼케이스로 보여 드리겠습니다. 즉, 급여 테이블에 새 열을 추가하고 이 열에 대해 무작위 숫자를 생성합니다.\n\n```js\nALTER TABLE salaries ADD weight double;\n\nUPDATE salaries SET weight = rand_mt();\n```\n\n## 정규 분포의 변변량\n\n데이터 분석에 정규 분포가 필요한 경우 다음 쿼리로 변변량을 생성할 수 있습니다 (rand_norm([σ, [μ]])):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT rand_norm(); // μ=0, σ=1\nSELECT rand_norm(0.3);// μ=0.3, σ=1\nSELECT rand_norm(0.3, 4);// μ=0.3, σ=0.4\n```\n\n평균 μ의 기본 값은 0이며, 표준 편차 σ의 기본 값은 1입니다.\n\n# 통계 함수\n\n이제 통계 함수로 넘어가 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 평균 또는 평균값\n\n평균 또는 산술평균(avg)은 시리즈의 모든 숫자의 합을 시리즈의 숫자 수로 나눈 값입니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:412/1*PIl3An_ZP3gWtqmAhO9S8g.gif)\n\n해당 SQL 쿼리는 다음과 같이 보이며 직원들의 평균 급여를 반환합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// 임금의 평균은 63,810.7448이에요.\n\n## 가중평균\n\n가중평균(avgw(x [,w]))은 시리즈에서 일부 데이터 포인트가 다른 것보다 더 많은 영향을 미치는 평균이에요.\n\n![이미지](https://miro.medium.com/v2/resize:fit:394/1*k4So1dgcswrkuOjlYUOfBQ.gif)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 SQL 쿼리는 다음과 같습니다. 직원들의 가중 평균 급여를 반환합니다 (임의의 가중치를 사용하여 보여주기 위한 것입니다):\n\n```js\nSELECT AVG(s.salary * s.weight) AS 'weighted mean' FROM salaries s;\n```\n\n## 분산과 표준편차\n\nMySQL은 데이터 샘플의 분산 (variance) 및 표준편차 (std)를 계산하기 위한 내장 함수를 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT \n  VARIANCE(salary) as '분산',\n  STD(salary) as '표준편차'\nFROM salaries;\n```\n\n분산은 데이터 세트 내 숫자 사이의 차이를 측정하는 통계적 측정 값이며, 평균 값으로부터 제곱 차이의 평균으로 정의되며 아래와 같이 계산됩니다:\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:500/1*2x2aLPiAXX_Hz7zNAxE7hA.gif\" /\u003e\n\n분산 함수는 var_pop()의 동의어로, 특정 열의 모든 필드의 모평균 분산을 계산합니다. 반면에 var_samp()는 표본 분산을 계산합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 태그를 Markdown 형식으로 변경하면 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nSELECT skewness_pop(s.salary) as 'skew1' FROM salaries s;\nSELECT skewness_pop(s.salary, s.weight) as 'skew2' FROM salaries s;\n\nSELECT skewness_samp(s.salary) as 'skew3' FROM salaries s;\nSELECT skewness_samp(s.salary, s.weight) as 'skew4' FROM salaries s;\n```\n\n만약 두 번째 매개변수가 지정되지 않은 경우 가중치는 1로 설정됩니다 (즉, 동일하게 가중치가 적용됨).\n\n마지막 예제로, 성별로 그룹화된 평균 급여를 계산하고 데이터 샘플의 모든 관련 통계 속성을 함께 표시합니다.\n\n```js\nSELECT \n  e.gender,\n  AVG(s.salary) as '평균 급여',\n  skewness_samp(s.salary) as '왜도',\n  stddevw_samp(s.salary) as '표준편차',\n  var_samp(s.salary) as '분산'\nFROM employees e INNER JOIN salaries s ON e.emp_no = s.emp_no\nGROUP BY e.gender\nORDER by asalary ASC;\n\n// gender, avg salary, skew, std, variance\nF, 63769.6032, 0.7757583639505996, 16844.89107702957, 283750105.9957\nM, 63838.1769, 0.7793202853331737, 16944.629259215217, 287120292.4635\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 중앙값\n\n중앙값은 데이터 세트의 정확히 중간에 있는 값으로, 데이터 샘플의 상위 절반과 하위 절반을 분리합니다.\n\n이는 값의 50%가 중앙값보다 작거나 같고, 50%가 더 크거나 같음을 의미합니다. 널(Null) 값은 무시됩니다.\n\n```js\nSELECT MEDIAN(s.salary) as 'median' FROM salaries s;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 SQL 쿼리는 모든 직원의 중앙급여를 제공합니다.\n\n## 지니 계수\n\n지니 계수는 통계적 분산 또는 불평등 분포의 측정치입니다. 0은 모든 값이 동일함을 나타내며; 1은 하나를 제외한 모든 값이 0임을 나타냅니다.\n\n```js\nSELECT GINI(s.salary) as 'gini coefficients' FROM salaries s; // 0.14754749176775583\n\nSELECT gini(g.asalary)\nFROM(\n  SELECT \n    e.gender,\n    AVG(s.salary) as 'asalary'\n  FROM employees e INNER JOIN salaries s ON e.emp_no = s.emp_no\n  GROUP BY e.gender\n  ORDER by asalary ASC\n) as g; // 0.00026868933832358\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 SQL 쿼리들은 개인 급여에서 작은 불일치(0.1475)를 보여줍니다. 그러나 평균 성별별 급여에서는 동등함(0.0003)을 나타냅니다.\n\n# 두 변수의 통계적 관계\n\n다음으로, 우리는 두 변수 x와 y 간의 통계적 관계를 살펴봅니다.\n\n## 상관관계\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n통계 확장 기능은 두 변수 간의 선형 상관 관계를 측정하는 피어슨 상관 계수(corr(x,y [,w]))를 제공합니다. 이 계수는 다음과 같이 계산됩니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:924/1*xi9Wpe-uaMa_vZtSOvR-fQ.gif)\n\n결과값은 -1과 1 사이의 숫자로, 관계의 강도와 방향을 나타냅니다:\n\n- -1부터 0 사이: 음의 상관 관계, 즉 하나의 변수가 변화할 때 다른 변수는 반대 방향으로 변화합니다.\n- 0: 상관 관계 없음, 즉 이러한 변수 간에는 관계가 없습니다.\n- 0부터 1 사이: 양의 상관 관계, 즉 하나의 변수가 변화할 때 다른 변수도 동일한 방향으로 변화합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 데이터 세트에서는 나이와 연봉 간의 상관 관계가 있는지 알아보려고 합니다.\n\n```js\nSELECT\n corr(m.start_year - m.birth_year,m.salary)\nFROM\n(\n    SELECT\n        YEAR(e.birth_date) as 'birth_year',\n        YEAR(s.from_date) as 'start_year',\n        s.salary as 'salary'\n    FROM employees e INNER JOIN salaries s ON e.emp_no = s.emp_no\n) as m; // 0.20731856518839656\n```\n\n우리가 볼 수 있듯이, 나이와 연봉 간에 매우 약간의 (무시해도 될 정도의) 양의 상관 관계(0.207)가 있습니다.\n\n# 순위\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n순위 매기기는 숫자 또는 서수 값이 데이터가 정렬될 때 해당 순위로 대체되는 데이터 변환입니다.\n\n이 함수 `rownumber()`를 사용하여 순위 목록을 만들 수 있습니다.\n\n## 행 번호\n\n그러나 첫 번째 예제에서는 함수가 전체 데이터 세트의 행 번호를 반환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\nSELECT \n  rownumber() AS rowNo,\n  e.first_name,\n  e.last_name,\n  e.gender,\n  s.salary\nFROM employees e INNER JOIN salaries s ON e.emp_no = s.emp_no\nWHERE s.to_date \u003e NOW()\nORDER by s.salary DESC\nLIMIT 10;\n```\n\n두 번째 예제에서는 데이터 세트를 필터링하고 정렬한 후에 rownumber 함수를 사용하여 순위 목록을 만들 수 있습니다.\n\n```sql\nSELECT\n  rownumber() AS rank,\n  r.*\nFROM\n(\n  SELECT\n      e.first_name,\n      e.last_name,\n      e.gender,\n      s.salary\n    FROM employees e INNER JOIN salaries s ON e.emp_no = s.emp_no\n    WHERE s.to_date \u003e NOW()\n    ORDER by s.salary DESC\n    LIMIT 10\n) as r;\n\n\n//rank,first_name,last_name,gender,salary\n//1,Tokuyasu,Pesch,M,158220\n//2,Honesty,Mukaidono,M,156286\n//3,Xiahua,Whitcomb,M,155709\n//4,Sanjai,Luders,M,155513\n//5,Tsutomu,Alameldin,M,155190\n//6,Willard,Baca,M,154459\n//7,Lidong,Meriste,M,154376\n//8,Charmane,Griswold,M,153715\n//9,Weijing,Chenoweth,F,152710\n//10,Weicheng,Hatcliff,F,152687\n```\n\n위의 SQL 쿼리는 현재 상위 10명의 최고 수입자를 제공합니다 (salaries 테이블의 to_date가 현재 유효한 급여인 경우 MAX입니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n이 글에서는 MySQL 데이터베이스에서 통계 확장을 사용하여 고급 데이터 분석을 수행하는 방법을 소개했습니다.\n\n이러한 함수들(물론 MySQL의 내장 함수 포함)을 사용하면 대규모 데이터셋의 심층적인 통찰을 효율적으로 얻을 수 있습니다. 그리고 추후 글에서 설명할 통계/머신 러닝 도구로 내보내기하기 전에 대규모 데이터셋에 대한 내용을 얻을 수 있습니다.\n\n저희의 기술 뉴스레터를 구독하세요(Spring Boot, 웹 에이전시, SaaS 앱, 코스), 그리고 다른 열정적인 코더들과 함께 커뮤니티에 참여하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n행복한 독서, 행복한 코딩!\n\n더 많은 소식을 받으려면 thebootcode.io에서 Coders를 팔로우하세요.","ogImage":{"url":"/assets/img/2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions_0.png"},"coverImage":"/assets/img/2024-06-20-AdvancedDataAnalysisinMySQLStatisticalFunctions_0.png","tag":["Tech"],"readingTime":9},{"title":"데이터 분석가가 되기 전 알았으면 하는 것들","description":"","date":"2024-06-20 15:55","slug":"2024-06-20-ThingsIwishIknewbeforebecomingaDataAnalyst","content":"\n\n데이터 분석가들을 위한 조언입니다. 제가 경험했던 것보다 더 잘 준비할 수 있도록 아래에 나열했어요.\n\n![이미지](/assets/img/2024-06-20-ThingsIwishIknewbeforebecomingaDataAnalyst_0.png)\n\n이제 데이터 분석을 한지 두 년이 넘었는데, 처음 시작했을 때보다 이직에서 놀라운 사건이 적게 일어나요.\n\n이 기사의 의도는 데이터 분석가로서 경력을 시작하는 전문가들을 두려워하게 하려는 것이 아니라, 실제 데이터와 실제 사람들과 일하는 것이 Kaggle이나 다른 온라인 데이터셋과 일하는 것과 약간 다를 수 있다는 것을 알려드리려는 것이에요. 저의 경험을 여기서 공유함으로써 데이터 분석가로서 꿈꾸는 분들과 초보자들이 여정을 더 잘 준비할 수 있기를 바라요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 데이터 분석가가 되기 전에 알았으면 하는 몇 가지 사항입니다:\n\n## 1. 견고한 기초를 다지고 속임수 증후군 극복하기.\n\n시작하기 전에 모든 도구와 기술에서 전문가가 되어야 할 필요는 없습니다. Excel, SQL, 데이터 시각화 도구, Python 및 통계와 같은 주요 영역의 기초지식을 가지고 있으면 충분합니다. 시간이 지남에 따라 필요에 따라 자연스럽게 새로운 도구와 방법론을 익히고 적응할 것입니다. 또한 충분히 알지 못하거나 동료들보다 숙련되지 않은 것 같은 느낌을 가질 수 있습니다. 모두가 어딘가에서 시작하며 전문가들도 일단은 초보였다는 것을 기억하는 것이 좋습니다. 계속해서 학습하고 개선에 집중하고 자신의 능력을 믿으며 속임수 증후군을 피해야 합니다.\n\n## 2. 데이터 정제는 복잡하고 시간이 많이 소요되는 작업일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 분석에서 가장 놀라운 측면 중 하나는 작업할 데이터의 상태입니다. 데이터가 서로 다른 소스에서 올 수 있으며, 데이터는 종종 지저분하고 불완전하며, 분석을 위해 준비되기 전에 심각한 정리가 필요합니다. 데이터 준비에 많은 시간을 보내야한다고 생각하세요. 데이터 분석가로서, 유용한 통찰을 얻는 대신 정보를 수집하고 준비하는 데 대부분의 시간을 보내게 됩니다. 그럼에도 불구하고, 데이터 정리 과정은 데이터 중심 조직에 꼭 필요합니다.\n\n## 3. 비즈니스 지각이 도움이 될 수 있습니다.\n\n기술적 기술은 중요하지만, 작업하는 비즈니스 컨텍스트를 이해하는 것이 똑같이 중요합니다. 이 지식은 조직에 관련성이 있고 실행 가능한 통찰을 제공하는 데 도움이됩니다.\n\n국제 기관에서 인사 데이터 분석가로 일하고 있다고 가정해 봅시다. 통찰을 얻기 위해 기술 스택을 활용하는 방법을 알아야 하는 것 외에, 인사의 KPI를 알고 있는 것이 도움이 됩니다. 예를 들어 직원 이탈률, 채용 시간, 직원 참여 점수 등이 있습니다. 이러한 지식은 상황을 이해하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4. 데이터 탐정이 되어보세요\n\n데이터 자체에 대해 많은 질문을 하고 데이터 생성 프로세스에 관여하는 사람들에게 질문해야 합니다. 이 조사적인 방식은 데이터를 더 잘 이해하고 의미 있는 결과를 도출하는 데 도움이 됩니다.\n\n## 5. 코딩보다는 분석적 사고 능력\n\n코딩은 데이터 분석가에게 중요한 기술이지만, 분석적 사고력이 훨씬 중요합니다. 코딩은 구글에서 검색하거나 온라인 플랫폼에서 배울 수 있지만, 데이터를 해석하고 패턴을 인식하며 실행 가능한 통찰력을 얻는 능력이 진정으로 성공적인 데이터 분석가를 구분짓는 것입니다. 따라서 분석 및 문제 해결 능력을 개발하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 6. 커뮤니케이션과 이해 관계자\n\n데이터 해석은 일부분을 차지하지만, 결과를 효과적으로 전달하고 이해 관계자의 요구사항을 이해하는 것은 더 어려울 수 있습니다. 강력한 커뮤니케이션 및 프레젠테이션 기술을 개발하는 것이 필요합니다. 많은 이해 관계자들은 기술적인 또는 데이터적인 배경이 없을 수 있으며, 이는 불확실성이나 변화하는 요구사항으로 이어질 수 있습니다. 그래서 요구사항에 대한 명확한 커뮤니케이션이 중요하며, 대시보드를 완성한 후에는 특정 관객을 위해 명확하게 제시해야 합니다.\n\n## 7. 회사 정치가 분석에 영향을 미칠 수 있습니다\n\n시간에 따라 회사 정치가 데이터 분석에 방해가 될 수 있습니다. 이해 관계자들은 편견을 가질 수 있으며, 그들의 의견을 지원하는 특정 데이터 포인트에 초점을 맞추도록 요구할 수 있습니다. 예를 들어, 판매 데이터를 분석할 때, 관리자는 전반적인 추세가 하락하는 경우라도 긍정적인 추세만 강조하여 경영진에게 더 유리한 상황을 제공하길 요구할 수 있습니다. 이러한 역학을 인식하는 것은 분석의 진정성을 유지하는 데 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 8. 모두가 아직 배우는 중입니다\n\n모든 사람이 모든 것을 알지는 못하며, 여전히 배우고 있습니다. 모르는 코드를 작성하거나 마주한 문제에 대한 해결책을 찾기 위해 구글과 같은 자원을 사용하거나 선임자에게 도움을 요청하는 것을 두려워하지 마세요. 그리고 건설적인 피드백을 받을 수 있도록 열려 있으세요. 계속된 학습은 데이터 분석가가 되는데 중요한 부분입니다.\n\n## 9. 다양한 책임과 기대\n\n조직마다 역할과 책임이 다릅니다. 예를 들어, 'ABC' 기관에서는 이해관계자를 관리하고 시각화를 만들어 결과를 발표해야 할 수도 있지만 'XYZ' 기관에서는 통찰을 찾고 Ad Hoc 대시보드를 생성해야 할 수도 있습니다. 또한 귀하가 근무하는 회사의 규모, 팀 내 기술 인력 수 등에 따라 다를 수 있습니다. 귀하의 특정 역할에 필요한 요구 사항을 이해하고 해당 기대치를 충족하기 위해 적응할 준비를 해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 팁들이 데이터 분석가로서의 도전을 더 효과적으로 극복하는 데 도움이 되길 바랍니다. 여러분의 여정을 더 부드럽게 만들어줄 거예요.\n\n그러나 다른 사람들의 경험에서도 배울 수 있어요.\n\n이 글이 유용했다면, 반성하고, 댓글을 남기고, 구독하고, 저를 팔로우해서 medium.com에서 더 많은 데이터 관련 콘텐츠를 만나보세요.\n\n즐거운 데이터 분석되세요!","ogImage":{"url":"/assets/img/2024-06-20-ThingsIwishIknewbeforebecomingaDataAnalyst_0.png"},"coverImage":"/assets/img/2024-06-20-ThingsIwishIknewbeforebecomingaDataAnalyst_0.png","tag":["Tech"],"readingTime":4},{"title":"도커를 사용하여 PostgreSQL 및 pgAdmin 4 설치하기","description":"","date":"2024-06-20 15:53","slug":"2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_0.png\" /\u003e\n\n이 글에서는 Docker 환경에서 PostgreSQL 및 pgAdmin 4를 설치하는 단계를 안내하겠습니다. 선택 사항인 마지막 단계로 pgAdmin 4를 사용하여 데이터베이스 및 테이블을 생성하고 터미널을 사용하여 액세스하는 방법을 테스트할 것입니다. 이 안내서는 데이터베이스 환경을 구축하고 실행하는 데 도움이 되도록 설계되었습니다.\n\n# Docker 설치\n\nDocker를 설치하는 방법은 사용 중인 운영 체제에 따라 다릅니다. 운영 체제에 따라 지침에 따라 설치하세요 (Docker에는 유료 버전도 있지만 무료 버전으로 우리 목적에는 충분합니다):\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# PostgreSQL 설정하기\n\nDocker에 PostgreSQL을 설치하려면 운영 체제에 따라 터미널, 명령 줄 또는 PowerShell을 열어야 합니다. 그런 다음 PostgreSQL 이미지를 설치할 것입니다. Docker 이미지는 코드, 런타임, 라이브러리, 환경 변수 및 시스템 도구를 포함하여 소프트웨어를 실행하는 데 필요한 모든 것이 포함된 가벼운 독립형 실행 가능 소프트웨어 패키지입니다.\n\n다음 명령을 사용하여 PostgreSQL 이미지를 가져오세요:\n\n```js\ndocker pull postgres\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 Docker 데스크톱 애플리케이션에서 이미지 탭에서 PostgreSQL 이미지를 볼 수 있어요.\n\n![PostgreSQL Image](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_1.png)\n\nDocker 이미지를 다운로드한 후에는 Docker 컨테이너를 시작하여 데이터베이스를 초기화하고 작동시켜야 해요.\n\nDocker 컨테이너는 애플리케이션의 필요한 종속성, 구성 및 코드를 캡슐화한 가벼우면서 격리된 런타임 환경으로, 다양한 시스템에서 일관되게 실행할 수 있게 해줘요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 명령어를 사용하여 도커 컨테이너를 생성하세요 (비밀번호는 꼭 바꾸세요):\n\n```js\ndocker run --name sqltutorial -e POSTGRES_PASSWORD=marviniscool -p 5432:5432 -d postgres\n```\n\n이제 Docker Desktop 앱에서 다음을 확인할 수 있어요:\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_2.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도커 run 명령어를 사용하여 컨테이너를 생성했어요. 우리는 이름을 선택하기 위해 -e를 사용해 환경 변수를 설정하고, 이 경우에는 데이터베이스 비밀번호를 \"marviniscool\"로 설정했어요 (비밀번호를 변경하는 걸 잊지 마세요). 마지막으로 -d를 사용해 컨테이너를 분리된 모드로 실행하고, 우리가 Postgres 이미지를 사용하고자 한다고 명시했어요. 이 명령어에서는 컴퓨터의 포트 5432를 컨테이너 내부의 포트 5432에 매핑하여 데이터베이스에 나중에 포트 관련 혼란 없이 액세스할 수 있어요. 또한 \"POSTGRES_USER=mycustomuser\"를 추가하여 \"postgres\"에서 원하는 이름으로 사용자 이름을 바꿀 수 있어요. 도커나 도커 run 명령어에 대해 더 알고 싶다면 문서를 확인해보세요:\n\n명령줄을 사용하여 도커 컨테이너가 실행 중인지 확인할 수도 있어요. 다음 명령을 실행하면 돼요:\n\n```js\ndocker ps\n```\n\n위와 같은 결과를 보면 컨테이너가 올바르게 작동 중인 걸 확인할 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_3.png\" /\u003e\n\n# PgAdmin4 설치하기\n\n이제 pgAdmin 4 설치로 넘어가보겠습니다. PgAdmin 4는 PostgreSQL을 위한 인기 있는 웹 기반 관리 및 운영 도구입니다. 이는 사용자 친화적인 인터페이스를 제공하여 데이터베이스와 상호 작용하고 SQL 쿼리를 실행하며 데이터베이스 성능을 모니터링하는 등 복잡한 명령 줄을 탐색하지 않고도 많은 기능을 제공합니다.\n\n설치 프로세스는 PostgreSQL을 설치하는 프로세스와 유사합니다. 우리는 Docker를 사용하여 pgAdmin 4 이미지를 가져와서 설정 프로세스를 단순화할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n터미널에 다음 명령어를 입력하여 pgAdmin 4를 설치할 수 있어요:\n\n```js\ndocker pull dpage/pgadmin4\n```\n\n당신의 Docker Desktop 앱의 '이미지' 탭에서 이미지를 확인할 수 있어요.\n\n이미지를 다운로드한 후에는 Docker 컨테이너를 생성하고 실행할 수 있어요. 아래 명령어는 새로운 'pgadmin-container' Docker 컨테이너를 설정하며, 당신의 컴퓨터의 포트 5050을 컨테이너의 포트 80에 매핑하고, pgAdmin 4 인터페이스에 액세스할 수 있는 기본 이메일과 비밀번호를 설정해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 pgAdmin 4 도커 컨테이너를 실행하는 명령어입니다:\n\n```bash\ndocker run --name pgadmin-container -p 5050:80 -e PGADMIN_DEFAULT_EMAIL=user@domain.com -e PGADMIN_DEFAULT_PASSWORD=catsarecool -d dpage/pgadmin4\n```\n\n이메일과 비밀번호를 본인의 이메일과 비밀번호로 바꿔 주시기 바랍니다.\n\n# pgAdmin 4를 사용하여 데이터베이스 컨테이너에 연결하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## pgAdmin 4에 로그인하기\n\n컨테이너가 성공적으로 실행되면 (문제가 발생하면 Docker Desktop 앱을 확인하여 컨테이너가 실행 중인지 확인하는 것이 좋습니다), 선택한 웹 브라우저에서 localhost:5050으로 이동하여 pgAdmin에 액세스할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_4.png)\n\n그런 다음 로그인 프롬프트가 표시되며, 이전에 지정한 이메일 주소와 비밀번호로 로그인할 수 있습니다. 이 경우 \"user@domain.com\" 및 \"catsarecool\"입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터베이스 컨테이너에 연결하기/ 서버 추가\n\n다음 단계에서는 데이터베이스 컨테이너에 연결할 것입니다. 이를 위해 '새 서버 추가'를 클릭해야 합니다:\n\n![이미지](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_5.png)\n\n그리고 데이터베이스에 연결할 관련 정보를 입력하세요. 이름 필드에는 pgAdmin에서 데이터베이스를 참조하기 위한 별칭을 선택할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_6.png\" /\u003e\n\n계속하기 전에 \"sqltutorial\" 컨테이너의 IP 주소를 얻는 것이 중요합니다. IP 주소를 찾으려면 터미널(Linux/macOS) 또는 PowerShell(Windows)에서 다음 명령을 실행할 수 있습니다:\n\n```js\ndocker inspect -f '{range .NetworkSettings.Networks}{.IPAddress}{end}' sqltutorial\n```\n\n저희 경우에는 IP 주소 172.17.0.2를 반환했습니다 (이것이 여러분에게도 해당될 수도 있고 아닐 수도 있습니다). 이제 모든 연결 정보를 입력합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 호스트 이름/주소: 172.17.0.2 (당신에게는 다를 수 있음)\n- 포트: 5432\n- 유지 보수 데이터베이스: postgres\n- 사용자 이름: postgres (변경했다면 다른 이름)\n- 비밀번호: marviniscool (또는 선택한 다른 비밀번호)\n- 선택 사항: 저장된 비밀번호를 true로 설정\n\n![이미지](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_7.png)\n\n\"저장\"을 클릭하면 왼쪽 메뉴에서 데이터베이스 서버를 선택할 수 있습니다:\n\n![이미지](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n축하합니다! 이제 환경이 구동 중이어야 합니다. pgAdmin 4에 관한 질문이 있으면 문서를 참조하세요:\n\n# 선택 사항: 연결 테스트\n\n마지막으로 선택 사항으로, pgAdmin 4를 사용하여 데이터베이스와 테이블을 생성한 다음 터미널에서 해당 테이블을 읽어보겠습니다. 데이터베이스 작업에 익숙하지 않다면 몇 가지 개념이 혼란스러울 수 있지만, 후속 튜토리얼에서 모든 것을 자세히 다룰 것입니다.\n\n## pgAdmin 4에서 데이터베이스 및 테이블 생성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n‘Databases’를 마우스 오른쪽 버튼으로 클릭하고 ‘만들기' - ` '데이터베이스'를 선택하십시오. 데이터베이스에 이름을 지정하고 ‘my_new_database’와 같이 이름을 지어주신 후에 ‘저장’을 클릭하십시오.\n\n![이미지](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_9.png)\n\n그런 다음, 방금 만든 데이터베이스로 이동하여 “테이블”을 마우스 오른쪽 버튼으로 클릭하고 ‘만들기' - ` '테이블'을 선택하십시오. 테이블에 이름을 지정하고, 예를 들어 “catbase”와 같이 지어주십시오.\n\n![이미지](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_10.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터베이스를 생성한 후 테이블을 만들겠습니다. 이를 위해 catbase -` 스키마 -` public -` 테이블 -` 생성 -` 테이블을 선택합니다...\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_11.png\" /\u003e\n\n이제 테이블 이름을 \"cattable\"로 설정합니다:\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_12.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 다음 단계에서 두 개의 열을 생성할 것입니다. 첫 번째 열은 id 열로서, 이는 우리의 주 키입니다 (이것이 무엇인지 모르더라도 걱정하지 마세요. 나중에 자습서에서 설명하겠습니다). 두 번째 열은 고양이의 이름을 나타내는 텍스트 열입니다. 우리는 \"Not Null?\"과 같은 제약 조건을 지정할 수도 있습니다. 이는 이 열의 모든 셀이 값을 가질 수 있음을 보장합니다.\n\n첫 번째 열의 이름을 id로, 데이터 유형을 시리얼로 설정하고 \"Not Null?\" 및 \"Primary Key?\" 제약 조건을 선택합니다. 그런 다음 플러스 기호를 클릭하여 두 번째 열의 이름을 \"catname\"으로 지정하고 데이터 유형을 텍스트로 설정하고 \"Not Null?\" 제약 조건을 선택합니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_13.png\" /\u003e\n\n저장을 클릭합니다. 이제 테이블을 생성했으므로 데이터의 하나의 행을 추가하려고 합니다. SQL을 사용하여도 되지만, 일관성을 유지하기 위해 이 경우에도 pgAdmin을 사용할 것입니다. 우리는 오른쪽 클릭해야합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n테이블 - `데이터 보기/편집 -` 모든 행\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_14.png\" /\u003e\n\n그다음, 데이터 출력 창에서 행 추가를 클릭해야합니다:\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_15.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 텍스트 필드를 클릭하고 \"Bam Bam\"과 같은 멋진 고양이 이름으로 이름을 설정할 것입니다. 다음 단계에서는 행을 데이터베이스에 저장할 것입니다. (키 필드에 값을 입력할 필요가 없다는 점을 유의해주세요. 데이터 유형을 시리얼라이저로 설정했으므로 id가 자동으로 선택됩니다)\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_16.png\" /\u003e\n\n## 터미널에서 테이블 쿼리\n\npgAdmin 4에서 데이터베이스와 테이블을 설정한 후, 터미널로 전환하여 테이블에서 데이터를 읽어봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 도커 컨테이너 내의 데이터베이스 서버에 연결해야 해요:\n\n```js\ndocker exec -it sqltutorial psql -U postgres\n```\n\n다음으로, 이전에 pgAdmin 4에서 생성한 \"catbase\" 데이터베이스에 연결해야 해요.\n\n```js\n\\c catbase\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 테이블에서 모든 행을 선택하기 위해 select 문을 사용할 수 있습니다:\n\n```js\nSELECT * FROM CATTABLE;\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_17.png\" /\u003e\n\n여기에 있습니다! pgAdmin 4와 터미널이 Docker 컨테이너 내의 PostgreSQL 데이터베이스와 성공적으로 상호 작용하고 있다는 것을 확인할 수 있습니다. 'catbase' 내 'cattable'의 내용이 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_18](/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_18.png)\n","ogImage":{"url":"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_0.png"},"coverImage":"/assets/img/2024-06-20-SettingupPostgreSQLandpgAdmin4withDocker_0.png","tag":["Tech"],"readingTime":8},{"title":"판다 라이브러리가 할 수 있는 5가지를 소개합니다","description":"","date":"2024-06-20 15:50","slug":"2024-06-20-5ThingsIWishthePandasLibraryCouldDo","content":"\n\n아래는 해당 기사에 대한 코드를 찾을 수 있습니다.\n\nPandas 라이브러리 덕분에 파이썬에서의 표 데이터 처리, 분석 및 처리가 오늘날 이렇게 쉽고 간단히 수행되는 일은 없습니다.\n\n현재, Pandas API는 표 데이터 관리에 필요한 다양한 기능을 제공하여 거의 모든 데이터 과학 프로젝트를 지원하고 있습니다. 예를 들어:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 입력 및 출력 작업\n- 데이터 필터링\n- 테이블 조인\n- 데이터 시각화\n- 중복 데이터 처리 등과 같은 여러 기능이 있습니다. 자세한 내용은 여기를 참조해 주세요.\n\n판다스는 실제로 표 형식의 데이터를 다루는 대부분의 데이터 과학자들에게 선택되는 도구이지만, 제 프로젝트에서 이를 활용하면서 판다스의 주요 단점/제약 조건 몇 가지를 깨달았습니다. 이 글에서는 이에 대해 논의하고자 합니다.\n\n따라서, 이 글에서는 현실 세계에서의 표 데이터셋에서 판다스가 해낼 수 있다고 희망하는 다섯 가지 기능을 제시합니다.\n\n이 기사의 하이라이트는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n#1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면 좋겠어요\n#2 Pandas가 한 번에 여러 CSV 파일을 읽을 수 있다면 좋겠어요\n#3 Pandas 데이터프레임이 더 적은 메모리를 사용하면 좋겠어요\n#4 Pandas가 대규모 데이터셋에 사용될 수 있다면 좋겠어요\n#5 Pandas가 SQL처럼 조건부 조인을 지원한다면 좋겠어요\n\n시작해봐요 🚀!\n\n## #1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면\n\n안타깝게도, Pandas의 CSV 파일에서/로의 입출력 작업은 직렬화되어 있어 Pandas에는 내재 된 멀티 쓰레딩 지원이 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우선, CSV 파일을 읽는 문맥에서의 직렬화는 판다스가 CSV 데이터를 한 번에 한 행(또는 한 줄)만 읽는 것을 의미합니다. 아래 애니메이션에서 이것이 설명되어 있습니다:\n\n![serialization](https://miro.medium.com/v2/resize:fit:780/1*2cE0tW6MpSL9o21DzWvsIw.gif)\n\n입력 작업과 비슷하게, 출력 작업 또한 좋지 않습니다. 판다스는 데이터프레임을 CSV 파일에 직렬화된 방식으로 저장합니다.\n\n직렬화된 입력 및 출력 작업의 과정은 굉장히 비효율적이고 시간이 많이 소요되는 작업입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가능한 대안\n\n제 탐색 결과, 전체 입력-출력 실행 시간을 개선하기 위한 두 가지 잠재적인 해결책이 있습니다.\n\n- Pickle, Parquet 및 Feather와 같은 다른 파일 형식을 사용하여 데이터프레임을 읽고 저장하는 것이 좋습니다.\n\n빠르면서도 디스크에 데이터를 저장하기 위해 적은 메모리를 사용하는 이러한 형식에 대해 더 자세히 알아보려면 아래 블로그에서 확인해주세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Pandas와는 달리 병렬화 기능을 갖춘 DataTable과 같은 라이브러리를 사용하세요.\n\n아래 블로그에서 DataTable에 대해 더 읽어보세요:\n\n## #2 Pandas가 동시에 여러 CSV 파일을 읽을 수 있다면 좋겠다\n\n여러 개의 CSV 파일이 포함된 폴더가 있고, 이를 Pandas DataFrame으로 읽고 가져와야 한다고 상상해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n판다스에서 이 작업을 수행하는 유일한 방법은 파일 목록을 반복하고 하나씩 읽는 것입니다. 아래에서 보여진 것처럼:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*9cPCbiuow73SBR4kWHlpAg.gif)\n\n위의 그림은 다음과 같이 프로그래밍적으로 시연될 수 있습니다:\n\n판다스에서 멀티스레딩을 지원하지 않기 때문에 병렬로 읽을 수 있는 파일 세트는 한 번에 하나씩 읽어야 하며, 이로 인해 실행 시간이 늘어나고 자원이 비효율적으로 사용될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가능한 대안\n\nDataTable 라이브러리는 다시 한 번 이 제한 사항을 해결하기 위한 Pandas의 좋은 대안으로 자리를 잡고 있습니다.\n\nDataTable을 사용하면 여러 CSV 파일을 효율적으로 읽을 수 있습니다. 아래에서 이를 확인해보세요:\n\n아래 블로그에서 런타임 성능에 대해 더 많이 알아보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# #3 판다 데이터프레임이 더 적은 메모리를 사용하도록 했으면 좋겠어요\n\n판다 데이터프레임은 작업에 있어서 굉장히 비효율적이고 메모리를 많이 소비합니다. 예를 들어, 아래에 보여지는 두 개의 열로 이루어진 데이터프레임을 생성한다고 가정해 봅시다:\n\n이제, 위의 데이터프레임 df의 두 열에 판다가 할당한 데이터 유형을 알아보기 위해 dtypes 속성을 사용해 봅시다:\n\n기본적으로, 판다는 항상 열에 가장 큰 메모리 데이터 유형을 할당합니다. 예를 들어, 판다가 위에서 colA를 정수 값으로 해석했을 때, 선택할 수 있는 4가지 하위 카테고리가 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- int8: 8비트 정수 데이터 유형으로 [-2⁷, 2⁷] 범위의 정수를 포함합니다.\n- int16: 16비트 정수 데이터 유형으로 [-2¹⁵, 2¹⁵] 범위의 정수를 포함합니다.\n- int32: 32비트 정수 데이터 유형으로 [-2³¹, 2³¹] 범위의 정수를 포함합니다.\n- int64: 64비트 정수 데이터 유형으로 [-2⁶³, 2⁶³] 범위의 정수를 포함합니다.\n\n그러나 판다스는 해당 열의 현재 값 범위와 관계없이 정수 값 열의 데이터 유형을 int64로 할당했습니다. 우리는 colB와 유사한 데이터 유형 행동을 발견했습니다.\n\n## 가능한 대안\n\n메모리 활용을 최적화하기 위해, \"민맥스 감소 분석(min-max-reduce analysis)\"이라고 부르는 방향이 있을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우선, 관심 있는 열에서 최소값과 최대값을 찾는 것부터 시작해요.\n\n마지막 단계는 열의 데이터 유형을 축약(줄이기)하는 것이에요.\n\n현재 값의 범위를 int16 데이터 유형으로 압축할 수 있기 때문에 (왜냐하면 -2¹⁵` 10000 (min)` 30000 (max) `2¹⁵), 아래에 보여지는 것처럼 astype() 메서드를 사용하여 데이터 유형을 int64에서 int16으로 변환할 거예요:\n\n이 간단한 한 줄짜리 데이터 유형 변환으로 colA 열이 사용하는 총 메모리가 약 40% 정도 감소했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비슷한 최소-최대-축소 분석을 통해 다른 정수 및 부동 소수점 값 열의 데이터 유형을 변경할 수도 있습니다.\n\n아래 블로그에서 메모리 최적화 기술에 대해 더 읽어보세요:\n\n# #4 파이썬 Pandas를 대규모 데이터셋에 사용할 수 있다면 좋겠어요\n\n위에서 논의한 대로, Pandas에는 내재적인 멀티 스레딩 지원이 없습니다. 결과적으로 데이터 규모와 관계없이 Pandas는 항상 단일 코어를 활용하므로 데이터 크기에 비례한 실행 시간 증가가 발생합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_1.png)\n\nFor instance, consider an experiment to study the correlation between DataFrame size and the run-time to execute a function on the DataFrame.\n\nWe start with a random DataFrame comprising a thousand rows and two columns.\n\nNext, we define a function that takes a row of the DataFrame and returns its sum. This function is implemented below:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 반복마다 DataFrame의 각 행의 합을 계산하는 데 걸리는 시간을 결정합니다. 무작위성을 제거하기 위해 각 반복을 run 번 반복할 것입니다. 각 반복의 끝에서 DataFrame의 크기를 두 배로 증가시킬 것입니다.\n\n다음에 실험이 구현되어 있습니다:\n\n아래 플롯은 반복 대 실행 시간 그래프를 나타냅니다. 각 반복마다 DataFrame의 크기가 두 배씩 증가하고 Pandas의 실행 시간도 그렇게 늘어납니다. 이는 Pandas의 실행 시간이 항상 DataFrame의 크기에 비례하며 병렬 처리를 채택하지 않는다는 것을 나타냅니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_2.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가능한 대안\n\nPandas는 작은 데이터셋에서 작업하기에 매우 좋습니다. 그러나 데이터 규모와 파이프라인의 복잡성이 증가함에 따라 데이터 과학자로서는 상기한 실행 시간 문제 때문에 활용을 자제해야 합니다.\n\n프로젝트를 제품화하는 것이 목표라면 PySpark가 이상적입니다. 다른 대안으로는 Terality, Vaex, DataTable 및 Dask가 있습니다 — 주로 대용량 데이터셋에 대한 Pandas보다 지역 계산을 권장합니다.\n\n# #5 Pandas가 SQL과 유사한 조인 조건을 지원했으면 좋겠네요 (어떤 방식으로든)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSQL 작업을 하는 사람들은 테이블을 병합하기 위해 복잡한 조인 조건을 쓰는 것을 즐기지 않나요?\n\n이름에서 알 수 있듯이 조건부 조인은 단순한 등가성 기반의 병합 조건을 넘어섭니다. 다시 말해, 여러 테이블에서 필드 간의 등가성 이외의 조건을 기반으로 조인을 설정할 수 있습니다.\n\n예를 들어, table1과 table2라는 두 테이블이 있다고 가정해 봅시다:\n\n다음 조건에 따라 이 두 테이블을 결합하는 것이 목적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\n(table1.col1 = table2.col1 + 2) 그리고 (table2.col2 \u003e= table2.col2 - 2) 그리고 (table2.col2 \u003c= table2.col2 + 2)\n```\n\n## SQL 조인\n\n위의 조건부 조인은 SQL에서 매우 간단하게 작업할 수 있습니다. 아래에 구현된 SQL 쿼리가 출력을 생성합니다:\n\n## 판다스 조인\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n판다는 데이터프레임에서 동일성을 기반으로 한 조인만 수행할 수 있습니다. 다시 말하면, 판다의 merge() 메소드는 조인 열의 값이 동일할 때에만 두 레코드를 조인하는 것이 가능하며, 조건부 조인의 가능성이 없어집니다.\n\n따라서, 판다의 merge() 메소드를 사용하여 조건부 조인을 수행하는 몇 가지 방법은 다음과 같습니다:\n\n- 조인 조건에서 정의된 연산을 사용하여 조인 열을 생성하고, 새 열에 대해 merge를 실행합니다.\n- 교차 조인을 수행하고 데이터프레임을 필터링합니다. 이는 대규모 데이터셋의 경우에 매우 어려울 수 있습니다.\n\n아래에서 접근 방법 1과 접근 방법 2를 조합한 예시가 제시되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 병합할 두 데이터프레임을 만들고 join 조건을 정의합니다.\n\n```js\n(table1.col1 = table2.col3 + 2) and (table2.col2 \u003e= table2.col4 - 2) and (table2.col2 \u003c= table2.col4 + 2)\n```\n\njoin 조건이 부등식으로 이루어져 있기 때문에 일단 부등식들을 잠시 두고, 처음에는 동등식 (table1.col1 = table2.col3 + 2) 에 따라 먼저 join을 수행합니다. 그런 다음 결과를 필터링하여 다음 두 조건을 반영할 것입니다.\n\n먼저, table2에 새로운 열을 생성할 것입니다. 이를 col3_1이라고 해보죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 table1의 col1과 table2의 col3_1을 기준으로 조인을 수행하고, 조인 조건으로부터 남은 조건을 기반으로 얻은 레코드를 필터링할 것입니다. 아래에서 구현되어 있습니다:\n\n## 가능한 대안\n\nPandaSQL은 Pandas와 SQL을 혼합한 인기 있는 Python 패키지로, SQL 문법의 강력함을 파이썬 환경에서 활용할 수 있습니다.\n\n따라서, PandaSQL을 사용하면 SQL 문법을 사용하여 pandas 데이터프레임을 쿼리할 수 있습니다. SQL과 유사한 조인을 실행하려면 PandaSQL을 탐색해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSQL을 Pandas DataFrames와 함께 사용하는 쉬움은 실행 시간이라는 대가를 지는데요. 이에 대해 이전 블로그 글에서 다뤄보았습니다:\n\n# 결론\n\n이번 포스트에서 다뤄본 바와 같이, Pandas의 주요 제한 사항 다섯 가지와 이러한 상황에서 갇힌 경우 대처 방법을 논의했습니다.\n\nPandas는 일상적인 탭형 데이터 분석, 관리 및 처리 작업에 놀라울 정도로 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만, 제작 수준의 솔루션을 개발하거나 처리할 데이터가 많을 경우, Pandas는 병렬화와 자원 활용에 제한이 있어 도움이 되지 않을 수 있습니다.\n\n읽어 주셔서 감사합니다!\n\n🚀 무료 데이터 과학 PDF(550페이지 이상)를 받아보세요. 매일 뉴스레터를 구독하시면 320개 이상의 게시물을 만나볼 수 있습니다:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/0*6rHTrx_iItXjC1hm.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_3.png)\n\nVisit us at DataDrivenInvestor.com\n\nSubscribe to DDIntel [here](link_here).\n\nHave a unique story to share? Submit to DDIntel [here](link_here).\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 창조자 생태계에 참여해 주세요.\n\nDDIntel은 주요 사이트와 인기 있는 DDI Medium 출판물에서 가장 주목할 만한 내용을 담고 있습니다. 커뮤니티에서 더 많은 통찰력 있는 작업을 확인해보세요.\n\nDDI 공식 텔레그램 채널: [https://t.me/+tafUp6ecEys4YjQ1](https://t.me/+tafUp6ecEys4YjQ1)\n\nLinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해 주세요.","ogImage":{"url":"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_0.png"},"coverImage":"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_0.png","tag":["Tech"],"readingTime":8},{"title":"SQL 집계 함수 마스터하기 예제와 함께 다루는 포괄적 가이드","description":"","date":"2024-06-20 15:48","slug":"2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples","content":"\n\n집계 함수는 데이터를 요약하고 분석할 때 SQL에서 중요한 역할을 합니다. 이들은 우리에게 통계 메트릭을 계산하고 데이터 그룹에 대한 계산을 수행하며 의미 있는 통찰을 얻을 수 있도록 해줍니다.\n\n![image](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_0.png)\n\n이 글에서는 COUNT, SUM, AVG, MIN, MAX, ROUND, GROUP BY, WITH ROLLUP, LIMIT, HAVING 등과 같은 가장 일반적으로 사용되는 10가지 MYSQL 집계 함수를 실제 예제와 함께 탐색해 보겠습니다.\n\n# 1. COUNT\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 테이블의 열에서 비 널 값의 수를 반환하거나 테이블의 행 수를 반환합니다.\n\n예시:\nSELECT COUNT(*) AS total_rows\nFROM table_name;\n\nSELECT COUNT(column_name)\nFROM table_name;\n\n```js\n-- 저자 테이블에는 몇 개의 행이 있나요?\n\nSELECT COUNT(*) AS total_rows\nFROM authors;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_1.png\" /\u003e\n\n```js\n-- 데이터셋에 있는 작가는 몇 명인가요?\n\nSELECT COUNT(DISTINCT au_id) AS number_of_authors\nFROM authors;\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_2.png\" /\u003e\n\n```js\n-- 산호세 또는 솔트레이크시티에 거주하는 작가는 몇 명인가요?\n\nSELECT COUNT(au_id)\nFROM authors\nWHERE city IN (\"San Jose\", \"Salt Lake City\");\n```   \n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_3.png)\n\n```js\n-- 캘리포니아 주(CA)에 기반을 둔 상점의 수는?\n\nSELECT COUNT(DISTINCT stor_id) AS \"CA에 있는 상점 수\"\nFROM stores\nWHERE state = \"CA\";\n```\n\n![image](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_4.png)\n\n# 2. SUM\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 열의 값들의 합을 계산합니다.\n\n예시:\nSELECT SUM(column_name)\nFROM table_name;\n\n```js\n-- 수량에 따른 총 매출을 계산합니다.\n\nSELECT SUM(qty) AS sales_quantity\nFROM sales;\n```\n\n![이미지](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n-- 각 상점의 판매량을 수량별로 찾아서 내림차순으로 정렬합니다.\n\nSELECT stor_id, SUM(qty) AS sales_quantity\nFROM sales\nGROUP BY stor_id\nORDER BY SUM(qty) DESC;\n```\n\n![마스터링 SQL 집계 함수: 예제를 활용한 포괄적인 가이드](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_6.png)\n\n# 3. AVG\n\n숫자 열의 평균 값을 계산합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시:\n\n```sql\n-- 테이블 sales에서 수량의 개수, 평균 및 합계를 표시합니다.\n\nSELECT COUNT(qty), AVG(qty), SUM(qty)\nFROM sales;\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_7.png\" /\u003e\n\n```sql\n-- 각 출판사가 가지고 있는 책의 수 및 책의 평균 가격을 찾습니다.\n\nSELECT pub_id, COUNT(title_id), AVG(price)\nFROM titles\nGROUP BY pub_id\nORDER BY COUNT(title_id) DESC;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_8.png)\n\n# 4. MIN\n\n특정 열에서 최솟값을 검색합니다.\n\n예시:\nSELECT MIN(열_이름)\nFROM 테이블_이름;\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\n-- 각 출판사의 책의 최소 가격을 찾아보세요.\n\nSELECT pub_id,  MIN(price) AS minimum_price\nFROM titles\nGROUP BY pub_id;\n```\n\n![이미지](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_9.png)\n\n# 5. MAX\n\n컬럼에서 최대값을 검색합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시:\n\n특정 발행사의 책들 중에서 가장 높은 가격을 알아봅시다.\n\n```js\nSELECT pub_id, MAX(price) AS maximum_price\nFROM titles\nGROUP BY pub_id;\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_10.png\" /\u003e\n\n# 6. ROUND\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지정된 소수점 자리 수로 숫자 값을 반올림하는 데 사용됩니다.\n\n예시:\nSELECT ROUND(column_name, 소수점 자리 수)\nFROM table_name;\n\n```js\n-- 각 출판사의 책 평균 가격을 2자리 소숫점으로 표시합니다.\n\nSELECT pub_id,  ROUND(AVG(price),2) AS average_book_price\nFROM titles\nGROUP BY pub_id;\n```\n\n![이미지](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 7. GROUP BY\n\n여러 열을 기반으로 행을 그룹화하고 각 그룹에 대해 집계를 수행합니다.\n\n예시:\n```sql\nSELECT column1, 집계_함수(column2)\nFROM table_name\nGROUP BY column1;\n```\n\n예시 코드:\n```sql\n-- 각 출판사의 누적 연간 매출을 찾아 내림차순으로 정렬합니다.\n\nSELECT pub_id,  SUM(ytd_sales)\nFROM titles\nGROUP BY pub_id\nORDER BY SUM(ytd_sales) DESC;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_12.png)\n\n```js\n-- 각 발행사 및 각 제목의 총 YTD 판매량을 찾고 내림차순으로 정렬합니다.\n\nSELECT pub_id,  title,  SUM(ytd_sales)\nFROM titles\nGROUP BY pub_id, title;\n```\n\n![image](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_13.png)\n\n# 8. WITH ROLLUP\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n쿼리 결과에 여러 레벨에서 소계 및 총계를 생성합니다.\n\n*** 결과의 \"NULL\" 값은 소계 및 총계 행을 나타냅니다.\n\n예:\nSELECT column1, column2, Aggregate_function(column3)\nFROM table_name\nGROUP BY column1, column2\nWITH ROLLUP;\n\n```js\n// 각 publisher와 title의 평균 가격을 내림차순으로 정렬하여 보려면 다음과 같은 쿼리를 사용하세요.\n// 또한 WITH ROLLUP을 사용하여 소계 및 총계를 표시합니다.\n\nSELECT pub_id, title, SUM(ytd_sales)\nFROM titles\nGROUP BY pub_id, title\nWITH ROLLUP;\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_14.png\" /\u003e\n\n# 9. LIMIT\n\n쿼리에서 반환되는 행의 수를 제한합니다.\n\n예시:\n```sql\nSELECT column1, column2\nFROM table_name\nLIMIT n;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\n-- 가장 많은 매출을 올린 상위 3개 매장을 찾아봅니다.\n\nSELECT stor_id, SUM(qty)\nFROM sales\nGROUP BY stor_id\nORDER BY SUM(qty) DESC\nLIMIT 3;\n```\n\n![링크](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_15.png)\n\n# 10. HAVING\n\n그룹화된 결과에 특정 조건을 기반으로 행을 필터링합니다.\nHAVING 절은 SUM, COUNT, AVG와 같은 집계 함수와 함께 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**표** 태그를 마크다운 형식으로 변경해주세요.\n\n예시:\nWHERE 절과 유사하지만, WHERE 절에서는 집계 함수를 사용할 수 없습니다!\n\n예시:\n```js\n-- 판매 수량이 50개 이상인 가게 선택하기.\n\nSELECT stor_id, SUM(qty)\nFROM sales\nGROUP BY stor_id\nHAVING SUM(qty) \u003e 50;\n```\n\n![이미지](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_16.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\n-- 50개 이상의 판매 수량이 있는 가게를 선택한 다음 내림차순으로 정렬합니다.\n\n\nSELECT stor_id, SUM(qty)\nFROM sales\nGROUP BY stor_id\nHAVING SUM(qty) \u003e 50\nORDER BY SUM(qty) DESC;\n```\n\n![이미지](/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_17.png)\n\n# 결론\n\nSQL 집계 함수는 데이터 분석과 보고에 꼭 필요합니다. 데이터를 요약하고 측정하며, 의사 결정에 유용한 통찰력을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 함수를 마스터하면 SQL에서 강력한 데이터 분석을 수행할 수 있게 됩니다. 계속 연습하고 탐험하여 SQL 기술을 향상시키세요.\n\n# SQL 기본 지식\n\n시간을 내주셔서 감사합니다! 🚀 SQL 기본 지식에서 더 많은 콘텐츠를 찾아볼 수 있습니다. 💫","ogImage":{"url":"/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_0.png"},"coverImage":"/assets/img/2024-06-20-MasteringSQLAggregationFunctionsAComprehensiveGuidewithExamples_0.png","tag":["Tech"],"readingTime":7},{"title":"여러분이 배워야 할 6가지 DuckDB SQL 향상 기능","description":"","date":"2024-06-20 15:45","slug":"2024-06-20-SixDuckDBSQLenhancementsyoushouldlearn","content":"\n\n\n![Image](/assets/img/2024-06-20-SixDuckDBSQLenhancementsyoushouldlearn_0.png)\n\nDuckDB의 SQL은 원래 PostgreSQL을 기반으로 하였으며, 이는 모방하기에 좋은 SQL 버전입니다. 그러나 시간이 흐름에 따라 DuckDB는 SQL 제공에 몇 가지 유용한 추가 기능을 도입하여 여러분의 삶을 조금 더 쉽게 만들었습니다. 다른 보다 인기 있는 RDBMS들이 언젠가는 이러한 유용한 SQL 확장을 본뜬다면 전혀 놀라지 않을 것입니다.\n\nDuckDB에 대해 들어보지 못한 분들을 위해, 이는 C++로 작성된 인메모리 데이터베이스로서 분석용 SQL 워크로드를 위해 설계되었습니다. 또한 Polars와 같은 성능으로 빠르며 경쟁력이 있습니다.\n\n아래 링크를 통해 DuckDB의 기능에 대해 깊이 있는 탐구를 해보세요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알겠어요. 이 기사에 나온 유용한 SQL 명령어 몇 가지를 살펴봐요.\n\n## 1. 정규 표현식을 사용한 동적 열 선택\n\n정규 표현식을 사용한 동적 열 선택을 통해 쿼리할 때 테이블에 포함된 정확한 열 이름을 사용할 필요가 없어져요. 이는 쿼리에서 유용한 단축키로 이어질 수 있어요.\n\n대신, COLUMNS() 키워드를 사용하고 해당 키워드와 적합한 와일드카드를 함께 사용하여 열 이름에 와일드카드 표현식을 넣을 수 있어요. DuckDB는 COLUMNS() 표현식 내에서 와일드카드와 일치하는 열에 대한 데이터만 검색해 줄 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같이 테이블이 있다고 가정해 봅시다.\n\n```js\ndb.sql(\"CREATE TABLE departments (department varchar, exmployee_count INT, average_salary INT, max_salary INT, min_salary INT)\")\n\ndb.sql(\"INSERT INTO departments VALUES ('영업', 300, 25000, 40000, 19000), ('인사', 50, 22000, 50000, 18500)\");\n\ndb.sql(\"SELECT * FROM departments\")\n```\n\n위와 같이, 예를 들어 부서와 최저/최고 급여만 가져오고 싶다면 다음과 같이 사용할 수 있습니다.\n\n```js\n# average_salary와 employee_count 열을 제외\ndb.sql(\"SELECT department, COLUMNS('m.*salary') FROM departments\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWHERE 절에서 COLUMNS 식을 사용하여 DuckDB는 와일드카드에서 나온 각 식 사이에 암시적 AND를 넣을 것입니다. 예를 들어,\n\n```js\ndb.sql(\"SELECT department, COLUMNS('m.*salary') FROM departments \\\n       WHERE COLUMNS('m.*salary') \u003e= 19000\")\n\n# 위 WHERE 절은 다음과 동일합니다.\n# WHERE max_salary \u003e= 19000 AND min_salary \u003e= 19000\n#\n\n| department | max_salary | min_salary |\n|  varchar   |   int32    |   int32    |\n|------------|------------|------------|\n| Sales      |      40000 |      19000 |\n\n```\n\n컬럼에 계산을 적용할 때도 이 구문을 사용할 수 있습니다. 부서 데이터 세트를 사용하면서, 컬럼에 대한 몇 가지 집계를 수행하려면 다음과 같이 할 수 있습니다.\n\n```js\ndb.sql(\"SELECT MAX(COLUMNS('m.*salary')) FROM departments\")\n\n| max(departments.max_salary) | max(departments.min_salary) |\n|            int32             |            int32            |\n|----------------------------- |-----------------------------|\n|             50000            |             19000          |\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2. 피벗/언피벗\n\n관계형 데이터베이스 시스템에서 가장 어려운 작업 중 하나인 데이터 집합을 피벗하고 언피벗하는 기능을 활용하면 데이터 분석이 훨씬 쉬워질 수 있어요.\n\n먼저 테스트 테이블 데이터를 설정해봅시다.\n\n```js\nimport duckdb as db\n\ndb.sql(\"CREATE TABLE purchases (productID int, year INT, sales INT)\")\n\ndb.sql(\"INSERT INTO purchases VALUES (12345, 2019, 15000), (12345,2020, 19500), (12345, 2021, 22000), (987654, 2019, 510), (987654,2020, 1900), (987654, 2021, 2100)\")\n\ndb.sql(\"SELECT * FROM purchases\")\n```\n\n\n| productID | year  | sales |\n|-----------|-------|-------|\n|     12345 |  2019 | 15000 |\n|     12345 |  2020 | 19500 |\n|     12345 |  2021 | 22000 |\n|    987654 |  2019 |   510 |\n|    987654 |  2020 |  1900 |\n|    987654 |  2021 |  2100 |\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요청하신 데이터가 아래와 같이 보이도록 하겠습니다.\n\n```js\n┌───────────┬────────┬────────┬────────┐\n│ productID │  2019  │  2020  │  2021  │\n│   int32   │ int128 │ int128 │ int128 │\n├───────────┼────────┼────────┼────────┤\n│     12345 │  15000 │  19500 │  22000 │\n│    987654 │    510 │   1900 │   2100 │\n└───────────┴────────┴────────┴────────┘\n```\n\n이를 위해 PIVOT를 사용할 수 있습니다.\n\n```js\nimport duckdb as db\n\n\ndb.sql(\"create table pivoted_purchases as PIVOT purchases ON year USING SUM(sales)  GROUP BY productID\")\ndb.sql(\"SELECT * FROM pivoted_purchases\")\n\n# PIVOT에 기반한 테이블을 생성하고 싶지 않을 경우 \n# 단순히 값을 표시하고 싶으면 이렇게도 할 수 있습니다\n# db.sql(\"PIVOT purchases ON year USING SUM(sales)  GROUP BY productID\")\n\n┌───────────┬────────┬────────┬────────┐\n│ productID │  2019  │  2020  │  2021  │\n│   int32   │ int128 │ int128 │ int128 │\n├───────────┼────────┼────────┼────────┤\n│     12345 │  15000 │  19500 │  22000 │\n│    987654 │    510 │   1900 │   2100 │\n└───────────┴────────┴────────┴────────┘\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPIVOT 명령어에서 수행한 SUM(salary) 집계는 숫자 데이터를 전혀 변경하지 않았기 때문에 이 프로세스를 UNPIVOT 및 이미 이야기한 COLUMNS 기능을 사용하여 반대로도 수행할 수 있습니다.\n\n```js\ndb.sql(\"UNPIVOT pivoted_purchases ON COLUMNS(* EXCLUDE productID) INTO NAME year VALUE sales\")\n\n| productID |  year   | sales  |\n|   int32   | varchar | int128 |\n|-----------|---------|--------|\n|    12345  |  2019   | 15000  |\n|    12345  |  2020   | 19500  |\n|    12345  |  2021   | 22000  |\n|   987654  |  2019   |  510   |\n|   987654  |  2020   |  1900  |\n|   987654  |  2021   |  2100  |\n```\n\n## 3. Union 데이터 유형\n\n이제 서로 다른 데이터 유형을 유니언할 수 있습니다. 네, 들으신 대로, 제 SQL 고통 중 하나가 사라졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndb.sql(\"SELECT '나는 문자열입니다' as col1 union select 100 union select 42.0\")\n\n\n\n┌───────────────┐\n│     col1      │\n│    varchar    │\n├───────────────┤\n│ 나는 문자열입니다 │\n│ 42.0          │\n│ 100           │\n└───────────────┘\n```\n\nDuckDB는 서로 다른 데이터 유형을 가져오는 모든 유형을 지원하는 \"가장 낮은 공통 분모\"로 강제로 변환합니다. 여기서 FLOAT 및 INT 열 값은 VARCHAR로 강제 변환됩니다.\n\n## 4. 재사용 가능한 열 별칭\n\n전통적인 SQL에서는 select 문 내에서 점진적으로 계산된 표현식을 처리할 때 일반적으로 각 열에 대해 전체 표현식을 복제하거나 각 계산 단계를 공통 테이블 표현식(CTE)으로 캡슐화해야 합니다. 그러나 재사용 가능한 열 별칭을 사용하면 이제 열 별칭을 동일한 select 문 전체에서 사용할 수 있으며, where 및 order by 절에서도 사용할 수 있어 프로세스를 간소화하고 중복을 줄일 수 있습니다. 예를 들어,\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndb.sql(\"SELECT 'The quick brown fox jumped over the lazy dog' AS my_text,\\\nsubstring(my_text, 17,3) AS my_text_substr,\\\nlength(my_text) AS my_text_len,\\\nmy_text_len * my_text_len AS my_text_calc\")\n\n## 5. 리스트 내포\n\n이 기능은 파이썬 스타일의 리스트 내포를 모델로 하며, 리스트 내 요소들에 대한 표현식을 계산하는 데 사용할 수 있습니다. 예를 들어, 다음과 같이 숫자 목록이 있는 경우:\n\n[1,2,3,4,5,6,7,8,9]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬에서는 우리가 원한다면, 위의 리스트의 각 숫자를 제곱하여 두 번째 리스트를 출력하고 싶다면 다음과 같이 진행될 것입니다.\n\n```js\n[x*x for x in [1,2,3,4,5,6,7,8,9]]\n\n\n# 위의 파이썬 코드는 다음과 같은 출력을 생성합니다\n#\n# [1, 4, 9, 16, 25, 36, 49, 64, 81]\n```\n\nDuckDB SQL에서도 매우 유사한 작업을 수행할 수 있습니다.\n\n```js\ndb.sql(\"SELECT [x*x for x in nums] as squares FROM (VALUES ([1,2,3,4,5,6,7,8,9])) t(nums)\")\n\n\n\n┌───────────────────────────────────┐\n│              squares              │\n│              int32[]              │\n├───────────────────────────────────┤\n│ [1, 4, 9, 16, 25, 36, 49, 64, 81] │\n└───────────────────────────────────┘\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n쿼리를 분석해보면 무엇을 하는 지 이해할 수 있습니다:\n\n다음 (VALUES([1,2,3,4,5,6,7,8,9])) t(nums)\n\n- 이 쿼리의 이 부분은 nums라는 단일 열을 갖는 임시 테이블 (또는 파생 테이블) t를 생성합니다.\n- VALUES 절은 리터럴 값을 제공하는 데 사용됩니다. 여기서는 1부터 9까지의 정수로 이루어진 목록(또는 배열)입니다.\n- t(nums)는 파생 테이블에 t라는 이름을 지어주고, 그 안의 배열을 포함하는 열을 nums로 명명한 부분입니다.\n\n다음과 같이 MARKDOWN 형식의 테이블 태그를 변경해 보세요:\n\nSELECT [x*x for x in nums] as squares\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이것은 계산이 발생하는 쿼리의 주요 부분입니다.\n- 이 쿼리는 파이썬에서 일반적으로 볼 수 있는 작업인 리스트 내포 [x*x for x in nums]을 사용합니다. 이 문맥에서 nums 배열의 각 요소 x에 대해 x의 제곱을 계산합니다.\n- 결과는 제곱된 값들의 배열입니다. 입력 배열에 대한 출력인 [1,2,3,4,5,6,7,8,9]는 [1,4,9,16,25,36,49,64,81]이 됩니다.\n- squares로 이 계산된 배열을 별칭 지어주고 있습니다.\n\n요약하자면, 이 쿼리는 1에서 9까지의 숫자 배열을 만든 다음, 각 숫자의 제곱을 계산하고 squares라는 배열로 결과를 반환합니다.\n\n## 6. 함수 체이닝\n\nDuckDB는 점 표기법(dot notation)을 사용하여 별도의 SQL 함수를 연결하는 것을 쉽게 만들어줍니다. 이렇게 하면 한 개의 SQL 문에서 함수 파이프라인을 구축할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 많은 데이터베이스 시스템에서 INITCAP과 같은 이름의 SQL 함수가 있습니다. 이 함수는 텍스트 문자열의 모든 단어를 대문자로 만듭니다. 안타깝게도 DuckDB에는 이 기능이 내장되어 있지 않으므로, 우리는 함수 체이닝 (그리고 리스트 내포)을 사용하여 이를 흉내 내볼 수 있는지 살펴볼까요?\n\n다음은 \"the quick brown fox jumped over the lazy dog\"이라는 문구에서 각 단어를 대문자로 바꾸고 싶을 때의 빠른 예제입니다.\n\n```js\ndb.sql(\"SELECT ([upper(x[1])||x[2:] for x in \\\n('the quick brown fox jumped over the lazy dog')\\\n.string_split(' ')]).list_aggr('string_agg',' ') as final_str\")\n\n\n┌──────────────────────────────────────────────┐\n│                  final_str                   │\n│                   varchar                    │\n├──────────────────────────────────────────────┤\n│ The Quick Brown Fox Jumped Over The Lazy Dog │\n└──────────────────────────────────────────────┘\n```\n\nstring_split 함수는 문구를 구성하는 개별 단어로 나누어주며, Python 리스트와 유사한 단어 목록을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[the, quick, brown, fox, jumped, over, the, lazy, dog]\n\n다음으로, 우리는 단어 목록 위에 리스트 컴프리헨션을 실행합니다. 목록의 각 단어마다 첫 글자를 대문자로 설정한 후 단어의 나머지 부분을 연결합니다. 이것이 표현식의 upper(x[1])||x[2:] 부분이 하는 일입니다.\n\n이후에 우리의 중간 단어 목록은 다음과 같이 됩니다,\n\n[The, Quick, Brown, Fox, Jumped, Over, The, Lazy, Dog]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 단어 목록에 대해 list_agg 함수를 실행합니다. 이 함수는 단어 목록을 다시 단어 문자열로 변환하고 각 단어를 공백 문자로 분리합니다.\n\nMedium은 이 두 기사의 내용이 특히 흥미롭다고 생각합니다.","ogImage":{"url":"/assets/img/2024-06-20-SixDuckDBSQLenhancementsyoushouldlearn_0.png"},"coverImage":"/assets/img/2024-06-20-SixDuckDBSQLenhancementsyoushouldlearn_0.png","tag":["Tech"],"readingTime":9},{"title":"SQLAlchemy MissingGreenletError","description":"","date":"2024-06-20 15:44","slug":"2024-06-20-SQLAlchemyMissingGreenletError","content":"\n\nSQLAlchemy은 Python을 위한 강력한 라이브러리로, Python 프로그램과 데이터베이스 간의 통신을 용이하게 해줍니다. 이는 고수준 ORM (객체-관계 매핑)과 저수준 SQL 표현 언어를 제공합니다. asyncio의 등장으로 SQLAlchemy는 비동기 작업을 지원하도록 도입되었는데, 이는 비동기 IO가 성능을 향상시킬 수 있는 웹 애플리케이션에 특히 유용합니다. SQLAlchemy에서의 MissingGreenletError는 SQLAlchemy가 asyncio나 다른 비동기 프레임워크와 함께 사용될 때 발생하는 일반적인 문제입니다. 이 오류는 SQLAlchemy의 기본 동작이 동기적이기 때문에 발생하며, 이는 데이터베이스 작업이 결과를 기다리는 동안 이벤트 루프를 차단한다는 것을 의미합니다.\n\n이 오류의 근본 원인을 이해하기 위해서는 SQLAlchemy와 asyncio가 어떻게 함께 작동하는지 이해해야 합니다.\n\nMissingGreenletError: 이 오류는 보통 비동기 컨텍스트 (예: async 함수 또는 코루틴 내부)에서 동기 작업(데이터베이스 작업)을 실행하려고 할 때 발생합니다. async 함수 내에서 동기 SQLAlchemy 함수나 메서드를 호출하면, 데이터베이스 작업이 완료될 때까지 이벤트 루프가 다른 작업으로 전환할 수 없습니다. 이는 이벤트 루프가 차단되어 응용 프로그램이 응답하지 않거나 성능 문제가 발생한다는 것을 의미합니다.\n\n다음은 MissingGreenletError를 설명하는 예시입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n엔진: AsyncEngine = create_async_engine(DB_ENGINE, echo=True)\n\nasync_session: AsyncSession = async_sessionmaker(engine, expire_on_commit=False)\n\n\nclass Base(DeclarativeBase):\n    \"\"\"모든 ORM 모델을 위한 기본 클래스.\"\"\"\n\n\nclass PirateCrew(Base):\n    \"\"\"해적 승무원의 세부 정보를 포함합니다.\"\"\"\n\n    __tablename__ = \"pirate_crew\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str]\n    ship_name: Mapped[str]\n    members: Mapped[List[\"Pirate\"]] = relationship(back_populates=\"pirate_crew\")\n\n    def __repr__(self) -\u003e str:\n        \"\"\"객체의 표현을 반환합니다.\"\"\"\n        return f\"{self.__class__.name}({self.name})\"\n\n\nclass Pirate(Base):\n    \"\"\"해적의 세부 정보를 포함합니다.\"\"\"\n\n    __tablename__ = \"pirates\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    name: Mapped[str]\n    role: Mapped[str]\n    devil_fruit_user: Mapped[bool]\n    pirate_crew_id = mapped_column(ForeignKey(\"pirate_crew.id\"))\n    pirate_crew: Mapped[\"PirateCrew\"] = relationship(back_populates=\"members\")\n\n    def __repr__(self) -\u003e str:\n        \"\"\"객체의 표현을 반환합니다.\"\"\"\n        return f\"{self.__class__.name}({self.name})\"\n\n\nasync def create_tables():\n    \"\"\"모든 테이블을 생성하는 메서드입니다.\"\"\"\n    async with engine.begin() as connection:\n        await connection.run_sync(Base.metadata.create_all)\n\n\nasync def db_seeder():\n    \"\"\"PirateCrew 및 Pirate 테이블에 데이터를 시드하는 시더입니다.\"\"\"\n    async with async_session() as session:\n        mugiwara = PirateCrew(name=\"Straw Hats\", ship_name=\"Thousand Sunny\")\n        mugiwara_members = [\n            Pirate(\n                name=\"Monkey D Luffy\",\n                role=\"Captain\",\n                devil_fruit_user=True,\n                pirate_crew=mugiwara,\n            ),\n            Pirate(\n                name=\"Roronoa Zoro\",\n                role=\"First Mate\",\n                devil_fruit_user=False,\n                pirate_crew=mugiwara,\n            ),\n            Pirate(\n                name=\"Nami\",\n                role=\"Navigator\",\n                devil_fruit_user=False,\n                pirate_crew=mugiwara,\n            ),\n        ]\n        session.add(mugiwara)\n        session.add_all(mugiwara_members)\n        await session.commit()\r\n```\n\n따라서 여기에서 우리는 PirateCrew와 Pirate 두 개의 테이블을 만들었습니다. Pirate와 PirateCrew 테이블 사이에 일대다 관계가 있음을 알 수 있습니다. 또한 데이터베이스에 테이블을 생성하고 일부 데이터로 씨드하는 두 개의 비동기 함수가 있습니다.\n\n이제 MissingGreenletError를 살펴보겠습니다.\n\n```js\nasync def missing_greenlet_error():\n    \"\"\"MissingGreenletError 예제입니다.\"\"\"\n    async with async_session() as session:\n        pirate_crew = (await session.execute(select(PirateCrew))).all()[0][0]\n        # 이제 해적 승무원의 멤버에 액세스하려고 시도해 보겠습니다 (members는 관련된 객체입니다).\n        members = pirate_crew.members\n        print(members)\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 함수를 실행하면 콘솔에서 다음과 같은 오류가 발생합니다.\n\n```js\nsqlalchemy.exc.MissingGreenlet: greenlet_spawn has not been called; can't call await_only() here. Was IO attempted in an unexpected place? (Background on this error at: https://sqlalche.me/e/20/xd2s)\n```\n\n이 오류는 members 속성이 관계 속성이기 때문에 발생합니다. SQLAlchemy의 기본 동작은 관련된 객체를 동기적으로 게으르게 로드하는 것입니다. members 속성에 액세스할 때 SQLAlchemy가 관련 Pirate 객체를 동기적으로 로드하려고 하면, 이는 비동기 함수와 호환되지 않습니다. 동기적으로 작동하는 SQLAlchemy가 기대하는 것은 동기 작업에 대해 사용 가능한 greenlet이 있기 때문에 MissingGreenletError가 발생하게 되는 것입니다. 그러나 비동기적인 컨텍스트에서는 greenlet은 사용할 수 없습니다.\n\n이와 같은 상황에서 MissingGreenletError를 피하려면 두 가지 옵션이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 관련 객체를 초기 쿼리에서 함께 로드하려면\n- AsyncAttrs\n\nEager load 접근 방식: Eager loading은 SQLAlchemy와 같은 객체-관계 매핑(ORM) 라이브러리에서 사용되는 기술로, 부모 객체와 관련된 객체를 동일한 쿼리에서 로드하여 필요할 때 게으르게로 로드하는 것이 아니라 한 번에 로드합니다. 이 방식은 관련 객체를 비동기적으로 처리할 때 MissingGreenletError를 피하는 데 도움이 될 수 있습니다.\n\n다음은 Eager load 방식으로 MissingGreenletError를 해결하는 예시입니다.\n\n```js\nasync def loading_techniques로 수정해주세요():\n    \"\"\"로딩 기술을 사용하여 MissingGreenletError를 해결하는 예시.\"\"\"\n    async with async_session() as session:\n        pirate_crew = (\n            await session.execute(\n                select(PirateCrew).options(selectinload(PirateCrew.members))\n            )\n        ).all()[0][0]\n        # 이곳에서 selectinload()를 사용하여 Pirate Table을 조인했습니다\n        members = pirate_crew.members\n        print(members)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 selectinload() 로더 전략을 사용하여 관련된 객체를 즉시 로드했습니다. 더 자세한 설명은 이전 게시물을 참고해주세요,\n\nAsyncAttrs: AsyncAttrs은 SQLAlchemy에서 제공하는 내장 mixin으로, awaitable_attrs 엑세서를 소개하여 어떤 속성도 awaitable로 취급할 수 있게 하며, 관련된 객체 또는 다른 속성에 대한 비동기 로딩 및 액세스를 용이하게 합니다.\n\n다음은 AsyncAttrs를 사용하여 MissingGreenletError를 해결하는 예시입니다.\n\n```js\nclass Base(DeclarativeBase, AsyncAttrs):\n    \"\"\"모든 ORM 모델의 기본 클래스\"\"\"\n\nasync def fix_with_async_attrs():\n    \"\"\"AsyncAttrs로 MissingGreenletError를 해결하는 예시\"\"\"\n    async with async_session() as session:\n        pirate_crew = (await session.execute(select(PirateCrew))).all()[0][0]\n        members = await pirate_crew.awaitable_attrs.members\n        print(members)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 우리는 AsyncAttrs를 Base 클래스에 추가했습니다. 이제 awaitable_attrs 액세서를 사용하여 관련 객체에 액세스할 수 있습니다. AsyncAttrs를 추가함으로써 이제 pirate_crew.members에 직접 액세스하는 대신 pirate_crew.awaitable_attrs.members를 사용할 수 있습니다. awaitable_attrs 부분은 SQLAlchemy에게 관련 Pirate 객체를 블로킹하지 않고 비동기적으로 로드하도록 지시합니다.\n\n참고: AsyncAttrs은 MissingGreenletError를 피하는 데 도움이 되지만 N+1 쿼리 문제나 불필요한 데이터 로딩과 같은 다른 잠재적인 문제를 반드시 예방하는 것은 아닙니다. 여전히 적절한 로딩 전략(예: joinedload 또는 selectinload)을 사용하고 데이터 액세스 패턴을 신중히 고려하여 성능을 최적화하고 불필요한 부하를 피하는 것이 좋습니다.\n\n참고 자료:\n\n코드 참조:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://github.com/vickypalani/sqlalchemy_missing_greenlet_error","ogImage":{"url":"/assets/img/2024-06-20-SQLAlchemyMissingGreenletError_0.png"},"coverImage":"/assets/img/2024-06-20-SQLAlchemyMissingGreenletError_0.png","tag":["Tech"],"readingTime":7},{"title":"파이썬과 SQL을 통합하여 견고한 데이터 솔루션 구축하기","description":"","date":"2024-06-20 15:43","slug":"2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions","content":"\n\n강력하고 효율적인 데이터 솔루션을 만들기 위해 Python과 SQL 통합을 숙달하세요.\n\n![image](/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_0.png)\n\n\"데이터는 새로운 석유다.\" - 클라이브 햄비. Python과 SQL은 그 석유를 잘 정제하기 위해 필수적이지만, 왜 우리는 동시에 사용할 수 없을까요?\n\nPython과 SQL을 사용하여 SQL 데이터베이스를 조작하려는 사람들을 위해, 우리는 다양한 접근 방식을 탐구하고 이 중 하나를 인터뷰 문제에서 구현해볼 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 그 전에, 파이썬을 사용하여 데이터베이스에 연결하는 장점과 옵션을 살펴보겠습니다.\n\n# 파이썬으로 SQL 서버에 연결하는 장점\n\nPython을 사용하여 SQL 데이터베이스에 연결하는 것에는 여러 가지 이점이 있습니다. 시스템 내에 저장된 데이터를 처리하고 분석하는 데 도움이 됩니다. 이러한 이점은 다음과 같습니다:\n\n- 향상된 데이터 분석: Python의 데이터 분석 라이브러리는 SQL 데이터베이스만 사용할 때 복잡한 방법의 효율성을 향상시켜 데이터 분석 프로세스를 용이하게 합니다.\n- 자동화: Python을 사용하면 사용자가 SQL 데이터베이스에서 데이터를 추출, 변환하여 다시 데이터베이스에로드하는 ETL 프로세스를 자동화할 수 있습니다. Python 스크립트는 데이터 이전 시에 오류가 발생하지 않도록 시간을 절약하는 옵션을 제공합니다.\n- 향상된 데이터 파이프라인: SQL과 Python을 결합하면 실시간 데이터 파이프라인을 제공하여 실시간으로 여러 지리적 위치의 데이터 맵을 전송, 변환 및 분석할 수 있습니다.\n- 확장성: Python은 데이터 세트를 관리할 수 있으며, 따라서 Python 서비스를 사용하여 대량의 데이터 세트를 실시간으로 처리할 수 있습니다. SQL 데이터베이스 외에도 Python 능력을 활용합니다.\n- 다양성: Python은 여러 데이터 유형에 적합하며 장르 간 데이터 전송을 지원하여 다양한 형식으로 데이터를 전송할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 고급 SQL 작업을 위한 Python 라이브러리 사용\n\n![image](/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_1.png)\n\nPython 라이브러리를 사용하면 복잡한 SQL 작업을 훨씬 쉽게 수행할 수 있습니다. 여러 가지 필수 라이브러리와 이점을 살펴보겠습니다:\n\n# Psycopg2\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPsycopg2는 널리 사용되는 Python PostgreSQL 어댑터 중 하나입니다. 이러한 상황에서 PostgreSQL 데이터베이스에 연결하여 SQL 쿼리를 효과적으로 실행할 수 있습니다.\n\nPsycopg2를 사용하여 다음을 수행할 수 있습니다:\n\n- 데이터베이스를 생성하고 닫기.\n- 트랜잭션 선택 및 처리.\n- 여러 SQL 쿼리를 빠르게 실행.\n\n아래는 간단한 코드 블록입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom sqlalchemy import create_engine\n\n# Create an engine instance\nengine = create_engine('postgresql://user-name:password@localhost:5432/your-db-name')\n\n# Connect to the database\nconnection = engine.connect()\n```\n\n이 코드는 연결 매개변수를 정의한 다음 Psycopg2를 사용하여 PostgreSQL 데이터베이스에 연결을 수립합니다. 연결은 데이터베이스와 통신하는 데 사용되는 객체인 conn입니다.\n\n# SQLAlchemy\n\nSQLAlchemy는 데이터베이스 작업을 효율적으로 처리하는 ORM(Object-Relational Mapping)입니다. SQLAlchemy를 사용하는 몇 가지 장점은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 더 쉬운 데이터베이스 스키마 관리\n- 코드 가독성 및 유지 관리성\n- 여러 데이터베이스 방언 지원\n\n```js\nimport psycopg2\n\n# 연결 매개변수 정의\nconn_params = {\n    'dbname': 'your-db-name',\n    'user': 'user-name',\n    'password': 'password',\n    'host': 'localhost',\n    'port': '5432'\n}\n\n# 연결 설정\nconn = psycopg2.connect(**conn_params)\n```\n\n이 코드는 SQLAlchemy를 사용하여 엔진 인스턴스를 생성하고 PostgreSQL 데이터베이스에 연결을 설정합니다.\n\nSQLAlchemy는 Python 객체를 사용하여 데이터베이스 상호 작용을 단순화합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 판다스\n\n판다스 라이브러리는 강력한 데이터 조작 도구로, SQL 데이터베이스에 쉽게 연결할 수 있습니다. SQL 쿼리에서 데이터를 직접 DataFrame으로 읽어와 간단한 분석과 효율적인 작업을 할 수 있습니다. 판다스를 사용하면 다음과 같은 작업을 수행할 수 있습니다:\n\n- 쉽게 복잡한 데이터 조작을 수행합니다.\n- 데이터셋을 원활하게 병합하고 결합합니다.\n- 내장 함수를 사용하여 데이터를 분석하고 시각화합니다.\n\n```python\nimport pandas as pd\nimport psycopg2\n\n# 연결 매개변수 정의\nconn_params = {\n    'dbname': 'your-db-name',\n    'user': 'user-name',\n    'password': 'password',\n    'host': 'localhost',\n    'port': '5432'\n}\n\n# 연결 설정\nconn = psycopg2.connect(**conn_params)\n\n# 데이터를 판다스 DataFrame으로 가져오기\nuser_posts_df = pd.read_sql('SELECT * FROM user_posts', conn)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 이 코드는 PostgreSQL 데이터베이스의 매개변수를 정의하고 Psycopg2를 사용하여 데이터베이스에 연결합니다. 그런 다음 user_posts 테이블에서 데이터를 검색하여 Pandas DataFrame에 보내고 데이터 조작이 가능해집니다.\n\n# 데이터베이스 다이브: 메타 챌린지 대응\n\n이제 StrataScratch의 Meta 챌린지 중 하나, Friday's Like Count를 해결하기 위해 데이터베이스에 연결해 봅시다.\n\n다음은 질문입니다: https://platform.stratascratch.com/coding/10364-fridays-likes-count\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![User_posts dataset](/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_2.png)\n\nWe have three different datasets. Here is the user_posts dataset.\n\n![Friendships dataset](/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 좋아요 데이터셋입니다.\n\n그리고 여기에 예상되는 결과가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_6.png\" /\u003e\n\n우선, 데이터셋을 읽기 위해 다음 단계를 따라야 합니다.\n\n## 1. 연결 정의하기\n\n우선, PostgreSQL 데이터베이스에 연결하기 위해 필요한 연결 매개변수를 정의할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport psycopg2\nimport pandas as pd\n\nconn_params = {\n    'dbname': 'your-db-name',\n    'user': 'user-name',\n    'password': 'password',\n    'host': 'localhost',\n    'port': '5432'\n}\n```\n\n여기서는 코드에서 필요한 라이브러리를 먼저 가져옵니다. 다음으로, 연결 매개변수를 포함하는 사전을 만듭니다. 이러한 매개변수에는 다음이 포함됩니다:\n\n- 데이터베이스 이름\n- 사용자\n- 비밀번호\n- 호스트\n- 포트 이름.\n\n이제 두 번째 단계인 연결을 설정하겠습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2. 연결 설정\n\n이제 정의된 연결 매개변수를 사용하여 PostgreSQL 데이터베이스에 연결합니다.\n\n```js\nconn = psycopg2.connect(**conn_params)\n```\n\n여기서는 이전 단계에서 이미 정의한 매개변수를 사용하여 pycop2 라이브러리의 connect() 메서드를 사용합니다. 다음 단계에서 데이터를 검색할 것이기 때문에 연결 부분이 끝났네요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3. 데이터 검색\n\n이미 데이터베이스에 연결되어 있으므로 거기서 데이터를 가져와 봅시다. 세 개의 다른 테이블이 있으므로 각각 1번씩 코드를 반복합니다.\n\n```js\nuser_posts_df = pd.read_sql('SELECT * FROM user_posts', conn)\nfriendships_df = pd.read_sql('SELECT * FROM friendships', conn)\nlikes_df = pd.read_sql('SELECT * FROM likes', conn)\n```\n\n이를 위해 판다스 라이브러리의 read_sql 메서드를 사용합니다. 이 메서드에서는 데이터를 선택하기 위한 쿼리를 작성하고 앞에서 정의한 연결인 \"conn\"을 인수로 추가합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4. 연결 닫기\n\n이미 이러한 테이블을 데이터프레임으로 변환했으므로 연결을 유지할 필요가 없습니다. 자원을 해제하기 위해 닫아야 합니다.\n\n```js\nconn.close()\n```\n\n이 단계에서는 앞에서 정의한 Postgresql 데이터베이스와의 연결을 닫기 위해 close() 메서드를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 데이터셋을 읽는 데 성공했습니다. 이제부터는 이를 조작할 수 있습니다. 우리가 해결해야 하는 문제를 해결하기 위해 이제부터 따라야 할 단계는 다음과 같습니다:\n\n- 친구 관계 데이터세트 정리\n- 좋아요 및 게시물 데이터세트 병합\n- 친구의 좋아요로 필터링\n- 금요일에 좋아요로 필터링\n- 날짜별 그룹화 및 좋아요 횟수 카운트\n- 결과 표시\n\n## 5. 친구 관계 정리 및 확장\n\n친구 관계 데이터를 정리하고, 양방향 친구관계를 보장하기 위해 확장할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfriendships_clean = friendships_df[['user_name1', 'user_name2']].drop_duplicates()\nfriendships_expanded_1 = friendships_clean.rename(columns={'user_name1': 'user_name1', 'user_name2': 'user_name2'})\nfriendships_expanded_2 = friendships_clean.rename(columns={'user_name1': 'user_name2', 'user_name2': 'user_name1'})\nfriendships_expanded = pd.concat([friendships_expanded_1, friendships_expanded_2]).drop_duplicates()\n```\n\n이 블록에서 수행하는 작업은 다음과 같습니다:\n\n- 우정 데이터를 정리합니다: 사용자 이름1과 사용자 이름2만 선택하여 중복 행을 제거합니다.\n- 두 가지 방식으로 우정을 나타내는 두 데이터 프레임을 만듭니다: friendships_expanded_1과 friendships_expanded_2.\n- 이 2개의 데이터 프레임을 연결하고 중복을 제거하여 friendships_expanded를 얻습니다. 즉, 두 방향의 모든 고유한 우정 쌍을 얻게 됩니다.\n\n## 6. 좋아요와 게시물을 결합하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n받은 좋아요와 함께 게시물을 결합하여 각 좋아요에 대한 필요한 세부 정보를 얻습니다.\n\n```js\nlikes_posts_joined = likes_df.merge(user_posts_df, left_on='post_id', right_on='post_id', suffixes=('', '_post'))\nlikes_posts_joined = likes_posts_joined[['user_name', 'post_id', 'date_liked', 'user_name_post']]\nlikes_posts_joined = likes_posts_joined.rename(columns={'user_name_post': 'poster_name'})\n```\n\n좋아요 DataFrame을 post_id 열을 기준으로 user_posts DataFrame과 병합하여 좋아요된 게시물에 대한 정보를 제공합니다. 그 후 필요한 열만 선택하고 편의를 위해 user_name_post를 poster_name으로 이름을 변경했습니다.\n\n## 7. 친구의 좋아요 필터링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 친구들이 한 좋아요만을 걸러내겠어요.\n\n```js\nfriends_likes = likes_posts_joined.merge(friendships_expanded, left_on=['user_name', 'poster_name'], right_on=['user_name1', 'user_name2'])\n```\n\nfriendships_expanded와 likes_posts_joined라는 두 개의 데이터프레임이 있어요. 우리는 이 둘을 결합해서 친구들이 한 좋아요를 찾아내요. 이것은 친구들이 한 게시물에 대한 좋아요를 추적하는 데 필요한 과정이에요.\n\n## 8. 금요일에 한 좋아요 걸러내기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 금요일에 한 좋아요만 포함하는 방법입니다.\n\n```python\nfriends_likes['date_liked'] = pd.to_datetime(friends_likes['date_liked'])\nfriends_likes['day_of_week'] = friends_likes['date_liked'].dt.dayofweek\nfriday_likes = friends_likes[friends_likes['day_of_week'] == 4]\nlikes_df = pd.read_sql('SELECT * FROM likes', conn)\n```\n\n이 경우 요일을 사용하여 date_liked 필드를 datetime처럼 보이게 만듭니다. 그런 다음 DataFrame은 금요일의 좋아요만 보여주도록 필터링됩니다 (day_of_week = 4).\n\n## 9. 날짜별로 그룹화하여 좋아요 횟수 세기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n매일마다 좋아요가 얼마나 있는지 세어본 후, 각 날짜별로 좋아요를 그룹화할 겁니다.\n\n```js\nresult = friday_likes.groupby(friday_likes['date_liked'].dt.date).size().reset_index(name='likes')\nresult = result.rename(columns={'date_liked': 'date'})\n```\n\n여기서는 friday_likes 데이터프레임에서 각 날짜별로 좋아요가 얼마나 있는지 센 다음, 결과를 보기 좋은 형식으로 바꾸어 줍니다.\n\n## 10. 결과 표시하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 우리는 매주 금요일마다 친구 게시물의 총 좋아요 수를 포함하는 결과를 표시할 것입니다.\n\n```js\nprint(result)\n```\n\n결과는 다음과 같습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 마무리 마음\n\n이 글에서 우리는 SQL 데이터베이스를 연결하는 다양한 옵션, 팬더스 방법을 사용하여 테이블을 조작하는 방법, 그리고 데이터베이스에 연결하는 이점을 탐색했습니다.\n\n증강된 분석부터 간소화된 자동화까지 이점은 명확합니다. Meta 문제를 해결하는 것과 같은 실용적인 예제로, 우리는 그들의 현실 세계적인 영향을 보았습니다. 함께 데이터 마스터리 여정을 계속해보죠.","ogImage":{"url":"/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_0.png"},"coverImage":"/assets/img/2024-06-20-IntegratingPythonwithSQLforRobustDataSolutions_0.png","tag":["Tech"],"readingTime":9},{"title":"2024년을 위한 SQL에서 재귀 CTE 사용 방법 알아야 할 모든 것","description":"","date":"2024-06-20 15:40","slug":"2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024","content":"\n\n## 데이터 과학\n\n![이미지](/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_0.png)\n\n![이미지](/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_1.png)\n\n공통 테이블 표현식인 CTE는 SQL에서 가장 강력하고 널리 사용되는 도구 중 하나입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCTE(공통 테이블 식)를 사용하면 복잡한 쿼리를 간소화하고 가독성이 좋고 유지보수가 쉬운 SQL 쿼리를 작성할 수 있습니다.\n\nCTE를 사용하면 쿼리 결과에서 임시 테이블을 생성할 수 있습니다. 사실, 복잡한 서브쿼리를 간단한 CTE로 분해할 수도 있어요.\n\nCTE에 대해 더 알아보려면 제 이전 이야기 중 하나를 읽어보세요.\n\n그러나 CTE를 더 강력하게 만드는 것은 계층 데이터를 분석하는 능력입니다. CTE는 재귀를 지원하여 서로 다른 엔티티 간의 관계를 분석하기 위해 자신을 참조할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단한 시나리오로 중첩된 인형 예시를 들어보겠습니다 —\n\n![인형 사진](/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_2.png)\n\n세트 안에 몇 개의 인형이 있는지 정확히 알고 싶을 때, 동일한 세트를 계속해서 살펴봐야 하며 가장 작은 인형을 찾아야 합니다. 가장 작은 인형은 내부에 더 작은 인형이 없는 인형으로, 이것이 세트 내 인형 수를 세는 중단 조건이 됩니다.\n\n재귀 공통 테이블 표현식(CTE)은 정확히 동일한 논리를 따르며 여러 레이어가 서로 아래에 존재하는 데이터 집합을 탐색하는 데 도움을 줍니다. 재귀 CTE의 각 반복에서는 특정 중단 조건을 만날 때까지 데이터 구조의 한 수준을 탐색합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현실에서는 소셜 미디어 네트워크(예: 페이스북의 친구 목록), 슬랙의 채팅 스레드, 회사의 직원 구조(고위 경영진부터 개별 직원까지)와 같은 계층적 데이터 유형을 볼 수 있습니다. 재귀 CTE는 이러한 데이터를 다룰 때 매우 유용할 수 있습니다.\n\n# 재귀 CTE의 기본 사항\n\n모든 재귀 CTE에는 두 가지 주요 부분이 포함됩니다 —\n\n- 앵커 부분 — 주 쿼리 또는 초기 쿼리라고 할 수 있습니다. 따라서 재귀 부분에서 참조할 수 있는 시작점입니다.\n- 재귀 부분 — 재귀 CTE의 두 번째 부분으로, 앵커 부분을 참조하고 일정 조건을 충족하는 한 반복적으로 실행됩니다. 따라서 한 번 반복의 결과가 다음 반복의 입력으로 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 두 가지 기본 내용을 처음에 이해하지 못해도 전혀 괜찮아요!\n\n다음 두 사용 사례를 탐험하면서 예제로 설명해드릴 거예요. 이 두 가지 사용 사례에서 재귀 CTE를 사용할 수 있어요.\n\n# 계층적 데이터 다루기\n\n계층 데이터는 이름에서 알 수 있듯이 트리 형식이거나 부모-자식 관계로 구성된 데이터를 포함하고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기관에서는 관리자 - 직원 또는 폴더 - 하위 폴더 구조와 같은 데이터 유형을 일반적으로 관찰할 수 있습니다.\n\n따라서 계층 구조에서 항목은 그 아래에 있는 모든 다른 항목의 '상위 항목'입니다.\n\n재귀 공통 테이블 식(CTE)은 이러한 종류의 데이터에서 통찰력을 얻는 데 매우 유용할 수 있습니다. 자기 자신을 참조하는 CTE를 활용하여 전체 계층 구조를 검색할 수 있습니다.\n\n이 개념을 이해하는 데 가장 좋은 예시를 살펴보겠습니다. 조직적인 계층 구조의 매우 흔한 예시를 살펴보죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 표에 표시된 대로 직원 테이블을 가지고 있고 각 목록이 관리자부터 직원까지의 경로를 나타내는 쉼표로 구분된 목록을 얻고 싶다고 가정해보세요.\n\n![Employee Table](/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_3.png)\n\n다음 쿼리를 사용하여 이 입력 데이터를 다시 생성할 수 있습니다.\n\nMySQL Workbench에 있는 analyticswithsuraj는 스키마 이름입니다. 여러분의 스키마로 대체할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nDROP TABLE IF EXISTS analyticswithsuraj.employee;\nCREATE TABLE analyticswithsuraj.employee (\n    EmployeeID VARCHAR(10),\n    EmployeeName VARCHAR(50),\n    ManagerID VARCHAR(10)\n);\n\n-- Insert sample data\nINSERT INTO analyticswithsuraj.employee VALUES (1, 'John', NULL);\nINSERT INTO analyticswithsuraj.employee VALUES (2, 'Jane', 1);\nINSERT INTO analyticswithsuraj.employee VALUES (3, 'Bob', 1);\nINSERT INTO analyticswithsuraj.employee VALUES (4, 'Alice', 2);\nINSERT INTO analyticswithsuraj.employee VALUES (5, 'Charlie', 2);\nINSERT INTO analyticswithsuraj.employee VALUES (6, 'David', 3);\nINSERT INTO analyticswithsuraj.employee VALUES (7, 'Eva', 3);\n```\n\n문제에 돌아가서... 완전한 해결책을 보여드릴게요. 그리고 그 후에 설명을 따라 읽어볼게요.\n\n```js\nWITH RECURSIVE RecursiveCTE AS (\n    SELECT\n        EmployeeID,\n        EmployeeName,\n        ManagerID,\n        EmployeeName AS Path -- 초기 경로는 직원의 ID입니다\n    FROM\n        analyticswithsuraj.employee\n    WHERE\n        ManagerID IS NULL -- 앵커 부분\n\n    UNION ALL\n\n    SELECT\n        e.EmployeeID,\n        e.EmployeeName,\n        e.ManagerID,\n        concat_ws(',', rc.Path, e.EmployeeName) AS Path\n    FROM\n        analyticswithsuraj.employee e\n    JOIN\n        RecursiveCTE rc ON e.ManagerID = rc.EmployeeID -- 재귀 부분\n)\n```\n\nMySQL Workbench에서 재귀 CTE를 작성하려면 CTE 이름 앞에 RECURSIVE 키워드를 입력해야 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCaveat: 재귀 CTE의 기본 개념을 읽으신다면, 솔루션은 두 부분으로 이뤄져야 합니다.\n\n첫 번째는 시작점인 앵커 부분입니다. 재귀 쿼리에서 참조할 수 있는 시작점으로, 아래와 같이 간단한 SELECT 문으로 표현됩니다.\n\n```js\n    SELECT\n        EmployeeID,\n        EmployeeName,\n        ManagerID,\n        EmployeeName AS Path -- 초기 경로는 직원의 ID만 포함합니다\n    FROM\n        analyticswithsuraj.employee\n    WHERE\n        ManagerID IS NULL -- 앵커 부분\n```\n\n여기서는 직원의 전체 계층 구조를 저장할 추가적인 Path 열을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 앵커 쿼리는 항상 ManagerID가 NULL 인 직원만 포함합니다. 즉, 그들 위에 매니저가 없는 직원만을 선택합니다.\n\n재귀 CTE의 두 번째 부분은 재귀 부분으로, 직원 이름을 선택하고 Path 열의 값을 업데이트하여 아래와 같이 쉼표로 구분된 경로를 만듭니다.\n\n```js\n    UNION ALL\n\n    SELECT\n        e.EmployeeID,\n        e.EmployeeName,\n        e.ManagerID,\n        concat_ws(', ', rc.Path, e.EmployeeName) AS Path\n    FROM\n        analyticswithsuraj.employee e\n    JOIN\n        RecursiveCTE rc ON e.ManagerID = rc.EmployeeID -- Recursive part\n```\n\n보시다시피 이 재귀 부분은 원래의 직원 테이블에서 데이터를 조회하고 안에 쓰여진 CTE와 조인합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUNION ALL은 앵커 쿼리와 순환 쿼리의 결과를 결합하는 데 사용됩니다.\n\n최종적으로는 이 순환 CTE를 간단한 SELECT 문으로 쿼리할 수 있습니다.\n\n```js\nSELECT\n    EmployeeID,\n    EmployeeName,\n    ManagerID,\n    Path\nFROM\n    RecursiveCTE;\n```\n\n![이미지](/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결과적으로 각 레코드마다 직원의 완전한 계층 구조를 볼 수 있습니다. 여기에는 John이 최종 관리자로 나타나며 그의 상사가 없는 것을 나타내고, Jane과 Bob이 그의 직속 보고자들이라는 것을 보여줍니다.\n\n입력 테이블에서 4번째 레코드에서 Jane이 Alice의 관리자이고 John이 Jane의 관리자인 것을 볼 수 있으므로 Alice의 전체 계층은 'John, Jane, Alice'입니다.\n\n그러나 데이터는 단순한 계층보다 복잡할 수 있습니다. Facebook 친구 목록이나 다른 소셜 네트워킹 데이터와 같이 요롯한 경우도 있습니다. 재귀 CTE가 어떻게 활용될 수 있는지 살펴보겠습니다.\n\n# 네트워크 데이터 처리하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네트워크 데이터는 이름에서 알 수 있듯이 사물, 엔티티 및 사람들의 네트워크에 대한 것입니다. 아래 그림에서 보이는 것처럼 네트워크 데이터를 노드(블록)와 노드를 연결하는 엣지(선)로 시각화할 수 있습니다.\n\n![그림](/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_5.png)\n\n노드는 사용자 또는 엔티티를 나타내며, 엣지는 그들 사이의 관계를 나타냅니다.\n\n간단히 말해서, 두 노드 사이에 엣지(선)가 있다면, 두 노드는 직접적으로 서로 연결되어있다는 것을 의미합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 테이블 `network_connections`에 표시된 11명의 친구들 중 파올로와 연결된 사람들을 분석하고 있습니다. 파올로의 친구와 친구의 친구들을 파악하고 싶습니다.\n\n```js\nDROP TABLE IF EXISTS alldata.network_connections;\nCREATE TABLE alldata.network_connections (\n    source_node VARCHAR(50),\n    target_node VARCHAR(50)\n);\n\nINSERT INTO alldata.network_connections (source_node, target_node) VALUES\n('Paolo', 'David'),\n('Paolo', 'Anna'),\n('David', 'Mark'),\n('Anna', 'Peter'),\n('Samar', 'Patrik'),\n('Mark', 'Vivan'),\n('Patrik', 'Maya'),\n('Julia', 'Robert');\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알다타는 MySQL Workbench에서의 스키마 이름입니다. 이를 여러분의 스키마 이름으로 바꿔 사용하실 수 있습니다.\n\n이전 계층 데이터의 예제에서 이미 앵커 부분과 재귀 부분을 설명했으니, 여기서 바로 솔루션으로 넘어가겠습니다.\n\n```js\nWITH RECURSIVE NetworkCTE AS (\n    -- 시작 노드를 선택하는 앵커 부분\n    SELECT source_node,\n            target_node\n    FROM network_connections\n    WHERE source_node = 'Paolo' -- 다른 사람의 네트워크를 보려면 여기를 변경하세요\n    \n    UNION ALL\n    \n    -- 연결된 노드를 선택하는 재귀 부분\n    SELECT nc.source_node,\n            nc.target_node\n    FROM network_connections nc\n    JOIN NetworkCTE n ON nc.source_node = n.target_node\n)\n\nSELECT * FROM NetworkCTE;\n```\n\n코드에서 설명한 대로, 앵커 부분은 먼저 모든 레코드를 가져와 Paolo를 소스 노드로 하는 것 즉, Paolo의 직접적인 친구들을 모두 가져옵니다. 반면 재귀 부분은 Paolo의 친구의 친구를 모두 가져옵니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 Paolo의 네트워크를 최종적으로 다음과 같이 볼 수 있습니다.\n\n![image](/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_7.png)\n\n네트워크 데이터 분석의 다른 사용 사례들은 공급망 산업에서 서로 다른 개체간의 의존 관계를 분석하거나 재무 거래 분석에 계정을 통해 자금 이동을 추적하는 데 사용될 수 있습니다.\n\n더 많은 재귀 CTE를 효과적으로 사용할 수 있는 예시가 있다면 댓글에 언급하지 않을래요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글이 유용하고 정보가 풍부하게 느껴졌으면 좋겠어요!\n\n공통 테이블 표현식(CTE)은 SQL에서 널리 사용되며 재귀 CTE는 특수한 경우입니다. 이 간편한 글에서 재귀 CTE를 사용하여 계층적 및 네트워크 데이터를 다루는 방법을 알아보았어요.\n\n여기서 실제 예시를 통해 배운 것처럼, 특정 시나리오에서 SQL에서 재귀 CTE가 게임 체인저가 될 수 있다는 점을 알게 되었어요. 동일한 내용에 대한 다른 통찰이 있으면 댓글로 자유롭게 공유해주시기 바랍니다!\n\n💡 저를 팔로우하고 제 이메일 목록에 가입하여 데이터 과학, SQL, Python 및 취업 검색 팁에 관한 다른 글을 더 이상 놓치지 않도록 해보세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n읽어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_0.png"},"coverImage":"/assets/img/2024-06-20-HowtoUseRecursiveCTEsinSQLAllYouNeedToKnowin2024_0.png","tag":["Tech"],"readingTime":8},{"title":"마법같은 메이지 글로벌 후크의 마법을 풀어보세요","description":"","date":"2024-06-20 15:39","slug":"2024-06-20-UnleashtheMagicofMageGlobalHooks","content":"\n\n\n![Global hooks in Mage](/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_0.png)\n\n# TLDR\n\nMage의 글로벌 훅은 API 작업 앞뒤에서 사용자 정의 코드를 실행할 수 있는 강력한 기능입니다. 이를 통해 응용 프로그램의 다양한 구성 요소 간에 기능을 확장하거나 외부 시스템과 통합하거나 데이터를 유효성 검사하는 유연성을 제공합니다. 대상 조건과 비동기 실행을 통해, 글로벌 훅은 세밀한 제어와 성능 최적화를 제공합니다.\n\n![Global hooks GIF](https://miro.medium.com/v2/resize:fit:1400/1*OirhBHxPRCvHwConOgnGgQ.gif)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 개요\n\n- 글로벌 훅이란?\n- 왜 글로벌 훅을 사용해야 하나요?\n- 글로벌 훅 생성하기\n- 결론\n\n# 글로벌 훅이란?\n\n매지(Mage)의 글로벌 훅은 애플리케이션 실행 주기 중 특정 시점에 사용자 정의 코드를 실행할 수 있는 강력한 기능입니다. 이 훅은 데이터 유효성 검사, 변환 또는 외부 시스템과의 통합과 같은 다양한 작업을 수행하는 데 사용할 수 있습니다. 글로벌 훅은 반복적인 작업을 자동화하거나 애플리케이션의 여러 구성 요소에 걸쳐 특정 비즈니스 규칙을 강제 적용해야 할 때 특히 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메이지(Mage)의 글로벌 훅(Global Hooks)은 파이프라인 실행 중 두 가지 다른 시점에서 트리거될 수 있습니다:\n\n- 블록 완료 전(pre-completion of a Block): 해당 훅은 파이프라인의 특정 블록이 실행되기 전에 실행됩니다. 이를 통해 해당 블록이 데이터를 처리하기 전에 데이터 유효성 검사, 변환 또는 데이터 풍부화와 같은 작업을 수행할 수 있습니다.\n- 블록 완료 후(post-completion of a Block): 해당 훅은 파이프라인의 특정 블록 실행이 완료된 후에 실행됩니다. 이를 통해 해당 블록의 출력을 기반으로 외부 시스템 통합, 로깅, 감사 또는 하류 프로세스 트리거와 같은 작업을 수행할 수 있습니다.\n\n이 두 실행 지점을 활용하여, 글로벌 훅(Global Hooks)은 데이터 파이프라인의 기능을 확장하는 유연한 방법을 제공합니다. 특정 요구 사항에 따라 블록 실행 전후에 사용자 정의 코드를 실행할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 전역 후크의 필요성은 무엇인가요?\n\n개발자들에게 전역 후크는 애플리케이션의 기능을 확장하는 강력하고 유연한 방법을 제공하여 코드 재사용과 유지 보수성을 증진시킵니다. 특정 지점에서 사용자 정의 코드의 실행을 허용함으로써, 전역 후크는 다른 구성 요소 사이에서 반복적으로 동일한 논리를 수동으로 구현해야 하는 문제를 해결합니다. 이 중앙 집중식 접근 방식은 시간과 노력을 절약해주며, 일관성을 유지하고 개발자가 핵심 응용프로그램 논리에 집중할 수 있게 하면서 로깅, 보안 또는 외부 시스템 통합과 같은 사업을 가로지르는 문제를 쉽게 통합할 수 있도록 지원합니다.\n\n전역 후크는 여러 구성 요소나 모듈에 걸쳐 있는 로깅, 오류 처리, 인증 및 권한 부여와 같은 사업을 가로지르는 문제를 구현하는 데 유용할 수 있습니다. 또한, 중앙 집중점을 제공함으로써 외부 서비스나 API와의 통합을 용이하게 할 수 있습니다. 게다가, 전역 후크는 애플리케이션 내에서 비즈니스 규칙, 데이터 유효성 검사 및 변환 논리를 일관되게 강화할 수 있습니다. 많은 구성 요소와 데이터 흐름이 있는 복잡한 애플리케이션의 경우, 전역 후크는 공유 기능을 캡슐화함으로써 코드 재사용과 유지 보수성을 증진시킬 수 있습니다.\n\n후크를 만들기 전에, 개발자들은 전역 후크 설정을 켜놓았는지 확인해야 합니다. Mage Project Overview 페이지에서 왼쪽 탐색 메뉴에서 설정을 선택하십시오. 설정 페이지에 들어가서 전역 후크를 켭니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![마법의 마법을 발휘하라](/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_1.png)\n\n# 훅 만들기\n\n만약 여러분이 팀 내에서 다양한 파이프라인을 소유하고 있고, 파이프라인 이름에 우리의 이니셜을 접두어로 쓰고 싶어서 쉽게 식별할 수 있도록 하고 싶다면 어떻게 해야 할까요?\n\n- 먼저 mage를 열고 새 파이프라인을 만드세요\n- mage가 없다면 시작하는 방법에 대한 문서를 확인하세요\n- 파이프라인 편집기 페이지에 들어간 후, 아래 그림과 같이 데이터 로더 블록을 선택한 후, 파이썬 위에 마우스를 올리고 일반 (템플릿 없음) 옵션을 클릭하세요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_2.png\" /\u003e\n\n- 해당 블록이 로드되면 내용을 삭제한 뒤 아래 코드를 추가해 주세요.\n\n```js\nimport os\nfrom datetime import datetime\n\nfrom mage_ai.settings.repo import get_repo_path\n\n@data_loader\ndef load_data(*args, **kwargs):\n    with open(os.path.join(get_repo_path(), f'ping_{datetime.utcnow().timestamp()}'), 'w') as f:\n        f.write('')\n\n    payload = kwargs.get('payload', {})\n    name = payload.get('name')\n\n    payload['name'] = f'cff_{name}'\n\n    return payload\n```\n\n- 접두사 'cff'를 본인의 이니셜로 바꾸거나 코드를 그대로 둘 수 있습니다.\n- Shift + Enter를 눌러 블록을 실행하세요 (블록은 `본인의 이니셜_None`을 반환해야 합니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMage는 개발자들이 대부분의 요구 사항을 선택하거나 전환할 수 있는 사용하기 쉬운 Global Hooks 사용자 인터페이스를 개발했습니다. 주요 파이프라인 페이지의 왼쪽 네비게이션 팝업에서 글로벌 후크를 선택하여 Global Hooks UI로 이동해 봅시다.\n\n- + 새 글로벌 후크 추가 선택\n- Global Hooks UI로 이동하면 후크에 고유한 이름, 리소스 유형 및 작업 유형을 생성하세요.\n- 각 후크에는 Mage의 API 호출인 리소스 유형을 선택해야 합니다. 파이프라인 리소스를 선택하면 후크가 파이프라인 API 호출에 영향을 미칩니다.\n- 새 파이프라인을 만들 때도 이 후크를 사용하므로 작업 유형을 만들기로 선택합니다.\n\n![이미지](/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_3.png)\n\n- 위에서 언급한 대로 후크는 작업이 시작되기 전이나 후에 실행됩니다. 이 경우 파이프라인 이름 앞에 이니셜을 삽입하면 작업이 시작되기 전에 실행됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_4.png)\n\n- 다음으로 실행 드롭다운을 클릭하고 후크를 위해 파이프라인을 선택하세요.\n- 후크의 스냅샷을 생성하려면 '스냅샷 업데이트' 버튼을 클릭하세요. 스냅샷이 유효할 때 개발자들은 초록색 스냅샷 유효 표시를 볼 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_5.png)\n\n- 프로젝트에서 블록 이름으로 데이터를 추출할 블록을 추가하세요.\n- 병합될 데이터의 출력 유형을 선택하세요.\n- 마지막으로 화면 하단의 '변경 사항 저장'을 클릭하여 후크를 저장하세요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_6.png\" /\u003e\n\n- 이제 파이프라인 생성 페이지로 이동하여 + 새로 만들기 버튼을 클릭하세요.\n- 파이프라인을 위한 새로운 이름을 입력하세요.\n- 생성을 클릭하세요.\n\n\u003cimg src=\"/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_7.png\" /\u003e\n\n위에서 안내한 대로 Global Hook을 구성했다면, 데이터 로더 블록에서 제공한 이니셜로 모든 파이프라인 이름이 시작됨을 확인할 수 있을 것입니다. 회사는 파이프라인을 생성하고 소유하는 개발자들이 쉽게 파이프라인을 찾을 수 있도록 명명 규칙을 만들 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_8.png)\n\n# 결론\n\n마지막으로, 글로벌 후크는 개발자들에게 애플리케이션을 강화하고 사용자 정의 기능을 원활하게 통합할 수 있는 유연하고 확장 가능한 기능을 제공하는 강력한 기능입니다. 사용자 정의 코드를 애플리케이션 라이프사이클의 특정 시점에서 실행할 수 있도록 허용함으로써, 글로벌 후크는 코드 중복, 교차 관심사 및 외부 시스템 통합과 같은 일반적인 문제를 해결합니다. 데이터 유효성 검사 및 변환부터 로깅 및 모니터링까지, 글로벌 후크는 개발자가 프로젝트 전반에 걸쳐 일관되게 다양한 사용 사례를 실행할 수 있도록 합니다. 또한, 특정 구성 요소를 대상으로 하거나 비동기 실행과 같은 기능은 세밀한 제어와 성능 최적화를 제공합니다. Mage의 글로벌 후크에 대한 자세한 정보는 문서를 참조하십시오.\n","ogImage":{"url":"/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_0.png"},"coverImage":"/assets/img/2024-06-20-UnleashtheMagicofMageGlobalHooks_0.png","tag":["Tech"],"readingTime":5}],"page":"54","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"54"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>