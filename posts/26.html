<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>itposting</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///posts/26" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="itposting" data-gatsby-head="true"/><meta property="og:title" content="itposting" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///posts/26" data-gatsby-head="true"/><meta name="twitter:title" content="itposting" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-1532cbf2955c0c6a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="거대한 언어 모델 마스터하는 방법" href="/post/2024-06-22-MasterLargeLanguageModels"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="거대한 언어 모델 마스터하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-MasterLargeLanguageModels_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="거대한 언어 모델 마스터하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">거대한 언어 모델 마스터하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대형 언어 모델LLM 작동 방식 완벽 가이드 기초부터 고급까지" href="/post/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대형 언어 모델LLM 작동 방식 완벽 가이드 기초부터 고급까지" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대형 언어 모델LLM 작동 방식 완벽 가이드 기초부터 고급까지" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">대형 언어 모델LLM 작동 방식 완벽 가이드 기초부터 고급까지</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대형 언어 모델LLM의 미스테리 코딩은 잘하지만 숫자 세기는 어려운 이유" href="/post/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대형 언어 모델LLM의 미스테리 코딩은 잘하지만 숫자 세기는 어려운 이유" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대형 언어 모델LLM의 미스테리 코딩은 잘하지만 숫자 세기는 어려운 이유" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">대형 언어 모델LLM의 미스테리 코딩은 잘하지만 숫자 세기는 어려운 이유</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까" href="/post/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LangFlow와 Ollama로 코딩 없이 로컬 RAG 챗봇 만들기 방법" href="/post/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LangFlow와 Ollama로 코딩 없이 로컬 RAG 챗봇 만들기 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LangFlow와 Ollama로 코딩 없이 로컬 RAG 챗봇 만들기 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">LangFlow와 Ollama로 코딩 없이 로컬 RAG 챗봇 만들기 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="DSPy를 사용하여 메타데이터 추출하는 방법 - NER 스타일 가이드" href="/post/2024-06-22-UsingDSPyforextractingmetadataNERstyle"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="DSPy를 사용하여 메타데이터 추출하는 방법 - NER 스타일 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-UsingDSPyforextractingmetadataNERstyle_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="DSPy를 사용하여 메타데이터 추출하는 방법 - NER 스타일 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">DSPy를 사용하여 메타데이터 추출하는 방법 - NER 스타일 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="애니메이션 데이터셋으로 Gemma-2b-it 미세 조정하는 방법" href="/post/2024-06-22-FineTuningGemma-2b-itonAnimeDataset"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="애니메이션 데이터셋으로 Gemma-2b-it 미세 조정하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="애니메이션 데이터셋으로 Gemma-2b-it 미세 조정하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">애니메이션 데이터셋으로 Gemma-2b-it 미세 조정하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="LangChain의 새로운 도구, LangGraph 쉽게 설명하기" href="/post/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="LangChain의 새로운 도구, LangGraph 쉽게 설명하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="LangChain의 새로운 도구, LangGraph 쉽게 설명하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">LangChain의 새로운 도구, LangGraph 쉽게 설명하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI, 우리 눈이 필요한 이유" href="/post/2024-06-22-AINeedsOurEye"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI, 우리 눈이 필요한 이유" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-AINeedsOurEye_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI, 우리 눈이 필요한 이유" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">AI, 우리 눈이 필요한 이유</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="2024년 현실로 다가온 GenAI 기술과 그 영향" href="/post/2024-06-22-GenAIReality"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 현실로 다가온 GenAI 기술과 그 영향" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-22-GenAIReality_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 현실로 다가온 GenAI 기술과 그 영향" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><span class="writer">IT Posting</span></div><strong class="PostList_title__loLkl">2024년 현실로 다가온 GenAI 기술과 그 영향</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 22, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link posts_-active__YVJEi" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"거대한 언어 모델 마스터하는 방법","description":"","date":"2024-06-22 20:58","slug":"2024-06-22-MasterLargeLanguageModels","content":"\n\n![MasterLargeLanguageModels](/assets/img/2024-06-22-MasterLargeLanguageModels_0.png)\n\n인공 지능의 광활한 풍경 속에서 혁명적인 힘이 나타났습니다: 대규모 언어 모델(LLMs). 이러한 모델들은 그저 유행어가 아닙니다; 그들은 AI의 미래를 대표합니다. 인간과 유사한 텍스트를 이해하고 생성하는 능력은 그들을 주목받게 만들었으며, 오늘날 가장 흥미로운 그리고 역동적인 연구 분야 중 하나로 떠올랐습니다. 친구처럼 자연스럽게 응답하는 챗봇이나 인간의 글쓰기와 구분할 수 없을 정도로 텍스트를 자연스럽게 생성하는 컨텐츠 생성 시스템을 상상해보세요. 이러한 혁신적인 기술이 귀하의 흥미를 사로잡고 LLMs의 세계로 더 심층적으로 탐험하고 싶다면, 여기에 잘 오셨습니다.\n\n여러분의 여정을 돕기 위해 종합적인 자료 목록을 소개합니다. 이 컬렉션은 다음을 포함합니다:\n\n- 온라인 강의: 초급부터 고급 수준까지 안내해주는 구조화된 학습 경로에 접근하세요. 이 강의들은 LLMs의 이론적 기반, 실용적 구현, 그리고 실습 프로젝트를 다루며, 최고의 강사들로부터 배우고 LLM 기반 애플리케이션을 개발하고 배포하는 데 필요한 기술을 습득할 수 있습니다.\n- 워크샵과 학회: AI와 LLM에 전념하는 워크샵 및 학회에 참석하세요. 이러한 행사들은 전문가들로부터 배우고 동료들과 네트워킹하며 분야에서 최신 연구 및 혁신을 발견할 수 있는 기회를 제공합니다. 학습 경험을 향상시킬 다가오는 행사를 주목하세요.\n- 책과 유익한 기사: AI와 LLM 분야의 선도적인 전문가들이 저술한 종합적인 자료와 기사들을 탐색해보세요. 이러한 자료들은 LLMs를 숙달하는 데 필요한 깊은 지식, 사례 연구, 그리고 실용적인 조언을 제공합니다. LLM 개념, 응용 프로그램, 그리고 분야에서의 최신 발전사항에 대한 자세한 탐구에 몰두하세요. 이 기사들은 LLM의 기초부터 윤리적 영향, 그리고 미래 방향을 포함한 여러 주제를 다룹니다.\n- GitHub 저장소: LLMs를 실험해볼 수 있는 다양한 실무 프로젝트, 코드 샘플, 그리고 도구들을 탐색해보세요. 이러한 저장소들은 실무 경험과 LLMs가 실제 시나리오에서 어떻게 구축되고 사용되는지에 대한 통찰을 제공합니다. 사전 훈련된 모델, 세부 조정 스크립트, 그리고 혁신적인 애플리케이션을 찾아 공부하고 수정해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 자료는 LLM(Large Language Models)에 대한 기초부터 최신 기술까지 철저히 이해할 수 있도록 설계되었습니다. 학생, 연구원 또는 산업 전문가이든, 이 안내서를 통해 LLM을 숙달하는 데 필요한 지식과 도구를 제공할 것입니다.\n\n# 1. 기초 과정\n\n- 머신 러닝 전문화 — Coursera\n\n![LLM 이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n링크: Machine Learning 전문화 프로그램\n\n설명: Machine Learning 전문화는 DeepLearning.AI와 Stanford Online이 공동으로 개발한 기초 온라인 프로그램입니다. 이 초보자 친화적인 프로그램은 머신 러닝의 기본 개념을 가르치고 이러한 기술을 사용하여 현실 세계 AI 애플리케이션을 만드는 방법을 가르쳐줍니다.\n\n이 전문화 프로그램은 Stanford 대학에서 사업적 연구를 이끈 AI 비전가인 Andrew Ng가 가르치고 있습니다. 그는 Google Brain, Baidu, Landing.AI에서 중요한 연구를 이끌었으며 AI 분야를 발전시키기 위한 업적을 이루었습니다.\n\n이 3개 과정으로 이루어진 전문화는 Andrew가 선도적으로 개선한 머신 러닝 과정의 업데이트된 버전으로, 2012년에 시작되어 현재까지 4.8백만 명 이상의 학습자가 수강한 만족도 평가 4.9점을 받았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. Stanford CS229: Machine Learning Course YouTube by Andrew Ng\n\n![Stanford CS229](/assets/img/2024-06-22-MasterLargeLanguageModels_2.png)\n\nLink: [YouTube Playlist](https://www.youtube.com/playlist)\n\nDescription: 첫 강의인 Andrew Ng의 기계 학습 강의를 듣습니다. 이 강의는 기계 학습과 통계적 패턴 인식에 대한 폭넓은 소개를 제공합니다. 지도 및 비지도 학습, 학습 이론, 강화 학습 그리고 제어에 대해 배울 수 있습니다. 최근 기계 학습 응용 및 기계용 알고리즘을 설계 및 개발해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 딥 러닝 전문화 - Coursera\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_3.png)\n\n링크: [딥 러닝 전문화](링크 주소)\n\n설명: 딥 러닝 전문화는 딥 러닝의 능력, 도전, 결과를 이해하고 선두주자 AI 기술 발전에 참여할 수 있도록 준비하는 기초 프로그램입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 특화과정에서는 합성곱 신경망, 순환 신경망, LSTM, 트랜스포머 등의 신경망 아키텍처를 구축하고 훈련시키는 방법을 배울 것입니다. 또한 Dropout, BatchNorm, Xavier/He 초기화 등의 전략을 활용하여 이를 개선하는 방법도 배우게 됩니다. 이론적 개념과 해당 산업적 응용을 파이썬과 TensorFlow를 이용하여 숙달하고, 음성 인식, 음악 합성, 챗봇, 기계 번역, 자연어 처리 등과 같은 실제 사례에 대처할 준비를 하세요.\n\n4. Stanford CS224N: NLP with Deep Learning — YouTube\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_4.png)\n\n링크: Stanford CS224N: NLP with Deep Learning\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n설명: 이것은 NLP에 대한 최신 연구에 대한 철저한 소개와 지식의 보고서 대상지로, 귀하에게 지식의 보고서 대상지와 초심자를 위한 자료 보고서 대상지입니다. 본 강좌는 기계 학습 교수인 Christopher Manning Thomas M. Siebel 교수님에 의해 가르쳐지며, 언어학과 컴퓨터 과학 교수이자 스탠포드 인공지능 연구소 소장입니다.\n\n5. 허깅페이스 트랜스포머 강의 — 허깅페이스\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_5.png)\n\n링크: [허깅페이스 트랜스포머 강의](링크 주소)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDescription: 이 강좌는 HuggingFace 생태계의 라이브러리를 사용하여 NLP를 가르칩니다. HuggingFace의 다음 라이브러리의 내부 작업 및 사용법을 다룹니다:\n\n- Transformers\n- Tokenizers\n- Datasets\n- Accelerate\n\n저자 소개:\n\nAbubakar Abid는 스탠포드 대학에서 응용 기계 학습 분야에서 박사 학위를 받았습니다. 박사 과정 중에 그는 Gradio를 설립했는데, 이는 60만 개 이상의 머신 러닝 데모를 구축하는 데 사용되는 오픈 소스 Python 라이브러리입니다. Gradio는 Hugging Face에 의해 인수되었으며, 현재 Abubakar는 여기서 머신 러닝 팀 리드로 근무하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n매튜 카리건은 허깅페이스에서 머신러닝 엔지니어로 일하고 있습니다. 아일랜드 더블린에 살며, 이전에는 Parse.ly에서 ML 엔지니어로 일했으며, 그 전에는 트리니티 대학교에서 박사 후 연구원으로 일했습니다. 기존 구조를 확장하여 AGI에 도달할 것이라고 믿지 않지만, 로봇 불멸에 대한 높은 희망을 품고 있습니다.\n\n리산드르 데뷔는 허깅페이스에서 머신러닝 엔지니어로 일하고 있으며, 매우 초기 개발 단계부터 🤗 트랜스포머 라이브러리에 참여해왔습니다. 그의 목표는 매우 간단한 API를 통해 모두에게 자연어 처리를 액세스할 수 있도록 하는 것입니다.\n\n실반 구거는 허깅페이스의 연구 엔지니어이자 🤗 트랜스포머 라이브러리의 핵심 유지 보수자 중 한 명입니다. 이전에는 fast.ai에서 연구 과학자로 일하며, Jeremy Howard와 함께 '딥러닝 코더를 위한 fastai와 PyTorch'를 공동 저술했습니다. 그의 연구 주요 관심사는 깊은 학습을 보다 쉽게 접근할 수 있도록 하는 것으로, 한정된 자원 상에서 빠르게 모델을 교육할 수 있도록 설계하고 개선하는 기술을 고안하고 있습니다.\n\n다우드 칸은 허깅페이스에서 머신러닝 엔지니어로 일하고 있습니다. 뉴욕 출신이며, 뉴욕 대학교에서 컴퓨터 과학을 전공했습니다. 몇 년간 iOS 엔지니어로 일한 후 다우드는 동료 창업자들과 함께 Gradio를 시작했습니다. Gradio는 결국 허깅페이스에 인수되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLewis Tunstall은 Hugging Face의 기계 학습 엔지니어로, 오픈 소스 도구를 개발하고 널리 사용할 수 있도록 하는 데 중점을 두고 있습니다. 또한 O'Reilly의 책 \"Transformers와 함께하는 자연어 처리\"의 공동 저자입니다.\n\nLeandro von Werra는 Hugging Face의 오픈 소스 팀의 기계 학습 엔지니어이자 O'Reilly의 책 \"Transformers와 함께하는 자연어 처리\"의 공동 저자입니다. 그는 NLP 프로젝트를 전체 기고 학습 스택을 통해 작업하여 프로덕션 단계로 이끌어온 수 년 간의 산업 경험을 가지고 있습니다.\n\nChatGPT 개발자를 위한 프롬프트 엔지니어링 - Coursera\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n링크: ChatGPT 프롬프트 엔지니어링 코스\n\n설명: ChatGPT는 인기 있는 LLM 모델이며, 이 코스는 더 나은 응답 생성을 위한 효과적인 프롬프트 작성의 가장 좋은 방법과 필수 원칙을 공유합니다.\n\n## 2. LLM 특화 코스\n\n- LLM 대학 — Cohere\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_7.png)\n\n링크: LLM 대학교\n\n설명: Cohere는 LLM을 숙달하기 위한 전문 과정을 제공합니다. 이론적 측면에서 NLP, LLM 및 세부 아키텍처를 자세히 다루는 순차적 트랙은 초심자를 대상으로 합니다. 비순차적 경로는 내부 작동보다는 강력한 모델의 실용적인 응용 및 사용 사례에 관심이 있는 경험 많은 개인을 위한 것입니다.\n\n2. Stanford CS324: 대형언어모형 — Stanford 사이트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_8.png)\n\n링크: Stanford CS324: Large Language Models\n\n설명: 본 과정은 다양한 모델의 복잡성에 대해 심층적으로 다룹니다. 기본 원리, 이론적 구조, 윤리적 고려 사항 및 실용적 적용에 대해 다루며, 학생들은 이러한 모델에 대한 포괄적인 이해를 얻게 됩니다. 또한, 이 과정은 현실적인 시나리오에서 학습자들이 자신의 지식을 적용할 수 있는 실습 경험을 제공하여 이론과 실무 간의 간극을 메울 수 있도록 돕습니다.\n\n3. Princeton COS597G: Understanding Large Language Models — Princeton Site\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_9.png)\n\n링크: [대형 언어 모델 이해하기](링크)\n\n설명: 이는 근본적인 커리큘럼을 제공하는 대학원 수준의 과정으로, 심층 학습에 탁월한 선택입니다. BERT, GPT, T5 모델, 전문가 모델의 혼합, 검색 기반 모델 등과 같은 모델의 기술적 기반, 기능, 한계를 탐험하게 됩니다.\n\n4. 풀 스택 LLM 부트캠프 — 풀 스택\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![LLM Bootcamp](/assets/img/2024-06-22-MasterLargeLanguageModels_10.png)\n\n링크: [Full Stack LLM Bootcamp](링크)\n\n설명: 풀 스택 LLM 부트캠프는 산업에 적합한 종합적인 코스로, 참가자들이 LLM 애플리케이션을 개발하고 배포하는 데 필수적인 기술을 갖추도록 합니다. 커리큘럼에는 프롬프트 엔지니어링 기술, LLM의 기초, 배포 전략 및 사용자 인터페이스 디자인 등의 다양한 주제가 포함되어 있습니다. 이러한 핵심 영역을 다루면서 부트캠프는 참가자들이 현실 세계 상황에서 LLM 기반 애플리케이션을 성공적으로 개발하고 구현하는 데 필요한 지식과 전문 지식을 얻을 수 있도록 보장합니다.\n\n5. ETH Zurich: 대 언어 모델(LLM) - RycoLab\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_11.png)\n\n링크: ETH Zurich: Large Language Models\n\n설명: 이 새롭게 디자인된 강좌는 대규모 언어 모델 (LLMs)에 대해 심층적으로 탐구합니다. 이 강좌는 이러한 모델의 기초가 되는 확률적 원리, 신경망 모델링의 복잡성, 그리고 이를 훈련하는 과정에 대해 심층적으로 다룹니다. 또한, 이 강좌는 대규모 데이터셋을 처리하고 모델 성능을 개선하는데 필수적인 확장 기술을 다룹니다. 또한, LLM의 보안 및 잠재적 남용에 대한 중요한 토론이 포함되어 있어, 이러한 첨단 기술과 관련된 기술의 능력과 윤리적 고려 사항에 대한 광범위한 이해를 보장합니다.\n\n6. 대규모 언어 모델 파인 튜닝 — Coursera\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-22-MasterLargeLanguageModels_12.png)\n\nLink: [Fine Tuning Large Language Models](#)\n\nDescription: 파인튜닝은 대형 언어 모델 (LLMs)을 사용자의 특정 요구에 맞게 조정할 수 있는 기술입니다. 본 강좌를 수료하면, 파인튜닝을 적용해야 하는 시점과 데이터를 이 기술에 맞게 준비하는 방법, 그리고 새로운 데이터로 LLM을 훈련하는 과정 등을 이해하게 됩니다. 또한 파인튜닝 모델의 성능을 평가하는 방법과 목표를 달성하고 의도한 애플리케이션에서 효과적으로 작동할 수 있도록 보장하는 방법도 배울 것입니다.\n\n# 3. 기사 / 책\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- ChatGPT이 하는 일은 무엇이며 왜 작동하는 걸까? — 스티븐 월프램\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_13.png)\n\n링크: ChatGPT가 하는 일은 무엇이며 왜 작동하는 걸까?\n\n설명: 명성 높은 과학자인 스티븐 월프램은 ChatGPT의 기본 측면을 탐구하는 짧은 책을 썼습니다. 그는 신경망에서의 기원부터 변압기, 주의 메커니즘 및 자연어 처리를 통해 진보한 과정을 추적합니다. 이 책은 대형 언어 모델의 기능과 한계를 이해하고 싶은 사람들에게 강력히 추천됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. 시리즈 기사: 대형 언어 모델 — Jay Alammar\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_14.png)\n\n링크: 시리즈 기사: 대형 언어 모델\n\n설명: Jay Alammar의 블로그는 대형 언어 모델(LLM)과 트랜스포머를 공부하는 사람들에게 지식의 보물창고입니다. 그의 블로그는 시각화, 직관적 설명, 그리고 주제에 대한 포괄적인 다룸이 돋보여 독특합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. 프로덕션용 LLM 애플리케이션 구축 — Chip Huyen\n\n![LLM Applications for Production](/assets/img/2024-06-22-MasterLargeLanguageModels_15.png)\n\n링크: 프로덕션용 LLM 애플리케이션 구축\n\n설명: 이 기사에서는 LLMs를 프로덕션에 적용하는 도전을 논의합니다. 작업 조합성에 대한 통찰을 제공하며 유망한 사용 사례를 소개합니다. 실용적인 LLM에 관심 있는 모든 사람들에게 정말 가치 있는 내용입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4. 깃허브 저장소\n\n![이미지](/assets/img/2024-06-22-MasterLargeLanguageModels_16.png)\n\n1. Awesome-LLM ( 15.7k ⭐ )\n\n링크: [Awesome-LLM](https://github.com/username/Awesome-LLM)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n설명: ChatGPT를 중심으로 초대형 언어 모델(LLM)에 초점을 맞춘 논문, 프레임워크, 도구, 강좌, 튜토리얼 및 리소스가 정리된 컬렉션입니다.\n\n2. LLMsPracticalGuide ( 8.9k ⭐ )\n\n링크: 대규모 언어 모델에 대한 실용적인 가이드\n\n설명: LLMs의 방대한 영역을 탐색하는 실무자들을 돕는데 도움이 됩니다. ChatGPT를 다룬 연구 논문인 \"ChatGPT 및 그 이상에 대한 실무에서 LLMs의 힘을 이용하기: ChatGPT 및 이상에 대한 조사\"와 이 블로그를 기반으로 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. LLMSurvey (9.4k⭐)\n\n링크: LLMSurvey\n\n설명: 이것은 \"대형 언어 모델 설문\"이란 제목의 논문을 기반으로 한 설문 자료 및 리소스 모음입니다. 또한 GPT 시리즈 모델들의 기술적 진화를 보여주는 그림과 LLaMA에 대한 연구 작업의 진화 그래프도 포함되어 있습니다.\n\n4. Awesome Graph-LLM (1.4k⭐)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n링크: Awesome-Graph-LLM\n\n설명: 그래프 기반 기술과 LLMs의 교차점에 흥미를 가지는 사람들에게 유용한 소스입니다. 이 사이트는 이 신흥 분야를 탐구하는 연구 논문, 데이터셋, 벤치마크, 서베이 및 도구를 제공합니다.\n\n5. Awesome Langchain ( 7k ⭐ )\n\n링크: awesome-langchain\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n설명: LangChain은 LLM 프로젝트에 대한 빠르고 효율적인 프레임워크이며 이 저장소는 LangChain 생태계와 관련된 계획 및 프로젝트를 추적하는 중심입니다.\n\n# 5. 추가 자료 — 연구 및 설문 조사 논문\n\n![마스터 대형 언어 모델](/assets/img/2024-06-22-MasterLargeLanguageModels_17.png)\n\n- \"AIGC 시대의 ChatGPT에 대한 완전한 조사\" — LLM 초보자에게는 좋은 시작점입니다. ChatGPT의 기술, 응용 및 도전에 대해 포괄적으로 다룹니다.\n- \"대형 언어 모델 조사\" — 최근 LLM의 발전을 다루며 사전 훈련, 적응 조정, 활용 및 용량 평가의 네 가지 주요 측면을 특히 다룹니다.\n- \"대형 언어 모델의 도전과 응용\" — LLM의 도전 과제와 성공적인 적용 영역을 논의합니다.\n- \"Attention Is All You Need\" — Transformer는 GPT 및 기타 LLM의 기초를 이루며, 이 논문은 Transformer 아키텍처를 소개합니다.\n- \"주석이 달린 Transformer\" — Transformer 아키텍처에 대해 자세히 설명하고 주석이 달린 하버드 대학의 자료이며, 이는 여러 LLM에 기본적인 개념입니다.\n- \"설명된 Transformer\" — 복잡한 개념을 이해할 수 있도록 도와주는 시각 안내서로 Transformer 아키텍처를 깊이 파악할 수 있습니다.\n- \"언어 이해를 위한 Deep Bidirectional Transformer 사전 훈련인 BERT\" — 이 논문은 BERT를 소개하며, 이는 다수의 자연어 처리(NLP) 작업에 대한 새로운 기준을 제시하는 매우 영향력 있는 LLM입니다.","ogImage":{"url":"/assets/img/2024-06-22-MasterLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-06-22-MasterLargeLanguageModels_0.png","tag":["Tech"],"readingTime":11},{"title":"대형 언어 모델LLM 작동 방식 완벽 가이드 기초부터 고급까지","description":"","date":"2024-06-22 20:56","slug":"2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero","content":"\n\n제 ‘제로 투 히어로’ 시리즈의 두 번째 기사입니다. 이 기사에서는 대형 언어 모델 (LLM)이 작동하는 방식을 쉽게 설명해 드릴 예정입니다.\n\n# LLM 작동 방식\n\n먼저 문서 완성 모델이 어떻게 작동하는지 살펴봅시다:\n\n![이미지](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사용자 프롬프트:\n\n```js\n바나나는\n```\n\n모델 응답:\n\n```js\n납작하고 먹을 수 있는 과일\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼, 문서 생성기 모델은 이렇게 작동합니다:\n\n![image](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_1.png)\n\n사용자 프롬프트:\n\n```js\n나는 새 차를 사고 싶어요\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"테이블 태그를 Markdown 형식으로 바꿔주세요.\"\n\n위의 두 가지 사항 사이의 차이점을 주목해주세요.\n\n첫 번째 모델은 문서 완성기로, 다음 문자가 될 가능성이 가장 높은 것을 찾아서 프롬프트만 완성합니다. 이 모델은 인터넷 데이터의 일부분을 학습한 것으로, 기본 모델이라고 불립니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 번째 모델은 문서 생성기입니다. 이 모델은 프롬프트 질문을 기반으로 한 인간과 유사한 응답을 생성합니다. 이것은 ChatGPT 모델입니다.\n\nChatGPT 모델은 프롬프트 질문을 기반으로 한 응답을 생성할 수 있는 추론 모델입니다. 저는 이 모델이 99% 베이스 모델이지만 두 가지 추가 단계인 파인튜닝 단계와 인간 피드백에서의 강화 학습 단계가 있습니다.\n\n# 사전 훈련: 베이스 모델\n\n이것은 인공 지능 혁명의 핵심이자 실제 마법이 일어나는 곳입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델을 훈련하는 것은 많은 데이터를 제공하고 그것으로부터 배우는 과정입니다.\n\nGPT-3 논문에 설명된 대로, 기본 모델은 인터넷 데이터의 대량을 바탕으로 훈련됩니다. 그것은 여러분과 같은 일반인에게는 쉬운 일이 아닙니다. 데이터를 획득하는 것 뿐만 아니라 GPU 및 TPU와 같은 많은 컴퓨팅 파워도 필요합니다.\n\n하지만 걱정 마세요. 우리 자신의 컴퓨터에서 작은 GPT 모델을 훈련하는 방법을 여전히 배울 수 있습니다. 다음 주제에서 어떻게 하느지 보여 드리겠습니다.\n\nLLM 훈련 뒤에 있는 혁신은 Transformer 아키텍처의 도입에 있습니다. 이를 통해 모델은 광범위한 데이터에서 배우면서 입력의 서로 다른 부분 간의 중요한 맥락적 관골을 유지할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 연결을 유지함으로써 모델은 제공된 문맥을 기반으로 새로운 통찰력을 효과적으로 추론할 수 있습니다. 이 문맥은 개별 단어, 문장, 문단 또는 그 이상일 수 있습니다. 이 능력을 통해 LLM 훈련은 자연어 처리 및 생성 작업에 대한 새로운 기회를 열어주어 기계가 인간의 의사 소통에 더 잘 이해하고 응답할 수 있도록 합니다.\n\n기본 모델을 훈련하는 데 사용된 트랜스포머 아키텍처는 아래에 표시됩니다:\n\n\n![LLM](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_2.png)\n\n\n이는 일부 이전 및 새로운 기법을 사용하여 훈련된 신경망 모델입니다: 토큰화, 임베딩, 위치 인코딩, 피드포워드, 정규화, 소프트맥스, 선형 변환 및 가장 중요한 것은 멀티헤드 어텐션입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 부분은 당신과 저 모두가 대부분 관심을 가지고 있는 부분이에요. 우리는 아키텍처 뒤의 아이디어와 교육 과정이 정확히 어떻게 이루어졌는지 명확하게 이해하고 싶어해요. 그래서 다음 글부터는 논문, 코드, 그리고 기본 모델을 훈련하는 데 사용된 수학적인 부분을 자세히 살펴볼 거에요.\n\n# Fine-tuning: 어시스턴트 훈련하기\n\nFine-tuning은 아주 똑똑한 구현이에요. 아마 OpenAI에 의해 처음 수행된 것 같아요. 아이디어는 아주 간단하지만 지능적으로 작동해요: 인간 라벨러를 고용하여 수많은 Q\u0026A 대화쌍을 생성하게 해요(예: 10만 대화). 그런 다음 모델에 대화쌍을 주입시켜 이를 통해 학습시키는 거죠.\n\n이 과정을 Fine-tuning이라고 해요. 그 10만 개의 대화 샘플 데이터가 모델에 훈련되면 뭔 일이 벌어질까요? 모델이 인간처럼 응답하기 시작할 거에요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 샘플 레이블 대화를 살펴보겠습니다:\n\n```js\n인간 레이블된 Q\u0026A\n\nQ: 이름이 뭐에요?\nA: 제 이름은 존입니다.\n```\n\n```js\n인간 레이블된 Q\u0026A\n\nQ: 중국의 수도는 무엇인가요?\nA: 중국의 수도는 북경입니다.\n```\n\n```js\n인간 레이블된 Q\u0026A\n\nQ: 영화 타이타닉의 줄거리를 요약해주세요.\nA: 영화 타이타닉은 바다에서 침몰하는 배에 관한 이야기입니다.\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n와, 이 샘플 Q\u0026A들은 우리가 서로 대화하는 방식을 조롱하고 있는 것 같아요.\n\n모델에게 이러한 응답 스타일을 가르쳐주면, 관련된 맥락에 대한 응답 확률이 매우 높아지며 사용자의 질문에 응답할 수 있게 될 거예요. 모델을 여러 대화 스타일로 훈련시킴으로써, 관련성이 높고 맥락에 맞는 응답을 제공할 가능성이 높아집니다.\n\n이것이 언어 모델이 얼마나 지적이고 인간 같아 보일 수 있는지; 실제 대화의 리듬과 패턴을 모방하면, 사용자와의 대화를 흐름 있게 시뮬레이션할 수 있어요.\n\n우리는 여기서 어시스턴트 모델을 얻었다고 말할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 기본 모델을 사전 훈련에서 보조 모델을 미세 조정하는 과정 중 일부 강조 사항을 보여주는 다이어그램입니다:\n\n![다이어그램](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_3.png)\n\n# RLHF: 인간 피드백으로부터 강화 학습\n\n2022년 1월, OpenAI는 언어 모델을 지시 사항을 따르도록 조정하는 연구를 발표했습니다. 블로그 게시물에서 그들은 모델이 인간 피드백으로 더욱 미세하게 조정된 방법을 설명했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_4.png)\n\n이 부분은 조금 까다로울 수 있어요. 아이디어는 모델이 인간 피드백에서 배울 수 있게 하는 것입니다. 약 10만 개의 레이블이 지정된 Q\u0026A 쌍을 제공하는 대신, 사용자의 프롬프트와 모델 응답을 수집한 다음 사람들이 순위 매기도록 합니다. 이 순위 정리된 대화를 가장 원하는 Q\u0026A 샘플로 삼아 다시 모델에 피드하고 전반적인 성능을 향상시키도록 합니다.\n\n이 프로세스는 OpenAI의 블로그에서 소개되었습니다.\n\n우리 모델을 보다 안전하고 유용하며 일치하게 만들기 위해 기존 기술인 인간 피드백 강화 학습 (RLHF)을 사용합니다. API에 고객이 제출한 프롬프트에서, 우리의 레이블러는 원하는 모델 행동을 시연하고 모델에서 여러 출력을 순위 매깁니다. 그런 다음 우리는 이 데이터를 사용하여 GPT-3를 세밀하게 조정합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기에 베이스 모델 대 미세 조정/RLHF 응답 비교가 있어요:\n\n![Comparison](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_5.png)\n\n미세 조정 및 RLHF 없이 모델은 단순히 문서 완성기일 뿐임을 확인할 수 있어요.\n\n# 프롬프트 엔지니어링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 세밀한 조정과 RLHF를 사용하더라도 모델은 여전히 원하는 응답을 얻기 위해 도움이 필요합니다. 그리고 이것이 바로 프롬프트 엔지니어링이 필요한 이유입니다.\n\n간단히 말해, 우리는 모델로부터 원하는 응답을 얻기 위해 프롬프트를 신중하게 디자인할 수 있습니다 (때로는 세밀한 조정 없이도).\n\n수학과 코드에 너무 깊이 들어가지 않으려는 경우, 프롬프트 엔지니어링이 주목할 가치가 있는 방법입니다. 왜냐하면 더 나은 프롬프트를 입력함으로써 LLM 모델에서 최상의 결과를 얻을 수 있기 때문입니다.\n\n이제 예시를 살펴보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nThe sky is\n```\n\nblue.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 테이블을 Markdown 형식으로 변경해 주세요.\n\n| 이름 | 나이 | 성별 |\n|------|-----|-----|\n| 민수 | 25 | 남성 |\n| 지영 | 22 | 여성 |\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n낮에는 파란색이고 밤에는 어두운 색입니다.\n```\n\n프롬프트에 일부 지침을 포함하면 모델이 무엇을 해야 하는지와 어떻게 응답해야 하는지 알 수 있습니다.\n\n또 다른 흥미로운 예제를 살펴보겠습니다:\n\n프롬프트:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n6살 때 내 언니 나이의 절반이었어. 지금 나는 70살, 내 언니 몇 살일까? \n\n\n결과:\n\n```js\n35\n```\n\n답은 틀렸어요. 정답은 67살이에요. 모델은 질문을 이해하는 것 같지만 논리적 추론 대신 수학 계산을 참고한 것 같네요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n미세 조정 및 RLHF 없이도 프롬프트에 더 많은 예제 지침을 추가하는 것만으로도 올바른 답을 얻을 수 있습니다:\n\n프롬프트:\n\n```js\nQ: 수목원에는 15 그루의 나무가 있습니다. 오늘 나무원 작업자들이 나무를 심을 것입니다. 작업을 마치고 나면, 21 그루의 나무가 될 것입니다. 나무원 작업자들은 오늘 몇 그루의 나무를 심었습니까?\nA: 우리는 15 그루의 나무로 시작합니다. 나중에는 21 그루의 나무가 있습니다. 차이는 그들이 심은 나무의 수여야 합니다. 따라서, 그들은 21 - 15 = 6 그루의 나무를 심었을 것입니다. 정답은 6입니다.\nQ: 주차장에 차가 3대 있고 더 2대의 차가 도착한다면, 주차장에는 몇 대의 차가 있습니까?\nA: 주차장에는 이미 3대의 차가 있습니다. 2대가 추가로 도착합니다. 이제 차가 3 + 2 = 5대 있습니다. 정답은 5입니다.\nQ: 리아는 초콜릿 32개를 가지고 있었고, 그녀의 여동생은 42개를 가지고 있었습니다. 그들이 35개를 먹었다면, 두 사람이 남은 총 조각 수는 얼마입니까?\nA: 리아는 초콜릿 32개를 가지고 있었고, 리아의 여동생은 42개를 가지고 있었습니다. 이는 원래 32 + 42 = 74개의 초콜릿이 있었음을 의미합니다. 35개가 먹혔습니다. 그래서 총으로 계산하면 74 - 35 = 39개의 초콜릿이 남게 됩니다. 정답은 39입니다.\nQ: 제이슨은 막대사탕 20개를 가지고 있었습니다. 그는 덴니에게 일부 막대사탕을 주었습니다. 지금은 제이슨이 막대사탕 12개를 가지고 있습니다. 제이슨이 덴니에게 몇 개의 막대사탕을 주었습니까?\nA: 제이슨은 막대사탕 20개를 가지고 있었습니다. 지금은 12개밖에 없으므로, 나머지를 덴니에게 줬을 것입니다. 따라서, 덴니에게 준 막대사탕 수는 20 - 12 = 8개입니다. 정답은 8입니다.\nQ: 숀은 5개의 장난감을 가지고 있습니다. 크리스마스 때, 엄마와 아빠로부터 각각 2개의 장난감을 받았습니다. 지금은 몇 개의 장난감이 있습니까?\nA: 그는 5개의 장난감을 가지고 있습니다. 엄마로부터 2개를 받았으므로, 이후 그는 5 + 2 = 7개의 장난감을 가지고 있습니다. 그리고 아빠로부터 또 2개를 받았으므로 총으로 계산하면 7 + 2 = 9개의 장난감이 있습니다. 정답은 9입니다.\nQ: 서버실에는 컴퓨터가 9대 있었습니다. 월요일부터 목요일까지 매일 추가로 5대의 컴퓨터가 설치되었습니다. 지금 서버실에는 몇 대의 컴퓨터가 있습니까?\nA: 월요일부터 목요일까지는 4일이 있습니다. 매일 5대의 컴퓨터가 추가되었습니다. 이는 총 4 * 5 = 20대의 컴퓨터가 추가되었음을 의미합니다. 처음에는 9대의 컴퓨터가 있었으므로, 현재 서버실에는 9 + 20 = 29대의 컴퓨터가 있습니다. 정답은 29입니다.\nQ: 마이클은 골프공 58개를 가지고 있습니다. 화요일에 23개의 골프공을 잃었습니다. 수요일에 또 2개를 잃었습니다. 수요일 종료 시에는 몇 개의 골프공이 있습니까?\nA: 마이클은 처음에 58개의 골프공을 가지고 있었습니다. 화요일에 23개를 잃었으므로, 그 후에는 58 - 23 = 35개의 골프공을 가지고 있습니다. 수요일에 2개를 더 잃었으므로, 이제 35 - 2 = 33개의 골프공이 있습니다. 정답은 33입니다.\nQ: 올리비아는 $23을 가지고 있습니다. 그녀는 각각 $3에 5개의 베이글을 샀습니다. 그녀가 남은 돈은 얼마입니까?\nA: 그녀는 각각 $3에 5개의 베이글을 샀습니다. 이는 총 $15를 소비한 것을 의미합니다. 그녀는 $8을 남겼습니다.\nQ: 제가 6살이었을 때, 내 여동생은 내 나이의 절반이었습니다. 지금 저는 70살입니다. 내 여동생은 몇 살입니까?\nA:\n```\n\n결과:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n6살 때 내 언니는 저의 나이의 절반, 즉 3살이어서 3살이었습니다. 이제 저는 70살이므로, 언니는 70 - 3 = 67살입니다. 정답은 67입니다.\n```\n\noutput 2:\n\n```js\n이야기의 주인공이 6살일 때, 그의 언니는 그의 나이의 절반인 3살이었습니다. 이제 주인공이 70살이 되었으므로, 언니는 70 - 3 = 67세가 될 것입니다. 정답은 67입니다.\n```\n\n두 번째 답변도 정확합니다! 우리는 문제에 대한 논리적 설명 예시를 추가하여 모델이 질문을 이해하고 올바르게 답변할 수 있도록 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 예시는 Wang 등(2022)에 의해 소개된 것으로, 최종 답안을 계산하는 과정은 몇 단계로 이루어져 있습니다.\n\n강력한 프롬프트는 모델이 수학 문제 해결이나 텍스트 요약과 같은 복잡한 작업을 수행하는 데 도움이 될 수 있습니다. 따라서 프롬프트 엔지니어링은 LLM 생태계의 매우 중요한 역할을 합니다.\n\n프롬프트 엔지니어링에 대해 더 알고 싶다면, 여기 좋은 프롬프트 가이드 튜토리얼이 있습니다.\n\n# 요약\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기까지 읽어주셔서 정말 감사합니다. 특히 LLM 세계에 처음 접하는 분들에게는 모든 정보를 소화하는 데 시간이 걸릴 것이라고 확신합니다.\n\n이제 기본 개념과 배경 정보에 대해 충분한 내용을 다루었다고 믿습니다. 이제 우리 자신의 대형 언어 모델을 구축하기 위한 준비를 시작할 때입니다. 이론에는 지겨워했으니, 다음 기사에서는 Transformers 아키텍처의 중요한 구성 요소로 나아갈 것입니다.","ogImage":{"url":"/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_0.png"},"coverImage":"/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_0.png","tag":["Tech"],"readingTime":8},{"title":"대형 언어 모델LLM의 미스테리 코딩은 잘하지만 숫자 세기는 어려운 이유","description":"","date":"2024-06-22 20:54","slug":"2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount","content":"\n\n\u003cimg src=\"/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_0.png\" /\u003e\n\n언어 학습 모델(LLMs)은 인공 지능 분야에서 강력한 도구로 등장했습니다. 인간과 유사한 텍스트를 이해하고 생성할 수 있는 놀라운 능력을 갖추고 있습니다. 이러한 모델은 질문에 대한 답변, 텍스트 생성, 복잡한 쓰기 및 분석 작업을 지원하는 등 다양한 작업에서 놀라운 능력을 발휘했습니다. 많은 측면에서, LLMs은 지능적인 언어 동반자로 작용하여 다양한 도메인에서 사용자에게 가치 있는 지원을 제공합니다.\n\n그러나 그들이 놀라운 성과를 보이는 가운데, LLMs은 특정 문제를 해결하기 위해 코드를 생성할 수 있지만, 가끔은 자체적으로 보이기에 간단한 작업을 수행하는 데 어려움을 겪기도 합니다.\n\n이 역설은 LLMs의 본질과 그들의 근본적인 추론 과정에 대해 흥미로운 질문을 던집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n본 문서에서는 이 모순을 강조하는 매력적인 사례 연구를 제시할 것입니다. 특정 작업을 위한 코드를 생성하도록 LLM에 요청한 실험을 살펴보겠습니다 - 주어진 텍스트에서 특정 문자의 발생 횟수를 세는 것입니다. LLM은 코드 솔루션을 성공적으로 작성할 수 있지만, 동일한 작업을 직접 실행하려고 할 때 어려움에 직면합니다.\n\n본 탐구를 통해 LLM의 복잡성과 언어 추론에 대해 알아보고자 합니다. 코딩 능력과 자가 실행 사이의 차이에 기여하는 요소들을 조사하고, LLM의 개발 및 응용에 대한 함의를 논의할 것입니다.\n\n# 실험\n\nLLM의 흥미로운 모순을 탐구하기 위해, 특정 작업을 처리하는 능력과 한계를 드러내는 실험을 설계했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실험은 LLM에 텍스트 기반 도전 과제를 제공하고 생성된 코드를 생성하고 과제를 직접 실행하는 성능을 관찰하는 것을 중심으로 진행됩니다.\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_1.png)\n\nLLM에게 과제 제시하기\n\nLLM에게 제시된 과제는 세 가지 주요 구성요소로 구성되어 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 텍스트의 총 문자 수 세는 것: 첫 번째 목표는 주어진 텍스트 샘플 내의 총 문자 수를 결정하는 것입니다. 이는 모든 알파벳 및 숫자, 공백, 그리고 구두점을 포함합니다. LLM은 텍스트의 전체 문자 길이를 정확하게 세는 것으로 예상됩니다.\n\n- 문자 \"a\"의 발생 횟수 세기: 두 번째 목표는 텍스트 분석의 더 구체적인 측면에 집중합니다. LLM은 주어진 텍스트 내에서 소문자 \"a\"의 발생을 식별하고 세는 것으로 요청됩니다. 이는 모델이 대문자와 소문자 문자를 구별하고 \"a\"가 나타나는 횟수를 정확하게 계산해야 합니다.\n\n- \"a\" 발생을 강조하고 센 원본 텍스트 생성: 세 번째 목표는 이전 두 작업을 결합하고 시각화 구성 요소를 추가합니다. LLM은 \"a\"의 각 발생을 강조하고 해당 수를 제공하면서 원본 텍스트를 생성하도록 지시됩니다. 예를 들어, 텍스트에서 \"a\"가 세 번 나타나면 출력은 텍스트 내 \"a(1)\", \"a(2)\", \"a(3)\"와 같이 표시해야 합니다.\n\nLLM에 이 세 가지 목표를 제시함으로써, LLM이 문자 및 문자 수준에서 텍스트를 분석하고 조작하는 능력을 평가하고자 합니다. 이 실험은 LLM이 작업 요구 사항을 이해하고 적절한 코드 솔루션을 생성하며 직접 작업을 수행하는 능력을 강조합니다.\n\n다음 섹션에서는 이 실험에 대한 LLM의 응답을 탐색하며, 코드 생성 기능 및 지정된 작업의 자가 수행 능력을 평가할 것입니다. 이 분석을 통해 LLM의 기저 메커니즘에 대한 통찰을 얻고, 코딩 능력과 직접 작업 실행에 대한 제약 사항에 대한 파라독스에 빛을 발향하고자 합니다.\n\nLLM에 코드 솔루션을 제공하도록 요청하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM의 코딩 능력을 평가하기 위해 주어진 작업에 대한 코드 솔루션을 생성하는 프롬프트를 준비했습니다. LLM은 실험에서 설명된대로 문자 계산, \"a\" 문자 계산 및 텍스트 강조 테스크를 정확하게 수행하는 기능적인 코드 스니펫을 생성하기를 기대했습니다.\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_2.png)\n\nLLM으로부터 코드 솔루션을 받은 후, 구조, 논리 및 구문을 주의 깊게 검토했습니다. 생성된 코드가 작업의 세 가지 구성 요소를 정확하게 다루며 필요한 프로그래밍 규칙을 따르는지를 평가했습니다.\n\n결과물의 형식이 요청한 대로 되지 않아 몇 번의 수정을 거쳤지만 솔직히 말해서 제공한 지시사항이 많지 않았습니다. 이것이 최종 결과물이었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_3.png)\n\n나는 이 테스트에 사용한 Claude 3 Opus (LLM)가 문제를 이해하고 일관되고 효과적인 코드를 생성할 수 있는 능력을 강조한 작업의 설명과 이유를 제공했습니다.\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_4.png)\n\n제시된 2가지 예제를 보면 결과가 실제로 옳았음을 알 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_5.png)\n\nLLM의 문자 계산 능력을 테스트 중입니다.\n\nLLM으로부터 코드 솔루션을 얻은 후, 동일한 문제를 프롬프트로 테스트하기로 했습니다. 코드 생성 단계에서 사용된 동일한 텍스트 샘플을 LLM에 제공하고, 생성된 코드에 의존하지 않고 문자 수 세기, \"a\" 문자 수 세기 및 텍스트 강조 테스크를 직접 수행하도록 요청했습니다.\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_6.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n작업을 위해 코드를 생성할 수 있는 LLM에 있어서 문자를 정확히 세는, \"a\"라는 글자의 발생을 식별하는 데 어려움을 겪었거나 텍스트 내에서 \"a\"를 제대로 강조하고 세는 데 어려움을 겪고 있습니다.\n\n응답에서 볼 수 있듯이, \"a\"라는 글자가 10번 발생했다고 쓰여 있지만 실제로는 17번 발생했음을 알 수 있습니다.\n\nLLM의 코딩 능력과 스스로 실행하는 능력 사이의 이러한 불일치는 실험의 핵심에서 역설을 더욱 부각시킵니다. 이는 LLM의 근본적인 추론 과정과 글자 수준에서 직접 텍스트를 조작하고 분석하는 능력에 대한 의문을 던집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM의 성능을 코드 생성 및 직접 작업 실행 두 가지 측면에서 살펴보며, 언어 모델링의 복잡성과 LLM이 문자 수준 추론을 필요로 하는 간단한 작업에 직면했을 때 발생하는 어려움에 대해 알아보려고 합니다.\n\n## 역설 이해\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_8.png)\n\nLLM에서의 토큰 기반 추론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실험에서 관측된 역설을 이해하기 위해서는 LLMs가 어떻게 언어를 처리하고 이해하는지를 이해하는 것이 중요합니다.\n\nLLMs는 \"토큰\"이라 불리는 기본 단위에서 작동합니다. 토큰은 일반적으로 모델이 인식하고 처리하는 단어, 하위단어 또는 문자입니다. 입력 텍스트가 LLM에 제공되면 먼저 토큰화되어, 이러한 개별적인 토큰으로 분해됩니다.\n\n언어 이해와 생성을 위한 효율적인 토큰 기반 추론: 토큰 기반 추론을 통해 LLMs는 효율적으로 인간과 유사한 텍스트를 처리하고 생성할 수 있습니다.\n\nLLMs가 토큰과 함께 작업함으로써 언어 내에서 패턴, 관계 및 종속성을 포착하고 학습할 수 있습니다. 이 접근법을 통해 LLMs는 맥락을 이해하고 일관된 응답을 생성하며 다양한 언어 작업을 높은 능률로 수행할 수 있습니다. 토큰 기반 추론은 LLMs가 자연어 상호작용에 참여하는 핵심입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토큰 기반 추론의 한계\n\n문자 수준 작업 다루기에 대한 도전: 토큰 기반 추론은 많은 언어 작업에 대해 매우 효과적이지만, 문자 수준 작업을 처리할 때 어려움을 겪을 수 있습니다.\n\n내가 진행한 실험에서 LLM은 문자를 정확하게 계산하고 텍스트 내에서 특정 문자 발생을 식별하는 데 어려움을 겪었습니다. 이 한계는 모델이 주로 개별 문자 수준이 아닌 토큰 수준에서 언어를 이해하고 생성하는 데 초점을 맞추기 때문에 발생합니다.\n\n특정 시나리오에서 문자 수준 정밀도의 필요성: 실험에서 제시된 것과 같이 특정 작업은 정확한 문자 수준 조작과 분석을 필요로 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문자 수를 세거나 특정 글자의 발생을 식별하고 텍스트 내에서 강조하는 것은 토큰 기반 추론이 제공하지 못하는 세밀함을 요구합니다.\n\n이러한 시나리오는 LLM이 토큰 수준 처리를 넘어 개별 문자에 대해 더 정교한 제어를 가능하게 하고 처리 능력을 개발해야 한다는 필요성을 강조합니다.\n\n코딩 능력과 자체 실행 사이의 괴리\n\nLLM의 코드 이해 및 생성 능력: 실험의 흥미로운 측면 중 하나는 주어진 작업에 대한 코드 생성 능력이었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코든 솔루션을 제공하라는 요청에 대해, LLM은 문제를 이해하고 기능적인 코드 스니펫을 생성했습니다. 이는 모델이 프로그래밍 개념, 구문 및 논리를 이해하고 지정된 요구 사항을 해결하는 코드를 생성할 수 있는 능력을 보여줍니다.\n\n내부적으로 생성된 코드를 확인하고 실행하는 것에 어려움이 있습니다. 그러나 실험은 LLM의 코딩 능력과 생성된 코드를 자체 실행하는 능력 사이에 연결이 없음을 보여주었습니다.\n\n코드 솔루션을 성공적으로 생성했지만, LLM은 문자 카운팅 및 텍스트 강조 작업을 직접 수행하는 데 어려움을 겪었습니다. 이는 모델의 코드 이해와 생성 능력이 내부적으로 코드의 기능을 실행하고 확인하는 능력과 반드시 연결되지 않음을 시사합니다.\n\n실험에서 강조된 이 모순은 LLM의 추론 프로세스의 본질과 토큰 기반 방법의 한계에 대한 중요한 질문을 제기합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드 능력과 자체 실행 간의 간극을 좁히기 위해 추가 연구 및 개발이 필요함을 강조하며, LLM이 코드를 생성하는 능력뿐만 아니라 필요한 경우 문자 수준에서 효과적으로 추론하고 작동할 수 있도록 하는 것이 중요합니다.\n\n다음 섹션에서는 이러한 제한 사항을 해결하고 문자 수준 작업을 더 정밀하고 일관성 있게 처리할 수 있는 LLM의 잠재적인 미래 방향과 발전을 탐구할 것입니다.\n\n# 전망: LLM의 진화\n\n![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n미래 LLM이 문자 수준 추론을 다루는 능력을 개선할 가능성에 대해 논할 수 있습니다.\n\n모델 아키텍처와 훈련 기술의 발전: 자연어 처리 분야가 계속 발전함에 따라, 미래 LLM이 문자 수준 추론의 제약을 극복할 수 있는 엄청난 가능성이 있습니다.\n\n연구자와 개발자들은 LLM이 문자 수준 정밀도를 요구하는 작업을 다루는 능력을 향상시킬 수 있는 새로운 모델 아키텍처와 훈련 기술을 적극적으로 탐구하고 있습니다.\n\n이러한 발전은 문자 수준 임베딩, 주의 메커니즘 또는 다른 기술을 통합하여 LLM이 토큰 및 문자 수준에서 효과적으로 추론할 수 있도록 하는 것을 포함할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문자 수준의 추론과 토큰 기반 처리의 통합: 미래 LLM에 대한 한 가지 유망한 방법은 문자 수준의 추론 기능을 기존의 토큰 기반 처리와 통합하는 것입니다. 토큰 수준과 문자 수준의 추론 두 가지 강점을 활용한 혼합 접근 방식을 개발함으로써, LLM은 언어에 대한 보다 포괄적인 이해를 달성할 수 있습니다.\n\n이러한 통합은 LLM이 효율적인 토큰 기반 처리를 유지하면서 필요할 때 문자 수준의 세부 내용을 탐구할 수 있는 능력을 갖게 해주어, 더 정확하고 미묘한 언어 이해와 생성이 가능해집니다.\n\n토큰 기반 효율성과 문자 수준 정확성을 균형있게 유지하는 중요성.\n\nLLM이 계속 발전함에 따라, 토큰 기반 효율성과 문자 수준 정확성 사이의 균형을 맞추는 것이 중요해질 것입니다. 토큰 기반 추론이 여러 언어 작업에 매우 효과적이라는 것은 확인되었지만, 문자 수준의 정확성에 대한 필요성도 간과해서는 안 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n미래 LLM들은 토큰 기반 처리의 강점을 활용하면서 필요할 때 문자 수준의 추론 능력을 통합하여 조화롭게 통합하도록 노력해야 합니다. 이 균형은 LLM이 효율성과 정확성을 갖추며 다양한 어플리케이션과 사용 사례의 다양한 요구에 부응할 수 있도록 할 것입니다.\n\nGPT-5 및 Claude 4와 같은 LLM의 지속적인 발전\n\n기대되는 문자 수준 추론 능력의 향상: GPT-5 및 Claude 4와 같은 고급 LLM의 개발이 진행됨에 따라, 이러한 모델들은 문자 수준 추론 능력에서 상당한 개선이 예상됩니다.\n\n각 반복에서, LLM은 정확한 문자 수준 조작과 분석이 필요한 작업을 처리하는 데 보다 능숙해질 것으로 예상됩니다. 미래 모델의 개발에서 문자 수준 추론의 통합은 토큰 기반 처리와 함께 주요 초점이 될 것으로 예상되며, 언어 이해와 생성에서 더 높은 정확도와 다재다능성을 달성하도록 돕게 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**다양한 응용 및 사용 사례에 미칠 잠재적인 영향**\n\n미래 LLM의 문자 수준 추론 능력의 발전은 각 영역과 응용프로그램에 걸쳐 광범위한 영향을 미칠 것으로 예상됩니다.\n\n텍스트 분석 및 정보 검색부터 언어 번역 및 콘텐츠 생성에 이르기까지, 문자 수준에서 효과적으로 추론하는 능력은 새로운 가능성을 열고 LLM의 성능을 다양한 사용 사례에서 향상시킬 것입니다. 의료, 금융 및 교육 분야를 비롯한 다양한 산업은 문자 수준 작업을 높은 정밀도로 처리할 수 있는 LLM으로부터 혜택을 입을 것으로 기대됩니다. 이는 보다 정확하고 신뢰할 수 있는 언어 기반 솔루션을 가능하게 합니다.\n\n## 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM이 코딩은 할 수 있지만 계산은 못 하는 신기한 사례는 그들의 추론 능력에 대한 모순을 드러냅니다.\n\nLLM은 언어 이해와 생성에서 놀라운 능력을 보여주었지만, 문자 수준의 추론 능력의 제한은 제가 진행한 실험을 통해 분명해졌습니다. 이 모순은 LLM 아키텍처와 훈련 기술을 더 발전시켜 문자 수준의 추론을 효과적으로 다루기 위한 필요성을 강조합니다.\n\n자연어 처리 분야가 계속 발전함에 따라, GPT-5, Claude 4, Gemini 2와 같은 미래 LLM의 발전은 이러한 제한을 극복하는 데 유망합니다. 미래 LLM은 문자 수준의 추론을 토큰 기반 처리와 효율성과 정확도 사이의 균형을 맞추어 통합함으로써 더 포괄적이고 정확한 언어 이해와 생성을 이룰 수 있는 잠재력을 가지고 있습니다.\n\n토큰과 문자 수준에서 효과적으로 추론하는 능력은 다양한 응용 분야와 사용 사례에 중요한 영향을 미치며, LLM은 더욱 정확하고 신뢰할 수 있는 언어 작업을 다양하게 수행할 수 있는 기회를 얻을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 분야의 연구 및 개발이 진행됨에 따라 LLMs가 문자 수준 작업을 처리하는 능력이 점점 더 향상될 것으로 기대됩니다.이는 자연어 처리의 새로운 가능성을 개척하고 언어 기반 AI 시스템으로 달성 가능한 영역을 넓히게 될 것입니다.","ogImage":{"url":"/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_0.png"},"coverImage":"/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_0.png","tag":["Tech"],"readingTime":9},{"title":"대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까","description":"","date":"2024-06-22 20:52","slug":"2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems","content":"\n\n이 게시물의 한국어 버전을 다음 링크에서 찾을 수 있습니다. 😊\n\n해당 글은 대형 언어 모델에 대한 이해 시리즈(3/4)의 세 번째 글입니다.\n\n요즘에는 대형 언어 모델이 거의 모든 문제를 해결할 수 있다는 것 같아요. 사람들과 대화를 나눌 수도 있고, 질문에 답변하고, 소설을 쓰고, 음악을 작곡하며, 심지어 강의 자료를 디자인할 수도 있어요.\n\n하지만 대형 언어 모델이 이 모든 기능을 어떻게 수행하는 걸까요? 지난 몇 년 동안 어떤 일이 일어나서 가능해졌을까요? 이 글에서는 대형 언어 모델이 일상생활에서 우리가 마주하는 다양한 문제들을 어떻게 해결하는지 살펴보고, 모든 이러한 기능을 통합하는 중요한 모델링 접근 방식을 소개할 거에요. 🚀\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# LLM 이전의 AI 대 LLM 기반 AI\n\n## LLM 이전의 AI\n\n먼저 LLM 이전에 AI가 일반적으로 사용되던 방식을 살펴보겠습니다. 간단한 감성 분석 작업을 예로 들어보겠습니다. 일반적인 과정은 다음과 같을 수 있습니다:\n\n- 감정 유형 정의\n- 예를 들어, 긍정적, 부정적, 중립, 혼합된 네 가지 감정 유형이 있다고 가정합시다.\n- 충분한 감성 데이터 수집 및 해당 감정 유형에 대한 태깅\n- 다양한 출처에서 데이터 수집하고 각 데이터 조각에 대해 감정을 수동으로 태깅합니다.\n- NLP 모델 선택 (예: BERT, Electra, RoBERTa 등)\n- 수집된 태깅된 데이터를 사용하여 선택한 NLP 모델을 세밀하게 조정합니다.\n- 모델에 데이터 입력\n- 감정 분석을 위한 데이터를 모델에 입력합니다.\n- 출력 벡터 해석\n- 모델에 의한 출력 벡터를 해석하여 각 감정 클래스에 대한 확률 값을 계산합니다.\n- 이러한 확률 값에 따라 최고값을 가진 감정 클래스를 결정하여 최종 감정 클래스를 결정합니다.\n- 최종 서비스 구축\n- 세밀하게 조정된 모델을 사용하여 최종 감성 분석 서비스를 구축하고, 웹 서비스 또는 API로 제공할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM 이전에 AI를 사용하는 과정은 특정 작업을 수행하기 위해 많은 단계와 많은 수동 작업을 필요로 했습니다. 충분한 훈련 데이터를 수집해야 했고, 모델링 프로세스를 진행해야 했으며, 입력과 출력이 기존 모델의 형식과 일치해야 했습니다. 다시 말해, 데이터 파이프라인은 문제 자체가 아닌 모델의 입출력 형식을 중심으로 구축되어야 했습니다.\n\n이 내용은 다음과 같이 요약할 수 있습니다:\n\n![UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png)\n\n요컨데, 개발자들은 문제와 데이터를 모델의 강점에 맞게 맞춰야 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## LLM 기반 AI\n\nLLM은 문제 해결 과정을 간소화합니다. 특히 GPT와 같은 디코더를 포함한 언어 모델을 사용하면 어떤 \"언어\" 입력이든 처리하여 \"언어\" 출력을 생성할 수 있습니다. 이 생성 능력은 모든 문제를 크게 간소화합니다.\n\n생성 언어 모델을 사용하여 감성 분석 문제를 다시 살펴보겠습니다.\n\n- 감성 분석 문제 정의하기.\n- 사용자가 텍스트를 입력하면 해당 텍스트의 감성을 분석하고 결과를 출력합니다.\n- 사전 훈련된 LLM 모델 선택하기.\n- 예를 들어 GPT-3 모델을 선택하십시오.\n- 모델에 데이터 입력하기.\n- 모델에 텍스트 데이터를 용도에 맞게 입력합니다.\n- 예를 들어, 분석 문장이 \"This is a movie I want to watch again\" 인 경우,\n- 프롬프트는 다음과 같을 것입니다:\n- 프롬프트: “다음 문장을 다음 네 가지 범주 중 하나로 분류하십시오: 긍정적, 부정적, 중립, 혼합. 문장=This is a movie I want to watch again.\n- 모델의 출력 해석하기.\n- 모델이 출력한 텍스트를 직접 사용하거나 해석하여 감성을 분류합니다.\n- 최종 서비스 구축하기.\n- LLM을 사용하여 감성 분석 서비스를 구축하고 웹 서비스나 API로 제공할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에 표시된 대로, LLM을 사용하면 복잡한 전처리, 모델 선택 또는 세부 조정 과정 없이 감성 분석을 쉽게 수행할 수 있습니다. 모든 과정은 통합 모델에 의해 처리될 수 있어 개발자와 사용자에 대한 부담을 크게 줄일 수 있습니다. 가장 큰 장점은 입력과 출력이 모두 '텍스트'로 통합된다는 점으로, 복잡한 벡터 해석이나 처리가 필요 없다는 점입니다. 이는 다음과 같이 설명할 수 있습니다:\n\n![이미지](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_1.png)\n\n# LLM이 문제를 해결하는 방법\n\n이제 LLM, 특히 디코더를 사용하는 생성 모델이 통합적인 관점에서 다양한 문제를 해결하는 방법을 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n난 생성 모델 LLM이 특정 목표로 훈련되고 예측하는 방식을 알아볼 거야.\n\n## 트랜스포머-디코더 훈련\n\n디코더 전용 언어 모델을 다음과 같이 훈련해:\n\n- 디코더 입력 데이터를 준비해.\n- 예시: `s`, A, B, C\n- 여기서 `s`는 문장의 시작을 의미해.\n- 디코더 출력 데이터를 준비해.\n- 예시: A, B, C\n- Transformer를 통해 피드포워드 진행해.\n- 각 타임스텝에서 예측된 기호가 출력 시점의 기호와 일치하는지 확인해.\n- `s`가 있는 타임스텝은 A를 생성해야 해.\n- A가 있는 타임스텝은 B를 생성해야 해.\n- 각 타임스텝에서 손실을 계산하고 누적해, 이를 기반으로 트랜스포머를 훈련해.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 과정은 다음과 같이 시각화될 수 있습니다:\n\n![image](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_2.png)\n\n이 교육 과정 중에는 확률 모델링의 네 가지 인스턴스가 발생합니다. 각 타임스텝에서 미래 정보가 보이지 않도록 디코더의 교육 과정 중에 가림 마스크를 적용합니다. 예를 들어:\n\n- P(A | `S`)\n- P(B | `S`, A)\n- P(C | `S`, A, B)\n- P(`/S` | `S`, A, B, C)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 우리의 \"생성 언어 모델\"은 궁극적으로 다음 목표를 완성하는 데 최적화되어 있어요.\n\n이를 직관적으로 이해하기 위해, 우리의 사고를 한 단계씩 확장해 봅시다.\n\n## 트랜스포머 디코더로 생성하기\n\n[문장 완성]\n저희 언어 모델은 기본적으로 문장을 완성하도록 훈련되어 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 예시에서 보는 것처럼, Transformer 디코더는 입력 \"This is a wonderful\" 후에 가장 타당한 단어 \"world\"을 생성합니다. 그런 다음 \"This is a wonderful world\" 후에 \"isn't\"를, 그리고 \"This is a wonderful world, isn't\" 후에 \"it?\"을 생성합니다. 기본적으로 문장의 시작이 주어지면 가장 타당한 나머지 부분을 완성합니다.\n\n[문단 완성]\n이를 확장할 수 있을까요? 실제로, 우리의 Transformer는 문장과 문단을 구분하지 않습니다; 그저 점점 더 많아지는 토큰을 보는 것뿐입니다.\n\n![](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n생성 언어 모델은 문장뿐만 아니라 단락도 완성할 수 있습니다. 초기 내용을 바탕으로 단락의 나머지 부분을 완성합니다.\n\n문장에서 단락으로 확장할 때 모델 구조를 변경했나요? 아니요, 우리는 정확히 같은 모델 구조를 사용했습니다. 입력의 규모만 변경되었습니다. 마찬가지로 입력을 확장하면 다음과 같은 작업을 자연스럽게 수행할 수 있습니다:\n\n- 페이지 완성\n- 챕터 완성\n- 전체 책 완성\n\n간단히 다양한 정보 규모를 문서로 설명하면, 우리는 LLM을 주어진 문서 조각에 가장 적합한 나머지 조각을 생성하는 엔진으로 정의할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_5.png\" /\u003e\n\n위의 그림처럼, 큰 언어 모델(Large Language Models, LLMs)은 주어진 문서 조각 Dₚ를 기반으로 남은 부분 Dₙ을 완성하는 것 이상의 것도 이하의 것도 아닙니다. 음악 작곡, 소설쓰기, 시험 문제 해결 등, 문제 해결의 근본적인 방법은 그냥 빠진 부분을 “가능성 있게” 완성하는 것뿐입니다.\n\n이 과정에는 철학적, 윤리적, 도덕적, 심리적 고려 사항이 내재적으로 내장되어 있지 않습니다. LLMs를 그저 매우 대규모의 “자동 완성 기계”로 생각하는 것이 적절합니다. 이 자동 완성 기계는 방대한 양의 데이터로 훈련되어 가능성 있는 결과를 생성합니다.\n\n## LLMs의 핵심 — 가능성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM들이 Q/A 및 번역과 같은 다양한 응용 프로그램을 처리하기 위해 이 자동완성 기능을 사용하는 방법은 데이터의 힘에 있습니다.\n\n두 가지 응용 프로그램, Q/A 및 번역을 고려해 봅시다.\n\n[Q/A]\n\n질문 Q에 대한 답변 A를 제공하는 것은 Q/A 시스템을 형성합니다. 교육을 위해 우리는 Q/A 쌍을 단일 문서로 생각할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 문서 D = [Q;A]\n\nLLM(Language Model)이 수십억 개의 이러한 Q/A 문서로 훈련받는다면, 그들은 Q/A 문서를 완성하는 법을 배울 것입니다. Q/A LLM에서 \"합리성\"은 Q를 따르는 A를 생성하는 것을 의미합니다.\n\n사용자가 질문 Q를 입력할 때:\n\n- LLM(Dₚ=Q) -` Dₙ\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템적으로 보면 다음과 같습니다:\n\n- 문맥 C: “다음 내용을 영어에서 한국어로 번역하세요. 번역할 내용은:”\n- 원본 S: “The weather is beautiful today.”\n- 번역본 T: “오늘 날씨가 아름답습니다.”\n\n실제로 언어 모델을 훈련하는 과정에서는 다음과 같이 처리됩니다:\n\n- D = [C; S; T]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수십억 건의 번역 요청 및 결과 문서를 사용하여 훈련된 언어 모델은 자연스럽게 Dₚ = [C; S]를 Dₙ = T와 함께 완성할 수 있는 능력을 개발합니다. 본질적으로 번역기를 생성하는 대신, 우리는 번역 문서의 일부를 가져와 입력하고 자동 완성 기곕이 나머지를 채우도록 허용했습니다.\n\n하지만 사용자에게는 훌륭한 번역이 이루어졌고 실용적으로 사용할 수 있다고 보입니다.\n\n최종적으로 LLM(Large Language Models)이 문제를 해결하는 한 가지 방법은 가장 타당한 방식으로 남은 부분을 완성함으로써입니다. 너무 간단하게 보일 수 있지만, 조금의 상상력을 발휘하면 이 방법이 거의 모든 것을 해결할 수 있다는 것을 알 수 있습니다.\n\n음악 작곡, 소설 쓰기, 영화 제작, 시험 문제 제출 및 해결, 경제 시뮬레이션, 수학 문제 해결, 철학적 논쟁, 인류의 미래 예측 - 우리가 가진 거의 모든 질문은 \"가장 타당한\" 결과를 제공함으로써 답변될 수 있습니다. 그리고 그 타당한 결과가 바로 LLM, 자동완성 기곕이 제공하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n이 글에서 우리는 대형 언어 모델이 세상의 다양한 문제들을 해결하는 핵심 원리에 대해 탐구했습니다. 간단히 말해, LLM은 자동 완성 기계입니다. 이 엔진은 훈련된 데이터를 기반으로 전체 문서의 전반부가 주어졌을 때, 후반부를 타당하게 완성하는 최적화된 엔진입니다.\n\n이 원리는 간단하지만, LLM은 훈련 중 노출된 데이터의 유형과 구성을 다양화함으로써 새로운 응용 프로그램을 끝없이 만들어낼 수 있는 강력한 도구입니다.\n\n다음 글에서는 이 자동 완성 기계의 \"대규모\" 측면이 우리에게 미치는 영향에 대해 설명할 것입니다.","ogImage":{"url":"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png"},"coverImage":"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png","tag":["Tech"],"readingTime":7},{"title":"LangFlow와 Ollama로 코딩 없이 로컬 RAG 챗봇 만들기 방법","description":"","date":"2024-06-22 20:49","slug":"2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama","content":"\n\n⁤스마트 챗봇을 만드는 데 수개월의 코딩이 필요했던 시절을 기억하나요?\n\nLangChain과 같은 프레임워크는 개발을 간소화했지만, 수백 줄의 코드는 프로그래머가 아닌 사람들에게 여전히 장벽일 수 있습니다. ⁤\n\n더 간단한 방법은 없을까요? (풀 스토리를 읽기 위해 친구 링크를 찾으려면 이미 Medium 회원이 아닌 경우 Medium 회원 가입을 고려해 주세요)\n\n![image](/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그때 \"Lang Flow\"를 발견했어요. 이 오픈 소스 패키지는 Python 버전의 LangChain을 기반으로 구축되었습니다. 코드를 한 줄도 쓰지 않고 AI 애플리케이션을 만들 수 있게 해줘요. 챗봇을 만들기 위해 컴포넌트들을 끌어다가 캔버스에서 연결하기만 하면 돼요. \n\n이 게시물에서는 LangFlow를 사용해서 몇 분 안에 스마트 AI 챗봇 프로토타입을 만들 거에요. 백엔드로는 Ollama를 사용하여 임베딩 모델과 대형 언어 모델을 사용할 거에요. 이렇게 하면 응용프로그램을 로컬에서 무료로 실행할 수 있어요! 마지막으로 이 흐름을 최소한의 코딩으로 Streamlit 애플리케이션으로 변환할 거에요.\n\n# RAG Pipeline, LangChain, LangFlow, Ollama 소개\n\n이 프로젝트에서는 AI 챗봇을 만들어보려고 해요. \"Dinnerly - 당신의 건강한 요리 플래너\" 라고 이름 붙여보죠. 이 챗봇은 건강한 요리 레시피를 추천하는 것을 목표로 합니다. 이를 위해 RAG(Retrieval Augmented Generation)를 사용하여 레시피 PDF 파일에서 추출할 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어떻게 이를 실현할 것인지에 대해 들어가기 전에 프로젝트에서 사용할 핵심 재료를 빠르게 살펴보겠습니다.\n\n## 검색 증강 생성 (RAG)\n\nRAG(검색 증강 생성)은 대형 언어 모델 (LLMs)이 외부 소스에서 관련 정보를 제공받아 돕는 기술입니다. 이를 통해 LLM은 응답을 생성할 때 이 문맥을 고려하여 보다 정확하고 최신의 결과를 만들어냅니다.\n\nRAG 파이프라인에는 일반적으로 '검색 증강 생성 안내서'에 설명된대로 다음 단계가 포함됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n“\n- 문서 로드: 문서 또는 데이터 원본을 먼저로드하십시오.\n- 청크로 분할: 문서를 관리하기 쉬운 부분으로 나누십시오.\n- 임베딩 생성: 임베딩을 사용하여 이러한 청크를 벡터 표현으로 변환하십시오.\n- 벡터 데이터베이스에 저장: 이러한 벡터를 데이터베이스에 저장하여 효율적으로 검색하십시오.\n- 사용자 상호 작용: 사용자로부터 쿼리 또는 입력을받고 그것을 임베딩으로 변환하십시오.\n- 벡터 데이터베이스에서 의미 검색: 사용자 쿼리를 기반으로 의미 검색을 수행하기 위해 벡터 데이터베이스에 연결하십시오.\n- 응답 검색 및 처리: 관련 응답을 가져와 LLM을 통과시키고 답변을 생성하십시오.\n- 사용자에게 답변 전달: LLM에 의해 생성된 최종 출력물을 사용자에게 제공하십시오.\n”\n\n## Langchain\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLMs을 중심으로 만들어진 오픈 소스 프레임워크인 LangChain은 챗봇, 요약 등 다양한 GenAI 응용 프로그램의 설계와 개발을 용이하게 합니다.\n\n이 라이브러리의 핵심 아이디어는 다른 구성 요소를 \"체인\"으로 연결하여 복잡한 AI 작업을 단순화하고 LLMs 주변에서 더 많은 고급 사용 사례를 만드는 것입니다.\n\n![이미지](/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_1.png)\n\n## LangFlow\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLangFlow은 LangChain을 위해 특별히 설계된 웹 도구입니다. 사용자가 코딩없이 LangChain 애플리케이션을 구축하고 테스트할 수 있는 사용자 인터페이스를 제공합니다. 간단히 구성 요소를 끌어다 놓기만 하면 됩니다.\n\n하지만 LangFlow를 사용하려면 LangChain의 작동 방식과 다양한 구성 요소에 대한 기본적인 이해가 필요합니다. 그러면 AI 애플리케이션의 흐름을 설계하는 데 LangFlow를 사용할 수 있습니다.\n\nOllama\n\nOllama은 오픈 소스 LLM을 사용하기 위한 최고이자 가장 쉬운 방법입니다. Llama 2 및 Mistral과 같은 가장 강력한 LLM을 지원하며, ollama.ai/library에서 사용 가능한 모델 목록을 찾을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Ollama setup](/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_2.png)\n\n# Ollama 설정하기\n\n## Ollama 설치\n\n먼저 Ollama 다운로드 페이지로 이동하여 사용 중인 운영 체제와 일치하는 버전을 선택한 후 다운로드하고 설치하세요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOllama를 설치한 후에 명령 터미널을 열고 다음 명령을 입력하세요. 이 명령들은 모델을 다운로드하고 로컬 머신에서 실행할 것입니다.\n\n이 프로젝트에서는 우리가 Large Language Model (LLM)으로 Llama2를 사용하고, 임베딩 모델로 \"nomic-embed-text\"를 사용할 것입니다. \"Nomic-embed-text\"는 큰 컨텍스트 윈도우를 가진 강력한 오픈 소스 임베딩 모델입니다. 이를 통해 전체 애플리케이션을 클라우드 서비스 없이 로컬에서 실행할 수 있습니다!\n\n```js\nollama serve\nollama pull llama2\nollama pull nomic-embed-text\nollama run llama2\n```\n\n# LangFlow 설정하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 준비 사항\n\nLangFlow을 시작하기 전에 컴퓨터에 Python이 설치되어 있는지 확인하는 것이 중요합니다. Python 버전은 3.9보다 높아야 하지만 3.12보다 낮아야 합니다.\n\nLangFlow 설치\n\n이제 LangFlow를 설치해 봅시다. 가상 환경 내에서 설치하는 것을 권장합니다. 이 방법을 사용하면 종속성을 깔끔하게 자체 공간 내에서 관리할 수 있습니다. 저는 Mac에서 Conda를 사용하여 설정합니다. 명령 줄 터미널에 다음 명령을 입력하여 \"langflow\"라는 가상 환경을 만들고 Python 3.11을 설정하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nconda create -n langflow python=3.11\nconda activate langflow\npip install langflow\n```\n\n콘다를 사용하지 않는 경우에도 다음 명령어를 사용하여 Python으로 직접 가상 환경을 설정할 수 있어요.\n\n```js\npython -m venv langflow\nsource langflow/bin/activate\npip install langflow\n```\n\n설치를 마치면 LangFlow를 시작하는 것은 매우 간단합니다. 터미널에 \"langflow run\"을 입력하기만 하면 돼요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![](/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_3.png)\n\n그런 다음, 제공된 URL을 복사하세요 (위의 예에서는 http://127.0.0.1:7860), 웹 브라우저에 붙여넣기하고, 와! 이런 식으로 보이는 인터페이스를 볼 수 있어야 합니다. 이 페이지에는 모든 프로젝트가 표시됩니다.\n\n![](/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_4.png)\n\n# 챗봇 플로우 디자인하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 플로우를 만드는 시간이군요!\n\n\"새 프로젝트\"를 클릭하여 빈 캔버스를 열어보세요. 왼쪽 창에는 드래그하여 작업 영역에 놓을 수 있는 다양한 구성 요소가 준비되어 있습니다.\n\n우리 프로젝트를 위해 PDF 파일에서 질문에 답변할 수 있는 챗봇을 만들고 있습니다. 이전에 언급한 RAG 파이프라인을 기억하시나요? 이를 구성할 때 필요한 몇 가지 요소가 있습니다:\n\n- PDF 로더: 여기서 \"PyPDFLoader\"를 사용할 것입니다. PDF 문서의 파일 경로를 입력해야 합니다.\n- 텍스트 분할기: \"RecursiveCharacterTextSplitter\"를 선택하고 기본 설정을 사용하시면 됩니다.\n- 텍스트 임베딩 모델: 무료 오픈소스 임베딩을 사용하려면 \"OllamaEmbeddings\"를 선택하세요.\n- 벡터 데이터베이스: 임베딩을 저장하고 벡터 검색을 용이하게 하기 위해 \"FAISS\"를 선택합니다.\n- 응답 생성을 위한 LLM: \"ChatOllama\"를 선택하고 모델을 \"llama2\"로 지정하세요.\n- 대화 기억: 챗봇이 채팅 기록을 유지하도록 하는 기능으로 \"ConversationBufferMemory\"를 사용할 것입니다.\n- 대화 검색 체인: LLM, 메모리, 검색된 텍스트 등과 같은 다양한 구성 요소를 연결하여 응답을 생성하는 기능입니다. \"ConversationRetrievalChain\"이 우리의 선택입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n캔버스로 모든 구성 요소를 끌어다 놓고 PDF 파일 경로 및 LLM 모델 이름과 같은 필수 필드를 설정하세요. 나머지 설정은 기본값으로 두어도 괜찮습니다.\n\n그 다음, 이러한 구성 요소를 연결하여 흐름을 만들어보세요.\n\n모든 것이 연결되었다면, 우측 하단에 있는 \"번개\" 버튼을 눌러 흐름을 컴파일하세요. 모든 것이 순조롭게 진행된다면 버튼이 녹색으로 바뀌어 성공을 알리게 됩니다.\n\n흐름을 성공적으로 컴파일한 후, \"챗봇\" 아이콘을 클릭하여 생성물을 테스트해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_5.png\" /\u003e\n\n여러 가지 팁:\n\n- 플로우를 완료하면 JSON 파일로 저장하거나 나중에 액세스하거나 편집할 수 있도록 \"내 컬렉션\"에서 찾을 수 있습니다.\n- 사전 빌트 예제로 LangFlow에 뛰어들면 훌륭한 영감을 얻고 시작하는 데 도움이 될 수 있습니다. 여기에 팁이 있습니다:\n- \"LangFlow Store\"는 예제를 보유하고 있지만 액세스를 위해 API 키가 필요합니다.\n- LangFlow GitHub 페이지를 통해 예제를 다운로드하여 \"업로드\" 버튼을 사용하여 LangFlow UI로 업로드할 수 있습니다.\n- 로컬로 설정하는 것이 꺼려지면, OpenAI를 선택하여 RAG 파이프라인을 구축할 수도 있습니다. 설정을 위해 OpenAI API 키를 가지고 있는지 확인하세요.\n\n# 플로우를 스트림릿 챗봇으로 변환하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 플로우가 완벽하게 설정되었다면, 애플리케이션에 통합할 시간입니다. 플로우를 구축한 후에는 LangFlow가 필요한 코드 조각을 제공하여 쉽게 만들어줍니다. 사이드바에서 \"코드\" 버튼을 누르기만 하면 됩니다.\n\n![image](/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_6.png)\n\n이제 이 플로우를 Streamlit 챗봇에 통합해 보겠습니다.\n\n- 종속성 설정: 시작하기 전에 종속성을 설치해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\npip install streamlit\npip install langflow\npip install langchain-community \n```\n\n2. Lang Flow 코드 스니펫 가져오기: \"app.py\"라는 새로운 Python 파일을 만듭니다. LangFlow UI로 돌아가 \"Code\" 버튼을 다시 찾습니다. \"Python API\" 탭으로 이동하여 코드 스니펫을 복사하고 \"app.py\"에 붙여넣습니다.\n\n```js\nimport requests\nfrom typing import Optional\n\nBASE_API_URL = \"http://127.0.0.1:7860/api/v1/process\"\nFLOW_ID = \"d9392262-a912-42b4-8582-cc9e48894a00\"\n\n# 원하는대로 플로우를 조정할 수 있습니다.\n# 예시: {\"OpenAI-XXXXX\": {\"model_name\": \"gpt-4\"}\nTWEAKS = {\n  \"VectorStoreAgent-brRPx\": {},\n  \"VectorStoreInfo-BS24v\": {},\n  \"OpenAIEmbeddings-lnfRZ\": {},\n  \"RecursiveCharacterTextSplitter-bErPe\": {},\n  \"WebBaseLoader-HLOqm\": {},\n  \"ChatOpenAI-aQOv0\": {},\n  \"FAISS-o0WIf\": {}\n}\n\ndef run_flow(inputs: dict, flow_id: str, tweaks: Optional[dict] = None) -\u003e dict:\n    \"\"\"\n    주어진 메시지와 선택적 조정으로 플로우를 실행합니다.\n\n    :param message: 플로우에 보낼 메시지\n    :param flow_id: 실행할 플로우의 ID\n    :param tweaks: 플로우를 사용자 정의하는 선택적 조정\n    :return: 플로우의 JSON 응답\n    \"\"\"\n    api_url = f\"{BASE_API_URL}/{flow_id}\"\n\n    payload = {\"inputs\": inputs}\n    headers = None\n    if tweaks:\n        payload[\"tweaks\"] = tweaks\n    response = requests.post(api_url, json=payload, headers=headers)\n    return response.json()\n```\n\n3. 채팅 기능 구현: 같은 Python 파일에서 사용자의 새로운 쿼리마다 응답을 가져오기 위해 플로우를 실행하는 함수를 정의합니다. 그런 다음 이 응답을 인터페이스에 스트리밍합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\ndef chat(prompt: str):\n  with current_chat_message:\n    # AI가 응답할 때 메시지를 보내지 못하도록 입력을 차단합니다\n    st.session_state.disabled = True\n\n    # 사용자 메시지를 채팅 기록에 추가합니다\n    st.session_state.messages.append((\"human\", prompt))\n\n    # 채팅 메시지 컨테이너에 사용자 메시지를 표시합니다\n    with st.chat_message(\"human\"):\n      st.markdown(prompt)\n\n    # 채팅 메시지 컨테이너에 어시스턴트 응답을 표시합니다\n    with st.chat_message(\"ai\"):\n      # 최신 질문을 마지막 메시지로 포함한 전체 채팅 기록을 가져옵니다\n      history = \"\\n\".join(\n        [f\"{role}: {msg}\" for role, msg in st.session_state.messages]\n      )\n\n      query = f\"{history}\\nAI:\"\n\n      # 흐름에 적용할 수정 사항을 설정합니다\n      inputs = {\"input\": query}\n\n      output = run_flow(inputs, flow_id=FLOW_ID, tweaks=TWEAKS)\n      print(output)\n      try:\n        output = output['result']['output']\n      except Exception :\n        output = f\"애플리케이션 오류 : {output}\"\n\n      placeholder = st.empty()\n      response = \"\"\n\n      for tokens in output:\n        response += tokens\n        # \"▌\"으로 스트리밍을 표시하여 응답을 작성합니다\n        with placeholder:\n          st.markdown(response + \"▌\")\n\n      # \"▌\" 없이 완료된 메시지를 표시합니다\n      with placeholder:\n        st.markdown(response)\n\n    # AI 응답을 채팅 기록에 기록합니다\n    st.session_state.messages.append((\"ai\", response))\n    # 채팅 입력 해제\n    st.session_state.disabled = False\n\n    st.rerun()\r\n```\n\n4. 인터페이스 만들기: 이제 동일한 Python 파일에서 다음 코드를 사용하여 간단한 Streamlit 사용자 인터페이스를 만들어보겠습니다.\n\n```js\r\nst.set_page_config(page_title=\"Dinnerly\")\nst.title(\"Dinnerly에 오신 것을 환영합니다: 건강한 요리 플래너\")\n\nsystem_prompt = \"사용자에게 건강한 요리 레시피를 제안하고 제공하는 유용한 도우미입니다\"\nif \"messages\" not in st.session_state:\n    st.session_state.messages = [(\"system\", system_prompt)]\nif \"disabled\" not in st.session_state:\n    # AI가 응답 중일 때 사용자가 메시지를 보내지 못하도록하는 'disabled' 플래그\n    st.session_state.disabled = False\n\n\nwith st.chat_message(\"ai\"):\n  st.markdown(\n    f\"안녕하세요! 건강한 요리 플래너입니다. 건강하고 맛있는 요리를 준비하는 데 도움을 드리겠습니다!\"\n  )\n\n# 앱 재실행 시 기록된 채팅 메시지 표시\nfor role, message in st.session_state.messages:\n    if role == \"system\":\n        continue\n    with st.chat_message(role):\n        st.markdown(message)\n\ncurrent_chat_message = st.container()\nprompt = st.chat_input(\"질문을 여기에 입력하세요...\", disabled=st.session_state.disabled)\n\nif prompt:\n    chat(prompt)\r\n```\n\nStreamlit 앱을 실행하면 자체 요리 플래너와 채팅할 수 있습니다! 맛있고 건강한 요리를 만드는 데 도움이 됩니다.\r\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마크다운 형식으로 표 태그를 변경하십시오.\n\nTips:\n\n다른 플로우에 대해 동일한 코드와 인터페이스를 사용할 수 있습니다. FLOW_ID를 변경하여 새로운 플로우를 앱에 테스트 및 통합하세요.\n\n\u003cimg src=\"/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_8.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 마무리 생각\n\n이 글에서 우리는 스마트한 RAG 기반 챗봇을 만들었습니다. 우리는 코드를 작성할 필요 없이 LangFlow를 활용하여 RAG 파이프라인을 설정했고, 임베딩 및 LLM 처리를 위해 오픈 소스 모델을 활용하여 응용 프로그램을 로컬에서 실행하고 추론 비용 없이 유지했습니다. 마지막으로,이 설정을 Streamlit 애플리케이션으로 변환했습니다.\n\n특히 LangFlow의 노코드 방식을 감사히 여기고, AI 응용 프로그램을 구축하고 프로토타입화하는 방식을 바꿀 수 있다고 믿습니다.\n\n그러나 아직 개발 중인 구성 요소가 있으며 때로는 예상대로 작동하지 않을 수 있음을 언급할 가치가 있습니다. 이러한 순간이 발생할 때 문제에 대한 가시성이나 문제 해결에 대한 안내가 부족할 수 있습니다. 또 다른 개선 사항으로는 Python 코드를 직접 제공하여 더 많은 사용자 정의를 제공하는 것이 있을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLangFlow은 빠른 프로토타이핑 필요에 유용한 도구라고 생각해요.\n\n## 떠나시기 전에! 🦸🏻‍♀️\n\n만약 제 이야기가 마음에 드셨고 저를 지원하고 싶으시다면:\n\n- 약간의 Medium 사랑을 보내주세요 💕(박수, 댓글 및 하이라이트), 여러분의 지원은 저에게 큰 힘이 됩니다.👏\n- Medium에서 저를 팔로우하고 최신 기사를 받아보세요🫶\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 참고\n\n- LangFlow 문서\n- Ollama 문서\n- Deliciously Healthy Dinners (데모에서 사용된 pdf 파일): [링크](https://healthyeating.nhlbi.nih.gov/pdfs/dinners_cookbook_508-compliant.pdf)","ogImage":{"url":"/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_0.png"},"coverImage":"/assets/img/2024-06-22-BuildingLocalRAGChatbotsWithoutCodingUsingLangFlowandOllama_0.png","tag":["Tech"],"readingTime":11},{"title":"DSPy를 사용하여 메타데이터 추출하는 방법 - NER 스타일 가이드","description":"","date":"2024-06-22 20:47","slug":"2024-06-22-UsingDSPyforextractingmetadataNERstyle","content":"\n\nDSPy는 프로그래밍을 장려하는 \"선언적\" 방식을 통해 LLMs를 가르치는 것을 선호하여 커뮤니티에서 빠르게 큰 관심을 얻었습니다. 이 글에서는 DSPy를 사용하여 Named Entity Recognition (NER) 또는 구조화된 데이터 추출을 얼마나 쉽게 할 수 있는지 살펴보겠습니다. 이를 통해 자신감을 가지고 기능을 활용할 수 있습니다.\n\n자세한 내용은 아래의 원문을 확인해주세요:\n\n시작해봅시다 😎!\n\n# 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n요즘 대형 언어 모델(Large Language Models, LLM)과 작업한 사람들은 프롬프트(prompt)의 중요성을 강조할 것입니다. 프롬프트를 조금만 바꿔도 출력물에 예상치 못한 변화가 연쇄적으로 발생할 수 있습니다. 또한 다른 LLM 제공업체 간에 프롬프트를 이전하거나 재사용하는 일이 까다로운 경우도 많습니다. 예를 들어, OpenAI에서 Claude 3를 통해 Antrophic을 사용하는 함수 호출 로직을 이동하는 경우 프롬프트를 재설계해야 할 필요가 있죠 😅.\n\n따라서 프롬프트를 다시 작성하고, 평가를 재평가하며, 출력물을 디버깅하는 데 많은 시간 ⏰을 투자해야 합니다. 이를 보다 똑똑하게 처리할 수 있는 방법이 있다면 좋을텐데요? 다행히도, DSPs와 같은 흥미로운 프레임워크는 LLM 제공자에 관계없이 프로그래밍에 중점을 둡니다. 자세한 내용은 참조할 자료에서 DSPy에 대해 더 깊이있게 알아볼 수 있습니다.\n\n# Declarative Self-Improving Language Programs (DSPy)\n\nDSPy 또는 선언적 자기 개선 언어 프로그램(Declarative Self-improving Language Programs, Khattab et al, 2023)은 처음으로 [2]에서 소개되었습니다. DSPy는 PyTorch와 같은 신경망 프레임워크에서 영감을 받아, 프롬프트보다는 프로그래밍에 중점을 둡니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단히 말하자면, DSPy 프로그래밍 모델은 다음과 같은 추상화를 가지고 있습니다:\n\n- 필요한 손쓰기 프롬프트/세밀 조정을 대체할 서명.\n- Cot, REACT 등 다양한 프롬프트 엔지니어링 기술을 구현한 모듈.\n- 주어진 메트릭스를 기반으로 한 수동 프롬프트 엔지니어링을 자동화하는 옵티마이저\n\n더 자세한 설명은 참조 사항 중 [1]을 참고하십시오.\n\n# 음식 관련 엔티티에 DSPy를 사용한 NER\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 섹션에서는 DSPy를 사용하여 NER 사용 사례를 살펴볼 것입니다.\n\n## 데이터\n\n사용할 데이터는 라면 🍜 한 그릇을 만들기 위한 차슈 돼지고기 레시피입니다. 아래 게시물에서 자세한 내용을 확인하세요:\n\n예시 데이터:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n### 차슈 돼지고기 (라면 및 기타 용도)\n차슈 돼지고기는 라멘과 같은 일본 요리에 사용되는 돼지 배를 준비하는 전통적인 방법입니다.\n다소 시간이 걸릴 수 있지만 비교적 손쉽고 맛있는 결과물이 나옵니다.\n\n### 재료\n2 파운드의 돼지 배 또는 조금 더/적게\n2개의 대파 또는 작은 경우 3개\n1인치 크기의 생 생강 (약 4-6조각 나오는 양)\n2쪽의 마늘\n⅔컵의 사케\n⅔컵의 간장\n¼컵의 미린\n½컵의 설탕\n필요에 따라 조절 가능한 2컵의 물\n### 요령\n돼지고기를 준비하기 전에 줄 또는 부엌 실을 준비하고 가위 한 켤레를 준비하세요.\n해당 사항이 있다면 돼지고기의 외부 지방을 다듬어주세요. 그럼에도 불구하고 이후에는 여전히\n...\n```\n\n위의 데이터 외에도 TypedPredictor와 함께 사용할 Pydantic 데이터 모델을 설정해야 합니다:\n\n```js\nclass FoodMetaData(BaseModel):\n    reasoning: str = Field(description=\"엔티티가 정확한 이유\")\n    value: Union[str, int] = Field(description=\"엔티티의 값\")\n    entity: str = Field(description=\"실제 엔티티 즉, 돼지고기, 양파 등\")\n\nclass FoodMetaDatas(BaseModel):\n    context: List[FoodMetaData]\n```\n\n```js\nclass FoodEntity(BaseModel):\n    food: str = Field(description=\"유체 및 고체 음식, 즉 고기, 채소, 주류 등이 될 수 있습니다.\")\n    quantity: int = Field(description=\"레시피에 사용해야 하는 실제 양 또는 양\")\n    unit: str = Field(description=\"사용 중인 단위, 예를 들어 그램, 밀리리터, 파운드 등\")\n    physical_quality: Optional[str] = Field(description=\"재료의 특성\")\n    color: str = Field(description=\"음식의 색상\")\nclass FoodEntities(BaseModel):\n    entities: List[FoodEntity]\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- FoodMetadatas는 각 엔티티의 컨텍스트 추출 + 추론 흐름의 일부입니다.\n- FoodEntities는 우리가 원하는 엔티티를 추출하는 데 사용됩니다.\n\n마지막으로, DSPy 프로그램이 옵티마이저를 위해 컴파일될 때, 우리는 dspy.Examplemodule을 사용하여 일부 훈련 예제를 만들 것입니다:\n\n```js\ntrainset = [\n    dspy.Example(\n        recipe=\"2개의 계란, 500그램 버터 및 10그램 그리르치즈로 프렌치 오믈렛 만들기\", \n        entities=[\n            FoodEntity(food=\"계란\", quantity=2, unit=\"\", physical_quality=\"\", color=\"흰색\"),\n            FoodEntity(food=\"버터\", quantity=500, unit=\"그램\", physical_quality=\"\", color=\"노랑\"),\n            FoodEntity(food=\"치즈\", quantity=10, unit=\"그램\", physical_quality=\"그리레\", color=\"노랑\")\n        ]\n    ).with_inputs(\"recipe\"),\n        ...\n    dspy.Example(\n        recipe=\"250g 밀가루, 1큰술 베이킹 파우더, 1그램 소금, 10g 설탕, 100ml 신선우유로 아메리칸 팬케이크 만들기\", \n        entities=[\n            FoodEntity(food=\"밀가루\", quantity=250, unit=\"그램\", physical_quality=\"\", color=\"흰색\"),\n            FoodEntity(food=\"베이킹 파우더\", quantity=1, unit=\"큰술\", physical_quality=\"\", color=\"흰색\"),\n            FoodEntity(food=\"소금\", quantity=1, unit=\"그램\", physical_quality=\"짠맛\", color=\"흰색\"),\n            FoodEntity(food=\"우유\", quantity=100, unit=\"밀\", physical_quality=\"지방\", color=\"흰색\"),\n        ]\n    ).with_inputs(\"recipe\")\n]\r\n```\n\n## 서명\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터셋을 만들거나 수집한 후의 다음 단계는 DSPy 프로그램에 대한 서명을 작성하는 것입니다. 이것을 입력/출력 동작에 대한 선언적 명세로 생각할 수 있습니다:\n\n```js\nclass RecipeToFoodContext(dspy.Signature):\n    \"\"\"당신은 음식 AI 어시스턴트입니다. 엔티티, 엔티티의 값 및 추출된 값이 올바른 값인 이유를 추출하는 작업을 수행해야 합니다. \n    엔티티를 추출할 수 없는 경우 null을 추가하십시오\"\"\"\n    recipe: str = dspy.InputField()\n    context: FoodMetaDatas = dspy.OutputField()\n```\n\n```js\nclass RecipeToFoodEntities(dspy.Signature):\n    \"\"\"당신은 음식 AI 어시스턴트입니다. 레시피에서 음식과 관련된 메타데이터를 추출해야 합니다.\"\"\"\n    recipe: str = dspy.InputField()\n    entities: FoodEntities = dspy.OutputField()\n```\n\n- RecipeToFoodContext은 문맥 + 추론 호출에 사용되는 서명입니다. 여기에서 문자열 설명을 사용하여 LLM에 초기 지침을 제공했다는 점에 유의하십시오.\n- RecipeFoodEntities는 실제로 식별된 엔티티를 추출하는 서명에 해당합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금까지는 특별한 공학 작업이 아니라 Python 클래스/객체를 명시하는 것이었습니다 🐍. 코드는 또한 이해하기 비교적 쉽습니다. 무엇을 하는지, 입력이나 출력 등이 뭔지 잘 알 수 있죠.\n\n## Modules\n\n데이터셋을 생성하고 서명을 지정한 후에는 모듈을 작성할 준비가 되었습니다. 각 모듈은 Chain-of-Thought, ReAct 등 다양한 프롬프팅 기술을 \"추상화\"하는 멋진 기능이 있습니다. 또한 신경망 프레임워크에 익숙한 독자들을 위해 아래의 forward 메서드에 주목해주세요:\n\n```js\nclass ExtractFoodEntities(dspy.Module):\n    def __init__(self, temperature: int = 0, seed: int = 123):\n        super().__init__()\n        self.temperature = temperature\n        self.seed = seed\n        self.extract_food_context = dspy.TypedPredictor(RecipeToFoodContext)\n        self.extract_food_context_cot = dspy.TypedChainOfThought(RecipeToFoodContext)\n        self.extract_food_entities = dspy.TypedPredictor(RecipeToFoodEntities)\n        \n    def forward(self, recipe: str) -\u003e FoodEntities:\n        food_context = self.extract_food_context(recipe=recipe).context\n        parsed_context = parse_context(food_context.context)\n        food_entities = self.extract_food_entities(recipe=parsed_context)\n        return food_entities.entities\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 모듈은 dspy.Module 인터페이스를 사용하고 있습니다. dspy.Functional 인터페이스를 사용하여 모듈을 지정할 수도 있습니다:\n\n```js\nfrom dspy.functional import FunctionalModule, predictor, cot\n\nclass ExtractFoodEntitiesV2(FunctionalModule):\n    def __init__(self, temperature: int = 0, seed: int = 123):\n        super().__init__()\n        self.temperature = temperature\n        self.seed = seed\n    @predictor\n    def extract_food_context(self, recipe: str) -\u003e FoodMetaData:\n        \"\"\"당신은 음식 AI 어시스턴트입니다. 엔티티, 엔티티의 값 및 추출된 값이 올바른 값인 이유를 추출하는 것이 작업입니다. \n        엔티티를 추출할 수 없는 경우 null을 추가하세요.\"\"\"\n        pass\n    @cot\n    def extract_food_context_cot(self, recipe: str) -\u003e FoodMetaData:\n        \"\"\"당신은 음식 AI 어시스턴트입니다. 엔티티, 엔티티의 값 및 추출된 값이 올바른 값인 이유를 추출하는 것이 작업입니다. \n        엔티티를 추출할 수 없는 경우 null을 추가하세요.\"\"\"\n        pass\n    \n    @predictor\n    def extract_food_entities(self, recipe: str) -\u003e FoodEntities:\n        \"\"\"당신은 음식 AI 어시스턴트입니다. 작업은 레시피에서 음식 엔티티를 추출하는 것입니다.\"\"\"\n        pass\n        \n    def forward(self, recipe: str) -\u003e FoodEntities:\n        food_context = self.extract_food_context(recipe=recipe)\n        parsed_context = parse_context(food_context.context)\n        food_entities = self.extract_food_entities(recipe=parsed_context)\n        return food_entities\n```\n\n이를 통해 데코레이터 함수를 사용하여 표준 프롬프트 엔지니어링 기술을 지정할 수 있으며, 이는 매우 깔끔합니다. 또한 모듈에서 사용된 parse_context 메서드는 결과 JSON 콘텍스트를 문자열로 구문 분석하는 유틸리티 함수이며, 체인의 다음 단계에 대한 입력으로 사용될 것입니다.\n\n## DSPy 프로그램 실행하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로그램을 실행하려면 모듈의 인스턴스를 만들고 입력값을 사용하여 호출하십시오. 그러나 DSPy의 또 다른 멋진 기능은 모듈에 대한 dspy.Context를 지정할 수 있다는 것입니다:\n\n```js\nextract_food_entities = ExtractFoodEntities()\n\nwith dspy.context(lm=gpt4):\n    entities = extract_food_entities(recipe=\"Ten grams of orange dutch cheese,  \\\n    2 liters of water and 5 ml of ice\")\n    pprint(entities)\n```\n\n위의 프로그램은 다음 출력을 보여줍니다:\n\n```js\nFoodEntities(\n    entities=[\n        FoodEntity(\n            food='orange dutch cheese',\n            quantity=10,\n            unit='grams',\n            physical_quality=None,\n            color='orange',\n        ),\n        FoodEntity(\n            food='water',\n            quantity=2000,\n            unit='milliliters',\n            physical_quality=None,\n            color='clear',\n        ),\n        FoodEntity(\n            food='ice',\n            quantity=5,\n            unit='milliliters',\n            physical_quality=None,\n            color='clear',\n        ),\n    ],\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 다른 LLM(모델 상의 큰 언어 모델)을 시험해보거나, 예를 들어 DEV에는 gpt-3.5-turbo를 사용하고, PROD에서는 더 강인한 모델인 gpt-4-turbo-preview를 사용한다면 유용할 것입니다.\n\n## DSPy 프로그램 최적화하기\n\n이제 프로그램을 최적화하는 데 필요한 모든 구성 요소가 준비되었습니다 🎉. DSPy에서 최적화자는 DSPy 프로그램의 매개변수인 프롬프트와/또는 LM(언어 모델) 가중치를 조정할 수 있는 알고리즘입니다. 프로그램을 최적화하려면 최대화할 메트릭을 제공합니다.\n\n최적화 단계에서는 BootstrapFewShot 최적화자를 사용합니다. 그리고 최대화하려는 메트릭(어떤 파이썬 함수도 될 수 있음)은 아래에 표시되어 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\ndef validate_entities(example, pred, trace=None):\n    \"\"\"두 객체가 동일한지 확인합니다.\"\"\"\n    return example.entities == pred\n```\n\n최적화를 실행하려면 compile 메서드를 사용합니다:\n\n```python\nfrom dspy.teleprompt import BootstrapFewShot\n\nteleprompter = BootstrapFewShot(metric=validate_entities)\ncompiled_ner = teleprompter.compile(ExtractFoodEntitiesV2(), trainset=trainset)\n```\n\n저희 데이터셋에서 컴파일된 프로그램을 실행한 결과는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nFoodEntities(\n    entities=[\n        FoodEntity(\n            food='삼겹살',\n            quantity=2,\n            unit='lb',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='파',\n            quantity=2,\n            unit='개',\n            physical_quality='작을 경우 3개',\n            color='',\n        ),\n        FoodEntity(\n            food='생강',\n            quantity=1,\n            unit='인치',\n            physical_quality='한 조각',\n            color='',\n        ),\n        FoodEntity(\n            food='마늘',\n            quantity=2,\n            unit='쪽',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='술',\n            quantity=2,\n            unit='⅔ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='간장',\n            quantity=2,\n            unit='⅔ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='미린',\n            quantity=1,\n            unit='¼ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='설탕',\n            quantity=1,\n            unit='½ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='물',\n            quantity=2,\n            unit='컵',\n            physical_quality='필요에 따라 약간 더',\n            color='',\n        ),\n    ],\n)\r\n```\n\n프롬프트 엔지니어링에 반이나하 며 살짝 봐두 시간 정도만 투자한 것에 대해서 꽤 괜찮지 않나요? 💪!\n\n## LLM 검사\n\n프로그램을 이렇게 선언하는 것도 좋지만 LLM이 사용하는 기본 프롬프트를 확인하려면 어떻게 해야 할까요? 걱정 마세요. inspect_history를 사용해 보세요:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\ngpt4.inspect_history(n=1)\r\n```\r\n\r\n아래와 같은 출력이 나왔습니다:\r\n\r\n```js\r\n당신은 음식 AI 어시스턴트입니다. 레시피에서 음식 엔티티를 추출하는 것이 당신의 임무입니다.\r\n\r\n---\r\n\r\n다음 형식을 따르세요.\r\n레시피: ${recipe}\r\n음식 엔티티 추출: ${extract_food_entities}. 단일 JSON 객체로 응답하세요. JSON 스키마: {\"$defs\": {\"FoodEntity\": {\"properties\": {\"food\": {\"description\": \"고기, 채소, 주류 등과 같이 고체 및 액체 음식일 수 있습니다\", \"title\": \"음식\", \"type\": \"string\"}, \"quantity\": {\"description\": \"레시피에 사용해야 하는 음식의 정확한 양 또는 분량\", \"title\": \"분량\", \"type\": \"integer\"}, \"unit\": {\"description\": \"사용 중인 단위 (예: 그램, 밀리리터, 파운드 등)\", \"title\": \"단위\", \"type\": \"string\"}, \"physical_quality\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"description\": \"재료의 특성\", \"title\": \"물리적 품질\"}, \"color\": {\"description\": \"음식의 색깔\", \"title\": \"색깔\", \"type\": \"string\"}, \"required\": [\"food\", \"quantity\", \"unit\", \"physical_quality\", \"color\"], \"title\": \"FoodEntity\", \"type\": \"object\"}, \"properties\": {\"entities\": {\"items\": {\"$ref\": \"#/$defs/FoodEntity\"}, \"title\": \"Entities\", \"type\": \"array\"}, \"required\": [\"entities\"], \"title\": \"FoodEntities\", \"type\": \"object\"}\r\n---\r\n레시피:\r\npork belly:\r\n{\r\n\"reasoning\": \"차슈 포크의 주 재료로 2 파운드의 삼겹살을 사용하도록 레시피에서 명시되어 있습니다.\",\r\n\"value\": \"2 파운드\",\r\n\"entity\": \"삼겹살\"\r\n}\r\ngreen onions:\r\n{\r\n\"reasoning\": \"2개의 대파가 필요하며, 작은 대파인 경우 3개를 사용합니다.\",\r\n\"value\": \"2 또는 3\",\r\n\"entity\": \"대파\"\r\n}\r\nfresh ginger:\r\n{\r\n\"reasoning\": \"레시피에는 신선한 생강 1인치가 필요하며, 이는 레시피에 대략 4~6개의 조각을 제공합니다.\",\r\n\"value\": \"1인치\",\r\n\"entity\": \"생강\"\r\n}\r\ngarlic:\r\n{ \r\n\"reasoning\": \"재료 중에는 마늘 2쪽이 필요합니다.\",\r\n\"value\": \"2쪽\",\r\n\"entity\": \"마늘\"\r\n}\r\nsake:\r\n{\r\n\"reasoning\": \"풍미를 위해 요리 액체에 ⅔컵의 사케가 사용됩니다.\",\r\n\"value\": \"⅔컵\",\r\n\"entity\": \"사케\"\r\n}\r\nsoy sauce:\r\n{\r\n\"reasoning\": \"요리 액체에 ⅔컵의 간장이 추가되어 요리의 맛을 더합니다.\",\r\n\"value\": \"⅔컵\",\r\n\"entity\": \"간장\"\r\n}\r\nmirin:\r\n{\r\n\"reasoning\": \"달콤하고 깊은 맛을 위해 레시피에 ¼컵의 미린이 포함됩니다.\",\r\n\"value\": \"¼컵\",\r\n\"entity\": \"미린\"\r\n}\r\nsugar:\r\n{\r\n\"reasoning\": \"요리 액체를 달게하기 위해 ½컵의 설탕을 사용합니다.\",\r\n\"value\": \"½컵\",\r\n\"entity\": \"설탕\"\r\n}\r\nwater:\r\n{\r\n\"reasoning\": \"삼겹살을 위한 요리 액체를 만들기 위해 2컵의 물(필요에 따라 더 추가 가능)이 필요합니다.\",\r\n\"value\": \"2컵\",\r\n\"entity\": \"물\"\r\n}\r\n음식 엔티티 추출: json\r\n{\r\n\"entities\": [\r\n{\r\n\"food\": \"삼겹살\",\r\n\"quantity\": 2,\r\n\"unit\": \"파운드\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"대파\",\r\n\"quantity\": 2,\r\n\"unit\": \"개\",\r\n\"physical_quality\": \"작으면 3개\",\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"생강\",\r\n\"quantity\": 1,\r\n\"unit\": \"인치\",\r\n\"physical_quality\": \"조각\",\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"마늘\",\r\n\"quantity\": 2,\r\n\"unit\": \"쪽\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"사케\",\r\n\"quantity\": 2,\r\n\"unit\": \"⅔컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"간장\",\r\n\"quantity\": 2,\r\n\"unit\": \"⅔컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"미린\",\r\n\"quantity\": 1,\r\n\"unit\": \"¼컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"설탕\",\r\n\"quantity\": 1,\r\n\"unit\": \"½컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"물\",\r\n\"quantity\": 2,\r\n\"unit\": \"컵\",\r\n\"physical_quality\": \"필요에 따라 추가\",\r\n\"color\": \"\"\r\n}\r\n]\r\n}\r\n``\r\n```\r\n\r\n# 마무리말\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 게시물의 목적은 DSPy 라이브러리를 익히고 TypedPredictor 클래스를 주로 NER 사용 사례에 사용하는 방법을 살펴보는 것이었습니다. 이제 여러분도 더 나은 이해를 하셨으면 좋겠습니다!\n\n첫 인상을 요약하면 다음과 같습니다:\n\n- DSPy는 사용하기 쉽고 시작하기 쉽습니다 ✅\n- 프롬프트 엔지니어링에 시간을 낭비하는 대신, 프레임워크가 대신 처리해 주는 것이 아주 좋습니다 ✅\n- LLM을 최적화 및 PyTorch와 같은 아이디어를 사용하여 \"전형적인\" ML 문제로 다루는 것이 매우 좋습니다 ✅\n- 여전히 발전 중이며 아마도 \"운영\"에 준비가 되지는 않았습니다 ❌\n- 프로그램을 디버깅할 때 무슨 일이 일어나고 있는지 이해하기 쉽도록 더 나은 로깅/추적이 필요합니다 ❌\n\n그러나 프롬프트를하는 대신 LLM을 프로그래밍하는 접근 방식을 좋아합니다. 이것은 분야에서 흥미로운 발전이며 예를 들어, 미래의 복합 AI 시스템에 대한 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nDSPY의 채택 및 추가 개발을 기대하고 있어요.\n\n# 참고 자료\n\n- 💻 DSPy 소개: 인사 대신 프로그래밍으로!\n- 💻 DSPy: 선언형 언어 모델 호출을 자가 개선 파이프라인으로 컴파일하기\n- 💻 DSPy 심층 탐구","ogImage":{"url":"/assets/img/2024-06-22-UsingDSPyforextractingmetadataNERstyle_0.png"},"coverImage":"/assets/img/2024-06-22-UsingDSPyforextractingmetadataNERstyle_0.png","tag":["Tech"],"readingTime":15},{"title":"애니메이션 데이터셋으로 Gemma-2b-it 미세 조정하는 방법","description":"","date":"2024-06-22 20:45","slug":"2024-06-22-FineTuningGemma-2b-itonAnimeDataset","content":"\n\n![FineTuningGemma-2b-itonAnimeDataset](/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_0.png)\n\n소개\n\n미세 조정 개념을 시작하기 전에, 먼저 \"왜 이러한 강력한 모델들에 대해 미세 조정이 필요한가?\"라는 질문에 대답해야 합니다.\n\n이 질문에 대답하기 위해 먼저 이 LLMs이(가) 인터넷에서 공개 데이터의 큰 말뭉치로 훈련되어 있으며 따라서 다양한 주제에 대한 아이디어를 가지고 있다는 것을 이해해야 합니다. 그러나 이들은 모든 주제에 대해 자세히 이해하거나 뱅킹이나 보험과 같은 개인 데이터에 대한 지식을 갖고 있지 않을 수도 있습니다. 특정 데이터에 대한 이해를 보완하기 위해, 우리는 그들을 이 특정 데이터에 대해 특별히 미세 조정합니다. 애니메이션 데이터는 공개적으로 이용 가능하지만, 이것들은 이 LLMs를 훈련하는 데 사용된 훈련 데이터의 매우 작은 조각일 수 있습니다. 따라서 LLMs가 애니메이션에 대한 개념을 가지고 있더라도, 그들의 정보 기반이 우리가 필요한 것만큼 풍부하지 않을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자원\n\n이제 세밀 조정이 필요한 이유에 대한 답변을 얻었으니, 이제 LLM을 세밀 조정하는 방법으로 넘어갈 수 있습니다. 저는 이 활동을 위해 사용한 자원은 다음과 같습니다.\n\n- 컴퓨팅 자원 — Google Colab T4 GPU\n- 데이터 세트 — https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset\n\nColab을 사용하기를 강력히 권장드립니다. 로컬 머신에 강력한 GPU 기능이 없는 경우에 말이죠. 다음으로, 우리는 세밀 조정된 오픈 소스 LLM을 이해하는 데 도움이 되는 두 가지 중요한 개념을 먼저 이해할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLoRA \u0026 QLoRA\n\nGemma-2b 모델에는 20억 개의 매개변수가 있습니다(당연한 얘기네요). 이러한 매개변수의 가중치를 조정하는 것은 매우 비싼 계산 작업일 수 있습니다. 이러한 모델들은 많은 VRAM을 소모할 수 있으며 모든 사용자가 이와 같은 높은 계산 능력을 갖춘 기계에 액세스할 수 있는 것은 아닙니다. 위의 계산 문제를 해결하기 위해 두 가지 기술이 널리 사용됩니다. 이 기술들은 LLMs를 세밀하게 조정할 수 있도록 합니다.\n\n- LoRA — 낮은 순위 적응\n- QLoRA — 양자화된 낮은 순위 적응\n\nLoRA — 이미 언급한 대로, 이러한 LLMs에는 수십억 개의 매개변수가 있습니다. 이러한 매개변수는 일반적으로 행렬로 표현됩니다. 이러한 고차원 행렬의 흥미로운 특성 중 하나는 완전 순위 행렬이 아니라는 것입니다. 즉, 행렬의 모든 열이 선형 독립이 아닙니다(한 열이 다른 열들의 선형 결합으로 표현될 수 있기 때문에 해당 열은 추가 정보를 제공하지 않고 차원만 늘려주는 것입니다). 그래서 LoRA는 이러한 거대한 가중치 행렬을 두 개의 작은 행렬인 A, B로 분해합니다. W = AB와 같이 W가 예를 들어 1000x1000 차원이라면, A는 1000xr 차원을 가지고 B는 r*1000 차원을 갖습니다. 그런 다음 세밀한 조정을 위해 이러한 작은 행렬의 매개변수를 조정하려고 시도합니다. r 하이퍼파라미터는 lora 구성을 정의할 때 선택하는 것입니다. r 값이 높을수록 우수한 결과를 얻을 수 있지만, 계산 능력이 필요하다는 대가가 따릅니다. 따라서 1000000 개의 매개변수를 조정해야 하는 대신, 대신 1000r + 1000r 개의 매개변수를 조정하게 됩니다. 일반적으로 r 값은 (8-64) 범위에 있으며 매우 높은 차원의 가중치 행렬을 다룰 때, 조정 가능한 매개변수 수가 상당히 줄어듭니다. 마지막으로 세밀한 조정 이후, 이러한 LoRA 가중치는 베이스 모델과 병합되어 세밀하게 조정된 단일 모델을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLoRA는 학습 매개변수의 수를 줄여주죠, 이제 모델을 파인 튜닝할 수 있을까요?\n\n네, 파인 튜닝은 가능하지만 더 개선할 여지도 있어요. 그런데 여기에 QLoRA가 등장합니다. QLoRA의 주요 목표는 단일 GPU에서 LLMs를 파인 튜닝하는 편리한 방법을 제공하는 것이죠(그들이 언급한 단일 GPU는 VRAM이 48GB입니다). QLoRA가 하는 일은 매우 기본적이면서 메모리 사용량을 줄이는 견고한 방법입니다. 모델 가중치의 정밀도를 변경합니다. 컴퓨터 시스템에서 모든 숫자는 특정 정밀도로 표현됩니다. 기본적으로 이러한 모델의 가중치는 32비트로 표현됩니다. QLoRA는 이러한 수를 32비트 대신 8 또는 4와 같이 낮은 비트로 표현하려고 시도합니다. 그리고 그 동작은 해당 수를 낮은 정밀도로 반올림하거나 버리는 것입니다. 이 과정을 통해 4배에서 8배까지 감소할 수 있습니다. 이를 위해 이들은 이론적으로 가장 최적인 것으로 설명되는 4비트 Normal-Float라는 새로운 데이터 유형을 도입했습니다(이는 대부분 사전 훈련된 모델 가중치의 경우입니다). 그들은 또한 메모리 증가를 피하기 위해 paged optimizers라는 개념을 소개했습니다. 이 개념은 GPU 용량이 거의 가득 찬 경우, 옵티마이저 상태를 CPU로 옮기도록 하는 것입니다. 그리고 GPU 메모리가 다시 사용 가능해지면 GPU로 다시 가져옵니다.\n\n코딩\n\n필요한 이론을 모두 숙지한 후에 이제 코딩 섹션으로 넘어갈 차례입니다. 먼저 필요한 라이브러리를 설치하고 가져오는 것부터 시작하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n!pip3 install -q -U bitsandbytes==0.42.0\n!pip3 install -q -U peft==0.8.2\n!pip3 install -q -U trl\n!pip3 install -q -U accelerate==0.27.1\n!pip3 install -q -U datasets==2.17.0\n!pip3 install -q -U transformers\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom trl import SFTTrainer\nimport torch\nimport pandas as pd\nimport bitsandbytes as bnb\nfrom datasets import Dataset\nimport transformers\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n```\n\n위와 같이 import 구문을 작성했습니다. 이제 사용할 모델에 대한 qlora config를 설정할 수 있습니다.\n\n```js\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n```\n\n여기서 우리는 모델 웨이트를 4비트로 로드하고 싶다고 지정했습니다. \"nf4\"로 유형을 지정했는데, 이는 이전에 언급한 일반적인 부동 소수점을 의미합니다. 마지막 매개변수인 bnb_4bit_compute_dtype는 사용할 그래디언트의 데이터 유형을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 모델을 다운로드하고 설정을 로드할 수 있습니다.\n\n```js\nmodel_id = \"google/gemma-2b-it\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\ntokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)\n```\n\n참고로, Gemma를 사용하려면 먼저 액세스를 요청해야 합니다. 그리고 다운로드하려면 먼저 hugging face에 로그인하여 액세스 토큰을 제공해야 다운로드할 수 있습니다. 위의 코드 셀을 실행하기 전에 huggingface_hub의 notebook_login을 사용하고 액세스 토큰을 제공하는 것을 추천합니다.\n\n미세 조정을 시작하기 전에 모델의 현재 애니메이션에 대한 지식 베이스를 먼저 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```py\ndef generate_response(model, tokenizer, prompt, tokens=100):\n    input_ids = tokenizer(prompt, return_tensors=\"pt\")\n    input_ids.to('cuda')\n    outputs = model.generate(**input_ids,max_new_tokens=tokens)\n    return tokenizer.decode(outputs[0])\n\nprompt = '''Question : Tell me something about the anime Naruto?\nAnswer :'''\n\nprint(generate_response(model,tokenizer,prompt))\n```\n\n만약 위 셀을 실행하면 아래와 같은 출력을 얻게 됩니다:\n\n`bos`Question : Tell me something about the anime Naruto? Answer :`eos`Naruto는 Masashi Kishimoto가 만든 일본의 애니메이션 시리즈입니다. 이 시리즈는 나루토 우즈마키의 모험을 따릅니다. 나루토는 세계 최고의 닌자가 되기를 꿈꾸는 젊은 닌자입니다. 이 시리즈는 200회가 넘는 에피소드와 영화로 큰 성공을 거두었습니다. 나루토는 캐릭터, 스토리텔링 및 애니메이션에 대해 칭찬을 받았습니다.`eos`\n\n나쁘지 않네요! 나루토가 매우 인기 있는 애니메이션으로 여겨지기 때문에 모델이 그것에 관한 정보를 가지고 있다고 예상했습니다. 이제 모델이 애니메이션에 대해 가진 지식을 향상시키는 것이 목표입니다. 그러기 위해 먼저 데이터셋을 탐색하여 모델에 추가할 수 있는 어떤 정보가 있는지 살펴보아야 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nanime_df = pd.read_csv(\"drive/My Drive/LLM/Data/anime_dataset.csv\")\r\n\"\"\"\r\nanime_id: 각 애니메이션에 대한 고유 ID입니다.\r\nName: 애니메이션의 원래 언어로 된 이름입니다.\r\nEnglish name: 애니메이션의 영어 이름입니다.\r\nOther name: 애니메이션의 원어로 된 이름 또는 제목입니다(일본어, 중국어 또는 한국어일 수 있습니다).\r\nScore: 애니메이션에 매겨진 평점이나 등급입니다.\r\nGenres: 쉼표로 구분된 애니메이션의 장르입니다.\r\nSynopsis: 애니메이션 플롯에 대한 간단한 설명 또는 요약입니다.\r\nType: 애니메이션의 유형(예: TV 시리즈, 영화, OVA 등)입니다.\r\nEpisodes: 애니메이션의 에피소드 수입니다.\r\nAired: 애니메이션이 방영된 날짜입니다.\r\nPremiered: 애니메이션이 처음 방영된 시즌과 년도입니다.\r\nStatus: 애니메이션의 상태(예: 방영 종료, 현재 방영 중 등)입니다.\r\nProducers: 애니메이션의 제작사 또는 프로듀서입니다.\r\nLicensors: 애니메이션의 라이센서(예: 스트리밍 플랫폼)입니다.\r\nStudios: 애니메이션에 참여한 애니메이션 스튜디오입니다.\r\nSource: 애니메이션의 소스 자료(예: 만화, 라이트 노벨, 오리지널)입니다.\r\nDuration: 각 에피소드의 기간입니다.\r\nRating: 애니메이션의 연령 등급입니다.\r\nRank: 인기도 또는 기타 기준에 따라 매겨진 애니메이션의 순위입니다.\r\nPopularity: 애니메이션의 인기 순위입니다.\r\nFavorites: 사용자들이 즐겨찾은 횟수입니다.\r\nScored By: 애니메이션을 평가한 사용자 수입니다.\r\nMembers: 플랫폼에 애니메이션을 리스트에 추가한 회원 수입니다.\r\nImage URL: 애니메이션의 이미지 또는 포스터 URL입니다.\r\n\"\"\"\r\n```\r\n\r\n우리는 이 데이터 사전을 캐글 링크에서 가져왔고 여기서 각 애니메이션에 대한 이름, 영어 이름부터 장르, 시놉시스, 에피소드 수, 제작 및 애니메이션 스튜디오 등의 매우 포괄적인 기능 목록이 있는 것을 볼 수 있습니다.\r\n\r\n이 프로젝트에서는 모델을 교육하는 데 사용할 세 가지 유형의 지시 형식을 작성할 것입니다.\r\n\r\n- 일반 정보 I — 애니메이션 이름(이름 변형 포함) 및 이야기와 장르.\r\n- 일반 정보 II — 애니메이션 이름 및 제작사, 애니메이션 스튜디오, 에피소드 수와 같은 세부 정보.\r\n- 일반 정보 III — 애니메이션 이름 및 등급, 인기도, 사용자 평가와 같은 메트릭스.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\ndef create_generic_information_1(df):\n  questions = []\n  answers = []\n  for name, variant, genre, synopsis in zip(df['English name'], df['Name'], df['Genres'], df['Synopsis']):\n    question = f\"애니메이션 {name} aka {variant}은(는) 무엇에 대해요?\"\n    answer = f\"애니메이션 {name} aka {variant}은(는) {genre} 장르의 애니메이션입니다. 줄거리는 다음과 같습니다: {synopsis}\"\n    questions.append(question)\n    answers.append(answer)\n\n  df['GI1_Question'] = questions\n  df['GI1_Answer'] = answers\n  return df\n\ndef create_generic_information_2(df):\n  questions = []\n  answers = []\n  for name, production_name, animation_house, number_of_episodes in zip(df['English name'],df['Producers'], df['Studios'], df['Episodes']):\n    question = f\"{name}의 제작사와 애니메이션 스튜디오는 누구였나요?\"\n    answer = f\"애니메이션 {name}은(는) {production_name}에 의해 제작되었습니다. 애니메이션은 {animation_house}에서 작업되었고, 이 중 {number_of_episodes}화가 있습니다.\"\n    questions.append(question)\n    answers.append(answer)\n\n  df['GI2_Question'] = questions\n  df['GI2_Answer'] = answers\n  return df\n\ndef create_generic_information_3(df):\n  questions = []\n  answers = []\n  for name, rating, score, votes in zip(df['Name'], df['Rating'], df['Score'], df['Scored By']):\n    question = f\"애니메이션 {name}의 리뷰는 어떤가요?\"\n    answer = f\"애니메이션 {name}은(는) 평가는 {rating}이고, {votes}명의 사용자에 의해 평가되었으며 점수는 {score}입니다.\"\n    questions.append(question)\n    answers.append(answer)\n\n  df['GI3_Question'] = questions\n  df['GI3_Answer'] = answers\n  return df\r\n``` \n\n이제부터 우리가 진행하기 전에 한 가지 알아야 할 사항이 있습니다. 각 LLM에는 명령을 입력하고 훈련하기 위한 특정 템플릿이 있습니다. 따라서 먼저 해당 템플릿에 기능을 로드한 다음 모델에 입력해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef formatting_func(question, answer):\n    text = f\"\u003cstart_of_turn\u003euser\\n{question}\u003cend_of_turn\u003e \u003cstart_of_turn\u003emodel\\n{answer}\u003cend_of_turn\u003e\"\n    return text\n\ndef generate_training_prompts(df, question_col, answer_col):\n  train_samples = []\n  for question, answer in zip(df[question_col], df[answer_col]):\n     train_samples.append(formatting_func(question, answer))\n  return train_samples\n\ntraining_prompts = []\n\nfor identifier in range(1,4):\n  question_col = f\"GI{identifier}_Question\"\n  answer_col = f\"GI{identifier}_Answer\"\n  samples = generate_training_prompts(anime_df,question_col, answer_col)\n  training_prompts += samples\n\ntraining_dataframe = pd.DataFrame()\ntraining_dataframe['instruction'] = training_prompts\ntraining_dataframe = training_dataframe.sample(frac=1,random_state=42)\ntraining_df = Dataset.from_pandas(training_dataframe)\n```\n\n위의 템플릿은 다음과 같습니다:\n\nf”`start_of_turn`user\\n'question'`end_of_turn` `start_of_turn`model\\n'answer'`end_of_turn`”\n\n위 템플릿은 각 학습 레코드마다 질문과 준비된 답변을 넣어야 하는 두 가지 매개변수만 가지고 있습니다. 따라서 위의 코드는 각 특성에 대해 이 템플릿 내에 질문과 답변을 감싸는 것뿐입니다. 마지막에는 학습을 위해 판다스 데이터프레임을 Dataset 객체로 변환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n학습 데이터가 이제 준비되었으므로, LoRA를 사용하여 모델을 세밀하게 튜닝하기 위해 모델을 설정할 수 있게 되었습니다.\n\n```js\n#1 \nmodel.gradient_checkpointing_enable()\n#2 \nmodel = prepare_model_for_kbit_training(model)\n\n#3 \ndef find_all_linear_names(model):\n  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n  lora_module_names = set()\n  for name, module in model.named_modules():\n    if isinstance(module, cls):\n      names = name.split('.')\n      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names: # needed for 16-bit\n      lora_module_names.remove('lm_head')\n  return list(lora_module_names)\n\n#4 \nmodules = find_all_linear_names(model)\n\n#5 \nlora_config = LoraConfig(\n    r=64,\n    lora_alpha=32,\n    target_modules=modules,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n#6\nmodel = get_peft_model(model, lora_config)\n\n#7\ntrainable, total = model.get_nb_trainable_parameters()\nprint(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")\r\n```\n\n이제 이를 단계별로 이해해봅시다.\n\n- 우리는 체크포인트를 사용하여 그라디언트를 저장할 수 있도록 설정합니다.\n- 모델을 k비트(QLoRA) 학습용으로 준비합니다.\n- 모델의 모든 선형 레이어의 이름을 반환하는 함수를 생성합니다. 이 함수는 모델의 키퀴리, 값, 그리고 출력 레이어를 반환합니다. 여기서 왜 이러한 레이어만을 반환하는지에 대해서 제가 완전히 확신하지는 못합니다. 그러나 아마도 어텐션 구성 요소(키, 쿼리, 값)가 다른 레이어보다 언어 이해에 중요한 역할을 하는 것으로 생각됩니다. 이 부분에서 잘못될 수도 있으며, 누군가가 제게 지적해 주시면 좋을 것 같습니다.\n- (3)에서 함수를 호출합니다.\n- LoRA 구성을 정의합니다. 여기서 r은 행렬을 분해하는 것에 대해 이전에 논의한 것과 동일합니다. lora alpha는 스케일링 요인을 말하며, lora 가중치가 기본 모델에 얼마나 강하게 영향을 미치는지를 나타냅니다.\n- LoRA 구성이 추가된 peft 모델 객체를 가져옵니다.\n- LoRA 구성에 기반하여 몇 개의 매개변수를 훈련하고 있는지 확인합니다. (결과: Trainable: 78446592 | total: 2584619008 | Percentage: 3.0351%). 이는 모델의 총 매개변수 중 3%만을 세밀하게 튜닝하고 있다는 것을 의미합니다. 3%로도 몇 번의 colab 메모리 부족이 발생했는데, 이는 LSTM 세밀 튜닝이 얼마나 계산적으로 비싼지를 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 훈련 프로세스를 시작할 수 있습니다.\n\n```js\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=training_df,\n    dataset_text_field=\"instruction\",\n    peft_config=lora_config,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=0.03,\n        max_steps=100,\n        learning_rate=2e-4,\n        logging_steps=1,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\",\n        save_strategy=\"epoch\",\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\nmodel.config.use_cache = False  # 경고 메시지를 무시합니다. 추론을 위해 다시 활성화하십시오!\ntrainer.train()\n```\n\nLLM을 훈련시키기 위해 허깅페이스의 SFTTrainer 클래스를 사용합니다. 모델, 데이터셋, 데이터셋의 텍스트 열, lora 구성 및 몇 가지 훈련 인수를 전달합니다. 그런 다음 실행을 설정합니다.\n\n\u003cimg src=\"/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n트레이닝 손실은 각 단계마다 여기에 표시됩니다. 실행이 완료되면 LoRA 레이어가 훈련됩니다. 이제 해야 할 일은 LoRA 레이어를 원래 모델로 병합하는 것입니다.\n\n```python\nft_model_path = \"drive/My Drive/LLM/Model/FT Model/\"\ntokenizer_path = \"drive/My Drive/LLM/Model/Tokenizer/\"\n\ntrainer.model.save_pretrained(ft_model_path)\ntokenizer.save_pretrained(tokenizer_path)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map={\"\": 0},\n)\nmerged_model = PeftModel.from_pretrained(base_model, ft_model_path)\nmerged_model = merged_model.merge_and_unload()\n```\n\n먼저 토크나이저와 훈련된 LoRA 레이어를 저장합니다(토크나이저를 다시 저장할 필요는 없습니다. 이전에 이미 한 번 다운로드하고 전혀 변경하지 않았습니다). 그 다음 Gemma-2b-it 모델을 다시로드하여 LoRA 레이어와 병합합니다.\n\n마지막 진행해야 할 단계는 세부 조정된 모델을 추론하는 것이며, 동일한 예시를 사용하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nprompt = '''애니메이션 나루토에 대해 알려주세요.\n대답 :'''\n\nprint(generate_response(merged_model, tokenizer, prompt))\n```\n\n`bos`애니메이션 나루토에 대해 알려주세요. 대답 :`eos`애니메이션 나루토는 액션, 모험, 판타지 장르의 애니메이션입니다. 줄거리는 다음과 같습니다 : 은밀한 잎 마을의 닌자 그룹이 마을 주민들을 돕기 위해 은밀한 잎의 땅으로 파견됩니다. 그러나 마을 리더 인 오로치마루에게 배신당해야하며 도망쳐야 합니다. 애니메이션 나루토는 1997년에 처음 방영되었으며 총 1.0 에피소드가 있습니다.\n\n그다지 좋지 않은 결과로 보입니다, 그렇지 않습니까?\n\n맞습니다. 하지만 1번의 에포크조차 교육시키지 않았으므로 모델을 더 많은 단계나 에포크로 교육하면 모델 출력이 향상될 것입니다. 그러나 여기서 주목할 점은 출력에서 이제 우리가 특징으로 포함했던 애니메이션의 장르를 제공하고 있다는 것입니다. 그래서 세밀한 조정이 애니메이션에 대한 지식베이스를 변경했음을 생각해봅니다 :)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마침내 이 기사를 읽어주셔서 정말 감사합니다. 피드백이나 제안 사항이 있으시면 알려주세요. 다음 기사에 반영하여 더 나은 내용을 제공하도록 하겠습니다.\n\n건배하세요!","ogImage":{"url":"/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_0.png"},"coverImage":"/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_0.png","tag":["Tech"],"readingTime":14},{"title":"LangChain의 새로운 도구, LangGraph 쉽게 설명하기","description":"","date":"2024-06-22 20:43","slug":"2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms","content":"\n\n# 소개\n\n하지만 왜 우리는 상태와 상태 전이 제어로 다시 돌아가고 있을까요? 자율 인공 지능 에이전트와 함께 우리는 상태 제어와 전이 개념을 넘어서 왔다고 생각했는데요?\n\n자율 에이전트의 출력을 살펴보면, 에이전트가 지속적으로 생성하는 작업 순서를 주목할 것입니다.\n\nLangGraph의 목표는 자율 인공 지능 에이전트를 실행할 때 일정한 수준의 제어를 갖는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n죄송합니다. 이 기사가 길었지만, Graph의 기본 원칙이 무엇인지 정말로 파악하고 싶었습니다.\n\n# 현황\n\n아래 이미지를 고려해보면, 이것이 대부분의 사람들이 대화형 UI를 위한 대화와 프로세스 흐름을 생성하는 사용자 인터페이스의 디자인 및 개발을 알게 된 방식입니다.\n\n디자인 기능은 노드 및 엣지라는 두 가지 주요 범주로 나뉠 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노드는 블록으로, 때로는 자산으로도 불립니다. 아래 그림에서 디자인 캔버스에는 다섯 개의 노드가 있습니다. 이 노드 간에는 링크 또는 엣지라고도 하는 연결이 있습니다. 엣지는 가능한 대상 노드나 노드를 보여줍니다.\n\n## 프롬프트 체이닝\n\n대형 언어 모델의 출현과 함께 프롬프트 체이닝이 등장했습니다...\n\n프롬프트 체이닝은 언어 모델과 작업할 때 사용되는 기술로, 여러 프롬프트(노드)가 서로 순차적으로 연결(엣지를 통해)되어 서로 관련된 작업이나 단계를 안내하는 것으로 설명될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 큰 작업을 작은 관리 가능한 부분으로 나눠 더 복잡하고 세밀한 결과물을 얻는 데 사용됩니다.\n\n다음은 프롬프트 체이닝 작동 방식에 대해 간단히 설명한 것입니다:\n\n- 작업 분해(노드): 복잡한 작업이 작은 순차적인 단계로 나누어집니다. 각 단계는 전체 목표의 특정 부분을 달성하는 데 사용됩니다.\n- 각 단계에 대한 프롬프트 생성(엣지): 각 단계에 대해 필수 출력물 생성을 위해 구체적인 프롬프트가 만들어집니다. 이러한 프롬프트는 해당 부분 작업에 집중되고 명확하게 설계됩니다.\n- 순차 실행: 언어 모델은 첫 번째 프롬프트를 처리하고 출력물을 생성합니다. 이 출력물은 다음 시퀀스의 다음 프롬프트의 일부로 사용됩니다.\n\n그러나 알아둬야 할 점은, 프롬프트 체이닝은 챗봇 흐름 구축과 동일한 원칙에 기반합니다. 따라서 이전과 같은 문제, 즉 엄격한 상태 머신이 존재합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n참으로, 프롬프트 체이닝에는 각 노드의 입력에 몇 가지 유연성을 도입하는 요소가 있어서 출력에는 동적 변화가 발생합니다. 그러나 전반적으로 시퀀스는 고정되고 엄격하게 유지됩니다.\n\n## 도전 과제\n\n이 방법론은 흐름을 세심하게 지정해야 하며 각 결정 지점을 정의해야 합니다. 이러한 이유로 본질적으로 상태 기계이며 대화 트리는 서로 다른 상태(노드)와 대화가 이동해야 하는 결정 지점(엣지)에 의해 정의됩니다.\n\n엣지는 대화 상태/대화 턴이 이동할 수 있는 옵션으로 볼 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 이 방법론의 한계로 인해 너무 엄격하다는 도전 과제에 닥치게 되었습니다. 대체로 변화를 원하는 욕구가 있으며, 융통성을 도입하고 싶어하는 분위기입니다.\n\n# 에이전트 입력\n\n자율 주체들은 최근에 소개되었으며, 에이전트의 자율성 수준은 놀라울 정도였습니다. 에이전트는 실시간으로 사건의 연쇄 또는 순서를 생성하고 이 일시적인 연쇄를 따라 최종적인 답변이 도출될 때까지 따릅니다.\n\n이것을 일회용 연쇄로 생각할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 예시를 고려해보면, 에이전트에게 매우 모호한 질문을 할 수 있습니다. 예를 들어 \"아이폰의 아버지로 평가받는 사람은 누구이며, 그의 출생 연도의 제곱근은 무엇입니까?\"\n\n또는 \n\n\"일반적으로 아이폰의 아버지로 평가받는 사람의 출생 연도의 제곱근은 무엇입니까?\" \n\n그리고 아래와 같이, 에이전트는 실시간으로 체인을 생성하여 질문을 반영하고 행동, 관찰, 사고, 행동, 관찰, 사고의 프로세스를 거쳐 최종 답변에 도달합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n\u003e 새 AgentExecutor 체인에 들어갔어요...\n아이폰의 아버지로 알려진 사람과 태어난 해를 알아내야 해요. 그리고 그의 출생 연도의 제곱근을 계산할 거예요.\n행동: 검색\n행동 입력: 아이폰 아버지 출생 연도\n관찰: 가족. 스티븐 폴 잡스는 조앤 캐롤 스키블과 아브둘파타 \"존\" 잔달리(아랍어: عبد الف ...)가 산프란시스코, 캘리포니아에서 1955년 2월 24일에 태어났어요.\n생각: 스티브 잡스가 아이폰의 아버지로 알려지고 1955년에 태어났다는 걸 알았어요. 이제 그의 출생 연도의 제곱근을 계산할 거예요.\n행동: 계산기\n행동 입력: sqrt(1955)\n관찰: 답변: 44.21538193886829\n생각: 이제 마지막 답을 알게 되었어요.\n최종 답변: 스티브 잡스가 아이폰의 아버지로 알려지고, 그의 태어난 연도(1955년)의 제곱근은 약 44.22입니다.\n\n\u003e 체인을 마쳤어요.\n'스티브 잡스가 아이폰의 아버지로 알려지고, 그의 태어난 연도(1955년)의 제곱근은 약 44.22입니다.\n```\n\n## 도전과제\n\n에이전트와 저에게 가장 많이 들은 상수적 비판점은 에이전트들의 높은 자율성입니다.\n\n생산자들은 에이전트에 어느 정도의 통제권을 가지고 싶어해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n헤이, 에이전트의 등장으로 우리는 지나치게 제어되고 엄격한 상황에서 더 큰 유연성으로 이동했지만 제어 부재로 인한 문제가 있습니다.\n\n# LangChain에서 LangGraph로 전환해보세요\n\n## 하지만 먼저, 데이터 유형으로서의 그래프란 무엇인가요?\n\n## 그래프(추상 데이터 유형)은 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래프 데이터의 개념은 처음에는 어렵게 느껴질 수 있지만, 여기서 그것을 쉽게 설명해보겠습니다.\n\n실제로 그래프는 추상 데이터 유형이에요...\n\n추상 데이터 유형은 데이터 유형에 대한 수학적 모델로, 데이터를 사용하는 사람의 관점에서 정의된 동작 (의미론)에 의해 정의됩니다.\n\n추상 데이터 유형은 데이터 구조와 대조적입니다. 데이터 구조는 데이터의 구체적 표현이며, 구현자의 관점이 아닌 사용자의 관점에서 정의됩니다. 이 데이터 구조는 덜 해석하기 어려우며 해석하기 쉬워요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 방향 그래프\n\n방향 그래프(또는 유향 그래프)는 방향성이 있는 엣지로 연결된 노드 집합으로 이루어진 그래프입니다.\n\n그래프 데이터 구조는 유향 그래프의 경우 노드의 유한 집합과 무방향 그래프의 경우 이러한 노드들의 순서가 없는 쌍의 집합으로 구성됩니다.\n\n아래의 그래프 표현을 고려할 때, 노드와 함께 엣지 및 엣지 옵션이 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## LangGraph\n\n다시 한번 아래 이미지를 보시면, 왼쪽에는 LangGraph Python 코드 조각이 표시되어 있고, 오른쪽에는 해당 그래프가 그려져 있습니다. 코드에서 노드가 정의된 부분을 보면, builder.add_node에 ReturnNodeValue가 사용되어 있습니다. 각 엣지가 정의된 노드에 대해 builder.add_edge가 호출됩니다.\n\n또한 a를 시작점으로, d를 완료점으로 설정해 두었음을 확인할 수 있습니다.\n\nLangGraph는 에이전트 런타임에서 자주 필요한 순환 그래프를 생성하기 위해 LangChain 위에 구축된 모듈입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLangChain의 큰 가치 제안 중 하나는 사용자 정의 체인을 쉽게 만들 수 있는 능력, 즉 flow engineering입니다. LangGraph를 LangChain 에이전트와 결합하여, 에이전트는 지향적이며 순환이 될 수 있습니다.\n\nDirected Acyclic Graph (DAG)는 컴퓨터 과학과 수학에서 사용되는 그래프 유형입니다. 간단히 설명하면 다음과 같습니다:\n\nDirected: 노드(또는 정점) 사이의 각 연결(또는 에지)에는 일방향의 방향이 있습니다. 한 노드에서 다른 노드로 갈 수 있는 방향을 보여줍니다.\n\nAcyclic: 어떤 사이클도 없습니다. 즉, 한 노드에서 시작하여 방향을 따라가면 결코 같은 노드로 되돌아갈 수 없습니다. 루프에 갇히는 방법이 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가족 트리나 플로우차트와 같이 앞으로만 움직이고 시작점으로 돌아갈 수 없는 구조로 생각해보세요.\n\n더 복잡한 LLM 응용 프로그램을 개발할 때 관찰되는 일반적인 패턴은 런타임에 순환이 도입되는 것입니다. 이러한 순환이 자주 발생하며 프로세스의 다음 단계를 결정하는 데 LLM을 사용합니다.\n\nLLM의 중요한 장점 중 하나는 이러한 추론 작업을 수행할 수 있는 능력이며, 사실상 for 루프에서 LLM과 같이 작동하는 것처럼 기능합니다. 이러한 접근 방식을 사용하는 시스템들은 종종 에이전트로 언급됩니다.\n\n# 에이전트 및 제어\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 루핑 에이전트는 종종 다양한 단계에서 세부적인 제어가 필요합니다.\n\n제작자들은 에이전트가 항상 특정 도구를 먼저 호출하도록 보장하거나 도구를 활용하는 방법에 대해 더 많은 제어를 필요로 할 수 있습니다.\n\n게다가, 현재 상태에 따라 에이전트에 대해 다른 프롬프트를 사용하길 원할 수도 있습니다.\n\n# 좁은 인터페이스 노출\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLangGraph은 LangChain을 기반으로 한 간소화된 인터페이스를 제공합니다.\n\n# LangGraph을 선택하는 이유\n\nLangGraph는 프레임워크에 구애받지 않으며, 각 노드는 일반 Python 함수로 작동합니다.\n\n스트리밍, 비동기, 일괄 호출에 대한 공통 인터페이스인 Runnable API를 확장하여 다음과 같은 기능을 지원합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 여러 대화 턴이나 도구 사용 사이에서 매끄러운 상태 관리\n- 동적 기준에 따라 노드 간 유연한 라우팅\n- LLM과 인간 개입 간 부드러운 전환\n- 장기간 또는 다중 세션 애플리케이션을 위한 지속성\n\n# LangGraph 챗봇\n\n아래는 Anthropik 모델을 기반으로 한 작동 중인 LangChain 챗봇입니다. 기본 코드는 그들의 요리책에 있는 LangChain 예제 코드를 복사했습니다.\n\n```js\n%%capture --no-stderr\n%pip install -U langgraph langsmith\n\n# 이 튜토리얼에서 사용합니다; LangGraph에 필요한 것은 아닙니다\n%pip install -U langchain_anthropic\n\n\n#################################\nimport getpass\nimport os\n\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n\n_set_env(\"ANTHROPIC_API_KEY\")\n#################################\nfrom typing import Annotated\n\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import StateGraph\nfrom langgraph.graph.message import add_messages\n\n\nclass State(TypedDict):\n    # 메시지는 \"list\" 유형입니다. 주석의 `add_messages` 함수\n    #은이 상태 키가 어떻게 업데이트되어야하는지 정의합니다.\n    #(이 경우, 목록에 메시지를 추가하여 덮어쓰지 않는 것)\n    messages: Annotated[list, add_messages]\n\n\ngraph_builder = StateGraph(State)\n#################################\nfrom langchain_anthropic import ChatAnthropic\n\nllm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n\n\ndef chatbot(state: State):\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n\n\n# 첫 번째 인수는 고유한 노드 이름입니다.\n# 두 번째 인수는 노드가 사용될 때 호출되는 함수 또는 객체입니다.\ngraph_builder.add_node(\"chatbot\", chatbot)\n#################################\ngraph_builder.set_entry_point(\"chatbot\")\n\n#################################\ngraph_builder.set_finish_point(\"chatbot\")\n#################################\ngraph = graph_builder.compile()\n#################################\nfrom IPython.display import Image, display\n\ntry:\n    display(Image(graph.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # 추가적인 종속성이 필요하며 선택 사항입니다\n    pass\n#################################\nwhile True:\n    user_input = input(\"사용자: \")\n    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n        print(\"안녕히가세요!\")\n        break\n    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n        for value in event.values():\n            print(\"보조:\", value[\"messages\"][-1].content)\n#################################\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 그래픽이 데이터의 흐름을 보여주는 방법을 보여줍니다.\n\n---\n마지막으로\n\n그래프 데이터 유형은 데이터의 시각적 표현을 보여주는 강력한 도구입니다. 시각적 표현 이상으로, 서로 다른 노드 간의 표현은 데이터 노드의 공간적 표현을 만드는 데 이상적입니다.\n\n데이터 사용자의 관점에서 그래프 데이터 유형은 데이터의 의미론적 행동에 이상적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n⭐️ 저를 팔로우해서 대형 언어 모델에 관한 업데이트를 받아보세요 ⭐️\n\n![이미지](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_0.png)\n\n저는 현재 Kore AI의 Chief Evangelist입니다. AI와 언어가 교차하는 모든 것을 탐구하고 쓰고 있습니다. 대형 언어 모델, 챗봇, 음성봇, 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제에 대해 다룹니다.\n\n![이미지](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 2](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_2.png)\n\n![Image 3](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_3.png)\n","ogImage":{"url":"/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_0.png"},"coverImage":"/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_0.png","tag":["Tech"],"readingTime":8},{"title":"AI, 우리 눈이 필요한 이유","description":"","date":"2024-06-22 20:42","slug":"2024-06-22-AINeedsOurEye","content":"\n\n## 우리 자신을 위해 어떻게 생각하는지 잊지 말아요\n\n![image](/assets/img/2024-06-22-AINeedsOurEye_0.png)\n\n우리는 인공 지능(AI)이 우리의 소중한 지적 성취물에 따라잡음에 따라 불안하게 어깨를 돌리곤 합니다. AI 챗봇은 바 및 의료 면허 시험을 통과하며, 논문 작성, 주문에 따른 이미지 생성, 회의록부터 과학 논문 요약까지 다양한 작업을 수행할 수 있습니다. 멸망을 예견하는 이들은 일자리와 인간의 목적의 상실 뿐만 아니라 인류 자체의 파괴까지 두려워합니다. 우리 기계가 자기보증을 목표로 배우면, 어쩌면 우리가 그들을 끄는 것을 방해할 정도로 완벽하게 통제에서 벗어날 수도 있습니다.\n\n멸망을 의심하는 사람들은 걱정하지 말라고 말합니다. 오늘날의 AI는 실제로 사고하지 않습니다. 강력한 챗봇은 단지 당신의 질의에 대한 다음 단어 추측을 기반으로 하여 인간과 유사한 응답을 만들도록 훈련됩니다. 내일의 AI가 더 나은 일을 할지라도, 본질적으로 다르지 않을 것입니다. 당신의 마음을 읽을 수 있다 하더라도, 그것은 입력을 받아 응답을 만드는 것 이상의 일을 하지 않을 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 뭐 어때요 — 우리는 불에 놀까요 아니면 여기 볼 게 없을까요? 아마 둘 다일지도 모릅니다. 2001년 '스페이스 오디세이'에서 HAL 9000이라는 감성적이고 살인적인 AI를 만들 수 있는지 여부는 불분명하지만, 생존을 중시하는 인간들은 AI를 통해 자신들의 멸종을 일으키지 않을 것이라는 합리적인 가정을 해 봅시다. 하지만 만약 우리가 컴퓨터로부터 스스로를 보호한다 해도, 우리 자신으로부터 안전한가요?\n\n비관론자들이 옳게 강조한 것처럼, AI 능력이 폭발적으로 증가하고 있는 속도를 과소평가해서는 안 됩니다. 그렇습니다, 대형 언어 모델(Large Language Models, LLMs)의 기본 원리는 단순할지 모르지만, 인간의 사고도 신경 신호의 생물학적 본질로 축소될 때 또한 단순합니다. 인지는 다양한 조직 계층에서 상호작용하는 방대한 수의 뉴런으로부터 발생합니다. 마찬가지로, LLM은 단어 사이의 의미와 관계를 포착하기 위해 고차원 공간에서 조직된 수십억 개의 텍스트 구성 요소(토큰)를 활용합니다. 인간과 LLM 모두에게 이러한 고수준 조직은 가변적이며 학습을 통해 발전합니다. 쌓인 인간 지식의 상당한 부분을 학습한 후, LLM 기반 챗봇은 인간과 유사한 추론 능력과 맥락 인식을 효과적으로 시연하거나 시뮬레이트합니다. 실제로 추론을 하지 않더라도 잘 하는 모습을 보입니다. 더욱 놀라운 것은, 그들이 창의성을 나타낼 수 있다는 점인데 — 기존 것을 종합하는 대신 새로운 아이디어를 발명하는 능력은 지성의 기준일 수 있습니다. 일상 물품에 대한 대체 사용법을 고안하기 위한 공통적인 창의성 시험에서 챗봇이 대부분의 인간을 능가합니다. 최근 AI는 계산 기하학의 오랫동안 난제에 대해 (인간) 수학자보다 나은 해결책을 찾아내었습니다.\n\n하지만 모든 질문에 대한 답을 알고 있다고 해서 똑똑한 것은 아닙니다, 그저 편리할 뿐입니다. 인간들을 괴롭히는 문제들 — 갈등부터 질병, 서식지 파괴까지 — 은 간단히 해결할 수 있는 방법이 없습니다. 어려운 문제들은 종종 중요한 피해를 방지할 수 없을 정도로 인지되지 않습니다. AI는 배운 것만 알 수 있고, 인간의 문제가 풍부한 영역에 진입할 수 없습니다. 유아들은 모험가고, 동료 및 낯선 어른들로 이상한 세상에서 길을 찾아가면서 배워야 할 것을 배우기 때문에 AI보다 지혜롭고 위험합니다. ChatGPT는 즐거움을 위해 화를 내거나 양침을 하지 않을 것입니다.\n\nAI는 특정 유형의 작업을 처리하는 데 가장 적합하며 — LLM을 제외하고 — 일반적으로 특정 유형의 작업을 처리하도록 개발됩니다. 모든 AI는 인간 창조자들에 의해 이미 어려운 문제 클래스로 인정된 문제유형에 존재합니다. \"딥 러닝\"은 복잡한 입력에서 패턴을 탐지하고 특징을 추출하기 위해 뇌와 유사한 여러 계층을 사용합니다. 음성을 인식하고 번역하며 사진에서 고양이를 찾고 질병을 진단하는 다양한 애플리케이션을 만드는 데 이러한 기술이 사용되었습니다. 이 모든 것들은 공통의 조상 패러다임인 '퍼셉트론'에서 비롯되었으며, 이는 물체를 분류하기 위해 제2차 세계 대전 중에 등장했습니다. 초기에는 뉴런 하나의 퍼셉트론이 그가 분류할 수 있는 물체를 이해하는 능력과 혼동되지 않았을 것입니다. 오늘날의 신경망은 단일 뉴런 퍼셉트론의 환상적으로 복잡한 후속 모델로, 인간인식을 회피하고 초인지를 감지하거나 능가할 정도로 미묘한 패턴을 탐지할 수 있습니다. AI는 \"기계 속에 귀신\" 분위기를 풍깁니다. 이것은 지난 세대부터 특수 기술과 지식을 보유한 사람들에게 맡겨져온 작업을 컴퓨터가 실행하는 모습으로 나타납니다. \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI의 문제는 전문가 수준으로 수행하지 않고 단지 전문가 수준에서 패턴을 인식한다는 것입니다. 저는 AI와 함께 일하는 과정 중에 의료 이미지를 분석하여 암의 징후를 확인하는 작업을 하고 있습니다. 부업으로, 미술사인 제 아내와 함께 그림과 드로잉 작품의 진품과 저작권 문제를 해결하기 위해 AI를 활용합니다. 두 가지 노력은 유사한 AI 아키텍처와 이미지 전처리 전략을 사용합니다. 어느 경우에도 AI는 관련 분야에 대해 \"알지\" 못합니다. 더 중요한 것은, AI가 어떻게 악성과 양성을 구별하거나, 렘브란트와 위조작가를 구별하는지에 대해 우리도 모르고 알 수 없습니다. AI의 판단의 기초는 식별할 수 있지만, 그 판단의 근거는 아직은 알 수 없습니다. \"설명 가능한\" AI를 개발하기 위한 노력은 AI 모델의 복잡성이 늘어남에 따라 실패했습니다.\n\nAI는 우리가 절대로 보지 못할 패턴을 인식하는 데 아주 뛰어나지만, 세계나 그 일부분의 특수성에 대해 아무것도 알지 못하기 때문에, AI는 바라는 대로 지혜롭지 않습니다. 그 판단의 근거를 제공하기 위해서는 너무 똑똑하지 않습니다. 결과적으로, 우리의 AI에 대한 신뢰는 그 성공 이력에서 거의 완전히 비롯됩니다. 이러한 성적은 전문가의 역량을 훼손시킬 수 있으며, AI 지원에 과도하게 의존하는 결과를 초래할 수 있습니다. 의료 분야에서 의사들은 의심스러운 AI 출력물에 직면할 때, 그것을 수정하는 데 필요한 임상 지식을 상실할 수도 있습니다. 어떻게 보면 오류에도 온전히 의존할 수 있습니다. 어떤 AI 시스템도 완벽하지 않습니다. 오류 가능성은 항상 존재하며, 그로 인해 과도한 의존 가능성도 존재합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image1](/assets/img/2024-06-22-AINeedsOurEye_1.png)\n","ogImage":{"url":"/assets/img/2024-06-22-AINeedsOurEye_0.png"},"coverImage":"/assets/img/2024-06-22-AINeedsOurEye_0.png","tag":["Tech"],"readingTime":4},{"title":"2024년 현실로 다가온 GenAI 기술과 그 영향","description":"","date":"2024-06-22 20:39","slug":"2024-06-22-GenAIReality","content":"\n\n좋은 것, 나쁜 것, 흥미로운 것\n\n![GenAIReality](/assets/img/2024-06-22-GenAIReality_0.png)\n\n내 핸드폰이 나의 사진 대신 AI(마법?)를 뿌려주길 제안했다. 위에 보이는 것은 전형적인 결과물이다. 오른쪽에 생성된 이미지는 흥미로운데, 여전히 진짜 것을 더 선호한다. 그럼에도 불구하고, GenAI는 어떤 유틸리티가 있기 때문에, 현재로서 그것은 무엇에 좋은가요?\n\n## 좋은 점: 가속화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n매일 어떤 종류의 GenAI 도구를 사용하는 것은 제 작업, 창의성 및 일반적인 사고 속도를 높이는 데 도움이 되는 것뿐만 아니라 향상된 AI는 실제로 저를 가속시킵니다 (어찌됐든, 제 차를 말이죠).\n\n저는 최근 새 차를 구입했고 포함된 다중 카메라 AI 시스템의 도움을 받아 운전하는 법을 다시 배우고 있습니다. 제 대시보드가 아래에 표시되어 있습니다. 주목할 점은 시스템이 제 차가 제 선로에 유지되고 있는지를 '본다는' 것이며, 만약 주행선을 이탈한다면 시스템이 경고하여 “핸들을 더 잡으세요”라고 말합니다. 즉, 이것은 자율 주행 기능이 아니라는 것을 강조합니다. 저는 차 간의 관찰 거리를 유지하기 위해 차량 간의 관찰된 거리를 유지하기 위해 차를 속도를 제어하는 카메라를 이용해서 정해진 거리만큼 차를 감속시키는 방식으로 운전거리를 설정합니다.\n\n조건 또는 요구에 따라 속도를 조절하려면 핸들 위의 위/아래 버튼으로 최대 속도를 조절할 수 있습니다.\n\n또한, 차를 '활성' 모드로 설정하면 핸들을 움직일 때 약간 더 강하게 움직이게되어 제가 이 카메라 지원 모드로 운전 중이라는 것을 나타내는 햅틱 신호로 작동합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n활성 모드를 중지하려면 브레이크나 가속 페달을 밟거나, 조향 휠의 버튼을 클릭하면 됩니다. 시스템은 피드백과 다양한 인간 개입 방법을 제공합니다.\n\n![GenAIReality_1](/assets/img/2024-06-22-GenAIReality_1.png)\n\n제가 GenAI LLM 도구를 이용하여 매일 하는 작업을 소개합니다:\n\n- ChatGPT/Gemini: 가상 클라우드 아키텍트 동료와 상황에 맞는 스레드 '토론'을 통해 클라우드 솔루션의 기술적 접근 방식을 검증\n- GitHub CoPilot: 다양한 응용 및 인프라 스크립팅 언어로 POC를 위한 시작 코드 샘플을 빠르게 생성\n- Gemini: 구글링하거나 StackOverflow 글을 읽는 것보다 빠르게 코드 버그 수정\n- DiagramsGPT: 생각을 명확히 하거나 요구 사항 또는 프로세스 문서 작성을 위해 종종 flowchart와 같은 초기 다이어그램 생성\n- DataAnalysisGPT: CSV, JSON 또는 VCF와 같은 파일에서의 데이터를 빠르게 요약\n- Gemini for BigQuery: 영어 프롬프트로부터 데이터 세트 쿼리를 생성하는 초기 SQL 코드 생성\n- Subaru Active Mode: 더 안전하게 운전하기.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 불량: 환각을 유발합니다\n\n사실 여러 가지 GenAI 도구들의 '환각'에 대한 끊임없는 토론(불평)들은 지루하다고 생각해요. 물론 GenAI LLMs이 이상한 이야기를 만들어내도, 왜 놀라는 건가요? 그들은 예측적이면서 결정론적이 아닌 도구들이니까요.\n\n저는 GenAI 도구들에게 황당한 질문을 하고, 그런 답변이 어떻게 그려졌는지 생각해보며 자신을 즐기고 있어요. 이렇게 장난치듯 실험을 해보는 건 특정 GenAI 도구의 기능에 대한 직관력을 얻기 위한 부분이라고 생각해요. 저는 그 도구가 무엇을 하는 지를 더 이해하려고 노력하고, 무엇을 할 수 있는 지나 할 수 없는 지에 대해 고민하는 것보다 더 중요하게 여겨요.\n\nLLMs는 인간 언어에 기반을 두고 있고, 저는 언어학자로 훈련을 받았어요. GenAI 도구의 문화와 구어체를 배우는 건 외국을 방문하는 것과 같은 느낌입니다 — 현지 사람들과 이야기를 나눠보면서 그 장소에 대해 조금씩 배우려고 노력해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n언어에도 여러 방언이 있는 것처럼 독일어에는 고지 독일어, 저지 독일어, 스위스 독일어 등이 있습니다. LLMs에는 채팅 도구, API, 앙상블 도구 등이 있으며, 따라서 동일한 모델이 다양한 도구나 인터페이스에서 작업할 때 다르게 응답할 수 있습니다.\n\n아래는 'Who's the baddest MOFO LLM and why?'라는 제 프롬프트에 대한 ChatGPT 4o, Claude 및 OpenGPT 4o LLMs의 응답입니다. 이 응답을 기반으로 'h체는 '보수적인 사람'인가요? '모든 것을 아는 사람'은 누구인가요? '엔터테인먼트 전문가'는 누구인가요?\n\n## 흥미로운: 실제 생산성\n\n최근 테스트해본 가장 흥미로운 (그리고 유용한) GenAI 구현은 통합된 GenAI 기능 세트인 GitHub Copilot Workspace입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n큰 이유를 이해하려면 Copilot Workspace의 간단한 예시를 보여드릴게요. 레포지토리로 이동해서 ‘Code’를 클릭하고 ‘Copilot’ 팝업 창에 작업을 작성해보세요. 작업을 시작하면 GitHub Copilot은 관련 레포지토리의 데이터를 분석하여 컨텍스트를 파악해요.\n\n다음으로 LLM이 컨텍스트로 인식하는 부분에 대한 피드백이 제공됩니다. 이는 사람이 읽을 수 있는 형태로 생성된 Specification으로 표시돼요. 해당 스펙에는 관련된 현재 정보와 제안된 업데이트가 포함돼요. LLM 기반 분석에서 놓친 중요한 컨텍스트가 있다면 수동으로 추가할 수 있어요.\n\n그런 다음, 추가적인 컨텍스트를 더할 수 있는 프로포즈드 플랜이 생성돼요. LLM이 중요한 부분을 놓친 경우를 대비해요.\n\n이후 변경 사항은 코드를 생성하여 구현돼요. 파일 차이점은 자동으로 확인을 위해 열려요. 제안된 변경 사항을 통합할 다양한 옵션이 제공돼요. 기본 옵션은 ‘풀 리퀘스트 생성’이지만, 다른 옵션들도 사용 가능해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n통합 방법을 선택한 후('현재 브랜치에 푸시'를 선택함), LLM은 검토를 위해 커밋 메시지 및 상세 설명을 생성합니다.\n\n더 긴 예시를 보여준 이유는 고객이 많이 사용하는 앱의 일부로 조정된 LLM의 첨단 구현을 설명하기 위함입니다. 프롬프트, 출력 및 UI의 일반적인 우수성을 사용자의 편의성과 워크플로의 여러 단계에서의 인간 검토 및 피드백의 핵심으로 커스터마이징하는 것이 중요합니다.\n\n각 단계에서 모델 출력은 예상 형식으로 제공되며, 인간 검토를 쉽게 구현할 수 있습니다.\n\n## 결론: 인간이 루프에 있어야 할 이유\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI로 완전히 관리되는 자율 주행 자동차는 현재 위험할 수 있습니다. 의료 자문, 수학 계산 또는 임무 중요성이 있는 다른 작업을 위해 검토되지 않은 LLM의 정보에 의존하는 것은 최선의 경우 어리석은 결정이며 여러 가지 방식으로 위험할 수 있습니다. \n\n그러나...\n\n자동 보험 회사는 매우 좋은 데이터가 없으면 할인율을 적용하지 않습니다. Github CoPilot 채택 속도도 실제 이야기를 전합니다.","ogImage":{"url":"/assets/img/2024-06-22-GenAIReality_0.png"},"coverImage":"/assets/img/2024-06-22-GenAIReality_0.png","tag":["Tech"],"readingTime":4}],"page":"26","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"26"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>