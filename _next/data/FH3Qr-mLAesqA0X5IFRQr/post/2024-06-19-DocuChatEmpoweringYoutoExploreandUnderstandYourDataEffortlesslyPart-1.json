{"pageProps":{"post":{"title":"문서챗 데이터를 손쉽게 탐색하고 이해하는 데 도움이 되는 방법  파트 1","description":"","date":"2024-06-19 19:14","slug":"2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1","content":"\n\n# 소개:\n\n대형 언어 모델(LLMs)의 가장 혁신적인 사용 사례 중 하나는 정교한 질의응답(Q&A) 챗봇을 개발하는 데 있습니다. 이러한 지능적인 시스템은 \"검색 증강 생성\"이라는 기술 덕분에 특정 데이터셋을 이용하여 질문에 대답하고 해석할 수 있습니다.\n\n본 기사는 기업용 챗봇을 구축하는 시리즈의 일환입니다. 우리는 기초적인 개념부터 시작하여 점차적으로 더 복잡한 주제로 나아갈 것입니다. 이 시리즈를 통해 다음과 같은 내용을 배우게 될 것입니다:\n\n- 메모리 인식 챗봇 구축을 위한 기초적인 개념: RAG, LangChain, LlamaIndex 등의 기초 개념부터 시작하여 챗봇이 맥락을 유지하고 일관된 장기적 상호작용을 제공할 수 있도록 합니다.\n- 고급 데이터 전처리 및 멀티모달 검색: 이미지나 테이블이 포함된 문서를 처리하여 챗봇이 이러한 데이터를 효과적으로 해석하고 활용할 수 있도록 합니다.\n- 기업용 데이터 수집: 기업 환경에 맞게 데이터 수집, 저장 및 조정을 위한 강력한 전략입니다.\n- 에이전트 전략: 기존 RAG 파이프라인 상에 에이전트를 구축하여 자동화된 의사결정 능력을 부여합니다.\n- 보안 및 거버넌스: 챗봇을 안전하게 보호하고 데이터 거버넌스 정책을 준수하는 데 필요한 모범 사례입니다.\n- 가시성: 챗봇의 건강과 성능을 유지하기 위해 모니터링 및 가시성을 구현합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_0.png\" />\n\n이 시리즈가 끝나면, 데이터 탐색과 이해를 쉽게 능력을 향상시킬 수 있는 강력한 기업급 챗봇을 구축하는 데 필요한 지식과 도구를 갖게 될 것입니다.\n\n## RAG란 무엇인가요?\n\nRAG는 LLM의 기능을 확장하여 추가 데이터를 통합하는 강력한 방법입니다. LLM은 다양한 주제를 토론할 수 있지만, 그들의 지식은 일정한 시점까지 공개 정보로 제한됩니다. 개인 정보나 보다 최근 데이터를 처리할 수 있는 AI 애플리케이션을 만들기 위해서는 모델의 지식을 관련 정보로 보충하는 것이 중요합니다.\n\n<div class=\"content-ad\"></div>\n\nRAG은 필요한 데이터를 검색하여 모델의 프롬프트에 삽입함으로써 이를 달성합니다. LangChain, LlamaIndex와 같은 프레임워크는 Q&A 애플리케이션 및 RAG 구현을 용이하게 하는 컴포넌트 스위트를 제공합니다. 전형적인 RAG 애플리케이션은 두 가지 주요 컴포넌트로 구성됩니다:\n\n- 색인화: 이는 여러 소스에서 데이터를 수집하고 색인화하는 파이프라인을 설정하는 과정입니다.\n\n- 데이터 로딩: 첫 번째 단계는 데이터를 로드하는 것인데, 여기서는 LangChain의 `PyPDFLoader`, `WebBaseLoader` 또는 LLamaIndex의 `SimpleDirectoryReader`와 같은 DocumentLoader를 사용합니다.\n- 텍스트 분할: 텍스트 분할기는 큰 문서를 작은 청크로 분할하여 검색이 쉽고 모델의 컨텍스트 창에 맞는 데이터로 만듭니다.\n- 데이터 저장: 분할된 데이터 청크는 추후 검색을 위해 저장되고 색인화됩니다. 이때 ChromaDB, Azure Search, AWS ElasticSearch와 같은 VectorStores(벡터 스토어)를 Embeddings 모델과 결합하여 종종 사용합니다.\n\n2. 검색 및 생성: 이 컴포넌트는 사용자 쿼리를 실시간으로 처리하고 색인에서 중요한 데이터를 검색하여 모델을 사용하여 응답을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n- 데이터 검색: 사용자가 쿼리를 입력하면, 관련 청크는 리트리버를 사용하여 저장소에서 검색됩니다.\n- 답변 생성: ChatModel 또는 LLM은 사용자의 질문과 검색된 데이터를 포함하여 답변을 생성합니다.\n\n## RAG 아키텍처\n\n![RAG 아키텍처](/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_1.png)\n\n```js\ndef process_pdf_simple(self, file_content):\n    # 문서 로드\n    loader = PyPDFLoader(file_content)\n    docs = loader.load()\n    \n    # 문서 분할\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000, \n        chunk_overlap=200\n    )\n    splits = text_splitter.split_documents(docs)\n    \n    # 문서 색인화\n    vectorstore = Chroma.from_documents(splits, self.embeddings)\n    \n    # 리트리버 정의\n    retriever = vectorstore.as_retriever()\r\n```\n\n<div class=\"content-ad\"></div>\n\n이 스니펫에서는 PyPDFLoader를 사용하여 PDF 콘텐츠를 초기화하고 문서를 로드합니다. 그런 다음 Chroma 클래스를 사용하여 문서 청크에서 벡터 저장소를 생성합니다. Chroma의 `from_documents` 메서드는 임베딩 모델을 사용하여 문서 분할에서 인덱스를 생성합니다. `as_retriever` 메서드는 벡터 저장소를 검색기 객체로 변환하여 챗봇이 인덱싱된 문서 청크를 검색하고 가장 관련성 높은 정보를 빠르게 찾을 수 있도록 합니다.\n\n# Q&A 챗봇의 주요 구성 요소:\n\n1. 챗 모델: 텍스트 기반 LLM과 달리 메시지 기반 상호작용에 최적화되어 더 자연스러운 대화 응답을 제공합니다.\n\n2. 프롬프트 템플릿: 이러한 템플릿은 기본 메시지, 사용자 입력, 채팅 기록 및 선택적으로 다른 소스에서 검색한 추가 컨텍스트를 결합하여 프롬프트를 만드는 데 도움이 됩니다. 이는 예를 들어, 금융 자문가로 챗봇을 가정하는 특정 페르소나를 만들어낼 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n3. 채팅 기록: 이 기능을 통해 챗봇은 과거 상호작용을 기억할 수 있어 후속 질문에 맥락을 제공하여 응답할 수 있습니다. Q&A 애플리케이션에서는 과거 질문과 답변을 기억하는 것이 일관된 대화를 위해 중요합니다.\n\n## 기록 인식 검색 구현:\n\n우리는 역사적 메시지와 최신 사용자 질문을 가져와 질문을 재정렬하여 이전 맥락없이도 이해할 수 있도록 할 서브-체인을 정의할 것입니다. 이를 위해 우리의 프롬프트에서 \"chat_history\"라는 `MessagesPlaceholder` 변수를 사용합니다. `create_history_aware_retriever`라는 도우미 함수를 사용하여 채팅 기록을 포함하고 시퀀스를 적용할 것입니다: `prompt | lIm | StrOutputParser | retriever`.\n\n```js\n####\n# 질문 맥락화\n####\ncontextualize_q_system_prompt = (\n    \"과거 채팅 기록과 최신 사용자 질문이 주어졌을 때, 채팅 기록에서 맥락을 참조할 수 있는 문제를 독립적으로 이해할 수 있는 혼자서도 이해할 수 있는 질문으로 재평가하세요. 질문에 대답하지 말고, 필요하다면 다시 정리하고 그렇지 않으면 그대로 반환하세요.\"\n)\n\ncontextualize_q_prompt = ChatPromptTemplate.from_messages(\n    (\"system\", contextualize_q_system_prompt),\n    MessagesPlaceholder(\"chat_history\"),\n    (\"human\", \"{input}\")\n)\n\nhistory_aware_retriever = create_history_aware_retriever(\n    self.llm, retriever, contextualize_q_prompt\n)\n```\n\n<div class=\"content-ad\"></div>\n\n## 전체 QA 체인 구축하기:\n\n마침내, 우리는 리트리버를 히스토리 인식 리트리버로 업데이트하고 `create_stuff_documents_chain`을 사용하여 질문-답변 체인을 구축할 것입니다. 이 체인은 검색된 컨텍스트, 채팅 기록 및 사용자 쿼리를 받아 답변을 생성합니다. 그런 다음 `create_retrieval_chain`을 사용하여 최종 RAG 체인을 구성합니다. 이 체인은 히스토리 인식 리트리버와 질문-답변 체인을 순차적으로 적용하여 검색된 컨텍스트와 같은 중간 출력을 유지합니다. 이러한 단계를 통해 과거 상호작용을 인식하고 기억하는 강력한 챗봇을 구축했습니다. 이는 사용자와의 원활하고 일관된 대화를 보장합니다.\n\n```js\n### 채팅 기록 상태 관리하기 ###\nstore = {}\n\n# 채팅 기록을 영속적으로 저장하고 있지 않지만, redis에 저장할 수도 있습니다\ndef get_session_history(session_id: str) -> BaseChatMessageHistory:\n    if session_id not in store:\n        store[session_id] = ChatMessageHistory()\n    return store[session_id]\n\nconversational_rag_chain = RunnableWithMessageHistory(\n    rag_chain,\n    get_session_history,\n    input_messages_key=\"input\",\n    history_messages_key=\"chat_history\",\n    output_messages_key=\"answer\"\n)\n\nreturn conversational_rag_chain\n```\n\n마지막으로, 입력 쿼리를 처리하고 색인된 문서 청크에서 관련 정보를 검색하는 conversational_rag_chain inbuilt 메서드 invoke를 호출할 수 있습니다. 결합된 질문, 컨텍스트 및 프롬프트는 LLM에 전송되어 응답을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nfile_path = 'amazon_2024_10q.pdf'\nuser_query = \"Amazon의 2024년 Q1 10-Q SEC 보고서에서 보고된 주요 재무 하이라이트 및 중요한 변화는 무엇입니까?\"\nobj = ConversationRetrieverAgent()\nchain = obj.process_pdf_simple(file_path)\nresult = chain.invoke({\"input\": user_query})\nprint(result[\"answer\"])\n```\n\n# 결론\n\nDocuChat 앱은 LangChain 및 검색 확장 생성 (RAG)과 같은 고급 기술을 활용하여 사용자가 데이터를 탐색하고 이해하는 데 편리하게 도와줍니다. 문서를 효율적으로 로드, 분리 및 색인화하고 정교한 검색 및 생성 기술을 활용하여, DocuChat은 사용자 쿼리에 정확하고 컨텍스트에 민감한 답변을 제공할 수 있습니다. 채팅 모델, 프롬프트 템플릿 및 채팅 기록을 통합함으로써 자연스럽고 일관된 대화를 보장합니다. 히스토리 인식 검색 및 견고한 세션 관리를 구현함으로써, DocuChat은 데이터를 더 접근 가능하고 실행 가능하게 만들어 스마트하고 원활한 상호 작용 경험을 제공합니다.\n\n# 다음 단계?\n\n<div class=\"content-ad\"></div>\n\n이번 시리즈의 다음 부분을 기대해주세요. 다음에는 고급 데이터 전처리와 멀티모달 검색에 대해 자세히 알아볼 것입니다. 이미지와 테이블을 포함한 문서를 어떻게 처리하는지, 이 데이터를 챗봇이 효과적으로 해석하고 활용하는 방법을 다룰 예정입니다. 이는 금융 서비스용 봇을 만들 때 특히 유용하며, SEC와 Bloomberg과 같은 출처에서 받은 금융 시장 데이터를 분석할 수 있게 해줍니다. 이 데이터는 종종 그래프, 지표, 테이블을 포함하고 있습니다. 이러한 통찰력을 놓치지 마시고 챗봇 역량을 향상시키세요!\n\n# 저자 정보\n\n이 기사를 읽어주셔서 감사합니다! 만약 여기서 논의된 전체 코드베이스를 보거나 완전히 기능하는 챗 앱을 사용해보고 싶다면, 아래 링크를 방문해 주세요:\n\n- LinkedIn: LinkedIn 프로필\n- GitHub: 이 기사의 전체 코드를 제 GitHub 프로필에서 확인하세요.\n- Streamlit: Streamlit 앱에서 완전히 기능하는 앱과 상호 작용해보세요. 기능을 탐색하고, 질문을 하며, DocuChat이 실시간으로 쿼리에 응답하는 방식을 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\nLinkedIn에서 업데이트, 토론 및 지적 응용 프로그램 구축에 대한 자세한 통찰력을 얻으세요. 피드백 및 기여는 언제나 환영합니다!\n\n참고 자료:\n\n- https://platform.openai.com/docs/quickstart\n- https://python.langchain.com/v0.2/docs/tutorials/chatbot/\n- https://blog.langchain.dev/semi-structured-multi-modal-rag/\n- https://docs.llamaindex.ai/en/stable/getting_started/concepts/","ogImage":{"url":"/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_0.png"},"coverImage":"/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_0.png","tag":["Tech"],"readingTime":7},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h1>소개:</h1>\n<p>대형 언어 모델(LLMs)의 가장 혁신적인 사용 사례 중 하나는 정교한 질의응답(Q&#x26;A) 챗봇을 개발하는 데 있습니다. 이러한 지능적인 시스템은 \"검색 증강 생성\"이라는 기술 덕분에 특정 데이터셋을 이용하여 질문에 대답하고 해석할 수 있습니다.</p>\n<p>본 기사는 기업용 챗봇을 구축하는 시리즈의 일환입니다. 우리는 기초적인 개념부터 시작하여 점차적으로 더 복잡한 주제로 나아갈 것입니다. 이 시리즈를 통해 다음과 같은 내용을 배우게 될 것입니다:</p>\n<ul>\n<li>메모리 인식 챗봇 구축을 위한 기초적인 개념: RAG, LangChain, LlamaIndex 등의 기초 개념부터 시작하여 챗봇이 맥락을 유지하고 일관된 장기적 상호작용을 제공할 수 있도록 합니다.</li>\n<li>고급 데이터 전처리 및 멀티모달 검색: 이미지나 테이블이 포함된 문서를 처리하여 챗봇이 이러한 데이터를 효과적으로 해석하고 활용할 수 있도록 합니다.</li>\n<li>기업용 데이터 수집: 기업 환경에 맞게 데이터 수집, 저장 및 조정을 위한 강력한 전략입니다.</li>\n<li>에이전트 전략: 기존 RAG 파이프라인 상에 에이전트를 구축하여 자동화된 의사결정 능력을 부여합니다.</li>\n<li>보안 및 거버넌스: 챗봇을 안전하게 보호하고 데이터 거버넌스 정책을 준수하는 데 필요한 모범 사례입니다.</li>\n<li>가시성: 챗봇의 건강과 성능을 유지하기 위해 모니터링 및 가시성을 구현합니다.</li>\n</ul>\n<p>이 시리즈가 끝나면, 데이터 탐색과 이해를 쉽게 능력을 향상시킬 수 있는 강력한 기업급 챗봇을 구축하는 데 필요한 지식과 도구를 갖게 될 것입니다.</p>\n<h2>RAG란 무엇인가요?</h2>\n<p>RAG는 LLM의 기능을 확장하여 추가 데이터를 통합하는 강력한 방법입니다. LLM은 다양한 주제를 토론할 수 있지만, 그들의 지식은 일정한 시점까지 공개 정보로 제한됩니다. 개인 정보나 보다 최근 데이터를 처리할 수 있는 AI 애플리케이션을 만들기 위해서는 모델의 지식을 관련 정보로 보충하는 것이 중요합니다.</p>\n<p>RAG은 필요한 데이터를 검색하여 모델의 프롬프트에 삽입함으로써 이를 달성합니다. LangChain, LlamaIndex와 같은 프레임워크는 Q&#x26;A 애플리케이션 및 RAG 구현을 용이하게 하는 컴포넌트 스위트를 제공합니다. 전형적인 RAG 애플리케이션은 두 가지 주요 컴포넌트로 구성됩니다:</p>\n<ul>\n<li>\n<p>색인화: 이는 여러 소스에서 데이터를 수집하고 색인화하는 파이프라인을 설정하는 과정입니다.</p>\n</li>\n<li>\n<p>데이터 로딩: 첫 번째 단계는 데이터를 로드하는 것인데, 여기서는 LangChain의 <code>PyPDFLoader</code>, <code>WebBaseLoader</code> 또는 LLamaIndex의 <code>SimpleDirectoryReader</code>와 같은 DocumentLoader를 사용합니다.</p>\n</li>\n<li>\n<p>텍스트 분할: 텍스트 분할기는 큰 문서를 작은 청크로 분할하여 검색이 쉽고 모델의 컨텍스트 창에 맞는 데이터로 만듭니다.</p>\n</li>\n<li>\n<p>데이터 저장: 분할된 데이터 청크는 추후 검색을 위해 저장되고 색인화됩니다. 이때 ChromaDB, Azure Search, AWS ElasticSearch와 같은 VectorStores(벡터 스토어)를 Embeddings 모델과 결합하여 종종 사용합니다.</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>검색 및 생성: 이 컴포넌트는 사용자 쿼리를 실시간으로 처리하고 색인에서 중요한 데이터를 검색하여 모델을 사용하여 응답을 생성합니다.</li>\n</ol>\n<ul>\n<li>데이터 검색: 사용자가 쿼리를 입력하면, 관련 청크는 리트리버를 사용하여 저장소에서 검색됩니다.</li>\n<li>답변 생성: ChatModel 또는 LLM은 사용자의 질문과 검색된 데이터를 포함하여 답변을 생성합니다.</li>\n</ul>\n<h2>RAG 아키텍처</h2>\n<p><img src=\"/assets/img/2024-06-19-DocuChatEmpoweringYoutoExploreandUnderstandYourDataEffortlesslyPart-1_1.png\" alt=\"RAG 아키텍처\"></p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">process_pdf_simple</span>(self, file_content):\n    # 문서 로드\n    loader = <span class=\"hljs-title class_\">PyPDFLoader</span>(file_content)\n    docs = loader.<span class=\"hljs-title function_\">load</span>()\n    \n    # 문서 분할\n    text_splitter = <span class=\"hljs-title class_\">RecursiveCharacterTextSplitter</span>(\n        chunk_size=<span class=\"hljs-number\">1000</span>, \n        chunk_overlap=<span class=\"hljs-number\">200</span>\n    )\n    splits = text_splitter.<span class=\"hljs-title function_\">split_documents</span>(docs)\n    \n    # 문서 색인화\n    vectorstore = <span class=\"hljs-title class_\">Chroma</span>.<span class=\"hljs-title function_\">from_documents</span>(splits, self.<span class=\"hljs-property\">embeddings</span>)\n    \n    # 리트리버 정의\n    retriever = vectorstore.<span class=\"hljs-title function_\">as_retriever</span>()\n</code></pre>\n<p>이 스니펫에서는 PyPDFLoader를 사용하여 PDF 콘텐츠를 초기화하고 문서를 로드합니다. 그런 다음 Chroma 클래스를 사용하여 문서 청크에서 벡터 저장소를 생성합니다. Chroma의 <code>from_documents</code> 메서드는 임베딩 모델을 사용하여 문서 분할에서 인덱스를 생성합니다. <code>as_retriever</code> 메서드는 벡터 저장소를 검색기 객체로 변환하여 챗봇이 인덱싱된 문서 청크를 검색하고 가장 관련성 높은 정보를 빠르게 찾을 수 있도록 합니다.</p>\n<h1>Q&#x26;A 챗봇의 주요 구성 요소:</h1>\n<ol>\n<li>\n<p>챗 모델: 텍스트 기반 LLM과 달리 메시지 기반 상호작용에 최적화되어 더 자연스러운 대화 응답을 제공합니다.</p>\n</li>\n<li>\n<p>프롬프트 템플릿: 이러한 템플릿은 기본 메시지, 사용자 입력, 채팅 기록 및 선택적으로 다른 소스에서 검색한 추가 컨텍스트를 결합하여 프롬프트를 만드는 데 도움이 됩니다. 이는 예를 들어, 금융 자문가로 챗봇을 가정하는 특정 페르소나를 만들어낼 수도 있습니다.</p>\n</li>\n</ol>\n<ol start=\"3\">\n<li>채팅 기록: 이 기능을 통해 챗봇은 과거 상호작용을 기억할 수 있어 후속 질문에 맥락을 제공하여 응답할 수 있습니다. Q&#x26;A 애플리케이션에서는 과거 질문과 답변을 기억하는 것이 일관된 대화를 위해 중요합니다.</li>\n</ol>\n<h2>기록 인식 검색 구현:</h2>\n<p>우리는 역사적 메시지와 최신 사용자 질문을 가져와 질문을 재정렬하여 이전 맥락없이도 이해할 수 있도록 할 서브-체인을 정의할 것입니다. 이를 위해 우리의 프롬프트에서 \"chat_history\"라는 <code>MessagesPlaceholder</code> 변수를 사용합니다. <code>create_history_aware_retriever</code>라는 도우미 함수를 사용하여 채팅 기록을 포함하고 시퀀스를 적용할 것입니다: <code>prompt | lIm | StrOutputParser | retriever</code>.</p>\n<pre><code class=\"hljs language-js\">####\n# 질문 맥락화\n####\ncontextualize_q_system_prompt = (\n    <span class=\"hljs-string\">\"과거 채팅 기록과 최신 사용자 질문이 주어졌을 때, 채팅 기록에서 맥락을 참조할 수 있는 문제를 독립적으로 이해할 수 있는 혼자서도 이해할 수 있는 질문으로 재평가하세요. 질문에 대답하지 말고, 필요하다면 다시 정리하고 그렇지 않으면 그대로 반환하세요.\"</span>\n)\n\ncontextualize_q_prompt = <span class=\"hljs-title class_\">ChatPromptTemplate</span>.<span class=\"hljs-title function_\">from_messages</span>(\n    (<span class=\"hljs-string\">\"system\"</span>, contextualize_q_system_prompt),\n    <span class=\"hljs-title class_\">MessagesPlaceholder</span>(<span class=\"hljs-string\">\"chat_history\"</span>),\n    (<span class=\"hljs-string\">\"human\"</span>, <span class=\"hljs-string\">\"{input}\"</span>)\n)\n\nhistory_aware_retriever = <span class=\"hljs-title function_\">create_history_aware_retriever</span>(\n    self.<span class=\"hljs-property\">llm</span>, retriever, contextualize_q_prompt\n)\n</code></pre>\n<h2>전체 QA 체인 구축하기:</h2>\n<p>마침내, 우리는 리트리버를 히스토리 인식 리트리버로 업데이트하고 <code>create_stuff_documents_chain</code>을 사용하여 질문-답변 체인을 구축할 것입니다. 이 체인은 검색된 컨텍스트, 채팅 기록 및 사용자 쿼리를 받아 답변을 생성합니다. 그런 다음 <code>create_retrieval_chain</code>을 사용하여 최종 RAG 체인을 구성합니다. 이 체인은 히스토리 인식 리트리버와 질문-답변 체인을 순차적으로 적용하여 검색된 컨텍스트와 같은 중간 출력을 유지합니다. 이러한 단계를 통해 과거 상호작용을 인식하고 기억하는 강력한 챗봇을 구축했습니다. 이는 사용자와의 원활하고 일관된 대화를 보장합니다.</p>\n<pre><code class=\"hljs language-js\">### 채팅 기록 상태 관리하기 ###\nstore = {}\n\n# 채팅 기록을 영속적으로 저장하고 있지 않지만, redis에 저장할 수도 있습니다\ndef <span class=\"hljs-title function_\">get_session_history</span>(<span class=\"hljs-attr\">session_id</span>: str) -> <span class=\"hljs-title class_\">BaseChatMessageHistory</span>:\n    <span class=\"hljs-keyword\">if</span> session_id not <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">store</span>:\n        store[session_id] = <span class=\"hljs-title class_\">ChatMessageHistory</span>()\n    <span class=\"hljs-keyword\">return</span> store[session_id]\n\nconversational_rag_chain = <span class=\"hljs-title class_\">RunnableWithMessageHistory</span>(\n    rag_chain,\n    get_session_history,\n    input_messages_key=<span class=\"hljs-string\">\"input\"</span>,\n    history_messages_key=<span class=\"hljs-string\">\"chat_history\"</span>,\n    output_messages_key=<span class=\"hljs-string\">\"answer\"</span>\n)\n\n<span class=\"hljs-keyword\">return</span> conversational_rag_chain\n</code></pre>\n<p>마지막으로, 입력 쿼리를 처리하고 색인된 문서 청크에서 관련 정보를 검색하는 conversational_rag_chain inbuilt 메서드 invoke를 호출할 수 있습니다. 결합된 질문, 컨텍스트 및 프롬프트는 LLM에 전송되어 응답을 생성합니다.</p>\n<pre><code class=\"hljs language-js\">file_path = <span class=\"hljs-string\">'amazon_2024_10q.pdf'</span>\nuser_query = <span class=\"hljs-string\">\"Amazon의 2024년 Q1 10-Q SEC 보고서에서 보고된 주요 재무 하이라이트 및 중요한 변화는 무엇입니까?\"</span>\nobj = <span class=\"hljs-title class_\">ConversationRetrieverAgent</span>()\nchain = obj.<span class=\"hljs-title function_\">process_pdf_simple</span>(file_path)\nresult = chain.<span class=\"hljs-title function_\">invoke</span>({<span class=\"hljs-string\">\"input\"</span>: user_query})\n<span class=\"hljs-title function_\">print</span>(result[<span class=\"hljs-string\">\"answer\"</span>])\n</code></pre>\n<h1>결론</h1>\n<p>DocuChat 앱은 LangChain 및 검색 확장 생성 (RAG)과 같은 고급 기술을 활용하여 사용자가 데이터를 탐색하고 이해하는 데 편리하게 도와줍니다. 문서를 효율적으로 로드, 분리 및 색인화하고 정교한 검색 및 생성 기술을 활용하여, DocuChat은 사용자 쿼리에 정확하고 컨텍스트에 민감한 답변을 제공할 수 있습니다. 채팅 모델, 프롬프트 템플릿 및 채팅 기록을 통합함으로써 자연스럽고 일관된 대화를 보장합니다. 히스토리 인식 검색 및 견고한 세션 관리를 구현함으로써, DocuChat은 데이터를 더 접근 가능하고 실행 가능하게 만들어 스마트하고 원활한 상호 작용 경험을 제공합니다.</p>\n<h1>다음 단계?</h1>\n<p>이번 시리즈의 다음 부분을 기대해주세요. 다음에는 고급 데이터 전처리와 멀티모달 검색에 대해 자세히 알아볼 것입니다. 이미지와 테이블을 포함한 문서를 어떻게 처리하는지, 이 데이터를 챗봇이 효과적으로 해석하고 활용하는 방법을 다룰 예정입니다. 이는 금융 서비스용 봇을 만들 때 특히 유용하며, SEC와 Bloomberg과 같은 출처에서 받은 금융 시장 데이터를 분석할 수 있게 해줍니다. 이 데이터는 종종 그래프, 지표, 테이블을 포함하고 있습니다. 이러한 통찰력을 놓치지 마시고 챗봇 역량을 향상시키세요!</p>\n<h1>저자 정보</h1>\n<p>이 기사를 읽어주셔서 감사합니다! 만약 여기서 논의된 전체 코드베이스를 보거나 완전히 기능하는 챗 앱을 사용해보고 싶다면, 아래 링크를 방문해 주세요:</p>\n<ul>\n<li>LinkedIn: LinkedIn 프로필</li>\n<li>GitHub: 이 기사의 전체 코드를 제 GitHub 프로필에서 확인하세요.</li>\n<li>Streamlit: Streamlit 앱에서 완전히 기능하는 앱과 상호 작용해보세요. 기능을 탐색하고, 질문을 하며, DocuChat이 실시간으로 쿼리에 응답하는 방식을 확인해보세요.</li>\n</ul>\n<p>LinkedIn에서 업데이트, 토론 및 지적 응용 프로그램 구축에 대한 자세한 통찰력을 얻으세요. 피드백 및 기여는 언제나 환영합니다!</p>\n<p>참고 자료:</p>\n<ul>\n<li><a href=\"https://platform.openai.com/docs/quickstart\" rel=\"nofollow\" target=\"_blank\">https://platform.openai.com/docs/quickstart</a></li>\n<li><a href=\"https://python.langchain.com/v0.2/docs/tutorials/chatbot/\" rel=\"nofollow\" target=\"_blank\">https://python.langchain.com/v0.2/docs/tutorials/chatbot/</a></li>\n<li><a href=\"https://blog.langchain.dev/semi-structured-multi-modal-rag/\" rel=\"nofollow\" target=\"_blank\">https://blog.langchain.dev/semi-structured-multi-modal-rag/</a></li>\n<li><a href=\"https://docs.llamaindex.ai/en/stable/getting_started/concepts/\" rel=\"nofollow\" target=\"_blank\">https://docs.llamaindex.ai/en/stable/getting_started/concepts/</a></li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}