{"pageProps":{"post":{"title":"라즈베리 파이를 사용한 자동 번호판 인식","description":"","date":"2024-06-20 17:43","slug":"2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi","content":"\n\n\n<img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_0.png\" />\n\n# 소개\n\n이 프로젝트의 목표는 Raspberry Pi 마이크로 컴퓨터를 사용하여 주차 장벽을 제어하기 위한 자동 번호판 인식 시스템을 설계하는 것입니다.\n\n왜 이 프로젝트를 하게 되었을까요?\n\n\n<div class=\"content-ad\"></div>\n\n어딘가에 참여 중인 프로젝트가 없는 Rpi가 하나 있고 카메라와 잠재적인 고민이 있는데요 ― 사무실 주차장에 자동 주차 장벽 제어 시스템이 없습니다. 그러니 이 프로젝트를 시작해보는 건 어떨까요?\n\n이 프로젝트의 목적은 생산에 적합한 안정적이고 경쟁력있는 솔루션을 만드는 것이 아니라, 한정된 장비를 사용하여 실제 문제를 위한 작동 제품을 만들면서 재미를 느끼는 것입니다. 그리고 그 이후에는 이 솔루션을 경량 엣지 디바이스에서 빠르게 작동하도록 최적화하는 재미도 봅시다)\n\n![image](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_1.png)\n\n일반적인 아이디어는 Rpi 카메라를 사용하여 일정 주기로 사진을 촬영하고, 이미지를 처리하여 차량 번호판을 감지하고 문자를 인식한 다음 데이터베이스에서 허용된 번호 목록과 비교하는 것입니다. 목록의 번호판과 일치한다면 장벽이 열릴 것입니다.\n\n<div class=\"content-ad\"></div>\n\n기본적인 단계에서는 다음 도구를 사용할 것입니다: \n\n- 이미지 소스 — Raspberry Pi Camera 모듈 v2;\n- 번호판 검출기 — pyTorch를 사용하여 제공되는 Yolo v7;\n- 광필 인식 (OCR) — EasyOCR;\n- \"데이터베이스\" — Google 시트의 테이블;\n\n모든 처리 작업과 계산은 Raspberry Pi 4b에서 로컬로 실행되어야 하며, 이 솔루션은 자율적으로 작동해야합니다.\n\n![이미지](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_2.png)\n\n<div class=\"content-ad\"></div>\n\n라즈베리 파이는 \"거의 실시간\"으로 Pi 카메라에서 프레임을 계속해서 읽습니다. 그런 다음, 사용자 정의 데이터셋 YOLOv7 모델을 미세 조정하여 번호판이 있는 영역을 감지합니다. 그 다음, 필요한 경우 이미지 전처리를 제공하고 EasyOCR 모델이 제공된 자르기된 프레임에서 번호를 감지합니다. 그런 다음 번호판 문자열을 \"데이터베이스\"에 저장된 번호판 중 어느 것과 일치하는지 확인하고 해당 작업을 실행합니다. 라즈베리 GPIO (General-Purpose Input-Output) - 제어 릴레이 스위치를 사용하여 주차장 장벽과 빛 등 추가 부하를 연결할 수 있습니다.\n\nGPIO 핀을 사용하면 입력 센서 (IR, PIR와 같은)를 연결하고 자동차가 감지됐을 때에만 카메라를 작동시킬 수 있습니다.\n\n이 작업은 여러 가지 방법으로 해결할 수 있습니다. 일부 방법은 특정 요구 사항과 사용 사례에 더 효율적이고 간편할 수 있습니다. 예를 들어, 모든 중요한 처리를 클라우드에서 수행하거나 GPU 기반 엣지 장치를 사용하거나 다른 모델을 사용할 수 있습니다. ONNX, TFLite 등을 사용하여 제공할 수도 있습니다. 그러나 이 프로젝트는 실험으로 진행되었고, 현재 사용 가능한 장비를 사용했으며, 쉬운 방법을 찾는 것이 아니었습니다 =)\n\n# 환경 설정\n\n<div class=\"content-ad\"></div>\n\n## 하드웨어 디자인\n\n필수 하드웨어:\n\n- 카메라 — Raspberry Pi Camera 모듈 v2 (Sony IMX219 8MPx, 1080p30, 720p60)\n- 엣지 디바이스 — Raspberry Pi 4 모델 B 4GB (CPU: Broadcom BCM2711, 쿼드 코어 Cortex-A72 (ARM v8) 64비트 SoC @ 1.5GHz; RAM: 4GB LPDDR4–3200 SDRAM; 40핀 GPIO 헤더; 2.4 GHz/5.0 GHz 802.11ac Wi-Fi, 블루투스 5.0)\n- SD 카드 (8GB)\n- 전원 공급 장치 — 5V 3A USB-C\n\n![image](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_3.png)\n\n<div class=\"content-ad\"></div>\n\n추가 내용:\n\n- 열흡수기, 냉각 팬\n- UPS\n- 디스플레이 (Waveshare 2.7인치 e-Paper HAT)\n- 외부 장치(장벽) 제어용 릴레이 / Raspberry HAT\n- 카메라 마운트 (\"카메라용 독특한 금속 와이어 마운트\" :))\n\n* 색깔 다시 채워주는 시간이 괜찮은 TFT 또는 OLED 유형의 화면을 사용하는 것이 좋지만, 그 당시에는 이 것만 사용할 수 있었습니다.\n\n[이미지](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_4.png)\n\n<div class=\"content-ad\"></div>\n\n설정하기\n\nPyTorch를 사용하여 솔루션을 만들기로 결정했으므로, Arm 64비트(aarch64)용 pip 패키지만 제공되므로 64비트 버전의 OS(데비안 버전: 11 - “Bullseye”)를 설치해야 합니다.\n\n최신 arm64 라즈베리 파이 OS는 공식 사이트에서 다운로드할 수 있으며 rpi-imager를 통해 설치할 수 있습니다.\n\n설치가 완료되면 다음과 같아야 합니다:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_5.png\" />\n\n라즈베리 파이에 SD 카드를 삽입한 후 부팅하면 다음과 같은 설정을 수행해야 합니다:\n\n/boot/config.txt 파일을 수정하여 카메라를 활성화합니다.\n\n```js\n# 이는 카메라와 같은 확장 기능을 사용하도록합니다.\nstart_x=1\n# 카메라 처리에 적어도 128M이 필요하며 더 크면 그대로 둘 수 있습니다.\ngpu_mem=128\n# 기존의 camera_auto_detect 줄을 주석 처리/삭제해야합니다. 이것은 OpenCV/V4L2 캡처에서 문제를 일으킵니다.\n#camera_auto_detect=1\n```\n\n<div class=\"content-ad\"></div>\n\n또한 아마 I2C, SSH 및 VNC을 활성화하려고 할 것입니다. 이 작업은 raspi-config 또는 GUI에서 할 수 있습니다.\n\n![image](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_6.png)\n\n요구 사항 설치\n\n저는 Python 버전 3.9 및 3.10을 사용했습니다. 일부 경우에 따르면 3.11 버전이 더 빠르다고 보고되지만 아직 안정적인 PyTorch가 3.11에는 없습니다.\n\n<div class=\"content-ad\"></div>\n\n`requirements.txt` 파일을 사용하여 pip 패키지 관리자를 통해 모든 필요한 라이브러리와 모듈을 설치하세요:\n\n\nmatplotlib>=3.2.2\nnumpy>=1.18.5\nopencv-python==4.5.4.60\nopencv-contrib-python==4.5.4.60\nPillow>=7.1.2\nPyYAML>=5.3.1\nrequests>=2.23.0\nscipy>=1.4.1\ntorch>=1.7.0,!=1.12.0\ntorchvision>=0.8.1,!=0.13.0\ntqdm>=4.41.0\nprotobuf<4.21.3\ntensorboard>=2.4.1\npandas>=1.1.4\nseaborn>=0.11.0\neasyocr>=1.6.2\n\n\n수동으로 직접 설치하거나 기존 환경에 구현할 경우 (하지 마세요 :)), 현재 OpenCV 버전에 문제가 있으므로 정확한 버전 4.5.4.60을 설치해야 합니다.\n\n모든 것이 올바르게 설치되었는지 확인하려면 `pip list` 명령어를 사용하세요.\n\n<div class=\"content-ad\"></div>\n\n`<img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_7.png\" />`\n\n그럼, 하드웨어와 환경을 설정해놓았으니 코딩을 시작해봅시다.\n\n# 소프트웨어 설계\n\n이미지 캡쳐\n\n<div class=\"content-ad\"></div>\n\n이미지 캡처를 위해 표준 picamera 라이브러리 대신 OpenCV를 사용하여 비디오 프레임을 스트리밍할 것입니다. 64비트 OS에서 picamera 라이브러리를 사용할 수 없고 그 속도도 느립니다. OpenCV는 직접 /dev/video0 장치에 액세스하여 프레임을 캡처합니다.\n\nOpenCV 카메라 읽기를 위한 사용자 정의 간단한 래퍼:\n\n```python\nclass PiCamera():\n    def __init__(self, src=0, img_size=(640,480), fps=36, rotate_180=False):\n        self.img_size = img_size\n        self.fps = fps\n        self.cap = cv2.VideoCapture(src)\n        #self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n        #self.cap.set(cv2.CAP_PROP_FPS, self.fps)\n        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.img_size[0])\n        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.img_size[1])\n        self.rotate_180 = rotate_180\n    def run(self):       \n        # 프레임 읽기\n        ret, image = self.cap.read()\n        if self.rotate_180:\n            image = cv2.rotate(image, cv2.ROTATE_180)\n        if not ret:\n            raise RuntimeError(\"프레임 읽기 실패\")\n        return image \n```\n\n여기서 카메라가 뒤집혀 있기 때문에 `image = cv2.rotate(image, cv2.ROTATE_180)`를 사용하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n버퍼 크기와 FPS 설정은 랙을 고치고 프레임 스트림을 적절하게 정렬하는 데 사용할 수 있습니다. 그러나 제 경우에는 카메라 제조사 및 프레임을 읽는 데 사용된 백엔드에 따라 달라서 작동하지 않습니다.\n\n카메라에서 이미지가 캡처된 후, 우리는 번호판을 감지하는 작업을 시작하여 이미지를 처리해야 합니다.\n\n번호판 감지 모듈\n\n이 작업에는 YOLOv7 사전 훈련된 모델을 사용할 것입니다. 이 모델을 사용하여 사용자 지정 번호판 데이터 세트에 대해 미세 조정할 것입니다.\n\n<div class=\"content-ad\"></div>\n\nYOLOv7는 정확성과 속도 측면에서 최신 기술인 실시간 객체 감지 알고리즘입니다. COCO 데이터셋에 미리 학습되어 있습니다.\n\n이 알고리즘에 대한 자세한 내용은 다음 논문에서 확인할 수 있어요: YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors.\n\n![이미지](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_8.png)\n\n공식 저장소에서 YOLOv7 레포지토리를 복제해보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\ngit clone https://github.com/WongKinYiu/yolov7.git\ncd yolov7\n```\n\n요로 요구 사항은 위에서 설치한 프로젝트 요구 사항에 이미 흡수되었습니다.\n\nFine-tuning을 위해 YOLOv7의 사전 훈련된 작은 버전인 이미지 크기 640을 적용하겠습니다.\n\n```js\n# 사전 훈련된 가중치 다운로드\n!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt\n```\n\n<div class=\"content-ad\"></div>\n\n기본 사전 훈련된 물체 탐지:\n\n![image](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_9.png)\n\nNumberplate Detection Model training\n\n커스텀 데이터셋에 대한 모델 훈련은 꽤 간단하고 직관적입니다.\n\n<div class=\"content-ad\"></div>\n\n친구야, 좋은 GPU를 이용해 Google Colab에서 모델 파인 튜닝을 진행할 거야.\n\n시작하기 전에 단일 번호판 클래스로 적절한 데이터셋을 생성하고 레이블을 지정해야 해.\n\n나의 데이터셋은 나만의 사진을 기반으로 부분적으로 만들었으며 AUTO.RIA Numberplate Dataset에서 일부를 활용했어 (이 멋진 분들에게 감사합니다!). 총 2000장의 이미지를 사용했어.\n\n레이블링은 Yolo 포맷으로 roboflow 서비스를 통해 진행했어.\n\n<div class=\"content-ad\"></div>\n\n```yaml\ntrain: dataset/train\nval: dataset/valid\n# Classes\nnc: 1  # number of classes\nnames: ['numberplate']  # class names\n```\n\n모델을 훈련하세요.\n\n<div class=\"content-ad\"></div>\n\n```yaml\npython train.py --epochs 25 --workers 8 --device 0 --batch-size 32 --data data/numberplates.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights 'yolov7-tiny.pt' --name yolov7_tiny_numberplates --hyp data/hyp.scratch.tiny.yaml\n``` \n\nBaseline으로 25회의 에포크가 충분하다고 결정했어요.\n\n![AutomaticNumberPlateRecognitionwithRaspberryPi_11.png](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_11.png)\n\n추론:\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_12.png\" />\n\n프로젝트의 첫 번째 버전으로는 충분해 보이지만, 실제 응용 프로그램 중 발견된 특수 사례들을 통해 나중에 업데이트할 수 있습니다.\n\nYOLOv7 디텍터를 위한 추상적인 간단한 래퍼 클래스를 생성하였습니다:\n\n```js\nclass Detector():\n    def __init__(self, model_weights, img_size=640, device='cpu', half=False, trace=True, log_level='INFO', log_dir = './logs/'):\n        # 초기화\n        self.model_weights = model_weights\n        self.img_size = img_size\n        self.device = torch.device(device)\n        self.half = half  # half = device.type != 'cpu'  # half precision only supported on CUDA\n        self.trace = trace  # 모델을 Traced-모델로 변환\n        self.log_level = log_level\n        if self.log_level:\n            self.num_log_level = getattr(logging, self.log_level.upper(), 20) ##log_level 입력 문자열을 로깅 모듈이 허용하는 값 중 하나로 변환합니다. 값이 없다면 20 - INFO로 설정됩니다.\n            self.log_dir = log_dir\n            log_formatter = logging.Formatter(\"%(asctime)s %(message)s\")\n            logFile = self.log_dir + 'detection.log'\n            my_handler = RotatingFileHandler(logFile, mode='a', maxBytes=25 * 1024 * 1024,\n                                             backupCount=10, encoding='utf-8', delay=False)\n            my_handler.setFormatter(log_formatter)\n            my_handler.setLevel(self.num_log_level)\n            self.logger = logging.getLogger(__name__)  \n            self.logger.setLevel(self.num_log_level)\n            self.logger.addHandler(my_handler)\n        # YOLO 모델의 경로를 추가합니다. ('weights.pt')를 로드할 때마다, pytorch는 path 환경 변수(models/yolo)에서 모델 구성을 찾습니다.\n        yolo_folder_dir = str(Path(__file__).parent.absolute()) +\"\\yolov7\" #  모델 폴더 경로\n        sys.path.insert(0, yolo_folder_dir)\n        # 모델 로드\n        self.model = attempt_load(self.model_weights, map_location=self.device)  # FP32 모델 로드\n        # 모델을 Traced-모델로 변환\n        if self.trace:\n            self.model = TracedModel(self.model, self.device, self.img_size)\n        # if half:\n        #     model.half()  # to FP16\n        # 이름과 색상 가져오기\n        self.names = self.model.module.names if hasattr(self.model, 'module') else self.model.names\n        if len(self.names) > 1:\n            self.colors = [[0, 255, 127]] + [[random.randint(0, 255) for _ in range(3)] for _ in self.names[1:]]\n        else:\n            self.colors = [[0, 255, 127]]\n        sys.path.remove(yolo_folder_dir)\n    def run(self, inp_image, conf_thres=0.25):\n        # 추론 실행\n        # 데이터 로드\n        dataset = LoadImage(inp_image, device=self.device, half=self.half)\n        t0 = time.time()\n        self.file_name, self.img, self.im0 = dataset.preprocess()\n        # 추론\n        t1 = time.time()\n        with torch.no_grad():  # 그래디언트를 계산하면 GPU 메모리 누수가 발생할 수 있습니다\n            self.pred = self.model(self.img)[0]\n        t2 = time.time()\n        # NMS 적용\n        self.pred = non_max_suppression(self.pred, conf_thres=conf_thres)\n        t3 = time.time()\n        # 검출 처리\n        bbox = None  # 최대 Confidence를 가진 검출 객체의 바운딩 상자\n        cropped_img = None  # 최대 Confidence를 가진 검출 객체를 자른 이미지\n        det_conf = None  # 최대 Confidence를 가진 검출 객체의 신뢰 수준\n        self.det = self.pred[0]  # pred[0] - NMX suppr는 이미지 당 1개의 텐서를 반환합니다;\n        if len(self.det):\n            # img_size에서 im0 크기로 상자 크기 조정\n            self.det[:, :4] = scale_coords(self.img.shape[2:], self.det[:, :4], self.im0.shape).round()\n            # 결과 출력\n            print_strng = \"\"\n            for c in self.det[:, -1].unique():\n                n = (self.det[:, -1] == c).sum()  # 클래스 당 검출\n                print_strng += f\"{n} {self.names[int(c)]}{'s' * (n > 1)}\"  # 문자열에 추가\n            # 시간 출력(추론 + NMS)\n            print(\n                f'{print_strng} 검출. ({(1E3 * (t1 - t0)):.1f}ms)-데이터 로드, ({(1E3 * (t2 - t1)):.1f}ms)-추론, ({(1E3 * (t3 - t2)):.1f}ms)-NMS')\n            # 디버그 모드이면 결과를 파일에 기록\n            if self.log_level:\n                self.logger.debug(\n                    f'{self.file_name} {print_strng} 검출. ({(1E3 * (t1 - t0)):.1f}ms)-Load data, ({(1E3 * (t2 - t1)):.1f}ms)-Inference, ({(1E3 * (t3 - t2)):.1f}ms)-NMS')\n                if self.logger.getEffectiveLevel() == 10:  # 레벨 10 = 디버그\n                    gn = torch.tensor(self.im0.shape)[[1, 0, 1, 0]]  # 정규화 gain whwh\n                    for *xyxy, conf, cls in reversed(self.det):\n                        # 바운딩 박스와 함께 xywh 형식으로 검출 저장\n                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # 정규화된 xywh\n                        line = (int(cls), np.round(conf, 3), *xywh)  # 라벨 형식\n                        self.logger.debug(f\"{self.file_name} {('%g ' * len(line)).rstrip() % line}\")\n            # 최대 Confidence를 가진 검출 찾기:\n            indx = self.pred[0].argmax(0)[\n                4]  # pred[0] - NMX suppr는 이미지 당 1개의 텐서를 반환; argmax(0)[4] - conf는 [x1,y1,x2,y2,conf,cls]에서 indx 4를 가짐\n            max_det = self.pred[0][indx]\n            # 검출 바운딩 상자와 해당 자른 이미지 수집\n            bbox = max_det[:4]\n            cropped_img = save_crop(max_det[:4], self.im0)\n            cropped_img = cropped_img[:, :, ::-1] # BGR to RGB\n            det_conf = max_det[4:5]\n        print(f'검출 총 시간: {time.time() - t0:.3f}s')\n        return {'file_name': self.file_name, 'orig_img': self.im0, 'cropped_img': cropped_img, 'bbox': bbox,\n                'det_conf': det_conf}\n```    \n\n\n<div class=\"content-ad\"></div>\n\n디버깅 목적을 위해 로깅 감지 데이터를 파일에 활성화할 수 있는 기능을 추가했습니다. 각 파일의 최대 크기는 25Mb이며 최대 10개의 파일을 저장한 후 덮어쓰기합니다.\n\n현재 작업에서는 감지기가 가장 높은 신뢰 점수를 가진 단일 감지만 반환하도록 설정해야 합니다. 감지기는 원본 이미지, 해당 경계 상자와 함께 자르기 감지된 영역, 신뢰 점수, 그리고 디버깅을 용이하게 하기 위해 각 이미지마다 생성된 고유한 이름을 출력합니다.\n\n번호판 영역 이미지 전처리\n\n일반적으로 다음 단계는 특정 이미지 전처리(예: RGB에서 그레이스케일로 변환, 노이즈 제거, 침식 + 팽창, 임계 처리, 히스토그램 평활화 등)를 수행하여 다음 OCR 단계를 위해 준비하는 것입니다. 전처리 작업은 OCR 솔루션 및 촬영 조건에 매우 의존하며 이에 맞게 조정됩니다. 그러나 EasyOCR로 이 기준 버전을 수행 중이며(나중에 사용자 지정 솔루션으로 대체해야 합니다), 저는 그레이스케일 변환 및 투영 프로필 방법을 이용한 기울기 보정이라는 두 가지 범용적인 단계로 전처리를 제한하기로 결정했습니다.\n\n<div class=\"content-ad\"></div>\n\n여기서는 평면 각도 보정을 사용하고 있지만 나중에는 원래의 번호판 모서리 탐지기와 호모그래피 계산 및 원근 변환을 사용한 보정으로 업데이트해야 합니다.\n\n```js\n# Skew Correction (projection profile)\ndef _find_score(arr, angle):\n    data = rotate(arr, angle, reshape=False, order=0)\n    hist = np.sum(data, axis=1)\n    score = np.sum((hist[1:] - hist[:-1]) ** 2)\n    return hist, score\n\ndef _find_angle(img, delta=0.5, limit=10):\n    angles = np.arange(-limit, limit+delta, delta)\n    scores = []\n    for angle in angles:\n        hist, score = _find_score(img, angle)\n        scores.append(score)\n    best_score = max(scores)\n    best_angle = angles[scores.index(best_score)]\n    print(f'Best angle: {best_angle}')\n    return best_angle\n\ndef correct_skew(img):\n    # correctskew\n    best_angle = _find_angle(img)\n    data = rotate(img, best_angle, reshape=False, order=0)\n    return data\n```\n\n![이미지](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_13.png)\n\n위 이미지 처리 단계 이후에는 인식을 위해 충분히 좋은 이미지로 간주할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n번호판 인식 (OCR)\n\n기준으로 EasyOCR 솔루션을 사용하기로 결정했어요. 쓰기 편하고 인식 정확도가 높아서 그리고 지루한 테서랙트에 비해 내가 알고 있는 괜찮은 대체재인 것 같아서요)\n\nEasyOCR을 이용한 번호판 인식을 위한 간단한 래퍼 클래스:\n\n```js\nclass EasyOcr():\n    def __init__(self, lang = ['en'], allow_list = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ', min_size=50, log_level='INFO', log_dir = './logs/'):\n        self.reader = easyocr.Reader(lang, gpu=False)\n        self.allow_list = allow_list\n        self.min_size = min_size\n        self.log_level = log_level\n        if self.log_level:\n            self.num_log_level = getattr(logging, log_level.upper(),\n                                         20)  ## log_level 입력 문자열을 로깅 모듈에서 허용하는 값 중 하나로 변환하고, 만약 없으면 20(INFO)으로 설정\n            self.log_dir = log_dir\n            # 로거 설정\n            log_formatter = logging.Formatter(\"%(asctime)s %(message)s\")\n            logFile = self.log_dir + 'ocr.log'\n            my_handler = RotatingFileHandler(logFile, mode='a', maxBytes=25 * 1024 * 1024,\n                                             backupCount=10, encoding='utf-8', delay=False)\n            my_handler.setFormatter(log_formatter)\n            my_handler.setLevel(self.num_log_level)\n            self.logger = logging.getLogger(__name__)  \n            self.logger.setLevel(self.num_log_level)\n            self.logger.addHandler(my_handler)\n\n    def run(self, detect_result_dict):\n        if detect_result_dict['cropped_img'] is not None:\n            t0 = time.time()\n            img = detect_result_dict['cropped_img']\n            img = ocr_img_preprocess(img)\n            file_name = detect_result_dict.get('file_name')\n            ocr_result = self.reader.readtext(img, allowlist = self.allow_list, min_size=self.min_size)\n            text = [x[1] for x in ocr_result]\n            confid = [x[2] for x in ocr_result]\n            text = \"\".join(text) if len(text) > 0 else None\n            confid = np.round(np.mean(confid), 2) if len(confid) > 0 else None   \n            t1 = time.time()\n            print(f'인식된 번호판: {text}, 신뢰도: {confid}.\\nOCR 총 시간: {(t1 - t0):.3f}s')\n            if self.log_level:\n                # 디버그 모드일 때 결과를 파일에 작성\n                self.logger.debug(f'{file_name} 인식된 번호판: {text}, 신뢰도: {confid}, OCR 총 시간: {(t1 - t0):.3f}s.')\n\n            return {'text': text, 'confid': confid}\n        else:\n            return {'text': None, 'confid': None}\n```\n\n<div class=\"content-ad\"></div>\n\n디버그 목적으로 Detector와 마찬가지로 OCR 데이터를 파일에 기록할 수 있는 기능도 추가되었다.\n\n인식 모듈은 인식된 문자열과 신뢰도 점수를 반환합니다.\n\n검증 및 조치\n\n검출된 번호판에서 성공적으로 인식된 텍스트를 가져왔으면, 이를 확인하고 일부 조치를 취해야 합니다. 번호판 확인 단계에서 가장 합리적인 일은 고객이 업데이트하는 데이터베이스를 사용하는 것입니다. 이 데이터베이스는 매번 또는 하루에 한 번씩 읽어서 로컬 저장소에 목록을 저장할 것입니다. 현재 기준 버전에서 데이터베이스를 설정하지 않고 주요 기능에 집중하기로 결정했습니다. 대신 Google Sheets를 예시로 사용할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_14.png\" />\n\n이 순간에는 아무런 조치 단계가 설정되어 있지 않습니다. 허용 목록에 있는 라이선스 번호 확인 결과만 표시됩니다. 하지만 라즈베리파이를 사용하면 GPIO 제어 릴레이 스위치를 통해 어떤 하중이든 매우 쉽게 작동시킬 수 있습니다.\n\n시각화\n\n해결책을 편안하게 모니터링하고 디버그할 수 있도록 시각화 모듈을 추가했습니다. 이 모듈은 번호판 인식 프로세스 표시, 입력 이미지 저장, 검출된 번호판이 있는 자르기된 영역 및 출력 결과 이미지 표시를 처리합니다. 또한, e-ink 스크린에 번호판 영역 및 인식된 텍스트를 표시하는 기능을 추가했습니다.\n\n<div class=\"content-ad\"></div>\n\n현재, 편의를 위해 이미지는 압축된 JPG로 저장되며 로그 폴더에 10800개의 이미지가 한정된 양으로 저장됩니다(폴더 최대 크기 약 500Mb). 프로덕션 솔루션에서 시각화가 필요하지 않으며, 디버깅을 위해 이미지는 NumPy ndarrays나 이진 문자열에 저장하는 것이 더 좋습니다.\n\n```js\nclass Visualize():\n    def __init__(self, im0, file_name, cropped_img=None, bbox=None, det_conf=None, ocr_num=None, ocr_conf=None, num_check_response=None, out_img_size=(720,1280), outp_orig_img_size = 640, log_dir ='./logs/', save_jpg_qual = 65, log_img_qnt_limit = 10800):\n        self.im0 = im0\n        self.input_img = im0.copy()\n        self.file_name = file_name\n        self.cropped_img = cropped_img\n        self.bbox = bbox\n        self.det_conf = det_conf\n        self.ocr_num = ocr_num\n        self.ocr_conf = ocr_conf\n        self.num_check_response = num_check_response\n        self.out_img_size = out_img_size\n        self.save_jpg_qual = save_jpg_qual\n        self.log_dir = log_dir\n        self.imgs_log_dir = self.log_dir + 'imgs/'\n        os.makedirs(os.path.dirname(self.imgs_log_dir), exist_ok=True)\n        self.crop_imgs_log_dir = self.log_dir + 'imgs/crop/'\n        os.makedirs(os.path.dirname(self.crop_imgs_log_dir), exist_ok=True)\n        self.orig_imgs_log_dir = self.log_dir + 'imgs/inp/'\n        os.makedirs(os.path.dirname(self.orig_imgs_log_dir), exist_ok=True)\n        self.log_img_qnt_limit = log_img_qnt_limit\n\n        # Create blank image\n        h, w = self.out_img_size\n        self.img = np.zeros((h, w, 3), np.uint8)\n        self.img[:, :] = (255, 255, 255)\n\n        # Draw bounding box on top the image\n        if (self.bbox is not None) and (self.det_conf is not None):\n            label = f'{self.det_conf.item():.2f}'\n            color = [0, 255, 127]\n            plot_one_box(self.bbox, self.im0, label=label, color=color, line_thickness=3)\n\n        # Resize img width to fit the plot, keep origin aspect ratio\n        h0, w0 = im0.shape[:2]\n        aspect = w0 / h0\n        if aspect > 1:  # horizontal image\n            new_w = outp_orig_img_size\n            new_h = np.round(new_w / aspect).astype(int)\n        elif aspect < 1:  # vertical image\n            new_h = outp_orig_img_size\n            new_w = np.round(new_h * aspect).astype(int)\n        else:  # square image\n            new_h, new_w = outp_orig_img_size, outp_orig_img_size\n        self.im0 = cv2.resize(self.im0, (new_w, new_h), interpolation=cv2.INTER_AREA)\n        im0_h, im0_w = self.im0.shape[:2]\n\n        # Add original full image\n        im0_offset = 0\n        self.img[im0_offset:im0_h + im0_offset, im0_offset:im0_w + im0_offset] = self.im0\n\n        # Add cropped image with detected number bbox\n        if self.cropped_img is not None:\n            # Resize cropped img\n            target_width = int((w - (im0_w + im0_offset)) / 3)\n            r = target_width / self.cropped_img.shape[1]\n            dim = (target_width, int(self.cropped_img.shape[0] * r))\n            self.cropped_img = cv2.resize(self.cropped_img, dim, interpolation=cv2.INTER_AREA)\n            crop_h, crop_w = self.cropped_img.shape[:2]\n            # Add cropped img\n            crop_h_y1 = int(h/7)\n            crop_w_x1 = im0_w + im0_offset + int((w - (im0_w + im0_offset) - crop_w) / 2)\n            self.img[crop_h_y1:crop_h + crop_h_y1, crop_w_x1:crop_w + crop_w_x1] = self.cropped_img\n            # Add `_det` to filename\n            self.file_name = Path(self.file_name).stem + \"_det\" + Path(self.file_name).suffix\n\n        # Add ocr recognized number\n        if self.ocr_num is not None:\n            label = f\"{self.ocr_num} ({self.ocr_conf})\"\n            t_thickn = 2  # text font thickness in px\n            font = cv2.FONT_HERSHEY_SIMPLEX  # font\n            fontScale = 1.05\n            # calculate position\n            text_size = cv2.getTextSize(label, font, fontScale=fontScale, thickness=t_thickn)[0]\n            w_center = int((im0_w + im0_offset + w)/2)\n            ocr_w_x1 = int(w_center - text_size[0]/2)\n            ocr_h_y1 = int(crop_h_y1 + crop_h + 55)\n            org = (ocr_w_x1, ocr_h_y1)  # position\n            # Plot text on img\n            cv2.putText(self.img, label, org, font, fontScale,  color=(0, 0, 0), thickness=t_thickn, lineType=cv2.LINE_AA)\n\n        # Add number check response if in allowed list\n        if self.num_check_response == 'Allowed':\n            label = \"-=Allowed=-\"\n            fontColor = (0,255,0)\n        else:\n            label = \"-=Prohibited!=-\"\n            fontColor = (0,0,255)\n        t_thickn = 2  # text font thickness in px\n        font = cv2.FONT_HERSHEY_SIMPLEX  # font\n        fontScale = 1.05\n        # calculate position\n        text_size = cv2.getTextSize(label, font, fontScale=fontScale, thickness=t_thickn)[0]\n        w_center = int((im0_w + im0_offset + w) / 2)\n        response_w_x1 = int(w_center - text_size[0] / 2)\n        response_h_y1 = int(h*3/7) #TBD\n        org = (response_w_x1, response_h_y1)  # position\n        # Plot text on img\n        cv2.putText(self.img, label, org, font, fontScale, color=fontColor, thickness=t_thickn, lineType=cv2.LINE_AA)\n\n    def show(self):\n        # Show the image\n        cv2.imshow('image', self.img)\n\n    def save(self):\n        # Remove oldest file if reach quantity limit\n        if self.get_dir_file_quantity(self.imgs_log_dir) > self.log_img_qnt_limit:\n            oldest_file = sorted([self.imgs_log_dir+f for f in os.listdir(self.imgs_log_dir)])[\n                0]  \n            os.remove(oldest_file)\n        # Write compressed jpeg with results\n        cv2.imwrite(f\"{self.imgs_log_dir}{self.file_name}\", self.img, [int(cv2.IMWRITE_JPEG_QUALITY), self.save_jpg_qual])\n\n    def save_input(self):\n        if self.input_img is not None:\n            # Remove oldest file if reach quantity limit\n            if self.get_dir_file_quantity(self.orig_imgs_log_dir) > self.log_img_qnt_limit:\n                oldest_file = sorted([self.orig_imgs_log_dir+f for f in os.listdir(self.orig_imgs_log_dir)])[\n                    0]  \n                os.remove(oldest_file)\n            # Write compressed jpeg with results\n            cv2.imwrite(f\"{self.orig_imgs_log_dir}orig_inp_{self.file_name}\", self.input_img)\n\n    def save_crop(self):\n        if self.cropped_img is not None:\n            # Remove oldest file if reach quantity limit\n            if self.get_dir_file_quantity(self.crop_imgs_log_dir) > self.log_img_qnt_limit:\n                oldest_file = sorted([self.crop_imgs_log_dir+f for f in os.listdir(self.crop_imgs_log_dir)])[\n                    0]  \n                os.remove(oldest_file)\n            # Write compressed jpeg with results\n            cv2.imwrite(f\"{self.crop_imgs_log_dir}crop_{self.file_name}\", self.cropped_img)\n\n    def display(self):\n        # Display img using e-ink display 176*264\n        disp_img = np.zeros((epd2in7.EPD_WIDTH, epd2in7.EPD_HEIGHT,3), np.uint8)\n        disp_img[:, :] = (255, 255, 255)\n        \n        if self.cropped_img is not None:\n            # Add cropped number\n            crop_resized = cv2.resize(self.cropped_img, (epd2in7.EPD_HEIGHT-4, 85), interpolation=cv2.INTER_AREA)\n            crop_resized_h, crop_resized_w = crop_resized.shape[:2]\n            crop_w_x1 = int(epd2in7.EPD_HEIGHT/2 - crop_resized_w/2)\n            disp_img[2:crop_resized_h+2, crop_w_x1:crop_resized_w+crop_w_x1] = crop_resized\n        \n        if\n\n<div class=\"content-ad\"></div>\n\n지금까지 이룩한 것을 시험해 봅시다. 정지 이미지에서의 탐지 및 인식 파이프라인:\n\n![image1](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_15.png)\n\n길거리에서 기기 카메라를 사용한 종단간 솔루션 테스트:\n\n![image2](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_16.png)\n\n<div class=\"content-ad\"></div>\n\n```\n![Image 1](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_17.png)\n\n![Image 2](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_18.png)\n\n![Image 3](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_19.png)\n\nPerformance\n\n\n<div class=\"content-ad\"></div>\n\n현재 구성으로는 감지에 약 700~800ms, OCR 단계에 약 900~1200ms가 소요되며, 평균 FPS는 약 0.4~0.5입니다.\n\n![이미지](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_20.png)\n\n현재 주차 장벽 자동화 프로젝트에는 이러한 프레임 속도 값이 중요하지 않지만, 개선할 여지가 분명히 많습니다.\n\nhtop에서 CPU 활용률이 거의 100%에 가깝다는 것을 알 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_21.png)\n\n모든 테스트는 Raspberry Pi OS의 기본 설정으로 수행되었습니다. UI를 비활성화하고 기본적으로 활성화된 다른 백그라운드 서비스를 모두 제거하면 성능과 안정성이 높아집니다.\n\n보너스\n\n추가 조정 없이도 우리의 감지기 모듈은 LEGO 자동차의 번호판을 완벽하게 감지할 수 있다는 것이 밝혀졌습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지1](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_22.png)\n\n![이미지2](/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_23.png)\n\n그래서 레고를 아들에게 빌려 Raspberry Pi Build Hat을 사용하여 나만의 주차장 바리어를 만들기로 결정했고, \"실제\" 조건에서 완전한 엔드 투 엔드 테스트를 제공하기로 했습니다.\n\nLEG 월드 햇 프로프라이어터리 라이브러리를 기반으로 한 Action 모듈용 간단한 랩퍼:\n\n\n<div class=\"content-ad\"></div>\n\n```python\nclass Action():\n    def __init__(self):\n        self.motor = Motor('A')\n        self.motor.set_default_speed(25)\n        self.matrix = Matrix('B')\n        self.ok_color = [[(6, 10) for x in range(3)] for y in range(3)]\n        self.nok_color = [[(9, 10) for x in range(3)] for y in range(3)]\n        self.matrix.set_transition(2) #fade-in/out\n        self.matrix.set_pixel((1, 1), (\"blue\", 10))\n\n    def _handle_motor(self, speed, pos, apos):\n        print(\"Motor:\", speed, pos, apos)\n\n    def run(self, action_status):\n        while True:\n            if action_status[0] == 'Allowed':\n                self.matrix.set_pixels(self.ok_color)\n                time.sleep(1)\n                self.motor.run_for_degrees(-90, blocking=False)\n                time.sleep(5)\n                self.motor.run_for_degrees(90, blocking=False)\n                time.sleep(1)\n            elif action_status[0] == 'Prohibited':\n                self.matrix.set_pixels(self.nok_color)\n                time.sleep(3)\n            else:\n                self.matrix.clear()\n                self.matrix.set_pixel((1, 1), (\"blue\", 10))\n                time.sleep(1)\n                self.matrix.set_pixel((1, 1), (0, 10))\n                time.sleep(1)\n```\n\nMain 프로그램에서 action_status가 감지되고 변경될 때 메인 프로그램에서 액션을 트리거하여 병렬 스레드에서 이 모듈을 실행합니다.\n\n<img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_24.png\" />\n\nLEGO 번호판 중 하나를 Google 시트 \"데이터베이스\"에 추가했으므로 이제 모든 조각들을 함께 조합하여 실행할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*ZHTFqk1E0pKLGAht0W_mnw.gif\" />\n\n# 최종 결론\n\n전반적으로 라즈베리 파이를 사용하여 주차장 장벽을 제어하기 위한 자동 번호판 인식 시스템을 완전히 구현하는 데 성공했습니다.\n\n강조해야 할 문제 중 하나는 처리 속도가 느린 관계로 이미지 지연이 발생할 수 있다는 점입니다. 카메라는 자체 버퍼가 있으며 이미지를 느린 속도로 캡처하는 동안 씬이 변경되어도 버퍼에서 여전히 \"이전\" 프레임을 읽는 문제가 있습니다. 현재 사용 사례에서는 그다지 중요하지 않지만 개선을 위해 전체 처리 시간과 거의 동일한 간격으로 프레임 스킵을 추가했습니다. 이렇게 하면 더 빠른 프레임 읽기와 버퍼의 정리가 가능하며 CPU의 부하를 줄일 수 있습니다. 그러나 지연 없이 거의 실시간 스무스한 이미지 스트리밍이 필요하다면 최상의 옵션은 카메라 읽기를 별도의 병렬 스레드로 설정하여 버퍼에서 가능한 최대 속도로 프레임을 읽도록 하는 것이며, 주 프로그램이 필요 시에만 이 프로세스에서 프레임을 가져 올 수 있도록 합니다. 그러나 파이썬에서 멀티 스레딩은 실제 다중 프로세스 처리가 아니라 아키텍처적 관점에서 코드를 보다 명확하게 조직화하고 실행하는 데 도움이 되는 시뮬레이션인 것을 기억해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n# 추가 단계\n\n- OCR. 현재 병목 현상인 OCR을 빠르게 처리할 수 있도록 개선해보세요. 나는 속도를 올리기 위해 작은 커스텀 RNN 기반 모델을 개발하기로 했습니다. 시간이 중요하지 않고 정확도만 필요한 경우 EasyOCR에서 다양한 모델을 사용하고 이를 여러분의 사례에 맞게 튜닝할 수 있습니다. 또는 WPOD-NET과 같은 다른 솔루션을 시도해볼 수도 있습니다. 또한 인식 품질을 향상시키는 중요한 포인트로는 정확한 사용 사례에 맞게 이미지 전처리를 조정하는 것이 있습니다.\n- Detector. 속도를 높이기 위해 카메라가 근거리에 있는 자동차에서만 작업해야 하는 경우 해상도가 높은 이미지가 필요하지 않습니다. 또 다른 옵션은 가능하다면 카메라와 차량의 위치가 대략 고정되어 있다면 전체 프레임이 아닌 번호판이 위치할 것으로 예상되는 영역만 캡처할 수 있습니다.\n\n나중에 이 두 모델 모두 전이 학습, 양자화, 가지치기 및 기타 방법을 사용하여 경량화하고 엣지 장치에서 더 빠르고 가벼운 작동이 가능하도록 할 수 있습니다.\n\n그러나 아무리 빠른 실시간 처리가 필수적이더라도 (물론 자동 주차 장벽에는 해당하지 않을 것입니다), 텐서 코어가 있는 장치가 없으면 NVIDIA Jetson과 같은 장치가 없으면 속도와 품질 사이에 항상 트레이드오프가 존재할 것입니다. CPU 전용 장치에서는 항상 속도와 품질 사이의 교환 관계가 발생할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n더 개선할 수 있는 다른 옵션이 있어요 — 현재 상황에서는 CPU를 24시간 7일 돌릴 필요가 없어요. 자동차가 다가올 때만 PIR 또는 IR 센서에 의해 카메라가 작동될 수 있어요.\n\n다음 번에 구현해보려고 하는 마지막 포인트 — 솔루션을 마이크로서비스로 전환하고 생산자-소비자 데이터 흐름 패턴을 구현할 거예요.\n\n그럼 이만 하겠습니다. 이 긴 지루한 프로젝트 구현 설명을 읽어 주셔서 감사해요.\n\n건강하게 지내시고 우크라이나를 응원해주세요 ❤.\n\n<div class=\"content-ad\"></div>\n\n# 프로젝트에서 사용된 장비에 대한 링크:\n\n- Raspberry Pi 4 Model B 4GB\n- Raspberry Pi Camera Module v2\n- Raspberry Pi 4 Aluminum Case with Dual Cooling Fan\n- GeeekPi(52pi) Raspberry Pi UPS EP-0136\n- 264x176 2.7인치 E-Ink 디스플레이 HAT for Raspberry Pi\n- Raspberry Pi Build HAT\n- LEGO 3x3 컬러 라이트 매트릭스\n- LEGO 작은 테크닉 직각 모터","ogImage":{"url":"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_0.png","tag":["Tech"],"readingTime":30},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h1>소개</h1>\n<p>이 프로젝트의 목표는 Raspberry Pi 마이크로 컴퓨터를 사용하여 주차 장벽을 제어하기 위한 자동 번호판 인식 시스템을 설계하는 것입니다.</p>\n<p>왜 이 프로젝트를 하게 되었을까요?</p>\n<p>어딘가에 참여 중인 프로젝트가 없는 Rpi가 하나 있고 카메라와 잠재적인 고민이 있는데요 ― 사무실 주차장에 자동 주차 장벽 제어 시스템이 없습니다. 그러니 이 프로젝트를 시작해보는 건 어떨까요?</p>\n<p>이 프로젝트의 목적은 생산에 적합한 안정적이고 경쟁력있는 솔루션을 만드는 것이 아니라, 한정된 장비를 사용하여 실제 문제를 위한 작동 제품을 만들면서 재미를 느끼는 것입니다. 그리고 그 이후에는 이 솔루션을 경량 엣지 디바이스에서 빠르게 작동하도록 최적화하는 재미도 봅시다)</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_1.png\" alt=\"image\"></p>\n<p>일반적인 아이디어는 Rpi 카메라를 사용하여 일정 주기로 사진을 촬영하고, 이미지를 처리하여 차량 번호판을 감지하고 문자를 인식한 다음 데이터베이스에서 허용된 번호 목록과 비교하는 것입니다. 목록의 번호판과 일치한다면 장벽이 열릴 것입니다.</p>\n<p>기본적인 단계에서는 다음 도구를 사용할 것입니다:</p>\n<ul>\n<li>이미지 소스 — Raspberry Pi Camera 모듈 v2;</li>\n<li>번호판 검출기 — pyTorch를 사용하여 제공되는 Yolo v7;</li>\n<li>광필 인식 (OCR) — EasyOCR;</li>\n<li>\"데이터베이스\" — Google 시트의 테이블;</li>\n</ul>\n<p>모든 처리 작업과 계산은 Raspberry Pi 4b에서 로컬로 실행되어야 하며, 이 솔루션은 자율적으로 작동해야합니다.</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_2.png\" alt=\"이미지\"></p>\n<p>라즈베리 파이는 \"거의 실시간\"으로 Pi 카메라에서 프레임을 계속해서 읽습니다. 그런 다음, 사용자 정의 데이터셋 YOLOv7 모델을 미세 조정하여 번호판이 있는 영역을 감지합니다. 그 다음, 필요한 경우 이미지 전처리를 제공하고 EasyOCR 모델이 제공된 자르기된 프레임에서 번호를 감지합니다. 그런 다음 번호판 문자열을 \"데이터베이스\"에 저장된 번호판 중 어느 것과 일치하는지 확인하고 해당 작업을 실행합니다. 라즈베리 GPIO (General-Purpose Input-Output) - 제어 릴레이 스위치를 사용하여 주차장 장벽과 빛 등 추가 부하를 연결할 수 있습니다.</p>\n<p>GPIO 핀을 사용하면 입력 센서 (IR, PIR와 같은)를 연결하고 자동차가 감지됐을 때에만 카메라를 작동시킬 수 있습니다.</p>\n<p>이 작업은 여러 가지 방법으로 해결할 수 있습니다. 일부 방법은 특정 요구 사항과 사용 사례에 더 효율적이고 간편할 수 있습니다. 예를 들어, 모든 중요한 처리를 클라우드에서 수행하거나 GPU 기반 엣지 장치를 사용하거나 다른 모델을 사용할 수 있습니다. ONNX, TFLite 등을 사용하여 제공할 수도 있습니다. 그러나 이 프로젝트는 실험으로 진행되었고, 현재 사용 가능한 장비를 사용했으며, 쉬운 방법을 찾는 것이 아니었습니다 =)</p>\n<h1>환경 설정</h1>\n<h2>하드웨어 디자인</h2>\n<p>필수 하드웨어:</p>\n<ul>\n<li>카메라 — Raspberry Pi Camera 모듈 v2 (Sony IMX219 8MPx, 1080p30, 720p60)</li>\n<li>엣지 디바이스 — Raspberry Pi 4 모델 B 4GB (CPU: Broadcom BCM2711, 쿼드 코어 Cortex-A72 (ARM v8) 64비트 SoC @ 1.5GHz; RAM: 4GB LPDDR4–3200 SDRAM; 40핀 GPIO 헤더; 2.4 GHz/5.0 GHz 802.11ac Wi-Fi, 블루투스 5.0)</li>\n<li>SD 카드 (8GB)</li>\n<li>전원 공급 장치 — 5V 3A USB-C</li>\n</ul>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_3.png\" alt=\"image\"></p>\n<p>추가 내용:</p>\n<ul>\n<li>열흡수기, 냉각 팬</li>\n<li>UPS</li>\n<li>디스플레이 (Waveshare 2.7인치 e-Paper HAT)</li>\n<li>외부 장치(장벽) 제어용 릴레이 / Raspberry HAT</li>\n<li>카메라 마운트 (\"카메라용 독특한 금속 와이어 마운트\" :))</li>\n</ul>\n<ul>\n<li>색깔 다시 채워주는 시간이 괜찮은 TFT 또는 OLED 유형의 화면을 사용하는 것이 좋지만, 그 당시에는 이 것만 사용할 수 있었습니다.</li>\n</ul>\n<p><a href=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_4.png\">이미지</a></p>\n<p>설정하기</p>\n<p>PyTorch를 사용하여 솔루션을 만들기로 결정했으므로, Arm 64비트(aarch64)용 pip 패키지만 제공되므로 64비트 버전의 OS(데비안 버전: 11 - “Bullseye”)를 설치해야 합니다.</p>\n<p>최신 arm64 라즈베리 파이 OS는 공식 사이트에서 다운로드할 수 있으며 rpi-imager를 통해 설치할 수 있습니다.</p>\n<p>설치가 완료되면 다음과 같아야 합니다:</p>\n<p>라즈베리 파이에 SD 카드를 삽입한 후 부팅하면 다음과 같은 설정을 수행해야 합니다:</p>\n<p>/boot/config.txt 파일을 수정하여 카메라를 활성화합니다.</p>\n<pre><code class=\"hljs language-js\"># 이는 카메라와 같은 확장 기능을 사용하도록합니다.\nstart_x=<span class=\"hljs-number\">1</span>\n# 카메라 처리에 적어도 128M이 필요하며 더 크면 그대로 둘 수 있습니다.\ngpu_mem=<span class=\"hljs-number\">128</span>\n# 기존의 camera_auto_detect 줄을 주석 처리/삭제해야합니다. 이것은 <span class=\"hljs-title class_\">OpenCV</span>/<span class=\"hljs-variable constant_\">V4L2</span> 캡처에서 문제를 일으킵니다.\n#camera_auto_detect=<span class=\"hljs-number\">1</span>\n</code></pre>\n<p>또한 아마 I2C, SSH 및 VNC을 활성화하려고 할 것입니다. 이 작업은 raspi-config 또는 GUI에서 할 수 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_6.png\" alt=\"image\"></p>\n<p>요구 사항 설치</p>\n<p>저는 Python 버전 3.9 및 3.10을 사용했습니다. 일부 경우에 따르면 3.11 버전이 더 빠르다고 보고되지만 아직 안정적인 PyTorch가 3.11에는 없습니다.</p>\n<p><code>requirements.txt</code> 파일을 사용하여 pip 패키지 관리자를 통해 모든 필요한 라이브러리와 모듈을 설치하세요:</p>\n<p>matplotlib>=3.2.2\nnumpy>=1.18.5\nopencv-python==4.5.4.60\nopencv-contrib-python==4.5.4.60\nPillow>=7.1.2\nPyYAML>=5.3.1\nrequests>=2.23.0\nscipy>=1.4.1\ntorch>=1.7.0,!=1.12.0\ntorchvision>=0.8.1,!=0.13.0\ntqdm>=4.41.0\nprotobuf&#x3C;4.21.3\ntensorboard>=2.4.1\npandas>=1.1.4\nseaborn>=0.11.0\neasyocr>=1.6.2</p>\n<p>수동으로 직접 설치하거나 기존 환경에 구현할 경우 (하지 마세요 :)), 현재 OpenCV 버전에 문제가 있으므로 정확한 버전 4.5.4.60을 설치해야 합니다.</p>\n<p>모든 것이 올바르게 설치되었는지 확인하려면 <code>pip list</code> 명령어를 사용하세요.</p>\n<p><code>&#x3C;img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_7.png\" /></code></p>\n<p>그럼, 하드웨어와 환경을 설정해놓았으니 코딩을 시작해봅시다.</p>\n<h1>소프트웨어 설계</h1>\n<p>이미지 캡쳐</p>\n<p>이미지 캡처를 위해 표준 picamera 라이브러리 대신 OpenCV를 사용하여 비디오 프레임을 스트리밍할 것입니다. 64비트 OS에서 picamera 라이브러리를 사용할 수 없고 그 속도도 느립니다. OpenCV는 직접 /dev/video0 장치에 액세스하여 프레임을 캡처합니다.</p>\n<p>OpenCV 카메라 읽기를 위한 사용자 정의 간단한 래퍼:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">PiCamera</span>():\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, src=<span class=\"hljs-number\">0</span>, img_size=(<span class=\"hljs-params\"><span class=\"hljs-number\">640</span>,<span class=\"hljs-number\">480</span></span>), fps=<span class=\"hljs-number\">36</span>, rotate_180=<span class=\"hljs-literal\">False</span></span>):\n        self.img_size = img_size\n        self.fps = fps\n        self.cap = cv2.VideoCapture(src)\n        <span class=\"hljs-comment\">#self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)</span>\n        <span class=\"hljs-comment\">#self.cap.set(cv2.CAP_PROP_FPS, self.fps)</span>\n        self.cap.<span class=\"hljs-built_in\">set</span>(cv2.CAP_PROP_FRAME_WIDTH, self.img_size[<span class=\"hljs-number\">0</span>])\n        self.cap.<span class=\"hljs-built_in\">set</span>(cv2.CAP_PROP_FRAME_HEIGHT, self.img_size[<span class=\"hljs-number\">1</span>])\n        self.rotate_180 = rotate_180\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>(<span class=\"hljs-params\">self</span>):       \n        <span class=\"hljs-comment\"># 프레임 읽기</span>\n        ret, image = self.cap.read()\n        <span class=\"hljs-keyword\">if</span> self.rotate_180:\n            image = cv2.rotate(image, cv2.ROTATE_180)\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> ret:\n            <span class=\"hljs-keyword\">raise</span> RuntimeError(<span class=\"hljs-string\">\"프레임 읽기 실패\"</span>)\n        <span class=\"hljs-keyword\">return</span> image \n</code></pre>\n<p>여기서 카메라가 뒤집혀 있기 때문에 <code>image = cv2.rotate(image, cv2.ROTATE_180)</code>를 사용하고 있습니다.</p>\n<p>버퍼 크기와 FPS 설정은 랙을 고치고 프레임 스트림을 적절하게 정렬하는 데 사용할 수 있습니다. 그러나 제 경우에는 카메라 제조사 및 프레임을 읽는 데 사용된 백엔드에 따라 달라서 작동하지 않습니다.</p>\n<p>카메라에서 이미지가 캡처된 후, 우리는 번호판을 감지하는 작업을 시작하여 이미지를 처리해야 합니다.</p>\n<p>번호판 감지 모듈</p>\n<p>이 작업에는 YOLOv7 사전 훈련된 모델을 사용할 것입니다. 이 모델을 사용하여 사용자 지정 번호판 데이터 세트에 대해 미세 조정할 것입니다.</p>\n<p>YOLOv7는 정확성과 속도 측면에서 최신 기술인 실시간 객체 감지 알고리즘입니다. COCO 데이터셋에 미리 학습되어 있습니다.</p>\n<p>이 알고리즘에 대한 자세한 내용은 다음 논문에서 확인할 수 있어요: YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors.</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_8.png\" alt=\"이미지\"></p>\n<p>공식 저장소에서 YOLOv7 레포지토리를 복제해보세요.</p>\n<pre><code class=\"hljs language-js\">git clone <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//github.com/WongKinYiu/yolov7.git</span>\ncd yolov7\n</code></pre>\n<p>요로 요구 사항은 위에서 설치한 프로젝트 요구 사항에 이미 흡수되었습니다.</p>\n<p>Fine-tuning을 위해 YOLOv7의 사전 훈련된 작은 버전인 이미지 크기 640을 적용하겠습니다.</p>\n<pre><code class=\"hljs language-js\"># 사전 훈련된 가중치 다운로드\n!wget <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt</span>\n</code></pre>\n<p>기본 사전 훈련된 물체 탐지:</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_9.png\" alt=\"image\"></p>\n<p>Numberplate Detection Model training</p>\n<p>커스텀 데이터셋에 대한 모델 훈련은 꽤 간단하고 직관적입니다.</p>\n<p>친구야, 좋은 GPU를 이용해 Google Colab에서 모델 파인 튜닝을 진행할 거야.</p>\n<p>시작하기 전에 단일 번호판 클래스로 적절한 데이터셋을 생성하고 레이블을 지정해야 해.</p>\n<p>나의 데이터셋은 나만의 사진을 기반으로 부분적으로 만들었으며 AUTO.RIA Numberplate Dataset에서 일부를 활용했어 (이 멋진 분들에게 감사합니다!). 총 2000장의 이미지를 사용했어.</p>\n<p>레이블링은 Yolo 포맷으로 roboflow 서비스를 통해 진행했어.</p>\n<pre><code class=\"hljs language-yaml\"><span class=\"hljs-attr\">train:</span> <span class=\"hljs-string\">dataset/train</span>\n<span class=\"hljs-attr\">val:</span> <span class=\"hljs-string\">dataset/valid</span>\n<span class=\"hljs-comment\"># Classes</span>\n<span class=\"hljs-attr\">nc:</span> <span class=\"hljs-number\">1</span>  <span class=\"hljs-comment\"># number of classes</span>\n<span class=\"hljs-attr\">names:</span> [<span class=\"hljs-string\">'numberplate'</span>]  <span class=\"hljs-comment\"># class names</span>\n</code></pre>\n<p>모델을 훈련하세요.</p>\n<pre><code class=\"hljs language-yaml\"><span class=\"hljs-string\">python</span> <span class=\"hljs-string\">train.py</span> <span class=\"hljs-string\">--epochs</span> <span class=\"hljs-number\">25</span> <span class=\"hljs-string\">--workers</span> <span class=\"hljs-number\">8</span> <span class=\"hljs-string\">--device</span> <span class=\"hljs-number\">0</span> <span class=\"hljs-string\">--batch-size</span> <span class=\"hljs-number\">32</span> <span class=\"hljs-string\">--data</span> <span class=\"hljs-string\">data/numberplates.yaml</span> <span class=\"hljs-string\">--img</span> <span class=\"hljs-number\">640</span> <span class=\"hljs-number\">640</span> <span class=\"hljs-string\">--cfg</span> <span class=\"hljs-string\">cfg/training/yolov7.yaml</span> <span class=\"hljs-string\">--weights</span> <span class=\"hljs-string\">'yolov7-tiny.pt'</span> <span class=\"hljs-string\">--name</span> <span class=\"hljs-string\">yolov7_tiny_numberplates</span> <span class=\"hljs-string\">--hyp</span> <span class=\"hljs-string\">data/hyp.scratch.tiny.yaml</span>\n</code></pre>\n<p>Baseline으로 25회의 에포크가 충분하다고 결정했어요.</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_11.png\" alt=\"AutomaticNumberPlateRecognitionwithRaspberryPi_11.png\"></p>\n<p>추론:</p>\n<p>프로젝트의 첫 번째 버전으로는 충분해 보이지만, 실제 응용 프로그램 중 발견된 특수 사례들을 통해 나중에 업데이트할 수 있습니다.</p>\n<p>YOLOv7 디텍터를 위한 추상적인 간단한 래퍼 클래스를 생성하였습니다:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Detector</span>():\n    def <span class=\"hljs-title function_\">__init__</span>(self, model_weights, img_size=<span class=\"hljs-number\">640</span>, device=<span class=\"hljs-string\">'cpu'</span>, half=<span class=\"hljs-title class_\">False</span>, trace=<span class=\"hljs-title class_\">True</span>, log_level=<span class=\"hljs-string\">'INFO'</span>, log_dir = <span class=\"hljs-string\">'./logs/'</span>):\n        # 초기화\n        self.<span class=\"hljs-property\">model_weights</span> = model_weights\n        self.<span class=\"hljs-property\">img_size</span> = img_size\n        self.<span class=\"hljs-property\">device</span> = torch.<span class=\"hljs-title function_\">device</span>(device)\n        self.<span class=\"hljs-property\">half</span> = half  # half = device.<span class=\"hljs-property\">type</span> != <span class=\"hljs-string\">'cpu'</span>  # half precision only supported on <span class=\"hljs-variable constant_\">CUDA</span>\n        self.<span class=\"hljs-property\">trace</span> = trace  # 모델을 <span class=\"hljs-title class_\">Traced</span>-모델로 변환\n        self.<span class=\"hljs-property\">log_level</span> = log_level\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">log_level</span>:\n            self.<span class=\"hljs-property\">num_log_level</span> = <span class=\"hljs-title function_\">getattr</span>(logging, self.<span class=\"hljs-property\">log_level</span>.<span class=\"hljs-title function_\">upper</span>(), <span class=\"hljs-number\">20</span>) ##log_level 입력 문자열을 로깅 모듈이 허용하는 값 중 하나로 변환합니다. 값이 없다면 <span class=\"hljs-number\">20</span> - <span class=\"hljs-variable constant_\">INFO</span>로 설정됩니다.\n            self.<span class=\"hljs-property\">log_dir</span> = log_dir\n            log_formatter = logging.<span class=\"hljs-title class_\">Formatter</span>(<span class=\"hljs-string\">\"%(asctime)s %(message)s\"</span>)\n            logFile = self.<span class=\"hljs-property\">log_dir</span> + <span class=\"hljs-string\">'detection.log'</span>\n            my_handler = <span class=\"hljs-title class_\">RotatingFileHandler</span>(logFile, mode=<span class=\"hljs-string\">'a'</span>, maxBytes=<span class=\"hljs-number\">25</span> * <span class=\"hljs-number\">1024</span> * <span class=\"hljs-number\">1024</span>,\n                                             backupCount=<span class=\"hljs-number\">10</span>, encoding=<span class=\"hljs-string\">'utf-8'</span>, delay=<span class=\"hljs-title class_\">False</span>)\n            my_handler.<span class=\"hljs-title function_\">setFormatter</span>(log_formatter)\n            my_handler.<span class=\"hljs-title function_\">setLevel</span>(self.<span class=\"hljs-property\">num_log_level</span>)\n            self.<span class=\"hljs-property\">logger</span> = logging.<span class=\"hljs-title function_\">getLogger</span>(__name__)  \n            self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">setLevel</span>(self.<span class=\"hljs-property\">num_log_level</span>)\n            self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">addHandler</span>(my_handler)\n        # <span class=\"hljs-variable constant_\">YOLO</span> 모델의 경로를 추가합니다. (<span class=\"hljs-string\">'weights.pt'</span>)를 로드할 때마다, pytorch는 path 환경 변수(models/yolo)에서 모델 구성을 찾습니다.\n        yolo_folder_dir = <span class=\"hljs-title function_\">str</span>(<span class=\"hljs-title class_\">Path</span>(__file__).<span class=\"hljs-property\">parent</span>.<span class=\"hljs-title function_\">absolute</span>()) +<span class=\"hljs-string\">\"\\yolov7\"</span> #  모델 폴더 경로\n        sys.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">insert</span>(<span class=\"hljs-number\">0</span>, yolo_folder_dir)\n        # 모델 로드\n        self.<span class=\"hljs-property\">model</span> = <span class=\"hljs-title function_\">attempt_load</span>(self.<span class=\"hljs-property\">model_weights</span>, map_location=self.<span class=\"hljs-property\">device</span>)  # <span class=\"hljs-title class_\">FP32</span> 모델 로드\n        # 모델을 <span class=\"hljs-title class_\">Traced</span>-모델로 변환\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">trace</span>:\n            self.<span class=\"hljs-property\">model</span> = <span class=\"hljs-title class_\">TracedModel</span>(self.<span class=\"hljs-property\">model</span>, self.<span class=\"hljs-property\">device</span>, self.<span class=\"hljs-property\">img_size</span>)\n        # <span class=\"hljs-keyword\">if</span> <span class=\"hljs-attr\">half</span>:\n        #     model.<span class=\"hljs-title function_\">half</span>()  # to <span class=\"hljs-title class_\">FP16</span>\n        # 이름과 색상 가져오기\n        self.<span class=\"hljs-property\">names</span> = self.<span class=\"hljs-property\">model</span>.<span class=\"hljs-property\">module</span>.<span class=\"hljs-property\">names</span> <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">hasattr</span>(self.<span class=\"hljs-property\">model</span>, <span class=\"hljs-string\">'module'</span>) <span class=\"hljs-keyword\">else</span> self.<span class=\"hljs-property\">model</span>.<span class=\"hljs-property\">names</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">len</span>(self.<span class=\"hljs-property\">names</span>) > <span class=\"hljs-number\">1</span>:\n            self.<span class=\"hljs-property\">colors</span> = [[<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">127</span>]] + [[random.<span class=\"hljs-title function_\">randint</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">255</span>) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-number\">3</span>)] <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> self.<span class=\"hljs-property\">names</span>[<span class=\"hljs-number\">1</span>:]]\n        <span class=\"hljs-attr\">else</span>:\n            self.<span class=\"hljs-property\">colors</span> = [[<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">127</span>]]\n        sys.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">remove</span>(yolo_folder_dir)\n    def <span class=\"hljs-title function_\">run</span>(self, inp_image, conf_thres=<span class=\"hljs-number\">0.25</span>):\n        # 추론 실행\n        # 데이터 로드\n        dataset = <span class=\"hljs-title class_\">LoadImage</span>(inp_image, device=self.<span class=\"hljs-property\">device</span>, half=self.<span class=\"hljs-property\">half</span>)\n        t0 = time.<span class=\"hljs-title function_\">time</span>()\n        self.<span class=\"hljs-property\">file_name</span>, self.<span class=\"hljs-property\">img</span>, self.<span class=\"hljs-property\">im0</span> = dataset.<span class=\"hljs-title function_\">preprocess</span>()\n        # 추론\n        t1 = time.<span class=\"hljs-title function_\">time</span>()\n        <span class=\"hljs-keyword\">with</span> torch.<span class=\"hljs-title function_\">no_grad</span>():  # 그래디언트를 계산하면 <span class=\"hljs-variable constant_\">GPU</span> 메모리 누수가 발생할 수 있습니다\n            self.<span class=\"hljs-property\">pred</span> = self.<span class=\"hljs-title function_\">model</span>(self.<span class=\"hljs-property\">img</span>)[<span class=\"hljs-number\">0</span>]\n        t2 = time.<span class=\"hljs-title function_\">time</span>()\n        # <span class=\"hljs-variable constant_\">NMS</span> 적용\n        self.<span class=\"hljs-property\">pred</span> = <span class=\"hljs-title function_\">non_max_suppression</span>(self.<span class=\"hljs-property\">pred</span>, conf_thres=conf_thres)\n        t3 = time.<span class=\"hljs-title function_\">time</span>()\n        # 검출 처리\n        bbox = <span class=\"hljs-title class_\">None</span>  # 최대 <span class=\"hljs-title class_\">Confidence</span>를 가진 검출 객체의 바운딩 상자\n        cropped_img = <span class=\"hljs-title class_\">None</span>  # 최대 <span class=\"hljs-title class_\">Confidence</span>를 가진 검출 객체를 자른 이미지\n        det_conf = <span class=\"hljs-title class_\">None</span>  # 최대 <span class=\"hljs-title class_\">Confidence</span>를 가진 검출 객체의 신뢰 수준\n        self.<span class=\"hljs-property\">det</span> = self.<span class=\"hljs-property\">pred</span>[<span class=\"hljs-number\">0</span>]  # pred[<span class=\"hljs-number\">0</span>] - <span class=\"hljs-variable constant_\">NMX</span> suppr는 이미지 당 <span class=\"hljs-number\">1</span>개의 텐서를 반환합니다;\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">len</span>(self.<span class=\"hljs-property\">det</span>):\n            # img_size에서 im0 크기로 상자 크기 조정\n            self.<span class=\"hljs-property\">det</span>[:, :<span class=\"hljs-number\">4</span>] = <span class=\"hljs-title function_\">scale_coords</span>(self.<span class=\"hljs-property\">img</span>.<span class=\"hljs-property\">shape</span>[<span class=\"hljs-number\">2</span>:], self.<span class=\"hljs-property\">det</span>[:, :<span class=\"hljs-number\">4</span>], self.<span class=\"hljs-property\">im0</span>.<span class=\"hljs-property\">shape</span>).<span class=\"hljs-title function_\">round</span>()\n            # 결과 출력\n            print_strng = <span class=\"hljs-string\">\"\"</span>\n            <span class=\"hljs-keyword\">for</span> c <span class=\"hljs-keyword\">in</span> self.<span class=\"hljs-property\">det</span>[:, -<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">unique</span>():\n                n = (self.<span class=\"hljs-property\">det</span>[:, -<span class=\"hljs-number\">1</span>] == c).<span class=\"hljs-title function_\">sum</span>()  # 클래스 당 검출\n                print_strng += f<span class=\"hljs-string\">\"{n} {self.names[int(c)]}{'s' * (n > 1)}\"</span>  # 문자열에 추가\n            # 시간 출력(추론 + <span class=\"hljs-variable constant_\">NMS</span>)\n            <span class=\"hljs-title function_\">print</span>(\n                f<span class=\"hljs-string\">'{print_strng} 검출. ({(1E3 * (t1 - t0)):.1f}ms)-데이터 로드, ({(1E3 * (t2 - t1)):.1f}ms)-추론, ({(1E3 * (t3 - t2)):.1f}ms)-NMS'</span>)\n            # 디버그 모드이면 결과를 파일에 기록\n            <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">log_level</span>:\n                self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">debug</span>(\n                    f<span class=\"hljs-string\">'{self.file_name} {print_strng} 검출. ({(1E3 * (t1 - t0)):.1f}ms)-Load data, ({(1E3 * (t2 - t1)):.1f}ms)-Inference, ({(1E3 * (t3 - t2)):.1f}ms)-NMS'</span>)\n                <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">getEffectiveLevel</span>() == <span class=\"hljs-number\">10</span>:  # 레벨 <span class=\"hljs-number\">10</span> = 디버그\n                    gn = torch.<span class=\"hljs-title function_\">tensor</span>(self.<span class=\"hljs-property\">im0</span>.<span class=\"hljs-property\">shape</span>)[[<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>]]  # 정규화 gain whwh\n                    <span class=\"hljs-keyword\">for</span> *xyxy, conf, cls <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">reversed</span>(self.<span class=\"hljs-property\">det</span>):\n                        # 바운딩 박스와 함께 xywh 형식으로 검출 저장\n                        xywh = (<span class=\"hljs-title function_\">xyxy2xywh</span>(torch.<span class=\"hljs-title function_\">tensor</span>(xyxy).<span class=\"hljs-title function_\">view</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">4</span>)) / gn).<span class=\"hljs-title function_\">view</span>(-<span class=\"hljs-number\">1</span>).<span class=\"hljs-title function_\">tolist</span>()  # 정규화된 xywh\n                        line = (<span class=\"hljs-title function_\">int</span>(cls), np.<span class=\"hljs-title function_\">round</span>(conf, <span class=\"hljs-number\">3</span>), *xywh)  # 라벨 형식\n                        self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">debug</span>(f<span class=\"hljs-string\">\"{self.file_name} {('%g ' * len(line)).rstrip() % line}\"</span>)\n            # 최대 <span class=\"hljs-title class_\">Confidence</span>를 가진 검출 찾기:\n            indx = self.<span class=\"hljs-property\">pred</span>[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">argmax</span>(<span class=\"hljs-number\">0</span>)[\n                <span class=\"hljs-number\">4</span>]  # pred[<span class=\"hljs-number\">0</span>] - <span class=\"hljs-variable constant_\">NMX</span> suppr는 이미지 당 <span class=\"hljs-number\">1</span>개의 텐서를 반환; <span class=\"hljs-title function_\">argmax</span>(<span class=\"hljs-number\">0</span>)[<span class=\"hljs-number\">4</span>] - conf는 [x1,y1,x2,y2,conf,cls]에서 indx <span class=\"hljs-number\">4</span>를 가짐\n            max_det = self.<span class=\"hljs-property\">pred</span>[<span class=\"hljs-number\">0</span>][indx]\n            # 검출 바운딩 상자와 해당 자른 이미지 수집\n            bbox = max_det[:<span class=\"hljs-number\">4</span>]\n            cropped_img = <span class=\"hljs-title function_\">save_crop</span>(max_det[:<span class=\"hljs-number\">4</span>], self.<span class=\"hljs-property\">im0</span>)\n            cropped_img = cropped_img[:, :, ::-<span class=\"hljs-number\">1</span>] # <span class=\"hljs-variable constant_\">BGR</span> to <span class=\"hljs-variable constant_\">RGB</span>\n            det_conf = max_det[<span class=\"hljs-number\">4</span>:<span class=\"hljs-number\">5</span>]\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">'검출 총 시간: {time.time() - t0:.3f}s'</span>)\n        <span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">'file_name'</span>: self.<span class=\"hljs-property\">file_name</span>, <span class=\"hljs-string\">'orig_img'</span>: self.<span class=\"hljs-property\">im0</span>, <span class=\"hljs-string\">'cropped_img'</span>: cropped_img, <span class=\"hljs-string\">'bbox'</span>: bbox,\n                <span class=\"hljs-string\">'det_conf'</span>: det_conf}\n</code></pre>\n<p>디버깅 목적을 위해 로깅 감지 데이터를 파일에 활성화할 수 있는 기능을 추가했습니다. 각 파일의 최대 크기는 25Mb이며 최대 10개의 파일을 저장한 후 덮어쓰기합니다.</p>\n<p>현재 작업에서는 감지기가 가장 높은 신뢰 점수를 가진 단일 감지만 반환하도록 설정해야 합니다. 감지기는 원본 이미지, 해당 경계 상자와 함께 자르기 감지된 영역, 신뢰 점수, 그리고 디버깅을 용이하게 하기 위해 각 이미지마다 생성된 고유한 이름을 출력합니다.</p>\n<p>번호판 영역 이미지 전처리</p>\n<p>일반적으로 다음 단계는 특정 이미지 전처리(예: RGB에서 그레이스케일로 변환, 노이즈 제거, 침식 + 팽창, 임계 처리, 히스토그램 평활화 등)를 수행하여 다음 OCR 단계를 위해 준비하는 것입니다. 전처리 작업은 OCR 솔루션 및 촬영 조건에 매우 의존하며 이에 맞게 조정됩니다. 그러나 EasyOCR로 이 기준 버전을 수행 중이며(나중에 사용자 지정 솔루션으로 대체해야 합니다), 저는 그레이스케일 변환 및 투영 프로필 방법을 이용한 기울기 보정이라는 두 가지 범용적인 단계로 전처리를 제한하기로 결정했습니다.</p>\n<p>여기서는 평면 각도 보정을 사용하고 있지만 나중에는 원래의 번호판 모서리 탐지기와 호모그래피 계산 및 원근 변환을 사용한 보정으로 업데이트해야 합니다.</p>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title class_\">Skew</span> <span class=\"hljs-title class_\">Correction</span> (projection profile)\ndef <span class=\"hljs-title function_\">_find_score</span>(arr, angle):\n    data = <span class=\"hljs-title function_\">rotate</span>(arr, angle, reshape=<span class=\"hljs-title class_\">False</span>, order=<span class=\"hljs-number\">0</span>)\n    hist = np.<span class=\"hljs-title function_\">sum</span>(data, axis=<span class=\"hljs-number\">1</span>)\n    score = np.<span class=\"hljs-title function_\">sum</span>((hist[<span class=\"hljs-number\">1</span>:] - hist[:-<span class=\"hljs-number\">1</span>]) ** <span class=\"hljs-number\">2</span>)\n    <span class=\"hljs-keyword\">return</span> hist, score\n\ndef <span class=\"hljs-title function_\">_find_angle</span>(img, delta=<span class=\"hljs-number\">0.5</span>, limit=<span class=\"hljs-number\">10</span>):\n    angles = np.<span class=\"hljs-title function_\">arange</span>(-limit, limit+delta, delta)\n    scores = []\n    <span class=\"hljs-keyword\">for</span> angle <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">angles</span>:\n        hist, score = <span class=\"hljs-title function_\">_find_score</span>(img, angle)\n        scores.<span class=\"hljs-title function_\">append</span>(score)\n    best_score = <span class=\"hljs-title function_\">max</span>(scores)\n    best_angle = angles[scores.<span class=\"hljs-title function_\">index</span>(best_score)]\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">'Best angle: {best_angle}'</span>)\n    <span class=\"hljs-keyword\">return</span> best_angle\n\ndef <span class=\"hljs-title function_\">correct_skew</span>(img):\n    # correctskew\n    best_angle = <span class=\"hljs-title function_\">_find_angle</span>(img)\n    data = <span class=\"hljs-title function_\">rotate</span>(img, best_angle, reshape=<span class=\"hljs-title class_\">False</span>, order=<span class=\"hljs-number\">0</span>)\n    <span class=\"hljs-keyword\">return</span> data\n</code></pre>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_13.png\" alt=\"이미지\"></p>\n<p>위 이미지 처리 단계 이후에는 인식을 위해 충분히 좋은 이미지로 간주할 수 있습니다.</p>\n<p>번호판 인식 (OCR)</p>\n<p>기준으로 EasyOCR 솔루션을 사용하기로 결정했어요. 쓰기 편하고 인식 정확도가 높아서 그리고 지루한 테서랙트에 비해 내가 알고 있는 괜찮은 대체재인 것 같아서요)</p>\n<p>EasyOCR을 이용한 번호판 인식을 위한 간단한 래퍼 클래스:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">EasyOcr</span>():\n    def <span class=\"hljs-title function_\">__init__</span>(self, lang = [<span class=\"hljs-string\">'en'</span>], allow_list = <span class=\"hljs-string\">'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'</span>, min_size=<span class=\"hljs-number\">50</span>, log_level=<span class=\"hljs-string\">'INFO'</span>, log_dir = <span class=\"hljs-string\">'./logs/'</span>):\n        self.<span class=\"hljs-property\">reader</span> = easyocr.<span class=\"hljs-title class_\">Reader</span>(lang, gpu=<span class=\"hljs-title class_\">False</span>)\n        self.<span class=\"hljs-property\">allow_list</span> = allow_list\n        self.<span class=\"hljs-property\">min_size</span> = min_size\n        self.<span class=\"hljs-property\">log_level</span> = log_level\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">log_level</span>:\n            self.<span class=\"hljs-property\">num_log_level</span> = <span class=\"hljs-title function_\">getattr</span>(logging, log_level.<span class=\"hljs-title function_\">upper</span>(),\n                                         <span class=\"hljs-number\">20</span>)  ## log_level 입력 문자열을 로깅 모듈에서 허용하는 값 중 하나로 변환하고, 만약 없으면 <span class=\"hljs-number\">20</span>(<span class=\"hljs-variable constant_\">INFO</span>)으로 설정\n            self.<span class=\"hljs-property\">log_dir</span> = log_dir\n            # 로거 설정\n            log_formatter = logging.<span class=\"hljs-title class_\">Formatter</span>(<span class=\"hljs-string\">\"%(asctime)s %(message)s\"</span>)\n            logFile = self.<span class=\"hljs-property\">log_dir</span> + <span class=\"hljs-string\">'ocr.log'</span>\n            my_handler = <span class=\"hljs-title class_\">RotatingFileHandler</span>(logFile, mode=<span class=\"hljs-string\">'a'</span>, maxBytes=<span class=\"hljs-number\">25</span> * <span class=\"hljs-number\">1024</span> * <span class=\"hljs-number\">1024</span>,\n                                             backupCount=<span class=\"hljs-number\">10</span>, encoding=<span class=\"hljs-string\">'utf-8'</span>, delay=<span class=\"hljs-title class_\">False</span>)\n            my_handler.<span class=\"hljs-title function_\">setFormatter</span>(log_formatter)\n            my_handler.<span class=\"hljs-title function_\">setLevel</span>(self.<span class=\"hljs-property\">num_log_level</span>)\n            self.<span class=\"hljs-property\">logger</span> = logging.<span class=\"hljs-title function_\">getLogger</span>(__name__)  \n            self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">setLevel</span>(self.<span class=\"hljs-property\">num_log_level</span>)\n            self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">addHandler</span>(my_handler)\n\n    def <span class=\"hljs-title function_\">run</span>(self, detect_result_dict):\n        <span class=\"hljs-keyword\">if</span> detect_result_dict[<span class=\"hljs-string\">'cropped_img'</span>] is not <span class=\"hljs-title class_\">None</span>:\n            t0 = time.<span class=\"hljs-title function_\">time</span>()\n            img = detect_result_dict[<span class=\"hljs-string\">'cropped_img'</span>]\n            img = <span class=\"hljs-title function_\">ocr_img_preprocess</span>(img)\n            file_name = detect_result_dict.<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'file_name'</span>)\n            ocr_result = self.<span class=\"hljs-property\">reader</span>.<span class=\"hljs-title function_\">readtext</span>(img, allowlist = self.<span class=\"hljs-property\">allow_list</span>, min_size=self.<span class=\"hljs-property\">min_size</span>)\n            text = [x[<span class=\"hljs-number\">1</span>] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ocr_result]\n            confid = [x[<span class=\"hljs-number\">2</span>] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ocr_result]\n            text = <span class=\"hljs-string\">\"\"</span>.<span class=\"hljs-title function_\">join</span>(text) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">len</span>(text) > <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-title class_\">None</span>\n            confid = np.<span class=\"hljs-title function_\">round</span>(np.<span class=\"hljs-title function_\">mean</span>(confid), <span class=\"hljs-number\">2</span>) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">len</span>(confid) > <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-title class_\">None</span>   \n            t1 = time.<span class=\"hljs-title function_\">time</span>()\n            <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">'인식된 번호판: {text}, 신뢰도: {confid}.\\nOCR 총 시간: {(t1 - t0):.3f}s'</span>)\n            <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">log_level</span>:\n                # 디버그 모드일 때 결과를 파일에 작성\n                self.<span class=\"hljs-property\">logger</span>.<span class=\"hljs-title function_\">debug</span>(f<span class=\"hljs-string\">'{file_name} 인식된 번호판: {text}, 신뢰도: {confid}, OCR 총 시간: {(t1 - t0):.3f}s.'</span>)\n\n            <span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">'text'</span>: text, <span class=\"hljs-string\">'confid'</span>: confid}\n        <span class=\"hljs-attr\">else</span>:\n            <span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">'text'</span>: <span class=\"hljs-title class_\">None</span>, <span class=\"hljs-string\">'confid'</span>: <span class=\"hljs-title class_\">None</span>}\n</code></pre>\n<p>디버그 목적으로 Detector와 마찬가지로 OCR 데이터를 파일에 기록할 수 있는 기능도 추가되었다.</p>\n<p>인식 모듈은 인식된 문자열과 신뢰도 점수를 반환합니다.</p>\n<p>검증 및 조치</p>\n<p>검출된 번호판에서 성공적으로 인식된 텍스트를 가져왔으면, 이를 확인하고 일부 조치를 취해야 합니다. 번호판 확인 단계에서 가장 합리적인 일은 고객이 업데이트하는 데이터베이스를 사용하는 것입니다. 이 데이터베이스는 매번 또는 하루에 한 번씩 읽어서 로컬 저장소에 목록을 저장할 것입니다. 현재 기준 버전에서 데이터베이스를 설정하지 않고 주요 기능에 집중하기로 결정했습니다. 대신 Google Sheets를 예시로 사용할 것입니다.</p>\n<p>이 순간에는 아무런 조치 단계가 설정되어 있지 않습니다. 허용 목록에 있는 라이선스 번호 확인 결과만 표시됩니다. 하지만 라즈베리파이를 사용하면 GPIO 제어 릴레이 스위치를 통해 어떤 하중이든 매우 쉽게 작동시킬 수 있습니다.</p>\n<p>시각화</p>\n<p>해결책을 편안하게 모니터링하고 디버그할 수 있도록 시각화 모듈을 추가했습니다. 이 모듈은 번호판 인식 프로세스 표시, 입력 이미지 저장, 검출된 번호판이 있는 자르기된 영역 및 출력 결과 이미지 표시를 처리합니다. 또한, e-ink 스크린에 번호판 영역 및 인식된 텍스트를 표시하는 기능을 추가했습니다.</p>\n<p>현재, 편의를 위해 이미지는 압축된 JPG로 저장되며 로그 폴더에 10800개의 이미지가 한정된 양으로 저장됩니다(폴더 최대 크기 약 500Mb). 프로덕션 솔루션에서 시각화가 필요하지 않으며, 디버깅을 위해 이미지는 NumPy ndarrays나 이진 문자열에 저장하는 것이 더 좋습니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Visualize</span>():\n    def <span class=\"hljs-title function_\">__init__</span>(self, im0, file_name, cropped_img=<span class=\"hljs-title class_\">None</span>, bbox=<span class=\"hljs-title class_\">None</span>, det_conf=<span class=\"hljs-title class_\">None</span>, ocr_num=<span class=\"hljs-title class_\">None</span>, ocr_conf=<span class=\"hljs-title class_\">None</span>, num_check_response=<span class=\"hljs-title class_\">None</span>, out_img_size=(<span class=\"hljs-number\">720</span>,<span class=\"hljs-number\">1280</span>), outp_orig_img_size = <span class=\"hljs-number\">640</span>, log_dir =<span class=\"hljs-string\">'./logs/'</span>, save_jpg_qual = <span class=\"hljs-number\">65</span>, log_img_qnt_limit = <span class=\"hljs-number\">10800</span>):\n        self.<span class=\"hljs-property\">im0</span> = im0\n        self.<span class=\"hljs-property\">input_img</span> = im0.<span class=\"hljs-title function_\">copy</span>()\n        self.<span class=\"hljs-property\">file_name</span> = file_name\n        self.<span class=\"hljs-property\">cropped_img</span> = cropped_img\n        self.<span class=\"hljs-property\">bbox</span> = bbox\n        self.<span class=\"hljs-property\">det_conf</span> = det_conf\n        self.<span class=\"hljs-property\">ocr_num</span> = ocr_num\n        self.<span class=\"hljs-property\">ocr_conf</span> = ocr_conf\n        self.<span class=\"hljs-property\">num_check_response</span> = num_check_response\n        self.<span class=\"hljs-property\">out_img_size</span> = out_img_size\n        self.<span class=\"hljs-property\">save_jpg_qual</span> = save_jpg_qual\n        self.<span class=\"hljs-property\">log_dir</span> = log_dir\n        self.<span class=\"hljs-property\">imgs_log_dir</span> = self.<span class=\"hljs-property\">log_dir</span> + <span class=\"hljs-string\">'imgs/'</span>\n        os.<span class=\"hljs-title function_\">makedirs</span>(os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">dirname</span>(self.<span class=\"hljs-property\">imgs_log_dir</span>), exist_ok=<span class=\"hljs-title class_\">True</span>)\n        self.<span class=\"hljs-property\">crop_imgs_log_dir</span> = self.<span class=\"hljs-property\">log_dir</span> + <span class=\"hljs-string\">'imgs/crop/'</span>\n        os.<span class=\"hljs-title function_\">makedirs</span>(os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">dirname</span>(self.<span class=\"hljs-property\">crop_imgs_log_dir</span>), exist_ok=<span class=\"hljs-title class_\">True</span>)\n        self.<span class=\"hljs-property\">orig_imgs_log_dir</span> = self.<span class=\"hljs-property\">log_dir</span> + <span class=\"hljs-string\">'imgs/inp/'</span>\n        os.<span class=\"hljs-title function_\">makedirs</span>(os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">dirname</span>(self.<span class=\"hljs-property\">orig_imgs_log_dir</span>), exist_ok=<span class=\"hljs-title class_\">True</span>)\n        self.<span class=\"hljs-property\">log_img_qnt_limit</span> = log_img_qnt_limit\n\n        # <span class=\"hljs-title class_\">Create</span> blank image\n        h, w = self.<span class=\"hljs-property\">out_img_size</span>\n        self.<span class=\"hljs-property\">img</span> = np.<span class=\"hljs-title function_\">zeros</span>((h, w, <span class=\"hljs-number\">3</span>), np.<span class=\"hljs-property\">uint8</span>)\n        self.<span class=\"hljs-property\">img</span>[:, :] = (<span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">255</span>)\n\n        # <span class=\"hljs-title class_\">Draw</span> bounding box on top the image\n        <span class=\"hljs-keyword\">if</span> (self.<span class=\"hljs-property\">bbox</span> is not <span class=\"hljs-title class_\">None</span>) and (self.<span class=\"hljs-property\">det_conf</span> is not <span class=\"hljs-title class_\">None</span>):\n            label = f<span class=\"hljs-string\">'{self.det_conf.item():.2f}'</span>\n            color = [<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">127</span>]\n            <span class=\"hljs-title function_\">plot_one_box</span>(self.<span class=\"hljs-property\">bbox</span>, self.<span class=\"hljs-property\">im0</span>, label=label, color=color, line_thickness=<span class=\"hljs-number\">3</span>)\n\n        # <span class=\"hljs-title class_\">Resize</span> img width to fit the plot, keep origin aspect ratio\n        h0, w0 = im0.<span class=\"hljs-property\">shape</span>[:<span class=\"hljs-number\">2</span>]\n        aspect = w0 / h0\n        <span class=\"hljs-keyword\">if</span> aspect > <span class=\"hljs-number\">1</span>:  # horizontal image\n            new_w = outp_orig_img_size\n            new_h = np.<span class=\"hljs-title function_\">round</span>(new_w / aspect).<span class=\"hljs-title function_\">astype</span>(int)\n        elif aspect &#x3C; <span class=\"hljs-number\">1</span>:  # vertical image\n            new_h = outp_orig_img_size\n            new_w = np.<span class=\"hljs-title function_\">round</span>(new_h * aspect).<span class=\"hljs-title function_\">astype</span>(int)\n        <span class=\"hljs-attr\">else</span>:  # square image\n            new_h, new_w = outp_orig_img_size, outp_orig_img_size\n        self.<span class=\"hljs-property\">im0</span> = cv2.<span class=\"hljs-title function_\">resize</span>(self.<span class=\"hljs-property\">im0</span>, (new_w, new_h), interpolation=cv2.<span class=\"hljs-property\">INTER_AREA</span>)\n        im0_h, im0_w = self.<span class=\"hljs-property\">im0</span>.<span class=\"hljs-property\">shape</span>[:<span class=\"hljs-number\">2</span>]\n\n        # <span class=\"hljs-title class_\">Add</span> original full image\n        im0_offset = <span class=\"hljs-number\">0</span>\n        self.<span class=\"hljs-property\">img</span>[<span class=\"hljs-attr\">im0_offset</span>:im0_h + im0_offset, <span class=\"hljs-attr\">im0_offset</span>:im0_w + im0_offset] = self.<span class=\"hljs-property\">im0</span>\n\n        # <span class=\"hljs-title class_\">Add</span> cropped image <span class=\"hljs-keyword\">with</span> detected number bbox\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">cropped_img</span> is not <span class=\"hljs-title class_\">None</span>:\n            # <span class=\"hljs-title class_\">Resize</span> cropped img\n            target_width = <span class=\"hljs-title function_\">int</span>((w - (im0_w + im0_offset)) / <span class=\"hljs-number\">3</span>)\n            r = target_width / self.<span class=\"hljs-property\">cropped_img</span>.<span class=\"hljs-property\">shape</span>[<span class=\"hljs-number\">1</span>]\n            dim = (target_width, <span class=\"hljs-title function_\">int</span>(self.<span class=\"hljs-property\">cropped_img</span>.<span class=\"hljs-property\">shape</span>[<span class=\"hljs-number\">0</span>] * r))\n            self.<span class=\"hljs-property\">cropped_img</span> = cv2.<span class=\"hljs-title function_\">resize</span>(self.<span class=\"hljs-property\">cropped_img</span>, dim, interpolation=cv2.<span class=\"hljs-property\">INTER_AREA</span>)\n            crop_h, crop_w = self.<span class=\"hljs-property\">cropped_img</span>.<span class=\"hljs-property\">shape</span>[:<span class=\"hljs-number\">2</span>]\n            # <span class=\"hljs-title class_\">Add</span> cropped img\n            crop_h_y1 = <span class=\"hljs-title function_\">int</span>(h/<span class=\"hljs-number\">7</span>)\n            crop_w_x1 = im0_w + im0_offset + <span class=\"hljs-title function_\">int</span>((w - (im0_w + im0_offset) - crop_w) / <span class=\"hljs-number\">2</span>)\n            self.<span class=\"hljs-property\">img</span>[<span class=\"hljs-attr\">crop_h_y1</span>:crop_h + crop_h_y1, <span class=\"hljs-attr\">crop_w_x1</span>:crop_w + crop_w_x1] = self.<span class=\"hljs-property\">cropped_img</span>\n            # <span class=\"hljs-title class_\">Add</span> <span class=\"hljs-string\">`_det`</span> to filename\n            self.<span class=\"hljs-property\">file_name</span> = <span class=\"hljs-title class_\">Path</span>(self.<span class=\"hljs-property\">file_name</span>).<span class=\"hljs-property\">stem</span> + <span class=\"hljs-string\">\"_det\"</span> + <span class=\"hljs-title class_\">Path</span>(self.<span class=\"hljs-property\">file_name</span>).<span class=\"hljs-property\">suffix</span>\n\n        # <span class=\"hljs-title class_\">Add</span> ocr recognized number\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">ocr_num</span> is not <span class=\"hljs-title class_\">None</span>:\n            label = f<span class=\"hljs-string\">\"{self.ocr_num} ({self.ocr_conf})\"</span>\n            t_thickn = <span class=\"hljs-number\">2</span>  # text font thickness <span class=\"hljs-keyword\">in</span> px\n            font = cv2.<span class=\"hljs-property\">FONT_HERSHEY_SIMPLEX</span>  # font\n            fontScale = <span class=\"hljs-number\">1.05</span>\n            # calculate position\n            text_size = cv2.<span class=\"hljs-title function_\">getTextSize</span>(label, font, fontScale=fontScale, thickness=t_thickn)[<span class=\"hljs-number\">0</span>]\n            w_center = <span class=\"hljs-title function_\">int</span>((im0_w + im0_offset + w)/<span class=\"hljs-number\">2</span>)\n            ocr_w_x1 = <span class=\"hljs-title function_\">int</span>(w_center - text_size[<span class=\"hljs-number\">0</span>]/<span class=\"hljs-number\">2</span>)\n            ocr_h_y1 = <span class=\"hljs-title function_\">int</span>(crop_h_y1 + crop_h + <span class=\"hljs-number\">55</span>)\n            org = (ocr_w_x1, ocr_h_y1)  # position\n            # <span class=\"hljs-title class_\">Plot</span> text on img\n            cv2.<span class=\"hljs-title function_\">putText</span>(self.<span class=\"hljs-property\">img</span>, label, org, font, fontScale,  color=(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>), thickness=t_thickn, lineType=cv2.<span class=\"hljs-property\">LINE_AA</span>)\n\n        # <span class=\"hljs-title class_\">Add</span> number check response <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">in</span> allowed list\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">num_check_response</span> == <span class=\"hljs-string\">'Allowed'</span>:\n            label = <span class=\"hljs-string\">\"-=Allowed=-\"</span>\n            fontColor = (<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">255</span>,<span class=\"hljs-number\">0</span>)\n        <span class=\"hljs-attr\">else</span>:\n            label = <span class=\"hljs-string\">\"-=Prohibited!=-\"</span>\n            fontColor = (<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">255</span>)\n        t_thickn = <span class=\"hljs-number\">2</span>  # text font thickness <span class=\"hljs-keyword\">in</span> px\n        font = cv2.<span class=\"hljs-property\">FONT_HERSHEY_SIMPLEX</span>  # font\n        fontScale = <span class=\"hljs-number\">1.05</span>\n        # calculate position\n        text_size = cv2.<span class=\"hljs-title function_\">getTextSize</span>(label, font, fontScale=fontScale, thickness=t_thickn)[<span class=\"hljs-number\">0</span>]\n        w_center = <span class=\"hljs-title function_\">int</span>((im0_w + im0_offset + w) / <span class=\"hljs-number\">2</span>)\n        response_w_x1 = <span class=\"hljs-title function_\">int</span>(w_center - text_size[<span class=\"hljs-number\">0</span>] / <span class=\"hljs-number\">2</span>)\n        response_h_y1 = <span class=\"hljs-title function_\">int</span>(h*<span class=\"hljs-number\">3</span>/<span class=\"hljs-number\">7</span>) #<span class=\"hljs-variable constant_\">TBD</span>\n        org = (response_w_x1, response_h_y1)  # position\n        # <span class=\"hljs-title class_\">Plot</span> text on img\n        cv2.<span class=\"hljs-title function_\">putText</span>(self.<span class=\"hljs-property\">img</span>, label, org, font, fontScale, color=fontColor, thickness=t_thickn, lineType=cv2.<span class=\"hljs-property\">LINE_AA</span>)\n\n    def <span class=\"hljs-title function_\">show</span>(self):\n        # <span class=\"hljs-title class_\">Show</span> the image\n        cv2.<span class=\"hljs-title function_\">imshow</span>(<span class=\"hljs-string\">'image'</span>, self.<span class=\"hljs-property\">img</span>)\n\n    def <span class=\"hljs-title function_\">save</span>(self):\n        # <span class=\"hljs-title class_\">Remove</span> oldest file <span class=\"hljs-keyword\">if</span> reach quantity limit\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-title function_\">get_dir_file_quantity</span>(self.<span class=\"hljs-property\">imgs_log_dir</span>) > self.<span class=\"hljs-property\">log_img_qnt_limit</span>:\n            oldest_file = <span class=\"hljs-title function_\">sorted</span>([self.<span class=\"hljs-property\">imgs_log_dir</span>+f <span class=\"hljs-keyword\">for</span> f <span class=\"hljs-keyword\">in</span> os.<span class=\"hljs-title function_\">listdir</span>(self.<span class=\"hljs-property\">imgs_log_dir</span>)])[\n                <span class=\"hljs-number\">0</span>]  \n            os.<span class=\"hljs-title function_\">remove</span>(oldest_file)\n        # <span class=\"hljs-title class_\">Write</span> compressed jpeg <span class=\"hljs-keyword\">with</span> results\n        cv2.<span class=\"hljs-title function_\">imwrite</span>(f<span class=\"hljs-string\">\"{self.imgs_log_dir}{self.file_name}\"</span>, self.<span class=\"hljs-property\">img</span>, [<span class=\"hljs-title function_\">int</span>(cv2.<span class=\"hljs-property\">IMWRITE_JPEG_QUALITY</span>), self.<span class=\"hljs-property\">save_jpg_qual</span>])\n\n    def <span class=\"hljs-title function_\">save_input</span>(self):\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">input_img</span> is not <span class=\"hljs-title class_\">None</span>:\n            # <span class=\"hljs-title class_\">Remove</span> oldest file <span class=\"hljs-keyword\">if</span> reach quantity limit\n            <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-title function_\">get_dir_file_quantity</span>(self.<span class=\"hljs-property\">orig_imgs_log_dir</span>) > self.<span class=\"hljs-property\">log_img_qnt_limit</span>:\n                oldest_file = <span class=\"hljs-title function_\">sorted</span>([self.<span class=\"hljs-property\">orig_imgs_log_dir</span>+f <span class=\"hljs-keyword\">for</span> f <span class=\"hljs-keyword\">in</span> os.<span class=\"hljs-title function_\">listdir</span>(self.<span class=\"hljs-property\">orig_imgs_log_dir</span>)])[\n                    <span class=\"hljs-number\">0</span>]  \n                os.<span class=\"hljs-title function_\">remove</span>(oldest_file)\n            # <span class=\"hljs-title class_\">Write</span> compressed jpeg <span class=\"hljs-keyword\">with</span> results\n            cv2.<span class=\"hljs-title function_\">imwrite</span>(f<span class=\"hljs-string\">\"{self.orig_imgs_log_dir}orig_inp_{self.file_name}\"</span>, self.<span class=\"hljs-property\">input_img</span>)\n\n    def <span class=\"hljs-title function_\">save_crop</span>(self):\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">cropped_img</span> is not <span class=\"hljs-title class_\">None</span>:\n            # <span class=\"hljs-title class_\">Remove</span> oldest file <span class=\"hljs-keyword\">if</span> reach quantity limit\n            <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-title function_\">get_dir_file_quantity</span>(self.<span class=\"hljs-property\">crop_imgs_log_dir</span>) > self.<span class=\"hljs-property\">log_img_qnt_limit</span>:\n                oldest_file = <span class=\"hljs-title function_\">sorted</span>([self.<span class=\"hljs-property\">crop_imgs_log_dir</span>+f <span class=\"hljs-keyword\">for</span> f <span class=\"hljs-keyword\">in</span> os.<span class=\"hljs-title function_\">listdir</span>(self.<span class=\"hljs-property\">crop_imgs_log_dir</span>)])[\n                    <span class=\"hljs-number\">0</span>]  \n                os.<span class=\"hljs-title function_\">remove</span>(oldest_file)\n            # <span class=\"hljs-title class_\">Write</span> compressed jpeg <span class=\"hljs-keyword\">with</span> results\n            cv2.<span class=\"hljs-title function_\">imwrite</span>(f<span class=\"hljs-string\">\"{self.crop_imgs_log_dir}crop_{self.file_name}\"</span>, self.<span class=\"hljs-property\">cropped_img</span>)\n\n    def <span class=\"hljs-title function_\">display</span>(self):\n        # <span class=\"hljs-title class_\">Display</span> img using e-ink display <span class=\"hljs-number\">176</span>*<span class=\"hljs-number\">264</span>\n        disp_img = np.<span class=\"hljs-title function_\">zeros</span>((epd2in7.<span class=\"hljs-property\">EPD_WIDTH</span>, epd2in7.<span class=\"hljs-property\">EPD_HEIGHT</span>,<span class=\"hljs-number\">3</span>), np.<span class=\"hljs-property\">uint8</span>)\n        disp_img[:, :] = (<span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">255</span>, <span class=\"hljs-number\">255</span>)\n        \n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">cropped_img</span> is not <span class=\"hljs-title class_\">None</span>:\n            # <span class=\"hljs-title class_\">Add</span> cropped number\n            crop_resized = cv2.<span class=\"hljs-title function_\">resize</span>(self.<span class=\"hljs-property\">cropped_img</span>, (epd2in7.<span class=\"hljs-property\">EPD_HEIGHT</span>-<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">85</span>), interpolation=cv2.<span class=\"hljs-property\">INTER_AREA</span>)\n            crop_resized_h, crop_resized_w = crop_resized.<span class=\"hljs-property\">shape</span>[:<span class=\"hljs-number\">2</span>]\n            crop_w_x1 = <span class=\"hljs-title function_\">int</span>(epd2in7.<span class=\"hljs-property\">EPD_HEIGHT</span>/<span class=\"hljs-number\">2</span> - crop_resized_w/<span class=\"hljs-number\">2</span>)\n            disp_img[<span class=\"hljs-number\">2</span>:crop_resized_h+<span class=\"hljs-number\">2</span>, <span class=\"hljs-attr\">crop_w_x1</span>:crop_resized_w+crop_w_x1] = crop_resized\n        \n        <span class=\"hljs-keyword\">if</span>\n\n&#x3C;div <span class=\"hljs-keyword\">class</span>=<span class=\"hljs-string\">\"content-ad\"</span>>&#x3C;/div>\n\n지금까지 이룩한 것을 시험해 봅시다. 정지 이미지에서의 탐지 및 인식 파이프라인:\n\n![image1](<span class=\"hljs-regexp\">/assets/img</span><span class=\"hljs-regexp\">/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_15.png)\n\n길거리에서 기기 카메라를 사용한 종단간 솔루션 테스트:\n\n![image2](/</span>assets/img/<span class=\"hljs-number\">2024</span>-<span class=\"hljs-number\">06</span>-<span class=\"hljs-number\">20</span>-<span class=\"hljs-title class_\">AutomaticNumberPlateRecognitionwithRaspberryPi</span>_16.<span class=\"hljs-property\">png</span>)\n\n&#x3C;div <span class=\"hljs-keyword\">class</span>=<span class=\"hljs-string\">\"content-ad\"</span>>&#x3C;/div>\n\n</code></pre>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_17.png\" alt=\"Image 1\"></p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_18.png\" alt=\"Image 2\"></p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_19.png\" alt=\"Image 3\"></p>\n<p>Performance</p>\n<p>현재 구성으로는 감지에 약 700<del>800ms, OCR 단계에 약 900</del>1200ms가 소요되며, 평균 FPS는 약 0.4~0.5입니다.</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_20.png\" alt=\"이미지\"></p>\n<p>현재 주차 장벽 자동화 프로젝트에는 이러한 프레임 속도 값이 중요하지 않지만, 개선할 여지가 분명히 많습니다.</p>\n<p>htop에서 CPU 활용률이 거의 100%에 가깝다는 것을 알 수 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_21.png\" alt=\"이미지\"></p>\n<p>모든 테스트는 Raspberry Pi OS의 기본 설정으로 수행되었습니다. UI를 비활성화하고 기본적으로 활성화된 다른 백그라운드 서비스를 모두 제거하면 성능과 안정성이 높아집니다.</p>\n<p>보너스</p>\n<p>추가 조정 없이도 우리의 감지기 모듈은 LEGO 자동차의 번호판을 완벽하게 감지할 수 있다는 것이 밝혀졌습니다.</p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_22.png\" alt=\"이미지1\"></p>\n<p><img src=\"/assets/img/2024-06-20-AutomaticNumberPlateRecognitionwithRaspberryPi_23.png\" alt=\"이미지2\"></p>\n<p>그래서 레고를 아들에게 빌려 Raspberry Pi Build Hat을 사용하여 나만의 주차장 바리어를 만들기로 결정했고, \"실제\" 조건에서 완전한 엔드 투 엔드 테스트를 제공하기로 했습니다.</p>\n<p>LEG 월드 햇 프로프라이어터리 라이브러리를 기반으로 한 Action 모듈용 간단한 랩퍼:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Action</span>():\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):\n        self.motor = Motor(<span class=\"hljs-string\">'A'</span>)\n        self.motor.set_default_speed(<span class=\"hljs-number\">25</span>)\n        self.matrix = Matrix(<span class=\"hljs-string\">'B'</span>)\n        self.ok_color = [[(<span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>)] <span class=\"hljs-keyword\">for</span> y <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>)]\n        self.nok_color = [[(<span class=\"hljs-number\">9</span>, <span class=\"hljs-number\">10</span>) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>)] <span class=\"hljs-keyword\">for</span> y <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>)]\n        self.matrix.set_transition(<span class=\"hljs-number\">2</span>) <span class=\"hljs-comment\">#fade-in/out</span>\n        self.matrix.set_pixel((<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>), (<span class=\"hljs-string\">\"blue\"</span>, <span class=\"hljs-number\">10</span>))\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_handle_motor</span>(<span class=\"hljs-params\">self, speed, pos, apos</span>):\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Motor:\"</span>, speed, pos, apos)\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>(<span class=\"hljs-params\">self, action_status</span>):\n        <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n            <span class=\"hljs-keyword\">if</span> action_status[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'Allowed'</span>:\n                self.matrix.set_pixels(self.ok_color)\n                time.sleep(<span class=\"hljs-number\">1</span>)\n                self.motor.run_for_degrees(-<span class=\"hljs-number\">90</span>, blocking=<span class=\"hljs-literal\">False</span>)\n                time.sleep(<span class=\"hljs-number\">5</span>)\n                self.motor.run_for_degrees(<span class=\"hljs-number\">90</span>, blocking=<span class=\"hljs-literal\">False</span>)\n                time.sleep(<span class=\"hljs-number\">1</span>)\n            <span class=\"hljs-keyword\">elif</span> action_status[<span class=\"hljs-number\">0</span>] == <span class=\"hljs-string\">'Prohibited'</span>:\n                self.matrix.set_pixels(self.nok_color)\n                time.sleep(<span class=\"hljs-number\">3</span>)\n            <span class=\"hljs-keyword\">else</span>:\n                self.matrix.clear()\n                self.matrix.set_pixel((<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>), (<span class=\"hljs-string\">\"blue\"</span>, <span class=\"hljs-number\">10</span>))\n                time.sleep(<span class=\"hljs-number\">1</span>)\n                self.matrix.set_pixel((<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>), (<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">10</span>))\n                time.sleep(<span class=\"hljs-number\">1</span>)\n</code></pre>\n<p>Main 프로그램에서 action_status가 감지되고 변경될 때 메인 프로그램에서 액션을 트리거하여 병렬 스레드에서 이 모듈을 실행합니다.</p>\n<p>LEGO 번호판 중 하나를 Google 시트 \"데이터베이스\"에 추가했으므로 이제 모든 조각들을 함께 조합하여 실행할 수 있습니다.</p>\n<h1>최종 결론</h1>\n<p>전반적으로 라즈베리 파이를 사용하여 주차장 장벽을 제어하기 위한 자동 번호판 인식 시스템을 완전히 구현하는 데 성공했습니다.</p>\n<p>강조해야 할 문제 중 하나는 처리 속도가 느린 관계로 이미지 지연이 발생할 수 있다는 점입니다. 카메라는 자체 버퍼가 있으며 이미지를 느린 속도로 캡처하는 동안 씬이 변경되어도 버퍼에서 여전히 \"이전\" 프레임을 읽는 문제가 있습니다. 현재 사용 사례에서는 그다지 중요하지 않지만 개선을 위해 전체 처리 시간과 거의 동일한 간격으로 프레임 스킵을 추가했습니다. 이렇게 하면 더 빠른 프레임 읽기와 버퍼의 정리가 가능하며 CPU의 부하를 줄일 수 있습니다. 그러나 지연 없이 거의 실시간 스무스한 이미지 스트리밍이 필요하다면 최상의 옵션은 카메라 읽기를 별도의 병렬 스레드로 설정하여 버퍼에서 가능한 최대 속도로 프레임을 읽도록 하는 것이며, 주 프로그램이 필요 시에만 이 프로세스에서 프레임을 가져 올 수 있도록 합니다. 그러나 파이썬에서 멀티 스레딩은 실제 다중 프로세스 처리가 아니라 아키텍처적 관점에서 코드를 보다 명확하게 조직화하고 실행하는 데 도움이 되는 시뮬레이션인 것을 기억해야 합니다.</p>\n<h1>추가 단계</h1>\n<ul>\n<li>OCR. 현재 병목 현상인 OCR을 빠르게 처리할 수 있도록 개선해보세요. 나는 속도를 올리기 위해 작은 커스텀 RNN 기반 모델을 개발하기로 했습니다. 시간이 중요하지 않고 정확도만 필요한 경우 EasyOCR에서 다양한 모델을 사용하고 이를 여러분의 사례에 맞게 튜닝할 수 있습니다. 또는 WPOD-NET과 같은 다른 솔루션을 시도해볼 수도 있습니다. 또한 인식 품질을 향상시키는 중요한 포인트로는 정확한 사용 사례에 맞게 이미지 전처리를 조정하는 것이 있습니다.</li>\n<li>Detector. 속도를 높이기 위해 카메라가 근거리에 있는 자동차에서만 작업해야 하는 경우 해상도가 높은 이미지가 필요하지 않습니다. 또 다른 옵션은 가능하다면 카메라와 차량의 위치가 대략 고정되어 있다면 전체 프레임이 아닌 번호판이 위치할 것으로 예상되는 영역만 캡처할 수 있습니다.</li>\n</ul>\n<p>나중에 이 두 모델 모두 전이 학습, 양자화, 가지치기 및 기타 방법을 사용하여 경량화하고 엣지 장치에서 더 빠르고 가벼운 작동이 가능하도록 할 수 있습니다.</p>\n<p>그러나 아무리 빠른 실시간 처리가 필수적이더라도 (물론 자동 주차 장벽에는 해당하지 않을 것입니다), 텐서 코어가 있는 장치가 없으면 NVIDIA Jetson과 같은 장치가 없으면 속도와 품질 사이에 항상 트레이드오프가 존재할 것입니다. CPU 전용 장치에서는 항상 속도와 품질 사이의 교환 관계가 발생할 것입니다.</p>\n<p>더 개선할 수 있는 다른 옵션이 있어요 — 현재 상황에서는 CPU를 24시간 7일 돌릴 필요가 없어요. 자동차가 다가올 때만 PIR 또는 IR 센서에 의해 카메라가 작동될 수 있어요.</p>\n<p>다음 번에 구현해보려고 하는 마지막 포인트 — 솔루션을 마이크로서비스로 전환하고 생산자-소비자 데이터 흐름 패턴을 구현할 거예요.</p>\n<p>그럼 이만 하겠습니다. 이 긴 지루한 프로젝트 구현 설명을 읽어 주셔서 감사해요.</p>\n<p>건강하게 지내시고 우크라이나를 응원해주세요 ❤.</p>\n<h1>프로젝트에서 사용된 장비에 대한 링크:</h1>\n<ul>\n<li>Raspberry Pi 4 Model B 4GB</li>\n<li>Raspberry Pi Camera Module v2</li>\n<li>Raspberry Pi 4 Aluminum Case with Dual Cooling Fan</li>\n<li>GeeekPi(52pi) Raspberry Pi UPS EP-0136</li>\n<li>264x176 2.7인치 E-Ink 디스플레이 HAT for Raspberry Pi</li>\n<li>Raspberry Pi Build HAT</li>\n<li>LEGO 3x3 컬러 라이트 매트릭스</li>\n<li>LEGO 작은 테크닉 직각 모터</li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}