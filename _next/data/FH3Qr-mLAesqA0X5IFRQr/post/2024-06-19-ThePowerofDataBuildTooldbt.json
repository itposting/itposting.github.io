{"pageProps":{"post":{"title":"데이터 빌드 도구 dbt의 힘","description":"","date":"2024-06-19 05:17","slug":"2024-06-19-ThePowerofDataBuildTooldbt","content":"\n\n## 데이터 분석 엔지니어를 위한 안내서\n\n데이터 분석은 끊임없이 발전하는 프로세스이며, 효율적인 워크플로우를 개선하고 결과물을 제공하는 데 도움이 되는 여러 도구들이 있습니다. 저는 2018년 초부터 데이터 빌드 도구 (dbt)를 활용하여 다양한 데이터 웨어하우스에 빠르게 데이터 모델을 작성해 왔습니다. 이번 몇 년 동안 dbt-core와 dbt-cloud를 모두 활용하며, 그들의 비즈니스 가치를 직접 확인해 왔습니다. 또한 제 배우자는 dbt 인증 개발자이자 자신이 소속된 컨설팅 회사에서 정기적으로 dbt 교육을 담당하고 있습니다.\n\n![데이터 빌드 도구 (dbt)](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_0.png)\n\n본 문서에서는 dbt의 특징 중 주목할 만한 몇 가지를 살펴보고, DuckDB를 활용한 기술적인 솔루션을 스크린샷, 코드 조각, 그리고 지원하는 GitHub 저장소와 함께 안내해 드리겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# dbt의 특징\n\ndbt는 데이터 변환을 위한 강력한 도구로서 주목받고 있으며, 데이터 모델의 개발과 관리를 간편화하는 다양한 기능을 제공합니다. dbt는 ETL 도구가 아닌 것에 유의해야 합니다. 그것은 변환 단계에 특히 초점을 맞추고 있습니다. 그러나 데이터 무결성을 테스트하여 확실하게 유지하거나 포괄적인 문서를 생성하는 것과 같이, dbt는 분석 워크플로우를 향상시키는 데 필요한 능력을 제공합니다. 아래에서는 dbt를 Analytics 엔지니어에게 필수적인 도구로 만드는 주요 기능을 살펴보겠습니다.\n\n## 데이터 모델의 무결성을 위한 모델 테스팅\n\ndbt의 가장 강력한 기능 중 하나는 데이터 모델의 무결성을 테스트하는 능력입니다. 테스트를 데이터 변환 프로세스에 직접 통합함으로써, dbt는 데이터 품질 문제를 조기에 식별하고 해결할 수 있도록 보장합니다. 이 기능은 분석 신뢰성을 유지하는 데 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n다음은 ‘상자에서 나오는’ 몇 가지 테스트가 있습니다:\n\n- unique는 열의 모든 값이 고유한지 여부를 확인합니다.\n- not_null은 열에 NULL 값이 있는지 여부를 확인합니다.\n- accepted_values는 값이 정의된 목록에서 벗어나는지 확인합니다(열거형에 적합).\n- relationships는 열의 값이 다른 모델의 열에 있는지 확인합니다(외래 키에 적합).\n\n하지만 원하는 테스트를 정의할 수 있습니다. 테스트를 정의한 후에는 dbt test를 실행하고 모든 것이 통과되었는지 확인하는 것이 매우 쉽습니다:\n\n![이미지](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_1.png)\n\n<div class=\"content-ad\"></div>\n\n또한 v1.8부터 dbt는 단위 테스트를 소개했습니다. 이는 파이썬에서 오랫동안 사용 가능했던 unittest 패키지와는 달리 (2022년 2월에 릴리스된 버전 1.0.0부터 사용 가능했음), SQL 단위 테스트할 수 있는 능력은 매우 새로운 것입니다. 매우 간단한 예제 코드에서는 단위 테스트의 범위가 제한적이었지만, 단위 테스트에 대해 더 자세히 알아보려면 여기를 참고하십시오.\n\n## 문서 웹사이트 구축\n\n또 다른 주목할만한 dbt의 기능은 데이터 모델에 대한 포괄적인 문서를 자동으로 생성할 수 있는 능력입니다. 이 문서는 프로젝트의 yaml 파일에서 작성되며, 모델 및 레코드 레벨의 설명 및 메타데이터로 보강될 수 있어 데이터 파이프라인을 명확하게 이해할 수 있게 해줍니다.\n\n문서는 명령줄에서 dbt docs generate && dbt docs serve를 입력하여 생성할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_2.png\" />\n\n웹 브라우저에서 문서가 열릴 겁니다. 아래에는 dim_employee 테이블에 대한 문서가 나와 있어요. 이 문서에는 테이블에 대한 설명, 데이터 유형을 가진 필드들, 그들의 설명, 그리고 그들에 대해 정의된 테스트들이 포함돼 있어요.\n\n<img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_3.png\" />\n\n## 데이터 계통\n\n<div class=\"content-ad\"></div>\n\n문서 사이트 내에서 데이터 연형을 보여주는 링크가 오른쪽 하단에 있습니다. 이것은 상류 및 하류 모델, 소스 및 노출물을 모두 보여주어 매우 가치 있습니다:\n\n![show data lineage](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_4.png)\n\n여기서 우리는 선택된 모델인 dim_employee를 보라면, 두 개의 모델을 참조하는 것을 확인할 수 있습니다 (파란색으로 식별된 단계). 이 모델들은 또한 두 개의 이전 모델(우리의 스냅샷)과 그 외부 소스(초록색으로 식별)를 참조합니다. 이것이 하나의 하류 모델에서 사용되고 있으며, 비즈니스에 노출되어 대시보드에서 사용되고 있음을 확인할 수 있습니다 (주황색으로 식별). \n\n## 데이터 계약\n\n<div class=\"content-ad\"></div>\n\n스키마.yml 내의 모델 정의 일부로 각 필드의 데이터 유형을 정의할 수 있습니다. 데이터 유형이 여기서 업데이트되지 않고 변경되면 모델이 실패합니다. 이렇게 함으로써 코드 변경 중에도 생성된 테이블 스키마가 일관되게 유지되며 변경이 발생할 때 변경 사항을 알 수 있어서 변경이 프로덕션에 영향을 미치기 전에 하류 사용자에게 알릴 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_5.png)\n\n## dbt의 모델 유형\n\ndbt에서는 데이터 파이프라인에서 특정 목적을 제공하는 각기 다른 유형의 모델을 생성할 수 있습니다. 이는 다음을 포함합니다:\n\n<div class=\"content-ad\"></div>\n\n- 스냅샷: 특정 시점에서 데이터의 상태를 캡처하여 유효 기간과 유효 종료 날짜를 갖는 Type 2 SCD와 유사한 형태로 저장합니다. 모든 변경 가능한 소스에서 스냅샷을 활용합니다. 지난 주에 데이터가 다르게 보인다는 사람이 나에게 말했을 때 매우 유용하며, 왜 다른지 알고 싶어하는 경우에 큰 도움이 됩니다.\n- 테이블: 데이터베이스에 지속적으로 실제 테이블로 쿼리 결과를 작성합니다.\n- 뷰: 데이터의 동적 뷰를 제공하는 가상 테이블을 생성합니다.\n- 점진적 모델: 마지막 실행 이후에 변경된 데이터만 처리하고 저장하여 성능 및 저장 공간을 최적화합니다.\n\n# 기술적 솔루션: DuckDB를 활용한 dbt 프로젝트 구축\n\n이제 DuckDB를 활용하는 dbt 프로젝트를 구축하는 단계별 가이드로 들어가 봅시다. CSV 파일에서 소스를 추출하고 간단한 팩트 및 디멘젼 모델을 구축하는 간단한 프로젝트를 사용할 것입니다. 두 가지 다른 디멘젼 모델을 만들었는데, 이 중 하나는 두 가지 기본 스냅샷을 활용한 Type 2 Slowly Changing Dimension 모델입니다.\n\n## 단계 1: 환경 설정하기\n\n<div class=\"content-ad\"></div>\n\n시작하려면 dbt 및 DuckDB를 설치해야 합니다. 자세한 지침은 공식 dbt 및 DuckDB 문서에서 찾을 수 있지만, 기본적으로 가상 Python 환경을 만들고 다음을 입력하는 것뿐입니다:\n\n```js\npip install dbt-core dbt-duckdb\n```\n\n## 단계 2: dbt 프로젝트 생성\n\ndbt 프로젝트를 초기화하고 데이터 웨어하우스로 DuckDB를 사용하도록 구성하십시오. dbt에 새 프로젝트 빌드를 시작하도록 지시하여이 작업을 수행합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\ndbt init\n```\n\n프로젝트의 이름을 지정하고 원하는 데이터베이스를 선택하도록 안내받을 것입니다:\n\n![이미지](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_6.png)\n\n## 단계 3: 소스 및 모델 정의하기\n\n<div class=\"content-ad\"></div>\n\nCSV 파일에서 데이터를 추출하기 위해 dbt에서 소스 정의를 만들어주세요. 그런 다음 이러한 소스가 가변적이라면 스냅샷 폴더 내에 스냅샷을 생성해주세요.\n\n스냅샷이 준비되면, 여기에서 '강력한 규칙'을 구현할 수 있는 스테이징 뷰를 생성하고 마지막으로 모델 폴더 내에서 사실 및 차원 모델을 정의해주세요.\n\n최종 구조는 다음과 같습니다:\n\n![구조](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_7.png)\n\n<div class=\"content-ad\"></div>\n\nDuckDB를 사용할 때 dbt와 함께 사용하는 것 중 하나가 dbt가 변환 단계에만 집중하는 반면, DuckDB의 기능을 통해 외부 테이블을 참조할 수 있다는 점이 마음에 듭니다. 아래 스크린샷에서는 demo_files 폴더에 있는 네 개의 csv 파일을 가리키고 있습니다. 데이터를 데이터베이스에 로드해야만 참조할 수 있는 번거로움보다 훨씬 쉽습니다. \n\n![스크린샷](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_8.png)\n\n소스가 생성되면 Jinja를 사용하여 모델에서 이를 참조할 수 있습니다. dbt는 이를 통해 소스, 모델 및 노출 사이의 계보와 관계를 생성하는 방법을 알고 있습니다.\n\n아래 스크린샷에서는 스냅샷 테이블 중 하나를 만든 모습을 볼 수 있습니다. CREATE TABLE을 생성할 필요도 없고 MERGE 문을 만드는 로직에 대해 걱정할 필요도 없습니다. dbt가 대신해줍니다. 단순히 SQL 문을 쓰고 Jinja 블록 내에서 정의된 코드를 사용하면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n![2024-06-19-ThePowerofDataBuildTooldbt_9](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_9.png)\n\n위에 있는 설정은 스냅숏이 생성될 스키마, 고유 키 및 스냅숏 빌드 전략을 정의합니다.\n\n비슷하게, 다른 모델들도 동일한 방식으로 작성할 수 있습니다. 아래는 두 개의 하위 스냅숏에서 가져온 더 복잡한 Type 2 Slowly Changing Dimension 테이블입니다. 각각에 자체 유효한 시작 및 종료 날짜가 있는 두 하위 스냅숏에서 이상적인 to와 from 날짜를 원본으로 했습니다. 쿼리 끝에 내 차원 테이블의 -1 및 -2 값들을 간단한 UNION으로 추가했습니다 (화면 밖에서). 두 dbt 스냅숏을 결합하여 두 테이블을 통해 시간에 따른 변경 사항을 보여주고 있습니다. 스냅숏과 마찬가지로 타겟 스키마를 설정 블록에 추가하지 않았으므로 기본 스키마를 사용하도록 되어 있습니다:\n\n![2024-06-19-ThePowerofDataBuildTooldbt_10](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_10.png)\n\n<div class=\"content-ad\"></div>\n\n내 팩트 테이블은 차원들과 조인하여 올바른 매핑을 식별하고 문서화는 관계를 보여주도록 합니다. 이 접근 방식은 분석가가 항상 INNER JOIN을 사용하여 테이블을 조인할 수 있도록 합니다. dim_employee 테이블에 대한 조인은 Type 2 SCD에 연결될 때 날짜 범위를 사용합니다:\n\n![image](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_11.png)\n\n## 단계 4: 테스트 실행 및 문서 작성\n\ndbt 테스트를 실행하여 모델의 무결성을 확인하세요. 문서 웹사이트를 생성하여 데이터 파이프라인의 명확한 개요를 얻으세요.\n\n<div class=\"content-ad\"></div>\n\n(자세한 내용은 위쪽 섹션을 참조해주세요)\n\n## 단계 5: 결과 검토\n\ndbt run 결과를 검토하여 구축된 모델 및 생성된 문서를 확인하여 모든 것이 예상대로인지 확인하세요.\n\nDuckDB 데이터베이스를 생성하기 위해 이를 실행 중이므로 DuckDB cli로 이동하여 SQL 문을 실행하여 결과를 확인할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_12.png)\n\nDuckDB를 dbt 프로젝트에 사용하는 이유에 대해 궁금해할 수 있지만, 개발 환경에서 실행 중이라는 점을 강조하고 싶습니다. 개발 환경에서 DuckDB를 사용하고 프로덕션 환경에서는 Snowflake를 사용할 수 있습니다. 이렇게 함으로써 Snowflake의 개발 비용을 크게 줄일 수 있습니다. 개발 환경과 프로덕션 환경 간에 SQL 방언이 다른 경우, 하드코딩된 SQL 대신 Jinja 매크로를 활용할 수 있습니다. 이를 통해 현재 환경에 따라 올바른 SQL을 반환할 수 있습니다.\n\n# 결론\n\ndbt는 데이터 모델을 구축하고 관리하는 방식을 혁신적으로 바꿔놨으며, 모델 테스트 및 자동 문서화와 같은 강력한 기능을 제공합니다. 이 안내서를 따라가면 DuckDB를 이용한 dbt 프로젝트를 빠르게 설정하고 이 강력한 도구의 혜택을 누릴 수 있습니다. dbt를 사용해보고 더 많은 기능을 탐색해보기를 권장합니다. 여기서 전체 프로젝트와 코드 스니펫을 찾을 수 있습니다: [링크된 GitHub 저장소](링크).\n","ogImage":{"url":"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_0.png"},"coverImage":"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_0.png","tag":["Tech"],"readingTime":7},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>데이터 분석 엔지니어를 위한 안내서</h2>\n<p>데이터 분석은 끊임없이 발전하는 프로세스이며, 효율적인 워크플로우를 개선하고 결과물을 제공하는 데 도움이 되는 여러 도구들이 있습니다. 저는 2018년 초부터 데이터 빌드 도구 (dbt)를 활용하여 다양한 데이터 웨어하우스에 빠르게 데이터 모델을 작성해 왔습니다. 이번 몇 년 동안 dbt-core와 dbt-cloud를 모두 활용하며, 그들의 비즈니스 가치를 직접 확인해 왔습니다. 또한 제 배우자는 dbt 인증 개발자이자 자신이 소속된 컨설팅 회사에서 정기적으로 dbt 교육을 담당하고 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_0.png\" alt=\"데이터 빌드 도구 (dbt)\"></p>\n<p>본 문서에서는 dbt의 특징 중 주목할 만한 몇 가지를 살펴보고, DuckDB를 활용한 기술적인 솔루션을 스크린샷, 코드 조각, 그리고 지원하는 GitHub 저장소와 함께 안내해 드리겠습니다.</p>\n<h1>dbt의 특징</h1>\n<p>dbt는 데이터 변환을 위한 강력한 도구로서 주목받고 있으며, 데이터 모델의 개발과 관리를 간편화하는 다양한 기능을 제공합니다. dbt는 ETL 도구가 아닌 것에 유의해야 합니다. 그것은 변환 단계에 특히 초점을 맞추고 있습니다. 그러나 데이터 무결성을 테스트하여 확실하게 유지하거나 포괄적인 문서를 생성하는 것과 같이, dbt는 분석 워크플로우를 향상시키는 데 필요한 능력을 제공합니다. 아래에서는 dbt를 Analytics 엔지니어에게 필수적인 도구로 만드는 주요 기능을 살펴보겠습니다.</p>\n<h2>데이터 모델의 무결성을 위한 모델 테스팅</h2>\n<p>dbt의 가장 강력한 기능 중 하나는 데이터 모델의 무결성을 테스트하는 능력입니다. 테스트를 데이터 변환 프로세스에 직접 통합함으로써, dbt는 데이터 품질 문제를 조기에 식별하고 해결할 수 있도록 보장합니다. 이 기능은 분석 신뢰성을 유지하는 데 중요합니다.</p>\n<p>다음은 ‘상자에서 나오는’ 몇 가지 테스트가 있습니다:</p>\n<ul>\n<li>unique는 열의 모든 값이 고유한지 여부를 확인합니다.</li>\n<li>not_null은 열에 NULL 값이 있는지 여부를 확인합니다.</li>\n<li>accepted_values는 값이 정의된 목록에서 벗어나는지 확인합니다(열거형에 적합).</li>\n<li>relationships는 열의 값이 다른 모델의 열에 있는지 확인합니다(외래 키에 적합).</li>\n</ul>\n<p>하지만 원하는 테스트를 정의할 수 있습니다. 테스트를 정의한 후에는 dbt test를 실행하고 모든 것이 통과되었는지 확인하는 것이 매우 쉽습니다:</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_1.png\" alt=\"이미지\"></p>\n<p>또한 v1.8부터 dbt는 단위 테스트를 소개했습니다. 이는 파이썬에서 오랫동안 사용 가능했던 unittest 패키지와는 달리 (2022년 2월에 릴리스된 버전 1.0.0부터 사용 가능했음), SQL 단위 테스트할 수 있는 능력은 매우 새로운 것입니다. 매우 간단한 예제 코드에서는 단위 테스트의 범위가 제한적이었지만, 단위 테스트에 대해 더 자세히 알아보려면 여기를 참고하십시오.</p>\n<h2>문서 웹사이트 구축</h2>\n<p>또 다른 주목할만한 dbt의 기능은 데이터 모델에 대한 포괄적인 문서를 자동으로 생성할 수 있는 능력입니다. 이 문서는 프로젝트의 yaml 파일에서 작성되며, 모델 및 레코드 레벨의 설명 및 메타데이터로 보강될 수 있어 데이터 파이프라인을 명확하게 이해할 수 있게 해줍니다.</p>\n<p>문서는 명령줄에서 dbt docs generate &#x26;&#x26; dbt docs serve를 입력하여 생성할 수 있습니다:</p>\n<p>웹 브라우저에서 문서가 열릴 겁니다. 아래에는 dim_employee 테이블에 대한 문서가 나와 있어요. 이 문서에는 테이블에 대한 설명, 데이터 유형을 가진 필드들, 그들의 설명, 그리고 그들에 대해 정의된 테스트들이 포함돼 있어요.</p>\n<h2>데이터 계통</h2>\n<p>문서 사이트 내에서 데이터 연형을 보여주는 링크가 오른쪽 하단에 있습니다. 이것은 상류 및 하류 모델, 소스 및 노출물을 모두 보여주어 매우 가치 있습니다:</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_4.png\" alt=\"show data lineage\"></p>\n<p>여기서 우리는 선택된 모델인 dim_employee를 보라면, 두 개의 모델을 참조하는 것을 확인할 수 있습니다 (파란색으로 식별된 단계). 이 모델들은 또한 두 개의 이전 모델(우리의 스냅샷)과 그 외부 소스(초록색으로 식별)를 참조합니다. 이것이 하나의 하류 모델에서 사용되고 있으며, 비즈니스에 노출되어 대시보드에서 사용되고 있음을 확인할 수 있습니다 (주황색으로 식별).</p>\n<h2>데이터 계약</h2>\n<p>스키마.yml 내의 모델 정의 일부로 각 필드의 데이터 유형을 정의할 수 있습니다. 데이터 유형이 여기서 업데이트되지 않고 변경되면 모델이 실패합니다. 이렇게 함으로써 코드 변경 중에도 생성된 테이블 스키마가 일관되게 유지되며 변경이 발생할 때 변경 사항을 알 수 있어서 변경이 프로덕션에 영향을 미치기 전에 하류 사용자에게 알릴 수 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_5.png\" alt=\"이미지\"></p>\n<h2>dbt의 모델 유형</h2>\n<p>dbt에서는 데이터 파이프라인에서 특정 목적을 제공하는 각기 다른 유형의 모델을 생성할 수 있습니다. 이는 다음을 포함합니다:</p>\n<ul>\n<li>스냅샷: 특정 시점에서 데이터의 상태를 캡처하여 유효 기간과 유효 종료 날짜를 갖는 Type 2 SCD와 유사한 형태로 저장합니다. 모든 변경 가능한 소스에서 스냅샷을 활용합니다. 지난 주에 데이터가 다르게 보인다는 사람이 나에게 말했을 때 매우 유용하며, 왜 다른지 알고 싶어하는 경우에 큰 도움이 됩니다.</li>\n<li>테이블: 데이터베이스에 지속적으로 실제 테이블로 쿼리 결과를 작성합니다.</li>\n<li>뷰: 데이터의 동적 뷰를 제공하는 가상 테이블을 생성합니다.</li>\n<li>점진적 모델: 마지막 실행 이후에 변경된 데이터만 처리하고 저장하여 성능 및 저장 공간을 최적화합니다.</li>\n</ul>\n<h1>기술적 솔루션: DuckDB를 활용한 dbt 프로젝트 구축</h1>\n<p>이제 DuckDB를 활용하는 dbt 프로젝트를 구축하는 단계별 가이드로 들어가 봅시다. CSV 파일에서 소스를 추출하고 간단한 팩트 및 디멘젼 모델을 구축하는 간단한 프로젝트를 사용할 것입니다. 두 가지 다른 디멘젼 모델을 만들었는데, 이 중 하나는 두 가지 기본 스냅샷을 활용한 Type 2 Slowly Changing Dimension 모델입니다.</p>\n<h2>단계 1: 환경 설정하기</h2>\n<p>시작하려면 dbt 및 DuckDB를 설치해야 합니다. 자세한 지침은 공식 dbt 및 DuckDB 문서에서 찾을 수 있지만, 기본적으로 가상 Python 환경을 만들고 다음을 입력하는 것뿐입니다:</p>\n<pre><code class=\"hljs language-js\">pip install dbt-core dbt-duckdb\n</code></pre>\n<h2>단계 2: dbt 프로젝트 생성</h2>\n<p>dbt 프로젝트를 초기화하고 데이터 웨어하우스로 DuckDB를 사용하도록 구성하십시오. dbt에 새 프로젝트 빌드를 시작하도록 지시하여이 작업을 수행합니다:</p>\n<pre><code class=\"hljs language-js\">dbt init\n</code></pre>\n<p>프로젝트의 이름을 지정하고 원하는 데이터베이스를 선택하도록 안내받을 것입니다:</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_6.png\" alt=\"이미지\"></p>\n<h2>단계 3: 소스 및 모델 정의하기</h2>\n<p>CSV 파일에서 데이터를 추출하기 위해 dbt에서 소스 정의를 만들어주세요. 그런 다음 이러한 소스가 가변적이라면 스냅샷 폴더 내에 스냅샷을 생성해주세요.</p>\n<p>스냅샷이 준비되면, 여기에서 '강력한 규칙'을 구현할 수 있는 스테이징 뷰를 생성하고 마지막으로 모델 폴더 내에서 사실 및 차원 모델을 정의해주세요.</p>\n<p>최종 구조는 다음과 같습니다:</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_7.png\" alt=\"구조\"></p>\n<p>DuckDB를 사용할 때 dbt와 함께 사용하는 것 중 하나가 dbt가 변환 단계에만 집중하는 반면, DuckDB의 기능을 통해 외부 테이블을 참조할 수 있다는 점이 마음에 듭니다. 아래 스크린샷에서는 demo_files 폴더에 있는 네 개의 csv 파일을 가리키고 있습니다. 데이터를 데이터베이스에 로드해야만 참조할 수 있는 번거로움보다 훨씬 쉽습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_8.png\" alt=\"스크린샷\"></p>\n<p>소스가 생성되면 Jinja를 사용하여 모델에서 이를 참조할 수 있습니다. dbt는 이를 통해 소스, 모델 및 노출 사이의 계보와 관계를 생성하는 방법을 알고 있습니다.</p>\n<p>아래 스크린샷에서는 스냅샷 테이블 중 하나를 만든 모습을 볼 수 있습니다. CREATE TABLE을 생성할 필요도 없고 MERGE 문을 만드는 로직에 대해 걱정할 필요도 없습니다. dbt가 대신해줍니다. 단순히 SQL 문을 쓰고 Jinja 블록 내에서 정의된 코드를 사용하면 됩니다.</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_9.png\" alt=\"2024-06-19-ThePowerofDataBuildTooldbt_9\"></p>\n<p>위에 있는 설정은 스냅숏이 생성될 스키마, 고유 키 및 스냅숏 빌드 전략을 정의합니다.</p>\n<p>비슷하게, 다른 모델들도 동일한 방식으로 작성할 수 있습니다. 아래는 두 개의 하위 스냅숏에서 가져온 더 복잡한 Type 2 Slowly Changing Dimension 테이블입니다. 각각에 자체 유효한 시작 및 종료 날짜가 있는 두 하위 스냅숏에서 이상적인 to와 from 날짜를 원본으로 했습니다. 쿼리 끝에 내 차원 테이블의 -1 및 -2 값들을 간단한 UNION으로 추가했습니다 (화면 밖에서). 두 dbt 스냅숏을 결합하여 두 테이블을 통해 시간에 따른 변경 사항을 보여주고 있습니다. 스냅숏과 마찬가지로 타겟 스키마를 설정 블록에 추가하지 않았으므로 기본 스키마를 사용하도록 되어 있습니다:</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_10.png\" alt=\"2024-06-19-ThePowerofDataBuildTooldbt_10\"></p>\n<p>내 팩트 테이블은 차원들과 조인하여 올바른 매핑을 식별하고 문서화는 관계를 보여주도록 합니다. 이 접근 방식은 분석가가 항상 INNER JOIN을 사용하여 테이블을 조인할 수 있도록 합니다. dim_employee 테이블에 대한 조인은 Type 2 SCD에 연결될 때 날짜 범위를 사용합니다:</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_11.png\" alt=\"image\"></p>\n<h2>단계 4: 테스트 실행 및 문서 작성</h2>\n<p>dbt 테스트를 실행하여 모델의 무결성을 확인하세요. 문서 웹사이트를 생성하여 데이터 파이프라인의 명확한 개요를 얻으세요.</p>\n<p>(자세한 내용은 위쪽 섹션을 참조해주세요)</p>\n<h2>단계 5: 결과 검토</h2>\n<p>dbt run 결과를 검토하여 구축된 모델 및 생성된 문서를 확인하여 모든 것이 예상대로인지 확인하세요.</p>\n<p>DuckDB 데이터베이스를 생성하기 위해 이를 실행 중이므로 DuckDB cli로 이동하여 SQL 문을 실행하여 결과를 확인할 수 있습니다:</p>\n<p><img src=\"/assets/img/2024-06-19-ThePowerofDataBuildTooldbt_12.png\" alt=\"이미지\"></p>\n<p>DuckDB를 dbt 프로젝트에 사용하는 이유에 대해 궁금해할 수 있지만, 개발 환경에서 실행 중이라는 점을 강조하고 싶습니다. 개발 환경에서 DuckDB를 사용하고 프로덕션 환경에서는 Snowflake를 사용할 수 있습니다. 이렇게 함으로써 Snowflake의 개발 비용을 크게 줄일 수 있습니다. 개발 환경과 프로덕션 환경 간에 SQL 방언이 다른 경우, 하드코딩된 SQL 대신 Jinja 매크로를 활용할 수 있습니다. 이를 통해 현재 환경에 따라 올바른 SQL을 반환할 수 있습니다.</p>\n<h1>결론</h1>\n<p>dbt는 데이터 모델을 구축하고 관리하는 방식을 혁신적으로 바꿔놨으며, 모델 테스트 및 자동 문서화와 같은 강력한 기능을 제공합니다. 이 안내서를 따라가면 DuckDB를 이용한 dbt 프로젝트를 빠르게 설정하고 이 강력한 도구의 혜택을 누릴 수 있습니다. dbt를 사용해보고 더 많은 기능을 탐색해보기를 권장합니다. 여기서 전체 프로젝트와 코드 스니펫을 찾을 수 있습니다: <a href=\"%EB%A7%81%ED%81%AC\">링크된 GitHub 저장소</a>.</p>\n</body>\n</html>\n"},"__N_SSG":true}