{"pageProps":{"post":{"title":"시계열 회귀 및 교차 검증 깔끔한 접근 방식","description":"","date":"2024-06-19 20:22","slug":"2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach","content":"\n\n![Image](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_0.png)\n\n시계열 예측 방법은 항상 발전하고 있습니다. ARIMA가 오랫동안 기초를 이루어 왔지만, 머신러닝 모델도 큰 약속을 보여줍니다. 다양한 산업 분야에서 자료를 시간에 따라 더 정확하게 모델링할 수 있는 경우가 있습니다. 이 글에서는 그 중 하나인 매출 예측을 다루어 보겠습니다. 소중한 시간을 아끼기 위해, 바로 본문으로 넘어가겠습니다.\n\n# 코드\n\n이 글에서 모든 것을 재현하는 코드는 제 GitHub 저장소에서 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 데이터 세트\n\n이 연습에서는 Kaggle에서 Samuel Cortinhas가 공개한 CC0: Public 도메인으로 제공되는 시계열 데이터 연습 데이터 세트를 사용합니다. 이 데이터 세트는 10년(2010년부터 2019년) 동안의 모의 시계열 데이터를 포함하며 날짜, 상점 ID, 제품 ID 및 매출 기능이 포함되어 있습니다. 이 분석에서는 회귀 구성 요소에 초점을 맞추기 위해 단일 상점과 제품을 선택했습니다.\n\n![](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_1.png)\n\n# 시계열 분석\n\n<div class=\"content-ad\"></div>\n\n## 단계 0: 설정하기\n\n나는 데이터 탐색과 회귀를 위해 다음 패키지들을 사용할 것입니다. 로딩하기 전에 아래 명령어를 사용하여 설치할 수 있습니다: install.packages(\"package_name\").\n\n```js\n# 필요한 라이브러리 로딩하기\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(tidymodels)\nlibrary(modeltime)\nlibrary(timetk)\nlibrary(viridis)\n``` \n\n## Step 1: 날짜 및 해당할 수 있는 모든 것들!!\n\n<div class=\"content-ad\"></div>\n\n날짜는 제가 가장 좋아하는 변수입니다. 하나의 날짜 열은 많은 정보를 담고 있어요. 이 시나리오에서는 판매와의 관계를 탐색하기 위해 날짜 열에서 새로운 특징들을 만들 거에요. 하지만 먼저, 날짜 열을 문자열로만 사용하는 것보다는 as.Date()를 사용하여 정리할 거에요.\n\n```r\ndata <- data %>%\n  mutate(date = as.Date(date, format = \"%m/%d/%Y\"))\n```\n\n다음으로 회귀 분석을 위해 이 날짜 열에서 새로운 특징들을 만들 거에요. Lubridate 패키지는 이 작업을 간단하게 만들어 주는 편리한 함수들로 구성돼 있어요.\n\n```r\n# 시간과 관련된 요소를 포함하기 위해 데이터 전처리\ndf <- data %>%\n  mutate(\n    year = year(date),\n    semester = factor(semester(date)),\n    quarter = factor(quarter(date)),\n    day_in_week = factor(wday(date, label = TRUE)),\n    week_in_year = factor(week(date)),\n    day_in_year = factor(yday(date)),\n    month = factor(month(date, label = TRUE))\n  )\n```\n\n<div class=\"content-ad\"></div>\n\n이제 데이터가 다음과 같이 보입니다:\n\n![image](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_2.png)\n\n## 단계 2: 탐색적 데이터 분석\n\n단일 날짜 열에서 생성된 모든 이러한 새로운 흥미로운 기능들과 매출과의 관골을 탐색해 볼 것입니다. 연간 계절성부터 시작하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndf %>%\n  ggplot(aes(date, sales)) +\n  geom_line(alpha = 1, size = 1, color = \"darkblue\") +  \n  theme_bw() +\n  labs(title = \"일별 매출 분포 변화\", x = \"날짜\", y = \"매출\") +\n  scale_x_date(date_labels = \"%Y\", date_breaks = \"2 years\") +  \n  scale_y_continuous(labels = scales::comma) \n```\n\n<img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_3.png\" />\n\n매출 데이터에는 명확한 계절성과 특정한 추세가 있습니다. 이제 요일과의 관계를 살펴보겠습니다.\n\n```js\ndf %>%\n  ggplot(aes(day_in_week, sales, color = day_in_week)) +\n  geom_boxplot() +\n  geom_jitter(alpha = 0.1) +\n  theme_bw() +\n  scale_colour_viridis_d() +\n  labs(title = \"요일별 일일 매출 분포\", x = \"요일\", y = \"매출\") +\n  scale_x_discrete() +\n  scale_y_continuous(labels = scales::comma)\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_4.png)\n\n이제 월별 분포를 살펴보겠습니다.\n\n```js\ndf |> \n  ggplot(aes(month, sales)) +\n  geom_violin(color = \"darkgreen\") +  \n  geom_jitter(alpha = 0.2, aes(color = sales)) +  \n  theme_light() +\n  geom_smooth(method = \"loess\", se = FALSE) +  \n  scale_colour_viridis_c() +\n  labs(title = \"Daily Sales Distribution by Month\", x = \"\", y = \"Sales\", color= \"Sales\")\n```\n\n![Image](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_5.png)\n\n\n<div class=\"content-ad\"></div>\n\n이제 모델링으로 넘어가겠습니다.\n\n## 단계 3: 데이터 분할 및 교차 검증 설정\n\ntidymodels에서 제공하는 initial_time_split() 함수를 사용하여 데이터를 학습 및 테스트 세트로 나누겠습니다.\n\n```R\ndf_split <- df |> \n  initial_time_split(prop=0.9)  # 90% 데이터를 학습에, 10%를 테스트에 할당\n\ndf_train <- training(df_split)\ndf_test <- testing(df_split)\n```\n\n<div class=\"content-ad\"></div>\n\n이것이 분할의 모습입니다:\n\n<img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_6.png\" />\n\n교차 검증은 입력 데이터의 하위 집합에서 모델을 학습시키고 나머지 데이터에서 평가하여 모델을 평가하는 데 사용할 수 있습니다. 일반적인 교차 검증 방법은 데이터 포인트를 무작위로 선택하여 학습 데이터 집합에 할당합니다. 그러나 이 방법은 데이터가 순차적이어야하기 때문에 시계열에 적합하지 않습니다. Timetk 패키지에는 시계열 데이터 세트에 대한 교차 검증 폴드를 특별히 생성하고 해당 분할을 시각화하는 데 사용할 수있는 멋진 함수인 time_series_cv()가 있습니다.\n\n```R\n# 교차 검증 분할 생성\ndf_folds <- \n  time_series_cv(\n    df_train, \n    initial = \"3 years\", \n    assess = \"1 year\", \n    skip = \"6 months\",\n    slice_limit = 5)  \n\n# 분할 시각화\nplot_time_series_cv_plan(df_folds, date, sales)\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_7.png\" />\n\n## 단계 4: 모델링을 위한 데이터 준비\n\n레시피는 새로운 예측 변수를 만들고 모델에서 필요한 몇 가지 전처리를 수행할 수 있는 객체입니다. 저는 auto ARIMA 및 랜덤 포레스트 두 모델을 시도하고 싶기 때문에 두 레시피 객체를 만들 것입니다. 레시피()의 첫 번째 단계는 회귀 분석을 위한 공식입니다.\n\n```js\nrecipe_autoarima <- \n  recipe(sales ~ date,\n         data = df_train)\n```\n\n<div class=\"content-ad\"></div>\n\n두 번째 랜덤 포레스트 레시피에는 step_holiday()를 사용하여 date 데이터를 공휴일에 대한 하나 이상의 이진 지표 변수로 변환하는 기능을 추가할 것입니다. 또한 step_rm()을 사용하여 date 열을 제거하고 step_dummy()를 사용하여 모든 명목 예측 변수를 더미 변수로 변환할 것입니다.\n\n```js\nrecipe_rf <- \n  recipe(sales ~ ., data = df_train) |>\n  step_holiday(date, holidays = timeDate::listHolidays(\"US\")) |>  \n  step_rm(date) |>  \n  step_dummy(all_nominal_predictors())\n```\n\n다음은 recipe 객체가 보이는 모습입니다:\n\n![Recipe Object](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_8.png)\n\n<div class=\"content-ad\"></div>\n\n레시피 객체는 학습 및 테스트 데이터셋에서 반복 가능한 단계 시퀀스를 만들어주어 긴 피처 엔지니어링 코드를 작성하지 않고도 사용할 수 있습니다. 저는 이를 피처 엔지니어링의 단축키로 생각해요!\n\n아래 명령은 레시피 객체가 데이터셋을 업데이트하고 새로 생성된 열을 이해하는 데 사용될 수 있습니다.\n\n```js\nrecipe_rf |> prep() |> bake(new_data = NULL)\n```\n\n## 단계 5: 모델 사양 및 재표본화\n\n<div class=\"content-ad\"></div>\n\n레시피를 만들면, 각각의 두 모델에 대한 명세서를 작성할 것입니다. ARIMA에 Modeltime을 사용하고 랜덤 포레스트에는 Tidymodels를 사용할 예정이에요. 이것들은 일관된 단계적 흐름으로 여러 모델에 대한 명세를 만드는 훌륭한 방법을 제공합니다.\n\n```js\n# Auto ARIMA 모델 명세\nauto_arima_spec <- arima_boost() |> \n  set_mode(\"regression\") |> \n  set_engine('auto_arima_xgboost')\n\n# Random Forest 모델 명세\nrf_spec <- \n  rand_forest(trees = 500) |>  \n  set_mode(\"regression\") |> \n  set_engine(\"ranger\")\n```\n\n## 단계 6: Workflow 세트\n\nworkflow()는 전처리, 모델링, 후처리 요청을 함께 묶을 수 있는 객체입니다. 여러 모델과 리샘플링을 사용할 때, workflow 세트를 사용하는 것이 더 편리하다고 발견했어요.\n\n<div class=\"content-ad\"></div>\n\n이제 recipe 객체와 해당하는 모델 사양을 workflow_set()을 사용하여 결합할 것입니다. 기본적으로 cross 파라미터는 TRUE로 설정되어 있어서 각 recipe 객체가 각 모델 사양과 일치하도록 합니다. 이 경우에는 각 recipe 객체가 해당하는 모델 사양과 일치하도록 FALSE로 설정할 것입니다.\n\n```js\nworkflowset_df <- \n  workflow_set(\n    list(recipe_autoarima, recipe_rf),\n    list(auto_arima_spec, rf_spec),\n    cross=FALSE\n  )\n```\n\n이것이 workflow 객체입니다. 현재 결과가 없지만, 교차 검증이 완료되면 결과를 저장하기 위한 자리 표시자가 있습니다.\n\n![그림](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_9.png)\n\n<div class=\"content-ad\"></div>\n\n## 단계 7: 모델 학습 시간입니다\n\n지금까지 새로운 특성을 만들고 데이터를 전처리하고 모델 사양을 만들고 워크플로 세트를 구축했습니다. 이제 훈련 세트 및 리샘플링 폴드를 사용하여 모델을 적합시키겠습니다. 결과를 나중에 분석할 df_results에 결과를 저장할 것입니다.\n\n```js\ndf_results <-\n  workflow_map(\n    workflowset_df,\n    \"fit_resamples\",\n    resamples = df_folds\n  )\n```\n\n이렇게 하면 workflowset_df의 모든 워크플로에 대해 루프를 반복하고 각각에 fit_resamples 함수를 적용하여 df_folds 교차 검증 객체를 사용합니다. 각 실행의 결과는 df_results의 해당 모델 행 아래에 저장됩니다. 결과 열이 이제 교차 검증 결과로 채워졌음을 유의하십시오. 이러한 결과는 필요한 경우 unnest()를 사용하여 추출할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_10.png)\n\n결과는 tidymodels의 정말 멋진 기능인 autoplot() 명령을 사용하여 신속하게 시각화할 수도 있습니다.\n\n```js\nautoplot(df_results)\n```\n\n![image](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_11.png)\n\n\n<div class=\"content-ad\"></div>\n\n모든 리샘플에서 랜덤 포레스트가 ARIMA와 비교했을 때 더 낮은 RMSE(평균 제곱근 오차)와 R-제곱을 보여주고 있습니다.\n\n## 단계 8: 테스트 데이터 적합\n\n이제 df_results의 결과를 순위 매겨 가장 낮은 RMSE를 기준으로 가장 성능이 좋은 모델을 식별하겠습니다. 해당 모델의 ID 및 매개변수를 검색하고 이 최적화된 모델을 훈련 데이터에 맞출 것입니다. 그런 다음, 이 모델을 사용하여 테스트 데이터셋에서 판단하고 새로운 지표를 확인하겠습니다.\n\n```r\n# 최고의 rmse를 가진 workflow의 ID 가져오기\nbest_workflow_id <- df_results %>%\n  rank_results(rank_metric = \"rmse\") %>%\n  head(1) %>%\n  pull(wflow_id)  \n\n## best_workflow_id와 관련된 매개변수 가져오기\nbest_params <- df_results %>%\n  extract_workflow_set_result(id = best_workflow_id) %>%\n  select_best(metric = \"rmse\")  \n\n## best_workflow_id와 관련된 workflow 가져오기\nbest_workflow <- df_results %>%\n  extract_workflow(id = best_workflow_id)  \n\n# 최적화된 매개변수로 workflow 완성\nfinalized_workflow <- finalize_workflow(best_workflow, best_params) \n\nfinalized_workflow\n```\n\n<div class=\"content-ad\"></div>\n\n다음은 최종 워크플로우의 모습입니다:\n\n![image](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_12.png)\n\n이제 이 워크플로우를 사용하여 fit() 및 augment()를 사용하여 테스트 데이터 세트에서 예측하겠습니다. 이 예측을 기반으로 지표를 측정할 것입니다.\n\n```R\npredictions <- finalized_workflow %>%\n  fit(df_train) %>%\n  augment(df_test)  \n\n## 평가 지표 계산\nevaluation_metrics <- metric_set(rmse, mae, rsq)\nresults <- evaluation_metrics(predictions, truth = sales, estimate = .pred) \nprint(results)  \n```\n\n<div class=\"content-ad\"></div>\n\n다음은 최종 지표가 표시되는 모습입니다:\n\n![Final Metrics](/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_13.png)\n\n정말 잘 했어요!\n\n# 성공했어요!\n\n<div class=\"content-ad\"></div>\n\n이 기사를 통해 tidymodels, modeltime 및 timetk가 시계열 회귀 모델을 구축하는 강력한 프레임워크를 제공하는 방법에 대해 명확해졌으면 좋겠고, 여러분이 한 번 시도해볼 것으로 바랍니다! 이 기사는 한 가게와 제품 ID를 위해 만들어 졌지만, 이것은 어떤 가게와 제품 조합에 대해 이를 복제할 수 있는 Shiny 웹 애플리케이션을 구축하기 위한 좋은 사례가 될 수 있습니다. 즐거운 코딩하세요!\n\n# 코드\n\n이 기사의 모든 내용을 다시 만들기 위한 코드는 제 GitHub 저장소에서 찾을 수 있습니다.\n\n마음껏 찾아주세요. LinkedIn에서 저를 찾아보세요.\n\n<div class=\"content-ad\"></div>\n\n글에서 언급되지 않는 한, 모든 이미지는 저자가 찍은 것입니다.","ogImage":{"url":"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_0.png"},"coverImage":"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_0.png","tag":["Tech"],"readingTime":10},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_0.png\" alt=\"Image\"></p>\n<p>시계열 예측 방법은 항상 발전하고 있습니다. ARIMA가 오랫동안 기초를 이루어 왔지만, 머신러닝 모델도 큰 약속을 보여줍니다. 다양한 산업 분야에서 자료를 시간에 따라 더 정확하게 모델링할 수 있는 경우가 있습니다. 이 글에서는 그 중 하나인 매출 예측을 다루어 보겠습니다. 소중한 시간을 아끼기 위해, 바로 본문으로 넘어가겠습니다.</p>\n<h1>코드</h1>\n<p>이 글에서 모든 것을 재현하는 코드는 제 GitHub 저장소에서 찾을 수 있습니다.</p>\n<h1>데이터 세트</h1>\n<p>이 연습에서는 Kaggle에서 Samuel Cortinhas가 공개한 CC0: Public 도메인으로 제공되는 시계열 데이터 연습 데이터 세트를 사용합니다. 이 데이터 세트는 10년(2010년부터 2019년) 동안의 모의 시계열 데이터를 포함하며 날짜, 상점 ID, 제품 ID 및 매출 기능이 포함되어 있습니다. 이 분석에서는 회귀 구성 요소에 초점을 맞추기 위해 단일 상점과 제품을 선택했습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_1.png\" alt=\"\"></p>\n<h1>시계열 분석</h1>\n<h2>단계 0: 설정하기</h2>\n<p>나는 데이터 탐색과 회귀를 위해 다음 패키지들을 사용할 것입니다. 로딩하기 전에 아래 명령어를 사용하여 설치할 수 있습니다: install.packages(\"package_name\").</p>\n<pre><code class=\"hljs language-js\"># 필요한 라이브러리 로딩하기\n<span class=\"hljs-title function_\">library</span>(tidyverse)\n<span class=\"hljs-title function_\">library</span>(lubridate)\n<span class=\"hljs-title function_\">library</span>(tidymodels)\n<span class=\"hljs-title function_\">library</span>(modeltime)\n<span class=\"hljs-title function_\">library</span>(timetk)\n<span class=\"hljs-title function_\">library</span>(viridis)\n</code></pre>\n<h2>Step 1: 날짜 및 해당할 수 있는 모든 것들!!</h2>\n<p>날짜는 제가 가장 좋아하는 변수입니다. 하나의 날짜 열은 많은 정보를 담고 있어요. 이 시나리오에서는 판매와의 관계를 탐색하기 위해 날짜 열에서 새로운 특징들을 만들 거에요. 하지만 먼저, 날짜 열을 문자열로만 사용하는 것보다는 as.Date()를 사용하여 정리할 거에요.</p>\n<pre><code class=\"hljs language-r\">data <span class=\"hljs-operator\">&#x3C;-</span> data <span class=\"hljs-operator\">%>%</span>\n  mutate<span class=\"hljs-punctuation\">(</span>date <span class=\"hljs-operator\">=</span> as.Date<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">,</span> format <span class=\"hljs-operator\">=</span> <span class=\"hljs-string\">\"%m/%d/%Y\"</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">)</span>\n</code></pre>\n<p>다음으로 회귀 분석을 위해 이 날짜 열에서 새로운 특징들을 만들 거에요. Lubridate 패키지는 이 작업을 간단하게 만들어 주는 편리한 함수들로 구성돼 있어요.</p>\n<pre><code class=\"hljs language-r\"><span class=\"hljs-comment\"># 시간과 관련된 요소를 포함하기 위해 데이터 전처리</span>\ndf <span class=\"hljs-operator\">&#x3C;-</span> data <span class=\"hljs-operator\">%>%</span>\n  mutate<span class=\"hljs-punctuation\">(</span>\n    year <span class=\"hljs-operator\">=</span> year<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">,</span>\n    semester <span class=\"hljs-operator\">=</span> factor<span class=\"hljs-punctuation\">(</span>semester<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">,</span>\n    quarter <span class=\"hljs-operator\">=</span> factor<span class=\"hljs-punctuation\">(</span>quarter<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">,</span>\n    day_in_week <span class=\"hljs-operator\">=</span> factor<span class=\"hljs-punctuation\">(</span>wday<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">,</span> label <span class=\"hljs-operator\">=</span> <span class=\"hljs-literal\">TRUE</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">,</span>\n    week_in_year <span class=\"hljs-operator\">=</span> factor<span class=\"hljs-punctuation\">(</span>week<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">,</span>\n    day_in_year <span class=\"hljs-operator\">=</span> factor<span class=\"hljs-punctuation\">(</span>yday<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">,</span>\n    month <span class=\"hljs-operator\">=</span> factor<span class=\"hljs-punctuation\">(</span>month<span class=\"hljs-punctuation\">(</span>date<span class=\"hljs-punctuation\">,</span> label <span class=\"hljs-operator\">=</span> <span class=\"hljs-literal\">TRUE</span><span class=\"hljs-punctuation\">)</span><span class=\"hljs-punctuation\">)</span>\n  <span class=\"hljs-punctuation\">)</span>\n</code></pre>\n<p>이제 데이터가 다음과 같이 보입니다:</p>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_2.png\" alt=\"image\"></p>\n<h2>단계 2: 탐색적 데이터 분석</h2>\n<p>단일 날짜 열에서 생성된 모든 이러한 새로운 흥미로운 기능들과 매출과의 관골을 탐색해 볼 것입니다. 연간 계절성부터 시작하겠습니다.</p>\n<pre><code class=\"hljs language-js\">df %>%\n  <span class=\"hljs-title function_\">ggplot</span>(<span class=\"hljs-title function_\">aes</span>(date, sales)) +\n  <span class=\"hljs-title function_\">geom_line</span>(alpha = <span class=\"hljs-number\">1</span>, size = <span class=\"hljs-number\">1</span>, color = <span class=\"hljs-string\">\"darkblue\"</span>) +  \n  <span class=\"hljs-title function_\">theme_bw</span>() +\n  <span class=\"hljs-title function_\">labs</span>(title = <span class=\"hljs-string\">\"일별 매출 분포 변화\"</span>, x = <span class=\"hljs-string\">\"날짜\"</span>, y = <span class=\"hljs-string\">\"매출\"</span>) +\n  <span class=\"hljs-title function_\">scale_x_date</span>(date_labels = <span class=\"hljs-string\">\"%Y\"</span>, date_breaks = <span class=\"hljs-string\">\"2 years\"</span>) +  \n  <span class=\"hljs-title function_\">scale_y_continuous</span>(labels = <span class=\"hljs-attr\">scales</span>::comma) \n</code></pre>\n<p>매출 데이터에는 명확한 계절성과 특정한 추세가 있습니다. 이제 요일과의 관계를 살펴보겠습니다.</p>\n<pre><code class=\"hljs language-js\">df %>%\n  <span class=\"hljs-title function_\">ggplot</span>(<span class=\"hljs-title function_\">aes</span>(day_in_week, sales, color = day_in_week)) +\n  <span class=\"hljs-title function_\">geom_boxplot</span>() +\n  <span class=\"hljs-title function_\">geom_jitter</span>(alpha = <span class=\"hljs-number\">0.1</span>) +\n  <span class=\"hljs-title function_\">theme_bw</span>() +\n  <span class=\"hljs-title function_\">scale_colour_viridis_d</span>() +\n  <span class=\"hljs-title function_\">labs</span>(title = <span class=\"hljs-string\">\"요일별 일일 매출 분포\"</span>, x = <span class=\"hljs-string\">\"요일\"</span>, y = <span class=\"hljs-string\">\"매출\"</span>) +\n  <span class=\"hljs-title function_\">scale_x_discrete</span>() +\n  <span class=\"hljs-title function_\">scale_y_continuous</span>(labels = <span class=\"hljs-attr\">scales</span>::comma)\n</code></pre>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_4.png\" alt=\"Image\"></p>\n<p>이제 월별 분포를 살펴보겠습니다.</p>\n<pre><code class=\"hljs language-js\">df |> \n  <span class=\"hljs-title function_\">ggplot</span>(<span class=\"hljs-title function_\">aes</span>(month, sales)) +\n  <span class=\"hljs-title function_\">geom_violin</span>(color = <span class=\"hljs-string\">\"darkgreen\"</span>) +  \n  <span class=\"hljs-title function_\">geom_jitter</span>(alpha = <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-title function_\">aes</span>(color = sales)) +  \n  <span class=\"hljs-title function_\">theme_light</span>() +\n  <span class=\"hljs-title function_\">geom_smooth</span>(method = <span class=\"hljs-string\">\"loess\"</span>, se = <span class=\"hljs-variable constant_\">FALSE</span>) +  \n  <span class=\"hljs-title function_\">scale_colour_viridis_c</span>() +\n  <span class=\"hljs-title function_\">labs</span>(title = <span class=\"hljs-string\">\"Daily Sales Distribution by Month\"</span>, x = <span class=\"hljs-string\">\"\"</span>, y = <span class=\"hljs-string\">\"Sales\"</span>, color= <span class=\"hljs-string\">\"Sales\"</span>)\n</code></pre>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_5.png\" alt=\"Image\"></p>\n<p>이제 모델링으로 넘어가겠습니다.</p>\n<h2>단계 3: 데이터 분할 및 교차 검증 설정</h2>\n<p>tidymodels에서 제공하는 initial_time_split() 함수를 사용하여 데이터를 학습 및 테스트 세트로 나누겠습니다.</p>\n<pre><code class=\"hljs language-R\">df_split <span class=\"hljs-operator\">&#x3C;-</span> df <span class=\"hljs-operator\">|></span> \n  initial_time_split<span class=\"hljs-punctuation\">(</span>prop<span class=\"hljs-operator\">=</span><span class=\"hljs-number\">0.9</span><span class=\"hljs-punctuation\">)</span>  <span class=\"hljs-comment\"># 90% 데이터를 학습에, 10%를 테스트에 할당</span>\n\ndf_train <span class=\"hljs-operator\">&#x3C;-</span> training<span class=\"hljs-punctuation\">(</span>df_split<span class=\"hljs-punctuation\">)</span>\ndf_test <span class=\"hljs-operator\">&#x3C;-</span> testing<span class=\"hljs-punctuation\">(</span>df_split<span class=\"hljs-punctuation\">)</span>\n</code></pre>\n<p>이것이 분할의 모습입니다:</p>\n<p>교차 검증은 입력 데이터의 하위 집합에서 모델을 학습시키고 나머지 데이터에서 평가하여 모델을 평가하는 데 사용할 수 있습니다. 일반적인 교차 검증 방법은 데이터 포인트를 무작위로 선택하여 학습 데이터 집합에 할당합니다. 그러나 이 방법은 데이터가 순차적이어야하기 때문에 시계열에 적합하지 않습니다. Timetk 패키지에는 시계열 데이터 세트에 대한 교차 검증 폴드를 특별히 생성하고 해당 분할을 시각화하는 데 사용할 수있는 멋진 함수인 time_series_cv()가 있습니다.</p>\n<pre><code class=\"hljs language-R\"><span class=\"hljs-comment\"># 교차 검증 분할 생성</span>\ndf_folds <span class=\"hljs-operator\">&#x3C;-</span> \n  time_series_cv<span class=\"hljs-punctuation\">(</span>\n    df_train<span class=\"hljs-punctuation\">,</span> \n    initial <span class=\"hljs-operator\">=</span> <span class=\"hljs-string\">\"3 years\"</span><span class=\"hljs-punctuation\">,</span> \n    assess <span class=\"hljs-operator\">=</span> <span class=\"hljs-string\">\"1 year\"</span><span class=\"hljs-punctuation\">,</span> \n    skip <span class=\"hljs-operator\">=</span> <span class=\"hljs-string\">\"6 months\"</span><span class=\"hljs-punctuation\">,</span>\n    slice_limit <span class=\"hljs-operator\">=</span> <span class=\"hljs-number\">5</span><span class=\"hljs-punctuation\">)</span>  \n\n<span class=\"hljs-comment\"># 분할 시각화</span>\nplot_time_series_cv_plan<span class=\"hljs-punctuation\">(</span>df_folds<span class=\"hljs-punctuation\">,</span> date<span class=\"hljs-punctuation\">,</span> sales<span class=\"hljs-punctuation\">)</span>\n</code></pre>\n<h2>단계 4: 모델링을 위한 데이터 준비</h2>\n<p>레시피는 새로운 예측 변수를 만들고 모델에서 필요한 몇 가지 전처리를 수행할 수 있는 객체입니다. 저는 auto ARIMA 및 랜덤 포레스트 두 모델을 시도하고 싶기 때문에 두 레시피 객체를 만들 것입니다. 레시피()의 첫 번째 단계는 회귀 분석을 위한 공식입니다.</p>\n<pre><code class=\"hljs language-js\">recipe_autoarima &#x3C;- \n  <span class=\"hljs-title function_\">recipe</span>(sales ~ date,\n         data = df_train)\n</code></pre>\n<p>두 번째 랜덤 포레스트 레시피에는 step_holiday()를 사용하여 date 데이터를 공휴일에 대한 하나 이상의 이진 지표 변수로 변환하는 기능을 추가할 것입니다. 또한 step_rm()을 사용하여 date 열을 제거하고 step_dummy()를 사용하여 모든 명목 예측 변수를 더미 변수로 변환할 것입니다.</p>\n<pre><code class=\"hljs language-js\">recipe_rf &#x3C;- \n  <span class=\"hljs-title function_\">recipe</span>(sales ~ ., data = df_train) |>\n  <span class=\"hljs-title function_\">step_holiday</span>(date, holidays = <span class=\"hljs-attr\">timeDate</span>::<span class=\"hljs-title function_\">listHolidays</span>(<span class=\"hljs-string\">\"US\"</span>)) |>  \n  <span class=\"hljs-title function_\">step_rm</span>(date) |>  \n  <span class=\"hljs-title function_\">step_dummy</span>(<span class=\"hljs-title function_\">all_nominal_predictors</span>())\n</code></pre>\n<p>다음은 recipe 객체가 보이는 모습입니다:</p>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_8.png\" alt=\"Recipe Object\"></p>\n<p>레시피 객체는 학습 및 테스트 데이터셋에서 반복 가능한 단계 시퀀스를 만들어주어 긴 피처 엔지니어링 코드를 작성하지 않고도 사용할 수 있습니다. 저는 이를 피처 엔지니어링의 단축키로 생각해요!</p>\n<p>아래 명령은 레시피 객체가 데이터셋을 업데이트하고 새로 생성된 열을 이해하는 데 사용될 수 있습니다.</p>\n<pre><code class=\"hljs language-js\">recipe_rf |> <span class=\"hljs-title function_\">prep</span>() |> <span class=\"hljs-title function_\">bake</span>(new_data = <span class=\"hljs-variable constant_\">NULL</span>)\n</code></pre>\n<h2>단계 5: 모델 사양 및 재표본화</h2>\n<p>레시피를 만들면, 각각의 두 모델에 대한 명세서를 작성할 것입니다. ARIMA에 Modeltime을 사용하고 랜덤 포레스트에는 Tidymodels를 사용할 예정이에요. 이것들은 일관된 단계적 흐름으로 여러 모델에 대한 명세를 만드는 훌륭한 방법을 제공합니다.</p>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title class_\">Auto</span> <span class=\"hljs-variable constant_\">ARIMA</span> 모델 명세\nauto_arima_spec &#x3C;- <span class=\"hljs-title function_\">arima_boost</span>() |> \n  <span class=\"hljs-title function_\">set_mode</span>(<span class=\"hljs-string\">\"regression\"</span>) |> \n  <span class=\"hljs-title function_\">set_engine</span>(<span class=\"hljs-string\">'auto_arima_xgboost'</span>)\n\n# <span class=\"hljs-title class_\">Random</span> <span class=\"hljs-title class_\">Forest</span> 모델 명세\nrf_spec &#x3C;- \n  <span class=\"hljs-title function_\">rand_forest</span>(trees = <span class=\"hljs-number\">500</span>) |>  \n  <span class=\"hljs-title function_\">set_mode</span>(<span class=\"hljs-string\">\"regression\"</span>) |> \n  <span class=\"hljs-title function_\">set_engine</span>(<span class=\"hljs-string\">\"ranger\"</span>)\n</code></pre>\n<h2>단계 6: Workflow 세트</h2>\n<p>workflow()는 전처리, 모델링, 후처리 요청을 함께 묶을 수 있는 객체입니다. 여러 모델과 리샘플링을 사용할 때, workflow 세트를 사용하는 것이 더 편리하다고 발견했어요.</p>\n<p>이제 recipe 객체와 해당하는 모델 사양을 workflow_set()을 사용하여 결합할 것입니다. 기본적으로 cross 파라미터는 TRUE로 설정되어 있어서 각 recipe 객체가 각 모델 사양과 일치하도록 합니다. 이 경우에는 각 recipe 객체가 해당하는 모델 사양과 일치하도록 FALSE로 설정할 것입니다.</p>\n<pre><code class=\"hljs language-js\">workflowset_df &#x3C;- \n  <span class=\"hljs-title function_\">workflow_set</span>(\n    <span class=\"hljs-title function_\">list</span>(recipe_autoarima, recipe_rf),\n    <span class=\"hljs-title function_\">list</span>(auto_arima_spec, rf_spec),\n    cross=<span class=\"hljs-variable constant_\">FALSE</span>\n  )\n</code></pre>\n<p>이것이 workflow 객체입니다. 현재 결과가 없지만, 교차 검증이 완료되면 결과를 저장하기 위한 자리 표시자가 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_9.png\" alt=\"그림\"></p>\n<h2>단계 7: 모델 학습 시간입니다</h2>\n<p>지금까지 새로운 특성을 만들고 데이터를 전처리하고 모델 사양을 만들고 워크플로 세트를 구축했습니다. 이제 훈련 세트 및 리샘플링 폴드를 사용하여 모델을 적합시키겠습니다. 결과를 나중에 분석할 df_results에 결과를 저장할 것입니다.</p>\n<pre><code class=\"hljs language-js\">df_results &#x3C;-\n  <span class=\"hljs-title function_\">workflow_map</span>(\n    workflowset_df,\n    <span class=\"hljs-string\">\"fit_resamples\"</span>,\n    resamples = df_folds\n  )\n</code></pre>\n<p>이렇게 하면 workflowset_df의 모든 워크플로에 대해 루프를 반복하고 각각에 fit_resamples 함수를 적용하여 df_folds 교차 검증 객체를 사용합니다. 각 실행의 결과는 df_results의 해당 모델 행 아래에 저장됩니다. 결과 열이 이제 교차 검증 결과로 채워졌음을 유의하십시오. 이러한 결과는 필요한 경우 unnest()를 사용하여 추출할 수 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_10.png\" alt=\"image\"></p>\n<p>결과는 tidymodels의 정말 멋진 기능인 autoplot() 명령을 사용하여 신속하게 시각화할 수도 있습니다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-title function_\">autoplot</span>(df_results)\n</code></pre>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_11.png\" alt=\"image\"></p>\n<p>모든 리샘플에서 랜덤 포레스트가 ARIMA와 비교했을 때 더 낮은 RMSE(평균 제곱근 오차)와 R-제곱을 보여주고 있습니다.</p>\n<h2>단계 8: 테스트 데이터 적합</h2>\n<p>이제 df_results의 결과를 순위 매겨 가장 낮은 RMSE를 기준으로 가장 성능이 좋은 모델을 식별하겠습니다. 해당 모델의 ID 및 매개변수를 검색하고 이 최적화된 모델을 훈련 데이터에 맞출 것입니다. 그런 다음, 이 모델을 사용하여 테스트 데이터셋에서 판단하고 새로운 지표를 확인하겠습니다.</p>\n<pre><code class=\"hljs language-r\"><span class=\"hljs-comment\"># 최고의 rmse를 가진 workflow의 ID 가져오기</span>\nbest_workflow_id <span class=\"hljs-operator\">&#x3C;-</span> df_results <span class=\"hljs-operator\">%>%</span>\n  rank_results<span class=\"hljs-punctuation\">(</span>rank_metric <span class=\"hljs-operator\">=</span> <span class=\"hljs-string\">\"rmse\"</span><span class=\"hljs-punctuation\">)</span> <span class=\"hljs-operator\">%>%</span>\n  head<span class=\"hljs-punctuation\">(</span><span class=\"hljs-number\">1</span><span class=\"hljs-punctuation\">)</span> <span class=\"hljs-operator\">%>%</span>\n  pull<span class=\"hljs-punctuation\">(</span>wflow_id<span class=\"hljs-punctuation\">)</span>  \n\n<span class=\"hljs-comment\">## best_workflow_id와 관련된 매개변수 가져오기</span>\nbest_params <span class=\"hljs-operator\">&#x3C;-</span> df_results <span class=\"hljs-operator\">%>%</span>\n  extract_workflow_set_result<span class=\"hljs-punctuation\">(</span>id <span class=\"hljs-operator\">=</span> best_workflow_id<span class=\"hljs-punctuation\">)</span> <span class=\"hljs-operator\">%>%</span>\n  select_best<span class=\"hljs-punctuation\">(</span>metric <span class=\"hljs-operator\">=</span> <span class=\"hljs-string\">\"rmse\"</span><span class=\"hljs-punctuation\">)</span>  \n\n<span class=\"hljs-comment\">## best_workflow_id와 관련된 workflow 가져오기</span>\nbest_workflow <span class=\"hljs-operator\">&#x3C;-</span> df_results <span class=\"hljs-operator\">%>%</span>\n  extract_workflow<span class=\"hljs-punctuation\">(</span>id <span class=\"hljs-operator\">=</span> best_workflow_id<span class=\"hljs-punctuation\">)</span>  \n\n<span class=\"hljs-comment\"># 최적화된 매개변수로 workflow 완성</span>\nfinalized_workflow <span class=\"hljs-operator\">&#x3C;-</span> finalize_workflow<span class=\"hljs-punctuation\">(</span>best_workflow<span class=\"hljs-punctuation\">,</span> best_params<span class=\"hljs-punctuation\">)</span> \n\nfinalized_workflow\n</code></pre>\n<p>다음은 최종 워크플로우의 모습입니다:</p>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_12.png\" alt=\"image\"></p>\n<p>이제 이 워크플로우를 사용하여 fit() 및 augment()를 사용하여 테스트 데이터 세트에서 예측하겠습니다. 이 예측을 기반으로 지표를 측정할 것입니다.</p>\n<pre><code class=\"hljs language-R\">predictions <span class=\"hljs-operator\">&#x3C;-</span> finalized_workflow <span class=\"hljs-operator\">%>%</span>\n  fit<span class=\"hljs-punctuation\">(</span>df_train<span class=\"hljs-punctuation\">)</span> <span class=\"hljs-operator\">%>%</span>\n  augment<span class=\"hljs-punctuation\">(</span>df_test<span class=\"hljs-punctuation\">)</span>  \n\n<span class=\"hljs-comment\">## 평가 지표 계산</span>\nevaluation_metrics <span class=\"hljs-operator\">&#x3C;-</span> metric_set<span class=\"hljs-punctuation\">(</span>rmse<span class=\"hljs-punctuation\">,</span> mae<span class=\"hljs-punctuation\">,</span> rsq<span class=\"hljs-punctuation\">)</span>\nresults <span class=\"hljs-operator\">&#x3C;-</span> evaluation_metrics<span class=\"hljs-punctuation\">(</span>predictions<span class=\"hljs-punctuation\">,</span> truth <span class=\"hljs-operator\">=</span> sales<span class=\"hljs-punctuation\">,</span> estimate <span class=\"hljs-operator\">=</span> .pred<span class=\"hljs-punctuation\">)</span> \nprint<span class=\"hljs-punctuation\">(</span>results<span class=\"hljs-punctuation\">)</span>  \n</code></pre>\n<p>다음은 최종 지표가 표시되는 모습입니다:</p>\n<p><img src=\"/assets/img/2024-06-19-TimeSeriesRegressionandCross-ValidationATidyApproach_13.png\" alt=\"Final Metrics\"></p>\n<p>정말 잘 했어요!</p>\n<h1>성공했어요!</h1>\n<p>이 기사를 통해 tidymodels, modeltime 및 timetk가 시계열 회귀 모델을 구축하는 강력한 프레임워크를 제공하는 방법에 대해 명확해졌으면 좋겠고, 여러분이 한 번 시도해볼 것으로 바랍니다! 이 기사는 한 가게와 제품 ID를 위해 만들어 졌지만, 이것은 어떤 가게와 제품 조합에 대해 이를 복제할 수 있는 Shiny 웹 애플리케이션을 구축하기 위한 좋은 사례가 될 수 있습니다. 즐거운 코딩하세요!</p>\n<h1>코드</h1>\n<p>이 기사의 모든 내용을 다시 만들기 위한 코드는 제 GitHub 저장소에서 찾을 수 있습니다.</p>\n<p>마음껏 찾아주세요. LinkedIn에서 저를 찾아보세요.</p>\n<p>글에서 언급되지 않는 한, 모든 이미지는 저자가 찍은 것입니다.</p>\n</body>\n</html>\n"},"__N_SSG":true}