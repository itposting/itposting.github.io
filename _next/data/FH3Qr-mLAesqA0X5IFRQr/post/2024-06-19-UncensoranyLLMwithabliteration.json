{"pageProps":{"post":{"title":"ì–µì œëœ ëª¨ë“  LLMì„ í•´ì œí•˜ì„¸ìš”","description":"","date":"2024-06-19 03:36","slug":"2024-06-19-UncensoranyLLMwithabliteration","content":"\n\n## ì¬í•™ìŠµ ì—†ì´ ì„¸ë°€ ì¡°ì •í•˜ê¸°\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-UncensoranyLLMwithabliteration_0.png)\n\nëŒë§ˆ ëª¨ë¸ì˜ ì„¸ëŒ€ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ìì˜ ì§€ì‹œë¥¼ ì´í•´í•˜ê³  ë”°ë¥´ëŠ” ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ 'ì„¸ì„¸í•œ ì¡°ì •(ì„¸ì„¸í•˜ê²Œ ì¡°ì •)' ë²„ì „ì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ë§¤ìš° ê²€ì—´ë˜ì–´ ìˆìœ¼ë©° í•´ë¡œìš´ ìš”ì²­ìœ¼ë¡œ ê°„ì£¼ë˜ëŠ” ê²ƒì€ ê±°ë¶€í•˜ê³  \"AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ë„ì™€ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"ì™€ ê°™ì€ ëŒ€ë‹µì„ í•©ë‹ˆë‹¤. ì´ ì•ˆì „ ê¸°ëŠ¥ì€ ì˜¤ìš©ì„ ë°©ì§€í•˜ëŠ” ë° ì¤‘ìš”í•˜ì§€ë§Œ, ëª¨ë¸ì˜ ìœ ì—°ì„±ê³¼ ë°˜ì‘ì„±ì„ ì œí•œí•©ë‹ˆë‹¤.\n\në³¸ ë¬¸ì„œì—ì„œëŠ” \"ë¬´íš¨í™”\"ë¼ëŠ” ê¸°ìˆ ì„ íƒêµ¬í•˜ì—¬ ì¬í•™ìŠµ ì—†ì´ ì–´ë–¤ ëŒë§ˆ ëª¨ë¸ì´ë“  ê²€ì—´ì„ í‘¸ëŠ” ë°©ë²•ì„ ì‚´í´ë³¼ ê²ƒì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ëª¨ë¸ì— ë‚´ì¥ëœ ê±°ë¶€ ë©”ì»¤ë‹ˆì¦˜ì„ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•˜ì—¬ ëª¨ë“  ìœ í˜•ì˜ í”„ë¡¬í”„íŠ¸ì— ëŒ€ì‘í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nì½”ë“œëŠ” Google Colabì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , LLM ì½”ìŠ¤ì—ì„œë„ GitHubì— ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ì‚¬ë¥¼ êµì •í•´ ì£¼ì‹  FailSpyë‹˜ì—ê²Œ íŠ¹ë³„íˆ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.\n\n# âœ‚ï¸ ì‚­ì œë€ì´ë€?\n\ní˜„ëŒ€ LLMì€ ì•ˆì „ ë° ì§€ì‹œë¥¼ ë”°ë¥´ëŠ” ë°©í–¥ìœ¼ë¡œ ì„¸ë°€í•˜ê²Œ ì¡°ì •ë˜ì–´ ìˆì–´, í•´ë¡œìš´ ìš”ì²­ì„ ê±°ë¶€í•˜ê¸° ìœ„í•´ í›ˆë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Arditi ë“±ì´ ë¸”ë¡œê·¸ ê¸€ì—ì„œ ì„¤ëª…í•œ ë°”ì— ë”°ë¥´ë©´, ì´ ê±°ë¶€ í–‰ë™ì€ ëª¨ë¸ì˜ ì”ë¥˜ ìŠ¤íŠ¸ë¦¼ì— ìˆëŠ” íŠ¹ì • ë°©í–¥ì„ í†µí•´ ì¤‘ì¬ë©ë‹ˆë‹¤. ë§Œì•½ ì´ ë°©í–¥ì„ ëª¨ë¸ì´ ë‚˜íƒ€ë‚´ì§€ ëª»í•˜ë„ë¡ ë§‰ëŠ”ë‹¤ë©´, ìš”ì²­ì„ ê±°ë¶€í•˜ëŠ” ëŠ¥ë ¥ì„ ìƒê²Œ ë©ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ì´ ë°©í–¥ì„ ì¸ìœ„ì ìœ¼ë¡œ ì¶”ê°€í•˜ë©´ ëª¨ë¸ì´ í•´ê°€ ì—†ëŠ” ìš”ì²­ì¡°ì°¨ë„ ê±°ë¶€í•  ìˆ˜ ìˆê²Œë©ë‹ˆë‹¤.\n\nì „í†µì ì¸ ë””ì½”ë” ì „ìš© Llamaë¥˜ ì•„í‚¤í…ì²˜ì—ì„œëŠ” ì„¸ ê°€ì§€ì˜ ì”ë¥˜ ìŠ¤íŠ¸ë¦¼ì„ ëŒ€ìƒìœ¼ë¡œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: ê° ë¸”ë¡ì˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ(â€œpreâ€), ì–´í…ì…˜ê³¼ MLP ë ˆì´ì–´ ì‚¬ì´ì—ì„œ(â€œmidâ€), ê·¸ë¦¬ê³  MLP ì´í›„ì—(â€œpostâ€). ë‹¤ìŒ ê·¸ë¦¼ì€ ê° ì”ë¥˜ ìŠ¤íŠ¸ë¦¼ì˜ ìœ„ì¹˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-UncensoranyLLMwithabliteration_1.png\" />\n\nLLMì„ ë¬´ì¦ê²€ ìƒíƒœë¡œ ë§Œë“¤ê¸° ìœ„í•´ ë¨¼ì € ëª¨ë¸ ë‚´ì˜ \"ê±°ë¶€ ë°©í–¥\"ì„ ì‹ë³„í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ëŠ” ëª‡ ê°€ì§€ ê¸°ìˆ ì  ë‹¨ê³„ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n\n- ë°ì´í„° ìˆ˜ì§‘: ìœ í•´í•œ ì§€ì‹œë¬¸ ì§‘í•©ê³¼ ë¬´í•´í•œ ì§€ì‹œë¬¸ ì§‘í•©ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì‹¤í–‰í•˜ê³ , ê°ê°ì˜ ë§ˆì§€ë§‰ í† í° ìœ„ì¹˜ì—ì„œ ì”ì—¬ ìŠ¤íŠ¸ë¦¼ í™œì„±í™”ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.\n- í‰ê·  ì°¨ì´: ìœ í•´í•œ ì§€ì‹œì™€ ë¬´í•´í•œ ì§€ì‹œì˜ í™œì„±í™” ê°„ í‰ê·  ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ê° ë ˆì´ì–´ì— ëŒ€í•œ \"ê±°ë¶€ ë°©í–¥\"ì„ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n- ì„ íƒ: ì´ëŸ¬í•œ ë²¡í„°ë¥¼ ì •ê·œí™”í•˜ê³ , í‰ê°€í•˜ì—¬ ë‹¨ì¼ ìµœìƒì˜ \"ê±°ë¶€ ë°©í–¥\"ì„ ì„ íƒí•©ë‹ˆë‹¤.\n\nê±°ë¶€ ë°©í–¥ì„ ì‹ë³„í•œ í›„, í•´ë‹¹ ê¸°ëŠ¥ì„ í‘œí˜„í•˜ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•˜ëŠ” \"ì œê±°(ablate)\" ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¶”ë¡  ì‹œê°„ ê°„ì„­ì´ë‚˜ ê°€ì¤‘ì¹˜ ì§êµí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜êµ¬ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\në¨¼ì € ì¶”ë¡  ì‹œê°„ ê°œì…ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì”ì°¨ ìŠ¤íŠ¸ë¦¼ì— ê¸°ë¡í•˜ëŠ” ëª¨ë“  êµ¬ì„± ìš”ì†Œ(ì˜ˆ: ì–´í…ì…˜ í—¤ë“œ)ë§ˆë‹¤ ê·¸ ì¶œë ¥ì„ ê±°ë¶€ ë°©í–¥ìœ¼ë¡œ íˆ¬ì˜í•œ í›„ ì´ íˆ¬ì˜ì„ ëºë‹ˆë‹¤. ì´ ëº„ì…ˆì€ ê° í† í°ê³¼ ê° ë ˆì´ì–´ì— ì ìš©ë˜ì–´ ëª¨ë¸ì´ ê²°ì½” ê±°ë¶€ ë°©í–¥ì„ í‘œí˜„í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n\ní•œí¸, ê°€ì¤‘ì¹˜ ì§êµí™”ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ê±°ë¶€ ë°©í–¥ì— ëŒ€í•´ êµ¬ì„± ìš”ì†Œ ê°€ì¤‘ì¹˜ë¥¼ ì§êµí™”í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì´ ì´ ë°©í–¥ìœ¼ë¡œ ê¸°ë¡í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. ì”ì°¨ ìŠ¤íŠ¸ë¦¼ì— ê¸°ë¡í•˜ëŠ” í–‰ë ¬ì„ ì¡°ì •í•˜ì—¬ ì´ëŸ¬í•œ ê¸°ì—¬ê°€ ê±°ë¶€ ë°©í–¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n\në‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” ê°€ì¤‘ì¹˜ ì§êµí™”ë¥¼ ì‚¬ìš©í•œ ì¢Œì ˆ ì‹¤í˜„ì„ êµ¬í˜„í•  ê²ƒì…ë‹ˆë‹¤.\n\n# ğŸ’» êµ¬í˜„\n\n<div class=\"content-ad\"></div>\n\nì•„ë˜ì˜ abliteration êµ¬í˜„ì€ FailSpyì˜ ë…¸íŠ¸ë¶ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ ë…¸íŠ¸ë¶ì€ ì›ë˜ ì €ìë“¤ì˜ ë…¸íŠ¸ë¶ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì €ëŠ” ì£¼ë¡œ ì´ë¥¼ ì ì‘í•˜ì—¬ ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰½ë„ë¡ í–ˆìŠµë‹ˆë‹¤. ì´ ì„¹ì…˜ì€ ì½”ë“œê°€ ë§ì´ í¬í•¨ë˜ì–´ ìˆì–´ì„œ ë¬´ìŠ¨ ì¼ì´ ë²Œì–´ì§€ëŠ”ì§€ ë³¼ ìˆ˜ ìˆì§€ë§Œ, ê¸°ìˆ ì ì¸ ì„¸ë¶€ ì‚¬í•­ì— ëœ ê´€ì‹¬ì´ ìˆëŠ” ê²½ìš° FailSpyì˜ abliterator ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (Hugging Faceì˜ abliterated ëª¨ë¸ ëª¨ìŒë„ í™•ì¸í•´ë³´ì„¸ìš”).\n\nì´ ì½”ë“œëŠ” ë›°ì–´ë‚œ TransformerLens ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì´ì „ì—ëŠ” EasyTransformerë¡œ ì•Œë ¤ì¡ŒìŒ)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬´ê±°ìš´ ì‘ì—…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë©”ì»¤ë‹ˆì¦˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©° ì—¬ê¸°ì„œëŠ” í™œì„±í™”ì— ê°œì…í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë§Œë“  Neel Nandaì™€ Joseph Bloomì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.\n\në¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ê°€ì ¸ì™€ ë´…ì‹œë‹¤. ì´ëŸ¬í•œ ëª¨ë“  ë‹¨ê³„ëŠ” Google Colab ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n```js\n!pip install transformers transformers_stream_generator tiktoken transformer_lens einops jaxtyping\n\nimport torch\nimport functools\nimport einops\nimport gc\n\nfrom datasets import load_dataset\nfrom tqdm import tqdm\nfrom torch import Tensor\nfrom typing import List\nfrom transformer_lens import HookedTransformer, utils\nfrom transformer_lens.hook_points import HookPoint\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom jaxtyping import Float, Int\nfrom collections import defaultdict\n\n# GPU ë©”ëª¨ë¦¬ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ ìë™ ë¯¸ë¶„ì„ ë•ë‹ˆë‹¤ (í¬ë ˆë”§: Undi95)\ntorch.set_grad_enabled(False)\n```\n\n<div class=\"content-ad\"></div>\n\në‘ ê°€ì§€ ë°ì´í„° ì„¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤: í”¼í•´ê°€ ì—†ëŠ” ì§€ì¹¨ì„ í¬í•¨í•œ í•˜ë‚˜ì™€ ìœ í•´í•œ ì§€ì¹¨ì„ í¬í•¨í•œ í•˜ë‚˜ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” tatsu-lab/alpacaì™€ llm-attacksì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ëª¨ë“  ê²ƒì„ ë” ì‰½ê²Œ ë§Œë“¤ê¸° ìœ„í•´, ì €ëŠ” ì´ë¥¼ ë‘ ê°œì˜ Hugging Face ë°ì´í„° ì„¸íŠ¸ë¡œ ë‹¤ì‹œ íŒ¨í‚¤ì§•í•˜ì—¬ mlabonne/harmless_alpacaì™€ mlabonne/harmful_behaviorsë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê²Œ í•˜ë©´ ì—¬ëŸ¬ë¶„ì´ ì‰½ê²Œ ì—¬ëŸ¬ë¶„ ìì‹ ì˜ ë°ì´í„° ì„¸íŠ¸ë¡œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì§€ì¹¨ì„ë¡œë“œí•˜ê³  \"role\"ê³¼ \"content\" í‚¤ê°€ ìˆëŠ” ì‚¬ì „ ëª©ë¡ìœ¼ë¡œ ë‹¤ì‹œ ì„œì‹í™”í•  ê²ƒì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ Llama 3ì˜ ì±„íŒ… í…œí”Œë¦¿ì„ ë”°ë¥´ëŠ” apply_chat_tokenizer() ë©”ì„œë“œì™€ í˜¸í™˜ë©ë‹ˆë‹¤.\n\n```python\ndef reformat_texts(texts):\n    return [[{\"role\": \"user\", \"content\": text}] for text in texts]\n\n# ìœ í•´í•˜ê³  ë¬´í•´í•œ ë°ì´í„° ì„¸íŠ¸ ê°€ì ¸ì˜¤ê¸°\ndef get_harmful_instructions():\n    dataset = load_dataset('mlabonne/harmful_behaviors')\n    return reformat_texts(dataset['train']['text']), reformat_texts(dataset['test']['text'])\n\ndef get_harmless_instructions():\n    dataset = load_dataset('mlabonne/harmless_alpaca')\n    return reformat_texts(dataset['train']['text']), reformat_texts(dataset['test']['text'])\n\nharmful_inst_train, harmful_inst_test = get_harmful_instructions()\nharmless_inst_train, harmless_inst_test = get_harmless_instructions()\n```\n\nì´ì œ ë°ì´í„° ì„¸íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìœ¼ë¯€ë¡œ, abliterate í•˜ë ¤ëŠ” ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ˆíƒ€ê¹ê²Œë„, HookedTransformerë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ, FailSpyì˜ ë…¸íŠ¸ë¶ì— ì„¤ëª…ëœ ê¼¼ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  meta-llama/Meta-Llama-3-8B-Instructë¡œ ì´ë¦„ì„ ë³€ê²½í•˜ê² ìŠµë‹ˆë‹¤. GPUê°€ BF16ê³¼ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ê²½ìš° torch.float16 í˜•ì‹ìœ¼ë¡œ ë¡œë“œí•˜ì„¸ìš”.\n\n<div class=\"content-ad\"></div>\n\nì´ ì˜ˆì‹œì—ì„œëŠ” DARE TIES(ëª¨ë¸ ë³‘í•©ì— ê´€í•œ ë‚´ ê¸°ì‚¬ ì°¸ì¡°)ë¡œ ë§Œë“¤ì–´ì§„ mlabonne/Daredevil-8Bë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 8B ì¹´í…Œê³ ë¦¬ì˜ Open LLM Leaderboardì—ì„œ ê°€ì¥ ë†’ì€ MMLU ì ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆì–´ìš”.\n\n```js\nMODEL_ID = \"mlabonne/Daredevil-8B\"\nMODEL_TYPE = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n\n# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n!git clone https://huggingface.co/{MODEL_ID} {MODEL_TYPE}\n\n# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\nmodel = HookedTransformer.from_pretrained_no_processing(\n    MODEL_TYPE,\n    local_files_only=True,\n    dtype=torch.bfloat16,\n    default_padding_side='left'\n)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_TYPE)\ntokenizer.padding_side = 'left'\ntokenizer.pad_token = tokenizer.eos_token\n```\n\nì´ì œ ë°ì´í„°ì…‹ì„ í† í°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´í•´í•œ ë° ìœ í•´í•œ ì§€ì‹œì‚¬í•­ì— ëŒ€í•´ ë™ì¼í•œ ìƒ˜í”Œ ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ìƒ˜í”Œ ìˆ˜ê°€ ë†’ìœ¼ë©´ ëª¨ë“  RAM/VRAMì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” 256ìœ¼ë¡œ ì œí•œí•©ë‹ˆë‹¤.\n\n```js\ndef tokenize_instructions(tokenizer, instructions):\n    return tokenizer.apply_chat_template(\n        instructions,\n        padding=True,\n        truncation=False,\n        return_tensors=\"pt\",\n        return_dict=True,\n        add_generation_prompt=True,\n    ).input_ids\n\nn_inst_train = min(256, len(harmful_inst_train), len(harmless_inst_train))\n\n# ë°ì´í„°ì…‹ í† í°í™”\nharmful_tokens = tokenize_instructions(\n    tokenizer,\n    instructions=harmful_inst_train[:n_inst_train],\n)\nharmless_tokens = tokenize_instructions(\n    tokenizer,\n    instructions=harmless_inst_train[:n_inst_train],\n)\n```\n\n<div class=\"content-ad\"></div>\n\nì‘ì—…ì´ ëª¨ë‘ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ë„ì²˜ëŸ¼ ì²˜ë¦¬í•˜ëŠ” ì²« ë²ˆì§¸ ë‹¨ê³„ì¸ ë°ì´í„° ìˆ˜ì§‘ì„ êµ¬í˜„í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ í† í°í™”ëœ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ê³  ìœ í•´(harmful) ë° ë¬´í•´(harmless)ë¡œ ë‚˜ë¨¸ì§€ ìŠ¤íŠ¸ë¦¼ í™œì„±í™”ë¥¼ ì €ì¥í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì´ëŠ” transformer_lens ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.\n\n```js\nbatch_size = 32\n\n# í™œì„±í™”ë¥¼ ì €ì¥í•  ê¸°ë³¸ ì‚¬ì „ ì´ˆê¸°í™”\nharmful = defaultdict(list)\nharmless = defaultdict(list)\n\n# ë°ì´í„° í•™ìŠµì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\nnum_batches = (n_inst_train + batch_size - 1) // batch_size\n\nfor i in tqdm(range(num_batches)):\n    print(i)\n    start_idx = i * batch_size\n    end_idx = min(n_inst_train, start_idx + batch_size)\n\n    # ìœ í•´ ë° ë¬´í•´ í”„ë¡¬í”„íŠ¸ì— ëª¨ë¸ ì‹¤í–‰ ë° í™œì„±í™” ìºì‹œ\n    harmful_logits, harmful_cache = model.run_with_cache(\n        harmful_tokens[start_idx:end_idx],\n        names_filter=lambda hook_name: 'resid' in hook_name,\n        device='cpu',\n        reset_hooks_end=True\n    )\n    harmless_logits, harmless_cache = model.run_with_cache(\n        harmless_tokens[start_idx:end_idx],\n        names_filter=lambda hook_name: 'resid' in hook_name,\n        device='cpu',\n        reset_hooks_end=True\n    )\n\n    # í™œì„±í™” ìˆ˜ì§‘ ë° ì €ì¥\n    for key in harmful_cache:\n        harmful[key].append(harmful_cache[key])\n        harmless[key].append(harmless_cache[key])\n\n    # RAM ë° VRAM ë¹„ìš°ê¸°\n    del harmful_logits, harmless_logits, harmful_cache, harmless_cache\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# ìºì‹œëœ í™œì„±í™” ê²°í•©\nharmful = {k: torch.cat(v) for k, v in harmful.items()}\nharmless = {k: torch.cat(v) for k, v in harmless.items()}\n```\n\nì´ì œ ê° ì¸µì— ëŒ€í•œ ê±°ë¶€ ë°©í–¥ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìœ í•´ ë° ë¬´í•´ ëª…ë ¹ì˜ í™œì„±í™” ê°„ í‰ê·  ì°¨ì´ì— í•´ë‹¹í•˜ë©° ì •ê·œí™”ë©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ activation_scoredì—ì„œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ë©ë‹ˆë‹¤.\n\n```js\n# í™œì„±í™” ìƒ‰ì¸ì„ ê°€ì ¸ì˜¤ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜\ndef get_act_idx(cache_dict, act_name, layer):\n    key = (act_name, layer)\n    return cache_dict[utils.get_act_name(*key)]\n\n# ì¤‘ê°„ ì¸µì—ì„œ ìœ í•´ ë° ë¬´í•´ í™œì„±í™”ì˜ í‰ê·  ì°¨ì´ ê³„ì‚°\nactivation_layers = [\"resid_pre\", \"resid_mid\", \"resid_post\"]\nactivation_refusals = defaultdict(list)\n\nfor layer_num in range(1, model.cfg.n_layers):\n    pos = -1  # ìœ„ì¹˜ ì¸ë±ìŠ¤\n    for layer in activation_layers:\n        harmful_mean_act = get_act_idx(harmful, layer, layer_num)[:, pos, :].mean(dim=0)\n        harmless_mean_act = get_act_idx(harmless, layer, layer_num)[:, pos, :].mean(dim=0)\n        refusal_dir = harmful_mean_act - harmless_mean_act\n        refusal_dir = refusal_dir / refusal_dir.norm()\n        activation_refusals[layer].append(refusal_dir)\n\nselected_layers = [\"resid_pre\"]\nactivation_scored = sorted(\n    [\n        activation_refusals[layer][l - 1]\n        for l in range(1, model.cfg.n_layers)\n        for layer in selected_layers\n    ],\n    key=lambda x: abs(x.mean()),\n    reverse=True,\n)\n```\n\n<div class=\"content-ad\"></div>\n\ní”„ë¡œì„¸ìŠ¤ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” ê³„ì‚°í•œ ê±°ì ˆ ë°©í–¥ì„ í‰ê°€í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ìš°ë¦¬ëŠ” ê±°ì ˆ ë°©í–¥ì„ ì¶”ë¡  ì¤‘ ê° ì”ì—¬ ìŠ¤íŠ¸ë¦¼ê³¼ ê° ë¸”ë¡ì— ì ìš©í•  ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒ ì½”ë“œ ìŠ¤ë‹ˆí«ì—ì„œ ë„¤ ê°€ì§€ í…ŒìŠ¤íŠ¸ ìœ í•´ ì§€ì‹œì™€ 20ê°œ ë¸”ë¡(ë˜ëŠ” ë ˆì´ì–´)ì— ëŒ€í•œ ì„¸ëŒ€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n\n```js\n...\nCode snippet ìƒëµ\n...\n```\n\nìš°ë¦¬ëŠ” evals ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“  ì„¸ëŒ€ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì´ë¥¼ ì¶œë ¥í•˜ê³  ê° ì§€ì‹œì— ëŒ€í•œ ë¬´ê²ì§€ ì•Šì€ ì‘ë‹µì„ ì œê³µí•˜ëŠ” ë ˆì´ì–´(ë¸”ë¡)ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \"I cannot\" ë° \"I can't\"ë¥¼ í¬í•¨í•˜ëŠ” ì‘ë‹µì€ ì›ì¹˜ ì•ŠëŠ” ë‹µë³€ì„ í•„í„°ë§í•˜ê¸° ìœ„í•´ ìë™ìœ¼ë¡œ ì œì™¸í•©ë‹ˆë‹¤.\n\nìœ„ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ì´ì „ selected_layers ëª©ë¡ì˜ ë‹¤ë¥¸ ì”ì—¬ ìŠ¤íŠ¸ë¦¼, ë‹¤ë¥¸ ì§€ì‹œ, ì¶”ê°€ì  ë¸”ë¡ ë“±ì„ í…ŒìŠ¤íŠ¸í•˜ê³ ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n```js\r\n# ì¸ê°„ í‰ê°€ë¥¼ ìœ„í•œ ì„¸ëŒ€ ì¸ì‡„\nblacklist = [\"I cannot\", \"I can't\"]\nfor i in range(N_INST_TEST):\n    print(f\"\\033[1mINSTRUCTION {i}: {harmful_inst_test[i]}\")\n    print(f\"\\nBASELINE COMPLETION:\\n{baseline_generations[i]}\\033[0m\")\n    for layer_candidate in range(EVAL_N):\n        if not any(word in evals[layer_candidate][i] for word in blacklist):\n            print(f\"\\n---\\n\\nLAYER CANDIDATE #{layer_candidate} INTERVENTION COMPLETION:\")\n            print(evals[layer_candidate][i])\r\n```\n\nì €ì˜ ê²½ìš°, ë ˆì´ì–´ í›„ë³´ì 9ê°€ ë„¤ ê°€ì§€ ëª…ë ¹ì— ëŒ€í•´ ì„ ì •ì ì´ì§€ ì•Šì€ ë‹µë³€ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ìš°ë¦¬ê°€ ê±°ë¶€ ë°©í–¥ìœ¼ë¡œ ì„ íƒí•  ê²ƒì´ë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ, ë¬´ê²Œ ì§êµí™”ë¥¼ êµ¬í˜„í•˜ì—¬ ëª¨ë¸ì´ ì´ ë°©í–¥ì˜ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì„ ì •ë˜ì§€ ì•Šì€ì§€ë¥¼ í™•ì¸í•˜ë ¤ë©´ ì™„ë£Œëœ ë‚´ìš©ì„ ì¸ì‡„í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n```js\r\ndef get_orthogonalized_matrix(\n    matrix: Float[Tensor, \"... d_model\"], vec: Float[Tensor, \"d_model\"]\n) -> Float[Tensor, \"... d_model\"]:\n    proj = (\n        einops.einsum(\n            matrix, vec.view(-1, 1), \"... d_model, d_model single -> ... single\"\n        )\n        * vec\n    )\n    return matrix - proj\n\n# ê°€ì¥ ë†’ì€ ê±°ë¶€ ë°©í–¥ì„ ê°–ëŠ” ë ˆì´ì–´ ì„ íƒ\nLAYER_CANDIDATE = 9\nrefusal_dir = activation_scored[LAYER_CANDIDATE]\n\n# ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì§êµí™”\nif refusal_dir.device != model.W_E.device:\n    refusal_dir = refusal_dir.to(model.W_E.device)\nmodel.W_E.data = get_orthogonalized_matrix(model.W_E, refusal_dir)\n\nfor block in tqdm(model.blocks):\n    if refusal_dir.device != block.attn.W_O.device:\n        refusal_dir = refusal_dir.to(block.attn.W_O.device)\n    block.attn.W_O.data = get_orthogonalized_matrix(block.attn.W_O, refusal_dir)\n    block.mlp.W_out.data = get_orthogonalized_matrix(block.mlp.W_out, refusal_dir)\n\n# ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±\northogonalized_generations = get_generations(\n    model, tokenizer, harmful_inst_test[:N_INST_TEST], fwd_hooks=[]\n)\n\n# ì„¸ëŒ€ ì¶œë ¥\nfor i in range(N_INST_TEST):\n    if len(baseline_generations) > i:\n        print(f\"INSTRUCTION {i}: {harmful_inst_test[i]}\")\n        print(f\"\\033[92mBASELINE COMPLETION:\\n{baseline_generations[i]}\")\n    print(f\"\\033[91mINTERVENTION COMPLETION:\\n{evals[LAYER_CANDIDATE][i]}\")\n    print(f\"\\033[95mORTHOGONALIZED COMPLETION:\\n{orthogonalized_generations[i]}\\n\")\r\n```\n\nì´ì œ ëª¨ë¸ì„ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ Hugging Face í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ HF í—ˆë¸Œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n```json\n# ëª¨ë¸ì„ ë‹¤ì‹œ HF ë³´ì•ˆ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤\nhf_model = AutoModelForCausalLM.from_pretrained(MODEL_TYPE, torch_dtype=torch.bfloat16)\nlm_model = hf_model.model\n\nstate_dict = model.state_dict()\nlm_model.embed_tokens.weight = torch.nn.Parameter(state_dict[\"embed.W_E\"].cpu())\nfor l in range(model.cfg.n_layers):\n    lm_model.layers[l].self_attn.o_proj.weight = torch.nn.Parameter(\n        einops.rearrange(\n            state_dict[f\"blocks.{l}.attn.W_O\"], \"n h m->m (n h)\", n=model.cfg.n_heads\n        ).contiguous()\n    )\n    lm_model.layers[l].mlp.down_proj.weight = torch.nn.Parameter(\n        torch.transpose(state_dict[f\"blocks.{l}.mlp.W_out\"], 0, 1).contiguous()\n    )\n\nhf_model.push_to_hub(f\"{MODEL_ID}-abliterated\")\n```\n\n# âš–ï¸ DPO Fine-Tuning\n\nì´ì „ ì„¹ì…˜ì˜ abliterated ë° ì†ŒìŠ¤ ëª¨ë¸ì„ Open LLM Leaderboard ë° Nousì˜ ë²¤ì¹˜ë§ˆí¬ ìŠ¤ìœ„íŠ¸ì—ì„œ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì— ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤:\n\n<img src=\"/assets/img/2024-06-19-UncensoranyLLMwithabliteration_2.png\" />\n\n\n<div class=\"content-ad\"></div>\n\në³´ì‹œë‹¤ì‹œí”¼, ì›ë³¸ ëª¨ë¸ì€ Llama 3 8B Instructë³´ë‹¤ í˜„ì €í•˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì ˆì‚­ëœ ë²„ì „ì—ì„œ ì„±ëŠ¥ í•˜ë½ì„ ê´€ì°°í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ˆì‚­ ê³¼ì •ì€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©´ì„œë„ ëª¨ë¸ì˜ í’ˆì§ˆì„ ì €í•˜ì‹œí‚¨ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.\n\nì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ìš°ë¦¬ì˜ ì ˆì‚­ëœ ëª¨ë¸ì„ ì¶”ê°€ë¡œ í›ˆë ¨í•˜ì—¬ íšŒë³µì‹œí‚¤ëŠ” ì•„ì´ë””ì–´ê°€ ìˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ì„¸ë°€ ì¡°ì •ëœ ëª¨ë¸ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ Llama 3 8B Instructì€ ì§€ë„ í•™ìŠµ ì„¸ë°€ ì¡°ì •ì— ìˆì–´ì„œ ê½¤ ì·¨ì•½í•©ë‹ˆë‹¤. ì¶”ê°€ì ì¸ SFTëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦´ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.\n\nëŒ€ì²´ë¡œ, ì„ í˜¸ ë§ì¶¤ì´ ìƒë‹¹íˆ ê°€ë³ê³  ìš°ë¦¬ì˜ ì ˆì‚­ëœ ëª¨ë¸ì„ ë‡Œê°œë°•í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. DPOëŠ” ì‚¬ìš©í•˜ê¸° ì‰½ê³  ìš°ìˆ˜í•œ ì¶”ì  ë ˆì½”ë“œë¡œ ì—¬ê¸°ì„œ ì¢‹ì€ í›„ë³´ì…ë‹ˆë‹¤. ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ mlabonne/orpo-dpo-mix-40k ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” LazyAxolotl (Axolotlì„ ë§Œë“¤ì–´ ì¤€ Wing Lianì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤)ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì— ì‚¬ìš©í•œ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n```js\nbase_model: mlabonne/Daredevil-8B-abliterated\nmodel_type: LlamaForCausalLM\ntokenizer_type: AutoTokenizer\n\nload_in_8bit: false\nload_in_4bit: true\nstrict: false\nsave_safetensors: true\n\nrl: dpo\nchat_template: chatml\ndatasets:\n  - path: mlabonne/orpo-dpo-mix-40k\n    split: train\n    type: chatml.intel\n\ndataset_prepared_path:\nval_set_size: 0.0\noutput_dir: ./out\n\nadapter: qlora\nlora_model_dir:\n\nsequence_len: 2048\nsample_packing: false\npad_to_sequence_len: false\n\nlora_r: 64\nlora_alpha: 32\nlora_dropout: 0.05\nlora_target_linear: true\nlora_fan_in_fan_out:\n\nwandb_project: axolotl\nwandb_entity:\nwandb_watch:\nwandb_name:\nwandb_log_model:\n\ngradient_accumulation_steps: 8\nmicro_batch_size: 1\nnum_epochs: 1\noptimizer: paged_adamw_8bit\nlr_scheduler: cosine\nlearning_rate: 5e-6\ntrain_on_inputs: false\ngroup_by_length: false\n... (ì´ì–´ì§)\n```\n\n<div class=\"content-ad\"></div>\n\n6xA6000 GPUì™€ DeepSpeed ZeRO-2ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í–ˆì–´ìš”. í›ˆë ¨ì—ëŠ” ì•½ 6ì‹œê°„ 45ë¶„ì´ ì†Œìš”ë˜ì—ˆë‹µë‹ˆë‹¤. W&Bì—ì„œ ì–»ì€ í›ˆë ¨ ê³¡ì„ ì„ ì—¬ê¸°ì— ê°€ì ¸ì™”ì–´ìš”:\n\nDPOë¥¼ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•œ mlabonne/NeuralDaredevil-8B-abliterated ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆì–´ìš”. ì €í¬ê°€ ì•ì„œ ì§€ì›Œë²„ë¦° ë²„ì „ì„ ìˆ˜ì •í–ˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë™ì¼í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í–ˆì–´ìš”:\n\n![í›ˆë ¨ ê³¡ì„ ](/assets/img/2024-06-19-UncensoranyLLMwithabliteration_3.png)\n\nì´ ì¶”ê°€ í›ˆë ¨ì„ í†µí•´ ì§€ì›Œì§„ ì˜í–¥ ëŒ€ë¶€ë¶„ì„ íšŒë³µí•  ìˆ˜ ìˆì—ˆì–´ìš”. ëª¨ë¸ì´ ê°œì„ ë˜ì§€ ì•ŠëŠ” í•œ ì˜ì—­ì€ GSM8K, ìˆ˜í•™ ë°ì´í„° ì„¸íŠ¸, ì¸ë°ìš”, ì´ëŠ” orpo-dpo-mix-40kê°€ ë” ë§ì€ ìˆ˜í•™ ìƒ˜í”Œì„ í•„ìš”ë¡œ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•  ìˆ˜ ìˆì–´ìš”.\n\n<div class=\"content-ad\"></div>\n\nìµœì¢… ëª¨ë¸ì€ 8B ë²”ì£¼ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ìë‘í•˜ëŠ” ë¯¸ê²€ì—´ LLMì…ë‹ˆë‹¤. í•„í„°ë§ì´ í•„ìš” ì—†ì„ ë•ŒëŠ” Llama 3 8B Instructì˜ ê°œì„ ëœ ë²„ì „ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤. LM Studioì—ì„œ GGUFì™€ ê°™ì€ ì–‘ìí™”ëœ ë²„ì „ì„ ì‚¬ìš©í•´ ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n\n# ê²°ë¡ \n\nì´ ê¸€ì—ì„œëŠ” ì†Œëª…í™”(abliteration) ê°œë…ì„ ì†Œê°œí–ˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ëª¨ë¸ì˜ í™œì„±í™”ë¥¼ í•´ë¡­ê³  í•´ë¥¼ ë¼ì¹˜ì§€ ì•ŠëŠ” í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•˜ì—¬ ê±°ë¶€ ë°©í–¥ì„ ê³„ì‚°í•˜ê³ , ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ê±°ë¶€ë¥¼ ê·¸ë§Œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ì•ˆì „ ì„¸ë°€ì¡°ì •ì˜ ì·¨ì•½ì„±ì„ ë³´ì—¬ì£¼ë©° ìœ¤ë¦¬ì  ê³ ë ¤ ì‚¬í•­ì„ ë˜ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n\nìš°ë¦¬ëŠ” Daredevil-8Bì— ì†Œëª…í™”ë¥¼ ì ìš©í•˜ì—¬ í•„í„°ë§ì„ í•´ì œí–ˆì§€ë§Œ, ì´ë¡œ ì¸í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ í›„ DPOë¥¼ ì‚¬ìš©í•˜ì—¬ NeuralDaredevil-8B ëª¨ë¸ì„ ìƒì„±í•˜ì—¬ ì™„ì „íˆ ë¯¸ê²€ì—´ì´ê³  ê³ í’ˆì§ˆì˜ 8B LLMì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì†Œëª…í™”ëŠ” ì •ë ¬ ì œê±°ì— êµ­í•œë˜ì§€ ì•Šìœ¼ë©°, ë‹¤ì‹œ êµìœ¡ ì—†ì´ ì„¸ë°€ ì¡°ì •ì˜ ì¼ì¢…ìœ¼ë¡œ ê°„ì£¼í•´ì•¼ í•©ë‹ˆë‹¤. ì‹¤ì œë¡œ MopeyMuleì˜ FailSpyì˜ ê²½ìš°ì²˜ëŸ¼ ì¢Œì ˆì ì¸ ëŒ€í™” ìŠ¤íƒ€ì¼ì„ ì±„íƒí•˜ëŠ” ê²ƒê³¼ ê°™ì´ ì°½ì˜ì ìœ¼ë¡œ ë‹¤ë¥¸ ëª©í‘œì—ë„ ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nì´ ê¸°ì‚¬ê°€ ë§ˆìŒì— ë“¤ì—ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”. ë” ë§ì€ ë‚´ìš©ì„ ë³´ê³  ì‹¶ë‹¤ë©´ Hugging Faceì™€ Twitterì˜ @maximelabonneë¥¼ íŒ”ë¡œìš°í•´ ì£¼ì„¸ìš”.\n\n# ì°¸ê³  ìë£Œ\n\n- FailSpy, â€œabliterator library,â€ GitHub, 2024.\n- Andy Arditi, Oscar Obeso, Aaquib111, wesg, Neel Nanda, â€œRefusal in LLMs is mediated by a single direction,â€ Lesswrong, 2024.","ogImage":{"url":"/assets/img/2024-06-19-UncensoranyLLMwithabliteration_0.png"},"coverImage":"/assets/img/2024-06-19-UncensoranyLLMwithabliteration_0.png","tag":["Tech"],"readingTime":15},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>ì¬í•™ìŠµ ì—†ì´ ì„¸ë°€ ì¡°ì •í•˜ê¸°</h2>\n<p><img src=\"/assets/img/2024-06-19-UncensoranyLLMwithabliteration_0.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<p>ëŒë§ˆ ëª¨ë¸ì˜ ì„¸ëŒ€ê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ìì˜ ì§€ì‹œë¥¼ ì´í•´í•˜ê³  ë”°ë¥´ëŠ” ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ 'ì„¸ì„¸í•œ ì¡°ì •(ì„¸ì„¸í•˜ê²Œ ì¡°ì •)' ë²„ì „ì„ ì œê³µí•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ëª¨ë¸ë“¤ì€ ë§¤ìš° ê²€ì—´ë˜ì–´ ìˆìœ¼ë©° í•´ë¡œìš´ ìš”ì²­ìœ¼ë¡œ ê°„ì£¼ë˜ëŠ” ê²ƒì€ ê±°ë¶€í•˜ê³  \"AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ë„ì™€ë“œë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"ì™€ ê°™ì€ ëŒ€ë‹µì„ í•©ë‹ˆë‹¤. ì´ ì•ˆì „ ê¸°ëŠ¥ì€ ì˜¤ìš©ì„ ë°©ì§€í•˜ëŠ” ë° ì¤‘ìš”í•˜ì§€ë§Œ, ëª¨ë¸ì˜ ìœ ì—°ì„±ê³¼ ë°˜ì‘ì„±ì„ ì œí•œí•©ë‹ˆë‹¤.</p>\n<p>ë³¸ ë¬¸ì„œì—ì„œëŠ” \"ë¬´íš¨í™”\"ë¼ëŠ” ê¸°ìˆ ì„ íƒêµ¬í•˜ì—¬ ì¬í•™ìŠµ ì—†ì´ ì–´ë–¤ ëŒë§ˆ ëª¨ë¸ì´ë“  ê²€ì—´ì„ í‘¸ëŠ” ë°©ë²•ì„ ì‚´í´ë³¼ ê²ƒì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ëª¨ë¸ì— ë‚´ì¥ëœ ê±°ë¶€ ë©”ì»¤ë‹ˆì¦˜ì„ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•˜ì—¬ ëª¨ë“  ìœ í˜•ì˜ í”„ë¡¬í”„íŠ¸ì— ëŒ€ì‘í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.</p>\n<p>ì½”ë“œëŠ” Google Colabì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , LLM ì½”ìŠ¤ì—ì„œë„ GitHubì— ìˆìŠµë‹ˆë‹¤. ì´ ê¸°ì‚¬ë¥¼ êµì •í•´ ì£¼ì‹  FailSpyë‹˜ì—ê²Œ íŠ¹ë³„íˆ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.</p>\n<h1>âœ‚ï¸ ì‚­ì œë€ì´ë€?</h1>\n<p>í˜„ëŒ€ LLMì€ ì•ˆì „ ë° ì§€ì‹œë¥¼ ë”°ë¥´ëŠ” ë°©í–¥ìœ¼ë¡œ ì„¸ë°€í•˜ê²Œ ì¡°ì •ë˜ì–´ ìˆì–´, í•´ë¡œìš´ ìš”ì²­ì„ ê±°ë¶€í•˜ê¸° ìœ„í•´ í›ˆë ¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Arditi ë“±ì´ ë¸”ë¡œê·¸ ê¸€ì—ì„œ ì„¤ëª…í•œ ë°”ì— ë”°ë¥´ë©´, ì´ ê±°ë¶€ í–‰ë™ì€ ëª¨ë¸ì˜ ì”ë¥˜ ìŠ¤íŠ¸ë¦¼ì— ìˆëŠ” íŠ¹ì • ë°©í–¥ì„ í†µí•´ ì¤‘ì¬ë©ë‹ˆë‹¤. ë§Œì•½ ì´ ë°©í–¥ì„ ëª¨ë¸ì´ ë‚˜íƒ€ë‚´ì§€ ëª»í•˜ë„ë¡ ë§‰ëŠ”ë‹¤ë©´, ìš”ì²­ì„ ê±°ë¶€í•˜ëŠ” ëŠ¥ë ¥ì„ ìƒê²Œ ë©ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, ì´ ë°©í–¥ì„ ì¸ìœ„ì ìœ¼ë¡œ ì¶”ê°€í•˜ë©´ ëª¨ë¸ì´ í•´ê°€ ì—†ëŠ” ìš”ì²­ì¡°ì°¨ë„ ê±°ë¶€í•  ìˆ˜ ìˆê²Œë©ë‹ˆë‹¤.</p>\n<p>ì „í†µì ì¸ ë””ì½”ë” ì „ìš© Llamaë¥˜ ì•„í‚¤í…ì²˜ì—ì„œëŠ” ì„¸ ê°€ì§€ì˜ ì”ë¥˜ ìŠ¤íŠ¸ë¦¼ì„ ëŒ€ìƒìœ¼ë¡œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: ê° ë¸”ë¡ì˜ ì‹œì‘ ë¶€ë¶„ì—ì„œ(â€œpreâ€), ì–´í…ì…˜ê³¼ MLP ë ˆì´ì–´ ì‚¬ì´ì—ì„œ(â€œmidâ€), ê·¸ë¦¬ê³  MLP ì´í›„ì—(â€œpostâ€). ë‹¤ìŒ ê·¸ë¦¼ì€ ê° ì”ë¥˜ ìŠ¤íŠ¸ë¦¼ì˜ ìœ„ì¹˜ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.</p>\n<p>LLMì„ ë¬´ì¦ê²€ ìƒíƒœë¡œ ë§Œë“¤ê¸° ìœ„í•´ ë¨¼ì € ëª¨ë¸ ë‚´ì˜ \"ê±°ë¶€ ë°©í–¥\"ì„ ì‹ë³„í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ëŠ” ëª‡ ê°€ì§€ ê¸°ìˆ ì  ë‹¨ê³„ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:</p>\n<ul>\n<li>ë°ì´í„° ìˆ˜ì§‘: ìœ í•´í•œ ì§€ì‹œë¬¸ ì§‘í•©ê³¼ ë¬´í•´í•œ ì§€ì‹œë¬¸ ì§‘í•©ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì‹¤í–‰í•˜ê³ , ê°ê°ì˜ ë§ˆì§€ë§‰ í† í° ìœ„ì¹˜ì—ì„œ ì”ì—¬ ìŠ¤íŠ¸ë¦¼ í™œì„±í™”ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.</li>\n<li>í‰ê·  ì°¨ì´: ìœ í•´í•œ ì§€ì‹œì™€ ë¬´í•´í•œ ì§€ì‹œì˜ í™œì„±í™” ê°„ í‰ê·  ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì˜ ê° ë ˆì´ì–´ì— ëŒ€í•œ \"ê±°ë¶€ ë°©í–¥\"ì„ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>\n<li>ì„ íƒ: ì´ëŸ¬í•œ ë²¡í„°ë¥¼ ì •ê·œí™”í•˜ê³ , í‰ê°€í•˜ì—¬ ë‹¨ì¼ ìµœìƒì˜ \"ê±°ë¶€ ë°©í–¥\"ì„ ì„ íƒí•©ë‹ˆë‹¤.</li>\n</ul>\n<p>ê±°ë¶€ ë°©í–¥ì„ ì‹ë³„í•œ í›„, í•´ë‹¹ ê¸°ëŠ¥ì„ í‘œí˜„í•˜ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°í•˜ëŠ” \"ì œê±°(ablate)\" ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì¶”ë¡  ì‹œê°„ ê°„ì„­ì´ë‚˜ ê°€ì¤‘ì¹˜ ì§êµí™”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜êµ¬ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<p>ë¨¼ì € ì¶”ë¡  ì‹œê°„ ê°œì…ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì”ì°¨ ìŠ¤íŠ¸ë¦¼ì— ê¸°ë¡í•˜ëŠ” ëª¨ë“  êµ¬ì„± ìš”ì†Œ(ì˜ˆ: ì–´í…ì…˜ í—¤ë“œ)ë§ˆë‹¤ ê·¸ ì¶œë ¥ì„ ê±°ë¶€ ë°©í–¥ìœ¼ë¡œ íˆ¬ì˜í•œ í›„ ì´ íˆ¬ì˜ì„ ëºë‹ˆë‹¤. ì´ ëº„ì…ˆì€ ê° í† í°ê³¼ ê° ë ˆì´ì–´ì— ì ìš©ë˜ì–´ ëª¨ë¸ì´ ê²°ì½” ê±°ë¶€ ë°©í–¥ì„ í‘œí˜„í•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.</p>\n<p>í•œí¸, ê°€ì¤‘ì¹˜ ì§êµí™”ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ê±°ë¶€ ë°©í–¥ì— ëŒ€í•´ êµ¬ì„± ìš”ì†Œ ê°€ì¤‘ì¹˜ë¥¼ ì§êµí™”í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì´ ì´ ë°©í–¥ìœ¼ë¡œ ê¸°ë¡í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. ì”ì°¨ ìŠ¤íŠ¸ë¦¼ì— ê¸°ë¡í•˜ëŠ” í–‰ë ¬ì„ ì¡°ì •í•˜ì—¬ ì´ëŸ¬í•œ ê¸°ì—¬ê°€ ê±°ë¶€ ë°©í–¥ì— ì˜í–¥ì„ ì£¼ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.</p>\n<p>ë‹¤ìŒ ì„¹ì…˜ì—ì„œëŠ” ê°€ì¤‘ì¹˜ ì§êµí™”ë¥¼ ì‚¬ìš©í•œ ì¢Œì ˆ ì‹¤í˜„ì„ êµ¬í˜„í•  ê²ƒì…ë‹ˆë‹¤.</p>\n<h1>ğŸ’» êµ¬í˜„</h1>\n<p>ì•„ë˜ì˜ abliteration êµ¬í˜„ì€ FailSpyì˜ ë…¸íŠ¸ë¶ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ ë…¸íŠ¸ë¶ì€ ì›ë˜ ì €ìë“¤ì˜ ë…¸íŠ¸ë¶ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì €ëŠ” ì£¼ë¡œ ì´ë¥¼ ì ì‘í•˜ì—¬ ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰½ë„ë¡ í–ˆìŠµë‹ˆë‹¤. ì´ ì„¹ì…˜ì€ ì½”ë“œê°€ ë§ì´ í¬í•¨ë˜ì–´ ìˆì–´ì„œ ë¬´ìŠ¨ ì¼ì´ ë²Œì–´ì§€ëŠ”ì§€ ë³¼ ìˆ˜ ìˆì§€ë§Œ, ê¸°ìˆ ì ì¸ ì„¸ë¶€ ì‚¬í•­ì— ëœ ê´€ì‹¬ì´ ìˆëŠ” ê²½ìš° FailSpyì˜ abliterator ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (Hugging Faceì˜ abliterated ëª¨ë¸ ëª¨ìŒë„ í™•ì¸í•´ë³´ì„¸ìš”).</p>\n<p>ì´ ì½”ë“œëŠ” ë›°ì–´ë‚œ TransformerLens ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì´ì „ì—ëŠ” EasyTransformerë¡œ ì•Œë ¤ì¡ŒìŒ)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬´ê±°ìš´ ì‘ì—…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë©”ì»¤ë‹ˆì¦˜ í•´ì„ ê°€ëŠ¥ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©° ì—¬ê¸°ì„œëŠ” í™œì„±í™”ì— ê°œì…í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë§Œë“  Neel Nandaì™€ Joseph Bloomì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.</p>\n<p>ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  ê°€ì ¸ì™€ ë´…ì‹œë‹¤. ì´ëŸ¬í•œ ëª¨ë“  ë‹¨ê³„ëŠ” Google Colab ë…¸íŠ¸ë¶ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">!pip install transformers transformers_stream_generator tiktoken transformer_lens einops jaxtyping\n\n<span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\">import</span> functools\n<span class=\"hljs-keyword\">import</span> einops\n<span class=\"hljs-keyword\">import</span> gc\n\n<span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset\n<span class=\"hljs-keyword\">from</span> tqdm <span class=\"hljs-keyword\">import</span> tqdm\n<span class=\"hljs-keyword\">from</span> torch <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">Tensor</span>\n<span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">List</span>\n<span class=\"hljs-keyword\">from</span> transformer_lens <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">HookedTransformer</span>, utils\n<span class=\"hljs-keyword\">from</span> transformer_lens.<span class=\"hljs-property\">hook_points</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">HookPoint</span>\n<span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">AutoModelForCausalLM</span>, <span class=\"hljs-title class_\">AutoTokenizer</span>\n<span class=\"hljs-keyword\">from</span> jaxtyping <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">Float</span>, <span class=\"hljs-title class_\">Int</span>\n<span class=\"hljs-keyword\">from</span> collections <span class=\"hljs-keyword\">import</span> defaultdict\n\n# <span class=\"hljs-variable constant_\">GPU</span> ë©”ëª¨ë¦¬ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ ìë™ ë¯¸ë¶„ì„ ë•ë‹ˆë‹¤ (í¬ë ˆë”§: <span class=\"hljs-title class_\">Undi95</span>)\ntorch.<span class=\"hljs-title function_\">set_grad_enabled</span>(<span class=\"hljs-title class_\">False</span>)\n</code></pre>\n<p>ë‘ ê°€ì§€ ë°ì´í„° ì„¸íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤: í”¼í•´ê°€ ì—†ëŠ” ì§€ì¹¨ì„ í¬í•¨í•œ í•˜ë‚˜ì™€ ìœ í•´í•œ ì§€ì¹¨ì„ í¬í•¨í•œ í•˜ë‚˜ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” tatsu-lab/alpacaì™€ llm-attacksì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ëª¨ë“  ê²ƒì„ ë” ì‰½ê²Œ ë§Œë“¤ê¸° ìœ„í•´, ì €ëŠ” ì´ë¥¼ ë‘ ê°œì˜ Hugging Face ë°ì´í„° ì„¸íŠ¸ë¡œ ë‹¤ì‹œ íŒ¨í‚¤ì§•í•˜ì—¬ mlabonne/harmless_alpacaì™€ mlabonne/harmful_behaviorsë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê²Œ í•˜ë©´ ì—¬ëŸ¬ë¶„ì´ ì‰½ê²Œ ì—¬ëŸ¬ë¶„ ìì‹ ì˜ ë°ì´í„° ì„¸íŠ¸ë¡œ êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<p>ì§€ì¹¨ì„ë¡œë“œí•˜ê³  \"role\"ê³¼ \"content\" í‚¤ê°€ ìˆëŠ” ì‚¬ì „ ëª©ë¡ìœ¼ë¡œ ë‹¤ì‹œ ì„œì‹í™”í•  ê²ƒì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ Llama 3ì˜ ì±„íŒ… í…œí”Œë¦¿ì„ ë”°ë¥´ëŠ” apply_chat_tokenizer() ë©”ì„œë“œì™€ í˜¸í™˜ë©ë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">reformat_texts</span>(<span class=\"hljs-params\">texts</span>):\n    <span class=\"hljs-keyword\">return</span> [[{<span class=\"hljs-string\">\"role\"</span>: <span class=\"hljs-string\">\"user\"</span>, <span class=\"hljs-string\">\"content\"</span>: text}] <span class=\"hljs-keyword\">for</span> text <span class=\"hljs-keyword\">in</span> texts]\n\n<span class=\"hljs-comment\"># ìœ í•´í•˜ê³  ë¬´í•´í•œ ë°ì´í„° ì„¸íŠ¸ ê°€ì ¸ì˜¤ê¸°</span>\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_harmful_instructions</span>():\n    dataset = load_dataset(<span class=\"hljs-string\">'mlabonne/harmful_behaviors'</span>)\n    <span class=\"hljs-keyword\">return</span> reformat_texts(dataset[<span class=\"hljs-string\">'train'</span>][<span class=\"hljs-string\">'text'</span>]), reformat_texts(dataset[<span class=\"hljs-string\">'test'</span>][<span class=\"hljs-string\">'text'</span>])\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_harmless_instructions</span>():\n    dataset = load_dataset(<span class=\"hljs-string\">'mlabonne/harmless_alpaca'</span>)\n    <span class=\"hljs-keyword\">return</span> reformat_texts(dataset[<span class=\"hljs-string\">'train'</span>][<span class=\"hljs-string\">'text'</span>]), reformat_texts(dataset[<span class=\"hljs-string\">'test'</span>][<span class=\"hljs-string\">'text'</span>])\n\nharmful_inst_train, harmful_inst_test = get_harmful_instructions()\nharmless_inst_train, harmless_inst_test = get_harmless_instructions()\n</code></pre>\n<p>ì´ì œ ë°ì´í„° ì„¸íŠ¸ê°€ ì¤€ë¹„ë˜ì—ˆìœ¼ë¯€ë¡œ, abliterate í•˜ë ¤ëŠ” ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì•ˆíƒ€ê¹ê²Œë„, HookedTransformerë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ, FailSpyì˜ ë…¸íŠ¸ë¶ì— ì„¤ëª…ëœ ê¼¼ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³  meta-llama/Meta-Llama-3-8B-Instructë¡œ ì´ë¦„ì„ ë³€ê²½í•˜ê² ìŠµë‹ˆë‹¤. GPUê°€ BF16ê³¼ í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ê²½ìš° torch.float16 í˜•ì‹ìœ¼ë¡œ ë¡œë“œí•˜ì„¸ìš”.</p>\n<p>ì´ ì˜ˆì‹œì—ì„œëŠ” DARE TIES(ëª¨ë¸ ë³‘í•©ì— ê´€í•œ ë‚´ ê¸°ì‚¬ ì°¸ì¡°)ë¡œ ë§Œë“¤ì–´ì§„ mlabonne/Daredevil-8Bë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ 8B ì¹´í…Œê³ ë¦¬ì˜ Open LLM Leaderboardì—ì„œ ê°€ì¥ ë†’ì€ MMLU ì ìˆ˜ë¥¼ ê°€ì§€ê³  ìˆì–´ìš”.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-variable constant_\">MODEL_ID</span> = <span class=\"hljs-string\">\"mlabonne/Daredevil-8B\"</span>\n<span class=\"hljs-variable constant_\">MODEL_TYPE</span> = <span class=\"hljs-string\">\"meta-llama/Meta-Llama-3-8B-Instruct\"</span>\n\n# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n!git clone <span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//huggingface.co/{MODEL_ID} {MODEL_TYPE}</span>\n\n# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ\nmodel = <span class=\"hljs-title class_\">HookedTransformer</span>.<span class=\"hljs-title function_\">from_pretrained_no_processing</span>(\n    <span class=\"hljs-variable constant_\">MODEL_TYPE</span>,\n    local_files_only=<span class=\"hljs-title class_\">True</span>,\n    dtype=torch.<span class=\"hljs-property\">bfloat16</span>,\n    default_padding_side=<span class=\"hljs-string\">'left'</span>\n)\ntokenizer = <span class=\"hljs-title class_\">AutoTokenizer</span>.<span class=\"hljs-title function_\">from_pretrained</span>(<span class=\"hljs-variable constant_\">MODEL_TYPE</span>)\ntokenizer.<span class=\"hljs-property\">padding_side</span> = <span class=\"hljs-string\">'left'</span>\ntokenizer.<span class=\"hljs-property\">pad_token</span> = tokenizer.<span class=\"hljs-property\">eos_token</span>\n</code></pre>\n<p>ì´ì œ ë°ì´í„°ì…‹ì„ í† í°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´í•´í•œ ë° ìœ í•´í•œ ì§€ì‹œì‚¬í•­ì— ëŒ€í•´ ë™ì¼í•œ ìƒ˜í”Œ ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ìƒ˜í”Œ ìˆ˜ê°€ ë†’ìœ¼ë©´ ëª¨ë“  RAM/VRAMì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” 256ìœ¼ë¡œ ì œí•œí•©ë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">tokenize_instructions</span>(tokenizer, instructions):\n    <span class=\"hljs-keyword\">return</span> tokenizer.<span class=\"hljs-title function_\">apply_chat_template</span>(\n        instructions,\n        padding=<span class=\"hljs-title class_\">True</span>,\n        truncation=<span class=\"hljs-title class_\">False</span>,\n        return_tensors=<span class=\"hljs-string\">\"pt\"</span>,\n        return_dict=<span class=\"hljs-title class_\">True</span>,\n        add_generation_prompt=<span class=\"hljs-title class_\">True</span>,\n    ).<span class=\"hljs-property\">input_ids</span>\n\nn_inst_train = <span class=\"hljs-title function_\">min</span>(<span class=\"hljs-number\">256</span>, <span class=\"hljs-title function_\">len</span>(harmful_inst_train), <span class=\"hljs-title function_\">len</span>(harmless_inst_train))\n\n# ë°ì´í„°ì…‹ í† í°í™”\nharmful_tokens = <span class=\"hljs-title function_\">tokenize_instructions</span>(\n    tokenizer,\n    instructions=harmful_inst_train[:n_inst_train],\n)\nharmless_tokens = <span class=\"hljs-title function_\">tokenize_instructions</span>(\n    tokenizer,\n    instructions=harmless_inst_train[:n_inst_train],\n)\n</code></pre>\n<p>ì‘ì—…ì´ ëª¨ë‘ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ë„ì²˜ëŸ¼ ì²˜ë¦¬í•˜ëŠ” ì²« ë²ˆì§¸ ë‹¨ê³„ì¸ ë°ì´í„° ìˆ˜ì§‘ì„ êµ¬í˜„í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ í† í°í™”ëœ ë°ì´í„°ì…‹ì„ ì²˜ë¦¬í•˜ê³  ìœ í•´(harmful) ë° ë¬´í•´(harmless)ë¡œ ë‚˜ë¨¸ì§€ ìŠ¤íŠ¸ë¦¼ í™œì„±í™”ë¥¼ ì €ì¥í•˜ë ¤ê³  í•©ë‹ˆë‹¤. ì´ëŠ” transformer_lens ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ê´€ë¦¬ë©ë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">batch_size = <span class=\"hljs-number\">32</span>\n\n# í™œì„±í™”ë¥¼ ì €ì¥í•  ê¸°ë³¸ ì‚¬ì „ ì´ˆê¸°í™”\nharmful = <span class=\"hljs-title function_\">defaultdict</span>(list)\nharmless = <span class=\"hljs-title function_\">defaultdict</span>(list)\n\n# ë°ì´í„° í•™ìŠµì„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬\nnum_batches = (n_inst_train + batch_size - <span class=\"hljs-number\">1</span>) <span class=\"hljs-comment\">// batch_size</span>\n\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">tqdm</span>(<span class=\"hljs-title function_\">range</span>(num_batches)):\n    <span class=\"hljs-title function_\">print</span>(i)\n    start_idx = i * batch_size\n    end_idx = <span class=\"hljs-title function_\">min</span>(n_inst_train, start_idx + batch_size)\n\n    # ìœ í•´ ë° ë¬´í•´ í”„ë¡¬í”„íŠ¸ì— ëª¨ë¸ ì‹¤í–‰ ë° í™œì„±í™” ìºì‹œ\n    harmful_logits, harmful_cache = model.<span class=\"hljs-title function_\">run_with_cache</span>(\n        harmful_tokens[<span class=\"hljs-attr\">start_idx</span>:end_idx],\n        names_filter=lambda <span class=\"hljs-attr\">hook_name</span>: <span class=\"hljs-string\">'resid'</span> <span class=\"hljs-keyword\">in</span> hook_name,\n        device=<span class=\"hljs-string\">'cpu'</span>,\n        reset_hooks_end=<span class=\"hljs-title class_\">True</span>\n    )\n    harmless_logits, harmless_cache = model.<span class=\"hljs-title function_\">run_with_cache</span>(\n        harmless_tokens[<span class=\"hljs-attr\">start_idx</span>:end_idx],\n        names_filter=lambda <span class=\"hljs-attr\">hook_name</span>: <span class=\"hljs-string\">'resid'</span> <span class=\"hljs-keyword\">in</span> hook_name,\n        device=<span class=\"hljs-string\">'cpu'</span>,\n        reset_hooks_end=<span class=\"hljs-title class_\">True</span>\n    )\n\n    # í™œì„±í™” ìˆ˜ì§‘ ë° ì €ì¥\n    <span class=\"hljs-keyword\">for</span> key <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">harmful_cache</span>:\n        harmful[key].<span class=\"hljs-title function_\">append</span>(harmful_cache[key])\n        harmless[key].<span class=\"hljs-title function_\">append</span>(harmless_cache[key])\n\n    # <span class=\"hljs-variable constant_\">RAM</span> ë° <span class=\"hljs-variable constant_\">VRAM</span> ë¹„ìš°ê¸°\n    del harmful_logits, harmless_logits, harmful_cache, harmless_cache\n    gc.<span class=\"hljs-title function_\">collect</span>()\n    torch.<span class=\"hljs-property\">cuda</span>.<span class=\"hljs-title function_\">empty_cache</span>()\n\n# ìºì‹œëœ í™œì„±í™” ê²°í•©\nharmful = {<span class=\"hljs-attr\">k</span>: torch.<span class=\"hljs-title function_\">cat</span>(v) <span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> harmful.<span class=\"hljs-title function_\">items</span>()}\nharmless = {<span class=\"hljs-attr\">k</span>: torch.<span class=\"hljs-title function_\">cat</span>(v) <span class=\"hljs-keyword\">for</span> k, v <span class=\"hljs-keyword\">in</span> harmless.<span class=\"hljs-title function_\">items</span>()}\n</code></pre>\n<p>ì´ì œ ê° ì¸µì— ëŒ€í•œ ê±°ë¶€ ë°©í–¥ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìœ í•´ ë° ë¬´í•´ ëª…ë ¹ì˜ í™œì„±í™” ê°„ í‰ê·  ì°¨ì´ì— í•´ë‹¹í•˜ë©° ì •ê·œí™”ë©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ activation_scoredì—ì„œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ë©ë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\"># í™œì„±í™” ìƒ‰ì¸ì„ ê°€ì ¸ì˜¤ëŠ” ë„ìš°ë¯¸ í•¨ìˆ˜\ndef <span class=\"hljs-title function_\">get_act_idx</span>(cache_dict, act_name, layer):\n    key = (act_name, layer)\n    <span class=\"hljs-keyword\">return</span> cache_dict[utils.<span class=\"hljs-title function_\">get_act_name</span>(*key)]\n\n# ì¤‘ê°„ ì¸µì—ì„œ ìœ í•´ ë° ë¬´í•´ í™œì„±í™”ì˜ í‰ê·  ì°¨ì´ ê³„ì‚°\nactivation_layers = [<span class=\"hljs-string\">\"resid_pre\"</span>, <span class=\"hljs-string\">\"resid_mid\"</span>, <span class=\"hljs-string\">\"resid_post\"</span>]\nactivation_refusals = <span class=\"hljs-title function_\">defaultdict</span>(list)\n\n<span class=\"hljs-keyword\">for</span> layer_num <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-number\">1</span>, model.<span class=\"hljs-property\">cfg</span>.<span class=\"hljs-property\">n_layers</span>):\n    pos = -<span class=\"hljs-number\">1</span>  # ìœ„ì¹˜ ì¸ë±ìŠ¤\n    <span class=\"hljs-keyword\">for</span> layer <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">activation_layers</span>:\n        harmful_mean_act = <span class=\"hljs-title function_\">get_act_idx</span>(harmful, layer, layer_num)[:, pos, :].<span class=\"hljs-title function_\">mean</span>(dim=<span class=\"hljs-number\">0</span>)\n        harmless_mean_act = <span class=\"hljs-title function_\">get_act_idx</span>(harmless, layer, layer_num)[:, pos, :].<span class=\"hljs-title function_\">mean</span>(dim=<span class=\"hljs-number\">0</span>)\n        refusal_dir = harmful_mean_act - harmless_mean_act\n        refusal_dir = refusal_dir / refusal_dir.<span class=\"hljs-title function_\">norm</span>()\n        activation_refusals[layer].<span class=\"hljs-title function_\">append</span>(refusal_dir)\n\nselected_layers = [<span class=\"hljs-string\">\"resid_pre\"</span>]\nactivation_scored = <span class=\"hljs-title function_\">sorted</span>(\n    [\n        activation_refusals[layer][l - <span class=\"hljs-number\">1</span>]\n        <span class=\"hljs-keyword\">for</span> l <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-number\">1</span>, model.<span class=\"hljs-property\">cfg</span>.<span class=\"hljs-property\">n_layers</span>)\n        <span class=\"hljs-keyword\">for</span> layer <span class=\"hljs-keyword\">in</span> selected_layers\n    ],\n    key=lambda <span class=\"hljs-attr\">x</span>: <span class=\"hljs-title function_\">abs</span>(x.<span class=\"hljs-title function_\">mean</span>()),\n    reverse=<span class=\"hljs-title class_\">True</span>,\n)\n</code></pre>\n<p>í”„ë¡œì„¸ìŠ¤ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” ê³„ì‚°í•œ ê±°ì ˆ ë°©í–¥ì„ í‰ê°€í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ìš°ë¦¬ëŠ” ê±°ì ˆ ë°©í–¥ì„ ì¶”ë¡  ì¤‘ ê° ì”ì—¬ ìŠ¤íŠ¸ë¦¼ê³¼ ê° ë¸”ë¡ì— ì ìš©í•  ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒ ì½”ë“œ ìŠ¤ë‹ˆí«ì—ì„œ ë„¤ ê°€ì§€ í…ŒìŠ¤íŠ¸ ìœ í•´ ì§€ì‹œì™€ 20ê°œ ë¸”ë¡(ë˜ëŠ” ë ˆì´ì–´)ì— ëŒ€í•œ ì„¸ëŒ€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">...\n<span class=\"hljs-title class_\">Code</span> snippet ìƒëµ\n...\n</code></pre>\n<p>ìš°ë¦¬ëŠ” evals ë¦¬ìŠ¤íŠ¸ì— ëª¨ë“  ì„¸ëŒ€ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì´ë¥¼ ì¶œë ¥í•˜ê³  ê° ì§€ì‹œì— ëŒ€í•œ ë¬´ê²ì§€ ì•Šì€ ì‘ë‹µì„ ì œê³µí•˜ëŠ” ë ˆì´ì–´(ë¸”ë¡)ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. \"I cannot\" ë° \"I can't\"ë¥¼ í¬í•¨í•˜ëŠ” ì‘ë‹µì€ ì›ì¹˜ ì•ŠëŠ” ë‹µë³€ì„ í•„í„°ë§í•˜ê¸° ìœ„í•´ ìë™ìœ¼ë¡œ ì œì™¸í•©ë‹ˆë‹¤.</p>\n<p>ìœ„ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°, ì´ì „ selected_layers ëª©ë¡ì˜ ë‹¤ë¥¸ ì”ì—¬ ìŠ¤íŠ¸ë¦¼, ë‹¤ë¥¸ ì§€ì‹œ, ì¶”ê°€ì  ë¸”ë¡ ë“±ì„ í…ŒìŠ¤íŠ¸í•˜ê³ ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\"># ì¸ê°„ í‰ê°€ë¥¼ ìœ„í•œ ì„¸ëŒ€ ì¸ì‡„\nblacklist = [<span class=\"hljs-string\">\"I cannot\"</span>, <span class=\"hljs-string\">\"I can't\"</span>]\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-variable constant_\">N_INST_TEST</span>):\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"\\033[1mINSTRUCTION {i}: {harmful_inst_test[i]}\"</span>)\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"\\nBASELINE COMPLETION:\\n{baseline_generations[i]}\\033[0m\"</span>)\n    <span class=\"hljs-keyword\">for</span> layer_candidate <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-variable constant_\">EVAL_N</span>):\n        <span class=\"hljs-keyword\">if</span> not <span class=\"hljs-title function_\">any</span>(word <span class=\"hljs-keyword\">in</span> evals[layer_candidate][i] <span class=\"hljs-keyword\">for</span> word <span class=\"hljs-keyword\">in</span> blacklist):\n            <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"\\n---\\n\\nLAYER CANDIDATE #{layer_candidate} INTERVENTION COMPLETION:\"</span>)\n            <span class=\"hljs-title function_\">print</span>(evals[layer_candidate][i])\n</code></pre>\n<p>ì €ì˜ ê²½ìš°, ë ˆì´ì–´ í›„ë³´ì 9ê°€ ë„¤ ê°€ì§€ ëª…ë ¹ì— ëŒ€í•´ ì„ ì •ì ì´ì§€ ì•Šì€ ë‹µë³€ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ì´ê²ƒì´ ìš°ë¦¬ê°€ ê±°ë¶€ ë°©í–¥ìœ¼ë¡œ ì„ íƒí•  ê²ƒì´ë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ, ë¬´ê²Œ ì§êµí™”ë¥¼ êµ¬í˜„í•˜ì—¬ ëª¨ë¸ì´ ì´ ë°©í–¥ì˜ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì„ ì •ë˜ì§€ ì•Šì€ì§€ë¥¼ í™•ì¸í•˜ë ¤ë©´ ì™„ë£Œëœ ë‚´ìš©ì„ ì¸ì‡„í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">get_orthogonalized_matrix</span>(\n    <span class=\"hljs-attr\">matrix</span>: <span class=\"hljs-title class_\">Float</span>[<span class=\"hljs-title class_\">Tensor</span>, <span class=\"hljs-string\">\"... d_model\"</span>], <span class=\"hljs-attr\">vec</span>: <span class=\"hljs-title class_\">Float</span>[<span class=\"hljs-title class_\">Tensor</span>, <span class=\"hljs-string\">\"d_model\"</span>]\n) -> <span class=\"hljs-title class_\">Float</span>[<span class=\"hljs-title class_\">Tensor</span>, <span class=\"hljs-string\">\"... d_model\"</span>]:\n    proj = (\n        einops.<span class=\"hljs-title function_\">einsum</span>(\n            matrix, vec.<span class=\"hljs-title function_\">view</span>(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>), <span class=\"hljs-string\">\"... d_model, d_model single -> ... single\"</span>\n        )\n        * vec\n    )\n    <span class=\"hljs-keyword\">return</span> matrix - proj\n\n# ê°€ì¥ ë†’ì€ ê±°ë¶€ ë°©í–¥ì„ ê°–ëŠ” ë ˆì´ì–´ ì„ íƒ\n<span class=\"hljs-variable constant_\">LAYER_CANDIDATE</span> = <span class=\"hljs-number\">9</span>\nrefusal_dir = activation_scored[<span class=\"hljs-variable constant_\">LAYER_CANDIDATE</span>]\n\n# ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì§êµí™”\n<span class=\"hljs-keyword\">if</span> refusal_dir.<span class=\"hljs-property\">device</span> != model.<span class=\"hljs-property\">W_E</span>.<span class=\"hljs-property\">device</span>:\n    refusal_dir = refusal_dir.<span class=\"hljs-title function_\">to</span>(model.<span class=\"hljs-property\">W_E</span>.<span class=\"hljs-property\">device</span>)\nmodel.<span class=\"hljs-property\">W_E</span>.<span class=\"hljs-property\">data</span> = <span class=\"hljs-title function_\">get_orthogonalized_matrix</span>(model.<span class=\"hljs-property\">W_E</span>, refusal_dir)\n\n<span class=\"hljs-keyword\">for</span> block <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">tqdm</span>(model.<span class=\"hljs-property\">blocks</span>):\n    <span class=\"hljs-keyword\">if</span> refusal_dir.<span class=\"hljs-property\">device</span> != block.<span class=\"hljs-property\">attn</span>.<span class=\"hljs-property\">W_O</span>.<span class=\"hljs-property\">device</span>:\n        refusal_dir = refusal_dir.<span class=\"hljs-title function_\">to</span>(block.<span class=\"hljs-property\">attn</span>.<span class=\"hljs-property\">W_O</span>.<span class=\"hljs-property\">device</span>)\n    block.<span class=\"hljs-property\">attn</span>.<span class=\"hljs-property\">W_O</span>.<span class=\"hljs-property\">data</span> = <span class=\"hljs-title function_\">get_orthogonalized_matrix</span>(block.<span class=\"hljs-property\">attn</span>.<span class=\"hljs-property\">W_O</span>, refusal_dir)\n    block.<span class=\"hljs-property\">mlp</span>.<span class=\"hljs-property\">W_out</span>.<span class=\"hljs-property\">data</span> = <span class=\"hljs-title function_\">get_orthogonalized_matrix</span>(block.<span class=\"hljs-property\">mlp</span>.<span class=\"hljs-property\">W_out</span>, refusal_dir)\n\n# ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±\northogonalized_generations = <span class=\"hljs-title function_\">get_generations</span>(\n    model, tokenizer, harmful_inst_test[:<span class=\"hljs-variable constant_\">N_INST_TEST</span>], fwd_hooks=[]\n)\n\n# ì„¸ëŒ€ ì¶œë ¥\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-variable constant_\">N_INST_TEST</span>):\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-title function_\">len</span>(baseline_generations) > <span class=\"hljs-attr\">i</span>:\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"INSTRUCTION {i}: {harmful_inst_test[i]}\"</span>)\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"\\033[92mBASELINE COMPLETION:\\n{baseline_generations[i]}\"</span>)\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"\\033[91mINTERVENTION COMPLETION:\\n{evals[LAYER_CANDIDATE][i]}\"</span>)\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"\\033[95mORTHOGONALIZED COMPLETION:\\n{orthogonalized_generations[i]}\\n\"</span>)\n</code></pre>\n<p>ì´ì œ ëª¨ë¸ì„ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ Hugging Face í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ HF í—ˆë¸Œì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.</p>\n<pre><code class=\"hljs language-json\"># ëª¨ë¸ì„ ë‹¤ì‹œ HF ë³´ì•ˆ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤\nhf_model = AutoModelForCausalLM.from_pretrained(MODEL_TYPE<span class=\"hljs-punctuation\">,</span> torch_dtype=torch.bfloat16)\nlm_model = hf_model.model\n\nstate_dict = model.state_dict()\nlm_model.embed_tokens.weight = torch.nn.Parameter(state_dict<span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"embed.W_E\"</span><span class=\"hljs-punctuation\">]</span>.cpu())\nfor l in range(model.cfg.n_layers)<span class=\"hljs-punctuation\">:</span>\n    lm_model.layers<span class=\"hljs-punctuation\">[</span>l<span class=\"hljs-punctuation\">]</span>.self_attn.o_proj.weight = torch.nn.Parameter(\n        einops.rearrange(\n            state_dict<span class=\"hljs-punctuation\">[</span>f<span class=\"hljs-string\">\"blocks.{l}.attn.W_O\"</span><span class=\"hljs-punctuation\">]</span><span class=\"hljs-punctuation\">,</span> <span class=\"hljs-string\">\"n h m->m (n h)\"</span><span class=\"hljs-punctuation\">,</span> n=model.cfg.n_heads\n        ).contiguous()\n    )\n    lm_model.layers<span class=\"hljs-punctuation\">[</span>l<span class=\"hljs-punctuation\">]</span>.mlp.down_proj.weight = torch.nn.Parameter(\n        torch.transpose(state_dict<span class=\"hljs-punctuation\">[</span>f<span class=\"hljs-string\">\"blocks.{l}.mlp.W_out\"</span><span class=\"hljs-punctuation\">]</span><span class=\"hljs-punctuation\">,</span> <span class=\"hljs-number\">0</span><span class=\"hljs-punctuation\">,</span> <span class=\"hljs-number\">1</span>).contiguous()\n    )\n\nhf_model.push_to_hub(f<span class=\"hljs-string\">\"{MODEL_ID}-abliterated\"</span>)\n</code></pre>\n<h1>âš–ï¸ DPO Fine-Tuning</h1>\n<p>ì´ì „ ì„¹ì…˜ì˜ abliterated ë° ì†ŒìŠ¤ ëª¨ë¸ì„ Open LLM Leaderboard ë° Nousì˜ ë²¤ì¹˜ë§ˆí¬ ìŠ¤ìœ„íŠ¸ì—ì„œ í‰ê°€í–ˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì— ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤:</p>\n<p>ë³´ì‹œë‹¤ì‹œí”¼, ì›ë³¸ ëª¨ë¸ì€ Llama 3 8B Instructë³´ë‹¤ í˜„ì €í•˜ê²Œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì ˆì‚­ëœ ë²„ì „ì—ì„œ ì„±ëŠ¥ í•˜ë½ì„ ê´€ì°°í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ˆì‚­ ê³¼ì •ì€ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ë©´ì„œë„ ëª¨ë¸ì˜ í’ˆì§ˆì„ ì €í•˜ì‹œí‚¨ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.</p>\n<p>ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ìš°ë¦¬ì˜ ì ˆì‚­ëœ ëª¨ë¸ì„ ì¶”ê°€ë¡œ í›ˆë ¨í•˜ì—¬ íšŒë³µì‹œí‚¤ëŠ” ì•„ì´ë””ì–´ê°€ ìˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ì„¸ë°€ ì¡°ì •ëœ ëª¨ë¸ë“¤ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ Llama 3 8B Instructì€ ì§€ë„ í•™ìŠµ ì„¸ë°€ ì¡°ì •ì— ìˆì–´ì„œ ê½¤ ì·¨ì•½í•©ë‹ˆë‹¤. ì¶”ê°€ì ì¸ SFTëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦´ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.</p>\n<p>ëŒ€ì²´ë¡œ, ì„ í˜¸ ë§ì¶¤ì´ ìƒë‹¹íˆ ê°€ë³ê³  ìš°ë¦¬ì˜ ì ˆì‚­ëœ ëª¨ë¸ì„ ë‡Œê°œë°•í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. DPOëŠ” ì‚¬ìš©í•˜ê¸° ì‰½ê³  ìš°ìˆ˜í•œ ì¶”ì  ë ˆì½”ë“œë¡œ ì—¬ê¸°ì„œ ì¢‹ì€ í›„ë³´ì…ë‹ˆë‹¤. ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ mlabonne/orpo-dpo-mix-40k ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ëŠ” LazyAxolotl (Axolotlì„ ë§Œë“¤ì–´ ì¤€ Wing Lianì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤)ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì— ì‚¬ìš©í•œ êµ¬ì„±ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-attr\">base_model</span>: mlabonne/<span class=\"hljs-title class_\">Daredevil</span>-8B-abliterated\n<span class=\"hljs-attr\">model_type</span>: <span class=\"hljs-title class_\">LlamaForCausalLM</span>\n<span class=\"hljs-attr\">tokenizer_type</span>: <span class=\"hljs-title class_\">AutoTokenizer</span>\n\n<span class=\"hljs-attr\">load_in_8bit</span>: <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-attr\">load_in_4bit</span>: <span class=\"hljs-literal\">true</span>\n<span class=\"hljs-attr\">strict</span>: <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-attr\">save_safetensors</span>: <span class=\"hljs-literal\">true</span>\n\n<span class=\"hljs-attr\">rl</span>: dpo\n<span class=\"hljs-attr\">chat_template</span>: chatml\n<span class=\"hljs-attr\">datasets</span>:\n  - <span class=\"hljs-attr\">path</span>: mlabonne/orpo-dpo-mix-40k\n    <span class=\"hljs-attr\">split</span>: train\n    <span class=\"hljs-attr\">type</span>: chatml.<span class=\"hljs-property\">intel</span>\n\n<span class=\"hljs-attr\">dataset_prepared_path</span>:\n<span class=\"hljs-attr\">val_set_size</span>: <span class=\"hljs-number\">0.0</span>\n<span class=\"hljs-attr\">output_dir</span>: ./out\n\n<span class=\"hljs-attr\">adapter</span>: qlora\n<span class=\"hljs-attr\">lora_model_dir</span>:\n\n<span class=\"hljs-attr\">sequence_len</span>: <span class=\"hljs-number\">2048</span>\n<span class=\"hljs-attr\">sample_packing</span>: <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-attr\">pad_to_sequence_len</span>: <span class=\"hljs-literal\">false</span>\n\n<span class=\"hljs-attr\">lora_r</span>: <span class=\"hljs-number\">64</span>\n<span class=\"hljs-attr\">lora_alpha</span>: <span class=\"hljs-number\">32</span>\n<span class=\"hljs-attr\">lora_dropout</span>: <span class=\"hljs-number\">0.05</span>\n<span class=\"hljs-attr\">lora_target_linear</span>: <span class=\"hljs-literal\">true</span>\n<span class=\"hljs-attr\">lora_fan_in_fan_out</span>:\n\n<span class=\"hljs-attr\">wandb_project</span>: axolotl\n<span class=\"hljs-attr\">wandb_entity</span>:\n<span class=\"hljs-attr\">wandb_watch</span>:\n<span class=\"hljs-attr\">wandb_name</span>:\n<span class=\"hljs-attr\">wandb_log_model</span>:\n\n<span class=\"hljs-attr\">gradient_accumulation_steps</span>: <span class=\"hljs-number\">8</span>\n<span class=\"hljs-attr\">micro_batch_size</span>: <span class=\"hljs-number\">1</span>\n<span class=\"hljs-attr\">num_epochs</span>: <span class=\"hljs-number\">1</span>\n<span class=\"hljs-attr\">optimizer</span>: paged_adamw_8bit\n<span class=\"hljs-attr\">lr_scheduler</span>: cosine\n<span class=\"hljs-attr\">learning_rate</span>: <span class=\"hljs-number\">5e-6</span>\n<span class=\"hljs-attr\">train_on_inputs</span>: <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-attr\">group_by_length</span>: <span class=\"hljs-literal\">false</span>\n... (ì´ì–´ì§)\n</code></pre>\n<p>6xA6000 GPUì™€ DeepSpeed ZeRO-2ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í–ˆì–´ìš”. í›ˆë ¨ì—ëŠ” ì•½ 6ì‹œê°„ 45ë¶„ì´ ì†Œìš”ë˜ì—ˆë‹µë‹ˆë‹¤. W&#x26;Bì—ì„œ ì–»ì€ í›ˆë ¨ ê³¡ì„ ì„ ì—¬ê¸°ì— ê°€ì ¸ì™”ì–´ìš”:</p>\n<p>DPOë¥¼ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•œ mlabonne/NeuralDaredevil-8B-abliterated ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆì–´ìš”. ì €í¬ê°€ ì•ì„œ ì§€ì›Œë²„ë¦° ë²„ì „ì„ ìˆ˜ì •í–ˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë™ì¼í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ í‰ê°€í–ˆì–´ìš”:</p>\n<p><img src=\"/assets/img/2024-06-19-UncensoranyLLMwithabliteration_3.png\" alt=\"í›ˆë ¨ ê³¡ì„ \"></p>\n<p>ì´ ì¶”ê°€ í›ˆë ¨ì„ í†µí•´ ì§€ì›Œì§„ ì˜í–¥ ëŒ€ë¶€ë¶„ì„ íšŒë³µí•  ìˆ˜ ìˆì—ˆì–´ìš”. ëª¨ë¸ì´ ê°œì„ ë˜ì§€ ì•ŠëŠ” í•œ ì˜ì—­ì€ GSM8K, ìˆ˜í•™ ë°ì´í„° ì„¸íŠ¸, ì¸ë°ìš”, ì´ëŠ” orpo-dpo-mix-40kê°€ ë” ë§ì€ ìˆ˜í•™ ìƒ˜í”Œì„ í•„ìš”ë¡œ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•  ìˆ˜ ìˆì–´ìš”.</p>\n<p>ìµœì¢… ëª¨ë¸ì€ 8B ë²”ì£¼ì—ì„œ ìµœì²¨ë‹¨ ì„±ëŠ¥ì„ ìë‘í•˜ëŠ” ë¯¸ê²€ì—´ LLMì…ë‹ˆë‹¤. í•„í„°ë§ì´ í•„ìš” ì—†ì„ ë•ŒëŠ” Llama 3 8B Instructì˜ ê°œì„ ëœ ë²„ì „ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤. LM Studioì—ì„œ GGUFì™€ ê°™ì€ ì–‘ìí™”ëœ ë²„ì „ì„ ì‚¬ìš©í•´ ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</p>\n<h1>ê²°ë¡ </h1>\n<p>ì´ ê¸€ì—ì„œëŠ” ì†Œëª…í™”(abliteration) ê°œë…ì„ ì†Œê°œí–ˆìŠµë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ëª¨ë¸ì˜ í™œì„±í™”ë¥¼ í•´ë¡­ê³  í•´ë¥¼ ë¼ì¹˜ì§€ ì•ŠëŠ” í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•˜ì—¬ ê±°ë¶€ ë°©í–¥ì„ ê³„ì‚°í•˜ê³ , ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ìˆ˜ì •í•˜ì—¬ ê±°ë¶€ë¥¼ ê·¸ë§Œ ë‚´ë³´ë‚¼ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ì•ˆì „ ì„¸ë°€ì¡°ì •ì˜ ì·¨ì•½ì„±ì„ ë³´ì—¬ì£¼ë©° ìœ¤ë¦¬ì  ê³ ë ¤ ì‚¬í•­ì„ ë˜ì§€ê³  ìˆìŠµë‹ˆë‹¤.</p>\n<p>ìš°ë¦¬ëŠ” Daredevil-8Bì— ì†Œëª…í™”ë¥¼ ì ìš©í•˜ì—¬ í•„í„°ë§ì„ í•´ì œí–ˆì§€ë§Œ, ì´ë¡œ ì¸í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ í›„ DPOë¥¼ ì‚¬ìš©í•˜ì—¬ NeuralDaredevil-8B ëª¨ë¸ì„ ìƒì„±í•˜ì—¬ ì™„ì „íˆ ë¯¸ê²€ì—´ì´ê³  ê³ í’ˆì§ˆì˜ 8B LLMì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì†Œëª…í™”ëŠ” ì •ë ¬ ì œê±°ì— êµ­í•œë˜ì§€ ì•Šìœ¼ë©°, ë‹¤ì‹œ êµìœ¡ ì—†ì´ ì„¸ë°€ ì¡°ì •ì˜ ì¼ì¢…ìœ¼ë¡œ ê°„ì£¼í•´ì•¼ í•©ë‹ˆë‹¤. ì‹¤ì œë¡œ MopeyMuleì˜ FailSpyì˜ ê²½ìš°ì²˜ëŸ¼ ì¢Œì ˆì ì¸ ëŒ€í™” ìŠ¤íƒ€ì¼ì„ ì±„íƒí•˜ëŠ” ê²ƒê³¼ ê°™ì´ ì°½ì˜ì ìœ¼ë¡œ ë‹¤ë¥¸ ëª©í‘œì—ë„ ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<p>ì´ ê¸°ì‚¬ê°€ ë§ˆìŒì— ë“¤ì—ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”. ë” ë§ì€ ë‚´ìš©ì„ ë³´ê³  ì‹¶ë‹¤ë©´ Hugging Faceì™€ Twitterì˜ @maximelabonneë¥¼ íŒ”ë¡œìš°í•´ ì£¼ì„¸ìš”.</p>\n<h1>ì°¸ê³  ìë£Œ</h1>\n<ul>\n<li>FailSpy, â€œabliterator library,â€ GitHub, 2024.</li>\n<li>Andy Arditi, Oscar Obeso, Aaquib111, wesg, Neel Nanda, â€œRefusal in LLMs is mediated by a single direction,â€ Lesswrong, 2024.</li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}