{"pageProps":{"post":{"title":"ìœ íŠœë¸Œ íŠ¸ë Œë“œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ Airflow, Spark, S3 ë° Dockerë¥¼ ì´ìš©í•œ ETL","description":"","date":"2024-06-19 09:37","slug":"2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker","content":"\n\nì´ ê¸°ì‚¬ì—ì„œëŠ” Apache Airflowì™€ PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ ETL (ì¶”ì¶œ, ë³€í™˜, ë¡œë“œ) íŒŒì´í”„ë¼ì¸ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. ì´ íŒŒì´í”„ë¼ì¸ì€ YouTube Data APIì—ì„œ íŠ¸ë Œë“œ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì²˜ë¦¬í•œ í›„ ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ S3ì— ì €ì¥í•  ê²ƒì…ë‹ˆë‹¤.\n\nTwitter APIë¥¼ ì‚¬ìš©í•œ íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì£¼ëŠ” Darshil Parmarì˜ YouTube ë¹„ë””ì˜¤ë¥¼ ì‹œì²­í•œ í›„, ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ì— ë„ì „í•˜ê¸°ë¡œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Twitter APIì˜ ê°€ê²© ì •ì±… ë³€ê²½ìœ¼ë¡œ ì¸í•´, ì‹œì²­ìê°€ YouTube Data APIë¥¼ ëŒ€ì²´ë¡œ ì œì•ˆí–ˆê³  ì´ê²ƒì´ ì œ í¥ë¯¸ë¥¼ ìê·¹í–ˆìŠµë‹ˆë‹¤.\n\ní”„ë¡œì íŠ¸ì— ëŒì…í•˜ê¸° ì „ì— ë‘ ê°€ì§€ í•„ìˆ˜ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤:\n\n1. Youtube Data API í‚¤ íšë“\n\n<div class=\"content-ad\"></div>\n\n- Google Developers Consoleì„ ë°©ë¬¸í•´ ì£¼ì„¸ìš”.\n- ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.\n- \"YouTube Data API\"ë¥¼ ê²€ìƒ‰í•˜ê³  í™œì„±í™”í•´ ì£¼ì„¸ìš”.\n- ìƒˆ ìê²© ì¦ëª…ì„ ìƒì„±í•˜ê³  í”„ë¡œì íŠ¸ì—ì„œ ë‚˜ì¤‘ì— ì‚¬ìš©í•  API í‚¤ë¥¼ ë³µì‚¬í•´ ì£¼ì„¸ìš”.\n\nìì„¸í•œ ì§€ì¹¨ì€ YouTube Data API ì‹œì‘ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•´ ì£¼ì„¸ìš”.\n\n2. AWS ì•¡ì„¸ìŠ¤ í‚¤ ID ë° ë¹„ë°€ ì•¡ì„¸ìŠ¤ í‚¤ íšë“\n\n- AWS Management Consoleì— ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.\n- IAM(Identity and Access Management) ì„¹ì…˜ìœ¼ë¡œ ì´ë™í•˜ê³  ìƒˆ ì‚¬ìš©ìë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.\n- í•„ìš”í•œ S3 ì•¡ì„¸ìŠ¤ ì •ì±…ì„ ë¶€ì—¬í•˜ê³  ì•¡ì„¸ìŠ¤ í‚¤ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.\n- í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  ì•¡ì„¸ìŠ¤ í‚¤ IDì™€ ë¹„ë°€ ì•¡ì„¸ìŠ¤ í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ì €ì¥í•´ ì£¼ì„¸ìš”.\n\n<div class=\"content-ad\"></div>\n\nì´ì œ ì‹¤ì œ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤! ì¤€ë¹„ëë‚˜ìš” ì—¬ëŸ¬ë¶„!!\n\n![YouTube Trend Analysis Pipeline ETL with Airflow, Spark, S3, and Docker](/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_0.png)\n\nì´ ê¸€ì€ 4ê°€ì§€ ì£¼ìš” ë‹¨ê³„ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ìš”:\n\n- ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜ ë° ì„¤ì •\n- Youtube Data APIì—ì„œ ë°ì´í„° ì¶”ì¶œ\n- PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë³€í™˜\n- AWS S3ë¡œ ë°ì´í„° ë¡œë“œ\n\n<div class=\"content-ad\"></div>\n\n# 1. ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜ ë° ì„¤ì •:\n\n- VS Code â€” [VS Code ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜](https://code.visualstudio.com/).\n- Docker Desktop â€” [Docker Desktop ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜](https://www.docker.com/products/docker-desktop).\n- (ì„ íƒì‚¬í•­) Windows Subsystem for Linux (WSL) â€” ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì— ì‚¬ìš©ë˜ëŠ” Apache Airflow ë° PySparkì™€ ê°™ì€ ë§ì€ ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ Unix ê³„ì—´ ì‹œìŠ¤í…œì„ ìœ„í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë„êµ¬ë¥¼ Windowsì—ì„œ ì‚¬ìš©í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” í˜¸í™˜ì„± ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ WSLì„ í†µí•´ ë„¤ì´í‹°ë¸Œ Linux í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n  - ` ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ PowerShellì„ ì—½ë‹ˆë‹¤.\n  - ` ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”: wsl --install.\n  - ` ëª…ë ¹ì— ë”°ë¼ WSLì„ ì„¤ì¹˜í•˜ê³  Microsoft Storeì—ì„œ Linux ë°°í¬íŒ(ì˜ˆ: Ubuntu)ì„ ì„ íƒí•˜ì„¸ìš”.\n  - ` Linux ë°°í¬íŒì— ì‚¬ìš©ì ì´ë¦„ ë° ì•”í˜¸ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\n\nì´ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° WSLì´ ë°˜ë“œì‹œ í•„ìš”í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. Docker Desktopì€ Windowsì—ì„œ ë„¤ì´í‹°ë¸Œë¡œ ì‹¤í–‰ë  ìˆ˜ ìˆìœ¼ë©° Docker ìì²´ê°€ ê´€ë¦¬í•˜ëŠ” ê°€ë²¼ìš´ Linux ê°€ìƒ ë¨¸ì‹ (VM)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Docker Desktopê³¼ í•¨ê»˜ WSLì„ ì‚¬ìš©í•˜ë©´ Windowsì—ì„œ ì§ì ‘ Linux ëª…ë ¹ ë° ì‘ì—…ì„ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ ë³´ë‹¤ ë„¤ì´í‹°ë¸Œí•œ ê°œë°œ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n\nì´ì œ ì„¤ì •ì„ ì‹œì‘í•´ ë´…ì‹œë‹¤.\n\n<div class=\"content-ad\"></div>\n\në¶€ë¶„ 1 â€” ë„ì»¤ ì´ë¯¸ì§€ ë§Œë“¤ê¸°\n\n- í”„ë¡œì íŠ¸ìš© ìƒˆ í´ë”ë¥¼ ë§Œë“¤ê³  \"Airflow-Project\"ë¡œ ì´ë¦„ì„ ì§€ì–´ì£¼ì„¸ìš”.\n- í•´ë‹¹ í´ë”ì—ì„œ ëª…ë ¹ í”„ë¡¬í”„íŠ¸ë¥¼ ì—½ë‹ˆë‹¤.\n- ëª…ë ¹ í”„ë¡¬í”„íŠ¸ì—ì„œ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:\n\n```bash\ncode .\n```\n\n- ì´ ëª…ë ¹ì€ VS Codeì—ì„œ í•´ë‹¹ í´ë”ë¥¼ í”„ë¡œì íŠ¸ë¡œ ì—½ë‹ˆë‹¤.\n- VS Codeì—ì„œ \"dockerfile\"ì´ë¼ëŠ” ìƒˆ íŒŒì¼ì„ ë§Œë“¤ê³  ì•„ë˜ ì½”ë“œë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:\n\n<div class=\"content-ad\"></div>\n\n```js\nFROM apache/airflow:latest\n\n# ì‹œìŠ¤í…œ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ê¸° ìœ„í•´ ë£¨íŠ¸ ì‚¬ìš©ìë¡œ ì „í™˜í•©ë‹ˆë‹¤\nUSER root\n\n# git, OpenJDKë¥¼ ì„¤ì¹˜í•˜ê³  apt ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤\nRUN apt-get update && \\\n    apt-get -y install git default-jdk && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\n# Python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê¸° ìœ„í•´ airflow ì‚¬ìš©ìë¡œ ì „í™˜í•©ë‹ˆë‹¤\nUSER airflow\n\n# í•„ìš”í•œ Python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤\nRUN pip install --no-cache-dir pyspark pandas google-api-python-client emoji boto3\n```\n\nì´ Docker íŒŒì¼ì€ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  íŒ¨í‚¤ì§€ë¥¼ í¬í•¨í•˜ê³  ìˆì–´ìš”.\n\n- íŒŒì¼ì„ ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ìœ¼ë¡œ í´ë¦­í•˜ê³  VS Codeì—ì„œ \"ì´ë¯¸ì§€ ë¹Œë“œ\" ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”. ì´ë¦„ì„ ì…ë ¥í•˜ë¼ëŠ” í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚˜ë©´ \"airflow-project\"ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì´ ëª…ë ¹ì€ Docker ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ docker-compose.yml íŒŒì¼ì„ ìƒì„±í•˜ê³  ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë„ë¡ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n\n(ì¬ë¯¸ìˆëŠ” ì‚¬ì‹¤: íŒŒì¼ì—ì„œ Python ì„¤ì¹˜ê°€ ì—†ëŠ” ì´ìœ  ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ì‹¤ì œë¡œ Dockerfileì—ì„œ ì‚¬ìš©ëœ ê¸°ë³¸ ì´ë¯¸ì§€ì¸ apache/airflow:latestì—ëŠ” Pythonì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ìš”. ì™œëƒí•˜ë©´ Airflow ìì²´ê°€ Pythonìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ì£¼ë¡œ ì›Œí¬í”Œë¡œ ë° ì‘ì—… ì •ì˜ì— Pythonì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë”°ë¼ì„œ Dockerfileì—ì„œ ë³„ë„ë¡œ Pythonì„ ì„¤ì¹˜í•  í•„ìš”ê°€ ì—†ë‹µë‹ˆë‹¤!)\n\n<div class=\"content-ad\"></div>\n\níŒŒíŠ¸ 2 â€” ë„ì»¤ ì»´í¬ì¦ˆ íŒŒì¼ ìƒì„±í•˜ê¸°\n\në„ì»¤ ì»´í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ë©´ ë©€í‹° ì»¨í…Œì´ë„ˆ ë„ì»¤ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¨ì¼ ëª…ë ¹ìœ¼ë¡œ ì—¬ëŸ¬ ë„ì»¤ ì»¨í…Œì´ë„ˆë¥¼ ì •ì˜í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìœ¼ë©° ê° ì„œë¹„ìŠ¤ì˜ í™˜ê²½ ë³€ìˆ˜, ë³¼ë¥¨, í¬íŠ¸ ë° ê¸°íƒ€ ì„¤ì •ì„ ëª…í™•í•˜ê³  ì¡°ì§ì ì¸ ë°©ì‹ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„ì»¤ ì»´í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¨ì¼ ëª…ë ¹ì–´ì¸ docker-compose up ë˜ëŠ” docker-compose downì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ë¥¼ ì‰½ê²Œ ì‹œì‘, ì¤‘ì§€ ë° ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n- \"docker-compose.yml\" íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ íŒŒì¼ì— ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤:\n\n```js\nversion: '3'\nservices:\n\n  airflowproject:\n    image: airflow-project:latest\n    environment:\n      - AWS_ACCESS_KEY_ID=your-aws-access-key\n      - AWS_SECRET_ACCESS_KEY=your-aws-secret-access-key\n      - YOUTUBE_API_KEY=your-youtube-api-key\n    volumes:\n      - ./airflow:/opt/airflow\n    ports:\n      - \"8080:8080\"\n    command: airflow standalone\n```\n\n<div class=\"content-ad\"></div>\n\n- ì´ì œ íŒŒì¼ì„ ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ìœ¼ë¡œ í´ë¦­í•œ í›„ VS Codeì—ì„œ 'Compose Up' ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”. í™˜ê²½ì„ ì„¤ì •í•˜ê¸° ìœ„í•´ í´ë¦­í•˜ì„¸ìš”.\n- ê¹œì§ ë†€ë„ ì¼ì´ ë²Œì–´ì¡Œì–´ìš”! ì´ ì‘ì—…ì„ ì™„ë£Œí•œ í›„ì—ëŠ” VS Code í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì— \"airflow\"ë¼ëŠ” ìƒˆ í´ë”ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nDocker ë°ìŠ¤í¬í†±ì„ ì—´ì–´ì„œ ëª¨ë“  ê²ƒì´ ì˜¬ë°”ë¥´ê²Œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì˜¬ë°”ë¥´ê²Œ ì™„ë£Œëœ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ì´ í‘œì‹œë©ë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_1.png)\n\n- ì´ì œ Airflow í”„ë¡œì íŠ¸ë¥¼ í´ë¦­í•˜ì—¬ Airflowê°€ 8080 í¬íŠ¸ì—ì„œ ì‹¤í–‰ ì¤‘ì„ì„ ë‚˜íƒ€ë‚´ëŠ” ë¡œê·¸ê°€ í‘œì‹œë˜ëŠ” í™”ë©´ì„ ì—½ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_2.png)\n\n- í¬íŠ¸ë¥¼ í´ë¦­í•˜ë©´ Airflow ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤. ì´ ë§í¬ë¥¼ ì²˜ìŒ ì—´ì–´ë³´ëŠ” ê²½ìš° ìê²© ì¦ëª…ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.\n- ì‚¬ìš©ì ì´ë¦„ì€ \"admin\"ì´ê³  ë¹„ë°€ë²ˆí˜¸ëŠ” compose up ëª…ë ¹ì„ ì‹¤í–‰í•œ í›„ ìƒì„±ëœ Airflow í´ë” ë‚´ì˜ \"standalone_admin_password.txt\" íŒŒì¼ì— ìˆìŠµë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_3.png)\n\n- ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ ìê²© ì¦ëª…ì„ ì…ë ¥í•œ í›„, ë¡œì»¬ í˜¸ìŠ¤íŠ¸ì—ì„œ Airflowê°€ ì‹¤í–‰ ì¤‘ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤:\n\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_4.png\" />\n\në‹¹ì‹ ì˜ í™˜ê²½ ì„¤ì • ì™„ë£Œì…ë‹ˆë‹¤! íœ´â€•!!\n\n# 2. YouTube ë°ì´í„° APIì—ì„œ ë°ì´í„° ì¶”ì¶œí•˜ê¸°:\n\n<div class=\"content-ad\"></div>\n\n- Airflow í´ë” ì•„ë˜ì— \"dags\"ë¼ëŠ” ì´ë¦„ì˜ í´ë”ë¥¼ ë§Œë“¤ê³ , dags í´ë” ì•„ë˜ì— \"youtube_etl_dag.py\"ë¼ëŠ” íŒŒì´ì¬ íŒŒì¼ì„ ë§Œë“­ë‹ˆë‹¤.\n- ì´ì œ \"youtube_etl_dag.py\" íŒŒì¼ì— ë‹¤ìŒì„ importí•˜ì„¸ìš”.\n\n```js\nimport logging\nimport os\nimport re\nimport shutil\nfrom datetime import datetime, timedelta\n\nimport boto3\nimport emoji\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, to_date, udf\nfrom pyspark.sql.types import (DateType, IntegerType, LongType, StringType,\n                               StructField, StructType)\n\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\n```\n\n- ì´ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° ìœ„ì˜ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤(ì½”ë“œ ì‘ì„±ì„ ì‹œì‘í•˜ë©´ ëª¨ë‘ ìœ ìš©í•´ì§‘ë‹ˆë‹¤)\n- VS Codeì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ëª¨ë“  ì¢…ì†ì„±ì´ ë„ì»¤ì— ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ ë¡œì»¬ ë¨¸ì‹ ì—ëŠ” ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šê¸° ë•Œë¬¸ì´ë¯€ë¡œ ì‹ ê²½ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.\n- Airflowì—ì„œ êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ í™”ë©´ ìƒë‹¨ì— í‘œì‹œë˜ê³ , ë…¼ë¦¬ ì˜¤ë¥˜/ì˜ˆì™¸ëŠ” Airflow ë¡œê·¸ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n```js\n# DAGì™€ ê¸°ë³¸ ì¸ìˆ˜ ì •ì˜\ndefault_args = {\n    'owner': 'airflow',  # DAG ì†Œìœ ì\n    'depends_on_past': False,  # ê³¼ê±° DAG ì‹¤í–‰ì— ì¢…ì†í•˜ëŠ”ì§€ ì—¬ë¶€\n    'email_on_failure': False,  # ì‹¤íŒ¨ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    'email_on_retry': False,  # ì¬ì‹œë„ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    'retries': 1,  # ì¬ì‹œë„ íšŸìˆ˜\n    'retry_delay': timedelta(minutes=5),  # ì¬ì‹œë„ ê°„ì˜ ì§€ì—° ì‹œê°„\n     'start_date': datetime(2023, 6, 10, 0, 0, 0),  # ë§¤ì¼ ìì •(00:00) UTCì— ì‹¤í–‰\n}\n\ndag = DAG(\n    'youtube_etl_dag',  # DAG ì‹ë³„ì\n    default_args=default_args,  # ê¸°ë³¸ ì¸ìˆ˜ í• ë‹¹\n    description='ê°„ë‹¨í•œ ETL DAG',  # DAG ì„¤ëª…\n    schedule_interval=timedelta(days=1),  # ì¼ë³„ ìŠ¤ì¼€ì¤„ ê°„ê²©\n    catchup=False,  # ëˆ„ë½ëœ DAG ì‹¤í–‰ì„ ë³µêµ¬í•˜ì§€ ì•ŠìŒ\n)\n```  \n\n<div class=\"content-ad\"></div>\n\në§¤ì¼ ìì •(0ì‹œ)ì— ì‹¤í–‰ë˜ëŠ” DAGì¸ 'youtube_etl_dag'ì„ ì •ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ DAGì€ Airflowì—ì„œ ê´€ë¦¬ ë° íŠ¸ë¦¬ê±°ë˜ë©°, VS Codeì—ì„œ ë³„ë„ë¡œ ì‹¤í–‰í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. Python íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•˜ë©´ Airflowì—ì„œ ìë™ìœ¼ë¡œ ë³€ê²½ ì‚¬í•­ì„ ê°ì§€í•˜ê³  ë°˜ì˜í•  ê²ƒì…ë‹ˆë‹¤.\n\ní˜„ì¬ Airflowì—ëŠ” DAGì´ í‘œì‹œë˜ì§€ë§Œ ì•„ì§ ì •ì˜ëœ ì‘ì—…ì´ ì—†ì–´ì„œ ì–´ë–¤ ì‘ì—…ë„ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. DAGë¥¼ ê¸°ëŠ¥ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ë°ì´í„° ì¶”ì¶œ ì‘ì—…ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤.\n\n```js\n# YouTube APIì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ Python callable í•¨ìˆ˜\ndef extract_data(**kwargs):\n    api_key = kwargs['api_key']\n    region_codes = kwargs['region_codes']\n    category_ids = kwargs['category_ids']\n    \n    df_trending_videos = fetch_data(api_key, region_codes, category_ids)\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    output_path = f'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'\n    # DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥\n    df_trending_videos.to_csv(output_path, index=False)\n\ndef fetch_data(api_key, region_codes, category_ids):\n    \"\"\"\n    YouTube APIì—ì„œ ì—¬ëŸ¬ ë‚˜ë¼ì™€ ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ë™ì˜ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n    \"\"\"\n    # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n    video_data = []\n\n    # YouTube API ì„œë¹„ìŠ¤ ë¹Œë“œ\n    youtube = build('youtube', 'v3', developerKey=api_key)\n\n    for region_code in region_codes:\n        for category_id in category_ids:\n            # ê° ì§€ì—­ ë° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ next_page_tokenì„ Noneìœ¼ë¡œ ì´ˆê¸°í™”\n            next_page_token = None\n            while True:\n                # ì¸ê¸° ë™ì˜ìƒì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ YouTube APIì— ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\n                request = youtube.videos().list(\n                    part='snippet,contentDetails,statistics',\n                    chart='mostPopular',\n                    regionCode=region_code,\n                    videoCategoryId=category_id,\n                    maxResults=50,\n                    pageToken=next_page_token\n                )\n                response = request.execute()\n                videos = response['items']\n\n                # ê° ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ê³  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n                for video in videos:\n                    video_info = {\n                        'region_code': region_code,\n                        'category_id': category_id,\n                        'video_id': video['id'],\n                        'title': video['snippet']['title'],\n                        'published_at': video['snippet']['publishedAt'],\n                        'view_count': int(video['statistics'].get('viewCount', 0)),\n                        'like_count': int(video['statistics'].get('likeCount', 0)),\n                        'comment_count': int(video['statistics'].get('commentCount', 0)),\n                        'channel_title': video['snippet']['channelTitle']\n                    }\n                    video_data.append(video_info)\n\n                # ê²°ê³¼ì˜ ë” ë§ì€ í˜ì´ì§€ê°€ ìˆëŠ” ê²½ìš° ë‹¤ìŒ í˜ì´ì§€ í† í°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n                next_page_token = response.get('nextPageToken')\n                if not next_page_token:\n                    break\n\n    return pd.DataFrame(video_data)\n\n# DAGë¥¼ ìœ„í•œ ë°ì´í„° ì¶”ì¶œ ì‘ì—… ì •ì˜\nextract_task = PythonOperator(\n    task_id='extract_data_from_youtube_api',\n    python_callable=extract_data,\n    op_kwargs={\n        'api_key': os.getenv('YOUTUBE_API_KEY'),\n        'region_codes': ['US', 'GB', 'IN', 'AU', 'NZ'],\n        'category_ids': ['1', '2', '10', '15', '20', '22', '23']\n    },\n    dag=dag,\n)\n\nextract_task # ì´ ì‘ì—…ì„ ì‹¤í–‰í•˜ë„ë¡ DAGë¥¼ ì„¤ì •í•¨\n```\n\nì´ ì½”ë“œì—ì„œ ë‘ ê°€ì§€ ì£¼ìš” ì‘ì—…ì´ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤:\n\n<div class=\"content-ad\"></div>\n\n- DAGì— extract_taskë¼ëŠ” ì‘ì—…ì„ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤.\n- extract_taskì—ì„œ í˜¸ì¶œë˜ëŠ” callable í•¨ìˆ˜ì¸ extract_dataë¥¼ ì •ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” YouTube Data APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ \"Youtube_Trending_Data_Raw\"ë¡œ ì‹œì‘í•˜ëŠ” CSV íŒŒì¼ì— pandas DataFrameì„ ì‚¬ìš©í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n\nYouTube Data API ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ APIì˜ ë‹¤ë¥¸ ë¶€ë¶„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì— ëŒ€í•´ ìì„¸íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” íŠ¸ë Œë”© ë¹„ë””ì˜¤ ë°ì´í„°ì— ê´€ì‹¬ì´ ìˆìœ¼ë¯€ë¡œ APIì˜ í•´ë‹¹ ë¶€ë¶„ì— ì§‘ì¤‘í•  ê²ƒì…ë‹ˆë‹¤. next_page_tokenì€ ëª¨ë“  í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.\n\nì½”ë“œë¥¼ ìˆ˜ì •í•œ í›„ Airflow í˜ì´ì§€ì— ë³€ê²½ ì‚¬í•­ì´ ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. DAGë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ë ¤ë©´ ì™¼ìª½ ìƒë‹¨ì— ìˆëŠ” ì‹¤í–‰ ë²„íŠ¼ì„ í´ë¦­í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ê·¸ë˜í”„ì—ì„œ ì‘ì—… ìƒíƒœ (ëŒ€ê¸°, ì‹¤í–‰ ì¤‘, ì„±ê³µ ë“±)ëŠ” ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. DAGê°€ ì‹¤í–‰ ì¤‘ì¼ ë•Œ ë¡œê·¸ë¥¼ ë³´ì‹¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n\n<img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_5.png\" />\n\n<div class=\"content-ad\"></div>\n\nëŸ° ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  íŒŒì¼ì— ì €ì¥í•˜ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤. ì‘ì—…ì˜ ê° ë‹¨ê³„ì—ì„œ ê·¸ë˜í”„ ìƒ‰ìƒì´ ë³€ê²½ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆì„ ê±°ì—ìš”. ë©‹ì§€ì£ ? :)\n\nì‘ì—… ìƒíƒœê°€ ì„±ê³µì„ ë‚˜íƒ€ë‚´ëŠ” ë…¹ìƒ‰ìœ¼ë¡œ ë³€í•˜ë©´, ìƒˆ íŒŒì¼ì¸ \"Youtube-Trending-Data-Raw\"ê°€ ìƒê¸´ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.\n\nìš°ë¦¬ì˜ Raw ë°ì´í„°ëŠ” ì´ë ‡ê²Œ ìƒê²¼ì–´ìš”:\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_6.png)\n\n<div class=\"content-ad\"></div>\n\nì´ì œ ì¶”ì¶œ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ìœ¼ë¡œ ë„˜ì–´ê°€ ë´…ì‹œë‹¤!\n\n## 3. PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë³€í™˜í•˜ê¸°:\n\nì›ì‹œ ë°ì´í„° íŒŒì¼ì„ ì‚´í´ë³´ë©´ ë°ì´í„°ì— ë§ì€ í•´ì‹œíƒœê·¸ì™€ ì´ëª¨ì§€ê°€ ìˆëŠ”ë°, ì´ëŠ” ìš°ë¦¬ í”„ë¡œì íŠ¸ì—ëŠ” í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ì •ë¦¬í•˜ì—¬ ì¶”ê°€ ë¶„ì„ì— ìœ ìš©í•˜ë„ë¡ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.\n\nì´ ì‘ì—…ì— PySparkë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. PySparkëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ë³€í™˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë°ì´í„° ì„¸íŠ¸ê°€ íŠ¹íˆ í¬ì§€ ì•Šê¸° ë•Œë¬¸ì— Pandasë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì „ì— PySparkë¥¼ ì‚¬ìš©í•œ ì ì´ ìˆì–´ ì´ë²ˆì—ë„ PySparkë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ìµœê·¼ PySparkë¥¼ ê³µë¶€í•˜ê³  ìˆìœ¼ë©°, ì´ë¡ ì„ ê³µë¶€í•˜ëŠ” ê²ƒë³´ë‹¤ ì‹¤ì œ êµ¬í˜„ì´ ë” í¥ë¯¸ë¡­ë‹¤ê³  ëŠë‚ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n\n# Python callable function to extract data from YouTube API\ndef extract_data(**kwargs):\n    api_key = kwargs['api_key']\n    region_codes = kwargs['region_codes']\n    category_ids = kwargs['category_ids']\n    \n    df_trending_videos = fetch_data(api_key, region_codes, category_ids)\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    output_path = f'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'\n    # Save DataFrame to CSV file\n    df_trending_videos.to_csv(output_path, index=False)\n\ndef fetch_data(api_key, region_codes, category_ids):\n    \"\"\"\n    Fetches trending video data for multiple countries and categories from YouTube API.\n    Returns a pandas data frame containing video data.\n    \"\"\"\n    video_data = []\n\n    # Build YouTube API service\n    youtube = build('youtube', 'v3', developerKey=api_key)\n\n    for region_code in region_codes:\n        for category_id in category_ids:\n            # Initialize the next_page_token to None for each region and category\n            next_page_token = None\n            while True:\n                # Make a request to the YouTube API to fetch trending videos\n                request = youtube.videos().list(\n                    part='snippet,contentDetails,statistics',\n                    chart='mostPopular',\n                    regionCode=region_code,\n                    videoCategoryId=category_id,\n                    maxResults=50,\n                    pageToken=next_page_token\n                )\n                response = request.execute()\n                videos = response['items']\n\n                # Process each video and collect data\n                for video in videos:\n                    video_info = {\n                        'region_code': region_code,\n                        'category_id': category_id,\n                        'video_id': video['id'],\n                        'title': video['snippet']['title'],\n                        'published_at': video['snippet']['publishedAt'],\n                        'view_count': video['statistics'].get('viewCount', 0),\n                        'like_count': video['statistics'].get('likeCount', 0),\n                        'comment_count': video['statistics'].get('commentCount', 0),\n                        'channel_title': video['snippet']['channelTitle']\n                    }\n                    video_data.append(video_info)\n\n                # Get the next page token, if there are more pages of results\n                next_page_token = response.get('nextPageToken')\n                if not next_page_token:\n                    break\n\n    return pd.DataFrame(video_data)\n\ndef preprocess_data_pyspark_job():\n    spark = SparkSession.builder.appName('YouTubeTransform').getOrCreate()\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    output_path = f'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'\n    df = spark.read.csv(output_path, header=True)\n    \n    # Define UDF to remove hashtag data, emojis\n    def clean_text(text):\n     if text is not None:\n        # Remove emojis\n        text = emoji.demojize(text, delimiters=('', ''))\n        \n        # Remove hashtag data\n        if text.startswith('#'):\n            text = text.replace('#', '').strip()\n        else:\n            split_text = text.split('#')\n            text = split_text[0].strip()\n        \n        # Remove extra double quotes and backslashes\n        text = text.replace('\\\\\"', '')  # Remove escaped quotes\n        text = re.sub(r'\\\"+', '', text)  # Remove remaining double quotes\n        text = text.replace('\\\\', '')  # Remove backslashes\n        \n        return text.strip()  # Strip any leading or trailing whitespace\n\n     return text\n    # Register UDF\n    clean_text_udf = udf(clean_text, StringType())\n\n    # Clean the data\n    df_cleaned = df.withColumn('title', clean_text_udf(col('title'))) \\\n                   .withColumn('channel_title', clean_text_udf(col('channel_title'))) \\\n                   .withColumn('published_at', to_date(col('published_at'))) \\\n                   .withColumn('view_count', col('view_count').cast(LongType())) \\\n                   .withColumn('like_count', col('like_count').cast(LongType())) \\\n                   .withColumn('comment_count', col('comment_count').cast(LongType())) \\\n                   .dropna(subset=['video_id'])\n    \n    # Generate the filename based on the current date\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    output_path = f'/opt/airflow/Transformed_Youtube_Data_{current_date}'\n    \n    # Write cleaned DataFrame to the specified path\n    df_cleaned.write.csv(output_path, header=True, mode='overwrite')   \n\n\n# Define extract task for the DAG\nextract_task = PythonOperator(\n    task_id='extract_data_from_youtube_api',\n    python_callable=extract_data,\n    op_kwargs={\n        'api_key': os.getenv('YOUTUBE_API_KEY'),\n        'region_codes': ['US', 'GB', 'IN', 'AU', 'NZ'],\n        'category_ids': ['1', '2', '10', '15', '20', '22', '23']\n    },\n    dag=dag,\n)\n\n# Define preprocessing task for the DAG\npreprocess_data_pyspark_task= PythonOperator(\n    task_id='preprocess_data_pyspark_task',\n    python_callable=preprocess_data_pyspark_job,\n    dag=dag\n)\n\nextract_task >> preprocess_data_pyspark_task\n\n\nì—¬ê¸°ì„œëŠ” ì´ ì½”ë“œê°€ í•˜ëŠ” ì¼ì„ ì„¤ëª…í•´ ë“œë ¸ìŠµë‹ˆë‹¤.\n\n- \"preprocess_data_pyspark_task\"ë¼ëŠ” ì‘ì—…ì„ ë§Œë“­ë‹ˆë‹¤.\n- ì´ ì‘ì—…ì€ preprocess_data_pyspark_job í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n- preprocess_data_pyspark_job í•¨ìˆ˜ëŠ” ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.\n- ê·¸ë¦¬ê³  ì •ë¦¬ëœ ë°ì´í„°ëŠ” \"Transformed_Youtube_Data_currentDate\"ë¼ëŠ” í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.\n- ì´ í´ë” ì•ˆì—ëŠ” ì •ë¦¬ëœ ë°ì´í„°ê°€ ë‹´ê¸´ \"part-\" ì ‘ë‘ì‚¬ê°€ ë¶™ì€ ìƒˆ CSV íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.\n\në§Œì•½ Airflowë¥¼ ë³´ì‹ ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ ì²« ë²ˆì§¸ ì‘ì—…ì— ìƒˆë¡œìš´ ì‘ì—…ì´ ì¶”ê°€ëœ ê²ƒì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n\n<div class=\"content-ad\"></div>\n\nì•„ë˜ëŠ” ìš°ë¦¬ê°€ ë³€í™˜í•œ ë°ì´í„°ì˜ ëª¨ìŠµì…ë‹ˆë‹¤:\n\n![Transformed Data](/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_8.png)\n\nì´ ì‘ì—…ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ìµœì¢… ì‘ì—…ìœ¼ë¡œ ë„˜ì–´ê°ˆ ì°¨ë¡€ì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n# 4. S3ë¡œ ë°ì´í„° ë¡œë“œí•˜ê¸°:\n\nì´ ì‘ì—…ì„ ì‹œì‘í•˜ê¸° ì „ì— ì²˜ìŒì— ì„¤ì •í•œ IAM ì‚¬ìš©ìë¥¼ ì‚¬ìš©í•˜ì—¬ S3 ë²„í‚·ì„ ìƒì„±í•˜ê³  ë²„í‚· ì´ë¦„ì„ ë©”ëª¨í•´ì£¼ì„¸ìš”.\n\nìš°ë¦¬ì˜ ìµœì¢… ì½”ë“œì…ë‹ˆë‹¤!\n\n```js\nimport logging\nimport os\nimport re\nimport shutil\nfrom datetime import datetime, timedelta\n\nimport boto3\nimport emoji\nimport pandas as pd\nfrom googleapiclient.discovery import build\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, to_date, udf\nfrom pyspark.sql.types import (DateType, IntegerType, LongType, StringType,\n                               StructField, StructType)\n\nfrom airflow import DAG\nfrom airflow.operators.python_operator import PythonOperator\n\n# DAG ë° ê¸°ë³¸ ì¸ì ì •ì˜\ndefault_args = {\n    'owner': 'airflow',  # DAG ì†Œìœ ì\n    'depends_on_past': False,  # ì´ì „ DAG ì‹¤í–‰ì— ì˜ì¡´ ì—¬ë¶€\n    'email_on_failure': False,  # ì‹¤íŒ¨ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    'email_on_retry': False,  # ì¬ì‹œë„ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    'retries': 1,  # ì¬ì‹œë„ íšŸìˆ˜\n    'retry_delay': timedelta(minutes=5),  # ì¬ì‹œë„ ì‚¬ì´ ê°„ê²©\n    'start_date': datetime(2023, 6, 10, 0, 0, 0),  # ë§¤ì¼ ìì •(00:00) UTCì— ì‹¤í–‰\n}\n\n# DAG ì •ì˜\ndag = DAG(\n    'youtube_etl_dag',  # DAG ì‹ë³„ì\n    default_args=default_args,  # ê¸°ë³¸ ì¸ìˆ˜ í• ë‹¹\n    description='ê°„ë‹¨í•œ ETL DAG',  # DAG ì„¤ëª…\n    schedule_interval=timedelta(days=1),  # ìŠ¤ì¼€ì¤„ ê°„ê²©: ë§¤ì¼\n    catchup=False,  # ëˆ„ë½ëœ DAG ì‹¤í–‰ì„ ë³µêµ¬í•˜ì§€ ì•ŠìŒ\n)\n\n# YouTube APIì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” Python ìœ í˜•ì˜ í•¨ìˆ˜\ndef extract_data(**kwargs):\n    api_key = kwargs['api_key']\n    region_codes = kwargs['region_codes']\n    category_ids = kwargs['category_ids']\n    \n    df_trending_videos = fetch_data(api_key, region_codes, category_ids)\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    output_path = f'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'\n    # DataFrameì„ CSV íŒŒì¼ë¡œ ì €ì¥\n    df_trending_videos.to_csv(output_path, index=False)\n\n# YouTube APIì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\ndef fetch_data(api_key, region_codes, category_ids):\n    \"\"\"\n    YouTube APIì—ì„œ ì—¬ëŸ¬ êµ­ê°€ ë° ì¹´í…Œê³ ë¦¬ì˜ íŠ¸ë Œë“œ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n    ë¹„ë””ì˜¤ ë°ì´í„°ê°€ í¬í•¨ëœ Pandas ë°ì´í„° í”„ë ˆì„ ë°˜í™˜.\n    \"\"\"\n    # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ë³´ê´€í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n    video_data = []\n\n    # YouTube API ì„œë¹„ìŠ¤ ë¹Œë“œ\n    youtube = build('youtube', 'v3', developerKey=api_key)\n\n    for region_code in region_codes:\n        for category_id in category_ids:\n            # ê° ì§€ì—­ ë° ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ next_page_tokenì„ Noneìœ¼ë¡œ ì´ˆê¸°í™”\n            next_page_token = None\n            while True:\n                # YouTube APIì— íŠ¸ë Œë“œ ë¹„ë””ì˜¤ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ìš”ì²­\n                request = youtube.videos().list(\n                    part='snippet,contentDetails,statistics',\n                    chart='mostPopular',\n                    regionCode=region_code,\n                    videoCategoryId=category_id,\n                    maxResults=50,\n                    pageToken=next_page_token\n                )\n                response = request.execute()\n                videos = response['items']\n\n                # ê° ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ë°ì´í„° ìˆ˜ì§‘\n                for video in videos:\n                    video_info = {\n                        'region_code': region_code,\n                        'category_id': category_id,\n                        'video_id': video['id'],\n                        'title': video['snippet']['title'],\n                        'published_at': video['snippet']['publishedAt'],\n                        'view_count': video['statistics'].get('viewCount', 0),\n                        'like_count': video['statistics'].get('likeCount', 0),\n                        'comment_count': video['statistics'].get('commentCount', 0),\n                        'channel_title': video['snippet']['channelTitle']\n                    }\n                    video_data.append(video_info)\n\n                # ê²°ê³¼ì˜ ì¶”ê°€ í˜ì´ì§€ê°€ ìˆëŠ” ê²½ìš° ë‹¤ìŒ í˜ì´ì§€ í† í° ê°€ì ¸ì˜¤ê¸°\n                next_page_token = response.get('nextPageToken')\n                if not next_page_token:\n                    break\n\n    return pd.DataFrame(video_data)\n\n# PySpark ì‘ì—… ì „ì²˜ë¦¬ í•¨ìˆ˜\ndef preprocess_data_pyspark_job():\n    spark = SparkSession.builder.appName('YouTubeTransform').getOrCreate()\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    output_path = f'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'\n    df = spark.read.csv(output_path, header=True)\n    \n    # í•´ì‹œíƒœê·¸ ë°ì´í„°, ì´ëª¨ì§€ ì œê±°ë¥¼ ìœ„í•œ UDF ì •ì˜\n    def clean_text(text):\n     if text is not None:\n        # ì´ëª¨ì§€ ì œê±°\n        text = emoji.demojize(text, delimiters=('', ''))\n        \n        # í•´ì‹œíƒœê·¸ ë° ì´í›„ ëª¨ë“  ê²ƒ ì œê±°\n        if text.startswith('#'):\n            text = text.replace('#', '').strip()\n        else:\n            split_text = text.split('#')\n            text = split_text[0].strip()\n        \n        # ì¶”ê°€ ì´ì¤‘ ì¸ìš©ë¶€í˜¸ì™€ ë°±ìŠ¬ë˜ì‹œ ì œê±°\n        text = text.replace('\\\\\"', '')  # ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œ ì œê±°\n        text = re.sub(r'\\\"+', '', text)  # ë‚¨ì€ ì´ì¤‘ ì¸ìš©ë¶€í˜¸ ì œê±°\n        text = text.replace('\\\\', '')  # ë°±ìŠ¬ë˜ì‹œ ì œê±°\n        \n        return text.strip()  # ì„ í–‰ ë˜ëŠ” í›„í–‰ ê³µë°± ì œê±°\n\n     return text\n    # UDF ë“±ë¡\n    clean_text_udf = udf(clean_text, StringType())\n\n    # ë°ì´í„° ì •ë¦¬\n    df_cleaned = df.withColumn('title', clean_text_udf(col('title'))) \\\n                   .withColumn('channel_title', clean_text_udf(col('channel_title'))) \\\n                   .withColumn('published_at', to_date(col('published_at'))) \\\n                   .withColumn('view_count', col('view_count').cast(LongType())) \\\n                   .withColumn('like_count', col('like_count').cast(LongType())) \\\n                   .withColumn('comment_count', col('comment_count').cast(LongType())) \\\n                   .dropna(subset=['video_id'])\n    \n    # í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ ì´ë¦„ ìƒì„±\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    output_path = f'/opt/airflow/Transformed_Youtube_Data_{current_date}'\n    \n    # ì •ë¦¬ëœ DataFrameì„ ì§€ì •ëœ ê²½ë¡œì— ì‘ì„±\n    df_cleaned.write.csv(output_path, header=True, mode='overwrite')   \n\n# S3ë¡œ ë°ì´í„° ì—…ë¡œë“œ í•¨ìˆ˜\ndef load_data_to_s3(**kwargs):\n    bucket_name = kwargs['bucket_name']\n    today = datetime.now().strftime('%Y/%m/%d')\n    prefix = f\"processed-data/{today}\"\n    current_date = datetime.now().strftime(\"%Y%m%d\")\n    local_dir_path  = f'/opt/airflow/Transformed_Youtube_Data_{current_date}'\n    upload_to_s3(bucket_name, prefix, local_dir_path)\n\ndef upload_to_s3(bucket_name, prefix, local_dir_path):\n    aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')\n    aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')\n\n    s3_client = boto3.client(\n        's3',\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key\n    )\n\n    for root, dirs, files in os.walk(local_dir_path):\n         for file in files:\n            if file.endswith('.csv'):\n                file_path = os.path.join(root, file)\n                s3_key = f\"{prefix}/{file}\"\n                logging.info(f\"Uploading {file_path} to s3://{bucket_name}/{s3_key}\")\n                s3_client.upload_file(file_path, bucket_name, s3_key)\n\n# DAGì˜ ì¶”ì¶œ ì‘ì—… ì •ì˜\nextract_task = PythonOperator(\n    task_id='extract_data_from_youtube_api',\n    python_callable=extract_data,\n    op_kwargs={\n        'api_key': os.getenv('YOUTUBE_API_KEY'),\n        'region_codes': ['US', 'GB', 'IN', 'AU', 'NZ'],\n        'category_ids': ['1', '2', '10', '15', '20', '22', '23']\n    },\n    dag=dag,\n)\n\n# DAGì˜ ë°ì´í„° ì „ì²˜ë¦¬ ì‘ì—… ì •ì˜\npreprocess_data_pyspark_task= PythonOperator(\n    task_id='preprocess_data_pyspark_task',\n    python_callable=preprocess_data_pyspark_job,\n    dag=dag\n)\n\n\n\n<div class=\"content-ad\"></div>\n\nì´ì œ ì €í¬ê°€ ë§Œë“  ìµœì¢… ì‘ì—…ì¸ load_data_to_s3_taskë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ load_data_to_s3 í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ íŒŒì¼ì„ S3 ë²„í‚·ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤. ì—…ë¡œë“œê°€ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ S3 ë²„í‚·ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.\n\në§ˆì¹¨ë‚´ ìš°ë¦¬ì˜ AirflowëŠ” ì´ë ‡ê²Œ ìƒê²¼ìŠµë‹ˆë‹¤!\n\n![Airflow](/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_9.png)\n\nì´ì œ ì´ ë°ì´í„°ë¥¼ Tableauë‚˜ ë‹¤ë¥¸ BI ë„êµ¬ì— ì—°ê²°í•˜ì—¬ í¥ë¯¸ë¡œìš´ ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“¤ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì‹œê°í™”í•´ ë³´ì„¸ìš”!\n\n<div class=\"content-ad\"></div>\n\ní•¨ê»˜ ì´ íŒŒì´í”„ë¼ì¸ì„ ë”°ë¼ ì˜¤ë©´ì„œ ìƒˆë¡œìš´ ê¸°ìˆ  ëª‡ ê°€ì§€ë¥¼ ë°°ì› ìœ¼ë©´ ì¢‹ê² ì–´ìš”! ğŸš€ ì„±ê³µì ìœ¼ë¡œ ì—¬ê¸°ê¹Œì§€ ì™”ë‹¤ë©´ ì¶•í•˜í•´ìš”! ğŸ‰ ì´ ìƒˆë¡­ê²Œ ì–»ì€ ì§€ì‹ì´ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì—ì„œì˜ í–¥í›„ ëª¨í—˜ì— í° ë„ì›€ì´ ë˜ê¸¸ ë°”ë˜ìš”!\n\nì´ í”„ë¡œì íŠ¸ì˜ Github ì €ì¥ì†Œë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤:\n\në§Œì•½ ì´ ê¸€ì„ ì¢‹ì•„í•˜ì…¨ë‹¤ë©´, ê³µìœ í•˜ê³ , ì¢‹ì•„ìš”ë¥¼ ëˆŒëŸ¬ì£¼ì‹œê³ , ì•„ë˜ì— ëŒ“ê¸€ì„ ë‚¨ê²¨ì£¼ì‹œê³  êµ¬ë…í•´ì£¼ì„¸ìš”. ğŸ‰ğŸ‘ğŸ“\n\nì»¤íŠ¼ì„ ë‹«ìŠµë‹ˆë‹¤! ğŸ­","ogImage":{"url":"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_0.png"},"coverImage":"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_0.png","tag":["Tech"],"readingTime":25},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>ì´ ê¸°ì‚¬ì—ì„œëŠ” Apache Airflowì™€ PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ ETL (ì¶”ì¶œ, ë³€í™˜, ë¡œë“œ) íŒŒì´í”„ë¼ì¸ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. ì´ íŒŒì´í”„ë¼ì¸ì€ YouTube Data APIì—ì„œ íŠ¸ë Œë“œ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ì²˜ë¦¬í•œ í›„ ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ S3ì— ì €ì¥í•  ê²ƒì…ë‹ˆë‹¤.</p>\n<p>Twitter APIë¥¼ ì‚¬ìš©í•œ íŒŒì´í”„ë¼ì¸ì„ ë³´ì—¬ì£¼ëŠ” Darshil Parmarì˜ YouTube ë¹„ë””ì˜¤ë¥¼ ì‹œì²­í•œ í›„, ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ì— ë„ì „í•˜ê¸°ë¡œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Twitter APIì˜ ê°€ê²© ì •ì±… ë³€ê²½ìœ¼ë¡œ ì¸í•´, ì‹œì²­ìê°€ YouTube Data APIë¥¼ ëŒ€ì²´ë¡œ ì œì•ˆí–ˆê³  ì´ê²ƒì´ ì œ í¥ë¯¸ë¥¼ ìê·¹í–ˆìŠµë‹ˆë‹¤.</p>\n<p>í”„ë¡œì íŠ¸ì— ëŒì…í•˜ê¸° ì „ì— ë‘ ê°€ì§€ í•„ìˆ˜ ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤:</p>\n<ol>\n<li>Youtube Data API í‚¤ íšë“</li>\n</ol>\n<ul>\n<li>Google Developers Consoleì„ ë°©ë¬¸í•´ ì£¼ì„¸ìš”.</li>\n<li>ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.</li>\n<li>\"YouTube Data API\"ë¥¼ ê²€ìƒ‰í•˜ê³  í™œì„±í™”í•´ ì£¼ì„¸ìš”.</li>\n<li>ìƒˆ ìê²© ì¦ëª…ì„ ìƒì„±í•˜ê³  í”„ë¡œì íŠ¸ì—ì„œ ë‚˜ì¤‘ì— ì‚¬ìš©í•  API í‚¤ë¥¼ ë³µì‚¬í•´ ì£¼ì„¸ìš”.</li>\n</ul>\n<p>ìì„¸í•œ ì§€ì¹¨ì€ YouTube Data API ì‹œì‘ ê°€ì´ë“œë¥¼ ì°¸ì¡°í•´ ì£¼ì„¸ìš”.</p>\n<ol start=\"2\">\n<li>AWS ì•¡ì„¸ìŠ¤ í‚¤ ID ë° ë¹„ë°€ ì•¡ì„¸ìŠ¤ í‚¤ íšë“</li>\n</ol>\n<ul>\n<li>AWS Management Consoleì— ë¡œê·¸ì¸í•´ ì£¼ì„¸ìš”.</li>\n<li>IAM(Identity and Access Management) ì„¹ì…˜ìœ¼ë¡œ ì´ë™í•˜ê³  ìƒˆ ì‚¬ìš©ìë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.</li>\n<li>í•„ìš”í•œ S3 ì•¡ì„¸ìŠ¤ ì •ì±…ì„ ë¶€ì—¬í•˜ê³  ì•¡ì„¸ìŠ¤ í‚¤ë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.</li>\n<li>í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•  ì•¡ì„¸ìŠ¤ í‚¤ IDì™€ ë¹„ë°€ ì•¡ì„¸ìŠ¤ í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ì €ì¥í•´ ì£¼ì„¸ìš”.</li>\n</ul>\n<p>ì´ì œ ì‹¤ì œ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤! ì¤€ë¹„ëë‚˜ìš” ì—¬ëŸ¬ë¶„!!</p>\n<p><img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_0.png\" alt=\"YouTube Trend Analysis Pipeline ETL with Airflow, Spark, S3, and Docker\"></p>\n<p>ì´ ê¸€ì€ 4ê°€ì§€ ì£¼ìš” ë‹¨ê³„ë¡œ êµ¬ì„±ë˜ì–´ ìˆì–´ìš”:</p>\n<ul>\n<li>ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜ ë° ì„¤ì •</li>\n<li>Youtube Data APIì—ì„œ ë°ì´í„° ì¶”ì¶œ</li>\n<li>PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë³€í™˜</li>\n<li>AWS S3ë¡œ ë°ì´í„° ë¡œë“œ</li>\n</ul>\n<h1>1. ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ì¹˜ ë° ì„¤ì •:</h1>\n<ul>\n<li>VS Code â€” <a href=\"https://code.visualstudio.com/\" rel=\"nofollow\" target=\"_blank\">VS Code ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜</a>.</li>\n<li>Docker Desktop â€” <a href=\"https://www.docker.com/products/docker-desktop\" rel=\"nofollow\" target=\"_blank\">Docker Desktop ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜</a>.</li>\n<li>(ì„ íƒì‚¬í•­) Windows Subsystem for Linux (WSL) â€” ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì— ì‚¬ìš©ë˜ëŠ” Apache Airflow ë° PySparkì™€ ê°™ì€ ë§ì€ ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ Unix ê³„ì—´ ì‹œìŠ¤í…œì„ ìœ„í•´ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë„êµ¬ë¥¼ Windowsì—ì„œ ì‚¬ìš©í•  ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” í˜¸í™˜ì„± ë¬¸ì œë¥¼ í”¼í•˜ê¸° ìœ„í•´ WSLì„ í†µí•´ ë„¤ì´í‹°ë¸Œ Linux í™˜ê²½ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n<ul>\n<li>` ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ PowerShellì„ ì—½ë‹ˆë‹¤.</li>\n<li>` ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”: wsl --install.</li>\n<li>` ëª…ë ¹ì— ë”°ë¼ WSLì„ ì„¤ì¹˜í•˜ê³  Microsoft Storeì—ì„œ Linux ë°°í¬íŒ(ì˜ˆ: Ubuntu)ì„ ì„ íƒí•˜ì„¸ìš”.</li>\n<li>` Linux ë°°í¬íŒì— ì‚¬ìš©ì ì´ë¦„ ë° ì•”í˜¸ë¥¼ ì„¤ì •í•˜ì„¸ìš”.</li>\n</ul>\n</li>\n</ul>\n<p>ì´ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° WSLì´ ë°˜ë“œì‹œ í•„ìš”í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. Docker Desktopì€ Windowsì—ì„œ ë„¤ì´í‹°ë¸Œë¡œ ì‹¤í–‰ë  ìˆ˜ ìˆìœ¼ë©° Docker ìì²´ê°€ ê´€ë¦¬í•˜ëŠ” ê°€ë²¼ìš´ Linux ê°€ìƒ ë¨¸ì‹ (VM)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Docker Desktopê³¼ í•¨ê»˜ WSLì„ ì‚¬ìš©í•˜ë©´ Windowsì—ì„œ ì§ì ‘ Linux ëª…ë ¹ ë° ì‘ì—…ì„ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ ë³´ë‹¤ ë„¤ì´í‹°ë¸Œí•œ ê°œë°œ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.</p>\n<p>ì´ì œ ì„¤ì •ì„ ì‹œì‘í•´ ë´…ì‹œë‹¤.</p>\n<p>ë¶€ë¶„ 1 â€” ë„ì»¤ ì´ë¯¸ì§€ ë§Œë“¤ê¸°</p>\n<ul>\n<li>í”„ë¡œì íŠ¸ìš© ìƒˆ í´ë”ë¥¼ ë§Œë“¤ê³  \"Airflow-Project\"ë¡œ ì´ë¦„ì„ ì§€ì–´ì£¼ì„¸ìš”.</li>\n<li>í•´ë‹¹ í´ë”ì—ì„œ ëª…ë ¹ í”„ë¡¬í”„íŠ¸ë¥¼ ì—½ë‹ˆë‹¤.</li>\n<li>ëª…ë ¹ í”„ë¡¬í”„íŠ¸ì—ì„œ ì•„ë˜ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:</li>\n</ul>\n<pre><code class=\"hljs language-bash\">code .\n</code></pre>\n<ul>\n<li>ì´ ëª…ë ¹ì€ VS Codeì—ì„œ í•´ë‹¹ í´ë”ë¥¼ í”„ë¡œì íŠ¸ë¡œ ì—½ë‹ˆë‹¤.</li>\n<li>VS Codeì—ì„œ \"dockerfile\"ì´ë¼ëŠ” ìƒˆ íŒŒì¼ì„ ë§Œë“¤ê³  ì•„ë˜ ì½”ë“œë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”:</li>\n</ul>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-variable constant_\">FROM</span> apache/<span class=\"hljs-attr\">airflow</span>:latest\n\n# ì‹œìŠ¤í…œ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ê¸° ìœ„í•´ ë£¨íŠ¸ ì‚¬ìš©ìë¡œ ì „í™˜í•©ë‹ˆë‹¤\n<span class=\"hljs-variable constant_\">USER</span> root\n\n# git, <span class=\"hljs-title class_\">OpenJDK</span>ë¥¼ ì„¤ì¹˜í•˜ê³  apt ìºì‹œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤\n<span class=\"hljs-variable constant_\">RUN</span> apt-get update &#x26;&#x26; \\\n    apt-get -y install git <span class=\"hljs-keyword\">default</span>-jdk &#x26;&#x26; \\\n    apt-get clean &#x26;&#x26; \\\n    rm -rf /<span class=\"hljs-keyword\">var</span>/lib/apt/lists<span class=\"hljs-comment\">/*\n\n# Python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê¸° ìœ„í•´ airflow ì‚¬ìš©ìë¡œ ì „í™˜í•©ë‹ˆë‹¤\nUSER airflow\n\n# í•„ìš”í•œ Python íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤\nRUN pip install --no-cache-dir pyspark pandas google-api-python-client emoji boto3\n</span></code></pre>\n<p>ì´ Docker íŒŒì¼ì€ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° í•„ìš”í•œ ëª¨ë“  íŒ¨í‚¤ì§€ë¥¼ í¬í•¨í•˜ê³  ìˆì–´ìš”.</p>\n<ul>\n<li>íŒŒì¼ì„ ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ìœ¼ë¡œ í´ë¦­í•˜ê³  VS Codeì—ì„œ \"ì´ë¯¸ì§€ ë¹Œë“œ\" ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”. ì´ë¦„ì„ ì…ë ¥í•˜ë¼ëŠ” í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚˜ë©´ \"airflow-project\"ë¥¼ ì…ë ¥í•˜ì„¸ìš”. ì´ ëª…ë ¹ì€ Docker ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ docker-compose.yml íŒŒì¼ì„ ìƒì„±í•˜ê³  ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë„ë¡ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤.</li>\n</ul>\n<p>(ì¬ë¯¸ìˆëŠ” ì‚¬ì‹¤: íŒŒì¼ì—ì„œ Python ì„¤ì¹˜ê°€ ì—†ëŠ” ì´ìœ  ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ì‹¤ì œë¡œ Dockerfileì—ì„œ ì‚¬ìš©ëœ ê¸°ë³¸ ì´ë¯¸ì§€ì¸ apache/airflow:latestì—ëŠ” Pythonì´ ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆì–´ìš”. ì™œëƒí•˜ë©´ Airflow ìì²´ê°€ Pythonìœ¼ë¡œ ì‘ì„±ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ì£¼ë¡œ ì›Œí¬í”Œë¡œ ë° ì‘ì—… ì •ì˜ì— Pythonì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë”°ë¼ì„œ Dockerfileì—ì„œ ë³„ë„ë¡œ Pythonì„ ì„¤ì¹˜í•  í•„ìš”ê°€ ì—†ë‹µë‹ˆë‹¤!)</p>\n<p>íŒŒíŠ¸ 2 â€” ë„ì»¤ ì»´í¬ì¦ˆ íŒŒì¼ ìƒì„±í•˜ê¸°</p>\n<p>ë„ì»¤ ì»´í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ë©´ ë©€í‹° ì»¨í…Œì´ë„ˆ ë„ì»¤ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ë‹¨ì¼ ëª…ë ¹ìœ¼ë¡œ ì—¬ëŸ¬ ë„ì»¤ ì»¨í…Œì´ë„ˆë¥¼ ì •ì˜í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìœ¼ë©° ê° ì„œë¹„ìŠ¤ì˜ í™˜ê²½ ë³€ìˆ˜, ë³¼ë¥¨, í¬íŠ¸ ë° ê¸°íƒ€ ì„¤ì •ì„ ëª…í™•í•˜ê³  ì¡°ì§ì ì¸ ë°©ì‹ìœ¼ë¡œ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„ì»¤ ì»´í¬ì¦ˆë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¨ì¼ ëª…ë ¹ì–´ì¸ docker-compose up ë˜ëŠ” docker-compose downì„ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ë¥¼ ì‰½ê²Œ ì‹œì‘, ì¤‘ì§€ ë° ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>\n<ul>\n<li>\"docker-compose.yml\" íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ì½”ë“œë¥¼ íŒŒì¼ì— ë¶™ì—¬ë„£ìŠµë‹ˆë‹¤:</li>\n</ul>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-attr\">version</span>: <span class=\"hljs-string\">'3'</span>\n<span class=\"hljs-attr\">services</span>:\n\n  <span class=\"hljs-attr\">airflowproject</span>:\n    <span class=\"hljs-attr\">image</span>: airflow-<span class=\"hljs-attr\">project</span>:latest\n    <span class=\"hljs-attr\">environment</span>:\n      - <span class=\"hljs-variable constant_\">AWS_ACCESS_KEY_ID</span>=your-aws-access-key\n      - <span class=\"hljs-variable constant_\">AWS_SECRET_ACCESS_KEY</span>=your-aws-secret-access-key\n      - <span class=\"hljs-variable constant_\">YOUTUBE_API_KEY</span>=your-youtube-api-key\n    <span class=\"hljs-attr\">volumes</span>:\n      - ./<span class=\"hljs-attr\">airflow</span>:<span class=\"hljs-regexp\">/opt/</span>airflow\n    <span class=\"hljs-attr\">ports</span>:\n      - <span class=\"hljs-string\">\"8080:8080\"</span>\n    <span class=\"hljs-attr\">command</span>: airflow standalone\n</code></pre>\n<ul>\n<li>ì´ì œ íŒŒì¼ì„ ë§ˆìš°ìŠ¤ ì˜¤ë¥¸ìª½ ë²„íŠ¼ìœ¼ë¡œ í´ë¦­í•œ í›„ VS Codeì—ì„œ 'Compose Up' ì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”. í™˜ê²½ì„ ì„¤ì •í•˜ê¸° ìœ„í•´ í´ë¦­í•˜ì„¸ìš”.</li>\n<li>ê¹œì§ ë†€ë„ ì¼ì´ ë²Œì–´ì¡Œì–´ìš”! ì´ ì‘ì—…ì„ ì™„ë£Œí•œ í›„ì—ëŠ” VS Code í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì— \"airflow\"ë¼ëŠ” ìƒˆ í´ë”ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>\n</ul>\n<p>Docker ë°ìŠ¤í¬í†±ì„ ì—´ì–´ì„œ ëª¨ë“  ê²ƒì´ ì˜¬ë°”ë¥´ê²Œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì˜¬ë°”ë¥´ê²Œ ì™„ë£Œëœ ê²½ìš° ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ì´ í‘œì‹œë©ë‹ˆë‹¤.</p>\n<p><img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_1.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<ul>\n<li>ì´ì œ Airflow í”„ë¡œì íŠ¸ë¥¼ í´ë¦­í•˜ì—¬ Airflowê°€ 8080 í¬íŠ¸ì—ì„œ ì‹¤í–‰ ì¤‘ì„ì„ ë‚˜íƒ€ë‚´ëŠ” ë¡œê·¸ê°€ í‘œì‹œë˜ëŠ” í™”ë©´ì„ ì—½ë‹ˆë‹¤.</li>\n</ul>\n<p><img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_2.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<ul>\n<li>í¬íŠ¸ë¥¼ í´ë¦­í•˜ë©´ Airflow ë¡œê·¸ì¸ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤. ì´ ë§í¬ë¥¼ ì²˜ìŒ ì—´ì–´ë³´ëŠ” ê²½ìš° ìê²© ì¦ëª…ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.</li>\n<li>ì‚¬ìš©ì ì´ë¦„ì€ \"admin\"ì´ê³  ë¹„ë°€ë²ˆí˜¸ëŠ” compose up ëª…ë ¹ì„ ì‹¤í–‰í•œ í›„ ìƒì„±ëœ Airflow í´ë” ë‚´ì˜ \"standalone_admin_password.txt\" íŒŒì¼ì— ìˆìŠµë‹ˆë‹¤.</li>\n</ul>\n<p><img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_3.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<ul>\n<li>ë¡œê·¸ì¸ í˜ì´ì§€ì—ì„œ ìê²© ì¦ëª…ì„ ì…ë ¥í•œ í›„, ë¡œì»¬ í˜¸ìŠ¤íŠ¸ì—ì„œ Airflowê°€ ì‹¤í–‰ ì¤‘ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤:</li>\n</ul>\n<p>ë‹¹ì‹ ì˜ í™˜ê²½ ì„¤ì • ì™„ë£Œì…ë‹ˆë‹¤! íœ´â€•!!</p>\n<h1>2. YouTube ë°ì´í„° APIì—ì„œ ë°ì´í„° ì¶”ì¶œí•˜ê¸°:</h1>\n<ul>\n<li>Airflow í´ë” ì•„ë˜ì— \"dags\"ë¼ëŠ” ì´ë¦„ì˜ í´ë”ë¥¼ ë§Œë“¤ê³ , dags í´ë” ì•„ë˜ì— \"youtube_etl_dag.py\"ë¼ëŠ” íŒŒì´ì¬ íŒŒì¼ì„ ë§Œë“­ë‹ˆë‹¤.</li>\n<li>ì´ì œ \"youtube_etl_dag.py\" íŒŒì¼ì— ë‹¤ìŒì„ importí•˜ì„¸ìš”.</li>\n</ul>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> logging\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> shutil\n<span class=\"hljs-keyword\">from</span> datetime <span class=\"hljs-keyword\">import</span> datetime, timedelta\n\n<span class=\"hljs-keyword\">import</span> boto3\n<span class=\"hljs-keyword\">import</span> emoji\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> googleapiclient.<span class=\"hljs-property\">discovery</span> <span class=\"hljs-keyword\">import</span> build\n<span class=\"hljs-keyword\">from</span> pyspark.<span class=\"hljs-property\">sql</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">SparkSession</span>\n<span class=\"hljs-keyword\">from</span> pyspark.<span class=\"hljs-property\">sql</span>.<span class=\"hljs-property\">functions</span> <span class=\"hljs-keyword\">import</span> col, to_date, udf\n<span class=\"hljs-keyword\">from</span> pyspark.<span class=\"hljs-property\">sql</span>.<span class=\"hljs-property\">types</span> <span class=\"hljs-keyword\">import</span> (<span class=\"hljs-title class_\">DateType</span>, <span class=\"hljs-title class_\">IntegerType</span>, <span class=\"hljs-title class_\">LongType</span>, <span class=\"hljs-title class_\">StringType</span>,\n                               <span class=\"hljs-title class_\">StructField</span>, <span class=\"hljs-title class_\">StructType</span>)\n\n<span class=\"hljs-keyword\">from</span> airflow <span class=\"hljs-keyword\">import</span> <span class=\"hljs-variable constant_\">DAG</span>\n<span class=\"hljs-keyword\">from</span> airflow.<span class=\"hljs-property\">operators</span>.<span class=\"hljs-property\">python_operator</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">PythonOperator</span>\n</code></pre>\n<ul>\n<li>ì´ í”„ë¡œì íŠ¸ë¥¼ ì‹¤í–‰í•˜ëŠ” ë° ìœ„ì˜ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤(ì½”ë“œ ì‘ì„±ì„ ì‹œì‘í•˜ë©´ ëª¨ë‘ ìœ ìš©í•´ì§‘ë‹ˆë‹¤)</li>\n<li>VS Codeì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ëª¨ë“  ì¢…ì†ì„±ì´ ë„ì»¤ì— ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ ë¡œì»¬ ë¨¸ì‹ ì—ëŠ” ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šê¸° ë•Œë¬¸ì´ë¯€ë¡œ ì‹ ê²½ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤.</li>\n<li>Airflowì—ì„œ êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ í™”ë©´ ìƒë‹¨ì— í‘œì‹œë˜ê³ , ë…¼ë¦¬ ì˜¤ë¥˜/ì˜ˆì™¸ëŠ” Airflow ë¡œê·¸ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>\n</ul>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-variable constant_\">DAG</span>ì™€ ê¸°ë³¸ ì¸ìˆ˜ ì •ì˜\ndefault_args = {\n    <span class=\"hljs-string\">'owner'</span>: <span class=\"hljs-string\">'airflow'</span>,  # <span class=\"hljs-variable constant_\">DAG</span> ì†Œìœ ì\n    <span class=\"hljs-string\">'depends_on_past'</span>: <span class=\"hljs-title class_\">False</span>,  # ê³¼ê±° <span class=\"hljs-variable constant_\">DAG</span> ì‹¤í–‰ì— ì¢…ì†í•˜ëŠ”ì§€ ì—¬ë¶€\n    <span class=\"hljs-string\">'email_on_failure'</span>: <span class=\"hljs-title class_\">False</span>,  # ì‹¤íŒ¨ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    <span class=\"hljs-string\">'email_on_retry'</span>: <span class=\"hljs-title class_\">False</span>,  # ì¬ì‹œë„ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    <span class=\"hljs-string\">'retries'</span>: <span class=\"hljs-number\">1</span>,  # ì¬ì‹œë„ íšŸìˆ˜\n    <span class=\"hljs-string\">'retry_delay'</span>: <span class=\"hljs-title function_\">timedelta</span>(minutes=<span class=\"hljs-number\">5</span>),  # ì¬ì‹œë„ ê°„ì˜ ì§€ì—° ì‹œê°„\n     <span class=\"hljs-string\">'start_date'</span>: <span class=\"hljs-title function_\">datetime</span>(<span class=\"hljs-number\">2023</span>, <span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>),  # ë§¤ì¼ ìì •(<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>) <span class=\"hljs-variable constant_\">UTC</span>ì— ì‹¤í–‰\n}\n\ndag = <span class=\"hljs-title function_\">DAG</span>(\n    <span class=\"hljs-string\">'youtube_etl_dag'</span>,  # <span class=\"hljs-variable constant_\">DAG</span> ì‹ë³„ì\n    default_args=default_args,  # ê¸°ë³¸ ì¸ìˆ˜ í• ë‹¹\n    description=<span class=\"hljs-string\">'ê°„ë‹¨í•œ ETL DAG'</span>,  # <span class=\"hljs-variable constant_\">DAG</span> ì„¤ëª…\n    schedule_interval=<span class=\"hljs-title function_\">timedelta</span>(days=<span class=\"hljs-number\">1</span>),  # ì¼ë³„ ìŠ¤ì¼€ì¤„ ê°„ê²©\n    catchup=<span class=\"hljs-title class_\">False</span>,  # ëˆ„ë½ëœ <span class=\"hljs-variable constant_\">DAG</span> ì‹¤í–‰ì„ ë³µêµ¬í•˜ì§€ ì•ŠìŒ\n)\n</code></pre>\n<p>ë§¤ì¼ ìì •(0ì‹œ)ì— ì‹¤í–‰ë˜ëŠ” DAGì¸ 'youtube_etl_dag'ì„ ì •ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ DAGì€ Airflowì—ì„œ ê´€ë¦¬ ë° íŠ¸ë¦¬ê±°ë˜ë©°, VS Codeì—ì„œ ë³„ë„ë¡œ ì‹¤í–‰í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. Python íŒŒì¼ì„ ì—…ë°ì´íŠ¸í•˜ë©´ Airflowì—ì„œ ìë™ìœ¼ë¡œ ë³€ê²½ ì‚¬í•­ì„ ê°ì§€í•˜ê³  ë°˜ì˜í•  ê²ƒì…ë‹ˆë‹¤.</p>\n<p>í˜„ì¬ Airflowì—ëŠ” DAGì´ í‘œì‹œë˜ì§€ë§Œ ì•„ì§ ì •ì˜ëœ ì‘ì—…ì´ ì—†ì–´ì„œ ì–´ë–¤ ì‘ì—…ë„ í‘œì‹œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. DAGë¥¼ ê¸°ëŠ¥ì ìœ¼ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ë°ì´í„° ì¶”ì¶œ ì‘ì—…ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤.</p>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-title class_\">YouTube</span> <span class=\"hljs-variable constant_\">API</span>ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê¸° ìœ„í•œ <span class=\"hljs-title class_\">Python</span> callable í•¨ìˆ˜\ndef <span class=\"hljs-title function_\">extract_data</span>(**kwargs):\n    api_key = kwargs[<span class=\"hljs-string\">'api_key'</span>]\n    region_codes = kwargs[<span class=\"hljs-string\">'region_codes'</span>]\n    category_ids = kwargs[<span class=\"hljs-string\">'category_ids'</span>]\n    \n    df_trending_videos = <span class=\"hljs-title function_\">fetch_data</span>(api_key, region_codes, category_ids)\n    current_date = datetime.<span class=\"hljs-title function_\">now</span>().<span class=\"hljs-title function_\">strftime</span>(<span class=\"hljs-string\">\"%Y%m%d\"</span>)\n    output_path = f<span class=\"hljs-string\">'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'</span>\n    # <span class=\"hljs-title class_\">DataFrame</span>ì„ <span class=\"hljs-variable constant_\">CSV</span> íŒŒì¼ë¡œ ì €ì¥\n    df_trending_videos.<span class=\"hljs-title function_\">to_csv</span>(output_path, index=<span class=\"hljs-title class_\">False</span>)\n\ndef <span class=\"hljs-title function_\">fetch_data</span>(api_key, region_codes, category_ids):\n    <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n    YouTube APIì—ì„œ ì—¬ëŸ¬ ë‚˜ë¼ì™€ ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ë™ì˜ìƒ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n    \"</span><span class=\"hljs-string\">\"\"</span>\n    # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n    video_data = []\n\n    # <span class=\"hljs-title class_\">YouTube</span> <span class=\"hljs-variable constant_\">API</span> ì„œë¹„ìŠ¤ ë¹Œë“œ\n    youtube = <span class=\"hljs-title function_\">build</span>(<span class=\"hljs-string\">'youtube'</span>, <span class=\"hljs-string\">'v3'</span>, developerKey=api_key)\n\n    <span class=\"hljs-keyword\">for</span> region_code <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">region_codes</span>:\n        <span class=\"hljs-keyword\">for</span> category_id <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">category_ids</span>:\n            # ê° ì§€ì—­ ë° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ next_page_tokenì„ <span class=\"hljs-title class_\">None</span>ìœ¼ë¡œ ì´ˆê¸°í™”\n            next_page_token = <span class=\"hljs-title class_\">None</span>\n            <span class=\"hljs-keyword\">while</span> <span class=\"hljs-title class_\">True</span>:\n                # ì¸ê¸° ë™ì˜ìƒì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ <span class=\"hljs-title class_\">YouTube</span> <span class=\"hljs-variable constant_\">API</span>ì— ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\n                request = youtube.<span class=\"hljs-title function_\">videos</span>().<span class=\"hljs-title function_\">list</span>(\n                    part=<span class=\"hljs-string\">'snippet,contentDetails,statistics'</span>,\n                    chart=<span class=\"hljs-string\">'mostPopular'</span>,\n                    regionCode=region_code,\n                    videoCategoryId=category_id,\n                    maxResults=<span class=\"hljs-number\">50</span>,\n                    pageToken=next_page_token\n                )\n                response = request.<span class=\"hljs-title function_\">execute</span>()\n                videos = response[<span class=\"hljs-string\">'items'</span>]\n\n                # ê° ë¹„ë””ì˜¤ë¥¼ ì²˜ë¦¬í•˜ê³  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n                <span class=\"hljs-keyword\">for</span> video <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">videos</span>:\n                    video_info = {\n                        <span class=\"hljs-string\">'region_code'</span>: region_code,\n                        <span class=\"hljs-string\">'category_id'</span>: category_id,\n                        <span class=\"hljs-string\">'video_id'</span>: video[<span class=\"hljs-string\">'id'</span>],\n                        <span class=\"hljs-string\">'title'</span>: video[<span class=\"hljs-string\">'snippet'</span>][<span class=\"hljs-string\">'title'</span>],\n                        <span class=\"hljs-string\">'published_at'</span>: video[<span class=\"hljs-string\">'snippet'</span>][<span class=\"hljs-string\">'publishedAt'</span>],\n                        <span class=\"hljs-string\">'view_count'</span>: <span class=\"hljs-title function_\">int</span>(video[<span class=\"hljs-string\">'statistics'</span>].<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'viewCount'</span>, <span class=\"hljs-number\">0</span>)),\n                        <span class=\"hljs-string\">'like_count'</span>: <span class=\"hljs-title function_\">int</span>(video[<span class=\"hljs-string\">'statistics'</span>].<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'likeCount'</span>, <span class=\"hljs-number\">0</span>)),\n                        <span class=\"hljs-string\">'comment_count'</span>: <span class=\"hljs-title function_\">int</span>(video[<span class=\"hljs-string\">'statistics'</span>].<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'commentCount'</span>, <span class=\"hljs-number\">0</span>)),\n                        <span class=\"hljs-string\">'channel_title'</span>: video[<span class=\"hljs-string\">'snippet'</span>][<span class=\"hljs-string\">'channelTitle'</span>]\n                    }\n                    video_data.<span class=\"hljs-title function_\">append</span>(video_info)\n\n                # ê²°ê³¼ì˜ ë” ë§ì€ í˜ì´ì§€ê°€ ìˆëŠ” ê²½ìš° ë‹¤ìŒ í˜ì´ì§€ í† í°ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n                next_page_token = response.<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'nextPageToken'</span>)\n                <span class=\"hljs-keyword\">if</span> not <span class=\"hljs-attr\">next_page_token</span>:\n                    <span class=\"hljs-keyword\">break</span>\n\n    <span class=\"hljs-keyword\">return</span> pd.<span class=\"hljs-title class_\">DataFrame</span>(video_data)\n\n# <span class=\"hljs-variable constant_\">DAG</span>ë¥¼ ìœ„í•œ ë°ì´í„° ì¶”ì¶œ ì‘ì—… ì •ì˜\nextract_task = <span class=\"hljs-title class_\">PythonOperator</span>(\n    task_id=<span class=\"hljs-string\">'extract_data_from_youtube_api'</span>,\n    python_callable=extract_data,\n    op_kwargs={\n        <span class=\"hljs-string\">'api_key'</span>: os.<span class=\"hljs-title function_\">getenv</span>(<span class=\"hljs-string\">'YOUTUBE_API_KEY'</span>),\n        <span class=\"hljs-string\">'region_codes'</span>: [<span class=\"hljs-string\">'US'</span>, <span class=\"hljs-string\">'GB'</span>, <span class=\"hljs-string\">'IN'</span>, <span class=\"hljs-string\">'AU'</span>, <span class=\"hljs-string\">'NZ'</span>],\n        <span class=\"hljs-string\">'category_ids'</span>: [<span class=\"hljs-string\">'1'</span>, <span class=\"hljs-string\">'2'</span>, <span class=\"hljs-string\">'10'</span>, <span class=\"hljs-string\">'15'</span>, <span class=\"hljs-string\">'20'</span>, <span class=\"hljs-string\">'22'</span>, <span class=\"hljs-string\">'23'</span>]\n    },\n    dag=dag,\n)\n\nextract_task # ì´ ì‘ì—…ì„ ì‹¤í–‰í•˜ë„ë¡ <span class=\"hljs-variable constant_\">DAG</span>ë¥¼ ì„¤ì •í•¨\n</code></pre>\n<p>ì´ ì½”ë“œì—ì„œ ë‘ ê°€ì§€ ì£¼ìš” ì‘ì—…ì´ ì´ë£¨ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤:</p>\n<ul>\n<li>DAGì— extract_taskë¼ëŠ” ì‘ì—…ì„ ë§Œë“¤ê³  ìˆìŠµë‹ˆë‹¤.</li>\n<li>extract_taskì—ì„œ í˜¸ì¶œë˜ëŠ” callable í•¨ìˆ˜ì¸ extract_dataë¥¼ ì •ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” YouTube Data APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ \"Youtube_Trending_Data_Raw\"ë¡œ ì‹œì‘í•˜ëŠ” CSV íŒŒì¼ì— pandas DataFrameì„ ì‚¬ìš©í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.</li>\n</ul>\n<p>YouTube Data API ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì—¬ APIì˜ ë‹¤ë¥¸ ë¶€ë¶„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì— ëŒ€í•´ ìì„¸íˆ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” íŠ¸ë Œë”© ë¹„ë””ì˜¤ ë°ì´í„°ì— ê´€ì‹¬ì´ ìˆìœ¼ë¯€ë¡œ APIì˜ í•´ë‹¹ ë¶€ë¶„ì— ì§‘ì¤‘í•  ê²ƒì…ë‹ˆë‹¤. next_page_tokenì€ ëª¨ë“  í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.</p>\n<p>ì½”ë“œë¥¼ ìˆ˜ì •í•œ í›„ Airflow í˜ì´ì§€ì— ë³€ê²½ ì‚¬í•­ì´ ë°˜ì˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. DAGë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•˜ë ¤ë©´ ì™¼ìª½ ìƒë‹¨ì— ìˆëŠ” ì‹¤í–‰ ë²„íŠ¼ì„ í´ë¦­í•˜ì‹œë©´ ë©ë‹ˆë‹¤. ê·¸ë˜í”„ì—ì„œ ì‘ì—… ìƒíƒœ (ëŒ€ê¸°, ì‹¤í–‰ ì¤‘, ì„±ê³µ ë“±)ëŠ” ë‹¤ë¥¸ ìƒ‰ìƒìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. DAGê°€ ì‹¤í–‰ ì¤‘ì¼ ë•Œ ë¡œê·¸ë¥¼ ë³´ì‹¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.</p>\n<p>ëŸ° ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  íŒŒì¼ì— ì €ì¥í•˜ëŠ” ë° ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤. ì‘ì—…ì˜ ê° ë‹¨ê³„ì—ì„œ ê·¸ë˜í”„ ìƒ‰ìƒì´ ë³€ê²½ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆì„ ê±°ì—ìš”. ë©‹ì§€ì£ ? :)</p>\n<p>ì‘ì—… ìƒíƒœê°€ ì„±ê³µì„ ë‚˜íƒ€ë‚´ëŠ” ë…¹ìƒ‰ìœ¼ë¡œ ë³€í•˜ë©´, ìƒˆ íŒŒì¼ì¸ \"Youtube-Trending-Data-Raw\"ê°€ ìƒê¸´ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.</p>\n<p>ìš°ë¦¬ì˜ Raw ë°ì´í„°ëŠ” ì´ë ‡ê²Œ ìƒê²¼ì–´ìš”:</p>\n<p><img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_6.png\" alt=\"ì´ë¯¸ì§€\"></p>\n<p>ì´ì œ ì¶”ì¶œ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‘ì—…ìœ¼ë¡œ ë„˜ì–´ê°€ ë´…ì‹œë‹¤!</p>\n<h2>3. PySparkë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ë³€í™˜í•˜ê¸°:</h2>\n<p>ì›ì‹œ ë°ì´í„° íŒŒì¼ì„ ì‚´í´ë³´ë©´ ë°ì´í„°ì— ë§ì€ í•´ì‹œíƒœê·¸ì™€ ì´ëª¨ì§€ê°€ ìˆëŠ”ë°, ì´ëŠ” ìš°ë¦¬ í”„ë¡œì íŠ¸ì—ëŠ” í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ì •ë¦¬í•˜ì—¬ ì¶”ê°€ ë¶„ì„ì— ìœ ìš©í•˜ë„ë¡ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.</p>\n<p>ì´ ì‘ì—…ì— PySparkë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. PySparkëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„¸íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ë³€í™˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì„¤ê³„ëœ ê°•ë ¥í•œ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë°ì´í„° ì„¸íŠ¸ê°€ íŠ¹íˆ í¬ì§€ ì•Šê¸° ë•Œë¬¸ì— Pandasë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì „ì— PySparkë¥¼ ì‚¬ìš©í•œ ì ì´ ìˆì–´ ì´ë²ˆì—ë„ PySparkë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ìµœê·¼ PySparkë¥¼ ê³µë¶€í•˜ê³  ìˆìœ¼ë©°, ì´ë¡ ì„ ê³µë¶€í•˜ëŠ” ê²ƒë³´ë‹¤ ì‹¤ì œ êµ¬í˜„ì´ ë” í¥ë¯¸ë¡­ë‹¤ê³  ëŠë‚ë‹ˆë‹¤.</p>\n<h1>Python callable function to extract data from YouTube API</h1>\n<p>def extract_data(**kwargs):\napi_key = kwargs['api_key']\nregion_codes = kwargs['region_codes']\ncategory_ids = kwargs['category_ids']</p>\n<pre><code>df_trending_videos = fetch_data(api_key, region_codes, category_ids)\ncurrent_date = datetime.now().strftime(\"%Y%m%d\")\noutput_path = f'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'\n# Save DataFrame to CSV file\ndf_trending_videos.to_csv(output_path, index=False)\n</code></pre>\n<p>def fetch_data(api_key, region_codes, category_ids):\n\"\"\"\nFetches trending video data for multiple countries and categories from YouTube API.\nReturns a pandas data frame containing video data.\n\"\"\"\nvideo_data = []</p>\n<pre><code># Build YouTube API service\nyoutube = build('youtube', 'v3', developerKey=api_key)\n\nfor region_code in region_codes:\n    for category_id in category_ids:\n        # Initialize the next_page_token to None for each region and category\n        next_page_token = None\n        while True:\n            # Make a request to the YouTube API to fetch trending videos\n            request = youtube.videos().list(\n                part='snippet,contentDetails,statistics',\n                chart='mostPopular',\n                regionCode=region_code,\n                videoCategoryId=category_id,\n                maxResults=50,\n                pageToken=next_page_token\n            )\n            response = request.execute()\n            videos = response['items']\n\n            # Process each video and collect data\n            for video in videos:\n                video_info = {\n                    'region_code': region_code,\n                    'category_id': category_id,\n                    'video_id': video['id'],\n                    'title': video['snippet']['title'],\n                    'published_at': video['snippet']['publishedAt'],\n                    'view_count': video['statistics'].get('viewCount', 0),\n                    'like_count': video['statistics'].get('likeCount', 0),\n                    'comment_count': video['statistics'].get('commentCount', 0),\n                    'channel_title': video['snippet']['channelTitle']\n                }\n                video_data.append(video_info)\n\n            # Get the next page token, if there are more pages of results\n            next_page_token = response.get('nextPageToken')\n            if not next_page_token:\n                break\n\nreturn pd.DataFrame(video_data)\n</code></pre>\n<p>def preprocess_data_pyspark_job():\nspark = SparkSession.builder.appName('YouTubeTransform').getOrCreate()\ncurrent_date = datetime.now().strftime(\"%Y%m%d\")\noutput_path = f'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'\ndf = spark.read.csv(output_path, header=True)</p>\n<pre><code># Define UDF to remove hashtag data, emojis\ndef clean_text(text):\n if text is not None:\n    # Remove emojis\n    text = emoji.demojize(text, delimiters=('', ''))\n    \n    # Remove hashtag data\n    if text.startswith('#'):\n        text = text.replace('#', '').strip()\n    else:\n        split_text = text.split('#')\n        text = split_text[0].strip()\n    \n    # Remove extra double quotes and backslashes\n    text = text.replace('\\\\\"', '')  # Remove escaped quotes\n    text = re.sub(r'\\\"+', '', text)  # Remove remaining double quotes\n    text = text.replace('\\\\', '')  # Remove backslashes\n    \n    return text.strip()  # Strip any leading or trailing whitespace\n\n return text\n# Register UDF\nclean_text_udf = udf(clean_text, StringType())\n\n# Clean the data\ndf_cleaned = df.withColumn('title', clean_text_udf(col('title'))) \\\n               .withColumn('channel_title', clean_text_udf(col('channel_title'))) \\\n               .withColumn('published_at', to_date(col('published_at'))) \\\n               .withColumn('view_count', col('view_count').cast(LongType())) \\\n               .withColumn('like_count', col('like_count').cast(LongType())) \\\n               .withColumn('comment_count', col('comment_count').cast(LongType())) \\\n               .dropna(subset=['video_id'])\n\n# Generate the filename based on the current date\ncurrent_date = datetime.now().strftime(\"%Y%m%d\")\noutput_path = f'/opt/airflow/Transformed_Youtube_Data_{current_date}'\n\n# Write cleaned DataFrame to the specified path\ndf_cleaned.write.csv(output_path, header=True, mode='overwrite')   \n</code></pre>\n<h1>Define extract task for the DAG</h1>\n<p>extract_task = PythonOperator(\ntask_id='extract_data_from_youtube_api',\npython_callable=extract_data,\nop_kwargs={\n'api_key': os.getenv('YOUTUBE_API_KEY'),\n'region_codes': ['US', 'GB', 'IN', 'AU', 'NZ'],\n'category_ids': ['1', '2', '10', '15', '20', '22', '23']\n},\ndag=dag,\n)</p>\n<h1>Define preprocessing task for the DAG</h1>\n<p>preprocess_data_pyspark_task= PythonOperator(\ntask_id='preprocess_data_pyspark_task',\npython_callable=preprocess_data_pyspark_job,\ndag=dag\n)</p>\n<p>extract_task >> preprocess_data_pyspark_task</p>\n<p>ì—¬ê¸°ì„œëŠ” ì´ ì½”ë“œê°€ í•˜ëŠ” ì¼ì„ ì„¤ëª…í•´ ë“œë ¸ìŠµë‹ˆë‹¤.</p>\n<ul>\n<li>\"preprocess_data_pyspark_task\"ë¼ëŠ” ì‘ì—…ì„ ë§Œë“­ë‹ˆë‹¤.</li>\n<li>ì´ ì‘ì—…ì€ preprocess_data_pyspark_job í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.</li>\n<li>preprocess_data_pyspark_job í•¨ìˆ˜ëŠ” ë°ì´í„°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.</li>\n<li>ê·¸ë¦¬ê³  ì •ë¦¬ëœ ë°ì´í„°ëŠ” \"Transformed_Youtube_Data_currentDate\"ë¼ëŠ” í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.</li>\n<li>ì´ í´ë” ì•ˆì—ëŠ” ì •ë¦¬ëœ ë°ì´í„°ê°€ ë‹´ê¸´ \"part-\" ì ‘ë‘ì‚¬ê°€ ë¶™ì€ ìƒˆ CSV íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.</li>\n</ul>\n<p>ë§Œì•½ Airflowë¥¼ ë³´ì‹ ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ ì²« ë²ˆì§¸ ì‘ì—…ì— ìƒˆë¡œìš´ ì‘ì—…ì´ ì¶”ê°€ëœ ê²ƒì„ ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:</p>\n<p>ì•„ë˜ëŠ” ìš°ë¦¬ê°€ ë³€í™˜í•œ ë°ì´í„°ì˜ ëª¨ìŠµì…ë‹ˆë‹¤:</p>\n<p><img src=\"/assets/img/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_8.png\" alt=\"Transformed Data\"></p>\n<p>ì´ ì‘ì—…ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ìµœì¢… ì‘ì—…ìœ¼ë¡œ ë„˜ì–´ê°ˆ ì°¨ë¡€ì…ë‹ˆë‹¤.</p>\n<h1>4. S3ë¡œ ë°ì´í„° ë¡œë“œí•˜ê¸°:</h1>\n<p>ì´ ì‘ì—…ì„ ì‹œì‘í•˜ê¸° ì „ì— ì²˜ìŒì— ì„¤ì •í•œ IAM ì‚¬ìš©ìë¥¼ ì‚¬ìš©í•˜ì—¬ S3 ë²„í‚·ì„ ìƒì„±í•˜ê³  ë²„í‚· ì´ë¦„ì„ ë©”ëª¨í•´ì£¼ì„¸ìš”.</p>\n<p>ìš°ë¦¬ì˜ ìµœì¢… ì½”ë“œì…ë‹ˆë‹¤!</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> logging\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> re\n<span class=\"hljs-keyword\">import</span> shutil\n<span class=\"hljs-keyword\">from</span> datetime <span class=\"hljs-keyword\">import</span> datetime, timedelta\n\n<span class=\"hljs-keyword\">import</span> boto3\n<span class=\"hljs-keyword\">import</span> emoji\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> googleapiclient.<span class=\"hljs-property\">discovery</span> <span class=\"hljs-keyword\">import</span> build\n<span class=\"hljs-keyword\">from</span> pyspark.<span class=\"hljs-property\">sql</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">SparkSession</span>\n<span class=\"hljs-keyword\">from</span> pyspark.<span class=\"hljs-property\">sql</span>.<span class=\"hljs-property\">functions</span> <span class=\"hljs-keyword\">import</span> col, to_date, udf\n<span class=\"hljs-keyword\">from</span> pyspark.<span class=\"hljs-property\">sql</span>.<span class=\"hljs-property\">types</span> <span class=\"hljs-keyword\">import</span> (<span class=\"hljs-title class_\">DateType</span>, <span class=\"hljs-title class_\">IntegerType</span>, <span class=\"hljs-title class_\">LongType</span>, <span class=\"hljs-title class_\">StringType</span>,\n                               <span class=\"hljs-title class_\">StructField</span>, <span class=\"hljs-title class_\">StructType</span>)\n\n<span class=\"hljs-keyword\">from</span> airflow <span class=\"hljs-keyword\">import</span> <span class=\"hljs-variable constant_\">DAG</span>\n<span class=\"hljs-keyword\">from</span> airflow.<span class=\"hljs-property\">operators</span>.<span class=\"hljs-property\">python_operator</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">PythonOperator</span>\n\n# <span class=\"hljs-variable constant_\">DAG</span> ë° ê¸°ë³¸ ì¸ì ì •ì˜\ndefault_args = {\n    <span class=\"hljs-string\">'owner'</span>: <span class=\"hljs-string\">'airflow'</span>,  # <span class=\"hljs-variable constant_\">DAG</span> ì†Œìœ ì\n    <span class=\"hljs-string\">'depends_on_past'</span>: <span class=\"hljs-title class_\">False</span>,  # ì´ì „ <span class=\"hljs-variable constant_\">DAG</span> ì‹¤í–‰ì— ì˜ì¡´ ì—¬ë¶€\n    <span class=\"hljs-string\">'email_on_failure'</span>: <span class=\"hljs-title class_\">False</span>,  # ì‹¤íŒ¨ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    <span class=\"hljs-string\">'email_on_retry'</span>: <span class=\"hljs-title class_\">False</span>,  # ì¬ì‹œë„ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ë¹„í™œì„±í™”\n    <span class=\"hljs-string\">'retries'</span>: <span class=\"hljs-number\">1</span>,  # ì¬ì‹œë„ íšŸìˆ˜\n    <span class=\"hljs-string\">'retry_delay'</span>: <span class=\"hljs-title function_\">timedelta</span>(minutes=<span class=\"hljs-number\">5</span>),  # ì¬ì‹œë„ ì‚¬ì´ ê°„ê²©\n    <span class=\"hljs-string\">'start_date'</span>: <span class=\"hljs-title function_\">datetime</span>(<span class=\"hljs-number\">2023</span>, <span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>),  # ë§¤ì¼ ìì •(<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>) <span class=\"hljs-variable constant_\">UTC</span>ì— ì‹¤í–‰\n}\n\n# <span class=\"hljs-variable constant_\">DAG</span> ì •ì˜\ndag = <span class=\"hljs-title function_\">DAG</span>(\n    <span class=\"hljs-string\">'youtube_etl_dag'</span>,  # <span class=\"hljs-variable constant_\">DAG</span> ì‹ë³„ì\n    default_args=default_args,  # ê¸°ë³¸ ì¸ìˆ˜ í• ë‹¹\n    description=<span class=\"hljs-string\">'ê°„ë‹¨í•œ ETL DAG'</span>,  # <span class=\"hljs-variable constant_\">DAG</span> ì„¤ëª…\n    schedule_interval=<span class=\"hljs-title function_\">timedelta</span>(days=<span class=\"hljs-number\">1</span>),  # ìŠ¤ì¼€ì¤„ ê°„ê²©: ë§¤ì¼\n    catchup=<span class=\"hljs-title class_\">False</span>,  # ëˆ„ë½ëœ <span class=\"hljs-variable constant_\">DAG</span> ì‹¤í–‰ì„ ë³µêµ¬í•˜ì§€ ì•ŠìŒ\n)\n\n# <span class=\"hljs-title class_\">YouTube</span> <span class=\"hljs-variable constant_\">API</span>ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ëŠ” <span class=\"hljs-title class_\">Python</span> ìœ í˜•ì˜ í•¨ìˆ˜\ndef <span class=\"hljs-title function_\">extract_data</span>(**kwargs):\n    api_key = kwargs[<span class=\"hljs-string\">'api_key'</span>]\n    region_codes = kwargs[<span class=\"hljs-string\">'region_codes'</span>]\n    category_ids = kwargs[<span class=\"hljs-string\">'category_ids'</span>]\n    \n    df_trending_videos = <span class=\"hljs-title function_\">fetch_data</span>(api_key, region_codes, category_ids)\n    current_date = datetime.<span class=\"hljs-title function_\">now</span>().<span class=\"hljs-title function_\">strftime</span>(<span class=\"hljs-string\">\"%Y%m%d\"</span>)\n    output_path = f<span class=\"hljs-string\">'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'</span>\n    # <span class=\"hljs-title class_\">DataFrame</span>ì„ <span class=\"hljs-variable constant_\">CSV</span> íŒŒì¼ë¡œ ì €ì¥\n    df_trending_videos.<span class=\"hljs-title function_\">to_csv</span>(output_path, index=<span class=\"hljs-title class_\">False</span>)\n\n# <span class=\"hljs-title class_\">YouTube</span> <span class=\"hljs-variable constant_\">API</span>ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\ndef <span class=\"hljs-title function_\">fetch_data</span>(api_key, region_codes, category_ids):\n    <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n    YouTube APIì—ì„œ ì—¬ëŸ¬ êµ­ê°€ ë° ì¹´í…Œê³ ë¦¬ì˜ íŠ¸ë Œë“œ ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n    ë¹„ë””ì˜¤ ë°ì´í„°ê°€ í¬í•¨ëœ Pandas ë°ì´í„° í”„ë ˆì„ ë°˜í™˜.\n    \"</span><span class=\"hljs-string\">\"\"</span>\n    # ë¹„ë””ì˜¤ ë°ì´í„°ë¥¼ ë³´ê´€í•  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n    video_data = []\n\n    # <span class=\"hljs-title class_\">YouTube</span> <span class=\"hljs-variable constant_\">API</span> ì„œë¹„ìŠ¤ ë¹Œë“œ\n    youtube = <span class=\"hljs-title function_\">build</span>(<span class=\"hljs-string\">'youtube'</span>, <span class=\"hljs-string\">'v3'</span>, developerKey=api_key)\n\n    <span class=\"hljs-keyword\">for</span> region_code <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">region_codes</span>:\n        <span class=\"hljs-keyword\">for</span> category_id <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">category_ids</span>:\n            # ê° ì§€ì—­ ë° ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ next_page_tokenì„ <span class=\"hljs-title class_\">None</span>ìœ¼ë¡œ ì´ˆê¸°í™”\n            next_page_token = <span class=\"hljs-title class_\">None</span>\n            <span class=\"hljs-keyword\">while</span> <span class=\"hljs-title class_\">True</span>:\n                # <span class=\"hljs-title class_\">YouTube</span> <span class=\"hljs-variable constant_\">API</span>ì— íŠ¸ë Œë“œ ë¹„ë””ì˜¤ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ìš”ì²­\n                request = youtube.<span class=\"hljs-title function_\">videos</span>().<span class=\"hljs-title function_\">list</span>(\n                    part=<span class=\"hljs-string\">'snippet,contentDetails,statistics'</span>,\n                    chart=<span class=\"hljs-string\">'mostPopular'</span>,\n                    regionCode=region_code,\n                    videoCategoryId=category_id,\n                    maxResults=<span class=\"hljs-number\">50</span>,\n                    pageToken=next_page_token\n                )\n                response = request.<span class=\"hljs-title function_\">execute</span>()\n                videos = response[<span class=\"hljs-string\">'items'</span>]\n\n                # ê° ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° ë°ì´í„° ìˆ˜ì§‘\n                <span class=\"hljs-keyword\">for</span> video <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">videos</span>:\n                    video_info = {\n                        <span class=\"hljs-string\">'region_code'</span>: region_code,\n                        <span class=\"hljs-string\">'category_id'</span>: category_id,\n                        <span class=\"hljs-string\">'video_id'</span>: video[<span class=\"hljs-string\">'id'</span>],\n                        <span class=\"hljs-string\">'title'</span>: video[<span class=\"hljs-string\">'snippet'</span>][<span class=\"hljs-string\">'title'</span>],\n                        <span class=\"hljs-string\">'published_at'</span>: video[<span class=\"hljs-string\">'snippet'</span>][<span class=\"hljs-string\">'publishedAt'</span>],\n                        <span class=\"hljs-string\">'view_count'</span>: video[<span class=\"hljs-string\">'statistics'</span>].<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'viewCount'</span>, <span class=\"hljs-number\">0</span>),\n                        <span class=\"hljs-string\">'like_count'</span>: video[<span class=\"hljs-string\">'statistics'</span>].<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'likeCount'</span>, <span class=\"hljs-number\">0</span>),\n                        <span class=\"hljs-string\">'comment_count'</span>: video[<span class=\"hljs-string\">'statistics'</span>].<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'commentCount'</span>, <span class=\"hljs-number\">0</span>),\n                        <span class=\"hljs-string\">'channel_title'</span>: video[<span class=\"hljs-string\">'snippet'</span>][<span class=\"hljs-string\">'channelTitle'</span>]\n                    }\n                    video_data.<span class=\"hljs-title function_\">append</span>(video_info)\n\n                # ê²°ê³¼ì˜ ì¶”ê°€ í˜ì´ì§€ê°€ ìˆëŠ” ê²½ìš° ë‹¤ìŒ í˜ì´ì§€ í† í° ê°€ì ¸ì˜¤ê¸°\n                next_page_token = response.<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">'nextPageToken'</span>)\n                <span class=\"hljs-keyword\">if</span> not <span class=\"hljs-attr\">next_page_token</span>:\n                    <span class=\"hljs-keyword\">break</span>\n\n    <span class=\"hljs-keyword\">return</span> pd.<span class=\"hljs-title class_\">DataFrame</span>(video_data)\n\n# <span class=\"hljs-title class_\">PySpark</span> ì‘ì—… ì „ì²˜ë¦¬ í•¨ìˆ˜\ndef <span class=\"hljs-title function_\">preprocess_data_pyspark_job</span>():\n    spark = <span class=\"hljs-title class_\">SparkSession</span>.<span class=\"hljs-property\">builder</span>.<span class=\"hljs-title function_\">appName</span>(<span class=\"hljs-string\">'YouTubeTransform'</span>).<span class=\"hljs-title function_\">getOrCreate</span>()\n    current_date = datetime.<span class=\"hljs-title function_\">now</span>().<span class=\"hljs-title function_\">strftime</span>(<span class=\"hljs-string\">\"%Y%m%d\"</span>)\n    output_path = f<span class=\"hljs-string\">'/opt/airflow/Youtube_Trending_Data_Raw_{current_date}'</span>\n    df = spark.<span class=\"hljs-property\">read</span>.<span class=\"hljs-title function_\">csv</span>(output_path, header=<span class=\"hljs-title class_\">True</span>)\n    \n    # í•´ì‹œíƒœê·¸ ë°ì´í„°, ì´ëª¨ì§€ ì œê±°ë¥¼ ìœ„í•œ <span class=\"hljs-variable constant_\">UDF</span> ì •ì˜\n    def <span class=\"hljs-title function_\">clean_text</span>(text):\n     <span class=\"hljs-keyword\">if</span> text is not <span class=\"hljs-title class_\">None</span>:\n        # ì´ëª¨ì§€ ì œê±°\n        text = emoji.<span class=\"hljs-title function_\">demojize</span>(text, delimiters=(<span class=\"hljs-string\">''</span>, <span class=\"hljs-string\">''</span>))\n        \n        # í•´ì‹œíƒœê·¸ ë° ì´í›„ ëª¨ë“  ê²ƒ ì œê±°\n        <span class=\"hljs-keyword\">if</span> text.<span class=\"hljs-title function_\">startswith</span>(<span class=\"hljs-string\">'#'</span>):\n            text = text.<span class=\"hljs-title function_\">replace</span>(<span class=\"hljs-string\">'#'</span>, <span class=\"hljs-string\">''</span>).<span class=\"hljs-title function_\">strip</span>()\n        <span class=\"hljs-attr\">else</span>:\n            split_text = text.<span class=\"hljs-title function_\">split</span>(<span class=\"hljs-string\">'#'</span>)\n            text = split_text[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">strip</span>()\n        \n        # ì¶”ê°€ ì´ì¤‘ ì¸ìš©ë¶€í˜¸ì™€ ë°±ìŠ¬ë˜ì‹œ ì œê±°\n        text = text.<span class=\"hljs-title function_\">replace</span>(<span class=\"hljs-string\">'\\\\\"'</span>, <span class=\"hljs-string\">''</span>)  # ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œ ì œê±°\n        text = re.<span class=\"hljs-title function_\">sub</span>(r<span class=\"hljs-string\">'\\\"+'</span>, <span class=\"hljs-string\">''</span>, text)  # ë‚¨ì€ ì´ì¤‘ ì¸ìš©ë¶€í˜¸ ì œê±°\n        text = text.<span class=\"hljs-title function_\">replace</span>(<span class=\"hljs-string\">'\\\\'</span>, <span class=\"hljs-string\">''</span>)  # ë°±ìŠ¬ë˜ì‹œ ì œê±°\n        \n        <span class=\"hljs-keyword\">return</span> text.<span class=\"hljs-title function_\">strip</span>()  # ì„ í–‰ ë˜ëŠ” í›„í–‰ ê³µë°± ì œê±°\n\n     <span class=\"hljs-keyword\">return</span> text\n    # <span class=\"hljs-variable constant_\">UDF</span> ë“±ë¡\n    clean_text_udf = <span class=\"hljs-title function_\">udf</span>(clean_text, <span class=\"hljs-title class_\">StringType</span>())\n\n    # ë°ì´í„° ì •ë¦¬\n    df_cleaned = df.<span class=\"hljs-title function_\">withColumn</span>(<span class=\"hljs-string\">'title'</span>, <span class=\"hljs-title function_\">clean_text_udf</span>(<span class=\"hljs-title function_\">col</span>(<span class=\"hljs-string\">'title'</span>))) \\\n                   .<span class=\"hljs-title function_\">withColumn</span>(<span class=\"hljs-string\">'channel_title'</span>, <span class=\"hljs-title function_\">clean_text_udf</span>(<span class=\"hljs-title function_\">col</span>(<span class=\"hljs-string\">'channel_title'</span>))) \\\n                   .<span class=\"hljs-title function_\">withColumn</span>(<span class=\"hljs-string\">'published_at'</span>, <span class=\"hljs-title function_\">to_date</span>(<span class=\"hljs-title function_\">col</span>(<span class=\"hljs-string\">'published_at'</span>))) \\\n                   .<span class=\"hljs-title function_\">withColumn</span>(<span class=\"hljs-string\">'view_count'</span>, <span class=\"hljs-title function_\">col</span>(<span class=\"hljs-string\">'view_count'</span>).<span class=\"hljs-title function_\">cast</span>(<span class=\"hljs-title class_\">LongType</span>())) \\\n                   .<span class=\"hljs-title function_\">withColumn</span>(<span class=\"hljs-string\">'like_count'</span>, <span class=\"hljs-title function_\">col</span>(<span class=\"hljs-string\">'like_count'</span>).<span class=\"hljs-title function_\">cast</span>(<span class=\"hljs-title class_\">LongType</span>())) \\\n                   .<span class=\"hljs-title function_\">withColumn</span>(<span class=\"hljs-string\">'comment_count'</span>, <span class=\"hljs-title function_\">col</span>(<span class=\"hljs-string\">'comment_count'</span>).<span class=\"hljs-title function_\">cast</span>(<span class=\"hljs-title class_\">LongType</span>())) \\\n                   .<span class=\"hljs-title function_\">dropna</span>(subset=[<span class=\"hljs-string\">'video_id'</span>])\n    \n    # í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ ì´ë¦„ ìƒì„±\n    current_date = datetime.<span class=\"hljs-title function_\">now</span>().<span class=\"hljs-title function_\">strftime</span>(<span class=\"hljs-string\">\"%Y%m%d\"</span>)\n    output_path = f<span class=\"hljs-string\">'/opt/airflow/Transformed_Youtube_Data_{current_date}'</span>\n    \n    # ì •ë¦¬ëœ <span class=\"hljs-title class_\">DataFrame</span>ì„ ì§€ì •ëœ ê²½ë¡œì— ì‘ì„±\n    df_cleaned.<span class=\"hljs-property\">write</span>.<span class=\"hljs-title function_\">csv</span>(output_path, header=<span class=\"hljs-title class_\">True</span>, mode=<span class=\"hljs-string\">'overwrite'</span>)   \n\n# <span class=\"hljs-variable constant_\">S3</span>ë¡œ ë°ì´í„° ì—…ë¡œë“œ í•¨ìˆ˜\ndef <span class=\"hljs-title function_\">load_data_to_s3</span>(**kwargs):\n    bucket_name = kwargs[<span class=\"hljs-string\">'bucket_name'</span>]\n    today = datetime.<span class=\"hljs-title function_\">now</span>().<span class=\"hljs-title function_\">strftime</span>(<span class=\"hljs-string\">'%Y/%m/%d'</span>)\n    prefix = f<span class=\"hljs-string\">\"processed-data/{today}\"</span>\n    current_date = datetime.<span class=\"hljs-title function_\">now</span>().<span class=\"hljs-title function_\">strftime</span>(<span class=\"hljs-string\">\"%Y%m%d\"</span>)\n    local_dir_path  = f<span class=\"hljs-string\">'/opt/airflow/Transformed_Youtube_Data_{current_date}'</span>\n    <span class=\"hljs-title function_\">upload_to_s3</span>(bucket_name, prefix, local_dir_path)\n\ndef <span class=\"hljs-title function_\">upload_to_s3</span>(bucket_name, prefix, local_dir_path):\n    aws_access_key_id = os.<span class=\"hljs-title function_\">getenv</span>(<span class=\"hljs-string\">'AWS_ACCESS_KEY_ID'</span>)\n    aws_secret_access_key = os.<span class=\"hljs-title function_\">getenv</span>(<span class=\"hljs-string\">'AWS_SECRET_ACCESS_KEY'</span>)\n\n    s3_client = boto3.<span class=\"hljs-title function_\">client</span>(\n        <span class=\"hljs-string\">'s3'</span>,\n        aws_access_key_id=aws_access_key_id,\n        aws_secret_access_key=aws_secret_access_key\n    )\n\n    <span class=\"hljs-keyword\">for</span> root, dirs, files <span class=\"hljs-keyword\">in</span> os.<span class=\"hljs-title function_\">walk</span>(local_dir_path):\n         <span class=\"hljs-keyword\">for</span> file <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">files</span>:\n            <span class=\"hljs-keyword\">if</span> file.<span class=\"hljs-title function_\">endswith</span>(<span class=\"hljs-string\">'.csv'</span>):\n                file_path = os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">join</span>(root, file)\n                s3_key = f<span class=\"hljs-string\">\"{prefix}/{file}\"</span>\n                logging.<span class=\"hljs-title function_\">info</span>(f<span class=\"hljs-string\">\"Uploading {file_path} to s3://{bucket_name}/{s3_key}\"</span>)\n                s3_client.<span class=\"hljs-title function_\">upload_file</span>(file_path, bucket_name, s3_key)\n\n# <span class=\"hljs-variable constant_\">DAG</span>ì˜ ì¶”ì¶œ ì‘ì—… ì •ì˜\nextract_task = <span class=\"hljs-title class_\">PythonOperator</span>(\n    task_id=<span class=\"hljs-string\">'extract_data_from_youtube_api'</span>,\n    python_callable=extract_data,\n    op_kwargs={\n        <span class=\"hljs-string\">'api_key'</span>: os.<span class=\"hljs-title function_\">getenv</span>(<span class=\"hljs-string\">'YOUTUBE_API_KEY'</span>),\n        <span class=\"hljs-string\">'region_codes'</span>: [<span class=\"hljs-string\">'US'</span>, <span class=\"hljs-string\">'GB'</span>, <span class=\"hljs-string\">'IN'</span>, <span class=\"hljs-string\">'AU'</span>, <span class=\"hljs-string\">'NZ'</span>],\n        <span class=\"hljs-string\">'category_ids'</span>: [<span class=\"hljs-string\">'1'</span>, <span class=\"hljs-string\">'2'</span>, <span class=\"hljs-string\">'10'</span>, <span class=\"hljs-string\">'15'</span>, <span class=\"hljs-string\">'20'</span>, <span class=\"hljs-string\">'22'</span>, <span class=\"hljs-string\">'23'</span>]\n    },\n    dag=dag,\n)\n\n# <span class=\"hljs-variable constant_\">DAG</span>ì˜ ë°ì´í„° ì „ì²˜ë¦¬ ì‘ì—… ì •ì˜\npreprocess_data_pyspark_task= <span class=\"hljs-title class_\">PythonOperator</span>(\n    task_id=<span class=\"hljs-string\">'preprocess_data_pyspark_task'</span>,\n    python_callable=preprocess_data_pyspark_job,\n    dag=dag\n)\n\n\n\n&#x3C;div <span class=\"hljs-keyword\">class</span>=<span class=\"hljs-string\">\"content-ad\"</span>>&#x3C;/div>\n\nì´ì œ ì €í¬ê°€ ë§Œë“  ìµœì¢… ì‘ì—…ì¸ load_data_to_s3_taskë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ì‘ì—…ì€ load_data_to_s3 í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ íŒŒì¼ì„ <span class=\"hljs-variable constant_\">S3</span> ë²„í‚·ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤. ì—…ë¡œë“œê°€ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ <span class=\"hljs-variable constant_\">S3</span> ë²„í‚·ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.\n\në§ˆì¹¨ë‚´ ìš°ë¦¬ì˜ <span class=\"hljs-title class_\">Airflow</span>ëŠ” ì´ë ‡ê²Œ ìƒê²¼ìŠµë‹ˆë‹¤!\n\n![<span class=\"hljs-title class_\">Airflow</span>](<span class=\"hljs-regexp\">/assets/img</span><span class=\"hljs-regexp\">/2024-06-19-YouTubeTrendAnalysisPipelineETLwithAirflowSparkS3andDocker_9.png)\n\nì´ì œ ì´ ë°ì´í„°ë¥¼ Tableauë‚˜ ë‹¤ë¥¸ BI ë„êµ¬ì— ì—°ê²°í•˜ì—¬ í¥ë¯¸ë¡œìš´ ëŒ€ì‹œë³´ë“œë¥¼ ë§Œë“¤ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ì‹œê°í™”í•´ ë³´ì„¸ìš”!\n\n&#x3C;div class=\"content-ad\">&#x3C;/</span>div>\n\ní•¨ê»˜ ì´ íŒŒì´í”„ë¼ì¸ì„ ë”°ë¼ ì˜¤ë©´ì„œ ìƒˆë¡œìš´ ê¸°ìˆ  ëª‡ ê°€ì§€ë¥¼ ë°°ì› ìœ¼ë©´ ì¢‹ê² ì–´ìš”! ğŸš€ ì„±ê³µì ìœ¼ë¡œ ì—¬ê¸°ê¹Œì§€ ì™”ë‹¤ë©´ ì¶•í•˜í•´ìš”! ğŸ‰ ì´ ìƒˆë¡­ê²Œ ì–»ì€ ì§€ì‹ì´ ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ì—ì„œì˜ í–¥í›„ ëª¨í—˜ì— í° ë„ì›€ì´ ë˜ê¸¸ ë°”ë˜ìš”!\n\nì´ í”„ë¡œì íŠ¸ì˜ <span class=\"hljs-title class_\">Github</span> ì €ì¥ì†Œë¥¼ ì²¨ë¶€í•©ë‹ˆë‹¤:\n\në§Œì•½ ì´ ê¸€ì„ ì¢‹ì•„í•˜ì…¨ë‹¤ë©´, ê³µìœ í•˜ê³ , ì¢‹ì•„ìš”ë¥¼ ëˆŒëŸ¬ì£¼ì‹œê³ , ì•„ë˜ì— ëŒ“ê¸€ì„ ë‚¨ê²¨ì£¼ì‹œê³  êµ¬ë…í•´ì£¼ì„¸ìš”. ğŸ‰ğŸ‘ğŸ“\n\nì»¤íŠ¼ì„ ë‹«ìŠµë‹ˆë‹¤! ğŸ­\n</code></pre>\n</body>\n</html>\n"},"__N_SSG":true}