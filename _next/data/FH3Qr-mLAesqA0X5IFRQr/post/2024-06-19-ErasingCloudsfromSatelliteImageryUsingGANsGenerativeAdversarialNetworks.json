{"pageProps":{"post":{"title":"위성 이미지에서 GANs적대적 생성 신경망을 사용하여 구름 제거하기","description":"","date":"2024-06-19 18:49","slug":"2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks","content":"\n\n## 파이썬으로부터 GAN(Generative Adversarial Networks) 만들어 보기\n\n![이미지](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png)\n\nGAN(Generative Adversarial Networks)이라는 아이디어는 2014년 Goodfellow와 그 동료들에 의해 소개되었고, 곧 그 이후에 컴퓨터 비전 및 이미지 생성 분야에서 극도로 인기를 끌게 되었습니다. 인공지능 분야에서의 급속한 발전과 새로운 알고리즘의 수가 늘어나는 것을 고려하더라도, 이 개념의 단순함과 창의성은 여전히 매우 인상적입니다. 그래서 오늘은 이러한 네트워크가 얼마나 강력할 수 있는지를 보여주기 위해 위성 RGB(빨강, 녹색, 파랑) 이미지에서 구름을 제거하는 시도를 해보려고 합니다.\n\n적절히 균형 잡히고 충분히 크며 올바르게 전처리된 컴퓨터 비전 데이터셋을 준비하는 데에는 상당한 시간이 소요되므로, 저는 Kaggle에 어떤 것이 있는지 살펴보기로 결정했습니다. 이 작업에 가장 적합하다고 생각한 데이터셋은 EuroSat이며, 이는 오픈 라이선스를 가지고 있습니다. 이 데이터셋은 Sentinel-2에서 64x64 픽셀의 27000개의 레이블이 지정된 RGB 이미지로 구성되어 있고, 다중 클래스 분류 문제를 해결하기 위해 만들어졌습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_1.png)\n\n우리는 분류 자체에 흥미가 없지만 EuroSat 데이터셋의 주요 기능 중 하나는 모든 이미지에 맑은 하늘이 있습니다. 그것이 정확히 우리가 필요한 것입니다. [3]에서 이 접근법을 채택하여, 우리는 이 Sentinel-2 샷을 대상으로 사용하고 입력을 추가하여 (구름) 노이즈를 생성할 것입니다.\n\n그래서 우리가 GANs에 대해 실제로 이야기하기 전에 데이터를 준비해 봅시다. 우선, 데이터를 다운로드하고 모든 클래스를 하나의 디렉토리로 병합해야 합니다.\n\n🐍전체 Python 코드: GitHub.\n\n\n<div class=\"content-ad\"></div>\n\n```js\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom os import listdir, mkdir, rename\nfrom os.path import join, exists\nimport shutil\nimport datetime\n\nimport matplotlib.pyplot as plt\nfrom highlight_text import ax_text, fig_text\nfrom PIL import Image\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n```\n\n```js\nclasses = listdir('./EuroSat')\npath_target = './EuroSat/all_targets'\npath_input = './EuroSat/all_inputs'\n\n\"\"\"UNPACK한 아카이브 파일의 파일 이름을 변경하기 위해 단 한 번만 실행하세요\"\"\"\nmkdir(path_input)\nmkdir(path_target)\nk = 1\nfor kind in classes:\n  path = join('./EuroSat', str(kind))\n  for i, f in enumerate(listdir(path)):\n    shutil.copyfile(join(path, f),\n                  join(path_target, f))\n    rename(join(path_target, f), join(path_target, f'{k}.jpg'))\n    k += 1\n```\n\n중요한 두 번째 단계는 노이즈 생성입니다. 다양한 방법을 사용할 수 있지만, 예를 들어 일부 픽셀을 무작위로 마스킹하거나 가우시안 노이즈를 추가하는 등의 방법이 있습니다. 그러나 이 글에서는 저는 새로운 방식인 Perlin 노이즈를 시도해 보고 싶습니다. Perlin 노이즈는 80년대에 Ken Perlin이 영화 연기 효과를 개발할 때 발명했습니다. 이 종류의 노이즈는 일반적인 랜덤 노이즈에 비해 더 유기적인 외관을 가지고 있습니다. 저에게 이를 증명하는 기회를 주세요.\n\n```js\ndef generate_perlin_noise(width, height, scale, octaves, persistence, lacunarity):\n    noise = np.zeros((height, width))\n    for i in range(height):\n        for j in range(width):\n            noise[i][j] = pnoise2(i / scale,\n                                  j / scale,\n                                  octaves=octaves,\n                                  persistence=persistence,\n                                  lacunarity=lacunarity,\n                                  repeatx=width,\n                                  repeaty=height,\n                                  base=0)\n    return noise\n\ndef normalize_noise(noise):\n    min_val = noise.min()\n    max_val = noise.max()\n    return (noise - min_val) / (max_val - min_val)\n\ndef generate_clouds(width, height, base_scale, octaves, persistence, lacunarity):\n    clouds = np.zeros((height, width))\n    for octave in range(1, octaves + 1):\n        scale = base_scale / octave\n        layer = generate_perlin_noise(width, height, scale, 1, persistence, lacunarity)\n        clouds += layer * (persistence ** octave)\n\n    clouds = normalize_noise(clouds)\n    return clouds\n\ndef overlay_clouds(image, clouds, alpha=0.5):\n\n    clouds_rgb = np.stack([clouds] * 3, axis=-1)\n\n    image = image.astype(float) / 255.0\n    clouds_rgb = clouds_rgb.astype(float)\n\n    blended = image * (1 - alpha) + clouds_rgb * alpha\n\n    blended = (blended * 255).astype(np.uint8)\n    return blended\n```\n\n<div class=\"content-ad\"></div>\n\n```js\n가로, 세로 = 64, 64\n옥타브 = 12  # 합쳐지는 잡음 레이어의 수\n지속성 = 0.5  # 낮은 지속성은 높은 주파수 옥타브의 진폭을 줄입니다.\n라쿠나리티 = 2  # 높은 라쿠나리티는 높은 주파수 옥타브의 주파수를 늘립니다.\nfor i in range(len(listdir(path_target))):\n  기본_스케일 = random.uniform(5, 120)  # 잡음 주파수\n  알파 = random.uniform(0, 1)  # 투명도\n\n  구름 = generate_clouds(가로, 세로, 기본_스케일, 옥타브, 지속성, 라쿠나리티)\n\n  이미지 = np.asarray(Image.open(join(path_target, f'{i+1}.jpg')))\n  이미지 = Image.fromarray(overlay_clouds(이미지, 구름, 알파))\n  이미지.save(join(path_input, f'{i+1}.jpg'))\n  print(f'{i+1}/{len(listdir(path_target))}번째 처리 완료')\n```\n\n```js\n인덱스 = np.random.randint(27000)\nfig, ax = plt.subplots(1,2)\nax[0].imshow(np.asarray(Image.open(join(path_target, f'{인덱스}.jpg')))\nax[1].imshow(np.asarray(Image.open(join(path_input, f'{인덱스}.jpg')))\nax[0].set_title(\"원본\")\nax[0].axis('off')\nax[1].set_title(\"입력\")\nax[1].axis('off')\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_2.png\" />\n\n위에서 볼 수 있듯이 이미지의 구름은 매우 현실적이며 다양한 \"밀도\"와 질감을 가지며 실제 구름과 유사합니다.\n\n<div class=\"content-ad\"></div>\n\n만약 저처럼 Perlin 소음에 흥미를 느낀다면, 게임 개발 산업에서 이 소음이 어떻게 적용될 수 있는지에 대한 정말 멋진 비디오가 있어요!\n\n이제 우리가 사용할 준비가 된 데이터셋이 있으니, GANs에 대해 이야기해 보겠습니다.\n\n# 생성적 적대 신경망\n\n이 아이디어를 더 잘 설명하기 위해, 동남아시아를 여행하다가 밖이 너무 춥다고 느낄 때 후디가 절실하게 필요하다고 상상해 보세요. 가장 가까운 거리 시장에 가보니, 몇 가지 브랜드 의류가 있는 작은 가게를 발견했어요. 판매자가 유명한 브랜드 ExpensiveButNotWorthIt의 후디를 시도해보라며 괜찮은 후디를 가져다줍니다. 더 자세히 살펴보고 분명히 가짜라고 결론 내리게 됩니다. 판매자가 말합니다: '잠시만요, 진짜 것이 있어요.' 그가 다른 후디를 가져오는데, 브랜드 제품과 더 닮았지만 여전히 가짜입니다. 이와 같은 반복 작업을 몇 번 거친 후, 판매자가 전설적인 ExpensiveButNotWorthIt의 구별이 어려운 사본을 가져와 여러분은 기꺼이 구매하게 됩니다. 이것이 바로 GANs가 작동하는 방식입니다!\n\n<div class=\"content-ad\"></div>\n\nGAN의 경우, 당신은 판별자(D)라고 불립니다. 판별자의 목표는 진짜 물체와 가짜 물체를 구별하거나 이진 분류 작업을 수행하는 것입니다. 이에 반해, 생성자(G)는 높은 품질의 가짜를 생성하려고 하는 판매자라고 불립니다. 판별자와 생성자는 서로 능가하기 위해 독립적으로 훈련됩니다. 따라서 최종적으로 우리는 높은 품질의 가짜를 얻습니다.\n\n![이미지](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_3.png)\n\n훈련 과정은 일반적으로 다음과 같이 진행됩니다:\n\n- 입력 노이즈를 샘플링합니다 (우리의 경우 구름이 있는 이미지).\n- 노이즈를 생성자(G)에 공급하고 예측을 수집합니다.\n- D 손실을 계산합니다. G의 출력에 대한 하나와 실제 데이터에 대한 다른 예측을 얻어서 이루어집니다.\n- D의 가중치를 업데이트합니다.\n- 다시 입력 노이즈를 샘플링합니다.\n- 노이즈를 생성자(G)에 공급하고 예측을 수집합니다.\n- G 손실을 계산합니다. G의 예측을 D에 공급하여 이루어집니다.\n- G의 가중치를 업데이트합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Erasing Clouds from Satellite Imagery Using GANs](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_4.png)\n\nIn other words, we can define a value function V(G,D):\n\n![Value function V(G,D)](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_5.png)\n\nwhere we want to minimize the term log(1-D(G(z))) to train G and maximize log D(x) to train D (in this notation x — real data sample and z — noise).\n\n\n<div class=\"content-ad\"></div>\n\n이제 파이토치에서 구현해 봅시다!\n\n원본 논문에서 저자들은 Multilayer Perceptron (MLP)을 사용하는 것에 대해 언급합니다; 이것은 ANN으로 간단히도 불립니다만, 저는 미세한 접근을 시도하고 싶습니다 — Generator로 UNet [5] 아키텍처를 사용하고, Discriminator로는 ResNet [6]을 사용하고 싶습니다. 이들은 둘 다 잘 알려진 CNN 아키텍처이기 때문에 여기서 설명하지는 않겠습니다 (댓글에서 별도의 글을 쓸지 여부를 알려주세요).\n\n이제 구축해 봅시다. Discriminator:\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.utils.data import Subset\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n                        nn.BatchNorm2d(out_channels),\n                        nn.ReLU())\n        self.conv2 = nn.Sequential(\n                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n                        nn.BatchNorm2d(out_channels))\n        self.downsample = downsample\n        self.relu = nn.ReLU()\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.conv2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block=ResidualBlock, all_connections=[3,4,6,3]):\n        super(ResNet, self).__init__()\n        self.inputs = 16\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1),\n                        nn.BatchNorm2d(16),\n                        nn.ReLU()) #16x64x64\n        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2) #16x32x32\n\n\n        self.layer0 = self.makeLayer(block, 16, all_connections[0], stride = 1) #connections = 3, shape: 16x32x32\n        self.layer1 = self.makeLayer(block, 32, all_connections[1], stride = 2)#connections = 4, shape: 32x16x16\n        self.layer2 = self.makeLayer(block, 128, all_connections[2], stride = 2)#connections = 6, shape: 1281x8x8\n        self.layer3 = self.makeLayer(block, 256, all_connections[3], stride = 2)#connections = 3, shape: 256x4x4\n        self.avgpool = nn.AvgPool2d(4, stride=1)\n        self.fc = nn.Linear(256, 1)\n\n    def makeLayer(self, block, outputs, connections, stride=1):\n        downsample = None\n        if stride != 1 or self.inputs != outputs:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inputs, outputs, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(outputs),\n            )\n        layers = []\n        layers.append(block(self.inputs, outputs, stride, downsample))\n        self.inputs = outputs\n        for i in range(1, connections):\n            layers.append(block(self.inputs, outputs))\n\n        return nn.Sequential(*layers)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(-1, 256)\n        x = self.fc(x).flatten()\n        return F.sigmoid(x)\n```\n\nGenerator:\n\n```js\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self):\n      super().__init__()\n      self.conv_1 = DoubleConv(3, 32) # 32x64x64\n      self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32x32\n\n      self.conv_2 = DoubleConv(32, 64)  #64x32x32\n      self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2) #64x16x16\n\n      self.conv_3 = DoubleConv(64, 128)  #128x16x16\n      self.pool_3 = nn.MaxPool2d(kernel_size=2, stride=2) #128x8x8\n\n      self.conv_4 = DoubleConv(128, 256)  #256x8x8\n      self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2) #256x4x4\n\n      self.conv_5 = DoubleConv(256, 512)  #512x2x2\n\n      #DECODER\n      self.upconv_1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) #256x4x4\n      self.conv_6 = DoubleConv(512, 256) #256x4x4\n\n\n      self.upconv_2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) #128x8x8\n      self.conv_7 = DoubleConv(256, 128)  #128x8x8\n\n      self.upconv_3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2) #64x16x16\n      self.conv_8 = DoubleConv(128, 64)  #64x16x16\n\n      self.upconv_4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2) #32x32x32\n      self.conv_9 = DoubleConv(64, 32)  #32x32x32\n\n      self.output = nn.Conv2d(32, 3, kernel_size = 3, stride = 1, padding = 1) #3x64x64\n\n    def forward(self, batch):\n\n      conv_1_out = self.conv_1(batch)\n      conv_2_out = self.conv_2(self.pool_1(conv_1_out))\n      conv_3_out = self.conv_3(self.pool_2(conv_2_out))\n      conv_4_out = self.conv_4(self.pool_3(conv_3_out))\n      conv_5_out = self.conv_5(self.pool_4(conv_4_out))\n\n      conv_6_out = self.conv_6(torch.cat([self.upconv_1(conv_5_out), conv_4_out], dim=1))\n      conv_7_out = self.conv_7(torch.cat([self.upconv_2(conv_6_out), conv_3_out], dim=1))\n      conv_8_out = self.conv_8(torch.cat([self.upconv_3(conv_7_out), conv_2_out], dim=1))\n      conv_9_out = self.conv_9(torch.cat([self.upconv_4(conv_8_out), conv_1_out], dim=1))\n\n      output = self.output(conv_9_out)\n\n\n      return F.sigmoid(output)\n```\n\n이제 데이터를 훈련/테스트 세트로 분할하고 torch 데이터 세트로 래핑해야합니다:\n\n<div class=\"content-ad\"></div>\n\n```python\nclass dataset(Dataset):\n    def __init__(self, batch_size, images_paths, targets, img_size=64):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.images_paths = images_paths\n        self.targets = targets\n        self.len = len(self.images_paths) // batch_size\n\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n        ])\n\n        self.batch_im = [self.images_paths[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]\n        self.batch_t = [self.targets[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]\n\n    def __getitem__(self, idx):\n        pred = torch.stack([\n            self.transform(Image.open(join(path_input, file_name)))\n            for file_name in self.batch_im[idx]\n        ])\n        target = torch.stack([\n            self.transform(Image.open(join(path_target, file_name)))\n            for file_name in self.batch_im[idx]\n        ])\n        return pred, target\n\n    def __len__(self):\n        return self.len\n```\n\n멋져요. 이제 훈련 루프를 작성할 시간입니다. 그 전에 손실 함수와 옵티마이저를 정의해 봅시다:\n\n```python\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size = 64\nnum_epochs = 15\nlearning_rate_D = 1e-5\nlearning_rate_G = 1e-4\n\ndiscriminator = ResNet()\ngenerator = UNet()\n\nbce = nn.BCEWithLogitsLoss()\nl1loss = nn.L1Loss()\n\noptimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate_D)\noptimizer_G = optim.Adam(generator.parameters(), lr=learning_rate_G)\n\nscheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.1)\nscheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)\n```\n\n이전 GAN 알고리즘 그림의 손실 함수와는 다른 것을 볼 수 있습니다. 특히 L1 손실을 추가했습니다. 이 아이디어는 우리가 무작위로 이미지를 생성하는 것이 아니라 입력에서 대부분의 정보를 유지하고 노이즈만 제거하려고 한다는 것입니다. 따라서 G 손실은 다음과 같을 것입니다:\n\n<div class=\"content-ad\"></div>\n\n\nG_loss = log(1 − D(G(z))) + 𝝀 |G(z)-y|\n\ninstead of just\n\nG_loss = log(1 − D(G(z)))\n\n𝝀 is an arbitrary coefficient, which balances two components of the losses.\n\n\n<div class=\"content-ad\"></div>\n\n이제 데이터를 분할하여 훈련 과정을 시작해봅시다:\n\n```js\ntest_ratio, train_ratio = 0.3, 0.7\nnum_test = int(len(listdir(path_target)) * test_ratio)\nnum_train = int((int(len(listdir(path_target))) - num_test))\n\nimg_size = (64, 64)\n\nprint(\"훈련 샘플 수:\", num_train)\nprint(\"테스트 샘플 수:\", num_test)\n\nrandom.seed(231)\ntrain_idxs = np.array(random.sample(range(num_test + num_train), num_train))\nmask = np.ones(num_train + num_test, dtype=bool)\nmask[train_idxs] = False\n\nimages = {}\nfeatures = random.sample(listdir(path_input), num_test + num_train)\ntargets = random.sample(listdir(path_target), num_test + num_train)\n\nrandom.Random(231).shuffle(features)\nrandom.Random(231).shuffle(targets)\n\ntrain_input_img_paths = np.array(features)[train_idxs]\ntrain_target_img_path = np.array(targets)[train_idxs]\ntest_input_img_paths = np.array(features)[mask]\ntest_target_img_path = np.array(targets)[mask]\n\ntrain_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=train_input_img_paths, targets=train_target_img_path)\ntest_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=test_input_img_paths, targets=test_target_img_path)\n```\n\n이제 훈련 루프를 실행해봅시다:\n\n```js\ntrain_loss_G, train_loss_D, val_loss_G, val_loss_D = [], [], [], []\nall_loss_G, all_loss_D = [], []\nbest_generator_epoch_val_loss, best_discriminator_epoch_val_loss = -np.inf, -np.inf\nfor epoch in range(num_epochs):\n\n    discriminator.train()\n    generator.train()\n\n    discriminator_epoch_loss, generator_epoch_loss = 0, 0\n\n    for inputs, targets in train_loader:\n        inputs, true = inputs, targets\n\n        '''1. 판별자 (ResNet) 훈련하기'''\n        optimizer_D.zero_grad()\n\n        fake = generator(inputs).detach()\n\n        pred_fake = discriminator(fake).to(device)\n        loss_fake = bce(pred_fake, torch.zeros(batch_size, device=device))\n\n        pred_real = discriminator(true).to(device)\n        loss_real = bce(pred_real, torch.ones(batch_size, device=device))\n\n        loss_D = (loss_fake + loss_real) / 2\n\n        loss_D.backward()\n        optimizer_D.step()\n\n        discriminator_epoch_loss += loss_D.item()\n        all_loss_D.append(loss_D.item())\n\n        '''2. 생성자 (UNet) 훈련하기'''\n        optimizer_G.zero_grad()\n\n        fake = generator(inputs)\n        pred_fake = discriminator(fake).to(device)\n\n        loss_G_bce = bce(pred_fake, torch.ones_like(pred_fake, device=device))\n        loss_G_l1 = l1loss(fake, targets) * 100\n        loss_G = loss_G_bce + loss_G_l1\n        loss_G.backward()\n        optimizer_G.step()\n\n        generator_epoch_loss += loss_G.item()\n        all_loss_G.append(loss_G.item())\n\n    discriminator_epoch_loss /= len(train_loader)\n    generator_epoch_loss /= len(train_loader)\n    train_loss_D.append(discriminator_epoch_loss)\n    train_loss_G.append(generator_epoch_loss)\n\n    discriminator.eval()\n    generator.eval()\n\n    discriminator_epoch_val_loss, generator_epoch_val_loss = 0, 0\n\n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs, targets\n\n            fake = generator(inputs)\n            pred = discriminator(fake).to(device)\n\n            loss_G_bce = bce(fake, torch.ones_like(fake, device=device))\n            loss_G_l1 = l1loss(fake, targets) * 100\n            loss_G = loss_G_bce + loss_G_l1\n            loss_D = bce(pred.to(device), torch.zeros(batch_size, device=device))\n\n            discriminator_epoch_val_loss += loss_D.item()\n            generator_epoch_val_loss += loss_G.item()\n\n    discriminator_epoch_val_loss /= len(test_loader)\n    generator_epoch_val_loss /= len(test_loader)\n\n    val_loss_D.append(discriminator_epoch_val_loss)\n    val_loss_G.append(generator_epoch_val_loss)\n\n    print(f\"------에포크 [{epoch+1}/{num_epochs}]------\\n훈련 손실 D: {discriminator_epoch_loss:.4f}, 검증 손실 D: {discriminator_epoch_val_loss:.4f}\")\n    print(f'훈련 손실 G: {generator_epoch_loss:.4f}, 검증 손실 G: {generator_epoch_val_loss:.4f}')\n\n    if discriminator_epoch_val_loss > best_discriminator_epoch_val_loss:\n        discriminator_epoch_val_loss = best_discriminator_epoch_val_loss\n        torch.save(discriminator.state_dict(), \"discriminator.pth\")\n    if generator_epoch_val_loss > best_generator_epoch_val_loss:\n        generator_epoch_val_loss = best_generator_epoch_val_loss\n        torch.save(generator.state_dict(), \"generator.pth\")\n\n    fig, ax = plt.subplots(1,3)\n    ax[0].imshow(np.transpose(inputs.numpy()[7], (1,2,0)))\n    ax[1].imshow(np.transpose(targets.numpy()[7], (1,2,0)))\n    ax[2].imshow(np.transpose(fake.detach().numpy()[7], (1,2,0)))\n    plt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n코드가 끝나면 손실을 그래프로 그려볼 수 있어요. 이 코드는 이 멋진 웹사이트에서 일부 채택되었어요:\n\n```js\nfrom matplotlib.font_manager import FontProperties\n\nbackground_color = '#001219'\nfont = FontProperties(fname='LexendDeca-VariableFont_wght.ttf')\nfig, ax = plt.subplots(1, 2, figsize=(16, 9))\nfig.set_facecolor(background_color)\nax[0].set_facecolor(background_color)\nax[1].set_facecolor(background_color)\n\nax[0].plot(range(len(all_loss_G)), all_loss_G, color='#bc6c25', lw=0.5) \nax[1].plot(range(len(all_loss_D)), all_loss_D, color='#00b4d8', lw=0.5)\n\nax[0].scatter(\n      [np.array(all_loss_G).argmax(), np.array(all_loss_G).argmin()],\n      [np.array(all_loss_G).max(), np.array(all_loss_G).min()],\n      s=30, color='#bc6c25',\n   )\nax[1].scatter(\n      [np.array(all_loss_D).argmax(), np.array(all_loss_D).argmin()],\n      [np.array(all_loss_D).max(), np.array(all_loss_D).min()],\n      s=30, color='#00b4d8',\n   )\n\nax.text(\n      np.array(all_loss_G).argmax()+60, np.array(all_loss_G).max()+0.1,\n      f'{round(np.array(all_loss_G).max(),1)}',\n      fontsize=13, color='#bc6c25',\n      font=font,\n      ax=ax[0]\n   )\nax.text(\n      np.array(all_loss_G).argmin()+60, np.array(all_loss_G).min()-0.1,\n      f'{round(np.array(all_loss_G).min(),1)}',\n      fontsize=13, color='#bc6c25',\n      font=font,\n      ax=ax[0]\n   )\n\nax.text(\n      np.array(all_loss_D).argmax()+60, np.array(all_loss_D).max()+0.01,\n      f'{round(np.array(all_loss_D).max(),1)}',\n      fontsize=13, color='#00b4d8',\n      font=font,\n      ax=ax[1]\n   )\nax.text(\n      np.array(all_loss_D).argmin()+60, np.array(all_loss_D).min()-0.005,\n      f'{round(np.array(all_loss_D).min(),1)}',\n      fontsize=13, color='#00b4d8',\n      font=font,\n      ax=ax[1]\n   )\nfor i in range(2):\n    ax[i].tick_params(axis='x', colors='white')\n    ax[i].tick_params(axis='y', colors='white')\n    ax[i].spines['left'].set_color('white') \n    ax[i].spines['bottom'].set_color('white') \n    ax[i].set_xlabel('Epoch', color='white', fontproperties=font, fontsize=13)\n    ax[i].set_ylabel('Loss', color='white', fontproperties=font, fontsize=13)\n\nax[0].set_title('Generator', color='white', fontproperties=font, fontsize=18)\nax[1].set_title('Discriminator', color='white', fontproperties=font, fontsize=18)\nplt.savefig('Loss.jpg')\nplt.show()\n# ax[0].set_axis_off()\n# ax[1].set_axis_off()\n```\n\n또한 테스트 데이터셋에서 임의의 샘플을 시각화할게요:\n\n```js\nrandom.Random(2).shuffle(test_target_img_path)\nrandom.Random(2).shuffle(test_input_img_paths)\nsubset_loader = dataset(batch_size=5, img_size=img_size, images_paths=test_input_img_paths,\n                        targets=test_target_img_path)\ngenerator = UNet()\ngenerator.load_state_dict(torch.load('generator.pth'))\n\ngenerator.eval()\nfor X, y in subset_loader:\n    fig, axes = plt.subplots(5, 3, figsize=(9, 9))\n\n    for i in range(5):\n        axes[i, 0].imshow(np.transpose(X.numpy()[i], (1, 2, 0)))\n        axes[i, 0].set_title(\"Input\")\n        axes[i, 0].axis('off')\n        \n        axes[i, 1].imshow(np.transpose(y.numpy()[i], (1, 2, 0)))\n        axes[i, 1].set_title(\"Target\")\n        axes[i, 1].axis('off')\n        \n        generated_image = generator(X[i].unsqueeze(0)).detach().numpy()[0]\n        axes[i, 2].imshow(np.transpose(generated_image, (1, 2, 0)))\n        axes[i, 2].set_title(\"Generated\")\n        axes[i, 2].axis('off')\n    \n    # 레이아웃 조정\n    plt.tight_layout()\n    plt.savefig('Test.jpg')\n    plt.show()\n    break \n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_6.png\" />\n\n여기서 보시다시피, 결과는 완벽하지 않고 땅커버 유형에 매우 의존합니다. 그럼에도 불구하고, 구축된 모델은 이미지에서 구름을 제거하며, G 및 D 깊이를 늘리는 것으로 성능을 향상시킬 수 있습니다. 다른 유망한 전략은 서로 다른 땅커버 유형을 위해 별도의 모델을 훈련시키는 것입니다. 예를 들어, 작물밭과 물 투구는 분명히 다른 공간적 특징을 가지고 있기 때문에 일반화 모델의 능력에 영향을 주는 경우가 있습니다.\n\n이 기사가 지리정보 도메인에서 심층 학습 알고리즘을 적용하는 데 새로운 시각을 제공해 드렸기를 바랍니다. 내 생각에는, GANs는 데이터 과학자가 활용할 수 있는 가장 강력한 도구 중 하나이며, 여러분의 도구 상자의 필수적인 부분이 되길 희망합니다!\n\n===========================================\n\n<div class=\"content-ad\"></div>\n\n참고문헌:\n\n1. Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville 및 Yoshua Bengio. “Generative adversarial nets.” Advances in neural information processing systems 27 (2014). [논문 링크](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)\n\n2. Helber, Patrick, Benjamin Bischke, Andreas Dengel 및 Damian Borth. “Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 12, no. 7 (2019): 2217–2226. [논문 링크](https://arxiv.org/pdf/1709.00029)\n\n3. Wen, Xue, Zongxu Pan, Yuxin Hu 및 Jiayin Liu. “Generative adversarial learning in YUV color space for thin cloud removal on satellite imagery.” Remote Sensing 13, no. 6 (2021): 1079. [논문 링크](https://www.mdpi.com/2072-4292/13/6/1079)\n\n<div class=\"content-ad\"></div>\n\n5. Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. “U-net: Convolutional networks for biomedical image segmentation.” In Medical image computing and computer-assisted intervention–MICCAI 2015: 18th international conference, Munich, Germany, October 5–9, 2015, proceedings, part III 18, pp. 234–241. Springer International Publishing, 2015. [Link](https://arxiv.org/pdf/1505.04597)\n\n6. He, Kaiming, et al. “Deep residual learning for image recognition.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [Link](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n\n===========================================\n\n<div class=\"content-ad\"></div>\n\n제 Medium의 모든 게시물은 무료이며 공개되어 있습니다. 그래서 여기서 저를 팔로우해 주시면 정말 감사하겠습니다!\n\nP.s. 저는 (지리)데이터 과학, 머신 러닝/인공지능, 기후 변화에 대해 열정적으로 관심을 가지고 있습니다. 그래서 어떤 프로젝트에서 함께 작업하고 싶다면 LinkedIn에서 연락 주세요.\n\n🛰️더 많은 소식을 받아보려면 팔로우하세요!🛰️","ogImage":{"url":"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png"},"coverImage":"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png","tag":["Tech"],"readingTime":25},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>파이썬으로부터 GAN(Generative Adversarial Networks) 만들어 보기</h2>\n<p><img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png\" alt=\"이미지\"></p>\n<p>GAN(Generative Adversarial Networks)이라는 아이디어는 2014년 Goodfellow와 그 동료들에 의해 소개되었고, 곧 그 이후에 컴퓨터 비전 및 이미지 생성 분야에서 극도로 인기를 끌게 되었습니다. 인공지능 분야에서의 급속한 발전과 새로운 알고리즘의 수가 늘어나는 것을 고려하더라도, 이 개념의 단순함과 창의성은 여전히 매우 인상적입니다. 그래서 오늘은 이러한 네트워크가 얼마나 강력할 수 있는지를 보여주기 위해 위성 RGB(빨강, 녹색, 파랑) 이미지에서 구름을 제거하는 시도를 해보려고 합니다.</p>\n<p>적절히 균형 잡히고 충분히 크며 올바르게 전처리된 컴퓨터 비전 데이터셋을 준비하는 데에는 상당한 시간이 소요되므로, 저는 Kaggle에 어떤 것이 있는지 살펴보기로 결정했습니다. 이 작업에 가장 적합하다고 생각한 데이터셋은 EuroSat이며, 이는 오픈 라이선스를 가지고 있습니다. 이 데이터셋은 Sentinel-2에서 64x64 픽셀의 27000개의 레이블이 지정된 RGB 이미지로 구성되어 있고, 다중 클래스 분류 문제를 해결하기 위해 만들어졌습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_1.png\" alt=\"이미지\"></p>\n<p>우리는 분류 자체에 흥미가 없지만 EuroSat 데이터셋의 주요 기능 중 하나는 모든 이미지에 맑은 하늘이 있습니다. 그것이 정확히 우리가 필요한 것입니다. [3]에서 이 접근법을 채택하여, 우리는 이 Sentinel-2 샷을 대상으로 사용하고 입력을 추가하여 (구름) 노이즈를 생성할 것입니다.</p>\n<p>그래서 우리가 GANs에 대해 실제로 이야기하기 전에 데이터를 준비해 봅시다. 우선, 데이터를 다운로드하고 모든 클래스를 하나의 디렉토리로 병합해야 합니다.</p>\n<p>🐍전체 Python 코드: GitHub.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> random\n\n<span class=\"hljs-keyword\">from</span> os <span class=\"hljs-keyword\">import</span> listdir, mkdir, rename\n<span class=\"hljs-keyword\">from</span> os.<span class=\"hljs-property\">path</span> <span class=\"hljs-keyword\">import</span> join, exists\n<span class=\"hljs-keyword\">import</span> shutil\n<span class=\"hljs-keyword\">import</span> datetime\n\n<span class=\"hljs-keyword\">import</span> matplotlib.<span class=\"hljs-property\">pyplot</span> <span class=\"hljs-keyword\">as</span> plt\n<span class=\"hljs-keyword\">from</span> highlight_text <span class=\"hljs-keyword\">import</span> ax_text, fig_text\n<span class=\"hljs-keyword\">from</span> <span class=\"hljs-variable constant_\">PIL</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">Image</span>\n\n<span class=\"hljs-keyword\">import</span> warnings\n\nwarnings.<span class=\"hljs-title function_\">filterwarnings</span>(<span class=\"hljs-string\">'ignore'</span>)\n</code></pre>\n<pre><code class=\"hljs language-js\">classes = <span class=\"hljs-title function_\">listdir</span>(<span class=\"hljs-string\">'./EuroSat'</span>)\npath_target = <span class=\"hljs-string\">'./EuroSat/all_targets'</span>\npath_input = <span class=\"hljs-string\">'./EuroSat/all_inputs'</span>\n\n<span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"UNPACK한 아카이브 파일의 파일 이름을 변경하기 위해 단 한 번만 실행하세요\"</span><span class=\"hljs-string\">\"\"</span>\n<span class=\"hljs-title function_\">mkdir</span>(path_input)\n<span class=\"hljs-title function_\">mkdir</span>(path_target)\nk = <span class=\"hljs-number\">1</span>\n<span class=\"hljs-keyword\">for</span> kind <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">classes</span>:\n  path = <span class=\"hljs-title function_\">join</span>(<span class=\"hljs-string\">'./EuroSat'</span>, <span class=\"hljs-title function_\">str</span>(kind))\n  <span class=\"hljs-keyword\">for</span> i, f <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">enumerate</span>(<span class=\"hljs-title function_\">listdir</span>(path)):\n    shutil.<span class=\"hljs-title function_\">copyfile</span>(<span class=\"hljs-title function_\">join</span>(path, f),\n                  <span class=\"hljs-title function_\">join</span>(path_target, f))\n    <span class=\"hljs-title function_\">rename</span>(<span class=\"hljs-title function_\">join</span>(path_target, f), <span class=\"hljs-title function_\">join</span>(path_target, f<span class=\"hljs-string\">'{k}.jpg'</span>))\n    k += <span class=\"hljs-number\">1</span>\n</code></pre>\n<p>중요한 두 번째 단계는 노이즈 생성입니다. 다양한 방법을 사용할 수 있지만, 예를 들어 일부 픽셀을 무작위로 마스킹하거나 가우시안 노이즈를 추가하는 등의 방법이 있습니다. 그러나 이 글에서는 저는 새로운 방식인 Perlin 노이즈를 시도해 보고 싶습니다. Perlin 노이즈는 80년대에 Ken Perlin이 영화 연기 효과를 개발할 때 발명했습니다. 이 종류의 노이즈는 일반적인 랜덤 노이즈에 비해 더 유기적인 외관을 가지고 있습니다. 저에게 이를 증명하는 기회를 주세요.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">generate_perlin_noise</span>(width, height, scale, octaves, persistence, lacunarity):\n    noise = np.<span class=\"hljs-title function_\">zeros</span>((height, width))\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(height):\n        <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(width):\n            noise[i][j] = <span class=\"hljs-title function_\">pnoise2</span>(i / scale,\n                                  j / scale,\n                                  octaves=octaves,\n                                  persistence=persistence,\n                                  lacunarity=lacunarity,\n                                  repeatx=width,\n                                  repeaty=height,\n                                  base=<span class=\"hljs-number\">0</span>)\n    <span class=\"hljs-keyword\">return</span> noise\n\ndef <span class=\"hljs-title function_\">normalize_noise</span>(noise):\n    min_val = noise.<span class=\"hljs-title function_\">min</span>()\n    max_val = noise.<span class=\"hljs-title function_\">max</span>()\n    <span class=\"hljs-keyword\">return</span> (noise - min_val) / (max_val - min_val)\n\ndef <span class=\"hljs-title function_\">generate_clouds</span>(width, height, base_scale, octaves, persistence, lacunarity):\n    clouds = np.<span class=\"hljs-title function_\">zeros</span>((height, width))\n    <span class=\"hljs-keyword\">for</span> octave <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-number\">1</span>, octaves + <span class=\"hljs-number\">1</span>):\n        scale = base_scale / octave\n        layer = <span class=\"hljs-title function_\">generate_perlin_noise</span>(width, height, scale, <span class=\"hljs-number\">1</span>, persistence, lacunarity)\n        clouds += layer * (persistence ** octave)\n\n    clouds = <span class=\"hljs-title function_\">normalize_noise</span>(clouds)\n    <span class=\"hljs-keyword\">return</span> clouds\n\ndef <span class=\"hljs-title function_\">overlay_clouds</span>(image, clouds, alpha=<span class=\"hljs-number\">0.5</span>):\n\n    clouds_rgb = np.<span class=\"hljs-title function_\">stack</span>([clouds] * <span class=\"hljs-number\">3</span>, axis=-<span class=\"hljs-number\">1</span>)\n\n    image = image.<span class=\"hljs-title function_\">astype</span>(float) / <span class=\"hljs-number\">255.0</span>\n    clouds_rgb = clouds_rgb.<span class=\"hljs-title function_\">astype</span>(float)\n\n    blended = image * (<span class=\"hljs-number\">1</span> - alpha) + clouds_rgb * alpha\n\n    blended = (blended * <span class=\"hljs-number\">255</span>).<span class=\"hljs-title function_\">astype</span>(np.<span class=\"hljs-property\">uint8</span>)\n    <span class=\"hljs-keyword\">return</span> blended\n</code></pre>\n<pre><code class=\"hljs language-js\">가로, 세로 = <span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">64</span>\n옥타브 = <span class=\"hljs-number\">12</span>  # 합쳐지는 잡음 레이어의 수\n지속성 = <span class=\"hljs-number\">0.5</span>  # 낮은 지속성은 높은 주파수 옥타브의 진폭을 줄입니다.\n라쿠나리티 = <span class=\"hljs-number\">2</span>  # 높은 라쿠나리티는 높은 주파수 옥타브의 주파수를 늘립니다.\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-title function_\">len</span>(<span class=\"hljs-title function_\">listdir</span>(path_target))):\n  기본_스케일 = random.<span class=\"hljs-title function_\">uniform</span>(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">120</span>)  # 잡음 주파수\n  알파 = random.<span class=\"hljs-title function_\">uniform</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>)  # 투명도\n\n  구름 = <span class=\"hljs-title function_\">generate_clouds</span>(가로, 세로, 기본_스케일, 옥타브, 지속성, 라쿠나리티)\n\n  이미지 = np.<span class=\"hljs-title function_\">asarray</span>(<span class=\"hljs-title class_\">Image</span>.<span class=\"hljs-title function_\">open</span>(<span class=\"hljs-title function_\">join</span>(path_target, f<span class=\"hljs-string\">'{i+1}.jpg'</span>)))\n  이미지 = <span class=\"hljs-title class_\">Image</span>.<span class=\"hljs-title function_\">fromarray</span>(<span class=\"hljs-title function_\">overlay_clouds</span>(이미지, 구름, 알파))\n  이미지.<span class=\"hljs-title function_\">save</span>(<span class=\"hljs-title function_\">join</span>(path_input, f<span class=\"hljs-string\">'{i+1}.jpg'</span>))\n  <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">'{i+1}/{len(listdir(path_target))}번째 처리 완료'</span>)\n</code></pre>\n<pre><code class=\"hljs language-js\">인덱스 = np.<span class=\"hljs-property\">random</span>.<span class=\"hljs-title function_\">randint</span>(<span class=\"hljs-number\">27000</span>)\nfig, ax = plt.<span class=\"hljs-title function_\">subplots</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>)\nax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">asarray</span>(<span class=\"hljs-title class_\">Image</span>.<span class=\"hljs-title function_\">open</span>(<span class=\"hljs-title function_\">join</span>(path_target, f<span class=\"hljs-string\">'{인덱스}.jpg'</span>)))\nax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">asarray</span>(<span class=\"hljs-title class_\">Image</span>.<span class=\"hljs-title function_\">open</span>(<span class=\"hljs-title function_\">join</span>(path_input, f<span class=\"hljs-string\">'{인덱스}.jpg'</span>)))\nax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">set_title</span>(<span class=\"hljs-string\">\"원본\"</span>)\nax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">axis</span>(<span class=\"hljs-string\">'off'</span>)\nax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">set_title</span>(<span class=\"hljs-string\">\"입력\"</span>)\nax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">axis</span>(<span class=\"hljs-string\">'off'</span>)\nplt.<span class=\"hljs-title function_\">show</span>()\n</code></pre>\n<p>위에서 볼 수 있듯이 이미지의 구름은 매우 현실적이며 다양한 \"밀도\"와 질감을 가지며 실제 구름과 유사합니다.</p>\n<p>만약 저처럼 Perlin 소음에 흥미를 느낀다면, 게임 개발 산업에서 이 소음이 어떻게 적용될 수 있는지에 대한 정말 멋진 비디오가 있어요!</p>\n<p>이제 우리가 사용할 준비가 된 데이터셋이 있으니, GANs에 대해 이야기해 보겠습니다.</p>\n<h1>생성적 적대 신경망</h1>\n<p>이 아이디어를 더 잘 설명하기 위해, 동남아시아를 여행하다가 밖이 너무 춥다고 느낄 때 후디가 절실하게 필요하다고 상상해 보세요. 가장 가까운 거리 시장에 가보니, 몇 가지 브랜드 의류가 있는 작은 가게를 발견했어요. 판매자가 유명한 브랜드 ExpensiveButNotWorthIt의 후디를 시도해보라며 괜찮은 후디를 가져다줍니다. 더 자세히 살펴보고 분명히 가짜라고 결론 내리게 됩니다. 판매자가 말합니다: '잠시만요, 진짜 것이 있어요.' 그가 다른 후디를 가져오는데, 브랜드 제품과 더 닮았지만 여전히 가짜입니다. 이와 같은 반복 작업을 몇 번 거친 후, 판매자가 전설적인 ExpensiveButNotWorthIt의 구별이 어려운 사본을 가져와 여러분은 기꺼이 구매하게 됩니다. 이것이 바로 GANs가 작동하는 방식입니다!</p>\n<p>GAN의 경우, 당신은 판별자(D)라고 불립니다. 판별자의 목표는 진짜 물체와 가짜 물체를 구별하거나 이진 분류 작업을 수행하는 것입니다. 이에 반해, 생성자(G)는 높은 품질의 가짜를 생성하려고 하는 판매자라고 불립니다. 판별자와 생성자는 서로 능가하기 위해 독립적으로 훈련됩니다. 따라서 최종적으로 우리는 높은 품질의 가짜를 얻습니다.</p>\n<p><img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_3.png\" alt=\"이미지\"></p>\n<p>훈련 과정은 일반적으로 다음과 같이 진행됩니다:</p>\n<ul>\n<li>입력 노이즈를 샘플링합니다 (우리의 경우 구름이 있는 이미지).</li>\n<li>노이즈를 생성자(G)에 공급하고 예측을 수집합니다.</li>\n<li>D 손실을 계산합니다. G의 출력에 대한 하나와 실제 데이터에 대한 다른 예측을 얻어서 이루어집니다.</li>\n<li>D의 가중치를 업데이트합니다.</li>\n<li>다시 입력 노이즈를 샘플링합니다.</li>\n<li>노이즈를 생성자(G)에 공급하고 예측을 수집합니다.</li>\n<li>G 손실을 계산합니다. G의 예측을 D에 공급하여 이루어집니다.</li>\n<li>G의 가중치를 업데이트합니다.</li>\n</ul>\n<p><img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_4.png\" alt=\"Erasing Clouds from Satellite Imagery Using GANs\"></p>\n<p>In other words, we can define a value function V(G,D):</p>\n<p><img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_5.png\" alt=\"Value function V(G,D)\"></p>\n<p>where we want to minimize the term log(1-D(G(z))) to train G and maximize log D(x) to train D (in this notation x — real data sample and z — noise).</p>\n<p>이제 파이토치에서 구현해 봅시다!</p>\n<p>원본 논문에서 저자들은 Multilayer Perceptron (MLP)을 사용하는 것에 대해 언급합니다; 이것은 ANN으로 간단히도 불립니다만, 저는 미세한 접근을 시도하고 싶습니다 — Generator로 UNet [5] 아키텍처를 사용하고, Discriminator로는 ResNet [6]을 사용하고 싶습니다. 이들은 둘 다 잘 알려진 CNN 아키텍처이기 때문에 여기서 설명하지는 않겠습니다 (댓글에서 별도의 글을 쓸지 여부를 알려주세요).</p>\n<p>이제 구축해 봅시다. Discriminator:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn\n<span class=\"hljs-keyword\">import</span> torch.optim <span class=\"hljs-keyword\">as</span> optim\n<span class=\"hljs-keyword\">import</span> torch.nn.functional <span class=\"hljs-keyword\">as</span> F\n<span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Dataset, DataLoader\n<span class=\"hljs-keyword\">from</span> torchvision <span class=\"hljs-keyword\">import</span> transforms\n<span class=\"hljs-keyword\">from</span> torch.utils.data <span class=\"hljs-keyword\">import</span> Subset\n</code></pre>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ResidualBlock</span>(nn.<span class=\"hljs-property\">Module</span>):\n    def <span class=\"hljs-title function_\">__init__</span>(self, in_channels, out_channels, stride = <span class=\"hljs-number\">1</span>, downsample = <span class=\"hljs-title class_\">None</span>):\n        <span class=\"hljs-variable language_\">super</span>(<span class=\"hljs-title class_\">ResidualBlock</span>, self).<span class=\"hljs-title function_\">__init__</span>()\n        self.<span class=\"hljs-property\">conv1</span> = nn.<span class=\"hljs-title class_\">Sequential</span>(\n                        nn.<span class=\"hljs-title class_\">Conv2</span>d(in_channels, out_channels, kernel_size = <span class=\"hljs-number\">3</span>, stride = stride, padding = <span class=\"hljs-number\">1</span>),\n                        nn.<span class=\"hljs-title class_\">BatchNorm2</span>d(out_channels),\n                        nn.<span class=\"hljs-title class_\">ReLU</span>())\n        self.<span class=\"hljs-property\">conv2</span> = nn.<span class=\"hljs-title class_\">Sequential</span>(\n                        nn.<span class=\"hljs-title class_\">Conv2</span>d(out_channels, out_channels, kernel_size = <span class=\"hljs-number\">3</span>, stride = <span class=\"hljs-number\">1</span>, padding = <span class=\"hljs-number\">1</span>),\n                        nn.<span class=\"hljs-title class_\">BatchNorm2</span>d(out_channels))\n        self.<span class=\"hljs-property\">downsample</span> = downsample\n        self.<span class=\"hljs-property\">relu</span> = nn.<span class=\"hljs-title class_\">ReLU</span>()\n        self.<span class=\"hljs-property\">out_channels</span> = out_channels\n\n    def <span class=\"hljs-title function_\">forward</span>(self, x):\n        residual = x\n        out = self.<span class=\"hljs-title function_\">conv1</span>(x)\n        out = self.<span class=\"hljs-title function_\">conv2</span>(out)\n        <span class=\"hljs-keyword\">if</span> self.<span class=\"hljs-property\">downsample</span>:\n            residual = self.<span class=\"hljs-title function_\">downsample</span>(x)\n        out += residual\n        out = self.<span class=\"hljs-title function_\">relu</span>(out)\n        <span class=\"hljs-keyword\">return</span> out\n\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ResNet</span>(nn.<span class=\"hljs-property\">Module</span>):\n    def <span class=\"hljs-title function_\">__init__</span>(self, block=<span class=\"hljs-title class_\">ResidualBlock</span>, all_connections=[<span class=\"hljs-number\">3</span>,<span class=\"hljs-number\">4</span>,<span class=\"hljs-number\">6</span>,<span class=\"hljs-number\">3</span>]):\n        <span class=\"hljs-variable language_\">super</span>(<span class=\"hljs-title class_\">ResNet</span>, self).<span class=\"hljs-title function_\">__init__</span>()\n        self.<span class=\"hljs-property\">inputs</span> = <span class=\"hljs-number\">16</span>\n        self.<span class=\"hljs-property\">conv1</span> = nn.<span class=\"hljs-title class_\">Sequential</span>(\n                        nn.<span class=\"hljs-title class_\">Conv2</span>d(<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">16</span>, kernel_size = <span class=\"hljs-number\">3</span>, stride = <span class=\"hljs-number\">1</span>, padding = <span class=\"hljs-number\">1</span>),\n                        nn.<span class=\"hljs-title class_\">BatchNorm2</span>d(<span class=\"hljs-number\">16</span>),\n                        nn.<span class=\"hljs-title class_\">ReLU</span>()) #16x64x64\n        self.<span class=\"hljs-property\">maxpool</span> = nn.<span class=\"hljs-title class_\">MaxPool2</span>d(kernel_size = <span class=\"hljs-number\">2</span>, stride = <span class=\"hljs-number\">2</span>) #16x32x32\n\n\n        self.<span class=\"hljs-property\">layer0</span> = self.<span class=\"hljs-title function_\">makeLayer</span>(block, <span class=\"hljs-number\">16</span>, all_connections[<span class=\"hljs-number\">0</span>], stride = <span class=\"hljs-number\">1</span>) #connections = <span class=\"hljs-number\">3</span>, <span class=\"hljs-attr\">shape</span>: 16x32x32\n        self.<span class=\"hljs-property\">layer1</span> = self.<span class=\"hljs-title function_\">makeLayer</span>(block, <span class=\"hljs-number\">32</span>, all_connections[<span class=\"hljs-number\">1</span>], stride = <span class=\"hljs-number\">2</span>)#connections = <span class=\"hljs-number\">4</span>, <span class=\"hljs-attr\">shape</span>: 32x16x16\n        self.<span class=\"hljs-property\">layer2</span> = self.<span class=\"hljs-title function_\">makeLayer</span>(block, <span class=\"hljs-number\">128</span>, all_connections[<span class=\"hljs-number\">2</span>], stride = <span class=\"hljs-number\">2</span>)#connections = <span class=\"hljs-number\">6</span>, <span class=\"hljs-attr\">shape</span>: 1281x8x8\n        self.<span class=\"hljs-property\">layer3</span> = self.<span class=\"hljs-title function_\">makeLayer</span>(block, <span class=\"hljs-number\">256</span>, all_connections[<span class=\"hljs-number\">3</span>], stride = <span class=\"hljs-number\">2</span>)#connections = <span class=\"hljs-number\">3</span>, <span class=\"hljs-attr\">shape</span>: 256x4x4\n        self.<span class=\"hljs-property\">avgpool</span> = nn.<span class=\"hljs-title class_\">AvgPool2</span>d(<span class=\"hljs-number\">4</span>, stride=<span class=\"hljs-number\">1</span>)\n        self.<span class=\"hljs-property\">fc</span> = nn.<span class=\"hljs-title class_\">Linear</span>(<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">1</span>)\n\n    def <span class=\"hljs-title function_\">makeLayer</span>(self, block, outputs, connections, stride=<span class=\"hljs-number\">1</span>):\n        downsample = <span class=\"hljs-title class_\">None</span>\n        <span class=\"hljs-keyword\">if</span> stride != <span class=\"hljs-number\">1</span> or self.<span class=\"hljs-property\">inputs</span> != <span class=\"hljs-attr\">outputs</span>:\n            downsample = nn.<span class=\"hljs-title class_\">Sequential</span>(\n                nn.<span class=\"hljs-title class_\">Conv2</span>d(self.<span class=\"hljs-property\">inputs</span>, outputs, kernel_size=<span class=\"hljs-number\">1</span>, stride=stride),\n                nn.<span class=\"hljs-title class_\">BatchNorm2</span>d(outputs),\n            )\n        layers = []\n        layers.<span class=\"hljs-title function_\">append</span>(<span class=\"hljs-title function_\">block</span>(self.<span class=\"hljs-property\">inputs</span>, outputs, stride, downsample))\n        self.<span class=\"hljs-property\">inputs</span> = outputs\n        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-number\">1</span>, connections):\n            layers.<span class=\"hljs-title function_\">append</span>(<span class=\"hljs-title function_\">block</span>(self.<span class=\"hljs-property\">inputs</span>, outputs))\n\n        <span class=\"hljs-keyword\">return</span> nn.<span class=\"hljs-title class_\">Sequential</span>(*layers)\n\n\n    def <span class=\"hljs-title function_\">forward</span>(self, x):\n        x = self.<span class=\"hljs-title function_\">conv1</span>(x)\n        x = self.<span class=\"hljs-title function_\">maxpool</span>(x)\n        x = self.<span class=\"hljs-title function_\">layer0</span>(x)\n        x = self.<span class=\"hljs-title function_\">layer1</span>(x)\n        x = self.<span class=\"hljs-title function_\">layer2</span>(x)\n        x = self.<span class=\"hljs-title function_\">layer3</span>(x)\n        x = self.<span class=\"hljs-title function_\">avgpool</span>(x)\n        x = x.<span class=\"hljs-title function_\">view</span>(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">256</span>)\n        x = self.<span class=\"hljs-title function_\">fc</span>(x).<span class=\"hljs-title function_\">flatten</span>()\n        <span class=\"hljs-keyword\">return</span> F.<span class=\"hljs-title function_\">sigmoid</span>(x)\n</code></pre>\n<p>Generator:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DoubleConv</span>(nn.<span class=\"hljs-property\">Module</span>):\n    def <span class=\"hljs-title function_\">__init__</span>(self, in_channels, out_channels):\n        <span class=\"hljs-variable language_\">super</span>(<span class=\"hljs-title class_\">DoubleConv</span>, self).<span class=\"hljs-title function_\">__init__</span>()\n        self.<span class=\"hljs-property\">double_conv</span> = nn.<span class=\"hljs-title class_\">Sequential</span>(\n            nn.<span class=\"hljs-title class_\">Conv2</span>d(in_channels, out_channels, kernel_size=<span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>),\n            nn.<span class=\"hljs-title class_\">BatchNorm2</span>d(out_channels),\n            nn.<span class=\"hljs-title class_\">ReLU</span>(inplace=<span class=\"hljs-title class_\">True</span>),\n            nn.<span class=\"hljs-title class_\">Conv2</span>d(out_channels, out_channels, kernel_size=<span class=\"hljs-number\">3</span>, padding=<span class=\"hljs-number\">1</span>),\n            nn.<span class=\"hljs-title class_\">BatchNorm2</span>d(out_channels),\n            nn.<span class=\"hljs-title class_\">ReLU</span>(inplace=<span class=\"hljs-title class_\">True</span>)\n        )\n\n    def <span class=\"hljs-title function_\">forward</span>(self, x):\n        <span class=\"hljs-keyword\">return</span> self.<span class=\"hljs-title function_\">double_conv</span>(x)\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">UNet</span>(nn.<span class=\"hljs-property\">Module</span>):\n    def <span class=\"hljs-title function_\">__init__</span>(self):\n      <span class=\"hljs-variable language_\">super</span>().<span class=\"hljs-title function_\">__init__</span>()\n      self.<span class=\"hljs-property\">conv_1</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">32</span>) # 32x64x64\n      self.<span class=\"hljs-property\">pool_1</span> = nn.<span class=\"hljs-title class_\">MaxPool2</span>d(kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) # 32x32x32\n\n      self.<span class=\"hljs-property\">conv_2</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">64</span>)  #64x32x32\n      self.<span class=\"hljs-property\">pool_2</span> = nn.<span class=\"hljs-title class_\">MaxPool2</span>d(kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) #64x16x16\n\n      self.<span class=\"hljs-property\">conv_3</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">128</span>)  #128x16x16\n      self.<span class=\"hljs-property\">pool_3</span> = nn.<span class=\"hljs-title class_\">MaxPool2</span>d(kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) #128x8x8\n\n      self.<span class=\"hljs-property\">conv_4</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">256</span>)  #256x8x8\n      self.<span class=\"hljs-property\">pool_4</span> = nn.<span class=\"hljs-title class_\">MaxPool2</span>d(kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) #256x4x4\n\n      self.<span class=\"hljs-property\">conv_5</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">512</span>)  #512x2x2\n\n      #<span class=\"hljs-variable constant_\">DECODER</span>\n      self.<span class=\"hljs-property\">upconv_1</span> = nn.<span class=\"hljs-title class_\">ConvTranspose2</span>d(<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">256</span>, kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) #256x4x4\n      self.<span class=\"hljs-property\">conv_6</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">256</span>) #256x4x4\n\n\n      self.<span class=\"hljs-property\">upconv_2</span> = nn.<span class=\"hljs-title class_\">ConvTranspose2</span>d(<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">128</span>, kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) #128x8x8\n      self.<span class=\"hljs-property\">conv_7</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">128</span>)  #128x8x8\n\n      self.<span class=\"hljs-property\">upconv_3</span> = nn.<span class=\"hljs-title class_\">ConvTranspose2</span>d(<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">64</span>, kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) #64x16x16\n      self.<span class=\"hljs-property\">conv_8</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">64</span>)  #64x16x16\n\n      self.<span class=\"hljs-property\">upconv_4</span> = nn.<span class=\"hljs-title class_\">ConvTranspose2</span>d(<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">32</span>, kernel_size=<span class=\"hljs-number\">2</span>, stride=<span class=\"hljs-number\">2</span>) #32x32x32\n      self.<span class=\"hljs-property\">conv_9</span> = <span class=\"hljs-title class_\">DoubleConv</span>(<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">32</span>)  #32x32x32\n\n      self.<span class=\"hljs-property\">output</span> = nn.<span class=\"hljs-title class_\">Conv2</span>d(<span class=\"hljs-number\">32</span>, <span class=\"hljs-number\">3</span>, kernel_size = <span class=\"hljs-number\">3</span>, stride = <span class=\"hljs-number\">1</span>, padding = <span class=\"hljs-number\">1</span>) #3x64x64\n\n    def <span class=\"hljs-title function_\">forward</span>(self, batch):\n\n      conv_1_out = self.<span class=\"hljs-title function_\">conv_1</span>(batch)\n      conv_2_out = self.<span class=\"hljs-title function_\">conv_2</span>(self.<span class=\"hljs-title function_\">pool_1</span>(conv_1_out))\n      conv_3_out = self.<span class=\"hljs-title function_\">conv_3</span>(self.<span class=\"hljs-title function_\">pool_2</span>(conv_2_out))\n      conv_4_out = self.<span class=\"hljs-title function_\">conv_4</span>(self.<span class=\"hljs-title function_\">pool_3</span>(conv_3_out))\n      conv_5_out = self.<span class=\"hljs-title function_\">conv_5</span>(self.<span class=\"hljs-title function_\">pool_4</span>(conv_4_out))\n\n      conv_6_out = self.<span class=\"hljs-title function_\">conv_6</span>(torch.<span class=\"hljs-title function_\">cat</span>([self.<span class=\"hljs-title function_\">upconv_1</span>(conv_5_out), conv_4_out], dim=<span class=\"hljs-number\">1</span>))\n      conv_7_out = self.<span class=\"hljs-title function_\">conv_7</span>(torch.<span class=\"hljs-title function_\">cat</span>([self.<span class=\"hljs-title function_\">upconv_2</span>(conv_6_out), conv_3_out], dim=<span class=\"hljs-number\">1</span>))\n      conv_8_out = self.<span class=\"hljs-title function_\">conv_8</span>(torch.<span class=\"hljs-title function_\">cat</span>([self.<span class=\"hljs-title function_\">upconv_3</span>(conv_7_out), conv_2_out], dim=<span class=\"hljs-number\">1</span>))\n      conv_9_out = self.<span class=\"hljs-title function_\">conv_9</span>(torch.<span class=\"hljs-title function_\">cat</span>([self.<span class=\"hljs-title function_\">upconv_4</span>(conv_8_out), conv_1_out], dim=<span class=\"hljs-number\">1</span>))\n\n      output = self.<span class=\"hljs-title function_\">output</span>(conv_9_out)\n\n\n      <span class=\"hljs-keyword\">return</span> F.<span class=\"hljs-title function_\">sigmoid</span>(output)\n</code></pre>\n<p>이제 데이터를 훈련/테스트 세트로 분할하고 torch 데이터 세트로 래핑해야합니다:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">dataset</span>(<span class=\"hljs-title class_ inherited__\">Dataset</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, batch_size, images_paths, targets, img_size=<span class=\"hljs-number\">64</span></span>):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.images_paths = images_paths\n        self.targets = targets\n        self.<span class=\"hljs-built_in\">len</span> = <span class=\"hljs-built_in\">len</span>(self.images_paths) // batch_size\n\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n        ])\n\n        self.batch_im = [self.images_paths[idx * self.batch_size:(idx + <span class=\"hljs-number\">1</span>) * self.batch_size] <span class=\"hljs-keyword\">for</span> idx <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(self.<span class=\"hljs-built_in\">len</span>)]\n        self.batch_t = [self.targets[idx * self.batch_size:(idx + <span class=\"hljs-number\">1</span>) * self.batch_size] <span class=\"hljs-keyword\">for</span> idx <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(self.<span class=\"hljs-built_in\">len</span>)]\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__getitem__</span>(<span class=\"hljs-params\">self, idx</span>):\n        pred = torch.stack([\n            self.transform(Image.<span class=\"hljs-built_in\">open</span>(join(path_input, file_name)))\n            <span class=\"hljs-keyword\">for</span> file_name <span class=\"hljs-keyword\">in</span> self.batch_im[idx]\n        ])\n        target = torch.stack([\n            self.transform(Image.<span class=\"hljs-built_in\">open</span>(join(path_target, file_name)))\n            <span class=\"hljs-keyword\">for</span> file_name <span class=\"hljs-keyword\">in</span> self.batch_im[idx]\n        ])\n        <span class=\"hljs-keyword\">return</span> pred, target\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__len__</span>(<span class=\"hljs-params\">self</span>):\n        <span class=\"hljs-keyword\">return</span> self.<span class=\"hljs-built_in\">len</span>\n</code></pre>\n<p>멋져요. 이제 훈련 루프를 작성할 시간입니다. 그 전에 손실 함수와 옵티마이저를 정의해 봅시다:</p>\n<pre><code class=\"hljs language-python\">device = torch.device(<span class=\"hljs-string\">\"cuda\"</span> <span class=\"hljs-keyword\">if</span> torch.cuda.is_available() <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"cpu\"</span>)\n\nbatch_size = <span class=\"hljs-number\">64</span>\nnum_epochs = <span class=\"hljs-number\">15</span>\nlearning_rate_D = <span class=\"hljs-number\">1e-5</span>\nlearning_rate_G = <span class=\"hljs-number\">1e-4</span>\n\ndiscriminator = ResNet()\ngenerator = UNet()\n\nbce = nn.BCEWithLogitsLoss()\nl1loss = nn.L1Loss()\n\noptimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate_D)\noptimizer_G = optim.Adam(generator.parameters(), lr=learning_rate_G)\n\nscheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=<span class=\"hljs-number\">10</span>, gamma=<span class=\"hljs-number\">0.1</span>)\nscheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=<span class=\"hljs-number\">10</span>, gamma=<span class=\"hljs-number\">0.1</span>)\n</code></pre>\n<p>이전 GAN 알고리즘 그림의 손실 함수와는 다른 것을 볼 수 있습니다. 특히 L1 손실을 추가했습니다. 이 아이디어는 우리가 무작위로 이미지를 생성하는 것이 아니라 입력에서 대부분의 정보를 유지하고 노이즈만 제거하려고 한다는 것입니다. 따라서 G 손실은 다음과 같을 것입니다:</p>\n<p>G_loss = log(1 − D(G(z))) + 𝝀 |G(z)-y|</p>\n<p>instead of just</p>\n<p>G_loss = log(1 − D(G(z)))</p>\n<p>𝝀 is an arbitrary coefficient, which balances two components of the losses.</p>\n<p>이제 데이터를 분할하여 훈련 과정을 시작해봅시다:</p>\n<pre><code class=\"hljs language-js\">test_ratio, train_ratio = <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.7</span>\nnum_test = <span class=\"hljs-title function_\">int</span>(<span class=\"hljs-title function_\">len</span>(<span class=\"hljs-title function_\">listdir</span>(path_target)) * test_ratio)\nnum_train = <span class=\"hljs-title function_\">int</span>((<span class=\"hljs-title function_\">int</span>(<span class=\"hljs-title function_\">len</span>(<span class=\"hljs-title function_\">listdir</span>(path_target))) - num_test))\n\nimg_size = (<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">64</span>)\n\n<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"훈련 샘플 수:\"</span>, num_train)\n<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"테스트 샘플 수:\"</span>, num_test)\n\nrandom.<span class=\"hljs-title function_\">seed</span>(<span class=\"hljs-number\">231</span>)\ntrain_idxs = np.<span class=\"hljs-title function_\">array</span>(random.<span class=\"hljs-title function_\">sample</span>(<span class=\"hljs-title function_\">range</span>(num_test + num_train), num_train))\nmask = np.<span class=\"hljs-title function_\">ones</span>(num_train + num_test, dtype=bool)\nmask[train_idxs] = <span class=\"hljs-title class_\">False</span>\n\nimages = {}\nfeatures = random.<span class=\"hljs-title function_\">sample</span>(<span class=\"hljs-title function_\">listdir</span>(path_input), num_test + num_train)\ntargets = random.<span class=\"hljs-title function_\">sample</span>(<span class=\"hljs-title function_\">listdir</span>(path_target), num_test + num_train)\n\nrandom.<span class=\"hljs-title class_\">Random</span>(<span class=\"hljs-number\">231</span>).<span class=\"hljs-title function_\">shuffle</span>(features)\nrandom.<span class=\"hljs-title class_\">Random</span>(<span class=\"hljs-number\">231</span>).<span class=\"hljs-title function_\">shuffle</span>(targets)\n\ntrain_input_img_paths = np.<span class=\"hljs-title function_\">array</span>(features)[train_idxs]\ntrain_target_img_path = np.<span class=\"hljs-title function_\">array</span>(targets)[train_idxs]\ntest_input_img_paths = np.<span class=\"hljs-title function_\">array</span>(features)[mask]\ntest_target_img_path = np.<span class=\"hljs-title function_\">array</span>(targets)[mask]\n\ntrain_loader = <span class=\"hljs-title function_\">dataset</span>(batch_size=batch_size, img_size=img_size, images_paths=train_input_img_paths, targets=train_target_img_path)\ntest_loader = <span class=\"hljs-title function_\">dataset</span>(batch_size=batch_size, img_size=img_size, images_paths=test_input_img_paths, targets=test_target_img_path)\n</code></pre>\n<p>이제 훈련 루프를 실행해봅시다:</p>\n<pre><code class=\"hljs language-js\">train_loss_G, train_loss_D, val_loss_G, val_loss_D = [], [], [], []\nall_loss_G, all_loss_D = [], []\nbest_generator_epoch_val_loss, best_discriminator_epoch_val_loss = -np.<span class=\"hljs-property\">inf</span>, -np.<span class=\"hljs-property\">inf</span>\n<span class=\"hljs-keyword\">for</span> epoch <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(num_epochs):\n\n    discriminator.<span class=\"hljs-title function_\">train</span>()\n    generator.<span class=\"hljs-title function_\">train</span>()\n\n    discriminator_epoch_loss, generator_epoch_loss = <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>\n\n    <span class=\"hljs-keyword\">for</span> inputs, targets <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">train_loader</span>:\n        inputs, <span class=\"hljs-literal\">true</span> = inputs, targets\n\n        <span class=\"hljs-string\">''</span><span class=\"hljs-string\">'1. 판별자 (ResNet) 훈련하기'</span><span class=\"hljs-string\">''</span>\n        optimizer_D.<span class=\"hljs-title function_\">zero_grad</span>()\n\n        fake = <span class=\"hljs-title function_\">generator</span>(inputs).<span class=\"hljs-title function_\">detach</span>()\n\n        pred_fake = <span class=\"hljs-title function_\">discriminator</span>(fake).<span class=\"hljs-title function_\">to</span>(device)\n        loss_fake = <span class=\"hljs-title function_\">bce</span>(pred_fake, torch.<span class=\"hljs-title function_\">zeros</span>(batch_size, device=device))\n\n        pred_real = <span class=\"hljs-title function_\">discriminator</span>(<span class=\"hljs-literal\">true</span>).<span class=\"hljs-title function_\">to</span>(device)\n        loss_real = <span class=\"hljs-title function_\">bce</span>(pred_real, torch.<span class=\"hljs-title function_\">ones</span>(batch_size, device=device))\n\n        loss_D = (loss_fake + loss_real) / <span class=\"hljs-number\">2</span>\n\n        loss_D.<span class=\"hljs-title function_\">backward</span>()\n        optimizer_D.<span class=\"hljs-title function_\">step</span>()\n\n        discriminator_epoch_loss += loss_D.<span class=\"hljs-title function_\">item</span>()\n        all_loss_D.<span class=\"hljs-title function_\">append</span>(loss_D.<span class=\"hljs-title function_\">item</span>())\n\n        <span class=\"hljs-string\">''</span><span class=\"hljs-string\">'2. 생성자 (UNet) 훈련하기'</span><span class=\"hljs-string\">''</span>\n        optimizer_G.<span class=\"hljs-title function_\">zero_grad</span>()\n\n        fake = <span class=\"hljs-title function_\">generator</span>(inputs)\n        pred_fake = <span class=\"hljs-title function_\">discriminator</span>(fake).<span class=\"hljs-title function_\">to</span>(device)\n\n        loss_G_bce = <span class=\"hljs-title function_\">bce</span>(pred_fake, torch.<span class=\"hljs-title function_\">ones_like</span>(pred_fake, device=device))\n        loss_G_l1 = <span class=\"hljs-title function_\">l1loss</span>(fake, targets) * <span class=\"hljs-number\">100</span>\n        loss_G = loss_G_bce + loss_G_l1\n        loss_G.<span class=\"hljs-title function_\">backward</span>()\n        optimizer_G.<span class=\"hljs-title function_\">step</span>()\n\n        generator_epoch_loss += loss_G.<span class=\"hljs-title function_\">item</span>()\n        all_loss_G.<span class=\"hljs-title function_\">append</span>(loss_G.<span class=\"hljs-title function_\">item</span>())\n\n    discriminator_epoch_loss /= <span class=\"hljs-title function_\">len</span>(train_loader)\n    generator_epoch_loss /= <span class=\"hljs-title function_\">len</span>(train_loader)\n    train_loss_D.<span class=\"hljs-title function_\">append</span>(discriminator_epoch_loss)\n    train_loss_G.<span class=\"hljs-title function_\">append</span>(generator_epoch_loss)\n\n    discriminator.<span class=\"hljs-built_in\">eval</span>()\n    generator.<span class=\"hljs-built_in\">eval</span>()\n\n    discriminator_epoch_val_loss, generator_epoch_val_loss = <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>\n\n    <span class=\"hljs-keyword\">with</span> torch.<span class=\"hljs-title function_\">no_grad</span>():\n        <span class=\"hljs-keyword\">for</span> inputs, targets <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">test_loader</span>:\n            inputs, targets = inputs, targets\n\n            fake = <span class=\"hljs-title function_\">generator</span>(inputs)\n            pred = <span class=\"hljs-title function_\">discriminator</span>(fake).<span class=\"hljs-title function_\">to</span>(device)\n\n            loss_G_bce = <span class=\"hljs-title function_\">bce</span>(fake, torch.<span class=\"hljs-title function_\">ones_like</span>(fake, device=device))\n            loss_G_l1 = <span class=\"hljs-title function_\">l1loss</span>(fake, targets) * <span class=\"hljs-number\">100</span>\n            loss_G = loss_G_bce + loss_G_l1\n            loss_D = <span class=\"hljs-title function_\">bce</span>(pred.<span class=\"hljs-title function_\">to</span>(device), torch.<span class=\"hljs-title function_\">zeros</span>(batch_size, device=device))\n\n            discriminator_epoch_val_loss += loss_D.<span class=\"hljs-title function_\">item</span>()\n            generator_epoch_val_loss += loss_G.<span class=\"hljs-title function_\">item</span>()\n\n    discriminator_epoch_val_loss /= <span class=\"hljs-title function_\">len</span>(test_loader)\n    generator_epoch_val_loss /= <span class=\"hljs-title function_\">len</span>(test_loader)\n\n    val_loss_D.<span class=\"hljs-title function_\">append</span>(discriminator_epoch_val_loss)\n    val_loss_G.<span class=\"hljs-title function_\">append</span>(generator_epoch_val_loss)\n\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"------에포크 [{epoch+1}/{num_epochs}]------\\n훈련 손실 D: {discriminator_epoch_loss:.4f}, 검증 손실 D: {discriminator_epoch_val_loss:.4f}\"</span>)\n    <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">'훈련 손실 G: {generator_epoch_loss:.4f}, 검증 손실 G: {generator_epoch_val_loss:.4f}'</span>)\n\n    <span class=\"hljs-keyword\">if</span> discriminator_epoch_val_loss > <span class=\"hljs-attr\">best_discriminator_epoch_val_loss</span>:\n        discriminator_epoch_val_loss = best_discriminator_epoch_val_loss\n        torch.<span class=\"hljs-title function_\">save</span>(discriminator.<span class=\"hljs-title function_\">state_dict</span>(), <span class=\"hljs-string\">\"discriminator.pth\"</span>)\n    <span class=\"hljs-keyword\">if</span> generator_epoch_val_loss > <span class=\"hljs-attr\">best_generator_epoch_val_loss</span>:\n        generator_epoch_val_loss = best_generator_epoch_val_loss\n        torch.<span class=\"hljs-title function_\">save</span>(generator.<span class=\"hljs-title function_\">state_dict</span>(), <span class=\"hljs-string\">\"generator.pth\"</span>)\n\n    fig, ax = plt.<span class=\"hljs-title function_\">subplots</span>(<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">3</span>)\n    ax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">transpose</span>(inputs.<span class=\"hljs-title function_\">numpy</span>()[<span class=\"hljs-number\">7</span>], (<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">0</span>)))\n    ax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">transpose</span>(targets.<span class=\"hljs-title function_\">numpy</span>()[<span class=\"hljs-number\">7</span>], (<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">0</span>)))\n    ax[<span class=\"hljs-number\">2</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">transpose</span>(fake.<span class=\"hljs-title function_\">detach</span>().<span class=\"hljs-title function_\">numpy</span>()[<span class=\"hljs-number\">7</span>], (<span class=\"hljs-number\">1</span>,<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">0</span>)))\n    plt.<span class=\"hljs-title function_\">show</span>()\n</code></pre>\n<p>코드가 끝나면 손실을 그래프로 그려볼 수 있어요. 이 코드는 이 멋진 웹사이트에서 일부 채택되었어요:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">from</span> matplotlib.<span class=\"hljs-property\">font_manager</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">FontProperties</span>\n\nbackground_color = <span class=\"hljs-string\">'#001219'</span>\nfont = <span class=\"hljs-title class_\">FontProperties</span>(fname=<span class=\"hljs-string\">'LexendDeca-VariableFont_wght.ttf'</span>)\nfig, ax = plt.<span class=\"hljs-title function_\">subplots</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, figsize=(<span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">9</span>))\nfig.<span class=\"hljs-title function_\">set_facecolor</span>(background_color)\nax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">set_facecolor</span>(background_color)\nax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">set_facecolor</span>(background_color)\n\nax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">plot</span>(<span class=\"hljs-title function_\">range</span>(<span class=\"hljs-title function_\">len</span>(all_loss_G)), all_loss_G, color=<span class=\"hljs-string\">'#bc6c25'</span>, lw=<span class=\"hljs-number\">0.5</span>) \nax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">plot</span>(<span class=\"hljs-title function_\">range</span>(<span class=\"hljs-title function_\">len</span>(all_loss_D)), all_loss_D, color=<span class=\"hljs-string\">'#00b4d8'</span>, lw=<span class=\"hljs-number\">0.5</span>)\n\nax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">scatter</span>(\n      [np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">argmax</span>(), np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">argmin</span>()],\n      [np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">max</span>(), np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">min</span>()],\n      s=<span class=\"hljs-number\">30</span>, color=<span class=\"hljs-string\">'#bc6c25'</span>,\n   )\nax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">scatter</span>(\n      [np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">argmax</span>(), np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">argmin</span>()],\n      [np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">max</span>(), np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">min</span>()],\n      s=<span class=\"hljs-number\">30</span>, color=<span class=\"hljs-string\">'#00b4d8'</span>,\n   )\n\nax.<span class=\"hljs-title function_\">text</span>(\n      np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">argmax</span>()+<span class=\"hljs-number\">60</span>, np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">max</span>()+<span class=\"hljs-number\">0.1</span>,\n      f<span class=\"hljs-string\">'{round(np.array(all_loss_G).max(),1)}'</span>,\n      fontsize=<span class=\"hljs-number\">13</span>, color=<span class=\"hljs-string\">'#bc6c25'</span>,\n      font=font,\n      ax=ax[<span class=\"hljs-number\">0</span>]\n   )\nax.<span class=\"hljs-title function_\">text</span>(\n      np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">argmin</span>()+<span class=\"hljs-number\">60</span>, np.<span class=\"hljs-title function_\">array</span>(all_loss_G).<span class=\"hljs-title function_\">min</span>()-<span class=\"hljs-number\">0.1</span>,\n      f<span class=\"hljs-string\">'{round(np.array(all_loss_G).min(),1)}'</span>,\n      fontsize=<span class=\"hljs-number\">13</span>, color=<span class=\"hljs-string\">'#bc6c25'</span>,\n      font=font,\n      ax=ax[<span class=\"hljs-number\">0</span>]\n   )\n\nax.<span class=\"hljs-title function_\">text</span>(\n      np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">argmax</span>()+<span class=\"hljs-number\">60</span>, np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">max</span>()+<span class=\"hljs-number\">0.01</span>,\n      f<span class=\"hljs-string\">'{round(np.array(all_loss_D).max(),1)}'</span>,\n      fontsize=<span class=\"hljs-number\">13</span>, color=<span class=\"hljs-string\">'#00b4d8'</span>,\n      font=font,\n      ax=ax[<span class=\"hljs-number\">1</span>]\n   )\nax.<span class=\"hljs-title function_\">text</span>(\n      np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">argmin</span>()+<span class=\"hljs-number\">60</span>, np.<span class=\"hljs-title function_\">array</span>(all_loss_D).<span class=\"hljs-title function_\">min</span>()-<span class=\"hljs-number\">0.005</span>,\n      f<span class=\"hljs-string\">'{round(np.array(all_loss_D).min(),1)}'</span>,\n      fontsize=<span class=\"hljs-number\">13</span>, color=<span class=\"hljs-string\">'#00b4d8'</span>,\n      font=font,\n      ax=ax[<span class=\"hljs-number\">1</span>]\n   )\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-number\">2</span>):\n    ax[i].<span class=\"hljs-title function_\">tick_params</span>(axis=<span class=\"hljs-string\">'x'</span>, colors=<span class=\"hljs-string\">'white'</span>)\n    ax[i].<span class=\"hljs-title function_\">tick_params</span>(axis=<span class=\"hljs-string\">'y'</span>, colors=<span class=\"hljs-string\">'white'</span>)\n    ax[i].<span class=\"hljs-property\">spines</span>[<span class=\"hljs-string\">'left'</span>].<span class=\"hljs-title function_\">set_color</span>(<span class=\"hljs-string\">'white'</span>) \n    ax[i].<span class=\"hljs-property\">spines</span>[<span class=\"hljs-string\">'bottom'</span>].<span class=\"hljs-title function_\">set_color</span>(<span class=\"hljs-string\">'white'</span>) \n    ax[i].<span class=\"hljs-title function_\">set_xlabel</span>(<span class=\"hljs-string\">'Epoch'</span>, color=<span class=\"hljs-string\">'white'</span>, fontproperties=font, fontsize=<span class=\"hljs-number\">13</span>)\n    ax[i].<span class=\"hljs-title function_\">set_ylabel</span>(<span class=\"hljs-string\">'Loss'</span>, color=<span class=\"hljs-string\">'white'</span>, fontproperties=font, fontsize=<span class=\"hljs-number\">13</span>)\n\nax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">set_title</span>(<span class=\"hljs-string\">'Generator'</span>, color=<span class=\"hljs-string\">'white'</span>, fontproperties=font, fontsize=<span class=\"hljs-number\">18</span>)\nax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">set_title</span>(<span class=\"hljs-string\">'Discriminator'</span>, color=<span class=\"hljs-string\">'white'</span>, fontproperties=font, fontsize=<span class=\"hljs-number\">18</span>)\nplt.<span class=\"hljs-title function_\">savefig</span>(<span class=\"hljs-string\">'Loss.jpg'</span>)\nplt.<span class=\"hljs-title function_\">show</span>()\n# ax[<span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">set_axis_off</span>()\n# ax[<span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">set_axis_off</span>()\n</code></pre>\n<p>또한 테스트 데이터셋에서 임의의 샘플을 시각화할게요:</p>\n<pre><code class=\"hljs language-js\">random.<span class=\"hljs-title class_\">Random</span>(<span class=\"hljs-number\">2</span>).<span class=\"hljs-title function_\">shuffle</span>(test_target_img_path)\nrandom.<span class=\"hljs-title class_\">Random</span>(<span class=\"hljs-number\">2</span>).<span class=\"hljs-title function_\">shuffle</span>(test_input_img_paths)\nsubset_loader = <span class=\"hljs-title function_\">dataset</span>(batch_size=<span class=\"hljs-number\">5</span>, img_size=img_size, images_paths=test_input_img_paths,\n                        targets=test_target_img_path)\ngenerator = <span class=\"hljs-title class_\">UNet</span>()\ngenerator.<span class=\"hljs-title function_\">load_state_dict</span>(torch.<span class=\"hljs-title function_\">load</span>(<span class=\"hljs-string\">'generator.pth'</span>))\n\ngenerator.<span class=\"hljs-built_in\">eval</span>()\n<span class=\"hljs-keyword\">for</span> X, y <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">subset_loader</span>:\n    fig, axes = plt.<span class=\"hljs-title function_\">subplots</span>(<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">3</span>, figsize=(<span class=\"hljs-number\">9</span>, <span class=\"hljs-number\">9</span>))\n\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-number\">5</span>):\n        axes[i, <span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">transpose</span>(X.<span class=\"hljs-title function_\">numpy</span>()[i], (<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">0</span>)))\n        axes[i, <span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">set_title</span>(<span class=\"hljs-string\">\"Input\"</span>)\n        axes[i, <span class=\"hljs-number\">0</span>].<span class=\"hljs-title function_\">axis</span>(<span class=\"hljs-string\">'off'</span>)\n        \n        axes[i, <span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">transpose</span>(y.<span class=\"hljs-title function_\">numpy</span>()[i], (<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">0</span>)))\n        axes[i, <span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">set_title</span>(<span class=\"hljs-string\">\"Target\"</span>)\n        axes[i, <span class=\"hljs-number\">1</span>].<span class=\"hljs-title function_\">axis</span>(<span class=\"hljs-string\">'off'</span>)\n        \n        generated_image = <span class=\"hljs-title function_\">generator</span>(X[i].<span class=\"hljs-title function_\">unsqueeze</span>(<span class=\"hljs-number\">0</span>)).<span class=\"hljs-title function_\">detach</span>().<span class=\"hljs-title function_\">numpy</span>()[<span class=\"hljs-number\">0</span>]\n        axes[i, <span class=\"hljs-number\">2</span>].<span class=\"hljs-title function_\">imshow</span>(np.<span class=\"hljs-title function_\">transpose</span>(generated_image, (<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">0</span>)))\n        axes[i, <span class=\"hljs-number\">2</span>].<span class=\"hljs-title function_\">set_title</span>(<span class=\"hljs-string\">\"Generated\"</span>)\n        axes[i, <span class=\"hljs-number\">2</span>].<span class=\"hljs-title function_\">axis</span>(<span class=\"hljs-string\">'off'</span>)\n    \n    # 레이아웃 조정\n    plt.<span class=\"hljs-title function_\">tight_layout</span>()\n    plt.<span class=\"hljs-title function_\">savefig</span>(<span class=\"hljs-string\">'Test.jpg'</span>)\n    plt.<span class=\"hljs-title function_\">show</span>()\n    <span class=\"hljs-keyword\">break</span> \n</code></pre>\n<p>여기서 보시다시피, 결과는 완벽하지 않고 땅커버 유형에 매우 의존합니다. 그럼에도 불구하고, 구축된 모델은 이미지에서 구름을 제거하며, G 및 D 깊이를 늘리는 것으로 성능을 향상시킬 수 있습니다. 다른 유망한 전략은 서로 다른 땅커버 유형을 위해 별도의 모델을 훈련시키는 것입니다. 예를 들어, 작물밭과 물 투구는 분명히 다른 공간적 특징을 가지고 있기 때문에 일반화 모델의 능력에 영향을 주는 경우가 있습니다.</p>\n<p>이 기사가 지리정보 도메인에서 심층 학습 알고리즘을 적용하는 데 새로운 시각을 제공해 드렸기를 바랍니다. 내 생각에는, GANs는 데이터 과학자가 활용할 수 있는 가장 강력한 도구 중 하나이며, 여러분의 도구 상자의 필수적인 부분이 되길 희망합니다!</p>\n<p>===========================================</p>\n<p>참고문헌:</p>\n<ol>\n<li>\n<p>Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville 및 Yoshua Bengio. “Generative adversarial nets.” Advances in neural information processing systems 27 (2014). <a href=\"https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf\" rel=\"nofollow\" target=\"_blank\">논문 링크</a></p>\n</li>\n<li>\n<p>Helber, Patrick, Benjamin Bischke, Andreas Dengel 및 Damian Borth. “Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification.” IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 12, no. 7 (2019): 2217–2226. <a href=\"https://arxiv.org/pdf/1709.00029\" rel=\"nofollow\" target=\"_blank\">논문 링크</a></p>\n</li>\n<li>\n<p>Wen, Xue, Zongxu Pan, Yuxin Hu 및 Jiayin Liu. “Generative adversarial learning in YUV color space for thin cloud removal on satellite imagery.” Remote Sensing 13, no. 6 (2021): 1079. <a href=\"https://www.mdpi.com/2072-4292/13/6/1079\" rel=\"nofollow\" target=\"_blank\">논문 링크</a></p>\n</li>\n</ol>\n<ol start=\"5\">\n<li>\n<p>Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. “U-net: Convolutional networks for biomedical image segmentation.” In Medical image computing and computer-assisted intervention–MICCAI 2015: 18th international conference, Munich, Germany, October 5–9, 2015, proceedings, part III 18, pp. 234–241. Springer International Publishing, 2015. <a href=\"https://arxiv.org/pdf/1505.04597\" rel=\"nofollow\" target=\"_blank\">Link</a></p>\n</li>\n<li>\n<p>He, Kaiming, et al. “Deep residual learning for image recognition.” Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. <a href=\"https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\" rel=\"nofollow\" target=\"_blank\">Link</a></p>\n</li>\n</ol>\n<p>===========================================</p>\n<p>제 Medium의 모든 게시물은 무료이며 공개되어 있습니다. 그래서 여기서 저를 팔로우해 주시면 정말 감사하겠습니다!</p>\n<p>P.s. 저는 (지리)데이터 과학, 머신 러닝/인공지능, 기후 변화에 대해 열정적으로 관심을 가지고 있습니다. 그래서 어떤 프로젝트에서 함께 작업하고 싶다면 LinkedIn에서 연락 주세요.</p>\n<p>🛰️더 많은 소식을 받아보려면 팔로우하세요!🛰️</p>\n</body>\n</html>\n"},"__N_SSG":true}