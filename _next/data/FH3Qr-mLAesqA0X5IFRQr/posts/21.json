{"pageProps":{"posts":[{"title":"인공지능 생성 보컬의 유별난 윤리 문제","description":"","date":"2024-06-19 20:51","slug":"2024-06-19-TheWeirdEthicsofAI-GeneratedVocals","content":"\n\n<img src=\"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_0.png\" />\n\n요즘 증가하는 생성 AI와 함께 실제 가수들의 목소리로 훈련된 AI 생성 보컬이 등장했습니다. 이 AI 음성 \"크롬\"은 음악 산업과 인터넷 전반을 동요시켰으며, 다양한 윤리 문제들을 제기했습니다. 일부는 음악에서 복제된 목소리의 사용을 음악 작가와 청취자들에게 엄청난 혜택으로 보지만, 다른 사람들은 그것만으로는 위험요인만을 보았습니다. 여기에 몇 가지 재미있는 사례가 있습니다:\n\nAI로 생성된 드레이크와 더 위켄드 보컬이 특집된 노래가 스트리밍 서비스에 의해 제거되기 전에 바이럴로 퍼졌습니다. AI 음악을 비난하는 Universal Music Group 대표는 Music Business Worldwide에 발표된 성명에서, \"우리 아티스트들의 음악을 사용하여 생성 AI를 훈련한다는 것은 음악 생태계의 모든 이해관계자들이 어느 쪽 역사에 서길 원하는지 의문을 제기합니다: 아티스트, 팬 및 인간의 창의적 표현을 지지하는 쪽인가요, 아니면 딥 페이크, 사기 및 아티스트들에게 정당한 보상을 제공하지 않는 쪽인가요?\" 라고 말했습니다. (강조는 제가 한 것입니다.)\n\n아이스 큐브는 AI를 \"악마적\"이라고 지적하면서 음악에는 그 자리가 없다고 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n스테파니 선은 2017년 이후 휴식을 취했던 싱가포르 가수인데, 자신의 컴백을 목도하게 되었지만, 사실상 그녀가 아닌 그녀의 AI 복제품이었습니다. 그녀의 AI가 생성한 보컬이 담긴 노래들이 이전 노래보다 더 인기를 끌자, 어떤 인간 아티스트도 AI와 경쟁할 수 없다고 말했습니다. \"어떻게 하류에 누군가와 경쟁하나요? 몇 분 단위로 새로운 앨범을 내놓는 사람과 어떻게 싸우나요?\"\n\n폴 맥카트니는 전 동료의 목소리를 부활시켰는데, AI의 도움으로 이제는 사망한 존 레논의 보컬을 사용하여 비틀즈의 마지막 레코드를 만들 수 있게 되었습니다. The Verge의 기사에 따르면, \"과거 녹음물을 복원하는 데 AI를 사용하는 가능성에 흥분하던 맥카트니는 존 레논의 목소리로 자신의 노래를 부르는 것을 듣는 것이 '좀 무서운' 것이라 말했습니다.\"\n\n가장 흥미로운 케이스 중 하나는 클레어 부처의 것인데, 많은 사람들이 그녀의 음악 프로젝트 이름인 그라임즈로 아는 사람들이 대부분입니다. 이론상 엘론 머스크의 자식엄마가 아닌 그녀는 '어버이없는 자'로서 그라임즈라는 '대인견문 인격체'로 음악을 작곡하고 녹음하며 제작하는 창조자입니다. 그녀의 아방가르드 음악은 장르에 도전하며 예술성과 엔지니어링을 융합시키고 있습니다(그녀는 여전히 기테제로 테마 앨범을 만드는 아티스트 중 한 명입니다). 그녀는 완전히 자학하며 종종 별난데 섬세하고 악순함이 없습니다. 그녀는 독특한 음악, 지식, 그리고 삶에 대한 견해로 자신의 이름을 알리게 되었습니다: 그녀는 시대에 따라 변하는 페미니스트로서 역사에 대한 심층적인 이해력이 있고, 지속가능한 에너지를 창조하고 인류를 다중행성종으로 만들며 의식을 보존하는 세 가지 목표를 가진 미래학자입니다.\n\n# 그라임즈의 AI 음악 혁명에서의 역할\n\n<div class=\"content-ad\"></div>\n\n클레어는 2003년 4월 23일에 트윗해 \"내 목소리를 사용한 성공적인 AI 생성 곡에 대해서는 50% 저작권료를 쪼개드릴게요. 협업하는 아티스트와의 계약과 동일한 조건이에요. 벌금 없이 내 목소리 자유롭게 사용해도 돼요. 레이블도 없고 법적 제약도 없어요.\"라며 음악에 AI 클론을 특징으로 한 미래를 공개적으로 받아들였어요.\n\n클레어의 제안은 더욱 현실로 다가왔습니다. 딱 일주일 후에는 Elf.Tech를 선보였는데, 이는 CreateSafe와의 파트너십을 통해 탄생한 AI 보컬 생성기로, CreateSafe는 다양한 도구를 활용하여 아티스트들을 지원하는 기업입니다. Elf.Tech 앱을 사용하기 위해 등록하는 사용자들은 미리 녹음된 노래를 업로드하거나 앱에 직접 보컬을 녹음할 수 있어요. 그리고 해당 보컬은 GrimesAI 음성 프린트로 변환됩니다. CreateSafe의 사이트에는 \"GrimesAI 녹음을 만드는 크리에이터들은 이 새로운 녹음물들을 소유하게 될 거예요. GrimesAI-1은 이 음원 녹음이나 기반이 되는 작품에 대한 소유권을 주장하지 않아요 (Grimes 노래의 커버인 경우 제외).\" 라고 나와 있어요.\n\n<div class=\"content-ad\"></div>\n\n맞아요, 클레어는 다른 창작자들이 그라임스의 보컬을 사용하길 원합니다. 그녀가 클론된 목소리를 사용하는 다른 창작자들의 시나리오를 법적이나 도덕적으로 부당하다고 생각하지 않는다는 것은 몇몇 다른 예술가들이 그렇게 생각하지 않는 것과는 다르다. 그녀는 심지어 자신의 목소리를 특징으로 한 노래를 만드는 과정을 단순화하는 필수 도구를 예술가들과 팬들에게 제공했습니다.\n\n# Elf.Tech를 통해 음악 민주화\n\nElf.Tech는 몇몇 사람들이 생각할 수 있는 클레어의 완전한 허영 프로젝트가 아닙니다. 그녀는 심지어 자신의 목소리나 가수로서의 능력을 좋아하지 않는다고 주장합니다. 클레어는 최근 이비사의 비트포트 국제 음악 정상회의에서 키노트 인터뷰를 하면서 말했습니다. \"아무도 나를 가수로 잘하는 걸로 생각하지 않아. 나는 그냥... 부디 나를 가수라고 부르지 말아줘. 사람들이 들어가서 내가 전문적으로 한다고 생각한다면... 나에게 좋은 모습이 아니야.\"\n\n이 프로젝트의 핵심은 AI가 세상에 미칠 긍정적인 영향과 AI 혁명의 중심에 서기를 원하는 그녀의 신념에 관한 것입니다.\n\n<div class=\"content-ad\"></div>\n\n지난 국제 음악 정상 회의에서 클레어는 Elf.Tech을 창립하기 전에 AI 기술을 활용하는 기업들에 전화를 걸어 그들의 발전 상황을 살펴볼 수 있는지 여쭸었던 경험에 대해 이야기했습니다. 이 경험이 그녀를 \"연구 심층 탐구\"에 이끄는데 큰 역할을 했고, 그 결과 음악적으로 하는 일을 \"재조정\"하게 되었을 것으로 보입니다. 이로써 Elf.Tech를 창립하게 된 것으로 예상됩니다.\n\nElf.Tech는 음악의 민주화를 목표로 하는 고귀한 야망의 결과물입니다. 클레어는 세계가 대체로 AI로 혜택을 받을 수 있다고 믿지만, 그녀 자신은 음악 산업에 초점을 맞추고 있습니다. 음악 산업에서 \"정말 많은 관문이 있다\"며 \"저작권이 최악이야\"라고 주장합니다. 그녀는 역사상 위대한 예술은 알려지지 않은 예술가들이 만든다고 말합니다. 고대 이집트의 큰 피라미드를 상상해보세요. 현재 예술이 자아와 너무 뒤얽혀있는 것은 아주 \"현대적인 개념\"이며, 클레어는 이를 버릴 필요가 있다고 생각하는 것으로 보입니다.\n\n회의에서 그녀가 말한 내용을 요약하면 다음과 같습니다: \"음악 산업은 매우 변호사들에 의해 규정되어 왔는데, 이것이 창의성을 제약하는 구속을 가하고 있다고 생각해요. 예술에서 가장 위대한 순간들은 저작권이 가장 없을 때, 예를 들어 랩의 초기 시기나 샘플링의 초창기처럼 말이에요.\"\n\n저작권 제약으로 인해 발생하는 문제뿐만 아니라 AI가 해결할 수 있는 가능성이 많을 뿐만 아니라, AI가 창조할 수 있는 팬과의 상호 작용 가능성도 무수히 존재합니다. 클레어는 지적 재산권을 사용하는 팬덤들을 처벌하지 않는 실제 기업들의 사례에 근거해 이런 주장을 합니다. 그러한 팬덤들이 많은 멋진 예술 작품을 만들어내느라는 점을 생각해보세요. 음악에서 AI의 광범위한 활용을 가능하게 함으로써, 클레어와 그녀의 팀이 \"공동창작물\"로 틀어놓은 놀라운 팬 아트가 탄생할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n물론 그녀는 복제된 AI 생성 보컬의 잠재적 위험을 인지하고 있습니다.\n\n콘센트에 대한 그녀의 생각을 물었을 때, 그녀는 예술가가 동의하기 전에 그들의 목소리가 사용될 때 좋다고 분명히 했습니다. 특히, 다른 창작자들에 의해 사용되는 예술가들은 예술적 통제를 포기할 것이기 때문에 이러한 동의가 중요하다고 말했습니다.\n\n죽은 가수들의 목소리 사용에 대한 그녀의 생각은 조금 덜 형성되어 있지만, 죽은 사람들은 목소리가 사용될 동의를 줄 수 없기 때문에 이 문제가 복잡하다는 점을 인정했습니다. 그녀는 “정말 어렵다”며 이야기했습니다. “아마도 아니라고 말할 것 같아” (즉, 죽은 가수들의 목소리는 사용되지 말아야 한다는 의미). “하지만 프린스 같은 사람은 좀 괜찮아 할 것 같아”라고 말했습니다. 그녀는 또한 예술가나 소비자들이 죽은 가수들의 목소리를 선호함으로써 새로운 가수가 음악계에 진입하기 어려워질 것을 우려한다고 말했습니다. 만약 모두가 마이클 잭슨의 목소리를 사용하기를 원한다면, 세상은 다음 마이클 잭슨을 어떻게 발견할 수 있을까요?\n\n음악 써밋에서 인터뷰어가 클레어에게 물었습니다. “만약 누군가가 당신의 목소리를 사용해 끔찍하고 싫어하는 무언가를 만들었다면 어떻게 하시겠어요?” 클레어는 “나는 그들이 그렇게 만들었으면 하는데”라고 대답했습니다. 인간들은 AI에 의해 가져다줄 위험에 대해 개방해야 하며 그 결과를 지켜봐야 한다고 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n키노트 인터뷰에서 클레어가 AI로 생성된 보컬이 인간 보컬리스트를 앞으로 가려지게 할 수 있는 가능성에 대해 이야기하지는 않았지만, 클레어는 인간들이 AI의 한계를 집단적으로 이해하지 못하고 있다고 말했으며, 그녀는 AI가 우리의 모든 일에서 우리보다 우수해져서 우리를 이기게 될 것이라고 믿는다.\n\n# AI 음악 배포의 현재 법적 기술적 문제들\n\nElf.Tech의 출시 이후, YouTube와 스트리밍 사이트에서 여러 개의 GrimesAI 비디오가 확산되었습니다. 그러나 이 중 많은 비디오들이 흐릿한 법적 문제 때문에 스트리밍 사이트에서 삭제되었는데, Grimes 팀이 이 문제에 대해 노력하고 있다고 합니다.\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_3.png)\n\n<div class=\"content-ad\"></div>\n\n국제 음악 정상회의 중에 클레어는 스트리밍 서비스가 \"AI\"로 명확하게 표시된 AI 음악 하위 섹션이 생성될 것을 상상한다고 언급했습니다. 아마 그녀의 팀의 주요 목표 중 하나는 플랫폼에서 AI 음악을 위한 지정된 공간을 마련하는 것입니다. 국제 음악 정상회의에서 그녀가 한 말을 요약한 것이 여기 있습니다: \"우리 팀과 저는 정말 스포티파이에게 AI 섹션을 만들 것을 촉구하고 싶어합니다. 그 플랫폼에서 가수들은 최고의 트랙, 앨범 및 신작을 가지고 있죠; 스포티파이가 AI 섹션도 만든다면, 청취자들이 음악을 구분하고 'AI'로 표시된 음악이 아티스트의 창작물이 아님을 이해하기가 더 쉬울 것입니다. 그렇게 하면 품질 관리가 좀 더 쉬워질 거에요. 이 AI가 정말 새로운데 음악 산업이 이를 대비하도록 구성되어 있지 않아요, 그래서 필요한 변경을 해야 해요.\"\n\n저작권에 대한 클레어의 싫증에도 불구하고, 그녀와 그녀의 팀은 여전히 그녀의 비전을 실현하기 위해 음악 저작권의 복잡한 세계를 탐험해야 했습니다. 그들이 경험한 대부분의 문제는 배급과 관련이 있습니다: 주요 스트리밍 서비스 중 일부가 AI를 사용한 음악을 차단하고 있기 때문에, 창작자들이 GrimesAI 보컬을 사용하는 음악을 유통할 수 있게 어떻게 할 수 있을까요? 그 음악 산업이 그러한 음악에 대한 윤리가 격하게 논의되고 있는 상황에서, 아직 AI 지원 음악을 다루기에 적합하게 준비되어 있지 않기 때문에 어려움을 겪고 있습니다.\n\n그들은 마침내 어떤 진전을 이룬 것으로 보입니다.\n\n자립 발매 아티스트를 위한 음악 유통업체인 TuneCore가 CreateSafe와 Grimes와 협력하여 스트리밍 플랫폼에 AI 음악을 선보이는 데 기여했습니다. 그들의 주요 역할은 이러한 일에 관련된 모든 법적 및 기술적 사항들을 처리하는 것인 것 같습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_4](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_4.png)\n\nTunecore의 CEO에 따르면,\n\n이 협력의 결과는 이러한 공동 창작물이 라이선스 프로세스를 보다 쉽게 통과하도록 지원되어 저작권 관련 문제를 회피할 수 있다는 것입니다. GrimesAI를 이용하는 아티스트들은 음악을 제출하려면 Elf.Tech를 통해 배포 비용을 지불하거나 자체 라이선스 승인을 요청해야 합니다. 두 가지 방법 모두 승인이 필요하며, 노래가 충족해야 할 제약 사항과 특정 기준이 있습니다. 클레어는 아직 저작권을 무력화시키지는 않았습니다. 그녀는 오히려 그것과 함께 춤추는 법을 익혔습니다.\n\n2023년 6월 6일의 트윗에서, 클레어는 미래에 더 많은 변화가 있을 것이라 시사했으며, 이는 더 큰 스트리밍 서비스인 Spotify와 같은 곳도 곧 자신들의 플랫폼에서 AI 생성 보컬을 허용할지도 모른다는 것을 의미할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_5.png\" />\n\n아직 큰 플랫폼에서 AI 음악을 허용할지 여부에 대한 업데이트가 제공되지 않았습니다.\n\n생성적 AI는 다양한 형태의 예술을 민주화하고, 예술 창작을 쉽고 매우 자동화할 수 있도록 합니다. 음악 산업에서는 이는 결국 새로운 또는 훈련이 덜 된 예술가들이 더 쉽게 진입할 수 있다는 것을 의미할 수 있으며, 창의적 과정의 일부를 쉽게 할 수도 있습니다. 그러나 그에는 악의적인 목적으로 다른 사람의 음성을 사용하는 사람들, 다른 사람들의 음성으로 수익을 얻는 사람들, 그리고 인간 예술가들이 그들의 AI 상대방이 더 인기가 많아지면 잊혀지는 등 부정적인 가능성이 딸려옵니다.\n\n시간은 이 기술을 사실로 어떻게 사용할지를 말해줄 것이지만, Grimes는 음악계의 실험대로 나서고 있습니다. 우연한 결과의 법칙이 승리할 것이라는 것을 그녀도 알지만, 그녀는 이를 실험하려고 준비가 되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_6.png)\n\n이미 어려운 상황을 마주했어요. 그녀가 트윗에서 '그라임스의 모습'을 사용해 '나쁜 마음 바이러스'를 퍼뜨리는 콘텐츠를 제거해 달라고 요청할 것이라고 밝힌 것을 알 수 있었어요. 이는 일부 사람들이 그라임스 AI 보이스프린트를 악용했을 수도 있다는 신호예요.\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_7.png)\n\n그리고 떠오르는 잠재적 무명의 미래를 조금 맛 본 것으로 보입니다. 2023년 5월 8일 트윗에서 \"사실, 사람들이 나보다 경쟁적으로(아니면 더 나은가요??) 퀄리티 좋게 그라임스 같은 노래를 만들기 시작한 것이 약간 스트레스 받게 만드네요. 그러나 또한 이게 또 다른 커리어에서 죽고 다시 부활할 가장 아름다운 시적인 방법일지도 몰라요.\"라고 썼어요.\n\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_8.png)\n\n물론, 클레어 부셰의 경우에는 AI 생성 보컬을 둘러싼 많은 사례 중 하나일 뿐이며, AI 생성 또는 지원 형태를 사용하는 음악과 관련된 사례는 더욱 많습니다. 그녀는 창의적인 통제를 희생하고 자신의 목소리를 누구나의 악기로 사용할 수 있도록 제공함으로써 AI 음악 혁명의 중심에 위치하게 되었습니다.\n\n그녀의 음악 산업에서의 행동과 다른 이들이 그녀의 목표에 대해 얼마나 수용하는지는 예술 전반에 영향을 미칠 것입니다.\n\n작가들도 AI 생성 보컬을 둘러싼 논쟁의 부작용을 볼 것입니다. 모든 이러한 생성적 AI에 관한 논쟁은 교차되기 때문입니다. 예를 들어, 사망한 작가들이 AI \"쓰기 클론\"을 통해 그들이 완결하지 못한 시리즈를 마무리해야 하는가? 오디오북을 만드는 작가들은 어떻게 AI 생성 보컬에 접근해야 하는가 - 그러한 윤리적 고민을 어떻게 해결해야 하는가? 작가들은 대형 언어 모델이나 유사한 AI들에 의해 자신의 저자 \"목소리\"가 복제된 것에 대해 어떻게 생각하는가?\n\n<div class=\"content-ad\"></div>\n\n우리는 낯선, 탁한 물속에 있어요. 그리고 깊이에 기다리는 것은 알 수 없지만, 가능성은 두려울 만큼 두렵고 흥미롭습니다.\n\n(*저스틴 콕스의 Medium 기사 덕분에 Stefanie Sun 사건에 대해 알게 되었어요!)","ogImage":{"url":"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_0.png"},"coverImage":"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_0.png","tag":["Tech"],"readingTime":9},{"title":"Midjourney로 추상적인 것을 탐험하기","description":"","date":"2024-06-19 20:50","slug":"2024-06-19-GoingabstractwithMidjourney","content":"\n\nMidjourney의 새로운 개인화 기능을 더 철저히 테스트하고, 그 과정에서 조금은 추상 미술로 놀았어요.\n\n이것이 이상한 선택처럼 들릴 수 있겠죠. 추상 미술은 정의하기 어려운 미묘한 개념인데, 이미 어렵게 평가해야 할 성능 기능을 평가할 때 왜 사용해야 하죠?\n\n내 추론은 이렇습니다. 개인화 기능은 내가 사진을 평가할 때의 선호도를 기반으로 합니다. 평가 프로세스는 상당히 주관적인 일이에요; 가끔은 기술적 요소를 기준으로 사진을 선택하기도 해요 — 예를 들어, 적당한 손가락과 다리의 양. 하지만 대부분은 미학적 감각을 기반으로 — 적절한 구성, 색상, 그리고 기술이 콘텐츠와 일치하는 것을 따라 사진을 선택해 왔어요.\n\n그렇기에 추상 미술을 좋아하거나 싫어하는 것도 비슷해요. 추상 미술은 현실적인 객체를 표현하는 것이 아니에요; 그것은 색채, 형상, 그리고 특정 기술로 감정, 분위기, 또는 아이디어를 전달하는 것이기 때문이에요.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-GoingabstractwithMidjourney_0.png\" />\n\n그래서, 만약 개인 맞춤 설정이 내가 평가한 다양한 이미지에서 선호도를 선택한다면, 이 기능을 사용하여 만들어지는 추상 예술 작품에 반영되어야 한다고 판단했습니다. 나는 내 개인 맞춤 설정으로 만들어진 이미지에 더 잘 공감할 수 있어야 합니다.\n\n추상 예술은 추상적인 생각으로부터 시작됩니다. 복잡한 감정이나 아이디어를 말로 표현하는 것이 얼마나 어려운지 놀라울 정도이며, 더 어렵게는 붓으로 그것을 하는 것입니다.\n\n그래서 대부분의 Midjourney 사용자들은 원하는 예술적 효과와 감정 요소를 달성하기 위해 아이디어를 설명하는 대신 기술이나 스타일을 정의하는 것을 고수합니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사는 추상적 사고나 기계에 추상적 개념을 전달하는 데 관한 것이 아니므로, 우리도 이 간소화된 방법을 사용할 겁니다.\n\n하지만 그래도 추상 미술은 매우 폭넓은 개념이며 다양한 형태로 나타날 수 있기 때문에, 하얀 테스트를 적어도 어느 정도 측정 가능하도록 하기 위해 일부 선택이 필요합니다.\n\n사진 작가로서 나도 추상 이미지를 만드는 것을 좋아했어요. 하지만 \"추상\"이라는 사진 작품 개념은 Pollock의 추상 미술과는 매우 다릅니다.\n\n![이미지](/assets/img/2024-06-19-GoingabstractwithMidjourney_1.png)\n\n<div class=\"content-ad\"></div>\n\n추상적인 그래픽은 추상 회화와 같은 것이 아닙니다. 그리고 추상 조각 예술 및 설치 예술은 서로에게 더 멀리 떨어진 개념입니다. 그러나 모두가 '추상적'일 수 있습니다.\n\n그리고 넓은 개념이기 때문에 재미있게 놀 수 있으며, Midjourney는 당신만의 추상적 추상 예술 운동을 만들 수 있는 도구가 될 수도 있습니다.\n\n난 항상 짧은 프롬프트를 선호해. 이번 테스트에서도 짧은 프롬프트를 사용할 거야. 인지 테스트를 거치지 않고 Midjourney의 성능을 가장 쉽게 평가할 수 있어.\n\n그래서 여기 한 프롬프트의 예제가 있어:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-GoingabstractwithMidjourney_2.png\" />\n\n이 프롬프트는 추상 예술 양식에 특정한 용어가 없으며, 추상 이미지로 만들라는 간단한 지시이지만, 귀하의 프롬프트에 포함할 가능성이 있는 용어와 스타일을 짧게 모았습니다.\n\n- 비목적적: 인식 가능한 대상을 나타내거나 묘사하지 않는 예술.\n- 기하학적 추상: 기하학적 모양과 형태를 주요 요소로 사용하는 예술.\n- 유기적 추상: 유기적이고 자연적인 형태와 모양을 강조하는 예술로, 종종 생명체를 닮았습니다.\n- 추상 표현주의: spontaneity, expressiveness, and often large-scale works that emphasize the act of painting itself을 특징으로 하는 운동.\n- 미니멀리즘: 단순함에 초점을 맞춘 예술 운동으로, 최소한의 요소와 종종 단색 계통을 사용합니다.\n- 데 스테일: 순전한 추상과 단순함을 주장하는 예술 운동으로, 직선, 기하학적 모양, 주요 색상을 사용합니다.\n- 최정주의: 재스 키 클러 국 한, 기본적인 기하학적 형태와 제한된 색상을 중점으로 하는 추상 예술 운동.\n- 액션 페인팅: 캔버스에 페인트를 무심코 묻거나 튀기거나 문지르는 스타일의 페인팅으로, 그림 그리는 행위를 강조합니다.\n- 색면 회화: 단일 색상의 큰 영역이나 몇 가지 색상으로 구성된 단순한 구성을 특징으로 하는 추상 회화 스타일.\n- 리릭 약술: 개인적 표현, 감정 및 색상과 형태의 서정적인 사용을 강조하는 운동.\n- 하드 에지 페인팅: 날카롭고 깨끗한 가장자리와 기하학적 모양을 사용하는 추상 회화 스타일로, 종종 단색을 사용합니다.\n- 건축주의: 러시아에서 유래한 예술 운동으로, 산업 재료와 건축적인 느낌과 연결된 추상적 기하학적 형태에 초점을 맞춥니다.\n- 입체파: 파블로 피카소와 조르주 브락에 이끌린 초기 20세기 운동으로, 단일 작품 내에서 파편화된 물체와 다양한 시점을 특징으로 합니다.\n- 타시즘: 브러시 워크, 물감의 뭉치 및 뚜렷한 특징으로 Abstract Expressionism과 유사한 유럽 추상 예술 운동.\n- 싱크로미즘: 색상을 사용하여 형태와 구조를 만드는 것을 강조하는 추상 예술 운동으로, 종종 음악적 또는 조화로운 방식으로 구성합니다.\n\n이 용어들은 각각 독특한 특성과 Midjourney 이미지 생성에 미치는 영향을 갖는 추상 예술 내의 다양한 개념과 운동을 다룹니다.\n\n<div class=\"content-ad\"></div>\n\n물론, 이것은 짧은 목록입니다. 하지만 \"추상\" 기술과 아이디어의 다양한 스타일, 움직임, 명확한 개념을 더 찾는 것은 어려운 일이 아닙니다.\n\nMidjourney의 성과에서 개인화의 차이를 찾고 있어서 각 일련의 프롬프트를 두 번 실행했습니다. 아래에는 여러분이 스스로 판단할 수 있도록 작은 이미지 라이브러리를 정리해 두었습니다.\n\n이미지 아래에 프롬프트가 제공됩니다. 이미지의 왼쪽에는 개인화 없이 생성된 이미지 그리드가 있고, 오른쪽에는 있는 것입니다.\n\n대부분의 경우, 개인화는 더 나은 이미지를 만들어 냈거나, 적어도 내게는 더 마음에 든 것 같아요.\n\n<div class=\"content-ad\"></div>\n\n중요한 관찰 하나 있어요. 개인화를 사용할 때는 프롬프트 문구에 따르는 정확도가 낮아집니다. Midjourney는 프롬프트에서 키워드를 건너뛸 가능성이 높아질 거에요. 또한 이미지 격자의 변화가 뚜렷하게 감소할 거예요.\n\n저는 개인화의 효과를 선호하는 편이에요. 이미지가 보다 명암이 선명해지고, 제 시각에는 색 균형이 더 좋아 보입니다.\n\n또한, 제 생각에는 개인화가 프롬프트에서 제공된 감정 콘텐츠를 더 잘 전달해 준다고 생각해요. 그러니 그 점은 플러스 되죠.\n\n![이미지](/assets/img/2024-06-19-GoingabstractwithMidjourney_3.png)\n\n<div class=\"content-ad\"></div>\n\n지금까지의 결론은 이 기능이 훌륭하며 이미지에 긍정적인 영향을 미친다는 것입니다. 복잡한 프롬프트와 함께 사용할 때 조심할 것이며, 이미지 그리드의 변이가 줄어드는 것을 보상하기 위해 \"혼돈\"의 작은 설정을 발견했습니다. \n\n추상적인 이미지를 만드는 것이 정말 재미있었고, 여러분도 즐기시길 바랍니다.\n\nAivaras Grauzinis","ogImage":{"url":"/assets/img/2024-06-19-GoingabstractwithMidjourney_0.png"},"coverImage":"/assets/img/2024-06-19-GoingabstractwithMidjourney_0.png","tag":["Tech"],"readingTime":4},{"title":"NLP에서 Named Entity Recognition 텍스트로부터 정보 추출하기 제7부","description":"","date":"2024-06-19 20:47","slug":"2024-06-19-NamedEntityRecognitioninNLPExtractingInformationfromTextPart7","content":"\n\n<img src=\"/assets/img/2024-06-19-NamedEntityRecognitioninNLPExtractingInformationfromTextPart7_0.png\" />\n\n목차\n1. 명명된 엔티티 인식(Unveiling Named Entity Recognition): 구조화된 데이터로 가는 문\n2. NLP에서 정보 추출의 작동 방식\n2.1. 명명된 엔티티 인식에서의 핵심 개념\n2.2. 고급 기술과 알고리즘\n3. 다양한 산업에서 NER의 실용적인 응용\n4. NER의 구성 요소: 도구 및 프레임워크\n5. NER 시스템 평가: 지표 및 벤치마크\n6. 명명된 엔티티 인식에서의 도전 극복\n7. NER의 미래: 트렌드와 예측\n\n더 자세한 자습서는 GPTutorPro에서 확인하세요. (무료)\n\n42페이지의 데이터 과학 | 종합 핸드북을 무료로 받아보세요. (구독)\n\n<div class=\"content-ad\"></div>\n\n## 1. Named Entity Recognition (NER) 소개: 구조화된 데이터로 가는 길\r\n\r\n명명된 개체 인식(NER)은 자연어 처리(NLP)에서 텍스트를 이해하는 데 중요합니다. NER은 이름, 조직, 장소 등의 중요한 요소를 식별함으로써 비구조화된 데이터를 구조화된 형식으로 변환합니다. 이 과정을 통해 기계는 문서 내 내용을 이해하고 분류할 수 있습니다.\r\n\r\nNER의 핵심 개념을 살펴보겠습니다:\r\n\r\n- 텍스트 내 개체의 식별\r\n- 미리 정의된 카테고리로의 분류\r\n- 모호성 해소를 위한 문맥 분석\n\n<div class=\"content-ad\"></div>\n\nspaCy 라이브러리를 사용한 간단한 Python 예제를 보여드릴게요:\n\n```js\nimport spacy\nnlp = spacy.load('en_core_web_sm')\ntext = \"Google was founded by Larry Page and Sergey Brin.\"\ndoc = nlp(text)\nfor ent in doc.ents:\n    print(ent.text, ent.label_)\n```\n\n개체명 인식 시스템은 정밀도, 재현율 및 F1 스코어를 기반으로 평가됩니다. 이러한 지표는 NER 시스템의 정확성과 효율성을 결정하는 데 도움을 줍니다.\n\nNER을 숙달함으로써 방대한 양의 텍스트에서 가치 있는 정보를 추출하여 데이터 분석 및 지식 발견에 강력한 도구로 활용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 2. NLP에서 정보 추출의 메커니즘\n\nNLP에서의 정보 추출은 텍스트로부터 데이터를 식별하고 구조화하는 중요한 프로세스입니다. 이는 Named Entity Recognition (NER)의 기반입니다. 동작 방식은 다음과 같습니다:\n\n먼저, 텍스트는 단어나 구문 등 작은 단위로 토큰화됩니다. 이는 이어지는 단계에 있어서 필수적입니다. 그런 다음, 품사 태깅을 통해 각 토큰에 문법적 범주를 할당하여 역할을 이해하는 데 도움을 줍니다.\n\n이어서 NER 시스템은 엔티티를 인식하기 위해 알고리즘을 적용합니다. 통계적 방법이나 기계 학습 모델을 사용할 수 있습니다. 예를 들어:\n\n<div class=\"content-ad\"></div>\n\n```python\nimport nltk\nfrom nltk import ne_chunk, pos_tag, word_tokenize\nfrom nltk.tree import Tree\n\ndef get_entities(text):\n    # 텍스트 토큰화하기\n    tokens = word_tokenize(text)\n    # POS 태깅 적용\n    tags = pos_tag(tokens)\n    # 태깅된 토큰 청크\n    tree = ne_chunk(tags)\n    return find_named_entities(tree)\n\ndef find_named_entities(tree):\n    entities = []\n    for subtree in tree:\n        if type(subtree) == Tree:\n            entity = \" \".join([token for token, pos in subtree.leaves()])\n            entities.append(entity)\n    return entities\n\ntext = \"Apple Inc. is looking at buying U.K. startup for $1 billion\"\nentities = get_entities(text)\nprint(entities)\n```\n\n마지막으로, 추출된 엔티티들은 사람, 조직 또는 위치와 같은 사전 정의된 그룹으로 분류됩니다. 이러한 구조화된 데이터는 다양한 응용 프로그램에 사용될 수 있어 원시 텍스트 데이터의 가치를 향상시킵니다.\n\n정보 추출 메커니즘을 이해함으로써, NER을 효율적으로 다양한 양의 텍스트 정보를 조직화하고 해석할 수 있습니다.\n\n## 2.1. Named Entity Recognition의 핵심 개념\n\n\n<div class=\"content-ad\"></div>\n\nNamed Entity Recognition (NER)은 정보 추출의 하위 작업으로, 명명된 개체를 미리 정의된 범주로 분류합니다. 사람, 조직, 위치, 시간 표현, 수량, 통화 가치, 백분율 등이 여기에 해당됩니다.\n\nNER의 핵심은 텍스트에서 개체를 찾아 분류하는 것입니다. 이 과정은 구조화되지 않은 데이터를 구조화된 정보로 변환하여 추가 분석을 준비합니다. NLP 파이프라인에서 중요한 단계입니다.\n\nNER은 여러 중요한 단계를 포함합니다:\n\n- 토큰화: 텍스트를 단어, 구, 기호 또는 다른 의미 있는 요소인 토큰으로 분할합니다.\n- 품사 태깅: 각 토큰에 명사, 동사, 형용사 등과 같은 품사를 할당합니다.\n- 청킹: 토큰을 품사 태그를 기반으로 청크로 묶습니다.\n- 개체 인식: 청크를 명명된 개체로 식별합니다.\n- 개체 분류: 명명된 개체를 미리 정의된 그룹으로 분류합니다.\n\n<div class=\"content-ad\"></div>\n\nNLTK 라이브러리를 사용한 간단한 Python 예제를 준비해봤어요:\n\n```python\nimport nltk\nfrom nltk import word_tokenize, pos_tag, ne_chunk\n\nnltk.download('maxent_ne_chunker')\nnltk.download('words')\n\ntext = \"Apple Inc. is looking at buying U.K. startup for $1 billion\"\ntokens = word_tokenize(text)\ntags = pos_tag(tokens)\ntree = ne_chunk(tags)\n\nprint(tree)\n```\n\n이 코드는 텍스트의 명명된 엔터티인 'Apple Inc.'를 조직으로, 'U.K.'를 위치로 인식하게 됩니다.\n\n이러한 개념을 이해하는 것은 챗봇부터 콘텐츠 분석까지 다양한 애플리케이션에서 명명 개체 인식(NER)을 효과적으로 활용하기 위한 필수요소입니다.\n\n<div class=\"content-ad\"></div>\n\n## 2.2. 고급 기술과 알고리즘\n\n고급 기술과 알고리즘은 명명된 개체 인식(NER)의 경계를 넓히는 역할을 합니다. 이러한 정교한 방법들을 자세히 알아봅시다.\n\n머신 러닝 모델은 NER을 향상시키기 위해 발전해 왔습니다. 특히 딥러닝은 중대한 역할을 하였습니다. 이는 데이터의 복잡한 패턴을 이해하기 위해 신경망을 활용합니다.\n\n하나의 모델은 Long Short-Term Memory (LSTM) 네트워크입니다. 이는 텍스트 내의 문장과 같은 시퀀스를 처리하는 데 뛰어납니다. 아래는 간단화된 Python 예시입니다:\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\n\nmodel = Sequential()\nmodel.add(LSTM(50, return_sequences=True, input_shape=(...)))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(...)\n```\n\n다른 고급 기술로는 전이 학습(Transfer Learning)이 있습니다. 미리 훈련된 모델을 활용하여 시간과 자원을 절약할 수 있습니다. BERT와 GPT와 같은 모델이 인기가 있습니다.\n\n마지막으로, 어텐션 메커니즘(Attention Mechanisms)은 모델 성능을 향상시켰습니다. 이를 통해 모델이 텍스트의 관련 부분에 집중할 수 있습니다. 이는 정확한 Entity Recognition에 중요합니다.\n\n이러한 발전으로 NER이 더욱 효율적이고 정확해졌습니다. 이것들은 비구조적인 방대한 양의 텍스트로부터 가치 있는 통찰을 추출하는 데 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n## 3. 다양한 산업 분야에서 NER의 실용적 응용\n\nNamed Entity Recognition (NER)은 구조화되지 않은 텍스트를 구조화된 데이터로 변환하는 데 중요합니다. 이 프로세스는 의미 있는 정보를 추출하는 데 다양한 산업에서 필수적입니다. 다음은 일부 실용적인 응용 분야입니다:\n\n- **의료 분야**: NER은 임상 노트에서 환자 정보를 추출하는 데 도움을 줍니다. 의학 용어, 약물명 및 용량을 식별하여 환자 치료와 연구에 도움이 됩니다.\n\n- **금융 분야**: 금융 부문은 NER을 사용하여 경제 보고서를 모니터링합니다. 회사명, 주식 심볼 및 재무 지표를 추출하여 시장 분석에 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n미디어와 저널리즘 분야에서 NER은 뉴스 기사에서 사람, 조직 및 위치와 같은 엔티티를 추적합니다. 이는 콘텐츠 분류와 트렌드 분석을 지원합니다.\n\n소매 회사들은 NER을 고객 피드백에 적용합니다. 제품 이름 및 속성을 식별하여 재고 관리와 마케팅 전략에 도움이 됩니다.\n\n법률 전문가들에게 NER은 법적 문서에서 관련 엔티티를 추출합니다. 관련 당사자, 법적 용어 및 사건 세부 정보를 식별하여 사건 분석을 간소화합니다.\n\n정보 추출에서 NER의 역할은 산업 전반에 걸쳐 꼭 필요합니다. 이는 기업이 데이터 기반 의사결정을 내리고 경쟁력 있는 통찰력을 얻는 데 도움이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 NER을 사용하는 간단한 파이썬 예제입니다:\n\n```js\nimport spacy\nnlp = spacy.load('en_core_web_sm')\ntext = \"Apple is looking at buying U.K. startup for $1 billion\"\ndoc = nlp(text)\nfor ent in doc.ents:\n    print(ent.text, ent.label_)\n```\n\n이 코드 스니펫은 spaCy 라이브러리를 사용하여 주어진 텍스트에서 엔티티를 식별합니다. 이것은 NLP에서 NER의 강력함을 간략하게 보여줍니다.\n\n## 4. NER의 구성 요소: 도구와 프레임워크\n\n<div class=\"content-ad\"></div>\n\nNamed Entity Recognition (NER)은 비구조화된 텍스트에서 정보를 추출하는 데 중요합니다. 이는 이름, 위치, 조직과 같은 엔티티를 식별합니다. NER을 구현하기 위해 다양한 도구와 프레임워크가 있습니다.\n\n인기 있는 Python 라이브러리 중 하나는 spaCy입니다. 이는 NER을 위한 사전 훈련된 모델을 제공하며 대규모 정보 추출에 효율적입니다. 아래는 spaCy를 사용한 기본적인 코드 조각입니다:\n\n```python\nimport spacy\nnlp = spacy.load('en_core_web_sm')\ntext = \"Google was founded by Larry Page and Sergey Brin.\"\ndoc = nlp(text)\nentities = [(ent.text, ent.label_) for ent in doc.ents]\nprint(entities)\n```\n\n이 코드는 사전 훈련된 영어 모델을 로드하고 주어진 텍스트를 처리하여 인식된 엔티티를 출력합니다.\n\n<div class=\"content-ad\"></div>\n\n다른 프레임워크로는 교육 목적과 프로토타이핑에 적합한 NLTK가 있습니다. NER에 대한 간단한 접근 방법을 제공하지만 최적의 성능을 얻으려면 수동으로 세밀한 조정이 필요합니다.\n\n더 고급화된 사용을 위해 BERT와 GPT와 같은 트랜스포머 기반 모델을 사용할 수 있습니다. 이러한 모델은 NER 작업에서 최첨단의 정확도를 제공합니다.\n\n적절한 도구를 선택하는 것은 프로젝트의 요구 사항에 따라 다릅니다. 언어 지원, 정확성 및 컴퓨팅 리소스 등을 고려해야 합니다.\n\n## 5. NER 시스템 평가: 메트릭 및 기준\n\n<div class=\"content-ad\"></div>\n\n개별 이름 인식(NER) 시스템을 평가하는 것은 그 효과를 이해하는 데 중요합니다. 다음은 그들을 평가하는 방법입니다:\n\n정밀도는 NER 시스템에서 정확하게 식별된 개체의 백분율을 측정합니다. 높은 정밀도는 거짓 양성이 적다는 것을 의미합니다.\n\n```js\n# 정밀도 계산\ntrue_positives = 100\nfalse_positives = 10\nprecision = true_positives / (true_positives + false_positives)\nprint(f\"정밀도: {precision:.2f}\")\n```\n\n회수율은 실제 개체 중 올바르게 식별된 개체의 백분율을 나타냅니다. 모든 관련 개체를 찾는 시스템의 능력을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 재현율 계산\ntrue_positives = 100\nfalse_negatives = 20\nrecall = true_positives / (true_positives + false_negatives)\nprint(f\"재현율: {recall:.2f}\")\n```\n\nF1-Score는 정밀도와 재현율을 하나의 지표로 결합한 값입니다. 이는 정밀도와 재현율의 조화 평균값입니다.\n\n```js\n# F1-Score 계산\nprecision = 0.83\nrecall = 0.77\nf1_score = 2 * (precision * recall) / (precision + recall)\nprint(f\"F1-Score: {f1_score:.2f}\")\n```\n\n이러한 지표들은 서로 다른 NER 시스템을 비교하고 정보 추출의 개선을 추적하는 데 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 6. 개체명 인식(NER)에서의 도전 극복하기\n\n개체명 인식(NER)은 자연어 처리(NLP)의 정보 추출에서 중요한 구성 요소입니다. 그러나 NER은 몇 가지 도전에 직면합니다. 여기에 이를 극복할 수 있는 방법이 있습니다:\n\n1. 텍스트의 모호성: 맥락적 단서가 중요합니다. 주변 텍스트를 고려하는 알고리즘을 사용하여 올바른 개체를 결정합니다.\n\n```js\n# 예시: spaCy를 활용한 맥락적 NER\nimport spacy\nnlp = spacy.load('en_core_web_sm')\ndoc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\nfor ent in doc.ents:\n    print(ent.text, ent.label_)\n```\n\n<div class=\"content-ad\"></div>\n\n2. Entity Variations: Entity는 여러 형태를 가질 수 있습니다. 모든 변형을 인식하는 시스템을 구현하는 것이 중요합니다.\n\n3. 데이터 희소성: 모든 엔티티가 흔하지는 않습니다. 희귀 엔티티를 인식하기 위해 가짜 예제와 함께 데이터셋을 보강하세요.\n\n4. Cross-domain 적응력: 한 도메인에서 훈련된 모델이 다른 도메인에서 잘 동작하지 않을 수 있습니다. 새로운 도메인에 모델을 적응시키기 위해 전이 학습을 사용하세요.\n\n이러한 문제에 대처하여 Named Entity Recognition 시스템이 더 견고하고 정확해질 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 7. NER의 미래: 트렌드와 예측\n\nNamed Entity Recognition (NER) 분야는 빠르게 발전하고 있으며, 앞으로의 새로운 발전이 예상됩니다. 아래는 예상되는 트렌드입니다:\n\n딥 러닝 통합: NER 시스템은 점점 더 딥 러닝 모델을 활용하며, 엔티티 감지의 정확도를 향상시킬 것입니다.\n\n```python\n# NER용 딥 러닝 모델 예시\nfrom transformers import AutoModelForTokenClassification, AutoTokenizer\nmodel = AutoModelForTokenClassification.from_pretrained('bert-base-ner')\ntokenizer = AutoTokenizer.from_pretrained('bert-base-ner')\n```\n\n<div class=\"content-ad\"></div>\n\n새로운 언어로의 확장: NER 기술은 더 많은 언어를 지원하기 위해 확대되어, 전 세계적으로 더 접근성이 좋아질 것입니다.\n\n실시간 처리: 미래의 NER 시스템은 정보를 실시간으로 처리하여 다양한 소스에서 즉각적인 데이터 추출이 가능해질 것입니다.\n\n향상된 맥락 이해: 맥락 분석의 발전으로 복잡한 텍스트에서도 더 세밀한 개체 인식이 가능해질 것입니다.\n\n이러한 추세들은 NLP에서 정보 추출에 밝은 미래를 암시하며, 더 정교하고 다재다능한 NER 시스템을 약속하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n다음은 완전한 튜토리얼 목록입니다:\n\n무료 튜토리얼 및 정신 건강 스타트업 지원.\n\n파이썬, 머신러닝, 딥러닝 및 LLMs 마스터: E-북 50% 할인 (쿠폰: RP5JT1RL08)","ogImage":{"url":"/assets/img/2024-06-19-NamedEntityRecognitioninNLPExtractingInformationfromTextPart7_0.png"},"coverImage":"/assets/img/2024-06-19-NamedEntityRecognitioninNLPExtractingInformationfromTextPart7_0.png","tag":["Tech"],"readingTime":9},{"title":"BERT 마스터하기 자연어 처리NLP 초보부터 고급까지의 포괄적 가이드","description":"","date":"2024-06-19 20:42","slug":"2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP","content":"\n\n<img src=\"/assets/img/2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP_0.png\" />\n\n# 소개:\n\nBERT (Bidirectional Encoder Representations from Transformers)는 구글이 개발한 혁명적인 자연어 처리(NLP) 모델입니다. 이 모델은 언어 이해 작업의 환경을 변화시켜 기계가 언어의 맥락과 뉘앙스를 이해할 수 있게 하였습니다. 이 블로그에서는 BERT의 기본부터 고급 개념까지 설명, 예제 및 코드 스니펫과 함께 여러분을 안내할 것입니다.\n\n# 목차\n\n<div class=\"content-ad\"></div>\n\n- BERT 소개\n\n- BERT란 무엇인가요?\n- BERT의 중요성은 무엇인가요?\n- BERT는 어떻게 작동하나요?\n\n2. BERT를 위한 텍스트 전처리\n\n- 토큰화(Tokenization)\n- 입력 형식 지정(Input Formatting)\n- 가리고(LMasked) 언어 모델 (MLM) 목표\n\n<div class=\"content-ad\"></div>\n\n3. 특정 작업을 위한 BERT 파인 튜닝\n\n- BERT의 아키텍처 변형(BERT-base, BERT-large 등)\n- NLP에서의 전이 학습\n- 하류 작업 및 파인 튜닝\n- 예시: BERT를 사용한 텍스트 분류\n\n4. BERT의 어텐션 메커니즘\n\n- Self-Attention\n- Multi-Head Attention\n- BERT에서의 어텐션\n- 어텐션 가중치 시각화\n\n<div class=\"content-ad\"></div>\n\n5. BERT의 학습 과정\n\n- 사전 훈련 단계\n- 가리고 있는 언어 모델 (MLM) 목적\n- 다음 문장 예측 (NSP) 목적\n\n6. BERT 임베딩\n\n- 단어 임베딩 대 컨텍스트 임베딩\n- WordPiece 토큰화\n- 위치 인코딩\n\n<div class=\"content-ad\"></div>\n\n7. BERT의 고급 기술들\n\n- 파인 튜닝 전략\n- 어휘 외 단어 처리\n- BERT로의 도메인 적응\n- BERT로부터의 지식 증류\n\n8. 최근 개발 및 변형\n\n- RoBERTa (더 강력한 기준선)\n- ALBERT (라이트 BERT)\n- DistilBERT (콤팩트한 버전)\n- ELECTRA (효율적인 인코더 학습)\n\n<div class=\"content-ad\"></div>\n\n9. 시퀀스 대 시퀀스 작업을 위한 BERT\n\n- 텍스트 요약을 위한 BERT\n- 언어 번역을 위한 BERT\n- 대화형 인공지능을 위한 BERT\n\n10. 공통적인 도전 과제 및 완화 방안\n\n- BERT의 계산 요구사항\n- 긴 시퀀스 처리\n- BERT 내 편견 극복\n\n<div class=\"content-ad\"></div>\n\n11. BERT와 함께하는 자연어 처리의 미래 방향\n\n- OpenAI의 GPT 모델\n- 사전 훈련된 언어 모델에서의 BERT 역할\n- BERT 응용 프로그램에서의 윤리적 고려 사항\n\n12. Hugging Face Transformers 라이브러리로 BERT 구현하기\n\n- Transformers 설치하기\n- 사전 훈련된 BERT 모델 불러오기\n- 토큰화 및 입력 형식 지정\n- 사용자 정의 작업을 위한 BERT 파인튜닝\n\n<div class=\"content-ad\"></div>\n\n# 제1장: BERT 소개\n\n# BERT란 무엇인가요?\n\n자연어 처리(NLP)의 끊임없이 진화하는 세계에서, BERT라는 혁신적인 기술이 등장하여 게임 체인저로 인정받고 있습니다. BERT는 Transformer의 양방향 인코더 표현(Bidirectional Encoder Representations from Transformers)을 의미하며, 기계 학습 용어의 다양한 약어들 속에서 또 다른 약어가 아닙니다. 이는 기계가 언어를 이해하는 방식을 변화시키며, 인간들이 소통을 풍부하고 의미 있게 만드는 복잡한 뉘앙스와 맥락적 종속성을 이해할 수 있게 합니다.\n\n# BERT는 왜 중요한가요?\n\n<div class=\"content-ad\"></div>\n\n한 문장을 상상해보세요: \"그녀는 바이올린을 아름답게 연주합니다.\" 기존 언어 모델은 이 문장을 왼쪽에서 오른쪽으로 처리하여 악기(\"바이올린\")의 정체성이 전체 문장의 해석에 영향을 미친다는 중요한 사실을 놓치게 됩니다. 그러나 BERT는 단어 사이의 문맥 주도적 관계가 의미 파악에 중요한 역할을 한다는 사실을 이해합니다. BERT는 각 단어 주변의 완전한 문맥을 고려할 수 있도록 양방향성의 본질을 포착해, 언어 이해의 정확도와 심도를 혁신적으로 개선합니다.\n\n# BERT는 어떻게 작동하나요?\n\nBERT의 핵심은 Transformers라는 강력한 신경망 구조에 의해 제공됩니다. 이 구조는 셀프 어텐션(self-attention) 메커니즘을 포함하는데, 이를 통해 BERT는 각 단어의 중요성을 문맥에 따라 가중치를 부여할 수 있습니다. 선행 및 후행 단어를 모두 고려하는 이 문맥 인식은 BERT에 문장 내 단어의 의미를 고려한 단어 임베딩을 생성할 수 있는 능력을 제공합니다. 이는 BERT가 문장을 여러 차례 읽어 단어 역할에 대한 깊은 이해를 얻는 것과 비슷합니다.\n\n문장을 고려해보세요: \"‘리드’ 가수가 밴드를 이끌 것입니다.\" 기존 모델은 \"리드\"라는 단어의 모호성에 어려움을 겪을 수 있지만, BERT는 첫 번째 \"리드\"가 명사이고 두 번째가 동사임을 손쉽게 구분하여 언어 구조를 명확히 하는 능력을 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n다가올 장에서 BERT를 해부하며, 여러분을 기초 개념에서부터 고급 응용까지 안내할 여정이 시작됩니다. BERT가 다양한 NLP 작업에 활용되는 방법을 살펴보고, BERT의 attention 메커니즘에 대해 배우고, 그 교육 과정에 관심을 두며, NLP 분야를 혁신하는 데 BERT가 미치는 영향을 직접 목격하게 될 것입니다.\n\nBERT의 세부 사항에 대해 탐구할수록, 여러분은 BERT가 모델에 그치는 것이 아니라 기계가 인간 언어의 본질을 이해하는 방식을 패러다임이 변경된 것임을 알게 될 것입니다. 그러므로, 우리는 언어 이해가 보통을 벗어나 특별한 수준으로 도약하는 BERT 세계로의 흥미로운 여행을 함께 떠날 준비를 해봅시다.\n\n# 제2장: BERT를 위한 텍스트 전처리\n\n![이미지](/assets/img/2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP_1.png)\n\n<div class=\"content-ad\"></div>\n\nBERT가 텍스트에 마법을 부리기 전에, 이를 이해할 수 있는 방식으로 준비하고 구조화해야 합니다. 이 장에서는 BERT를 위한 텍스트 전처리의 중요한 단계들을 살펴보겠습니다. 이에는 토큰화, 입력 형식 지정, 그리고 마스크된 언어 모델 (MLM) 목표가 포함됩니다.\n\n# 토큰화: 의미 있는 조각으로 텍스트 나누기\n\nBERT에게 책을 읽는 방법을 가르친다고 상상해보세요. 전체 책을 한꺼번에 주지 않을 것이며, 문장과 단락으로 나눌 것입니다. 마찬가지로, BERT는 텍스트를 토큰이라 불리는 작은 단위로 나눠야 합니다. 그러나 여기서 중요한 점은, BERT는 WordPiece 토큰화를 사용한다는 것입니다. 이 방식은 단어를 더 작은 조각으로 분리하여 \"running\"을 \"run\"과 \"ning\"으로 나눕니다. 이는 어려운 단어를 처리하고, BERT가 생소한 단어에 어려움을 겪지 않도록 도와줍니다.\n\n예시: 원본 텍스트: “ChatGPT is fascinating.” WordPiece 토큰: [“Chat”, “##G”, “##PT”, “is”, “fascinating”, “.”]\n\n<div class=\"content-ad\"></div>\n\n# 입력 포맷: BERT에게 문맥 제공하기\n\nBERT는 문맥을 좋아해요. 우리는 그에게 문맥을 제공해야 해요. 그를 위해 BERT가 이해하는 방식으로 토큰을 포맷합니다. 우리는 [CLS] (분류를 나타냄)와 같은 특수 토큰을 문장 사이에 놓습니다. 그림 (기계 언어 모델)에 나타난 것처럼요. 우리는 또한 문장에 속하는 토큰을 알려주는 세그먼트 임베딩을 할당해요.\n\n예시: 원본 텍스트: “ChatGPT is fascinating.” 포맷팅된 토큰: [“[CLS]”, “Chat”, “##G”, “##PT”, “is”, “fascinating”, “.”, “[SEP]”]\n\n# 가려진 언어 모델 (MLM) 목표: BERT에게 문맥 가르치기\n\n<div class=\"content-ad\"></div>\n\nBERT의 비밀 무기는 양방향 문맥을 이해하는 능력에 있습니다. 학습 중에는 일부 단어가 마스크 처리되어 문장 내에서 [MASK]로 대체되며, BERT는 이를 context에 따라 예측하는 방법을 학습합니다. 이는 BERT가 단어들이 서로 어떻게 관련되는지 알아내는 데 도움이 됩니다. 아래 그림에서 확인할 수 있듯이 (Machine Language Model)\n\n예시: 원본 문장: “The cat is on the mat.” 마스크 처리된 문장: “The [MASK] is on the mat.”\n\n코드 스니펫: Hugging Face Transformers로 토큰화\n\n```python\nfrom transformers import BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntext = \"BERT preprocessing is essential.\"\ntokens = tokenizer.tokenize(text)\n\nprint(tokens)\n```\n\n<div class=\"content-ad\"></div>\n\n이 코드는 Hugging Face Transformers 라이브러리를 사용하여 BERT 토크나이저를 통해 텍스트를 토큰화합니다.\n\n다음 장에서는 BERT를 특정 작업에 대해 세밀하게 조정하는 흥미로운 세계에 대해 탐구하고, 그 주의 메커니즘이 언어 이해 챔피언으로 만드는 방식을 알아보겠습니다. 더 많은 정보 습득을 위해 망설이지 마세요!\n\n# 3장: 특정 작업에 대한 BERT 세밀 조정\n\n![이미지](/assets/img/2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP_2.png)\n\n<div class=\"content-ad\"></div>\n\nBERT가 어떻게 작동하는지 이해한 후에는 이제 그 마법을 실용적으로 활용해 보는 시간입니다. 이 장에서는 BERT를 특정 언어 작업에 대해 세밀하게 조정하는 방법을 살펴볼 것입니다. 이는 사전 훈련된 BERT 모델을 텍스트 분류와 같은 작업을 수행할 수 있도록 조정하는 것을 포함합니다. 함께 알아보겠습니다!\n\n# BERT의 아키텍처 변형: 적합한 모델 선택\n\nBERT는 BERT-base, BERT-large 등과 같이 다양한 플레이버로 나옵니다. 다양한 모델 크기와 복잡성을 가지고 있습니다. 선택은 작업의 요구 사항과 가지고 있는 자원에 따라 다릅니다. 더 큰 모델은 성능이 더 좋을 수 있지만 더 많은 컴퓨팅 성능이 필요합니다.\n\n# NLP의 전이 학습: 사전 학습된 지식을 기반으로 빌드하기\n\n<div class=\"content-ad\"></div>\n\n버트를 언어 전문가로 상상해보세요. 이미 많은 텍스트를 읽고 이해한 전문가입니다. 처음부터 모든 것을 가르치는 대신에, 특정 작업에 맞게 세부 조정을 거쳐 학습시킵니다. 이것이 전이 학습의 마법입니다 — 버트의 기존 지식을 활용하고 특정 작업에 맞게 맞춤화하는 것입니다. 이는 많은 것을 알고 있는 가르침을 받는 과외 선생님과 비슷합니다.\n\n# 하류 작업 및 세부 조정: 버트의 지식 적용하기\n\n우리가 버트를 세부 조정하는 작업을 \"하류 작업\"이라고 합니다. 감정 분석, 개체명 인식 등의 예시가 포함됩니다. 세부 조정은 작업별 데이터를 사용하여 버트의 가중치를 업데이트하는 것을 포함합니다. 이를 통해 버트를 처음부터 학습시키지 않고도 이러한 작업에 특화되도록 도와줍니다.\n\n예시: 버트를 활용한 텍스트 분류\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom transformers import BertForSequenceClassification, BertTokenizer\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n\ntext = \"This movie was amazing!\"\ninputs = tokenizer(text, return_tensors='pt')\noutputs = model(**inputs)\npredictions = torch.argmax(outputs.logits, dim=1)\nprint(predictions)\n```\n\n이 코드는 Hugging Face Transformers를 사용하여 텍스트 분류를 위한 사전 훈련된 BERT 모델을 사용하는 것을 보여줍니다.\n\n이 스니펫에서는 텍스트 분류를 위해 설계된 사전 훈련된 BERT 모델을 로드합니다. 입력 텍스트를 토큰화하고 모델을 통해 전달하여 예측을 얻습니다.\n\n특정 작업에 대한 BERT의 세부 튜닝은 실제 응용 프로그램에서 빛을 발할 수 있습니다. 다음 장에서는 BERT의 문맥 이해에 중요한 주의 메커니즘을 해독할 것이며 더 많은 정보를 발견하려면 계속 주목해주세요!\n\n\n<div class=\"content-ad\"></div>\n\n# 제4장: BERT의 어텐션 메커니즘\n\n![BERT](/assets/img/2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP_3.png)\n\n이제 BERT를 작업에 적용하는 방법을 살펴 보았으니, BERT를 강력하게 만드는 요소인 어텐션 메커니즘에 대해 더 자세히 살펴보겠습니다. 이 장에서는 셀프 어텐션, 멀티헤드 어텐션, 그리고 BERT의 어텐션 메커니즘이 언어의 맥락을 파악할 수 있도록 하는 방법을 알아보겠습니다.\n\n# 셀프 어텐션: BERT의 슈퍼파워\n\n<div class=\"content-ad\"></div>\n\n책을 읽고 중요하다고 생각되는 단어를 강조해본 적이 있나요? Self-attention은 그것과 비슷한데요, BERT를 위한 것입니다. Self-attention은 문장의 각 단어를 살펴보고, 중요성에 따라 다른 단어에 얼마나 주의를 기울여야 하는지 결정합니다. 이를 통해 BERT는 문장 속에서 멀리 떨어져 있어도 관련된 단어에 집중할 수 있어요.\n\n# Multi-Head Attention: 팀워크의 비밀\n\nBERT는 하나의 관점에만 의존하지 않고, 여러 “헤드”의 주의를 사용합니다. 이 헤드들은 문장의 다양한 측면에 초점을 맞춘 다양한 전문가로 생각할 수 있어요. 이 다중 헤드 접근법은 BERT가 단어 간의 다양한 관계를 포착하여 이해를 더욱 풍부하고 정확하게 만들어줍니다.\n\n# BERT 안의 Attention: 문맥적인 매력\n\n<div class=\"content-ad\"></div>\n\nBERT의 주의는 단어 앞이나 뒤로만 제한되지 않아요. 양방향을 모두 고려해요! BERT가 단어를 읽을 때, 혼자가 아니에요; 이웃들을 알아차려요. 이러한 방식으로, BERT는 단어의 전체 맥락을 고려한 임베딩을 생성해요. 이는 글의 전체적인 맥락을 이해하는 것과 같아요. 그게 바로 설치뿐만 아니라 문장 전체를 고려해서 웃음 소리를 이해하는 것과 같아요.\n\n코드 조각: 주의 차중 시각화\n\n```js\nimport torch\nfrom transformers import BertModel, BertTokenizer\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\ntext = \"BERT의 주의 메커니즘은 매혹적입니다.\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\noutputs = model(**inputs, output_attentions=True)\n\nattention_weights = outputs.attentions\nprint(attention_weights)\n```\n\n이 코드에서는 Hugging Face Transformers를 사용하여 BERT의 주의 가중치를 시각화합니다. 이 가중치는 BERT가 문장에서 다른 단어들에 얼마나 주의를 기울이는지를 보여줘요.\n\n<div class=\"content-ad\"></div>\n\nBERT의 주의 메커니즘은 마치 주목할 가치 있는 부분에 초점을 맞춰주는 형광등처럼 작동합니다. 다음 장에서는 BERT의 훈련 과정과 어떻게 언어 마에스트로가 되는지 알아볼 것입니다. 더 많은 통찰력을 기대해주세요!\n\n# 제 5장: BERT의 훈련 과정\n\nBERT가 어떻게 학습하는지를 이해하는 것은 그 능력을 평가하는 데 중요합니다. 이 장에서는 BERT의 훈련 과정의 복잡성을 파헤치며, 사전 훈련 단계, 가려진 언어 모델 (MLM) 목표, 다음 문장 예측 (NSP) 목표를 살펴볼 것입니다.\n\n# 사전 훈련 단계: 지식의 기초\n\n<div class=\"content-ad\"></div>\n\nBERT의 여정은 사전 훈련으로 시작됩니다. 여기서 BERT는 엄청난 양의 텍스트 데이터에서 학습합니다. BERT에게 수백만 개의 문장을 보여주고 빠진 단어를 예측하게 합니다. 이 연습은 BERT가 언어 패턴과 관계를 탄탄히 구축하는 데 도움이 됩니다.\n\n# 가리거나 문장 모델 (MLM) 목표: 빈칸 채우기 게임\n\n사전 훈련 중에 BERT는 일부 단어가 가려진 문장을 제공받습니다. 그러면 주변 맥락을 기반으로 이를 예측하려고 합니다. 이는 빈칸을 채우는 게임의 언어 버전과 같습니다. 빈칸을 추측함으로써 BERT는 단어 간의 관련성을 학습하고 맥락을 통해 빛을 발합니다.\n\n# 문장 다음 예측 (NSP) 목표: 문장 흐름 파악\n\n<div class=\"content-ad\"></div>\n\nBERT는 단어를 이해하는 것뿐만 아니라 문장의 흐름을 파악합니다. NSP 목표에서 BERT는 텍스트 쌍에서 한 문장이 다른 문장을 따르는지 예측하도록 훈련됩니다. 이를 통해 BERT는 문장 사이의 논리적 연결을 이해하며, 이를 통해 문단 및 더 긴 텍스트를 이해하는 데 능숙해집니다.\n\n예: 사전 훈련 및 MLM\n\n```python\nfrom transformers import BertForMaskedLM, BertTokenizer\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForMaskedLM.from_pretrained('bert-base-uncased')\n\ntext = \"BERT is a powerful language model.\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, add_special_tokens=True)\noutputs = model(**inputs, labels=inputs['input_ids'])\n\nloss = outputs.loss\nprint(loss)\n```\n\n이 코드는 BERT의 마스크 언어 모델 (MLM) 사전 훈련을 보여줍니다. 모델은 마스킹된 단어를 예측하면서 예측 오류를 최소화하도록 훈련됩니다.\n\n<div class=\"content-ad\"></div>\n\nBERT의 교육 과정은 언어 규칙을 학습시키는 것과 관련된 문장 내용을 이해하는 연습의 조합을 통해 진행됩니다. 다음 장에서는 BERT의 임베딩에 대해 자세히 알아볼 것이며, 이 임베딩이 언어 능력에 어떻게 기여하는지 알아볼 것입니다. 계속 학습해 주세요!\n\n# 제 6장: BERT 임베딩\n\n![이미지](/assets/img/2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP_4.png)\n\nBERT의 강점은 단어를 특정 컨텍스트 내에서 의미를 포착하는 방식으로 표현할 수 있는 능력에 있습니다. 이 장에서는 BERT의 임베딩, 콘텍스트 단어 임베딩, WordPiece 토큰화 및 위치 인코딩을 다룰 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 단어 임베딩 vs. 문맥 단어 임베딩\n\n단어 임베딩은 코드 단어로 각 단어를 대체하는 것으로 생각해보세요. BERT는 문맥 단어 임베딩으로 더 나아가요. 각 단어에 대해 하나의 코드 단어가 아니라 문장에서의 문맥에 따라 다른 임베딩을 만듭니다. 이렇게 하면 각 단어의 표현이 더 세밀해지고 주변 단어에 의해 영향을 받습니다.\n\n# WordPiece 토큰화: 복잡한 어휘 처리\n\nBERT의 어휘는 하위 단어라고 불리는 작은 조각으로 구성된 퍼즐과 같아요. WordPiece 토큰화를 사용하여 단어를 이러한 하위 단어로 분해합니다. 이는 긴 단어와 복잡한 단어를 처리하거나 이전에 본 적이 없는 단어를 다루는 데 특히 유용합니다.\n\n<div class=\"content-ad\"></div>\n\n# 위치 부호화: 문장 구조 탐색\n\nBERT는 단어를 양방향으로 읽기 때문에 문장에서 각 단어의 위치를 알아야 합니다. 위치 부호화는 BERT에게 이러한 공간 인식을 제공하기 위해 임베딩에 추가됩니다. 이를 통해 BERT는 단어의 의미뿐만 아니라 문장에서의 위치도 파악할 수 있습니다.\n\n코드 스니펫: Hugging Face Transformers를 사용하여 단어 임베딩 추출\n\n```js\nfrom transformers import BertTokenizer, BertModel\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\ntext = \"BERT embeddings are fascinating.\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, add_special_tokens=True)\noutputs = model(**inputs)\n\nword_embeddings = outputs.last_hidden_state\nprint(word_embeddings)\n```\n\n<div class=\"content-ad\"></div>\n\n이 코드는 Hugging Face Transformers를 사용하여 단어 임베딩을 추출하는 방법을 보여줍니다. 이 모델은 입력 텍스트의 각 단어에 대해 문맥 임베딩을 생성합니다.\n\nBERT의 임베딩은 단어가 고유한 문맥 기반 신원을 얻는 언어 놀이터와 같습니다. 다음 장에서는 BERT를 세밀하게 조정하고 다양한 작업에 적응시키는 고급 기술을 탐색할 것입니다. 계속해서 배우고 실험해보세요!\n\n# 제7장: BERT의 고급 기술\n\nBERT를 능숙하게 사용하기 시작했다면, 이제 그 잠재력을 극대화하는 고급 기술을 탐색할 때입니다. 이 장에서는 세밀한 조정, 단어 사전에 없는 단어 처리, 도메인 적응, 심지어 BERT로부터 지식 증류를 다루는 전략에 대해 탐구할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 세밀 조정 전략: 적응 능력 향상\n\nBERT의 세밀 조정에는 신중한 고려가 필요합니다. 단순히 마지막 분류 레이어뿐만 아니라 중간 레이어도 세밀 조정할 수 있습니다. 이를 통해 BERT가 특정 작업에 더 효과적으로 적응할 수 있습니다. 다양한 레이어와 학습 속도를 실험하여 최적의 조합을 찾아보세요.\n\n# OOV(Out-of-Vocabulary) 단어 처리: 알 수 없는 것 다루기\n\nBERT의 어휘는 무한하지 않기 때문에 인식하지 못할 수 있는 단어를 마주할 수 있습니다. OOV 단어를 처리할 때 WordPiece 토큰화를 사용하여 부분 단어로 분할할 수 있습니다. 또는 알 수 없는 단어를 “[UNK]”와 같은 특별한 토큰으로 대체할 수도 있습니다. OOV 전략을 균형있게 유지하는 것은 연습을 통해 개선되는 기술입니다.\n\n<div class=\"content-ad\"></div>\n\n# BERT를 활용한 도메인 적응: BERT를 내 것으로 만들기\n\nBERT는 강력하지만 모든 도메인에서 최적으로 동작하지는 않을 수 있습니다. 도메인 적응은 도메인 특화 데이터로 BERT를 세밀하게 조정하는 것을 의미합니다. BERT에 도메인 특화 텍스트를 노출시킴으로써, 해당 도메인의 고유한 언어 패턴을 이해하도록 학습합니다. 이는 특정 작업에 대한 성능을 크게 향상시킬 수 있습니다.\n\n# BERT로부터의 지식 증류: 지혜 전달하기\n\n지식 증류는 작은 모델(학생)을 더 큰 사전 훈련된 모델(BERT와 같은 선생님)의 동작을 모방하도록 훈련하는 과정을 의미합니다. 이 압축된 모델은 선생님의 예측 뿐만 아니라 신뢰도와 추론 능력도 학습합니다. 이 접근 방식은 자원이 제한된 기기에 BERT를 배포할 때 특히 유용합니다.\n\n<div class=\"content-ad\"></div>\n\n코드 스니펫: Hugging Face Transformers를 사용하여 중간 레이어 Featurie Fine-Tuning\n\n```js\nfrom transformers import BertForSequenceClassification, BertTokenizer\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n\ntext = \"Advanced fine-tuning with BERT.\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\noutputs = model(**inputs, output_hidden_states=True)\n\nintermediate_layer = outputs.hidden_states[6]  # 7th layer\nprint(intermediate_layer)\n```\n\n이 코드는 Hugging Face Transformers를 사용하여 BERT의 중간 레이어를 세밀하게 조정하는 방법을 보여줍니다. 중간 레이어를 추출하면 BERT를 특정 작업에 더 효과적으로 세밀하게 조정할 수 있습니다.\n\n이러한 고급 기술을 탐험하면서 BERT의 적응성과 잠재력을 마스터하는 길을 걷게 될 것입니다. 다음 장에서는 NLP 분야를 더욱 더 높은 수준으로 끌어올린 BERT의 최근 개발 및 변형에 대해 알아보겠습니다. 호기심을 가지고 혁신을 이어가세요!\n\n<div class=\"content-ad\"></div>\n\n# 8장: 최근 개발 및 변형\n\n자연어 처리(NLP) 분야가 발전함에 따라 BERT도 발전하고 있습니다. 이 장에서는 BERT의 성능을 더욱 향상시킨 최근 개발 사항 및 변형인 RoBERTa, ALBERT, DistilBERT, ELECTRA 등을 살펴보겠습니다.\n\n## RoBERTa: BERT의 기본을 넘어서\n\nRoBERTa는 BERT의 똑똑한 형제입니다. 더 큰 배치, 더 많은 데이터, 그리고 더 많은 학습 단계를 포함한 보다 철저한 레시피로 훈련됩니다. 이 강화된 훈련 방법은 다양한 작업에서 더 나은 언어 이해 및 성능 향상을 이끌어냅니다.\n\n<div class=\"content-ad\"></div>\n\n# ALBERT: 가벼운 BERT\n\nALBERT은 \"A Lite BERT\"의 약자입니다. 효율적으로 설계된 ALBERT은 파라미터 공유 기술을 사용하여 메모리 소비를 줄입니다. 크기는 작지만 BERT의 성능을 유지하며 자원이 제한적인 경우에 유용합니다.\n\n# DistilBERT: 소형이지만 알짜\n\nDistilBERT는 BERT의 축약 버전입니다. BERT의 동작을 모방하도록 훈련되었지만 파라미터가 적습니다. 이로 인해 DistilBERT는 가볍고 빠르며 여전히 BERT의 성능을 상당 부분 유지합니다. 속도와 효율이 중요한 애플리케이션에 적합한 선택지입니다.\n\n<div class=\"content-ad\"></div>\n\n# ELECTRA: BERT로부터 효율적으로 학습하기\n\nELECTRA는 훈련에 흥미로운 변화를 가져왔어요. 가리킨 단어를 예측하는 대신, ELECTRA는 교체된 단어가 실제인지 인공적으로 생성된 것인지 감지하여 훈련합니다. 이 효율적인 방법으로 ELECTRA는 전체 계산 비용 없이도 대형 모델을 훈련시키는 유망한 방법으로 자리 잡았어요.\n\n코드 스니펫: Hugging Face Transformers와 함께 RoBERTa 사용하기\n\n```python\nfrom transformers import RobertaTokenizer, RobertaModel\nimport torch\n\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\nmodel = RobertaModel.from_pretrained('roberta-base')\n\ntext = \"RoBERTa는 BERT의 고급 변형입니다.\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\noutputs = model(**inputs)\n\nembeddings = outputs.last_hidden_state\nprint(embeddings)\n```\n\n<div class=\"content-ad\"></div>\n\nRoBERTa는 BERT의 변형 중 하나로, Hugging Face Transformers를 사용하여 문맥 임베딩을 생성하는 방법을 보여주는 코드입니다. \n\n이러한 최근의 발전과 변형은 BERT의 영향이 자연어 처리 분야에 파장을 일으키고, 새로운 강화된 모델들을 영감을 주고 있음을 보여줍니다. 다음 장에서는 BERT가 텍스트 요약 및 언어 번역과 같은 시퀀스-투-시퀀스 작업에 어떻게 활용될 수 있는지 살펴볼 것입니다. BERT의 더 흥미로운 응용 프로그램을 기대해 주세요!\n\n# 9장: 시퀀스-투-시퀀스 작업을 위한 BERT\n\n이 장에서는 개별 문장을 이해하기 위해 처음에 설계된 BERT가 텍스트 요약, 어어 번역과 같이 시퀀스-투-시퀀스 응용 프로그램과 같은 더 복잡한 작업에 적응되는 방법을 살펴볼 것입니다. 텍스트 요약, 언어 번역, 대화형 AI에서의 잠재력에 대해 탐구해 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# 텍스트 요약을 위한 BERT: 정보 압축\n\n텍스트 요약은 더 긴 텍스트의 본질을 유지한 채 더 짧은 버전으로 요약하는 작업을 말합니다. BERT는 이 작업을 위해 특별히 설계된 모델은 아니지만, 제공하는 문맥 이해력을 활용하여 원본 텍스트를 입력하고 간결한 요약을 생성할 수 있습니다.\n\n# 언어 번역을 위한 BERT: 언어 간의 연결 다리\n\n언어 번역은 한 언어에서 다른 언어로 텍스트를 변환하는 작업을 의미합니다. BERT는 직접적인 번역 모델은 아니지만, 문맥 임베딩을 통해 번역 모델의 품질을 향상시킬 수 있습니다. 단어의 문맥을 이해함으로써 BERT는 번역 중 원래 텍스트의 뉘앙스를 보존하는 데 도움을 줄 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 대화형 AI에서의 BERT: 대화 내용 이해하기\n\n대화형 AI는 개별 문장뿐만 아니라 대화 흐름도 이해해야 합니다. BERT의 양방향 컨텍스트는 여기에서 유용합니다. 이를 통해 문맥적으로 일관된 응답을 분석하고 생성할 수 있어 더 매력적인 챗봇과 가상 비서를 만드는 데 유용한 도구가 됩니다.\n\n코드 스니펫: 허깅페이스 트랜스포머를 활용한 BERT를 이용한 텍스트 요약\n\n```js\nfrom transformers import BertTokenizer, BertForSequenceClassification\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n\noriginal_text = \"텍스트 요약을 위한 긴 텍스트...\"\ninputs = tokenizer(original_text, return_tensors='pt', padding=True, truncation=True)\n\nsummary_logits = model(**inputs).logits\nsummary = tokenizer.decode(torch.argmax(summary_logits, dim=1))\nprint(\"요약:\", summary)\n```\n\n<div class=\"content-ad\"></div>\n\n이 코드는 Hugging Face Transformers를 사용하여 BERT를 텍스트 요약에 활용하는 방법을 보여줍니다. 이 모델은 입력 텍스트의 가장 관련성 높은 부분을 예측하여 요약을 생성합니다.\n\nBERT의 시퀀스-투-시퀀스 작업에서의 능력을 탐험하면, 원래 의도된 용도를 넘어 다양한 응용에 적응할 수 있음을 발견할 것입니다. 다음 장에서는 BERT 사용 시 일반적인 문제를 다루고 효과적으로 해결하는 방법을 살펴보겠습니다. BERT 기반 프로젝트에서 장애물을 극복하는 통찰을 기대해 주세요!\n\n# 장 10: 일반적인 문제와 완화 전략\n\nBERT가 강력하지만 도전 과제가 없는 것은 아닙니다. 이 장에서는 BERT 작업 시 마주할 수 있는 일반적인 문제들을 보다 심층적으로 다루고 극복 전략을 제시합니다. 긴 텍스트 처리부터 계산 자원 관리까지 다룰 주제가 다양하니 안심하세요.\n\n<div class=\"content-ad\"></div>\n\n# 도전 과제 1: 긴 텍스트 처리하기\n\nBERT는 입력에 대한 최대 토큰 제한이 있으며 긴 텍스트는 잘릴 수 있습니다. 이를 완화하기 위해 텍스트를 처리 가능한 조각으로 나누어 처리할 수 있습니다. 이때 이러한 조각 사이의 문맥을 신중하게 관리하여 의미 있는 결과를 보장해야 합니다.\n\n코드 스니펫: BERT로 긴 텍스트 다루기\n\n```js\nmax_seq_length = 512  # BERT의 최대 토큰 제한\ntext = \"다룰 긴 텍스트...\"\ntext_chunks = [text[i:i + max_seq_length] for i in range(0, len(text), max_seq_length)]\n\nfor chunk in text_chunks:\n    inputs = tokenizer(chunk, return_tensors='pt', padding=True, truncation=True)\n    outputs = model(**inputs)\n    # 각 조각에 대한 결과 처리\n```\n\n<div class=\"content-ad\"></div>\n\n# 도전 과제 2: 자원 집약적 연산\n\nBERT 모델은 특히 큰 모델인 경우 계산이 많이 필요할 수 있습니다. 이를 해결하기 위해 메모리 소비를 줄이고 훈련 속도를 높이는 mixed-precision 훈련과 같은 기술을 사용할 수 있습니다. 또한, 무거운 작업에 대해 작은 모델이나 클라우드 자원을 활용하는 것을 고려할 수 있습니다.\n\n코드 스니펫: BERT와 함께 Mixed-Precision 훈련\n\n```js\nfrom torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()\nwith autocast():\n    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n    outputs = model(**inputs)\n    loss = outputs.loss\n\nscaler.scale(loss).backward()\nscaler.step(optimizer)\nscaler.update()\n```\n\n<div class=\"content-ad\"></div>\n\n# 도전 과제 3: 도메인 적응\n\nBERT는 다재다능하지만 특정 도메인에서 최적으로 작동하지 않을 수 있습니다. 이를 해결하기 위해 도메인별 데이터로 BERT를 세밀하게 튜닝하세요. 대상 도메인의 텍스트를 노출함으로써 BERT는 해당 분야에 특정한 뉘앙스와 용어를 이해하도록 학습합니다.\n\n코드 스니펫: BERT를 활용한 도메인 적응\n\n```js\ndomain_data = load_domain_specific_data()  # 도메인별 데이터 로드\ndomain_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\ntrain_domain(domain_model, domain_data)\n```\n\n<div class=\"content-ad\"></div>\n\n이러한 도전을 극복하면 BERT의 능력을 효과적으로 활용할 수 있습니다. 만날 수 있는 복잡성과 상관없이요. 마지막 장에서는 여정을 되돌아보며 언어 모델의 미래 발전 가능성을 탐구할 것입니다. BERT로 어떤 것을 달성할 수 있는지 계속해서 경계를 넓혀 보세요!\n\n# 11장: BERT와 함께하는 자연어처리의 미래 방향\n\nBERT를 탐험한 것으로 마무리하면서, 앞으로 언어 모델이 나아갈 흥미로운 방향을 엿보고자 합니다. 다국어 이해부터 교차 언어 학습까지, NLP 풍경을 형성할 전망있는 트렌드들을 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\nBERT의 능력은 영어에만 국한되어 있지 않습니다. 연구자들은 다국어로 확장하고 있습니다. 다양한 언어로 BERT를 훈련시킴으로써, 다양한 언어로 텍스트를 이해하고 생성할 수 있는 능력을 향상시킬 수 있습니다.\n\n코드 스니펫: Hugging Face Transformers를 사용한 다국어 BERT\n\n```python\nfrom transformers import BertTokenizer, BertModel\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\nmodel = BertModel.from_pretrained('bert-base-multilingual-cased')\n\ntext = \"BERT는 여러 언어를 이해합니다!\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\noutputs = model(**inputs)\n\nembeddings = outputs.last_hidden_state\nprint(embeddings)\n```\n\n# 크로스-모달 학습: 텍스트를 넘어서\n\n<div class=\"content-ad\"></div>\n\nBERT의 문맥 이해 능력은 텍스트에만 국한되어 있지 않습니다. 최근 연구에서는 BERT를 이미지와 오디오와 같은 다른 데이터 형식에도 적용하는 방법을 탐구하고 있습니다. 이러한 교차 모달 학습은 다양한 소스에서 정보를 연결함으로써 보다 심층적인 통찰력을 제공할 수 있습니다.\n\n# 평생 학습: 변화에 적응하기\n\nBERT의 현재 학습은 정적 데이터셋을 기반으로 하지만, 미래의 NLP 모델은 언어 트렌드의 발전에 적응할 것으로 예상됩니다. 평생 학습 모델은 지속적으로 지식을 업데이트하여 언어와 맥락이 변화함에 따라 relevancy를 유지합니다.\n\n코드 스니펫: BERT를 활용한 평생 학습\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom transformers import BertForSequenceClassification, BertTokenizer\nimport torch\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n\nnew_data = load_latest_data()  # 최신 데이터 불러오기\nfor epoch in range(epochs):\n    train_lifelong(model, new_data)\n```\n\n# 챗봇의 양극화: 보다 인간다운 대화\n\nGPT-3와 같은 NLP 모델의 발전은 AI와 자연스러운 대화의 잠재력을 보여주고 있습니다. BERT가 맥락과 대화의 이해력을 향상시키면서 더 자연스러운 상호작용의 가능성이 열릴 것으로 기대됩니다.\n\nNLP의 미래는 혁신과 가능성으로 가득한 수채화입니다. 이러한 트렌드를 받아들이는 동안 BERT가 언어 이해의 기본 요철로 남아있어 기술 및 상호작용의 방식을 계속 형성할 것임을 기억하세요. 여러분의 호기심을 유지하고 앞으로 펼쳐질 분야를 탐험해 보세요!\n\n\n<div class=\"content-ad\"></div>\n\n# 제 12 장: Hugging Face Transformers 라이브러리를 사용하여 BERT 구현하기\n\n이제 BERT에 대한 탄탄한 이해를 얻었으니, 이 지식을 실제로 활용할 때입니다. 이 장에서는 Hugging Face Transformers 라이브러리를 사용하여 BERT 및 기타 트랜스포머 기반 모델을 다루는 강력한 도구 상자로 실제 구현에 대해 자세히 살펴보겠습니다.\n\n# Hugging Face Transformers 설치\n\n시작하려면, Hugging Face Transformers 라이브러리를 설치해야 합니다. 터미널이나 명령 프롬프트를 열고 다음 명령을 사용하십시오:\n\n<div class=\"content-ad\"></div>\n\n```js\npip install transformers\n```\n\n# 사전 학습된 BERT 모델 불러오기\n\nHugging Face Transformers를 사용하면 사전 학습된 BERT 모델을 쉽게 불러올 수 있습니다. 다양한 모델 크기와 구성 중에서 선택할 수 있습니다. 텍스트 분류를 위한 기본 BERT 모델을 불러와보겠습니다:\n\n```js\nfrom transformers import BertForSequenceClassification, BertTokenizer\n\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n```\n\n<div class=\"content-ad\"></div>\n\n# 텍스트 토크나이징 및 인코딩\n\nBERT는 텍스트를 토큰화된 형태로 처리합니다. 모델에 대한 입력으로 사용하려면 텍스트를 토크나이저를 사용하여 토큰화하고 인코딩해야 합니다:\n\n```js\ntext = \"BERT is amazing!\"\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n```\n\n# 예측하기\n\n<div class=\"content-ad\"></div>\n\n텍스트를 인코딩한 후에는 모델을 사용하여 예측할 수 있습니다. 예를 들어, 감성 분석을 수행해 봅시다:\n\n```js\noutputs = model(**inputs)\npredicted_class = torch.argmax(outputs.logits).item()\nprint(\"예측된 감성 클래스:\", predicted_class)\n```\n\n# BERT 파인튜닝\n\n특정 작업을 위해 BERT를 파인튜닝하는 과정은 미리 학습된 모델을 로드하고 작업에 맞추어 조정한 후 데이터셋에 대해 훈련하는 것을 포함합니다. 텍스트 분류를 위한 간단한 예제를 살펴보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom transformers import BertForSequenceClassification, BertTokenizer, AdamW\nimport torch\n\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\ntext = \"학습용 샘플 텍스트입니다.\"\nlabel = 1  # 긍정 감정으로 가정합니다.\n\ninputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\noutputs = model(**inputs, labels=torch.tensor([label]))\n\nloss = outputs.loss\noptimizer = AdamW(model.parameters(), lr=1e-5)\nloss.backward()\noptimizer.step()\n```\n\n# 더 많은 작업과 모델 탐구하기\n\nHugging Face Transformers 라이브러리는 다양한 모델과 작업을 탐색할 수 있는 기회를 제공합니다.\nBERT를 텍스트 분류, 개체 인식, 질문 응답 등으로 정교 조정할 수 있습니다.\n\nHugging Face Transformers 라이브러리를 사용해보면 BERT 및 기타 트랜스포머 기반 모델을 프로젝트에 구현하는 데 귀중한 도구라는 것을 알게 될 것입니다.\n이론을 실용적인 응용 프로그램으로 전환하는 여정을 즐기세요!\n\n<div class=\"content-ad\"></div>\n\n# 결론: BERT의 힘을 발휘해보세요\n\n이 블로그 글에서는 BERT(Bidirectional Encoder Representations from Transformers)의 변혁적인 세계를 탐험하는 여정을 시작했습니다. 공식적인 도입부터 실용적인 구현까지, 우리는 BERT가 자연어 처리(NLP)뿐만 아니라 더 나아가 미치는 영향의 풍경을 탐험해 왔습니다.\n\n실제 상황에서 BERT를 활용할 때 발생하는 도전에 대해 탐색하면서, 긴 텍스트를 처리하고 계산 리소스를 관리하는 등의 문제에 대처하는 전략을 발견했습니다. Hugging Face Transformers 라이브러리를 탐험하면서, 여러분의 프로젝트에서 BERT의 힘을 활용할 수 있는 실용적인 도구를 제공해 드렸습니다.\n\n미래를 엿보면, NLP 분야에서 미래에 기대되는 다국어 이해, 교차 모달 학습, 그리고 언어 모델의 지속적인 발전과 같은 무한한 가능성을 엿볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n저희의 여정은 여기서 끝나지 않아요. BERT는 기계와 인간의 커뮤니케이션 간격을 좁히며 새로운 언어 이해의 시대를 열었어요. AI의 다이내믹한 세계로 나아가면 BERT가 더 많은 혁신을 위한 발판이 되는 것을 기억해주세요. 더 많은 것을 탐험하고 배우며 창조하세요. 기술의 전선은 끊임없이 확장되고 있답니다.\n\nBERT 탐구 여정에 참여해 주셔서 감사드려요. 학습을 계속할 때 궁금증이 더 큰 미스터리를 해결하게 하고, AI와 NLP의 혁신적인 환경에 기여할 수 있기를 바래요.","ogImage":{"url":"/assets/img/2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP_0.png"},"coverImage":"/assets/img/2024-06-19-MasteringBERTAComprehensiveGuidefromBeginnertoAdvancedinNaturalLanguageProcessingNLP_0.png","tag":["Tech"],"readingTime":24},{"title":"프롬프트 엔지니어링 최상의 실천 방법 반복적인 프롬프트 개발","description":"","date":"2024-06-19 20:40","slug":"2024-06-19-PromptEngineeringBestPracticesIterativePromptDevelopment","content":"\n\n대형 언어 모델을 사용하여 애플리케이션을 개발할 때, 첫 번째 시도에서 최종 애플리케이션에 사용할 프롬프트를 만들기 어려울 수 있습니다.\n\n그러나 프롬프트를 점진적으로 개선하는 좋은 프로세스가 있다면, 당신이 원하는 작업에 잘 작동하는 것으로 어느 정도 도달할 수 있을 것입니다.\n\n기계 학습 모델을 훈련할 때, 첫 번째 시도에서 잘 작동하지 않는 경우가 많다고 들어 볼 수도 있습니다. 프롬프팅 또한 보통 처음부터 잘 작동하지 않습니다. 이 글에서는 점진적 개발을 통해 애플리케이션에 동작하는 프롬프트를 얻는 과정을 탐색하겠습니다.\n\n![image](/assets/img/2024-06-19-PromptEngineeringBestPracticesIterativePromptDevelopment_0.png)\n\n<div class=\"content-ad\"></div>\n\n## 목차:\n\n- Prompt 엔지니어링의 반복적 성격\n- 작업 환경 설정 및 시작하기\n- LLM 결과가 너무 길 때 극복하기\n- LLM을 어떤 세부 사항에 집중하도록 유도하기\n- 복잡한 응답 획득\n\n# 1. Prompt 엔지니어링의 반복적 성격\n\n이전에 머신러닝 수업을 들었다면, 머신러닝 개발이 반복적인 과정이라는 다이어그램을 본 적이 있을 것입니다. 데이터를 얻어 모델을 훈련시킨 후 실험 결과를 얻게 됩니다. 그런 다음 출력물을 살펴보고 오류 분석을 수행하여 작동 여부를 파악하고 문제를 해결하거나 해결 방법을 접근하는 방식을 조정할 수도 있습니다. 구현을 변경한 후 다시 실험을 실행하여 효과적인 머신러닝 모델을 도출하기 위해 반복 작업을 거쳐야 합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Prompt Engineering Best Practices](/assets/img/2024-06-19-PromptEngineeringBestPracticesIterativePromptDevelopment_1.png)\n\n애플리케이션을 개발할 때 LLM을 사용하여 프롬프트를 작성할 때, 프로세스는 꽤 유사할 수 있습니다. 무엇을 하고자 하는지, 완료하고자 하는 작업에 대한 아이디어가 있으며, 명확하고 구체적인 프롬프트를 작성하는 첫 번째 시도를 할 수 있습니다. 그리고 적절하다면 시스템이 생각할 시간을 주는 방식으로 적기를 노령할 수 있습니다.\n\n그런 다음 실행하여 얻는 결과를 확인할 수 있습니다. 처음에 충분히 잘 작동하지 않는 경우에는, 예를 들어, 지시사항이 충분히 명확하지 않거나, 알고리즘이 충분한 시간을 가지지 못한 이유 등을 파악하면서 반복적인 프로세스를 통해 아이디어를 수정하고, 프롬프트를 개선하고, 이 과정을 여러 번 반복하여 애플리케이션에 적합한 프롬프트를 얻을 수 있습니다.\n\n앤드루 엔지\n\n\n<div class=\"content-ad\"></div>\n\n# 2. 작업 환경 설정 및 시작하기\n\n작업 환경을 설정하는 것으로 시작해봅시다. OpenAI 및 OS 패키지를 가져와서 OpenAI API 키를 정의하고, 프롬프트를 입력하면 응답을 반환하는 get_completion 함수를 정의할 것입니다.\n\n```js\nimport openai\nimport os\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # 로컬 .env 파일 읽기\n\nopenai.api_key  = os.getenv('OPENAI_API_KEY')\n\n\ndef get_completion(prompt, model=\"gpt-3.5-turbo\"):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.ChatCompletion.create(\n        model=model,\n        messages=messages,\n        temperature=0, # 모델 출력의 랜덤성 정도\n    )\n    return response.choices[0].message[\"content\"]\n```\n\n여기에는 노트북 기술 세부 정보가 포함된 팩트 시트가 있습니다. 구성에 대해 이야기하며, 치수, 노트북 옵션, 재료 등이 포함되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nfact_sheet_laptop = \"\"\"\n개요\n\n저희의 극세사한 노트북 시리즈를 소개합니다. 현대적인 작업 환경을 위한 최첨단 디자인과 기능의 상징입니다.\n랩톱, 도킹 스테이션, 액세서리 등을 포함한 합리적인 테크 제품군의 일부입니다.\n다양한 색상과 마감으로 제공되어, 개인적이거나 전문적인 미적 취향과 시원하게 조화됩니다.\n탁월한 내구성과 스타일리시한 매력을 위해 프리미엄 소재로 제작되었습니다.\n집에서의 사무실이든 기업 환경이든 다양한 환경에 적합합니다.\n탁월한 성능과 생산성을 위해 고안되어, 전문가들을 위한 이상적인 선택지입니다.\n디자인\n\n노트북은 여러 색상 옵션으로 제공되어, 개인화할 수 있습니다.\n브러시 알루미늄, 매트 블랙, 광택 와이트 또는 크롬 액센트와 같은 다양한 마감 선택이 가능합니다.\n표준 디스플레이 또는 터치스크린 옵션 중 선택할 수 있습니다.\n백라이트 키보드, 지문 센서 또는 얼굴 인식 기술과 같은 추가 기능 옵션도 있습니다.\n획기적이고 가벼운 디자인으로, 출퇴근용으로 휴대성을 높이면서도 성능을 희생하지 않습니다.\n사양\n\n실행 가능한 Intel/AMD 프로세서로 원활한 멀티태스킹과 고성능 컴퓨팅을 제공합니다.\n35CM 너비, 24CM 깊이, 1.5CM 높이와 같은 초박형 디자인:\n넓이 35CM | 13.78”\n깊이 24CM | 9.45”\n높이 1.5CM | 0.59”\n몰입형 작업 또는 엔터테인먼트 경험에 맞춘 해상도로 선명하고 생동감 넘치는 디스플레이를 제공합니다.\n옵션\n\nSSD 또는 HDD 저장 옵션 중 선택하여 속도와 수용 용량을 개인화할 수 있습니다.\nUSB-C, HDMI 및 Thunderbolt와 같은 다양한 연결 옵션을 제공하여 다양성 있는 호환성을 지원합니다.\n처리 요구 사항에 맞는 다양한 RAM 구성이 가능합니다.\nWindows 및 MacOS 기호를 모두 충족하는 운영 체제 옵션을 제공합니다.\n소재\n\n프리미엄 룩과 견고한 보호를 위해 내구성 있는 알루미늄 케이싱으로 제작되었습니다.\n눈부시지 않게 어두운 조명에서도 편안하게 볼 수 있도록 안티글레어 코팅이 적용된 고해상도 디스플레이입니다.\n장거리 사용 중에도 최적 성능을 보장하기 위한 최첨단 냉각 기술이 탑재되어 있습니다.\n원산지\n\n일본의 현대적인 시설에서 전통 기술과 기술 혁신을 결합하여 정밀하게 제작되었습니다.\n\n\"\"\"\n```\n당신이 이 정보를 가지고 마케팅 팀이 온라인 소매 웹사이트 설명을 작성하는 것을 도와야 한다고 가정해보겠습니다. 여기서 말하는 프롬프트는, 기술사양을 기반으로 한 제품에 대한 소매 웹사이트 설명을 작성하는 마케팅 팀을 도와야 한다면 어떤 제품 설명을 작성할 것인지에 대한 정보를 쓰세요. 기술사양에 제공된 정보를 기반으로 제품 설명을 작성하세요.\n\n기술적 사양: {fact_sheet_laptop}\n\n\n<div class=\"content-ad\"></div>\n\n하지만 이걸 보면, 좀 긴 것 같다고 생각해. 정확히 요청한 대로 테크니컬 팩트 시트에서 시작하여 제품 설명을 작성하는 데 잘 해냈어. 하지만 이걸 보면, 좀 긴 것 같아. 아마 우리는 조금 더 짧게 원할지도 몰라.\n\n# 3. 너무 긴 LLM 결과 극복하기\n\n이전 섹션에서 프롬프트를 작성하고 결과를 받았어. 너무 길어서 그렇게 만족스럽지 않아. 그래서 나는 내 프롬프트를 명확히 하고, 최대 50단어를 사용해 이에 대한 원하는 길이에 대한 더 나은 지침을 제공하도록 말할 것이야. 다시 실행해보자.\n\n```js\nprompt = f\"\"\"\n마케팅 팀이 소매 웹사이트의 제품에 대한 설명을 만들 수 있도록 도와주는 것이 당신의 작업입니다.\n테크니컬 팩트 시트에 제공된 정보를 기반으로 제품 설명을 작성하십시오.\n제공된 기술 사양을 기반으로 제품 설명을 작성하십시오(삼중 백틱(delimited by triple backticks)).\n\n최대 50단어를 사용하십시오.\n\n기술 사양: {fact_sheet_laptop}\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n<div class=\"content-ad\"></div>\n\n이 제품에 대한 아주 멋진 간단한 설명 같아요. 이 응답의 길이를 확인해볼게요. 나는 이 응답을 공백을 기준으로 나누고, 길이를 출력할 거에요.\n\n그러니까 47개의 단어에요. 나쁘지 않아요. 대형 언어 모델은 명확한 단어 수에 대한 지시를 따르는 데 꽤 괜찮지만, 때로는 60이나 65개의 단어로 무언가를 출력할 때도 있지만, 타당한 범위 내에 있어요. 할 수 있는 일 중 일부는 최대 세 문장을 사용하는 것이죠.\n\n\nlen(response.split())\n\n\n# 4. 일부 세부사항에 집중하도록 LLM에 강제하기\n\n<div class=\"content-ad\"></div>\n\n이 텍스트를 웹 사이트에 계속 보왈하면서, 소비자에게 직접 판매하지 않는 웹 사이트인 것을 결정할 수 있습니다. 대신, 랩톱을 랩톱 소매업체에 판매하는 것이 목적이며, 이들은 랩톱의 기술적 세부 사항에 더 관심이 있을 것입니다.\n\n이런 경우, 이 프롬프트를 가져와서 이 프롬프트를 수정하여 랩톱의 기술적 세부 사항에 대해 더 정확하게 명시하고 싶습니다. 나는 이 설명이 랩톱 소매업체를 위해 작성되었으므로 기술적이고 랩톱이 구성된 재료에 초점을 맞춰야 한다고 말할 수 있습니다.\n\n```js\nprompt = f\"\"\"\n마케팅 팀이 기술 사양서를 기반으로 한 \n제품에 대한 소개 설명을 작성하는데 도움을 \n주세요.\n\n기술 사양서에 제공된 정보를 기반으로 제품 \n설명을 작성하십시오. 제품이 구성된 재료에 \n중점을 두어 기술적 성격으로 작성되어야 합니다.\n\n설명의 끝에는 기술 사양서에서 7자리 제품 \nID를 모두 포함하십시오.\n\n최대 50단어로 작성하십시오.\n\n기술 사양서: {fact_sheet_laptop}\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n프롬프트를 변경함으로써 특정 문자와 특성에 더 초점을 맞출 수 있습니다. 설명 끝에 제품 ID를 추가할 것이라고 결정한 경우, 설명 프롬프트 끝에 기술 사양서에 있는 모든 7자리 제품 ID를 포함할 지시를 추가할 수 있습니다. 이렇게 하고 실행하여 결과를 확인해 보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nprompt = f\"\"\"\n마케팅 팀이 소재에 초점을 맞춰 제품에 대한 상세한 설명을 만들 수 있도록 돕는 것이 당신의 일입니다.\n\n기술 사양서에 제공된 정보를 기반으로 제품 설명을 작성하세요.\n\n제품 설명은 노트북 소매업자를 대상으로 하므로 기술적이며 제품 구성 소재에 중점을 두어야 합니다.\n\n제품 사양서의 7자리 Product ID를 설명 끝에 포함하세요.\n\n단어 수를 최대 50개로 제한합니다.\n\n기술 사양서: {fact_sheet_laptop}\n\"\"\"\nresponse = get_completion(prompt)\nprint(response)\n```\n\n개발자가 많은 경우에 지나칠 수도 있는 반복적인 프롬프트 개발의 짧은 예시를 제공했습니다. 따라서 프롬프트를 처음으로 작성해보고 결과를 살펴본 후 점차적으로 프롬프트를 다듬어 필요한 결과에 점점 가까워지는 것이 좋습니다.\n\n# 5. 복잡한 응답 얻기\n\nchatGPT의 능력에 대한 더 나은 이해를 위해 좀 더 복잡한 프롬프트를 살펴봅시다. 설명 뒤에 제품의 치수를 제공하는 테이블을 포함하도록 요청하고 모든 내용을 HTML로 형식화해야 합니다. 실제로 이러한 프롬프트를 얻기 위해서는 여러 번의 반복한 작업이 필요할 것입니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\nprompt = f\"\"\"\n마케팅팀이 상품 기술사양에 기초하여 소매 웹사이트를 위한 제품 설명을 만들 수 있도록 도와주어야 합니다.\n\n3연결 따옴표로 구분된 기술 명세서에 제공된 정보를 기반으로 제품 설명을 작성해 주세요.\n\n설명은 노트북 소매업체를 대상으로 하므로 기술적이며 제품 구성 재료에 중점을 두어야 합니다.\n\n기술 사양에 있는 모든 7자 제품 ID를 설명에 포함하세요.\n\n설명 뒤에 제품의 치수를 제공하는 표를 포함해 주세요. 표에는 두 개의 열이 있어야 합니다. \n첫 번째 열에는 치수의 이름을, 두 번째 열에는 인치 단위로 측정된 치수를 넣어주세요.\n\n표에 '제품 치수'라는 제목을 붙여주세요.\n\n웹사이트에서 사용할 수 있는 HTML 형식으로 모든 것을 서식화해주세요. \n설명을 <div> 요소에 넣어주세요.\n\n기술 사양: {fact_sheet_laptop}\n\"\"\"\n\nresponse = get_completion(prompt)\nprint(response)\n```\n\n이 HTML을 표시하여 이게 유효한 HTML인지 확인하고 작동하는지 확인해봅시다.\n\n```js\nfrom IPython.display import display, HTML\ndisplay(HTML(response))\n```\n\n<img src=\"/assets/img/2024-06-19-PromptEngineeringBestPracticesIterativePromptDevelopment_2.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n## 만약 이 기사를 좋아하고 저를 지원하고 싶다면, 아래와 같은 내용을 확인해 주세요:\n\n- 👏 기사에 박수를 보내주세요 (50번) - 이 기사가 주목받을 수 있도록 도와주세요\n- To Data & Beyond 뉴스레터를 구독해주세요\n- 저를 Medium에서 팔로우해주세요\n- 📰 제 Medium 프로필에서 더 많은 콘텐츠를 확인해주세요\n- 🔔 저를 팔로우해주세요: LinkedIn | Youtube | GitHub | Twitter\n\n## 제 뉴스레터 To Data & Beyond를 구독하여 제 기사에 대한 전체적이고 일찍 접근하세요:\n\n## 데이터 과학과 인공지능에서의 경력을 시작하려는데 걸리는데 어려움을 겪고 계신가요? 데이터 과학 멘토링 세션과 장기적인 경력 멘토링을 제공하고 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 멘토링 세션: [링크](https://lnkd.in/dXeg3KPW)\n- 장기 멘토링: [링크](https://lnkd.in/dtdUYBrM)\n\n![이미지](/assets/img/2024-06-19-PromptEngineeringBestPracticesIterativePromptDevelopment_3.png)","ogImage":{"url":"/assets/img/2024-06-19-PromptEngineeringBestPracticesIterativePromptDevelopment_0.png"},"coverImage":"/assets/img/2024-06-19-PromptEngineeringBestPracticesIterativePromptDevelopment_0.png","tag":["Tech"],"readingTime":8},{"title":"LLM Alignments Part 21 RLAIF","description":"","date":"2024-06-19 20:39","slug":"2024-06-19-LLMAlignmentsPart21RLAIF","content":"\n\n안녕하세요!\n\n오늘의 주제는 조금 가벼울 수 있지만, 이미 RLHF에 대해 다뤘으니 이제 RLAIF에 대해 이야기해야 합니다. RLAIF이 점점 더 보편화되는 것이 중요하기 때문이죠.\n\n![이미지](/assets/img/2024-06-19-LLMAlignmentsPart21RLAIF_0.png)\n\nRLAIF의 개념은 간단합니다: RLHF의 \"H\" (Human)를 AI로 교체하는 것만을 의미합니다. 이 전환이 필요한 이유는 인간으로부터 데이터를 수집하는 것이 시간이 많이 소요되고 비용이 많이 들며 확장하기 어려울 수 있기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\nLLM 기반 에이전트의 효과가 입증되었으며, 사고 체인(Chain of thought, CoT)에서 사고 트리(Tree of thought, ToT), ReAct, Reflexion 및 기타 다양한 요소들까지, LLM을 강화 학습(Reinforcement Learning, RL), 검색 보강 생성(Retrieval-augmented generation, RAG) 또는 유사한 프레임워크에 통합함으로써 추론 성능을 크게 향상시킬 수 있다는 것이 명백해졌습니다.\n\n이 논문에서 강조된 바에 따르면, 데이터 생성을 위해 AI를 사용하는 것은 회귀로 이어지지 않으며, 실제로 특정 작업에서 RLHF를 능가할 수도 있습니다.\n\n다음은 위에서 설명한 RLHF와 RLAIF의 차이를 더 자세히 보여주는 다이어그램입니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-LLMAlignmentsPart21RLAIF_2.png)\n\nLLM(라지앤 러닝 모델)을 사용한 에이전트의 관점에서 대안적인 접근 방식은 학습된 보상 모델(RM)을 입력으로 사용자의 선호도를 받아들이고 엔지니어링된 프롬프트와 에이전트 아키텍처를 통해 점수를 출력하는 에이전트로 대체하는 것입니다.\n\n참고:\n- RLHF로부터 학습된 RM은 종종 SFT 모델에서 증류된 학습을 통해 훈련되기 때문에 증류된 RM으로 언급됩니다.\n- 에이전트 스타일의 RM은 훈련을 필요로 하지 않기 때문에 직접 RM으로 언급됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n오른쪽 표를 보면 직접 RM의 성능이 간접 RM의 성능과 일치한다는 것을 보여줍니다. 여기서 '동일 크기의 RLAIF'는 인공지능에 의해 생성된 교육 데이터가 RLHF에서 사용된 것과 동일한 크기인 간접 RM을 나타냅니다.\n\n<img src=\"/assets/img/2024-06-19-LLMAlignmentsPart21RLAIF_3.png\" />\n\n마지막으로 RLHF와 RLAIF를 비교합니다. 요약 및 유용성 작업에서 성능이 일치하는 방법과 RLAIF가 무해성 측면에서 RLHF를 능가하는 것을 주목해주세요.\n\n오늘은 여기까지입니다! 다음에는 DPO에 대해 이야기해볼 수 있겠네요~\n\n<div class=\"content-ad\"></div>\n\n참고:\n\nRLAIF: 인공지능 피드백을 활용한 인간 피드백으로 강화 학습 확장","ogImage":{"url":"/assets/img/2024-06-19-LLMAlignmentsPart21RLAIF_0.png"},"coverImage":"/assets/img/2024-06-19-LLMAlignmentsPart21RLAIF_0.png","tag":["Tech"],"readingTime":2},{"title":"LLM의 내부 작업 공개 고유 값 관점","description":"","date":"2024-06-19 20:37","slug":"2024-06-19-UnveilingtheInnerWorkingsofLLMsASingularValuePerspective","content":"\n\n## Llama3–8B 투영 행렬에 대한 특이값 분해 분석\n\n![이미지](/assets/img/2024-06-19-UnveilingtheInnerWorkingsofLLMsASingularValuePerspective_0.png)\n\nLLM이 얼마나 잘 훈련되었는지 생각해 보셨나요? 매개변수의 수가 많은데, 그 매개변수들이 훈련 데이터로부터 정보나 지식을 최대한으로 얻어내고 있는지 궁금해 하시지 않나요? 그렇지 않다면, LLM에서 유용하지 않은 매개변수들을 제거하여 더 효율적으로 만들 수 있을까요?\n\n이 글에서는 Singular Values 관점에서 Llama-3–8B 모델을 깊게 분석하여 이러한 질문에 답해보겠습니다. 더 이상 시간을 낭비하지 말고 편안하게 앉아, SVD를 적용하여 Llama-3–8B 행렬의 품질을 분석해 보세요!\n\n<div class=\"content-ad\"></div>\n\n# SVD 다시 살펴보기\n\n특이값 분해(SVD)에서 행렬 A는 세 가지 다른 행렬로 분해됩니다:\n\n여기서:\n\n- A는 원래 행렬입니다.\n- U는 A의 왼쪽 특이벡터인 열로 이루어진 행렬입니다.\n- Σ은 A의 특이값을 포함하는 대각행렬입니다. 이 값들은 항상 음이 아닌 값이며 일반적으로 가장 큰 값부터 가장 작은 값 순서로 정렬됩니다.\n- V_t는 V의 전치행렬이며, V의 열은 A의 오른쪽 특이벡터입니다.\n\n<div class=\"content-ad\"></div>\n\n더 간단한 용어로 설명하면, 특이값 분해(SVD)는 행렬의 복잡한 변환을 간단하고 이해하기 쉬운 회전 및 스케일링 과정으로 나누어 줍니다. Σ의 특이값은 스케일링 요소를 알려주고 U와 V_t의 특이벡터는 해당 스케일링이 행렬을 적용하기 전과 후의 방향을 알려줍니다.\n\n특이값은 행렬이 공간에서 다양한 방향으로 얼마나 늘어나거나 줄어드는지를 측정하는 방법으로 생각할 수 있습니다. 각 특이값은 특이벡터 쌍에 해당되며, 하나는 오른쪽 특이벡터(입력 공간에서의 방향), 다른 하나는 왼쪽 특이벡터(출력 공간에서의 방향)입니다.\n\n행렬의 특이값이 급격하게 감소하는 경우(가장 큰 특이값이 작은 것들보다 현저히 큰 경우), 이는 행렬의 유효 랭크(중요한 특이값의 수)가 실제 행렬의 차원보다 훨씬 작다는 것을 의미합니다. 이는 행렬이 낮은 랭크 행렬로 잘 근사될 수 있음을 시사합니다.\n\nLLM(대형 언어 모델)의 맥락에서, 가중치 행렬(예: 어텐션 메커니즘 또는 피드포워드 레이어의 행렬)들은 입력 데이터(예: 단어 임베딩)를 출력 표현으로 변환합니다. 주요한 특이값은 변환에 의해 가장 강조되는 입력 공간의 방향을 나타내며, 모델이 민감하거나 표현력이 강한 방향을 보여줍니다. 작은 특이값은 변환에서 중요하지 않거나 영향력이 적은 방향을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n특이값의 분포는 모델의 일반화 능력과 견고성에 영향을 줄 수 있습니다. 느린 감소(많은 큰 특이값)는 과적합을 초래할 수 있으며, 빠른 감소(소수의 큰 특이값)는 과소적합이거나 정보의 손실을 나타낼 수 있습니다.\n\n# Llama-3 아키텍처 재방문\n\n다음은 meta-llama/Meta-Llama-3-8B-Instructmodel의 config.json 파일입니다. 이 LLM은 8개의 num_key_value_heads를 사용하여 Grouped Query Attention을 활용하며, 이는 그룹 크기가 32/8=4임을 의미합니다.\n\n```js\n{\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 128000,\n  \"eos_token_id\": 128009,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 8192,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 500000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.40.0.dev0\",\n  \"use_cache\": true,\n  \"vocab_size\": 128256\n}\n```\n\n<div class=\"content-ad\"></div>\n\n# (Q, K, V, O) 행렬의 특이값 분석\n\n자, 이제 이 기사의 본격적인 내용으로 들어가 봅시다. Llama-3–8B-Instruct 모델의 (Q, K, V, O) 행렬들을 그들의 특이값을 통해 분석해 보겠습니다!\n\n## 코드\n\n우선, 이 분석에 필요한 모든 패키지를 가져와 봅시다.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport transformers\nimport torch\nimport numpy as np\nfrom transformers import AutoConfig, LlamaModel\nfrom safetensors import safe_open\nimport os\nimport matplotlib.pyplot as plt\n```\n\n그런 다음, 모델을 다운로드하고 로컬 /tmp디렉토리에 저장합시다.\n\n```js\nMODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n!huggingface-cli download {MODEL_ID} --quiet --local-dir /tmp/{MODEL_ID}\n```\n\n만약 GPU를 많이 가지고 계신 분이시라면, 다음 코드는 관련이 없을 수 있습니다. 그러나 저와 같이 GPU가 부족한 분들에겐, LLama-3–8B 모델의 특정 레이어만 로드하는 데 매우 유용할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndef load_specific_layers_safetensors(model, model_name, layer_to_load):\n    state_dict = {}\n    files = [f for f in os.listdir(model_name) if f.endswith('.safetensors')]\n    for file in files:\n        filepath = os.path.join(model_name, file)\n        with safe_open(filepath, framework=\"pt\") as f:\n            for key in f.keys():\n                if f\"layers.{layer_to_load}.\" in key:\n                    new_key = key.replace(f\"model.layers.{layer_to_load}.\", 'layers.0.')\n                    state_dict[new_key] = f.get_tensor(key)\n\n    missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n    if missing_keys:\n        print(f\"Missing keys: {missing_keys}\")\n    if unexpected_keys:\n        print(f\"Unexpected keys: {unexpected_keys}\")\n```\n\n이렇게 하는 이유는 Google Colab GPU의 무료 티어로는 LLama-3-8B를 fp16 정밀도로도 불러올 수 없기 때문입니다. 또한, 이 분석은 np.linalg.svd가 구축된 방식으로 인해 fp32 정밀도에서 작동해야 합니다. 다음으로, 주어진 matrix_type, layer_number 및 head_number에 대해 특이값을 얻는 메인 함수를 정의할 수 있습니다.\n\n```js\ndef get_singular_values(model_path, matrix_type, layer_number, head_number):\n    \"\"\"\n    Llama-3 모델의 지정된 행렬의 특이값을 계산합니다.\n\n    Parameters:\n    model_path (str): 모델 경로\n    matrix_type (str): 행렬 유형 ('q', 'k', 'v', 'o')\n    layer_number (int): 레이어 번호 (0에서 31까지)\n    head_number (int): 헤드 번호 (0에서 31까지)\n\n    Returns:\n    np.array: 특이값의 배열\n    \"\"\"\n    assert matrix_type in ['q', 'k', 'v', 'o'], \"잘못된 행렬 유형\"\n    assert 0 <= layer_number < 32, \"잘못된 레이어 번호\"\n    assert 0 <= head_number < 32, \"잘못된 헤드 번호\"\n\n    # RAM이 제한되어 있어 사용한 후에도 fp16을 사용해도 제한된 레이어만을 위해 모델을로드합니다.\n    config = AutoConfig.from_pretrained(model_path)\n    config.num_hidden_layers = 1\n    model = LlamaModel(config)\n    load_specific_layers_safetensors(model, model_path, layer_number)\n\n    # 지정된 레이어에 액세스합니다.\n    # 특정 레이어를로드했으므로 항상 인덱스 0을 사용합니다.\n    layer = model.layers[0]\n\n    # 각 헤드의 크기 결정합니다.\n    num_heads = layer.self_attn.num_heads\n    head_dim = layer.self_attn.head_dim\n\n    # 지정된 행렬에 액세스합니다.\n    weight_matrix = getattr(layer.self_attn, f\"{matrix_type}_proj\").weight.detach().numpy()\n    if matrix_type in ['q','o']:\n        start = head_number * head_dim\n        end = (head_number + 1) * head_dim\n    else:  # 'k', 'v' matrices\n        # num_key_value_heads로 나눠 헤드 번호를 조절합니다.\n        # llama3-8b는 그룹화된 쿼리 어텐션을 사용하기 때문에 수행됩니다.\n        num_key_value_groups = num_heads // config.num_key_value_heads\n        head_number_kv = head_number // num_key_value_groups\n        start = head_number_kv * head_dim\n        end = (head_number_kv + 1) * head_dim\n\n    # 지정된 헤드에 대한 가중치를 추출합니다.\n    if matrix_type in ['q', 'k', 'v']:\n        weight_matrix = weight_matrix[start:end, :]\n    else:  # 'o' matrix\n        weight_matrix = weight_matrix[:, start:end]\n\n    # 특이값 계산합니다.\n    singular_values = np.linalg.svd(weight_matrix, compute_uv=False)\n\n    del model, config\n\n    return list(singular_values)\n```\n\nHuggingFace에서 구현된 방식으로 인해 K, Q 및 V 행렬에 대한 지정된 헤드의 가중치를 추출할 수 있는 이유는 행별로 슬라이싱을 통해할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-UnveilingtheInnerWorkingsofLLMsASingularValuePerspective_1.png)\n\nO 행렬의 경우 선형 대수를 통해 O 가중치에서 지정된 헤드에 대한 가중치를 추출하기 위해 열별로 슬라이싱을 할 수 있습니다! 자세한 내용은 다음 그림에서 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-UnveilingtheInnerWorkingsofLLMsASingularValuePerspective_2.png)\n\n## 결과\n\n\n<div class=\"content-ad\"></div>\n\n분석을 위해 다양한 헤드, 레이어 및 행렬 유형에서 get_singular_values() 함수를 실행해야 합니다. 그리고 이러한 다양한 조합을 비교할 수 있도록 분석을 위한 여러 보조 지표도 정의해야 합니다:\n\n- 상위 10개 비율: 상위 10개 특이값의 합과 모든 특이값의 합 사이의 비율\n- 첫 번째/마지막 비율: 가장 높은 특이값과 가장 낮은 특이값 간의 비율\n- 최소 10개 비율: 최소 10개 특이값의 합과 모든 특이값의 합 사이의 비율\n\n(레이어 0, 헤드 0) 분석\n\n- Q(쿼리) 행렬은 초기 최대 특이값(약 10)을 갖고 있으며, 다음으로 K(키) 행렬(약 8)이 있습니다. 이 2개의 행렬은 초기 특이값이 V(값)와 O(출력) 행렬보다 현저히 높습니다.\n- 초기 특이값 뿐만 아니라, Q와 K 행렬의 상위 10개 비율과 첫 번째/마지막 비율을 확인하면, 이 두 행렬이 V와 O 행렬보다 훨씬 높은 값을 갖는다는 것을 알 수 있습니다. 이는 Q와 K 행렬이 대부분의 차원에 집중된 정보를 포함하고 있으며, V와 O 행렬은 정보가 구성요소 전반에 분산되어 있는 것을 시사합니다.\n- 최소 10개 비율을 살펴보면, Q와 K 행렬의 특이값이 거의 0에 가깝고 V와 O 행렬에 비해 상대적으로 훨씬 낮다는 것을 알 수 있습니다. 이는 Q와 K 행렬이 저랭크 구조를 가지고 있음을 나타내는 증거 중 하나이며, 이 차원들이 모델의 전반적인 성능에 미미한 영향을 미칩니다. 이러한 가중치는 구조적으로 제거하여 모델의 정확도에 큰 영향을 미치지 않는 경우가 있을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## (레이어 0, 다중 헤드) 분석\n\n- 헤드 번호가 증가함에 따라 Q 및 K 행렬의 상위 10 비율은 V 및 O 행렬보다 훨씬 빠른 속도로 증가하는 경향이 있습니다. 이 관찰 결과는 Q 및 K 행렬의 최하 10 비율에도 동일하게 적용되며, 헤드 번호가 증가함에 따라 값이 0에 가까워지는 경향을 보입니다. 그러나 V 및 O 행렬에는 해당 경향이 나타나지 않습니다.\n- 이 결과는 헤드 번호가 높은 헤드의 Q 및 K 행렬이 낮은 차원에서 정보를 저장하는 경향이 있다는 것을 나타냅니다. 다시 말해, 헤드 번호가 증가함에 따라 Q 및 K 행렬은 더 적은 차원에서 정보를 저장하려고 합니다.\n\n## 교차-레이어 분석\n\n- 더 깊은 레이어로 갈수록, Q 및 K 행렬의 초기값이 감소되는 경향을 발견했지만, 여전히 V 및 O 행렬과 비교하면 비교적 높습니다.\n- 더 깊은 레이어로 갈수록, 특정 헤드의 Q 및 K 행렬의 상위 10 비율 및 첫 번째/마지막 비율에 대한 하락 트렌드 패턴이 나타납니다. 또한 최하 10 비율의 약간의 상승 트렌드 패턴이 있습니다. 이는 더 깊은 레이어의 Q 및 K 행렬이 낮은 레이어와 비교하여 더 잘 훈련된 것으로 나타납니다.\n\n<div class=\"content-ad\"></div>\n\n- \"레이어 0, 다중 헤드\" 섹션에서 발견한 동일 레이어 내의 헤드 간 패턴은 더 깊은 레이어로 이동할 때 명확하지 않습니다. \n\n요약\n\n- K 및 Q 행렬은 V 및 O 행렬과 비교하여 상대적으로 낮은 순위를 가지고 있습니다. 가지치기(pruning) 또는 차원 축소 방법을 수행하려면 K 및 Q 행렬에 더 집중할 수 있습니다.\n- 레이어가 깊어질수록 모든 (K, Q, V, O) 행렬이 더 잘 훈련됩니다. 가지치기 또는 차원 축소 방법을 수행하려면 낮은 레이어에 더 집중할 수 있습니다.\n- 가지치기 외에도 초기 몇 레이어에서만 전체 미세 조정을 수행하거나 LoRA로도 이를 수행하는 것이 흥미로울 수 있습니다.\n\n# 마무리 말씀\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-19-UnveilingtheInnerWorkingsofLLMsASingularValuePerspective_3.png)\n\n이 시점까지 참석해 주셔서 축하드립니다! 이 기사에서 새로운 것을 배우셨으면 좋겠습니다. 선형 대수의 좋은 오래된 개념들을 적용하여, LLM의 훈련이 얼마나 잘 이루어졌는지 이해하는 것은 정말 흥미롭습니다.\n\n이 유형의 콘텐츠를 좋아하신다면, 저의 Medium 계정을 팔로우해주시어 앞으로의 다른 글 알림을 받아보세요.\n\n# 저자 소개\n\n\n<div class=\"content-ad\"></div>\n\n루이스 오웬은 인도네시아 출신의 데이터 과학자 및 AI 연구 엔지니어로, 항상 새로운 지식에 굶주립니다. 그의 경력 여정을 통해 그는 비영리 단체, 전자 상거래, 대화형 AI, OTA, 스마트 시티 및 핀테크 등 다양한 산업 분야에서 일해 왔습니다. 일 안에서 해외에선, 그는 자신의 기사나 멘토링 세션을 통해 데이터 과학 애호가들이 데이터 과학자로 성장할 수 있도록 시간을 보내는 것을 즐깁니다.\n\n지금은 루이스가 전 세계적인 CX 자동화 플랫폼 인 Yellow.ai의 NLP 연구 엔지니어로 일하고 있습니다. 루이스의 웹사이트를 방문하여 그에 대해 더 알아보세요! 마지막으로, 궁금한 점이나 이야기할 주제가 있으면 망설이지 마시고 LinkedIn을 통해 루이스에게 연락해보세요.","ogImage":{"url":"/assets/img/2024-06-19-UnveilingtheInnerWorkingsofLLMsASingularValuePerspective_0.png"},"coverImage":"/assets/img/2024-06-19-UnveilingtheInnerWorkingsofLLMsASingularValuePerspective_0.png","tag":["Tech"],"readingTime":9},{"title":"위에서 바라본 Transformer 구조","description":"","date":"2024-06-19 20:35","slug":"2024-06-19-TheTransformerArchitectureFromaTopView","content":"\n\n지금까지 사용되던 최신 언어 처리(NLP) 모델은 다른 모델들 중에서 순환 신경망(RNN)이었습니다.\n\n그런데 그 이후로 트랜스포머가 등장했습니다.\n\n트랜스포머 아키텍처는 이전 RNN과 비교하여 자연어 처리 성능을 크게 향상시켰습니다.\n\n2017년 Vaswani 등이 발표한 논문 \"Attention is All You Need\"에서 개발된 트랜스포머는 자가 주의 메커니즘을 활용하여 문장 내 모든 단어의 관련성과 문맥을 학습할 수 있게 되어 NLP를 혁신했습니다.\n\n<div class=\"content-ad\"></div>\n\nRNN(Recurrent Neural Networks)이 데이터를 순차적으로 처리하는 것과는 달리, Transformer는 문장의 모든 부분을 동시에 분석합니다. 이 병렬 처리 능력 덕분에 Transformer는 문장이나 문서에서 각 단어의 맥락과 관련성을 모든 다른 단어에 대해 학습할 수 있습니다. 이는 RNN에서 발견되는 장기 의존성과 계산 효율성과 관련된 한계를 극복하는 데 도움이 됩니다.\n\n하지만 이 아키텍처를 단계별로 살펴보겠습니다.\n\n![Transformer Architecture](/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png)\n\n- Transformer 아키텍처에는 두 가지 구성 요소가 있습니다: 인코더(Encoder)와 디코더(Decoder).\n- 이러한 구성 요소들은 함께 작동하며 여러 유사성을 공유합니다.\n- 인코더: 토큰 시퀀스의 입력을 각 토큰의 맥락을 포착하는 풍부하고 연속적인 표현으로 변환합니다. 그 출력은 임베딩 벡터의 시퀀스이며, 종종 숨겨진 상태 또는 컨텍스트로 불립니다.\n- 디코더: 인코더의 숨겨진 상태를 사용하여 반복적으로 한 번에 하나씩 토큰의 출력 시퀀스를 생성합니다.\n\n<div class=\"content-ad\"></div>\n\nTransformer 아키텍처에는 Encoder와 Decoder 두 가지가 모두 존재하지만, Encoder만 사용하는 경우, Decoder만 사용하는 경우, 또는 둘 다 사용하는 경우 등 3가지 유형의 트랜스포머가 있습니다.\n\n## Encoder-only Transformers\n\n- 이러한 모델은 텍스트 블록을 깊게 이해하고 해석할 수 있는 전문가 분석가로 생각할 수 있습니다.\n- 이러한 모델은 텍스트 입력 시퀀스를 풍부한 숫자 표현으로 변환하여 텍스트 분류나 명명된 개체 인식(NER)과 같은 작업에 적합합니다.\n- BERT 및 RoBERTa, DistilBERT와 같은 변형들은 이러한 아키텍처 클래스에 속합니다.\n- 이러한 모델은 양방향 어텐션을 사용합니다. 단어 주변의 전체 문맥에 주의를 기울이도록 설계되었습니다.\n\n## Decoder-only Transformers\n\n<div class=\"content-ad\"></div>\n\n- 여기서 모델들을 느슨하게 번역의 역할을 수행하는 창의적인 이야기꾼으로 상상해봅시다.\n- \"트랜스포머를 학습하는 것은...\"과 같은 텍스트 자극이 주어지면, 이러한 모델들은 가장 가능성 있는 다음 단어를 예측하며 시퀀스를 자동으로 완성합니다 (바람직하게는 \"즐겁다\").\n- GPT 모델 패밀리는 이 범주에 속합니다.\n- 이 구조에서 주어진 토큰에 대해 계산된 표현은 미래를 예측하기 위해(자기 회귀적 주의라고도 함) 한 부분에 의존함과 동시에 왼쪽 컨텍스트(지금까지의 이야기)에만 의존합니다.\n\n## 인코더-디코더 트랜스포머\n\n- 이들은 변환기 패밀리의 다재다능한 멀티태스커입니다. 하나의 형태에서 텍스트를 다른 형태로 변환하는 능력이 있습니다.\n- 입력 텍스트를 먼저 소화하여, 그 본질과 뉘앙스를 잡는 것(인코더 덕분)을 하고 이를 깊이 이해하여 디코더 부분에서 새로운 텍스트 조각을 응답으로 만들어냅니다.\n- 기계 번역 및 요약 작업에 적합합니다.\n- 이 범주에 속하는 트랜스포머 모델로는 T5와 BART가 있습니다.\n\n# 1. 토크나이저\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_1.png\" />\n\n- 모델로 텍스트를 처리하기 전에 첫 번째 단계는 토큰화입니다.\n- 이 단계는 컴퓨터가 단어를 해석할 수 있도록 돕습니다. 각 고유한 토큰은 고유한 번호를 갖게 됩니다.\n- 모델을 학습시키기 위해 토크나이저를 선택했다면, 텍스트를 생성할 때도 동일한 토크나이저를 사용해야 합니다.\n- 이제 입력을 임베딩 레이어에 전달할 수 있습니다.\n\n# 2. 임베딩 레이어\n\n<img src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_2.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n위의 이미지를 참고하면 내부에는 하나의 임베딩 레이어를 엿볼 수 있지만 두 레이어가 동일합니다.\n\n- 임베딩 레이어는 토큰화된 숫자 표현을 밀도 있는 벡터 임베딩으로 변환합니다.\n- 학습 가능한 벡터 임베딩 공간은 각 토큰이 벡터로 표현되고 해당 공간 내에서 고유한 위치를 차지하는 고차원 공간입니다.\n- 어휘 사전의 각 토큰은 다차원 벡터에 매칭되며(예: 크기가 512인), 이러한 벡터는 입력 시퀀스의 개별 토큰의 의미와 맥락을 인코딩하는 것을 학습하는 것입니다.\n\n## 포지셔널 임베딩\n\n- 원시 임베딩과 결합하여 위치 정보를 추가합니다.\n- 모델은 각 입력 토큰을 병렬로 처리합니다.\n- 포지셔널 임베딩을 통해 모델은 단어 순서에 대한 정보를 얻으며, 텍스트를 이해하려고 할 때 매우 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n# 3. 인코더\n\n![이미지](/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_3.png)\n\n- 먼저, 트랜스포머에는 단일 인코더가 아니라 서로 옆에 많은 인코더 스택이 있는 것이 중요합니다. 모든 인코더는 동일합니다. 예를 들어, BERT는 24개의 인코더 스택을 가지고 있습니다.\n- 임베드 레이어에서의 임베딩 시퀀스는 인코더의 입력이며, 먼저 멀티 헤드 셀프 어텐션 레이어에 공급되고 그 다음에 완전히 연결된 피드포워드 레이어에 공급됩니다.\n- 출력은 토크나이저 사전의 각 가능한 토큰에 대한 확률 점수에 비례하는 로짓의 벡터입니다.\n\n## 멀티 헤드 셀프 어텐션\n\n<div class=\"content-ad\"></div>\n\n- 인코더 내부의 이 레이어는 특정 작업을 수행합니다: 문장 속 각 단어를 그 자체로 이해하는 것뿐만 아니라 다른 모든 단어와도 함께 이해하는 것입니다.\n\n그럼, 왜 \"다중 헤드\"일까요?\n\n- 단순히 이 관계를 한 가지 방법으로만 보지 않기 때문입니다. 대신, 다중 \"헤드\"를 갖고 있어서 각각이 문장을 다른 관점에서 바라볼 수 있습니다.\n- 한 헤드는 문법 구조에 집중할 수 있고, 다른 헤드는 특정 용어의 의미에 초점을 맞출 수 있으며, 또 다른 헤드는 문장의 어조에 집중할 수 있습니다.\n- 이러한 다양한 측면을 동시에 검토함으로써, 모델은 텍스트를 더 깊이 이해할 수 있습니다.\n\n## 전방향\n\n<div class=\"content-ad\"></div>\n\n- 이는 두 층으로 구성된 완전 연결 (밀집) 신경망 구조입니다.\n- 임베딩 시퀀스 전체를 하나의 벡터로 처리하지 않습니다.\n- 각 임베딩은 개별적으로 처리됩니다.\n- 변환된 임베딩이 출력됩니다.\n- 그런 다음, Transformer의 최종 출력 계층을 통해 (이 전방향 계층 자체 내부가 아닌) 로짓이 생성되며, 이는 전체 모델 구조의 문맥 내 토큰 확률에 비례합니다.\n- 다른 신경망과 마찬가지로 활성화 함수를 사용해야 합니다. 이 경우 GELU가 사용됩니다.\n- GELU는 자연어 처리에서 만나는 데이터 분포 유형에 특히 효과적인 방식으로 선형 및 비선형 변환 사이의 균형을 유지하면서 비선형성을 도입할 수 있습니다.\n\n# 4. 디코더\n\n![그림](/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_4.png)\n\n인코더와 유사하게 디코더도 많은 디코더들의 스택으로 구성되어 있으며(인코더-디코더 모델의 인코더 수와 동일), 서로 동일합니다. 예를 들어 (디코더 전용인) GPT-2 Extra Large 모델은 48개의 디코더 레이어 스택을 가지고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n👋 디코더와 인코더의 주요 차이점은 디코더에는 두 가지 어텐션 서브레이어가 있다는 것입니다:\n\n### 마스킹된 멀티헤드 셀프 어텐션\n\n- 각 시간 단계에서 생성되는 토큰이 과거 출력 및 현재 예측 중인 토큰에만 기초함을 보장합니다. 이것이 \"마스킹\" 뒤의 개념입니다.\n- 이것이 없으면 디코더가 훈련 중에 간단히 대상 번역을 복사함으로써 속일 수 있습니다.\n- 멀티헤드는 인코더와 동일합니다. 각 헤드는 데이터의 다른 측면을 배우며 시퀀스의 다른 부분에 초점을 맞추고 토큰 사이의 다양한 관계를 고려합니다.\n\n### 인코더-디코더 어텐션\n\n<div class=\"content-ad\"></div>\n\n- 이 레이어는 각 출력 시퀀스 토큰을 생성하는 동안 입력 시퀀스의 서로 다른 부분(두 가지 다른 언어 같은)에 초점을 맞출 수 있도록 디코더에 가능하게 합니다.\n- 디코더는 출력 시퀀스에서 다음 토큰을 생성하면서 현재 문맥과 지금까지 생성한 내용을 고려합니다.\n- 이를 통해 디코더는 다음 출력 토큰의 생성에 영향을 미쳐야 할 가장 관련성 높은 입력 시퀀스 부분을 파악할 수 있습니다.\n\n디코더의 출력은 토큰화 사전에 있는 각 토큰의 확률 점수(모두 1에 모두 더해짐)이며 더 높은 확률을 가진 토큰이 반환됩니다.\n\n# 연락을 유지하자\n\n➥이와 같은 콘텐츠 더 보려면 Medium에서 팔로우하세요.\n➥LinkedIn이나 𝕏에서 연결합시다.\n➥제 GitHub을 확인하세요.\n\n<div class=\"content-ad\"></div>\n\n# 다음에 무엇을 읽을지 고민이세요? 여기 두 가지 추천이 있어요:\n\n## 이 주제에 대해 더 깊게 알아갈 수 있는 멋진 참고 자료와 자원:\n\n- Tunstall, Lewis, Leandro Von Werra, 그리고 Thomas Wolf. Natural language processing with transformers. “ O’Reilly Media, Inc.”, 2022.\n- [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n- [YouTube - Illustrated Transformer](https://youtu.be/-QH8fRhqFHM?si=GWPYodFv60vQFNEb)","ogImage":{"url":"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png"},"coverImage":"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png","tag":["Tech"],"readingTime":6},{"title":"질문-답변 캐글 대회에서 Sentence Transformer를 활용하기","description":"","date":"2024-06-19 20:34","slug":"2024-06-19-Question-AnswerKaggleCompetitionusingSentenceTransformer","content":"\n\n이 대회는 DataTalks.Club 코스의 Q&A 비디오에서 얻은 독특한 데이터셋을 활용하여 참가자들에게 질문과 정확한 답변을 맞추도록 도전합니다.\n\n위 노트북에서는 Pandas를 사용하여 CSV 파일의 데이터를 정리하고 분석하여 데이터프레임에 저장하는 방법을 사용했습니다. 이를 위해 sentence transformer를 활용하였습니다. 첫 번째로, 해당 usecase에 대해 triplet loss를 사용해 보았는데, 이는 지도 학습 유사성 또는 메트릭 학습에 가장 많이 사용되는 손실 함수 중 하나입니다. 가장 간단하게 설명하면, Triplet Loss는 유사하지 않은 쌍이 비슷한 쌍에서 최소한 일정한 여백 값만큼 떨어져 있도록 장려합니다.\n\n이 때의 점수는 0.69이었는데, Triplet pair는 (질문, 답변, 다른 가능한 답변(100% 관련은 아님))이었습니다. Triplet loss는 질문과 답변의 임베딩을 가깝게 정렬하고 다른 가능한 답변은 멀게 밀어냅니다.\n\n다음 시도한 단계는 다른 여러 가능한 답변을 추가하는 것이었습니다. 예를 들어, 각 질문에 대해 같은 질문과 답변에 대한 세 가지 다른 가능한 답변이있는 샘플이 세 개씩 포함되었습니다. 이것은 학습이 잘 되지 않았고, 0.5648의 점수가 나왔는데, 이는 질문, 답변 쌍 당 하나의 샘플만 사용하는 것보다 훨씬 낮은 점수입니다.\n\n<div class=\"content-ad\"></div>\n\n다음으로, [(a1, b1), …, (an, bn)]를 사용하는 MultipleNegativesRankingLoss를 사용하여 간단하게 만들고 싶습니다. 여기서 (ai, bi)가 유사한 문장이며 (ai, bj)가 다른 문장으로 가정됩니다. 여기서 i != j 입니다.\n\n이는 (ai, bi) 사이의 거리를 최소화하고 동시에 모든 i != j에 대해 (ai, bj)의 거리를 최대화합니다. 이렇게 하면 부정적인 것을 지정할 필요가 없고 i != j의 경우 거리를 자동으로 최대화합니다. 성능이 향상되었다 0.962를 얻었습니다.\n\n질문당 하나의 샘플을 가진 triple loss에 대한 KaggleNotebook\n\n질문당 여러 샘플을 가진 triple loss에 대한 KaggleNotebook.\n\n<div class=\"content-ad\"></div>\n\n이 작업을 더 개선하려면 쌍을 사용하는 대신 삼중체를 추가하고 세 번째는 \"하드-부정사\"여야 합니다. 이때, 어휘 수준에서는 (a1, b1)과 유사하지만 의미 수준에서는 (a1, b1)과 유사하지 않아야 합니다.","ogImage":{"url":"/assets/img/2024-06-19-Question-AnswerKaggleCompetitionusingSentenceTransformer_0.png"},"coverImage":"/assets/img/2024-06-19-Question-AnswerKaggleCompetitionusingSentenceTransformer_0.png","tag":["Tech"],"readingTime":2},{"title":"RAGRetrieval Augmented Generation 소개 및 응용 데모","description":"","date":"2024-06-19 20:32","slug":"2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos","content":"\n\n# RAG 소개\n\n안녕하세요. 오늘은 검색 증강 생성 (RAG)에 대한 소개와 몇 가지 응용 프로그램을 시연하겠습니다. 이 토크의 자료는 아래의 GitHub 저장소에서 확인할 수 있어요.\n\n해당 저장소에서 제 발표용 슬라이드가 포함된 PDF 파일을 찾을 수 있습니다. 이후에는 RAG를 적용하기 위해 몇 가지 실습을 진행할 것입니다. 코드와 데이터는 GitHub 저장소에서 모두 제공되므로 함께 따라해볼 수 있어요.\n\nRAG 개요부터 시작해봅시다. RAG는 대형 언어 모델을 개선하는 강력한 기술입니다. 제 생각에는 대형 언어 모델을 최상의 방식으로 적용하는 데 초점을 맞춰야 하며, RAG는 특히 개발자들에게 가장 효과적인 접근 중 하나입니다.\n\n<div class=\"content-ad\"></div>\n\n대형 언어 모델에는 일부 고유한 제약이 있습니다. 외부 지식이 부족하기 때문에 잘못된 정보를 제공하거나 환각적인 정보를 제공할 수 있습니다. 훈련 데이터의 컷오프 날짜 때문에 잠재적으로 오래된 정보에 의존합니다. 예를 들어, GPT-3는 2021년 이전에 훈련을 받았습니다. 그들은 훈련 데이터 외의 특정 주제에 대한 깊이나 구체성이 부족합니다. LLMs의 훈련 및 세밀한 조정은 많은 조직에게 계산 비용이 많이 들어서 현실적으로 불가능합니다. 모델은 지식의 출처를 보여주거나 민감한 데이터가 제공될 때 개인 정보 보호 규정을 준수할 수 없습니다.\n\nRAG는 생성된 콘텐츠의 정확성과 관련성을 크게 향상시킬 수 있습니다. 먼저 텍스트를 생성하기 전에 외부 데이터베이스나 문서에서 관련 정보를 검색합니다. [1]\n\n\n![image](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_0.png)\n\n\n예를 들어, 사용자가 다음과 같은 질문을 할 때를 상상해보세요. “OpenAI의 CEO Sam Altman이 이사회에 의해 갑자기 해임당하고 회사에 재취직되었다는 사실을 어떻게 평가하십니까? 이것은 권력 동력 측면에서 게임 오브 스론의 현실적 버전처럼 세 일 동안에 벌어진 일입니다.”\n\n<div class=\"content-ad\"></div>\n\nChatGPT가 적절하게 대답하지 못할 것입니다. 그 이유는 이벤트가 2021년 이후에 발생했기 때문입니다. RAG를 사용하면 먼저 관련 문서를 검색하고 \"Sam Altman이 CEO로 OpenAI에 복귀, 실리콘밸리의 드라마가 코미디와 비슷해짐\", \"드라마가 결론에 이르렀나요? Sam Altman이 OpenAI의 CEO로 복귀, 이사회가 구조 재편을 할 예정\", \"OpenAI의 인사 불화가 종결됐습니다. 누가 이겼고 누가 졌나요?\"와 같은 중요한 부분을 추출합니다. 이 세 개의 단락은 질문에 맥락을 제공하기 위해 결합됩니다. 그 후 대형 언어 모델은 검색된 정보를 기반으로 일관된 답변을 생성할 수 있습니다.\n\nRAG 타임라인 및 기술\n\n![image](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_1.png)\n\n역사를 살펴보면, RAG는 세 가지 주요 방식(사전 훈련, 세밀한 조정 및 추론 검색)을 갖춘 학계에서 유래되었습니다. 최근에는 더 실용적인 기술들이 추론 시간 검색에 초점을 맞추고 있습니다. 또한, 2022년 이전에는 제안된 RAG 기술이 몇 없었지만, 2023년 이후에는 다양한 RAG 기술이 급증한 것을 볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![RAG process](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_2.png)\n\nRAG은 응답을 생성하기 전에 외부 지식 소스에서 관련 정보를 먼저 검색하여 LLM 출력의 정밀성과 관련성을 향상시킵니다. 전통적인 기본 RAG 프로세스, Naive RAG로도 알려진 과정은 주로 세 가지 기본 단계로 구성됩니다.\n\n- 색인화: 문서는 더 짧은 텍스트(\"체크\")로 분할되어 인코더 모델을 사용하여 벡터 데이터베이스에 색인화됩니다.\n- 검색: 질문과 청크 간 유사성을 기반으로 관련 청크를 찾습니다.\n- 생성: LLM은 검색된 컨텍스트를 조건으로 하는 답변을 생성합니다.\n\n고급 RAG 패러다임에는 Pre-Retrieval 및 Post-Retrieval에서 추가 처리가 포함되어 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n- 검색 전에는 질문과 문서 조각 사이의 의미 차이를 조정하기 위해 쿼리 재작성, 라우팅, 확장과 같은 방법을 사용할 수 있습니다.\n- 검색 후에는 검색된 문서 코퍼스를 재랭크하면 \"중간에서 길을 잃음\" 현상을 피하거나 컨텍스트가 필터링되어 윈도우 길이가 줄어들도록 압축될 수 있습니다.\n\n모듈식 RAG도 소개되었습니다. 구조적으로 더 자유롭고 유연하며, 쿼리 검색 엔진 및 여러 답변의 퓨전과 같은 특정 기능 모듈들이 더 많이 도입되었습니다. 기술적으로는 검색을 세밀하게 조정, 강화 학습 및 기타 기술과 통합합니다. 프로세스 측면에서는 RAG 모듈이 설계되고 조율되어 다양한 RAG 패턴이 생성됩니다.\n\n좋은 RAG 시스템을 구축하기 위해 고려해야 할 세 가지 중요한 질문은 무엇을 검색할 것인가? 언제 검색할 것인가? 검색된 콘텐츠를 어떻게 활용할 것인가?\n\n증강 소스. 텍스트 단락, 구절 또는 개별 단어와 같은 비구조적 데이터. 색인된 문서, 트리플 데이터 또는 서브그래프와 같은 구조화된 데이터 또한 사용할 수 있습니다. 또는 LLMs가 생성한 콘텐츠에서 검색할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n증강 단계. 사전 훈련, 세밀 조정 및 추론 단계에서 실행됩니다.\n\n증강 과정. 초기 검색은 일회성이지만, 반복 검색, 재귀 검색 및 적응적 검색 방법이 발전하는 과정에서 LLMs가 자체적으로 검색 시기를 결정하는 방식이 점차 RAG의 개발 과정에서 나타났습니다.\n\n아래 그림은 RAG triage에 대한 더 자세한 정보를 보여줍니다. 이는 증강 단계(사전 훈련, 세밀 조정, 추론), 증강 소스(비구조화된 데이터, 구조화된 데이터, LLM이 생성한 콘텐츠), 증강 프로세스(일회성 검색, 반복 검색, 적응적 검색, 재귀 검색)를 포함합니다.\n\n<img src=\"/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_3.png\" />\n\n<div class=\"content-ad\"></div>\n\n아래 그림은 RAG와 관련된 용어와 그들의 참고 논문을 보여줍니다.\n\n![RAG Terminology](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_4.png)\n\n# RAG 특징\n\nRAG를 더 잘 이해하기 위해 비교해보면 좋습니다. RAG는 모델에게 맞춤형 정보 검색을 위한 교과서를 제공하는 것과 같습니다. 특정 질의에 매우 적합합니다. 비유를 통해 설명해드릴게요. RAG는 모델에게 외부 지식 원천을 제공해주는데, 마치 학생에게 여는 책 시험을 볼 수 있게 해주는 것과 같습니다. 그럼에도 불구하고, 파인튜닝은 특정 작업에 적합한 지식을 점차적으로 습득하는 학생과 유사하며, 시간이 지남에 따라 지식을 내면화하며 특정 구조, 스타일 또는 형식을 모방하는 데 더 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image5](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_5.png)\n\n외부 지식과 모델 사용자 정의에 따라 RAG 및 세밀한 조정이 각각 적합한 응용 프로그램을 갖고 있습니다. 두 가지를 함께 사용하면 최상의 성능을 얻을 수 있습니다. RAG는 모델 적응이 적게 필요하지만 외부 지식이 필요하며, 세밀한 조정은 모델을 크게 적응시키지만 외부 데이터가 적게 필요합니다. 대부분의 경우, RAG, Fine-tuning, Prompt Engineering을 결합하면 최상의 결과를 얻을 수 있습니다.\n\n![image6](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_6.png)\n\n# RAG 평가\n\n\n<div class=\"content-ad\"></div>\n\nRAG을 구현한 후, 세 가지 품질 점수인 문맥적 타당성, 답변 충실도 및 답변 관련성을 사용하여 철저한 평가가 필수적입니다. 이 평가에는 소음에 대한 견고성, 거부 능력, 정보 통합 및 여우틀 분석의 네 가지 핵심 능력이 포함됩니다. RGB 및 RECALL과 같은 표준화된 벤치마크뿐만 아니라 RAG 시스템을 평가하기 위한 자동화된 도구인 RAGAS, ARES 및 TruLens도 이용할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_7.png)\n\n![이미지](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_8.png)\n\n# RAG의 미래\n\n<div class=\"content-ad\"></div>\n\n파워풀한 RAG는 몇 가지 도전에 직면합니다. 큰 컨텍스트 창을 가지면 성능이 향상되지 않을 수 있습니다. 검색을 강력하게 만들고 낮은 품질의 콘텐츠를 걸러내는 것은 어려울 수 있습니다. 잘못된 콘텐츠를 검색하면 최종 답변을 오염시킬 수 있습니다. RAG와 세밀한 조정 사이의 균형을 맞추는 것은 까다로울 수 있습니다. 더 큰 모델이 항상 RAG를 개선하는지 여전히 불분명합니다. LLM의 역할을 더 탐구해야 합니다. 대규모로 RAG를 제작하고 민감한 데이터를 보호하는 것도 다른 고려 사항입니다. RAG를 확장하여 이미지, 오디오 및 비디오를 처리하는 것은 여전히 열려 있는 문제입니다.\n\n하지만 RAG는 질문 답변, 추천 시스템, 정보 추출 및 보고서 생성에 대한 약속을 보여줍니다. 성숙한 RAG 기술 스택은 Langchain 및 LlamaIndex와 같이 번창하고 있고, 시장에서는 맞춤형 도구 및 간소화된 도구와 같은 더 타깃팅 된 RAG 도구들이 등장하고 있습니다. 따라서 생태계는 RAG에 맞는 새로운 도구들이 계속해서 확장되어갈 것입니다.\n\n![이미지](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_9.png)\n\n# RAG 실무\n\n<div class=\"content-ad\"></div>\n\n지금까지 RAG에 대한 고수준 개요를 제공했습니다. 다음으로는 손을 더럽히는 RAG 실험 몇 가지를 시연할 것이며, 여러분의 프로젝트에서 이러한 기술을 적용할 수 있도록 도와드리겠습니다. LlamaIndex를 활용하여 다양한 RAG 파이프라인을 소개하는 Python 스크립트가 세 개 있습니다.\n\n1. 기본 RAG 파이프라인\n2. 문장 창 RAG 파이프라인\n3. 자동 생성 RAG 파이프라인\n\n![이미지](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_10.png)\n\n기본 RAG 파이프라인은 기존 데이터베이스로 대규모 언어 모델을 보완합니다. 쿼리는 먼저 데이터베이스에서 관련 콘텍스트를 검색한 후 답변을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n문서를 64토큰씩 2토큰의 중첩으로 작은 단락으로 나눌 수 있어요. 이러한 단락들은 벡터로 인코딩되고 벡터 데이터베이스에 색인됩니다. 쿼리를 받으면 가장 유사한 단락을 찾아 질문과 함께 프롬프트로 둘러싸서 언어 모델에 전달하여 답변을 생성합니다.\n\n![image](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_11.png)\n\n![image](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_12.png)\n\n문장 윈도우 검색 파이프라인은 더 많은 문맥이 필요할 때 유용합니다. 토큰 청크 대신 문장으로 문서를 세그먼트화합니다. 가장 유사한 문장뿐만 아니라 직전 및 직후 문장을 가져와서 문맥 창을 형성합니다. 이러한 문맥 창은 재정렬되어 언어 모델에 제공됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_13.png)\n\n자동 생성되는 검색 파이프라인은 검색을 위한 계층 구조를 만듭니다. 작은 16 토큰 단락은 64 토큰 단락을 형성하고, 이는 다시 256 토큰 단락에 연결됩니다. 충분히 많은 작은 단락이 부모에 연결되면 해당 단락은 부모 청크로 병합됩니다. 최종 청크는 다시 순위를 매기고 검색됩니다. 이를 통해 동적으로 크기가 조정된 컨텍스트를 사용할 수 있습니다.\n\n코드를 사용하려면 먼저 NLP.yml 파일의 yaml 파일을 사용하여 python_env 폴더 아래에 Python 가상 환경을 생성하십시오. common 폴더 아래 openAI.env 파일에 OpenAI API 키를 추가하십시오. 샘플 데이터는 data 폴더의 Henry.txt에 있지만, 직접 문서를 제공할 수도 있습니다.\n\n기본 파이프라인은 문서를 청킹하고 벡터 데이터베이스에 색인화한 다음 쿼리를 수행하여 유사한 단락을 검색하고 프롬프트로 래핑하여 언어 모델에 보냅니다. 검색된 단락의 원본 소스를 확인할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n문장-창 파이프라인은 문장 수준에서 검색을 수행하여 이전 두 문장과 다음 한 문장을 포함하여 문장을 확장합니다. 다시 순위 지정은 가장 관련성 높은 창을 선택하는 방법을 보여줍니다.\n\n자동 생성 파이프라인은 16에서 256 토큰까지의 통과구조의 계층 구조를 작성하며, 필요에 따라 통과를 더 큰 청크로 병합합니다. 이는 정밀도를 유지하면서 더 긴 문맥을 제공합니다.\n\n이 코드는 연결하고 사용하기 쉽게 설계되어 있습니다. API 키 및 가상 환경을 구성한 후에는 자신의 문서 및 사용 사례에 RAG를 적용할 수 있습니다. 한 번 시도해보시고 다른 궁금한 점이 있으면 알려주세요!\n\n# 참고문헌\n\n<div class=\"content-ad\"></div>\n\n[1] Gao, Y., Xiong, Y., Gao, X., Jia, K., Pan, J., Bi, Y., Dai, Y., Sun, J. and Wang, H., 2023. 대규모 언어 모델을 위한 검색 보완 생성: 조사. arXiv preprint arXiv:2312.10997.\n\n[2] https://github.com/HenryHengLUO/Retrieval-Augmented-Generation-Intro-Project\n\n[3] https://www.llamaindex.ai/\n\n[4] https://learn.deeplearning.ai/building-evaluating-advanced-rag\n\n<div class=\"content-ad\"></div>\n\n# 부록\n\n이 문서는 2024년 1월 27일 GDG 홍콩 AI/ML 스터디 그룹에서 Henry의 발표에 따라 수정 및 재작성되었습니다. 결론적으로 모든 참석자들은 데모에서 웃음을 자아낸 까탈스러운 농담을 외웠습니다: \"Henry is the most pretty boy in Hong Kong.\"\n\nThomas와 Kin이 이 훌륭한 행사를 기획해 준 데에 감사드립니다.\n\n![이미지](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_14.png)\n\n<div class=\"content-ad\"></div>\n\n```Markdown\n![2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_15](/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_15.png)\n```  ","ogImage":{"url":"/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_0.png"},"coverImage":"/assets/img/2024-06-19-IntroofRetrievalAugmentedGenerationRAGandapplicationdemos_0.png","tag":["Tech"],"readingTime":9}],"page":"21","totalPageCount":71,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}