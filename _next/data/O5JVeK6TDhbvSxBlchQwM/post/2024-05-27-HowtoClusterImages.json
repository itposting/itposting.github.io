{"pageProps":{"post":{"title":"이미지를 클러스터링하는 방법","description":"","date":"2024-05-27 12:46","slug":"2024-05-27-HowtoClusterImages","content":"\n\n![FiftyOne](https://miro.medium.com/v2/resize:fit:1400/1*b6uzxatq8ELEOu-1SjMmGg.gif)\n\n# FiftyOne, Scikit-learn 및 Feature Embeddings을 사용하기\n\n2024년 깊은 학습의 계산 집약적인 환경에서 \"클러스터\"라는 단어는 주로 GPU 클러스터를 논할 때 가장 자주 나타납니다. 이는 매우 최적화된 행렬 곱셈 기계의 대규모 컬렉션으로, 동등하게 거대한 생성 모델을 훈련시키기 위해 설정된 것입니다.\n모두가 더 크고 더 나은 모델을 훈련시키고, AI 모델 성능의 한계를 끌어올리며, 최신의 구조적 진보를 자료에 적용하는 데 주력합니다.\n\n그런데 더 나은 모델을 구축하려고 할 때 더 중요할 수 있는 다른 유형의 클러스터가 있는데요. 저는 CPU나 TPU, 또는 다른 어떤 종류의 하드웨어에 대해 언급하는 게 아닙니다. 심지어 모델 훈련 과정에 대해서도 말하는 게 아닙니다. 저는 데이터를 깊이 이해하는 데 도움이 되는 옛날의 비지도 학습 작업인 클러스터링을 말하는 것입니다. 끝내 우리에게 예측력이 흐르는 원천이기 때문이죠.\n\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-05-27-HowtoClusterImages_0.png)\n\nIn this blog, we’ll cover the basics of clustering and show you how to structure your visual data using the open-source machine learning libraries Scikit-learn and FiftyOne!\n\n# What is Clustering?\n\n![Image](/assets/img/2024-05-27-HowtoClusterImages_1.png)\n\n\n<div class=\"content-ad\"></div>\n\n## 클러스터링의 기본 요소\n\n바닥에 펼쳐진 다양한 모양과 크기의 레고 블록이 많이 있다고 상상해보세요. 이제 레고 블록을 정리해야 할 때, 모든 블록을 보관할 충분히 큰 용기가 없다는 것을 깨닫게 됩니다. 운좋게도, 각각이 거의 동일한 수의 조각을 수납할 수 있는 작은 상자 네 개를 찾을 수 있습니다. 단순히 임의로 레고를 각 상자에 넣고 하루를 끝내도 좋습니다. 하지만, 그 다음에 특정 조각을 찾으러 갈 때, 그것을 찾기 위해 꽤나 많은 시간이 걸릴 것입니다.\n\n대신 비슷한 조각을 동일한 상자에 넣는 것이 훨씬 많은 시간과 고민을 덜어줄 것입니다. 그러나 Legos를 어떤 기준으로 상자에 넣을 것입니까? 다른 색깔에 상자를 할당할 것입니까? 아니면 하나의 상자에 모든 네모난 조각을, 다른 하나에는 원형 조각을 넣을 것입니까? 실제 사용하는 Legos에 달렸습니다! 요약하자면, 이것이 클러스터링입니다.\n\n보다 형식적으로 말하면, 클러스터링 또는 군집 분석은 데이터 포인트를 그룹화하기 위한 기술입니다. 클러스터링 알고리즘은 다수의 개체를 입력 받아 각 개체에 대한 할당을 출력합니다. 그러나 분류와 달리 클러스터링은 개체를 사전 설정된 버킷으로 강제로 분류하는 클래스 목록으로 시작하지 않습니다. 오히려 데이터를 통해 주어진 버킷을 발견하려고 시도합니다. 다시 말해, 클러스터링은 데이터에서 구조를 발견하는 데 관한 것이며, 이미 존재하는 구조에서 레이블을 예측하는 것이 아닙니다.\n\n<div class=\"content-ad\"></div>\n\n마지막으로 강조해야 할 점은 클러스터링이 레이블을 예측하는 것과는 관련이 없다는 점입니다. 분류, 탐지 및 분할 작업과는 달리 클러스터링 작업에 대한 'ground truth' 레이블이 없습니다. 이러한 알고리즘을 비지도학습이라고 하며, 지도학습과 자기지도학습과 대비됩니다.\n\n클러스터링은 교육이 필요하지 않습니다. 클러스터링 알고리즘은 데이터 포인트(객체)의 특징을 입력으로 받아 이러한 특징을 사용하여 객체를 그룹으로 분할합니다. 성공적일 때, 이러한 그룹은 독특한 특성을 강조하여 데이터 구조를 파악할 수 있게 해줍니다.\n\n💡 이는 클러스터링이 데이터를 탐색하는 데 매우 강력한 도구임을 의미합니다 - 특히 데이터가 레이블이 없는 경우에 유용합니다!\n\n## 클러스터링은 어떻게 작동합니까?\n\n<div class=\"content-ad\"></div>\n\n주의 깊게 살펴보셨다면 클러스터링과 클러스터링 알고리즘 사이에 섬세한 차이를 발견할 수 있을 겁니다. 이는 클러스터링이 여러 기법을 포괄하는 더 큰 범주이기 때문이에요!\n\n클러스터링 알고리즘은 몇 가지 다른 유형으로 나눠집니다. 이들은 클러스터 멤버십을 할당하는데 사용하는 기준에 의해 구분됩니다. 가장 일반적인 클러스터링 유형 중 일부는 다음과 같아요:\n\n1. 중심 기반 클러스터링: 예를 들어, K-평균 및 평균 변이 클러스터링과 같은 기법들이 속합니다. 이러한 방법들은 각 클러스터를 정의하기 위해 중심점을 찾으려고 합니다. 클러스터 내의 점들 간 일정한 일관성 개념을 최대화하는 중심점을 살펴봐요. 이 클러스터링 유형은 대규모 데이터셋에 잘 확장되지만 이상점과 무작위 초기화에 민감합니다. 종종 여러 번 실행하고 가장 나은 결과를 선택합니다. K-평균과 같은 기법이 고차원 데이터에서 어려움을 겪을 수 있고, 고차원 축소 기법과 함께 사용할 때 구조를 더 잘 발견할 수 있는 것을 발견할 거에요. 아래에서 두 가지를 어떻게 함께 사용하는지 설명하겠습니다.\n\n2. 밀도 기반 클러스터링: DBSCAN, HDBSCAN 및 OPTICS와 같은 기법은 특징 공간이 얼마나 희소하거나 밀집되어 있는지에 기반하여 클러스터를 선택합니다. 개념적으로, 이 알고리즘은 고밀도 영역을 클러스터로 취급하고, 특징 공간에서 포인트가 충분히 퍼져있을 때 클러스터를 분리합니다. DBSCAN과 같이 간단한 밀도 기반 기법은 데이터가 밀접하게 위치하지 않을 수 있는 고차원 데이터에서 작업하는 데 어려움을 겪을 수 있습니다. 그러나 HDBSCAN과 같은 더 정교한 기법은 이러한 한계를 극복하고 고차원 특징에서 탁월한 구조를 발견할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n계층적 군집화: 이러한 기술은 다음 중 하나를 추구합니다:\n\n- 개별 점부터 시작하여 군집을 반복적으로 결합하여 더 큰 복합체를 구성하거나\n- 하나의 군집에 있는 모든 객체로 시작하여 군집을 작은 구성요소로 반복적으로 분할하는 방식\n\n데이터셋이 커질수록 구성기술은 계산적으로 소모적이 되지만, 작고 중간 규모의 데이터셋 및 저차원 특징에 대해서는 성능이 꽤 뛰어날 수 있습니다.\n\n📚 가장 일반적으로 사용되는 10가지 이상의 군집화 알고리즘에 대한 포괄적인 논의를 원한다면, Scikit-learn의 직관적이고 잘 쓰여진 가이드를 확인해보세요!\n\n<div class=\"content-ad\"></div>\n\n## 어떤 기능에 클러스터링 해야 할까요?\n\n우리는 이 글에서 시작한 레고 블록들에 대한 토론 중, 특징들(길이, 너비, 높이, 곡률 등)을 독립적인 엔티티로 생각할 수 있는 데이터 테이블의 열로 볼 수 있습니다. 이 데이터를 정규화하여 각 특징이 다른 특징들을 지배하지 않도록 한 후, 각 레고 블록에 대한 수치값의 행을 특징 벡터로 클러스터링 알고리즘에 전달할 수 있습니다. 클러스터링은 이와 같은 많은 응용 분야를 가졌으며, 가벼운 전처리가 된 수치값이나 시계열 데이터로 작동합니다.\n\n이미지와 같은 구조화되지 않은 데이터는 몇 가지 간단한 이유로 이 프레임워크에 매끄럽게 들어가지 않습니다:\n\n- 이미지는 크기(가로세로 비율과 해상도)가 다를 수 있습니다.\n- 원시 픽셀 값은 매우 노이즈가 있을 수 있습니다.\n- 픽셀 간의 상관 관계는 매우 비선형 일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n우리가 모든 이미지 크기를 재정렬하고 표준화하며, 픽셀 값 정규화를 하고, 노이즈 제거를 하고, 다차원 배열을 \"특성 벡터\"로 평평하게 만들면, 이러한 처리된 픽셀 배열을 특성으로 다루는 것은 비지도 클러스터링 알고리즘에 많은 양의 스트레스를 줄 수 있습니다. 이는 MNIST와 같은 간단한 데이터 세트에 대해서는 작동할 수 있지만, 실제로는 종종 선택사항이 아닙니다.\n\n다행히도, 깊은 신경망이라 불리는 강력한 비선형 함수 근사 도구들이 있습니다! 이미지 도메인에 주목한다면, CLIP 및 DINOv2와 같은 모델이 있습니다. 이러한 모델의 출력은 입력 데이터의 의미 있는 표현이며, 이미지 분류와 같은 특정 작업을 위해 훈련된 모델들도 있습니다. 일반적으로 네트워크의 끝에서 두 번째 층의 출력을 취합니다. 또한 변수적 오토인코더(VAE) 네트워크도 있으며, 일반적으로 중간 층에서 표현을 취하는 것이 일반적입니다!\n\n💡다양한 모델에는 서로 다른 아키텍처가 있으며, 서로 다른 데이터 세트에서 훈련되었으며 서로 다른 작업을 향해 훈련되었습니다. 이러한 모든 요소는 모델이 학습하는 특성의 유형에 영향을 줍니다. 당신의 과제를 해보세요 📚:)\n\n<div class=\"content-ad\"></div>\n\n## 설정 및 설치\n\n지금까지 배경 지식을 살펴보았으니, 그 이론을 실제로 적용하여 비구조적 데이터를 구조화하는 클러스터링 방법을 배워봅시다. 이를 위해 가장 흔한 클러스터링 알고리즘을 구현한 scikit-learn과 unstructured data의 관리 및 시각화를 간소화하는 fiftyone이라는 두 개의 오픈 소스 머신 러닝 라이브러리를 활용할 것입니다:\n\n```js\npip install -U scikit-learn fiftyone\n```\n\nFiftyOne Clustering Plugin은 우리의 일상을 더욱 쉽게 만들어줍니다. 이 플러그인은 scikit-learn의 클러스터링 알고리즘과 이미지 사이의 연결 조직 역할을 하며, FiftyOne App 내에서 간단한 UI로 이러한 작업을 모두 래핑합니다. 플러그인을 CLI에서 설치할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n\nfiftyone 플러그인을 https://github.com/jacobmarks/clustering-plugin 에서 다운로드하세요.\n\n또한 CLIP 모델을 사용하여 이미지 피처를 생성할 수 있게 해주는 OpenAI의 CLIP GitHub 저장소와, 이러한 피처를 2D로 시각화하기 위해 Uniform Manifold Approximation and Projection (UMAP)이라는 차원 축소 기술을 적용할 수 있게 해주는 umap-learn 라이브러리를 두 가지 더 필요로 할 것입니다:\n\n```js\npip install umap-learn git+https://github.com/openai/CLIP.git\n```\n\n이 두 라이브러리가 꼭 필요한 것은 아닙니다. FiftyOne Model Zoo에서 임베딩을 노출하는 임의의 모델로 피처를 생성하고, PCA나 tSNE와 같은 대체 기술로 차원 축소를 수행할 수도 있습니다.\n\n\n\n<div class=\"content-ad\"></div>\n\n필요한 모든 라이브러리를 설치한 후에, Python 프로세스에서 관련 FiftyOne 모듈을 가져와 FiftyOne Dataset Zoo에서 데이터셋을 로드하세요 (또는 원하는 데이터를 사용하세요!). 이 가이드에서는 MS COCO 데이터셋의 검증 분할 (5,000 샘플)을 사용할 것입니다:\n\n```python\nimport fiftyone as fo\nimport fiftyone.brain as fob\nimport fiftyone.zoo as foz\nfrom fiftyone import ViewField as F\n\n# FiftyOne 모듈 import 및 Zoo에서 데이터셋 로드\ndataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\")\n\n# 라벨을 삭제하여 라벨이 없는 데이터로 시작하는 시뮬레이션\ndataset.select_fields().keep_fields()\n\n# 이름 변경하고 데이터베이스에 유지\ndataset.name = \"clustering-demo\"\ndataset.persistent = True\n\n# 데이터셋을 시각화하기 위해 앱 실행\nsession = fo.launch_app(dataset)\n```\n\n만약 Jupyter Notebook에서 작업 중이라면, auto=False를 전달하고 session.url이 가리키는 곳에 브라우저 탭을 열어주세요 (일반적으로 http://localhost:5151/) 앱을 전체 화면에서 볼 수 있습니다.\n\n<img src=\"/assets/img/2024-05-27-HowtoClusterImages_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n## 기능 생성하기\n\n이제 우리가 데이터를 가지고 있으니, 클러스터링에 사용할 기능을 생성해야 합니다. 이 튜토리얼에서는 두 가지 다른 기능을 살펴볼 것입니다: CLIP Vision Transformer에 의해 생성된 512차원 벡터 및 이러한 고차원 벡터를 UMAP 차원 축소 루틴을 통해 실행하여 생성된 2차원 벡터.\n\nFiftyOne 샘플 컬렉션에 차원 축소를 실행하기 위해, FiftyOne Brain의 `compute_visualization()` 함수를 사용할 것입니다. 해당 함수는 method 키워드 인수를 통해 UMAP, PCA 및 tSNE를 지원합니다. 우리는 데이터셋의 `compute_embeddings()` 메서드를 사용하여 CLIP 임베딩을 생성한 다음 이를 명시적으로 차원 축소 루틴에 전달할 수 있습니다. 그러나 대신, `compute_visualization()`에 CLIP로 임베딩을 계산하도록 암시적으로 지시하고 이러한 임베딩을 필드 \"clip_embeddings\"에 저장한 다음 이를 사용하여 2D 표현을 얻을 수 있습니다:\n\n```js\nres = fob.compute_visualization(\n  dataset,\n  (model = \"clip-vit-base32-torch\"),\n  (embeddings = \"clip_embeddings\"),\n  (method = \"umap\"),\n  (brain_key = \"clip_vis\"),\n  (batch_size = 10)\n);\ndataset.set_values(\"clip_umap\", res.current_points);\n```\n\n<div class=\"content-ad\"></div>\n\nbrain_key 인자를 사용하면 이러한 결과에 이름으로 프로그래밍적으로 또는 FiftyOne 앱에서 앞으로 액세스할 수 있습니다. 마지막 줄은 생성된 2D 벡터의 배열을 가져와 데이터셋의 새 필드 \"clip_umap\"에 저장합니다.\n\n앱을 새로 고침하고 Embeddings 패널을 열면 데이터셋의 2D 표현을 볼 수 있습니다. 플롯의 각 점이 단일 이미지에 해당합니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/0*vsnStl9tEHaj90yr.gif)\n\n## 클러스터 계산 및 시각화\n\n<div class=\"content-ad\"></div>\n\n저희의 특징 벡터를 사용하면 FiftyOne 클러스터링 플러그인을 사용하여 데이터에 구조를 부여할 수 있습니다. FiftyOne 앱에서 키보드의 역따옴표 키를 누른 후 compute_clusters를 입력하십시오. 드롭다운 목록에서 항목을 클릭하여 클러스터링 모달을 엽니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*YG-ldErYMMZd8gV2lNSXPA.gif)\n\n클러스터링 실행 결과에 액세스하기 위해 run_key(앞에서 본 brain_key와 유사함)를 입력하십시오. 이렇게 하면 input 폼이 동적으로 업데이트되는 것을 확인할 수 있습니다. 이 시점에서 클러스터링할 특징과 사용할 클러스터링 알고리즘을 선택해야 합니다!\n\n클러스터링 방법으로 \"kmeans\"를 선택하고 특징 벡터로 \"clip_umap\"을 선택하십시오. 클러스터 수를 20으로 설정하고 다른 모든 매개변수는 기본값을 사용하십시오. 엔터 키를 눌러 클러스터링 알고리즘을 실행하십시오. 몇 초만 기다리면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n컴퓨팅이 완료되면 샘플에 새로운 필드가 추가된 것을 알 수 있습니다. 이 필드에는 정수의 문자열 표현이 포함되어 있고, 해당 샘플이 할당된 클러스터를 나타냅니다. 이 값들을 직접 필터링하고 샘플 그리드에서 한 클러스터씩 볼 수 있습니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*mptQ960wfczV7HWhnWC--w.gif)\n\n더 흥미로운 점은 우리의 임베딩 플롯에서 이 클러스터 레이블에 의해 색칠된 것입니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*-vJwIeVRsfFs2y4_DPbzqA.gif)\n\n<div class=\"content-ad\"></div>\n\n클러스터링된 데이터를 이런 식으로 시각화하면 클러스터링 루틴을 간단히 점검할 수 있고 데이터의 구조에 대한 직관적인 시각을 제공할 수 있습니다. 이 예시에서는 테디 베어들의 클러스터가 다른 데이터와 꽤나 잘 분리된 것을 볼 수 있습니다. 또한, 이 클러스터링 루틴은 농장 동물과 코끼리, 얼룩말과 같은 더 이국적인 동물들 사이의 경계를 찾아냈습니다.\n\n이제, 클러스터링 실행을 새로 만들어보세요. 클러스터의 수를 30개로 늘려볼 거에요 (이 새로운 필드에서 임베딩을 색칠하는 걸 잊지 마세요). 약간의 임의성에 따라 (이 루틴의 초기화가 모두 무작위임에 주의하세요), 이제는 코끼리와 얼룩말이 각자의 클러스터를 차지할 가능성이 높아질 것입니다.\n\n초기 클러스터 세트로 돌아와서, 임베딩 플롯에서 마지막 영역 중 하나를 살펴봐봅시다. 축구를 하는 사람들의 이미지 몇 장이 주로 테니스 이미지의 클러스터에 속해있는 것을 확인할 수 있습니다. 이는 2D 차원 축소된 벡터들을 임베딩 벡터 그 자체 대신에 우리의 클러스터링 루틴으로 전달했기 때문입니다. 2D 투영은 시각화에 도움이 되지만, UMAP과 같은 기술은 구조를 상당히 잘 보존하는데, 상대적 거리는 정확히 보존되지 않고 일부 정보가 손실됩니다.\n\n만약 대신 CLIP 임베딩을 직접 클러스터링 계산에 동일한 하이퍼파라미터로 전달한다면, 이러한 축구 이미지들은 다른 축구 이미지와 함께 피리스비나 야구와 같은 다른 필드 스포츠들과 함께 같은 클러스터에 할당됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*2cjbVS8JBKe8CNyyTzBQRQ.gif)\n\n주요 포인트는 고차원 특성이 저차원 특성보다 나은 것도 그 반대도 아니라는 점입니다. 각 선택에는 어떤 대가가 따릅니다. 이것이 다른 기술, 하이퍼파라미터 및 특성을 실험해보아야 하는 이유입니다.\n\n이것을 더 명확하게 보여주기 위해 HDBSCAN을 클러스터링 알고리즘으로 사용해보겠습니다. 이 알고리즘은 클러스터 수를 지정할 수 없게 하며, 대신 min_cluster_size 및 max_cluster_size와 같은 매개변수를 사용하며 클러스터를 병합할 때 기준을 명시합니다. 우리는 CLIP 임베딩을 특성으로 사용할 것이며, 대략적인 시작점으로 10부터 300까지의 요소로 이루어진 클러스터 만 원한다고 말할 것입니다. 클러스터가 너무 크면 도움이 되지 않을 수 있고, 너무 작으면 신호가 아닌 잡음에 반응할 수 있습니다. 특정 값은 물론 데이터셋에 따라 다를 것입니다!\n\n클러스터 레이블에 따라 색을 입히면 결과가 조금 어수선해 보입니다. 그러나 각 클러스터에 대한 이미지를 개별적으로 살펴보면 데이터셋에서 매우 흥미로운 샘플 집합을 식별한 것을 확인할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*hKcCc7r-OCrFsgfwMT-WYA.gif)\n\n💡 HDBSCAN의 경우, 모든 백그라운드 이미지에 \" -1 \" 레이블이 지정됩니다. 이러한 이미지는 최종 클러스터 중 어느 것에도 병합되지 않습니다.\n\n## 클러스터링 실행 추적하기\n\n다양한 피처 조합, 클러스터링 기술 및 하이퍼파라미터를 테스트하면서 특정 군집 세트를 생성하는 데 사용한 \"구성\"을 추적하고 싶을 수 있습니다. 다행히도 FiftyOne Clustering 플러그인은 사용자 지정 실행을 사용하여 이 모든 작업을 처리합니다. 플러그인은 run_key로 실행을 선택하고 모든 실행 매개변수를 앱에서 멋지게 서식이 있는 출력으로 볼 수 있는 get_clustering_run_info 연산자를 노출합니다.\n\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-05-27-HowtoClusterImages_3.png)\n\n데이터셋의 `get_run_info()` 메서드에 run_key를 전달하여 이 정보에 프로그래밍 방식으로 액세스할 수도 있어요!\n\n## GPT-4V로 클러스터 레이블링하기\n\n지금까지 우리의 클러스터는 단지 번호만 있었는데, 이는 우리가 사용한 일종의 정리 수단이에요. 그러나 만약 우리가 데이터셋에서 특정 특성에 따라 클러스터를 형성한다면, 그 특성을 식별하고 샘플을 대강 레이블로 사용해야 할 거에요. 단순하게 우리는 각각의 클러스터를 개별적으로 살펴보고 주어진 클러스터 내의 이미지만 선택하고 시각화해서 클러스터를 직접 태그해 볼 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n혹시… 우리가 모두가 함께 할 수 있는 멀티모달 대형 언어 모델을 사용해보는 건 어떨까요? FiftyOne Clustering 플러그인은 GPT-4V의 멀티모달 이해 능력을 활용하여 각 클러스터에 개념적 레이블을 제공합니다.\n\n이 기능을 사용하려면 OpenAI API 키 환경 변수가 필요합니다(필요한 경우 계정을 생성할 수 있음). 아래와 같이 설정할 수 있습니다:\n\n```js\nexport OPENAI_API_KEY=sk-...\n```\n\n이 기능은 label_clusters_with_gpt4v 연산자를 통해 제공되며, 각 클러스터에서 이미지 다섯 개를 무작위로 선택하여 GPT-4V에 과제별 프롬프트와 함께 공급하고 결과를 처리합니다.\n\n<div class=\"content-ad\"></div>\n\n클러스터의 개수에 따라 (GPT-4V는 느릴 수 있으며, 이는 클러스터 수의 선형적인 비례로 확장됩니다) 작업 실행을 위임하고 싶을 수 있습니다. 이를 위해 운영자 모달에서 상자를 선택하고 다음 명령어를 사용하여 작업을 시작할 수 있습니다:\n\n```js\nfiftyone delegated launch\n```\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*qkTocuUvrFm2ye8nDRuQNA.gif\" />\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n이 워크스루에서는 scikit-learn과 FiftyOne을 사용하여 인기있는 클러스터링 알고리즘과 심층 신경망을 결합하여 비구조화된 데이터에 구조를 부여하는 방법을 다뤘어요. 그 과정에서 특징 벡터, 알고리즘 및 선택하는 하이퍼파라미터가 클러스터링 계산의 최종 결과에 큰 영향을 미칠 수 있다는 점을 알 수 있었어요. 클러스터가 무엇을 선택하고 데이터의 구조를 얼마나 잘 식별하는지에 대해서도 그의 결과가 영향을 줄 수 있어요.\n\n이러한 클러스터링 루틴을 데이터에 적용한 후에 몇 가지 중요한 질문이 생기게 돼요:\n\n- 이러한 클러스터링 실행을 어떻게 양적으로 비교하고 대조할 수 있을까요?\n- 여러 클러스터링 실행에서 얻은 통찰력을 종합하여 데이터를 더 잘 이해하는 데 도움이 될까요?\n- 이러한 통찰력을 활용하여 더 나은 모델을 훈련하는 데 어떻게 사용할까요?\n\n이러한 질문에 답하면 클러스터링의 장점을 누리는 데 도움이 될 거예요. 만약 이 게시물을 즐겼고 이러한 후속 주제를 다루길 원한다면 알려주세요 👋!\n\n<div class=\"content-ad\"></div>\n\n# 다음에는 무엇을 해야 할까요\n\n더 심층적으로 클러스터링 세계로 들어가고 싶다면, 다음 몇 가지 방법을 살펴보세요:\n\n- 임베딩 모델 선택: 이 가이드에서는 CLIP, 시맨틱 기반 모델을 사용했습니다. 허깅페이스의 Transformers 라이브러리나 OpenCLIP와 같은 다른 시맨틱 모델을 사용하면 어떻게 달라지는지 확인해보세요. 또한 ResNet50와 같은 \"픽셀 및 패치\" 컴퓨터 비전 모델이나 DINOv2와 같은 자기 지도 학습 모델을 사용할 때 어떻게 변하는지 살펴보세요.\n- 클러스터링 하이퍼파라미터: 이 가이드에서는 클러스터 수에 거의 손 대지 않았습니다. 이 수를 증가하거나 감소시킬 때 결과가 달라질 수 있습니다. k-평균 클러스터링과 같은 몇 가지 기술에서는 최적의 클러스터 수를 추정하기 위해 사용할 수 있는 휴리스틱이 있습니다. 여기서 멈추지 마시고 다른 하이퍼파라미터들도 실험해보세요!\n- 개념 모델링 기법: 이 가이드에서 제공된 내장 개념 모델링 기법은 GPT-4V와 약간의 가볍게 힌트를 사용하여 각 클러스터의 핵심 개념을 식별합니다. 이것은 오픈 엔드 문제를 다루는 한 가지 방법일 뿐입니다. 이미지 캡션 및 주제 모델링을 사용하거나 자신만의 기법을 만들어보세요!\n\n이 글이 마음에 들었고 FiftyOne의 활기찬 오픈 소스 커뮤니티와 소통하고 싶다면:\n\n<div class=\"content-ad\"></div>\n\n- 🎉 FiftyOne Slack 커뮤니티에 거의 3,000명의 AI 애호가 및 실무자들과 함께 참여해보세요!\n- 🎉 AI 모임 네트워크의 12,000명 이상에 가입하여 다가오는 이벤트에 대한 소식을 받아보세요!\n- 💪 FiftyOne 프로젝트를 오픈소스인 GitHub에서 기여해보세요!\n","ogImage":{"url":"/assets/img/2024-05-27-HowtoClusterImages_0.png"},"coverImage":"/assets/img/2024-05-27-HowtoClusterImages_0.png","tag":["Tech"],"readingTime":13},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*b6uzxatq8ELEOu-1SjMmGg.gif\" alt=\"FiftyOne\"></p>\n<h1>FiftyOne, Scikit-learn 및 Feature Embeddings을 사용하기</h1>\n<p>2024년 깊은 학습의 계산 집약적인 환경에서 \"클러스터\"라는 단어는 주로 GPU 클러스터를 논할 때 가장 자주 나타납니다. 이는 매우 최적화된 행렬 곱셈 기계의 대규모 컬렉션으로, 동등하게 거대한 생성 모델을 훈련시키기 위해 설정된 것입니다.\n모두가 더 크고 더 나은 모델을 훈련시키고, AI 모델 성능의 한계를 끌어올리며, 최신의 구조적 진보를 자료에 적용하는 데 주력합니다.</p>\n<p>그런데 더 나은 모델을 구축하려고 할 때 더 중요할 수 있는 다른 유형의 클러스터가 있는데요. 저는 CPU나 TPU, 또는 다른 어떤 종류의 하드웨어에 대해 언급하는 게 아닙니다. 심지어 모델 훈련 과정에 대해서도 말하는 게 아닙니다. 저는 데이터를 깊이 이해하는 데 도움이 되는 옛날의 비지도 학습 작업인 클러스터링을 말하는 것입니다. 끝내 우리에게 예측력이 흐르는 원천이기 때문이죠.</p>\n<p><img src=\"/assets/img/2024-05-27-HowtoClusterImages_0.png\" alt=\"Image\"></p>\n<p>In this blog, we’ll cover the basics of clustering and show you how to structure your visual data using the open-source machine learning libraries Scikit-learn and FiftyOne!</p>\n<h1>What is Clustering?</h1>\n<p><img src=\"/assets/img/2024-05-27-HowtoClusterImages_1.png\" alt=\"Image\"></p>\n<h2>클러스터링의 기본 요소</h2>\n<p>바닥에 펼쳐진 다양한 모양과 크기의 레고 블록이 많이 있다고 상상해보세요. 이제 레고 블록을 정리해야 할 때, 모든 블록을 보관할 충분히 큰 용기가 없다는 것을 깨닫게 됩니다. 운좋게도, 각각이 거의 동일한 수의 조각을 수납할 수 있는 작은 상자 네 개를 찾을 수 있습니다. 단순히 임의로 레고를 각 상자에 넣고 하루를 끝내도 좋습니다. 하지만, 그 다음에 특정 조각을 찾으러 갈 때, 그것을 찾기 위해 꽤나 많은 시간이 걸릴 것입니다.</p>\n<p>대신 비슷한 조각을 동일한 상자에 넣는 것이 훨씬 많은 시간과 고민을 덜어줄 것입니다. 그러나 Legos를 어떤 기준으로 상자에 넣을 것입니까? 다른 색깔에 상자를 할당할 것입니까? 아니면 하나의 상자에 모든 네모난 조각을, 다른 하나에는 원형 조각을 넣을 것입니까? 실제 사용하는 Legos에 달렸습니다! 요약하자면, 이것이 클러스터링입니다.</p>\n<p>보다 형식적으로 말하면, 클러스터링 또는 군집 분석은 데이터 포인트를 그룹화하기 위한 기술입니다. 클러스터링 알고리즘은 다수의 개체를 입력 받아 각 개체에 대한 할당을 출력합니다. 그러나 분류와 달리 클러스터링은 개체를 사전 설정된 버킷으로 강제로 분류하는 클래스 목록으로 시작하지 않습니다. 오히려 데이터를 통해 주어진 버킷을 발견하려고 시도합니다. 다시 말해, 클러스터링은 데이터에서 구조를 발견하는 데 관한 것이며, 이미 존재하는 구조에서 레이블을 예측하는 것이 아닙니다.</p>\n<p>마지막으로 강조해야 할 점은 클러스터링이 레이블을 예측하는 것과는 관련이 없다는 점입니다. 분류, 탐지 및 분할 작업과는 달리 클러스터링 작업에 대한 'ground truth' 레이블이 없습니다. 이러한 알고리즘을 비지도학습이라고 하며, 지도학습과 자기지도학습과 대비됩니다.</p>\n<p>클러스터링은 교육이 필요하지 않습니다. 클러스터링 알고리즘은 데이터 포인트(객체)의 특징을 입력으로 받아 이러한 특징을 사용하여 객체를 그룹으로 분할합니다. 성공적일 때, 이러한 그룹은 독특한 특성을 강조하여 데이터 구조를 파악할 수 있게 해줍니다.</p>\n<p>💡 이는 클러스터링이 데이터를 탐색하는 데 매우 강력한 도구임을 의미합니다 - 특히 데이터가 레이블이 없는 경우에 유용합니다!</p>\n<h2>클러스터링은 어떻게 작동합니까?</h2>\n<p>주의 깊게 살펴보셨다면 클러스터링과 클러스터링 알고리즘 사이에 섬세한 차이를 발견할 수 있을 겁니다. 이는 클러스터링이 여러 기법을 포괄하는 더 큰 범주이기 때문이에요!</p>\n<p>클러스터링 알고리즘은 몇 가지 다른 유형으로 나눠집니다. 이들은 클러스터 멤버십을 할당하는데 사용하는 기준에 의해 구분됩니다. 가장 일반적인 클러스터링 유형 중 일부는 다음과 같아요:</p>\n<ol>\n<li>\n<p>중심 기반 클러스터링: 예를 들어, K-평균 및 평균 변이 클러스터링과 같은 기법들이 속합니다. 이러한 방법들은 각 클러스터를 정의하기 위해 중심점을 찾으려고 합니다. 클러스터 내의 점들 간 일정한 일관성 개념을 최대화하는 중심점을 살펴봐요. 이 클러스터링 유형은 대규모 데이터셋에 잘 확장되지만 이상점과 무작위 초기화에 민감합니다. 종종 여러 번 실행하고 가장 나은 결과를 선택합니다. K-평균과 같은 기법이 고차원 데이터에서 어려움을 겪을 수 있고, 고차원 축소 기법과 함께 사용할 때 구조를 더 잘 발견할 수 있는 것을 발견할 거에요. 아래에서 두 가지를 어떻게 함께 사용하는지 설명하겠습니다.</p>\n</li>\n<li>\n<p>밀도 기반 클러스터링: DBSCAN, HDBSCAN 및 OPTICS와 같은 기법은 특징 공간이 얼마나 희소하거나 밀집되어 있는지에 기반하여 클러스터를 선택합니다. 개념적으로, 이 알고리즘은 고밀도 영역을 클러스터로 취급하고, 특징 공간에서 포인트가 충분히 퍼져있을 때 클러스터를 분리합니다. DBSCAN과 같이 간단한 밀도 기반 기법은 데이터가 밀접하게 위치하지 않을 수 있는 고차원 데이터에서 작업하는 데 어려움을 겪을 수 있습니다. 그러나 HDBSCAN과 같은 더 정교한 기법은 이러한 한계를 극복하고 고차원 특징에서 탁월한 구조를 발견할 수 있어요.</p>\n</li>\n</ol>\n<p>계층적 군집화: 이러한 기술은 다음 중 하나를 추구합니다:</p>\n<ul>\n<li>개별 점부터 시작하여 군집을 반복적으로 결합하여 더 큰 복합체를 구성하거나</li>\n<li>하나의 군집에 있는 모든 객체로 시작하여 군집을 작은 구성요소로 반복적으로 분할하는 방식</li>\n</ul>\n<p>데이터셋이 커질수록 구성기술은 계산적으로 소모적이 되지만, 작고 중간 규모의 데이터셋 및 저차원 특징에 대해서는 성능이 꽤 뛰어날 수 있습니다.</p>\n<p>📚 가장 일반적으로 사용되는 10가지 이상의 군집화 알고리즘에 대한 포괄적인 논의를 원한다면, Scikit-learn의 직관적이고 잘 쓰여진 가이드를 확인해보세요!</p>\n<h2>어떤 기능에 클러스터링 해야 할까요?</h2>\n<p>우리는 이 글에서 시작한 레고 블록들에 대한 토론 중, 특징들(길이, 너비, 높이, 곡률 등)을 독립적인 엔티티로 생각할 수 있는 데이터 테이블의 열로 볼 수 있습니다. 이 데이터를 정규화하여 각 특징이 다른 특징들을 지배하지 않도록 한 후, 각 레고 블록에 대한 수치값의 행을 특징 벡터로 클러스터링 알고리즘에 전달할 수 있습니다. 클러스터링은 이와 같은 많은 응용 분야를 가졌으며, 가벼운 전처리가 된 수치값이나 시계열 데이터로 작동합니다.</p>\n<p>이미지와 같은 구조화되지 않은 데이터는 몇 가지 간단한 이유로 이 프레임워크에 매끄럽게 들어가지 않습니다:</p>\n<ul>\n<li>이미지는 크기(가로세로 비율과 해상도)가 다를 수 있습니다.</li>\n<li>원시 픽셀 값은 매우 노이즈가 있을 수 있습니다.</li>\n<li>픽셀 간의 상관 관계는 매우 비선형 일 수 있습니다.</li>\n</ul>\n<p>우리가 모든 이미지 크기를 재정렬하고 표준화하며, 픽셀 값 정규화를 하고, 노이즈 제거를 하고, 다차원 배열을 \"특성 벡터\"로 평평하게 만들면, 이러한 처리된 픽셀 배열을 특성으로 다루는 것은 비지도 클러스터링 알고리즘에 많은 양의 스트레스를 줄 수 있습니다. 이는 MNIST와 같은 간단한 데이터 세트에 대해서는 작동할 수 있지만, 실제로는 종종 선택사항이 아닙니다.</p>\n<p>다행히도, 깊은 신경망이라 불리는 강력한 비선형 함수 근사 도구들이 있습니다! 이미지 도메인에 주목한다면, CLIP 및 DINOv2와 같은 모델이 있습니다. 이러한 모델의 출력은 입력 데이터의 의미 있는 표현이며, 이미지 분류와 같은 특정 작업을 위해 훈련된 모델들도 있습니다. 일반적으로 네트워크의 끝에서 두 번째 층의 출력을 취합니다. 또한 변수적 오토인코더(VAE) 네트워크도 있으며, 일반적으로 중간 층에서 표현을 취하는 것이 일반적입니다!</p>\n<p>💡다양한 모델에는 서로 다른 아키텍처가 있으며, 서로 다른 데이터 세트에서 훈련되었으며 서로 다른 작업을 향해 훈련되었습니다. 이러한 모든 요소는 모델이 학습하는 특성의 유형에 영향을 줍니다. 당신의 과제를 해보세요 📚:)</p>\n<h2>설정 및 설치</h2>\n<p>지금까지 배경 지식을 살펴보았으니, 그 이론을 실제로 적용하여 비구조적 데이터를 구조화하는 클러스터링 방법을 배워봅시다. 이를 위해 가장 흔한 클러스터링 알고리즘을 구현한 scikit-learn과 unstructured data의 관리 및 시각화를 간소화하는 fiftyone이라는 두 개의 오픈 소스 머신 러닝 라이브러리를 활용할 것입니다:</p>\n<pre><code class=\"hljs language-js\">pip install -U scikit-learn fiftyone\n</code></pre>\n<p>FiftyOne Clustering Plugin은 우리의 일상을 더욱 쉽게 만들어줍니다. 이 플러그인은 scikit-learn의 클러스터링 알고리즘과 이미지 사이의 연결 조직 역할을 하며, FiftyOne App 내에서 간단한 UI로 이러한 작업을 모두 래핑합니다. 플러그인을 CLI에서 설치할 수 있습니다:</p>\n<p>fiftyone 플러그인을 <a href=\"https://github.com/jacobmarks/clustering-plugin\" rel=\"nofollow\" target=\"_blank\">https://github.com/jacobmarks/clustering-plugin</a> 에서 다운로드하세요.</p>\n<p>또한 CLIP 모델을 사용하여 이미지 피처를 생성할 수 있게 해주는 OpenAI의 CLIP GitHub 저장소와, 이러한 피처를 2D로 시각화하기 위해 Uniform Manifold Approximation and Projection (UMAP)이라는 차원 축소 기술을 적용할 수 있게 해주는 umap-learn 라이브러리를 두 가지 더 필요로 할 것입니다:</p>\n<pre><code class=\"hljs language-js\">pip install umap-learn git+<span class=\"hljs-attr\">https</span>:<span class=\"hljs-comment\">//github.com/openai/CLIP.git</span>\n</code></pre>\n<p>이 두 라이브러리가 꼭 필요한 것은 아닙니다. FiftyOne Model Zoo에서 임베딩을 노출하는 임의의 모델로 피처를 생성하고, PCA나 tSNE와 같은 대체 기술로 차원 축소를 수행할 수도 있습니다.</p>\n<p>필요한 모든 라이브러리를 설치한 후에, Python 프로세스에서 관련 FiftyOne 모듈을 가져와 FiftyOne Dataset Zoo에서 데이터셋을 로드하세요 (또는 원하는 데이터를 사용하세요!). 이 가이드에서는 MS COCO 데이터셋의 검증 분할 (5,000 샘플)을 사용할 것입니다:</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> fiftyone <span class=\"hljs-keyword\">as</span> fo\n<span class=\"hljs-keyword\">import</span> fiftyone.brain <span class=\"hljs-keyword\">as</span> fob\n<span class=\"hljs-keyword\">import</span> fiftyone.zoo <span class=\"hljs-keyword\">as</span> foz\n<span class=\"hljs-keyword\">from</span> fiftyone <span class=\"hljs-keyword\">import</span> ViewField <span class=\"hljs-keyword\">as</span> F\n\n<span class=\"hljs-comment\"># FiftyOne 모듈 import 및 Zoo에서 데이터셋 로드</span>\ndataset = foz.load_zoo_dataset(<span class=\"hljs-string\">\"coco-2017\"</span>, split=<span class=\"hljs-string\">\"validation\"</span>)\n\n<span class=\"hljs-comment\"># 라벨을 삭제하여 라벨이 없는 데이터로 시작하는 시뮬레이션</span>\ndataset.select_fields().keep_fields()\n\n<span class=\"hljs-comment\"># 이름 변경하고 데이터베이스에 유지</span>\ndataset.name = <span class=\"hljs-string\">\"clustering-demo\"</span>\ndataset.persistent = <span class=\"hljs-literal\">True</span>\n\n<span class=\"hljs-comment\"># 데이터셋을 시각화하기 위해 앱 실행</span>\nsession = fo.launch_app(dataset)\n</code></pre>\n<p>만약 Jupyter Notebook에서 작업 중이라면, auto=False를 전달하고 session.url이 가리키는 곳에 브라우저 탭을 열어주세요 (일반적으로 <a href=\"http://localhost:5151/\" rel=\"nofollow\" target=\"_blank\">http://localhost:5151/</a>) 앱을 전체 화면에서 볼 수 있습니다.</p>\n<h2>기능 생성하기</h2>\n<p>이제 우리가 데이터를 가지고 있으니, 클러스터링에 사용할 기능을 생성해야 합니다. 이 튜토리얼에서는 두 가지 다른 기능을 살펴볼 것입니다: CLIP Vision Transformer에 의해 생성된 512차원 벡터 및 이러한 고차원 벡터를 UMAP 차원 축소 루틴을 통해 실행하여 생성된 2차원 벡터.</p>\n<p>FiftyOne 샘플 컬렉션에 차원 축소를 실행하기 위해, FiftyOne Brain의 <code>compute_visualization()</code> 함수를 사용할 것입니다. 해당 함수는 method 키워드 인수를 통해 UMAP, PCA 및 tSNE를 지원합니다. 우리는 데이터셋의 <code>compute_embeddings()</code> 메서드를 사용하여 CLIP 임베딩을 생성한 다음 이를 명시적으로 차원 축소 루틴에 전달할 수 있습니다. 그러나 대신, <code>compute_visualization()</code>에 CLIP로 임베딩을 계산하도록 암시적으로 지시하고 이러한 임베딩을 필드 \"clip_embeddings\"에 저장한 다음 이를 사용하여 2D 표현을 얻을 수 있습니다:</p>\n<pre><code class=\"hljs language-js\">res = fob.<span class=\"hljs-title function_\">compute_visualization</span>(\n  dataset,\n  (model = <span class=\"hljs-string\">\"clip-vit-base32-torch\"</span>),\n  (embeddings = <span class=\"hljs-string\">\"clip_embeddings\"</span>),\n  (method = <span class=\"hljs-string\">\"umap\"</span>),\n  (brain_key = <span class=\"hljs-string\">\"clip_vis\"</span>),\n  (batch_size = <span class=\"hljs-number\">10</span>)\n);\ndataset.<span class=\"hljs-title function_\">set_values</span>(<span class=\"hljs-string\">\"clip_umap\"</span>, res.<span class=\"hljs-property\">current_points</span>);\n</code></pre>\n<p>brain_key 인자를 사용하면 이러한 결과에 이름으로 프로그래밍적으로 또는 FiftyOne 앱에서 앞으로 액세스할 수 있습니다. 마지막 줄은 생성된 2D 벡터의 배열을 가져와 데이터셋의 새 필드 \"clip_umap\"에 저장합니다.</p>\n<p>앱을 새로 고침하고 Embeddings 패널을 열면 데이터셋의 2D 표현을 볼 수 있습니다. 플롯의 각 점이 단일 이미지에 해당합니다:</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/0*vsnStl9tEHaj90yr.gif\" alt=\"이미지\"></p>\n<h2>클러스터 계산 및 시각화</h2>\n<p>저희의 특징 벡터를 사용하면 FiftyOne 클러스터링 플러그인을 사용하여 데이터에 구조를 부여할 수 있습니다. FiftyOne 앱에서 키보드의 역따옴표 키를 누른 후 compute_clusters를 입력하십시오. 드롭다운 목록에서 항목을 클릭하여 클러스터링 모달을 엽니다.</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*YG-ldErYMMZd8gV2lNSXPA.gif\" alt=\"이미지\"></p>\n<p>클러스터링 실행 결과에 액세스하기 위해 run_key(앞에서 본 brain_key와 유사함)를 입력하십시오. 이렇게 하면 input 폼이 동적으로 업데이트되는 것을 확인할 수 있습니다. 이 시점에서 클러스터링할 특징과 사용할 클러스터링 알고리즘을 선택해야 합니다!</p>\n<p>클러스터링 방법으로 \"kmeans\"를 선택하고 특징 벡터로 \"clip_umap\"을 선택하십시오. 클러스터 수를 20으로 설정하고 다른 모든 매개변수는 기본값을 사용하십시오. 엔터 키를 눌러 클러스터링 알고리즘을 실행하십시오. 몇 초만 기다리면 됩니다.</p>\n<p>컴퓨팅이 완료되면 샘플에 새로운 필드가 추가된 것을 알 수 있습니다. 이 필드에는 정수의 문자열 표현이 포함되어 있고, 해당 샘플이 할당된 클러스터를 나타냅니다. 이 값들을 직접 필터링하고 샘플 그리드에서 한 클러스터씩 볼 수 있습니다:</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*mptQ960wfczV7HWhnWC--w.gif\" alt=\"이미지\"></p>\n<p>더 흥미로운 점은 우리의 임베딩 플롯에서 이 클러스터 레이블에 의해 색칠된 것입니다:</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*-vJwIeVRsfFs2y4_DPbzqA.gif\" alt=\"이미지\"></p>\n<p>클러스터링된 데이터를 이런 식으로 시각화하면 클러스터링 루틴을 간단히 점검할 수 있고 데이터의 구조에 대한 직관적인 시각을 제공할 수 있습니다. 이 예시에서는 테디 베어들의 클러스터가 다른 데이터와 꽤나 잘 분리된 것을 볼 수 있습니다. 또한, 이 클러스터링 루틴은 농장 동물과 코끼리, 얼룩말과 같은 더 이국적인 동물들 사이의 경계를 찾아냈습니다.</p>\n<p>이제, 클러스터링 실행을 새로 만들어보세요. 클러스터의 수를 30개로 늘려볼 거에요 (이 새로운 필드에서 임베딩을 색칠하는 걸 잊지 마세요). 약간의 임의성에 따라 (이 루틴의 초기화가 모두 무작위임에 주의하세요), 이제는 코끼리와 얼룩말이 각자의 클러스터를 차지할 가능성이 높아질 것입니다.</p>\n<p>초기 클러스터 세트로 돌아와서, 임베딩 플롯에서 마지막 영역 중 하나를 살펴봐봅시다. 축구를 하는 사람들의 이미지 몇 장이 주로 테니스 이미지의 클러스터에 속해있는 것을 확인할 수 있습니다. 이는 2D 차원 축소된 벡터들을 임베딩 벡터 그 자체 대신에 우리의 클러스터링 루틴으로 전달했기 때문입니다. 2D 투영은 시각화에 도움이 되지만, UMAP과 같은 기술은 구조를 상당히 잘 보존하는데, 상대적 거리는 정확히 보존되지 않고 일부 정보가 손실됩니다.</p>\n<p>만약 대신 CLIP 임베딩을 직접 클러스터링 계산에 동일한 하이퍼파라미터로 전달한다면, 이러한 축구 이미지들은 다른 축구 이미지와 함께 피리스비나 야구와 같은 다른 필드 스포츠들과 함께 같은 클러스터에 할당됩니다.</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*2cjbVS8JBKe8CNyyTzBQRQ.gif\" alt=\"image\"></p>\n<p>주요 포인트는 고차원 특성이 저차원 특성보다 나은 것도 그 반대도 아니라는 점입니다. 각 선택에는 어떤 대가가 따릅니다. 이것이 다른 기술, 하이퍼파라미터 및 특성을 실험해보아야 하는 이유입니다.</p>\n<p>이것을 더 명확하게 보여주기 위해 HDBSCAN을 클러스터링 알고리즘으로 사용해보겠습니다. 이 알고리즘은 클러스터 수를 지정할 수 없게 하며, 대신 min_cluster_size 및 max_cluster_size와 같은 매개변수를 사용하며 클러스터를 병합할 때 기준을 명시합니다. 우리는 CLIP 임베딩을 특성으로 사용할 것이며, 대략적인 시작점으로 10부터 300까지의 요소로 이루어진 클러스터 만 원한다고 말할 것입니다. 클러스터가 너무 크면 도움이 되지 않을 수 있고, 너무 작으면 신호가 아닌 잡음에 반응할 수 있습니다. 특정 값은 물론 데이터셋에 따라 다를 것입니다!</p>\n<p>클러스터 레이블에 따라 색을 입히면 결과가 조금 어수선해 보입니다. 그러나 각 클러스터에 대한 이미지를 개별적으로 살펴보면 데이터셋에서 매우 흥미로운 샘플 집합을 식별한 것을 확인할 수 있습니다.</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*hKcCc7r-OCrFsgfwMT-WYA.gif\" alt=\"이미지\"></p>\n<p>💡 HDBSCAN의 경우, 모든 백그라운드 이미지에 \" -1 \" 레이블이 지정됩니다. 이러한 이미지는 최종 클러스터 중 어느 것에도 병합되지 않습니다.</p>\n<h2>클러스터링 실행 추적하기</h2>\n<p>다양한 피처 조합, 클러스터링 기술 및 하이퍼파라미터를 테스트하면서 특정 군집 세트를 생성하는 데 사용한 \"구성\"을 추적하고 싶을 수 있습니다. 다행히도 FiftyOne Clustering 플러그인은 사용자 지정 실행을 사용하여 이 모든 작업을 처리합니다. 플러그인은 run_key로 실행을 선택하고 모든 실행 매개변수를 앱에서 멋지게 서식이 있는 출력으로 볼 수 있는 get_clustering_run_info 연산자를 노출합니다.</p>\n<p><img src=\"/assets/img/2024-05-27-HowtoClusterImages_3.png\" alt=\"이미지\"></p>\n<p>데이터셋의 <code>get_run_info()</code> 메서드에 run_key를 전달하여 이 정보에 프로그래밍 방식으로 액세스할 수도 있어요!</p>\n<h2>GPT-4V로 클러스터 레이블링하기</h2>\n<p>지금까지 우리의 클러스터는 단지 번호만 있었는데, 이는 우리가 사용한 일종의 정리 수단이에요. 그러나 만약 우리가 데이터셋에서 특정 특성에 따라 클러스터를 형성한다면, 그 특성을 식별하고 샘플을 대강 레이블로 사용해야 할 거에요. 단순하게 우리는 각각의 클러스터를 개별적으로 살펴보고 주어진 클러스터 내의 이미지만 선택하고 시각화해서 클러스터를 직접 태그해 볼 수 있어요.</p>\n<p>혹시… 우리가 모두가 함께 할 수 있는 멀티모달 대형 언어 모델을 사용해보는 건 어떨까요? FiftyOne Clustering 플러그인은 GPT-4V의 멀티모달 이해 능력을 활용하여 각 클러스터에 개념적 레이블을 제공합니다.</p>\n<p>이 기능을 사용하려면 OpenAI API 키 환경 변수가 필요합니다(필요한 경우 계정을 생성할 수 있음). 아래와 같이 설정할 수 있습니다:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">export</span> <span class=\"hljs-variable constant_\">OPENAI_API_KEY</span>=sk-...\n</code></pre>\n<p>이 기능은 label_clusters_with_gpt4v 연산자를 통해 제공되며, 각 클러스터에서 이미지 다섯 개를 무작위로 선택하여 GPT-4V에 과제별 프롬프트와 함께 공급하고 결과를 처리합니다.</p>\n<p>클러스터의 개수에 따라 (GPT-4V는 느릴 수 있으며, 이는 클러스터 수의 선형적인 비례로 확장됩니다) 작업 실행을 위임하고 싶을 수 있습니다. 이를 위해 운영자 모달에서 상자를 선택하고 다음 명령어를 사용하여 작업을 시작할 수 있습니다:</p>\n<pre><code class=\"hljs language-js\">fiftyone delegated launch\n</code></pre>\n<h1>결론</h1>\n<p>이 워크스루에서는 scikit-learn과 FiftyOne을 사용하여 인기있는 클러스터링 알고리즘과 심층 신경망을 결합하여 비구조화된 데이터에 구조를 부여하는 방법을 다뤘어요. 그 과정에서 특징 벡터, 알고리즘 및 선택하는 하이퍼파라미터가 클러스터링 계산의 최종 결과에 큰 영향을 미칠 수 있다는 점을 알 수 있었어요. 클러스터가 무엇을 선택하고 데이터의 구조를 얼마나 잘 식별하는지에 대해서도 그의 결과가 영향을 줄 수 있어요.</p>\n<p>이러한 클러스터링 루틴을 데이터에 적용한 후에 몇 가지 중요한 질문이 생기게 돼요:</p>\n<ul>\n<li>이러한 클러스터링 실행을 어떻게 양적으로 비교하고 대조할 수 있을까요?</li>\n<li>여러 클러스터링 실행에서 얻은 통찰력을 종합하여 데이터를 더 잘 이해하는 데 도움이 될까요?</li>\n<li>이러한 통찰력을 활용하여 더 나은 모델을 훈련하는 데 어떻게 사용할까요?</li>\n</ul>\n<p>이러한 질문에 답하면 클러스터링의 장점을 누리는 데 도움이 될 거예요. 만약 이 게시물을 즐겼고 이러한 후속 주제를 다루길 원한다면 알려주세요 👋!</p>\n<h1>다음에는 무엇을 해야 할까요</h1>\n<p>더 심층적으로 클러스터링 세계로 들어가고 싶다면, 다음 몇 가지 방법을 살펴보세요:</p>\n<ul>\n<li>임베딩 모델 선택: 이 가이드에서는 CLIP, 시맨틱 기반 모델을 사용했습니다. 허깅페이스의 Transformers 라이브러리나 OpenCLIP와 같은 다른 시맨틱 모델을 사용하면 어떻게 달라지는지 확인해보세요. 또한 ResNet50와 같은 \"픽셀 및 패치\" 컴퓨터 비전 모델이나 DINOv2와 같은 자기 지도 학습 모델을 사용할 때 어떻게 변하는지 살펴보세요.</li>\n<li>클러스터링 하이퍼파라미터: 이 가이드에서는 클러스터 수에 거의 손 대지 않았습니다. 이 수를 증가하거나 감소시킬 때 결과가 달라질 수 있습니다. k-평균 클러스터링과 같은 몇 가지 기술에서는 최적의 클러스터 수를 추정하기 위해 사용할 수 있는 휴리스틱이 있습니다. 여기서 멈추지 마시고 다른 하이퍼파라미터들도 실험해보세요!</li>\n<li>개념 모델링 기법: 이 가이드에서 제공된 내장 개념 모델링 기법은 GPT-4V와 약간의 가볍게 힌트를 사용하여 각 클러스터의 핵심 개념을 식별합니다. 이것은 오픈 엔드 문제를 다루는 한 가지 방법일 뿐입니다. 이미지 캡션 및 주제 모델링을 사용하거나 자신만의 기법을 만들어보세요!</li>\n</ul>\n<p>이 글이 마음에 들었고 FiftyOne의 활기찬 오픈 소스 커뮤니티와 소통하고 싶다면:</p>\n<ul>\n<li>🎉 FiftyOne Slack 커뮤니티에 거의 3,000명의 AI 애호가 및 실무자들과 함께 참여해보세요!</li>\n<li>🎉 AI 모임 네트워크의 12,000명 이상에 가입하여 다가오는 이벤트에 대한 소식을 받아보세요!</li>\n<li>💪 FiftyOne 프로젝트를 오픈소스인 GitHub에서 기여해보세요!</li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}