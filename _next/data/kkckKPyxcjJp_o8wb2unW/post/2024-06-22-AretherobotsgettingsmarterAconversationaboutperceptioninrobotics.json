{"pageProps":{"post":{"title":"로봇은 더 똑똑해지고 있을까 로봇 공학에서 인식에 대한 대화","description":"","date":"2024-06-22 19:41","slug":"2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics","content":"\n\n이 기사는 보통 여기서 하는 시리즈와는 별도로 됩니다. 이젠 대화를 나누는 것처럼 얘기하는 걸 좋아합니다 (하지만 전 며칠 동안 계속 말을 할 거에요 ㅋㅋ). 그래서 당신이 좋아하는 음료를 준비하고 로봇과 그들이 얼마나 \"똑똑\"해졌는지에 대해 이야기해봐요.\n\n![로봇](/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_0.png)\n\n지난 달들에 로봇이 놀라운 일들을 하는 비디오를 보셨을 것입니다. 그런 비디오를 보면서 \"와, 이건 놀라워. 이제 로봇들이 이것을 할 수 있나? 그들은 매일 더 똑똑해지고 있어\"라고 생각했을 수 있어요. 예를 들면, Figure 01 인간형 로봇이 물체를 다루는 모습이나 Scythe 로봇이 자율적으로 잔디를 자르는 것 등이 있습니다.\n\n여기서 잠깐 멈추고 로봇의 인식 관점에서 관련 두 가지 문제, 동시 위치 추정 및 지도 작성(SLAM) 그리고 빈 피킹(bin picking)을 바라봅시다.\n\n<div class=\"content-ad\"></div>\n\n## 로봇의 과거와 현재의 인식\n\n우선, 로봇 공학 분야에서 \"인식\"이란 무엇인가요? 모르는 분을 위해 설명드리자면, 로봇의 카메라, LiDAR, 레이더 또는 접촉 센서와 같은 다양한 센서를 사용해 환경을 감지하고 해석하는 능력을 의미합니다. 환경에 대한 유용한 정보를 추출하기 위해 센서 데이터를 수집하고 처리하는 것을 포함합니다.\n\n인식은 로봋의 SLAM에 매우 중요합니다. 다시 말씀드리면, 동시 위치 추정 및 지도 작성(SLAM)은 로봇 공학에서 기본적인 문제입니다. 이는 로봇이 알 수 없는 환경을 탐색하면서 동시에 그 환경의 지도를 작성하고 그 안에서 자신의 위치를 판단하는 것을 의미합니다.\n\n2016년에 Cadena와 다른 저자들은 \"동시 위치 및 지도 작성의 과거, 현재 및 미래: 견고한 인식 시대를 향하여\"라는 과학 논문을 발표했습니다. 그들의 연구에서는 SLAM 분야에서 30년 이상의 작업을 검토하고, 이를 고전적 시대(1986-2004), 알고리즘 분석 시대(2004-2015), 그리고 견고한 인식 시대(2015-현재)로 그룹화했습니다. 각 시대를 간단히 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n고전 시대:\n이것은 Extended Kalman Filters, Rao-Blackwellized Particle Filters 및 최대 우도 추정을 사용하여 SLAM이 불확실성을 처리하는 주요 방법을 소개합니다. 또한 모든 것이 원활하게 작동하고 올바른 데이터 조각을 연결하는 데 필요한 기본 도전에 대해 이야기합니다.이 시대의 SLAM의 두 가지 예는 아래에 나와 있습니다.\n\n![image](/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_1.png)\n\n일반적으로, 첫 번째 제안된 SLAM 시스템은 환경에서 장애물을 감지하고 맵에 표현할 수 있었습니다. 맵핑에 사용된 가장 인기 있는 센서는 초음파 및 LiDAR였습니다.\n\n알고리즘 분석 시대:\n연구자들은 SLAM의 기본 기능인 시간이 지남에 따른 위치 추적이 얼마나 잘되는지, 신뢰할 수 있는지, 그리고 대량의 데이터를 어떻게 처리하는지 등을 조사했습니다. 드문 데이터가 SLAM이 더 빠르고 더 잘 작동하게 하는 것을 발견했습니다. 이때 무료로 사용할 수 있는 주요 SLAM 소프트웨어인 Gmapping 및 ORB-SLAM을 만들기 시작했습니다.\n\n<div class=\"content-ad\"></div>\n\n![그림](/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_2.png)\n\n이전 시대의 기초를 활용하여 이 시대에는 카메라와 다른 시각 센서들이 보다 인기를 끌게 되었으며, \"Visual-SLAM\"이라는 용어가 제안되었습니다. 게다가 커뮤니티는 3D 환경 표현을 이용한 다양한 SLAM 기술을 소개했습니다.\n\n로버스트-인식 시대:\nSLAM 시스템은 단순히 형상을 매핑하는 것을 넘어, 환경에 대한 고수준의 이해를 얻기 위해 기하학적 재구성을 위해 높은 수준의 고려를 합니다. 물체의 의미(의미론)나 관련된 물리학적 측면과 같은 것들을 고려합니다. 당사자가 수행해야 하는 작업에 맞게 로봇이 필요한 세부 사항에 초점을 맞추어 센서 데이터에서 추가 잡음을 걸러내어 로봇이 작업을 성취하는 데 도움을 줍니다. 로봇이 수행해야 할 작업에 따라 맵을 조정합니다.\n\n이 애니메이션 이미지를 자세히 살펴보면 많은 세부 사항을 알 수 있습니다. 장면 속 물체는 환경의 일부로 이해되며, 같은 클래스의 물체는 경계 상자에서 동일한 색으로 레이블이 지정되며, LiDAR 및 레이더의 3D 데이터는 카메라의 2D 이미지와 결합됩니다. 게다가 다양한 물체가 결합되어 장면으로부터 더 많은 정보를 추출하는데 활용됩니다. 마지막 애니메이션 이미지에서와 같이 흰색 차량과 그의 깜박임등, 후방등, 브레이크 라이트 등이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 빈 피킹에서의 인식\n\n빈 피킹은 컴퓨터 비전 및 로봇 공학 분야에서의 기본적인 도전으로 자리 잡고 있습니다. 로봇 팔은 빈(또는 컨테이너)으로부터 다양한 방향의 물체를 효율적으로 잡기 위해 진공 그리퍼, 평행 그리퍼 또는 대체 로봇 도구를 사용하여 센서로 장착되어 있습니다. 이 문제는 Cadena의 논문에 언급되지 않았지만, SLAM의 동일한 연령 그룹이 여기에 적용될 수 있습니다(그리고 이것은 내 의견입니다).\n\n이 문제에 대한 가장 인기 있는 접근 방식 중 하나는 알고리즘 분석 시대부터 출발한 포인트 클라우드(PC) 등록에 기반하고 있습니다. 섭취 아이템의 3D 형태는 미리 알려져 있어야하며, 센서를 사용하여 매번 픽하기 전에 빈을 스캔했습니다. 이 스캔을 통해 3D PC가 생성되었고, 이후 PC 등록 알고리즘으로 전송되었습니다. 이 알고리즘은 섭취된 아이템과 빈의 PC 간에 일치를 찾는 역할을 했습니다. 아래의 애니메이션 이미지가 이 과정을 설명합니다.\n\n이 접근 방식이 그 당시에 작동했지만, 그 한계를 쉽게 이해할 수 있습니다. 예를 들어, 빈당 하나의 아이템 유형만 있어야 한다면, 그렇지 않은 경우에는 빈의 PC와 여러 섭취 아이템을 매칭하는 계산 비용이 막대할 수 있습니다. 게다가, 이러한 접근 방식은 빠르게 확장되지 않으며, 새로운 아이템을 위해서는 항상 아이템을 스캔하여 3D 형태 표현을 생성해야 합니다(또는 제조사에게 CAD 파일을 요청해야 합니다).\n\n<div class=\"content-ad\"></div>\n\n이들은 여러 종류의 항목이 들어있는 소스 바구니를 비울 수 있습니다. 게다가, 그들의 시스템은 새로운 (시스템이 이전에 본 적이 없는 항목) 항목을 즉시 선택할 수 있을 정도로 광범위한 수준의 일반화를 달성했습니다.\n\n마지막으로, 빠른 확장과 새로운 항목에 적응하는 부분 이외에, 이같은 지각 개선은 \"모든 음식 항목을 선택해 주세요\", \"장난감을 선택해 주세요\", 또는 \"놀 수 있는 항목을 가져다 주세요\"와 같은 다른 인간 수준의 명령을 처리할 수 있도록 합니다. 위의 예에서, 그들의 시스템이 바구니에서 고장난 항목을 선택하는 것을 볼 수 있습니다.\n\n이제 우리가 로봇의 지각 발전에 대해 다루었으니, 이 기사의 가장 흥미로운 부분으로 넘어갈 수 있습니다.\n\n## 로봇의 지각 발전의 영향과 속도\n\n<div class=\"content-ad\"></div>\n\n제가 각 시대의 주요 작품에서 몇 장의 이미지를 넣었는데, 그냥 이 기사를 읽기 쉽게 만들기 위해서 하는 게 아니에요. 고대 시대의 이미지를 보면 환경으로부터의 장애물을 거의 표현하지 못했음을 알 수 있어요. 대부분의 구축된 지도는 2D였고, 환경에서의 3D 장애물을 평평하게 만들었어요. 환경 내의 다양한 물체들은 모두 \"장애물\"로 라벨링되었고, 로봇이 그것들을 피한다면 괜찮았어요.\n\n시각 센서의 발전으로, 알고리즘 분석 시대는 더 많은 3D 맵을 보여주고 환경에 색상을 추가함으로써 지각을 개선했어요. 비록 이것에 대해 언급하지 않았지만, 이 시대는 또한 장면의 동적 부분을 걸러내기 시작했어요. 따라서 2004년부터 2015년까지 가장 큰 차이는 3D 맵의 탐험과 이러한 맵에 색상 정보를 추가한 것이었어요. 여기서 간략하게 설명하고 있지만, 11년간 로봇 지각에서는 발전이 그리 크지 않았다는 점이요.\n\n반면에, 견고한 지각 시대는 다른 두 시대를 무색하게 만들었어요. 여전히 제가 박사 학위 논문 제안을 작성하는 중이던 2016년에 카데나(Cadena)의 작품을 읽었을 때를 기억해요. 그 논문에서, 제 마음에 남는 한 문장을 적었어요:\n\n생각해보면, 이야기가 너무 맞죠. 2015년까지의 로봇 지각은 방법론과 기술적인 측면에서 견고한 기반을 구축하고 개선하는 데 초점을 맞췄어요. 그 부분이 충분히 견고해지면, 연구 커뮤니티와 산업계는 환경을 \"자유로운(free)\", \"점유된(occupied)\", 혹은 \"알 수 없는(unknown)\"로만 라벨링하는 것이 충분하지 않다는 것을 깨달았어요. 그 때들이 생김새를 가볍게 생각하면, 환경에서 고수준 정보를 추론하는 의미론을 추구하기로 결정했어요. 이 정보는 다양한 물체, 방, 위치의 이름과 범주를 포함하지만 이에 한정되지 않아요.\n\n<div class=\"content-ad\"></div>\n\n2015년부터 2020년까지 Zoox와 Sereact가 환경에 대한 그 수준의 이해를 달성했다는 사실이 놀라운 것 같아요. 그들로부터 일부 세부 정보를 논의해보고, 이미지를 다시 여기에 포함해서 위로 스크롤할 필요 없도록 할게요.\n\n아래 부분에서 자율 주행 자동차가 사람들이 앉아 있고 걷고 있지 않을 때를 이해할 수 있다는 것을 볼 수 있어요. 또한, 인간의 제스처를 이해할 수 있어서 앞으로 나아갈 수 있다는 의미입니다.\n\n또 다른 경우에는, 자동차가 안전 조끼를 입은 공사모를 쓴 사람이 교통 표지판을 들고 있는 상황을 이해한 것을 볼 수 있어요. 이 사람은 보통 사람이 아니라 차량이 멈추라는 도로 공사 작업자입니다.\n\n마지막으로, 주차된 차량에 문이 열려 있는 것을 이해한 자동차는 그곳에서 사람이 나올 수 있다는 것을 의미해요. 이 상황에서 Zoox 차는 어떤 사고도 예방하기 위해 더 주의 깊게 운전합니다.\n\n<div class=\"content-ad\"></div>\n\n저는 bin picking 분야의 지각 개선 사항도 다룰 예정이라고 언급했던 것 같아요. 이곳에서 Sereact에서의 좋은 예시를 소개하고 있습니다. 이 경우에는 사람이 로봇에게 상품 존 폐기품을 선택하도록 요청하고 있습니다. 출처 창고에는 6개의 프링글스 캔이 들어 있고 이 중 하나가 부서졌습니다. 시스템의 인식 부분은 이를 이해할 수 있고, 부서진 캔을 선택합니다.\n\n# 요약\n\n우리는 로봇 지각의 의미론적을 고려하는 강인한-지각 시대에 살고 있습니다. 이는 로봇이 Sereact가 보여준 것처럼, 상품 존에서 부서진 항목을 선택하거나 Zoox가 하는 것처럼 사고를 예측하는 고수준 작업을 수행할 수 있게 합니다. 우리 인간들에게는 \"부서진\"이 무엇을 의미하는지는 명확하고 간단하지만, 정의할 수 있나요? 창고의 모든 항목에 대해 이 조건을 설명하는 규칙과 특성을 정의하는 건 거의 불가능합니다 (예: 부서진 캔과 부서진 머그잔은 다릅니다).\n\n실제로 이러한 의미론적 이해는 LLM과 VLM에서 출발하며, 텍스트 및 시각적 정보를 결합합니다. 로봇이 사람의 옷이 그들이 본 상황에서 다른 역할을 함을 이해할 때야 (길 공사 작업자와 같이 보여진 것처럼) 이 사람에 적절히 반응할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n물론, 로봇학의 하드웨어 부분에서도 상당한 발전이 있었습니다. 예를 들어, Boston Dynamics와 그 Atlas 로봇을 생각해 볼 수 있습니다. 수압식 버전은 폐지되고 새로운 완전 전기식 버전이 출시되었습니다. 그러나 저는 고수준 작업을 수행하는 로봇들에게 있어서 인식 소프트웨어의 개선이 더욱 중요하다고 느낍니다.\n\n이 기사의 주요 질문에 대한 대답이 있습니다. 한 번 들은 적이 있는데, 지식을 축적하는 것이 아닌 그 지식을 활용하는 방법을 아는 사람이 똑똑하다고 합니다. 그래서 로봇이 \"새로운\" 지식을 활용하여 보다 복잡한 작업을 해결한다면, 그들은 실제로 똑똑해지고 있는 것이 맞습니다.\n\n어떻게 생각하시나요?\n\n지금은 여기까지입니다.\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n- Newman, Paul 등. “탐색 및 복귀: 실시간 동시 매핑 및 로컬라이제이션의 실험적 검증.” ICRA, 2002.\n- Thrun, Sebastian. “팀의 이동 로봇을 위한 온라인 매핑 알고리즘.” Carnegie-Mellon Univ Pittsburgh PA School of Computer Science, 2000.\n- Mur-Artal, R., Montiel, J.M.M., 및 Tardos, J.D. “ORB-SLAM: 다목적 및 정확한 단안 SLAM 시스템.” IEEE Transactions on Robotics. 2015.\n- Grisetti, G., Stachniss, C., 및 Burgard, W. “적응적 제안 및 선택적 리샘플링을 통한 Rao-Blackwellized 입자 필터를 사용한 그리드 기반 SLAM 개선.” ICRA. 2005.\n- youtube.com/watch?v=BVRMh9NO9Cs에서 추출.\n- Cadena C, Carlone L, Carrillo H, Latif Y, Scaramuzza D, Neira J, Reid I, Leonard JJ. 동시 위치 결정 및 매핑의 과거, 현재 및 미래: 견고한 인식 시대로. IEEE Transactions on robotics. 2016.\n- https://www.youtube.com/watch?v=gRV4KvIDn9Y&ab_channel=T³TipsTricksTests에서 추출.\n- https://www.youtube.com/watch?v=_ieObX5f_ws&ab_channel=Sereact에서 추출.","ogImage":{"url":"/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_0.png"},"coverImage":"/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_0.png","tag":["Tech"],"readingTime":8},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>이 기사는 보통 여기서 하는 시리즈와는 별도로 됩니다. 이젠 대화를 나누는 것처럼 얘기하는 걸 좋아합니다 (하지만 전 며칠 동안 계속 말을 할 거에요 ㅋㅋ). 그래서 당신이 좋아하는 음료를 준비하고 로봇과 그들이 얼마나 \"똑똑\"해졌는지에 대해 이야기해봐요.</p>\n<p><img src=\"/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_0.png\" alt=\"로봇\"></p>\n<p>지난 달들에 로봇이 놀라운 일들을 하는 비디오를 보셨을 것입니다. 그런 비디오를 보면서 \"와, 이건 놀라워. 이제 로봇들이 이것을 할 수 있나? 그들은 매일 더 똑똑해지고 있어\"라고 생각했을 수 있어요. 예를 들면, Figure 01 인간형 로봇이 물체를 다루는 모습이나 Scythe 로봇이 자율적으로 잔디를 자르는 것 등이 있습니다.</p>\n<p>여기서 잠깐 멈추고 로봇의 인식 관점에서 관련 두 가지 문제, 동시 위치 추정 및 지도 작성(SLAM) 그리고 빈 피킹(bin picking)을 바라봅시다.</p>\n<div class=\"content-ad\"></div>\n<h2>로봇의 과거와 현재의 인식</h2>\n<p>우선, 로봇 공학 분야에서 \"인식\"이란 무엇인가요? 모르는 분을 위해 설명드리자면, 로봇의 카메라, LiDAR, 레이더 또는 접촉 센서와 같은 다양한 센서를 사용해 환경을 감지하고 해석하는 능력을 의미합니다. 환경에 대한 유용한 정보를 추출하기 위해 센서 데이터를 수집하고 처리하는 것을 포함합니다.</p>\n<p>인식은 로봋의 SLAM에 매우 중요합니다. 다시 말씀드리면, 동시 위치 추정 및 지도 작성(SLAM)은 로봇 공학에서 기본적인 문제입니다. 이는 로봇이 알 수 없는 환경을 탐색하면서 동시에 그 환경의 지도를 작성하고 그 안에서 자신의 위치를 판단하는 것을 의미합니다.</p>\n<p>2016년에 Cadena와 다른 저자들은 \"동시 위치 및 지도 작성의 과거, 현재 및 미래: 견고한 인식 시대를 향하여\"라는 과학 논문을 발표했습니다. 그들의 연구에서는 SLAM 분야에서 30년 이상의 작업을 검토하고, 이를 고전적 시대(1986-2004), 알고리즘 분석 시대(2004-2015), 그리고 견고한 인식 시대(2015-현재)로 그룹화했습니다. 각 시대를 간단히 살펴보겠습니다.</p>\n<div class=\"content-ad\"></div>\n<p>고전 시대:\n이것은 Extended Kalman Filters, Rao-Blackwellized Particle Filters 및 최대 우도 추정을 사용하여 SLAM이 불확실성을 처리하는 주요 방법을 소개합니다. 또한 모든 것이 원활하게 작동하고 올바른 데이터 조각을 연결하는 데 필요한 기본 도전에 대해 이야기합니다.이 시대의 SLAM의 두 가지 예는 아래에 나와 있습니다.</p>\n<p><img src=\"/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_1.png\" alt=\"image\"></p>\n<p>일반적으로, 첫 번째 제안된 SLAM 시스템은 환경에서 장애물을 감지하고 맵에 표현할 수 있었습니다. 맵핑에 사용된 가장 인기 있는 센서는 초음파 및 LiDAR였습니다.</p>\n<p>알고리즘 분석 시대:\n연구자들은 SLAM의 기본 기능인 시간이 지남에 따른 위치 추적이 얼마나 잘되는지, 신뢰할 수 있는지, 그리고 대량의 데이터를 어떻게 처리하는지 등을 조사했습니다. 드문 데이터가 SLAM이 더 빠르고 더 잘 작동하게 하는 것을 발견했습니다. 이때 무료로 사용할 수 있는 주요 SLAM 소프트웨어인 Gmapping 및 ORB-SLAM을 만들기 시작했습니다.</p>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_2.png\" alt=\"그림\"></p>\n<p>이전 시대의 기초를 활용하여 이 시대에는 카메라와 다른 시각 센서들이 보다 인기를 끌게 되었으며, \"Visual-SLAM\"이라는 용어가 제안되었습니다. 게다가 커뮤니티는 3D 환경 표현을 이용한 다양한 SLAM 기술을 소개했습니다.</p>\n<p>로버스트-인식 시대:\nSLAM 시스템은 단순히 형상을 매핑하는 것을 넘어, 환경에 대한 고수준의 이해를 얻기 위해 기하학적 재구성을 위해 높은 수준의 고려를 합니다. 물체의 의미(의미론)나 관련된 물리학적 측면과 같은 것들을 고려합니다. 당사자가 수행해야 하는 작업에 맞게 로봇이 필요한 세부 사항에 초점을 맞추어 센서 데이터에서 추가 잡음을 걸러내어 로봇이 작업을 성취하는 데 도움을 줍니다. 로봇이 수행해야 할 작업에 따라 맵을 조정합니다.</p>\n<p>이 애니메이션 이미지를 자세히 살펴보면 많은 세부 사항을 알 수 있습니다. 장면 속 물체는 환경의 일부로 이해되며, 같은 클래스의 물체는 경계 상자에서 동일한 색으로 레이블이 지정되며, LiDAR 및 레이더의 3D 데이터는 카메라의 2D 이미지와 결합됩니다. 게다가 다양한 물체가 결합되어 장면으로부터 더 많은 정보를 추출하는데 활용됩니다. 마지막 애니메이션 이미지에서와 같이 흰색 차량과 그의 깜박임등, 후방등, 브레이크 라이트 등이 있습니다.</p>\n<div class=\"content-ad\"></div>\n<h1>빈 피킹에서의 인식</h1>\n<p>빈 피킹은 컴퓨터 비전 및 로봇 공학 분야에서의 기본적인 도전으로 자리 잡고 있습니다. 로봇 팔은 빈(또는 컨테이너)으로부터 다양한 방향의 물체를 효율적으로 잡기 위해 진공 그리퍼, 평행 그리퍼 또는 대체 로봇 도구를 사용하여 센서로 장착되어 있습니다. 이 문제는 Cadena의 논문에 언급되지 않았지만, SLAM의 동일한 연령 그룹이 여기에 적용될 수 있습니다(그리고 이것은 내 의견입니다).</p>\n<p>이 문제에 대한 가장 인기 있는 접근 방식 중 하나는 알고리즘 분석 시대부터 출발한 포인트 클라우드(PC) 등록에 기반하고 있습니다. 섭취 아이템의 3D 형태는 미리 알려져 있어야하며, 센서를 사용하여 매번 픽하기 전에 빈을 스캔했습니다. 이 스캔을 통해 3D PC가 생성되었고, 이후 PC 등록 알고리즘으로 전송되었습니다. 이 알고리즘은 섭취된 아이템과 빈의 PC 간에 일치를 찾는 역할을 했습니다. 아래의 애니메이션 이미지가 이 과정을 설명합니다.</p>\n<p>이 접근 방식이 그 당시에 작동했지만, 그 한계를 쉽게 이해할 수 있습니다. 예를 들어, 빈당 하나의 아이템 유형만 있어야 한다면, 그렇지 않은 경우에는 빈의 PC와 여러 섭취 아이템을 매칭하는 계산 비용이 막대할 수 있습니다. 게다가, 이러한 접근 방식은 빠르게 확장되지 않으며, 새로운 아이템을 위해서는 항상 아이템을 스캔하여 3D 형태 표현을 생성해야 합니다(또는 제조사에게 CAD 파일을 요청해야 합니다).</p>\n<div class=\"content-ad\"></div>\n<p>이들은 여러 종류의 항목이 들어있는 소스 바구니를 비울 수 있습니다. 게다가, 그들의 시스템은 새로운 (시스템이 이전에 본 적이 없는 항목) 항목을 즉시 선택할 수 있을 정도로 광범위한 수준의 일반화를 달성했습니다.</p>\n<p>마지막으로, 빠른 확장과 새로운 항목에 적응하는 부분 이외에, 이같은 지각 개선은 \"모든 음식 항목을 선택해 주세요\", \"장난감을 선택해 주세요\", 또는 \"놀 수 있는 항목을 가져다 주세요\"와 같은 다른 인간 수준의 명령을 처리할 수 있도록 합니다. 위의 예에서, 그들의 시스템이 바구니에서 고장난 항목을 선택하는 것을 볼 수 있습니다.</p>\n<p>이제 우리가 로봇의 지각 발전에 대해 다루었으니, 이 기사의 가장 흥미로운 부분으로 넘어갈 수 있습니다.</p>\n<h2>로봇의 지각 발전의 영향과 속도</h2>\n<div class=\"content-ad\"></div>\n<p>제가 각 시대의 주요 작품에서 몇 장의 이미지를 넣었는데, 그냥 이 기사를 읽기 쉽게 만들기 위해서 하는 게 아니에요. 고대 시대의 이미지를 보면 환경으로부터의 장애물을 거의 표현하지 못했음을 알 수 있어요. 대부분의 구축된 지도는 2D였고, 환경에서의 3D 장애물을 평평하게 만들었어요. 환경 내의 다양한 물체들은 모두 \"장애물\"로 라벨링되었고, 로봇이 그것들을 피한다면 괜찮았어요.</p>\n<p>시각 센서의 발전으로, 알고리즘 분석 시대는 더 많은 3D 맵을 보여주고 환경에 색상을 추가함으로써 지각을 개선했어요. 비록 이것에 대해 언급하지 않았지만, 이 시대는 또한 장면의 동적 부분을 걸러내기 시작했어요. 따라서 2004년부터 2015년까지 가장 큰 차이는 3D 맵의 탐험과 이러한 맵에 색상 정보를 추가한 것이었어요. 여기서 간략하게 설명하고 있지만, 11년간 로봇 지각에서는 발전이 그리 크지 않았다는 점이요.</p>\n<p>반면에, 견고한 지각 시대는 다른 두 시대를 무색하게 만들었어요. 여전히 제가 박사 학위 논문 제안을 작성하는 중이던 2016년에 카데나(Cadena)의 작품을 읽었을 때를 기억해요. 그 논문에서, 제 마음에 남는 한 문장을 적었어요:</p>\n<p>생각해보면, 이야기가 너무 맞죠. 2015년까지의 로봇 지각은 방법론과 기술적인 측면에서 견고한 기반을 구축하고 개선하는 데 초점을 맞췄어요. 그 부분이 충분히 견고해지면, 연구 커뮤니티와 산업계는 환경을 \"자유로운(free)\", \"점유된(occupied)\", 혹은 \"알 수 없는(unknown)\"로만 라벨링하는 것이 충분하지 않다는 것을 깨달았어요. 그 때들이 생김새를 가볍게 생각하면, 환경에서 고수준 정보를 추론하는 의미론을 추구하기로 결정했어요. 이 정보는 다양한 물체, 방, 위치의 이름과 범주를 포함하지만 이에 한정되지 않아요.</p>\n<div class=\"content-ad\"></div>\n<p>2015년부터 2020년까지 Zoox와 Sereact가 환경에 대한 그 수준의 이해를 달성했다는 사실이 놀라운 것 같아요. 그들로부터 일부 세부 정보를 논의해보고, 이미지를 다시 여기에 포함해서 위로 스크롤할 필요 없도록 할게요.</p>\n<p>아래 부분에서 자율 주행 자동차가 사람들이 앉아 있고 걷고 있지 않을 때를 이해할 수 있다는 것을 볼 수 있어요. 또한, 인간의 제스처를 이해할 수 있어서 앞으로 나아갈 수 있다는 의미입니다.</p>\n<p>또 다른 경우에는, 자동차가 안전 조끼를 입은 공사모를 쓴 사람이 교통 표지판을 들고 있는 상황을 이해한 것을 볼 수 있어요. 이 사람은 보통 사람이 아니라 차량이 멈추라는 도로 공사 작업자입니다.</p>\n<p>마지막으로, 주차된 차량에 문이 열려 있는 것을 이해한 자동차는 그곳에서 사람이 나올 수 있다는 것을 의미해요. 이 상황에서 Zoox 차는 어떤 사고도 예방하기 위해 더 주의 깊게 운전합니다.</p>\n<div class=\"content-ad\"></div>\n<p>저는 bin picking 분야의 지각 개선 사항도 다룰 예정이라고 언급했던 것 같아요. 이곳에서 Sereact에서의 좋은 예시를 소개하고 있습니다. 이 경우에는 사람이 로봇에게 상품 존 폐기품을 선택하도록 요청하고 있습니다. 출처 창고에는 6개의 프링글스 캔이 들어 있고 이 중 하나가 부서졌습니다. 시스템의 인식 부분은 이를 이해할 수 있고, 부서진 캔을 선택합니다.</p>\n<h1>요약</h1>\n<p>우리는 로봇 지각의 의미론적을 고려하는 강인한-지각 시대에 살고 있습니다. 이는 로봇이 Sereact가 보여준 것처럼, 상품 존에서 부서진 항목을 선택하거나 Zoox가 하는 것처럼 사고를 예측하는 고수준 작업을 수행할 수 있게 합니다. 우리 인간들에게는 \"부서진\"이 무엇을 의미하는지는 명확하고 간단하지만, 정의할 수 있나요? 창고의 모든 항목에 대해 이 조건을 설명하는 규칙과 특성을 정의하는 건 거의 불가능합니다 (예: 부서진 캔과 부서진 머그잔은 다릅니다).</p>\n<p>실제로 이러한 의미론적 이해는 LLM과 VLM에서 출발하며, 텍스트 및 시각적 정보를 결합합니다. 로봇이 사람의 옷이 그들이 본 상황에서 다른 역할을 함을 이해할 때야 (길 공사 작업자와 같이 보여진 것처럼) 이 사람에 적절히 반응할 수 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>물론, 로봇학의 하드웨어 부분에서도 상당한 발전이 있었습니다. 예를 들어, Boston Dynamics와 그 Atlas 로봇을 생각해 볼 수 있습니다. 수압식 버전은 폐지되고 새로운 완전 전기식 버전이 출시되었습니다. 그러나 저는 고수준 작업을 수행하는 로봇들에게 있어서 인식 소프트웨어의 개선이 더욱 중요하다고 느낍니다.</p>\n<p>이 기사의 주요 질문에 대한 대답이 있습니다. 한 번 들은 적이 있는데, 지식을 축적하는 것이 아닌 그 지식을 활용하는 방법을 아는 사람이 똑똑하다고 합니다. 그래서 로봇이 \"새로운\" 지식을 활용하여 보다 복잡한 작업을 해결한다면, 그들은 실제로 똑똑해지고 있는 것이 맞습니다.</p>\n<p>어떻게 생각하시나요?</p>\n<p>지금은 여기까지입니다.</p>\n<div class=\"content-ad\"></div>\n<h1>참고 자료</h1>\n<ul>\n<li>Newman, Paul 등. “탐색 및 복귀: 실시간 동시 매핑 및 로컬라이제이션의 실험적 검증.” ICRA, 2002.</li>\n<li>Thrun, Sebastian. “팀의 이동 로봇을 위한 온라인 매핑 알고리즘.” Carnegie-Mellon Univ Pittsburgh PA School of Computer Science, 2000.</li>\n<li>Mur-Artal, R., Montiel, J.M.M., 및 Tardos, J.D. “ORB-SLAM: 다목적 및 정확한 단안 SLAM 시스템.” IEEE Transactions on Robotics. 2015.</li>\n<li>Grisetti, G., Stachniss, C., 및 Burgard, W. “적응적 제안 및 선택적 리샘플링을 통한 Rao-Blackwellized 입자 필터를 사용한 그리드 기반 SLAM 개선.” ICRA. 2005.</li>\n<li>youtube.com/watch?v=BVRMh9NO9Cs에서 추출.</li>\n<li>Cadena C, Carlone L, Carrillo H, Latif Y, Scaramuzza D, Neira J, Reid I, Leonard JJ. 동시 위치 결정 및 매핑의 과거, 현재 및 미래: 견고한 인식 시대로. IEEE Transactions on robotics. 2016.</li>\n<li><a href=\"https://www.youtube.com/watch?v=gRV4KvIDn9Y&#x26;ab_channel=T%C2%B3TipsTricksTests%EC%97%90%EC%84%9C\" rel=\"nofollow\" target=\"_blank\">https://www.youtube.com/watch?v=gRV4KvIDn9Y&#x26;ab_channel=T³TipsTricksTests에서</a> 추출.</li>\n<li><a href=\"https://www.youtube.com/watch?v=_ieObX5f_ws&#x26;ab_channel=Sereact%EC%97%90%EC%84%9C\" rel=\"nofollow\" target=\"_blank\">https://www.youtube.com/watch?v=_ieObX5f_ws&#x26;ab_channel=Sereact에서</a> 추출.</li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}