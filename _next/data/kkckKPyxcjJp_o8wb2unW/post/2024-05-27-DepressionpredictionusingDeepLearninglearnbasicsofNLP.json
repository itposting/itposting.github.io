{"pageProps":{"post":{"title":"딥 러닝을 이용한 우울증 예측 NLP 기초 배우기","description":"","date":"2024-05-27 14:08","slug":"2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP","content":"\n<table>\n  <tr>\n    <td><img src=\"/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_0.png\" /></td>\n  </tr>\n</table>\n\n# 이 논문에서는 우리가 어떻게 NLP 애플리케이션을 쉽게 만들 수 있는지 보여드리고 싶습니다.\n\n이 논문에서는 NLP의 기본을 배우게 될 것입니다.\n다음은 여러분이 배우게 될 내용입니다:\n\n1 — Tokenizer가 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n2 — texts_to_sequences란 무엇인가요?\n\n3 — pad sequence란 무엇인가요?\n\n4 — Embedding이란 무엇인가요?\n\n5 — 예측 모델을 만들어 볼까요?\n\n이 코드는 텍스트 데이터를 포함하는 이진 NLP 데이터셋에 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 1 — 토크나이저란:\n\n기계는 숫자만 이해할 수 있다는 것을 우리 모두 알고 있습니다. 그래서 우리는 단어를 숫자로 변환해야 합니다.\n\n예를 들어, 만약 'hello world'를 기계가 이해할 수 있게 하려면 이렇게 숫자로 변환해야 합니다:\nhello는 0으로 표현\nworld는 1로 표현\n\n이를 수행하기 위해 토크나이저를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n토크나이저를 사용하여 단어, 하위 단어, 문자를 숫자로 변환하고 각 단어를 숫자로 변환한 것을 토큰이라고 합니다.\n\n요약하자면, 토크나이저는 텍스트를 토큰으로 변환합니다.\n\n## 데이터셋\n\n우선 데이터셋을 가져와야 합니다. 이 논문에서 사용된 데이터셋은 아래 링크를 통해 찾을 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n# 프로그래밍 해봐요 :))\n\n데이터셋을 위한 변수를 정의해볼게요 :\n\n```js\ndataset = pd.read_csv(\"D:ITML projectPredict depressiondepression_dataset_reddit_cleaned.csv\");\n```\n\n이제 문장과 레이블을 위한 변수 두 개를 정의해야 해요 :\n\n<div class=\"content-ad\"></div>\n\n```js\nsentences = dataset[\"clean_text\"];\nlabels = dataset[\"is_depression\"];\n```\n\n모델을 훈련하기 위해 훈련 데이터와 모델을 시험하고 최적화하는 테스트 데이터가 필요합니다.\n\n따라서 이제 데이터를 두 부분, 훈련 및 테스트용으로 분리해야 합니다.\n\n데이터는 7731개의 행(샘플)을 포함하고 있으며, 0부터 6000까지는 훈련 데이터로 정의하며, 즉 6000 이전의 모든 데이터는 훈련에, 그 이후의 모든 데이터는 테스트에 사용합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\ntraining_size = 6000\n\ntraining_sentences = sentences[0:training_size]\ntesting_sentences = sentences[training_size:]\n\ntraining_labels = labels[0:training_size]\ntesting_labels = labels[training_size:]\n```\n\nTokenizer 작업을 해봅시다.\n\n```js\n'''\n여기서는 텐서플로우 토크나이저를 사용합니다.\n'''\n\nfrom keras.preprocessing.text import Tokenizer #Tokenizer 가져오기\n\nvocab_size = 10000 #토크나이저가 기대하는 단어의 개수\n\ntokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>', lower=True)\ntokenizer.fit_on_texts(training_sentences) #단어를 숫자로 변환하기\n#word_index = tokenizer.word_index #각 단어의 숫자(토큰)를 표시\n# print(word_index)\n```\n\noov_token='`OOV`': 이 매개변수는 어휘에 없는 단어를 처리하는 데 도움을 줍니다.\n\n<div class=\"content-ad\"></div>\n\nlower=True : 모든 단어를 소문자로 변환합니다.\n\n# 2 — texts_to_sequences\n\n이 방법을 사용하면 단어를 나타내는 모든 숫자가 순서로 변환됩니다.\n\n예를 살펴보겠습니다\n\n<div class=\"content-ad\"></div>\n\n```js\nsentence1 = '개는 좋은 동물이다'\nsentence2 = '내 이름은 오미드야'\n\ntokenizer = Tokenizer(num_words=10, oov_token='<OOV>', lower=True)\ntokenizer.fit_on_texts([sentence1, sentence2])\nword_index = tokenizer.word_index\nprint(word_index)\n\nsequences = tokenizer.texts_to_sequences([sentence1, sentence2])\nprint(sequences)\n\n'''\nOutput:\n{'<OOV>': 1, '은': 2, '개는': 3, '좋은': 4, '동물이다': 5, '내': 6, '이름은': 7, '오미드야': 8}\n[[3, 2, 4, 5], [6, 7, 2, 8]]\n'''\n```\n\n# 3 — 시퀀스 패딩\n\n모든 문장이 같은 길이를 가지고 있지 않기 때문에, 이를 처리하기 위해 시퀀스 패딩을 사용합니다.\n\n예를 들어 2개의 문장이 있는데, 하나는 3단어이고 다른 하나는 4단어를 가지고 있다고 가정해보겠습니다. 이런 상황에서, 패딩 시퀀스는 2x4 행렬을 만들어줍니다. 3단어를 가진 문장은 맨 끝이나 맨 처음 행렬 요소를 0으로 처리할 것입니다.\n\n예제로 살펴보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom keras.preprocessing.sequence import pad_sequences\n\nsequences = tokenizer.texts_to_sequences([sentence1, sentence2]) #지난 코드와 비슷함\n\nsentences_padded = pad_sequences(sequences)\nprint(sentences_padded)\n\n'''\noutput:\n[[3 2 4 5 6]\n [0 7 8 2 9]]\n'''\n```\n\n더 많은 정보를 원하시면 문서를 읽어보세요.\n\n이제 우리의 주요 코드(우울증 예측)로 돌아가보겠습니다.\n\n이제 texts_to_sequences와 Pad sequences가 무엇인지 알았으니 이를 통해 데이터를 처리해봅시다!\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom keras.preprocessing.sequence import pad_sequences\n\nmax_length = 100 # tokenizer가 허용할 문장의 최대 길이\n\ntraining_sequences = tokenizer.texts_to_sequences(training_sentences)\ntraining_padded = pad_sequences(training_sequences, maxlen=max_length)\n\ntesting_sequences = tokenizer.texts_to_sequences(testing_sentences)\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length)\n```\n\n이제 데이터가 준비되었으니 모델을 만들 수 있지만, 그 전에 Embedding이 무엇인지 알아보겠습니다.\n\n# 4 — Embedding\n\nEmbedding은 단어를 벡터로 변환합니다. 이를 통해 모델은 단어 간의 관계를 이해할 수 있습니다.\n\n\n\n<div class=\"content-ad\"></div>\n\n예를 들어, '좋은'과 '나쁜'이라는 단어가 있다고 상상해보세요. 그런데 '나쁘지 않은'처럼 특정한 단어가 있는 경우에는 이 단어가 부정적인 느낌을 나타내는 '나쁜'과 연관되어 있음을 모델이 이해하도록 임베딩이 도움이 됩니다.\n\n# 5 — 예측 모델 만들기\n\n모델은 임베딩 레이어로 훈련되었으며, 그 후에는 글로벌 평균 풀링 1D, 24개의 밀집 (완전 연결) 레이어(relu 활성화 함수 사용) 및 마지막 레이어에 시그모이드 활성화 함수를 사용한 1개의 밀집 레이어로 구성되어 있습니다. 이를 10번의 epoch 동안 훈련시켰습니다.\n\n활성화 함수는 모델이 데이터를 더 잘 이해하도록 돕습니다.\n\n<div class=\"content-ad\"></div>\n\n## ReLU 활성화 함수\n\nReLU는 값이 0보다 큰 경우에만 활성화되는 활성화 함수입니다:\n\nR(x) = max(0,x)\n\n## 시그모이드 활성화 함수\n\n<div class=\"content-ad\"></div>\n\n\n\n![Image](/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_1.png)\n\nIf the labels of the data are binary (0 or 1) like the dataset we are using, we use the sigmoid activation function.\n\nIf the output of the sigmoid activation function (the last layer) is greater than 0.5, it is assigned the label 1. If it is lower than 0.5, it is assigned the label 0.\n\nIn summary:\n\n\n\n<div class=\"content-ad\"></div>\n\n\n\n출력 결과 `0.5 — — → 1\n\n출력 결과 `0.5 — — -` 0\n\n## 코드\n\n```js\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Dense, GlobalAveragePooling1D\n\nembedding_dim = 16 #임베딩 레이어의 차원\nmodel = Sequential([\n    Embedding(vocab_size, output_dim=embedding_dim, input_length=max_length),\n    GlobalAveragePooling1D(),\n    Dense(24, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nnum_epochs = 10\nhistory = model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels))\n```\n\n\n\n<div class=\"content-ad\"></div>\n\n## 플롯\n\n10 epochs에서 모델의 진행 상황을 확인해 봅시다.\n\n```python\nimport matplotlib.pyplot as plt\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['accuracy', 'loss'])\n```\n\n![image](/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_2.png)\n\n<div class=\"content-ad\"></div>\n\n각 epoch마다 모델이 개선되었음을 확인할 수 있습니다. 정확도가 증가하고 손실이 감소했어요.\n\n## 모델 테스트\n\n이제 모델을 테스트해볼게요. 입력 텍스트에 texts_to_sequence 및 pad_sequences를 수행할 필요가 있다는 것을 잊지 마세요.\n\n```js\ntest_sentence = ['the life became so hard i can not take it any more i just wanna die ']\ntest_sentence = tokenizer.texts_to_sequences(test_sentence)\npadded_test_sentence = pad_sequences(test_sentence, maxlen=max_length)\nprint(model.predict(padded_test_sentence))\n\n'''\noutput :\n[[0.6440944]]\n'''\n```\n\n<div class=\"content-ad\"></div>\n\n입력 텍스트 (test_sentence)에는 분명히 슬픈 감정이 있습니다. 모델의 출력값은 0.64로, 0.5보다 큽니다. 이전에 언급했듯이, 레이블 1로 할당되어 우울증이 긍정적이라는 것을 의미합니다.\n\n# GitHub:\n\n아래 링크를 통해 GitHub에서 코드에 접근할 수 있습니다.\n\n# 마지막 요청\n\n<div class=\"content-ad\"></div>\n\n읽어 주셔서 감사합니다. 즐거워하셨으면 좋겠어요!\n","ogImage":{"url":"/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_0.png"},"coverImage":"/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_0.png","tag":["Tech"],"readingTime":7},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<table>\n  <tbody><tr>\n    <td><img src=\"/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_0.png\"></td>\n  </tr>\n</tbody></table>\n<h1>이 논문에서는 우리가 어떻게 NLP 애플리케이션을 쉽게 만들 수 있는지 보여드리고 싶습니다.</h1>\n<p>이 논문에서는 NLP의 기본을 배우게 될 것입니다.\n다음은 여러분이 배우게 될 내용입니다:</p>\n<p>1 — Tokenizer가 무엇인가요?</p>\n<div class=\"content-ad\"></div>\n<p>2 — texts_to_sequences란 무엇인가요?</p>\n<p>3 — pad sequence란 무엇인가요?</p>\n<p>4 — Embedding이란 무엇인가요?</p>\n<p>5 — 예측 모델을 만들어 볼까요?</p>\n<p>이 코드는 텍스트 데이터를 포함하는 이진 NLP 데이터셋에 사용할 수 있습니다.</p>\n<div class=\"content-ad\"></div>\n<h1>1 — 토크나이저란:</h1>\n<p>기계는 숫자만 이해할 수 있다는 것을 우리 모두 알고 있습니다. 그래서 우리는 단어를 숫자로 변환해야 합니다.</p>\n<p>예를 들어, 만약 'hello world'를 기계가 이해할 수 있게 하려면 이렇게 숫자로 변환해야 합니다:\nhello는 0으로 표현\nworld는 1로 표현</p>\n<p>이를 수행하기 위해 토크나이저를 사용합니다.</p>\n<div class=\"content-ad\"></div>\n<p>토크나이저를 사용하여 단어, 하위 단어, 문자를 숫자로 변환하고 각 단어를 숫자로 변환한 것을 토큰이라고 합니다.</p>\n<p>요약하자면, 토크나이저는 텍스트를 토큰으로 변환합니다.</p>\n<h2>데이터셋</h2>\n<p>우선 데이터셋을 가져와야 합니다. 이 논문에서 사용된 데이터셋은 아래 링크를 통해 찾을 수 있습니다:</p>\n<div class=\"content-ad\"></div>\n<h1>프로그래밍 해봐요 :))</h1>\n<p>데이터셋을 위한 변수를 정의해볼게요 :</p>\n<pre><code class=\"hljs language-js\">dataset = pd.<span class=\"hljs-title function_\">read_csv</span>(<span class=\"hljs-string\">\"D:ITML projectPredict depressiondepression_dataset_reddit_cleaned.csv\"</span>);\n</code></pre>\n<p>이제 문장과 레이블을 위한 변수 두 개를 정의해야 해요 :</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">sentences = dataset[<span class=\"hljs-string\">\"clean_text\"</span>];\nlabels = dataset[<span class=\"hljs-string\">\"is_depression\"</span>];\n</code></pre>\n<p>모델을 훈련하기 위해 훈련 데이터와 모델을 시험하고 최적화하는 테스트 데이터가 필요합니다.</p>\n<p>따라서 이제 데이터를 두 부분, 훈련 및 테스트용으로 분리해야 합니다.</p>\n<p>데이터는 7731개의 행(샘플)을 포함하고 있으며, 0부터 6000까지는 훈련 데이터로 정의하며, 즉 6000 이전의 모든 데이터는 훈련에, 그 이후의 모든 데이터는 테스트에 사용합니다:</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">training_size = <span class=\"hljs-number\">6000</span>\n\ntraining_sentences = sentences[<span class=\"hljs-number\">0</span>:training_size]\ntesting_sentences = sentences[<span class=\"hljs-attr\">training_size</span>:]\n\ntraining_labels = labels[<span class=\"hljs-number\">0</span>:training_size]\ntesting_labels = labels[<span class=\"hljs-attr\">training_size</span>:]\n</code></pre>\n<p>Tokenizer 작업을 해봅시다.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-string\">''</span><span class=\"hljs-string\">'\n여기서는 텐서플로우 토크나이저를 사용합니다.\n'</span><span class=\"hljs-string\">''</span>\n\n<span class=\"hljs-keyword\">from</span> keras.<span class=\"hljs-property\">preprocessing</span>.<span class=\"hljs-property\">text</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">Tokenizer</span> #<span class=\"hljs-title class_\">Tokenizer</span> 가져오기\n\nvocab_size = <span class=\"hljs-number\">10000</span> #토크나이저가 기대하는 단어의 개수\n\ntokenizer = <span class=\"hljs-title class_\">Tokenizer</span>(num_words=vocab_size, oov_token=<span class=\"hljs-string\">'&#x3C;OOV>'</span>, lower=<span class=\"hljs-title class_\">True</span>)\ntokenizer.<span class=\"hljs-title function_\">fit_on_texts</span>(training_sentences) #단어를 숫자로 변환하기\n#word_index = tokenizer.<span class=\"hljs-property\">word_index</span> #각 단어의 숫자(토큰)를 표시\n# <span class=\"hljs-title function_\">print</span>(word_index)\n</code></pre>\n<p>oov_token='<code>OOV</code>': 이 매개변수는 어휘에 없는 단어를 처리하는 데 도움을 줍니다.</p>\n<div class=\"content-ad\"></div>\n<p>lower=True : 모든 단어를 소문자로 변환합니다.</p>\n<h1>2 — texts_to_sequences</h1>\n<p>이 방법을 사용하면 단어를 나타내는 모든 숫자가 순서로 변환됩니다.</p>\n<p>예를 살펴보겠습니다</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">sentence1 = <span class=\"hljs-string\">'개는 좋은 동물이다'</span>\nsentence2 = <span class=\"hljs-string\">'내 이름은 오미드야'</span>\n\ntokenizer = <span class=\"hljs-title class_\">Tokenizer</span>(num_words=<span class=\"hljs-number\">10</span>, oov_token=<span class=\"hljs-string\">'&#x3C;OOV>'</span>, lower=<span class=\"hljs-title class_\">True</span>)\ntokenizer.<span class=\"hljs-title function_\">fit_on_texts</span>([sentence1, sentence2])\nword_index = tokenizer.<span class=\"hljs-property\">word_index</span>\n<span class=\"hljs-title function_\">print</span>(word_index)\n\nsequences = tokenizer.<span class=\"hljs-title function_\">texts_to_sequences</span>([sentence1, sentence2])\n<span class=\"hljs-title function_\">print</span>(sequences)\n\n<span class=\"hljs-string\">''</span><span class=\"hljs-string\">'\nOutput:\n{'</span>&#x3C;<span class=\"hljs-variable constant_\">OOV</span>><span class=\"hljs-string\">': 1, '</span>은<span class=\"hljs-string\">': 2, '</span>개는<span class=\"hljs-string\">': 3, '</span>좋은<span class=\"hljs-string\">': 4, '</span>동물이다<span class=\"hljs-string\">': 5, '</span>내<span class=\"hljs-string\">': 6, '</span>이름은<span class=\"hljs-string\">': 7, '</span>오미드야<span class=\"hljs-string\">': 8}\n[[3, 2, 4, 5], [6, 7, 2, 8]]\n'</span><span class=\"hljs-string\">''</span>\n</code></pre>\n<h1>3 — 시퀀스 패딩</h1>\n<p>모든 문장이 같은 길이를 가지고 있지 않기 때문에, 이를 처리하기 위해 시퀀스 패딩을 사용합니다.</p>\n<p>예를 들어 2개의 문장이 있는데, 하나는 3단어이고 다른 하나는 4단어를 가지고 있다고 가정해보겠습니다. 이런 상황에서, 패딩 시퀀스는 2x4 행렬을 만들어줍니다. 3단어를 가진 문장은 맨 끝이나 맨 처음 행렬 요소를 0으로 처리할 것입니다.</p>\n<p>예제로 살펴보겠습니다:</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">from</span> keras.<span class=\"hljs-property\">preprocessing</span>.<span class=\"hljs-property\">sequence</span> <span class=\"hljs-keyword\">import</span> pad_sequences\n\nsequences = tokenizer.<span class=\"hljs-title function_\">texts_to_sequences</span>([sentence1, sentence2]) #지난 코드와 비슷함\n\nsentences_padded = <span class=\"hljs-title function_\">pad_sequences</span>(sequences)\n<span class=\"hljs-title function_\">print</span>(sentences_padded)\n\n<span class=\"hljs-string\">''</span><span class=\"hljs-string\">'\noutput:\n[[3 2 4 5 6]\n [0 7 8 2 9]]\n'</span><span class=\"hljs-string\">''</span>\n</code></pre>\n<p>더 많은 정보를 원하시면 문서를 읽어보세요.</p>\n<p>이제 우리의 주요 코드(우울증 예측)로 돌아가보겠습니다.</p>\n<p>이제 texts_to_sequences와 Pad sequences가 무엇인지 알았으니 이를 통해 데이터를 처리해봅시다!</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">from</span> keras.<span class=\"hljs-property\">preprocessing</span>.<span class=\"hljs-property\">sequence</span> <span class=\"hljs-keyword\">import</span> pad_sequences\n\nmax_length = <span class=\"hljs-number\">100</span> # tokenizer가 허용할 문장의 최대 길이\n\ntraining_sequences = tokenizer.<span class=\"hljs-title function_\">texts_to_sequences</span>(training_sentences)\ntraining_padded = <span class=\"hljs-title function_\">pad_sequences</span>(training_sequences, maxlen=max_length)\n\ntesting_sequences = tokenizer.<span class=\"hljs-title function_\">texts_to_sequences</span>(testing_sentences)\ntesting_padded = <span class=\"hljs-title function_\">pad_sequences</span>(testing_sequences, maxlen=max_length)\n</code></pre>\n<p>이제 데이터가 준비되었으니 모델을 만들 수 있지만, 그 전에 Embedding이 무엇인지 알아보겠습니다.</p>\n<h1>4 — Embedding</h1>\n<p>Embedding은 단어를 벡터로 변환합니다. 이를 통해 모델은 단어 간의 관계를 이해할 수 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>예를 들어, '좋은'과 '나쁜'이라는 단어가 있다고 상상해보세요. 그런데 '나쁘지 않은'처럼 특정한 단어가 있는 경우에는 이 단어가 부정적인 느낌을 나타내는 '나쁜'과 연관되어 있음을 모델이 이해하도록 임베딩이 도움이 됩니다.</p>\n<h1>5 — 예측 모델 만들기</h1>\n<p>모델은 임베딩 레이어로 훈련되었으며, 그 후에는 글로벌 평균 풀링 1D, 24개의 밀집 (완전 연결) 레이어(relu 활성화 함수 사용) 및 마지막 레이어에 시그모이드 활성화 함수를 사용한 1개의 밀집 레이어로 구성되어 있습니다. 이를 10번의 epoch 동안 훈련시켰습니다.</p>\n<p>활성화 함수는 모델이 데이터를 더 잘 이해하도록 돕습니다.</p>\n<div class=\"content-ad\"></div>\n<h2>ReLU 활성화 함수</h2>\n<p>ReLU는 값이 0보다 큰 경우에만 활성화되는 활성화 함수입니다:</p>\n<p>R(x) = max(0,x)</p>\n<h2>시그모이드 활성화 함수</h2>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_1.png\" alt=\"Image\"></p>\n<p>If the labels of the data are binary (0 or 1) like the dataset we are using, we use the sigmoid activation function.</p>\n<p>If the output of the sigmoid activation function (the last layer) is greater than 0.5, it is assigned the label 1. If it is lower than 0.5, it is assigned the label 0.</p>\n<p>In summary:</p>\n<div class=\"content-ad\"></div>\n<p>출력 결과 `0.5 — — → 1</p>\n<p>출력 결과 <code>0.5 — — -</code> 0</p>\n<h2>코드</h2>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">from</span> keras.<span class=\"hljs-property\">models</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">Sequential</span>\n<span class=\"hljs-keyword\">from</span> keras.<span class=\"hljs-property\">layers</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">Embedding</span>, <span class=\"hljs-title class_\">Dense</span>, <span class=\"hljs-title class_\">GlobalAveragePooling1D</span>\n\nembedding_dim = <span class=\"hljs-number\">16</span> #임베딩 레이어의 차원\nmodel = <span class=\"hljs-title class_\">Sequential</span>([\n    <span class=\"hljs-title class_\">Embedding</span>(vocab_size, output_dim=embedding_dim, input_length=max_length),\n    <span class=\"hljs-title class_\">GlobalAveragePooling1D</span>(),\n    <span class=\"hljs-title class_\">Dense</span>(<span class=\"hljs-number\">24</span>, activation=<span class=\"hljs-string\">'relu'</span>),\n    <span class=\"hljs-title class_\">Dense</span>(<span class=\"hljs-number\">1</span>, activation=<span class=\"hljs-string\">'sigmoid'</span>)\n])\n\nmodel.<span class=\"hljs-title function_\">compile</span>(loss=<span class=\"hljs-string\">'binary_crossentropy'</span>, optimizer=<span class=\"hljs-string\">'adam'</span>, metrics=[<span class=\"hljs-string\">'accuracy'</span>])\n\nnum_epochs = <span class=\"hljs-number\">10</span>\nhistory = model.<span class=\"hljs-title function_\">fit</span>(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels))\n</code></pre>\n<div class=\"content-ad\"></div>\n<h2>플롯</h2>\n<p>10 epochs에서 모델의 진행 상황을 확인해 봅시다.</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt\n\nplt.plot(history.history[<span class=\"hljs-string\">'accuracy'</span>])\nplt.plot(history.history[<span class=\"hljs-string\">'loss'</span>])\nplt.xlabel(<span class=\"hljs-string\">'Epoch'</span>)\nplt.ylabel(<span class=\"hljs-string\">'Accuracy'</span>)\nplt.legend([<span class=\"hljs-string\">'accuracy'</span>, <span class=\"hljs-string\">'loss'</span>])\n</code></pre>\n<p><img src=\"/assets/img/2024-05-27-DepressionpredictionusingDeepLearninglearnbasicsofNLP_2.png\" alt=\"image\"></p>\n<div class=\"content-ad\"></div>\n<p>각 epoch마다 모델이 개선되었음을 확인할 수 있습니다. 정확도가 증가하고 손실이 감소했어요.</p>\n<h2>모델 테스트</h2>\n<p>이제 모델을 테스트해볼게요. 입력 텍스트에 texts_to_sequence 및 pad_sequences를 수행할 필요가 있다는 것을 잊지 마세요.</p>\n<pre><code class=\"hljs language-js\">test_sentence = [<span class=\"hljs-string\">'the life became so hard i can not take it any more i just wanna die '</span>]\ntest_sentence = tokenizer.<span class=\"hljs-title function_\">texts_to_sequences</span>(test_sentence)\npadded_test_sentence = <span class=\"hljs-title function_\">pad_sequences</span>(test_sentence, maxlen=max_length)\n<span class=\"hljs-title function_\">print</span>(model.<span class=\"hljs-title function_\">predict</span>(padded_test_sentence))\n\n<span class=\"hljs-string\">''</span><span class=\"hljs-string\">'\noutput :\n[[0.6440944]]\n'</span><span class=\"hljs-string\">''</span>\n</code></pre>\n<div class=\"content-ad\"></div>\n<p>입력 텍스트 (test_sentence)에는 분명히 슬픈 감정이 있습니다. 모델의 출력값은 0.64로, 0.5보다 큽니다. 이전에 언급했듯이, 레이블 1로 할당되어 우울증이 긍정적이라는 것을 의미합니다.</p>\n<h1>GitHub:</h1>\n<p>아래 링크를 통해 GitHub에서 코드에 접근할 수 있습니다.</p>\n<h1>마지막 요청</h1>\n<div class=\"content-ad\"></div>\n<p>읽어 주셔서 감사합니다. 즐거워하셨으면 좋겠어요!</p>\n</body>\n</html>\n"},"__N_SSG":true}