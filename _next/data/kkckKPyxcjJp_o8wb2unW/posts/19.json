{"pageProps":{"posts":[{"title":"코로나19 데이터와 의료 시설 분석 인사이트와 추천 사항","description":"","date":"2024-06-23 16:52","slug":"2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations","content":"\n\n\n![2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations](/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_0.png)\n\n# 소개\n\n본 보고서는 의료 시설과 COVID-19 데이터와의 관련성을 종합적으로 분석하는 것을 목표로 합니다. 이 분석은 COVID-19 사례 수, 사망률, 점유율 및 각 주별 의료 시설의 분포와 같은 주요 측면을 탐구합니다. 데이터는 2020년부터 2023년까지 이어지며, 시간에 따른 트렌드와 패턴을 깊이 파악할 수 있습니다.\n\n지속적인 COVID-19 유행으로 인해 의료 부문에 상당한 영향을 미쳤으며, 의료 시설은 환자 치료와 관리에서 중요한 역할을 합니다. COVID-19 사례 및 의료 시설과 관련된 데이터를 이해하는 것은 공공 보건 및 의료 관리에 관여하는 의료 관리자, 정책 결정자 및 기타 이해 관계자들에게 중요합니다.\n\n\n<div class=\"content-ad\"></div>\n\n2020년부터 2023년까지 다수의 데이터셋을 결합하여 이 분석에 사용된 데이터를 작성했습니다. 이를 통해 상황이 어떻게 변화되고 있는지를 전체적으로 파악할 수 있었습니다. 이 데이터셋에는 사망자, COVID-19 사례, 및 병원의 점유율, 공급자 이름, 그리고 공급자 주소와 같은 다양한 병원 특성에 관한 세부 정보가 포함되어 있습니다.\n\n이 데이터를 분석하는 목표는 중요한 추세와 통찰을 발견하여 의사 결정을 안내하는 데 있습니다. 이러한 통찰은 COVID-19 바이러스의 확산을 막는 전략을 돕고, 자원을 효율적으로 할당하는 데 도움을 주며, 의료 시스템의 결함을 식별할 수 있습니다.\n\n이 보고서는 COVID-19 사례의 총 수, 사망률, 점유율, 그리고 주별 건강시설의 분포를 포함한 다양한 분석을 다룹니다. 이러한 분석은 건강시설에 미치는 COVID-19 영향에 대한 포괄적인 이해를 제공하며, 개선할 수 있는 분야와 미래 방향을 명확히 합니다.\n\n우리는 이 분석에서 파생된 결과 및 권고사항을 제시함으로써 의료관리자, 정책 결정자, 그리고 의료 데이터 분석 분야에 관심을 가지는 사람들에게 유용한 통찰을 제공하기를 희망합니다. 이 보고서는 의료 부문 대비 준비 상태, 자원 할당, 그리고 기술 개발을 개선하기 위한 조치 및 데이터 기반 의사 결정의 시작점 역할을 합니다.\n\n<div class=\"content-ad\"></div>\n\n아래 섹션에서는 의료 시설 및 COVID-19 데이터를 분석한 결과 도출된 주요 결론, 분석 방법론 및 제안 사항에 대해 다룹니다.\n\n## 의료 시설 개요\n\n본 분석에 사용된 의료 시설 데이터셋에는 다양한 의료 제공자에 대한 포괄적인 정보가 포함되어 있습니다. 해당 데이터셋에는 이러한 시설들이 보고한 COVID-19 사례, 사망자 및 회복자에 대한 데이터가 포함되어 있습니다. 이 데이터셋은 병원, 양로원, 의료 센터 등 다양한 의료 제공자를 다루고 있습니다.\n\n데이터셋은 여기에서 찾을 수 있습니다. 데이터 사전은 여기에서 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 데이터 정제\n\n의료 시설 데이터 집합을 분석하는 동안 다음과 같은 데이터 정제 및 프로필링 단계가 수행되었습니다:\n\n- 결측값 처리: 결측값을 식별하고 데이터의 완전성과 정확성을 보장하기 위해 적절히 처리하였습니다.\n- 데이터 유효성 검사: 데이터 무결성 검사를 수행하여 데이터 집합에서 불일치나 이상을 식별했습니다. 잘못된 또는 일관성 없는 데이터 항목이 수정되거나 제거되어 데이터 품질을 유지하였습니다.\n- 데이터 변환: 데이터 유형 변환과 같은 필요한 데이터 변환을 적용하여 분석 및 시각화 작업을 용이하게 하였습니다.\n- 데이터 품질 평가: 데이터 집합의 전반적인 품질을 완전성, 정확성, 일관성 및 신뢰성 기준으로 평가하였습니다. 데이터 품질 문제를 해결하여 분석 결과의 신뢰성을 보장하였습니다.\n\n이러한 데이터 정제 및 프로필링 단계를 수행함으로써 데이터 집합이 신뢰성 있고 일관성 있으며 추가 분석을 위해 준비되었습니다. 이는 데이터 집합에서 도출된 통찰력의 신뢰성과 정확성을 향상시킵니다.\n\n<div class=\"content-ad\"></div>\n\n# 분석 및 결과\n\n- 2021년에 가장 많은 평균 일일 COVID-19 케이스를 보유한 의료 시설은 어디인가요? 상위 10개 시설을 표시하세요.\n\n```js\n--2021년에 가장 많은 평균 일일 COVID-19 케이스를 가진 의료 시설은 어디인가요? 상위 10개 시설 표시.\nSELECT TOP 10 Provider_Name, ROUND(AVG(Residents_Weekly_Confirmed_COVID_19),2) AS average_daily_cases\nFROM [dbo].[faclevel_2021]\nGROUP BY Provider_Name\nORDER BY average_daily_cases DESC;\n```\n\n![Healthcare Facilities Data Analysis](/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_1.png)\n\n<div class=\"content-ad\"></div>\n\n- NELLA'S AT AUTUMN LAKE HEALTHCARE은 평균 29건의 일일 COVID-19 케이스로 가장 높은 평균을 기록하며 돋보입니다. 이는 시설의 위치, 지역 커뮤니티 전파율, 검사 프로토콜, 감염 통제 조치, 환자 인구 통계 및 자원 배정과 같은 다양한 요인으로 인해 발생할 수 있습니다.\n- 일일 평균 7.5건의 케이스로 KENT COUNTY NURSING HOME이 뒤를 따르며, LAURELS OF HILLIARD THE는 평균 7건을 보고 있습니다. 이러한 시설들은 효과적인 예방 조치 또는 해당 지역의 COVID-19 유행률이 낮아 낮은 케이스 수를 경험할 수 있습니다.\n- 주목할만한 일일 평균 케이스를 가진 다른 시설로는 RIVERSIDE LIFELONG HEALTH AND REHABILITATION - M(4.38), WHITE OAK MANOR - CHARLOTTE(4.12), STOCKDALE RESIDENCE AND REHABILITATION CENTER(3.86), SAN MATEO MEDICAL CENTER D/P SNF(3.63), NORTHAMPTON COUNTY-GRACEDALE(3.37), ALLIED SERVICES SKILLED NURSING CENTER(3.29) 및 THE GRAND REHABILITATION AND NURSING AT UTICA(2.94)이 있습니다.\n\n2. 각 건강 시설의 COVID-19 케이스에 대한 7일 이동 평균을 계산하십시오. 이동 평균에서 가장 높은 피크를 기록한 시설은 무엇입니까?\n\n```js\n--각 건강 시설의 COVID-19 케이스에 대한 7일 이동 평균 계산. 가장 높은 피크를 기록한 시설은 무엇입니까?\nWITH cte AS (\n  SELECT \n    Provider_Name,\n    [Week_Ending],\n    [Residents_Weekly_Confirmed_COVID_19],\n    AVG([Residents_Weekly_Confirmed_COVID_19]) OVER (\n      PARTITION BY [Provider_Name] \n      ORDER BY CONVERT(DATE, [Week_Ending]) \n      ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n    ) AS moving_average\n  FROM (\n    SELECT [Provider_Name], [Week_Ending], [Residents_Weekly_Confirmed_COVID_19] \n    FROM [dbo].[faclevel_2020]\n    UNION ALL\n    SELECT [Provider_Name], [Week_Ending], [Residents_Weekly_Confirmed_COVID_19]\n    FROM [dbo].[faclevel_2021]\n    UNION ALL\n    SELECT [Provider_Name], [Week_Ending], [Residents_Weekly_Confirmed_COVID_19]\n    FROM [dbo].[faclevel_2022]\n    UNION ALL\n    SELECT [Provider_Name], [Week_Ending], [Residents_Weekly_Confirmed_COVID_19]\n    FROM [dbo].[faclevel_2023]\n  ) AS combined_data\n)\nSELECT TOP 10 [Provider_Name], MAX(moving_average) AS highest_peak\nFROM cte\nGROUP BY [Provider_Name]\nORDER BY highest_peak DESC;\n```\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n분석 결과, 최고 일일 COVID-19 케이스를 기록한 의료 시설이 강조되었습니다. 이러한 시설들은 특정 기간 동안 COVID-19 감염 증가로 큰 위기를 겪었습니다. 최고 피크 케이스를 가진 상위 10개 시설은 다음과 같습니다:\n\n- BRIGHTON REHABILITATION AND WELLNESS CENTER — 312 건\n- CHAPEL MANOR — 252 건\n- BERGEN NEW BRIDGE MEDICAL CENTER — 222 건\n- FAIR ACRES GERIATRIC CENTER — 178 건\n- ARDEN HOUSE — 173 건\n- MARPLE GARDENS REHABILITATION AND NURSING CENTER — 172 건\n- SPRING CREEK REHABILITATION AND NURSING CENTER — 168 건\n- ST JAMES REHABILITATION & HEALTHCARE CENTER — 166 건\n- COURTYARD NURSING CARE CENTER — 162 건\n- NEW VISTA NURSING & REHABILITATION CTR — 162 건\n\n이러한 결과는 COVID-19 전파를 완화하기 위해 의료 시설에서 견고한 감염 방지 조치 및 적시의 개입이 필요함을 강조합니다. 이러한 시설의 주민, 직원 및 방문객의 건강과 안녕을 보호하기 위해 효과적인 전략이 필수적입니다.\n\n3. 각 주별 COVID-19 케이스, 사망자 및 회복자의 총 수를 결정하십시오. 결과에는 주 이름과 해당 수를 포함하십시오.\n\n<div class=\"content-ad\"></div>\n\n```js\n-- 각 주별 COVID-19 총 환자 수, 사망자 수 및 회복자 수를 결정하세요. 결과에는 주 이름과 해당 수를 포함합니다.\nWITH cte AS (\n  SELECT\n    [Provider_State] AS State,\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS TotalCases,\n    SUM([Residents_Weekly_All_Deaths]) AS TotalDeaths,\n    SUM([Residents_Weekly_Confirmed_COVID_19] - [Residents_Weekly_All_Deaths]) AS TotalRecoveries\n  FROM (\n    SELECT [Provider_State], [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2020]\n    UNION ALL\n    SELECT [Provider_State], [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2021]\n    UNION ALL\n    SELECT [Provider_State], [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2022]\n    UNION ALL\n    SELECT [Provider_State], [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2023]\n  ) AS combined_data\n  GROUP BY [Provider_State]\n)\nSELECT State, TotalCases, TotalDeaths, TotalRecoveries\nFROM cte;\n```\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_3.png\" />\n\n분석은 주별 COVID-19 사례, 사망 및 회복 요약을 제공합니다. 다음 중요 지표가 제시됩니다:\n\n- TotalCases: 각 주에서보고된 COVID-19 사례의 총 수.\n- TotalDeaths: 각 주에서 COVID-19로 인한 사망한 사람들의 총 수.\n- TotalRecoveries: 각 주에서 COVID-19 완치한 사람들의 총 수.\n\n<div class=\"content-ad\"></div>\n\n다음은 주목할 만한 관찰 내용입니다:\n\n- 총 확진자 수가 가장 높은 주는 캘리포니아(132,178)이며, 그 뒤를 텍사스(118,726)와 뉴욕(103,308)이 따릅니다.\n- 총 사망자 수가 가장 높은 곳은 뉴욕(81,941)으로, 그 뒤를 오하이오(63,129)와 일리노이(49,104)가 차지합니다.\n- 플로리다(40,989), 일리노이(33,064), 캘리포니아(79,929) 등 여러 주에서 상당 수의 회복 사례가 보고되었습니다.\n\n이 통계 자료는 각 주에서의 COVID-19의 영향을 엿보게 해주며, 각 주별 사례, 사망자 수, 회복 방향의 다양성을 강조합니다. 바이러스 전파를 방지하고 각 주 개인의 안녕을 위해 효과적인 조치를 시행하는 것이 얼마나 중요한지를 강조합니다.\n\n2022년에 사망률(COVID-19 사례당 사망자 수)이 가장 높은 상위 5개 주를 찾아보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\n-- 2022년에 사망률이 가장 높은 상위 5개 주를 찾습니다.\nWITH cte AS (\n  SELECT\n    [Provider_State] AS State,\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS TotalCases,\n    SUM([Residents_Weekly_All_Deaths]) AS TotalDeaths,\n    SUM([Residents_Weekly_Confirmed_COVID_19] - [Residents_Weekly_All_Deaths]) AS TotalRecoveries\n  FROM [dbo].[faclevel_2022]\n  GROUP BY [Provider_State]\n)\nSELECT TOP 5\n  State,\n  TotalDeaths,\n  TotalCases,\n  ROUND(TotalDeaths * 100.0 / TotalCases, 2) AS MortalityRate\nFROM cte\nORDER BY MortalityRate DESC;\n```\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_4.png\" />\n\n다음은 주목할 만한 관측 결과입니다:\n\n- 북 다코타(ND)가 84.46%의 가장 높은 사망률을 보유하고 있으며, 남 다코타(SD)가 77.65%로 그 뒤를 이었으며, 네브래스카(NE)는 74.62%로 세 번째입니다.\n- 미네소타(MN)와 위스콘신(WI)도 각각 72.82%와 71.45%로 비교적 높은 사망률을 갖고 있습니다.\n\n<div class=\"content-ad\"></div>\n\nCOVID-19이 특정 주에 미친 영향의 심각성을 강조하며, 더 높은 사망률은 총 사례 대비 사망 비율이 높음을 나타냅니다.\n\n5. 2020년부터 2021년까지 COVID-19 사례에서 상당한 증가를 경험한 의료 시설을 식별하세요 (50% 이상 증가).\n\n```js\n--2020년부터 2021년까지 COVID-19 사례에서 상당한 증가를 경험한 의료 시설을 식별하세요 (50% 이상 증가).\n--시설명 및 백분율 증가를 표시하세요.\nWITH cte AS (\n  SELECT\n    [Provider_Name],\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS Cases_2020,\n    (SELECT SUM([Residents_Weekly_Confirmed_COVID_19])\n     FROM [dbo].[faclevel_2021]\n     WHERE [Provider_Name] = f.[Provider_Name]) AS Cases_2021\n  FROM [dbo].[faclevel_2020] AS f\n  GROUP BY [Provider_Name]\n)\nSELECT TOP 10\n  [Provider_Name],\n  CASE WHEN Cases_2020 = 0 THEN NULL\n       ELSE ((Cases_2021 - Cases_2020) * 100.0 / NULLIF(Cases_2020, 0))\n  END AS PercentageIncrease\nFROM cte\nWHERE Cases_2021 > Cases_2020 * 1.5\nORDER BY PercentageIncrease DESC;\n```\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_5.png\" />\n\n<div class=\"content-ad\"></div>\n\n가장 높은 증가율을 기록한 상위 10개 시설은 다음과 같습니다:\n\n- Chautauqua Nursing and Rehabilitation Center — 증가율: 11,200%\n- Delmar Center for Rehabilitation and Nursing — 증가율: 10,300%\n- Carthage Center for Rehabilitation and Nursing — 증가율: 9,800%\n- Cheshire Regional Rehab Center — 증가율: 9,500%\n- Cityview Nursing and Rehabilitation Center — 증가율: 9,000%\n- McCormick Rehabilitation and Healthcare Center — 증가율: 8,800%\n- MediLodge of Okemos — 증가율: 8,700%\n- MediLodge of Howell — 증가율: 8,600%\n- Auburn Rehabilitation & Nursing Center — 증가율: 8,500%\n- Park Bend Health Center — 증가율: 8,500%\n\n이러한 시설들은 이전과 비교해 COVID-19 사례가 상당히 증가했음을 나타냅니다. 그들의 시설 내 감염율이 높아졌음을 시사합니다.\n\n6. 데이터셋에 기록된 COVID-19 사례, 사망자 수, 회복자 수의 총합은 무엇입니까?\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- 데이터셋에 기록된 총 COVID-19 환자 수, 사망자 수 및 회복자 수는 얼마인가요?\nSELECT\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS 총확진자수,\n    SUM([Residents_Weekly_All_Deaths]) AS 총사망자수,\n    SUM([Residents_Weekly_Confirmed_COVID_19] - [Residents_Weekly_All_Deaths]) AS 총회복자수\nFROM (\n    SELECT [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2020]\n    UNION ALL\n    SELECT [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2021]\n    UNION ALL\n    SELECT [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2022]\n    UNION ALL\n    SELECT [Residents_Weekly_Confirmed_COVID_19], [Residents_Weekly_All_Deaths]\n    FROM [dbo].[faclevel_2023]\n) AS 결합된_데이터;\n```\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_6.png\" />\n\n제공된 데이터를 기반으로:\n\n- 총 COVID-19 환자 수: 1,632,695\n- 총 COVID-19 사망자 수: 1,058,889\n- 총 COVID-19 회복자 수: 573,806\n\n\n<div class=\"content-ad\"></div>\n\n이 숫자들은 COVID-19 환자 수, 사망자 수 및 회복자 수를 누적한 것입니다. 새로운 사례가 보고되고 사람들이 바이러스로부터 회복됨에 따라 이 숫자들이 시간이 지남에 따라 변할 수 있다는 점을 주목하는 것이 중요합니다.\n\n6. COVID-19 사례가 연이어 5개월 이상 증가한 의료 시설을 찾아보세요. 해당 시설 이름과 해당하는 월을 표시하세요.\n\n```js\n--COVID-19 사례가 연이어 5개월 이상 증가한 의료 시설을 찾아보세요. 해당 시설 이름과 해당하는 월을 표시하세요.\nWITH cte AS (\n  SELECT\n    [Provider_Name],\n    [Week_Ending],\n    [Residents_Weekly_Confirmed_COVID_19],\n    ROW_NUMBER() OVER (PARTITION BY [Provider_Name] ORDER BY [Week_Ending]) AS RowNum\n  FROM [dbo].[faclevel_2020]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    [Week_Ending],\n    [Residents_Weekly_Confirmed_COVID_19],\n    ROW_NUMBER() OVER (PARTITION BY [Provider_Name] ORDER BY [Week_Ending]) AS RowNum\n  FROM [dbo].[faclevel_2021]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    [Week_Ending],\n    [Residents_Weekly_Confirmed_COVID_19],\n    ROW_NUMBER() OVER (PARTITION BY [Provider_Name] ORDER BY [Week_Ending]) AS RowNum\n  FROM [dbo].[faclevel_2022]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    [Week_Ending],\n    [Residents_Weekly_Confirmed_COVID_19],\n    ROW_NUMBER() OVER (PARTITION BY [Provider_Name] ORDER BY [Week_Ending]) AS RowNum\n  FROM [dbo].[faclevel_2023]\n)\nSELECT\n  [Provider_Name],\n  MIN([Week_Ending]) AS StartMonth,\n  MAX([Week_Ending]) AS EndMonth\nFROM cte\nWHERE [Residents_Weekly_Confirmed_COVID_19] > 0\nGROUP BY [Provider_Name], [Residents_Weekly_Confirmed_COVID_19] - RowNum\nHAVING COUNT(*) >= 5;\n```\n\n![이미지](/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_7.png)\n\n<div class=\"content-ad\"></div>\n\n7. 각 의료 시설의 사망률(사망자 수 대비 COVID-19 사례)을 계산하세요.\n\n```js\n-- 각 의료 시설의 사망률(사망자 수 대비 COVID-19 사례)을 계산하세요.\nWITH cte AS (\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2020]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2021]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2022]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2023]\n  GROUP BY [Provider_Name]\n)\nSELECT\n  [Provider_Name],\n  ROUND(Deaths * 100.0 / Cases,0) AS MortalityRate\nFROM cte\nWHERE Cases > 0\nORDER BY MortalityRate DESC;\n```\n\n![2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_8.png](/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_8.png)\n\n다음은 각 요양원 및 관련 사망률 목록입니다:\n\n<div class=\"content-ad\"></div>\n\n- WESTPARK A WATERS COMMUNITY — 1675.00\n- NASSAWADOX REHABILITATION AND NURSING — 1600.00\n- THIBODAUX HEALTHCARE AND REHABILITATION CENTER — 1600.00\n- MONTROSE HEALTHCARE CENTER — 1500.00\n- THE OASIS AT BEAUMONT — 1500.00\n- PARK MERRITT CARE CENTER — 1300.00\n- MILTON HOME, THE — 1200.00\n- PRUITTHEALTH — ASHBURN — 1200.00\n- LEGACY TRANSITIONAL CARE & REHABILITATION — 1200.00\n- THE LODGE AT TAYLOR — 1200.00\n- ANDBE HOME, INC — 1150.00\n- STERLING HEALTH CARE AND REHAB CENTER — 1100.00\n- WILMINGTON REHAB CENTER — 1067.00\n- OAK HILL REHABILITATION AND NURSING CARE CENTER — 1050.00\n- LAKE PLEASANT POST ACUTE REHABILITATION CENTER — 1033.00\n- CAMBRIDGE REHABILITATION & NURSING CENTER — 1000.00\n- ABRAMSON SENIOR CARE AT LANKENAU MEDICAL CENTER — 1000.00\n- BRIA OF GENEVA — 950.00\n- DE LUNA HEALTH AND REHABILITATION CENTER — 900.00\n- CAMELLIA GARDENS CENTER FOR NURSING AND REHAB — 900.00\n\n이 요금은 각 요양원과 관련된 사망률을 나타냅니다.\n\n8. 건강 시설 유형(예: 병원, 요양원)에 따라 COVID-19 결과에 중요한 차이가 있습니까?\n\n```js\n--각 건강 시설별 사망률(COVID-19 사망자 수당 사망자 수) 계산하기\nWITH cte AS (\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2020]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2021]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2022]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    SUM(CAST([Residents_Weekly_Confirmed_COVID_19] AS int)) AS Cases,\n    SUM(CAST([Residents_Weekly_COVID_19_Deaths] AS int)) AS Deaths\n  FROM [dbo].[faclevel_2023]\n  GROUP BY [Provider_Name]\n)\nSELECT TOP 20\n  [Provider_Name],\n  ROUND(Deaths * 100.0 / Cases,0) AS MortalityRate\nFROM cte\nWHERE Cases > 0\nORDER BY MortalityRate DESC;\n\n--건강 시설 유형(예: 병원, 요양원)에 따라 COVID-19 결과에 중요한 차이가 있습니까?\nWITH cte AS (\n  SELECT\n    [Provider_Name],\n    CASE\n      WHEN [Provider_Name] LIKE '%HOSPITAL%' THEN '병원'\n      WHEN [Provider_Name] LIKE '%NURSING HOME%' THEN '요양원'\n      WHEN [Provider_Name] LIKE '%HEALTH CENTER%' THEN '의료 센터'\n      WHEN [Provider_Name] LIKE '%HEALTHCARE AND REHAB CENTER%' THEN '의료 및 재활 센터'\n      WHEN [Provider_Name] LIKE '%CARE CENTER%' THEN '치료 센터'\n      ELSE '기타'\n    END AS 시설_유형,\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS 총_사례,\n    SUM([Residents_Weekly_All_Deaths]) AS 총_사망자,\n    SUM([Residents_Weekly_Confirmed_COVID_19] - [Residents_Weekly_All_Deaths]) AS 총_회복자\n  FROM [dbo].[faclevel_2020]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    CASE\n      WHEN [Provider_Name] LIKE '%HOSPITAL%' THEN '병원'\n      WHEN [Provider_Name] LIKE '%NURSING HOME%' THEN '요양원'\n      WHEN [Provider_Name] LIKE '%HEALTH CENTER%' THEN '의료 센터'\n      WHEN [Provider_Name] LIKE '%HEALTHCARE AND REHAB CENTER%' THEN '의료 및 재활 센터'\n      WHEN [Provider_Name] LIKE '%CARE CENTER%' THEN '치료 센터'\n      ELSE '기타'\n    END AS 시설_유형,\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS 총_사례,\n    SUM([Residents_Weekly_All_Deaths]) AS 총_사망자,\n    SUM([Residents_Weekly_Confirmed_COVID_19] - [Residents_Weekly_All_Deaths]) AS 총_회복자\n  FROM [dbo].[faclevel_2021]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    CASE\n      WHEN [Provider_Name] LIKE '%HOSPITAL%' THEN '병원'\n      WHEN [Provider_Name] LIKE '%NURSING HOME%' THEN '요양원'\n      WHEN [Provider_Name] LIKE '%HEALTH CENTER%' THEN '의료 센터'\n      WHEN [Provider_Name] LIKE '%HEALTHCARE AND REHAB CENTER%' THEN '의료 및 재활 센터'\n      WHEN [Provider_Name] LIKE '%CARE CENTER%' THEN '치료 센터'\n      ELSE '기타'\n    END AS 시설_유형,\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS 총_사례,\n    SUM([Residents_Weekly_All_Deaths]) AS 총_사망자,\n    SUM([Residents_Weekly_Confirmed_COVID_19] - [Residents_Weekly_All_Deaths]) AS 총_회복자\n  FROM [dbo].[faclevel_2022]\n  GROUP BY [Provider_Name]\n  UNION ALL\n  SELECT\n    [Provider_Name],\n    CASE\n      WHEN [Provider_Name] LIKE '%HOSPITAL%' THEN '병원'\n      WHEN [Provider_Name] LIKE '%NURSING HOME%' THEN '요양원'\n      WHEN [Provider_Name] LIKE '%HEALTH CENTER%' THEN '의료 센터'\n      WHEN [Provider_Name] LIKE '%HEALTHCARE AND REHAB CENTER%' THEN '의료 및 재활 센터'\n      WHEN [Provider_Name] LIKE '%CARE CENTER%' THEN '치료 센터'\n      ELSE '기타'\n    END AS 시설_유형,\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS 총_사례,\n    SUM([Residents_Weekly_All_Deaths]) AS 총_사망자,\n    SUM([Residents_Weekly_Confirmed_COVID_19] - [Residents_Weekly_All_Deaths]) AS 총_회복자\n  FROM [dbo].[faclevel_2023]\n  GROUP BY [Provider_Name]\n)\n\nSELECT\n  시설_유형,\n  SUM(총_사례) AS 총_사례,\n  SUM(총_사망자) AS 총_사망자,\n  SUM(총_회복자) AS 총_회복자,\n  CASE\n    WHEN SUM(총_사례) > 0 THEN SUM(총_사망자) * 1.0 / SUM(총_사례)\n    ELSE 0\n  END AS 사망률\nFROM cte\nGROUP BY 시설_유형\nORDER BY 총_사례 DESC;\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_9.png\" />\n\n- 기타 시설: 총 사례 수: 1,290,082, 총 사망자 수: 843,209, 총 완치자 수: 446,873, 치명률: 65.36%\n- 요양원: 총 사례 수: 261,974, 총 사망자 수: 155,319, 총 완치자 수: 106,655, 치명률: 59.29%\n- 양로원: 총 사례 수: 41,367, 총 사망자 수: 31,065, 총 완치자 수: 10,302, 치명률: 75.10%\n- 보건 센터: 총 사례 수: 22,650, 총 사망자 수: 17,256, 총 완치자 수: 5,394, 치명률: 76.19%\n- 병원: 총 사례 수: 15,126, 총 사망자 수: 11,191, 총 완치자 수: 3,935, 치명률: 73.99%\n- 의료 재활 센터: 총 사례 수: 1,496, 총 사망자 수: 849, 총 완치자 수: 647, 치명률: 56.75%\n\n이러한 통계는 각 시설 유형별로 총 사례, 사망자, 완치자 및 치명률을 보여줍니다.\n\n9. COVID-19 사례 수가 시간이 지남에 따라 어떻게 변화했습니까(월별 또는 분기별)?\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- COVID-19 환자 수가 시간이 지남에 따라 어떻게 변화했습니까 (월별 또는 분기별)?\nWITH cte AS (\n  SELECT\n    '2020' AS [Year],\n    DATEPART(MONTH, [Week_Ending]) AS [Month],\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS TotalCases\n  FROM [dbo].[faclevel_2020]\n  GROUP BY DATEPART(MONTH, [Week_Ending])\n  UNION ALL\n  SELECT\n    '2021' AS [Year],\n    DATEPART(MONTH, [Week_Ending]) AS [Month],\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS TotalCases\n  FROM [dbo].[faclevel_2021]\n  GROUP BY DATEPART(MONTH, [Week_Ending])\n  UNION ALL\n  SELECT\n    '2022' AS [Year],\n    DATEPART(MONTH, [Week_Ending]) AS [Month],\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS TotalCases\n  FROM [dbo].[faclevel_2022]\n  GROUP BY DATEPART(MONTH, [Week_Ending])\n  UNION ALL\n  SELECT\n    '2023' AS [Year],\n    DATEPART(MONTH, [Week_Ending]) AS [Month],\n    SUM([Residents_Weekly_Confirmed_COVID_19]) AS TotalCases\n  FROM [dbo].[faclevel_2023]\n  GROUP BY DATEPART(MONTH, [Week_Ending])\n)\n\nSELECT\n  [Year],  [Month],\n  TotalCases AS [Total_Cases]\nFROM cte\nORDER BY [Year], [Month];\r\n```\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_10.png\" />\n\n여기에 월별 및 연도별 총 환자 수에 대한 요약이 있습니다:\n\n2020:  \n\n<div class=\"content-ad\"></div>\n\n- 5월: 103,428\n- 6월: 30,173\n- 7월: 40,303\n- 8월: 49,419\n- 9월: 29,419\n- 10월: 39,038\n- 11월: 110,936\n- 12월: 130,114\n\n2021:\n\n- 1월: 104,550\n- 2월: 14,656\n- 3월: 4,633\n- 4월: 4,162\n- 5월: 4,550\n- 6월: 1,604\n- 7월: 3,403\n- 8월: 19,983\n- 9월: 20,765\n- 10월: 18,248\n- 11월: 16,128\n- 12월: 20,437\n\n2022:\n\n<div class=\"content-ad\"></div>\n\n- 1월: 194,558\n- 2월: 58,284\n- 3월: 9,592\n- 4월: 8,612\n- 5월: 36,194\n- 6월: 35,521\n- 7월: 66,508\n- 8월: 52,004\n- 9월: 37,699\n- 10월: 51,372\n- 11월: 49,122\n- 12월: 74,699\n\n2023:\n\n- 1월: 81,054\n- 2월: 45,031\n- 3월: 35,215\n- 4월: 27,795\n- 5월: 3,486\n\n이 수치들은 각 월과 연도별로 보고된 총 사례 수를 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n10. 주별 의료 시설 분포는 어떻게 되나요?\n\n```js\n--주별 의료 시설 분포는 어떻게 되나요?\nWITH cte AS (\n  SELECT\n    [Provider_Name] AS Provider_Name,\n    [Provider_State] AS Provider_State\n  FROM [dbo].[faclevel_2020]\n  UNION ALL\n  SELECT\n    [Provider_Name] AS Provider_Name,\n    [Provider_State] AS Provider_State\n  FROM [dbo].[faclevel_2021]\n  UNION ALL\n  SELECT\n    [Provider_Name] AS Provider_Name,\n    [Provider_State] AS Provider_State\n  FROM [dbo].[faclevel_2022]\n  UNION ALL\n  SELECT\n    [Provider_Name] AS Provider_Name,\n    [Provider_State] AS Provider_State\n  FROM [dbo].[faclevel_2023]\n)\n\nSELECT\n  [Provider_State],\n  COUNT(DISTINCT [Provider_Name]) AS FacilityCount\nFROM cte\nGROUP BY [Provider_State]\nORDER BY FacilityCount DESC;\n```\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_11.png\" />\n\n# 대시보드\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_12.png\" />\n\n# 추천사항\n\n데이터 분석을 토대로 다음과 같은 추천사항이 제안되었습니다:\n\n1. 예방 조치 강화: 마스크 착용, 적절한 손 위생 실천, 거리두기 등의 예방 조치를 계속 강화하고 시행해야 합니다. 대중에게 이러한 조치가 COVID-19 전파 감소에 어떠한 중요성을 가지는지 강조하는 공공 인식 캠페인이 실시되어야 합니다.\n\n\n<div class=\"content-ad\"></div>\n\n2. 예방 접종 캠페인: COVID-19 백신을 홍보하고 모든 자격을 갖춘 사람들에게 백신을 제공할 수 있도록 노력을 강화하세요. 백신 망설임에 대처하고 접종률을 높이기 위해 대상 지역에 대한 열심히 홍보하고 교육을 실시하세요.\n\n3. 대상 중재: 증가된 사례 수를 갖는 지역이나 인구통계에 대한 대상 중재를 식별하고 증가된 검사, 접촉 추적 및 집중적인 의료 자원에 우선하여 대상 중재를 진행하세요. 전염병의 확산을 억제하고 그들의 추가 확산을 방지하기 위해 지역적인 전략을 시행하세요.\n\n4. 건강 시스템 대비: 의료 시설이 잠재적인 환자 수 증가에 대비할 충분한 수용량, 자원 및 인력을 갖추고 있는지 확인하세요. 의료 제공자와 협력하여 증가된 수용량 관리 및 보건 당국과의 협조를 포함한 대비 계획을 강화하세요.\n\n5. 데이터 모니터링 및 분석: 계속해서 데이터를 모니터링하고 분석하여 신흥되는 추세, 핫스팟 및 문제 지역을 식별하세요. 이 정보를 활용하여 의사 결정, 자원 할당 및 효과적인 공중보건 조치의 실행에 활용하세요.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n마무리하면, COVID-19 데이터 분석을 통해 공중 보건 대응과 의사 결정을 안내하는 가치 있는 통찰력과 권고사항을 제공했습니다.\n\n우리의 결론은 사용 가능한 데이터와 분석된 지역의 구체적인 상황을 기반으로 하고 있음을 강조하고 싶습니다. 지역 보건 당국은 이러한 발견을 공중 보건 전략을 수립하고 시행할 때 자신들의 데이터와 지침과 함께 고려해야 합니다.\n\nCOVID-19 대유행 대응은 정부 기관, 의료기관 및 대중의 협력과 집단적 노력이 필요합니다. 권고사항을 따르고 데이터 분석을 기반으로 전략을 계속적으로 적응시킴으로써 예방 조치의 효과를 향상시키고 접종률을 증가시키며 바이러스의 영향을 감소시킬 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n상황이 발전함에 따라 COVID-19 팬데믹으로 인한 도전에 대응하기 위해 계속해서 모니터링, 평가 및 전략적 적응이 필요할 것입니다. 함께 노력하여 바이러스 전파를 통제하고 공중 보건을 보호하며 정상 상태로 돌아가는 데 일조할 수 있습니다.\n\n트위터와 링크드인에서 저와 소통해보세요.\n\n여기서 저를 팔로우하지 않는 것을 잊지 마시고 더 많은 흥미로운 프로젝트를 확인하려면 내 미디엄 프로필을 읽어보세요.","ogImage":{"url":"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_0.png"},"coverImage":"/assets/img/2024-06-23-AnalysisofHealthcareFacilitiesandCOVID-19DataInsightsandRecommendations_0.png","tag":["Tech"],"readingTime":24},{"title":"호두 판매 사례 연구","description":"","date":"2024-06-23 16:51","slug":"2024-06-23-WalnutSalesCaseStudy","content":"\n\n호두 판매 탐험: 사례 연구 여정\n\n데이터 분석을 깊게 이해하고 실무 경험을 쌓기 위해 호두 판매에 초점을 맞춘 사례 연구를 시작했습니다. 이 프로젝트를 통해 고객 행동과 제품 수익 동태에 대한 소중한 통찰을 얻을 뿐만 아니라 데이터베이스 관리와 SQL 쿼리 작성 기술을 연마할 수 있었습니다.\n\n![Image](/assets/img/2024-06-23-WalnutSalesCaseStudy_0.png)\n\n데이터셋 획득 및 초기 설정~\n\n<div class=\"content-ad\"></div>\n\n먼저, 캐글에서 포괄적인 월넛 판매 데이터셋을 확보하여 다양한 측면을 아우르도록 세심하게 정리했습니다. 이 데이터셋을 사용하여 `walnut_sales`라는 전용 데이터베이스를 설정하고 그 안에 철저히 구조화된 테이블을 만들었습니다. 각 테이블은 적합한 열과 데이터 유형으로 세심하게 설계되어 이후 분석을 위해 최적의 구성과 사용성을 보장합니다.\n\n![Walnut Sales Case Study](/assets/img/2024-06-23-WalnutSalesCaseStudy_1.png)\n\n데이터 변환 및 준비\n\n기본 단계로, SQL 함수를 사용하여 `day_name` 및 `time_of_day`와 같은 보조 열을 생성했습니다. `DAYNAME()` 및 `MONTHNAME()`과 같은 기능을 활용하여 거래를 의미 있는 시간 및 요일 범주로 분류했습니다 — 아침, 오후, 저녁 또는 주중 구체적인 일 등. 이러한 분할은 자세한 시간적 분석과 추세 식별을 위한 기초를 마련했습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-WalnutSalesCaseStudy_2.png\" />\n\n초기 탐색적 분석\n\n분석의 초기 단계에서는 다음과 같은 핵심적인 통찰력을 발견하기 위해 노력했습니다:\n- 데이터셋에서 대표되는 독특한 도시와 지점 식별.\n- 고객들 사이에서 일반적인 결제 수단 분석.\n- 인기 있는 제품 라인과 해당 매출 분석.\n- 다양한 제품 라인에서 가장 큰 부가가치세(VAT) 기여를 계산하여 중요한 재정적 영향을 밝혀냈습니다.\n\n고급 분석 기술\n\n<div class=\"content-ad\"></div>\n\n기본 통찰력을 바탕으로, 나는 심층적인 통찰력을 추출하고 정교한 분석을 수행하기 위해 고급 SQL 기술을 활용했습니다:\n\n- CASE 문을 활용한 질적 평가: 수익성 지표나 고객 만족도 지수에 기반하여 각 제품 라인을 \"좋음\" 또는 \"나쁨\"으로 레이블링하여 제품 라인 데이터를 보완적으로 분석했습니다.\n- HAVING 절을 활용한 집계 필터링: 집계된 데이터를 필터링하기 위해 HAVING 절을 적용하여 매출 성과에 중대한 영향을 미치는 고객 세그먼트나 제품 카테고리를 식별했습니다.\n- 사용자 정의 함수: SQL 쿼리 내에서 복잡한 계산이나 비즈니스 로직을 캡슐화하기 위해 사용자 정의 함수를 개발하고 배포하여 반복적인 작업을 간소화하고 분석 효율성을 향상시켰습니다.\n\n# 결론 및 다음 단계\n\n이 심도있는 사례 연구를 통해 SQL 쿼리 및 데이터베이스 관리에 대한 능숙성을 향상시키는 동시에 소비자 선호도부터 재정적 영향까지 왈넛 판매 역학에 대한 세심한 이해를 개발했습니다. 실무 경험은 내 기술 세트를 풍부하게 해줄 뿐만 아니라 다양한 분야에 적용 가능한 실용적인 통찰력을 제공했습니다.\n\n<div class=\"content-ad\"></div>\n\n해당 연구 중 수행된 SQL 쿼리 및 분석 내용을 자세히 살펴보려면 Walnut 케이스 스터디를 여기에서 확인해보세요.\n\n호두 판매 데이터를 통해 진행된 이 여정은 데이터 기반 의사 결정의 힘을 보여주며, 심도 있는 사례 연구가 분석 능력을 갖추는 데 있어 혁신적 잠재력을 강조합니다.","ogImage":{"url":"/assets/img/2024-06-23-WalnutSalesCaseStudy_0.png"},"coverImage":"/assets/img/2024-06-23-WalnutSalesCaseStudy_0.png","tag":["Tech"],"readingTime":2},{"title":"SQL 윈도우 함수 완벽 정복 종합 튜토리얼","description":"","date":"2024-06-23 16:48","slug":"2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial","content":"\n\n# SQL 창 함수의 전체 잠재력을 발휘하세요. 기본적인 이해부터 고급 기술까지, 데이터 분석 및 쿼리 기술을 높이는 방법을 알아봅니다.\n\n![SQL Window Functions](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_0.png)\n\n# 창 함수란?\n\n데이터베이스 관리와 데이터 분석의 복잡한 영역을 탐험하는 것은 종종 미개척된 영토에서 탐험하는 것과 같은 기분일 수 있습니다. 숨겨진 패턴을 발견하고 원시 데이터에서 의미 있는 통찰력을 얻는 것에는 특별한 즐거움이 있습니다. SQL은 강력한 도구 세트로 이 여정에서 우리의 나침반 역할을 합니다.\n\n<div class=\"content-ad\"></div>\n\n길을 따라 가다 보면 기존 도구나 기술로 해결하기 어려운 도전이나 장애물에 부딪히곤 합니다. GROUP BY 작업에서 사용되는 \"집계 함수\"의 한계가 그 중 하나인 것이죠. 데이터 각 행에 대한 새로운 필드를 계산해야 하는 경우가 있을텐데, 이 경우에는 집계 함수 작업이 불가능합니다. 또한, 들어오는 데이터의 량이 지속적으로 변하는(즉, 정적이지 않은 데이터) 경우에 러닝 토탈, 평균 또는 다른 통계 측정치를 찾아야 하는 상황일 수도 있습니다.\n\n처음에는 SQL 창 함수(Window Functions)가 방대한 SQL 레퍼토리에 있는데 또다른 일련의 명령들로 보일 수 있지만, 이들은 특별한 힘을 지녔으며 숨겨진 묻힌 브러시로, 데이터를 다양한 가능성의 캔버스로 변신시키는 능력을 가지고 있습니다. 오늘은 이 강력한 함수들을 해부하고, 내재된 예술성과 효율성을 데이터 분석에 가져다주는 과정으로 나아가겠습니다.\n\n우리가 창 함수의 복잡함을 탐험하면서, 이들의 질문에 답하는 능력 뿐만 아니라 데이터와 함께 이야기를 만들어내며 행의 리듬과 숫자의 멜로디를 찾는 능력을 발견할 수 있을 것입니다. 데이터에 대한 감이 있는 데이터 초보자든, 숙련된 SQL 마에스트로든, 이 안내서는 창 함수의 복잡한 댄스를 안내하고 데이터의 심포니를 엿볼 수 있도록 디자인되어 있습니다.\n\n# 언제 창 함수를 사용해야 할까요? (ELI5)\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_1.png)\n\n어떤 건물 블록들이 있다고 상상해보세요. 각 건물 블록은 어떤 데이터를 나타냅니다. 여러분의 작업은 특정한 블록 그룹을 살펴보거나 이미 있는 블록들에 의존하여 새로운 블록을 만드는 것입니다.\n\n## 1. 블록을 섞지 않고 비교하려면?\n\n한 블록이 옆에 있는 블록들보다 더 큰지 확인하고 싶다고 상상해보세요. 윈도우 함수를 사용하면 모든 블록들을 섞지 않고 각 블록과 그 이웃들을 쉽게 비교할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n## 2. 한 행의 블록을 세거나 더하려고 합니다\n\n만약 한 열에 총 몇 개의 블록이 있는지 세고, 블록의 숫자를 더하려면, 창 함수를 사용하여 각 블록을 하나씩 살펴보고 누적 합계를 유지할 수 있습니다. 이를 통해 해당 블록들의 러닝 평균을 찾을 수도 있습니다!\n\n## 3. 섹션에서 가장 큰 또는 작은 블록을 찾고 싶습니다\n\n예를 들어, 색으로 정렬된 블록이 행별로 있고, 각 행에서 가장 큰 블록을 찾고 싶다고 가정해 봅시다. 창 함수를 사용하면 각 행을 개별적으로 살펴보고 각 행에서 가장 큰 블록을 선택할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 4. 블록에 점수 또는 순위를 부여하고 싶다면\n\n만약 각 블록에 크기나 색상에 따라 점수나 순위를 부여하고 싶으면 창 함수가 그 역할을 맡을 수 있습니다. 이 함수는 모든 블록을 살펴보고, 원하는 대로 정렬한 뒤, 각 블록에 번호를 부여하여 해당 블록이 전체 블록 세트에서의 순위를 표시합니다.\n\n## 5. 블록이 주변 블록들과 비교되는 방법을 알고 싶다면\n\n어떤 블록이 주변 블록들의 평균 높이보다 크다면 어떨지 보고 싶을 수 있습니다. 창 함수는 특정 블록과 그 주변 블록들을 살펴보고, 평균 높이를 계산한 다음 해당 블록이 어떻게 비교되는지 알려줄 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n윈도우 함수는 현재 행과 관련된 일련의 행을 기반으로 계산을 수행하는 SQL 작업입니다. 집계 함수와 달리 행을 단일 출력 행으로 그룹화하지 않으며, 행은 각각 별도로 유지됩니다. 윈도우 함수는 현재 행과 관련된 일련의 행을 기반으로 계산을 수행할 수 있습니다. 이러한 함수는 행들의 “윈도우”를 통해 계산을 수행하므로 윈도우 함수라고 불립니다. 예를 들어, 매출의 누적 합계를 계산하거나 그룹에서 가장 높은 점수를 찾을 수 있습니다.\n\n집계 함수와 비교하면 어떻게 다른지 아래 이미지를 참조하세요.\n\n![윈도우 함수 이미지](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_2.png)\n\n# 윈도우 함수의 구조\n\n<div class=\"content-ad\"></div>\n\nWindow Functions을 설명하는 것은 많은 사람들이 매우 복잡한 방법을 사용하는데, 저의 목표는 여러분을 위해 정말 쉽게 설명하는 것입니다!\n\n창문 함수(Window Functions)를 상상해보세요. 관광 버스에 타고 창문을 통해 바라보고 있는 것과 같아요. 한 가지씩 보여지는 것을 보죠, 맞죠? SQL 창문 함수는 그것처럼 작동합니다. 데이터를 한 행씩 보며, 그 전에 봤던 것과 다음에 오는 것을 기억해요. 관광 중에 사진 기억력이 있는 것과 같아요!\n\n![이미지](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_3.png)\n\n- 함수(Function): 이것은 SUM, AVG, MAX 또는 필요한 다른 함수일 수 있어요. 수학 연산을 수행하려는 핵심입니다. 이것들은 일반적인 집계 함수와 유사하지만 반환되는 행의 수를 줄이지는 않아요.\n- OVER(): SQL에게 특별한 작업을 할 것이라고 알리는 부분으로, 창문 함수(Window Function)를 준비하는 역할을 해요. OVER()는 SQL의 창문 함수의 기초입니다. 이 절은 함수가 처리할 \"창문\" 또는 데이터 하위 집합을 지정할 수 있도록 권한을 부여해요.\n- PARTITION BY: (선택 사항) 데이터의 특정 청크(그룹)에 대해 계산을 수행하려면 SQL에 나눌 방법을 알려주는 것입니다. PARTITION BY가 지정되지 않으면 함수는 쿼리 결과 세트의 모든 행을 단일 파티션으로 처리해요. GROUP BY 절과 유사하게 작동하지만 GROUP BY는 데이터를 집계하지만 PARTITION BY는 데이터를 그룹화하지만 창 함수의 목적을 위해 데이터를 그룹화하지 않아요.\n- ORDER BY: (선택 사항) 각 파티션 내의 행을 순서대로 정렬합니다. ORDER BY가 지정되지 않으면 함수는 파티션의 모든 행을 단일 그룹으로 처리해요.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_4.png\" />\n\n이제 SQL 코드에서 이를 실제로 확인해 봅시다:\n\n```js\nSELECT column_name, \n       WINDOW_FUNCTION(column_name) OVER (\n           PARTITION BY column_name \n           ORDER BY column_name \n           RANGE/ROWS BETWEEN ... AND ...\n       ) \nFROM table_name;\n```\n\n그렇습니다! 이제 윈도우 함수가 어떻게 작동하는지 간단히 살펴보았습니다. 물론 이를 연결시키기 위해 몇 가지 기본적인 예제를 살펴보고 싶으실 것입니다. 그러므로 다음에 그것을 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# 기억에 남는 예시\n\n간단한 판매 데이터와 이 판매 데이터의 항목들이 있다고 상상해 봅시다.\n\n# 1. 러닝 토탈\n\n```js\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  SaleDate, \n  SUM(SaleAmount) OVER (ORDER BY SaleDate) AS RunningTotal\nFROM Sales;\n``` \n\n<div class=\"content-ad\"></div>\n\n이 코드는 SaleDate 기준으로 각 행의 SaleAmount 누적 총액을 계산합니다. 아래 결과를 확인해보세요. 새로운 RunningTotal이라는 열을 주목해주세요! 여기서 새로운 열을 만들었습니다! 다른 곳에서 \"계산된 필드\"로 본 적이 있을 수도 있어요.\n\n# 2. 누적 합계 (판매 담당자별)\n\n이제 만약 판매 팀 구성원마다 시간이 지남에 따라 어떻게 변하는지 확인하고 싶다면 어떻게 할까요? 판매 팀에서 숫자(즉, 목표)를 추적하는 것은 매우 중요하므로 우리는 데이터 집합 전체에 대한 Running Total을 계산하는 것이 아니라 각 팀 구성원마다 총액을 계산하는 다른 요구 사항을 가질 수 있습니다. 이런 경우를 어떻게 다룰까요?\n\n먼저 코드와 결과를 확인해보고, 모든 것이 더 분명해질 것입니다. 그런데 먼저 이 코드에서 지난 예제와 비교했을 때 어떤 변경 사항이 있는지 찾아보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  SaleDate, \n  SUM(SaleAmount) OVER (PARTITION BY Salesperson ORDER BY SaleDate) AS CumulativeSalePerPerson\nFROM Sales;\n```\n\n만약 새로운 필드 \"CumulativeSalePerPerson\"을 살펴보면 패턴이 조금 더 어려운 것을 알 수 있지만, 세 번째 행에 도달하면 훨씬 명확해집니다. \"Alice\"는 첫 번째 행에서 \"300\"의 판매를 하였고, 그 다음 세 번째 행에서 \"200\"의 판매를 하여 해당 시점에서 누적 판매액은 \"500\"이 되었습니다. 비슷하게, Bob은 두 번째와 다섯 번째 행에 판매 내역이 있으므로, 다섯 번째 행에서 \"300\"의 판매를 기록하여 이전의 \"150\"에 더하여 \"450\"에 도달합니다. 이렇게 간단합니다! 일반 SQL 쿼리로 이 작업을 어떻게 수행할지 생각해 보는 것은 불가능할 것입니다!\n\n<img src=\"/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_5.png\" />\n\n# 3. 판매 금액에 따른 판매 순위 매기기\n\n\n<div class=\"content-ad\"></div>\n\n이제 상상해 봐주세요. 우리가 가장 큰 승리(가장 큰 물고기를 낚는)가 성공적인 판매 대회가 진행 중이라면 어떨까요?\n\n![이미지](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_6.png)\n\n당연히 우리는 순위를 쉽게 매길 방법을 원할 것입니다. 일반 쿼리로는 SaleAmount를 기준으로 ORDER BY SaleAmount DESC로 간단히 정렬하고 싶을 수 있지만, 다른 데이터의 기존 순서를 잃어버릴 수 있습니다. 이때 RANK() 함수가 필요합니다!\n\n```js\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  SaleDate, \n  RANK() OVER (ORDER BY SaleAmount DESC) AS SaleRank\nFROM Sales;\n```\n\n<div class=\"content-ad\"></div>\n\n9번째 행으로 내려갔을 때, Alice가 \"450\"의 가장 큰 어핻을 잡아 1위에 올랐음을 확인할 수 있어요! 그녀는 또한 3번째, 5번째, 10번째, 12번째, 14번째 \"순위\" 어핻을 잡았습니다.\n\n# 4. 판매액의 이동평균 (3일)\n\n바쁜 판매 팀으로서, 팀이 매출 목표를 달성하기 위해 나아가고 있는 전체적인 추세를 찾는 것은 중요합니다. 총계보다는 추세를 찾고 있다면, 3일 이동평균은 일일 변동을 완화하고 매출의 전반적인 방향을 강조합니다. 이는 개별적인 브러쉬 스트로크에 집중하는 대신 그림 전체를 보기 위해 일어서서 바라볼 때와 같은 느낌입니다.\n\n![image](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_7.png)\n\n<div class=\"content-ad\"></div>\n\n이 예제는 간단화를 위해 3일 창으로 설정하였지만, 7일 (주간 이동평균), 30일 (월간), 또는 어떤 기간을 살펴볼지 결정하셔도 됩니다! (참고: 이러한 창 함수는 한 줄에 굉장히 길어져서 코드 스타일링을 위해 적절한 공백으로 구분하셔야 합니다).\n\n```js\nSELECT SaleID, SaleDate, Salesperson, SaleAmount, \n       AVG(SaleAmount) OVER (\n                    ORDER BY SaleDate \n                    ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING\n                            ) AS MovingAverage\nFROM Sales;\n```\n\n우리는 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING을 사용하여 각 행의 이전 날과 다음 날을 살펴보았습니다 (즉, \"창\"을 생성하였습니다). 아마도 이것이 왜 누군가 이러한 함수들을 이런 이름으로 부르게 된 가장 관련성 있는 이유일 것입니다!\n\n이제 창 함수를 이용한 몇 가지 시행을 끝냈으니, 여러분이 스스로 묻고 있는 굉장히 중요한 질문이 있을 수 있습니다...\n\n<div class=\"content-ad\"></div>\n\n## 창 함수의 중요성\n\n창 함수(Window Functions)와 GROUP BY 집계 함수(Aggregate Functions)의 주요 차이점은 집계 함수가 각 그룹의 행에 대해 단일 결과를 반환하는 반면에(예: 그룹의 합계 또는 평균), 창 함수는 각 행마다 결과를 반환하며 종종 창(Window) 내 다른 행과 관련하여 작동합니다(예: 각 행에 대한 러닝 토탈). 제 학생들 중에는 이것이 창 함수가 작동하는 방법을 이해하는 핵심이자 더욱 중요한 이유라고 생각하는 경우가 많습니다.\n\nSQL 창 함수를 마스터하는 것은 데이터 조작 도구 상자에 강력한 도구를 추가하는 것과 같습니다. 이들은 복잡한 데이터 분석과 보고를 위한 고급 기능을 제공하여 통찰력을 얻고 정보 기반 결정을 내릴 수 있게 해줍니다. 러닝 토탈 계산, 결과 순위 매기기 또는 개별 행을 집계된 데이터셋 측정 지표와 비교하는 등, 창 함수는 필수불가결합니다. SQL 여정에서 이를 받아들이면 쿼리가 효율적이고 명확해지는 새로운 수준에 도달할 것입니다!\n\n창 함수의 복잡성에 더 깊이 파고들기 전에, SQL은 데이터 조작 기술을 향상시키기 위한 다양한 도구와 기능을 제공한다는 점을 어떻게든 눈여겨보는 것이 가치가 있습니다. 저희의 SQL 마스터리 시리즈를 따라오고 계시다면, 과거에 해당 주제에 대해 자세히 다룬 SQL 서브쿼리 마스터리 가이드를 기억하실 수도 있습니다. 서브쿼리를 이해하는 것은 더 고급 SQL 주제인 창 함수를 포함한 강력한 기초를 다지는 중요한 단계입니다. 아직 이 주제를 탐험해보지 못하셨다면, 읽어 보는 것을 강력히 추천합니다(또는 날씨가 구름낀 날을 위해 독서 목록에 저장하는 것도 좋습니다). 이를 통해 이해를 확고히 하고 복잡한 SQL 쿼리 작성 능력을 향상시킬 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n실은 때로는 동일한 작업을 수행하기 위해 창 함수 또는 하위 쿼리를 모두 사용할 수 있는 경우도 있습니다. 진정한 SQL 숙련도를 갖추려면 답을 찾는 데 여러 가지 방법에 능숙해지고 가장 효율적인 경로를 선택하는 능력이 필요합니다. 이는 Query Optimization 측면에서 가장 효율적인 것을 고려하기도 하며, 이에 대한 자세한 내용은 Mastering SQL 시리즈 다른 부분에서 다룰 예정입니다.\n\n# 창 함수의 종류\n\n![창 함수 이미지](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_8.png)\n\n이제 창 함수에 대한 탄탄한 소개가 있으니, 사용 가능한 창 함수의 다양한 종류를 알아보는 시간을 갖도록 하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n집계 윈도우 함수\n\n이것들은 일반 집계 함수와 비슷하지만 반환된 행의 수를 줄이지 않습니다. 예시로는 SUM(), AVG(), MIN(), MAX(), COUNT() 등이 있습니다.\n\n- SUM(): 이 함수는 숫자 열의 합계를 반환합니다.\n- AVG(): 이 함수는 숫자 열의 평균을 반환합니다.\n- COUNT(): 이 함수는 지정된 조건과 일치하는 행의 수를 반환합니다.\n- MIN(): 이 함수는 선택한 열의 가장 작은 값 반환합니다.\n- MAX(): 이 함수는 선택한 열의 가장 큰 값을 반환합니다.\n\n## 순위 윈도우 함수:\n\n<div class=\"content-ad\"></div>\n\n이러한 함수들은 결과 집합의 파티션 내 각 행에 고유한 순위를 할당합니다(또는 전체 데이터 집합). 예시로는 ROW_NUMBER(), RANK(), DENSE_RANK(), NTILE()이 있습니다.\n\n![이미지](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_9.png)\n\n- RANK(): 이 함수는 결과 집합의 파티션 내 각 고유한 행에 고유한 순위를 할당합니다. 순위는 OVER() 절의 ORDER BY 절에서 지정된 순서대로 할당됩니다. 만약 두 개 이상의 행이 동일한 순위를 가지게 되면, 각 같은 순위의 행에 동일한 순위가 할당되고, 다음 순위들은 건너뜁니다.\n- DENSE_RANK(): 이 함수는 RANK()와 유사하게 작동하지만, 두 개 이상의 행이 동일한 순위를 가질 때, 다음 순위가 건너뛰지 않습니다. 따라서 만약 랭크 2에 세 개의 항목이 있다면, 다음 순위로 나열된 것은 3이 됩니다.\n- ROW_NUMBER(): 이 함수는 중복 여부와 상관 없이 파티션 내 각 행에 고유한 행 번호를 할당합니다. 정렬된 집합 내에 중복 값이 있는 경우에도 각 행에 다른 행 번호가 할당됩니다.\n- NTILE() 함수는 정렬된 파티션을 지정된 그룹 수 또는 \"타일\"로 나누고, 각 행에 그룹 번호를 할당합니다. 이는 데이터 집합을 사분위수, 십분위수 또는 다른 크기의 균등한 그룹으로 나누는 데 유용합니다.\n\n아래에서 각각의 순위 함수들을 코드로 어떻게 작성할 수 있는지 살펴보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\n-- RANK() 예시\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  RANK() OVER (ORDER BY SaleAmount DESC) AS RankByAmount\nFROM Sales;\n\n-- DENSE_RANK() 예시\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  DENSE_RANK() OVER (ORDER BY SaleAmount DESC) AS DenseRankByAmount\nFROM Sales;\n\n-- ROW_NUMBER() 예시\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  ROW_NUMBER() OVER (ORDER BY SaleAmount DESC) AS RowNumByAmount\nFROM Sales;\n\n-- NTILE() 예시\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  NTILE(4) OVER (ORDER BY SaleAmount DESC) AS Quartile\nFROM Sales;\n```\n\n## 값 윈도우 함수\n\n이 함수들은 각 파티션에서 특정 값을 반환합니다. 이러한 함수는 파티션에서 특정 데이터에 액세스하는 방법을 제공하여 결과 집합 내의 값들 간의 차이를 비교하거나 계산할 수 있게 합니다.\n\n![이미지](/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_10.png)\n\n\n<div class=\"content-ad\"></div>\n\n예시로는 FIRST_VALUE(), LAST_VALUE(), LEAD(), LAG() 함수가 있습니다.\n\n- FIRST_VALUE(): 이 함수는 파티션 내에서 정렬된 값 세트에서 첫 번째 값을 반환합니다. 예를 들어, 이 함수를 사용하여 판매원이 한 초기 판매를 찾을 수 있습니다.\n- LAST_VALUE(): 이 함수는 파티션 내에서 정렬된 값 세트에서 마지막 값을 반환합니다. 특정 제품의 가장 최근 판매 금액을 찾는 데 사용할 수 있습니다.\n- LEAD(): 이 함수는 동일한 결과 집합의 후속 행에서 데이터에 액세스할 수 있도록 하여 현재 값과 다음 행의 값을 비교하는 방법을 제공합니다. 두 연속 일자 간의 판매 금액 차이를 계산하는 데 유용합니다.\n- LAG(): LEAD()와 유사하지만, LAG() 함수는 결과 집합의 이전 행에서 데이터에 액세스할 수 있도록 해줍니다. 이것은 현재 데이터를 과거 데이터와 비교하는 데 유용합니다. 이러한 함수들은 데이터 분석을 위한 강력한 도구로, 데이터를 탐색하고 특정 데이터를 다른 데이터 포인트와 관련하여 통찰력을 얻을 수 있도록 도와줍니다.\n\n```js\n-- FIRST_VALUE()와 LAST_VALUE() 예제\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  FIRST_VALUE(SaleAmount) OVER (ORDER BY SaleDate) AS FirstSaleAmount,\n  LAST_VALUE(SaleAmount)  OVER (ORDER BY SaleDate \n                               RANGE BETWEEN UNBOUNDED PRECEDING AND \n                               UNBOUNDED FOLLOWING\n                               ) AS LastSaleAmount\nFROM Sales;\n\n-- LEAD()와 LAG() 예제\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  LAG(SaleAmount) OVER (ORDER BY SaleDate) AS PreviousSaleAmount,\n  LEAD(SaleAmount) OVER (ORDER BY SaleDate) AS NextSaleAmount\nFROM Sales;\n```\n\n# 윈도우 프레임 명시화\n\n<div class=\"content-ad\"></div>\n\n이 개념은 특정 행에 대한 계산을 수행하는 subset을 의미합니다. 창 프레임은 ROWS 또는 RANGE 절을 사용하여 지정할 수 있으며, 모든 행을 고려하는 비바운드(unbounded)일 수도 있고 특정 범위로 제한될 수도 있습니다.\n\nROWS: 물리적 행을 기준으로 창 프레임을 정의합니다. 정해진 행 수를 지정하거나 UNBOUNDED PRECEDING 및 UNBOUNDED FOLLOWING을 사용하여 모든 행을 포함할 수 있습니다.\n\nRANGE: 논리적 행 그룹을 기준으로 창 프레임을 정의합니다. ROWS와 유사하게 범위를 지정하거나 UNBOUNDED 옵션을 사용할 수 있습니다.\n\n```js\n-- ROWS 창 프레임 명세\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  AVG(SaleAmount) OVER (ORDER BY SaleDate ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING) AS MovingAvg\nFROM Sales;\n\n-- RANGE 창 프레임 명세\nSELECT \n  SaleID, \n  Salesperson, \n  SaleAmount, \n  SUM(SaleAmount) OVER (ORDER BY SaleAmount RANGE BETWEEN 50 PRECEDING AND 50 FOLLOWING) AS CumulativeSum\nFROM Sales;\n```\n\n<div class=\"content-ad\"></div>\n\n창 프레임 명세는 현재 행과 전체 파티션 대신 일부 행 집합에 걸쳐 계산을 수행하려는 경우 중요합니다.\n\n# 창 함수 문제 해결\n\n창 함수가 예상대로 작동하지 않는 경우 다음을 고려해보세요:\n\n- OVER 절을 확인하세요: OVER 절은 창 함수의 동작 방식을 결정합니다. PARTITION BY 및 ORDER BY 절을 올바르게 지정했는지 확인하세요.\n- 함수 구문을 검토하세요: 각 창 함수마다 고유한 구문이 있습니다. 사용 중인 함수의 구문을 확인하여 올바른지 확인하세요.\n- 데이터 유형을 검토하세요: 사용 중인 함수의 데이터 유형이 호환되는지 확인하세요. 예를 들어, 텍스트 필드(또는 숨겨진 문자열 값이 있는 열)에서 SUM 작업을 수행할 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n# 창 함수 최적화\n\n창 함수는 여러 행을 대상으로 계산을 수행하기 때문에 종종 쿼리 실행이 느려질 수 있습니다. 다음은 창 함수를 최적화하는 몇 가지 팁입니다:\n\n- 행 수 줄이기: 가능하다면 창 함수를 적용하기 전에 데이터를 필터링하세요. 함수가 작업해야 하는 행이 적을수록 쿼리가 더 빨리 실행됩니다. 이는 데이터의 전체 범위에 대해 거인을 풀기 전 코드를 디버그하고 실행할 수 있도록 보다 효율적으로 작업할 수 있는 최선의 방법입니다.\n- 적절한 인덱싱 사용: 데이터를 파티셔닝하거나 정렬하는 경우 해당 열에 적절한 인덱스가 있는지 확인하세요. 이렇게 하면 창 함수의 성능이 크게 향상될 수 있습니다.\n- 복잡한 정렬 피하기: 가능하다면 창 함수 내 ORDER BY 절에서 여러 열을 사용하는 것을 피하세요. 각 추가 열은 계산 시간을 증가시킬 수 있습니다.\n- 창 프레임 제한: 기본적으로 창 함수는 파티션 내 모든 행을 고려합니다. 모든 행을 고려할 필요가 없다면 ROWS 또는 RANGE 절을 사용하여 창 프레임을 제한하세요.\n\n이러한 고급 창 함수 및 컨셉을 활용하면 데이터에 복잡한 변환 및 계산을 수행하여 SQL 쿼리를 더 강력하고 통찰력 있게 만들 수 있습니다. 결과를 순위 매기거나 누적 합계를 계산하거나 파티션 내 특정 값에 액세스하는 경우, 창 함수는 고급 데이터 분석에 필요한 유연성과 기능성을 제공합니다. 이제 이를 깊이 이해한 후 항상 참고할 수 있는 편리한 치트 시트 (출처: learnsql.com)가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_11.png\" />\n\nSQL 윈도우 함수의 복잡한 기능을 탐험하면서, 복잡한 데이터 분석을 더 쉬운 작업으로 변환할 수 있다는 것을 발견했습니다. 이러한 고급 함수는 우리의 쿼리를 최적화하는 뿐만 아니라 데이터 탐색과 보고의 가능성을 열어줍니다. SQL 레퍼토리에 윈도우 함수를 접목하면서, 숙련의 핵심은 실습과 실험이라는 것을 기억하세요. 그러니, 깊이 파고들어 탐험하고, 고급 SQL 쿼리의 영역에서 윈도우 함수가 당신의 안내자 역할을 하게 해보세요.\n\n## WINDOW 함수 즐기기\n\n이 내용을 즐겼다면? 최신 프로그래밍 및 데이터 과학 안내서와 자습서를 Medium 피드로 바로 받아보려면 팔로우 버튼을 클릭하세요!\n\n<div class=\"content-ad\"></div>\n\n읽어 주셔서 감사합니다.","ogImage":{"url":"/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_0.png"},"coverImage":"/assets/img/2024-06-23-MasteringSQLWindowFunctionsAComprehensiveTutorial_0.png","tag":["Tech"],"readingTime":14},{"title":"Python과 SQL로 데이터 마스터하기 4가지 전략적 사용 사례를 통한 효율성과 보안 강화","description":"","date":"2024-06-23 16:46","slug":"2024-06-23-DataMasterywithPythonandSQLUnleashingEfficiencyandSecuritythrough4StrategicUseCases","content":"\n\n\n![Data Mastery with Python and SQL: Unleashing Efficiency and Security through 4 Strategic Use Cases](/assets/img/2024-06-23-DataMasterywithPythonandSQLUnleashingEfficiencyandSecuritythrough4StrategicUseCases_0.png)\n\n# 소개\n\n데이터 분석과 관리는 현대 기업 운영의 필수 구성 요소입니다. 데이터의 힘을 효과적으로 이용하기 위해 전문가들은 프로그래밍 언어와 도구의 조합을 활용하여 효율적인 데이터 처리, 조작 및 분석을 실현합니다. 이 기사에서는 데이터 분석가와 과학자들이 효과적인 의사 결정을 내리기 위해 널리 사용되는 두 가지 기본 언어인 Python과 SQL의 놀라운 기능을 탐색합니다.\n\nPython은 다양한 데이터 관련 도전 과제에 대처하기 위한 다양한 라이브러리와 프레임워크를 제공한다는 사실은 널리 알려져 있습니다. Python과 SQL은 함께 강력한 조합을 이루어 데이터 전문가들이 데이터의 최대 잠재력을 발휘하고 데이터베이스를 보다 효과적으로 탐색할 수 있도록 지원합니다.\n\n\n<div class=\"content-ad\"></div>\n\n이 기사에서는 Python과 SQL의 효과와 시너지를 보여주는 네 가지 구별된 사용 사례를 살펴봅니다. 각 사용 사례는 Python의 유연성과 SQL의 질의 능력이 결합된 능력이 돋보이는 고유한 시나리오를 대표합니다.\n\n자세히 알아보겠습니다!\n\n# 사용 사례\n\n사용 사례 1: Python으로 작성된 SQL 쿼리의 가독성 향상\n\n<div class=\"content-ad\"></div>\n\n웹 API를 사용하여 GridDB와 같은 클라우드 데이터베이스에 연결하고 SQL 쿼리를 실행하여 데이터를 검색하는 상황을 상상해보세요. JSON 페이로드를 수용하는 API 엔드포인트를 위한 HTTP 요청 본문을 작성할 때 SQL 쿼리를 요청 본문에 포함해야 합니다. 그러나 실제로는 다양한 어려움이 있을 수 있습니다.\n\n실제로 사용되는 SQL 쿼리는 점점 복잡해지며 적절한 들여쓰기, 줄 바꿈을 포함하고 코드를 읽기 쉽도록 형식화하는 것이 어려워질 수 있습니다. 또한 VScode 또는 Jupyter와 같은 Python 노트북에서 쿼리를 한 줄로 작성해야 하는 경우, 코드 기능을 설명하는 유용한 주석 행을 추가하는 것이 불가능해집니다. 이러한 쿼리가 포함된 노트북은 장기적으로 유지 및 디버깅하기 어려워집니다.\n\n아래 솔루션은 여러 줄에 걸쳐 SQL 쿼리를 작성할 수 있게 해 주어 코드의 가독성과 유지보수성을 향상시킵니다. 적절한 줄 바꿈과 들여쓰기를 사용하여 복잡한 쿼리를 쉽게 구성하고 이해할 수 있으며 명확성을 희생시키지 않고 처리할 수 있습니다.\n\n여기 Python에서 SQL 쿼리를 작성하는 더 좋은 방법이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nsql_query1 = (f\"\"\"\n-- 지역, 카테고리 및 판매 등급별로 판매 데이터를 분류하는 쿼리\n\nSELECT region,\n    CASE WHEN lower(category) LIKE 'a%' THEN 'Category A'\n         WHEN lower(category) LIKE 'b%' THEN 'Category B'\n         WHEN lower(category) LIKE 'c%' THEN 'Category C'\n         ELSE '기타 카테고리'\n    END AS category_classification,\n    CASE WHEN subquery.total_sales BETWEEN 1 AND 1000 THEN '낮은 판매량' \n         WHEN subquery.total_sales BETWEEN 1001 AND 5000 THEN '중간 판매량'\n         WHEN subquery.total_sales > 5000 THEN '높은 판매량'\n    END AS sales_classification\nFROM Sales_Dataset\nJOIN (\n    SELECT region, SUM(sales) AS total_sales\n    FROM Sales_Dataset\n    GROUP BY region\n) AS subquery\nON Sales_Dataset.region = subquery.region\nGROUP BY 1, 2\nORDER BY 3 DESC\n\"\"\")\n```\n\n그런 다음 아래와 같이 파이썬의 JSON 라이브러리를 사용하여 요청 본문에 전달할 수 있습니다 -\n\n```js\nimport json\n# 요청 본문 작성\nrequest_body = json.dumps([\n    {\n        \"type\": \"sql-select\",\n        \"stmt\": sql_query1\n    }\n])\n\n# 작성된 요청 본문 유효성 검사\nprint(request_body)\n```\n\nJSON 물체를 생성하며, 해당 물체에는 작업 유형(\"sql-select\")과 SQL 쿼리문(stmt)가 포함됩니다. json.dumps() 함수를 사용하여 파이썬 사전을 JSON 문자열 표현으로 변환합니다.\n\n<div class=\"content-ad\"></div>\n\n다음으로 requests 라이브러리를 사용하여 요청을 게시할 수 있습니다.\n\n```js\ndata_req1 = requests.post(url, data=request_body, headers=header_obj)\n```\n\n## 사용 사례 2: 텍스트 열에서 해시태그 추출\n\nTikTok와 Instagram과 같은 플랫폼의 소셜 미디어 분석을 수행할 때, API를 통해 데이터를 추출하고 Azure나 Redshift와 같은 데이터베이스에 저장하는 것이 일반적입니다. 그러나 API 응답에는 종종 콘텐츠가 문자열로 제공되며, 해시태그가 비디오 제목 전체에 흩어져 있는 경우가 많습니다. 이를 해결하기 위해 다음 쿼리를 사용하여 비디오 제목과 같은 텍스트 열에서 해시태그를 추출할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```sql\nselect * from \n(SELECT distinct TRIM(SPLIT_PART(title, '#', num)) AS hashtag\nFROM social_media_video_info\nCROSS JOIN (\n    SELECT 1 AS num UNION ALL\n    SELECT 2 AS num UNION ALL\n    SELECT 3 AS num UNION ALL\n    SELECT 4 AS num UNION ALL\n    SELECT 5 AS num UNION ALL\n    SELECT 6 AS num UNION ALL\n    SELECT 7 AS num UNION ALL\n    SELECT 8 AS num UNION ALL\n    SELECT 9 AS num UNION ALL\n    SELECT 10 AS num\n) AS nums\nWHERE num <= LENGTH(title) - LENGTH(REPLACE(title, '#', '')) + 1\n  AND TRIM(SPLIT_PART(title, '#', num)) <> ''\n) \nwhere hashtag not like '% %'\n```\n\n하위 쿼리는 다음 단계를 수행합니다:\n\n- 'social_media_video_info' 테이블의 'title' 열을 '#' 문자로 구분자로 사용하여 분할합니다.\n- SPLIT_PART(title, '#', num) 함수는 지정된 \"num\" 위치에서 '#'로 구분된 \"title\" 열의 일부를 추출합니다.\n- TRIM() 함수는 추출된 부분에서 선행 또는 후행 공백을 제거합니다.\n- DISTINCT 키워드는 고유한 해시태그만 선택됨을 보장합니다.\n- 부하 쿼리 \"nums\"와의 CROSS JOIN은 숫자 1에서 10까지를 가진 임시 결과 집합을 생성합니다.\n- 조건 num `= LENGTH(title) — LENGTH(REPLACE(title, ‘#’, ‘’)) + 1은 \"title\" 열의 해시태그 최대 수에 따라 분할이 이루어짐을 보장합니다.\n- 조건 TRIM(SPLIT_PART(title, ' # ', num)) `` ‘’는 빈 해시태그를 필터링합니다.\n- 요약하면 쿼리는 'social_media_video_info' 테이블의 'title' 열에서 '#'를 구분자로 사용하여 해시태그를 추출합니다. 고유하며 비어있지 않은 해시태그만 선택하며 결과에서 공백이 포함된 해시태그는 제외합니다. 이 쿼리는 제목 당 최대 10개의 해시태그만 고려합니다.\n\n## Use Case 3: Python에서 미래 및 폐기 경고 억제하기\n\n<div class=\"content-ad\"></div>\n\n이 몇 줄의 코드는 프로그램 실행 중 미래 경고와 사용이 중단된 경고를 억제하는 데 목적이 있습니다.\n\n```js\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=DeprecationWarning) \n```\n\n현재 라이브러리 버전과 호환되는 코드를 사용하고 있고 잠재적인 문제나 사용이 중단된 기능에 대해 알림을 받고 싶지 않은 경우 유용할 수 있습니다.\n\n경고는 종종 라이브러리의 미래 버전에서의 잠재적인 문제나 변경 사항에 대한 유용한 정보를 제공합니다. 경고가 발생하는 근본적인 문제를 완전히 무시하는 대신에 그에 대응하고 해결하는 것이 일반적으로 권장됩니다. 'warnings' 모듈은 파이썬 코드에서 어떻게 경고가 처리되는지 제어할 수 있는 simplefilter() 옵션도 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n## 사용 사례 4: 가능한 경우 매개변수화된 쿼리 사용\n\nPython을 사용하여 SQL 쿼리를 실행할 때, SQL 문에 값을 직접 포함하는 대신 매개변수화된 쿼리나 준비된 문장을 사용하는 것이 좋습니다. 이렇게 함으로써 SQL 인젝션 공격을 방지하고 데이터 유형을 올바르게 처리할 수 있습니다.\n\n만약 당신의 애플리케이션이나 스크립트가 아래의 select 쿼리를 사용한다고 가정해봅시다 -\n\n```js\nSELECT * FROM \nTABLE \nWHERE \nCOLUMN1 IN ('abcd')\n```\n\n<div class=\"content-ad\"></div>\n\n만약 공격자가 데이터베이스에 악의적인 값을 삽입하려고 한다면, 그들은 다음 쿼리를 사용하여 이를 수행할 수 있는 구멍을 이용할 수 있습니다. 아래는 공격자가 '선택 쿼리'에 삽입 문을 추가하여 데이터베이스에 불필요한 값들을 주입하는 방법의 기본 예시입니다. 아래 회색 부분은 공격자가 제공한 악의적인 입력으로, 결과적으로 한 번에 2개의 쿼리가 실행되는 것입니다 - 1. 선택하고 2. 삽입하다.\n\n![이미지](/assets/img/2024-06-23-DataMasterywithPythonandSQLUnleashingEfficiencyandSecuritythrough4StrategicUseCases_1.png)\n\n'테이블 삽입'에만 해당하는 것은 아닙니다. 공격자는 다른 선택, 업데이트, 삭제 또는 심지어 테이블 삭제를 실행할 수 있습니다. 'DROP TABLE'이 얼마나 재앙을 초래할 수 있는지 상상해보세요!\n\nSQL 주입은 입력을 살균화하거나 매개변수화함으로써 방지할 수 있습니다. 각각에 대한 자세한 내용을 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## 매개변수화\n\n매개변수화는 수동으로 또는 파이썬에서 사용할 수 있는 패키지를 통해 수행할 수 있습니다. 설문 응용 프로그램을 사용한다고 상상해보세요. 사용자가 채우기 위해 설문 조사를 보내는 상황입니다. 사용자들은 제공된 두 개의 텍스트 상자에 세부 정보를 입력하도록 요청받습니다. 사용자가 두 텍스트 상자에 세부 정보를 입력할 때마다 아래와 같이 백그라운드에서 Insert SQL 쿼리가 실행된다고 가정해 봅시다 -\n\ntheVal1 = 설문 텍스트 상자 1에서 가져옴\ntheVal2 = 설문 텍스트 상자 2에서 가져옴\n\n아래는 백그라운드에서 실행되는 응용 프로그램 코드입니다 -\n\n<div class=\"content-ad\"></div>\n\n```js\n  sql = \"INSERT INTO TABLE VALUES ('\" + theVal1 + \"','\" + theVal2 + \"')\"\n```\n\n만약 1번 사용자가 텍스트 상자 1에 A3를 입력하고 텍스트 상자 2에 A4를 입력한다면, 백엔드에서 실행되는 쿼리는 다음과 같을 것입니다 -\n\n```js\nINSERT INTO TABLE VALUES ('A3','A4')\n```\n\n만약 두 번째 사용자가 해커라면 굉장히 교활한 사용자일 겁니다. 이 사용자는 테이블 구조와 백엔드 쿼리를 이해하고 있다면, 이를 악의적으로 이용하여 추가적인 레코드를 삽입할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n사용자가 텍스트 상자 1에 값 A1을 입력하고 텍스트 상자 2에 다음 값을 입력한다고 가정해 봅시다.\n\n```js\nA2 ');INSERT INTO TABLE VALUES ('B1','B2\n```\n\n본질적으로 발생하는 일은 값이 백엔드 쿼리에 추가되어 아래와 같이 됩니다.\n\n```js\nINSERT INTO TABLE VALUES ('A1','A2');INSERT INTO TABLE VALUES ('B1','B2')\n```\n\n<div class=\"content-ad\"></div>\n\n그래서, 이 해킹 사용자에 의해 2개의 레코드가 삽입될 것입니다.\n\n당신의 테이블은 세 개의 값이 있을 것입니다. 첫 번째 사용자가 삽입한 값 1개와 두 번째 사용자가 삽입한 값 2개 -\n\n![image](/assets/img/2024-06-23-DataMasterywithPythonandSQLUnleashingEfficiencyandSecuritythrough4StrategicUseCases_2.png)\n\n## 입력 살균 처리\n\n<div class=\"content-ad\"></div>\n\n산소화는 입력 값의 특수 문자를 이스케이핑하여 수행할 수 있습니다. 이 작업은 대상 컨텍스트(예: SQL 쿼리)에서 특별한 의미를 가지는 문자를 해당하는 이스케이프 표현으로 대체하거나 인코딩하는 것을 포함합니다. 예를 들어 SQL에서는 작은따옴표(') 문자가 흔히 두 번 반복하여 이스케이프됩니다(그것을 대체함으로써 문자열에서 작은따옴표를 2개로 대체). 다시 말해, 쿼리에 입력 값을 넣기 전에 값을 수동으로 이스케이프할 수 있습니다. 이를 위해 str.replace를 사용할 수 있습니다.\n\n응용 프로그램 코드는 동일한 상태로 유지하면서 다음에 보여지는 몇 개의 문자열 대체 문을 추가합니다 -\n\ntheVal1 = 설문조사 텍스트상자1에서 가져옴\ntheVal2 = 설문조사 텍스트상자2에서 가져옴\n\n```js\nescapedVal1 = theVal1.replace(\"'\", \"''\")\nescapedVal2 = theVal2.replace(\"'\", \"''\")\nsql = \"INSERT INTO TABLE VALUES ('\" + escapedVal1 + \"','\" + escapedVal2 + \"')\"\n```\n\n<div class=\"content-ad\"></div>\n\n해커가 악성 레코드를 삽입하려고 시도할 때 사용자의 삽입문과 함께 삽입이 됩니다. 아래와 같이 보일 거에요 -\n\n```js\nINSERT INTO TABLE VALUES ('A1','A2'');INSERT INTO TABLE VALUES (''B1'',''B2')\n```\n\n테이블에 삽입된 값은 아래와 같을 거에요 -\n\n![이미지](/assets/img/2024-06-23-DataMasterywithPythonandSQLUnleashingEfficiencyandSecuritythrough4StrategicUseCases_3.png)\n\n<div class=\"content-ad\"></div>\n\n따라서 백엔드 테이블에서 사용자 중 한 명이 삽입문을 실행하려고 시도한 사실을 확인할 수 있을 것입니다. 입력 변수를 이스케이핑하는 것만으로 SQL 인젝션을 효과적으로 막았습니다.\n\n더 나은 방법은 psycopg2, pyodbc, sqlite3 또는 SQLAlchemy와 같은 Python 라이브러리를 사용하는 것입니다. 이러한 SQL 어댑터들은 다른 기능들과 함께 매개변수화된 쿼리를 지원하는 내장 기능을 갖추고 있습니다.\n\n# 마무리\n\n본 문서에서는 SQL 쿼리를 다룰 때 Python 프로그래밍 기술을 향상시키기 위한 네 가지 실용적인 사용 사례를 살펴보았습니다. Python으로 작성된 SQL 쿼리의 가독성을 향상시키기 위한 Use Case 1부터 시작하여 쿼리 포맷팅과 들여쓰기와 같은 기술을 활용함으로써 코드를 더 체계적이고 이해하기 쉽도록 만들 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nUse Case 2로 넘어가면서, 텍스트 열에서 해시태그를 추출하는 방법에 대해 살펴보았습니다. SQL 및 문자열 조작 함수를 활용하여 관련 해시태그를 효과적으로 추출하고 데이터 분석 프로세스를 강화하는 방법을 배웠습니다.\n\nUse Case 3에서는 Python에서 미래 및 폐기 경고 메시지를 억제하는 중요성을 다뤘습니다. `warnings` 모듈을 활용하여 더 깨끗한 Python 출력과 오류 없는 코드 실행을 보장할 수 있어, 불필요한 방해요소와 호환성 문제를 피할 수 있습니다.\n\n마지막으로, Use Case 4에서는 보안을 강화하고 성능을 개선하며 SQL 인젝션 공격을 방지하기 위해 처리된 코드와 매개변수화된 쿼리를 사용하는 중요성을 강조했습니다.\n\n이러한 사용 사례를 이해하고 구현함으로써 Python 개발자와 데이터 분석가는 SQL 쿼리 실행 및 최적화 기술을 향상시켜 훨씬 견고하고 효율적인 코드를 작성할 수 있습니다. 실제 상황에서 이러한 기술을 적용하면 더 깨끗한 워크플로우를 만들고 효율적이고 안전하게 실행 가능한 통찰력을 도출할 수 있을 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-DataMasterywithPythonandSQLUnleashingEfficiencyandSecuritythrough4StrategicUseCases_0.png"},"coverImage":"/assets/img/2024-06-23-DataMasterywithPythonandSQLUnleashingEfficiencyandSecuritythrough4StrategicUseCases_0.png","tag":["Tech"],"readingTime":9},{"title":"SQL에서 Anti-Join과 Semi-Join 쉽게 이해하기","description":"","date":"2024-06-23 16:45","slug":"2024-06-23-Anti-JoinSemi-JoininSQL","content":"\n\n## Anti-Join 및 Semi-Join 이해하기 - 예제와 함께\n\n### Anti-Join\n\nAnti-Join은 테이블 A에 있는 행 중 테이블 B에 없는 행을 얻는 경우입니다.\n\n예를 들어, 주문을 한 번도 하지 않은 고객을 식별하려면 Anti-Join을 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n여기서 테이블 A를 고객이고 테이블 B를 주문으로 고려해 봅시다.\n\n```js\nSELECT c.customer_id, c.customer_name\nFROM customers c\nLEFT JOIN orders o\non c.customer_id = o.customer_id\nWHERE o.customer_id IS NULL;\n```\n\n# Semi-Join\n\n세미 조인은 테이블 B에서 조건이 일치하는 경우에만 테이블 A에서 행을 반환합니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 주문을 한 고객만 식별하고 싶다면 이 세미 조인을 활용할 수 있습니다.\n\n```js\nSELECT customer_id\nFROM orders \nWHERE customer_id IN (SELECT customer_id FROM customers);\n```\n\n# 요약\n\n- Anti-Join: 두 번째 테이블에 일치하는 행이 없는 첫 번째 테이블의 행을 검색합니다.\n- Semi-Join: 두 번째 테이블에서 적어도 일치하는 행이 하나 이상 있는 첫 번째 테이블의 행을 검색합니다.\n\n<div class=\"content-ad\"></div>\n\n행복한 학습되세요! 화이팅!\n\n만약 제 글이 도움이 되셨다면, 클랩 버튼을 눌러서 지지를 보여주시고 나중을 위해 글을 저장하는 것을 잊지 마세요.","ogImage":{"url":"/assets/img/2024-06-23-Anti-JoinSemi-JoininSQL_0.png"},"coverImage":"/assets/img/2024-06-23-Anti-JoinSemi-JoininSQL_0.png","tag":["Tech"],"readingTime":1},{"title":"PostgreSQL 테이블 파티셔닝 가이드 효율적인 데이터 관리 방법","description":"","date":"2024-06-23 16:43","slug":"2024-06-23-GuidetoPostgreSQLTablePartitioning","content":"\n\n\n![2024-06-23-GuidetoPostgreSQLTablePartitioning](/assets/img/2024-06-23-GuidetoPostgreSQLTablePartitioning_0.png)\n\nPostgreSQL는 강력한 오픈 소스 관계형 데이터베이스 관리 시스템으로 대규모 및 복잡한 데이터 세트를 관리하기 위한 다양한 고급 기능을 제공합니다. 이 중 하나가 테이블 파티셔닝 기능입니다. 이 기능을 사용하면 대규모 테이블을 더 작고 관리하기 쉬운 파티션으로 나눌 수 있습니다.\n\n# 테이블 파티셔닝이란?\n\n테이블 파티셔닝은 대규모 테이블을 더 작고 관리하기 쉬운 청킹된 파티션으로 나누는 데이터베이스 디자인 기술입니다. 각 파티션은 본질적으로 원본 데이터의 하위 집합을 저장하는 별도의 테이블입니다. 이 기술을 사용하면 대규모 데이터 세트에 대한 쿼리 성능과 데이터 관리를 크게 향상시킬 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n파티셔닝은 날짜 열이나 값 범위와 같은 하나 이상의 열을 기준으로 수행될 수 있습니다. 예를 들어, 레코드의 날짜를 기반으로 테이블을 파티션할 수 있으며, 각 파티션은 특정 날짜 범위의 데이터를 나타냅니다. 데이터를 쿼리할 때 PostgreSQL은 쿼리에 관련이 없는 파티션을 빠르게 제거하여 빠른 쿼리 실행을 가능하게 합니다.\n\n# 테이블 파티셔닝의 장점\n\n- 향상된 쿼리 성능: 파티셔닝을 통해 데이터베이스가 데이터를 특정 파티션으로 빠르게 좁힐 수 있어 쿼리 중 스캔해야 하는 데이터 양이 줄어들어 더 빠른 쿼리 실행 시간을 가능하게 합니다, 특히 대규모 데이터 집합의 경우에는 특히 유용합니다.\n- 쉬운 데이터 관리: 테이블 파티셔닝을 통해 대규모 데이터 집합을 더 작고 관리하기 쉬운 파티션으로 분할하여 쉽게 관리할 수 있습니다. 데이터 아카이빙, 데이터 삭제, 백업 및 복원 작업과 같은 작업을 단순화할 수 있습니다.\n- 향상된 데이터 로딩 및 인덱싱: 파티션된 테이블에 데이터를로드할 때 프로세스를 병렬화할 수 있어 더 빠른 데이터 삽입이 가능합니다. 또한 파티션된 테이블에있는 인덱스는 더 효율적일 수 있으며 더 작은 데이터 하위 집합만 다루면 되기 때문에 데이터 처리 속도가 빨라질 수 있습니다.\n- 비용 효율적인 스토리지: 파티셔닝을 통해 오래된 데이터나 덜 액세스되는 데이터를 더 저렴한 스토리지 미디어에 저장할 수 있으며, 자주 액세스되는 데이터는 더 빠른 스토리지 장치에 유지할 수 있습니다.\n\n# PostgreSQL에서의 파티셔닝 방법\n\n<div class=\"content-ad\"></div>\n\nPostgreSQL는 다음과 같은 다양한 분할 방법을 제공합니다:\n\n- 범위 분할 (Range Partitioning)\n- 목록 분할 (List Partitioning)\n- 해시 분할 (Hash Partitioning)\n\n## 범위 분할 (Range Partitioning)\n\n범위 분할은 특정 열의 지정된 값 범위를 기반으로 데이터를 분할하는 테이블 분할의 일종입니다. 이는 시계열 데이터나 자연적인 순서를 갖는 데이터를 다룰 때 유용합니다. 각 파티션은 고유한 값 범위를 나타내며, 그 범위 내에 속하는 데이터는 해당 파티션에 저장됩니다. 범위 분할을 사용하면 특정 범위 내의 데이터를 효율적으로 검색할 수 있어 쿼리 성능이 향상됩니다.\n\n<div class=\"content-ad\"></div>\n\n다음과 같은 구조로 sales 테이블의 예제를 고려해 봅시다.\n\n\nCREATE TABLE sales (\n    sale_id SERIAL PRIMARY KEY,\n    sale_date DATE,\n    product_id INT,\n    quantity INT,\n    amount NUMERIC\n) partition by range (sale_date);\n\n\nsale_date 열을 기준으로 한 판매 데이터에 대한 범위 분할 테이블을 생성하기 위해서는 다음 단계를 따라해야 합니다:\n\n파티션 생성\n\n<div class=\"content-ad\"></div>\n\n각 날짜 범위를 나타내는 개별 테이블을 만들 것입니다. 데모를 위해 \"sales_january,\" \"sales_february,\" 그리고 \"sales_march\" 세 개의 파티션을 만들 것입니다.\n\n```js\nCREATE TABLE sales_january PARTITION OF sales\n    FOR VALUES FROM ('2023-01-01') TO ('2023-02-01');\n\nCREATE TABLE sales_february PARTITION OF sales\n    FOR VALUES FROM ('2023-02-01') TO ('2023-03-01');\n\nCREATE TABLE sales_march PARTITION OF sales\n    FOR VALUES FROM ('2023-03-01') TO ('2023-04-01');\n```\n\n제약 설정하기\n\n각 파티션에 제약 조건을 정의하여 데이터가 올바른 파티션으로 라우팅되도록 보장해야 합니다. 이 예제에서는 각 파티션의 sale_date 열에 대해 CHECK 제약 조건을 사용할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nALTER TABLE sales_january ADD CONSTRAINT sales_january_check\n    CHECK (sale_date >= '2023-01-01' AND sale_date < '2023-02-01');\n\nALTER TABLE sales_february ADD CONSTRAINT sales_february_check\n    CHECK (sale_date >= '2023-02-01' AND sale_date < '2023-03-01');\n\nALTER TABLE sales_march ADD CONSTRAINT sales_march_check\n    CHECK (sale_date >= '2023-03-01' AND sale_date < '2023-04-01');\n```\n\n파티션에 데이터 삽입\n\n이제 sales 테이블에 데이터를 삽입할 수 있고, PostgreSQL은 sale_date를 기준으로 데이터를 적절한 파티션으로 자동으로 라우팅할 것입니다:\n\n```js\nINSERT INTO sales (sale_date, product_id, quantity, amount)\nVALUES ('2023-01-15', 101, 5, 100.00);\n\nINSERT INTO sales (sale_date, product_id, quantity, amount)\nVALUES ('2023-02-20', 102, 10, 200.00);\n\nINSERT INTO sales (sale_date, product_id, quantity, amount)\nVALUES ('2023-03-10', 103, 8, 150.00);\n```\n\n<div class=\"content-ad\"></div>\n\n파티션에서 데이터 조회하기\n\n데이터를 조회할 때, PostgreSQL은 WHERE 절을 기반으로 관련 파티션에만 자동으로 액세스합니다.\n\n```js\n-- 1월의 판매 데이터 검색\nSELECT * FROM sales WHERE sale_date >= '2023-01-01' AND sale_date < '2023-02-01';\n\n-- 2월의 판매 데이터 검색\nSELECT * FROM sales WHERE sale_date >= '2023-02-01' AND sale_date < '2023-03-01';\n\n-- 3월의 판매 데이터 검색\nSELECT * FROM sales WHERE sale_date >= '2023-03-01' AND sale_date < '2023-04-01';\n```\n\n이러한 쿼리는 적절한 파티션에만 액세스하므로 쿼리 성능이 향상됩니다.\n\n<div class=\"content-ad\"></div>\n\n# PostgreSQL에서의 List Partitioning\n\n리스트 파티셔닝은 PostgreSQL에서의 다른 종류의 테이블 파티셔닝 방법으로, 데이터가 특정 열의 값에 기반하여 파티션으로 분할되는 방식입니다. 값의 범위를 사용하는 범위 파티셔닝과 달리, 리스트 파티셔닝은 각 파티션에 대한 특정 값을 정의할 수 있게 합니다. 이 파티셔닝 기술은 데이터를 구별되고 서로 겹치지 않는 세트로 분류할 수 있는 경우에 유용합니다.\n\n다음과 같은 구조를 가진 제품 테이블의 예시를 살펴봅시다:\n\n```js\nCREATE TABLE products (\n    product_id SERIAL PRIMARY KEY,\n    category TEXT,\n    product_name TEXT,\n    price NUMERIC\n) partition by list(category);\n```\n\n<div class=\"content-ad\"></div>\n\n제품 데이터를 카테고리 열을 기반으로 한 테이블 분할 테이블을 만들기 위해서는 다음 단계를 따라야합니다:\n\n분할 생성\n\n각 분할을 나타내는 개별 테이블을 만들어야 합니다. 각 분할은 특정 카테고리의 제품을 커버하도록 설계됩니다. 데모를 위해 \"전자제품\", \"의류\", \"가구\" 세 가지 분할을 만들어 보겠습니다.\n\n```js\nCREATE TABLE electronics PARTITION OF products\n    FOR VALUES IN ('전자제품');\n\nCREATE TABLE clothing PARTITION OF products\n    FOR VALUES IN ('의류');\n\nCREATE TABLE furniture PARTITION OF products\n    FOR VALUES IN ('가구');\n```\n\n<div class=\"content-ad\"></div>\n\n제약 조건 설정\n\n리스트 분할은 특정 값에 기반을 두기 때문에 CHECK 제약 조건이 필요하지 않습니다. 그러나 적절한 테이블에 행을 추가하여 파티션을 올바르게 설정해야 합니다.\n\n파티션에 데이터 삽입\n\n이제 제품 테이블에 데이터를 삽입할 수 있으며, PostgreSQL은 카테고리에 따라 데이터를 자동으로 해당 파티션으로 라우팅합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nINSERT INTO products (category, product_name, price)\nVALUES ('Electronics', 'Smartphone', 500.00);\n\nINSERT INTO products (category, product_name, price)\nVALUES ('Clothing', 'T-Shirt', 25.00);\n\nINSERT INTO products (category, product_name, price)\nVALUES ('Furniture', 'Sofa', 800.00);\n```\n\n파티션에서 데이터 쿼리하기\n\n데이터를 쿼리할 때, PostgreSQL은 WHERE 절을 기반으로 관련 파티션에 자동으로 액세스합니다.\n\n```js\n-- 전자제품 제품 검색\nSELECT * FROM products WHERE category = 'Electronics';\n\n-- 의류 제품 검색\nSELECT * FROM products WHERE category = 'Clothing';\n\n-- 가구 제품 검색\nSELECT * FROM products WHERE category = 'Furniture';\n```\n\n<div class=\"content-ad\"></div>\n\n포스트그리스큐엘에서는 목록 파티셔닝이란 열의 특정 값에 따라 데이터를 관리하고 쿼리하는 데 유용한 기술입니다. 카테고리나 기타 고유한 집합을 기준으로 데이터를 파티션으로 나누면, 목록 파티셔닝을 통해 빠른 데이터 검색과 효율적인 데이터 관리가 가능해집니다.\n\n# 해시 파티셔닝 PostgreSQL\n\n해시 파티셔닝은 PostgreSQL에서 사용되는 테이블 파티셔닝의 한 유형으로, 데이터를 지정한 열의 해시 값에 기반하여 파티션으로 나누는 방식입니다. 특정 값이나 범위를 사용하는 범위 또는 목록 파티셔닝과 달리, 해시 파티셔닝은 해시 함수를 사용하여 데이터를 파티션 간에 균일하게 분배합니다. 이 파티셔닝 기술은 데이터를 균등하게 분산시켜 부하 분산을 달성하려는 경우 유용합니다.\n\n주문 테이블의 구조를 가진 예시를 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nCREATE TABLE orders (\n    order_id SERIAL PRIMARY KEY,\n    order_date DATE,\n    customer_id INT,\n    total_amount NUMERIC\n) partition by hash(customer_id);\n```\n\n주문 데이터를 고객 ID 열을 기반으로 한 해시 파티션 테이블을 만들려면 다음 단계를 따라야 합니다.\n\n파티션 생성\n\n각 파티션을 나타내는 개별 테이블을 만들어야 합니다. 각 파티션은 특정 해시 값 범위를 나타냅니다. 예제로, 세 개의 파티션을 만들어 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\r\nCREATE TABLE orders_1 PARTITION OF orders\r\n    FOR VALUES WITH (MODULUS 3, REMAINDER 0);\r\n\r\nCREATE TABLE orders_2 PARTITION OF orders\r\n    FOR VALUES WITH (MODULUS 3, REMAINDER 1);\r\n\r\nCREATE TABLE orders_3 PARTITION OF orders\r\n    FOR VALUES WITH (MODULUS 3, REMAINDER 2);\r\n```\r\n\r\n이 예시에서는 HASH() 함수를 사용하여 customer_id 열의 해시 값에 기반하여 데이터를 분할해야 함을 지정합니다. MODULUS와 REMAINDER를 사용하여 분할의 수(이 경우 3)와 각 분할의 나머지 값을 지정합니다.\r\n\r\n분할에 데이터 삽입하기\r\n\r\n이제 주문 테이블에 데이터를 삽입하면 PostgreSQL이 customer_id의 해시 값을 기반으로 적절한 분할로 데이터를 자동으로 라우팅합니다:\r\n\n\n<div class=\"content-ad\"></div>\n\n```js\nINSERT INTO orders (order_date, customer_id, total_amount) \nVALUES ('2023-01-15', 101, 500.00);\n\nINSERT INTO orders (order_date, customer_id, total_amount) \nVALUES ('2023-02-20', 102, 600.00);\n\nINSERT INTO orders (order_date, customer_id, total_amount) \nVALUES ('2023-03-10', 103, 700.00);\n```\n\n파티션에서 데이터 조회하기\n\n데이터를 조회할 때 PostgreSQL은 customer_id의 해시 값에 기반하여 적절한 파티션에 자동으로 액세스합니다.\n\n```js\n-- customer_id 101에 대한 주문 검색\nSELECT * FROM orders WHERE customer_id = 101;\n\n-- customer_id 102에 대한 주문 검색\nSELECT * FROM orders WHERE customer_id = 102;\n\n-- customer_id 103에 대한 주문 검색\nSELECT * FROM orders WHERE customer_id = 103;\n```\n\n<div class=\"content-ad\"></div>\n\nPostgreSQL에서의 해시 파티셔닝은 지정한 열의 해시 값에 기반하여 데이터를 파티션 간에 고르게 분산시키는 유용한 기술입니다. 해시 함수를 활용하여 데이터를 균일하게 분산시키는 해시 파티셔닝은 부하 분산을 실현하고 쿼리 성능을 향상시킵니다.\n\nPostgreSQL 테이블 파티셔닝은 대규모 데이터 집합의 성능 및 관리를 현저히 향상시킬 수 있는 강력한 기능입니다. 데이터를 작은 파티션으로 나누어 쿼리 성능을 최적화하고 데이터 관리를 간소화하며 효율적인 데이터 로딩 및 색인화를 달성할 수 있습니다. 파티셔닝 전략을 설계할 때는 데이터와 쿼리 패턴을 고려하여 가장 적합한 파티셔닝 방법을 선택하세요. 올바른 구현으로 PostgreSQL에서 대규모 데이터 처리에 변화를 줄 수 있는 게임 체인저가 될 수 있습니다.\n\n파티셔닝 시작!\n\n다른 블로그도 살펴보세요!\n\n<div class=\"content-ad\"></div>\n\n읽어주셔서 감사합니다!\n\n데이터, AI, 스타트업, 리더십, 글쓰기 및 문화에 관한 내용을 올립니다.\n\n다음 블로그도 기대해주세요!!","ogImage":{"url":"/assets/img/2024-06-23-GuidetoPostgreSQLTablePartitioning_0.png"},"coverImage":"/assets/img/2024-06-23-GuidetoPostgreSQLTablePartitioning_0.png","tag":["Tech"],"readingTime":9},{"title":"ChatGPT를 이용한 플레이어 이탈 예측 방법","description":"","date":"2024-06-23 16:39","slug":"2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT","content":"\n\n## 저 코드 머신 러닝 플랫폼을 활용한 데이터 과학 | ACTABLE AI\n\n![이미지](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_0.png)\n\n# 소개\n\n게임 산업에서 기업들은 플레이어를 유치하는 것 뿐만 아니라 특히 인게임 마이크로 트랜잭션에 의존하는 프리투플레이 게임에서 가능한 한 오랫동안 유지시키려고 노력합니다. 이러한 마이크로 트랜잭션은 종종 인게임 화폐 구매를 포함하며, 플레이어가 진행 또는 사용자 정의를 위한 아이템을 획득하고 게임 개발을 지원합니다. 중단하는 플레이어 수를 나타내는 이탈률을 모니터링하는 것이 중요합니다. 이는 높은 이탈율은 수입 손실을 의미하며, 이는 개발자와 관리자의 스트레스 수준이 증가하게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사는 특정 모바일 앱에서 획득한 데이터를 기반으로 한 실제 데이터셋의 사용을 탐색하며, 사용자들이 플레이한 레벨에 중점을 둡니다. 기계 학습을 활용하여 기술 현장에서 중요한 역할을 하며 인공 지능(AI)의 기초를 형성한 이후, 기업들은 자신들의 데이터에서 가치 있는 통찰을 얻을 수 있습니다.\n\n하지만, 기계 학습 모델을 구축하는 것은 일반적으로 코딩과 데이터 과학 전문 지식이 필요하므로, 많은 사람들 및 자원이 부족한 소규모 기업들에게는 접근하기 어렵습니다. 이러한 도전에 대처하기 위해, 로우코드와 노코드 기계 학습 플랫폼이 나타나기 시작했으며, 기계 학습과 데이터 과학 과정을 간소화하여 방대한 코딩 지식이 필요하지 않도록 하는 것을 목표로 합니다. Einblick, KNIME, Dataiku, Alteryx, Akkio와 같은 플랫폼의 예시가 있습니다.\n\n이 기사에서는 하나의 로우코드 기계 학습 플랫폼을 사용하여 사용자가 게임을 중단할지 예측할 수 있는 모델을 훈련하는 방법을 다룹니다. 뿐만 아니라 결과 해석 및 모델 성능을 향상시키는 데 사용할 수 있는 기술에 대해 탐구합니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사의 나머지 부분은 다음과 같이 구성되어 있습니다:\n\n- 플랫폼\n- 데이터셋\n- 탐색적 데이터 분석\n- 분류 모델 훈련\n- 모델 성능 향상\n- 새로운 특징 생성\n- 새로운 (개선된) 분류 모델 훈련\n- 생산 환경에 모델 배포\n- 결론\n\n# 플랫폼\n\n전체 공개 - 이 기사 작성 시점에 제가 Actable AI의 데이터 과학자인 사실을 알려드립니다. 따라서 이 기사에서는 해당 플랫폼을 사용할 예정입니다. 또한, 저는 ML 라이브러리에 새로운 기능을 구현하고 유지보수하는 일에 관여하고 있어서, 이 플랫폼이 실제 문제에 대해 어떻게 대응하는지 궁금했습니다.\n\n<div class=\"content-ad\"></div>\n\n플랫폼은 전통적인 분류, 회귀 및 세분화 애플리케이션을 위한 여러 인기있는 머신 러닝 방법을 제공합니다. 시계열 예측, 감성 분석 및 인과 추론과 같은 일부 일반적이지 않은 도구도 이용할 수 있습니다. 또한, 결측 데이터를 보완할 수 있으며 데이터 세트의 통계를 계산하고(특성 간 상관 관계, 분산 분석(ANOVA) 등), 막대 차트, 히스토그램, 워드 클라우드와 같은 도구를 사용하여 데이터를 시각화할 수 있습니다.\n\nGoogle Sheets 애드온도 제공되어 스프레드시트 내에서 직접 분석과 모델 훈련을 할 수 있습니다. 다만, 이 애드온에서는 최신 기능이 지원되지 않을 수 있으니 참고 바랍니다.\n\n![image](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_1.png)\n\n핵심 라이브러리는 GitHub에서 오픈 소스로 제공되며 AutoGluon 및 scikit-learn과 같은 잘 알려진 신뢰할 수 있는 프레임워크로 구성되어 있습니다. 이는 기존의 오픈 소스 솔루션을 활용하는 다른 관련 플랫폼과 유사합니다.\n\n<div class=\"content-ad\"></div>\n\n그러나, 이에 대한 질문이 생깁니다: 대부분의 도구들이 이미 사용 가능하고 무료로 제공되는데, 왜 이러한 플랫폼을 사용해야 하는지요?\n\n가장 중요한 이유는 이러한 도구들이 Python과 같은 프로그래밍 언어에 대한 지식이 필요하다는 것입니다. 일반적으로 코딩에 익숙하지 않은 사람은 사용하기 어렵거나 불가능할 수 있습니다. 따라서 이러한 플랫폼은 프로그래밍 명령어의 형태로가 아닌 GUI(그래픽 사용자 인터페이스) 형식으로 모든 기능을 제공하려고 합니다.\n\n더 경험이 많은 전문가들은 또한 시간을 절약할 수 있을 뿐만 아니라 쉽게 사용할 수 있는 그래픽 인터페이스를 통해 지원 도구와 기법의 정보를 제공할 수도 있습니다. 일부 플랫폼은 익숙하지 않았던 도구들을 제공하거나 데이터 작업 시 유용한 경고(예: 데이터 누출의 존재 - 모델이 볼 수 없는 데이터의 생산 환경에 배포될 때 사용할 수 없는 특징에 액세스할 수 있는 경우)를 제공할 수도 있습니다.  \n\n이러한 종류의 플랫폼을 사용하는 또 다른 이유는 모델을 실행할 하드웨어도 제공하기 때문입니다. 따라서 자신의 컴퓨터나 GPU(Graphical Processing Units)와 같은 구성 요소를 구매하고 유지 관리할 필요가 없습니다.\n\n<div class=\"content-ad\"></div>\n\n# 데이터셋\n\n게임 회사가 제공한 데이터셋은 이곳에서 확인할 수 있으며 CC BY-SA-4 라이센스가 적용되어있어 적절한 크레딧이 제공된다면 공유 및 수정이 허용됩니다. 이 데이터셋은 789,879개의 행(샘플)을 가지고 있어 과적합과 같은 영향을 줄여줄 것으로 예상됩니다.\n\n이 데이터셋은 개인이 모바일 앱에서 플레이한 각 레벨에 관한 정보를 포함하고 있습니다. 예를 들어, 플레이한 시간, 플레이어가 레벨에서 승리했는지 패배했는지, 레벨 번호 등에 대한 정보가 있습니다.\n\n사용자 ID도 포함되어 있지만 원래 플레이어의 신원을 드러내지 않도록 익명화되었습니다. 일부 필드도 제거되었지만, 이 데이터셋은 이 기사에서 고려된 ML 플랫폼에서 제공된 도구가 플레이어의 이탈을 예측하는 데 유용할 수 있는지 확인하는 견고한 기초를 제공할 것으로 예상됩니다.\n\n<div class=\"content-ad\"></div>\n\n각 기능의 의미는 다음과 같습니다:\n\n- Churn: 플레이어가 게임을 2주 이상 플레이하지 않았을 경우 '1', 그렇지 않으면 '0'\n- ServerTime: 레벨이 플레이된 서버의 타임스탬프\n- EndType: 레벨이 종료된 이유 ('승리'일 경우 주로 게임에서 이겼을 때, '패배'일 경우 게임에서 졌을 때)\n- LevelType: 레벨의 유형\n- Level: 레벨 번호\n- SubLevel: 하위 레벨 번호\n- Variant: 레벨 변형\n- Levelversion: 레벨 버전\n- NextCar: 사용되지 않음 (플랫폼이 한 라벨만 포함하는 기능을 처리하는 방법 확인용으로 포함됨)\n- AddMoves: 추가 이동 횟수\n- DoubleMana: 사용되지 않음 (플랫폼이 한 라벨만 포함하는 기능을 처리하는 방법 확인용으로 포함됨)\n- StartMoves: 레벨 시작 시 사용 가능한 이동횟수\n- ExtraMoves: 구매한 추가 이동 횟수\n- UsedMoves: 플레이어가 사용한 이동 횟수\n- UsedChangeCar: 사용되지 않음 (플랫폼이 한 라벨만 포함하는 기능을 처리하는 방법 확인용으로 포함됨)\n- WatchedVideo: 비디오를 시청했는지 여부, 추가 이동 제공\n- BuyMoreMoves: 플레이어가 추가 이동을 구매한 횟수\n- PlayTime: 레벨 플레이에 소요된 시간\n- Scores: 플레이어가 달성한 점수\n- UsedCoins: 레벨에서 사용된 총 코인 수\n- MaxLevel: 플레이어가 도달한 최대 레벨\n- Platform: 장치 유형\n- UserID: 플레이어의 ID\n- RollingLosses: 플레이어의 연속적인 패배 횟수\n\n# 탐색적 데이터 분석\n\n학습 전 첫 번째 단계는 탐색적 데이터 분석(EDA)을 통해 데이터를 이해하는 것입니다. EDA는 데이터를 요약, 시각화하고 주요 특성을 이해하는 데이터 분석 방법론입니다. 목표는 데이터로부터 통찰력을 얻고, 어떠한 패턴, 추세, 이상 현상 또는 존재할 수 있는 이슈(예: 결측값)를 식별하여 사용될 특성 및 모델을 확인하는 데 도움이 되는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n주요 이유들을 확인해 보면서 레벨이 종료된 이유에 대해 살펴보겠습니다:\n\n![Image](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_2.png)\n\n위 이미지를 보면 레벨 종료의 주된 이유(EndType으로 표시됨)는 플레이어가 게임에서 패배한 경우(63.6%)가 승리한 경우의 35.2%에 비해 더 많다는 것을 알 수 있습니다. 또한 UsedChangeCar 열은 모든 행에 동일한 값을 포함하고 있어 쓸모없어 보입니다.\n\n매우 중요한 점은 우리의 대상값이 매우 불균형하다는 것입니다. 처음 10,000행 중에서 63개의 샘플만이 (데이터의 0.6%) Churn 값이 1(즉, 플레이어가 이탈함)을 가지고 있다는 것입니다. 이것은 염두에 둘 필요가 있습니다. 왜냐하면 우리의 모델이 Churn에 대해 0의 값을 예측하는 데 매우 편향될 수 있기 때문입니다. 모델이 정확도와 같은 몇 가지 지표에 대해 매우 좋은 값을 얻을 수 있기 때문에, 이 경우에는 가장 일반적인 클래스를 선택하는 더미 모델이 99.4%의 정확도로 정답을 맞출 것입니다! 이에 대해 Baptiste Rocca와 Jason Brownlee의 두 훌륭한 기사에서 더 읽어보시기를 권합니다.\n\n<div class=\"content-ad\"></div>\n\n아쉽게도 Actable AI는 SMOTE(합성 소수 샘플링 기법)를 통해 불균형 데이터를 처리하거나 클래스 가중치 또는 다른 샘플링 전략을 사용하는 방법을 아직 제공하지 않습니다. 이는 최적화를 위해 선택된 지표에 주의를 기울여야 한다는 것을 의미합니다. 위에서 언급한 대로, 정확도는 한 클래스의 샘플이 올바르게 레이블링되지 않아도 높은 비율을 달성할 수 있는 경우라면 최선의 선택이 아닐 것입니다.\n\n또 다른 유용한 분석 유형은 특징들 간의 상관 관계, 특히 예측자 특징과 대상 특징 간의 상관 관계입니다. 이를 수행하기 위해 '상관 분석' 도구를 사용할 수 있으며, 해당 결과는 Actable AI 플랫폼에서 직접 확인할 수 있습니다:\n\n![HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_3](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_3.png)\n\n위 차트에서 파란 막대는 특징이 Churn과 양의 상관 관계가 있는 경우를 나타내며 값이 1인 경우이고, 주황색 막대는 음의 특징 상관 관계를 나타냅니다. 상관 관계는 -1에서 1 사이에 있음을 주의해야 합니다. 양의 값은 두 특징이 함께 변화하는 경향이 있다는 것을 나타내며(예: 둘 다 증가하거나 감소), 음의 상관 관계는 한 특징이 증가하거나 감소할 때 다른 특징이 반대로 변화한다는 것을 나타냅니다. 따라서 상관 관계의 크기(음의 부호를 무시한)가 아마도 가장 중요한 사항일 것입니다.\n\n<div class=\"content-ad\"></div>\n\n특정 수준을 잃은 플레이어들이 (가장 위쪽의 파란 막대) 막적회전에 민감하다는 것이나, 반대로 특정 수준을 이긴 플레이어들은 계속해서 플레이하는 경향이 있다는 등 여러 가지 교훈이 있습니다 (세 번째 오렌지 막대). 그러나 값이 상당히 낮다는 것도 주목해야 합니다. 이는 이러한 특징이 목표와 상관 관계가 약한 것을 의미합니다. 이는 모델이 더 정확한 예측을 수행하기 위해 더 중요한 정보를 포착하는 새로운 기능을 만들어 사용하는 특성 엔지니어링을 수행해야 할 것으로 예상됩니다. 특성 엔지니어링은 이 글의 뒷부분에서 자세히 다룰 것입니다.\n\n하지만 새로운 특성을 생성하기 전에 데이터셋의 원래 특성만 사용하여 어떤 성능을 달성할 수 있는지 살펴보는 것도 좋은 방법입니다. 따라서 다음 단계는 더 흥미로운 것으로, 모델을 훈련시켜 어떤 성능을 달성할 수 있는지 알아보는 것이 될 것입니다.\n\n# 분류 모델 훈련\n\n사용자가 플레이를 중단할지 여부를 예측하고 싶기 때문에, 이는 여러 레이블 중 하나를 선택해야 하는 분류 문제입니다. 우리의 경우, 문제는 두 가지 레이블 중 하나('1'은 '이탈', '0'은 '이탈하지 않음'에 해당)를 할당하는 것을 포함하므로, 이는 이진 분류 문제로 만듭니다.\n\n<div class=\"content-ad\"></div>\n\n이 프로세스는 주로 AutoGluon 라이브러리를 통해 수행되며, 이 라이브러리는 자동으로 여러 모델을 학습한 다음 가장 우수한 성능을 달성한 모델을 선택합니다. 이렇게 하면 각각의 모델을 수동으로 학습하고 그 성능을 비교할 필요가 없어집니다.\n\nActable AI 플랫폼에서 설정해야 할 여러 매개변수가 있으며, 제가 선택한 옵션은 아래에 나와 있습니다:\n\n![이미지](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_4.png)\n\n모델의 최적화를 위해 사용할 메트릭도 선택할 수 있습니다. 저는 수신자 조작 특성 (ROC) 아래 영역 (AUC ROC) 곡선을 사용했습니다. 이는 이전에 논의된 클래스 불균형 문제에 대해 훨씬 민감하지 않기 때문입니다. 값은 0부터 1까지의 범위를 가지며 (1일수록 완벽한 점수입니다).\n\n<div class=\"content-ad\"></div>\n\n일정 시간이 지난 후에는 결과가 생성되어 표시되며, 여기서도 볼 수 있습니다. 여러 가지 다른 측정 항목이 계산되며, 이는 좋은 실천 방식일 뿐만 아니라 각 측정 항목이 모델 성능의 특정 측면에 집중하기 때문에 우리가 모델을 실제로 이해하려면 거의 필수적입니다.\n\n표시된 첫 번째 메트릭은 최적화 메트릭으로, 값이 0.675입니다:\n\n![이미지](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_5.png)\n\n이것은 크게 좋지는 않지만, EDA 중에 특성이 대상과 상관성이 약한 것을 상기하면, 성능이 별로 두드러지지 않는 것은 놀라운 일이 아닙니다.\n\n<div class=\"content-ad\"></div>\n\n이 결과는 결과를 이해하는 중요성을 강조합니다. 보통 0.997 (즉, 99.7%) 정확도에 대해 매우 만족스러워할 것입니다. 그러나 이는 앞서 언급한 것처럼 데이터 세트의 심각한 불균형 때문이 대부분이므로 그다지 중요하지 않습니다. 한편, 정밀도와 재현율과 같은 점수는 기본적으로 임계값 0.5를 기반으로 하며, 이는 우리의 응용 프로그램에 가장 적합하지 않을 수 있습니다.\n\nROC 및 정밀도-재현율 곡선도 표시되는데, 이것들 또한 성능이 약간 부족함을 명확히 보여줍니다:\n\n이러한 곡선들은 최종 응용 프로그램에서 사용할 임계값을 결정하는 데도 유용합니다. 예를 들어, 거짓 양성의 수를 최소화하려면 모델이 더 높은 정밀도를 얻는 임계값을 선택하고 해당하는 재현을 확인할 수 있습니다.\n\n얻은 최상의 모델에서 각 피처의 중요성을 확인할 수도 있습니다. 이는 AutoGluon을 통해 순열 중요성을 사용하여 계산됩니다. 결과의 신뢰성을 결정하기 위해 P-값도 표시됩니다:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_6.png\" />\n\n아마도 놀랍지 않게도, 가장 중요한 기능은 EndType입니다(레벨이 종료된 이유를 보여주는데, 승리나 패배와 같은 요인), 그 다음은 MaxLevel(사용자가 플레이 한 가장 높은 레벨로, 숫자가 높을수록 플레이어가 게임에 매우 집중하고 활발하다는 것을 의미합니다).\n\n반면에, UsedMoves(플레이어가 수행한 움직임의 수)는 사실상 쓸모없지만, StartMoves(플레이어가 사용할 수있는 움직임의 수)는 실제로 성능을 해칠 수 있습니다. 이것도 논리적입니다. 사용된 움직임 수와 플레이어가 사용할 수있는 움직임 수가 그 자체로는 높은 정보를 가지고 있지 않기 때문에, 두 값간의 비교가 훨씬 유용할 것입니다.\n\n또한 각 클래스(이 경우 1 또는 0)의 추정 확률을 살펴볼 수 있습니다. 이 확률은 예측된 클래스를 도출하기 위해 사용되며(기본적으로 가장 높은 확률을 가진 클래스가 예측된 클래스로 할당됩니다):\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_7.png\" />\n\nAI의 설명 가능성은 모델 동작을 이해하는 데 더 중요해지고 있으며, 이로 인해 Shapley 값과 같은 도구가 인기를 끌고 있습니다. 이러한 값은 기능이 예측된 클래스의 확률에 미치는 기여를 나타냅니다. 예를 들어, 첫 번째 행에서 RollingLosses 값이 36인 경우, 해당 플레이어가 게임을 계속하는 클래스 (클래스 0)의 확률이 감소함을 볼 수 있습니다.\n\n반대로, 이는 다른 클래스(즉, 플레이어가 이탈하는 클래스 1)의 확률이 증가함을 의미합니다. 이는 RollingLosses 값이 높을수록 플레이어가 연속해서 많은 레벨을 잃었고, 따라서 좌절하여 게임을 그만 둘 가능성이 높다는 것을 의미합니다. 반면, RollingLosses 값이 낮을수록 부정적인 클래스(즉, 플레이어가 게임을 그만 두지 않을 가능성)의 확률이 일반적으로 향상됩니다.\n\n언급한 바와 같이 여러 모델이 훈련되고 평가된 후, 그 중에서 최적의 모델이 선택됩니다. 흥미로운 점은 이 경우 최고의 모델이 LightGBM임과 동시에 가장 빠른 모델 중 하나인 것입니다:\n\n<div class=\"content-ad\"></div>\n\n마크다운 형식으로 테이블 태그를 변경해보세요.\n\n# 모델 성능 향상\n\n지금 이 시점에서는 모델의 성능을 향상시킬 수 있습니다. 아마도 가장 쉬운 방법 중 하나는 '품질 최적화' 옵션을 선택하고 얼마나 나아질 수 있는지 확인하는 것입니다. 이 옵션은 일반적으로 성능을 향상시키는 몇 가지 매개변수를 구성하며, 단단한 학습 시간의 비용으로 이루어집니다. 다음 결과를 얻었습니다 (여기에서도 확인할 수 있습니다):\n\n<img src=\"/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_9.png\" />\n\n<div class=\"content-ad\"></div>\n\n다시 ROC AUC 지표에 초점을 맞추면, 성능이 0.675에서 0.709로 향상되었습니다. 이렇게 간단한 변경으로 성능이 상당히 향상된 것입니다. 하지만 여전히 이상적인 수준에서는 멀리 떨어져 있습니다. 더 나은 성능을 위해 우리가 할 수 있는 다른 방법이 있을까요?\n\n# 새로운 기능 만들기\n\n이전에 논의한 대로, 이것을 특성 공학을 사용하여 수행할 수 있습니다. 이것은 기존 기능에서 새로운 기능을 만드는 것을 의미하며, 이러한 새로운 기능은 더 강력한 패턴을 포착하고 예측할 변수와 더 높은 상관 관계를 갖도록 할 수 있습니다.\n\n우리의 경우, 데이터 세트의 기능은 사용자가 플레이한 레벨에 관한 정보에 대한 값만을 갖기 때문에 범위가 상당히 좁습니다. 따라서, 시간을 거쳐 레코드를 요약함으로써 더 전반적인 전망을 얻는 것이 매우 유용할 수 있습니다. 이렇게 함으로써 모델은 사용자의 역사적인 추세에 대한 지식을 가질 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 플레이어가 사용한 추가 움직임의 수를 확인하여 경험한 난이도를 측정할 수 있습니다. 추가 움직임이 거의 필요하지 않았다면, 레벨이 너무 쉬웠을 수도 있습니다. 반대로 많은 숫자는 레벨이 너무 어려웠을 수도 있습니다.\n\n또한, 플레이어가 게임에 몰입하고 참여하고 있는지 확인하기 위해 이전 몇 날 동안 게임을 플레이한 시간을 확인하는 것도 좋은 아이디어일 것입니다. 게임을 별로 하지 않았다면, 그들이 흥미를 잃고 곧 그만둘 수도 있다는 의미일 수 있습니다.\n\n유용한 특징들은 서로 다른 도메인에서 다양하기 때문에 현재 작업과 관련된 정보를 찾는 것이 중요합니다. 예를 들어, 연구 논문, 사례 연구 및 기사를 찾거나 해당 분야에서 일한 회사나 전문가들의 조언을 구하면 가장 일반적인 특징, 특징 간의 관계, 잠재적인 함정 및 유용할 것으로 예상되는 새로운 특징들에 대해 숙련된 지식이 있는 사람들로부터 도움을 받을 수 있습니다. 이러한 접근 방식은 시행착오를 줄이고 특징 엔지니어링 프로세스를 가속화하는 데 도움이 됩니다.\n\n최근 대규모 언어 모델(LLMs)의 발전과 (예: ChatGPT를 들어본 적이 있을지도 모르죠...), 그리고 특징 엔지니어링 프로세스가 경험 부족한 사용자에게는 다소 어려울 수 있기 때문에, LLMs가 어떤 특징을 생성할 수 있는 아이디어를 제공하는 데 어떤 지원이 될 수 있는지 궁금했습니다. 저는 이를 테스트해보았고, 다음 결과가 나왔습니다:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_10.png\" />\n\n차트 GPT의 답변은 실제로 아주 좋습니다. 또한 앞서 언급한 바와 같이 여러 시간 기반 특성을 가리키기도 합니다. 물론 필요한 정보가 없을 경우 모든 제안된 기능을 구현할 수 없을 수도 있음을 염두에 두세요. 게다가 이것은 망상에 빠지기 쉬우며, 따라서 완전히 정확한 답변을 제공하지 못할 수도 있습니다.\n\nChatGPT로부터 더 관련성 높은 응답을 받으려면 사용 중인 특성을 지정하거나 프롬프트를 활용하는 등의 방법을 사용할 수 있습니다. 그러나 이는 본 문서의 범위를 벗어나므로 독자들에게 연습 과제로 남겨두겠습니다. 그럼에도 불구하고, LLMs는 시작 단계로 고려할 수 있지만, 논문, 전문가 등보다 신뢰할 만한 정보를 얻기 위해 노력하는 것이 강력히 권장됩니다.\n\nActable AI 플랫폼에서는 상당히 잘 알려진 SQL 프로그래밍 언어를 사용하여 새로운 기능을 만들 수 있습니다. SQL에 익숙하지 않은 사용자를 위해 ChatGPT를 활용하여 쿼리를 자동으로 생성하는 방법이 유용할 수 있습니다. 그러나 내가 제한된 실험을 통해 이 방법의 신뢰성은 다소 일관되지 않을 수 있다는 것을 발견했습니다.\n\n<div class=\"content-ad\"></div>\n\n원하는 결과를 정확하게 계산하기 위해 의도한 출력물을 수동으로 확인하여 검증하는 것이 좋습니다. SQL Lab에서 쿼리를 실행한 후에 나타나는 테이블을 확인하여 이를 확인할 수 있습니다. Actable AI는 SQL 코드를 작성하고 실행하는 인터페이스입니다.\n\n다음은 새로운 열을 생성하는 데 사용한 SQL 코드입니다. 다른 기능을 만들고 싶다면 이것을 참고하여 시작할 수 있을 것입니다.\n\n```js\nSELECT \n    *,\n    SUM(\"PlayTime\") OVER UserLevelWindow AS \"time_spent_on_level\",\n    (a.\"Max_Level\" - a.\"Min_Level\") AS \"levels_completed_in_last_7_days\",\n    COALESCE(CAST(\"total_wins_in_last_14_days\" AS DECIMAL)/NULLIF(\"total_losses_in_last_14_days\", 0), 0.0) AS \"win_to_lose_ratio_in_last_14_days\",\n    COALESCE(SUM(\"UsedCoins\") OVER User1DayWindow, 0) AS \"UsedCoins_in_last_1_days\",\n    COALESCE(SUM(\"UsedCoins\") OVER User7DayWindow, 0) AS \"UsedCoins_in_last_7_days\",\n    COALESCE(SUM(\"UsedCoins\") OVER User14DayWindow, 0) AS \"UsedCoins_in_last_14_days\",\n    COALESCE(SUM(\"ExtraMoves\") OVER User1DayWindow, 0) AS \"ExtraMoves_in_last_1_days\",\n    COALESCE(SUM(\"ExtraMoves\") OVER User7DayWindow, 0) AS \"ExtraMoves_in_last_7_days\",\n    COALESCE(SUM(\"ExtraMoves\") OVER User14DayWindow, 0) AS \"ExtraMoves_in_last_14_days\",\n    AVG(\"RollingLosses\") OVER User7DayWindow AS \"RollingLosses_mean_last_7_days\",\n    AVG(\"MaxLevel\") OVER PastWindow AS \"MaxLevel_mean\"\nFROM (\n    SELECT\n        *,\n        MAX(\"Level\") OVER User7DayWindow AS \"Max_Level\",\n        MIN(\"Level\") OVER User7DayWindow AS \"Min_Level\",\n        SUM(CASE WHEN \"EndType\" = 'Lose' THEN 1 ELSE 0 END) OVER User14DayWindow AS \"total_losses_in_last_14_days\",\n        SUM(CASE WHEN \"EndType\" = 'Win' THEN 1 ELSE 0 END) OVER User14DayWindow AS \"total_wins_in_last_14_days\",\n        SUM(\"PlayTime\") OVER User7DayWindow AS \"PlayTime_cumul_7_days\",\n        SUM(\"RollingLosses\") OVER User7DayWindow AS \"RollingLosses_cumul_7_days\",\n        SUM(\"PlayTime\") OVER UserPastWindow AS \"PlayTime_cumul\"\n    FROM \"game_data_levels\"\n    WINDOW\n        User7DayWindow AS (\n            PARTITION BY \"UserID\"\n            ORDER BY \"ServerTime\"\n            RANGE BETWEEN INTERVAL '7' DAY PRECEDING AND CURRENT ROW\n        ),\n        User14DayWindow AS (\n            PARTITION BY \"UserID\"\n            ORDER BY \"ServerTime\"\n            RANGE BETWEEN INTERVAL '14' DAY PRECEDING AND CURRENT ROW\n        ),\n        UserPastWindow AS (\n        PARTITION BY \"UserID\"\n        ORDER BY \"ServerTime\"\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n        )\n) AS a\nWINDOW\n    UserLevelWindow AS (\n        PARTITION BY \"UserID\", \"Level\"\n        ORDER BY \"ServerTime\"\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ),\n    PastWindow AS (\n        ORDER BY \"ServerTime\"\n        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW\n    ),\n    User1DayWindow AS (\n        PARTITION BY \"UserID\" \n        ORDER BY \"ServerTime\" \n        RANGE BETWEEN INTERVAL '1' DAY PRECEDING AND CURRENT ROW\n    ),\n    User7DayWindow AS (\n        PARTITION BY \"UserID\"\n        ORDER BY \"ServerTime\"\n        RANGE BETWEEN INTERVAL '7' DAY PRECEDING AND CURRENT ROW\n    ),\n    User14DayWindow AS (\n        PARTITION BY \"UserID\"\n        ORDER BY \"ServerTime\"\n        RANGE BETWEEN INTERVAL '14' DAY PRECEDING AND CURRENT ROW\n    )\nORDER BY \"ServerTime\";\n```\n\n이 코드에서 '윈도우'는 고려할 시간 범위를 정의하기 위해 생성되어 마지막 날, 지난 주 또는 지난 2주와 같은 것을 나타냅니다. 해당 범위 내에 속한 레코드가 기능 계산 중에 사용되며, 이는 주로 게임에서 플레이어의 여정에 대한 일부 역사적 맥락을 제공하기 위해 의도되었습니다. 전체 기능 목록은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- level_time_spend: 사용자가 레벨을 플레이하는 데 소요된 시간을 나타냅니다. 레벨의 난이도를 나타냅니다.\n- levels_completed_last_7_days: 사용자가 지난 7일 동안(1주일) 완료한 레벨 수를 나타냅니다. 난이도, 인내력 및 게임에 대한 몰입도를 보여줍니다.\n- total_wins_last_14_days: 사용자가 레벨을 이긴 총 횟수\n- total_losses_last_14_days: 사용자가 레벨을 진 총 횟수\n- win_to_lose_ratio_last_14_days: 승리 횟수와 패배 횟수의 비율 (total_wins_last_14_days/total_losses_last_14_days)\n- used_coins_last_1_days: 이전 날 사용된 코인 수. 레벨 난이도 및 플레이어가 게임 내 통화를 사용할 의지를 보여줍니다.\n- used_coins_last_7_days: 지난 7일간 사용된 코인 수 (1주일)\n- used_coins_last_14_days: 지난 14일간 사용된 코인 수 (2주)\n- extra_moves_last_1_days: 사용자가 이전 날에 사용한 추가 움직임 수. 레벨 난이도를 나타냅니다.\n- extra_moves_last_7_days: 사용자가 지난 7일 동안 사용한 추가 움직임 수 (1주)\n- extra_moves_last_14_days: 사용자가 지난 14일 동안 사용한 추가 움직임 수 (2주)\n- rolling_losses_mean_last_7_days: 사용자가 지난 7일 동안 누적으로 경험한 평균 손실 횟수 (1주). 레벨 난이도를 보여줍니다.\n- max_level_mean: 모든 사용자가 달성한 최고 레벨의 평균.\n- max_level: 사용자가 지난 7일 동안(1주) 달성한 최고 레벨. max_level_mean과 결합하여 플레이어의 다른 플레이어들에 대한 진행 상황을 보여줍니다.\n- min_level: 사용자가 지난 7일 동안(1주) 플레이한 최소 레벨\n- play_time_cumul_7_days: 사용자가 지난 7일 동안(1주) 플레이한 총 시간. 플레이어의 게임 몰입도를 나타냅니다.\n- play_time_cumul: 사용자가 플레이한 총 시간(첫 번째 기록부터)\n- rolling_losses_cumul_7_days: 지난 7일 동안(1주) 누적된 롤링 손실 총 횟수. 레벨의 난이도를 나타냅니다.\n\n새로운 기능의 값을 계산할 때는 이전 레코드만 사용하는 것이 중요합니다. 다시 말해, 향후 관측치의 사용은 피해야 합니다. 왜냐하면 모델이 상용 환경에 배포될 때 미래 값에 액세스할 방법이 없기 때문입니다.\n\n생성된 피처에 만족하셨다면 테이블을 새 데이터 세트로 저장하고 (희망적으로) 성능이 향상된 새 모델을 실행할 수 있습니다.\n\n# 새로운 (희망적으로 향상된) 분류 모델 훈련\n\n<div class=\"content-ad\"></div>\n\n새로운 열이 유용한지 확인할 시간이에요. 이전과 동일한 단계를 반복할 수 있어요. 유일한 차이점은 이제 추가 기능을 포함하는 새 데이터 세트를 사용한다는 것이에요. 기존 모델과 공정한 비교를 위해 동일한 설정을 사용하여 원본 모델과 다음 결과와 함께 최적화합니다(여기서도 확인할 수 있습니다):\n\n![image](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_11.png)\n\n0.918의 ROC AUC 값은 원래 값인 0.675와 비교했을 때 크게 향상되었어요. 심지어 품질에 최적화된 모델(0.709)보다 더 나아요! 이는 데이터를 이해하고 더 풍부한 정보를 제공할 수 있는 새로운 기능을 만드는 중요성을 보여줍니다.\n\n이제 어떤 새로운 기능이 실제로 가장 유용했는지 확인하는 것이 흥미롭겠죠. 다시 한번 특징 중요도 표를 확인할 수 있어요:\n\n<div class=\"content-ad\"></div>\n\n![그림](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_12.png)\n\n최근 두 주간의 총 패배 횟수가 매우 중요한 것으로 보입니다. 이는 게임에서 더 자주 패배할수록 플레이어가 좌절하고 플레이를 그만둘 가능성이 더 높아진다는 논리적입니다.\n\n모든 사용자의 평균 최대 레벨도 중요한 것으로 보입니다. 다시 한번, 플레이어가 다수의 다른 플레이어와 얼마나 멀리 떨어져 있는지를 결정하는 데 사용될 수 있습니다. 평균보다 훨씬 높은 level은 플레이어가 게임에 깊게 몰두해 있다는 것을 나타내고, 평균보다 훨씬 낮은 값은 플레이어가 여전히 충분히 동기 부여받지 못했을 수 있다는 것을 나타낼 수 있습니다.\n\n이것들은 우리가 만들었을 수 있는 몇 가지 간단한 기능에 불과합니다. 성능을 더 향상시킬 수 있는 다른 기능들이 있을 수 있습니다. 독자에게 어떤 다른 기능들이 만들어질 수 있는지 확인해 보도록 남겨두겠습니다.\n\n<div class=\"content-ad\"></div>\n\n지난과 동일한 시간 제한으로 품질에 최적화된 모델을 훈련시키는 것은 성능을 향상시키지 않았습니다. 그러나 더 많은 피처를 사용하고 있기 때문에 최적화에 더 많은 시간이 필요할 수 있기 때문에 이해할 만한 일입니다. 여기서 시간 제한을 6시간으로 늘리면 성능이 실제로 0.923(AUC 기준)로 향상된 것을 확인할 수 있습니다:\n\n![이미지](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_13.png)\n\n또한 정밀도 및 재현율과 같은 몇 가지 메트릭이 여전히 상당히 낮다는 점에 유의해야 합니다. 그러나 이는 0.5의 분류 임계값을 가정했기 때문일 수 있습니다. 임계값을 곡선을 클릭하여 변경할 수 있지만 AUC는 임계값에 독립적이며 성능을 더 포괄적으로 나타낼 수 있습니다. 앞서 언급했듯이 AUC는 불균형 데이터셋을 기반으로 훈련하는 동안 최적화 메트릭으로 사용될 때 특히 유용합니다.\n\n훈련된 모델의 AUC 성능은 다음과 같이 요약할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n\n|                         Model                           | AUC (ROC) |\n|--------------------------------------------------------|-----------|\n| Original features                                      |     0.675 |\n| Original features + optim. for quality                 |     0.709 |\n| Engineered features                                    |     0.918 |\n| Engineered features + optim. for quality + longer time |     0.923 |\n\n\n# 프로덕션 환경에 모델 배포하기\n\n새로운 데이터에서 실제로 모델을 사용할 수 없다면 좋은 모델이 있어도 쓸모가 없습니다. 머신러닝 플랫폼은 훈련된 모델을 사용하여 미래의 보이지 않는 데이터에 대한 예측을 생성하는 기능을 제공할 수 있습니다. 예를 들어, Actable AI 플랫폼은 API를 통해 모델을 사용하여 플랫폼 외부 데이터에 사용할 수 있게 해주며, 모델을 내보내거나 원시 값을 삽입하여 즉시 예측을 얻을 수 있습니다.\n\n그러나 모델을 주기적으로 미래 데이터에 테스트하는 것은 매우 중요합니다. 모델이 여전히 예상대로 작동하는지 확인하기 위해 필요합니다. 실제로 더 최신 데이터로 모델을 다시 훈련해야 할 수도 있습니다. 이는 특징(예: 피처 분포)이 시간이 지남에 따라 변경될 수 있어 모델의 정확도에 영향을 미칠 수 있기 때문입니다.\n\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 회사에서 새로운 정책을 도입할 수 있으며 이는 고객 행동에 영향을 미칠 수 있습니다(긍정적 또는 부정적). 그러나 새로운 변화를 반영하는 기능이 없는 경우 모델은 새로운 정책을 고려하지 못할 수 있습니다. 만일 그런 심각한 변화가 있지만 모델에 정보를 제공할 수 있는 기능이 없다면, 고려해볼 가치가 있는 것은 두 모델을 사용하는 것입니다: 하나는 이전 데이터를 훈련시키고 사용하는 데에 특화되고, 다른 하나는 최신 데이터를 훈련시키고 사용하는 데에 특화하는 것입니다. 이렇게 함으로써 모델이 단일 모델로 잡기 어려운 서로 다른 특성을 가진 데이터에서 작동할 수 있도록 보장할 수 있습니다.\n\n# 결론\n\n본 글에서는 사용자가 모바일 앱에서 각 레벨을 하면서 생성된 정보를 포함하는 실제 데이터 세트를 사용하여, 플레이어가 2주 후에 게임을 그만둘지를 예측할 수 있는 분류 모델을 훈련시켰습니다.\n\n데이터 탐색부터 모델 훈련, 피처 엔지니어링까지 전반적인 처리 파이프라인을 고려했습니다. 결과의 해석에 대한 토론과 어떻게 향상시킬 수 있는지가 제공되었으며, 0.675에서 0.923으로 가치를 향상시키는 방법을 탐색했습니다(1.0이 최대값입니다).\n\n<div class=\"content-ad\"></div>\n\n새로 만들어진 기능들은 비교적 간단합니다. 더 많은 기능들이 있을 수 있지만, Feature Normalisation과 Standardisation 같은 기술들 역시 고려해볼 만 합니다. 여기와 여기에서 유용한 자료들을 찾을 수 있습니다.\n\nActable AI 플랫폼에 관해서, 제가 조금 편협한 의견을 가지고 있을 수도 있지만, 이 플랫폼이 데이터 과학자와 머신 러닝 전문가에 의해 수행되어야 하는 좀 더 성가신 프로세스들을 간단화할 수 있다고 생각합니다. 다음과 같은 우수한 측면이 있습니다:\n\n- Core ML 라이브러리는 오픈 소스이기 때문에 좋은 프로그래밍 지식을 가진 사람이라면 안전하게 사용할 수 있습니다. 또한 Python을 알고 있는 사람이라면 누구나 사용할 수 있습니다.\n- Python을 모르거나 코딩에 익숙하지 않은 사람들을 위해 GUI를 통해 쉽게 분석 및 시각화를 할 수 있는 방법을 제공합니다.\n- 플랫폼을 사용하기 시작하는 것이 너무 어렵지 않습니다. 기술적인 정보가 너무 많아서 지식이 부족한 사람들이 사용을 꺼려할 정도로 사용자를 압도하지 않습니다.\n- 무료 계층을 통해 공개적으로 사용 가능한 데이터셋에 대한 분석을 실행할 수 있습니다.\n- 이 글에서 고려된 분류 이외에도 다양한 도구가 제공됩니다.\n\n그럼에도 불구하고, 개선할 부분들이 몇 가지 존재하며, 몇 가지 측면들이 개선되어야 할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n- 무료 티어는 개인 데이터에서 ML 모델을 실행할 수 없습니다.\n- 사용자 인터페이스가 다소 오래된 느낌이 있습니다.\n- 일부 시각화 요소가 명확하지 않고 해석하기 어려울 수 있습니다.\n- 어플리케이션이 가끔 반응이 느릴 수 있습니다.\n- 불균형 데이터를 지원하지 않습니다.\n- 이 플랫폼의 최대 잠재력을 발휘하려면 데이터 과학 및 기계 학습에 대한 일부 지식이 여전히 필요합니다 (다른 플랫폼에서도 마찬가지일 수 있습니다).\n\n다음 기사에서는 다른 플랫폼들을 사용하여 그들의 장단점을 파악하고, 각 플랫폼에 최적인 사용 사례를 확인할 것입니다.\n\n그 때까지 이 기사가 흥미로운 내용이었길 바랍니다! 피드백이나 질문이 있으시면 언제든지 자유롭게 남겨주세요!\n\n이 기사에 대한 생각이 있으신가요? LinkedIn에서 메시지를 보내거나 직접 연락 주십시오!\n\n<div class=\"content-ad\"></div>\n\n저를 팔로우해주세요! 이렇게 하면 미래의 기사 발행 알림을 받을 수 있습니다.\n\n![Image](/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_14.png)\n\n이 기사를 작성한 저자는 작성 시점에 Actable AI의 데이터 과학자였습니다.","ogImage":{"url":"/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_0.png"},"coverImage":"/assets/img/2024-06-23-HowtoPredictPlayerChurnwithSomeHelpFromChatGPT_0.png","tag":["Tech"],"readingTime":21},{"title":"지금 바로 탐험하세요 AI가 지원하는 PDF 채팅 동반자 AskToPDF","description":"","date":"2024-06-23 16:38","slug":"2024-06-23-ExploreAskToPDFnowYourAI-poweredPDFChatCompanion","content":"\n\n문서 상호 작용의 혁명적인 여정을 시작하세요. AskToPDF는 PDF 문서와 상호 작용하는 방법을 간소화하기 위해 설계된 새로운 AI 애플리케이션입니다. 세심한 개발과 정제 작업을 거친 끝에, 저는 AskToPDF가 모든 사람들에게 www.asktopdf.com에서 사용 가능하다는 것을 기쁘게 알려드립니다!\n\n최초 제공 기간 동안 무료로 제공되며, 또한 데이터베이스 채팅을 위한 새로운 AI 애플리케이션을 계획 중입니다. 아이디어는 데이터베이스나 스키마에 연결한 다음 자연 언어로 데이터베이스와 대화를 시작하는 것입니다. 이 새로운 generateSQL 애플리케이션에 대한 더 많은 업데이트를 받으시려면 저를 팔로우해주세요. 개발에 사용된 모든 기술/전략에 관련된 이야기를 게시할 예정입니다.\n\nAskToPDF란 무엇인가요?\n\nAskToPDF는 문서를 더 이상 전에 없던 방식으로 찾아볼 수 있도록 하는 혁신적인 AI 기반 PDF 채팅 앱입니다. 고급 언어 모델 (LLM) 기술을 기반으로, AskToPDF를 사용하면 어떤 PDF 문서든 업로드하고 쉽게 정보를 조회할 수 있습니다. 강의 노트를 검토하는 학생, 프로젝트 보고서를 재방문하는 전문가 또는 문서 내용에 대해 궁금한 사용자라면 AskToPDF가 도움을 줄 준비가 되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-06-23-ExploreAskToPDFnowYourAI-poweredPDFChatCompanion_0.png)\n\nAskToPDF는 어떻게 작동하나요?\n\nAskToPDF는 첨단 검색 증강 생성(RAG) 기술을 활용하여 업로드된 PDF를 심층적으로 이해합니다. 한 번 업로드하면 문서와 관련된 질문을 입력하기만 하면 AskToPDF가 나머지를 처리해줍니다. 저희 지능형 시스템은 문서를 스캔하여 관련 정보를 검색하고 실시간으로 간결하고 정확한 답변을 생성합니다.\n\nAskToPDF를 선택하는 이유는 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n- 효율성: 모든 페이지를 읽지 않고도 긴 문서에서 즉각적인 답변을 얻을 수 있습니다.\n- 정확성: 문서 내용에서 직접 유도된 정확한 답변을 얻을 수 있습니다.\n- 접근성: 사용자 친화적인 웹 인터페이스를 통해 언제 어디서나 AskToPDF에 접속할 수 있습니다.\n\n지금 AskToPDF 커뮤니티에 가입하세요!\n\nAskToPDF를 통해 문서 상호작용의 미래를 경험해보세요. 학자, 전문가, 또는 단순히 궁금한 사람이라면, AI 기술을 활용한 답변 시스템은 PDF 탐색을 원활하고 생산적으로 만들어줍니다.\n\n지금 www.asktopdf.com을 방문하여 AskToPDF가 문서 탐색 경험을 어떻게 변화시킬지 살펴보세요. AskToPDF를 통해 쉽고 빠르게 질문하고 답변을 얻는 즐거움을 느껴보시죠!\n\n<div class=\"content-ad\"></div>\n\nAI를 활용하여 문서를 탐색하는 힘을 발휘해보세요 - 오늘 AskToPDF를 시도해보세요!","ogImage":{"url":"/assets/img/2024-06-23-ExploreAskToPDFnowYourAI-poweredPDFChatCompanion_0.png"},"coverImage":"/assets/img/2024-06-23-ExploreAskToPDFnowYourAI-poweredPDFChatCompanion_0.png","tag":["Tech"],"readingTime":2},{"title":"SQL로 MLflow 모델 구축하기 머신러닝 라이프사이클 관리 쉽게 하는 방법","description":"","date":"2024-06-23 16:37","slug":"2024-06-23-BridgingtheGapConstructingSQL-BasedModelsinMLflowforStreamlinedMLLifecycleManagement","content":"\n\n## MLflow 생태계에 SQL 모델을 통합하는 단계별 안내서\n\n![이미지](/assets/img/2024-06-23-BridgingtheGapConstructingSQL-BasedModelsinMLflowforStreamlinedMLLifecycleManagement_0.png)\n\n## 소개\n\n기계 학습의 끊임없이 진화하는 풍경에서, 모델의 끝-끝 수명주기를 원할하게 관리해야 하는 필요성이 중요해졌습니다. 이러한 복잡한 프로세스를 단순화하는 오픈 소스 플랫폼인 MLflow가 나타납니다. 이 포괄적인 안내서에서는 SQL 기반 모델과 MLflow의 기능을 융합하는 과정을 탐색할 것입니다. 우리의 주요 목표는 두 가지입니다: 첫째, 간단한 SQL 기반 모델을 사용하여 MLflow의 기본 원리를 실습적으로 이해하는 것이며, 둘째로, MLflow의 모델 저장소 내에 SQL 쿼리를 캡슐화하는 흥미로운 도전에 대응하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## SQL 기반 모델의 중요성\n\nSQL(구조화된 쿼리 언어) 기반 모델은 현실 세계 비즈니스 시나리오에서 독특하게 중요하며 순위 매기기, 추천 시스템 및 데이터 필터링 작업에서 중추적 역할을 합니다. SQL 기반 모델이 중요한 역할을 하는 몇 가지 추가 도메인을 살펴보겠습니다:\n\n- 재고 관리: SQL 데이터베이스는 재고 수준, 재주문 점 및 공급망 데이터를 추적합니다. SQL 쿼리는 재고 수준을 모니터링하고 재고 보충 알림을 생성하며 재고 순환을 최적화하는 데 도움을 줍니다.\n- 고객 세분화 및 타겟 마케팅: 마케터들은 SQL 기반 모델을 활용하여 고객 베이스를 세분화하고 타겟 마케팅 캠페인을 설계합니다. 이러한 모델은 고객 인구 통계, 구매 이력 및 온라인 행동을 분석하여 특정 선호도를 갖는 고객 세그먼트를 식별함으로써 맞춤형 마케팅 전략을 구현할 수 있습니다.\n- 공급망 최적화: 복잡한 공급망을 관리하는 기업들은 SQL 모델을 사용하여 재고 수준을 최적화하고 물류를 최적화하며 비용을 최소화합니다. SQL 쿼리는 공급업체 성과, 수요 예측 및 생산 일정을 분석하여 적시에 납품하고 효율적인 운영을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n## MLflow이란 무엇인가요?\n\nMLflow는 Databricks에서 개발한 오픈 소스 플랫폼으로, 기계 학습 수명주기의 end-to-end 관리를 용이하게 합니다. 실험 추적, 코드를 재현 가능한 실행으로 패키징하고 모델을 공유하고 배포하는 도구를 제공하며, 모든 것을 통합된 프레임워크 내에서 처리합니다. 데이터 과학자, 기계 학습 엔지니어, 또는 비즈니스 분석가이든, MLflow는 기계 학습 프로젝트를 구성하고 협력하는 구조화된 방식을 제공합니다.\n\nMLflow의 주요 구성 요소:\n\n- 추적: MLflow의 추적 구성 요소를 사용하면 중요한 메트릭, 매개 변수 및 다른 실행에 연결된 아티팩트를 기록하고 모니터링할 수 있습니다.\n- 프로젝트: MLflow의 프로젝트 기능을 사용하면 코드, 종속성 및 환경 사양을 재사용 가능한 형식으로 패키징할 수 있습니다. 이를 통해 실험을 재현 가능하게 하여, 개발에서 제품화로의 전환 시에 일관성이 깨지지 않도록 할 수 있습니다.\n- 모델: 훈련된 기계 학습 모델의 모음입니다. 서로 다른 모델을 나타내는 서로 다른 책을 개인 서재로 상상해보세요. MLflow는 여러분이 이러한 모델을 패키징, 구성 및 관리할 수 있게 해주어 나중에 쉽게 찾아서 사용할 수 있습니다.\n- 모델 레지스트리: 모델 레지스트리를 정리된 서재로 생각해보세요. 여러분이 훈련된 기계 학습 모델의 서로 다른 버전을 저장하고 관리할 수 있는 곳입니다. 여러분이 좋아하는 책의 다른 버전이 있는 책장이 있는 것처럼 생각해보세요. MLflow의 모델 레지스트리는 모델이 시간이 지남에 따라 진화하는 것을 추적하여 필요할 때 쉽게 찾아서 사용할 수 있도록 해줍니다.\n\n<div class=\"content-ad\"></div>\n\nMLflow은 scikit-learn 및 TensorFlow와 같은 다양한 모델 라이브러리를 조화롭게 통합하여 배포를 최적화하고 모델 알고리즘 변경에 대한 우려를 덜어주는 통합 플랫폼으로 빛난다. MLflow를 사용하면 기업은 다양한 알고리즘 실험을 통해 일정한 배포 프로세스를 준수하는 동시에 유연성을 얻을 수 있습니다. 이 플랫폼은 라이브러리 간의 차이를 추상화하여 개발에서 배포로의 수동 변환 없이 원활한 전환을 가능하게 합니다. 이 유연성은 알고리즘 잠금을 회피하고 새로운 혁신에 적응하며, 배포 파이프라인을 중앙 집중화하여 유지 관리 부담을 줄입니다.\n\n![이미지](/assets/img/2024-06-23-BridgingtheGapConstructingSQL-BasedModelsinMLflowforStreamlinedMLLifecycleManagement_1.png)\n\n## Mflow에 SQL 기반 모델 통합하는 이유\n\nMLflow는 Python 모델 및 TensorFlow 아티팩트를 관리하는 데 뛰어나지만, 모델 컨텍스트 내에서 SQL 쿼리를 수용하는 것은 원래 지원되지 않습니다. 이 분리는 종종 기관이 SQL 기반 및 Python 모델을 배포하기 위해 별도의 시스템을 유지하도록 강요하여 유지 보수 노력과 추적 불일치가 증가하게 합니다.\n\n<div class=\"content-ad\"></div>\n\n해당 도전을 극복하기 위해, 우리는 파이썬 함수 내에서 SQL 쿼리의 논리를 캡슐화하는 천재적인 전략을 곧 발표할 예정이에요. 이를 통해, 우리는 SQL 기반 모델을 MLflow의 생태계에 원활하게 통합하여 효율적인 저장, 버전 관리, 배포를 가능하게 합니다.\n\n이 통합은 전통적인 기계 학습 알고리즘을 넘어 플랫폼의 능력을 확장하여, 데이터 과학 작업에서 SQL 쿼리의 파워를 활용하려는 기관들에게 가치 있는 자산이 됩니다. 이는 모델 라이프사이클 관리에 대한 통합된 접근 방식을 제공하며, 동일한 프레임워크 내에서 SQL 및 Python 기반 모델을 효율적으로 결합하여, 데이터 분석 및 모델 개발에 SQL 전문 지식을 필요로 하는 기관에 대응합니다. 이는 MLflow의 유틸리티를 확장하여 더 넓은 범위의 모델링 작업을 처리하고, 모델 개발 라이프사이클 전반에 걸쳐 개선된 효율성과 협업을 촉진합니다.\n\n## 단계별 구현\n\n문제 진단: 에어비앤비를 고려해봅시다. 웹 사이트에서 사용자 경험을 향상시키기 위해, 에어비앤비는 숙박 정보의 랭킹 모델을 최적화하고자 합니다. 고급 기계 학습 알고리즘으로 진입하기 전에, 그들은 SQL 기반 모델을 벤치마크로 구축하고자 합니다. 주요 목표는 사용자가 특정 지역에 대한 요청을 제출할 때, 웹 사이트의 리스트를 평균 리뷰 점수를 기반으로 순위를 매기는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 차례로 수행할 단계입니다:\n\n1. 모의 데이터 생성: 먼저 Airbnb 리스트 데이터를 모방하는 모의 데이터 세트를 생성할 것입니다. 이 데이터 세트에는 리스트 ID, 지역, 리뷰 점수, 생성 날짜 및 방의 수가 포함됩니다. 이 데이터 생성을 통해 모델에 대한 대표적인 데이터 세트로 작업할 수 있게 됩니다.\n\n방금 생성한 데이터 세트를 간략히 살펴보겠습니다:\n\n![데이터세트](/assets/img/2024-06-23-BridgingtheGapConstructingSQL-BasedModelsinMLflowforStreamlinedMLLifecycleManagement_2.png)\n\n<div class=\"content-ad\"></div>\n\n2. 랭킹 함수 정의하기: 지역별로 목록을 랭킹하는 함수를 정의할 거에요. 이 함수는 지역(지역)을 입력으로 받아와서 SQL 쿼리를 사용하여 리뷰 점수를 기반으로 내림차순으로 필터링하고 정렬할 거에요.\n\n함수에 대해 빠르게 테스트를 해 보겠습니다:\n\n3. MLflow를 위한 함수 랩핑: 이 랭킹 함수를 MLflow에 통합하기 위해서는 MLflow의 규칙을 따라 랩핑할 필요가 있어요. mlflow.pyfunc.PythonModel을 상속하는 RankingModel이라는 파이썬 클래스를 만들 거에요. 이 클래스에는 스파크 세션을 초기화하는 predict 메서드가 포함되며 입력에서 지역을 추출하고 랭킹 함수를 호출할 거에요.\n\n4. 모델 테스트: RankingModel이 예상대로 작동하는지 확인하기 위해 빠른 테스트를 실행할 거에요. 이 테스트에서 모델의 인스턴스를 만들고 모델 입력(지역)을 정의하고 predict 메서드를 호출하여 순위가 매겨진 목록을 얻을 거에요.\n\n<div class=\"content-ad\"></div>\n\n4. 모델 등록: 성공적인 테스트 후, 앞으로 사용할 모델을 MLflow에 등록합니다. 이 단계에는 MLflow 런을 정의, 테스트 데이터로 predict() 메서드를 호출, predict 함수의 시그니처 추론, 모델 아티팩트를 MLflow에 로깅, 그리고 모델 레지스트리에 모델 등록이 포함됩니다.\n\n등록된 모델을 살펴보겠습니다.\n\n![등록된 모델](/assets/img/2024-06-23-BridgingtheGapConstructingSQL-BasedModelsinMLflowforStreamlinedMLLifecycleManagement_3.png)\n\n이제 등록 후에 다른 노트북이나 콘텍스트에서 이 모델을 로드하고 해당 지역을 입력으로 예측 메서드를 호출하면 그 지역에 대한 리뷰 점수별로 순위가 매겨진 목록 ID가 반환됩니다.\n\n<div class=\"content-ad\"></div>\n\n5. 등록된 모델 로드 및 사용하기: 마지막으로 등록된 모델을 다른 컨텍스트나 노트북에서 로드하고 예측에 사용하는 방법을 보여드리겠습니다. 이를 통해 모델을 다양한 애플리케이션에 원활하게 통합할 수 있습니다.\n\n이러한 단계를 따르면 SQL 기반 모델을 성공적으로 구축했고, MLflow와 통합했으며, 다양한 데이터 기반 하위 응용 프로그램에서 사용할 수 있게 될 것입니다.\n\n## 결론\n\n마지막으로, 우리는 SQL 모델을 성공적으로 작성하고 MLflow에 통합했습니다. 이 모델은 이제 등록되어 다른 서비스의 엔드포인트로 제공되어 리뷰 점수 기반 순위 목록에 대한 확장 가능하고 효율적인 솔루션으로 사용할 준비가 되었습니다. 이 접근 방식은 MLflow의 다양한 유형의 모델을 통합하여 통일된 프레임워크 내에서 다루는 다양성을 보여주며, Python 기반 모델에서 SQL 기반 모델로의 능력을 확장합니다. 전체 노트북은 여기에서 확인할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사가 유익하고 재미있었으면 좋겠습니다. 좋아요로 감사를 표현해 주시고, 댓글로 피드백을 공유해 주세요.\n\n# 추가 정보\n\n제가 작성한 PySpark 튜토리얼 컬렉션을 소개합니다. 이 튜토리얼은 PySpark의 다양한 측면을 마스터하는 데 도움이 되도록 설계되었습니다. 제가 다음 기사에서 우선적으로 다루기를 원하는 구체적인 주제나 기술이 있으면 자유롭게 제안해 주세요. 여러분의 피드백은 귀중합니다. 만약 이 PySpark 튜토리얼이 유익하고 도움이 되었다면, 더 깊은 내용의 컨텐츠를 제공하는 Medium에서 저를 팔로우하시기를 권장합니다. PySpark의 세계로의 여정을 즐기세요! 즐거운 학습과 코딩되세요!","ogImage":{"url":"/assets/img/2024-06-23-BridgingtheGapConstructingSQL-BasedModelsinMLflowforStreamlinedMLLifecycleManagement_0.png"},"coverImage":"/assets/img/2024-06-23-BridgingtheGapConstructingSQL-BasedModelsinMLflowforStreamlinedMLLifecycleManagement_0.png","tag":["Tech"],"readingTime":6},{"title":"IPL 통계 분석을 위한 고급 SQL 쿼리 완벽 가이드","description":"","date":"2024-06-23 16:34","slug":"2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics","content":"\n<img src=\"/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_0.png\" />\n\n# 소개:\n\n상상해보세요. BCCI(인도크리켓통제위원회)에서 IPL 2150의 데이터 분석가로 고용되었다고 가정해 봅시다. 네, 2150 년에도 데이터 분석가는 여전히 높은 수요가 있고, AI가 아직 모든 일자리를 대체하지는 않았습니다. 누가 생각했겠습니까? 아마도 AI는 여전히 크리켓의 규칙을 이해하려고 노력 중일지도 모릅니다! 그런데, 이 프로젝트에서는 2150 년 자료가 제공되지 않습니다. 그래서 신경 쓰지 마세요.\n\n당신의 팀 매니저가 IPL 시즌 전체 기록을 포함하는 여러 CSV 파일을 손에 쥐고 여러분에게 접근합니다. 그들은 여러분에게 포괄적인 분석을 수행하고 이 데이터를 Postgres(RDBMS)로 이전하여 팀 내에서 더 효율적인 데이터 관리를 요청합니다.\n모든 데이터 집합과 마찬가지로, 도메인 지식은 데이터 분석가가 효과적으로 데이터 분석을 수행하는 데 중요합니다. IPL 크리켓에 익숙하지 않다면, 분석을 진행하기 전에 데이터 집합의 열을 먼저 살펴봄으로써 도메인 지식을 얻는 것이 좋습니다.\n\n<div class=\"content-ad\"></div>\n\n# 데이터 세트:\n\nCSV 파일에는 아래 그림에 표시된 6개의 테이블이 포함되어 있으며, 이를 pgAdmin (postgreSQL의 RDMS)에서 다음 데이터베이스 스키마처럼 변환해야 합니다.\n실제 시나리오에서 기업은 일반적으로 CSV에서 SQL 데이터베이스로의 전환보다 DBMS(데이터베이스 관리 시스템)를 직접 사용합니다. 그러나 우리의 SQL 프로젝트 목적으로 이 전환이 수행되었습니다.\n\n<img src=\"/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_1.png\" />\n\n제약 조건:\n\n<div class=\"content-ad\"></div>\n\n- 주어진 스키마에 포함된 기본 키 (Primary Key)와 외래 키 (Foreign Key) 제약 조건\n- out_type은 'caught', 'caught and bowled', 'bowled', 'stumped', 'retired hurt', 'keeper catch', 'lbw', 'run out', 'hit wicket', 또는 NULL(실제 null이 아닌 문자열 형태) 값만 가질 수 있습니다.\n- role_desc는 'Player', 'Keeper', 'CaptainKeeper' 또는 'Captain' 값만 가질 수 있습니다.\n- toss_name은 'field' 또는 'bat' 값만 가질 수 있습니다.\n- win_type은 'wickets', 'runs', 또는 NULL(실제 null이 아닌 문자열 형태) 값만 가질 수 있습니다.\n- ball_by_ball 테이블의 runs_scored 값은 0에서 6 사이여야 합니다.\n- ball_by_ball 테이블의 innings_no 값은 1 또는 2만 가능합니다.\n\n# 분석적 질문 및 해결책:\n\n자세한 분석을 위해 팀 매니저가 다음 작업을 할당하고 명확한 경로를 제시했습니다.\n\nQ 1: 주어진 데이터베이스 스키마에 따라 CSV 파일을 생성하고, 모든 제약 조건과 테이블 간 관계가 올바르게 반영되도록 하고, 그 후 pgAdmin에 가져오세요. (다른 RDBMS를 사용하는 경우, 모든 쿼리에 대해 구문을 조정하십시오)\n\n<div class=\"content-ad\"></div>\n\n해결책: 지정된 데이터베이스 스키마와 일치하도록 필요한 테이블을 적절한 제약 조건과 관계와 함께 생성하고 해당 CSV 파일에서 데이터를 가져옵니다.\n\n```js\n-- 해결책 1:\n-- 테이블을 생성할 때 위의 데이터베이스 스키마에 따라\n-- 필요한 제약 조건 및 관계 키를 추가해주세요\n\n-- venue 테이블 생성\ncreate table if not exists venue(\n venue_id int,\n venue_name varchar(50) not null,\n city_name varchar(50) not null,\n country_name varchar(50) not null,\n constraint pk_venue_venue_id primary key (venue_id)\n);\n-- venue.csv 파일에서 값 가져오기\ncopy venue\nfrom 'D:\\Downloads\\A Portfolio Projects\\SQL Projects\\IPL Analysis\\Dataset CSV\\venue.csv'\ndelimiter ','\ncsv header;\n\n-- team 테이블 생성\ncreate table if not exists team(\n team_id int,\n team_name varchar(50) not null,\n constraint pk_team_team_id primary key(team_id)\n);\n-- team.csv 파일에서 값 가져오기\ncopy team\nfrom 'D:\\Downloads\\A Portfolio Projects\\SQL Projects\\IPL Analysis\\Dataset CSV\\team.csv'\ndelimiter ','\ncsv header;\n\n-- player 테이블 생성\ncreate table if not exists player(\n player_id int,\n player_name varchar(50) not null,\n dob date not null,\n batting_hand varchar(50) not null,\n bowling_skill varchar(50) not null,\n country_name varchar(50) not null,\n constraint pk_player_player_id primary key(player_id)\n);\n-- player.csv 파일에서 값 가져오기\ncopy player\nfrom 'D:\\Downloads\\A Portfolio Projects\\SQL Projects\\IPL Analysis\\Dataset CSV\\player.csv'\ndelimiter ','\ncsv header;\n\n-- match 테이블 생성\ncreate table if not exists match(\n match_id int primary key,\n season_year int not null,\n team1 int not null references team(team_id),\n team2 int not null references team(team_id),\n venue_id int not null references venue(venue_id),\n toss_winner int not null references team(team_id),\n match_winner int not null references team(team_id),\n toss_name varchar(50) not null check(toss_name in ('field', 'bat')),\n win_type varchar(50) not null check(win_type in ('wickets', 'runs', 'NULL')),\n man_of_match int not null references player(player_id),\n win_margin int not null\n)\n-- match.csv 파일에서 값 가져오기\ncopy match\nfrom 'D:\\Downloads\\A Portfolio Projects\\SQL Projects\\IPL Analysis\\Dataset CSV\\match.csv'\ndelimiter ','\ncsv header;\n\n-- player_match 테이블 생성\ncreate table if not exists player_match(\n playermatch_key bigint primary key,\n match_id int not null references match(match_id),\n player_id int not null references player(player_id),\n role_desc varchar(50) not null check(role_desc in ('Player', 'Keeper', 'CaptainKeeper', 'Captain')),\n team_id int not null references team(team_id)\n);\n-- player_match.csv 파일에서 값 가져오기\ncopy player_match\nfrom 'D:\\Downloads\\A Portfolio Projects\\SQL Projects\\IPL Analysis\\Dataset CSV\\player_match.csv'\ndelimiter ','\ncsv header;\n\n-- ball_by_ball 테이블 생성\ncreate table if not exists ball_by_ball(\n match_id int not null references match(match_id),\n innings_no int not null check(innings_no<3 and innings_no>0),\n over_id int not null,\n ball_id int not null,\n runs_scored int not null check(runs_scored<=6 and runs_scored>=0),\n extra_runs int not null,\n out_type varchar(50) not null check(out_type in ('caught', 'caught and bowled', 'bowled', 'stumped', 'retired hurt', 'keeper catch', 'lbw', 'run out', 'hit wicket', 'NULL')),\n striker int not null references player(player_id),\n non_striker int not null references player(player_id),\n bowler int not null references player(player_id),\n constraint pk_ball_by_ball_id primary key(match_id, innings_no, over_id, ball_id)\n)\n-- ball_by_ball.csv 파일에서 값 가져오기\ncopy ball_by_ball\nfrom 'D:\\Downloads\\A Portfolio Projects\\SQL Projects\\IPL Analysis\\Dataset CSV\\ball_by_ball.csv'\ndelimiter ','\ncsv header;\n```\n\n질문 2: 생성한 테이블에서 각 경기장 마다 스코어된 평균 달성량을 찾으려면 스타디움에서 경기당 평균 달성량(두 팀의 총점)을 계산해야 합니다.\n총 점수를 계산하려면 ball_by_ball 테이블에서 runs_scored 및 extra_runs를 합산해야 합니다.\n\n해결책: 각 경기장에서 스코어된 평균 달성량을 찾으려면 다음 단계를 따라야 합니다. 먼저 각 경기장에서 플레이된 총 경기수를 계산하고, 그 다음 각 경기장에서 스코어된 총 점수를 결정합니다. 마지막으로 총 점수를 플레이된 경기수로 나누어 각 경기장의 경기 당 평균 달성량을 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- 2단계: 각 구장에서의 경기 수 계산\nwith\nno_of_match_per_venue as\n (\n  select v.venue_id, v.venue_name, count(match_id) as no_of_matches\n  from match m\n  join venue v\n  on v.venue_id=m.venue_id\n  group by v.venue_id, v.venue_name\n ),\n-- 2단계: 각 구장에서의 총 득점 계산\ntotal_run_per_venue as\n (\n  select v.venue_id, sum(b.runs_scored+b.extra_runs) as total_run\n  from ball_by_ball b\n  join match m\n  on m.match_id = b.match_id\n  join venue v\n  on v.venue_id = m.venue_id\n  group by v.venue_id\n )\n-- 마지막으로 위의 두 임시 테이블을 사용하여\n-- 각 구장에서의 경기 당 평균 득점을 계산합니다\nselect  npv.venue_name, tpv.total_run, npv.no_of_matches,\nround(tpv.total_run/npv.no_of_matches::numeric,3) as avg_run\nfrom no_of_match_per_venue npv\njoin total_run_per_venue tpv\non npv.venue_id = tpv.venue_id\norder by avg_run desc;\n```\n\n![2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_2.png](/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_2.png)\n\n질문 3: 평균으로 경기 당 가장 많은 볼을 친 선수들을 찾고 상위 10명으로 제한하십시오.\n스트라이커로서 해당 선수가 등록된 경우 선수가 공을 쳤다고 간주합니다.\n\n해결책: 먼저 각 선수가 참가한 총 경기 수를 계산해야 합니다. 그 다음 각 선수가 스트라이커로서 받은 총 볼 수를 확인해야 합니다. 마지막으로 경기 당 평균으로 가장 많은 볼을 친 상위 10명의 선수를 식별할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n-- 솔루션 3:\n-- 단계 1: player_match 테이블에서 플레이어가 참가한 경기 수를 세기\nwith num_of_match_by_player as\n(\nselect player_id, count(match_id) as no_of_match from player_match\ngroup by player_id\n),\n-- 단계 2: 공격수로서 플레이어가 참가한 총 볼 수 계산\ntotal_ball_played_by_player as\n(\nselect striker, count(ball_id) as total_ball_played from ball_by_ball\ngroup by striker\n)\n-- 최종적으로 플레이어 당 평균 한 경기에서 가장 많이 볼을 친 상위 10명을 계산\nselect player_id, player_name, avg_ball_played from\n(\nselect \\*,\n-- 동률이 있는 경우를 포함하기 위해 rank 함수 사용\nrank() over(order by avg_ball_played desc) from\n(\n-- 평균 계산\nselect p.player_id, p.player_name,\n(tp.total_ball_played/mp.no_of_match) as avg_ball_played\nfrom num_of_match_by_player mp, total_ball_played_by_player tp, player p\nwhere mp.player_id = tp.striker\nand\np.player_id = mp.player_id\n)\n)\nwhere rank<=10; -- 상위 10개 가져오기\n\n![](/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_3.png)\n\nQ 4: 가장 빈도가 높은 6타자를 찾아보세요.\n즉, 플레이어가 차지한 볼 중에서 가장 높은 비율로 6점을 친 플레이어를 찾으세요. 플레이어 ID, 플레이어 이름, 플레이어가 6점을 얻은 횟수, 차진 볼 수, 6의 비율을 출력하세요.\n\n솔루션: 먼저 각 플레이어가 차진 볼 수를 계산합니다. 그런 다음, 각 플레이어가 친 6점을 결정합니다. 마지막으로 각 플레이어의 6의 비율을 계산하세요.\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- Solution 4:\n-- 각 세션에서 각 선수가 참가한 공의 수 계산\nwith ball_by_player as(\n select striker, count(ball_id) as ball_played from ball_by_ball\n group by striker\n),\n-- 각 선수가 기록한 6점 수 계산\nsix_by_player as(\n select striker, count(ball_id) as no_of_six from ball_by_ball\n where runs_scored = 6\n group by striker\n)\n-- 최종 비율 얻기\nselect p.player_id, p.player_name, bp.ball_played, sp.no_of_six,\nround((sp.no_of_six::numeric/bp.ball_played),2) as fraction\nfrom ball_by_player as bp, six_by_player as sp, player as p\nwhere bp.striker = sp.striker and bp.striker = p.player_id\norder by fraction desc;\n```\n\n<img src=\"/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_4.png\" />\n\nQ 5: 각 시즌에서 가장 많은 득점을 기록한 상위 3 타자 및 가장 많은 wickets를 따낸 상위 3 볼러 player_ids를 찾아보세요. Output (season_year, batsman, runs, bowler, wickets). 여기서 batsman 및 bowler는 선수들의 player_ids입니다. 동점인 경우 더 낮은 player_id를 먼저 출력합니다. season_year (날짜가 빠른 순)와 rank(특정 시즌에 더 많은 득점 및 wickets를 기록한 타자와 볼러)로 정렬합니다. (no_of_seasons\\*3)개의 행이 있을 것입니다.\n\nSolution: 먼저, 각 시즌에서 가장 많은 wickets를 기록한 상위 3 타자를 식별합니다. 다음으로, 각 시즌에서 가장 많은 wickets를 기록한 상위 3 볼러를 결정합니다. 마지막으로, 이러한 결과를 결합하여 최종 목록을 얻습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n-- 솔루션 5:\n-- 먼저 각 시즌에서 각각 가장 많은 횟수의 릴리를 기록한 상위 3명의 타자를 찾습니다.\nwith top_batsman as\n (\n select *,\n rank() over(partition by season_year order by run desc, striker) from\n  (\n  select m.season_year, b.striker, p.player_name, sum(runs_scored) as run\n  from ball_by_ball as b, match as m, player as p\n  where b.match_id = m.match_id and p.player_id = b.striker\n  group by m.season_year, b.striker, p.player_name\n  )\n ),\n-- 그리고 두 번째로, 각 시즌에서 각각 가장 많은 볼을 기록한 상위 3명의 볼러를 찾는다.\ntop_bowlers as(\n select *,\n rank() over(partition by season_year order by wicket desc, bowler) from\n  (\n  select m.season_year, b.bowler, p.player_name, count(out_type) as wicket\n  from ball_by_ball as b, match as m, player as p\n  where b.match_id = m.match_id and p.player_id = b.bowler\n  and b.out_type not in ('run out', 'retired hurt')\n  group by m.season_year, b.bowler, p.player_name\n  )\n )\n-- 위 두 가지를 조인하여 최종 결과를 얻으세요\nselect tbt.season_year, tbt.striker, tbt.player_name, tbt.run, tbo.bowler, tbo.player_name, tbo.wicket\nfrom top_batsman as tbt, top_bowlers as tbo\nwhere tbt.rank=tbo.rank and tbt.rank<=3 and tbo.rank<=3 and tbt.season_year = tbo.season_year\norder by season_year;\n```\n\n<img src=\"/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_5.png\" />\n\n질문 6: 각 경기에서 최대 파트너십 득점을 달성한 선수의 ID를 찾기 위한 SQL 쿼리를 작성하세요. 결과에는 (match_id, player1, runs1, player2, runs2)가 포함되어야 하며, 파트너십 득점의 내림차순으로 정렬되어야 합니다. 동점의 경우 match_id가 오름차순으로 정렬되어야 합니다. runs1이 항상 runs2보다 큰지 확인하고, runs1과 runs2가 동일한 경우 player1_id가 player2_id보다 커야 합니다. extra_runs는 포함되어서는 안 됩니다. 서로 다른 선수가 동일한 파트너십 득점을 여러 번 달성하는 경우 각 경기의 여러 행이 존재할 수 있습니다.\n\n솔루션:\n단계 1- partnership이라는 공통 테이블 표현(CTE)을 사용하여 각 파트너십(경기 ID 및 연결된 선수 ID로 식별)이 가져온 총 득점(extr):\n단계 2- 다른 CTE인 striker_run_contributed는 각 파트너십에서 스트라이커가 기여한 총 득점을 계산합니다.\n단계 3- CTE final_table은 파트너십 득점을 스트라이커의 득점 기여와 결합하고, 비 스트라이커의 득점을 계산합니다. 각 경기의 최고 파트너십 득점만 포함하도록 필터링합니다.\n단계 4- 주 쿼리는 결과를 선택하고 정렬하여 더 높은 득점자가 항상 먼저 나오고 run1이 항상 run2보다 크도록 합니다. 두 선수가 동일한 득점인 경우 더 높은 ID를 가진 선수가 먼저 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n-- 질문 5:\n-- 각 경기에서 가장 많은 협력 득점을 얻은 플레이어들의 ID 찾기?\n-- 한 경기에 여러 개의 행이 있을 수 있습니다.\n-- 출력 (match_id, player1, runs1, player2, runs2),\n-- 협력 득점의 내림차순으로(동점인 경우 match_id는 오름차순으로 비교).\n-- 각 행에서 run1 > run2\n-- runs1=runs2인 경우 player1_id > player2_id. 참고: extra_runs는 계산하지 않아야 함\n-- 솔루션\n\nwith partnership as\n(\n select match_id, striker, non_striker, p_id, p_run from\n (\n  select *,\n  sum(runs_scored) over(partition by match_id, p_id order by match_id) as p_run,\n  row_number() over(partition by match_id, p_id order by match_id) as rank\n  from(\n   select b.match_id, b.runs_scored, b.striker, b.non_striker,\n   case when striker<non_striker then concat(non_striker,' ',striker)\n   else concat(striker, ' ', non_striker)\n   end as p_id\n   from ball_by_ball as b\n  )\n ) where rank=1\n order by p_run desc, match_id asc\n),\nstriker_run_contributed as\n (\n select b.match_id, b.striker, b.non_striker, sum(b.runs_scored) as striker_run\n from ball_by_ball as b\n group by b.match_id, b.striker, b.non_striker\n  ),\nfinal_table as\n(\n select p.match_id, p.striker, p.non_striker, sr.striker_run, (p.p_run-sr.striker_run) as non_striker_run,\n p.p_run\n from partnership as p, striker_run_contributed as sr\n where p.match_id = sr.match_id and p.striker = sr.striker and p.non_striker = sr.non_striker\n and p.p_run = (select max(p_run) from partnership as pt where pt.match_id = p.match_id)\n order by p.p_run desc, p.match_id asc\n  )\nselect match_id,\ncase when (striker_run = non_striker_run and striker>non_striker) then striker\n  when striker_run>non_striker_run then striker\n  else non_striker end as player_1,\ncase when (striker_run>non_striker_run) then striker_run\n  else non_striker_run end as run1,\ncase when (striker_run = non_striker_run and striker>non_striker) then non_striker\n  when striker_run>non_striker_run then non_striker\n  else striker end as player_2,\ncase when (striker_run>non_striker_run) then non_striker_run\n  else striker_run end as run2,\np_run as total_partnership\nfrom final_table;\n```\n\n<img src=\"/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_6.png\" />\n\n질문 7: 이닝 유형이 wickets인 모든 경기에서 득점이 6점 미만인 이닝 ID를 찾으세요.\n출력 (match_id, innings_no, over_id). 참고: 이닝에서 득점된 점수에는 extra_runs도 포함됨.\n\n솔루션: 먼저 ball_by_ball 테이블과 이긴 경기 정보를 포함하는 match 테이블을 조인한 후, 득점이 6점 미만인 경우에 해당하는 over_id를 가져옵니다.\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- 질문 7:\n-- 이닝 종료로 승리한 경기 중에서 6 미만의 점수를 기록한 이닝 ID를 찾아주세요.\n-- 출력 (match_id, innings_no, over_id). 참고: 이닝에서 기록된 점수에는 추가 점수도 포함됩니다.\n\n-- 해결 방법 7:\n\nselect b.match_id, b.innings_no, b.over_id\nfrom ball_by_ball as b\njoin match as m on m.match_id = b.match_id\nwhere win_type = 'wickets'\ngroup by b.match_id, b.innings_no, b.over_id\nhaving sum(b.runs_scored) + sum(extra_runs) < 6\n```\n\n![이미지](/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_7.png)\n\nQ 8: 2013 시즌에서 가장 많은 홈런을 친 상위 5명의 타자 나열하기?\n출력 (player_name).\n\n해결 방법: ball_by_ball 테이블을 match 테이블과 연결하여 시즌 연도를 얻고, player 테이블과 연결하여 선수명을 얻습니다. 2013년에 홈런을 세어 상위 5명을 제한하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- 질문 8:\n-- 2013 시즌에서 가장 많은 홈런을 친 상위 5명의 타자를 나열하십시오.\n-- 알파벳순으로 동점이 발생했을 경우를 고려하십시오. 결과 (선수 이름).\n\n-- 해결책 8:\nselect p.player_name from ball_by_ball as b, match as m, player as p\nwhere (b.match_id = m.match_id and b.striker = p.player_id)\nand (m.season_year = 2013 and b.runs_scored = 6)\ngroup by b.striker, p.player_name order by count(runs_scored) desc limit 5\n```\n\n![2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_8.png](/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_8.png)\n\nQ 9: 2013 시즌에서 가장 낮은 스트라이크 비율(평균 당 탈아웃당한 볼의 수)으로 상위 5명의 볼러를 나열하십시오. 알파벳순으로 동점이 발생했을 경우를 고려하십시오. 결과 (선수 이름).\n\n해결책: 우선 2013년에 각 선수가 얼마나 많은 아웃을 기록했는지를 계산하십시오. 'NULL', 'retired hurt', 'run out'과 같은 out_type은 볼러로 카운트되지 않습니다. 그래서 데이터 분석가는 데이터 세트에 대한 도메인 지식을 어느 정도 알고 있는 것이 중요합니다. 그런 다음 각 볼러가 한 공을 던진 횟수를 계산하십시오. 마지막으로 평균 비율을 구하고, 비율이 높을수록 볼러로서의 스트라이크 비율이 낮습니다.\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- 질문 9: 2013 시즌에서 볼링 스트라이크율(얻은 퍼스트볼당 볼이 던져진 평균 수)이 가장 낮은 5명의 볼러를 나열하십시오. 알파벳순으로 동률 발생 시 이름순으로 정렬하십시오. 결과값은 (선수 이름)으로 출력합니다.\n\n-- 해결책 9:\nwith wicket as\n(\n select b.bowler, p.player_name, count(out_type) as no_of_wicket\n from ball_by_ball as b, player as p, match as m\n where (b.bowler = p.player_id and b.match_id = m.match_id)\n and (b.out_type not in ('NULL', 'retired hurt', 'run out')\n and m.season_year = 2013)\n group by b.bowler, p.player_name\n),\nballs as\n(\n select b.bowler, p.player_name, count(ball_id) as no_of_ball\n from ball_by_ball as b, player as p, match as m\n where (b.bowler = p.player_id and b.match_id = m.match_id)\n and m.season_year = 2013\n group by b.bowler, p.player_name\n\n)\nselect b.player_name, b.no_of_ball/w.no_of_wicket as ratio from wicket as w, balls as b\nwhere w.bowler = b.bowler\norder by ratio desc , b.player_name limit 5;\n```\n\n![이미지](/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_9.png)\n\nQ 10: 각 나라(적어도 한 명의 선수가 아웃 처리됨)별로 어떤 경기에서 볼 아웃된 선수의 수를 찾아내십시오? 결과값은 (나라 이름, 수)으로 출력합니다. 여기서 나라는 선수의 속한 국적입니다.\n\n해결책: 볼링 백볼 테이블을 선수 테이블과 조인하여 국가 이름을 얻고, out_type = \"볼드\"로 필터링합니다. 적어도 한 명의 선수가 있는 각 나라별로 볼드 아웃된 선수의 수를 그룹화하여 계산합니다.\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- 질문 10:\n-- 적어도 한 명의 선수가 볼을 던진 나라마다\n-- 임의의 경기에서 볼 처리를 받은 플레이어의 수를 찾으세요.\n-- 출력 (country_name, count). 여기서 나라는 선수의 국적입니다.\n\n-- 해결 방법:\nselect p.country_name, count(striker) no_of_bowled_out\nfrom ball_by_ball as b, player as p\nwhere p.player_id = b.striker and b.out_type = 'bowled'\ngroup by p.country_name having count(striker) > 0 order by no_of_bowled_out desc\n```\n\n![이미지](/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_10.png)\n\nQ 11: ‘푸네’에서 진행된 임의의 경기에서 적어도 백을 득점한 오른손 타자의 이름을 나열해주세요? 출력 (player_name, run).\n\n해결 방법:\n\n<div class=\"content-ad\"></div>\n\n```sql\n-- 질문 11:\n-- 'Pune'에서 플레이된 모든 경기 중에서 적어도 한 번 센추리를 기록한 우포수 선수들의 이름을 나열하십시오. player_name을 알파벳순으로 출력하십시오.\n\n-- 해결책:\nselect p.player_name, sum(runs_scored) as run\nfrom ball_by_ball as b, match as m, venue as v, player as p\nwhere (b.match_id = m.match_id and m.venue_id = v.venue_id\n    and p.player_id = b.striker and v.city_name = 'Pune'\n    and p.batting_hand = 'Right-hand bat')\ngroup by b.striker, p.player_name having sum(runs_scored)>=100\norder by run desc, p.player_name;\n```\n\n![이미지](/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_11.png)\n\n보너스 질문:\n자체 해결해보기-\n적어도 한 번의 경기를 이겨온 모든 팀에 대한 승률을 찾으십시오(모든 시즌에 걸쳐). 팀 이름으로 알파벳순으로 결과를 정렬하십시오. 출력 (team_name, win_percentage).\n팀의 승률은 = (팀이 이긴 경기수 / 팀이 플레이한 총 경기수) \\* 100로 계산될 수 있습니다.\n참고: 소수점 셋째 자리까지 백분율로 계산하십시오.\n\n# 결론:\n\n<div class=\"content-ad\"></div>\n\n간단히 말씀드리자면, SQL을 사용하여 IPL 통계에 뛰어들어 본 것은 정말 즐거운 경험이었어요! 선수, 팀 및 경기에 관한 멋진 통찰력을 발견하여 트렌드와 우수한 성적을 눈에 띄게하기 쉬웠습니다.\n\n저의 Github 저장소를 참조하여 SQL 쿼리, 질문 및 데이터셋을 이용할 수 있습니다.\n\n도움이 되었기를 바라며 다시 한번 감사합니다.\n","ogImage":{"url":"/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_0.png"},"coverImage":"/assets/img/2024-06-23-In-DepthAdvanceSQLQueriesforIPLStatistics_0.png","tag":["Tech"],"readingTime":18}],"page":"19","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}