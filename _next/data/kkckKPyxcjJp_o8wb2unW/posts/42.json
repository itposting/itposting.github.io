{"pageProps":{"posts":[{"title":"Swift 6 시대의 새벽 무엇이 달라졌을까","description":"","date":"2024-06-22 16:18","slug":"2024-06-22-TheDawnoftheSwift6Era","content":"\n\n![image](/assets/img/2024-06-22-TheDawnoftheSwift6Era_0.png)\n\n1. 소개\n최근 Apple WorldWide Developers Conference(WWDC)에서, 많이 기대되었던 Apple Intelligence 발표에 이어 Apple이 공식적으로 Swift 6.0을 발표했습니다.\n\n2. Swift 개발의 10년\n\n2014년 데뷔 이후, Swift는 놀라운 진전을 이루며 10년을 건너왔습니다. 처음 논란을 빚었지만 현재 인기 있는 프로그래밍 언어 중 하나로 발전한 Swift의 개발 속도는 놀라운 속도로 진행되고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 2015년: Apple이 Swift를 오픈 소스로 공개하고 개발 속도를 가속화했습니다.\n- 2016년: Swift 3 및 Swift Package Manager가 출시되었습니다.\n- 2017년: Swift 4가 출시되었으며 더 큰 견고함과 안정성을 제공했씁니다.\n- 2018년: Swift 4.2가 일반화에서 중요한 발전을 이루었습니다.\n- 2019년: Swift 5.0이 출시되었고, 응용 프로그램 이진 인터페이스(ABI)의 안정한 버전을 도입했습니다.\n- 2020년: Swift 5.3이 출시되었으며, 공식 플랫폼 지원 확장 기능을 Windows 및 기타 Linux 배포판을 포함하여 제공했습니다.\n- 2021년: Swift 5.5가 표준 라이브러리에 Concurrency를 추가했습니다.\n- 2022년: Swift가 분산 액터 기능을 도입했습니다.\n- 2023년: Swift 5.9가 출시되어 C++ 상호 운용성 기능을 지원했습니다.\n\n2.1. 2024년 Swift 6의 새로운 변경 사항\n\nSwift 6에는 다양한 새로운 변경 사항이 포함되어 있습니다. Swift 6의 주요 변경 사항은 다음과 같습니다:\n\n2.1.1 Concurrency Support\n\n<div class=\"content-ad\"></div>\n\nSwift 6는 새로운 기능과 개선사항을 도입하여 동시성 프로그래밍을 더 간단하고 안전하게 만들었습니다. 이러한 변경 사항은 다음과 같습니다:\n\n- 기본값으로 허용된 전체 동시성 확인: 많은 잘못된 양의 레이스 경고를 제거하여 코드 품질을 향상시킵니다.\n- Sendable 개념: 어떤 유형이 동시 환경에서 안전하게 전달될 수 있는지 명확히하며, 동시성 프로그래밍의 어려움을 줄입니다.\n- async/await 메커니즘 및 actor: 비동기 프로그래밍을 지원하여 동시성 프로그래밍을 보다 직관적이고 효율적으로 만듭니다.\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_1.png)\n\n2.1.2. Typed Throws\n\n<div class=\"content-ad\"></div>\n\nSwift 6에서는 typed throws를 도입하여 개발자가 함수가 던질 수 있는 오류의 종류를 더 명시적으로 지정할 수 있게 되었습니다. 이는 코드의 가독성과 탄탄함을 향상시키며 잠재적인 오류를 줄입니다.\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_2.png)\n\n2.1.3. 제네릭 제약조건에 대한 새로운 구문\n\nSwift 6.0에서는 제네릭 제약조건에 대한 새로운 구문을 소개하며, `where` 키워드를 사용하여 제네릭 매개변수가 충족해야 하는 조건을 지정할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image 1](/assets/img/2024-06-22-TheDawnoftheSwift6Era_3.png)\n\n2.1.4. Property Wrappers\n\nSwift 6.0 introduces property wrappers, allowing developers to encapsulate the storage and access logic of properties, enhancing code modularity and reusability.\n\n![Image 2](/assets/img/2024-06-22-TheDawnoftheSwift6Era_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n2.1.5. 기능 빌더\n\nSwift 6.0에서는 기능 빌더를 소개하여 개발자들이 식의 파싱 및 변환 프로세스를 사용자 정의할 수 있게 하여 더 복잡한 구문 구조를 생성할 수 있습니다.\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_5.png)\n\n2.1.6. 새로운 SwiftUI 뷰 빌더\n\n<div class=\"content-ad\"></div>\n\nSwift 6.0은 SwiftUI를 위한 새로운 뷰 빌더를 도입하여 개발자들이 더 유연하게 사용자 인터페이스를 만들고 관리할 수 있게 했습니다.\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_6.png)\n\n2.1.7. 기타 중요 변경 사항\n\nSwift 6는 동시성 지원과 타입드 쓰로우에 추가로 다음과 같은 새로운 기능을 도입합니다:\n\n<div class=\"content-ad\"></div>\n\n- Parameter Pack Iteration: Swift 5.9에서 소개된 매개변수 팩에 대해 반복하는 기능으로 코드의 유연성을 향상시킵니다.\n- Non-Copyable Type Upgrades: 전이 중에 비복사 가능한 유형을 빌릴 수 있도록 하여 비복사 가능한 유형의 사용을 간단화합니다.\n- 128비트 정수 유형: Int128 및 UInt128 유형을 소개하여 특정 시나리오 요구 사항을 충족시킵니다.\n\nSwift 6의 출시는 Swift를 위한 새로운 시대의 시작을 알립니다. 강력한 새로운 기능과 크로스 플랫폼 지원을 통해 Swift는 미래에 주류 프로그래밍 언어가 될 전망입니다.\n\n3. 크로스 플랫폼 지원\n\n3.1. 크로스 플랫폼 개발 전략\n\n<div class=\"content-ad\"></div>\n\nSwift의 프로모션은 애플 플랫폼에만 국한되지 않습니다. 애플은 오픈 소스 커뮤니티와 밀접히 협력하여 Swift를 더 많은 플랫폼과 분야로 확장하려고 노력하고 있습니다. 다음과 같은 것들을 포함합니다:\n\n- 우분투, CentOS, Amazon Linux, 레드햇을 포함한 리눅스 플랫폼에서 Swift 지원\n- 윈도우에서의 Swift 지원 개선으로 더 많은 운영 체제에서 Swift 실행 가능\n\n3.2. 개발자 도구와 생태계 개발\n\n- swift-evolution: 변경 제안을 유지하여 Swift의 지속적인 개선을 보장\n- 공식 VS Code 확장 프로그램: 비주얼 스튜디오 코드에서 Swift 지원을 제공하여 개발자가 윈도우와 기타 플랫폼에서 Swift를 사용하기 쉽게 함\n- Swiftly: 명령줄에서 Swift 툴체인을 관리하여 Rust의 rustup과 유사한 경험을 제공\n\n<div class=\"content-ad\"></div>\n\n4. 결론\n\nSwift 6의 출시는 이 프로그래밍 언어의 새로운 시대를 알리는 것뿐만 아니라, Apple의 지속적인 혁신과 프로그래밍 언어 분야에서의 진보도 보여줍니다. Swift 6은 동시성 지원, 타입드 스로우, 일반적인 제약 조건의 새로운 구문, 프로퍼티 래퍼, 함수 빌더, 그리고 새로운 SwiftUI 뷰 빌더 등을 통해 개발자의 프로그래밍 경험과 코드 품질을 크게 향상시켰습니다.\n\n게다가, Swift의 크로스 플랫폼 지원 전략은 어플리케이션 적용 범위를 확장하여, Apple 생태계뿐만 아니라 Linux 및 Windows와 같은 다양한 플랫폼에서도 실행할 수 있도록 합니다. swift-evolution, 공식 VS Code 익스텐션, 그리고 Swiftly 툴체인 관리 도구와 같은 계속 발전하는 개발자 도구 및 생태계 개발과 결합된 이 크로스 플랫폼 기능은 Swift를 미래의 주요 프로그래밍 언어 중 하나로 만들어 줍니다.\n\nSwift 6의 출시를 통해 개발자들에게 더 많은 가능성과 편의를 제공합니다. 강력한 새로운 기능과 광범위한 크로스 플랫폼 지원으로, Swift가 미래 주요 프로그래밍 언어 중 하나로 자리매김할 것으로 기대됩니다. 개발자들은 Swift 6의 도움으로 더 효율적이고 안전하며 혁신적인 애플리케이션을 만들 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n5. Codia AI 제품들\nCodia AI는 다중 모달, 이미지 처리, 개발 및 AI 분야에서 풍부한 경험을 갖고 있어요.\n1. Codia AI Figma to code: HTML, CSS, React, Vue, iOS, Android, Flutter, Tailwind, Web, Native,...\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_7.png)\n\n2. Codia AI DesignGen: 웹사이트, 랜딩 페이지, 블로그를 위한 UI 제작 도구\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_8.png)\n\n<div class=\"content-ad\"></div>\n\n3. Codia AI Design: 스크린샷을 편집 가능한 Figma 디자인으로 변경\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_9.png)\n\n4. Codia AI VectorMagic: 이미지를 풀 컬러 벡터/PNG를 SVG로 변환\n\n![이미지](/assets/img/2024-06-22-TheDawnoftheSwift6Era_10.png)","ogImage":{"url":"/assets/img/2024-06-22-TheDawnoftheSwift6Era_0.png"},"coverImage":"/assets/img/2024-06-22-TheDawnoftheSwift6Era_0.png","tag":["Tech"],"readingTime":5},{"title":"MacOS에서 Docker로 SQL 서버 설정하는 방법  단계별 가이드","description":"","date":"2024-06-22 16:17","slug":"2024-06-22-SettingUpSQLServerwithDockeronMacOSAStep-by-StepGuide","content":"\n\n# 단계 1: Docker와 Azure Data Studio 다운로드하기\n\n먼저 docker.com에서 작업 중인 운영 체제와 프로세서에 적합한 Docker 버전을 다운로드하세요. 추가로 이 링크에서 Azure Data Studio를 얻으세요.\n\n# 단계 2: Docker 계정 만들기\n\nDocker를 시작하고 사용자 계정을 만들어 시작하세요.\n\n<div class=\"content-ad\"></div>\n\n# 단계 3: SQL Server 이미지 다운로드하기\n\n터미널을 열고 다음 명령을 사용하여 SQL Server 이미지를 다운로드하세요:\n\n```js\ndocker pull mcr.microsoft.com/azure-sql-edge\n```\n\n![이미지](/assets/img/2024-06-22-SettingUpSQLServerwithDockeronMacOSAStep-by-StepGuide_0.png)\n\n<div class=\"content-ad\"></div>\n\n다운로드가 완료되면 확인 메시지가 나타납니다.\n\n# 단계 4: SQL Server 컨테이너 실행\n\n다음 명령어를 사용하여 SQL Server 컨테이너를 시작하세요:\n\n```js\ndocker run -e \"ACCEPT_EULA=1\" -e \"MSSQL_SA_PASSWORD=reallyStrongPwd123\" -e \"MSSQL_PID=Developer\" -e \"MSSQL_USER=SA\" -p 1433:1433 -d --name=sql mcr.microsoft.com/azure-sql-edge\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-SettingUpSQLServerwithDockeronMacOSAStep-by-StepGuide_1.png)\n\n실행 중인 컨테이너를 확인하려면:\n\n```bash\ndocker container ls\n```\n\n이미지 섹션에는 생성된 컨테이너가 표시됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n# 단계 5: Azure Data Studio와 연결하기\n\nAzure Data Studio를 열고 \"Create a Connection\" 옵션을 사용하여 다음 세부 사항을 입력하세요:\n\n- 서버: localhost\n- 사용자 이름: SA\n- 암호: reallyStrongPwd123\n\n\"Remember Password\" 옵션을 확인하고 \"Connect\"를 클릭하세요. 연결 확인은 왼쪽 상단에 나타날 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 단계 6: 컨테이너 중지\n\n컨테이너를 중지하려면 다음 명령을 실행하세요:\n\n```js\ndocker container stop container_id\n```\n이제 SQL Server가 Docker에서 가동 중이며, Azure Data Studio를 사용하여 연결을 설정할 수 있습니다. 이 지침을 따라 개발 또는 테스트 환경을 빠르게 구축하고 관리할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-22-SettingUpSQLServerwithDockeronMacOSAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-06-22-SettingUpSQLServerwithDockeronMacOSAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":2},{"title":"ChatGPT MacOS 앱 PDF 문서 분석하는 방법 가이드","description":"","date":"2024-06-22 16:16","slug":"2024-06-22-ChatGPTMacOSAppGuidetoAnalysingPDFDocuments","content":"\n\n\n![ChatGPT MacOS App Guide](/assets/img/2024-06-22-ChatGPTMacOSAppGuidetoAnalysingPDFDocuments_0.png)\n\n만약 맥 사용자이자 ChatGPT의 팬이라면 기쁜 소식이 있습니다. OpenAI가 MacOS용 ChatGPT 앱을 출시했으며, 이를 통해 컴퓨터에서 AI의 능력을 활용하는 것이 더욱 쉬워졌습니다. 이 앱은 무료 및 유료 사용자 모두에게 제공되며, 여기에서는 특히 PDF 문서를 분석하는 방법에 대해 다운로드, 설치 및 사용 방법을 안내해 드리겠습니다.\n\n# ChatGPT MacOS 앱 시작하기\n\n우선, 시스템이 요구 사항을 충족하는지 확인하십시오. MacOS 14 이상과 Apple 실리콘 칩(M1 이상)이 필요합니다. OpenAI 웹사이트로 이동하여 앱을 다운로드하고, 설치 프로세스는 기타 MacOS 응용 프로그램과 마찬가지로 간단합니다.\n\n\n<div class=\"content-ad\"></div>\n\n# 인터페이스 탐색\n\n설치가 완료되면 앱을 열어 사용하기 편리한 인터페이스를 찾을 수 있습니다. ChatGPT 모델을 선택하고 플러스 구독을 등록했다면 플러그인을 통합할 수도 있습니다. 앱에는 음성 명령을 사용하여 ChatGPT와 상호 작용할 수 있도록 마이크 버튼이 포함되어 있습니다.\n\n# PDF 문서 업로드 및 분석\n\nChatGPT MacOS 앱의 한 가지 뛰어난 기능은 PDF 문서를 업로드하고 분석할 수 있는 기능입니다. 아래는 단계별 안내서입니다:\n\n<div class=\"content-ad\"></div>\n\n1. 문서 업로드하기: PDF 문서를 앱으로 끌어 놓기만 하면 됩니다. 이 기능은 학술 및 비학술 목적에 모두 유용한 다양한 문서를 다룰 수 있어요.\n\n2. 문서 분석하기: 업로드 후에 ChatGPT에 요약과 주요 통찰을 제공하도록 요청할 수 있어요. 예를 들어, 저는 제 연구 논문을 업로드하고 요약을 요청했습니다. ChatGPT는 본문의 핵심 포인트와 통찰을 강조한 간결하고 정확한 개요를 제공해 주었어요.\n\n# 전체 튜토리얼 보기\n\n# 실용적인 용도\n\n<div class=\"content-ad\"></div>\n\n학술 논문 이상으로 다양한 목적으로이 기능을 활용할 수 있습니다. 예를 들어, 식물 사진을 찍어 ChatGPT에게 식물을 식별하고 관리 지침을 제공하도록 요청할 수 있습니다. 이러한 넓은 기능은 이 앱을 일상 업무에 매우 유용하게 만듭니다.\n\n# 마무리의 말\n\nChatGPT MacOS 앱은 ChatGPT의 기능을 직접 컴퓨터로 가져오는 강력한 도구입니다. 학술 논문을 분석하거나 일상적인 질문에 빠른 답변을 찾고 싶을 때 이 앱이 도와줄 것입니다. OpenAI가 계속해서 더 많은 기능을 개발하고 추가함에 따라 잠재적인 사용 영역은 계속 확장될 것입니다.\n\n3시간 웨비나로 학술 성공을 위한 Pro AI 도구 배우기 (참가자들이 사랑하는 웨비나):\n\n<div class=\"content-ad\"></div>\n\nhttps://offers.lennartnacke.com/ai-academics-webinar-recording\n\n프로페서 레나트 낙케와 함께 다양한 전략, 전술, 프롬프트 샘플 및 AI 도구의 명확한 사용 사례와 함께 라이브 데모를 다루었습니다.\n\nChatGPT MacOS 앱을 시도해 보셨나요? 댓글에서 사용 경험을 공유해 주세요. 이 기사에 박수를 보내고 최신 기술 도구에 대한 통찰력과 업데이트를 더 받으려면 구독하세요.\n\n읽어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-22-ChatGPTMacOSAppGuidetoAnalysingPDFDocuments_0.png"},"coverImage":"/assets/img/2024-06-22-ChatGPTMacOSAppGuidetoAnalysingPDFDocuments_0.png","tag":["Tech"],"readingTime":2},{"title":"Stable Diffusion 설치 및 실행 방법 MacOS용","description":"","date":"2024-06-22 16:15","slug":"2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS","content":"\n\n안녕하세요, 독자 여러분! 저는 AI 및 LLM(언어 모델) 기술의 흥미로운 세계를 안내해 드리는 탈립입니다. 이것은 흥미진진한 여정이며, 제가 여러분과 제 경험과 발견을 공유할 수 있어 정말 기쁩니다.\n\n# 목차\n\n- Stable Diffusion이란 무엇인가요?\n- 맥에 Stable Diffusion 웹 UI 설치하기\n- 맥에서 Stable Diffusion 웹 UI 실행하기\n- 맥에서 Stable Diffusion 웹 UI 종료하기\n- 맥에서 Stable Diffusion 웹 UI 업데이트하기\n\n# Stable Diffusion이란 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n안정적인 확산은 Stability AI에서 2022년에 출시된 텍스트-이미지 확산 모델입니다. 이 모델은 이미지에 점진적으로 잡음을 추가하여 완전히 무작위로 만들어지는 확산 과정에 기반을 두고 있습니다. 안정적인 확산은 반대 방향으로 작동하여, 잡음이 많이 섞인 이미지에서 시작하여 점진적으로 잡음을 제거하여 선명한 이미지를 생성합니다.\n\n이 모델은 텍스트와 이미지의 대량 데이터셋으로 훈련되어 있어 텍스트 설명으로 실제적이고 고품질의 이미지를 생성할 수 있습니다. 안정적인 확산은 매우 다재다능하며, 사실적인, 예술적인 및 추상적인 이미지 스타일 등 다양한 이미지 스타일을 생성하는 데 사용할 수 있습니다.\n\n![이미지](/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_0.png)\n\n# 맥에서 안정적인 확산 웹 UI 설치\n\n<div class=\"content-ad\"></div>\n\n## 단계 1 — Homebrew 설치하기\n\n- 먼저 터미널 애플리케이션을 열어주세요. 이 앱은 Applications 디렉토리 내의 Utilities 하위폴더에 있습니다. 또는 Spotlight 검색을 이용하여 Command + Space를 눌러 \"터미널\"을 입력해도 됩니다.\n- 터미널을 열었으면, 다음 명령어를 붙여넣어 실행합니다. 이 명령어는 Homebrew 설치 스크립트를 다운로드하고 실행합니다.\n\n```js\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```\n\n- 스크립트는 설치를 계속할지 여부를 묻고, Homebrew를 설치하려면 관리자 권한이 필요하므로 비밀번호를 요청합니다. 비밀번호를 입력하고 (입력할 때는 보이지 않습니다) Enter 키를 누릅니다. 설치 과정은 몇 분 정도 소요되며 필요한 파일과 종속성을 다운로드하고 설치합니다.\n- 설치가 완료되면, Homebrew가 성공적으로 설치되었다는 메시지가 표시됩니다.\n- 터미널에서 어느 디렉토리에서든 Homebrew 명령어를 인식하고 사용할 수 있도록 하려면, PATH 환경 변수를 조정해야 합니다. 프롬프트에서 제공된 명령어를 복사하여 붙여넣고 Enter 키를 눌러 환경 변수를 설정할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_1.png\" />\n\n## 단계 2 — Homebrew를 사용하여 필요한 애플리케이션 설치하기\n\n터미널 앱에서 다음 명령어를 실행하세요:\n\n```js\nbrew install cmake protobuf rust python@3.10 git wget\n```\n\n<div class=\"content-ad\"></div>\n\n홈브루가 Mac에 다운로드하고 설치할 패키지 목록입니다:\n\n- CMake: CMake은 오픈 소스이며 크로스 플랫폼 빌드 시스템입니다. 이를 통해 소프트웨어 프로젝트의 빌드 프로세스를 관리하는 것이 간편화되며, 플랫폼 독립적인 방법으로 소프트웨어를 구성, 빌드 및 테스트할 수 있습니다.\n- Protocol Buffers (protobuf): Protocol Buffers는 Google에서 개발한 언어에 상관없는 직렬화 포맷입니다. 간단한 언어를 사용하여 데이터 구조를 정의한 다음 다양한 프로그래밍 언어의 코드를 생성할 수 있습니다. 생성된 코드를 통해 효율적으로 직렬화, 역직렬화 및 데이터 조작을 수행할 수 있습니다.\n- Rust: Rust는 메모리 안정성, 동시성 및 성능에 중점을 둔 시스템 프로그래밍 언어로 유명합니다. 운영 체제, 장치 드라이버 및 임베디드 시스템을 포함한 저수준 소프트웨어를 개발하는 신뢰할 수 있고 효율적인 방법을 제공합니다.\n- Python@3.10: 이 패키지는 Homebrew를 사용하여 Python 버전 3.10을 설치합니다. Python은 간결함과 다재다능성으로 유명한 인기 있는 프로그래밍 언어입니다. 이 경우의 특정 버전 번호인 3.10은 시간이 지남에 따라 변경될 수 있으며 필요에 따라 다른 버전으로 대체할 수 있습니다.\n- Git: Git은 다수의 개발자가 프로젝트에서 동시에 작업하고 코드의 다른 버전을 관리하며 변경 사항을 원활하게 병합할 수 있도록 돕는 널리 사용되는 버전 관리 시스템입니다.\n- Wget: Wget은 웹에서 파일을 다운로드하는 명령 줄 유틸리티입니다. HTTP, HTTPS 및 FTP를 포함한 다양한 프로토콜을 지원하며 재귀적 다운로드, 중단된 다운로드 재개, 백그라운드 파일 검색 등의 기능을 제공합니다.\n\n## 단계 3 - 안정적인 확산 웹 UI 설치\n\nMac에서 GitHub 저장소 AUTOMATIC1111/stable-diffusion-webui에서 \"Stable Diffusion Web UI\"를 설치하려면 다음 단계를 따라주십시오:\n\n<div class=\"content-ad\"></div>\n\n1. 맥에서 터미널 애플리케이션을 엽니다.\n\n2. 리포지토리를 복제할 디렉토리를 선택하려면 cd 명령을 사용하세요. 예를 들어, 리포지토리를 \"문서\" 폴더에 복제하려는 경우 다음 명령을 실행하십시오:\n\n```js\ncd Documents\n```\n\n3. 이 명령을 실행하면 \"문서\" 디렉토리로 이동합니다. 그러나 리포지토리를 복제할 다른 디렉토리로 경로를 대체할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n```\n\nGit이 복제 작업을 시작하여 저장소를 가져와 현재 디렉토리에 저장할 것입니다.\n\n4. 터미널에서 프로세스를 확인할 수 있습니다. 복제가 완료되면 Mac에 \"Stable Diffusion Web UI\" 저장소의 로컬 복제본이 생성됩니다.\n\n축하합니다! 이제 Mac에 \"stable-diffusion-webui\" 저장소를 복제하였습니다. 내용을 살펴보려면 `cd` 명령을 사용하여 복제된 저장소로 이동하여 필요한 파일 및 폴더에 액세스할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 모델 다운로드\n\n- 링크를 클릭하여 안정적인 확산 모델 버전 1.5를 다운로드하세요.\n- 다운로드한 파일을 클론한 GitHub 저장소의 다음 폴더에 넣어주세요.\n\n```js\nstable-diffusion-webui/models/Stable-diffusion\n```\n\n잘 했어요! 이제 Mac에 Stable Diffusion Web UI를 성공적으로 설치하였으며 이미지 생성을 시작할 준비가 되었습니다.\n\n<div class=\"content-ad\"></div>\n\n# Mac에서 Stable Diffusion Web UI 실행하기\n\n- Mac에서 터미널 애플리케이션을 엽니다.\n- 복제한 저장소가 있는 디렉토리에 액세스하려면 현재 디렉토리를 변경하려면 `cd` 명령을 사용합니다. 예를 들어, \"stable-diffusion-webui\" 폴더로 이동하려면 아래 명령을 실행하세요:\n\n```bash\ncd stable-diffusion-webui\n```\n\n3. 원하는 디렉토리에 들어간 후에는 다음 명령을 실행하여 Stable Diffusion Web UI를 시작합니다:\n\n<div class=\"content-ad\"></div>\n\n```sh\n./webui.sh\n```\n\n이 명령은 안정적인 확산을 웹 브라우저에서 실행할 수 있는 Python 가상 환경을 설정합니다. 이 가상 환경에 직접 액세스할 수 있는 링크가 터미널 앱에서 제공됩니다.\n\n4. 터미널 앱에서 제공된 URL을 복사하여 웹 브라우저에 붙여넣기합니다. Python은 항상 동일한 URL을 생성하므로 이를 즐겨찾기로 저장할 수 있습니다. 그러나 이 가상 환경이 활성화된 경우에만 기능합니다.\n\n![이미지](/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_2.png)\n\n\n<div class=\"content-ad\"></div>\n\n# 맥에서 Stable Diffusion Web UI 종료\n\nStable Diffusion Web UI를 사용 중인 가상 환경은 단순히 브라우저 창을 닫는 것으로는 종료되지 않습니다. 이를 올바르게 종료하려면 다음 단계를 따라주십시오:\n\n- 맥에서 여전히 열려 있는 터미널 애플리케이션으로 돌아갑니다.\n- 키보드에서 CONTROL + C를 동시에 누릅니다. 이 동작은 가상 환경 세션을 중단시켜 종료할 것입니다.\n\n# 맥에서 Stable Diffusion Web UI 업데이트하기\n\n<div class=\"content-ad\"></div>\n\nMac에서 Stable Diffusion 웹 UI를 업데이트하려면 GitHub 저장소 AUTOMATIC1111/stable-diffusion-webui에서 최신 변경 사항을 가져오는 다음 단계를 따르세요:\n\n1. Mac에서 Terminal 애플리케이션을 엽니다.\n\n2. 원래 복제된 저장소가 있는 디렉토리로 이동합니다. `cd` 명령을 사용하여 디렉토리를 변경할 수 있습니다. 예를 들어 \"stable-diffusion-webui\" 폴더로 이동하려면 다음 명령을 사용하세요:\n\n```sh\ncd stable-diffusion-webui\n```\n\n<div class=\"content-ad\"></div>\n\n진행하기 전에 올바른 디렉토리에 있는지 확인해주세요.\n\n3. 원하는 디렉토리에 들어간 후 (이 경우 \"stable-diffusion-webui\"), 다음 명령을 실행하여 최신 변경 사항이 반영된 Stable Diffusion Web UI를 GitHub 저장소에서 업데이트하세요:\n\n```js\ngit pull\n```\n\n이 명령은 Stable Diffusion Web UI의 로컬 사본에 가장 최근 업데이트를 가져와 적용합니다.\n\n<div class=\"content-ad\"></div>\n\n이제 맥에서 Stable Diffusion Web UI를 성공적으로 업데이트했습니다. 로컬 사본이 GitHub 리포지토리의 최신 변경 사항과 동기화됩니다.\n\n블로그를 마무리하며, 다음에 어떤 주제를 탐구하고 싶은지 알고 싶습니다. 여러분의 의견은 중요하니 댓글로 의견을 자유롭게 공유해 주세요. 함께해 주셔서 감사합니다. 호기심을 유지하세요!\n\n즐겁게 보내세요!!\n\nLinkedIn에서 연락해요.\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_3.png\" />\n\n<img src=\"/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_4.png\" />\n\n이 이야기는 Generative AI에서 발행되었습니다. 최신 AI 이야기에 대해 알아가기 위해 LinkedIn에서 저희와 연락을 유지하고 Zeniteq를 팔로우해 주세요.\n\n최신 뉴스 및 Generative AI 업데이트를 받으려면 뉴스레터를 구독해 주세요. 함께 AI의 미래를 함께 만들어 가요!\n\n\n<div class=\"content-ad\"></div>\n\n\n![HowtoInstallandRunStableDiffusiononyourMacOS_5.png](/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_5.png)\n","ogImage":{"url":"/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_0.png"},"coverImage":"/assets/img/2024-06-22-HowtoInstallandRunStableDiffusiononyourMacOS_0.png","tag":["Tech"],"readingTime":7},{"title":"리눅스에서 LVM 사용하여 논리 볼륨 생성 및 확장하는 방법","description":"","date":"2024-06-22 16:12","slug":"2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume","content":"\n\n## XFS 파일 시스템에 LVM 논리 볼륨을 생성하고 확장하는 방법 안내서\n\n![image](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_0.png)\n\n## LVM에 대해 간단히 알아봅시다\n\n논리 볼륨 관리자는 기존의 디스크 관리보다 훨씬 더 효율적인 방식으로 저장소를 다룹니다. 표준 디스크 파티션은 각 디스크의 용량에 기반하여 저장 공간을 할당하지만 LVM은 사용 가능한 모든 물리 하드 드라이브를 하나의 풀의 일부인 것처럼 결합하여 저장 공간을 효율적으로 관리하며 개별적으로 다루는 대신 전체로 사용할 수 있게 만듭니다.\n\n<div class=\"content-ad\"></div>\n\n가정 해 보겠습니다. 4개의 1TB 드라이브가 있습니다. 전통적인 디스크 체계에서는 개별적으로 처리하지만 LVM을 사용하면 이 4개의 1TB 드라이브가 4TB 단일 청크 또는 집계된 저장 용량으로 간주됩니다. 이를 통해 디스크 레이아웃에 대한 더 큰 유연성과 제어권을 얻을 수 있으며 디스크를 더 쉽게 조작할 수 있습니다. LVM을 사용하는 주요 이점 중 하나는 파일 시스템을 쉽게 확장할 수 있는 능력입니다.\n\nLVM을 이해하고 사용하기 위해서 우리는 세 가지 주요 구성 요소를 이해해야 합니다. 이들은 서로 연결되어 있으며 함께 하나의 논리적 볼륨이라는 것을 만듭니다. 이러한 구성 요소는 다음과 같습니다:\n\n- 물리적 볼륨\n- 볼륨 그룹\n- 논리적 볼륨\n\n물리적 볼륨: 이들은 LVM을 만들기 위해 사용되는 기본 블록입니다. 물리적 볼륨 또는 \"PVs\"는 단순히 물리적 저장 장치인 SSD 또는 HDD 드라이브입니다. 하드 드라이브가 물리적 볼륨로 간주되려면 물리적 볼륨로 초기화되어야 하므로 LVM에서 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nVolume Group: 우리는 볼륨 그룹 \"VG\"를 물리적 볼륨으로 구성된 풀로 생각할 수 있습니다. 예를 들어, 1TB SSD 하드 드라이브 세 개가 볼륨 그룹의 일부인 경우, 이 \"VG\"는 총 저장 용량이 3TB로 나타나며, 논리적 볼륨을 생성하는 데 사용됩니다.\n\n논리적 볼륨: 우리의 VG가 생성되면, 마침내 논리적 볼륨을 생성할 수 있습니다. 단일 볼륨 그룹에서 하나 이상의 논리적 볼륨을 생성할 수 있습니다. 논리적 볼륨은 디렉터리에 마운트된 기존 파티션으로 처리되고 사용될 것입니다.\n\n아래 그림은 논리적 볼륨의 구조를 설명합니다:\n\n![논리적 볼륨 구조](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_1.png)\n\n<div class=\"content-ad\"></div>\n\n(특정 예시에서 우리가 사용하는 데모 서버가 구성된대로, 여러 논리 볼륨 및 볼륨 그룹이 있습니다.)\n\n물리 장치인 하드 드라이브로부터 시작해요, 이들은 물리 볼륨 또는 PVs를 만드는 데 사용됩니다. 이 예에서, 우리는 세 개의 별도 HDD가 있으며, 각각은 하나의 물리 볼륨을 만드는 데 사용됩니다. 파티션 /dev/sda2는 첫 번째 PV를 만들고, /dev/sdb1은 두 번째이며 sdc1은 세 번째입니다.\n\n이어서 두 개의 별도 볼륨 그룹이 있고, 각각에는 개별적인 논리 볼륨이 있습니다. 언급한 대로, LVs는 볼륨 그룹에서 잘려 나온 것입니다. 한 VG에서 하나 이상의 논리 볼륨이 올 수 있습니다.\n\n이 추상화에서 최종 계층은 논리 볼륨입니다. 예를 들어, vg-data 볼륨 그룹에서 나온 lv-data가 있습니다. lv-data가 준비되면 포맷하여 마운트 지점으로 사용할 수 있습니다. 이 경우: /dev/vg-data/lv-data.\n\n<div class=\"content-ad\"></div>\n\n## LVM 논리 볼륨 만드는 방법:\n\n기존 논리 볼륨을 확장/확장하는 것에 대한 내용을 살펴보기 전에, 이전에 설정되지 않은 시스템에서 처음부터 하나를 만드는 방법을 살펴보고, 그 다음 섹션에서 확장하는 방법을 살펴보겠습니다. 이미 존재하는 LV를 확장하고 싶다면, 이 섹션을 건너뛰시면 됩니다.\n\n새로운 논리 볼륨을 설정하려면 다음 순서대로 진행해야 합니다:\n\n- 기존 하드 드라이브에서 물리 볼륨을 생성합니다.\n- 볼륨 그룹을 생성하고 물리 볼륨을 추가합니다.\n- 볼륨 그룹에서 논리 볼륨을 생성합니다.\n- 필요에 따라 논리 볼륨을 포맷합니다 — xfs, ext4 등.\n- 마지막으로 새 파일 시스템을 마운트합니다.\n\n<div class=\"content-ad\"></div>\n\n— 물리 볼륨을 생성하려면 디스크 공간을 사용할 수 있어야 합니다. 이 서버(가상 머신)에서는 논리 볼륨 생성 데모에 사용할 두 개의 별도의 원시 하드 드라이브가 있습니다.\n\n![이미지](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_2.png)\n\n/dev/sdb 및 /dev/sdc 두 개의 원시 디스크가 있는 것을 확인할 수 있습니다. 아직 사용할 수 없으므로 이를 포맷해야 합니다.\n\n이 새 디스크 /dev/sdb를 사용할 수 있게 하는 방법을 빠르게 살펴보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*XLof11Om75NHy4PY2-2S2Q.gif)\n\n저희가 한 몇가지에 대해 몇 가지 소식을 전합니다:\n\n- 새로운 드라이브 /dev/sdb를 사용할 수 있도록 새로운 파티션을 생성하고 적절한 레이블을 할당함으로써 진행되고 있습니다.\n- 이 파티션의 특정 크기를 지정하지 않았지만, 기본값을 선택하여 전체 디스크를 사용할 수 있습니다. 크기를 지정하지 않고 엔터를 누르면 사용 가능한 전체 공간이 할당됩니다.\n- 여기서 중요한 부분은 이 새로운 파티션을 레이블링하여 LVM 유형으로 지정하는 “8e” 16진수 코드를 선택하는 것입니다. ext4 파티션을 만들고자 한다면 레이블 코드가 다를 것입니다. 새로운 파티션을 만들 때, 사용하기 전에 레이블링해야 합니다.\n- 우리가 한 변경 사항을 저장하기 위해 “w”를 입력해야 합니다.\n\n이제 디스크가 준비되었으니, pvcreate로 물리적 볼륨을 생성하는 것부터 시작해보겠습니다:\n\n\n<div class=\"content-ad\"></div>\n\n피지컬 볼륨이 성공적으로 생성되었습니다! 이제 pvdisplay를 사용하여 PV가 만들어졌는지 확인해봅시다 (pvs도 사용할 수 있습니다):\n\n\n[itadmin@localhost ~]$ sudo pvdisplay\n[sudo] password for itadmin:\n  --- Physical volume ---\n  PV Name               /dev/sda2\n  VG Name               centos\n  PV Size               <19.00 GiB / not usable 3.00 MiB\n  Allocatable           yes (but full)\n  PE Size               4.00 MiB\n  Total PE              4863\n  Free PE               0\n  Allocated PE          4863\n  PV UUID               sa3xFR-jbDb-SKuS-yQN1-VzzW-bveG-aA0yha\n\"/dev/sdb1\"은 \"<30.00 GiB\"의 새로운 피지컬 볼륨입니다\n  --- NEW Physical volume ---\n  PV Name               /dev/sdb1\n  VG Name\n  PV Size               <30.00 GiB\n  Allocatable           NO\n  PE Size               0\n  Total PE              0\n  Free PE               0\n  Allocated PE          0\n  PV UUID               Q54fqC-Np3X-XUaF-j5vE-Px29-pT9H-JYsDUh\n[itadmin@localhost ~]$\n\n\n이미 /dev/sda2에 PV가 있습니다. 이는 루트 파티션도 논리 볼륨 위에 구축되어 있음을 의미합니다. 새로운 디스크 /dev/sdb1은 이제 피지컬 볼륨입니다. 이 새로운 피지컬 볼륨의 VG 이름이 비어있는 것을 알 수 있습니다! 이는 이제까지 볼륨 그룹에 추가되지 않았기 때문입니다! 이를 바로 해결해봅시다:\n\n<div class=\"content-ad\"></div>\n\n```bash\n[itadmin@localhost ~]$ sudo vgcreate vg-data /dev/sdb1\n  Volume group \"vg-data\" successfully created\n[itadmin@localhost ~]$\n```\n\n- 새 볼륨 그룹을 만들 때 vgcreate를 사용하며, 새 볼륨 그룹에 이름을 할당하고 물리 볼륨 또는 볼륨을 추가합니다. 이 경우에는 /dev/sdb1을 이 VG의 일부로 만듭니다.\n\n새로 만든 볼륨 그룹을 확인해봅시다:\n\n```bash\n[itadmin@localhost ~]$ sudo vgs\n  VG      #PV #LV #SN Attr   VSize   VFree\n  centos    1   2   0 wz--n- <19.00g      0\n  vg-data   1   0   0 wz--n- <30.00g <30.00g\n[itadmin@localhost ~]$\n```\n\n<div class=\"content-ad\"></div>\n\n- vg-data은 실제로 존재하며 30GB의 여유 공간이 있어요 — 이는 이전에 추가한 물리 볼륨(새로운 파티션)의 크기입니다.\n\n이제 lvcreate을 사용하여 논리 볼륨을 생성합니다:\n\n```bash\n[itadmin@localhost ~]$ sudo lvcreate --name lv-data -l 100%FREE vg-data\n논리 볼륨 \"lv-data\"이(가) 생성되었습니다.\n[itadmin@localhost ~]$\n```\n\n- -l : 우리가 볼륨 그룹에서 얼마의 공간을 사용할지를 지정하는 데 사용됩니다. 여기서는 해당 그룹의 100%를 할당합니다. 명령어에 볼륨 그룹 이름을 명시해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n새로운 Logical Volume을 lvdisplay로 확인하고 있어요:\n\n![LV](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_3.png)\n\n우리의 Logical Volume이 성공적으로 생성되었어요!\n\n이제 사용할 수 있도록 이 논리적 볼륨을 포맷해야 해요. 새로운 LV를 포맷하는 방법은 mkfs.xfs 명령을 사용하는 거에요:\n\n<div class=\"content-ad\"></div>\n\n```bash\n[itadmin@localhost ~]$ sudo mkfs.xfs /dev/vg-data/lv-data\n[sudo] itadmin 님의 암호:\nmeta-data=/dev/vg-data/lv-data   isize=512    agcount=4, agsize=1965824 블록\n         =                       sectsz=512   attr=2, projid32bit=1\n         =                       crc=1        finobt=0, sparse=0\ndata     =                       bsize=4096   블록=7863296, imaxpct=25\n         =                       sunit=0      swidth=0 블록\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\nlog      =internal log           bsize=4096   블록=3839, version=2\n         =                       sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none                   extsz=4096   블록=0, rtextents=0\n[itadmin@localhost ~]$\n```\n\n.mkfs는 \"파일 시스템 생성\"을 의미하며, 이를 수행합니다. 이 경우에는 xfs 파일 시스템을 생성하려고 하므로 mkfs.xfs를 사용합니다. xfs 파일 시스템은 여러 측면에서 ext4보다 업그레이드된 것이며 RHEL 서버에서 기본 파일 시스템입니다. 그럼에도 불구하고 상황에 따라 ext4를 사용하는 것이 xfs보다 우위를 가질 수 있습니다.\n\n새로 생성된 논리 볼륨을 마운트하려면 해당 마운트 포인트를 만들고 다음 단계를 수행합니다:\n\n```bash\n[itadmin@localhost ~]$ sudo mkdir /data\n[itadmin@localhost ~]$ sudo mount /dev/vg-data/lv-data /data\n```\n\n<div class=\"content-ad\"></div>\n\n저희는 새 파일 시스템이 마운트될 새로운 디렉토리를 생성했어요. /data 하위에 있는 모든 것들은 이 새 논리 볼륨에 속합니다.\n\n— 부가적인 사항으로 — 새로운 마운트 포인트를 /etc/fstab 파일에 추가해야 부팅 중에도 지속되도록 해야 해요.\n\n새롭게 마운트된 /data 디렉토리를 df 명령어로 살펴봅시다:\n\n![이미지](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_4.png)\n\n<div class=\"content-ad\"></div>\n\n- 파일 시스템이 실제로 XFS인지 확인해야 하기 때문에 df 명령에 \"T\" 스위치가 필요합니다. 이 스위치는 파일 시스템 유형을 보여주는 데 사용됩니다.\n- 우리의 논리 볼륨 lv-data는 모두 준비되어 있고 /data에 마운트되어 있습니다!\n\n작업이 완료되었습니다!\n\n## 논리 볼륨 확장 방법\n\n우리는 처음부터 논리 볼륨을 만드는 방법을 보았지만, 대부분의 경우 이미 존재하는 논리 볼륨의 크기를 늘려야 하므로 더 많은 데이터를 수용할 수 있게 할 필요가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 Markdown 형식으로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_5.png)\n\n- 우리는 Volume Group vg-data에 사용 가능한 빈 공간이 없음을 확인할 수 있습니다. 새 물리 볼륨을 추가해 보겠습니다.\n\n먼저, 이 새 드라이브를 사용할 수 있도록 새 파티션을 만들고 \"LVM\" 레이블을 할당해야 합니다. 이를 위해 아래와 같이 fdisk를 사용하여 수행합니다:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*qB2R3x5Zc2Lt46xIq-bEFQ.gif)\n\n\n<div class=\"content-ad\"></div>\n\n- fdisk를 사용하여 새 파티션을 만들고, 크기를 지정하지 않은 전체 크기를 할당했어요 (값을 지정하지 않고 Enter를 누르면 사용 가능한 크기를 할당합니다).\n- 정확한 라벨을 지정해야 해요, \"LVM 타입\"으로 만들기 위해 필요한 라벨은 8e에요.\n\n디스크가 준비되었고, 이제 물리 볼륨을 생성할 수 있어요:\n\n```js\n[root@localhost ~]$ pvcreate /dev/sdc1\n  Physical volume \"/dev/sdc1\" successfully created.\n[root@localhost ~]$\n```\n\n생성 완료! 이제 vg-data 볼륨 그룹에 추가하려면, vgextend 명령어를 사용해요:\n\n<div class=\"content-ad\"></div>\n\n```bash\n[root@localhost ~]$ vgextend vg-data /dev/sdc1\n  Volume group \"vg-data\" successfully extended\n[root@localhost ~]$\n```\n\nVG가 확장되었습니다! 한 번 더 확인해 봐요:\n\n![이미지](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_6.png)\n\n훌륭해요! 이제 vg-data에 25GB의 여유 공간이 있는 것을 확인할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n지금은 Logical Volume에 뛰어들어 보겠습니다. 지금 상태는 다음과 같습니다:\n\n![Logical Volume Status](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_7.png)\n\n우리는 lvextend 명령어로 lv-data Logical Volume을 확장했습니다:\n\n```js\n[root@localhost ~]$ lvextend -l +100%FREE /dev/vg-data/lv-data\n  Size of logical volume vg-data/lv-data changed from <30.00 GiB (7679 extents) to 54.99 GiB (14078 extents).\n  Logical volume vg-data/lv-data successfully resized.\n[root@localhost ~]$\n```\n\n<div class=\"content-ad\"></div>\n\n- lvextend 명령은 lv-data 논리 볼륨을 확장하며, +100%FREE 옵션은 해당 볼륨을 볼륨 그룹에서 남아있는 모든 가능한 크기로 확장합니다.\n- 만약 우리가 논리 볼륨을 특정 크기로 확장하고 싶었다면, 예를 들어 5GB로 확장하고 싶다면 다음과 같이 진행할 것입니다:\n\n```js\n[root@localhost ~]$ lvextend -L +5G /dev/vg-data/lv-data\n```\n\n이제 우리의 논리 볼륨 상태를 확인해봅시다:\n\n![논리 볼륨 상태](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_8.png)\n\n<div class=\"content-ad\"></div>\n\n출력을 통해 LSize가 실제로 증가했고, 논리 볼륨이 확장되었습니다!\n\n아직 끝나지 않았어요! 마지막 단계는 새로 추가된 저장 용량을 사용할 수 있도록 파일 시스템의 크기를 조정하는 것입니다. 이 작업은 xfs_growfs 명령으로 수행할 수 있어요:\n\n```js\n[root@localhost ~]$ xfs_growfs /dev/vg-data/lv-data\n```\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*yu72eMpz12FUdIOTeL0qgg.gif\" />\n\n<div class=\"content-ad\"></div>\n\n- 데이터 블록이 변경되고 파일 시스템이 확장되었음을 알 수 있습니다.\n- 여기서 언급해야 할 또 다른 훌륭한 점은 파일 시스템을 확장할 때 마운트 포인트인 /data를 해제할 필요가 없었다는 것입니다!\n\ndf -kh 명령의 출력에서 /data 마운트 포인트가 확장되었음을 확인할 수 있습니다. 여기에는 lv-data 논리 볼륨이 마운트된 곳입니다:\n\n![Image](/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_9.png)\n\n모두 완료되었습니다. 논리 볼륨이 성공적으로 확장되었습니다!\n\n<div class=\"content-ad\"></div>\n\n이 글은 Linux에서 논리 볼륨 매니저에 대해 간략히 다룬 내용이었습니다. 논리 볼륨을 생성하고 확장하는 방법에 대해 설명했습니다. 궁금한 점이나 의견, 추가할 내용이 있으면 자유롭게 남겨주세요.\n\n읽어주셔서 감사합니다! 다음 포스트에서 만나요 :)","ogImage":{"url":"/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_0.png"},"coverImage":"/assets/img/2024-06-22-LVMinLinuxCreateandExtendaLogicalVolume_0.png","tag":["Tech"],"readingTime":10},{"title":"자정에 크론 작업을 절대 예약하면 안 되는 이유","description":"","date":"2024-06-22 16:11","slug":"2024-06-22-WhyYouShouldNeverScheduleCronJobsExactlyatMidnight","content":"\n\n제 개발자로서, 제가 직접 체험한 바에 의하면 새벽 정각에(0 0 * * *) cron 작업을 예약하는 것이 일으킬 수 있는 혼란에 대해 알고 있습니다. 왜 그렇게 하는 것이 좋지 않은지, 그리고 보다 효과적으로 cron 작업을 예약하는 방법에 대한 팁을 소개하겠습니다.\n\n![Why You Should Never Schedule Cron Jobs Exactly at Midnight](/assets/img/2024-06-22-WhyYouShouldNeverScheduleCronJobsExactlyatMidnight_0.png)\n\n새벽의 신비\n\n이전 직무 중 하나에서, 우리 팀은 심각한 시스템 업데이트를 밤 12시에 예약했을 때 수수께끼 같은 문제에 직면했습니다. 작업이 무작위로 실패하고 시스템이 크게 느려져 서비스 중단을 야기했습니다. 수없이 많은 디버깅 시간 끝에, 우리는 여러 작업이 밤 12시에 실행되도록 설정되어 있음을 발견했습니다. 동시에 발생한 부하로 리소스 충돌과 예측할 수 없는 동작이 발생하여 근본 원인을 식별하는 데 매우 어려워졌습니다.\n\n<div class=\"content-ad\"></div>\n\n## 배운 교훈\n\n## 크론 작업 예약을 위한 최상의 실천 방법\n\n1. 일정 시간을 무작위로 설정: 작업을 동시에 설정하는 대신 무작위 시간을 사용하여 부하를 분산시킵니다. 이렇게 하면 사용량이 많은 시기를 피할 수 있고 충돌 가능성을 줄일 수 있습니다.\n\n2. 지수 백오프 및 지터 사용: 지수 백오프와 지터를 사용하여 재시도를 구현하면 크론 작업이 능률적으로 수행될 수 있습니다. Marc Brooker의 AWS에서 제공하는 멋진 '지수 백오프와 지터' 아티클을 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-WhyYouShouldNeverScheduleCronJobsExactlyatMidnight_1.png)\n\n3. 라이브러리 활용: 파이썬을 사용한다면, Tenacity 라이브러리를 사용하여 백오프와 지터 지연을 가진 재시도를 고려해보세요. 이는 프로세스를 간단화하고 크론 작업을 더욱 강화할 수 있습니다.\n\n# 주기적인 작업을 더 견고하게 만들기\n\n크론 작업은 작업을 자동화하는 데 좋지만 부적절한 예약은 큰 문제를 일으킬 수 있습니다. 자정 예약을 피하고 이러한 팁을 따른다면 더욱 신뢰성이 높고 효율적인 작업 실행을 보장할 수 있습니다. 기억하세요, 약간의 무작위성은 \"0 0 * * *\"의 함정을 피하는 데 큰 도움이 됩니다.\n","ogImage":{"url":"/assets/img/2024-06-22-WhyYouShouldNeverScheduleCronJobsExactlyatMidnight_0.png"},"coverImage":"/assets/img/2024-06-22-WhyYouShouldNeverScheduleCronJobsExactlyatMidnight_0.png","tag":["Tech"],"readingTime":2},{"title":"안전한 원격 접속 간소화 리눅스 서버 간 패스워드 없는 SSH 연결 가이드","description":"","date":"2024-06-22 16:10","slug":"2024-06-22-StreamliningSecureRemoteAccessAGuidetoPasswordlessSSHConnectionsBetweenLinuxServers","content":"\n\n---markdown\n![SSH Connection](/assets/img/2024-06-22-StreamliningSecureRemoteAccessAGuidetoPasswordlessSSHConnectionsBetweenLinuxServers_0.png)\n\n두 대의 Linux 서버 간에 비밀번호 없는 SSH 연결을 설정하는 것은 안전한 원격 액세스를 간편하게하는 일반적인 방법입니다. 본 자습서는 비밀번호 없는 SSH 인증을 설정하는 단계를 안내하며, 연결이 예상대로 작동하지 않을 경우 해결 방법을 제공합니다.\n\n# 전제 조건\n\n- 두 대의 Linux 서버 (서버 A 및 서버 B)\n- 두 서버 모두에 대한 관리 액세스\n---\n\n<div class=\"content-ad\"></div>\n\n# 단계 1: 서버 A에서 SSH 키 쌍 생성하기\n\n- SSH 또는 물리적으로 서버 A에 로그인합니다.\n- 터미널 창을 엽니다.\n- 다음 명령을 실행하여 SSH 키 쌍을 생성합니다:\n\n```js\nssh-keygen -t rsa\n```\n\n키 쌍의 기본 위치를 사용하려면 Enter를 누르시고, 인증을 위해 암호를 비워둘 경우 비밀번호 없는 인증을 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n4. Enter 키를 눌러 키 생성을 확인해주세요.\n\n5. 이 작업은 ~/.ssh/ 디렉토리에 개인 키 (id_rsa) 및 공개 키 (id_rsa.pub)를 생성합니다.\n\n## 단계 2: 공개 키를 서버 B로 복사\n\n- ssh-copy-id 명령어를 사용하여 공개 키를 서버 B로 복사하세요:\n\n<div class=\"content-ad\"></div>\n\n```js\nssh-copy-id user@serverB_IP\n```\n\n- 사용자를 서버 B의 사용자 이름으로, serverB_IP를 서버 B의 IP 주소 또는 호스트 이름으로 바꿔주세요.\n- 서버 B의 사용자 계정 암호를 입력하라는 메시지가 표시됩니다.\n- 공개 키를 성공적으로 복사한 후, 키가 추가되었음을 확인하는 메시지가 표시됩니다.\n\n# 단계 3: 무비밀번호 연결 테스트\n\n서버 A에서 서버 B로 SSH 연결을 시도해보세요:\n\n<div class=\"content-ad\"></div>\n\n```js\nssh user@serverB_IP\n```\n\n이제 암호를 묻지 않고 서버 B에 액세스할 수 있어야 합니다.\n\n# 문제 해결 팁\n\n암호없는 연결이 작동하지 않는 경우, 다음 문제 해결 단계를 따라주세요:\n\n<div class=\"content-ad\"></div>\n\n- 권한 확인: Server A 및 Server B의 .ssh 디렉토리가 올바른 권한을 가지고 있는지 확인해주세요. 사용자의 소유이어야 하며 제한된 권한을 가져야 합니다:\n\n```js\nchmod 700 ~/.ssh \nchmod 600 ~/.ssh/authorized_keys\n```\n\n- 키 파일 이름: 기본 키 이름(id_rsa 및 id_rsa.pub) 또는 키 생성 중에 지정한 이름을 사용하는지 확인하세요.\n- SSH 에이전트: Server A에서 프라이빗 키를 SSH 에이전트에 추가했는지 확인해주세요. 다음 명령을 사용하여 추가할 수 있습니다:\n\n```js\nssh-add ~/.ssh/id_rsa\n```\n\n<div class=\"content-ad\"></div>\n\n3. 방화벽 및 SELinux: 각 서버의 방화벽이 SSH 액세스를 차단하는지 확인하고 SELinux 권한이 문제를 일으키지 않도록 합니다.\n\n4. 로그: Server B의 SSH 서버 로그에서 오류 메시지를 확인하세요:\n\n```js\ntail -f /var/log/auth.log  # Ubuntu/Debian에서\ntail -f /var/log/secure    # CentOS/RHEL에서\n```\n\n5. 디버깅 모드: 더 많은 정보를 얻기 위해 SSH를 디버깅 모드로 실행할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nssh -v user@serverB_IP\n```\n\n이 명령어는 자세한 디버그 출력을 제공하여 문제의 원인을 파악하는 데 도움이 될 것입니다.\n\n이러한 단계를 따르고 문제 해결 팁을 고려한다면, Linux 서버간의 안전하고 편리한 원격 액세스를 위한 비밀번호 없는 SSH 연결을 설정할 수 있을 것입니다.","ogImage":{"url":"/assets/img/2024-06-22-StreamliningSecureRemoteAccessAGuidetoPasswordlessSSHConnectionsBetweenLinuxServers_0.png"},"coverImage":"/assets/img/2024-06-22-StreamliningSecureRemoteAccessAGuidetoPasswordlessSSHConnectionsBetweenLinuxServers_0.png","tag":["Tech"],"readingTime":3},{"title":"방어 무력화 T1562012 Linux 감사 로그 변조 탐지 방법 2부","description":"","date":"2024-06-22 16:09","slug":"2024-06-22-ImpairDefensesT1562012DetectLinuxAuditLogsTamperingPart2","content":"\n\n![이미지](/assets/img/2024-06-22-ImpairDefensesT1562012DetectLinuxAuditLogsTamperingPart2_0.png)\n\n이 시리즈의 첫 번째 파트에서는 리눅스 감사 데몬(auditd)이 시스템 이벤트의 상세 로그를 기록하여 시스템 보안을 유지하는 중요한 역할을 강조했습니다. 이 핵심 기능은 악의적 활동을 숨기려는 공격자들에게 auditd를 주요 대상으로 삼게합니다.\n\n이전 토론은 auditd의 지속적인 작동을 보증하는 데 중점을 둔 반면, 본 기사에서는 auditd 규칙의 삭제와 설정 변경을 감지하는 데 깊이 파고들었습니다. 이러한 설정의 무결성을 보장하는 것은 효과적인 보안 모니터링에 중요합니다.\n\n본 기사에서는 auditd 규칙 및 설정에 대한 무단 변경을 감지하는 중요성을 다룰 것입니다. 이러한 변경사항을 식별하고 감사 로그의 신뢰성을 확보할 수 있는 방법과 도구, 예를 들어 auditd 규칙 및 Splunk 쿼리 등을 소개하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n끝나면 공격자가 시스템 보안을 강화하는 데 필요한 지식과 도구로 장착될 것입니다. 이를 위해 auditd 규칙과 설정을 감지하여 조작하는 것을 탐지할 수 있습니다.\n\n## 우리가 해결하려는 문제\n\n공격자는 종종 auditd 규칙을 삭제하거나 구성을 수정하여 로깅을 비활성화하고 활동을 숨깁니다. 이러한 무단 변경 사항을 감지하는 것은 공격자가 사용하는 다양한 방법 때문에 어려울 수 있습니다.\n\n우리의 목표는 auditd 규칙과 설정에 대한 무단 삭제 또는 수정을 감지하는 것입니다. 효과적인 감지 메커니즘을 구현함으로써 감사 로그의 신뢰성을 유지하고 시스템 보안을 강화할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 해결책: 오디트드 규칙 및 설정 변경 감지하기\n\n저희의 해결책은 공격자가 오디트드를 대상으로 하는 도전에 대응하기 위해 두 가지 주요 구성 요소를 활용합니다:\n\n- 오디트드 규칙 삭제 감지: 오디트드에 의해 기록된 감사 레코드 유형(예: CONFIG_CHANGE)을 활용하여 오디트드 규칙의 삭제를 감지하는 모니터링을 구현할 것입니다. 이러한 레코드 유형은 규칙 삭제의 내장 로깅을 제공하여 시스템 보안을 저해할 수 있는 미승인 변경을 사전에 식별하고 대응할 수 있도록 합니다.\n- 오디트드 구성 및 중요 파일 변경 모니터링: 중요한 오디트드 구성 변경을 모니터링하기 위해 새로운 오디트드 규칙을 구현할 것입니다. 이러한 규칙은 필수적인 구성 파일의 수정 또는 삭제를 캡처하여 언제든지 미승인 변경이 즉각적으로 조사 대상으로 표시되도록 보장합니다.\n\n## 로그 활동 이해하기\n\n<div class=\"content-ad\"></div>\n\nauditd는 감사 시스템 구성 변경 시 CONFIG_CHANGE 이벤트를 기록합니다. 이는 감사 규칙을 포함한 구성 변경이 있을 때 발생합니다. 이 레코드 유형은 수정의 타임스탬프와 성격과 같은 세부 정보를 캡처하여 감사 규칙의 무단 삭제를 모니터링하고 감지하는 데 이상적입니다.\n\n![Image](/assets/img/2024-06-22-ImpairDefensesT1562012DetectLinuxAuditLogsTamperingPart2_1.png)\n\n## 로그 검토\n\n감사 규칙 삭제를 감지하기 위한 상관 검색을 확인하기 위해 먼저 Splunk에서 필요한 로그를 생성하기 위해 규칙 삭제 시뮬레이션을 수행했습니다.\n\n<div class=\"content-ad\"></div>\n\n여기서 패턴을 찾기 매우 쉽습니다. type=CONFIG_CHANGE 및 op=remove_rule을 찾아야 합니다.\n\n![이미지](/assets/img/2024-06-22-ImpairDefensesT1562012DetectLinuxAuditLogsTamperingPart2_2.png)\n\n# Splunk에서 오디트된 규칙 삭제 감지 개발\n\n## 설명:\n\n<div class=\"content-ad\"></div>\n\n**검색 기준 (index, sourcetype, type, op, res):**\n\n- linux_audit 인덱스에서 type이 CONFIG_CHANGE이고 op이 remove_rule이며 res가 1인 linux:audit 이벤트를 검색합니다. (성공을 나타냄)\n\n**필드 평가 (eval key):**\n\n- key가 \"(null)\"인 경우 key를 \"unknown\"으로 설정하여 필드 일관성을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n3. 집계 (통계 값(key) AS deleted_rules):\n\n   - _time, host, type, auid, ses 및 op에 따라 이벤트를 집계하고, 삭제된 auditd 규칙의 모든 key 값(이름)을 deleted_rules로 모음.\n\n4. 시간 변환 (convert ctime(_time)):\n\n   - _time의 Unix 타임스탬프를 사람이 읽을 수 있는 날짜 및 시간 형식으로 변환합니다.\n\n<div class=\"content-ad\"></div>\n\n5. 삭제된 규칙 수 세기 (eval count=mvcount(deleted_rules)):\n\n- 삭제된 규칙 발생 횟수를 세줍니다.\n\n6. 이벤트 설명 (eval event_info):\n\n- 삭제된 규칙의 개수를 기반으로 event_info를 구성합니다.\n- 삭제된 auditd 규칙의 수와 타임스탬프를 지정합니다.\n- 규칙 삭제의 예기치 못한 성격으로 인해 조사를 권장합니다.\n\n<div class=\"content-ad\"></div>\n\n7. 최종 결과 (표 _time, 호스트, 유형, auid, ses, 작업, deleted_rules, 이벤트_정보):\n\n- 타임스탬프(_time), 호스트, 이벤트 유형 (유형), 감사 사용자 ID (auid), 세션 ID (ses), 작업 (op), 삭제된 규칙 (deleted_rules) 및 이벤트 세부정보 (이벤트_정보)를 포함한 구조화된 테이블 형식으로 결과를 제시합니다.\n\n# auditd 구성 수정/삭제를 모니터링하기 위한 탐지 개발\n\n## 단계 1: 구성 수정을 모니터링하기 위한 auditd 규칙 생성\n\n<div class=\"content-ad\"></div>\n\n설정 중인 auditd 규칙은 Linux 감사 인프라에 필수적인 핵심 구성 파일을 모니터링하기 위해 전략적으로 설계되었습니다. 이러한 파일에는 /etc/audit/auditd.conf, /etc/audit/rules.d/test.rules, /etc/audisp/audispd.conf 및 /etc/libaudit.conf이 포함됩니다. 각각이 중요한 이유는 다음과 같습니다:\n\n- /etc/audit/auditd.conf: 감사 데몬 (auditd)의 전역 설정을 제어하며 로그 위치, 보존 정책 및 시스템 전체 감사 구성을 포함합니다.\n- /etc/audit/rules.d/test.rules: 특정 이벤트 및 조건을 정의하는 감사 규칙을 포함합니다.\n- /etc/audisp/audispd.conf: 감사 이벤트 디스패처 (audispd)를 구성하며 감사 이벤트를 처리하고 전달하는 역할을 담당합니다.\n- /etc/libaudit.conf: 감사 프레임워크 (libaudit)의 라이브러리 수준 설정을 관리하며 그 동작과 기능성에 영향을 줍니다.\n\n<img src=\"/assets/img/2024-06-22-ImpairDefensesT1562012DetectLinuxAuditLogsTamperingPart2_3.png\" />\n\n이 auditd 규칙의 논리는 다른 설정 파일 간에 일관성을 유지합니다:\n\n<div class=\"content-ad\"></div>\n\n- 각 규칙은 관련 작업이 발생할 때마다 감사 이벤트가 생성되도록 항상 -a를 사용합니다.\n- 모두 -F path=를 지정하여 감시되는 특정 구성 파일의 경로를 정의합니다.\n- -F perm=wa는 쓰기(w) 및 속성 변경(a) 권한에 대해 이벤트가 트리거되도록 지정합니다.\n- -F success=1은 작업이 성공했을 때에만 이벤트가 기록되도록 합니다.\n- -k 매개변수는 auditd 규칙의 이름을 지정합니다.\n- 차이점은 지정된 경로(-F path=)에만 있으며, 다른 구성 파일(/etc/audit/auditd.conf, /etc/audit/rules.d/test.rules, /etc/audisp/audispd.conf, /etc/libaudit.conf)을 가리킵니다.\n\n구성 파일을 모니터링하기 위해 auditd 규칙을 구성하면 감지된 모든 수정 사항에 대한 로그가 생성됩니다. 이러한 로그는 Splunk에서 침입 탐지 규칙을 생성하기 위한 입력으로 사용됩니다.\n\n이러한 감사 로그를 상호 연관시키고 분석함으로써 Splunk는 무단 변경에 대한 예방적인 모니터링 및 경고를 제공합니다.\n\n## 단계 2: Splunk에서 상호 연관 검색 개발\n\n<div class=\"content-ad\"></div>\n\n새 감사 규칙을 테스트하여 auditd.conf에 다양한 수정 사항을 시뮬레이션하여 올바르게 작동하는지 확인했습니다.\n\n첫 번째 테스트에서는 rm 명령어를 사용하여 auditd.conf를 삭제하는 것을 포함했습니다. 두 번째 테스트에서는 설정 파일을 다른 디렉토리로 이동하고, 세 번째 테스트에서는 vim 텍스트 편집기를 사용하여 수정했습니다.\n\n## 설명:\n\n- 검색 기준 (인덱스, 소스 유형, 유형, 키):\n\n<div class=\"content-ad\"></div>\n\n- linux_audit 인덱스에서 linux:audit 소스 유형 및 type이 SYSCALL인 이벤트를 검색합니다.\n- 키 필드가 생성한 특정 감사 규칙 (auditrule_modification, auditd_conf_modification, audispd_conf_modification, libauditd_conf_modification) 중 하나와 일치하는 이벤트를 필터링합니다.\n\n2. 집계 (transaction host maxpause=1s):\n\n- 1초 시간 간격 내(최대 일시 중지 = 1초) 동일 호스트에서 연속된 이벤트 (SYSCALL 항목)를 그룹화합니다.\n- 이 집계는 위협 행위자의 특정 작업에 대한 추가 컨텍스트를 제공할 수 있는 시스템 호출 순서를 분석하는 데 도움이 됩니다.\n\n3. 통계 요약 (stats count by _time, host, key, comm, exe, uid, gid, _raw):\n\n<div class=\"content-ad\"></div>\n\n- 다양한 필드별로 그룹화된 카운트를 계산합니다: _time (타임스탬프), host (컴퓨터 이름), key (감사 키), comm (명령어 이름), exe (실행 파일 경로), uid (사용자 ID), gid (그룹 ID) 및 _raw (원시 로그 항목). 이 요약은 트랜잭션 내에서 이러한 속성의 각 고유한 조합의 빈도수를 나타냅니다.\n\n## SYSCALL 이벤트의 중요 역할\n\nSYSCALLs (시스템 콜)은 Linux 시스템의 감사 로그 내에서 이벤트를 탐지하고 이해하는 데 중요한 역할을 합니다. 이것이 어떻게 이벤트 탐지에 기여하는지 살펴보겠습니다:\n\n기본 시스템 작업: SYSCALLs는 Linux 시스템에서 프로세스가 수행하는 기본 작업을 나타내기 때문에 필수적입니다. 이러한 작업에는 파일 시스템 접근 (예: open, read, write, unlink), 프로세스 관리 (예: fork, execve, exit), 그리고 네트워크 통신 (예: socket, connect, sendmsg)이 포함됩니다.\n\n<div class=\"content-ad\"></div>\n\nAudit Logging: Linux 시스템은 SYSCALL 이벤트를 기록하기 위해 감사 메커니즘을 사용합니다. 감사 로그에 기록된 각 SYSCALL 이벤트에는 작업 유형 (시스템 호출), 성공 또는 실패 여부 (성공=yes/no), 관련된 프로세스 ID (pid, ppid), 사용자 및 그룹 ID (uid, gid), 그리고 실행 가능한 경로 (exe)와 같은 세부 정보가 포함됩니다.\n\n## Raw Log Entry 분석:\n\n- type=SYSCALL: 로그 항목이 시스템 호출 이벤트와 관련되어 있음을 나타냅니다.\n- msg=audit(1715771488.665:75612745): 감사 이벤트의 타임스탬프 및 일련 번호.\n- syscall=263: 시스템 호출 번호를 지정합니다.\n- success=yes: 시스템 호출이 성공했음을 나타냅니다 (yes).\n- a0, a1, a2, a3: 감사 로그 항목의 이 필드는 시스템 호출 (syscall=263) 실행 시 전달된 인수 (a0부터 a3)를 나타냅니다. 이들은 시스템 호출 작업에 대한 구체적인 세부 정보를 제공합니다.\n- exit=0: 시스템 호출의 종료 상태 (0은 성공을 나타냅니다).\n- auid=*****: 감사 사용자 ID.\n- uid=0, gid=0, euid=0, suid=0, fsuid=0, egid=0, sgid=0, fsgid=0: 프로세스와 관련된 사용자 및 그룹 ID (사용자 ID에 대한 uid 및 그룹 ID에 대한 gid).\n- comm=”rm”: 프로세스에 의해 실행된 명령 이름 (이 경우 'rm').\n- exe=”/usr/bin/rm”: 명령과 관련된 실행 가능 경로 (/usr/bin/rm).\n- key=”auditd_conf_modification”: 이 이벤트와 관련된 감사 키를 식별합니다 (auditd_conf_modification은 감사 구성에 관련된 수정을 나타냅니다).\n\n## 결론\n\n<div class=\"content-ad\"></div>\n\n리눅스 감사 로그 변조를 탐지하는 이 두 부작에서는 auditd 규칙과 구성의 무결성을 보호하는 필수 전략을 탐구했습니다. 우선, 우리는 보안 모니터링에서의 auditd의 중요 역할과 악의적인 변조에 대한 취약성을 강조했습니다. 이를 통해 auditd 규칙의 삭제와 구성 변경을 탐지하는 것에 중점을 두었는데, 이는 견고한 보안 관행을 유지하는 데 중요합니다.\n\nauditd 규칙과 Splunk 쿼리를 활용한 실용적인 구현을 통해 무단 수정을 모니터링하고 감지하는 효과적인 방법을 시연했습니다. CONFIG_CHANGE 및 SYSCALL과 같은 audit 레코드 유형을 활용하여 의심스러운 활동을 신속하게 식별할 수 있는 탐지 메커니즘을 개발했습니다. 이러한 노력은 사건 대응과 규정 준수에 중요한 감사 로그의 신뢰성을 보장합니다.\n\n## 다음 단계:\n\n앞으로의 다음 단계는:\n\n<div class=\"content-ad\"></div>\n\n- 지속적 모니터링: auditd 규칙과 설정을 계속 모니터링하여 향후 무단 변경을 감지합니다.\n- 향상된 경보 설정: Splunk에서 경보 메커니즘을 세밀하게 조정하여 auditd와 관련된 수상한 활동에 대한 실시간 알림을 제공합니다.\n- 사고 대응 준비: 신속하게 수사할 수 있도록 사고 조치를 준비하고 식별된 보안 위반 사항에 대해 대응합니다.\n- 주기적 검토: 진화하는 보안 위협과 조직적 요구에 적응하기 위해 auditd 설정과 규칙을 정기적으로 검토하고 업데이트합니다.\n\n이러한 실천 방법을 보안 운영에 통합함으로써 Linux 환경의 변경 방지 방어를 강화하고 효과적인 보안 모니터링과 규정 준수를 보장할 수 있습니다.\n\nAleksandar Matev 작성","ogImage":{"url":"/assets/img/2024-06-22-ImpairDefensesT1562012DetectLinuxAuditLogsTamperingPart2_0.png"},"coverImage":"/assets/img/2024-06-22-ImpairDefensesT1562012DetectLinuxAuditLogsTamperingPart2_0.png","tag":["Tech"],"readingTime":8},{"title":"Ubuntu Desktop 2404 LTS에서 Autoinstall 시작하는 방법","description":"","date":"2024-06-22 16:03","slug":"2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS","content":"\n\n![이미지](/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_0.png)\n\n우분투 24.04 LTS의 가장 흥미로운 새로운 기능 중 하나는 새로운 우분투 데스크톱 설치 프로그램에 자동 설치 지원이 추가된 것입니다.\n\n자동 설치는 오랫동안 우분투 서버의 기능이었습니다. 사용자는 설치 프로세스에 맞게 맞춤 설정 구성을 적용하고 필요에 맞게 조정할 수 있습니다. 이는 사용자 생성, 네트워크 설정 구성, 패키지 설치 등을 포함합니다.\n\n우분투 23.04 및 우분투 23.10을 통해 우분투 데스크톱 설치 프로그램을 동일한 기본 코드 기반으로 이주시켰으며, 데스크톱 구성용 자동 설치를 해제하였습니다. 이제 설치 경험의 과대포장을 일부분으로 사용자가 구성을 직접 가져 올 수 있는 기능을 추가했습니다.\n\n<div class=\"content-ad\"></div>\n\n이 게시물에서는 사용자의 필요에 맞게 커스텀하고 반복 가능한 데스크톱 설치를 생성하는 방법을 간단히 보여 드리겠습니다.\n\n## 단계 1: autoinstall.yaml 파일 생성\n\nAutoinstall은 구성 yaml을 사용하여 기본 설치에 원하는 변경 또는 추가를 구조화합니다. 이는 간단한 설정으로 기본 사용자 구성 및 선호 애플리케이션을 커버하는 매우 짧은 설정이 가능하며, 고급 사용자들은 저장 레이아웃, 사용자 정의 네트워킹 및 방대한 포스트-설치 스크립트를 지정할 수 있습니다.\n\n처음 사용하는 사용자를 대상으로 간단한 예제부터 시작해 보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n```yaml\nautoinstall:\n  version: 1\n  identity:\n    hostname: ubuntu-desktop\n    username: local-optimum\n    password: \"$6$ZE4WV3QRJhPUnsNv$BpkTBYjUOxOiWV5sNPYDSitTwxW.3NHLmhRqptzpa8a4KTxGpkvMaSDbyq4PVri9kdpD1t7ldUBgwB6uveObg.\"\n  storage:\n    layout:\n      name: lvm\n  snaps:\n    - name: spotify\n      classic: false\n    - name: telegram-desktop\n      classic: false\n    - name: obsidian\n      classic: true\n    - name: code\n      classic: true\n  packages:\n    - vim\n  late-commands:\n    - curtin in-target -- wget https://repo2.protonvpn.com/debian/dists/stable/main/binary-all/protonvpn-stable-release_1.0.3-3_all.deb\n    - curtin in-target -- dpkg -i ./protonvpn-stable-release_1.0.3-3_all.deb\n    - curtin in-target -- apt update\n    - curtin in-target -- apt install -y proton-vpn-gnome-desktop\n```\n\n오 이 건 무엇을 하는 거에요?\n\n- 먼저, 우분투 데스크톱 기계의 이름은 'ubuntu-desktop'이 되며, 'local-optimum'이라는 사용자 이름과 해당 계정의 비밀번호 해시를 생성합니다 (이 경우에는 'ubuntu'에 해당함).\n- 파일 시스템 레이아웃으로 LVM을 사용하도록 지정합니다.\n- Spotify, Telegram, 멋진 노트 앱 Obsidian 및 VS Code의 네 가지 스냅을 설치합니다. Obsidian 및 VS Code는 클래식 스냅이며 이에 대한 지정이 필요합니다.\n- 제 동료들이 나노를 사용하는 저를 비웃지 않도록 Vim을 설치합니다.\n- 마지막으로, Proton VPN이라는 타사 애플리케이션을 설치하여 Proton의 공식 안내에 따르되 이 형식에 맞게 재구성한 방식으로 시스템에 설치합니다.\n\n이 스크립트는 내 GitHub에 저장되어 있으므로 데스크톱 설치 프로그램을 가리키기 위해 원시 링크를 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![Step 2](/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_1.png)\n\n# 단계 2: Ubuntu 데스크톱 24.04 LTS 설치 프로그램에 가져오기\n\n이 설정을 테스트하기 위해 가상 머신 관리자에서 VM을 만들겠어요. ISO를 마운트한 후 라이브 세션으로 부팅하고 네트워크에 연결되어 있는지 확인한 다음 아래 화면에서 \"자동 설치\" 옵션을 선택하고 내 GitHub 구성 주소를 제공할 수 있어요.\n\n![Automated Installation](/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_2.png)\n\n<div class=\"content-ad\"></div>\n\n\"유회 > 확인'을 누른 후 설치 요약 화면이 표시됩니다. 여기서 구성이 성공적으로 가져와졌는지 확인할 수 있습니다.\n\n![이미지](/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_3.png)\n\n여기까지입니다! Subiquity가 이후의 모든 작업을 처리하고 몇 분 후에 새로 설치된 데스크톱으로 다시 부팅할 수 있습니다.\n\n참고: 자동 설치 후 첫 부팅은 스냅 설치와 같은 작업을 계속 수행하므로 보통보다 시간이 더 걸릴 수 있습니다.\"\n\n<div class=\"content-ad\"></div>\n\n# 단계 3: 맞춤 설정된 Ubuntu 데스크톱을 즐기세요!\n\n지정된 변경 사항이 모두 적용되었는지 확인해 봅시다!\n\n먼저 사용자 이름과 비밀번호가 올바른지 테스트할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_4.png\" />\n\n<div class=\"content-ad\"></div>\n\nVim, ProtonVPN, 그리고 설치된 스냅도 앱 뷰에 있습니다:\n\n![image1](/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_5.png)\n\n마지막으로, LVM을 사용 중임을 확인하기 위해 lvdisplay를 실행할 수 있습니다.\n\n![image2](/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_6.png)\n\n<div class=\"content-ad\"></div>\n\n# 로컬에서 자동 설치 구성을 호스팅하기\n\n이 설정은 개인화를 위한 것이므로, 공개적으로 공유되어서는 안 되는 정보나 설정 세부사항을 제공해야 하는 경우가 발생할 수 있습니다.\n\n이 경우 로컬 네트워크에서 구성을 제공하는 것이 쉽습니다. 다른 Ubuntu 기기의 디렉토리에 파일을 저장한 다음 해당 디렉토리 내에서 python3 -m http.server 8000을 실행하는 것이 가장 간단한 방법입니다.\n\n![이미지](/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_7.png)\n\n<div class=\"content-ad\"></div>\n\n설치 중에는 다음 이미지와 같이 머신 IP와 구성 파일 이름을 지정할 수 있습니다.\n\n\n# 더 많은 예제 살펴보기\n\n이 간단한 튜토리얼이 데스크탑을 표준화하고 구성하는 데 자동 설치의 힘을 이해하는 데 도움이 되기를 바랍니다. 선호하는 설정의 사용자 지정 구성을 유지 관리함으로써 Ubuntu 24.04 LTS의 각 설치를 필요에 맞게 쉽게 조정할 수 있어야 합니다.\n\n\n<div class=\"content-ad\"></div>\n\n더 심층적인 예제 구성을 보려면 정교한 서버 사용 사례도 포함된 공식 Subiquity 예제를 확인해보세요.","ogImage":{"url":"/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_0.png"},"coverImage":"/assets/img/2024-06-22-GettingstartedwithAutoinstallonUbuntuDesktop2404LTS_0.png","tag":["Tech"],"readingTime":5},{"title":" 리눅스가 내 램을 다 먹었어요","description":"","date":"2024-06-22 16:02","slug":"2024-06-22-Linuxatemyram","content":"\n\n린역 케어킹이 어렵고 복잡하다고 느끼셨던 적이 있나요? 걱정하지 마세요! 당신의 램은 괜찮아요! 이 비디오를 통해 리눅스가 메모리를 어떻게 관리하는지, 왜 램이 가득 차있는 것처럼 보이며 걱정할 필요가 없는지 설명해 드릴게요.\n\n🙋‍♂️ 그럼, 다음 질문은 무엇일까요?\n\n리눅스에서 높은 메모리 사용량을 보게 되면, 주로 디스크 캐싱 때문일 거예요. 리눅스는 사용 가능한 메모리를 디스크 작업 캐싱에 사용하여 시스템을 빠르고 효율적으로 만들어요. 이 캐싱된 메모리는 필요 없을 때 다른 곳으로 대여되고 필요할 때 언제든지 애플리케이션에 대해 즉시 확보할 수 있어요.\n\n🙋‍♂️ 다음 질문은, 왜 리눅스가 디스크 캐시를 사용할까요?\n\n<div class=\"content-ad\"></div>\n\n디스크 캐싱은 시스템 성능을 향상시키는데 도움이 됩니다. 자주 액세스되는 데이터를 메모리에 유지함으로써 디스크에서 데이터를 읽는 데 걸리는 시간을 줄일 수 있어 시스템이 더 빠르게 반응합니다. 하지만 이에는 단점이 있을까요? 사용자들이 자신의 메모리가 부족하다고 오해하게 만들 수 있지만, 이는 사실이 아닙니다.\n\n🙋‍♂️ 메모리 관리 방법을 이해해봅시다\n\n리눅스는 메모리 사용량을 다음과 같이 분류합니다:\n\n✅ 사용 중인 메모리는 응용 프로그램에서 활발히 사용되는 메모리입니다.\n\n<div class=\"content-ad\"></div>\n\n✅ 사용되지 않은 메모리가 Free Memory입니다.\n\n✅ Available Memory는 디스크 캐시에 사용되지만 즉시 애플리케이션에 재할당될 수 있는 메모리입니다.\n\n시스템 메모리를 이해해야 할 때에는 \"free\" 메모리가 아닌 \"available\" 메모리에 주목하세요.\n\n🙋‍♂️ 또 다른 혼란스러운 질문은, Swap이 더 필요한가요?\n\n<div class=\"content-ad\"></div>\n\n아마도 그렇지 않을거에요. 디스크 캐싱은 유휴 상태의 RAM을 사용하고 필요할 때 애플리케이션에 반환합니다. 스왑은 물리적 RAM이 완전히 활용될 때 사용됩니다. 애플리케이션이 더 많은 메모리를 필요로 하는 경우 커널이 디스크 캐시로부터 다시 할당하여 최소한의 스왑 사용을 보장합니다.\n\n🙋‍♂️ 메모리 사용량 확인 방법\n\n메모리 사용량을 정확하게 확인하려면 다음을 사용하세요:\n\n\nfree -m 명령어\n\n\n<div class=\"content-ad\"></div>\n\n\"실제로 응용 프로그램에 사용 가능한 메모리 양을 확인하려면 '사용 가능' 열을 보세요. 이것이 메모리 사용량을 정확히 보여줍니다.\n\n🙋‍♂️ 중요한 질문은 언제 걱정해야 하는가입니다.\n\n일반적으로 디스크 캐싱은 유용하지만, 진정한 저 메모리의 조짐이 있습니다:\n\n✅ 사용 가능한 메모리가 거의 0에 가까운 경우.\"\n\n<div class=\"content-ad\"></div>\n\n✅ 스왑 사용량이 계속해서 늘거나 변동하는 경우\n\n✅ o o m 킬러가 활성화되어 있으며, 이는 dmesg로 확인할 수 있습니다.\n\n🏁 요약하자면\n\nLinux가 메모리를 어떻게 관리하는지 이해하면 시스템 성능에 대한 불필요한 걱정이 덜어집니다. 디스크 캐싱은 시스템을 더 빠르고 반응성이 더 뛰어나게 만들며, 사용된 메모리는 즉시 애플리케이션을 위해 다시 확보할 수 있습니다. \"사용 가능한\" 메모리에 집중하면 시스템 상태에 대한 더 명확한 그림을 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n🖼 이미지 참고: [이미지](https://www.linuxatemyram.com/atemyram.png)\n\n📚 책 링크:\n\n![](/assets/img/2024-06-22-Linuxatemyram_0.png)\n\n[DevOps 면접 분석](https://pratimuniyal.gumroad.com/l/cracking-the-devops-interview)","ogImage":{"url":"/assets/img/2024-06-22-Linuxatemyram_0.png"},"coverImage":"/assets/img/2024-06-22-Linuxatemyram_0.png","tag":["Tech"],"readingTime":2}],"page":"42","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}