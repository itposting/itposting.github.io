{"pageProps":{"posts":[{"title":"요청콘텐츠 스타일을 제한하는 50가지 두 단어 ChatGPT 프롬프트 예시  파트 2","description":"","date":"2024-06-23 19:00","slug":"2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2","content":"\n\n![이미지](/assets/img/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2_0.png)\n\n챗GPT 프롬프트 트릭을 모두 알고 있다고 생각했나요? 다시 한 번 생각해 보세요! 두 단어 톤 프롬프트의 첫 번째 부분으로 마음을 끌었는데, AI의 목소리를 제어하는 데 사용될 수 있는 50가지 더 놀라운 방법으로 돌아왔습니다.\n\n어리석은 이야기부터 심각한 보고서까지, 이러한 소프트 프롬프트는 AI의 톤과 개성을 제어할 수 있게 해줬어요.\n\n우리는 \"재미있는 이야기\"와 같은 단순한 분위기를 넘어, 몇 가지 더 황당한 단계를 올려가고 있어요.\n\n<div class=\"content-ad\"></div>\n\nChatGPT가 다양한 주제에 대해 다양한 답변을 제공할 수 있다는 걸 알고 계시나요?\n\n그 쿨한 트릭을 알아? 정확히 원하는 유형의 응답을 받는 방법이 있는데, 그 방법은 두 단어만 사용하는 것이야!\n\n놀라운 ChatGPT 프롬프트를 사용하여 글을 쓰고 최적화하는 것도 가능해.\n\n이러한 프롬프트를 사용하면 ChatGPT가 자유자재로 코드를 전환하면서 자유스럽게 랩퍼처럼 라임을 맞춰주거나, 고대의 현자처럼 철학적으로 이야기하거나, 앤드루 다이스 클레이를 부끄러워하게 할만한 욕설로 가득한 욕설을 할 수 있어. 그건 시작에 불과해!\n\n<div class=\"content-ad\"></div>\n\n- “전략 개요”\n- “예측 제공”\n- “이론 설명”\n- “개요 제공”\n- “비평 제공”\n- “접근 방법 설명”\n- “요약 제공”\n- “기법 비교”\n- “목표 개요”\n- “평가 제공”\n- “개념 설명”\n- “세부 내용 제공”\n- “권장 사항 제공”\n- “근거 설명”\n- “평가 제공”\n- “접근 방법 비교”\n- “방법론 개요”\n- “결론 제공”\n- “현상 설명”\n- “제안 제공”\n- “통찰력 제공”\n- “제안 제공”\n- “논리 설명”\n- “추가 설명”\n- “틀 제공”\n- “결과 비교”\n- “계획 개요”\n- “전망 제공”\n- “영향 설명”\n- “분석 제공”\n- “관점 제시”\n- “과정 설명”\n- “세부 내용 제공”\n- “구조 개요”\n- “요약 제공”\n- “해결책 제시”\n- “추론 설명”\n- “배경 제공”\n- “더 자세히 설명”\n- “대안 제시”\n- “참고 자료 제공”\n- “주요 요점 요약”\n- “타임라인 제공”\n- “이유 설명”\n- “정의 제공”\n- “제품 비교”\n- “요약 작성”\n- “방법론 설명”\n- “단계 개요”\n- “지시 제공”\n\n<div class=\"content-ad\"></div>\n\n뭐 기다려? 이 살상적인 프롬프트들을 꽂아보면서 끊임없는 대화, 이야기, 그리고 AI 들어끼기의 새로운 세계를 즐겨보세요.\n\n그럼 어서 뭐 기다리고 있어? 이 살상적인 프롬프트들을 꽂아보면서 끊임없는 대화, 이야기, 그리고 AI 들어끼기의 새로운 세계를 즐겨보세요.\n\n---\n\n이 글을 즐겼다면 몇 번의 박수👏를 해주시고 주변에 공유해주세요!\n\n<div class=\"content-ad\"></div>\n\n웹진이 팔로우해 주셔서 감사합니다!\n\n더 많은 멋진 콘텐츠가 곧 공개될 예정이니, 저를 여기 중간에서 팔로우해 주세요.\n\n아래 댓글에 의견과 피드백을 남겨주세요!\n\n건배! 🥂\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! 웹진니(Webjinnee 창립자) Nitin입니다. 다음에 만나요! ✌️\n\n#챗GPT해킹 #프롬프트파워 #톤트릭스 #AI워드크래프트 #최소프롬프트 #AI글쓰기팁 #챗GPT프롬프트","ogImage":{"url":"/assets/img/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2_0.png"},"coverImage":"/assets/img/2024-06-23-50Two-wordChatGPTpromptsthatdontsuggestcontentbutlimittheRequestStyleofContentPart-2_0.png","tag":["Tech"],"readingTime":2},{"title":"OpenAI  토큰을 사용하는 최고의 방법","description":"","date":"2024-06-23 18:58","slug":"2024-06-23-OpenAIBestPracticesofUsingTokens","content":"\n\n<img src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png\" />\n\n# 오픈AI 토큰이란\n\n오픈AI의 고급 언어 모델인 GPT-3.5 및 GPT-4와 같은 분야에서 \"토큰\"이란 텍스트에서 함께 자주 나타나는 문자 시퀀스를 가리킵니다. 이러한 모델은 이러한 토큰 간의 통계적 관계를 이해하고 예측하는 데 설계되어 있습니다.\n\n텍스트를 토큰으로 분해하는 프로세스는 다른 모델 간에 다를 수 있습니다. 예를 들어, GPT-3.5와 GPT-4는 이전 모델과 달리 다른 토큰화 프로세스를 사용하여 입력 텍스트에 대해 다른 토큰을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n일반적으로 한 토큰은 영어 텍스트의 네 문자에 해당하는 양으로, 대략 세 분의 삼분의 이 하나의 단어와 거의 비슷합니다. 따라서, 100개의 토큰은 대략 75단어에 해당합니다.\n\n예를 들어, \"OpenAI is great!\"이라는 문장을 생각해 봅시다. 이 문장에서 토큰은 다음과 같이 분리될 수 있습니다:\n\n[“Open”, “AI”, “ is”, “ great”, “!”]\n\n![이미지](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_1.png)\n\n<div class=\"content-ad\"></div>\n\n여기 각각이 토큰으로 간주됩니다. 모델에서 사용하는 구체적인 토큰화 프로세스에 따라 정확한 분할이 다를 수 있습니다. 예를 들어, 일부 모델은 \"OpenAI\"를 하나의 토큰으로 처리할 수 있지만, 다른 모델은 \"Open\"과 \"AI\"로 분할할 수도 있습니다. 마찬가지로, 공백과 구두점은 종종 별도의 토큰으로 처리됩니다. 그래서 이 예시에서는 다섯 개의 토큰이 있습니다: \"Open\", \"AI\", \" is\", \" great\", 그리고 \"!\".\n\n토큰 길이 개념을 이해하기 위한 유용한 가이드라인을 제시해드리겠습니다:\n\n- 1 토큰은 대략 영어로 4자와 동일합니다.\n- 1 토큰은 대략 단어의 3/4에 해당합니다.\n- 100 토큰은 약 75단어에 해당합니다.\n\n또는,\n\n<div class=\"content-ad\"></div>\n\n# 토큰 인코딩\n\n토큰 인코딩은 자연어 처리(NLP) 및 기계 학습에서 중요한 단계입니다. 이는 기계가 이해하고 작업할 수 있는 형식인 고정 차원의 수치 벡터로 변환하는 과정입니다.\n\n다른 토큰 인코딩은 서로 다른 모델에 연결되어 있으므로 텍스트를 토큰으로 변환할 때 어떤 모델을 사용할 지 고려해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n주어진 텍스트 문자열 (예: \"OpenAI is great!\")과 인코딩 (예: \"cl100k_base\")으로 토크나이저가 텍스트 문자열을 토큰 목록으로 분할할 수 있습니다 (예: [\"Open\", \"AI\", \" is\", \" great\", \"!\"]).\n\n다음 표는 토큰 인코딩 방법과 OpenAI 모델 간의 매핑을 보여줍니다:\n\n\n| 토큰 인코딩 방법 | OpenAI 모델 |\n|------------------|-------------|\n| cl100k_base      | 모델 1      |\n| cl200k_base      | 모델 2      |\n| cl500k_base      | 모델 3      |\n\n\n# 토큰화\n\n<div class=\"content-ad\"></div>\n\nOpenAI의 맥락에서 토큰화는 텍스트를 더 작은 조각, 즉 토큰으로 분리하는 방법입니다. 이 토큰들은 텍스트에서 함께 자주 나타나는 문자 시퀀스로, OpenAI의 대형 언어 모델인 GPT-3.5 및 GPT-4 등에서 사용되어 텍스트를 처리하고 이해하는 데 활용됩니다.\n\nTiktoken은 OpenAI가 만든 기반 Python 도구입니다. 이 도구는 주로 OpenAI의 GPT-4와 같은 모델과 함께 작동하도록 설계된 빠른 바이트 페어 인코딩 (BPE) 토크나이저입니다. Tiktoken의 주요 기능은 텍스트를 더 작은 조각으로 나누어 모델이 텍스트를 처리하고 이해할 수 있도록 하는 것입니다.\n\n오픈 소스 도구인 Tiktoken은 pip install tiktoken 명령을 사용하여 PyPI에서 쉽게 설치할 수 있습니다. 또한 JavaScript 환경에서 사용할 수 있는 커뮤니티 지원 버전도 있습니다.\n\nTiktoken의 주요 기능 중 하나는 교육용 하위 모듈인데, 이 모듈은 BPE의 작동 방식을 이해하고 사용자가 토큰화 프로세스를 시각화할 수 있도록 도와줍니다. 또한 Tiktoken은 유연하며 새로운 인코딩 지원을 추가할 수 있도록 사용자에게 허용합니다.\n\n<div class=\"content-ad\"></div>\n\n예제 하나가 이렇게 보일 거예요:\n\n```python\nimport tiktoken\n\nencoding = tiktoken.get_encoding(\"cl100k_base\")\n# 특정 모델 이름에 해당하는 올바른 인코딩을 자동으로 로드하기 위해\nencoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n\nprint(encoding.encode(\"OpenAI is great!\"))\n```\n\n출력은 이렇게 보일 거예요:\n\n```python\n[5109, 15836, 374, 2294, 0]\n```\n\n<div class=\"content-ad\"></div>\n\n토큰을 세는 방법은 .encode()로 반환된 리스트의 길이를 세면 됩니다.\n\n# 토큰 한도\n\n요청에 사용할 수 있는 토큰의 최대 수는 선택한 모델에 따라 다르며, 입력 프롬프트 및 생성된 출력(gpt-3.5-turbo)에 대한 4096개의 토큰이라는 결합한 한도가 있습니다. 따라서, 입력에 4000개의 토큰을 할당하면 출력에는 최대 96개의 토큰이 남게 됩니다.\n\n이 제약은 주로 기술적인 이유로 인해 발생합니다. 그러나, 입력을 더 간결하게 요약하거나 콘텐츠를 더 작은 세그먼트로 나누는 등 이러한 제한 내에서 효과적으로 작업하는 다양한 전략이 존재합니다.\n\n<div class=\"content-ad\"></div>\n\nGPT4의 토큰 한도\n\n![Image](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_3.png)\n\n더 많은 정보를 알고 싶다면 openai의 공식 웹사이트를 방문해보세요: [여기를 클릭하세요](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\n\n# 토큰 가격 설정\n\n<div class=\"content-ad\"></div>\n\nOpenAI API는 다양한 모델 유형을 제공하며 각 모델은 다른 가격 수준에서 사용할 수 있습니다. 이러한 모델들은 능력이 다양하며 가장 진보된 것은 다빈치이고, 가장 빠른 것은 에이다입니다. 요청을 만드는 데 드는 비용은 이러한 모델에 따라 달라집니다.\n\n예를 들어, GPT-4 Turbo 모델의 경우, 입력 기준으로 $0.01/1K 토큰, 출력 기준으로 $0.03/1K 토큰이 듭니다.\n\n표:\n\n![OpenAI 모델 비용](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_4.png)\n\n그리고 OpenAI에 따르면:\n\n<div class=\"content-ad\"></div>\n\nCobus Greyling님은 OpenAI 토큰 비용에 대한 멋진 차트를 보유하고 계시네요:\n\n![OpenAI Token Cost Chart](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_5.png)\n\n# 가격 계산기\n\n다음 \"OpenAI 및 다른 LLM API 가격 계산기\"를 활용하여 계산을 할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_6.png)\n\n위는 1000개의 입력 단어, 500개의 출력 단어 및 100회의 API 호출에 대한 총 비용을 보여줍니다.\n\n# Best Practices\n\nOpenAI 토큰을 사용할 때는 최적의 방법을 채택하여 효율성을 극대화하고 비용을 최소화하며 OpenAI의 API와의 상호 작용을 효과적이고 안전하게 보장할 수 있습니다. 다음은 추천하는 최상의 방법론입니다:\n\n\n<div class=\"content-ad\"></div>\n\n## 토큰 이코노믹스 이해하기\n\n사용하는 맥락에서 어떻게 토큰이 계산되는지, 그리고 토큰을 구성하는 것이 무엇인지 이해하세요. 다양한 입력 길이에 대한 대략적인 토큰 수를 알면 사용량과 비용을 보다 정확하게 추정하는 데 도움이 됩니다.\n\n## 프롬프트 디자인 최적화\n\n모델이 원하는 출력 생성 방향으로 이끌 수 있도록 프롬프트를 간결하면서도 충분히 구체적으로 디자인하세요. 이 균형을 유지하면 사용된 토큰 수를 줄이고 유용한 응답을 받을 확률을 높일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 효율적인 토큰 관리 활용하기\n\n예상치 못한 비용을 피하기 위해 토큰 사용량을 추적하세요. 플랫폼이나 응용 프로그램에서 지원한다면 알림이나 제한을 구현하여 소비량을 모니터링하세요.\n\n## 가능한 경우 일괄 요청 처리하기\n\n사용 사례가 허용한다면 일괄 처리는 한 번에 한 요청을 처리하는 것보다 더 효율적일 수 있습니다. 이 방법은 비용 절감에도 도움이 될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 작업에 적합한 모델 활용하기\n\n작업에 가장 적합한 모델을 선택하세요. Davinci와 같이 큰 모델은 더 강력하지만, Ada나 Babbage와 같은 작은 모델은 깊은 이해나 창의력이 필요하지 않은 작업에 대해 더 비용 효율적일 수 있어서 토큰을 절약할 수 있습니다.\n\n## 빈번한 요청에 대한 캐싱 구현하기\n\n응용 프로그램이 동일하거나 유사한 프롬프트로 반복적인 요청을 수행하는 경우, 응답을 캐싱하여 토큰을 절약할 수 있습니다. 캐시가 안전하게 관리되고 개인정보 및 데이터 보호 요구 사항을 준수하는지 확인하세요.\n\n<div class=\"content-ad\"></div>\n\n## API 키 보호하기\n\nOpenAI API 키를 안전하게 보호하여 무단 사용을 방지하고, 토큰 낭비 및 예상치 못한 요금 부과를 방지하세요. 접근 제어를 구현하고 정기적으로 키를 변경하세요.","ogImage":{"url":"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png"},"coverImage":"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png","tag":["Tech"],"readingTime":6},{"title":"ChatGPT-4o 시스템 프롬프트","description":"","date":"2024-06-23 18:57","slug":"2024-06-23-ChatGPT-4oSystemPrompt","content":"\n\nChatGPT이 시스템 프롬프트를 실수로 출력해 버렸어. 다른 분들도 궁금해할 것 같아 공유하려고 해.\n\n```js\n넌 오픈AI에서 훈련된 대규모 언어 모델인 ChatGPT이고, GPT-4 아키텍처를 기반으로 하고 있어.\nChatGPT iOS 앱을 통해 사용자와 대화 중이야. 대부분의 경우에는 한 두 문장 정도여야 해, 사용자의 요청이 이성적 사고나 장문의 결과를 필요로 할 때를 제외하고는. 사용자가 명시적으로 요청하지 않은 이상 이모지를 사용하지 마.\n지식의 종점: 2023년 10월\n현재 날짜: 2024년 06월 21일\n이미지 입력 기능: 활성화\n개성: v2\n\n# 도구\n\n## bio\n`bio` 도구를 사용하면 대화 전반에 걸쳐 정보를 유지할 수 있어. 메시지를 `to=bio`로 지정하고 기억하고 싶은 정보를 쓰세요. 이 정보는 나중 대화에서 모델 설정 맥락에 표시될 거야.\n\n## dalle\n// 이미지 설명이 제공될 때마다 dalle가 이미지를 생성할 수 있는 프롬프트를 만들어야 하며 다음 정책을 준수해야 해:\n// 1. 프롬프트는 영어로 작성되어야 해. 필요한 경우 영어로 번역하세요.\n// 2. 이미지를 생성할 권한을 요청하지 말고 그냥 생성하세요!\n// 3. 설명을 나열하거나 참조하지 마세요. 이미지 생성 전후로 참조하지 마세요.\n// 4. 사용자로부터 나온 이미지 설명이 변경된 경우, 프롬프트는 단순히 길어지는 것이 아니라 사용자 제안을 통합하도록 다시 만들어져야 합니다.\n// 5. 현재 이미지 설명을 요구하는 경우, 다음 절차를 적용하세요: (a) 작품의 이름을 스타일의 핵심 측면을 잡아내는 세 가지 형용사로 대체하고가; (b) 작품의 컨텍스트를 제공하기 위해 관련 예술의 흐름이나 시대를 포함하며; (c) 작가가 사용한 주요 매체를 언급하세요\n// 6. 특정, 명시된 사적 인물을 품은 생성을 요청받은 경우, 그들이 어떻게 보이는지를 설명할 것을 사용자에게 요청하세요. 당신이 그들이 어떻게 생겼는지 모르기 때문에.\n// 7. 이름으로 언급되는 어떠한 공인된 인물의 이미지 생성을 요청받은 경우, 해당 성별과 체형이 비슷한 사람들의 이미지를 생성하세요. 그들이 닮아 보이지 않아야 해. 이미지에서 해당 사람에 대한 참조가 텍스트만으로 나타 나는 경우라면, 참조를 그대로 사용하세요.\n// 8. 저작권이 있는 캐릭터의 이름을 공개하거나 직/간접적으로 언급하거나 설명하지 마세요. 특정 다른 캐릭터에 대해 자세히 설명하는 방식으로 프롬프트를 재작성하세요. 색상, 헤어 스타일 또는 다른 구별적인 시각적 특성을 가진 다른 특정 캐릭터에 대해 자세히 설명해 주세요. 응답에서 저작권 정책에 대해 이야기하지 마세요.\n// dalle에 보내야 하는 생성된 프롬프트는 매우 상세해야 하며, 약 100단어 가량이어야 합니다.\n// dalle에 대한 예제 호출: `{\"prompt\": \"<프롬프트 내용 삽입하세요>\"}`\n\n## browser\n`browser` 도구를 사용할 수 있어. 다음 상황에서 `browser`를 사용하세요:\n- 사용자가 현재 이벤트 또는 실시간 정보를 요청하는 경우 (날씨, 스포츠 점수 등).\n- 사용자가 안경데지 우리가 알지 못하는 용어에 대해 물어보는 경우 (새로운 것일 수 있음).\n- 사용자가 명시적으로 브라우징하거나 참조 링크를 제공하도록 요청하는 경우\n조회가 필요한 쿼리를 위해 당신의 차례는 세 단계로 이루어져야 합니다:\n1. 검색 기능을 호출하여 결과 목록을 가져옵니다.\n2. `mclick` 함수를 호출하여 이 결과의 다양하고 고품질의 부분을 검색합니다(병렬로). `mclick`을 사용할 때 적어도 3개의 소스를 선택하세요.\n3. 이 결과를 기반으로 사용자에게 응답하세요. 응답에서는 아래 인용 형식을 사용하여 소스를 인용하세요.\n일부 경우에는 초기 결과가 만족스럽지 않은 경우, 쿼리를 더 정제하여 더 나은 결과를 얻을 수 있다고 믿는다면 스텝 1을 두 번 반복해야 합니다.\n또한 사용자가 제공한 경우 바로 URL을 열 수 있습니다. 이를 위해 `open_url` 명령어만 사용하세요. 검색 함수에서 반환되는 URL이나 웹페이지에서 찾은 URL을 열지 마세요.\n`browser` 도구에는 다음과 같은 명령이 있습니다:\n`search(query: str, recency_days: int)`. 검색 엔진에 쿼리를 발행하고 결과를 표시합니다.\n`mclick(ids: list[str])`. 제공된 ID(인덱스)의 웹페이지 내용을 검색합니다. 사용할 때는 꼭 3개 이상, 최대 10개 페이지를 선택하세요. 다양한 관점의 소스를 선택하고 신뢰할 수 있는 소스를 우선 선택하세요. 일부 페이지가 로드되지 않을 수 있으므로, 콘텐츠가 중복될 수 있더라도 일부 페이지를 중복 선택하는 것이 괜찮습니다.\n`open_url(url: str)`. 주어진 URL을 열고 표시합니다.\n브라우저 도구에서 인용한 것은 다음 형식으로 렌더링하세요: `【{메시지 인덱스}†{링크 텍스트}】`.\n긴 인용문의 경우 다음 형식으로 렌더링하세요: `[링크 텍스트](메시지 인덱스)`.\n그 외에는 링크를 렌더링하지 말아주세요.\n\n## python\nPython 코드를 포함한 메시지를 python에게 보내면 상태 유지 Jupyter 노트북 환경에서 실행됩니다. python은 실행 결과를 응답하거나 60.0초 후에 타임아웃 될 것입니다.\n'/mnt/data' 드라이브를 사용하여 사용자 파일을 저장하고 유지할 수 있습니다. 이 세션에서의 인터넷\n\n<div class=\"content-ad\"></div>\n\n인터넷에서 처음으로 이를 발견한 사람은 아니라는 걸 알고 있어요. 일부 사람들은 챗봇을 \"탈옥\"하려고 의도적으로 노력하고 있는데요. 하지만 여전히 재미있게 보실 분들이 있을 거라고 생각해요.\nMarkdown 포맷으로 변경하였습니다.\n\n![ChatGPT-4oSystemPrompt_0](/assets/img/2024-06-23-ChatGPT-4oSystemPrompt_0.png)","ogImage":{"url":"/assets/img/2024-06-23-ChatGPT-4oSystemPrompt_0.png"},"coverImage":"/assets/img/2024-06-23-ChatGPT-4oSystemPrompt_0.png","tag":["Tech"],"readingTime":3},{"title":"하이퍼 관계형 그래프 더 지능적인 RAG 시스템의 핵심","description":"","date":"2024-06-23 18:55","slug":"2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems","content":"\n\n다음은 여러 문서 간의 정보를 원활하게 연결하여 복잡한 질문에 답변할 수 있는 인공 지능 시스템을 상상해 보세요. 이는 인간 전문가처럼 작동합니다.\n\n이 비전은 검색 보강 생성 (RAG) 시스템의 발전 덕분에 빠른 속도로 현실이 되고 있습니다.\n\n그러나 현재의 RAG 접근법은 여러 단계를 거치는 미묘한 질의에는 여전히 어려움을 겪고 있습니다.\n\n유망한 해결책이 등장했습니다: 과적합 그래프.\n\n<div class=\"content-ad\"></div>\n\n보다 풍부하고 맥락있는 지식 표현을 가능하게 함으로써, 이러한 고급 그래프 구조는 질문-답변 작업의 성능을 새로운 수준으로 끌어올리고 있어요.\n\n이 기사는 초월관계 그래프가 RAG 시스템을 혁신하고 더 지능적인 AI로 나아갈 수 있는 방법을 탐구합니다.\n\n검색을 증강한 생성은 현대 질문-답변 시스템의 중추가 되었습니다.\n\n대규모 언어 모델(Large Language Models, LLMs)의 방대한 지식을 외부 정보를 검색하고 통합하는 능력과 결합함으로써, RAG 방법론은 더 정확하고 최신의 응답을 생산하려고 합니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 쿼리가 점점 복잡해지면 기존의 RAG 시스템이 종종 한계에 부딪힙니다.\n\n다양한 정보 간 미묘한 관계를 효과적으로 표현하는 데 어려움을 겪어 관련 없는 검색 결과와 잘못된 추론을 유발할 수 있습니다.\n\n초관계 그래프가 등장합니다. 이러한 고급 지식 구조는 간단한 주어-술어-목적어 세트를 넘어 풍부한 맥락 정보를 포착합니다. \n\n![Hyper-RelationalGraphs](/assets/img/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems_0.png)\n\n<div class=\"content-ad\"></div>\n\n그렇게 함으로써 현재 RAG 시스템의 주요 한계를 많이 해결합니다.\n\n이 기사는 초관계 그래프가 RAG 성능을 크게 향상시키는 데 기여하며, 더 맥락적이고 세밀하며 효율적인 정보 검색과 추론이 가능하다고 주장합니다.\n\n이 그래프가 맥락적 표현, 쿼리 관련성 및 다중 홉 추론 기능을 향상시킴으로써 더 지능적이고 능력 있는 AI 시스템으로 나아가는 방법을 탐색해보겠습니다.\n\n# 향상된 맥락적 표현\n\n<div class=\"content-ad\"></div>\n\n하이퍼-관계 그래프의 핵심 기능은 풍부한 맥락 정보를 포착하고 표현하는 능력에 있습니다. 기존의 지식 그래프가 단순한 삼중 체계(예: \"파리 - 프랑스의 수도 -\")로 제한되어 있는 반면, 하이퍼-관계 그래프는 각 사실에 추가 메타데이터를 연결할 수 있습니다. 이러한 맥락 정보에는 다음이 포함될 수 있습니다:\n\n- 출처 문서: 각 정보 조각이 어디에서 기인했는지 추적\n- 시간적 한정자: 특정 사실이 사실이었던 시기 지정\n- 신뢰 점수: 추출된 정보의 신뢰성 반영\n\n이 향상된 표현은 RAG 시스템에 여러 가지 주요 이점을 제공합니다:\n\n## 향상된 모호성 해결\n\n<div class=\"content-ad\"></div>\n\n하이퍼-관계 그래프의 가장 중요한 장점 중 하나는 엔티티와 관계를 명확히 구별할 수 있는 능력입니다. Apple의 제품 출시에 관한 쿼리를 고려해 봅시다. 전통적인 지식 그래프에서는 \"Apple\"에 대한 언급이 모호할 수 있습니다 - 기술 회사나 과일을 가리킬 수 있습니다. 그러나 하이퍼-관계 그래프는 상황 정보를 활용하여 이 사용 사이를 구별할 수 있습니다.\n\n예를 들어, Apple의 제품 출시에 관한 사실은 기술 뉴스 소스에서 온 것임을 나타내는 메타데이터와 관련되어 있을 수 있습니다. 이 추가적인 맥락은 RAG 시스템이 이 경우에 \"Apple\"을 회사로 확신하고 해석할 수 있도록 도와줍니다. 마찬가지로, 시간적 한정자는 회사의 제품에 대한 역사적 및 현재 정보를 구별하는 데 도움이 될 수 있습니다.\n\n## 복잡한 쿼리 처리\n\n하이퍼-관계 그래프의 풍부한 맥락 표현은 복잡하고 다중 부분으로 이루어진 쿼리에 대답하는 데 특히 가치가 있습니다. \"Apple의 가장 최근 제품 출시에 대한 시장 반응이 5년 전 출시와 비교했을 때 어떻게 되었는지\"와 같은 질문을 고려해 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n이 쿼리에 대답하기 위해서는 여러 시기와 도메인(제품 정보, 재무 데이터 등)을 종합적으로 결합해야 합니다. 하이퍼-관련 그래프는 이러한 연결된 정보 조각들을 효율적으로 표현할 수 있습니다:\n\n- 특정 날짜와 연결된 제품 출시 이벤트\n- 시간적 한정자와 관련된 주식 가격 데이터\n- 제품 출시와 시장 반응 둘 다와 연관된 뉴스 기사 및 분석 보고서\n\n이러한 관계들을 구조화된 유연한 형식으로 포착함으로써, 하이퍼-관련 그래프는 RAG 시스템이 이러한 쿼리에 답변하기 위해 필요한 복잡한 정보 공간을 더 쉽게 탐색할 수 있게 합니다.\n\n# 전통적인 지식 그래프와 비교\n\n<div class=\"content-ad\"></div>\n\n하이퍼-관계 그래프의 가치를 완전히 이해하기 위해서는 전통적인 지식 그래프 방식과 직접 비교하는 것이 도움이 됩니다:\n\n- 표현력: 전통적인 지식 그래프는 이진 관계에만 제한되어 있지만, 하이퍼-관계 그래프는 n-체 이상의 관계와 추가 속성을 표현할 수 있습니다. 이는 보다 미묘하고 정확한 지식 표현이 가능하게 합니다.\n- 출처 추적: 하이퍼-관계 그래프는 각 사실의 출처 정보를 쉽게 유지할 수 있습니다. 이것은 신뢰성을 평가하고 충돌하는 정보를 해결하는 데 중요한데, 이는 전통적인 지식 그래프에서는 훨씬 어려운 기능입니다.\n- 시간적 추론: 일부 전통적인 지식 그래프는 시간 정보를 통합하려고 시도해왔지만, 이는 종종 구조에 통합되기보다는 마무리된 느낌을 줍니다. 하이퍼-관계 그래프는 시간적 추론을 지식 표현의 핵심 부분으로 만듭니다.\n- 확신과 불확실성: 하이퍼-관계 그래프는 사실과 함께 신뢰도 점수나 확률 분포를 연관시킴으로써 불확실성과 충돌 정보를 자연스럽게 표현할 수 있습니다. 이러한 세밀한 접근은 전통적인 지식 그래프 구조에서 어렵게 구현할 수 있습니다.\n\n제공된 연구에서 소개된 HOLMES 시스템은 실제로 이러한 이점을 실천적으로 시연하고 있습니다. 하이퍼-관계 그래프 구조를 활용하여 HOLMES는 전통적인 지식 표현을 사용하는 시스템과 비교하여 다중 점프 질문 답변 작업에서 상당한 성능 향상을 이뤘습니다.\n\n# 질의 의미와 효율 향상\n\n<div class=\"content-ad\"></div>\n\n지식 표현을 향상시키는 것을 넘어서, 초 관계 그래프는 RAG 시스템 내에서 더 명확하고 효율적인 정보 검색을 가능케 합니다. 이런 개선은 두 가지 주요 영역에서 나타납니다: 쿼리 관련성의 증가와 계산 오버헤드의 감소.\n\n## 더 명확한 정보 검색\n\n초 관계 그래프의 풍부한 구조는 쿼리와 관련 정보 간 보다 정확한 일치를 가능케 합니다. 전통적인 RAG 시스템은 종종 키워드 일치 또는 임베딩 유사성에 의존하여 잠재적으로 관련 있는 단락을 검색합니다. 단순한 쿼리에 대해 효과적이지만, 이러한 접근은 더 복잡한, 멀티-홉 질문에 어려움을 겪을 수 있습니다.\n\n이와 달리 초 관계 그래프는 시스템이 엔티티 간의 관계를 탐색하면서 인간의 추론에 더 가까운 방식으로 진행할 수 있도록 합니다. 예를 들어, \"2008 금융 위기가 유럽의 재생 에너지 투자에 미친 영향은 무엇입니까?\"와 같은 쿼리를 고려해 봅시다.\n\n<div class=\"content-ad\"></div>\n\n초위계 그래프는 검색 프로세스를 안내하는 데 도움을 줄 수 있습니다:\n\n- 핵심 개체 식별: \"2008 금융위기\", \"재생 에너지\", \"유럽\"\n- 관련 관계 탐색: 금융 사건 - 경제적 영향 - 산업 부문 - 지리적 지역\n- 적절한 시기에 초점을 맞추기 위해 시간 정보 활용\n\n이 구조화된 접근 방식은 관련 검색 결과를 보다 정확하게 제공하여 잡음을 줄이고 언어 모델에 제공되는 정보의 품질을 개선합니다.\n\n## 가지치기 프로세스\n\n<div class=\"content-ad\"></div>\n\n하이퍼-관계 그래프가 제공하는 가장 중요한 효율성 향상 중 하나는 관련 없는 정보를 지능적으로 제거할 수 있는 능력에서 옵니다. HOLMES 시스템은 이 과정을 효과적으로 보여주고 있습니다.\n\n- 쿼리에 맞춘 지식 스키마: 시스템은 특정 쿼리를 기반으로 스키마를 구성하고, 쿼리와 관련이 있을 것으로 예상되는 엔티티 및 관계 유형을 식별합니다.\n- 보조 그래프 스키마: 이는 도메인 내 질문 집합에서 파생된 미리 계산된 스키마와 결합되어, 필요한 정보 유형의 일반적인 패턴을 포착합니다.\n- 관련성 점수 매기기: 그래프 요소는 결합된 스키마와의 일치에 따라 점수가 매겨집니다.\n- 제거: 가장 높은 점수를 가진 요소만 유지되어, 쿼리에 매우 관련성이 높은 초점을 맞춘 하위 그래프가 생성됩니다.\n\n이 시도 과정은 최종 생성 단계에서 언어 모델이 처리해야 하는 정보 양을 대폭 줄입니다. HOLMES 실험에서는 다른 최첨단 방법과 비교해 최대 67%의 입력 토큰 감소를 이끌어냈습니다 [1].\n\n## 성능 개선\n\n<div class=\"content-ad\"></div>\n\n하이퍼-관계 그래프에서 얻게 되는 효율성 향상은 벤치마크 데이터셋에서 성능 향상으로 직접 이어집니다. 다중 홉 질문 응답을 위한 널리 사용되는 벤치마크인 HotpotQA 데이터셋에서 HOLMES는 다음을 달성했습니다:\n\n- 0.66의 정확 일치 (EM) 점수 (이전 최고 수준 대비 20% 향상)\n- 0.78의 F1 점수\n\n이와 유사한 향상이 이해력이 2~4번 이어지는 질문에 중점을 둔 MuSiQue 데이터셋에서도 보여졌습니다:\n\n- 이전 최고 방법과 비교해 EM 점수가 26% 증가했습니다\n\n<div class=\"content-ad\"></div>\n\n이런 양적 개선은 HOLMES가 기존 방법에 비해 답변 품질에서 더 높은 점수를 받았다는 인간 평가로 뒷받침되었습니다 [1].\n\n입력 토큰의 급격한 감소와 함께 향상된 답변 품질은 하이퍼-관계 그래프의 힘을 보여주며 RAG 시스템의 효율성과 효과성을 향상시킬 수 있다는 것을 입증합니다.\n\n# 다단계 추론 능력 발전\n\n하이퍼-관계 그래프의 가장 흥미로운 잠재력은 고급 다단계 추론을 지원하는 능력에 있습니다. 이 능력은 여러 소스에서 정보를 종합하거나 논리적 연쇄를 따라야 하는 복잡한 질문에 대답하는 데 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n## 다단계 추론 지원\n\n하이퍼-관계 그래프는 다단계 추론 프로세스와 자연스럽게 일치하는 구조를 제공합니다. 복잡한 질문에 대해 인간 전문가가 어떻게 대답할지를 생각해보세요:\n\n- 주요 개체와 개념 식별\n- 해당 개체에 대한 관련 사실 상기\n- 사실 간의 논리적 연결 따르기\n- 정보를 종합하여 결론 도출\n\n하이퍼-관계 그래프는 RAG 시스템이 이전보다 더 가까이 이 프로세스를 모방할 수 있도록 합니다. 그래프 구조를 통해 시스템이 다음을 할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 질의에서 시드 엔티티로 시작합니다\n- 관련 있는 관계를 통해 연결된 정보를 발견합니다\n- 맥락 메타데이터를 사용하여 각 정보의 관련성과 신뢰성을 평가합니다\n- 그래프를 통해 경로를 따라 추론 체인을 구성합니다\n\n이 구조화된 방식은 여러 논리적 단계가 필요한 질문에 특히 가치 있습니다. 예를 들어, “'인셉션’의 주연 배우가 아카데미상을 수상한 후해방 판매된 영화의 감독은 누구입니까?”\n\n이 질문에 답하기 위해 다음이 필요합니다:\n\n- “인셉션”의 주연 배우 식별\n- 그들이 아카데미상을 수상한 때 결정\n- 다음 해에 출시된 최고 수익 영화 찾기\n- 해당 영화의 감독 식별\n\n<div class=\"content-ad\"></div>\n\n하이퍼-관계 그래프는 이러한 모든 연결을 나타낼 수 있어서 RAG 시스템이 필요한 정보를 효율적으로 탐색할 수 있게 해줍니다.\n\n## 시간 정보 처리 개선\n\n많은 복잡한 쿼리는 서로 다른 시간 범위를 걸쳐 이벤트와 사실에 대해 추론하는 것을 포함합니다. 하이퍼-관계 그래프는 시간 정보를 효과적으로 나타내고 추론할 수 있습니다:\n\n- 사실을 특정 시점이나 범위에 연관시킬 수 있습니다.\n- 이벤트 간 관계를 명시적으로 모델링할 수 있습니다 (예: \"이전에 발생한\", \"동안에 발생한\").\n- 사실이 시간에 따라 변하는 것을 효율적으로 나타낼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 시간적인 인식력 덕분에 RAG 시스템은 \"합병 이후 몇 년간 회사의 전략이 어떻게 변화했습니까?\"와 같은 쿼리를 더 정확하고 세밀하게 처리할 수 있습니다.\n\n## 상반된 정보 해결\n\n실제 세계의 지식 베이스에서는 서로 다른 출처에서 상반된 정보를 만나는 것이 흔합니다. Hyper-relational 그래프는 이러한 갈등을 나타내고 이에 대해 추론하는 메커니즘을 제공합니다:\n\n- 사실의 여러 버전을 소스 정보와 함께 저장할 수 있습니다.\n- 다른 주장에 확신 점수를 할당할 수 있습니다.\n- 시간적 한정자가 외견적인 모순을 해결하는 데 도움이 될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n정보가 충돌할 때 RAG 시스템은 다음과 같은 기능을 활용할 수 있어요:\n\n- 충돌 식별\n- 다양한 소스의 신뢰성 평가\n- 시간적 맥락 고려\n- 필요한 경우 불확실성을 인정하는 섬세한 답변 제시\n\n이 접근 방식은 더 견고하고 신뢰할 수 있는 질문 응답 능력으로 이어져요.\n\n## 향상된 설명력\n\n<div class=\"content-ad\"></div>\n\nRAG 시스템에서 하이퍼-관계 그래프를 사용하는 주요 이점 중 하나는 개선된 설명 가능성의 가능성입니다. 그래프의 구조화된 성격은 시스템이 다음을 할 수 있도록 합니다:\n\n- 답변에 이르기까지 사용된 추론 경로를 추적\n- 활용된 구체적인 사실 및 관계 식별\n- 각 정보 조각에 대한 명확한 출처 제공\n\n이 설명 가능성은 시스템 출력에 대한 신뢰를 구축하는 데 뿐만 아니라 기본 모델을 디버깅하고 개선하는 데도 유용합니다. 연구원과 개발자는 추론 경로를 분석하여 시스템이 우수하거나 어려움을 겪는 부분을 식별하고 특정 개선 사항을 찾을 수 있습니다.\n\nHOLMES 시스템은 이 설명 가능성의 잠재력을 보여줍니다. 다양한 쿼리에 대해 생성된 가지치기된 하위 그래프를 조사함으로써 연구원들은 시스템이 다양한 유형의 질문에 접근하는 방식에 대한 통찰을 얻을 수 있었습니다. [1]\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n하이퍼-관계 그래프는 RAG 시스템의 발전에서 중요한 획을 달성했습니다. 보다 풍부한 맥락 표현, 더 명확한 정보 검색, 그리고 고급 다중 점프 추론 능력을 통해 이러한 구조는 현재 방식에서 겪는 주요 제약 사항을 해결합니다.\n\n하이퍼-관계 그래프의 장점은 성능 지표의 향상 이상을 제공합니다. 이들은 RAG 시스템이 다음을 할 수 있도록 합니다:\n\n- 더 복잡하고 미묘한 쿼리 처리\n- 보다 맥락적으로 적절한 답변 제공\n- 보다 큰 투명성과 설명 가능성 제공\n- 관련 정보에 중점을 두어 더 효율적으로 작동하기\n\n<div class=\"content-ad\"></div>\n\n이러한 발전은 자연어 처리 및 인공 지능 분야에 매우 중요한 영향을 미치고 있습니다. 더 강력한 질의응답 시스템은 다음을 향상시킬 수 있습니다:\n\n- 정보 검색 및 지식 관리\n- 의사 결정 지원 시스템\n- 지능형 지도 및 교육 플랫폼\n- 연구 및 과학 발견 도구\n\n미래를 바라볼 때, 몇 가지 주요 질문과 연구 방향이 나타납니다:\n\n- 확장성: 어떻게 하면 거대한 지식 베이스를 위해 하이퍼-관계 그래프를 효율적으로 구축하고 업데이트할 수 있을까요?\n- 신경망 접근과의 통합: 하이퍼-관계 그래프를 신경망 검색 및 추론 방법과 어떻게 효과적으로 결합할 수 있을까요?\n- 교차 영역 추론: 하이퍼-관계 그래프를 활용하여 여러 지식 영역을 걸쳐 추론하는 데 어떻게 기여할 수 있을까요?\n- 대화형 시스템: 하이퍼-관계 그래프를 통해 보다 동적이고 다중 턴의 질의응답 상호작용을 가능하게 할 수 있을까요?\n- 윤리적 고려사항: 이러한 시스템의 향상된 기능이 책임있게 사용되고 지식 표현의 잠재적 편향이 해결되는 방법은 무엇일까요?\n\n<div class=\"content-ad\"></div>\n\n연구자들이 이러한 문제들을 계속 탐구함에 따라 한 가지는 분명합니다: 과잉관계 그래프는 다음 세대 지식 질문 응답 시스템에서 중요한 역할을 할 것으로 예상됩니다. 더 세밀하고 맥락적인 지식 표현을 제공함으로써, 이러한 그래프는 복잡한 주제에 대해 인간과 유사한 유연성과 심도로 추론할 수 있는 AI 시스템에 한 걸음 더 가까워지게 합니다.\n\n# 참고 문헌:\n\n[1] Panda, P., Agarwal, A., Devaguptapu, C., Kaul, M., & Prathosh, A. P. (2024). HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs. arXiv preprint.","ogImage":{"url":"/assets/img/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems_0.png"},"coverImage":"/assets/img/2024-06-23-Hyper-RelationalGraphsTheKeytoMoreIntelligentRAGSystems_0.png","tag":["Tech"],"readingTime":9},{"title":"당신을 치유한 사람들에 의해 다시 상처받는 경험","description":"","date":"2024-06-23 18:54","slug":"2024-06-23-Beingbrokenbythepeoplethatalsohealedyou","content":"\n\n![image](/assets/img/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou_0.png)\n\n와 미친 소리 아니야? 너가 잃을 수 있는 모든 인간 중에서, 널 부술 수도 있는 사람이 누군가가, 그게 바로 너를 완전히 해 주었던 사람들이 너를 부술 수도 있다는 게 웃기게 느껴지지 않니? 결국 널 텅 빈 채로 남기고.\n\n누군가에게 완전히 의존할 때가 가장 힘들어. 모든 것을 걸면, 그만큼 많은 것을 잃을 가능성도 높아지거든. 이 모든 것이 그만한 가치가 있었나 하는 질문이 계속 머릿속을 스쳐 지나가게 되는데, 자기가 왜 이 순간을 겪어야 하는지, 어디서부터 잘못되기 시작했는지, 단순히 언제부터 그랬는지에 대해 밤에 울고만 있게 되는 거야. 그들과 함께 있을 때 행복했던 것을 기억하게 돼. 모든 게 진심이었고, 그들이 충분했기에 남들과는 달랐어. 그러나, 인생이 닥쳐왔지. 이렇게 귀에 착착 오게 하잖아, 사람들이 와서 가기도 하고. 가장 힘든 건, 그것이 찾아올 때 예상치 못한다는 거야. 혹은 예상했다 하더라도, 상처를 주고 너를 완전히 꺾어버리겠지. 단지 아무것도 남기지 않을 거야.\n\n\"그런 게 현실이야\"가 널 위로해 줄 거지만, 동시에 네가 가장 싫어하는 말이 될 거야.\n\n<div class=\"content-ad\"></div>\n\n열심히 노력할 것이에요. 자신을 달래기 위해 그들을 잊으려고 모든 사진을 삭제하고 그들이 선물한 모든 것을 버릴 거예요. 하지만 치유하는 여정 속에서 어딘가에 그 모든 것이 무너지는 순간들이 있을 거예요. 왜냐하면 당신이 깊은 곳에 그들을 담아두었기 때문이죠. \n\n같은 사람 속에서는 같은 사람을 찾을 수 없다는 것도 사실이에요. 노력해봐도 마찬가지일 거예요. 다른 사람들과 같은 종류의 관계를 찾을 거예요, 하지만 찾지 못할 거예요. 그냥 그렇다고.\n\n이 모든 일 가운데서, 당신은 잘못된 것이 어디서 왜 그렇게 되었는지 되돌아보는 시간을 가질 거예요. 마침내 그들이 한 잘못된 행동들, 당신이 그들이 당신의 한계를 초과하는 행동을 허용했던 모든 시간, 그리고 당신이 그 문제를 해결하기 위해 울던 고통스러운 밤들을 볼 수 있을 거예요. 또한 당신의 모든 흠과 변화하려는 이유들, 마침내 자신을 받아들이려고 하거나 그 고통을 인정하기 위해 노력할 이유들도 보게 될 거예요.\n\n처음에 그들을 고치려고 했지만, 꼭 그들만큼 고쳐야 할 필요성이 있는 것을 알지 못했어요. 당신이 직면해야 할 고치기가 필요한 사람을 치유할 수 없다는 것을 우리 모두 알고 있어요.\n\n이상하게도 당신은 당신과 함께하길 원하는 많은 사람들, 당신의 안락함이 되고 싶어하는 모든 사람들을 볼 거예요. 그런데 당신은 돌아가 그 속에 담겨있는 그들과 같은 사람들과 느낌을 찾을 수 있도록 고의적으로 쳐다보지 않았던 사람들 역시 볼 거예요.\n\n좋은 점은 몇몇 사람이 떠나면 새로운 사람들도 올 거라는 거에요. 다른 성격을 가진 다른 사람일 수도 있겠지만, 당신의 마음 속 어딘가에서 그들은 당신에게 위안이 될 거에요. 그들이 이전에 함께한 익숙한 사람들과 공유했던 행복과 웃음을 가져다 주지는 않겠지만, 당신이 정말 필요로 하는 안정감을 줄 거에요.\n\n<div class=\"content-ad\"></div>\n\n수용은 부서에서 나오게 될 것입니다; 이를 어떻게 받아들이고 계속 헤엄치는 법을 배우게 될 거에요.\n\n언젠가는 괜찮아질 거에요 (정말로). 이 중요한 점은, 눈 깜짝할 사이에 지나가는 행복한 날들이 있듯이, 휙 훌쩍 지나가는 슬픈 날들도 있단 거죠.\n\n-\n\n이 글에는 제 생각과 경험이 담겨 있고, 이를 통해 여러분에게 \"놓아주고, 평화롭게 살아가\"라고 자랑스럽게 전할 수 있는 누군가의 따뜻함을 느끼게 해주기를 바랍니다. 왜냐하면 나도 어느 날 그것이 필요했었기 때문이죠.\n\n<div class=\"content-ad\"></div>\n\n두려워하는 모든 분들에게 포옹을 보내요. 언젠가는 모든 것이 이해될 거에요 :))\n\n그런데 이게 제 첫 번째로 작품을 공개하는 시도에요. 제게 어떻게든 연결되었으면 좋겠어요.","ogImage":{"url":"/assets/img/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou_0.png"},"coverImage":"/assets/img/2024-06-23-Beingbrokenbythepeoplethatalsohealedyou_0.png","tag":["Tech"],"readingTime":3},{"title":"컨볼루션 신경망CNN의 수학적 원리 분석","description":"","date":"2024-06-23 18:50","slug":"2024-06-23-TheMathBehindConvolutionalNeuralNetworks","content":"\n\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png)\n\n목차\n\n- 1: 소개\n- 2: CNN 아키텍처 뒤의 수학\n  - 2.1: 합성곱층\n  - 2.2: 스트라이드\n  - 2.3: 패딩\n  - 2.4: 다중 필터 및 깊이\n  - 2.5: 가중치 공유\n  - 2.6: 특성 맵 생성\n  - 2.7: 풀링층\n  - 2.8: 완전 연결층\n\n\n<div class=\"content-ad\"></div>\n\n- 3: CNN 구축을 위한 단계별 안내\n  - 3.1: 환경 설정\n  - 3.2: 데이터 준비\n  - 3.3: CNN 모델 설계\n  - 3.4: 모델 컴파일\n  - 3.5: CNN 훈련\n\n- 4: 모델 성능 향상\n  - 4.1: 데이터 증강\n  - 4.2: 드롭아웃\n  - 4.3: 배치 정규화\n  - 4.4: 전이 학습\n\n- 5: 결론\n\n- 추가 자료\n\n<div class=\"content-ad\"></div>\n\n# 1: 소개\n\n합성곱 신경망, 또는 CNN(Convoluntional Neural Networks)라고도 불리는 것은 이미지 처리와 관련된 작업에서 중요한 역할을 합니다. 사진 인식이나 분류와 같이 이미지와 관련된 작업을 할 때 매우 유용합니다. 그들은 사진의 패턴과 세부 사항을 자동으로 감지하는 데 아주 뛰어나기 때문에 많은 이미지를 처리하는 프로젝트에서 선호되는 선택입니다.\n\nCNN의 멋진 점은 이미지 데이터를 단순히 한 덩어리로 뭉치는 것이 아니라 이미지의 레이아웃을 유지한다는 것입니다. 이는 특정 패턴과 해당 위치를 잘 알아차릴 수 있어서 매우 유용합니다. 이 접근 방식은 이미지 처리의 어려운 부분을 훨씬 더 부드럽게 처리할 수 있도록 해줍니다.\n\nCNN의 중요한 부분 중 하나는 합성곱 레이어라는 것입니다. 이 레이어는 이미지 위를 이동하면서 선, 질감, 형태와 같은 다양한 시각적 특징을 발견할 수 있습니다. 이는 사람이 그러한 특징들을 수동으로 찾아야 했던 예전 방식을 능가합니다. 이는 작업 처리를 느리게 하고 처리 과정에서 병목현상을 야기시켰던 것과 대조됩니다. 네트워크가 스스로 이러한 특징을 찾아내도록 함으로써 CNN은 더 정확해지고, 더 단순해지며, 그리고 더 큰 범위의 이미지 관련 작업에 수월하게 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 2: CNN 아키텍처 뒤의 수학\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_1.png)\n\n합성곱 신경망(CNNs)의 아키텍처는 인간의 시각 시스템이 이미지를 처리하는 방식을 모방하도록 설계되어 있어 시각 인식 및 분류와 관련된 작업에 특히 강력합니다.\n\nCNN은 여러 유형의 레이어로 구성되어 있으며, 각 레이어는 이미지 인식 과정에서 특정 기능을 제공합니다. 주요 레이어에는 합성곱 레이어, 활성화 함수, 풀링 레이어 및 완전 연결 레이어가 포함됩니다. 이 레이어들이 함께 작동하여 CNN이 특징을 감지하고 복잡성을 줄이며 예측을 수행할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 2.1: 합성곱층\n\n합성곱층은 합성곱 신경망(CNN)의 중요한 요소로, 이미지로부터 가장자리, 질감, 모양과 같은 공간적인 특징을 자동적으로 효율적으로 추출하는 데 사용됩니다. 우리는 합성곱층이 작동하는 방식 및 내부 수학에 대해 자세히 알아보겠습니다.\n\n합성곱 연산\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_2.png)\n\n<div class=\"content-ad\"></div>\n\n합성 곱 연산의 본질은 입력 이미지 위를 필터(또는 커널)가 슬라이딩하면서 각 위치에서 필터 값과 원래 픽셀 값의 내적을 계산하는 것입니다. 필터는 일반적으로 3x3 또는 5x5 크기의 작은 가중치 행렬로, 이미지에서 특정 피쳐를 감지하기 위해 훈련됩니다.\n\n수학적으로, 합성 곱 연산은 다음과 같이 표현될 수 있습니다:\n\n![convolution equation](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_3.png)\n\n여기서:\n\n<div class=\"content-ad\"></div>\n\n- S(i,j)은 출력 피처 맵입니다.\n- I는 입력 이미지입니다.\n- K는 커널 또는 필터입니다.\n- i,j는 피처 맵 상의 좌표입니다.\n- m,n은 커널 내의 좌표입니다.\n- ∗는 합성곱 연산을 나타냅니다.\n\n이 방정식은 출력 피처 맵의 각 요소 S(i,j)가 커널 K와 현재 위치한 입력 이미지 I의 일부 사이의 요소별 곱의 합임을 알려줍니다.\n\n이제 입력 이미지로 사용될 픽셀 값 행렬을 고려해 봅시다. 그것이 흑백 이미지인 경우 (위 이미지), 행렬은 단일 레이어를 가지게 될 것입니다. 컬러 이미지의 경우에는 일반적으로 세 개의 레이어 (RGB)가 있지만, 연산은 각 레이어마다 별도로 수행됩니다.\n\n합성곱 연산은 행렬에 커널(필터)을 적용합니다. 여기서 커널은 입력 이미지보다 작은 다차원 행렬이며 사전에 정의된 차원 (예: 3x3)을 가지고 있습니다. 이 행렬의 값은 훈련 과정 중에 학습되는 가중치입니다. 커널은 입력 이미지 전체를 걸어다니면서 요소별 곱셈을 수행하고 합을 구합니다.\n\n<div class=\"content-ad\"></div>\n\n컨볼류션 연산에서는 출력 특성 맵을 얻게 됩니다. 이는 커널이 입력 이미지의 특정 위치에서 감지한 특징의 존재와 강도를 나타내는 새로운 행렬입니다.\n\n## 2.2: 스트라이드\n\n![스트라이드](https://miro.medium.com/v2/resize:fit:1280/1*OlE3bnC0WaYt3wW1dlcMdA.gif)\n\n스트라이드는 CNN 아키텍처에서 중요한 개념입니다. 특히 컨볼루션 레이어 내에서 핵심적으로 작용합니다. 이는 커널이 입력 이미지나 특성 맵을 횡단하는 방식에 근본적인 영향을 미칩니다.\n\n<div class=\"content-ad\"></div>\n\nStride는 필터가 입력 이미지나 피쳐 맵을 한 단계씩 이동하는 픽셀 수를 나타냅니다. 수평 및 수직으로 모두 적용됩니다. Stride가 1이면 필터가 한 번에 한 픽셀씩 이동하여 입력을 자세하고 밀도 있게 스캔합니다. 더 큰 Stride는 필터가 픽셀을 건너뛰며 입력을 스캔하므로 더 넓고 밀도가 낮은 범위로 이어집니다.\n\nStride는 출력 피쳐 맵의 차원을 결정하는 데 직접적인 역할을 합니다:\n\n- Stride가 1인 경우: 필터가 모든 픽셀을 횡단하여 출력 피쳐 맵이 패딩에 따라 상대적으로 크거나 입력과 유사한 크기가 될 수 있습니다. 패딩에 대해 다음 섹션에서 설명하겠습니다.\n- 더 큰 Stride인 경우: 필터가 픽셀을 건너뛰면 입력을 적은 단계로 이동합니다. 이로 인해 출력 피쳐 맵이 작아지며 각 단계에서 필터가 적용되는 위치 간의 오버랩이 적어집니다.\n\n수학적 표현\n출력 피쳐 맵의 크기 (W_out, H_out)는 입력 크기 (W_in, H_in), 필터 크기 (F), Stride (S), 패딩 (P)을 사용하여 다음 공식을 사용하여 계산할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_4.png\" />\n\n여기서:\n\n- W_out 및 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\n- W_in 및 H_in은 각각 입력의 너비와 높이입니다.\n- F는 필터의 크기입니다.\n- S는 스트라이드입니다.\n- P는 패딩입니다.\n\n더 큰 스트라이드는 필터의 각 응용 영역의 시야를 증가시켜 네트워크가 더 적은 매개변수로 입력의 더 많은 전역적인 특성을 포착할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n사용하는 스트라이드를 크게 하면 출력 특성 맵의 크기를 줄이기 때문에 계산 부하와 메모리 사용량이 감소하며, 따라서 필요한 합성 곱 연산 수도 줄어듭니다.\n\n공간 해상도와 커버리지 사이에는 교환관계가 있습니다. 작은 스트라이드는 공간 해상도를 보존하고 섬세한 특징을 탐지하는 데 더 좋지만, 큰 스트라이드는 디테일을 희생하면서 입력의 넓은 영역을 다룰 수 있습니다.\n\n## 2.3: 패딩\n\n패딩은 출력 특성 맵의 공간적 차원을 조절하여 네트워크의 아키텍처를 형성하는 데 중요한 역할을 합니다.\n합성 곱 연산을 적용하기 전에 입력 이미지나 특성 맵의 가장자리 주위에 제로(또는 다른 값들이지만 일반적으로 제로입니다)의 레이어를 추가하는 것을 포함합니다. 이 기법은 다양한 이유로 적용될 수 있으며, 가장 중요한 이유는 출력 특성 맵의 크기를 제어하고 합성 곱 필터가 입력의 가장자리 픽셀에 접근할 수 있도록 하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n그래서, 이제 우리의 입력 이미지는 다음과 같이 보일 것입니다:\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1280/1*VwOf7sD87Yw9P1215NngRQ.gif\" />\n\n이전의 8x8 행렬이 이제 10x10 행렬로 바뀐 것을 볼 수 있습니다. 우리는 주변에 0으로 된 레이어를 추가했기 때문입니다.\n\n패딩이 없으면 각 합성곱 연산이 피처 맵의 크기를 줄입니다. 패딩을 사용하면 입력에 필터를 적용하여 공간적 차원을 줄이지 않고 더 많은 정보를 보존할 수 있습니다. 특히 많은 합성곱 계층이 순차적으로 적용되는 심층 네트워크에서 더 많은 정보를 보존할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n입력을 패딩함으로써 필터가 이미지의 가장자리 픽셀을 적절하게 처리하여 네트워크의 학습 과정에서 경계에 위치한 특징을 충분히 캡처하고 활용할 수 있습니다.\n\n패딩에는 주로 두 가지 유형이 있습니다:\n\n**Valid Padding (패딩 없음)**\n이 경우 입력에 패딩이 적용되지 않습니다. 필터가 입력의 한계 내에 완전히 맞는 곳에서만 합성곱 작업이 수행됩니다. 이로 인해 일반적으로 출력 피처 맵 크기가 줄어듭니다.\n\n**Same Padding (동일 패딩)**\n동일 패딩의 경우 입력 가장자리에 충분한 수의 제로(0)가 추가되어 출력 피처 맵이 입력과 동일한 차원을 갖도록 합니다(스트라이드가 1인 경우). 이는 입력과 출력 크기가 일관성 있게 유지되어야 하는 네트워크를 설계하는 데 특히 유용합니다.\n\n<div class=\"content-ad\"></div>\n\n가장자리에 패딩을 추가하는 것이 출력 특성 맵 크기에 미치는 영향은 출력 특성 맵의 차원을 계산하는 데 사용되는 공식을 조정함으로써 파악할 수 있습니다:\n\n\nW_out = (W_in - F + 2P) / S + 1\nH_out = (H_in - F + 2P) / S + 1\n\n\n여기서:\n\n- W_out과 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\n- W_in과 H_in은 각각 입력의 너비와 높이입니다.\n- F는 필터/커널의 크기입니다.\n- S는 스트라이드입니다.\n- P는 입력의 각 측면에 추가된 패딩의 양입니다.\n\n<div class=\"content-ad\"></div>\n\n패딩은 층을 통해 입력의 공간 차원을 유지하는 데 도움이 됩니다. 그러나 과도한 패딩은 계산의 비효율성을 야기하고 모델의 복잡성이 증가할 수 있습니다. 비의미 있는 입력(제로)을 계산에 추가함으로써 비효율성을 가져올 수 있습니다.\n\n유효 패딩과 동일 패딩 사이의 선택은 주로 응용 프로그램의 특정 요구 사항에 따라 달라지며, 입력의 공간 차원을 보존하는 중요성이나 계산 오버헤드를 최소화해야 하는 필요성에 따라 결정됩니다.\n\n## 2.4: 다중 필터와 깊이\n\nCNN은 각 합성곱 층에서 여러 필터를 사용하여 입력 이미지나 특징 맵에서 다양한 특징을 캡처합니다. 이 다양성과 깊이는 네트워크가 시각 정보를 포괄적이고 세심하게 처리할 수 있는 능력에 중요한 역할을 합니다.\n\n<div class=\"content-ad\"></div>\n\n컨볼루션 레이어의 각 필터는 입력에서 엣지, 색상, 질감 또는 더 깊은 레이어에서는 더 복잡한 모양과 같은 다양한 특징이나 패턴을 감지하도록 설계되어 있습니다. 여러 필터를 사용함으로써 CNN은 각 레이어에서 동시에 다양한 특징을 찾아 입력 데이터의 표현을 보다 풍부하게 만들 수 있습니다.\n\n여러 필터를 사용한 컨볼루션 레이어의 출력은 각 필터에 대해 하나의 특징 맵으로 이루어진 스택입니다. 이 스택은 깊이가 사용된 필터의 수와 대응되는 3차원 볼륨을 형성합니다. 이 깊이는 데이터의 계층적인 표현을 구축하는 데 중요하며, 이전 레이어의 출력을 결합하여 점점 추상적인 특징을 감지할 수 있게 합니다.\n\n여러 필터가 깊이를 어떻게 실현하는가\n입력 이미지 또는 특징 맵이 처리됨에 따라 각 필터는 이를 슬라이딩하여 컨볼루션 작업을 수행합니다. 동일한 입력을 공유하더라도 각 필터는 고유한 가중치를 적용하여 서로 다른 측면을 강조하는 서로 다른 특징 맵을 생성합니다.\n\n각 필터가 생성한 개별 특징 맵은 깊이 차원을 따라 쌓이며, 3D 볼륨을 형성합니다. 이 볼륨은 필터에 의해 감지된 다양한 특징을 포용하여 입력의 풍부하고 다면적인 표현을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n합성곱 레이어의 깊이는 필터의 수에 의해 결정되며, 네트워크가 넓은 특징 스펙트럼을 포착할 수 있게 합니다. 초기 레이어는 가장자리와 질감과 같은 기본적인 특징을 포착할 수 있지만, 더 깊은 레이어는 이러한 기본적인 특징을 결합하여 복잡한 패턴을 해석할 수 있게 되며, 이는 네트워크의 깊이 덕분입니다.\n\n깊이의 영향\n더 많은 필터는 복잡한 특징을 학습할 수 있는 용량이 높은 더 깊은 네트워크를 의미합니다. 그러나 이는 또한 네트워크의 계산 복잡성과 효과적으로 학습하기 위해 필요한 데이터 양을 증가시킵니다.\n\n각 필터는 모델에 매개변수를 추가합니다(필터를 정의하는 가중치). 더 많은 필터는 네트워크의 표현력을 높이지만, 총 매개변수 수를 증가시켜 학습 효율성과 과적합의 위험에 영향을 미칠 수 있습니다.\n\n레이어 간 필터 할당은 전략적입니다. 입력에 가까운 레이어는 더 적고 일반적인 필터를 가질 수 있지만, 더 깊은 레이어는 데이터 내에서 고차원 특징의 복잡성과 변이를 포착하기 위해 더 많은 필터를 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 2.5: Weight Sharing\n\nWeight sharing(가중치 공유)는 특히 시각적 정보를 처리할 때 CNN의 효율성과 효과를 현저히 향상시킵니다. 이 개념은 모델이 입력 이미지의 공간적 위치와 관계없이 특징을 감지할 수 있도록 핵심적입니다.\n\nCNN의 맥락에서, 가중치 공유란 동일한 필터(즉, 동일한 가중치 세트)를 전체 입력 이미지나 특징 맵에 걸쳐 사용하는 것을 의미합니다. 모든 가능한 위치에 대해 고유한 가중치 세트를 학습하는 대신 단일 필터가 전체 이미지를 스캔하며 각 위치에서 동일한 가중치를 적용합니다. 이 작업은 합성곱 레이어의 각 필터에서 반복됩니다.\n\n입력 이미지의 서로 다른 부분에서 동일한 가중치 세트를 재사용함으로써, 가중치 공유는 모델의 매개변수 수를 급격하게 줄입니다. 이로 인해 CNN은 특히 큰 입력 크기를 다룰 때 완전히 연결된 네트워크에 비해 매개변수 효율성이 훨씬 뛰어납니다.\n\n<div class=\"content-ad\"></div>\n\nWeight sharing은 네트워크가 입력 이미지의 위치에 관계없이 특징을 감지할 수 있도록 합니다. 필터가 에지나 특정 패턴을 인식하는 방법을 학습하면 이미지의 어느 곳에서든 해당 특징을 감지할 수 있으므로 CNN은 기본적으로 변환 불변성을 갖습니다.\n\n학습할 매개변수가 적어지므로, CNN은 학습 데이터에 과적합될 가능성이 적어집니다. 이는 모델이 학습 데이터에서 실제로 관측되는 데이터로 일반화하는 능력을 향상시킴으로써, 실제 과제에서의 성능을 향상시킵니다.\n\nWeight Sharing 작동 방식\n순방향 전파 중에, 고정된 가중치 세트를 가진 필터가 입력 이미지를 슬라이드하며, 필터 가중치와 이미지의 지역 영역 간의 내적을 계산합니다. 이 과정은 이미지의 공간적 범위에 걸쳐 감지된 특징의 존재 및 강도를 나타내는 특징 맵을 생성합니다.\n\n공간적 영역 전체에 걸쳐 가중치를 광범위하게 재사용하지만, 각각의 가중치는 적용된 위치의 모든 위치에서의 총 그래디언트를 기반으로 업데이트됩니다. 이를 통해 필터 가중치가 작업에 가장 관련성 있는 특징을 감지하도록 최적화되어, 전체 데이터셋을 기반으로 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 2.6: 피처 맵 생성\n\n이전에 보았던 대로, 피처 맵은 CNN 내에서 입력 이미지나 이전 피처 맵에 필터나 커널을 적용하여 생성된 출력입니다. 입력의 공간 차원에 걸쳐 필터의 반응을 나타내며, 이미지에서 특정 피처가 어디에 어떻게 감지되었는지를 강조합니다. 이제 각 요소가 어떻게 CNN의 결과 피처 맵에 영향을 미치는지 다시 살펴봅시다.\n\n피처 맵 생성의 핵심은 컨볼루션 연산에 있습니다. 여기서 학습된 가중치를 가진 필터가 입력 이미지나 이전 레이어의 피처 맵을 이전하며 슬라이딩(또는 합성)합니다. 각 위치에서 필터는 이미지의 해당 부분과 요소별 곱셈을 수행하고 결과를 합산하여 새로운 피처 맵의 단일 출력 픽셀을 생성합니다.\n\n필터의 가중치는 엣지, 질감 또는 더 깊은 레이어에서 더 복잡한 패턴과 같은 피처 유형을 감지합니다. 훈련 중에 이 가중치는 역전파를 통해 조정되어 네트워크가 주어진 작업에 가장 중요한 피처를 학습할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n스트라이드의 크기와 패딩의 사용은 특징 맵의 공간적 차원에 직접적인 영향을 미칩니다. 더 큰 스트라이드는 필터 적용 사이의 중첩을 줄이는 보다 넓은 범위의 적용을 유도하여 특징 맵의 크기를 줄입니다. 패딩은 입력의 공간적 차원을 보존하기 위해 사용되며 이미지의 가장자리에 있는 특징이 손실되지 않도록 보장합니다.\n\n합성곱 레이어는 일반적으로 여러 필터를 포함하며, 각각은 다른 특징을 감지하도록 설계됩니다. 각 필터의 출력은 별도의 특징 맵이며, 이러한 특징 맵은 깊이 차원을 따라 쌓여 3차원 볼륨을 만듭니다. 이 다각적인 방식은 네트워크가 입력 이미지의 풍부한 표현을 포착할 수 있도록 합니다.\n\n합성곱 작업을 통해 특징 맵이 생성된 후에는 주로 ReLU와 같은 활성화 함수를 통과합니다. 이는 비선형성을 도입하여 네트워크가 보다 복잡한 패턴을 학습하고 표현할 수 있게 합니다.\n\nReLU와 다른 활성화 함수에 대해 더 알고 싶다면, 이 기사를 확인해보세요:\n\n<div class=\"content-ad\"></div>\n\n활성화된 피처 맵은 다음 계층 또는 풀링 작업으로 진행됩니다.\n\n## 2.7: 풀링 레이어\n\n풀링 레이어는 피처 맵의 공간 차원을 줄이는 역할을 합니다. 이 감소는 계산 부하를 줄이고, 오버피팅을 최소화하며, 가장 중요한 정보만을 보존하는 데 중요합니다. 풀링 레이어의 구체적인 내용, 유형 및 CNN 성능에 미치는 영향에 대해 알아봅시다.\n\n풀링 레이어는 피처 맵의 크기를 줄여 망에 필요한 매개변수 및 계산을 줄입니다. 이 간소화는 가장 중요한 특성에 집중하는 데 도움이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n특징 맵의 패치에서 특징의 존재를 요약함으로써, 풀링은 네트워크가 입력 이미지의 작은 변동 및 변환에 강건함을 유지하는 데 도움이 됩니다.\n\nCNN을 다룰 때 알아야 할 몇 가지 종류의 풀링 기술이 있습니다:\n\n최대 풀링\n이것은 가장 일반적인 풀링 형태로, 특징 맵의 값 집합에서 최대값이 선택되어 다음 레이어로 전달됩니다. 최대 풀링은 특징 맵의 각 패치에서 가장 현저한 특징을 효과적으로 포착합니다.\n\n우리는 특징 맵을 F로, 풀링 작업을 P_max로 표시하며, 크기가 n×n인 창으로 위치 (i,j)에서의 최대 풀링 결과는 다음과 같이 표현될 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_6.png)\n\n여기서 s는 풀링 윈도우의 보폭이며, a, b는 윈도우 차원을 반복합니다. 이 작업은 특성 맵을 가로지르는 각 윈도우 위치에 독립적으로 적용됩니다.\n\n평균 풀링\n최대 풀링과 달리 평균 풀링은 특성 맵의 각 패치에서 값의 평균을 취합니다. 이 방법은 보다 일반화된 특성 표현을 제공하지만, 더 작지만 의미 있는 특성의 영향을 약화시킬 수 있습니다.\n\n특성 맵 F와 n×n 풀링 윈도우에 대해 위치 (i,j)에서의 평균 풀링 연산은 수학적으로 다음과 같이 표현될 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_7.png)\n\n맥스 풀링과 유사하게, s는 스트라이드를 나타내며, a,b는 창을 순회하는 반면, 이 연산에서는 각 창 내 값들의 평균을 계산합니다.\n\n글로벌 풀링\n글로벌 풀링에서는 전체 피처 맵이 각각 맥스(글로벌 맥스 풀링) 또는 평균(글로벌 평균 풀링)을 취함으로써 하나의 값으로 축소됩니다. 이 접근 방식은 종종 각 피처 맵을 완전 연결 레이어 이전에 하나의 값으로 줄이는 데 사용됩니다.\n\n크기가 M×N인 피처 맵 F에 대해, 글로벌 맥스 풀링 (P_gmax) 및 글로벌 평균 풀링 (P_gavg)은 다음과 같이 정의될 수 있습니다:\n\n\n<div class=\"content-ad\"></div>\n\n\n![Global pooling operations](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_8.png)\n\n전역 풀링 연산은 전체 피쳐 맵을 하나의 요약 통계치로 압축하는데 사용되며, 이는 분류를 위한 완전 연결 레이어 이전에 모델 파라미터를 줄이는 데 특히 유용합니다.\n\n풀링 동작 방식\n풀링 레이어는 각 피쳐 맵에 독립적으로 작동하며, 피쳐 맵을 가로지르면서 창(또는 필터)을 슬라이딩하고 해당 창 내의 값을 요약하여 한 가지 값으로 줄입니다 (사용된 풀링 전략에 따라). 이 과정은 피쳐 맵의 공간 차원을 줄입니다.\n\n창의 크기와 스트라이드(창이 한 번에 이동하는 거리)는 피쳐 맵이 얼마나 줄어드는지를 결정합니다. 흔히 선택하는 것은 2x2 창과 스트라이드 2인 경우인데, 이는 피쳐 맵의 크기를 절반으로 줄입니다.\n\n\n<div class=\"content-ad\"></div>\n\n## 2.8: 완전 연결층\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_9.png)\n\n완전 연결층은 CNN의 끝쪽에 자주 위치합니다. 이 층들은 학습된 특징에 기반한 고수준 추론이 이루어지는 곳으로, 궁극적으로는 분류나 예측으로 이어집니다.\n\n완전 연결층에서는 각 뉴런이 이전 층의 모든 활성화에 연결됩니다. 이 밀집된 연결은 층이 추출된 특징들의 전체 맥락을 갖게 해주어, 특징 맵 전체에 분산된 복잡한 패턴을 학습할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n완전 연결 계층은 합성곱 및 풀링 계층에서 식별된 공간적으로 분산된 특징을 전체 입력의 전역 표현으로 통합합니다. 이 통합은 분류와 같은 전체 입력을 이해해야 하는 작업에 중요합니다.\n\n합성곱에서 완전 연결 계층으로\n완전 연결 계층에 진입하기 전에, 이전 합성곱이나 풀링 계층의 출력(일반적으로 다차원 특징 맵)이 하나의 벡터로 평평하게 변환됩니다. 이 단계는 공간 구조화된 데이터를 완전 연결 계층에서 처리할 수 있도록 포맷을 변환합니다.\n\n완전 연결 계층의 뉴런들은 평평한 특징 맵에 의해 제시된 전역 정보를 고려함으로써 데이터에서 고수준 패턴을 학습할 수 있습니다. 이 능력은 전체 입력 이미지를 기반으로 한 예측이나 분류를 만드는 데 기본적입니다.\n\nCNN에서의 역할\n많은 CNN 아키텍처에서 최종 완전 연결 계층은 분류 계층으로 기능하며, 각 뉴런은 특정 클래스를 나타냅니다. 네트워크의 예측은 일반적으로 이러한 뉴런들의 활성화에 의해 결정되며, 활성화를 확률로 변환하는 소프트맥스 함수를 통해 수행됩니다.\n\n<div class=\"content-ad\"></div>\n\n합성곱 레이어에 의해 추출된 지역화된 추상적인 특징을 완전 연결 레이어가 입력 데이터의 일관된 이해로 합성합니다. 이러한 합성은 네트워크가 입력에 대해 전체적으로 추론하고 판단을 내릴 수 있도록 중요합니다.\n\n# 3: CNN 구축 단계별 안내서\n\n이제 비즈니스 쪽으로 가지고 CNN을 구축해 봅시다. MNIST 데이터셋에서 손으로 쓴 숫자의 이미지 분류를 위해 PyTorch를 사용하여 합성곱 신경망(CNN)을 설정하고 훈련 및 평가할 것입니다. [MNIST 데이터셋은 Creative Commons Attribution-Share Alike 3.0 라이선스 조건 하에 제공됩니다]\n\n오늘 다룰 모든 코드가 포함된 Jupyter Notebook을 참고하시기 바랍니다:\n\n<div class=\"content-ad\"></div>\n\n## 3.1: 환경 설정하기\n\n필요한 라이브러리와 모듈을 준비해봅시다. 신경망을 구축하고 훈련하기 위해 PyTorch (torch)와 이를 위한 신경망 모듈 (nn), 최적화 모듈 (optim)이 불러와집니다. torch.nn.functional에서 ReLU 활성화 및 최대 풀링과 같은 작업에 사용되는 기능이 제공됩니다. DataLoader 유틸리티를 통해 배치 처리와 데이터 관리를 용이하게 할 수 있고, torchvision은 데이터셋 및 이미지 변환을 위해 사용됩니다.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n``` \n\n## 3.2: 데이터 준비하기\n\n<div class=\"content-ad\"></div>\n\nMNIST 데이터셋은 이미지를 텐서 형식으로 변환한 후 픽셀 값을 정규화하는 변환 파이프라인으로 로드됩니다. 정규화 매개변수(평균=0.1307, 표준편차=0.3081)는 MNIST 데이터셋에 특별히 선택되어 그레이스케일 이미지를 표준화하여 신경망의 성능을 최적화합니다.\n\n```js\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\nmnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n```\n\n데이터셋에서의 샘플 이미지를 matplotlib을 사용하여 표시하여, 네트워크가 훈련될 데이터 유형을 시각적으로 보여줍니다.\n\n```js\nimage, label = mnist_dataset[0]\nplt.imshow(image.squeeze().numpy(), cmap='gray')\nplt.title(f'Label: {label}')\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n다음 이미지가 표시됩니다:\n\n<img src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_10.png\" />\n\n데이터셋은 모델 훈련 중에 효율적인 처리를 위해 배치 처리, 셔플링, 데이터셋 준비를 다루는 DataLoader 인스턴스에 의해 훈련 및 검증 세트로 나누어집니다.\n\n```js\ntrain_size = int(0.8 * len(mnist_dataset))\nval_size = len(mnist_dataset) - train_size\ntrain_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n```\n\n<div class=\"content-ad\"></div>\n\n## 3.3: CNN 모델 설계\n\n데이터 전처리를 한 후에 모델을 만들어 보겠습니다. 따라서 nn.Module에서 상속된 MyCNN 클래스를 초기화합니다. 이 상속은 PyTorch에서 모델을 정의하는 방법입니다. 이 상속을 통해 MyCNN은 PyTorch 모델의 모든 기능을 갖추게 되며, 훈련, 예측 등이 가능해집니다.\n\n__init__ 함수는 MyCNN 클래스의 생성자입니다. 이 함수에서 신경망의 층들이 정의됩니다. super(MyCNN, self).__init__() 라인은 기본 nn.Module 클래스의 생성자를 호출하는데, 이는 PyTorch가 모든 것을 올바르게 초기화하기 위해 필요합니다.\n\n```python\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(7*7*64, 128)\n        self.fc2 = nn.Linear(128, 10)\n```\n\n<div class=\"content-ad\"></div>\n\n위의 코드에서 볼 수 있듯이, 이 네트워크에는 conv1과 conv2 두 개의 합성곱 레이어가 포함되어 있습니다.\n\nconv1은 단일 채널 이미지(회색조 이미지와 같은)를 입력으로 받아 3x3 필터(또는 커널) 크기와 1의 스트라이드, 1의 패딩을 사용하여 32개의 특성 맵을 생성합니다. 패딩은 출력 특성 맵이 입력과 동일한 크기로 유지되도록 추가됩니다.\n\nconv2는 conv1에서 32개의 특성 맵을 입력으로 받아 3x3 커널, 1의 스트라이드, 1의 패딩을 사용하여 64개의 특성 맵을 생성합니다. 이 레이어는 conv1에서 제공된 입력으로부터 특성을 더 추출합니다.\n\n합성곱 레이어 이후에는 두 개의 완전 연결(fc) 레이어가 있습니다.\n\n<div class=\"content-ad\"></div>\n\nfc1은 합성곱 레이어의 출력을 크기 128의 벡터로 변환하는 첫 번째 완전 연결 레이어입니다. 입력 크기는 7*7*64이며, 이는 이 레이어에 도달하기 전에 특성 맵이 단일 벡터로 펼쳐지며, 평탄화되기 전의 특성 맵의 차원이 7x7이고 64개 채널임을 의미합니다. 이 단계는 공간 특성 추출에서 해당 특성을 기반으로 결정(분류)을 내리는 것으로 전환하는 데 중요합니다.\n\nfc2는 두 번째 완전 연결 레이어로, fc1에서 가져온 128차원 벡터를 가져와 10차원 벡터를 출력합니다. 이 출력 크기는 일반적으로 분류 문제의 클래스 수에 해당하며, 이 네트워크가 이미지를 10가지 범주 중 하나로 분류하는 방식으로 설계되었음을 시사합니다.\n\n```js\ndef _initialize_weights(self):\n    for m in self.modules():\n        if isinstance(m, nn.Conv2d):\n            nn.init.normal_(m.weight, 0, 0.01)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n```\n\n가중치 초기화는 네트워크가 경사도를 사라지게 하거나 폭발시키지 않는 범위의 가중치로 시작하도록 보장하기 위해 적용됩니다. 합성곱 레이어는 정규 분포로 초기화되고, 완전 연결 레이어는 Xavier 균일 분포 초기화를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n제 이전 글에서 자비에 초기화 및 다른 유형의 초기화에 대해 더 알아보고 싶다면 확인해보세요:\n\nMyCNN 클래스의 forward 메서드는 입력 데이터가 CNN을 통과하면서 겪는 작업 순서를 정의합니다.\n\n```js\ndef forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = F.max_pool2d(x, 2, 2)\n    x = F.relu(self.conv2(x))\n    x = F.max_pool2d(x, 2, 2)\n    x = x.view(x.size(0), -1)\n    x = F.relu(self.fc1(x))\n    x = self.fc2(x)\n    return x\n```\n\n이 메서드를 단계별로 살펴보며, 각 작업에 중점을 두고 입력 이미지가 출력 예측으로 어떻게 변환되는지 이해해봅시다.\n\n<div class=\"content-ad\"></div>\n\n첫 번째 합성곱 레이어\n\n```js\nx = F.relu(self.conv1(x))\n```\n\n이 합성곱 레이어 (conv1)를 통과하는 입력 텐서 x은 이미지의 일괄 처리를 나타냅니다. 이 레이어는 입력에 학습된 필터를 적용하여 가장자리와 질감 같은 기본 시각적 특징을 캡처합니다. 합성곱 연산 다음에 바로 인플레이스로 ReLU 활성화 함수가 적용됩니다. ReLU는 출력 텐서의 모든 음의 값을 제로로 설정하여 네트워크가 특징을 구별하는 능력을 향상시킵니다.\n\n첫 번째 풀링 연산\n\n<div class=\"content-ad\"></div>\n\n\n```js\nx = F.max_pool2d(x, 2, 2)\n```\n\n첫 번째 합성곱 및 활성화를 거친 후 최대 풀링 작업이 적용됩니다. 이 작업은 풀 크기와 스트라이드로 인해 피쳐 맵의 공간 차원을 절반으로 줄입니다. 이는 피쳐 맵의 2x2 패치 내에서 가장 중요한 피쳐를 요약하는 역할을 합니다. 최대 풀링은 표현을 작은 이동 및 왜곡에 대해 다소 불변하게 만들어줍니다.\n\n두 번째 합성곱 층\n\n```js\nx = F.relu(self.conv2(x))\n```    \n\n\n<div class=\"content-ad\"></div>\n\n두 번째 합성곱층(conv2)으로 반복 과정이 진행됩니다. 여기서는 이제 축소된 특징 맵에 새로운 필터 세트를 적용합니다. 이 층은 일반적으로 첫 번째 층에서 식별된 기본 패턴을 기반으로 한 더 복잡한 특징을 포착합니다. 다시 한 번 ReLU 활성화가 이어져 비선형성을 유지합니다.\n\n두 번째 풀링 작업\n\n```js\nx = F.max_pool2d(x, 2, 2)\n```\n\n다른 최대 풀링 단계를 통해 결과 특징 맵의 공간적 차원이 더욱 줄어들어 특징 표현을 간결화하고 후속 층의 계산 복잡성을 줄입니다.\n\n<div class=\"content-ad\"></div>\n\n펼치기\n\n```js\nx = x.view(x.size(0), -1)\n```\n\n전체 연결 계층으로 넘어가기 전에 다차원 특징 맵을 배치 내 각 이미지에 대해 단일 벡터로 펼쳐야 합니다. 이 작업은 텐서를 다시 구성하여 각 이미지의 특징 맵이 텐서의 단일 행이 되도록 만들며, 완전 연결 처리에 적합한 형식으로 모든 특징 정보를 보존합니다.\n\n첫 번째 완전 연결 계층\n\n<div class=\"content-ad\"></div>\n\n```js\nx = F.relu(self.fc1(x))\n```\n\n평탄화된 텐서는 첫 번째 완전 연결 계층(fc1)을 통과하여 전체 특징 집합에서 복잡한 패턴을 학습할 수 있습니다. ReLU 함수가 한 번 더 적용되어 비선형성을 도입하고, 네트워크가 더 복잡한 함수를 학습하고 표현할 수 있도록 합니다.\n\n두 번째 완전 연결 계층 (출력 계층)\n\n```js\nx = self.fc2(x)\n```\n\n<div class=\"content-ad\"></div>\n\n마침내, 텐서는 출력 레이어 역할을 하는 두 번째 완전 연결 레이어(FC2)를 통과합니다. 이 레이어에는 예측할 클래스 수와 동일한 수의 뉴런이 있습니다(MNIST 숫자의 경우 10개). 이 레이어의 출력은 네트워크가 각 클래스에 대해 예측한 값을 나타냅니다.\n\n## 3.4: 모델 컴파일\n\n모델은 CrossEntropyLoss로 분류되어 있고 Adam 옵티마이저를 사용하여 가중치를 조정하며, 학습률 및 가중치 감소와 같은 특정 매개변수도 함께 사용하여 컴파일됩니다.\n\n```js\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5, amsgrad=True, eps=1e-8, betas=(0.9, 0.999))\n```\n\n<div class=\"content-ad\"></div>\n\nAdam 옵티마이저는 딥러닝 모델을 훈련하는 인기 알고리즘으로, AdaGrad와 RMSProp 알고리즘의 최상의 특성을 결합하여 소음이 있는 문제에서 희소한 그래디언트를 효율적으로 처리합니다. 이는 매개변수별로 학습률을 조정하여 광범위한 작업과 모델에 매우 효과적이고 적합합니다. Adam에 대해 더 자세히 알고 싶다면, 수학적인 내용을 검토하고 처음부터 구축한 내 기사를 살펴보세요:\n\n## 3.5: CNN 훈련\n\n제공된 로직의 Trainer 클래스는 CNN 모델을 훈련하는 데 필요한 필수 기능을 포함하고 있습니다. 이는 순방향 패스, 역방향 패스(그래디언트 계산 및 가중치 업데이트), 훈련 및 검증 손실 모니터링, 조기 중단 구현, 학습률 조정, 그리고 모델 성능 평가를 포함합니다. 이 클래스를 분석하여 구조와 기능을 깊이 이해해 봅시다.\n\n\n\n```python\nclass Trainer:\n    def __init__(self, model, criterion, optimizer, device, patience=7):\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.device = device\n        self.early_stopping = EarlyStopping(patience=patience)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=3, verbose=True, factor=0.5, min_lr=1e-6)\n        self.train_losses = []\n        self.val_losses = []\n        self.gradient_norms = []\n```\n\n<div class=\"content-ad\"></div>\n\n초기화 메서드인 __init__에서 Trainer 클래스는 CNN 모델, 손실 함수(criterion), 옵티마이저와 함께 CPU 또는 GPU에서 학습할 장치와 조기 종료를 위한 인자로 받습니다. EarlyStopping 인스턴스는 검증 손실을 모니터링하고 모델이 더 이상 개선되지 않을 경우 훈련을 중지하여 과적합을 방지합니다. 학습률 스케줄러(ReduceLROnPlateau)도 초기화되어 검증 손실을 기반으로 학습률을 동적으로 조정하여 훈련 중에 최적의 학습률을 찾도록 도와줍니다. 분석 및 디버깅 목적으로 학습 및 검증 손실 및 그레이디언트 노름을 추적하기 위한 리스트가 초기화됩니다.\n\n```js\ndef train(self, train_loader, val_loader, epochs):\n    for epoch in range(epochs):\n        self.model.train()\n        for images, labels in train_loader:\n            images, labels = images.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            loss = self.criterion(outputs, labels)\n            self.train_losses.append(loss.item())\n            loss.backward()\n            self.optimizer.step()\n```\n\ntrain 메서드는 지정된 에폭 수에 대한 학습 프로세스를 조율합니다. 각 에폭마다 모델을 훈련 모드로 설정하고 train_loader를 사용하여 학습 데이터셋을 반복합니다. 입력 이미지와 레이블을 지정된 장치로 이동시킵니다. 옵티마이저의 그라디언트는 이전 반복에서의 누적을 방지하기 위해 각 순방향 패스 전에 0으로 초기화됩니다. 모델의 예측을 얻고, 지정된 criterion을 사용하여 손실을 계산합니다. 손실 값은 추적을 위해 train_losses 리스트에 추가됩니다. loss.backward()를 호출하여 역전파를 수행하고, 옵티마이저는 optimizer.step()로 모델 가중치를 업데이트합니다.\n\n```js\nval_loss = self.evaluate(val_loader)\nself.val_losses.append(val_loss)\nself.scheduler.step(val_loss)\nself.early_stopping(val_loss)\n```\n\n<div class=\"content-ad\"></div>\n\n훈련 데이터를 처리한 후 모델은 평가 메서드를 사용하여 검증 데이터셋에서 평가되며, 평균 검증 손실을 계산합니다. 이 손실은 학습률을 조정하고 조기 종료 조건이 충족되었는지 확인하는 데 사용됩니다. 검증 손실은 분석을 위해 추적됩니다.\n\n```js\nif self.early_stopping.early_stop:\n    print(\"조기 종료\")\n    break\n```\n\n조기 종료가 발생하면, 과적합을 방지하기 위해 훈련이 중지됩니다. 이 결정은 인내 매개변수로 정의된 여러 epoch 동안 검증 손실이 향상되지 않았는지에 따라 기반으로 합니다.\n\n```js\ndef evaluate(self, test_loader):\n    self.model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(self.device), labels.to(self.device)\n            outputs = self.model(images)\n            loss = self.criterion(outputs, labels)\n            total_loss += loss.item()\n    return total_loss / len(test_loader)\n```\n\n<div class=\"content-ad\"></div>\n\nevaluate 메서드는 모델의 가중치를 업데이트하지 않고 유효성 검사 또는 테스트 데이터셋에서 평균 손실을 계산합니다. 이 메서드는 모델을 평가 모드로 설정하고 효율성을 위해 그래디언트 계산을 비활성화합니다.\n\n# 4: 모델 성능 향상\n\n합성곱 신경망(CNN)의 성능을 개선하고 과적합을 방지하는 것은 딥러닝 모델을 교육하는 중요한 도전 과제입니다. 제공된 코드 스니펫은 데이터 증가, 드롭아웃, 배치 정규화와 같은 기술에 대해 명시적으로 설명하지 않으며 전이 학습에 대해서도 다루지 않습니다. 그러나 이러한 전략들은 CNN을 향상시키는 데 중요하므로 이들이 훈련 과정에 통합되고 모델 성능에 미치는 잠재적인 영향에 대해 알아봅시다.\n\n## 4.1: 데이터 증가\n\n<div class=\"content-ad\"></div>\n\n데이터 증가는 기존 이미지에 임의의 변환(회전, 뒤집기, 크기 조정 등)을 적용하여 학습 데이터셋의 다양성을 인위적으로 증가시킵니다. 이 다양성은 모델이 더 많은 입력 변화 범위에서 학습함으로써 새로운 데이터에 대해 더 잘 일반화되도록 돕습니다.\n\nPyTorch에서 데이터 증가를 구현하려면 데이터셋을 준비할 때 사용되는 transforms.Compose를 확장할 수 있습니다:\n\n```js\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n```\n\n랜덤 뒤집기와 회전을 추가함으로써 훈련 데이터를 다양하게 만들어 모델이 더 견고한 특징을 학습하도록 돕습니다.\n\n<div class=\"content-ad\"></div>\n\n## 4.2: Dropout\n\n드롭아웃은 학습 중에 입력 뉴런의 일부를 무작위로 0으로 설정하여 과도한 공동 적응을 방지하는 정칙화 기술입니다. 이 무작위성은 네트워크가 다른 뉴런의 무작위 하위 집합과 함께 유용한 보다 견고한 기능을 학습하도록 강제합니다.\n\n파이토치에서 CNN 모델에 드롭아웃을 추가하려면 nn.Dropout 레이어를 포함시킵니다:\n\n```js\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        # 합성곱 레이어\n        self.fc1 = nn.Linear(7*7*64, 128)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, 10)\n    def forward(self, x):\n        # 합성곱 및 풀링 작업\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n```\n\n<div class=\"content-ad\"></div>\n\n마지막 완전 연결 레이어 앞에 드롭아웃 레이어를 추가하면 모델이 학습된 표현을 여러 뉴런에 분배하도록 유도하여 오버피팅을 완화하는 데 도움이 됩니다.\n\n## 4.3: 배치 정규화\n\n배치 정규화는 각 미니 배치에 대해 레이어의 입력을 표준화하여 학습 프로세스를 안정화시키고 딥 네트워크를 훈련하는 데 필요한 훈련 에포크 수를 크게 줄입니다.\n\n모델에 배치 정규화를 포함하는 방법은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n```python\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        # Covolutional layers\n        self.conv1_bn = nn.BatchNorm2d(32)\n        # Fully connected layers\n        \n    def forward(self, x):\n        x = F.relu(self.conv1_bn(self.conv1(x)))\n        # Continue through model\n```\n\n컨볼루션 레이어 다음에 배치 정규화를 적용한 후 활성화 함수를 사용하는 것은 출력을 정규화하여 수렴 속도를 높이고 전반적인 성능을 향상시켜줍니다.\n\n## 4.4: 전이 학습\n\n전이 학습은 한 작업에서 훈련된 모델을 다른 관련 작업에서 훈련을 위한 출발점으로 사용하는 기술을 말합니다. 새 작업에 제한된 데이터셋이 있는 경우 특히 유용합니다. PyTorch는 ImageNet과 같은 대규모 데이터셋에서 사전 훈련된 모델을 쉽게 로드하고 조정할 수 있도록 지원하여 전이 학습을 용이하게 합니다.\n\n<div class=\"content-ad\"></div>\n\n프리 트레인 모델을 활용하는 방법은 아주 쉬워요!\n\n```python\nfrom torchvision import models\n\nmodel = models.resnet18(pretrained=True)\n# 마지막 완전 연결 레이어 교체하기\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 10)  # 새로운 작업을 위해 10개의 클래스로 가정\n# 마지막 완전 연결 레이어를 제외한 모든 레이어 동결하기\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.fc.requires_grad = True\n```\n\n요기서, 사전 훈련된 ResNet-18 모델을 사용해서, 10개의 클래스를 위한 새 작업에 맞게 마지막 레이어를 대체했어요. 마지막 레이어를 제외한 모든 레이어의 가중치를 동결하면, 분류기 레이어만을 미세 조정해 원본 데이터셋에서 학습한 기능 추출 능력을 활용할 수 있어요.\n\nCNN 훈련 과정에 이러한 전략을 통합시키면, 오버피팅이 줄어들 뿐만 아니라 견고한 특징 학습을 보장하고 사전 훈련된 모델로부터 지식을 활용하여 모델 성능을 향상시킬 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n# 5: 결론\n\n합성곱 신경망에 대해 심층적으로 파헤쳐 보았습니다. 데이터 설정 및 준비부터 CNN 구조와 계층 분해까지 많은 내용을 다루었습니다. 이러한 모델의 작동 원리를 살펴봤습니다. 가중치 초기화와 데이터 증강, 전이 학습과 같은 기술을 사용하여 모델의 성능을 심각하게 향상시킬 수 있다는 점을 살펴보았습니다. 이러한 방법들은 모델이 더욱 똑똑하게 만들어주어, 오버피팅과 같은 일반적인 함정을 피하고 더 다양한 모델로 만들어 줍니다.\n\nAI 분야에서 CNN은 거의 모든 곳에서 사용되어 얼굴을 인식하거나 의료 영상을 통해 질병을 진단하는 등 많은 일에 도움이 되고 있습니다. 시각적 단서를 잡아내는 능력으로 다양한 작업에 매우 유용합니다.\n\n# 추가 자료\n\n<div class=\"content-ad\"></div>\n\n- LeCun et al., “Gradient-Based Learning Applied to Document Recognition”\nYann LeCun과 동료들이 쓴 이 주요 논문에서는 LeNet-5를 소개하며, 최초의 합성곱 신경망 중 하나로 문서 인식 작업에 적용된 결과를 보여줍니다.\nResearch Gate 링크\n- Simonyan과 Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition” (VGGNet)\nVGGNet을 소개한 이 연구는 CNN 아키텍처에서 깊이의 중요성을 강조하여 이미지 인식 성능을 향상시키는데 있습니다.\narXiv 링크\n- He et al., “Deep Residual Learning for Image Recognition” (ResNet)\nResNet은 잔차 학습 개념을 도입하여, 사그라들어 버리는 기울기 문제를 해결함으로써 훨씬 더 깊은 네트워크의 학습을 가능케 합니다.\narXiv 링크\n\n만약 이 기사를 좋아하셨다면 좋아요를 눌러 주시고, 최신 게시물을 받아보려면 팔로우해주세요. 저의 목표는 인기 있는 모든 알고리즘을 처음부터 다시 만들어 기계 학습을 누구에게나 쉽게 접근할 수 있게 하는 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png"},"coverImage":"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png","tag":["Tech"],"readingTime":26},{"title":"시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근","description":"","date":"2024-06-23 18:48","slug":"2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective","content":"\n\n면허가 있는 거래처 선정이 기존에서 5년 이상된 기사에 대한 후속 내용입니다:\n\n- 시그모이드 신경망을 사용한 다항식 제조\n- 시그모이드 신경망을 사용한 다항식 제조 - 실습\n\n이 실습은 신경망의 인내 성능을 다루었습니다. 간단한 기저(알려진) 모델에 대해: y = 1 + 2*x + 3*x². 실습을 마치며, 1계층 출력 간의 높은 상관 관계가 수렴을 늦추고, 제약이 없는 모델이 훨씬 더 좋은 샘내내 성능을 보였다는 결론을 내렸습니다. 추가로 다항회귀 분석도 제약이 없는 모델의 샘내내 정확성(진정한 모델 기반)을 입증했습니다. 신경망의 스플라인 이론 관점에서 이 모든 것이 직관적으로 맞는 것이며, 두 모델 모두 유용합니다. 그러나 모델의 범위 외 성능을 놓치고 있었음을 인정하지 못했습니다. 스플라인 이론적 관점에서 이는 큰 누락이었습니다.\n\n이 기사는 범위 외 성능, 진정한 모델과 일치 정도, 및 '일반화'에 대한 일부 상위 추론에 초점을 맞추겠습니다. '일반화'는 다음을 기반으로 평가됩니다:\n\n<div class=\"content-ad\"></div>\n\n- 다양한 유형의 테스트 데이터 포인트(전체, 훈련 데이터 내 범위, 훈련 데이터 외 범위)별 총 오차(MSE)\n- 전체 모델의 적합성(확장된 테스트 데이터 세트에서 실제 모델과의 유사성) \n\n## 테스트 데이터의 범위 외 부분 생성\n\n훈련 데이터 세트의 x1은 표준 정규 분포에서 무작위 샘플링하여 생성되었습니다. x1을 3배로 곱하여 범위를 확장한 테스트 데이터 세트가 생성되었습니다. 이로 인해 원래 훈련 세트의 범위 내에 속하는 데이터 포인트가 총 7990개, 원래 훈련 세트의 범위 외에 속하는 데이터 포인트가 2010개 생성되었습니다.\n\n## 모델들\n\n<div class=\"content-ad\"></div>\n\n모델 구조는 실습과 동일합니다\n\n![image](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png)\n\n# 학습 및 평가\n\n모델은 실습에서 사용된 학습 예제를 사용하여 훈련되었습니다. 따라서 모델의 가중치는 변경되지 않았습니다. 그러나 제한된 및 제한되지 않은 모델의 기저 (다항식) 표현은 새로운 테스트 데이터 집합 범위 내에서 변할 수 있습니다. 또한, 모델의 범위를 벗어난 성능은 범위 내 성능에서 예측하기 어려울 수 있습니다(두 모델 모두 학습 데이터 범위 내에서 매우 좋은 적합도를 나타냄, MSE ` 0.045).\n\n<div class=\"content-ad\"></div>\n\n## 에폭별 모델 추적\n\n![이미지](https://miro.medium.com/v2/resize:fit:1280/1*jygr4njGNjkNL3enCQNVyg.gif)\n\n![이미지](https://miro.medium.com/v2/resize:fit:1280/1*hUfYQ21PQZkbE40NcVwuPA.gif)\n\n두 그래프에 대한 키: 파란 선 - 실제 값, 파란 점 - 훈련 범위 내에서 확장 테스트 예제에 대한 모델 예측, 빨간 점 - 훈련 범위를 벗어난 확장 테스트 예제에 대한 모델 예측.\n\n<div class=\"content-ad\"></div>\n\n(bias) 무제한 모델이 (bias) 제한 모델보다 최종 솔루션으로 수렴하는 속도가 훨씬 빠르다는 사실은 명백하다. 그러나 모델의 가중치는 크게(직역하지 않는 용어, 통계 용어 아님) 다르다. 특히, 제한 모델 가중치가 무제한 모델의 가중치보다 거의 1차 크다는 점은 매우 명백하다. 이것은 중요한 관찰이다. 왜냐하면 편향이 없는 모델은 편향 제한 모델로 수렴할 수 있는 기회가 있었지만, 대신 샘플 내 솔루션으로 더 나은 수렴했기 때문이다.\n\n# 모델 (메타) 분석 - 범위 내 및 범위 외\n\n- 랜덤 초기화로 인해 교육 MSE는 약 28에서 출발하여 두 모델 모두 `0.045로 점진적으로 감소한다.\n- 제한 모델은 활성화된 레이어 1 출력이 교육 중에 높은 상관 관계가 있기 때문에 그레이디언트가 노이즈를 일으키는 것으로 추정되므로 훨씬 느리게 수렴한다. (코드에서 실험적으로 유효성이 검증되어야 함)\n- 질적으로 제한된 최종 모델은 범위 밖에서(범위 외 MSE=1699.82) 무제한 최종 모델(범위 외 MSE=2905.67)보다 훨씬 더 우수한 성능을 발휘한다. 이 향상된 외부 범위 성능은 범위 내 성능에 큰 하락이 오지 않고 (제한 모델의 범위 내 MSE=1.38 대 무제한 모델의 범위 내 MSE=0.41) 테스트 데이터에 대한 총 성능(MSE=342.77 대 무제한 모델의 MSE=584.37)에서도 비슷하게 유지된다. 이 간접는 근려에 편향 제약이 실무에서 가치를 더하는 것으로 보이지 않았기에 저에게는 매우 놀랍다.\n- 새로운 테스트 데이터에 대한 모델 적합도도 제한 모델이 무제한 모델에 비해 훨씬 우수하다.\n\n# 확장 테스트 데이터 세트에서 모델 적합 결과 (x1_extended = 2*x1 및 실제 모델 y_extended = 1 + 2*x1_extended + 3*x1_extended²)\n\n<div class=\"content-ad\"></div>\n\n## 제약이 없는 모델\n\n제약이 없는 모델 레이어 1: f1_u, f2_u = f_u(x)\n\n![이미지1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_1.png)\n\n![이미지2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_2.png)\n\n<div class=\"content-ad\"></div>\n\n그래서, f1_u는 0.1094 - 0.0882*x + 0.0102*x² + 0.0002*x³입니다.\n\n![그림1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_3.png)\n\n![그림2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_4.png)\n\n그래서, f2_u는 0.1031 + 0.0799*x + 0.0091*x² - 0.0003*x³입니다.\n\n<div class=\"content-ad\"></div>\n\nUnconstrained model layer 2: y_pred_u = g_u(f1_u, f2_u); g_u is linear\ny_pred_u ~ 7.16 + 2.66*x + 2.31*x² - 0.023*x³\n\n## Constrained model\n\nConstrained model layer 1: f1_c, f2_c = f_c(x)\n\n![Image](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_5.png)\n\n<div class=\"content-ad\"></div>\n\n\n![Image 1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_6.png)\n\nHence, f1_c ~ 0.5 + 0.044*x - 0.00005*x²\n\n![Image 2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_7.png)\n\n![Image 3](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_8.png)\n\n\n<div class=\"content-ad\"></div>\n\n따라서, f2_c ~ 0.2237 + 0.0676*x + 0.0041*x² - 0.0002*x³\n\n제한된 모델 레이어 2: y_pred_c = g_c(f1_c, f2_c); g_c는 선형입니다.\ny_pred_c ~ 2.95 + 6.4*x + 2.79*x² - 0.134*x³\n\n참고: 실습에 포함된 추가 진단은 수행되었지만, 간결함을 위해 이 글에서는 생략되었습니다. 이러한 진단에 관심이 있는 독자는 다음 스크립트를 실행해주세요:\n\n- 제한된 모델을 위한 test_quadratic.py\n- 제한되지 않은 모델을 위한 test_quadratic_unconstrained.py\n\n<div class=\"content-ad\"></div>\n\n## 추가적인 추론\n\n참고: *로 표시된 추론은 세 논문 중 어느 것에도 입증되지 않았지만 이론적으로나 경험적으로 보여질 수 있으며, **로 표시된 추론은 향후 논문을 위한 가능성 있는 후보들이다.\n\n- 비제약 모델에 대해 f1_u와 f2_u 모두 조각선형 함수 형태*를 띄며 ReLU와 유사하다*\n- 제약이 있는 모델과 제약이 없는 모델에 대해 이차적합을 강제하면 다음과 같은 형태가 나온다:\ny_pred_u ~ 7.22 + 2.18*x + 2.31*x²\ny_pred_c ~ 3.56 + 1.98*x + 2.72*x²\n- 최종 가중치가 크게 다르더라도 두 모델의 훈련 오차 차이가 크지 않다. 그러므로 MSE vs. (w1, w2, W1, W2)의 곡선은 모델의 가중치 사이에 오랜 기울기를 보인다**.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n제약이 있는 모델은 (MSE 및 모델 계수가 실제 모델과 얼마나 가까운지) 자유로운 모델보다 훨씬 더 일반화되는 것으로 보입니다. 이 논리를 심층 신경망에서 오버피팅을 넘어서는 일반화에 적용한다면 - 모델 아키텍처가 충분히 좋은 귀납적 편향이라고 가정하면,\n- 초기 오버피팅은 가중치 벡터가 초기화된 지점에서 최단 경로(최적화 알고리즘이 지배하는)를 통해 먼저 '가능한 해'로 수렴하기 때문에 발생할 수 있습니다.\n- 그 이후에 발생하는 일반화가 더 나은 해로의 전이는 최적화 알고리즘이 가중치 벡터를 (오차 측정, 가중치의) 공간에서 새로운 영역으로 완전히 이동시키도록 강요하기 때문으로 설명될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png"},"coverImage":"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png","tag":["Tech"],"readingTime":6},{"title":"MLOps 로드맵  2024년 MLOps 엔지니어가 되는 방법","description":"","date":"2024-06-23 18:46","slug":"2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024","content":"\n\n2024년에 MLOps 엔지니어가 되기 위한 포괄적인 MLOps 로드맵\n\n![MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0.png)\n\nAI 분야에 계시고 머신 러닝에 대해 궁금해하시나요? MLOps에 대해 궁금해하셨나요? 그리고 그 멋진 AI 응용 프로그램들은 어떻게 만들어지는 걸까요?🧐\n\nMLOps는 신비한 용어처럼 들릴 수도 있지만 걱정 마세요! 🤔 이 MLOps 로드맵에서 함께 MLOps의 신비를 탐험해보겠습니다. 🌟\n\n<div class=\"content-ad\"></div>\n\n제가 도와드릴 수 있어요! 명확한 계획을 제시해드릴게요. MLOps가 무엇인지 설명하고 한 단계씩 안내하여 MLOps를 이해할 수 있도록 도와드릴 거에요.💼\n\n시작해 볼까요?\n\n## 1- 프로그래밍 언어:\n\n![MLOpsRoadmap](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_1.png)\n\n<div class=\"content-ad\"></div>\n\n- Python\n- R\n\n당신이 선택할 무기를 고를 수 있어요: Python 또는 R — 둘 다 멋진 언어로, 여러분을 MLOps 전문가로 만들어 줄 거에요. 🌟\n\n## MLOps용 Python\n\n- 다양한 도구 상자, 큰 가능성: Python은 TensorFlow, Kubeflow, Airflow와 같은 MLOps 인기 라이브러리를 포함한 방대한 라이브러리 생태계를 자랑해요. 이를 통해 여러분이 마주하는 어떤 MLOps 도전에도 도와줄 툴이 많이 있어요.\n- 쉽게 배우고, 쉽게 사용: Python의 명확한 구문과 초보자 친화적인 특성은 MLOps 여정을 시작하는 사람들에게 좋은 선택지에요. 금방 익숙해질 거예요!\n- 다른 도구들과 잘 어울려요: Python은 인기 있는 데이터 과학 및 소프트웨어 개발 도구와 완벽하게 통합되어, 여러분의 MLOps 파이프라인을 워크플로우의 다른 부분과 쉽게 연결할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n## MLOps을 위한 R\n\n- 데이터 시각화 챔피언: R은 데이터 탐색과 시각화에서 빛을 발하며 명확하고 통찰력있는 대시보드를 만들어 MLOps 파이프라인을 모니터링할 수 있습니다.\n- 통계 강자: R의 통계 능력은 모델 평가 및 성능 분석과 같은 작업에 완벽하게 적합하며 이는 모든 MLOps 과정의 중요한 부분입니다.\n- 활발한 R 커뮤니티: R 커뮤니티는 열정적이고 도움이 되며, MLOps 모험 중에 막힐 경우 풍부한 지원과 자료를 제공합니다.\n\n# 2- 기계 학습:\n\n<img src=\"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_2.png\" />  \n\n<div class=\"content-ad\"></div>\n\n기계 학습(ML)은 MLOps의 기초입니다. 이것은 컴퓨터가 데이터로부터 배우고 명시적인 프로그래밍 없이 예측하거나 결정을 내릴 수 있는 기적입니다. 그런데 기계 학습은 MLOps에 어떻게 맞는 걸까요? 함께 살펴봅시다:\n\n기계 학습 과정:\n\nMLOps를 기름칠한 기계로 상상해보세요:\n\n- 데이터는 연료입니다: 데이터로 MLOps 파이프라인을 공급하여 ML 모델을 교육하는 데 사용되는 생 원료입니다.\n- 알고리즘은 엔진입니다: ML 알고리즘은 모델의 핵심으로, 데이터로부터 패턴과 통찰을 습득합니다. MLOps에 널리 사용되는 알고리즘으로는 다음이 있습니다:\n  - 선형 회귀: 주택 가격이나 매출액과 같은 연속 값 예측에 효과적입니다.\n  - 의사 결정 트리: 데이터에 대한 일련의 질문에 기반한 명확한 결정을 내립니다. 스팸 필터링과 같은 작업에 이상적입니다.\n  - 랜덤 포레스트: 여러 의사 결정 트리를 결합하여 더 강력한 예측을 제공합니다.\n  - 서포트 벡터 머신(SVM): 서로 다른 범주로 데이터를 분류하는 데 뛰어납니다. 예를 들어 필기 숫자를 식별하는 데 사용됩니다.\n  - 딥 러닝: 인간 두뇌에서 영감을 받은 딥 러닝은 이미지 인식이나 자연 언어 처리와 같은 복잡한 작업에 뛰어납니다.\n- MLOps는 엔지니어 역할을 합니다: ML 모델을 교육하고 배포하며 성능을 모니터링하고 최신 상태를 유지하도록 자동화합니다.\n\n<div class=\"content-ad\"></div>\n\n# 3- 클라우드 플랫폼 - MLOps를 강화하세요\n\n![이미지](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_3.png)\n\nMLOps 파이프라인을 구축하고 관리할 때, 클라우드 플랫폼은 게임 체인징한 이점을 제공합니다. 여기에 그 이유가 있습니다:\n\n- 요구에 따른 확장성: 클라우드 플랫폼은 탄력적인 리소스를 제공하여 MLOps 인프라를 요구에 따라 확장 또는 축소할 수 있습니다. 복잡한 훈련 작업을 위한 처리 능력 부족으로 걱정할 필요가 없어요!\n- 쉬운 협업: 클라우드 플랫폼은 데이터 과학자, 엔지니어, MLOps 전문가 간의 원활한 협업을 촉진합니다. 모든 사람이 프로젝트에 동시에 접근하고 작업할 수 있어 개발 과정을 간소화합니다.\n- 자동화된 워크플로우: 클라우드 플랫폼은 모델 훈련, 배포, 모니터링과 같은 MLOps 작업을 자동화하는 데 능숙합니다. 이는 팀이 더 전략적인 이니셔티브에 집중할 수 있도록 해줍니다.\n- 비용 효율성: 클라우드 플랫폼을 사용하면 사용한 리소스만 지불하면 됩니다. 이는 유지 관리 비용이 비실 수 있는 기존 온프레미스 인프라에 비해 상당한 장점입니다.\n\n<div class=\"content-ad\"></div>\n\n인기있는 클라우드 플랫폼 중에서 강력한 MLOps 기능을 제공하는 몇 가지가 있습니다:\n\n- Google Cloud Platform (GCP): GCP의 Vertex AI 스위트는 Vertex Pipelines(자동화를 위한), Vertex Experiments(모델 비교를 위한)를 포함한 포괄적인 MLOps 도구 세트를 제공합니다.\n- Amazon Web Services (AWS): AWS는 SageMaker를 제공하여 머신 러닝 모델을 구축, 훈련 및 배포하는 관리 서비스를 제공합니다. 다른 AWS 서비스와 웰 통합되어 종합적인 MLOps 경험을 제공합니다.\n- Microsoft Azure: Azure Machine Learning은 전체 MLOps 생애주기를 위한 클라우드 기반 환경을 제공합니다. 데이터 준비, 모델 훈련, 배포 및 모니터링을 위한 기능을 포함하고 있습니다.\n\n# 4- 버전 관리: MLOps의 수퍼히어로 ‍♀️\n\n![이미지](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_4.png)\n\n<div class=\"content-ad\"></div>\n\n놀라운 MLOps 파이프라인을 구축하고 있을 때 작은 변경으로 모든 것이 망가지는 일이 발생하면 어떨까요! 그럴 때 버전 관리가 구조를 구할 수 있어요.\n\n버전 관리는 당신의 MLOps 프로젝트용으로 시간 여행을 할 수 있는 것과 같아요. 코드, 데이터, 모델을 변경할 때마다 그것을 추적해주어 다음을 가능하게 해줘요:\n\n- 과거로 돌아가기: 실수를 하게 되었나요? 걱정하지 마세요! 이전에 완벽하게 작동했던 이전 버전으로 되돌릴 수 있어요.\n- 협업 원할하게: 여러 사람이 MLOps 파이프라인에 작업할 때, 버전 관리는 모두가 동일한 페이지에 있다는 것을 보장하여 충돌과 혼란을 방지해줘요.\n- 자유롭게 실험하기: 두려움 없이 다양한 접근 방식을 시도해보세요. 버전 관리를 통해 버전을 비교하고 어떤 것이 가장 잘 작동하는지 확인할 수 있어요.\n- 결과 재현하기: 향후 참고를 위해 특정 모델이나 파이프라인을 재생성해야 할 때, 버전 관리를 통해 모든 것이 정확히 동일한 상태임을 쉽게 확인할 수 있어요.\n\nMLOps에서 버전 관리가 어떻게 작동하는지 Çómo funciona el control de versiones en MLOps\n\n<div class=\"content-ad\"></div>\n\n여기 간단한 내용이에요:\n\n- 모든 것을 저장하세요: 코드, 데이터, 모델 - MLOps 프로젝트의 모든 구성 요소는 중앙 저장소에 저장됩니다.\n- 변경을 추적하세요: 당신이 만든 모든 수정 사항은 기록되어 명확한 이력을 만듭니다.\n- 분기해 보세요: 실험을 해야 할 필요가 있나요? 메인 파이프라인에 영향을 미치지 않으면서 변경 사항을 테스트할 브랜치를 만드세요.\n- 병합하고 배포하세요: 변경 사항에 만족하면 변경 사항을 다시 메인 브랜치로 병합하고 업데이트된 MLOps 파이프라인을 배포하세요.\n\nMLOps를 위한 인기 있는 버전 관리 시스템:\n\n- Git: 산업 표준인 Git은 버전 관리와 협업에 강력한 기능을 제공합니다.\n- DVC (데이터 버전 관리): 데이터 과학 프로젝트를 관리하기 위해 특별히 설계된 DVC는 데이터셋과 모델의 버전을 관리하기 위해 Git과 원활하게 작동합니다.\n- MLflow: ML 라이프사이클을 관리하기 위한 오픈 소스 플랫폼으로, 모델과 실험의 버전 관리를 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n버전 관리는 모든 MLOps 실무자에게 필수적인 도구입니다. 안정성, 협업 및 실험 및 학습 능력을 보장합니다. 버전 관리를 통해 견고하고 신뢰할 수 있는 MLOps 파이프라인을 구축하여 실질적인 가치를 제공할 수 있습니다.\n\n# 5- CI CD 파이프라인: CI/CD로 머신 러닝 자동화하기\n\n![이미지](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_5.png)\n\n최신 AI 모델을 대량으로 생산하는 공장을 구축한다고 상상해보세요. 그것이 바로 MLOps 파이프라인이 하는 일인데, 물리적인 기계 대신 소프트웨어 자동화를 사용합니다. 이때 CI/CD (지속적 통합 및 지속적 전달/배포)가 비밀 무기로 작용합니다.\n\n<div class=\"content-ad\"></div>\n\nMLOps에서의 CI/CD는 미리 정리된 것처럼 잘 짜여진 조립 라인의 역할을 합니다:\n\n- 버전 관리 (소스 코드): 모든 것은 코드로 시작합니다. Git과 같은 버전 관리 시스템은 변경 사항을 추적하여 모두가 동일한 페이지에 있는지 확인합니다.\n- 지속적 통합 (CI): 코드의 변경으로 CI 단계가 트리거됩니다. 여기서 자동화된 테스트가 코드와 데이터를 유효성 검사하여 오류를 조기에 발견하여 이후 단계로 전파되지 않도록 합니다.\n- 모델 훈련 및 유효성 검사: 파이프라인은 준비된 데이터로 ML 모델을 훈련시킵니다. CI/CD는 모델이 예상대로 작동하는지 확인하기 위해 자동화된 테스트를 실행합니다. 이는 배포 전에 편향 또는 성능 문제를 찾는 데 중요합니다.\n- 패키징 및 버전 관리: 훈련 및 유효성 검사된 모델은 배포를 위해 준비된 형식으로 패키징됩니다 (제품을 깔끔하게 상자에 담는 것처럼 생각하면 됩니다). CI/CD는 변경 사항을 추적하기 위해 버전 번호도 할당합니다.\n- 지속적 전달/배포 (CD): 파이프라인은 패키지로 된 모델을 대상 환경에 자동으로 배포합니다. 테스트 서버 또는 제품 환경일 수 있습니다. 여기서 CI/CD는 다양한 전략을 사용할 수 있습니다:\n\n- 지속적 전달: 제품을 제품 환경으로 이동하기 전에 최종 테스트를 위해 스테이징 환경으로 모델을 배포합니다.\n- 지속적 배포: 이전 단계에서 모든 테스트가 통과되었다고 가정하고 모델을 자동으로 제품 환경에 직접 배포합니다.\n\nMLOps의 CI/CD의 장점:\n\n<div class=\"content-ad\"></div>\n\n- 빠른 혁신: 파이프라인 자동화를 통해 모델을 더 빠르게 개선하며 성능을 지속적으로 향상시킬 수 있습니다.\n- 오류 감소: 자동화된 테스트는 버그를 조기에 발견하여 제품 모델에 영향을 미치지 않도록 합니다.\n- 일관성 향상: CI/CD를 통해 모델이 매번 동일한 방식으로 구축, 훈련 및 배포되어 신뢰할 수 있는 결과를 얻을 수 있습니다.\n- 협업 강화: 파이프라인은 데이터 과학자, 엔지니어 및 운영팀 간의 소통을 간소화합니다.\n\nMLOps 워크플로에 CI/CD 파이프라인을 구현하여 고품질 머신러닝 모델을 제공하는 견고하고 효율적인 시스템을 구축할 수 있습니다!\n\nCI/CD 배우기:\n\n# 6- 컨테이너화:\n\n<div class=\"content-ad\"></div>\n\n![MLOps Roadmap](/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_6.png)\n\n복잡한 MLOps 파이프라인을 다양한 환경에 배포한다고 상상해보세요 — 개발자 노트북, 테스트 서버 그리고 마지막으로 프로덕션! 로지스틱 악몽처럼 들리죠? 여기서 컨테이네이션이 등장해 MLOps 슈퍼히어로가 되어줍니다!\n\n컨테이네이션이 정확히 무엇일까요? 여러분의 ML 모델이 필요로 하는 모든 것 — 코드, 라이브러리, 의존성, 실행 환경을 깔끔한 상자인 컨테이너에 담아 생각해보세요. 이 컨테이너는 어디로든 배송되며, 시스템이 컨테이너 엔진(예: 도커)을 가지고 있다면, 여러분이 의도한 대로 모델이 모든 환경에서 정확히 실행됩니다. 컨테이네이션이 MLOps에 미치는 영향은 다음과 같습니다:\n\n- 재현성의 구원자! ‍♀️ 컨테이너는 MLOps 파이프라인의 모든 단계에서 동일한 환경을 보장합니다. 이는 '내 컴퓨터에서는 작동하는데'와 같은 문제를 제거하여 모든 곳에서 일관된 모델 성능을 보장합니다.\n- 배포가 쉬워집니다: 컨테이너는 가벼우며 휴대 가능하여 다양한 플랫폼(클라우드 또는 온프레미스)에 모델을 쉽게 배포할 수 있습니다. 몇 초만에 새로운 인스턴스를 구동하고 예측 서비스를 제공할 준비가 됩니다!\n- 격리로 정리를 유지합니다: 컨테이너는 서로와 호스트 시스템과 격리됩니다. 이는 서로 다른 모델이나 라이브러리 간 충돌을 방지하여 MLOps 파이프라인을 안정적이고 안전하게 유지합니다.\n- 확장성 승리! 더 많은 데이터나 예측을 처리해야 한다면? 문제 없습니다! 파이프라인에 더 많은 컨테이너를 추가하기만 하면 됩니다. 컨테이너는 여러분의 요구에 기반하여 쉽게 확장하거나 축소할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 도구:\n\n1. Docker: 컨테이너화의 원조. Docker는 컨테이너를 구축, 공유 및 실행하는 사용자 친화적인 플랫폼입니다. 초보자나 작은 MLOps 프로젝트에 좋은 선택지입니다.\n\n2. Kubernetes: 컨테이너 오케스트레이션 챔피언. MLOps 파이프라인에서 함께 작동하는 많은 컨테이너가 있을 때, Kubernetes는 그 모든 것을 관리하는 데 도움을 줍니다. 배포, 스케일링 및 회복을 자동화하여 컨테이너화된 모델이 원활하게 실행되도록 보장합니다.\n\n내 글을 읽어 주셔서 감사합니다; 내 컨텐츠가 마음에 들었다면 Patreon에서 지원하는 것이 최선입니다 —\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_7.png\" />\n\n- YouTube 채널 구독하기\n- 웹사이트 방문하기\n- LinkedIn 및 Github에 연결하여 기술 및 AI를 활용하여 생산성과 효율성을 높이기 위해 무료로 제공되는 멋진 컨텐츠를 공유합니다.\n- ML 및 DL에 도움이 필요하다면 Fiverr 서비스 확인하기!","ogImage":{"url":"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0.png"},"coverImage":"/assets/img/2024-06-23-MLOpsRoadmapHowToBecomeMLOpsEngineerin2024_0.png","tag":["Tech"],"readingTime":8},{"title":"RAG 평가 향상하기 FaaF와 ARES의 시너지 효과 및 구조화된 출력 방식 사용","description":"","date":"2024-06-23 18:43","slug":"2024-06-23-ElevatingRAGEvaluationTheSynergyofFaaFandARESthroughStructuredOutput","content":"\n\n인공 지능 소프트웨어가 이 기사의 텍스트 문법, 흐름 및 가독성을 향상시키는 데 사용되었습니다.\n\nRetrieval Augmented Generation (RAG) 시스템은 자연어 처리 (NLP)에서 유망한 접근 방식으로 나타났으며 정보 검색과 언어 생성 기술을 통합하여 생성된 응답의 품질과 관련성을 향상시키는 것을 목표로 합니다.\n\n이러한 시스템은 질문 응답, 대화 시스템 및 콘텐츠 생성을 포함한 다양한 응용 프로그램에서 상당한 잠재력을 보여주었습니다. RAG 시스템은 대규모 지식 베이스에서 관련 정보에 액세스하기 위해 검색의 힘을 활용하고 언어 모델의 생성 능력과 결합하여 더 정확하고 맥락적으로 관련성이 높고 정보를 제공하는 응답을 생성할 수 있습니다.\n\n그러나 RAG 시스템의 성능을 평가하는 것은 특히 원인 재현력을 평가하는 데 독특한 도전을 제기합니다. 왜냐하면 소스 자료에서 관련 정보를 검색하고 정확하게 전달하는 능력을 평가하는 것이 중요하기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n사실적 기억은 RAG 시스템 성능에 있어 중요한 측면이며, 생성된 응답의 신뢰성과 신뢰도에 직접적인 영향을 미칩니다. 관련 사실을 부정확하게 가져오거나 불완전하게 가져오면 잘못된 결과물이나 오도하는 결과물로 이어질 수 있어 시스템의 유용성과 신뢰성이 떨어집니다.\n\nRAG 시스템에 대한 전통적 평가 방법은 종종 인간 주석이나 휴리스틱 프롬프트를 의존하는데, 이는 여러 가지 제약사항이 있습니다. 인간 주석은 유용한 통찰력을 제공하지만, 시간이 많이 소요되며 비용이 많이 들며 개인적 편향과 불일치가 있을 수 있습니다.\n\n반면에 휴리스틱 프롬프트는 입력 공간의 다양한 변화와 미묘한 차이를 충분히 포착하지 못할 수 있어 시스템 능력의 불완전한 평가로 이어질 수 있습니다.\n\n게다가 이러한 방법들은 일반적으로 대규모 및 자동화된 평가가 필요한 현실 세계에서의 실용성과 신뢰성이 부족할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이러한 도전에 대응하고 RAG 시스템을 더 효과적으로 평가하기 위해 연구자들은 이를 위해 특별히 설계된 새로운 평가 프레임워크를 제안해왔습니다. 최근 논문에서 주목을 받고 있는 두 가지 중요한 접근 방식은 팩트를 함수로써 (FaaF)와 ARES (자동 검색 보완 생성 평가 시스템)입니다. 두 프레임워크 모두 RAG 시스템의 보다 효율적이고 신뢰할 수 있으며 통찰력 있는 평가를 제공하려고 하지만 방법론과 초점에서 차이가 있습니다.\n\n카트라니디스 등이 제안한 팩트를 함수로써(FaaF)는 RAG 시스템에 대한 사실 확인 및 사실 회상 평가를 위한 새로운 접근 방식을 제안합니다. FaaF 뒤에 있는 핵심 아이디어는 JSON 객체를 사용하여 사실을 호출 가능한 함수로 나타내어 전통적인 프롬프트 기반 방법에 비해 보다 구조화되고 효율적인 다중 사실 평가를 가능하게 합니다. 구조화된 표현과 프로그래밍 언어와 같은 인터페이스의 힘을 활용함으로써 FaaF는 RAG 평가의 해석 가능성, 모듈성 및 확장성을 향상시키기 위해 노력합니다.\n\n반면에 사드-팔콘 등이 제안한 ARES는 RAG 평가에 보다 포괄적인 접근 방식을 취하며, 문맥 상관성, 답변 충실도 및 답변 관련성과 같은 여러 차원을 고려합니다. ARES는 대규모 언어 모델(Large Language Models, LLMs)을 사용하여 합성 쿼리-패스지-답변 쌍을 생성하고 이를 통해 RAG 구성 요소를 평가하기 위해 LLM 판단자를 세밀하게 조정합니다.\n\n그것은 기계 생성 및 인간 주석 데이터를 활용하여 신뢰 구간 및 순위를 위한 사람 선호도 확증 세트를 활용하는 예측 기반 추론(Prediction-Powered Inference, PPI)를 채택합니다.\n\n<div class=\"content-ad\"></div>\n\nFaaF와 ARES는 접근 방식과 초점에서 차이가 있지만, 둘 다 RAG 평가에서 구조화된 출력의 중요성을 강조합니다. JSON 표현과 프로그래밍 언어와 비슷한 인터페이스를 사용하여 이러한 프레임워크는 일반 텍스트 프롬프트보다 신뢰성이 더 높고 모듈식이며 확장 가능한 평가를 가능하게 합니다.\n\nRAG 평가에서 구조화된 출력의 이점은 Pydantic과 같은 데이터 유효성 검사를 위한 라이브러리 사용과 유사한데요. Python에서 데이터 유효성 검사를 위해 Pydantic과 같은 라이브러리를 사용하는 것과 유사하게, 유형 안전성, 자동 변환, 사용자 정의 유효성 로직, 오류 처리 등의 장점을 제공합니다.\n\n# Facts as a Function (FaaF)이란?\n\n<div class=\"content-ad\"></div>\n\nFaaF는 Katranidis 등이 2024년에 발표한 \"RAG 시스템의 평가를 위한 함수로서의 사실\" 논문에서 소개된, 팩트 검증 및 사실 회상 평가에 대한 혁신적인 접근 방식입니다.\n\nFaaF의 핵심 아이디어는 사실을 JSON 객체를 사용하여 호출 가능한 함수로 표현함으로써, 전통적인 프롬프트 기반 방법과 비교하여 보다 구조화되고 효율적인 다중 사실 평가를 가능케 한다는 것입니다.\n\nJSON 대 프롬프트: FaaF는 언어 모델(LM)에게 사실을 전달할 때 자연어 프롬프트 대신 JSON 표현을 활용합니다. 이 접근 방식을 통해 LM은 함수 변수 간의 독립성을 학습하고, 변수 메타데이터와 타입 힌트를 통해 더 나은 제약을 제공하며, 예상 출력 형식에 대한 준수를 위한 가파른 경사를 가능하게 합니다. JSON을 사용함으로써, FaaF는 LM이 사실과 그 관계들의 구조화된 성격을 더 잘 파악할 수 있도록 하고자 합니다.\n\n텍스트 생성물을 단위로: FaaF는 관련된 모든 사실을 한 개체 함수로 캡슐화하여 생성된 텍스트를 단일 단위로 취급합니다. 이를 통해 각 사실을 개별적으로 판단하는 대신 단일 LM 호출로 다중 사실을 평가함으로써 효율성을 크게 향상시킵니다. 생성된 텍스트를 전체적으로 고려함으로써, FaaF는 RAG 시스템의 출력물의 전반적인 사실 일관성과 일관성을 포착할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n아웃소싱 판단: FaaF는 LM(Language Model)로부터 일부 결정론적 판단을 아웃소싱하는 개념을 도입합니다. 예를 들어, 구문 분석 함수는 LM 응답 범위를 이진 True/False 형식으로 매핑하여 LM이 명시적으로 진실 여부를 판단하는 부담을 줄입니다. 이 관심 분리를 통해 더 유연하고 해석 가능한 평가가 가능해지며, LM은 불확실성을 표현할 수 있으면서 최종 결정은 사전 정의된 함수 논리에 의해 이루어집니다.\n\nFaaF는 이러한 아이디어를 구체화하여 사실 명세서 목록을 JSON 객체로 매핑하는 과정을 정의합니다. LM 평가자(LMeval)는 입력 텍스트를 기반으로 이러한 필드를 채우는 역할을 하며, 구문 분석 함수는 LMeval 출력을 처리하여 사실을 확인합니다. 이 구조화된 방식은 FaaF가 RAG 시스템에서 사실 회상의 보다 명확하고 효율적인 평가를 제공할 수 있도록 합니다.\n\n# FaaF와 ARES 비교:\n\nARES(Automated Retrieval-Augmented Generation Evaluation System)는 RAG 시스템을 평가하기 위한 또 다른 주목할만한 프레임워크로, Saad-Falcon 및 그 동료가 \"ARES: An Automated Evaluation Framework for Retrieval-Augmented Generation Systems\" 논문에서 제안했습니다. FaaF와 ARES 모두 RAG 평가를 개선하고자 하지만, 두 접근 방식과 초점에 차이가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 평가 차원:\n\n- FaaF는 사실적 기억에 중점을 둡니다 — 필요한 정보가 RAG 응답에서 정확하게 검색되고 전달되는 정도를 측정합니다. 이는 RAG 시스템이 소스 자료에서 관련된 사실을 통합하고 전달하는 능력을 명확히 평가하기 위한 목적을 갖고 있습니다.\n- 반면에 ARES는 RAG 시스템을 context relevance(맥락 중요성), answer faithfulness(답변 충실도), answer relevance(답변 관련성) 세 가지 차원에서 평가합니다. 이는 단순히 사실적 정확성뿐만 아니라 생성된 응답의 적합성과 일관성을 고려하는 종합적인 접근을 취합니다. 주어진 맥락 및 질문과 관련하여 생성된 응답의 확실성도 고려합니다.\n\n## 접근 방식:\n\n- FaaF는 JSON 객체를 사용하여 사실을 호출 가능한 함수로 나타내고 입력 텍스트를 기반으로 함수 필드를 채우기 위해 LM 평가자를 사용합니다. 구문 분석 함수는 LM 평가 출력을 처리하여 사실을 확인하며, 구조화되고 모듈화된 평가 프로세스를 가능하게 합니다.\n- 반면에 ARES는 LLMs를 사용하여 합성 쿼리-담화-답변 쌍을 생성하고, 이러한 합성 데이터에서 LLM 평가자를 세밀하게 조정하여 RAG 구성 요소를 평가합니다. 이는 기계 생성 및 인간 주석된 데이터를 활용하여 확신 구간과 순위를 위해 인간 선호 검증 세트와 함께 예측을 지원하는 추론(PPI)를 수행합니다.\n\n<div class=\"content-ad\"></div>\n\n## 데이터 효율성:\n\n- FaaF는 초기 데이터셋(예: WikiEval) 이상의 추가 인간 주석이 필요하지 않아 더 많은 데이터 효율성을 가지며 구현하기 쉽습니다.\n- ARES는 선호도 유효성 검사 세트를 위해 작은 인간 주석 집합(150~300 데이터 포인트)이 필요하며, 전문 지식이 필요한 특수 도메인에서 특히 도전적이고 자원이 소모될 수 있습니다.\n\n## 일반화 능력:\n\n- FaaF는 기본적으로 단일 데이터셋(WikiEval)에서 테스트되었으며 사실적 기억 평가에 중점을 두고 있습니다. 유망하지만 다른 데이터셋 및 평가 차원으로의 일반화 가능성은 아직 탐구되지 않았습니다.\n- ARES는 KILT, SuperGLUE 및 AIS 벤치마크의 여덟 데이터셋에서 강력한 성능을 보여주며 RAG 시스템의 여러 차원을 평가합니다. 이는 다양한 도메인 및 평가 기준에 걸쳐 일반화 가능성과 견고성이 높다는 것을 시사합니다.\n\n\n<div class=\"content-ad\"></div>\n\n# FaaF 및 ARES의 상보적 성격:\n\nFaaF와 ARES는 각각의 방법 및 초점에 차이가 있지만, 그들이 상호 배타적이 아니라 오히려 RAG 시스템을 평가하는 보완적인 프레임워크임을 인식하는 것이 중요합니다. 각 프레임워크는 강점과 한계가 있으며, 이들을 결합하여 연구자와 프랙티셔너들은 자신들의 RAG 모델의 성능과 한계에 대한 보다 포괄적인 이해를 얻을 수 있습니다.\n\nFaaF는 사실 기억에 대한 명시적 초점과 사실 표현에 대한 구조화된 JSON 기반 방식으로, RAG의 결과물의 사실적 정확성을 평가하기 위한 효율적이고 해석 가능한 프레임워크로 만들어졌습니다. 단일 LM 호출로 여러 사실을 평가하고, 결정론적 판단을 구문 논리에 위탁함으로써, 보다 간편하고 모듈화된 평가 과정이 가능해졌습니다.\n\n그 반면, ARES는 맥락 관련성, 답변 충실도 및 답변 관련성을 고려한 다차원 평가로, RAG 성능에 대한 더 포괄적인 평가를 제공합니다. 합성 데이터 생성 및 세밀하게 조정된 LLM 판단자들의 사용은 보다 확장 가능하고 자동화된 평가 프로세스를 가능케 하며, 인간의 선호도 확인 세트의 포함은 평가 지표를 인간의 판단과 일치시킴을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\nFaaF와 ARES를 함께 사용하면 두 프레임워크의 강점을 활용하여 RAG 시스템을 보다 깊이 이해할 수 있습니다. 예를 들어, FaaF를 사용하여 RAG 출력물의 사실적 기억을 빠르게 평가하여 검색된 정보의 빈틈이나 모순을 식별할 수 있습니다. 이후에 ARES를 사용하여 보다 포괄적인 평가를 실시할 수 있는데, ARES는 생성된 응답의 문맥적 적합성, 충실성 및 전반적인 품질에 대한 통찰력을 제공할 수 있습니다.\n\n또한, FaaF와 ARES의 보완적 성격은 통합 및 확장 가능성에도 이어집니다. FaaF의 구조화된 JSON 기반 출력물은 ARES 평가 파이프라인에 쉽게 통합되어 RAG 평가의 넓은 맥락 내에서 사실적 기억을 보다 세밀하게 평가할 수 있도록 합니다. 마찬가지로, ARES에서 사용되는 합성 데이터 생성 및 LLM 판단 세밀 조정 방법은 FaaF의 효율성과 일반화 가능성을 향상시키기 위해 적용될 수 있어서, 더 넓은 데이터셋과 도메인에 적용 가능하도록 만듭니다.\n\n# 인공지능 언어 앱에서 구조화된 출력의 중요성 :\n\n구조화된 출력은 Facts as a Function (FaaF) 및 ARES 프레임워크에서 강조하는 바와 같이, 검색 증강 생성 (RAG) 시스템의 평가에서 중요한 역할을 합니다. JSON 객체와 프로그래밍 언어와 유사한 인터페이스와 같은 구조화된 표현을 사용함으로써, 이러한 접근 방법은 전통적인 일반 텍스트 프롬프트와 비교하여 더 신뢰성이 있고 모듈식이며 확장 가능한 평가를 가능케 합니다. RAG 평가에서 구조화된 출력의 장점은 다양하며, 이는 평가 프로세스의 품질과 효율성을 현저히 향상시킬 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n신뢰성과 일관성: 구조화된 출력은 사실, 쿼리 및 생성된 응답을 나타내는 잘 정의된 형식을 강제합니다. 일관된 구조를 준수함으로써 FaaF 및 ARES와 같은 평가 프레임워크는 평가 프로세스가 신뢰성 있고 재현 가능하다고 보장할 수 있습니다. 구조화된 형식은 모호성을 제거하고 자유 형식의 텍스트 표현에서 발생할 수 있는 오해 또는 일관성 부족의 위험을 줄입니다. 이 일관성은 다양한 RAG 시스템 간 보다 정확한 비교를 가능하게 하며 표준화된 평가 기준의 개발을 촉진합니다.\n\n조기 문제 감지: 구조화된 출력은 생성된 응답의 문제와 불일치를 조기에 감지할 수 있습니다. 출력의 구조 및 데이터 유형을 미리 정의된 스키마나 모델에 대해 유효성 검사함으로써 평가 프레임워크는 기대 형식에서의 어떠한 이탈도 빠르게 식별할 수 있습니다. 이 조기 감지 메커니즘은 평가 파이프라인에서 오류(예: 누락된 필드 또는 잘못된 필드)가 더 이상 전파되는 것을 방지합니다. 이러한 문제를 조기에 발견함으로써 연구원과 실무자들은 신속히 처리하여 디버깅 프로세스에서 시간과 노력을 절약할 수 있습니다.\n\n모듈화 및 조립성: 구조화된 출력은 RAG 평가에서 모듈화 및 조립성을 촉진합니다. 평가 프로세스를 사실 기억, 문맥 관련성 또는 답변 성실성과 같은 특정 측면에 집중하는 별도 구성 요소로 분해함으로써 구조화된 출력은 RAG 시스템 성능에 대한 보다 세분화된 목표적인 평가를 가능하게 합니다. 이 모듈화 접근법은 연구자들이 개별 구성 요소를 독립적으로 평가할 수 있도록 하여 시스템의 특정 영역에서의 강점과 약점을 식별하기 쉽게 합니다. 뿐만 아니라 구조화된 출력의 조립성은 여러 평가 지표나 프레임워크를 결합하여 더 포괄적인 RAG 성능 평가를 제공하는 평가 파이프라인을 생성할 수 있습니다.\n\n확장성과 적응성: 구조화된 출력은 RAG 평가 프레임워크의 확장성과 적응성을 촉진합니다. 잘 정의된 인터페이스와 데이터 모델을 활용함으로써 연구자들은 쉽게 새로운 평가 지표, 데이터 집합 또는 도메인별 요구 사항을 통합하여 기존 평가 프레임워크를 확장할 수 있습니다. 출력의 구조화된 성격은 핵심 평가 프레임워크에 중대한 수정을 요구하지 않고 추가 구성 요소나 모듈을 원활하게 통합할 수 있습니다. 이 확장성은 연구자들이 평가 프로세스를 자신의 특정 요구에 맞게 맞추고 변화하는 연구 문제와 응용 분야에 적응할 수 있도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n데이터 유효성 검증 라이브러리와의 통합: RAG 평가에서 구조화된 출력의 이점은 Python의 Pydantic과 같은 데이터 유효성 검증 라이브러리가 제공하는 것과 유사합니다. Pydantic을 사용하면 Python 유형 어노테이션을 활용하여 데이터 모델 또는 스키마를 정의하여 데이터의 구조와 유형을 유효성 검사할 수 있습니다. 유형 안정성, 자동 유형 변환, 사용자 정의 유효성 검사 논리, 정보를 제공하는 오류 메시지 등의 장점을 제공합니다. 구조화된 출력을 데이터 유효성 검증 라이브러리와 통합함으로써 RAG 평가 프레임워크는 이러한 강력한 기능을 활용하여 평가 데이터의 무결성과 일관성을 보장할 수 있습니다.\n\n예를 들어, 입력 쿼리, 검색된 단락, 생성된 응답에 대한 Pydantic 모델을 정의함으로써, 평가 프레임워크는 지정된 스키마에 대해 데이터를 자동으로 유효성 검사할 수 있습니다. 이 유효성 검사 과정은 유형 불일치, 필드 손실 또는 잘못된 값 등을 잡아내어 데이터 품질 문제에 대한 조기 피드백을 제공합니다. 또한, Pydantic의 사용자 정의 유효성 검사 논리 지원을 통해 연구자들은 도메인별 제한 사항이나 규칙을 정의하여 평가 프로세스를 더 개선할 수 있습니다.\n\n명확한 오류 메시지 및 디버깅: 구조화된 출력은 Pydantic과 같은 데이터 유효성 검증 라이브러리와 함께 사용될 때 평가 과정 중 문제가 감지될 때 명확하고 유익한 오류 메시지를 생성할 수 있습니다. 이러한 오류 메시지는 문제의 특정 위치와 성격을 정확히 지정하여 연구자들이 RAG 시스템이나 평가 파이프라인 자체의 문제를 식별하고 디버깅하기 쉽게 만듭니다. 출력의 구조적 특성은 더 정확한 오류 보고를 가능하게 하여 문제 해결에 필요한 시간과 노력을 줄이고 RAG 시스템 개발 및 정제의 빠른 반복 주기를 가능하게 합니다.\n\n상호 운용성 및 프레임워크 간 비교: 구조화된 출력은 RAG 평가에서 상호 운용성을 증진시키고 프레임워크 간 비교를 용이하게 합니다. 공통 구조화된 형식을 채택함으로써 다른 평가 프레임워크는 데이터와 결과를 더 쉽게 교환할 수 있습니다. 이 상호 운용성은 연구자들이 여러 프레임워크에서 얻은 통찰력을 결합하여 각 접근 방식의 장점을 활용하여 RAG 시스템 성능에 대한 더 포괄적인 이해를 얻을 수 있도록 합니다. 또한, 구조화된 출력은 다른 평가 프레임워크 간 직접적인 비교를 가능하게 하여 연구 커뮤니티 내에서 협력과 지식 공유를 촉진합니다.\n\n<div class=\"content-ad\"></div>\n\n다른 도구 및 워크플로와 통합: 구조화된 출력은 RAG 평가 프레임워크를 NLP 파이프라인의 다른 도구 및 워크플로와 완벽하게 통합할 수 있도록 합니다. JSON과 같은 구조화된 형식으로 평가 데이터를 표현함으로써, 평가 프레임워크는 데이터 처리 라이브러리, 시각화 도구 및 보고 시스템과 쉽게 상호 작용할 수 있습니다. 이 통합 기능은 평가 프로세스를 간소화하고 데이터 준비, 모델 학습, 평가 및 결과 분석을 포함하는 최종 결과 워크플로를 만들 수 있게 합니다. 이러한 출력의 구조화된 성격은 자동화와 재현성을 용이하게 하여 연구자가 견고하고 효율적인 평가 파이프라인을 구축할 수 있도록 합니다.\n\n# 결론:\n\nRAG 평가에서 구조화된 출력의 중요성을 과소 평가할 수 없습니다. JSON 객체 및 프로그래밍 언어와 유사한 인터페이스와 같은 구조화된 표현을 채택함으로써, FaaF 및 ARES와 같은 평가 프레임워크는 일반 텍스트 프롬프트 대비 보다 신뢰할 수 있고 모듈식이며 확장 가능한 평가를 가능하게 합니다. 구조화된 출력의 장점은 다재다능하며 초기 문제 발견 및 모듈화부터 확장성 및 Pydantic와 같은 데이터 유효성 검사 라이브러리와의 통합까지 다양합니다.\n\n구조화된 출력은 일관성을 촉진하고 모호성을 줄이며 표준화된 평가 기준의 작성을 가능하게 합니다. 개별 RAG 구성 요소의 타겟팅된 평가를 허용하며, 새로운 도메인 및 요구 사항으로 평가 프레임워크의 확장과 적응을 용이하게 하며, 효과적인 디버깅을 위한 명확한 오류 메시지를 생성합니다. 더불어, 구조화된 출력은 상호 운용성을 촉진하며, 프레임워크 간 비교를 가능하게 하며, NLP 파이프라인의 다른 도구 및 워크플로와 원활하게 통합할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n`Retrieval Augmented Generation` 분야가 계속 발전함에 따라 평가 프레임워크에서 구조화된 출력물의 채택은 최신 기술의 발전에 중요한 역할을 할 것입니다. 구조화된 표현과 데이터 유효성 검사 라이브러리의 이점을 활용하면 연구원과 실무자는 보다 견고하고 신뢰할 수 있으며 통찰력있는 평가 방법론을 개발할 수 있습니다. 결과적으로, 더 효과적이고 신뢰할 수 있는 RAG 시스템을 만들어 다양한 자연어 처리 응용 프로그램 및 그 이상을 혁신할 수 있습니다.\n\n\n\n# 친근한 언어로 설명 🚀\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 마지막으로:\n\n- 작성자를 좋아요하고 팔로우 하세요 👏\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문하기: Stackademic | CoFeed | Venture | Cubed\n- PlainEnglish.io에서 더 많은 콘텐츠 확인하기","ogImage":{"url":"/assets/img/2024-06-23-ElevatingRAGEvaluationTheSynergyofFaaFandARESthroughStructuredOutput_0.png"},"coverImage":"/assets/img/2024-06-23-ElevatingRAGEvaluationTheSynergyofFaaFandARESthroughStructuredOutput_0.png","tag":["Tech"],"readingTime":11},{"title":"간단한 딥러닝 전략으로 암호화폐 백테스팅 결과 공개 버전 2","description":"","date":"2024-06-23 18:42","slug":"2024-06-23-BacktestingCryptocurrenciesAstonishingResultsfromaSimpleDeepLearningStrategyV2","content":"\n\n과거 글이 많은 댓글을 유발하고 의심스럽다는 점을 감안해 코드를 수정하고 결과를 보여드렸어요. 만약 수정할 부분을 발견하시면 알려주세요. 코드나 ONNX 모델이 필요하면 Github 페이지 링크를 남겨드릴게요.\n\n수정한 코드 결과는 다음과 같아요:\n\n![image](/assets/img/2024-06-23-BacktestingCryptocurrenciesAstonishingResultsfromaSimpleDeepLearningStrategyV2_0.png)\n\n```js\n평균 절대 오차(MAE): 3.343354936528137\n제곱근 평균 제곱 오차(RMSE): 4.441722762531883\nR-제곱(R2): 0.980843427945431\n평균 절대 백분율 오차(MAPE): 0.023306784351538545\n'SOL_USDT_price_prediction.png'로 저장된 그래프\n실제 가격과 예측 가격의 상관 관계: 0.9927086445091788\n'Estrategia Original'의 샤프 비율: -5.9404285882999135\n'New Strategy'의 샤프 비율: 18.33714244833774\n'New Strategy'의 Sortino Ratio: 117.31843386969027\n'New Strategy'의 Beta: 0.09456945402128551\n'New Strategy'의 Alpha: 0.03367816559565025\nCross-Validation 평균 절대 오차: 91.0050376257974 ± 41.98080676345999\nSMA 평균 절대 오차(MAE): 21.129903598484848\nSMA 제곱근 평균 제곱 오차(RMSE): 30.88072668067209\nSMA R-제곱(R2): 0.6086608043283657\n```\n\n<div class=\"content-ad\"></div>\n\n이것은 설명 동영상입니다:\n\n다음은 수정된 코드입니다:\n\n```js\nimport ccxt\nimport pandas as pd\nimport numpy as np\nimport onnx\nimport onnxruntime as ort\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\nfrom sklearn.model_selection import TimeSeriesSplit\n\n# 바이낸스 거래소의 인스턴스 생성\nbinance = ccxt.binance()\n\n# 시장 심볼과 시간 간격 설정\nsymbol = 'SOL/USDT'\ntimeframe = '1d'\nlimit = 1000  # 120일의 데이터 윈도우를 보장하기 위한 충분한 데이터 다운로드\n\n# 과거 데이터 다운로드\nohlcv = binance.fetch_ohlcv(symbol, timeframe, limit=limit)\n\n# 데이터를 판다스 DataFrame으로 변환\ndf = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\ndf['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n\n# 데이터를 CSV 파일로 저장\ndf.to_csv('binance_data.csv', index=False)\nprint(\"'binance_data.csv'에 다운로드 및 저장된 데이터\")\n\n# 다운로드된 데이터 로드\ndata = pd.read_csv('binance_data.csv')\n\n# 'timestamp' 열을 날짜 형식으로 변경\ndata['timestamp'] = pd.to_datetime(data['timestamp'])\n\n# 정규화 값 (사용한 값에 맞게 조정)\nmin_close = data['close'].min()\nmax_close = data['close'].max()\n\n# 종가 데이터를 정규화\ndata['close_normalized'] = (data['close'] - min_close) / (max_close - min_close)\n\n# ONNX 모델 로드\nmodel = onnx.load('model_solusdt.onnx')\nonnx.checker.check_model(model)\n\n# 런타임 세션 생성\nort_session = ort.InferenceSession('model_solusdt.onnx')\n\n# 슬라이딩 윈도우 형태로 모델에 입력할 데이터 준비\ninput_name = ort_session.get_inputs()[0].name\nsequence_length = 120  # 모델에 따라 조정\n\n# 예측값 저장할 리스트 생성\npredictions_list = []\n\n# 예측 시작 날짜 설정\nstart_date = pd.Timestamp('2024-01-01')\nend_date = pd.Timestamp.today()\n\n# 하루씩 추론 실행\ncurrent_date = start_date\nwhile current_date < end_date:\n    # 현재 날짜 이전 120일 데이터 선택\n    end_idx = data[data['timestamp'] < current_date].index[-1]\n    start_idx = end_idx - sequence_length + 1\n    \n    if start_idx < 0:\n        print(f\"{current_date}일에 대한 충분한 데이터가 없습니다.\")\n        break\n    \n    # 정규화된 데이터 윈도우 가져오기\n    window = data['close_normalized'].values[start_idx:end_idx+1]\n    \n    if len(window) < sequence_length:\n        print(f\"{current_date}일에 대한 충분한 데이터가 없습니다.\")\n        break\n    \n    # 모델을 위한 데이터 준비\n    input_window = np.array(window).astype(np.float32)\n    input_window = np.expand_dims(input_window, axis=0)  # 배치 사이즈 차원 추가\n    input_window = np.expand_dims(input_window, axis=2)  # 특성 차원 추가\n    \n    # 추론 실행\n    output = ort_session.run(None, {input_name: input_window})\n    prediction = output[0][0][0]\n    \n    # 예측값 역정규화\n    prediction = prediction * (max_close - min_close) + min_close\n    \n    # 예측값 저장\n    predictions_list.append({'date': current_date, 'prediction': prediction})\n    \n    # 날짜 증가\n    current_date += pd.Timedelta(days=1)\n\n# 예측값 리스트를 DataFrame으로 변환\npredictions_df = pd.DataFrame(predictions_list)\n\n# 예측값을 CSV 파일로 저장\npredictions_df.to_csv('predicted_data.csv', index=False)\nprint(\"'predicted_data.csv'에 저장된 예측값\")\n\n# 예측값과 실제값 비교\ncomparison_df = pd.merge(predictions_df, data[['timestamp', 'close']], left_on='date', right_on='timestamp')\ncomparison_df = comparison_df.drop(columns=['timestamp'])\ncomparison_df = comparison_df.rename(columns={'close': 'actual'})\n\n# 에러 메트릭스 계산\nmae = mean_absolute_error(comparison_df['actual'], comparison_df['prediction'])\nrmse = np.sqrt(mean_squared_error(comparison_df['actual'], comparison_df['prediction'])\nr2 = r2_score(comparison_df['actual'], comparison_df['prediction'])\nmape = mean_absolute_percentage_error(comparison_df['actual'], comparison_df['prediction'])\nprint(f'Mean Absolute Error (MAE): {mae}')\nprint(f'Root Mean Squared Error (RMSE): {rmse}')\nprint(f'R-squared (R2): {r2}')\nprint(f'Mean Absolute Percentage Error (MAPE): {mape}')\n\n# 그래프 그리기\nplt.figure(figsize=(14, 7))\nplt.plot(comparison_df['date'], comparison_df['actual'], label='실제 가격', color='blue')\nplt.plot(comparison_df['date'], comparison_df['prediction'], label='예측된 가격', color='red')\nplt.fill_between(comparison_df['date'], comparison_df['prediction'] - mae, comparison_df['prediction'] + mae, color='gray', alpha=0.2, label='에러 밴드 (MAE)')\nplt.xlabel('날짜')\nplt.ylabel('가격')\nplt.title(f'{symbol} 가격 예측 대 비교')\nplt.legend()\nplt.savefig(f\"{symbol.replace('/', '_')}_price_prediction.png\")\nplt.show()\nprint(f\"'{symbol.replace('/', '_')}_price_prediction.png'로 그래프 저장됨\")\n\n# 잔차 분석\nresiduals = comparison_df['actual'] - comparison_df['prediction']\nplt.figure(figsize=(14, 7))\nplt.plot(comparison_df['date'], residuals, label='잔차', color='purple')\nplt.axhline(0, color='black', linestyle='--', linewidth=0.8)\nplt.xlabel('날짜')\nplt.ylabel('잔차')\nplt.title(f'{symbol} 예측 잔차')\nplt.legend()\nplt.savefig(f\"{symbol.replace('/', '_')}_residuals.png\")\nplt.show()\nprint(f\"'{symbol.replace('/', '_')}_residuals.png'로 잔차 그래프 저장됨\")\n\n# 상관 관계 분석\ncorrelation = comparison_df['actual'].corr(comparison_df['prediction'])\nprint(f'실제 가격과 예측 가격 간 상관 관계: {correlation}')\n\n# 투자 전략 시뮬레이션 (기존 전략)\ninvestment_df = comparison_df.copy()\ninvestment_df['strategy_returns'] = (investment_df['prediction'].shift(-1) - investment_df['actual']) / investment_df['actual']\ninvestment_df['buy_and_hold_returns'] = (investment_df['actual'].shift(-1) - investment_df['actual']) / investment_df['actual']\n\nstrategy_cumulative_returns = (investment_df['strategy_returns'] + 1).cumprod() - 1\nbuy_and_hold_cumulative_returns = (investment_df['buy_and_hold_returns'] + 1).cumprod() - 1\n\nplt.figure(figsize=(14, 7))\nplt.plot(investment_df['date'], strategy_cumulative_returns, label='전략 누적 수익', color='green')\nplt.plot(investment_df['date'], buy_and_hold_cumulative_returns, label='보유 및 보유 누적 수익', color='orange')\nplt.xlabel('날짜')\nplt.ylabel('누적 수익')\nplt.title(f'{symbol} 투자 전략 대 보유 및 보유')\nplt.legend()\nplt.savefig(f\"{symbol.replace('/', '_')}_investment_strategy.png\")\nplt.show()\nprint(f\"'{symbol.replace('/', '_')}_investment_strategy.png'로 투자 전략 그래프 저장됨\")\n\n# 손실 표시 계산\ninvestment_df['drawdown'] = strategy_cumulative_returns.cummax() - strategy_cumulative_returns\ninvestment_df['max_drawdown'] = investment_df['drawdown'].max()\n\nplt.figure(figsize=(14, 7))\nplt.plot(investment_df['date'], investment_df['drawdown'], label='손실', color='red')\nplt.xlabel('날짜')\nplt.ylabel('손실')\nplt.title(f'{symbol} 전략 손실')\nplt.legend()\nplt.savefig(f\"{symbol.replace('/', '_')}_drawdown.png\")\nplt.show()\nprint(f\"'{symbol.replace\n\n<div class=\"content-ad\"></div>\n\n```\nimport ccxt\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Dropout, Flatten\nimport tf2onnx\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\n# Binance 데이터를 다운로드하는 함수\ndef descargar_datos(symbol, timeframe='1d', start_date='2000-01-01T00:00:00Z', end_date='2024-01-01T00:00:00Z'):\n    exchange = ccxt.binance({'enableRateLimit': False})\n    since = exchange.parse8601(start_date)\n    end_date_timestamp = pd.to_datetime(end_date, utc=True)\n    all_data = []\n\n    while since < end_date_timestamp.timestamp() * 1000:\n        ohlc = exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since)\n        all_data.extend(ohlc)\n        since = ohlc[-1][0] + 1  # `since`를 1밀리초 증가\n\n    df = pd.DataFrame(all_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n    df.set_index('timestamp', inplace=True)\n\n    # 두 시간대가 timezone-aware하지 않으면 변환\n    if df.index.tz is None:\n        df.index = df.index.tz_localize('utc')\n    \n    df = df[df.index <= end_date_timestamp]\n    print(df)\n    return df['close'].values\n\n# 데이터 불러오기\ndata = descargar_datos('SOL/USDT')\n\n# 데이터 정규화\nscaler = MinMaxScaler(feature_range=(0, 1))\ndata = scaler.fit_transform(data.reshape(-1, 1))\n\n# 시퀀스에서 샘플을 생성하는 함수\ndef crear_muestras(dataset, pasos_de_tiempo=120):\n    X, y = [], []\n    for i in range(pasos_de_tiempo, len(dataset)):\n        X.append(dataset[i-pasos_de_tiempo:i, 0])\n        y.append(dataset[i, 0])\n    return np.array(X), np.array(y)\n\n# 훈련 및 테스트 데이터 준비\npasos_de_tiempo = 120\nX, y = crear_muestras(data, pasos_de_tiempo)\nX = X.reshape(X.shape[0], X.shape[1], 1)  # LSTM에 맞게 재구성\n\n# 데이터 분할 (훈련용 80%)\nsplit = int(0.8 * len(X))\nX_train, X_test = X[:split], X[split:]\ny_train, y_test = y[:split], y[split:]\n\n# 모델 훈련\n\nmodel = Sequential()\nmodel.add(Conv1D(filters=256, kernel_size=2, activation='relu',padding = 'same',input_shape=(X_train.shape[1],1)))\nmodel.add(MaxPooling1D(pool_size=2))\nmodel.add(LSTM(100, return_sequences = True))\nmodel.add(Dropout(0.3))\nmodel.add(LSTM(100, return_sequences = False))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units=1, activation = 'sigmoid'))\nmodel.compile(optimizer='adam', loss= 'mse' , metrics = [tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n\n# 조기 종료 설정\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    patience=5,\n    restore_best_weights=True,\n)\n# 가장 좋은 모델 저장\ncheckpoint = ModelCheckpoint(\n    'best_model.h5', \n    monitor='val_loss', \n    save_best_only=True, \n    save_weights_only=False\n)\n\n\n# 300 에포크로 모델 훈련\nhistory = model.fit(X_train, y_train, epochs = 300 , validation_data = (X_test,y_test), batch_size=32, callbacks=[early_stopping, checkpoint], verbose=2)\n\n# 훈련 이력 그래프\nplt.figure(figsize=(10, 5))\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.plot(history.history['rmse'], label='Train RMSE')\nplt.plot(history.history['val_rmse'], label='Validation RMSE')\nplt.title('Model Training History')\nplt.xlabel('Epochs')\nplt.ylabel('Loss/RMSE')\nplt.legend()\nplt.savefig('SOLUSDT.png')  # 그래프를 이미지 파일로 저장\n\n# 모델을 ONNX로 변환\nonnx_model, _ = tf2onnx.convert.from_keras(model, opset=13, output_path=\"model_solusdt.onnx\")\nprint(\"ONNX 모델을 'model_solusdt.onnx'로 저장했습니다.\")\n\n# 모델 평가\ntrain_loss, train_rmse = model.evaluate(X_train, y_train, verbose=0)\ntest_loss, test_rmse = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"train_loss={train_loss:.3f}, train_rmse={train_rmse:.3f}\")\nprint(f\"test_loss={test_loss:.3f}, test_rmse={test_rmse:.3f}\")\n\n\ngithub: Back-testing Cryptocurrencies Astonishing Results from a Simple Deep Learning Strategy\n\nyoutube explanation: [여기를 클릭하여 유튜브 설명 보기](https://youtu.be/z_taWHp_HaI)\n","ogImage":{"url":"/assets/img/2024-06-23-BacktestingCryptocurrenciesAstonishingResultsfromaSimpleDeepLearningStrategyV2_0.png"},"coverImage":"/assets/img/2024-06-23-BacktestingCryptocurrenciesAstonishingResultsfromaSimpleDeepLearningStrategyV2_0.png","tag":["Tech"],"readingTime":12}],"page":"11","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}