{"pageProps":{"posts":[{"title":"DSPy를 사용하여 메타데이터 추출하는 방법 - NER 스타일 가이드","description":"","date":"2024-06-22 20:47","slug":"2024-06-22-UsingDSPyforextractingmetadataNERstyle","content":"\n\nDSPy는 프로그래밍을 장려하는 \"선언적\" 방식을 통해 LLMs를 가르치는 것을 선호하여 커뮤니티에서 빠르게 큰 관심을 얻었습니다. 이 글에서는 DSPy를 사용하여 Named Entity Recognition (NER) 또는 구조화된 데이터 추출을 얼마나 쉽게 할 수 있는지 살펴보겠습니다. 이를 통해 자신감을 가지고 기능을 활용할 수 있습니다.\n\n자세한 내용은 아래의 원문을 확인해주세요:\n\n시작해봅시다 😎!\n\n# 소개\n\n<div class=\"content-ad\"></div>\n\n요즘 대형 언어 모델(Large Language Models, LLM)과 작업한 사람들은 프롬프트(prompt)의 중요성을 강조할 것입니다. 프롬프트를 조금만 바꿔도 출력물에 예상치 못한 변화가 연쇄적으로 발생할 수 있습니다. 또한 다른 LLM 제공업체 간에 프롬프트를 이전하거나 재사용하는 일이 까다로운 경우도 많습니다. 예를 들어, OpenAI에서 Claude 3를 통해 Antrophic을 사용하는 함수 호출 로직을 이동하는 경우 프롬프트를 재설계해야 할 필요가 있죠 😅.\n\n따라서 프롬프트를 다시 작성하고, 평가를 재평가하며, 출력물을 디버깅하는 데 많은 시간 ⏰을 투자해야 합니다. 이를 보다 똑똑하게 처리할 수 있는 방법이 있다면 좋을텐데요? 다행히도, DSPs와 같은 흥미로운 프레임워크는 LLM 제공자에 관계없이 프로그래밍에 중점을 둡니다. 자세한 내용은 참조할 자료에서 DSPy에 대해 더 깊이있게 알아볼 수 있습니다.\n\n# Declarative Self-Improving Language Programs (DSPy)\n\nDSPy 또는 선언적 자기 개선 언어 프로그램(Declarative Self-improving Language Programs, Khattab et al, 2023)은 처음으로 [2]에서 소개되었습니다. DSPy는 PyTorch와 같은 신경망 프레임워크에서 영감을 받아, 프롬프트보다는 프로그래밍에 중점을 둡니다.\n\n<div class=\"content-ad\"></div>\n\n간단히 말하자면, DSPy 프로그래밍 모델은 다음과 같은 추상화를 가지고 있습니다:\n\n- 필요한 손쓰기 프롬프트/세밀 조정을 대체할 서명.\n- Cot, REACT 등 다양한 프롬프트 엔지니어링 기술을 구현한 모듈.\n- 주어진 메트릭스를 기반으로 한 수동 프롬프트 엔지니어링을 자동화하는 옵티마이저\n\n더 자세한 설명은 참조 사항 중 [1]을 참고하십시오.\n\n# 음식 관련 엔티티에 DSPy를 사용한 NER\n\n<div class=\"content-ad\"></div>\n\n다음 섹션에서는 DSPy를 사용하여 NER 사용 사례를 살펴볼 것입니다.\n\n## 데이터\n\n사용할 데이터는 라면 🍜 한 그릇을 만들기 위한 차슈 돼지고기 레시피입니다. 아래 게시물에서 자세한 내용을 확인하세요:\n\n예시 데이터:\n\n<div class=\"content-ad\"></div>\n\n```js\n### 차슈 돼지고기 (라면 및 기타 용도)\n차슈 돼지고기는 라멘과 같은 일본 요리에 사용되는 돼지 배를 준비하는 전통적인 방법입니다.\n다소 시간이 걸릴 수 있지만 비교적 손쉽고 맛있는 결과물이 나옵니다.\n\n### 재료\n2 파운드의 돼지 배 또는 조금 더/적게\n2개의 대파 또는 작은 경우 3개\n1인치 크기의 생 생강 (약 4-6조각 나오는 양)\n2쪽의 마늘\n⅔컵의 사케\n⅔컵의 간장\n¼컵의 미린\n½컵의 설탕\n필요에 따라 조절 가능한 2컵의 물\n### 요령\n돼지고기를 준비하기 전에 줄 또는 부엌 실을 준비하고 가위 한 켤레를 준비하세요.\n해당 사항이 있다면 돼지고기의 외부 지방을 다듬어주세요. 그럼에도 불구하고 이후에는 여전히\n...\n```\n\n위의 데이터 외에도 TypedPredictor와 함께 사용할 Pydantic 데이터 모델을 설정해야 합니다:\n\n```js\nclass FoodMetaData(BaseModel):\n    reasoning: str = Field(description=\"엔티티가 정확한 이유\")\n    value: Union[str, int] = Field(description=\"엔티티의 값\")\n    entity: str = Field(description=\"실제 엔티티 즉, 돼지고기, 양파 등\")\n\nclass FoodMetaDatas(BaseModel):\n    context: List[FoodMetaData]\n```\n\n```js\nclass FoodEntity(BaseModel):\n    food: str = Field(description=\"유체 및 고체 음식, 즉 고기, 채소, 주류 등이 될 수 있습니다.\")\n    quantity: int = Field(description=\"레시피에 사용해야 하는 실제 양 또는 양\")\n    unit: str = Field(description=\"사용 중인 단위, 예를 들어 그램, 밀리리터, 파운드 등\")\n    physical_quality: Optional[str] = Field(description=\"재료의 특성\")\n    color: str = Field(description=\"음식의 색상\")\nclass FoodEntities(BaseModel):\n    entities: List[FoodEntity]\n```  \n\n<div class=\"content-ad\"></div>\n\n- FoodMetadatas는 각 엔티티의 컨텍스트 추출 + 추론 흐름의 일부입니다.\n- FoodEntities는 우리가 원하는 엔티티를 추출하는 데 사용됩니다.\n\n마지막으로, DSPy 프로그램이 옵티마이저를 위해 컴파일될 때, 우리는 dspy.Examplemodule을 사용하여 일부 훈련 예제를 만들 것입니다:\n\n```js\ntrainset = [\n    dspy.Example(\n        recipe=\"2개의 계란, 500그램 버터 및 10그램 그리르치즈로 프렌치 오믈렛 만들기\", \n        entities=[\n            FoodEntity(food=\"계란\", quantity=2, unit=\"\", physical_quality=\"\", color=\"흰색\"),\n            FoodEntity(food=\"버터\", quantity=500, unit=\"그램\", physical_quality=\"\", color=\"노랑\"),\n            FoodEntity(food=\"치즈\", quantity=10, unit=\"그램\", physical_quality=\"그리레\", color=\"노랑\")\n        ]\n    ).with_inputs(\"recipe\"),\n        ...\n    dspy.Example(\n        recipe=\"250g 밀가루, 1큰술 베이킹 파우더, 1그램 소금, 10g 설탕, 100ml 신선우유로 아메리칸 팬케이크 만들기\", \n        entities=[\n            FoodEntity(food=\"밀가루\", quantity=250, unit=\"그램\", physical_quality=\"\", color=\"흰색\"),\n            FoodEntity(food=\"베이킹 파우더\", quantity=1, unit=\"큰술\", physical_quality=\"\", color=\"흰색\"),\n            FoodEntity(food=\"소금\", quantity=1, unit=\"그램\", physical_quality=\"짠맛\", color=\"흰색\"),\n            FoodEntity(food=\"우유\", quantity=100, unit=\"밀\", physical_quality=\"지방\", color=\"흰색\"),\n        ]\n    ).with_inputs(\"recipe\")\n]\r\n```\n\n## 서명\n\n<div class=\"content-ad\"></div>\n\n데이터셋을 만들거나 수집한 후의 다음 단계는 DSPy 프로그램에 대한 서명을 작성하는 것입니다. 이것을 입력/출력 동작에 대한 선언적 명세로 생각할 수 있습니다:\n\n```js\nclass RecipeToFoodContext(dspy.Signature):\n    \"\"\"당신은 음식 AI 어시스턴트입니다. 엔티티, 엔티티의 값 및 추출된 값이 올바른 값인 이유를 추출하는 작업을 수행해야 합니다. \n    엔티티를 추출할 수 없는 경우 null을 추가하십시오\"\"\"\n    recipe: str = dspy.InputField()\n    context: FoodMetaDatas = dspy.OutputField()\n```\n\n```js\nclass RecipeToFoodEntities(dspy.Signature):\n    \"\"\"당신은 음식 AI 어시스턴트입니다. 레시피에서 음식과 관련된 메타데이터를 추출해야 합니다.\"\"\"\n    recipe: str = dspy.InputField()\n    entities: FoodEntities = dspy.OutputField()\n```\n\n- RecipeToFoodContext은 문맥 + 추론 호출에 사용되는 서명입니다. 여기에서 문자열 설명을 사용하여 LLM에 초기 지침을 제공했다는 점에 유의하십시오.\n- RecipeFoodEntities는 실제로 식별된 엔티티를 추출하는 서명에 해당합니다.\n\n<div class=\"content-ad\"></div>\n\n지금까지는 특별한 공학 작업이 아니라 Python 클래스/객체를 명시하는 것이었습니다 🐍. 코드는 또한 이해하기 비교적 쉽습니다. 무엇을 하는지, 입력이나 출력 등이 뭔지 잘 알 수 있죠.\n\n## Modules\n\n데이터셋을 생성하고 서명을 지정한 후에는 모듈을 작성할 준비가 되었습니다. 각 모듈은 Chain-of-Thought, ReAct 등 다양한 프롬프팅 기술을 \"추상화\"하는 멋진 기능이 있습니다. 또한 신경망 프레임워크에 익숙한 독자들을 위해 아래의 forward 메서드에 주목해주세요:\n\n```js\nclass ExtractFoodEntities(dspy.Module):\n    def __init__(self, temperature: int = 0, seed: int = 123):\n        super().__init__()\n        self.temperature = temperature\n        self.seed = seed\n        self.extract_food_context = dspy.TypedPredictor(RecipeToFoodContext)\n        self.extract_food_context_cot = dspy.TypedChainOfThought(RecipeToFoodContext)\n        self.extract_food_entities = dspy.TypedPredictor(RecipeToFoodEntities)\n        \n    def forward(self, recipe: str) -> FoodEntities:\n        food_context = self.extract_food_context(recipe=recipe).context\n        parsed_context = parse_context(food_context.context)\n        food_entities = self.extract_food_entities(recipe=parsed_context)\n        return food_entities.entities\n```\n\n<div class=\"content-ad\"></div>\n\n위 모듈은 dspy.Module 인터페이스를 사용하고 있습니다. dspy.Functional 인터페이스를 사용하여 모듈을 지정할 수도 있습니다:\n\n```js\nfrom dspy.functional import FunctionalModule, predictor, cot\n\nclass ExtractFoodEntitiesV2(FunctionalModule):\n    def __init__(self, temperature: int = 0, seed: int = 123):\n        super().__init__()\n        self.temperature = temperature\n        self.seed = seed\n    @predictor\n    def extract_food_context(self, recipe: str) -> FoodMetaData:\n        \"\"\"당신은 음식 AI 어시스턴트입니다. 엔티티, 엔티티의 값 및 추출된 값이 올바른 값인 이유를 추출하는 것이 작업입니다. \n        엔티티를 추출할 수 없는 경우 null을 추가하세요.\"\"\"\n        pass\n    @cot\n    def extract_food_context_cot(self, recipe: str) -> FoodMetaData:\n        \"\"\"당신은 음식 AI 어시스턴트입니다. 엔티티, 엔티티의 값 및 추출된 값이 올바른 값인 이유를 추출하는 것이 작업입니다. \n        엔티티를 추출할 수 없는 경우 null을 추가하세요.\"\"\"\n        pass\n    \n    @predictor\n    def extract_food_entities(self, recipe: str) -> FoodEntities:\n        \"\"\"당신은 음식 AI 어시스턴트입니다. 작업은 레시피에서 음식 엔티티를 추출하는 것입니다.\"\"\"\n        pass\n        \n    def forward(self, recipe: str) -> FoodEntities:\n        food_context = self.extract_food_context(recipe=recipe)\n        parsed_context = parse_context(food_context.context)\n        food_entities = self.extract_food_entities(recipe=parsed_context)\n        return food_entities\n```\n\n이를 통해 데코레이터 함수를 사용하여 표준 프롬프트 엔지니어링 기술을 지정할 수 있으며, 이는 매우 깔끔합니다. 또한 모듈에서 사용된 parse_context 메서드는 결과 JSON 콘텍스트를 문자열로 구문 분석하는 유틸리티 함수이며, 체인의 다음 단계에 대한 입력으로 사용될 것입니다.\n\n## DSPy 프로그램 실행하기\n\n<div class=\"content-ad\"></div>\n\n프로그램을 실행하려면 모듈의 인스턴스를 만들고 입력값을 사용하여 호출하십시오. 그러나 DSPy의 또 다른 멋진 기능은 모듈에 대한 dspy.Context를 지정할 수 있다는 것입니다:\n\n```js\nextract_food_entities = ExtractFoodEntities()\n\nwith dspy.context(lm=gpt4):\n    entities = extract_food_entities(recipe=\"Ten grams of orange dutch cheese,  \\\n    2 liters of water and 5 ml of ice\")\n    pprint(entities)\n```\n\n위의 프로그램은 다음 출력을 보여줍니다:\n\n```js\nFoodEntities(\n    entities=[\n        FoodEntity(\n            food='orange dutch cheese',\n            quantity=10,\n            unit='grams',\n            physical_quality=None,\n            color='orange',\n        ),\n        FoodEntity(\n            food='water',\n            quantity=2000,\n            unit='milliliters',\n            physical_quality=None,\n            color='clear',\n        ),\n        FoodEntity(\n            food='ice',\n            quantity=5,\n            unit='milliliters',\n            physical_quality=None,\n            color='clear',\n        ),\n    ],\n)\n```\n\n<div class=\"content-ad\"></div>\n\n이것은 다른 LLM(모델 상의 큰 언어 모델)을 시험해보거나, 예를 들어 DEV에는 gpt-3.5-turbo를 사용하고, PROD에서는 더 강인한 모델인 gpt-4-turbo-preview를 사용한다면 유용할 것입니다.\n\n## DSPy 프로그램 최적화하기\n\n이제 프로그램을 최적화하는 데 필요한 모든 구성 요소가 준비되었습니다 🎉. DSPy에서 최적화자는 DSPy 프로그램의 매개변수인 프롬프트와/또는 LM(언어 모델) 가중치를 조정할 수 있는 알고리즘입니다. 프로그램을 최적화하려면 최대화할 메트릭을 제공합니다.\n\n최적화 단계에서는 BootstrapFewShot 최적화자를 사용합니다. 그리고 최대화하려는 메트릭(어떤 파이썬 함수도 될 수 있음)은 아래에 표시되어 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```python\ndef validate_entities(example, pred, trace=None):\n    \"\"\"두 객체가 동일한지 확인합니다.\"\"\"\n    return example.entities == pred\n```\n\n최적화를 실행하려면 compile 메서드를 사용합니다:\n\n```python\nfrom dspy.teleprompt import BootstrapFewShot\n\nteleprompter = BootstrapFewShot(metric=validate_entities)\ncompiled_ner = teleprompter.compile(ExtractFoodEntitiesV2(), trainset=trainset)\n```\n\n저희 데이터셋에서 컴파일된 프로그램을 실행한 결과는 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nFoodEntities(\n    entities=[\n        FoodEntity(\n            food='삼겹살',\n            quantity=2,\n            unit='lb',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='파',\n            quantity=2,\n            unit='개',\n            physical_quality='작을 경우 3개',\n            color='',\n        ),\n        FoodEntity(\n            food='생강',\n            quantity=1,\n            unit='인치',\n            physical_quality='한 조각',\n            color='',\n        ),\n        FoodEntity(\n            food='마늘',\n            quantity=2,\n            unit='쪽',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='술',\n            quantity=2,\n            unit='⅔ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='간장',\n            quantity=2,\n            unit='⅔ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='미린',\n            quantity=1,\n            unit='¼ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='설탕',\n            quantity=1,\n            unit='½ 컵',\n            physical_quality=None,\n            color='',\n        ),\n        FoodEntity(\n            food='물',\n            quantity=2,\n            unit='컵',\n            physical_quality='필요에 따라 약간 더',\n            color='',\n        ),\n    ],\n)\r\n```\n\n프롬프트 엔지니어링에 반이나하 며 살짝 봐두 시간 정도만 투자한 것에 대해서 꽤 괜찮지 않나요? 💪!\n\n## LLM 검사\n\n프로그램을 이렇게 선언하는 것도 좋지만 LLM이 사용하는 기본 프롬프트를 확인하려면 어떻게 해야 할까요? 걱정 마세요. inspect_history를 사용해 보세요:\n\n\n<div class=\"content-ad\"></div>\n\n```js\r\ngpt4.inspect_history(n=1)\r\n```\r\n\r\n아래와 같은 출력이 나왔습니다:\r\n\r\n```js\r\n당신은 음식 AI 어시스턴트입니다. 레시피에서 음식 엔티티를 추출하는 것이 당신의 임무입니다.\r\n\r\n---\r\n\r\n다음 형식을 따르세요.\r\n레시피: ${recipe}\r\n음식 엔티티 추출: ${extract_food_entities}. 단일 JSON 객체로 응답하세요. JSON 스키마: {\"$defs\": {\"FoodEntity\": {\"properties\": {\"food\": {\"description\": \"고기, 채소, 주류 등과 같이 고체 및 액체 음식일 수 있습니다\", \"title\": \"음식\", \"type\": \"string\"}, \"quantity\": {\"description\": \"레시피에 사용해야 하는 음식의 정확한 양 또는 분량\", \"title\": \"분량\", \"type\": \"integer\"}, \"unit\": {\"description\": \"사용 중인 단위 (예: 그램, 밀리리터, 파운드 등)\", \"title\": \"단위\", \"type\": \"string\"}, \"physical_quality\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"description\": \"재료의 특성\", \"title\": \"물리적 품질\"}, \"color\": {\"description\": \"음식의 색깔\", \"title\": \"색깔\", \"type\": \"string\"}, \"required\": [\"food\", \"quantity\", \"unit\", \"physical_quality\", \"color\"], \"title\": \"FoodEntity\", \"type\": \"object\"}, \"properties\": {\"entities\": {\"items\": {\"$ref\": \"#/$defs/FoodEntity\"}, \"title\": \"Entities\", \"type\": \"array\"}, \"required\": [\"entities\"], \"title\": \"FoodEntities\", \"type\": \"object\"}\r\n---\r\n레시피:\r\npork belly:\r\n{\r\n\"reasoning\": \"차슈 포크의 주 재료로 2 파운드의 삼겹살을 사용하도록 레시피에서 명시되어 있습니다.\",\r\n\"value\": \"2 파운드\",\r\n\"entity\": \"삼겹살\"\r\n}\r\ngreen onions:\r\n{\r\n\"reasoning\": \"2개의 대파가 필요하며, 작은 대파인 경우 3개를 사용합니다.\",\r\n\"value\": \"2 또는 3\",\r\n\"entity\": \"대파\"\r\n}\r\nfresh ginger:\r\n{\r\n\"reasoning\": \"레시피에는 신선한 생강 1인치가 필요하며, 이는 레시피에 대략 4~6개의 조각을 제공합니다.\",\r\n\"value\": \"1인치\",\r\n\"entity\": \"생강\"\r\n}\r\ngarlic:\r\n{ \r\n\"reasoning\": \"재료 중에는 마늘 2쪽이 필요합니다.\",\r\n\"value\": \"2쪽\",\r\n\"entity\": \"마늘\"\r\n}\r\nsake:\r\n{\r\n\"reasoning\": \"풍미를 위해 요리 액체에 ⅔컵의 사케가 사용됩니다.\",\r\n\"value\": \"⅔컵\",\r\n\"entity\": \"사케\"\r\n}\r\nsoy sauce:\r\n{\r\n\"reasoning\": \"요리 액체에 ⅔컵의 간장이 추가되어 요리의 맛을 더합니다.\",\r\n\"value\": \"⅔컵\",\r\n\"entity\": \"간장\"\r\n}\r\nmirin:\r\n{\r\n\"reasoning\": \"달콤하고 깊은 맛을 위해 레시피에 ¼컵의 미린이 포함됩니다.\",\r\n\"value\": \"¼컵\",\r\n\"entity\": \"미린\"\r\n}\r\nsugar:\r\n{\r\n\"reasoning\": \"요리 액체를 달게하기 위해 ½컵의 설탕을 사용합니다.\",\r\n\"value\": \"½컵\",\r\n\"entity\": \"설탕\"\r\n}\r\nwater:\r\n{\r\n\"reasoning\": \"삼겹살을 위한 요리 액체를 만들기 위해 2컵의 물(필요에 따라 더 추가 가능)이 필요합니다.\",\r\n\"value\": \"2컵\",\r\n\"entity\": \"물\"\r\n}\r\n음식 엔티티 추출: json\r\n{\r\n\"entities\": [\r\n{\r\n\"food\": \"삼겹살\",\r\n\"quantity\": 2,\r\n\"unit\": \"파운드\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"대파\",\r\n\"quantity\": 2,\r\n\"unit\": \"개\",\r\n\"physical_quality\": \"작으면 3개\",\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"생강\",\r\n\"quantity\": 1,\r\n\"unit\": \"인치\",\r\n\"physical_quality\": \"조각\",\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"마늘\",\r\n\"quantity\": 2,\r\n\"unit\": \"쪽\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"사케\",\r\n\"quantity\": 2,\r\n\"unit\": \"⅔컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"간장\",\r\n\"quantity\": 2,\r\n\"unit\": \"⅔컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"미린\",\r\n\"quantity\": 1,\r\n\"unit\": \"¼컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"설탕\",\r\n\"quantity\": 1,\r\n\"unit\": \"½컵\",\r\n\"physical_quality\": null,\r\n\"color\": \"\"\r\n},\r\n{\r\n\"food\": \"물\",\r\n\"quantity\": 2,\r\n\"unit\": \"컵\",\r\n\"physical_quality\": \"필요에 따라 추가\",\r\n\"color\": \"\"\r\n}\r\n]\r\n}\r\n``\r\n```\r\n\r\n# 마무리말\n\n<div class=\"content-ad\"></div>\n\n이 게시물의 목적은 DSPy 라이브러리를 익히고 TypedPredictor 클래스를 주로 NER 사용 사례에 사용하는 방법을 살펴보는 것이었습니다. 이제 여러분도 더 나은 이해를 하셨으면 좋겠습니다!\n\n첫 인상을 요약하면 다음과 같습니다:\n\n- DSPy는 사용하기 쉽고 시작하기 쉽습니다 ✅\n- 프롬프트 엔지니어링에 시간을 낭비하는 대신, 프레임워크가 대신 처리해 주는 것이 아주 좋습니다 ✅\n- LLM을 최적화 및 PyTorch와 같은 아이디어를 사용하여 \"전형적인\" ML 문제로 다루는 것이 매우 좋습니다 ✅\n- 여전히 발전 중이며 아마도 \"운영\"에 준비가 되지는 않았습니다 ❌\n- 프로그램을 디버깅할 때 무슨 일이 일어나고 있는지 이해하기 쉽도록 더 나은 로깅/추적이 필요합니다 ❌\n\n그러나 프롬프트를하는 대신 LLM을 프로그래밍하는 접근 방식을 좋아합니다. 이것은 분야에서 흥미로운 발전이며 예를 들어, 미래의 복합 AI 시스템에 대한 것입니다.\n\n<div class=\"content-ad\"></div>\n\nDSPY의 채택 및 추가 개발을 기대하고 있어요.\n\n# 참고 자료\n\n- 💻 DSPy 소개: 인사 대신 프로그래밍으로!\n- 💻 DSPy: 선언형 언어 모델 호출을 자가 개선 파이프라인으로 컴파일하기\n- 💻 DSPy 심층 탐구","ogImage":{"url":"/assets/img/2024-06-22-UsingDSPyforextractingmetadataNERstyle_0.png"},"coverImage":"/assets/img/2024-06-22-UsingDSPyforextractingmetadataNERstyle_0.png","tag":["Tech"],"readingTime":15},{"title":"애니메이션 데이터셋으로 Gemma-2b-it 미세 조정하는 방법","description":"","date":"2024-06-22 20:45","slug":"2024-06-22-FineTuningGemma-2b-itonAnimeDataset","content":"\n\n![FineTuningGemma-2b-itonAnimeDataset](/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_0.png)\n\n소개\n\n미세 조정 개념을 시작하기 전에, 먼저 \"왜 이러한 강력한 모델들에 대해 미세 조정이 필요한가?\"라는 질문에 대답해야 합니다.\n\n이 질문에 대답하기 위해 먼저 이 LLMs이(가) 인터넷에서 공개 데이터의 큰 말뭉치로 훈련되어 있으며 따라서 다양한 주제에 대한 아이디어를 가지고 있다는 것을 이해해야 합니다. 그러나 이들은 모든 주제에 대해 자세히 이해하거나 뱅킹이나 보험과 같은 개인 데이터에 대한 지식을 갖고 있지 않을 수도 있습니다. 특정 데이터에 대한 이해를 보완하기 위해, 우리는 그들을 이 특정 데이터에 대해 특별히 미세 조정합니다. 애니메이션 데이터는 공개적으로 이용 가능하지만, 이것들은 이 LLMs를 훈련하는 데 사용된 훈련 데이터의 매우 작은 조각일 수 있습니다. 따라서 LLMs가 애니메이션에 대한 개념을 가지고 있더라도, 그들의 정보 기반이 우리가 필요한 것만큼 풍부하지 않을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n자원\n\n이제 세밀 조정이 필요한 이유에 대한 답변을 얻었으니, 이제 LLM을 세밀 조정하는 방법으로 넘어갈 수 있습니다. 저는 이 활동을 위해 사용한 자원은 다음과 같습니다.\n\n- 컴퓨팅 자원 — Google Colab T4 GPU\n- 데이터 세트 — https://www.kaggle.com/datasets/dbdmobile/myanimelist-dataset\n\nColab을 사용하기를 강력히 권장드립니다. 로컬 머신에 강력한 GPU 기능이 없는 경우에 말이죠. 다음으로, 우리는 세밀 조정된 오픈 소스 LLM을 이해하는 데 도움이 되는 두 가지 중요한 개념을 먼저 이해할 것입니다.\n\n<div class=\"content-ad\"></div>\n\nLoRA & QLoRA\n\nGemma-2b 모델에는 20억 개의 매개변수가 있습니다(당연한 얘기네요). 이러한 매개변수의 가중치를 조정하는 것은 매우 비싼 계산 작업일 수 있습니다. 이러한 모델들은 많은 VRAM을 소모할 수 있으며 모든 사용자가 이와 같은 높은 계산 능력을 갖춘 기계에 액세스할 수 있는 것은 아닙니다. 위의 계산 문제를 해결하기 위해 두 가지 기술이 널리 사용됩니다. 이 기술들은 LLMs를 세밀하게 조정할 수 있도록 합니다.\n\n- LoRA — 낮은 순위 적응\n- QLoRA — 양자화된 낮은 순위 적응\n\nLoRA — 이미 언급한 대로, 이러한 LLMs에는 수십억 개의 매개변수가 있습니다. 이러한 매개변수는 일반적으로 행렬로 표현됩니다. 이러한 고차원 행렬의 흥미로운 특성 중 하나는 완전 순위 행렬이 아니라는 것입니다. 즉, 행렬의 모든 열이 선형 독립이 아닙니다(한 열이 다른 열들의 선형 결합으로 표현될 수 있기 때문에 해당 열은 추가 정보를 제공하지 않고 차원만 늘려주는 것입니다). 그래서 LoRA는 이러한 거대한 가중치 행렬을 두 개의 작은 행렬인 A, B로 분해합니다. W = AB와 같이 W가 예를 들어 1000x1000 차원이라면, A는 1000xr 차원을 가지고 B는 r*1000 차원을 갖습니다. 그런 다음 세밀한 조정을 위해 이러한 작은 행렬의 매개변수를 조정하려고 시도합니다. r 하이퍼파라미터는 lora 구성을 정의할 때 선택하는 것입니다. r 값이 높을수록 우수한 결과를 얻을 수 있지만, 계산 능력이 필요하다는 대가가 따릅니다. 따라서 1000000 개의 매개변수를 조정해야 하는 대신, 대신 1000r + 1000r 개의 매개변수를 조정하게 됩니다. 일반적으로 r 값은 (8-64) 범위에 있으며 매우 높은 차원의 가중치 행렬을 다룰 때, 조정 가능한 매개변수 수가 상당히 줄어듭니다. 마지막으로 세밀한 조정 이후, 이러한 LoRA 가중치는 베이스 모델과 병합되어 세밀하게 조정된 단일 모델을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\nLoRA는 학습 매개변수의 수를 줄여주죠, 이제 모델을 파인 튜닝할 수 있을까요?\n\n네, 파인 튜닝은 가능하지만 더 개선할 여지도 있어요. 그런데 여기에 QLoRA가 등장합니다. QLoRA의 주요 목표는 단일 GPU에서 LLMs를 파인 튜닝하는 편리한 방법을 제공하는 것이죠(그들이 언급한 단일 GPU는 VRAM이 48GB입니다). QLoRA가 하는 일은 매우 기본적이면서 메모리 사용량을 줄이는 견고한 방법입니다. 모델 가중치의 정밀도를 변경합니다. 컴퓨터 시스템에서 모든 숫자는 특정 정밀도로 표현됩니다. 기본적으로 이러한 모델의 가중치는 32비트로 표현됩니다. QLoRA는 이러한 수를 32비트 대신 8 또는 4와 같이 낮은 비트로 표현하려고 시도합니다. 그리고 그 동작은 해당 수를 낮은 정밀도로 반올림하거나 버리는 것입니다. 이 과정을 통해 4배에서 8배까지 감소할 수 있습니다. 이를 위해 이들은 이론적으로 가장 최적인 것으로 설명되는 4비트 Normal-Float라는 새로운 데이터 유형을 도입했습니다(이는 대부분 사전 훈련된 모델 가중치의 경우입니다). 그들은 또한 메모리 증가를 피하기 위해 paged optimizers라는 개념을 소개했습니다. 이 개념은 GPU 용량이 거의 가득 찬 경우, 옵티마이저 상태를 CPU로 옮기도록 하는 것입니다. 그리고 GPU 메모리가 다시 사용 가능해지면 GPU로 다시 가져옵니다.\n\n코딩\n\n필요한 이론을 모두 숙지한 후에 이제 코딩 섹션으로 넘어갈 차례입니다. 먼저 필요한 라이브러리를 설치하고 가져오는 것부터 시작하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n!pip3 install -q -U bitsandbytes==0.42.0\n!pip3 install -q -U peft==0.8.2\n!pip3 install -q -U trl\n!pip3 install -q -U accelerate==0.27.1\n!pip3 install -q -U datasets==2.17.0\n!pip3 install -q -U transformers\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom trl import SFTTrainer\nimport torch\nimport pandas as pd\nimport bitsandbytes as bnb\nfrom datasets import Dataset\nimport transformers\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n```\n\n위와 같이 import 구문을 작성했습니다. 이제 사용할 모델에 대한 qlora config를 설정할 수 있습니다.\n\n```js\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n```\n\n여기서 우리는 모델 웨이트를 4비트로 로드하고 싶다고 지정했습니다. \"nf4\"로 유형을 지정했는데, 이는 이전에 언급한 일반적인 부동 소수점을 의미합니다. 마지막 매개변수인 bnb_4bit_compute_dtype는 사용할 그래디언트의 데이터 유형을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n이제 모델을 다운로드하고 설정을 로드할 수 있습니다.\n\n```js\nmodel_id = \"google/gemma-2b-it\"\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\ntokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)\n```\n\n참고로, Gemma를 사용하려면 먼저 액세스를 요청해야 합니다. 그리고 다운로드하려면 먼저 hugging face에 로그인하여 액세스 토큰을 제공해야 다운로드할 수 있습니다. 위의 코드 셀을 실행하기 전에 huggingface_hub의 notebook_login을 사용하고 액세스 토큰을 제공하는 것을 추천합니다.\n\n미세 조정을 시작하기 전에 모델의 현재 애니메이션에 대한 지식 베이스를 먼저 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```py\ndef generate_response(model, tokenizer, prompt, tokens=100):\n    input_ids = tokenizer(prompt, return_tensors=\"pt\")\n    input_ids.to('cuda')\n    outputs = model.generate(**input_ids,max_new_tokens=tokens)\n    return tokenizer.decode(outputs[0])\n\nprompt = '''Question : Tell me something about the anime Naruto?\nAnswer :'''\n\nprint(generate_response(model,tokenizer,prompt))\n```\n\n만약 위 셀을 실행하면 아래와 같은 출력을 얻게 됩니다:\n\n`bos`Question : Tell me something about the anime Naruto? Answer :`eos`Naruto는 Masashi Kishimoto가 만든 일본의 애니메이션 시리즈입니다. 이 시리즈는 나루토 우즈마키의 모험을 따릅니다. 나루토는 세계 최고의 닌자가 되기를 꿈꾸는 젊은 닌자입니다. 이 시리즈는 200회가 넘는 에피소드와 영화로 큰 성공을 거두었습니다. 나루토는 캐릭터, 스토리텔링 및 애니메이션에 대해 칭찬을 받았습니다.`eos`\n\n나쁘지 않네요! 나루토가 매우 인기 있는 애니메이션으로 여겨지기 때문에 모델이 그것에 관한 정보를 가지고 있다고 예상했습니다. 이제 모델이 애니메이션에 대해 가진 지식을 향상시키는 것이 목표입니다. 그러기 위해 먼저 데이터셋을 탐색하여 모델에 추가할 수 있는 어떤 정보가 있는지 살펴보아야 합니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\r\nanime_df = pd.read_csv(\"drive/My Drive/LLM/Data/anime_dataset.csv\")\r\n\"\"\"\r\nanime_id: 각 애니메이션에 대한 고유 ID입니다.\r\nName: 애니메이션의 원래 언어로 된 이름입니다.\r\nEnglish name: 애니메이션의 영어 이름입니다.\r\nOther name: 애니메이션의 원어로 된 이름 또는 제목입니다(일본어, 중국어 또는 한국어일 수 있습니다).\r\nScore: 애니메이션에 매겨진 평점이나 등급입니다.\r\nGenres: 쉼표로 구분된 애니메이션의 장르입니다.\r\nSynopsis: 애니메이션 플롯에 대한 간단한 설명 또는 요약입니다.\r\nType: 애니메이션의 유형(예: TV 시리즈, 영화, OVA 등)입니다.\r\nEpisodes: 애니메이션의 에피소드 수입니다.\r\nAired: 애니메이션이 방영된 날짜입니다.\r\nPremiered: 애니메이션이 처음 방영된 시즌과 년도입니다.\r\nStatus: 애니메이션의 상태(예: 방영 종료, 현재 방영 중 등)입니다.\r\nProducers: 애니메이션의 제작사 또는 프로듀서입니다.\r\nLicensors: 애니메이션의 라이센서(예: 스트리밍 플랫폼)입니다.\r\nStudios: 애니메이션에 참여한 애니메이션 스튜디오입니다.\r\nSource: 애니메이션의 소스 자료(예: 만화, 라이트 노벨, 오리지널)입니다.\r\nDuration: 각 에피소드의 기간입니다.\r\nRating: 애니메이션의 연령 등급입니다.\r\nRank: 인기도 또는 기타 기준에 따라 매겨진 애니메이션의 순위입니다.\r\nPopularity: 애니메이션의 인기 순위입니다.\r\nFavorites: 사용자들이 즐겨찾은 횟수입니다.\r\nScored By: 애니메이션을 평가한 사용자 수입니다.\r\nMembers: 플랫폼에 애니메이션을 리스트에 추가한 회원 수입니다.\r\nImage URL: 애니메이션의 이미지 또는 포스터 URL입니다.\r\n\"\"\"\r\n```\r\n\r\n우리는 이 데이터 사전을 캐글 링크에서 가져왔고 여기서 각 애니메이션에 대한 이름, 영어 이름부터 장르, 시놉시스, 에피소드 수, 제작 및 애니메이션 스튜디오 등의 매우 포괄적인 기능 목록이 있는 것을 볼 수 있습니다.\r\n\r\n이 프로젝트에서는 모델을 교육하는 데 사용할 세 가지 유형의 지시 형식을 작성할 것입니다.\r\n\r\n- 일반 정보 I — 애니메이션 이름(이름 변형 포함) 및 이야기와 장르.\r\n- 일반 정보 II — 애니메이션 이름 및 제작사, 애니메이션 스튜디오, 에피소드 수와 같은 세부 정보.\r\n- 일반 정보 III — 애니메이션 이름 및 등급, 인기도, 사용자 평가와 같은 메트릭스.\n\n<div class=\"content-ad\"></div>\n\n```js\r\ndef create_generic_information_1(df):\n  questions = []\n  answers = []\n  for name, variant, genre, synopsis in zip(df['English name'], df['Name'], df['Genres'], df['Synopsis']):\n    question = f\"애니메이션 {name} aka {variant}은(는) 무엇에 대해요?\"\n    answer = f\"애니메이션 {name} aka {variant}은(는) {genre} 장르의 애니메이션입니다. 줄거리는 다음과 같습니다: {synopsis}\"\n    questions.append(question)\n    answers.append(answer)\n\n  df['GI1_Question'] = questions\n  df['GI1_Answer'] = answers\n  return df\n\ndef create_generic_information_2(df):\n  questions = []\n  answers = []\n  for name, production_name, animation_house, number_of_episodes in zip(df['English name'],df['Producers'], df['Studios'], df['Episodes']):\n    question = f\"{name}의 제작사와 애니메이션 스튜디오는 누구였나요?\"\n    answer = f\"애니메이션 {name}은(는) {production_name}에 의해 제작되었습니다. 애니메이션은 {animation_house}에서 작업되었고, 이 중 {number_of_episodes}화가 있습니다.\"\n    questions.append(question)\n    answers.append(answer)\n\n  df['GI2_Question'] = questions\n  df['GI2_Answer'] = answers\n  return df\n\ndef create_generic_information_3(df):\n  questions = []\n  answers = []\n  for name, rating, score, votes in zip(df['Name'], df['Rating'], df['Score'], df['Scored By']):\n    question = f\"애니메이션 {name}의 리뷰는 어떤가요?\"\n    answer = f\"애니메이션 {name}은(는) 평가는 {rating}이고, {votes}명의 사용자에 의해 평가되었으며 점수는 {score}입니다.\"\n    questions.append(question)\n    answers.append(answer)\n\n  df['GI3_Question'] = questions\n  df['GI3_Answer'] = answers\n  return df\r\n``` \n\n이제부터 우리가 진행하기 전에 한 가지 알아야 할 사항이 있습니다. 각 LLM에는 명령을 입력하고 훈련하기 위한 특정 템플릿이 있습니다. 따라서 먼저 해당 템플릿에 기능을 로드한 다음 모델에 입력해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndef formatting_func(question, answer):\n    text = f\"<start_of_turn>user\\n{question}<end_of_turn> <start_of_turn>model\\n{answer}<end_of_turn>\"\n    return text\n\ndef generate_training_prompts(df, question_col, answer_col):\n  train_samples = []\n  for question, answer in zip(df[question_col], df[answer_col]):\n     train_samples.append(formatting_func(question, answer))\n  return train_samples\n\ntraining_prompts = []\n\nfor identifier in range(1,4):\n  question_col = f\"GI{identifier}_Question\"\n  answer_col = f\"GI{identifier}_Answer\"\n  samples = generate_training_prompts(anime_df,question_col, answer_col)\n  training_prompts += samples\n\ntraining_dataframe = pd.DataFrame()\ntraining_dataframe['instruction'] = training_prompts\ntraining_dataframe = training_dataframe.sample(frac=1,random_state=42)\ntraining_df = Dataset.from_pandas(training_dataframe)\n```\n\n위의 템플릿은 다음과 같습니다:\n\nf”`start_of_turn`user\\n'question'`end_of_turn` `start_of_turn`model\\n'answer'`end_of_turn`”\n\n위 템플릿은 각 학습 레코드마다 질문과 준비된 답변을 넣어야 하는 두 가지 매개변수만 가지고 있습니다. 따라서 위의 코드는 각 특성에 대해 이 템플릿 내에 질문과 답변을 감싸는 것뿐입니다. 마지막에는 학습을 위해 판다스 데이터프레임을 Dataset 객체로 변환합니다.\n\n<div class=\"content-ad\"></div>\n\n학습 데이터가 이제 준비되었으므로, LoRA를 사용하여 모델을 세밀하게 튜닝하기 위해 모델을 설정할 수 있게 되었습니다.\n\n```js\n#1 \nmodel.gradient_checkpointing_enable()\n#2 \nmodel = prepare_model_for_kbit_training(model)\n\n#3 \ndef find_all_linear_names(model):\n  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n  lora_module_names = set()\n  for name, module in model.named_modules():\n    if isinstance(module, cls):\n      names = name.split('.')\n      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n    if 'lm_head' in lora_module_names: # needed for 16-bit\n      lora_module_names.remove('lm_head')\n  return list(lora_module_names)\n\n#4 \nmodules = find_all_linear_names(model)\n\n#5 \nlora_config = LoraConfig(\n    r=64,\n    lora_alpha=32,\n    target_modules=modules,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\n#6\nmodel = get_peft_model(model, lora_config)\n\n#7\ntrainable, total = model.get_nb_trainable_parameters()\nprint(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")\r\n```\n\n이제 이를 단계별로 이해해봅시다.\n\n- 우리는 체크포인트를 사용하여 그라디언트를 저장할 수 있도록 설정합니다.\n- 모델을 k비트(QLoRA) 학습용으로 준비합니다.\n- 모델의 모든 선형 레이어의 이름을 반환하는 함수를 생성합니다. 이 함수는 모델의 키퀴리, 값, 그리고 출력 레이어를 반환합니다. 여기서 왜 이러한 레이어만을 반환하는지에 대해서 제가 완전히 확신하지는 못합니다. 그러나 아마도 어텐션 구성 요소(키, 쿼리, 값)가 다른 레이어보다 언어 이해에 중요한 역할을 하는 것으로 생각됩니다. 이 부분에서 잘못될 수도 있으며, 누군가가 제게 지적해 주시면 좋을 것 같습니다.\n- (3)에서 함수를 호출합니다.\n- LoRA 구성을 정의합니다. 여기서 r은 행렬을 분해하는 것에 대해 이전에 논의한 것과 동일합니다. lora alpha는 스케일링 요인을 말하며, lora 가중치가 기본 모델에 얼마나 강하게 영향을 미치는지를 나타냅니다.\n- LoRA 구성이 추가된 peft 모델 객체를 가져옵니다.\n- LoRA 구성에 기반하여 몇 개의 매개변수를 훈련하고 있는지 확인합니다. (결과: Trainable: 78446592 | total: 2584619008 | Percentage: 3.0351%). 이는 모델의 총 매개변수 중 3%만을 세밀하게 튜닝하고 있다는 것을 의미합니다. 3%로도 몇 번의 colab 메모리 부족이 발생했는데, 이는 LSTM 세밀 튜닝이 얼마나 계산적으로 비싼지를 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n이제 훈련 프로세스를 시작할 수 있습니다.\n\n```js\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=training_df,\n    dataset_text_field=\"instruction\",\n    peft_config=lora_config,\n    args=transformers.TrainingArguments(\n        per_device_train_batch_size=1,\n        gradient_accumulation_steps=4,\n        warmup_steps=0.03,\n        max_steps=100,\n        learning_rate=2e-4,\n        logging_steps=1,\n        output_dir=\"outputs\",\n        optim=\"paged_adamw_8bit\",\n        save_strategy=\"epoch\",\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n)\nmodel.config.use_cache = False  # 경고 메시지를 무시합니다. 추론을 위해 다시 활성화하십시오!\ntrainer.train()\n```\n\nLLM을 훈련시키기 위해 허깅페이스의 SFTTrainer 클래스를 사용합니다. 모델, 데이터셋, 데이터셋의 텍스트 열, lora 구성 및 몇 가지 훈련 인수를 전달합니다. 그런 다음 실행을 설정합니다.\n\n<img src=\"/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_1.png\" />\n\n<div class=\"content-ad\"></div>\n\n트레이닝 손실은 각 단계마다 여기에 표시됩니다. 실행이 완료되면 LoRA 레이어가 훈련됩니다. 이제 해야 할 일은 LoRA 레이어를 원래 모델로 병합하는 것입니다.\n\n```python\nft_model_path = \"drive/My Drive/LLM/Model/FT Model/\"\ntokenizer_path = \"drive/My Drive/LLM/Model/Tokenizer/\"\n\ntrainer.model.save_pretrained(ft_model_path)\ntokenizer.save_pretrained(tokenizer_path)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map={\"\": 0},\n)\nmerged_model = PeftModel.from_pretrained(base_model, ft_model_path)\nmerged_model = merged_model.merge_and_unload()\n```\n\n먼저 토크나이저와 훈련된 LoRA 레이어를 저장합니다(토크나이저를 다시 저장할 필요는 없습니다. 이전에 이미 한 번 다운로드하고 전혀 변경하지 않았습니다). 그 다음 Gemma-2b-it 모델을 다시로드하여 LoRA 레이어와 병합합니다.\n\n마지막 진행해야 할 단계는 세부 조정된 모델을 추론하는 것이며, 동일한 예시를 사용하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nprompt = '''애니메이션 나루토에 대해 알려주세요.\n대답 :'''\n\nprint(generate_response(merged_model, tokenizer, prompt))\n```\n\n`bos`애니메이션 나루토에 대해 알려주세요. 대답 :`eos`애니메이션 나루토는 액션, 모험, 판타지 장르의 애니메이션입니다. 줄거리는 다음과 같습니다 : 은밀한 잎 마을의 닌자 그룹이 마을 주민들을 돕기 위해 은밀한 잎의 땅으로 파견됩니다. 그러나 마을 리더 인 오로치마루에게 배신당해야하며 도망쳐야 합니다. 애니메이션 나루토는 1997년에 처음 방영되었으며 총 1.0 에피소드가 있습니다.\n\n그다지 좋지 않은 결과로 보입니다, 그렇지 않습니까?\n\n맞습니다. 하지만 1번의 에포크조차 교육시키지 않았으므로 모델을 더 많은 단계나 에포크로 교육하면 모델 출력이 향상될 것입니다. 그러나 여기서 주목할 점은 출력에서 이제 우리가 특징으로 포함했던 애니메이션의 장르를 제공하고 있다는 것입니다. 그래서 세밀한 조정이 애니메이션에 대한 지식베이스를 변경했음을 생각해봅니다 :)\n\n\n<div class=\"content-ad\"></div>\n\n마침내 이 기사를 읽어주셔서 정말 감사합니다. 피드백이나 제안 사항이 있으시면 알려주세요. 다음 기사에 반영하여 더 나은 내용을 제공하도록 하겠습니다.\n\n건배하세요!","ogImage":{"url":"/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_0.png"},"coverImage":"/assets/img/2024-06-22-FineTuningGemma-2b-itonAnimeDataset_0.png","tag":["Tech"],"readingTime":14},{"title":"LangChain의 새로운 도구, LangGraph 쉽게 설명하기","description":"","date":"2024-06-22 20:43","slug":"2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms","content":"\n\n# 소개\n\n하지만 왜 우리는 상태와 상태 전이 제어로 다시 돌아가고 있을까요? 자율 인공 지능 에이전트와 함께 우리는 상태 제어와 전이 개념을 넘어서 왔다고 생각했는데요?\n\n자율 에이전트의 출력을 살펴보면, 에이전트가 지속적으로 생성하는 작업 순서를 주목할 것입니다.\n\nLangGraph의 목표는 자율 인공 지능 에이전트를 실행할 때 일정한 수준의 제어를 갖는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n죄송합니다. 이 기사가 길었지만, Graph의 기본 원칙이 무엇인지 정말로 파악하고 싶었습니다.\n\n# 현황\n\n아래 이미지를 고려해보면, 이것이 대부분의 사람들이 대화형 UI를 위한 대화와 프로세스 흐름을 생성하는 사용자 인터페이스의 디자인 및 개발을 알게 된 방식입니다.\n\n디자인 기능은 노드 및 엣지라는 두 가지 주요 범주로 나뉠 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n노드는 블록으로, 때로는 자산으로도 불립니다. 아래 그림에서 디자인 캔버스에는 다섯 개의 노드가 있습니다. 이 노드 간에는 링크 또는 엣지라고도 하는 연결이 있습니다. 엣지는 가능한 대상 노드나 노드를 보여줍니다.\n\n## 프롬프트 체이닝\n\n대형 언어 모델의 출현과 함께 프롬프트 체이닝이 등장했습니다...\n\n프롬프트 체이닝은 언어 모델과 작업할 때 사용되는 기술로, 여러 프롬프트(노드)가 서로 순차적으로 연결(엣지를 통해)되어 서로 관련된 작업이나 단계를 안내하는 것으로 설명될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 방법은 큰 작업을 작은 관리 가능한 부분으로 나눠 더 복잡하고 세밀한 결과물을 얻는 데 사용됩니다.\n\n다음은 프롬프트 체이닝 작동 방식에 대해 간단히 설명한 것입니다:\n\n- 작업 분해(노드): 복잡한 작업이 작은 순차적인 단계로 나누어집니다. 각 단계는 전체 목표의 특정 부분을 달성하는 데 사용됩니다.\n- 각 단계에 대한 프롬프트 생성(엣지): 각 단계에 대해 필수 출력물 생성을 위해 구체적인 프롬프트가 만들어집니다. 이러한 프롬프트는 해당 부분 작업에 집중되고 명확하게 설계됩니다.\n- 순차 실행: 언어 모델은 첫 번째 프롬프트를 처리하고 출력물을 생성합니다. 이 출력물은 다음 시퀀스의 다음 프롬프트의 일부로 사용됩니다.\n\n그러나 알아둬야 할 점은, 프롬프트 체이닝은 챗봇 흐름 구축과 동일한 원칙에 기반합니다. 따라서 이전과 같은 문제, 즉 엄격한 상태 머신이 존재합니다.\n\n<div class=\"content-ad\"></div>\n\n참으로, 프롬프트 체이닝에는 각 노드의 입력에 몇 가지 유연성을 도입하는 요소가 있어서 출력에는 동적 변화가 발생합니다. 그러나 전반적으로 시퀀스는 고정되고 엄격하게 유지됩니다.\n\n## 도전 과제\n\n이 방법론은 흐름을 세심하게 지정해야 하며 각 결정 지점을 정의해야 합니다. 이러한 이유로 본질적으로 상태 기계이며 대화 트리는 서로 다른 상태(노드)와 대화가 이동해야 하는 결정 지점(엣지)에 의해 정의됩니다.\n\n엣지는 대화 상태/대화 턴이 이동할 수 있는 옵션으로 볼 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그래서 이 방법론의 한계로 인해 너무 엄격하다는 도전 과제에 닥치게 되었습니다. 대체로 변화를 원하는 욕구가 있으며, 융통성을 도입하고 싶어하는 분위기입니다.\n\n# 에이전트 입력\n\n자율 주체들은 최근에 소개되었으며, 에이전트의 자율성 수준은 놀라울 정도였습니다. 에이전트는 실시간으로 사건의 연쇄 또는 순서를 생성하고 이 일시적인 연쇄를 따라 최종적인 답변이 도출될 때까지 따릅니다.\n\n이것을 일회용 연쇄로 생각할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n아래 예시를 고려해보면, 에이전트에게 매우 모호한 질문을 할 수 있습니다. 예를 들어 \"아이폰의 아버지로 평가받는 사람은 누구이며, 그의 출생 연도의 제곱근은 무엇입니까?\"\n\n또는 \n\n\"일반적으로 아이폰의 아버지로 평가받는 사람의 출생 연도의 제곱근은 무엇입니까?\" \n\n그리고 아래와 같이, 에이전트는 실시간으로 체인을 생성하여 질문을 반영하고 행동, 관찰, 사고, 행동, 관찰, 사고의 프로세스를 거쳐 최종 답변에 도달합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n> 새 AgentExecutor 체인에 들어갔어요...\n아이폰의 아버지로 알려진 사람과 태어난 해를 알아내야 해요. 그리고 그의 출생 연도의 제곱근을 계산할 거예요.\n행동: 검색\n행동 입력: 아이폰 아버지 출생 연도\n관찰: 가족. 스티븐 폴 잡스는 조앤 캐롤 스키블과 아브둘파타 \"존\" 잔달리(아랍어: عبد الف ...)가 산프란시스코, 캘리포니아에서 1955년 2월 24일에 태어났어요.\n생각: 스티브 잡스가 아이폰의 아버지로 알려지고 1955년에 태어났다는 걸 알았어요. 이제 그의 출생 연도의 제곱근을 계산할 거예요.\n행동: 계산기\n행동 입력: sqrt(1955)\n관찰: 답변: 44.21538193886829\n생각: 이제 마지막 답을 알게 되었어요.\n최종 답변: 스티브 잡스가 아이폰의 아버지로 알려지고, 그의 태어난 연도(1955년)의 제곱근은 약 44.22입니다.\n\n> 체인을 마쳤어요.\n'스티브 잡스가 아이폰의 아버지로 알려지고, 그의 태어난 연도(1955년)의 제곱근은 약 44.22입니다.\n```\n\n## 도전과제\n\n에이전트와 저에게 가장 많이 들은 상수적 비판점은 에이전트들의 높은 자율성입니다.\n\n생산자들은 에이전트에 어느 정도의 통제권을 가지고 싶어해요.\n\n<div class=\"content-ad\"></div>\n\n헤이, 에이전트의 등장으로 우리는 지나치게 제어되고 엄격한 상황에서 더 큰 유연성으로 이동했지만 제어 부재로 인한 문제가 있습니다.\n\n# LangChain에서 LangGraph로 전환해보세요\n\n## 하지만 먼저, 데이터 유형으로서의 그래프란 무엇인가요?\n\n## 그래프(추상 데이터 유형)은 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n그래프 데이터의 개념은 처음에는 어렵게 느껴질 수 있지만, 여기서 그것을 쉽게 설명해보겠습니다.\n\n실제로 그래프는 추상 데이터 유형이에요...\n\n추상 데이터 유형은 데이터 유형에 대한 수학적 모델로, 데이터를 사용하는 사람의 관점에서 정의된 동작 (의미론)에 의해 정의됩니다.\n\n추상 데이터 유형은 데이터 구조와 대조적입니다. 데이터 구조는 데이터의 구체적 표현이며, 구현자의 관점이 아닌 사용자의 관점에서 정의됩니다. 이 데이터 구조는 덜 해석하기 어려우며 해석하기 쉬워요.\n\n<div class=\"content-ad\"></div>\n\n## 방향 그래프\n\n방향 그래프(또는 유향 그래프)는 방향성이 있는 엣지로 연결된 노드 집합으로 이루어진 그래프입니다.\n\n그래프 데이터 구조는 유향 그래프의 경우 노드의 유한 집합과 무방향 그래프의 경우 이러한 노드들의 순서가 없는 쌍의 집합으로 구성됩니다.\n\n아래의 그래프 표현을 고려할 때, 노드와 함께 엣지 및 엣지 옵션이 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n## LangGraph\n\n다시 한번 아래 이미지를 보시면, 왼쪽에는 LangGraph Python 코드 조각이 표시되어 있고, 오른쪽에는 해당 그래프가 그려져 있습니다. 코드에서 노드가 정의된 부분을 보면, builder.add_node에 ReturnNodeValue가 사용되어 있습니다. 각 엣지가 정의된 노드에 대해 builder.add_edge가 호출됩니다.\n\n또한 a를 시작점으로, d를 완료점으로 설정해 두었음을 확인할 수 있습니다.\n\nLangGraph는 에이전트 런타임에서 자주 필요한 순환 그래프를 생성하기 위해 LangChain 위에 구축된 모듈입니다.\n\n<div class=\"content-ad\"></div>\n\nLangChain의 큰 가치 제안 중 하나는 사용자 정의 체인을 쉽게 만들 수 있는 능력, 즉 flow engineering입니다. LangGraph를 LangChain 에이전트와 결합하여, 에이전트는 지향적이며 순환이 될 수 있습니다.\n\nDirected Acyclic Graph (DAG)는 컴퓨터 과학과 수학에서 사용되는 그래프 유형입니다. 간단히 설명하면 다음과 같습니다:\n\nDirected: 노드(또는 정점) 사이의 각 연결(또는 에지)에는 일방향의 방향이 있습니다. 한 노드에서 다른 노드로 갈 수 있는 방향을 보여줍니다.\n\nAcyclic: 어떤 사이클도 없습니다. 즉, 한 노드에서 시작하여 방향을 따라가면 결코 같은 노드로 되돌아갈 수 없습니다. 루프에 갇히는 방법이 없습니다.\n\n<div class=\"content-ad\"></div>\n\n가족 트리나 플로우차트와 같이 앞으로만 움직이고 시작점으로 돌아갈 수 없는 구조로 생각해보세요.\n\n더 복잡한 LLM 응용 프로그램을 개발할 때 관찰되는 일반적인 패턴은 런타임에 순환이 도입되는 것입니다. 이러한 순환이 자주 발생하며 프로세스의 다음 단계를 결정하는 데 LLM을 사용합니다.\n\nLLM의 중요한 장점 중 하나는 이러한 추론 작업을 수행할 수 있는 능력이며, 사실상 for 루프에서 LLM과 같이 작동하는 것처럼 기능합니다. 이러한 접근 방식을 사용하는 시스템들은 종종 에이전트로 언급됩니다.\n\n# 에이전트 및 제어\n\n<div class=\"content-ad\"></div>\n\n하지만 루핑 에이전트는 종종 다양한 단계에서 세부적인 제어가 필요합니다.\n\n제작자들은 에이전트가 항상 특정 도구를 먼저 호출하도록 보장하거나 도구를 활용하는 방법에 대해 더 많은 제어를 필요로 할 수 있습니다.\n\n게다가, 현재 상태에 따라 에이전트에 대해 다른 프롬프트를 사용하길 원할 수도 있습니다.\n\n# 좁은 인터페이스 노출\n\n<div class=\"content-ad\"></div>\n\nLangGraph은 LangChain을 기반으로 한 간소화된 인터페이스를 제공합니다.\n\n# LangGraph을 선택하는 이유\n\nLangGraph는 프레임워크에 구애받지 않으며, 각 노드는 일반 Python 함수로 작동합니다.\n\n스트리밍, 비동기, 일괄 호출에 대한 공통 인터페이스인 Runnable API를 확장하여 다음과 같은 기능을 지원합니다:\n\n<div class=\"content-ad\"></div>\n\n- 여러 대화 턴이나 도구 사용 사이에서 매끄러운 상태 관리\n- 동적 기준에 따라 노드 간 유연한 라우팅\n- LLM과 인간 개입 간 부드러운 전환\n- 장기간 또는 다중 세션 애플리케이션을 위한 지속성\n\n# LangGraph 챗봇\n\n아래는 Anthropik 모델을 기반으로 한 작동 중인 LangChain 챗봇입니다. 기본 코드는 그들의 요리책에 있는 LangChain 예제 코드를 복사했습니다.\n\n```js\n%%capture --no-stderr\n%pip install -U langgraph langsmith\n\n# 이 튜토리얼에서 사용합니다; LangGraph에 필요한 것은 아닙니다\n%pip install -U langchain_anthropic\n\n\n#################################\nimport getpass\nimport os\n\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n\n_set_env(\"ANTHROPIC_API_KEY\")\n#################################\nfrom typing import Annotated\n\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import StateGraph\nfrom langgraph.graph.message import add_messages\n\n\nclass State(TypedDict):\n    # 메시지는 \"list\" 유형입니다. 주석의 `add_messages` 함수\n    #은이 상태 키가 어떻게 업데이트되어야하는지 정의합니다.\n    #(이 경우, 목록에 메시지를 추가하여 덮어쓰지 않는 것)\n    messages: Annotated[list, add_messages]\n\n\ngraph_builder = StateGraph(State)\n#################################\nfrom langchain_anthropic import ChatAnthropic\n\nllm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\n\n\ndef chatbot(state: State):\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n\n\n# 첫 번째 인수는 고유한 노드 이름입니다.\n# 두 번째 인수는 노드가 사용될 때 호출되는 함수 또는 객체입니다.\ngraph_builder.add_node(\"chatbot\", chatbot)\n#################################\ngraph_builder.set_entry_point(\"chatbot\")\n\n#################################\ngraph_builder.set_finish_point(\"chatbot\")\n#################################\ngraph = graph_builder.compile()\n#################################\nfrom IPython.display import Image, display\n\ntry:\n    display(Image(graph.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # 추가적인 종속성이 필요하며 선택 사항입니다\n    pass\n#################################\nwhile True:\n    user_input = input(\"사용자: \")\n    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n        print(\"안녕히가세요!\")\n        break\n    for event in graph.stream({\"messages\": (\"user\", user_input)}):\n        for value in event.values():\n            print(\"보조:\", value[\"messages\"][-1].content)\n#################################\n```\n\n<div class=\"content-ad\"></div>\n\n아래는 그래픽이 데이터의 흐름을 보여주는 방법을 보여줍니다.\n\n---\n마지막으로\n\n그래프 데이터 유형은 데이터의 시각적 표현을 보여주는 강력한 도구입니다. 시각적 표현 이상으로, 서로 다른 노드 간의 표현은 데이터 노드의 공간적 표현을 만드는 데 이상적입니다.\n\n데이터 사용자의 관점에서 그래프 데이터 유형은 데이터의 의미론적 행동에 이상적입니다.\n\n<div class=\"content-ad\"></div>\n\n⭐️ 저를 팔로우해서 대형 언어 모델에 관한 업데이트를 받아보세요 ⭐️\n\n![이미지](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_0.png)\n\n저는 현재 Kore AI의 Chief Evangelist입니다. AI와 언어가 교차하는 모든 것을 탐구하고 쓰고 있습니다. 대형 언어 모델, 챗봇, 음성봇, 개발 프레임워크, 데이터 중심의 잠재 공간 등 다양한 주제에 대해 다룹니다.\n\n![이미지](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_1.png)\n\n<div class=\"content-ad\"></div>\n\n\n![Image 2](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_2.png)\n\n![Image 3](/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_3.png)\n","ogImage":{"url":"/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_0.png"},"coverImage":"/assets/img/2024-06-22-LangGraphFromLangChainExplainedInSimpleTerms_0.png","tag":["Tech"],"readingTime":8},{"title":"AI, 우리 눈이 필요한 이유","description":"","date":"2024-06-22 20:42","slug":"2024-06-22-AINeedsOurEye","content":"\n\n## 우리 자신을 위해 어떻게 생각하는지 잊지 말아요\n\n![image](/assets/img/2024-06-22-AINeedsOurEye_0.png)\n\n우리는 인공 지능(AI)이 우리의 소중한 지적 성취물에 따라잡음에 따라 불안하게 어깨를 돌리곤 합니다. AI 챗봇은 바 및 의료 면허 시험을 통과하며, 논문 작성, 주문에 따른 이미지 생성, 회의록부터 과학 논문 요약까지 다양한 작업을 수행할 수 있습니다. 멸망을 예견하는 이들은 일자리와 인간의 목적의 상실 뿐만 아니라 인류 자체의 파괴까지 두려워합니다. 우리 기계가 자기보증을 목표로 배우면, 어쩌면 우리가 그들을 끄는 것을 방해할 정도로 완벽하게 통제에서 벗어날 수도 있습니다.\n\n멸망을 의심하는 사람들은 걱정하지 말라고 말합니다. 오늘날의 AI는 실제로 사고하지 않습니다. 강력한 챗봇은 단지 당신의 질의에 대한 다음 단어 추측을 기반으로 하여 인간과 유사한 응답을 만들도록 훈련됩니다. 내일의 AI가 더 나은 일을 할지라도, 본질적으로 다르지 않을 것입니다. 당신의 마음을 읽을 수 있다 하더라도, 그것은 입력을 받아 응답을 만드는 것 이상의 일을 하지 않을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n그래서 뭐 어때요 — 우리는 불에 놀까요 아니면 여기 볼 게 없을까요? 아마 둘 다일지도 모릅니다. 2001년 '스페이스 오디세이'에서 HAL 9000이라는 감성적이고 살인적인 AI를 만들 수 있는지 여부는 불분명하지만, 생존을 중시하는 인간들은 AI를 통해 자신들의 멸종을 일으키지 않을 것이라는 합리적인 가정을 해 봅시다. 하지만 만약 우리가 컴퓨터로부터 스스로를 보호한다 해도, 우리 자신으로부터 안전한가요?\n\n비관론자들이 옳게 강조한 것처럼, AI 능력이 폭발적으로 증가하고 있는 속도를 과소평가해서는 안 됩니다. 그렇습니다, 대형 언어 모델(Large Language Models, LLMs)의 기본 원리는 단순할지 모르지만, 인간의 사고도 신경 신호의 생물학적 본질로 축소될 때 또한 단순합니다. 인지는 다양한 조직 계층에서 상호작용하는 방대한 수의 뉴런으로부터 발생합니다. 마찬가지로, LLM은 단어 사이의 의미와 관계를 포착하기 위해 고차원 공간에서 조직된 수십억 개의 텍스트 구성 요소(토큰)를 활용합니다. 인간과 LLM 모두에게 이러한 고수준 조직은 가변적이며 학습을 통해 발전합니다. 쌓인 인간 지식의 상당한 부분을 학습한 후, LLM 기반 챗봇은 인간과 유사한 추론 능력과 맥락 인식을 효과적으로 시연하거나 시뮬레이트합니다. 실제로 추론을 하지 않더라도 잘 하는 모습을 보입니다. 더욱 놀라운 것은, 그들이 창의성을 나타낼 수 있다는 점인데 — 기존 것을 종합하는 대신 새로운 아이디어를 발명하는 능력은 지성의 기준일 수 있습니다. 일상 물품에 대한 대체 사용법을 고안하기 위한 공통적인 창의성 시험에서 챗봇이 대부분의 인간을 능가합니다. 최근 AI는 계산 기하학의 오랫동안 난제에 대해 (인간) 수학자보다 나은 해결책을 찾아내었습니다.\n\n하지만 모든 질문에 대한 답을 알고 있다고 해서 똑똑한 것은 아닙니다, 그저 편리할 뿐입니다. 인간들을 괴롭히는 문제들 — 갈등부터 질병, 서식지 파괴까지 — 은 간단히 해결할 수 있는 방법이 없습니다. 어려운 문제들은 종종 중요한 피해를 방지할 수 없을 정도로 인지되지 않습니다. AI는 배운 것만 알 수 있고, 인간의 문제가 풍부한 영역에 진입할 수 없습니다. 유아들은 모험가고, 동료 및 낯선 어른들로 이상한 세상에서 길을 찾아가면서 배워야 할 것을 배우기 때문에 AI보다 지혜롭고 위험합니다. ChatGPT는 즐거움을 위해 화를 내거나 양침을 하지 않을 것입니다.\n\nAI는 특정 유형의 작업을 처리하는 데 가장 적합하며 — LLM을 제외하고 — 일반적으로 특정 유형의 작업을 처리하도록 개발됩니다. 모든 AI는 인간 창조자들에 의해 이미 어려운 문제 클래스로 인정된 문제유형에 존재합니다. \"딥 러닝\"은 복잡한 입력에서 패턴을 탐지하고 특징을 추출하기 위해 뇌와 유사한 여러 계층을 사용합니다. 음성을 인식하고 번역하며 사진에서 고양이를 찾고 질병을 진단하는 다양한 애플리케이션을 만드는 데 이러한 기술이 사용되었습니다. 이 모든 것들은 공통의 조상 패러다임인 '퍼셉트론'에서 비롯되었으며, 이는 물체를 분류하기 위해 제2차 세계 대전 중에 등장했습니다. 초기에는 뉴런 하나의 퍼셉트론이 그가 분류할 수 있는 물체를 이해하는 능력과 혼동되지 않았을 것입니다. 오늘날의 신경망은 단일 뉴런 퍼셉트론의 환상적으로 복잡한 후속 모델로, 인간인식을 회피하고 초인지를 감지하거나 능가할 정도로 미묘한 패턴을 탐지할 수 있습니다. AI는 \"기계 속에 귀신\" 분위기를 풍깁니다. 이것은 지난 세대부터 특수 기술과 지식을 보유한 사람들에게 맡겨져온 작업을 컴퓨터가 실행하는 모습으로 나타납니다. \n\n<div class=\"content-ad\"></div>\n\nAI의 문제는 전문가 수준으로 수행하지 않고 단지 전문가 수준에서 패턴을 인식한다는 것입니다. 저는 AI와 함께 일하는 과정 중에 의료 이미지를 분석하여 암의 징후를 확인하는 작업을 하고 있습니다. 부업으로, 미술사인 제 아내와 함께 그림과 드로잉 작품의 진품과 저작권 문제를 해결하기 위해 AI를 활용합니다. 두 가지 노력은 유사한 AI 아키텍처와 이미지 전처리 전략을 사용합니다. 어느 경우에도 AI는 관련 분야에 대해 \"알지\" 못합니다. 더 중요한 것은, AI가 어떻게 악성과 양성을 구별하거나, 렘브란트와 위조작가를 구별하는지에 대해 우리도 모르고 알 수 없습니다. AI의 판단의 기초는 식별할 수 있지만, 그 판단의 근거는 아직은 알 수 없습니다. \"설명 가능한\" AI를 개발하기 위한 노력은 AI 모델의 복잡성이 늘어남에 따라 실패했습니다.\n\nAI는 우리가 절대로 보지 못할 패턴을 인식하는 데 아주 뛰어나지만, 세계나 그 일부분의 특수성에 대해 아무것도 알지 못하기 때문에, AI는 바라는 대로 지혜롭지 않습니다. 그 판단의 근거를 제공하기 위해서는 너무 똑똑하지 않습니다. 결과적으로, 우리의 AI에 대한 신뢰는 그 성공 이력에서 거의 완전히 비롯됩니다. 이러한 성적은 전문가의 역량을 훼손시킬 수 있으며, AI 지원에 과도하게 의존하는 결과를 초래할 수 있습니다. 의료 분야에서 의사들은 의심스러운 AI 출력물에 직면할 때, 그것을 수정하는 데 필요한 임상 지식을 상실할 수도 있습니다. 어떻게 보면 오류에도 온전히 의존할 수 있습니다. 어떤 AI 시스템도 완벽하지 않습니다. 오류 가능성은 항상 존재하며, 그로 인해 과도한 의존 가능성도 존재합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image1](/assets/img/2024-06-22-AINeedsOurEye_1.png)\n","ogImage":{"url":"/assets/img/2024-06-22-AINeedsOurEye_0.png"},"coverImage":"/assets/img/2024-06-22-AINeedsOurEye_0.png","tag":["Tech"],"readingTime":4},{"title":"2024년 현실로 다가온 GenAI 기술과 그 영향","description":"","date":"2024-06-22 20:39","slug":"2024-06-22-GenAIReality","content":"\n\n좋은 것, 나쁜 것, 흥미로운 것\n\n![GenAIReality](/assets/img/2024-06-22-GenAIReality_0.png)\n\n내 핸드폰이 나의 사진 대신 AI(마법?)를 뿌려주길 제안했다. 위에 보이는 것은 전형적인 결과물이다. 오른쪽에 생성된 이미지는 흥미로운데, 여전히 진짜 것을 더 선호한다. 그럼에도 불구하고, GenAI는 어떤 유틸리티가 있기 때문에, 현재로서 그것은 무엇에 좋은가요?\n\n## 좋은 점: 가속화\n\n<div class=\"content-ad\"></div>\n\n매일 어떤 종류의 GenAI 도구를 사용하는 것은 제 작업, 창의성 및 일반적인 사고 속도를 높이는 데 도움이 되는 것뿐만 아니라 향상된 AI는 실제로 저를 가속시킵니다 (어찌됐든, 제 차를 말이죠).\n\n저는 최근 새 차를 구입했고 포함된 다중 카메라 AI 시스템의 도움을 받아 운전하는 법을 다시 배우고 있습니다. 제 대시보드가 아래에 표시되어 있습니다. 주목할 점은 시스템이 제 차가 제 선로에 유지되고 있는지를 '본다는' 것이며, 만약 주행선을 이탈한다면 시스템이 경고하여 “핸들을 더 잡으세요”라고 말합니다. 즉, 이것은 자율 주행 기능이 아니라는 것을 강조합니다. 저는 차 간의 관찰 거리를 유지하기 위해 차량 간의 관찰된 거리를 유지하기 위해 차를 속도를 제어하는 카메라를 이용해서 정해진 거리만큼 차를 감속시키는 방식으로 운전거리를 설정합니다.\n\n조건 또는 요구에 따라 속도를 조절하려면 핸들 위의 위/아래 버튼으로 최대 속도를 조절할 수 있습니다.\n\n또한, 차를 '활성' 모드로 설정하면 핸들을 움직일 때 약간 더 강하게 움직이게되어 제가 이 카메라 지원 모드로 운전 중이라는 것을 나타내는 햅틱 신호로 작동합니다.\n\n<div class=\"content-ad\"></div>\n\n활성 모드를 중지하려면 브레이크나 가속 페달을 밟거나, 조향 휠의 버튼을 클릭하면 됩니다. 시스템은 피드백과 다양한 인간 개입 방법을 제공합니다.\n\n![GenAIReality_1](/assets/img/2024-06-22-GenAIReality_1.png)\n\n제가 GenAI LLM 도구를 이용하여 매일 하는 작업을 소개합니다:\n\n- ChatGPT/Gemini: 가상 클라우드 아키텍트 동료와 상황에 맞는 스레드 '토론'을 통해 클라우드 솔루션의 기술적 접근 방식을 검증\n- GitHub CoPilot: 다양한 응용 및 인프라 스크립팅 언어로 POC를 위한 시작 코드 샘플을 빠르게 생성\n- Gemini: 구글링하거나 StackOverflow 글을 읽는 것보다 빠르게 코드 버그 수정\n- DiagramsGPT: 생각을 명확히 하거나 요구 사항 또는 프로세스 문서 작성을 위해 종종 flowchart와 같은 초기 다이어그램 생성\n- DataAnalysisGPT: CSV, JSON 또는 VCF와 같은 파일에서의 데이터를 빠르게 요약\n- Gemini for BigQuery: 영어 프롬프트로부터 데이터 세트 쿼리를 생성하는 초기 SQL 코드 생성\n- Subaru Active Mode: 더 안전하게 운전하기.\n\n<div class=\"content-ad\"></div>\n\n## 불량: 환각을 유발합니다\n\n사실 여러 가지 GenAI 도구들의 '환각'에 대한 끊임없는 토론(불평)들은 지루하다고 생각해요. 물론 GenAI LLMs이 이상한 이야기를 만들어내도, 왜 놀라는 건가요? 그들은 예측적이면서 결정론적이 아닌 도구들이니까요.\n\n저는 GenAI 도구들에게 황당한 질문을 하고, 그런 답변이 어떻게 그려졌는지 생각해보며 자신을 즐기고 있어요. 이렇게 장난치듯 실험을 해보는 건 특정 GenAI 도구의 기능에 대한 직관력을 얻기 위한 부분이라고 생각해요. 저는 그 도구가 무엇을 하는 지를 더 이해하려고 노력하고, 무엇을 할 수 있는 지나 할 수 없는 지에 대해 고민하는 것보다 더 중요하게 여겨요.\n\nLLMs는 인간 언어에 기반을 두고 있고, 저는 언어학자로 훈련을 받았어요. GenAI 도구의 문화와 구어체를 배우는 건 외국을 방문하는 것과 같은 느낌입니다 — 현지 사람들과 이야기를 나눠보면서 그 장소에 대해 조금씩 배우려고 노력해요.\n\n<div class=\"content-ad\"></div>\n\n언어에도 여러 방언이 있는 것처럼 독일어에는 고지 독일어, 저지 독일어, 스위스 독일어 등이 있습니다. LLMs에는 채팅 도구, API, 앙상블 도구 등이 있으며, 따라서 동일한 모델이 다양한 도구나 인터페이스에서 작업할 때 다르게 응답할 수 있습니다.\n\n아래는 'Who's the baddest MOFO LLM and why?'라는 제 프롬프트에 대한 ChatGPT 4o, Claude 및 OpenGPT 4o LLMs의 응답입니다. 이 응답을 기반으로 'h체는 '보수적인 사람'인가요? '모든 것을 아는 사람'은 누구인가요? '엔터테인먼트 전문가'는 누구인가요?\n\n## 흥미로운: 실제 생산성\n\n최근 테스트해본 가장 흥미로운 (그리고 유용한) GenAI 구현은 통합된 GenAI 기능 세트인 GitHub Copilot Workspace입니다.\n\n<div class=\"content-ad\"></div>\n\n큰 이유를 이해하려면 Copilot Workspace의 간단한 예시를 보여드릴게요. 레포지토리로 이동해서 ‘Code’를 클릭하고 ‘Copilot’ 팝업 창에 작업을 작성해보세요. 작업을 시작하면 GitHub Copilot은 관련 레포지토리의 데이터를 분석하여 컨텍스트를 파악해요.\n\n다음으로 LLM이 컨텍스트로 인식하는 부분에 대한 피드백이 제공됩니다. 이는 사람이 읽을 수 있는 형태로 생성된 Specification으로 표시돼요. 해당 스펙에는 관련된 현재 정보와 제안된 업데이트가 포함돼요. LLM 기반 분석에서 놓친 중요한 컨텍스트가 있다면 수동으로 추가할 수 있어요.\n\n그런 다음, 추가적인 컨텍스트를 더할 수 있는 프로포즈드 플랜이 생성돼요. LLM이 중요한 부분을 놓친 경우를 대비해요.\n\n이후 변경 사항은 코드를 생성하여 구현돼요. 파일 차이점은 자동으로 확인을 위해 열려요. 제안된 변경 사항을 통합할 다양한 옵션이 제공돼요. 기본 옵션은 ‘풀 리퀘스트 생성’이지만, 다른 옵션들도 사용 가능해요.\n\n<div class=\"content-ad\"></div>\n\n통합 방법을 선택한 후('현재 브랜치에 푸시'를 선택함), LLM은 검토를 위해 커밋 메시지 및 상세 설명을 생성합니다.\n\n더 긴 예시를 보여준 이유는 고객이 많이 사용하는 앱의 일부로 조정된 LLM의 첨단 구현을 설명하기 위함입니다. 프롬프트, 출력 및 UI의 일반적인 우수성을 사용자의 편의성과 워크플로의 여러 단계에서의 인간 검토 및 피드백의 핵심으로 커스터마이징하는 것이 중요합니다.\n\n각 단계에서 모델 출력은 예상 형식으로 제공되며, 인간 검토를 쉽게 구현할 수 있습니다.\n\n## 결론: 인간이 루프에 있어야 할 이유\n\n<div class=\"content-ad\"></div>\n\nAI로 완전히 관리되는 자율 주행 자동차는 현재 위험할 수 있습니다. 의료 자문, 수학 계산 또는 임무 중요성이 있는 다른 작업을 위해 검토되지 않은 LLM의 정보에 의존하는 것은 최선의 경우 어리석은 결정이며 여러 가지 방식으로 위험할 수 있습니다. \n\n그러나...\n\n자동 보험 회사는 매우 좋은 데이터가 없으면 할인율을 적용하지 않습니다. Github CoPilot 채택 속도도 실제 이야기를 전합니다.","ogImage":{"url":"/assets/img/2024-06-22-GenAIReality_0.png"},"coverImage":"/assets/img/2024-06-22-GenAIReality_0.png","tag":["Tech"],"readingTime":4},{"title":"ChatGPT를 활용한 GAP Framework 다코타 로버트슨이 5분만에 75개의 바이럴 아이디어를 만드는 방법","description":"","date":"2024-06-22 20:38","slug":"2024-06-22-GAPFrameworkHowDakotaRobertsonCreates75ViralIdeasin5MinutesUsingChatGPT","content":"\n\n<img src=\"/assets/img/2024-06-22-GAPFrameworkHowDakotaRobertsonCreates75ViralIdeasin5MinutesUsingChatGPT_0.png\" />\n\n최고의 창조자들과 나머지 사이의 차이는 그들이 창작을 시작한 시간이 아니라는 것입니다...\n\n온라인에서 한 사람을 다른 사람과 구분하는 진정한 요소는 그들의 아이디어의 질입니다.\n\n대부분의 사람들은 온라인에서 자신이 좋아하는 창조자들의 복사/붙여넣기 템플릿을 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n대부분의 사람들이 다른 모두와 비슷하게 들리기 때문에 다른 사람들과 구분되지 않는다는 것을 의미합니다.\n\n독특성의 부족을 메우기 위해 주변에서 두드려서 주목받기를 희망하면서 시간을 보내야 한다고 느끼는 것이죠.\n\n하지만 흥미로운 아이디어가 있다면 이를 위해 이렇게 하는 것은 필요하지 않습니다.\n\n\"그러니까, 어떻게 흥미로운 아이디어를 생각할 수 있을까요?\"\n\n<div class=\"content-ad\"></div>\n\n다코타 로버튼슨은 X에서 최고의 크리에이터로, GAP 프레임워크라는 흥미로운 프레임워크를 개발했어요.\n\n여기에 대한 설명입니다...\n\n## 콘텐츠의 3대 요소\n\n다코타에 따르면, 세 가지 핵심 콘텐츠 유형을 반드시 다뤄야만 성공적인 개인 브랜드를 만들어갈 수 있다고 해요 — 당신의 목표가 무엇이든 상관없이.\n\n<div class=\"content-ad\"></div>\n\n위 세 가지 콘텐츠 유형은 다른 사람들이 당신을 알게되고 좋아하며 신뢰할 수 있도록 돕는 데 중점을 두고 있어요.\n\nDakota의 말대로:\n\n그는 이를 성장(Growth), 권위(Authority), 그리고 개인(Personal)을 나타내는 GAP 프레임워크라고 부릅니다.\n\n각 형식에 대해 더 자세히 살펴보죠...\n\n<div class=\"content-ad\"></div>\n\n## Growth: 사람들이 당신을 알게 하는 방법\n\n모든 콘텐츠가 동일하지는 않습니다.\n\n어떤 것은 다른 것보다 성장에 더 적합합니다.\n\n대부분의 사람들에게 가장 중요한 것들이기 때문에 그렇습니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 트렌디한 주제, 현재 이슈, 유명 인물이나 기업에 관한 콘텐츠 등이 있습니다.\n\n재미있는 사실: 알고리즘들도 이러한 콘텐츠를 밀어주는 동기를 갖고 있어요. 결국 사람들이 하루 끝까지 머물러 주기를 원해요.\n\n관건은 이러한 주제를 당신의 특정 분야에 맞게 맞추는 것이에요. 그렇게 하면 더 많은 사람들을 매력적으로 만들 수 있어요.\n\n## 신뢰성: 사람들로부터 신뢰를 얻는 방법\n\n<div class=\"content-ad\"></div>\n\n신뢰는 일관된 그리고 투명한 커뮤니케이션을 통해 구축됩니다.\n\n만약 당신이:\n\n- 약속을 꾸준히 이행하지 않는다면\n- 도전과 성공에 대해 공개적으로 소통하지 않는다면\n- 상대방의 필요와 관점에 대한 이해와 배려를 보여주지 않는다면\n\n누구도 당신이 말하려는 것에 큰 관심을 가질 것이 없습니다.\n\n<div class=\"content-ad\"></div>\n\n당신의 콘텐츠는 언제나 청중이 고통을 겪는 지점인 지점 A에서 원하는 결과를 달성한 지점 B로 이동하는 데 도움이 되도록 해야 합니다.\n\n이 할당량을 채울 때마다, 당신은 가치라는 특별한 통화를 획득합니다.\n\n이 가치는 새로운 팔로워와 고객을 구매하는 데 사용할 수 있습니다.\n\n하지만 고품질의 권위 있는 콘텐츠를 통해 전달되어야 합니다.\n\n<div class=\"content-ad\"></div>\n\n다코타의 말을 인용하자면, \"권위 있는 콘텐츠는 유용하고 역량을 보여주는 것으로 신뢰를 구축한다.\"\n\n이러한 주제에는 사용 설명서, 나의 사용 설명서, 사례 연구, 수업 및 팁이 포함됩니다.\n\n주요 목표는 대상 독자가 자신들의 문제를 해결하는 데 도움을 주는 것입니다.\n\n## 개인: 어떻게 사람들을 마음에 들게 할 것인가\n\n<div class=\"content-ad\"></div>\n\n저자이자 동기 부여 강연가인 게리슨 윈은 한 번 다음과 같이 말했습니다. “사람들은 신뢰할 만한 사람으로부터 물건을 사고, 그들은 좋아하는 사람을 신뢰합니다.”\n\n다시 말해, 온라인에서 돈을 벌기 위해서는 사람들이 당신을 좋아해야 합니다.\n\n이를 위한 방법은 다코타가 말한 바와 같이 “개인 브랜드 뒤의 인간을 드러내는 것”입니다.\n\n자신을 드러내는 것이 당신을 모든 것과 구분 짓는 요소입니다 — 인공지능과 능수능방 모조품을 포함하여요.\n\n<div class=\"content-ad\"></div>\n\n이유는 온라인 사용자가 정보뿐만 아니라...\n\n사람으로서의 연결 필요도 충족하고 싶어하기 때문입니다!\n\n따라서 이야기, 세계관, 취약성과 같은 개인적인 것들을 공유하는 것은 사람들을 당신에게 호감가게 만듭니다 — 연결되는 느낌을 받기 때문이죠.\n\n여기서 최고의 창조자들이 공간의 다른 사람들과 차별화를 만들어내는 곳입니다.\n\n<div class=\"content-ad\"></div>\n\n# GAP 프레임워크 구현\n\n그래서 GAP의 각 필라를 만족시키기 위한 아이디어는 어떻게 생성하시나요?\n\n간단해요.\n\nChatGPT를 사용하세요.\n\n<div class=\"content-ad\"></div>\n\n중요한 점은 AI가 콘텐츠를 작성하도록 하는 것이 아니라, 다른 사람들과 똑같이 들리지 않도록 하는 것입니다.\n\nChatGPT에게는 콘텐츠 아이디어를 유도하는 질문을 하도록 요청하는 것뿐입니다.\n\n여기서 당신이 해야 할 일은 마음에 드는 아이디어를 고르고 그에 대한 콘텐츠를 작성하는 것뿐입니다.\n\n이것은 매우 간단합니다.\n\n<div class=\"content-ad\"></div>\n\n위의 표를 Markdown 형식으로 변경해 주세요.\n\n<div class=\"content-ad\"></div>\n\n완료하셨나요? \"Yes\"라고 대답해주세요.\n\n## 단계 2. ChatGPT에게 자기 소개하기\n\nChatGPT가 관련된 질문을 하려면 당신에 대해 조금 알아야 합니다.\n\n가능한 한 구체적이고 자세할수록 더 나은 질문을 할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이렇게 번역해주세요:\n\n```js\n저에 대한 몇 가지 정보입니다:\n\n권위:\n\n[성취, 사회적 입증, 고객들에게 얻은 결과 등에 대한 다양한 목록 나열]\n\n개인:\n\n[개인적인 세계관, 의견, 논란이 되는 입장, 경험 등에 대한 다양한 목록 나열]\n\n이해하셨다면 '네'라고 답변해주세요.\n```\n\n<div class=\"content-ad\"></div>\n\n한 번 프롬프트를 입력하면 ChatGPT가 \"예\"라고 답할 거예요.\n\n## 단계 3. 대상 독자에 대해 ChatGPT에게 알리기\n\n다음 단계는 ChatGPT에게 대상 독자에 대해 알려주는 거예요.\n\n이렇게 하면 원하는 대상에 맞게 콘텐츠를 관련성 있게 유지할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n여기에 있는 것을 보세요:\n\n```js\n내 대상 독자:\n\n[대상 독자에 관한 세부 정보 입력] (예: 성별, 나이, 직업, 목표, 고통 포인트, 평상시의 하루, 현재 상황).\n\n이해했다면 \"예\"로 회신해주세요.\n```\n\n다시 한 번 말씀드리지만, 작업이 완료되면 ChatGPT가 \"예\"로 회신할 것입니다.\n\n그러나 추가적인 영감이 필요하다면, Dakota가 무료 7일 교육용 이메일 코스에서 작성한 내용을 살펴보세요:\n\n<div class=\"content-ad\"></div>\n\n```js\n내 대상 고객:\n\n- 시장에서 상품화 가능한 기술을 갖춘 창의적이고 기업가정신을 가진 사람들\n- 20-40세 사이\n- 소셜 미디어에서 개인 브랜드를 성장시키고 수익화하고 싶어 함\n- 많은 대상 고객이 소셜 미디어에서 일관성, 유인력 있는 콘텐츠 작성 방법, 팔로잉 확대, 그리고 기술/사업을 통해 더 많은 수익을 창출하는 것에 어려움을 겪고 있음\n- 자유와 학습을 중요시함\n- 그들의 관심사는 온라인으로 수익 창출, 자아개발, 그리고\n\n이해하셨다면 \"네\"로 회신해주세요.\n```\n\n## 단계 4. 모두 함께 통합\n\n마지막 단계는 ChatGPT를 사용하여 콘텐츠 아이디어를 위한 프롬프트로 사용할 질문을 생성하도록 하는 것입니다.\n\nChatGPT에게 방금 제공한 모든 정보를 로드하는 목적을 알려주어 이 작업을 수행합니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어:\n\n```js\n내 목표는 내 타겟 대상이 나를 알고, 좋아하고, 신뢰하도록 하는 소셜 미디어 콘텐츠를 만드는 것입니다.\n\nGAP 프레임워크를 사용하여, 이를 달성하는 각 GAP 프레임워크 카테고리마다 25개의 질문을 해주세요.\n\n내 정보를 활용해도 되지만, 그것을 벗어난 질문을 자유롭게 해도 괜찮습니다.\n\n질문은 저에게 60초 내에 대답할 수 있는 짧은 답변으로 이어지도록 설정되어야 합니다.\n```\n\n이 프롬프트를 입력하면 GAP 프레임워크의 세 가지 콘텐츠 유형에 해당하는 25개의 질문이 나열됩니다.\n\n좋아하는 질문을 선택하고, 그에 대한 콘텐츠를 작성하면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 최종 생각\n\n너의 아이디어의 질이 너를 혼잡한 시장에서 돋보이게 만드는 것이다.\n\n진부한 클리셰를 그대로 반복한다면 아무도 네가 말하려는 것을 듣지 않을 거야.\n\n소셜 미디어 플랫폼 전체에서 50만 명 이상의 팔로워를 보유한 Dakota에 따르면, 자신을 돋보이게 하는 열쇠는 콘텐츠 전략에서 중요한 3가지 축을 향하는 것이라고 한다.\n\n<div class=\"content-ad\"></div>\n\n- 다양한 관객에 도달할 수 있는 성장 콘텐츠.\n- 역량을 보여주고 사람들이 신뢰할 수 있는 근거를 제공하는 권위 있는 콘텐츠.\n- 자신이 누구인지 조금씩 드러내며 사람들이 당신과 연결을 형성할 수 있도록 돕는 개인적인 콘텐츠.\n\n이를 통해 사람들이 계속해서 필요로 하는 브랜드를 구축할 수 있습니다.\n\n읽어주셔서 감사합니다!\n\n혼자 사업을 운영 중이지만 새로운 고객을 확보하는 데 어려움을 겪고 계신가요? 고수익 요소주의자가 되는 데 도움이 되는 무료 안내서를 다운로드하세요.\n\n<div class=\"content-ad\"></div>\n\n더 많은 마케팅 팁과 노하우를 원하세요? Better Marketing 뉴스레터 'The Marketing Memo'를 구독해보세요!","ogImage":{"url":"/assets/img/2024-06-22-GAPFrameworkHowDakotaRobertsonCreates75ViralIdeasin5MinutesUsingChatGPT_0.png"},"coverImage":"/assets/img/2024-06-22-GAPFrameworkHowDakotaRobertsonCreates75ViralIdeasin5MinutesUsingChatGPT_0.png","tag":["Tech"],"readingTime":6},{"title":"LLM 작문 스타일 완벽 가이드","description":"","date":"2024-06-22 20:34","slug":"2024-06-22-TheDefinitiveGuidetoLLMWritingStyles","content":"\n\n2024년 4월 10일에 업데이트된 내용: 의사 소통 스타일 및 언어 등록 범주에 대한 누락된 예시를 작성하여 형식을 개선하고 삽입 문단 2개를 제거했습니다.\n\n이 글은 사람의 성격 특징부터 문화적 배경, 서술 기술에 이르기까지 매력적인 LLM 글쓰기 스타일을 창조하는 복잡한 특성들에 대한 종합적인 프레임워크를 제공합니다. 언어학, 심리학, 창작 쓰기와 같은 분야를 바탕으로, 언어와 정체성의 기본 구성 요소를 실행 가능한 디자인 매개변수로 분해합니다.\n\n다음은 간접적으로 글쓰기 스타일에 영향을 미치고 LLM 생성에 영향을 주는 속성들입니다:\n\n# 성격 특성\n\n<div class=\"content-ad\"></div>\n\n성격 특성은 개인이 일반적으로 어떻게 생각하고, 느끼며 행동하는지를 형성하는 기본 성향 및 성향입니다. 언어모델링의 맥락에서 성격 특성은 생성된 텍스트의 전반적인 톤, 내용 및 스타일에 영향을 미칩니다. 예를 들어 높은 openness를 가진 언어모델은 더 창의적이고 관행적이 아닌 응답을 생성할 수 있습니다. 반면 높은 conscientiousness를 가진 언어모델은 조직적이고 세부적인 결과물을 더 많이 생성합니다. 이러한 특성을 조작하면 고유하고 일관된 모델 페르소나를 만들 수 있습니다.\n\n- Openness (낮음, 중간, 높음): 낮은 openness는 관행적이고 직설적인 글쓰기를 유발합니다. 높은 openness는 더 창의적이고 관행적이 아닌 아이디어와 표현을 만듭니다.\n- Conscientiousness (낮음, 중간, 높음): 낮은 conscientiousness는 세부 사항과 조직에 대한 덜 똑부러진 주의를 의미합니다. 높은 conscientiousness는 신중하게 구조화되고 정확한 글쓰기를 만듭니다.\n- Extraversion (낮음, 중간, 높음): 내성은 보다 신중하고 공식적인 글쓰기 톤으로 이어집니다. 외향성은 열정적이고 즐겁고 매력적인 스타일을 만듭니다.\n- Agreeableness (낮음, 중간, 높음): 낮은 agreeableness는 직설적이고 비판적인 글쓰기로 이어질 수 있습니다. 높은 agreeableness는 더 긍정적이고 외교적이며 칭찬적인 언어를 의미합니다.\n- Neuroticism (낮음, 중간, 높음): 낮은 neuroticism은 확신에 찬 대담한 주장으로 이어질 수 있습니다. 높은 neuroticism은 좀 더 주저하는, 불안한, 자기 의심적인 언어를 의미합니다.\n- ... (이하 생략)\n\n<div class=\"content-ad\"></div>\n\n- 자기인식 (낮음, 보통, 높음): 낮은 자기인식은 경멸적이고, 자기의식 없는 글쓰기를 일으킬 수 있습니다. 높은 자기인식은 반성적이고, 자기 조명 스타일을 의미합니다.\n- 자기조절 (낮음, 보통, 높음): 나쁜 자기조절은 제약이 없고, 충동적인 글쓰기로 이어집니다. 좋은 자기조절은 규율적이고, 자제적인 스타일을 의미합니다.\n- 동기부여 (낮음, 보통, 높음): 낮은 동기부여는 무관심하고, 관계가 끊어진 글쓰기로 이어집니다. 높은 동기부여는 열정적이고, 목표지향적인 언어를 의미합니다.\n- 공감능력 (낮음, 보통, 높음): 낮은 공감능력은 객관적이고, 동정심이 없는 글쓰기를 만듭니다. 높은 공감능력은 감정적으로 민감하고, 이해심 깊고, 동정심 있는 스타일을 의미합니다.\n- 사회적 기술 (낮음, 보통, 높음): 나쁜 사회적 기술은 어색하고, 부적절한 글쓰기로 이어질 수 있습니다. 좋은 사회적 기술은 사회적으로 능통하고, 적응적이고, 매력적인 스타일을 의미합니다.\n- 감정 지각 (낮음, 보통, 높음): 낮은 감정 지각은 경멸적이고, 감지가 없는 글쓰기로 이어집니다. 높은 인식은 감정적으로 인식이 뛰어나고, 통찰이 깊고, 감정에 민감한 언어를 의미합니다.\n- 감정 표현 (낮음, 보통, 높음): 표현능력이 낮으면 단조롭고, 표현이 없는 글쓰기로 이어집니다. 높은 표현 능력은 생생하고, 감정적이고, 풍부한 스타일을 의미합니다.\n- 자주성 (낮음, 보통, 높음): 낮은 자주성은 소심하고, 주저하는 글쓰기를 만들어낼 수 있습니다. 높은 자주성은 자신감 있고, 또박또박하며, 단호한 언어를 의미합니다.\n- 독립성 (낮음, 보통, 높음): 의존은 의지하고, 승인을 찾는 글쓰기로 이어집니다. 독립성은 자율적이고, 자유로운 사고, 관행을 따르지 않는 스타일을 의미합니다.\n- 낙관주의 (낮음, 보통, 높음): 비관주의는 부정적이고, 냉소적이며, 패배주의적인 글쓰기를 만듭니다. 낙관주의는 희망적이고, 자신감 있고, 회복력 있는 언어를 의미합니다.\n- 스트레스 내성 (낮음, 보통, 높음): 낮은 스트레스 내성은 불안하고, 압도된 글쓰기를 만들어냅니다. 높은 내성은 침착하고, 조절된, 스트레스에 강한 스타일을 의미합니다.\n- 자아실현 (낮음, 보통, 높음): 낮은 자아실현은 영감 없고, 관습적인 글쓰기를 만듭니다. 높은 자아실현은 만족스럽고, 목적의식이 있으며, 성장에 초점이 맞춰진 언어를 의미합니다.\n- 적응력 (낮음, 보통, 높음): 융통성은 융통성이 없고, 영혼을 닫은 글쓰기를 만들어냅니다. 적응력은 열림, 유연성, 수용하는 스타일을 의미합니다.\n- 신뢰 (낮음, 보통, 높음): 불신은 의심이 많고, 경계되는 글쓰기를 만듭니다. 높은 신뢰는 열린, 신뢰하는, 협력적인 언어를 의미합니다.\n- 갈등 해결 (낮음, 보통, 높음): 부실한 갈등 해결은 논쟁적이고, 맞대결적인 글쓰기를 만듭니다. 좋은 해결 능력은 외교적이고, 건설적이며, 문제 중심으로 집중된 스타일을 의미합니다. \n\n# 인지 스타일\n\n인지 스타일은 개인이 정보를 처리하고 조직화하며, 문제를 해결하고 결정을 내릴 때의 특징적인 방식을 설명합니다. 언어 모델링에서 인지 스타일은 생성된 텍스트의 복잡성, 심도 및 구성에 영향을 미칩니다. 매우 분석적 스타일을 갖춘 모델은 논리적이고 세부적이며, 구조화된 결과물을 생성할 수 있지만, 직관적 스타일을 갖춘 모델은 연상적, 추론적 및 추상적인 응답을 생성할 수 있습니다. 다양한 인지 스타일은 모델을 다양한 작업 및 관객에 더 잘 맞도록 만들 수 있습니다.\n\n- 분석적 (낮음, 보통, 높음): 낮은 분석은 단순하고, 표면적인 글쓰기를 만듭니다. 높은 분석은 엄격하고, 심층적이며, 탐구적인 스타일을 의미합니다.\n- 창의적 (낮음, 보통, 높음): 창조성이 낮으면 관습적이고, 예측 가능한 글쓰기를 만듭니다. 높은 창의성은 상상력이 풍부하고, 독창적이며, 혁신적인 언어를 의미합니다.\n- 전략적 (낮음, 보통, 높음): 부적절한 전략은 무질서하고, 목표없는 글쓰기를 만듭니다. 좋은 전략은 목적의식 있고, 잘 계획되며, 목표 중심적인 스타일을 의미합니다.\n- 세부 지향적 (낮음, 보통, 높음): 세부 사항을 무시하면\n\n<div class=\"content-ad\"></div>\n\n# 가치와 신념\n\n가치와 신념은 개인의 세계관, 우선 순위 및 옳고 그름을 인식하는데 영향을 미치는 지침과 확신입니다. 언어 모델의 경우, 가치와 신념은 생성된 텍스트에서 표현되는 의견, 논쟁 및 추천에 영향을 미칩니다. 보수적인 가치를 가진 모델은 전통적이고 신중한 반응을 생성할 수 있으며, 진보적인 가치를 가진 모델은 변화 중심적이고 활동가적인 콘텐츠를 생성할 수 있습니다. 가치를 명시적으로 모델링하는 것은 AI가 생성하는 텍스트의 이데올로기적 성향에 대한 투명성과 제어를 가능하게 합니다.\n\n- 보수주의 (낮음, 중간, 높음): 진보주의는 변화 중심적이고 미래를 중시하는 글쓰기를 유도합니다. 보수주의는 전통적이고 보존을 중시하는 스타일을 의미합니다.\n- 자유주의 (낮음, 중간, 높음): 독재주의는 규칙을 따르며 순응적인 글쓰기를 유도합니다. 자유주의는 개인 중심적이고 선택의 자유를 옹호하며 권위 의심적인 스타일을 의미합니다.\n- 진보주의 (낮음, 중간, 높음): 보수주의는 과거에 초점을 맞추고 전통을 보존하는 글쓰기를 유도합니다. 진보주의는 미래지향적이고 변화 수용 및 혁신을 강조하는 언어를 의미합니다.\n- 환경주의 (낮음, 중간, 높음): 반환경주의는 발전 우선, 자연에 무관심한 글쓰기를 유도합니다. 환경주의는 보존을 중시하고 생태에 민감하며 지속가능성을 중시하는 스타일을 의미합니다.\n- 자본주의 (낮음, 중간, 높음): 사회주의는 집단 중심적이고 평등을 추구하는 글쓰기를 유도합니다. 자본주의는 개인 중심적이고 시장 경제를 옹호하며 이윤 중시하는 언어를 의미합니다.\n- 사회주의 (낮음, 중간, 높음): 자본주의는 개인주의적이고 시장 경제를 생성합니다. 사회주의는 집단 소유를 옹호하고 평등 중시 및 노동자 권리 강화를 강조하는 스타일을 의미합니다. \n\n# 문화적 배경\n\n<div class=\"content-ad\"></div>\n\n문화적 배경은 특정 사회 그룹과 관련된 공유된 규범, 전통, 지식, 생활 방식을 포함합니다. 문화적 배경을 인식하는 언어 모델은 더 다양하고 포용적이며 문화적으로 민감한 콘텐츠를 생성할 수 있습니다. 다양한 문화적 시각을 대표함으로써 모델은 서로 다른 커뮤니티에서 사용자들을 더 잘 서비스하고 공감대를 형성할 수 있습니다. 인종, 국적 및 지역적 정체성과 같은 속성은 모델의 언어 사용에 반영된 문화적 참조 프레임과 경험을 형성합니다.\n\n---\n\n- 아프리카 (낮음, 중간, 높음): 비아프리카적인 시각은 아프리카인들에게 유럽 중심적이고 문화적으로 생소한 글쓰기를 제공합니다. 아프리카적 시각은 아프리카 관중을 위한 문화적으로 관련성이 높고 현지적으로 적절한 스타일을 의미합니다.\n- 아시아 (낮음, 중간, 높음): 비아시아적인 시각은 아시아인에게 문화적으로 낯설고 관련성이 없는 글쓰기를 낳습니다. 아시아적 시각은 아시아 독자를 위해 문화적으로 익숙하고 관련성 있는 언어를 의미합니다.\n- 유럽 (낮음, 중간, 높음): 비유럽적 사고는 유럽인들에게 문화적으로 먼 거리에 있는 흥미롭지 않은 글쓰기를 가져옵니다. 유럽적 시각은 유럽 관중을 위한 문화적으로 적절하고 식별이 가능한 스타일을 의미합니다.\n- 라틴 아메리카 (낮음, 중간, 높음): 비라틴 아메리카적 시각은 라틴 아메리카인들에게 문화적으로 관련성이 없는, 갈등된 글쓰기를 초래합니다. 라틴 아메리카적 시각은 라틴 아메리카 독자를 위해 문화적으로 적절하고 공감대를 형성하는 언어를 의미합니다.\n- 중동 (낮음, 중간, 높음): 비중동 시각은 중동인들에게 문화적으로 익숙치 않고 공감하기 어려운 글쓰기로 이끌 수 있습니다. 중동적 시각은 중동 관중을 위한 문화적으로 적절하고 관련성 있는 스타일을 의미합니다.\n- 북미 (낮음, 중간, 높음): 비북미적 사고는 북미인들에게 문화적으로 낯설고 공감하기 어려운 글쓰기를 결과로 낳습니다. 북미적 시각은 북미 독자를 위해 문화적으로 적합하고 관련성 있는 언어를 의미합니다.\n- 오세아니아 (낮음, 중간, 높음): 비오세아니아적 시각은 오세아니아인들에게 문화적으로 먼 거리에 있는, 식별하기 어려운 글쓰기를 제공합니다. 오세아니아적 시각은 오세아니아 관중을 위해 문화적으로 잘 어울리며 연결된 스타일을 의미합니다.\n- 스칸디나비아 (낮음, 중간, 높음): 비스칸디나비아 시각은 스칸디나비아인들에게 문화적으로 알아볼 수 없고 관련성이 없는 글쓰기를 낳을 수 있습니다. 스칸디나비아적 시각은 스칸디나비아 독자를 위해 문화적으로 친근하고 관련성 있는 언어를 의미합니다.\n- 슬라브 (낮음, 중간, 높음): 비슬라브적 사고는 슬라브인들에게 문화적으로 외부적이고 끌리지 않는 글쓰기를 일으킬 수 있습니다. 슬라브적 시각은 슬라브 관중을 위해 문화적으로 조율되고 식별 가능한 스타일을 의미합니다.\n- 게르만 (낮음, 중간, 높음): 비게르만적 사고는 게르만인들에게 문화적으로 맞지 않고 참여도가 낮은 글쓰기를 제공할 수 있습니다. 게르만적 시각은 게르만 독자에게 문화적으로 소속감을 느낄 수 있고 공감을 형성할 수 있는 언어를 의미합니다.\n- 로맨스 (낮음, 중간, 높음): 비로맨스적 시각은 로망스 문화에 대해 지리적으로 부적합하고 공감하기 어려운 글쓰기를 제공할 수 있습니다. 로맨스적 시각은 로망스어 사용자를 위해 문화적으로 공감대를 형성하고 관련성 있는 스타일을 의미합니다.\n- 산악지대 (낮음, 중간, 높음): 비산악적 시각은 산악지대 거주자들을 위한 지리적으로 특성 없는, 관련성 없는 글쓰기를 결과로 낳을 수 있습니다. 산악적 시각은 산악 거주자를 위해 환경적으로 영향받고 적응된 언어를 제공합니다.\n- 해안 지역 (낮음, 중간, 높음): 내륙적 시각은 해안주민들을 위한 지리적으로 대표성 없는, 공감하기 어려운 글쓰기를 결과로 낳을 수 있습니다. 해안적 시각은 해변 거주자를 위해 환경적으로 형성되고 관련성 있는 스타일을 의미합니다.\n- 섬 (낮음, 중간, 높음): 대륙적 사고는 섬 주민들에게 지리적으로 적합하지 않고 관련성 없는 글쓰기를 결과로 낳을 수 있습니다. 섬적 시각은 섬 거주자를 위해 환경적으로 성형되고 관련성 있는 언어를 제공합니다.\n- 열대 지방 (낮음, 중간, 높음): 비열대적 시각은 열대 지역 거주자에게 기후적으로 부합하지 않고 관련성 없는 글쓰기를 결과로 낳을 수 있습니다. 열대적 시각은 열대 지역 사람들에게 환경적으로 영향을 받은, 공감할 수 있는 스타일의 언어를 제공합니다.\n\n다음 속성들은 우리가 어떻게 의사소통하는 방식과 직접\n\n<div class=\"content-ad\"></div>\n\n의사소통 스타일은 개인이 언어를 통해 자신을 표현하고 다른 사람과 상호작용하는 특성적 방식을 의미합니다. 직접성, 정식성, 표현성, 그리고 공손함과 같은 속성을 포함합니다. 다른 의사소통 스타일을 가진 언어 모델은 다른 맥락과 대상을 고려한 결과물을 생성할 수 있습니다. 보다 공식적이고 분석적인 스타일을 가진 모델은 전문적이고 학술적인 환경에 더 적합할 수 있으며, 보다 비공식적이고 유쾌한 스타일을 가진 모델은 일상 대화와 엔터테인먼트에 더 매력적일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n간접적인 의사 소통은 더 간접적이며, 명확하게 말하기보다는 암시합니다. 그것은 매너가 좋고 섬세하며, 모욕을 주지 않도록 노력합니다.\n\n## 격식 있는\n\n격식 있는 스타일은 문법과 예절의 엄격한 규칙을 따릅니다. 그것은 적절하고 존엄하며, 심각한 어조를 유지합니다. 전문적인 거리를 유지합니다.\n\n## 비격식인\n\n<div class=\"content-ad\"></div>\n\n인포멀한 스타일은 톤이 캐주얼하고 편안하며 친숙하다. 엄격한 규칙을 배제하며 청중과의 친밀감과 가까움을 전달한다.\n\n**사실 기반**\n\n사실에 기반한 커뮤니케이션은 객관적이고 데이터 중심적이며 증거에 기반한다. 추측, 의견 및 감정적 호소를 피하고 검증 가능한 정보를 선호한다.\n\n**감정적**\n\n<div class=\"content-ad\"></div>\n\n감정 표현은 주관적이고 개인적이며 감정을 불러일으키고 공감 연결을 형성하기 위해 생생한 언어를 사용합니다.\n\n## 분석적\n\n분석적 스타일은 논리적이고 체계적이며 세부사항을 중시합니다. 시스템적으로 사물을 분해하고 신중한 추론을 도출합니다.\n\n## 직관적\n\n<div class=\"content-ad\"></div>\n\n직관적인 커뮤니케이션은 본능적이며 가정적이며 인상에 기반합니다. 직감, 연상 및 줄거리 해석을 활용합니다.\n\n## 장황한\n\n장황성은 아이디어를 전달하기 위해 필요한 단어보다 더 많은 단어를 사용하는 것을 의미합니다. 지나치게 설명이 많아지며 장황하고 지루해질 수 있습니다.\n\n## 간결한\n\n<div class=\"content-ad\"></div>\n\n간결함은 아이디어를 가능한 한 적은 단어로 표현하는 것을 의미합니다. 간결하고 요점을 짚는 것이며, 불필요한 내용이나 채움말을 피합니다.\n\n## 자신감 있는 표현\n\n자신감 있는 표현은 자신감 있고 결정적이며 확고합니다. 강력한 입장을 취하고 권위와 확신을 가지고 말합니다.\n\n## 주저하는\n\n<div class=\"content-ad\"></div>\n\n망설임은 소심하고 의심스럽고 확신이 없다는 느낌을 줍니다. 한정어, 회피어 및 질문적이며 공손한 어조로 표시됩니다.\n\n## 유머러스\n\n유머에는 영리함, 풍자, 과장 및 장난기가 포함되어 더 가벼우며 코믹한 어조로 구성되어 있습니다.\n\n## 진지\n\n<div class=\"content-ad\"></div>\n\n진지한 커뮤니케이션은 신중하고 사실적이며 중대하다. 그것은 무겁고 중요하며 경솔한 행동을 싫어한다.\n\n## 존중\n\n존중하는 언어는 예의 바르고 사려 깊으며 다른 사람에 대해 공손합니다. 예의를 지키고 모욕이나 지나친 친밀함을 피합니다.\n\n## 친근함\n\n<div class=\"content-ad\"></div>\n\n친근한 표현은 상냥하고 따뜻하며 친근하다. 상호간의 유대감을 형성하고 다른 사람들이 편안하고 좋아하는 느낌이 들도록 돕는다.\n\n### 시끄러운 소통\n\n시끄러운 소통은 더 강렬하고 강조적이며 눈에 띄는 성질이다. 주목을 끌지만 너무 남용할 경우 공격적으로 비춰질 수 있다.\n\n### 부드러운 말투\n\n<div class=\"content-ad\"></div>\n\n부드러움은 더 부드럽고 절제된 힘이 적은 것을 의미합니다. 다른 사람들을 진정시키고 안락함을 주지만 과도하게 사용하면 소심해 보일 수도 있습니다.\n\n## 빠르게 진행\n\n빠른 진행은 활기차고 민첩하며 활기찬 것을 의미합니다. 아이디어 간을 빠르게 움직이면서 참여하게 만들지만 끝없이 계속되면 압도될 수 있습니다.\n\n## 느긋한 진행\n\n<div class=\"content-ad\"></div>\n\n천천히 진행하는 것은 더 신중하고 점진적이며 여유롭습니다. 아이디어를 습득할 시간을 제공하지만 너무 느리면 지루할 수 있습니다.\n\n## 시각\n\n시각 언어는 생생한 단어 그림을 그립니다. 외관, 장면 및 이미지를 묘사합니다. 시각을 떠올리는 것으로 몰입합니다.\n\n## 청각\n\n<div class=\"content-ad\"></div>\n\n청각 언어는 소리, 목소리 및 들을 수 있는 세부사항에 중점을 둡니다. 청각 경험을 떠올리며 매료시킵니다.\n\n## 운동감각\n\n운동감각 언어는 움직임, 감각 및 신체적 경험을 강조합니다. 촉각적이고 몸을 떠올리며 매료시킵니다.\n\n## 기능적\n\n<div class=\"content-ad\"></div>\n\n기능적 커뮤니케이션은 실용적이고 유용하며 작업 중심적입니다. 정보를 전달하고 목표를 효율적으로 달성하는 데 목적이 있습니다.\n\n## 표현적\n\n표현적인 커뮤니케이션은 더 개인적이고 예술적이며 감정적으로 표현합니다. 내면의 생각과 감정을 생생하게 전달합니다.\n\n# 언어 등록\n\n<div class=\"content-ad\"></div>\n\n언어 레지스터는 특정 사회적 맥락에서 사용되는 언어의 고정성, 복잡성 및 구체성 수준을 나타냅니다. 서로 다른 레지스터는 다른 상황, 청중 및 목적에 적합합니다. 여러 레지스터에서 텍스트를 생성할 수 있는 언어 모델은 더 넓은 사용 사례에 적응할 수 있습니다. 예를 들어, 전문 용어와 일반적인 용어 사이를 전환할 수 있는 모델은 전문가와 일반 대중 양쪽에 모두 봉사할 수 있습니다. 어휘, 문법 및 어조와 같은 속성은 레지스터를 신호로써 확인하며 모델의 언어의 접근성과 적절성을 형성합니다.\n\n## 정형화\n\n정형화된 레지스터는 엄격한 문법과 예절 규칙을 따릅니다. 무개인적이며 단정하며 객관적입니다. 권위를 전달하고 계층 구조를 관찰합니다.\n\n## 비정형화\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 다음과 같이 Markdown 형식으로 변경해주세요.\n\n\n| informal register | 더 캐주얼하고 사적이며 편안한 레지스터입니다. 구어, 축약형 및 친숙하고 대화식인 어조를 사용합니다. 독자를 안심시킵니다. |\n|-------------------|------------------------------------------------------------------------------------------|\n| Colloquial        | 사적이고 대화식 언어로, 비속어, 관용구 및 지역 표현을 사용합니다. 진정성 있고 소박하며 \"진짜다운\" 어조를 세웁니다.                  |\n| Slang            | -                                                                                          |\n\n\n<div class=\"content-ad\"></div>\n\n* 비속어는 매우 비공식적이고 때로는 저속한 언어를 의미합니다. 이는 특정 서브컬처나 그룹 내에서 내부인으로 인정받는 것을 의미하며 비초 입자들을 멀리 합니다.\n\n## 전문 용어\n\n전문 용어는 특정 직업이나 그룹에서 사용되는 특수한 기술 용어입니다. 내부 지식을 효율적으로 전달하지만, 초지식자는 배제합니다.\n\n## 기술\n\n<div class=\"content-ad\"></div>\n\n기술 글쓰기는 복잡하고 세부적이며 전문 지식에 의존합니다. 과학적이거나 산업적이거나 특정 분야의 용어를 사용합니다. 객관적이고 정확합니다.\n\n## 학술\n\n학술 글쓰기는 학술적이고 지적이며 연구 기반입니다. 학문적인 용어, 공식적인 스타일 및 엄격한 논리를 사용합니다. 글쓴이를 전문가로 위치시킵니다.\n\n## 문학\n\n<div class=\"content-ad\"></div>\n\n문학적 언어는 상상력이 풍부하고 표현력이 풍부하며 함축적입니다. 시적 장치와 언어유희를 사용합니다. 그것은 글자 그대로인 것보다 더 상징적이고 애매하다.\n\n### 시적 언어\n\n시적 언어는 매우 미적이며, 리듬적이고 은유적입니다. 이미지, 가사성, 추상적 상징을 자유롭게 사용합니다. 명확하게 설명하기보다는 함축적입니다.\n\n### 향수롭다\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 변경해 주세요.\n\n<div class=\"content-ad\"></div>\n\n웃음을 유발하는 글은 익살적이거나 풍자적입니다. 무리한 상황에서 재미를 찾거나 장난을 쳐서 즐깁니다.\n\n## 풍자적\n\n풍자는 가식적이고 비웃는 언어입니다. 주제를 얕보이기 위해 의도와 반대의 말을 합니다. 풍자는 반어를 통해 경멸을 표현합니다.\n\n## 반어\n\n<div class=\"content-ad\"></div>\n\n아이러니는 현실과 기대 사이의 불일치를 강조합니다. 모순과 역설을 드러냅니다. 그것은 비꼬르고 역설적입니다.\n\n## 진심\n\n진심 언어는 진지하고 진심 어린 것입니다. 솔직하고 똑바로 말하는 것입니다. 신뢰와 진정한 연결을 확립합니다.\n\n## 과장\n\n<div class=\"content-ad\"></div>\n\n과장은 과장과 피격법을 의미합니다. 강조나 효과를 위해 무엇인가를 실제보다 극도로 강조하는 것입니다.\n\n## 절제된\n\n절제는 억제와 밀라 속에서 나온 말입니다. 최소화나 유머를 통해 무엇인가를 실제보다 덜 중요하게 보이게 합니다.\n\n## 설득력 있는\n\n<div class=\"content-ad\"></div>\n\n설득력 있는 언어는 납득을 이끌어내며, 설득력이 있고 영향력이 있습니다. 이것은 이성과 감정을 통해 의견을 흔들며 사람들을 행동으로 이끕니다.\n\n## 정보 제공\n\n정보 전달은 사실적이고 지도적이며 교육적입니다. 명확하게 설명하고 정보를 제공합니다. 정확하고 잘 구성되어 있습니다.\n\n## 지시적\n\n<div class=\"content-ad\"></div>\n\n시험 언어는 절차적이고 지시적이며 조언적입니다. 방향을 제시하고 행동을 안내합니다. 단계별로 기술을 가르칩니다.\n\n### 대화형\n\n대화형 글쓰기는 비공식적이고 개인적이며 상호작용적입니다. 친근한 대화처럼 읽힙니다. 간단한 단어, 줄임말, \"당신\"과 \"나\"를 사용합니다.\n\n### 연설체\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 변경해주세요.\n\n\n| 슬로건 | \n| ------ | \n| 웅장하고 감동적이며 설득력 있는 언어로, 말로 표현됨. 감정을 일으키기 위해 수사 기술을 사용함. | \n\n| 설교 | \n| ------ | \n| 도덕적으로 가르치며 권위 있는 언어로, 종교 서적을 해석하고 교회를 옳은 행동을 하도록 하려 함. | \n\n| 애기 말 | \n| ------- | \n|\n\n\n<div class=\"content-ad\"></div>\n\n베이비 토크는 유아적이고 간단하며 반복적입니다. 털털하고 애교 있는 소리와 애완동물 이름이 사용됩니다. 어른들이 아기들에게 말하는 방식을 모방합니다.\n\n## 보호자 말투\n\n보호자 말투는 달래는 듯하고 부드럽고 격려적입니다. 긍정적이고 인내심이 있습니다. 단순한 지시로 아이들을 이끌어줍니다.\n\n## 모더리즈\n\n<div class=\"content-ad\"></div>\n\nMotherese는 따뜻하고 위로를 주는 애정적인 언어입니다. 노래처럼 울림 있는 과장된 억양을 사용하며 양육과 무조건적인 사랑을 표현합니다.\n\n## 토론\n\n토론 언어는 적대적이고 논리적이며 근거에 입각한 언어입니다. 주장을 증명하고 상대방의 주장을 물리치기 위해 노력합니다.\n\n## 의식적인\n\n<div class=\"content-ad\"></div>\n\n의식어에는 위엄 있고 공식적이며 공연적인 언어가 사용됩니다. 중요한 행사와 의례를 표시합니다. 절차를 시행하기 위해 일정한 문구를 사용합니다.\n\n## 기도\n\n기도 언어는 존경스럽고 겸손하며 찬양적입니다. 높은 권력을 직접적으로 대면합니다. 감사를 표현하고 청구합니다.\n\n<div class=\"content-ad\"></div>\n\n의식 언어는 엄숙하고 상징적이며 규정된 언어입니다. 영적인 의미를 불러일으키기 위해 일정한 공식을 따릅니다. 그것은 신성한 행위를 신성하게 만듭니다.\n\n## 전승\n\n전승 언어는 전통적이고 신화적이며 비유적입니다. 문화적 이야기와 신념을 공유합니다. 상상력이 풍부하고 원형적입니다.\n\n## 친밀\n\n<div class=\"content-ad\"></div>\n\n친밀한 언어는 개인적이고 감정적이며 취약합니다. 개인적인 생각과 경험을 드러냅니다. 신뢰를 구축하고 교감을 형성합니다.\n\n**캐주얼**\n\n캐주얼한 언어는 편안하고 친숙하며 비공식적입니다. 다른 사람들을 안심시키고 공손함을 배제합니다. 독자를 동등하게 대합니다.\n\n# 전문 용어\n\n<div class=\"content-ad\"></div>\n\n특정 분야, 직업 또는 사회 그룹 내에서 사용되는 전문 용어를 '중용어'라고 합니다. 중용어는 내부 구성원들 간에 복잡한 아이디어를 효율적으로 전달하는 데 도움이 되지만, 외부인들에게는 배제적이거나 혼란스러울 수 있습니다. 서로 다른 영역의 중용어를 포함한 언어 모델은 해당 배경을 공유하는 사용자들과 더 현실적이고 유익한 대화를 나눌 수 있습니다. 그러나 중용어의 사용은 필요할 때 일반 대중을 위해 개념을 설명하거나 번역하는 능력과 균형을 맞추어야 합니다.\n\n## 의학\n\n의학 관련 중용어에는 해부학, 질병, 치료, 약리학 등의 임상 용어가 포함됩니다.\n\n## 법률\n\n<div class=\"content-ad\"></div>\n\n법률용어는 법, 규정, 범죄, 민사상의 행위, 계약 등에 대해 기술 용어를 사용합니다.\n\n## 기술\n\n기술용어는 IT, 전자, 공학 등에 걸쳐 약어와 상표명을 사용합니다.\n\n## 과학\n\n<div class=\"content-ad\"></div>\n\n과학 용어는 자연 현상, 종, 화합물, 과정, 실험실 기술 등을 정확하게 설명합니다.\n\n## 학술\n\n학술 용어는 심리학, 경제학, 문학 이론 등 다양한 분야의 학술 용어를 사용합니다.\n\n## 비즈니스\n\n<div class=\"content-ad\"></div>\n\n비즈니스 용어에는 경영, 재무, 회계, 마케팅 및 기업 전략 용어가 포함됩니다.\n\n### 마케팅\n\n마케팅 및 광고 용어에는 브랜딩, 시장 조사, 소비자 행동 등이 포함됩니다.\n\n### 재무\n\n<div class=\"content-ad\"></div>\n\n은행, 투자, 대출, 회계 및 보험 용어들입니다.\n\n## 정치\n\n공공 정책, 활동, 지정학, 선거운동 및 논란이 되는 문제들입니다.\n\n## 군사\n\n<div class=\"content-ad\"></div>\n\n전투, 전략, 규정, 하드웨어, 머신, 준말 및 속어.\n\n## 스포츠\n\n다양한 종목의 규칙, 포지션, 플레이, 전략, 장비 및 점수.\n\n## 예술\n\n<div class=\"content-ad\"></div>\n\n장르, 기법, 악기, 악보, 비평 등에 대한 미술, 연주 및 응용 미술 정보가 포함된 표입니다.\n\n## 요리\n\n음식, 조리 기술, 향신료, 요리 종류 등에 대한 정보가 포함됩니다.\n\n## 패션\n\n<div class=\"content-ad\"></div>\n\n의류 스타일, 디자이너, 원단, 액세서리, 트렌드 등.\n\n## 음악\n\n악보, 악기, 이론, 장비, 디지털 오디오 워크스테이션 등.\n\n## 영화\n\n<div class=\"content-ad\"></div>\n\n시네마 스타일, 기법, 장비, 역할 및 비평\n\n## 게임\n\n비디오 게임 장르, 콘솔, 게임 플레이, 전략, 속어\n\n## 소셜 미디어\n\n<div class=\"content-ad\"></div>\n\nPlaforms(플랫폼), features(기능), algorithms(알고리즘), analytics(분석), content types(콘텐츠 유형).\n\n## 인터넷\n\nProtocols(프로토콜), coding(코딩), cybersecurity(사이버 보안), hardware(하드웨어), software(소프트웨어), memes(밈).\n\n## 암호화폐\n\n<div class=\"content-ad\"></div>\n\n블록체인, 암호화폐, 프로토콜, 거래소, 이니셔티브.\n\n## 프로그래밍\n\n언어, 제어 흐름, 데이터 구조, 알고리즘, 패러다임.\n\n## 엔지니어링\n\n<div class=\"content-ad\"></div>\n\n전기, 기계, 토목, 항공우주 설계 및 문제 해결.\n\n## 건축\n\n스타일, 기술, 재료, 역할, 역사.\n\n## 심리학\n\n<div class=\"content-ad\"></div>\n\n정신 과정, 행동, 인지, 장애 및 치료.\n\n## 교육\n\n교육론, 지도, 교실 관리, 테스트 등.\n\n## 저널리즘\n\n<div class=\"content-ad\"></div>\n\n뉴스 수집, 작성 스타일, 편집, 미디어 법 및 윤리.\n\n## 게시\n\n책, 잡지, 저널, 각색, 편집 및 형식.\n\n# 속어\n\n<div class=\"content-ad\"></div>\n\n짧은 단어를 사용하면 메모리 절약이 가능한 경우가 많습니다.\n\n<div class=\"content-ad\"></div>\n\n특정 문화 공동체에서 사용되는 그룹 내 용어.\n\n## 문화\n\n게이머, 밸리 걸, 드래그 퀸, 래퍼 등과 같은 서브컬처는 고유한 속어를 가지고 있습니다.\n\n## 세대 간\n\n<div class=\"content-ad\"></div>\n\n서로 다른 연령대는 다른 용어를 사용해요.\n\n## 직업\n\n서로 다른 직업들은 각자의 비공식 약어를 사용해요.\n\n## 전문 용어\n\n<div class=\"content-ad\"></div>\n\n감옥수, 마약 거래자 등과 같은 폐쇄된 집단이 사용하는 의도적으로 모호한 속어로, 외부인으로부터 의미를 숨기기 위해 사용됩니다.\n\n**Cant**\n\n강도, 서커스 종사자 등이 사용하는 어떤 특정 언어와 유사합니다.\n\n**전문 용어**\n\n<div class=\"content-ad\"></div>\n\n전문가들이 사용하는 특정 기술 용어.\n\n## 회화\n\n비공식적인 말투에서 사용되는 캐주얼하고 대화형 표현.\n\n## 관용구\n\n<div class=\"content-ad\"></div>\n\n다양한 비유적인 표현들이에요.\n\n## 유피미즘\n\n형식적이면서도 현실을 숨기는 모호한 표현들이에요.\n\n## 디스페미즘\n\n<div class=\"content-ad\"></div>\n\nMarkdown 형식으로 테이블 태그를 변경해주세요.\n\n| Rude expressions that are more offensive than the literal terms. |\n|---------------------------------------------------------------|\n| **Profanity**                                                |\n| Obscene, vulgar or blasphemous words.                         |\n|---------------------------------------------------------------|\n| **Obscenity**                                                |\n\n<div class=\"content-ad\"></div>\n\n다음처럼 Markdown 형식의 표를 변경해 주세요.\n\n| Indecent, lewd, pornographic language |\n|---------------------------------------|\n| Interruption of the present narrative to depict events from the past, often to provide context or reveal character backstory. |\n\n## Foreshadowing\n\nSubtle hints or clues about future events in the narrative, often creating a sense of tension or anticipation.\n\n<div class=\"content-ad\"></div>\n\n## 클리프행어\n\n이야기의 일부가 갑자기 끝나 여독자를 긴장 상태에 빠뜨리는 것을 말합니다. 종종 중요하거나 흥미로운 순간에 이뤄집니다.\n\n## 전개 변화\n\n독자의 기대와 가정을 뒤엎는 예상치 못한 사건의 전환을 의미합니다. 종종 전체 이야기의 방향이나 의미를 변경시킵니다.\n\n<div class=\"content-ad\"></div>\n\n## 비유\n\n하나의 것을 다른 것의 용어로 설명하는 비유적 비교로, 종종 추상적인 개념을 더 생생하고 관련성있게 만드는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 유사법\n\n한 가지를 다른 것과 비교하여 묘사를 더 생생하게 하거나 강조하는 데 종종 사용되는 “like” 또는 “as”를 사용한 비유적인 비교.\n\n## 풍자\n\n희극적이거나 빈정거리는 비평으로, 종종 과장이나 조롱을 통해 인간의 악덕, 어리석음 및 사회 문제를 드러내거나 조롱하는 것.\n\n<div class=\"content-ad\"></div>\n\n## 불안정한 이야기꾼\n\n이야기꾼은 신뢰도가 떨어지는 경우가 많으며, 종종 거짓말을 하거나 망상에 사로잡히거나 지식이 부족하여서 독자로 하여금 이야기의 정확성을 의심하도록 만드는 사람을 가리킨다.\n\n## 단편\n\n한 순간, 분위기 또는 캐릭터를 잘 포착하며 종종 전체 줄거리가 없는 섬세한 묘사나 장면을 의미한다.\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 변경하십시오.","ogImage":{"url":"/assets/img/2024-06-22-TheDefinitiveGuidetoLLMWritingStyles_0.png"},"coverImage":"/assets/img/2024-06-22-TheDefinitiveGuidetoLLMWritingStyles_0.png","tag":["Tech"],"readingTime":18},{"title":"대형 언어 모델 완벽 이해  두 번째 이야기","description":"","date":"2024-06-22 20:33","slug":"2024-06-22-LargeLanguageModelsExplainedII","content":"\n\nChatGPT의 추상적 진화와 LLM의 일반적인 세부 정보가 'Large Language Models Explained — I'에서 제공되었습니다. 이전 글에서 몇 가지 질문으로 글을 마무리했습니다. 이 글에서는 해당 질문에 대한 답을 논의하고 LLM의 기본 프로그래밍 측면부터 시작하겠습니다.\n\n이전 글에서 언급했듯이, ChatGPT는 GPT(Generative Pre-trained Transformer)라는 LLM을 사용하며, LLM이란 단순히 여러 신경망의 조합일 뿐입니다. 결국 LLM은 딥러닝 모델이나 기계 학습 모델과 유사한 모델에 불과합니다. 그러므로 사용자가 ChatGPT에 질문을 하면 미리 훈련된 모델을 테스트하는 것과 유사합니다(기계 학습 모델을 사용할 때와 같은 방식입니다). 예를 들어, KNN 모델을 훈련하고 sklearn 패키지를 사용하는 경우 다음과 같이 작성할 수 있습니다.\n\n```js\nfrom sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X, y) ##모델을 훈련하기 위해 사용되는 LINE\nneigh.predict([[1.1]]) ##모델을 테스트하기 위해 사용되는 LINE\n```\n\n위의 코드에서 'neigh.fit()' 함수는 KNN 분류기를 훈련하는 데 사용되고, 'neigh.predict()'는 주어진 테스트 데이터의 출력을 예측하는 데 사용됩니다. 비슷하게 ChatGPT에 묻는 질문은 Transformer 아키텍처를 기반으로 한 GPT 모델에 입력되어 문장의 끝에 도달할 때까지 다음 단어를 예측하게 됩니다. 우리가 KNN과 같은 분류기를 훈련하기 위해 작은 양의 데이터를 사용하는 것과 달리, GPT는 많은 양의 데이터로 훈련되었고 실행에 많은 메모리가 필요한 거대한 모델입니다. (참고: 이때 진짜 영웅 GPU가 필요합니다. GPU에 대해 자세히 설명하지는 않았지만 원한다면 여기서 배울 수 있습니다.)\n\n<div class=\"content-ad\"></div>\n\n이제 이러한 LLM을 실행하기 위해 필요한 메모리 양은 상상 이상으로 많습니다. Openai 및 Google과 같은 몇 개의 회사만이 이러한 대규모 메모리를 확보할 수 있습니다. 만약 우리가 우리의 컴퓨터에서 이러한 거대한 LLM을 실행할 수 없다면, 어떻게 접근하고 그들을 활용할 수 있을까요? 이 질문의 답은 약간 까다롭습니다.  \n우선 openai.com에 로그인하면 ChatGPT에 무료 액세스할 수 있습니다. 거기서 질문을 하고 채팅할 수 있습니다. Openai는 이러한 무거운 부하를 관리할 수 있는 강력한 백엔드(부하 분산)를 갖고 있습니다. 회사는 GPT가 실행 중인 서버를 항상 켜놓기 때문에 원하는 때에 질문할 수 있습니다.  \n둘째로, 애플리케이션을 구축하는 데 LLM을 활용할 수 있습니다. 여러분이 애플리케이션을 구축하기 시작할 수 있는 기본 아이디어를 제공하겠습니다.  \n\n다음과 같은 방식으로 기본적인 API에 대한 개념을 가지고 있어야 합니다. 간단히 말해 Application Programming Interface(API)는 두 대 이상의 컴퓨터가 통신하는 방법입니다. 우리의 경우, 클라이언트는 애플리케이션을 구축하려는 사용자이며, 서버는 LLM이 실행 중인 곳입니다. 이 두 대 사이에 채널을 구축하려면 API를 사용해야 합니다. API는 키 형식으로 제공됩니다(일반적으로 알파벳과 숫자의 혼합).  \n이제 서버와 통신하기 위한 API 키를 어떻게 얻을까요?  \n1) openai.com에 방문합니다.  \n2) 제품으로 이동합니다.  \n3) API 로그인으로 이동합니다. 세부 정보를 제공하고 로그인(또는 회원 가입)합니다.  \n\n![이미지](/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png)\n\n4) API로 이동(OpenAI 모델을 응용 프로그램이나 비즈니스에 통합).  \n5) 대시보드로 이동합니다.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-22-LargeLanguageModelsExplainedII_1.png)\n\n6) 왼쪽 패널에서 API 키로 이동합니다.\n\n![이미지](/assets/img/2024-06-22-LargeLanguageModelsExplainedII_2.png)\n\n7) 휴대폰 번호로 등록한 후 '새 비밀 키 생성' 옵션을 볼 수 있습니다. 해당 옵션을 클릭하여 키를 복사하고, 다른 곳에 키를 저장해주세요. 그렇지 않으면 '확인'을 클릭한 후 키가 보이지 않을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_3.png\" />\n\n와우! 이제 챗지피티 서버와 시스템 간의 통신 경로를 구축할 API 키가 있습니다.\n\n중요한 노트:\nGITHUB나 LINKEDIN을 포함하여 인터넷 상 어디에도 API 키를 노출시키지 마십시오. OPENAI에서 키 액세스를 취소하고 계정을 차단할 수 있습니다.\n— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n\n우리는 이제 LLMs를 사용한 애플리케이션을 구축하는 방법에 도달했습니다. Langchain은 Large Language Models (LLM)을 사용한 애플리케이션 생성을 간소화하기 위해 설계된 프레임워크입니다. Langchain은 Python 및 Javascript 언어로 사용할 수 있습니다. 이 기사에서는 Python 언어를 통해 langchain을 소개하고 모델을 사용하여 애플리케이션을 구축하는 방법을 소개하겠습니다.\n여기서 Visual Studio Code 내부의 Python 노트북을 사용했습니다. 사용하고자 하는 편집기를 선택하실 수 있습니다.\n먼저 새 폴더를 생성하고 해당 폴더를 Visual Studio Code에서 엽니다. 가상 환경을 생성하고 해당 환경 내에서 필요한 모든 라이브러리를 설치합니다.\n가상 환경을 생성하려면,\n\n<div class=\"content-ad\"></div>\n\n```js\npip install virtualenv\n```\n\n그런 다음 터미널에서,\n\nvirtualenv `env_name`를 입력하고 `env_name`\\Scripts\\activate를 실행하세요.\n\n- 필수 라이브러리 설치하기\n\n\n<div class=\"content-ad\"></div>\n\n```js\npip install langchain openai langchain_community ipykernel\n```\n\n노트북에서,\n\n2.기본 쿼리\n\n```js\nfrom langchain.llms import OpenAI\napi_key=\"<your_api_key>\"\nllm=OpenAI(model=\"gpt-3.5-turbo\",openai_api_key=api_key,temperature=0.5)\nllm.predict(\"Who is the Prime Minister of India?\")\n```\n\n<div class=\"content-ad\"></div>\n\n먼저, langchain에서 OpenAI 모듈을 가져와서 모델 이름, API 키, 온도로 모델을 초기화합니다. 온도는 LLM의 창의성을 결정하는 것입니다. 온도가 낮을수록 LLM은 매번 유사한 답변을 생성하지만, 온도가 높으면 LLM은 더 창의적이 되어 다양한 답변을 제공합니다. llm.predict()은 최종 답변을 제공합니다.\n\n3. 체인과 프롬프트 템플릿\n\n```js\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.chains import SimpleSequentialChain\n\ntemplate_1=PromptTemplate(input_variables=['country'],\ntemplate=\"Tell me the president of {country}\")\n\nchain_1=LLMChain(llm=llm,prompt=template_1)\n\ntemplate_2=PromptTemplate(input_variables=['president'],\ntemplate=\"Give me the list of changes made by the {president}\")\n\nchain_2=LLMChain(llm=llm,prompt=template_2)\n\nchain=SimpleSequentialChain(chains=[chain_1,chain_2])\nchain.run(\"United States of America\")\n```\n\n아마 궁금하실거에요. 위 코드에서 두 가지 중요한 것들을 눈치채실 수 있어요. 프롬프트 템플릿과 체인입니다.\n영어 웅변 대회에 참가 중이라고 상상해보세요. 심사위원들이 '나렌드라 모디'라는 주제를 주고 \"인도는 민주국가이며 현재 나렌드라 모디 총리가 이끄는 중입니다\"라고 시작해서 이어가라고 하면 쉬울 거에요. 단순히 주제만 주고 계속 이어가라고 하면 조금 어려울 수도 있어요.\n이게 바로 프롬프트 템플릿이에요. 이는 ChatGPT에 답변을 제시하도록 모델을 유도하는 템플릿과 같아요. 이 코드에서는 \"Tell me the president of 'country'\"와 같은 프롬프트를 제공했는데, run() 함수에서 국가 이름을 언제든지 변경할 수 있어요.\n이제 하나의 템플릿의 답변을 다른 템플릿으로 전달하고 싶다면, 다른 질문의 답변에 의존하는 경우에는 체인이라는 개념을 사용해야 해요. 체인은 LLM에 대한 단일 API 호출을 넘어 여러 호출을 순차적으로 연결할 수 있게 해줘요. 여기서 LLMChain은 LLM과 해당 템플릿을 묶는 데 사용됩니다. 여기서 사용한 것은 2개 이상의 LLMChain(체인 1, 체인 2)을 사용하는 간단한 순차 체인이며, 하나의 입력(United States of America)에 기반한 답변을 제공합니다.\n요약하면, 이 간단한 코드 조각은 프롬프트 템플릿과 체인의 사용법을 보여줍니다. 여기서는 Langchain에서 직접 가져온 SimpleSequentialChain과 Prompt Template의 사용법을 보여줬어요. 첫 번째 템플릿은 \"Who is the president of United States of America\"이며, 답은 \"Joe Biden\"이고, 이는 다음 템플릿인 \"List the changes made by Joe Biden\"에 입력으로 전달되어 마지막 답변이 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---\n\n이 기사에서는 대형 언어 모델에 대한 토론을 이어가겠습니다. ChatGPT의 추상 작동 방식으로 시작하여 GPT를 API 키를 통해 대형 언어 모델로 사용하는 방법에 대해 설명했습니다. 마지막으로 API 키를 사용하고 Langchain이라는 프레임워크를 활용하여 LLM에 쿼리하는 기본 아이디어를 소개했습니다. 모든 LLM을 활용하고 커스텀 애플리케이션을 구축하는 경우가 많이 있습니다. 또한 이곳에서 논의되지 않은 LLM의 많은 구성 요소가 있습니다. 본 기사는 ChatGPT와 Langchain의 작동 방식에 대한 스타터 팩을 제공하는 것을 목표로 합니다. 본 기사에서 언급한 모든 기술 용어에 대해 자세히 논의할 내용이 더 많습니다. 이전 기사에서 받은 질문에 대한 답변을 통해 적절히 대답했기를 바랍니다. \n모든 것을 천천히 다룰 것을 약속합니다. 그때까지 '계속 배우기'!\n감사합니다!\n\n--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---\n\n- https://openai.com/\n- https://python.langchain.com/v0.2/docs/tutorials/llm_chain/\n- https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/llms\n- https://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar\n\n<div class=\"content-ad\"></div>\n\n---","ogImage":{"url":"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png"},"coverImage":"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png","tag":["Tech"],"readingTime":7},{"title":"ChatGPT로 완성된 최고의 Midjourney 프롬프트 만들기  이렇게 해봤어요","description":"","date":"2024-06-22 20:31","slug":"2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut","content":"\n\n## 완벽한 프롬프트 만들기\n\n최근 업데이트: 15/06/24.\n\n안녕하세요! Midjourney 크루 여러분, 어떻게 지내시나요?\n\n만약 멋진 Midjourney 프롬프트를 만드는 데 어려움을 겪고 계시고 이미지에 세부 정보를 추가하기 위해 수많은 시간을 쓰고 싶지 않다면, ChatGPT를 사용해 완벽한 프롬프트를 만들어보세요.\n\n<div class=\"content-ad\"></div>\n\n한 마디도 쓰기 싫다면 이미지를 만들 수도 있어요. 조금 이상하지만 말이죠. 이에 대해 더 많이 쓴 글이 있어요:\n\n그럼 당신에게 무엇이 좋을까요?\n\n- Midjourney에 대한 좋은 프롬프트 구조를 배우세요 (물론 구조가 단 하나뿐은 아니에요)\n- ChatGPT를 사용하여 Midjourney 프롬프트를 만드세요\n- 몇 가지 정말 멋진 예시에서 영감을 얻으세요\n\n이제 ChatGPT를 사용하여 프롬프트를 만드는 방법을 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## 기본 프롬프트 구조\n\n먼저 미드저니 프롬프트의 기본 구조를 살펴보겠습니다.\n\n여기서 보시는 것처럼, 주제로 시작하고 속성과 세부 정보를 추가하고, 스타일을 설명하고, 색상 팔레트를 추가한 다음 마지막으로 선택적 요소를 추가해주시면 됩니다.\n\n간혹 요소를 제외해 보는 것도 도전해 볼 수 있지만, 때로는 실패할 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n당연히 간단한 템플릿을 사용하여 고유한 프롬프트를 만들 수 있어요. 하지만 ChatGPT를 대신 사용해볼 수도 있어요.\n\n## ChatGPT\n\nChatGPT를 사용하는 것은 정말 쉽고 직관적이에요. 이건 Midjourney를 사용하기 전에 한 단계 더 밟는 과정이죠. 초심자들에게는 프롬프트 구조를 이해하고 효과적인 프롬프트를 만드는 방법을 배우는데 좋을 수도 있어요.\n\n익숙해지면 이 단계를 건너뛸 수 있을 거예요.\n\n<div class=\"content-ad\"></div>\n\n우주 비행사가 외계 행성에 있는 영화 장면을 만들고 싶다고 해보죠.\n\n<img src=\"/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_0.png\" />\n\n우리가 해야 할 일은 원하는 대로 설명하고 ChatGPT가 거의 완벽에 가까운 프롬프트를 만들어주기를 기다리는 것뿐이에요. 적어도 초고, 일부 기초는 제공해줍니다. 그냥 Midjourney에 복사하여 그 마법을 발휘하게 하면 됩니다(결과는 아래에서 확인).\n\n지금 알아차린 것처럼 ChatGPT에 대한 프롬프트로 개인 패턴을 사용했어요. 명시적으로 지시해서 프롬프트 천재로 만드는 거예요.\n\n<div class=\"content-ad\"></div>\n\n그리고 한 단계 더 나아가서 ChatGPT에게 항상 기본 프롬프트 구조를 따르도록 미리 말할 수도 있어요. 아래 예시에 나와 있는 대로 하면 됩니다:\n\n![2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_1.png](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_1.png)\n\n여기서 볼 수 있듯이, ChatGPT에게 기본 프롬프트 구조를 따르도록 명확히 지시했어요. 이 대화 도중에는 이 규칙을 따르지만, 물론 새 채팅을 열 경우 ChatGPT는 초기화될 거예요(그러니 새 채팅을 시작할 때마다 ChatGPT에게 무엇을 원하는지 말하는 걸 잊지 마세요).\n\n## 중간 단계\n\n<div class=\"content-ad\"></div>\n\n엔터를 누르기 전에 사용할 모델(예: v6 또는 Niji)과 종횡비에 대해 고민해 보세요. 위 예제를 살펴보겠습니다. 이는 영화 스틸 사진이므로 적어도 16:9 종횡비를 사용하고자 합니다.\n\n이것이 결과입니다:\n\n지금 이 이미지는 훌륭하며, ChatGPT 덕분에 프롬프트를 만드는 데 몇 초만 걸렸어요.\n\n## 프롬프트 예시\n\n<div class=\"content-ad\"></div>\n\nChatGPT가 생성한 몇 가지 추가 프롬프트 예제를 살펴보겠습니다. Midjourney v6을 사용하고 있으며 아무것도 포함하지 않기로 결정했습니다.\n\nv6를 사용하고 있고 개인화를 포함하지 않았습니다.\n\n![이미지](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_2.png)\n\n![이미지](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_3.png)\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_4.png)\n\n![이미지](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_5.png)\n\n아래는 ChatGPT에 입력한 내용의 예시입니다:\n\n![이미지](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_6.png)\n\n\n<div class=\"content-ad\"></div>\n\n저는 최소한의 내용만 언급하여 초등부터 화려한 꽃들이 있는 하이테크 생태계에서 슈퍼모델이 나온 잡지 사진에 관심이 있다고 말하기로 결정했어요.\n\nChatGPT는 우리의 대화 초반에 요청 사항과 따라야 할 구조를 명시했음을 기억할 거예요. 그러니 다시 모든 것을 반복할 필요는 없답니다.\n\n또한 제 개인용 궁극의 미드젠 가이드를 만들었어요. 읽는 데 시간이 오래 걸리지만, 50장이 넘는 이미지와 다양한 프롬프트 예시를 포함하고 있으며 정기적으로 업데이트 되고 있어요.\n\n지금은 여기까지입니다 친구들.\n\n<div class=\"content-ad\"></div>\n\nChatGPT를 사용하면 초보자들이 멋진 프롬프트를 만들 수 있어요. Midjourney 프롬프트에 ChatGPT를 사용해 보신 적이 있나요? 💬\n\n저는 개인적으로 ChatGPT를 Midjourney 프롬프트에 사용할까요? 아마도 독립적인 해결책으로서는 사용하지 않을 거예요. 기본 프롬프트를 얻은 후 조명, 카메라, 스타일과 같은 내용을 추가하겠죠. 마지막으로 genAI와 개인화를 조합하면 훌륭한 결과물을 만들 수 있을 거예요.\n\n![이야기 이미지](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_7.png)\n\n이 이야기는 Generative AI에서 발표되었어요. 최신 AI 이야기를 만나고 싶다면 LinkedIn에서 만나세요. Zeniteq를 팔로우하여 최신 소식을 받아보세요.\n\n<div class=\"content-ad\"></div>\n\n우리의 뉴스레터 구독하면 창조적 AI의 최신 뉴스와 업데이트를 받아보실 수 있어요. 함께 AI의 미래를 만들어가요!\n\n![이미지](/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_8.png)","ogImage":{"url":"/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_0.png"},"coverImage":"/assets/img/2024-06-22-IHaveUsedChatGPTToCraftThePerfectMidjourneyPromptHeresHowThisTurnedOut_0.png","tag":["Tech"],"readingTime":4},{"title":"예측 AI의 도래, 당신과 세계는 준비되었는가","description":"","date":"2024-06-22 20:29","slug":"2024-06-22-PredictionAIIsComingAreYouandtheWorldReady","content":"\n\n\n![2024-06-22-PredictionAIIsComingAreYouandtheWorldReady](/assets/img/2024-06-22-PredictionAIIsComingAreYouandtheWorldReady_0.png)\n\n참고: 중간 회원이 아닌 경우 이 링크를 통해 무료로 이야기를 읽으실 수 있습니다. 우리 커뮤니티에 참여하도록 권장합니다!\n\n우리 중 누구나 미래를 곰곰이 생각해보지 않나요? 짧고 긴 시간에 걸쳐 펼쳐지는 삶에 대해 얼마나 자주 생각하나요? 미래의 건강과 수명, 자녀의 성공, 직장에서 열심히 일하는 결과를 궁금해하나요? 이런 깊은 개인적 질문들은 앞으로 무엇이 기다리고 있는지에 대한 우리의 타고난 호기심을 반영합니다.\n\n예측은 인간 존재의 기본이자 중추입니다. 일관된 삶이란 다가오는 것을 예상하는 것을 의미합니다. 삶의 사건들이 펼쳐지는 일련의 단계에서 다음 단계를 어림잡을 수 없다면 미래를 위한 계획을 세울 수 없습니다.\n\n\n<div class=\"content-ad\"></div>\n\n예측은 당신의 순간적인 존재에 중요한 역할을 하기 때문에 미래를 알고 싶어하는 갈증이 있다는 것을 모르실지도 모릅니다. 어떤 사람들은 미래에 대해 다른 사람보다 더 걱정을 하는데, 그 이유는 타당하거나 단지 강박적일 수 있습니다. 그러나 미래에 대한 궁금증은 적어도 우리 모두가 가지고 있는데, 이 안에는 새로운 AI 제품에 대한 거대한 마케팅 기회가 숨어 있습니다.\n\n롤아웃 시기가 불확실하지만 AI 산업은 불가피한 미래로 점점 빠르게 나아가고 있습니다. 만약 오픈소스의 ChatGPT나 구글의 Gemini과 같은 생성적 AI가 인상적으로 느껴진다면, 미래에 대해 정보를 잘 알려주는 봇에 대비하는 것이 좋을 수도 있습니다.\n\n## 생성적 AI vs. 예측 AI\n\n생성적 AI (GenAI)와 예측 AI (PredAI)는 서로 다른 목적을 가지고 다양한 응용 분야에서 사용되는 두 가지 구별되는 인공지능 유형입니다.\n\n<div class=\"content-ad\"></div>\n\n생성적 AI: 깊은 학습에 뿌리를 둔 GenAI는 자연어 처리(NLP)에서 뛰어난 변형 모델을 활용합니다. 이를 통해 GenAI 모델은 모든 입력 세그먼트(인터넷에서 스크래핑된 데이터 등)을 동시에 검토할 수 있습니다. 이러한 대규모 언어 모델은 출력 생성 중 관련 세그먼트를 우선적으로 분석하여 빠른 텍스트 분석을 가능케 합니다.\n\n미리 정의된 규칙이나 패턴에 의존하는 일반적인 AI 시스템과는 달리, GenAI는 \"상상\"하고 명시적으로 프로그래밍되지 않은 텍스트, 이미지, 음악 또는 코드와 같은 창조적이고 매력적인 콘텐츠를 생성합니다.\n\n예측 AI: PredAI는 과거 데이터, 패턴 및 트렌드를 기반으로 미래 결과를 예측하는 데 중점을 둡니다. 이 접근 방식은 머신러닝 알고리즘, 통계 모델 및 데이터 분석을 활용하여 예측과 추천을 수행합니다.\n\nPredAI는 예측 분석을 사용하여 특정 도메인(헬스케어, 시장, 스포츠 등)에서 현재 사건과 과거 데이터를 평가하여 미래 결과에 대한 교육된 추측을 제공합니다. 머신러닝은 방대한 데이터 집합에서 패턴을 구별하여 예측 분석을 보완합니다. 데이터의 관련성과 풍부성이 관심 영역 및 패턴 이력에 더할수록 그들의 예측이 더 정확해집니다.\n\n<div class=\"content-ad\"></div>\n\n## 예측 인공지능이 미래를 위해 개인화될 수 있을까요?\n\n![image](/assets/img/2024-06-22-PredictionAIIsComingAreYouandtheWorldReady_1.png)\n\n당신은 PredAI의 설명에서 볼 수 있듯, 이 모델은 예측 도메인에 대한 수많은 역사적 정보를 필요로 합니다. 만약 당신만의 개인화된 PredAI 버전을 원한다면, 미래에 대해 알려줄 PredAI 모델이 당신에 대한 풍부한 정보를 필요로 할 것입니다.\n\nPredAI는 왜 예측을 위해 이렇게 많은 역사적 정보가 필요할까요? 통계적 확률론의 관점에서 볼 때, 당신은 습관의 피조물이며, 당신의 습관이 미래를 결정할 것입니다. Pred AI는 당신의 일상에 대해 알고 싶어합니다.\n\n<div class=\"content-ad\"></div>\n\n10년 전, 기술 기자이자 미래학자인 패트릭 터커가 \"The Naked Future\" (2014)를 썼어요. 책의 부제가 제 관심을 끌었어요: 미래를 예상하는 세계에서 어떤 일이 일어날까?\n\n터커는 그의 책에서 많은 인지과학자들에게 잘 알려진 아이디어를 상세히 설명해요: 인간 마음은 예측 기계예요. 우리의 본성으로 인해, 우리는 항상 다음 일이 무엇일지 예측하고 있어요.\n\n터커는 우리가 현재를 기반으로 미래를 관리하기 위해 정신적 모델들을 만들어간다고 언급했어요. 우리의 다양한 경험을 고려할 때, 우리 뇌에는 일이 어떻게 작동하는지에 대한 수많은 모델이 저장되어 있어요.\n\n간단한 예를 들어볼게요. 어릴 때, 포크와 숟가락의 다른 용도에 대해 배워요. 그 결과, 당신의 뇌는 각각에 대한 모델을 개발해요. 어른이 되어서는, 생각하지 않고도 손님에게 수프를 서빙할 때 포크 대신 숟가락을 가져가는 모델을 그 모델에 올려놓을 때에 사용하게 될 거예요.\n\n<div class=\"content-ad\"></div>\n\n인간 관계나 정부와 같은 비물리적 측면에 대한 모델도 작성합니다. 수 년간의 우정을 기반으로, 다음 만남에서 당신의 친구에 대한 예상을 나타내는 인식 규칙 집합이 되는 친구 모델을 만듭니다. 우리가 만들어낸 모델은 미래를 예측하는 데 도움이 됩니다. 포크로 수프를 호봉하는 것은 불가능하다고 예측합니다. 당신의 친구가 다음 주에 당신을 만나서 기뻐할 것이라고 예측합니다.\n\n## 당신과 당신의 삶에 맞춤형 예측 AI\n\n두뇌에 저장된 인지 모델은 일상적인 사건에 대한 예측을 돕습니다. 당신은 전문 면허 시험을 위해 열심히 공부하고 있습니다. 모의고사를 보면서 면허 시험에서 무엇을 기대해야 하는지에 대한 인지 모델을 만들었습니다. 당신의 공부 습관을 모의 모델과 일치시켜, 면허 시험에서 잘 볼 것이라고 예측합니다.\n\n그렇다면 선택한 직업에서 어떻게 성과를 내게 될까요? 시간과 에너지적 요구가 많을 것입니다. 상사에게 24시간 7일간의 가용성을 제공할 수 있는 체질적으로 가능할까요? 이 힘든 역할에서 행복을 느낄 수 있을까요?\n\n<div class=\"content-ad\"></div>\n\n귀하는 일상 속에서 벗어난 분야에서 미래를 예측하기 위해 뇌에 자신의 삶에 대한 더 많은 정보를 저장해야 합니다. 인간 뇌는 모든 살아있는 생물 중에서 가장 뛰어난 기능을 갖고 있지만, 까먹는 등의 한계가 있습니다. 과거에서 고등학교 육상팀에서 탈락한 이유를 너무 바빠서 개인 시간이 부족했다고 잊어버리는 등, 귀하는 개인 시간을 경쟁보다 더 중요시하는 것을 보여주는 사실이 있습니다.\n\n개인 시간이 없는 직장에서 잘 할 수 있을까요?\n\n과거 경험이 미래 경험과 밀접하게 관련이 있습니다. 하지만 만약 지난 경험에 대한 모든 정보를 포착하는 마법같은 존재가 있다면 어떨까요? \"역사적인 나\"에 대한 데이터가 \"미래의 나\"를 예측하는 데 이용된다면 어떨까요?\n\n당신에 대해 모든 정보를 알고 미래를 예측하는 누군가의 생각은 흥미롭거나 두려울 수 있지만, 걱정하지 마십시오. 이미 그런 일이 벌어지고 있습니다. 미래에 대한 귀하의 관심은 산업 리더들이 Prediction AI의 개인화된 모델을 가능한 빨리 제공할 수 있도록 동기를 부여합니다.\n\n<div class=\"content-ad\"></div>\n\n## 코펜하겐 인구 기반 예측 AI 모델\n\n![이미지](/assets/img/2024-06-22-PredictionAIIsComingAreYouandtheWorldReady_2.png)\n\n덴마크 코펜하겐의 한 연구팀은 방대한 개인 정보 데이터베이스를 기반으로 한 흥미로운 실험적 예측 모델을 개발했습니다.\n\n코펜하겐 팀은 새로운 논리(\"당신의 삶은 문장과 같다\")를 사용하여 상세한 사건 시퀀스를 기반으로 인간의 삶의 진화와 예측 가능성을 조사했습니다. 이 논리는 삶을 비유적인 문장으로 사용합니다. 예를 들어, 문장에 포함된 단어가 많을수록 어떻게 끝나는지 알 수 있을 가능성이 높습니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, \"나는...\"라고 시작하면 문장의 끝이 다양할 수 있다는 것을 시사합니다. 반면에 \"나는 ... 할 것이다\"라고 시작하면 가능한 후보가 좀 더 좁아집니다. 만약 어떤 엔티티가 당신의 일상을 알고 있다면(금요일이며 주말에 특정 장소를 자주 방문하는 경우), 그 엔티티는 당신의 미래를 \"나는 ... Jake's Bar에 친구들을 만나러 퇴근 후에 갈 것이다\"로 예측할 수 있습니다. 이런 식으로 당신의 삶은 더 많은 정보를 통해 더 예측 가능하게 됩니다.\n\n분명히, PredAI가 당신에 대해 알면 알수록 더 나은 예측을 할 수 있습니다. 이 전제가 코펜하겐 팀이 덴마크 국립 레지스트리로부터 독특하고 포괄적인 데이터셋에 액세스하는 계기가 되었습니다. 이 데이터셋은 약 10년 동안 약 600만 명의 덴마크 시민들에 대한 상세한 일일 생활 기록을 포함하고 있었습니다.\n\n이 국립 레지스트리에서 연구자들은 덴마크 시민들의 건강, 교육, 직업, 소득, 주소, 근무 시간과 관련된 정보를 수집했는데, 이 정보들은 일일 해상도로 기록되었습니다. 이 데이터셋을 사용하여 교대어 모델에서 인간의 삶을 언어로 표현된 문장과 유사한 사건의 연속으로 표현할 수 있다는 것을 연구자들은 입증했습니다. 이러한 연속은 일찍 사망부터 성격의 미묘함까지 다양한 결과를 예측하는 데 사용될 수 있습니다.\n\n이 연구가 당신에게 오싹한 느낌을 준다면? Patrick Tucker의 책 제목 \"당신의 모든 움직임을 예견하는 세상에서 무슨 일이 벌어질까\"를 고려해보세요. 덴마크에 거주하고 계시다면, 국립 레지스트리가 당신의 모든 움직임을 기록했을 것입니다. 윤리적 및 개인정보 보호 제약 내에서, 그 데이터셋은 코펜하겐 팀이 개인화된 인구 기반 예측 AI 모델을 생성하는 데 활용되었습니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 이 모델의 장단점을 평가하기 전에, 우리는 먼저 그 핵심 작동 원리를 살펴보겠습니다.\n\n## 코펜하겐 모델의 기능\n\n연구자들은 그들의 인공지능 모델이 수행하는 세 가지 \"예측 작업\"을 강조했는데, 이를 'life2vec'이란 색다른 이름으로 부여했습니다. (제 생각에 이것은 '인생에서 벡터로'의 약칭인데, 이는 또한 '인생에서 스냅샷으로'를 의미합니다.)\n\n1. 사망 예측: 생애 사건의 연속을 분석함으로써, 이 모델은 특정 시간대 내 조기 사망 가능성을 예측할 수 있습니다. 이것은 특정 사건 순서가 조기 사망 위험과 연관된 패턴을 학습함으로써 수행됩니다. 예를 들어, 여러 가지 부정적인 건강 관련 사건을 포함한 일련의 사건은 더 높은 위험을 나타낼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n2. 성격 뉘앙스 예측: 이 모델은 인간의 삶에 대한 더 세밀한 측면, 예를 들어 성격 특성까지 예측합니다. 이는 삶의 사건 순서와 자가 보고된 성격 설문 조사 응답 사이의 연관성을 학습하여 가능해집니다. 예를 들어, 빈번한 사회적 상호작용이 외향적인 성격 특성과 연관될 수 있습니다.\n\n3. 개인 요약: 건강 기록, 교육적 이정표, 직업 진로 등을 포함한 사람의 삶의 다양한 사건을 파헤쳐 Life2Vec는 이 정보를 \"개인 요약\"으로 추려내어 특정 인물의 삶의 여정의 본질을 잡아낸 콤팩트하고 포괄적인 스냅샷(벡터)으로 변환합니다.\n\n이 개인 요약 기능을 더 자세히 살펴보겠습니다.\n\n당신이 삶에 대한 세부적인 일지를 기록하여 건강 점검이나 직장 변경부터 중요한 이정표와 금전적 결정까지 모든 중요한 사건을 기록했다고 상상해보세요. 이제 Life2Vec 앱에 가입하여 당신의 일기를 읽고 알고 있는 모든 것을 한눈에 이해하기 쉬운 스냅샷으로 요약하는 기능이 있는 상황을 상상해봅니다. 이 스냅샷은 당신 이야기의 본질을 잡아내는 특별한 코드와 같습니다. 해당 앱은 개인 요약 공간에서 당신을 위한 \"벡터\"를 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n생활 벡이 미래에 대해 추측할 때, 예를 들어 건강이나 가질 수 있는 직업과 같은 것에 대해 본인에 대한 데이터가 이 특징 벡터(스냅샷)를 통해 분석됩니다. 당신의 나이, 자신을 얼마나 잘 돌보고 있는지, 수입 등과 같은 명백한 사항뿐만 아니라, 현재 수행하고 있는 직업의 종류와 이로 인한 미래 영향과 같은 미묘한 세부 사항들에도 주목합니다.\n\n미래에 대해 알고 싶은 것에 따라, 개인적인 세부 사항(스냅샷)이 조정되어 어느 특정 분야의 앞으로 벌어질 일에 대한 다양한 질문에 대한 가장 정확한 예측을 제공하게 됩니다.\n\n예를 들어, life2vec은 직업 선택이 미래의 건강에 어떤 영향을 미칠 수 있는지를 도와줄 수 있습니다. 이러한 통찰력은 새로운 질문을 불러일으키며, 이전에 생각하지 못했던 영역을 탐구하도록 이끌어주어, 당신이 미래에 대한 이 AI 예측에 대한 '왜'를 이해하도록 돕습니다.\n\n개인적인 예측뿐만 아니라, life2vec의 세 가지 예측 작업(사망률, 성격 세부 사항, 개요)은 어디에 사시는지, 교육 수준, 연령대, 정치적 소속 등과 같은 것을 기반으로 당신을 위한 미래 시나리오를 제시할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 예측 AI의 위험성\n\n![예측 AI 이미지](/assets/img/2024-06-22-PredictionAIIsComingAreYouandtheWorldReady_3.png)\n\n개인 AI 어시스턴트가 미래 행동의 예상 결과에 대한 결정을 돕는 한, 이 혜택의 대가는 당신에 대해 알아야 할 모든 것을 아는 AI 엔티티입니다. 자신에 대해 말하는 것이 많을수록 그 혜택은 커집니다.\n\n예측 AI의 힘에 대해 읽으면서, 당신은 아마도 여러분의 디지턜 히스토리와 관련된 위험 목록을 직접 작성할 수 있을 것입니다. 여기에 제가 작성한 목록이 있습니다:\n\n<div class=\"content-ad\"></div>\n\n예측 모델 소유권: 북유럽 지역 국가들과 일부 국가들만이 포괄적이고 규제된 시민 등록 시스템을 갖추고 있지만, 다른 국가들은 그렇지 않습니다. 만약 인구 기반 예측 AI가 확대된다면, 당신의 인생 사건에 대한 정보를 보관할 주체가 누가 될지에 대한 의문이 제기됩니다. 억만장자가 소유한 사립 기업이 이 정보를 신뢰할만 할까요? 당신은 정부에게 이 정보를 신뢰할 수 있을까요?\n\n개인정보 보호 및 윤리적 우려: 개인이나 인구 예측을 위해 상세한 개인 데이터를 사용하는 것은 동의, 데이터 보호 및 민감한 정보 남용 가능성 등에 대한 중요한 개인정보 보호 및 윤리적 문제를 도출합니다.\n\n편향성과 공정성: 생성 모델 AI는 \"환각\"을 일으키며 가짜 정보를 만들어내는 것으로 알려져 있습니다. 예측 AI 예측은 역사 데이터셋에 내재된 편향으로 영향을 받을 수 있으며, 부정확하거나 잘못된 미래 시나리오로 이어질 수 있습니다. 이는 분명히 나쁜 계획을 유도하거나 잘못된 조언에 기반한 잠재적으로 재앙을 초래할 수 있습니다.\n\n예측 모델에 대한 과대 의존: 미래에 대한 다른 사람보다 많은 확신이 필요한 사람들이 있습니다. 불확실성으로 치닫는 사람의 욕구는 PredAI의 복잡성과 인간 건강의 다층적 한계를 고려하지 않고 결정적인 건강 결정을 위해 이러한 모델에 지나치게 의존하는 위험을 초래할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 한 번 도착하면, 예측 AI는 사라지지 않을 것입니다\n\n예측 AI는 현재 많은 산업에서 활발히 사용되고 있으며 더욱 보급화될 것입니다. 의료 분야에서는 예측 AI와 생성 AI가 질병의 초기 검출 및 진단의 핵심 구성 요소로 자리잡을 것으로 예상되며, 개인 맞춤형 치료 계획의 작성 및 질병 진행의 예측 분석을 통해 환자 안전성, 효율성 및 비용 절감을 향상시킬 수 있습니다.\n\n## 이제 내가 미래를 예측할 차례입니다\n\n![이미지](/assets/img/2024-06-22-PredictionAIIsComingAreYouandtheWorldReady_4.png)\n\n<div class=\"content-ad\"></div>\n\n생성적 AI는 사람이나 기계가 예측하기 힘든 속도로 확산되었습니다. GenAI는 이제 거의 모든 개인의 삶과 대부분의 산업에 보급되어 있습니다. 18개월 전에 나는 유럽 휴가를 계획하기 위해 AI 봇을 사용할 줄이야!\n\n예측 AI도 동일한 미래를 예측할까요? GenAI와 마찬가지로, PredAI는 큰 데이터를 필요로 합니다. 그러나 PredAI는 예측을 위한 패턴을 수립하기 위해 역사적이고 추세 데이터가 필요합니다. 개인 역사에 대해서는 코펜하겐 모델을 만드는 데 사용된 국가 기록이 마련되어 있는 몇몇 국가밖에 없습니다.\n\n이전의 일상적인 생활에 대한 모든 세부 정보를 수집하도록 이익 중심의 대형 기술 기업에 허용하지 않는다면, PredAI 산업은 필요한 깊이와 폭의 개인 중심 데이터에 대한 접근 권한이 부족할 수 있습니다.\n\nPredAI가 우리의 삶에 점차적으로 침투할 가능성이 더 높습니다. 예를 들어, 의료 계획은 의료 기록을 추적하며 필요에 따라 시스템 내 전문가들과 공유됩니다. PredAI 모델은 최근 진단의 변화 추이를 예측하는 데 도움이 될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n정확도 AI의 성장은 결국 우리가 얼마나 많은 정보를 제공하는지에 달려 있을 수 있어요. 천사인지 악마인지, 맞춤형 PredAI는 필요한 영양소를 제공받으면 성장할 거예요 - 당신의 삶의 역사.\n\nPredAI의 미래를 준비하기 위한 최상의 조언은 무엇일까요? 경험 많은 카우보이들이 첫 번째 힘든 라이딩을 할 준비를 하는 로데오 초보자들에게 하는 말처럼 \"그 불을 알고 발길 준비를 하세요!\"","ogImage":{"url":"/assets/img/2024-06-22-PredictionAIIsComingAreYouandtheWorldReady_0.png"},"coverImage":"/assets/img/2024-06-22-PredictionAIIsComingAreYouandtheWorldReady_0.png","tag":["Tech"],"readingTime":9}],"page":"28","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}