{"pageProps":{"posts":[{"title":"이전에 사용하던 라즈베리 파이를 디지털 포토 프레임으로 재활용하기","description":"","date":"2024-06-19 06:10","slug":"2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe","content":"\n\n라즈베리 파이 프로젝트에 관한 몇 가지 이야기를 게시했어요. \"SaaS prepper\" 프로젝트 두 가지가 있어요: 하나는 플리커용이고, 다른 하나는 에버노트용이야. 그리고 후에는 휴 조명 자동화와 그에 대한 규칙 언어 추가도 있었어요. 모두 빌트인 와이파이가 있는 최신 모델 Pi에서 작동해.\n\n와이파이가 없는 구형 3 Pi 모델이 두 대 있어. 예전에 여러 프로젝트에 사용했지만 오랫동안 서랍 속에 방치되어 있었어. 정말 안쓰러워서, 저렴한 오프라인 프로젝트를 찾고 있었어.\n\n우리 둘째딸과 맏내아들은 매우 다른 관심사를 가지고 있어서, 각각에게 오프라인 사진액자를 만들어주면 방에 디지턈 장식물로서 멋진 효과를 줄 수 있을 것 같았어. 전체화면으로 슬라이드쇼를 열어서 디렉토리 안의 사진들을 랜덤하게 보여주면 될 거야. 9세 아들을 위한 것은 그의 고양이 사진, 예술품 스캔, 그리고 괴로운 미미들이겠지. 15세 딸을 위한 것은 앨범 커버, 영화 포스터, TikTok에서 찍은 포즈 사진, 가끔 친구들과 함께 한 인스타 셀카가 있겠지.\n\n돈을 많이 쓰기 싫었고, 프레임으로 사용하기에 적합한 상태의 중고 모니터가 많을 거라 생각했어. 디지털 입력이 있는 17\"~21\" 크기쯤의 뭔가를 찾을 수 있다면, 꽤 좋은 프레임이 될 것 같았어.\n\n<div class=\"content-ad\"></div>\n\n# 파이 준비하기\n\n가장 저렴한 클래스 10 Micro SD 카드를 구했습니다. 클래스 10보다 느린 것은 라즈베리 파이 운영체제를 실행하는 데 잘 작동하지 않습니다. 뉴질랜드에 PB Tech 라는 지역 컴퓨팅 및 전자 제품 소매업자가 있습니다. 그들은 때로는 가격 조작을 당한다는 비판을 받기도 하지만, 나는 그들을 항상 최고로 생각했습니다. 그들의 물류는 훌륭하고 문제가 발생하면 반품 및 교환에 매우 도움이 됩니다. 더 좋은 점은 \"PB\"가 \"팻 & 브렌다\"를 의미한다는 것입니다 - 그 창립 부부입니다. 그것만으로 충분히 충성심을 가질만한 이유입니다.\n\n![이미지](/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_0.png)\n\nNZD $6.78은 USD $4.25 정도입니다 - 그 정도로 돈이 많이 나가지는 않겠네요. 요즘에는 32GB가 적당한 크기인 것 같습니다. 저는 최대 12GB 정도만 필요하지만, 그보다 더 많은 용량이 있다면 GB 당 가격이 더 비싸질 것 같네요!\n\n<div class=\"content-ad\"></div>\n\n오피셜 라즈베리 파이 OS 사이트의 올인원 유틸리티는 요즘 정말 멋지네요. 이미지 파일을 다운로드하고 dd 구문을 뒤적일 필요 없이 모든 작업을 대신 해줍니다. 저는 최신 라즈베리 파이 OS 풀 데스크탑 버전으로 SD 카드를 플래싱했어요.\n\n# 모니터 찾기\n\n뉴질랜드에서 중고로 사고 파는 특이한 점은 우리만의 국내 플랫폼이 있다는 거예요. 예전에 이민 진입 가능성에 대해 이베이가 사용한 메트릭이 무엇이었든, 그들은 우리를 방치했죠. 그 때문에 우리에게 생겨난 건 TradeMe이라는 자체적인 경매 플랫폼인데, 2003년부터 사용해왔어요.\n\n제 집에서 차로 5분 거리 내의 리스트를 지켜보고 낮은 입찰을 넣은 후 1주일 정도 지켜보다가 어떤 경매에서 낙찰했어요:\n\n<div class=\"content-ad\"></div>\n\n\n![Up-cycling an old Raspberry Pi into a digital photo frame](/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_1.png)\n\n$11.50 NZD is approximately $7.20 USD. The resolution is adequate and it has a DVI input. My 9-year-old couldn't believe that such a budget-friendly purchase was possible!\n\n## A few more bits and pieces\n\nRaspberry Pis have an HDMI output, so I needed to convert that into the DVI format. Fortunately, I already had a 0.5m male-to-male HDMI cable that came with electronic items in a drawer. I only needed to buy an adapter to convert it to a female DVI-D.\n\n\n<div class=\"content-ad\"></div>\n\n![Up-cycling an old Raspberry Pi into a digital photo frame](/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_2.png)\n\nPB Tech가 다시 도와주었습니다. 32GB 마이크로 SD나 전자 모니터보다는 비싸지만 여전히 꽤 합리적인 가격입니다.\n\n물론 Pi에는 전원이 필요합니다. 뒷면에 USB에 최소 1.5암페어를 가진 모니터를 찾았지만, 이런 기능이 없는 거였다. Pi의 전원 공급은 약간 까다로울 수 있습니다. 전체 성능을 발휘하려면 공식 전원 공급이 정말 좋습니다. 이 가격은 합리적이지만, 마이크로 USB 플러그가 달린 구형 제품은 수급이 부족합니다 (새로운 모델은 USB-C를 사용합니다).\n\n아래 충전기는 이용하기 거의 완벽합니다. 대부분의 경우 잘 작동하지만 Pi가 무언가 I/O 또는 CPU 집약적인 작업을 수행해야 할 때 전압 경고가 발생하여 성능이 제한됩니다. 그래도 내 목적에는 괜찮다고 생각했습니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 Markdown 형식으로 변환해 보겠습니다.\n\n\n![Image 1](/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_3.png)\n\n그리고... $6.54 NZD: SD 카드보다 심지어 더 싸요.\n\n마지막 항목은 USB-A에서 USB-micro로 변환하는 것이었어요: $3.82. 제 서랍에 다 떨어져 있었던데요 — 이제는 USB-C 세상이에요.\n\n![Image 2](/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n# 슬라이드 쇼 설정\n\nPi OS는 기본적으로 십 분 후에 화면을 꺼버립니다. 이 기능을 비활성화하려면 raspi-config의 \"Display Options\"에서 설정할 수 있습니다.\n\n빠른 구글링 결과, Linux 및 Pi 슬라이드 쇼에는 FEH가 필수적이라고 합니다. 기본 Apt 저장소에 있으므로 sudo apt-get install feh을 실행하여 Pi에 FEH를 추가했습니다.\n\n32GB SD 카드로 공간이 많이 남아 있어 Pi에 SSH를 활성화하고 라우터의 네트워크 소켓에 연결하여 큰 양의 사진을 scp로 전송했습니다.\n\n<div class=\"content-ad\"></div>\n\nFEH 문서가 너무 최신이 아니라서 찾는 데 시간이 좀 걸렸어요. 제 요구 사항에 맞는 명령어를 찾는 데 조금 더 구글링을 해야 했어요. 다음과 같은 명령어를 사용했어요:\n\n```js\nDISPLAY=:0.0 feh --randomize --full-screen --slideshow-delay 30 --auto-rotate /home/pi/images\n```\n\n이 명령어는 다음을 제공해줘요:\n- X Windows의 첫 번째, 기본 가상 데스크톱\n- 디렉토리에서 랜덤 사진 선택\n- 전체 화면\n- 각 사진 변경 사이의 30초\n- 사진이 EXIF 태그에 포함된 방향에 따라 자동으로 회전됨 (기본적으로 그렇게 설정되어야겠죠!)\n- 기본 사용자의 홈 디렉토리의 \"images\" 디렉토리에서 읽기\n\n<div class=\"content-ad\"></div>\n\n지금 작동 중인 슬라이드 쇼가 있으나 작업을 끝내고 네트워크에서 연결을 해제하고 그 일을 맡길 수 있도록 하기 전에 할 일이 몇 가지 더 남았어요.\n\n# 부팅 시 자동 시작\n\n키보드가 연결되지 않은 상태에서 사진 프레임이 작동해야 했기 때문에 OS가 부팅될 때 바로 슬라이드 쇼가 실행되어야 했어요. rc.local을 사용하는 것에 대한 제안을 보았지만, 그 스크립트가 X가 실제로 업 및 완전히 사용 가능해지기 전에 실행될 수 있기 때문에 매우 신뢰할 수 없다는 점을 알았어요. 따라서 Pi 데스크톱 관리자인 LXDE에 내장된 \"자동 시작\" 기능을 사용하기로 했어요.\n\n/home/pi/runshow.sh에 셸 스크립트의 명령어를 넣고 이와 함께 .config/autostart/photos 경로에 이 텍스트 파일을 만들었어요:\n\n<div class=\"content-ad\"></div>\n\n```js\n[Desktop Entry]\nType=Application\nName=Slide show\nExec=/usr/bin/bash /home/pi/runshow.sh\n```\n\nLXDE가 X가 실행되었을 때 이를 읽고 명령을 실행합니다. 좋아요.\n\n# 마우스 커서 숨기기\n\n마우스가 없더라도 LXDE의 기본 동작은 화면 가운데에 마우스 포인터를 표시하는 것입니다. 짜증나죠.\n\n<div class=\"content-ad\"></div>\n\n다행히도, 이와 같은 거북한 상황을 다루는 기능이 기본 Apt 저장소에도 있습니다. 해당 튜토리얼에서 자세한 내용을 확인할 수 있지만, 제 간략한 버전은:\n\n```js\nsudo apt-get install unclutter\nmkdir -p ~/.config/lxsession/LXDE-pi\necho \"@unclutter -idle 0\" > ~/.config/lxsession/LXDE-pi/autostart\n```\n\n# 데스크톱에서 저전압 경고 비활성화\n\n제 성능이 약간 떨어지지만 매우 검소한 전원 공급 구매를 기억하시나요?\n\n<div class=\"content-ad\"></div>\n\n전압이 떨어질 때마다 화면 오른쪽 상단에 \"토스트\"가 나타나 경고로 팝업됩니다. 짜증나죠.\n\n다행히도, 이 경고는 전용 Apt 패키지에서 제공됩니다. 이것을 제거하면 그런 일이 일어나지 않습니다: sudo apt remove lxplug-ptbatt\n\n# 모두 끝났습니다\n\n이렇게 해서 50뉴질랜드 달러 미만으로 빈번하게 사용하지 않는 Pi를 재활용한 독립적인 사진 프레임을 만들었습니다!\n\n<div class=\"content-ad\"></div>\n\n그 행복한 고양이를 보세요...\n\n![행복한 고양이](/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_5.png)","ogImage":{"url":"/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_0.png"},"coverImage":"/assets/img/2024-06-19-Up-cyclinganoldRaspberryPiintoadigitalphotoframe_0.png","tag":["Tech"],"readingTime":6},{"title":"라즈베리 파이 홀딩스 작지만 큰 영향력을 지닌 장치","description":"","date":"2024-06-19 06:09","slug":"2024-06-19-RaspberryPiHoldingsASmallDevicewithaBigImpact","content":"\n\n\n![Raspberry Pi](/assets/img/2024-06-19-RaspberryPiHoldingsASmallDevicewithaBigImpact_0.png)\n\n기술 세계에서 혁신은 성공의 열쇠이며, Raspberry Pi Holdings는 이 분야의 마스터임을 입증했습니다. 컴퓨터 과학자 에벤 업톤이 2008년에 설립한 Raspberry Pi는 학교와 개발도상국에서 기초 컴퓨터 과학 교육을 촉진하기 위한 작은 프로젝트로 시작했습니다. 겸손한 시작에서 회사는 지수적으로 성장하여 최근 런던 증권 거래소에서 성공적인 기업공개를 선보였습니다.\n\n소매 투자자들이 주식을 거래하기 시작함에 따라 Raspberry Pi 주가는 상당한 폭으로 상승하며, 회사의 인기와 제품에 대한 높은 수요를 반영했습니다. 이 회사의 IPO는 1억 6600만 파운드 또는 2억 2800만 달러를 모아내며, 투자자들은 회사의 보통 주식의 30.7%를 사들였으며, 결제 가능한 과잉 배분 조항 하에 추가로 2.3%를 구입할 수 있는 옵션을 획득했습니다. 주가는 IPO 당일 14% 상승하여 계속 상승세를 이어가고 있습니다. 이 상승은 회사의 강력한 재정 성과, 혁신적인 제품 라인, 그리고 165억 파운드에 이르는 산업, 내장, 애호가, 교육용 컴퓨팅 시장에서의 성장 잠재력과 관련이 있습니다.\n\n60만 대 이상이 판매된 Raspberry Pi 컴퓨터는 회사의 기술에 대한 혁신적인 접근을 증명하는 것입니다. 이 소형 컴퓨터는 취미가 있는 사람, 교사 및 전문가들에게 다양한 프로젝트에 대한 다목적 플랫폼을 제공하여 교육용 도구부터 복잡한 인터넷 연결 장치까지 다양한 분야에서 활용되고 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n라즈베리 파이 재단인 회사의 자선 단체는 교육과 지원에서 중요한 역할을 합니다. 수백 가지의 무료 코딩 및 컴퓨팅 프로젝트를 제공하며, 다양한 경험 수준에 맞는 지침을 제공하고 여러 언어로 자료를 제공합니다. 이 재단은 원격 수업을 통해 교사를 지원하고, 자원봉사자가 가상 코딩 클럽을 운영하도록 돕고, 집에 컴퓨터가 없는 어린이들에게 컴퓨터를 제공하는 데 힘씁니다. 이러한 노력을 통해 라즈베리 파이 재단은 전 세계 사람들에게 컴퓨팅과 디지털 제작의 힘을 전달하는 미션을 성취하고 있습니다.\n\n소규모 프로젝트에서 공개 회사로의 여정을 거쳐 라즈베리 파이 홀딩스는 성공의 놀라운 이야기입니다. 최근의 증권상장과 이어지는 주가 상승은 회사의 잠재력과 투자자들이 그 미션에 대한 신뢰를 명백히 보여줍니다. 라즈베리 파이가 혁신을 지속하고 영향력을 확대하는 동안, 이 회사는 분명히 컴퓨팅의 미래를 선도하는 중요한 역할을 할 것입니다.","ogImage":{"url":"/assets/img/2024-06-19-RaspberryPiHoldingsASmallDevicewithaBigImpact_0.png"},"coverImage":"/assets/img/2024-06-19-RaspberryPiHoldingsASmallDevicewithaBigImpact_0.png","tag":["Tech"],"readingTime":2},{"title":"물감을 만들어보세요","description":"","date":"2024-06-19 06:08","slug":"2024-06-19-MakeYourOwnWatercolorPaint","content":"\n\n## DIY / ART\n\n![Image](/assets/img/2024-06-19-MakeYourOwnWatercolorPaint_0.png)\n\n# 레시피를 찾고 있어요\n\n몇 년 전에 이츠리에서 수제 수채화물감을 사서, 수채화 물감 레시피에 대해 연구해 왔어요. 그 수채화 물감 중 일부가 아직도 있고 그것을 아주 좋아해요.\n\n<div class=\"content-ad\"></div>\n\n제 궁금증은 항상 일어납니다. 무언가를 사는 대신에 직접 만들 수도 있다는 것을 깨달을 때 말이죠. 항상 성공하는 것은 아니지만, 시도하는 것이 재미 있어요.\n\n이 레시피는 시간을 들여 시도해 본 몇 가지 다른 레시피를 혼합한 것이고, 클로브 오일과 물 같은 제 개인적인 추가물도 포함되어 있어요.\n\n양을 약간 바꾸기도 했어요. 제가 찾은 대부분의 레시피보다 비술을 꽤 더 넣어요. 더 높은 농도로 모든 것을 더 잘 결합시킨다고 생각하기 때문이에요. 너무 많은 올리고당이 페인트를 끈적거리게 만들까 걱정했지만, 그렇지 않아요. 그림이 종이 위에 완전히 말랐어요.\n\n이 기사의 제목 이미지는 아래 DIY 수채화 페인트 레시피를 사용한 두 가지 예시를 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n하루 마무리할 때, 이 레시피는 절대적인 것이 아닙니다. 여러분의 변형은 나열된 재료들 중 어느 것이든 더 많거나 더 적게 필요할 수 있습니다. 자유롭게 시도해보세요. 무엇이 잘 작용하는지 확인해보세요.\n\n# 페인트 만들기\n\n재료:\n\n- 식용색소\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n<div class=\"content-ad\"></div>\n\n1큰술 물\n\n추가:\n\n위의 섞인 재료 1큰술 당 ½ 작은술의 경미한 옥수수 시럽 - 4.5 작은술\n\n재료를 섞는 방법:\n\n<div class=\"content-ad\"></div>\n\n베이킹 소다를 그릇에 넣고 식초를 추가하세요. 이 작업은 과학 실험처럼 거품이 일어날 거에요, 그러니 거품이 잘 포옹될 수 있도록 충분히 큰 그릇을 사용해 주세요.\n\n저어주세요.\n\n물과 크로브 오일을 추가하세요.\n\n저어주세요.\n\n<div class=\"content-ad\"></div>\n\n옥수수 전분을 넣어주세요.\n\n지속적으로 저어주세요.\n\n용기에 따라 붓습니다. 저는 달러 스토어에서 구입한 1 TBS 크기의 작은 용기를 사용했지만, 알약 정리함을 사용해도 됩니다.\n\n믹스 1 TBS 당 식품 염색약을 최소 2방울씩 넣어주세요. 그러나 선택은 여러분의 몫이에요. 더 많은 식품 염색약을 추가하면 더 짙은 색조를 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n젤 식용색소도 괜찮아요. 케이크 데코용 젤을 시도해봤는데 잘 작동하지 않았어요. 저는 액체 식용색소를 선호해요.\n\n참고: 이 작업은 두 날이 걸려요.\n\n물, 옥수수 시럽, 식용색소는 위로 떠오르고, 베이킹 소다와 옥수수 전분은 가라앉아요.\n\n![이미지](/assets/img/2024-06-19-MakeYourOwnWatercolorPaint_1.png)\n\n<div class=\"content-ad\"></div>\n\n미물을 몇 시간마다 섞어주어야 할 거에요 - 하루에 세 번정도인 거 같아요.\n\n둘째 날에는 내가 그림에 사용할 페인트를 팔레트 트레이에 붓고 하루를 더 말려놓았어요. 그랬더니 딱딱한 케이크 모양으로 말려있었답니다. 이 작은 페인트 팔레트 트레이들을 달러 상점에서 구했어요.\n\n## 동영상\n\n이 동영상을 만들어서 페인트 만드는 모습을 시청하고 싶다면 보세요.\n\n<div class=\"content-ad\"></div>\n\n# 그림칠 시간\n\n페인트를 사용하려면 물로 재수분화하고, 팬에 담긴 수채화 페인트를 사용하는 것처럼 사용하십시오.\n\n이 페인트의 유통 기한을 모르겠지만, 세기오일을 추가하고 서늘하고 건조한 곳에 보관한다면 몇 달 동안 좋을 것 같습니다.\n\n이를 시도해 보거나 다른 집에서 만든 페인트 레시피를 시도해 본 적이 있다면 알고 싶습니다.\n\n<div class=\"content-ad\"></div>\n\n## 팁:\n\n음식색을 섞는 데 사용할 수 있는 색상이 제한적이라면, 서로 다른 색조를 섞어 보세요. 예를 들어, 노랑과 빨강을 섞어 주황색을 만들 수 있습니다.\n\n또는 이미 섞인 초록색 페인트에 노랑 음식색을 추가하여 다른 색조의 초록을 만들 수도 있어요. 이해가 되시나요? 궁금하신 점이 있다면 댓글로 글을 남겨 주세요.\n\n# 온라인에서 저에게 방문해주세요:\n\n<div class=\"content-ad\"></div>\n\n유튜브 | 에츠이 | 웹사이트 | 티퍼블릭","ogImage":{"url":"/assets/img/2024-06-19-MakeYourOwnWatercolorPaint_0.png"},"coverImage":"/assets/img/2024-06-19-MakeYourOwnWatercolorPaint_0.png","tag":["Tech"],"readingTime":3},{"title":"달콤한 증말 커뮤니티","description":"","date":"2024-06-19 06:07","slug":"2024-06-19-DolceFavorCrate","content":"\n\n🔍 지금 Dolce Favor Crate를 확인해보세요! 📁 생일 3D SVG 공예를 둘러보고 여기서 🆓 무료 다운로드를 받으세요. 함께 크래프팅을 시작해봐요! 🚀\n\n이 품질 높은 SVG 템플릿은 마종 그레고리아에 의해 만들어졌어요. 소중한 사람에게 얼마나 신경쓰는지 보여줄 수 있는 완벽한 방법을 찾고 계신가요? 달체 페이버 크레이트를 확인해보세요! 이 크레이트는 어떤 행사에도 아름다운 종이 선물을 만들 수 있는 모든 것으로 가득한데요. 저희 SVG 템플릿을 사용하면 쉽게 모든 요소를 만들 수 있어요: — 종이 크레이트 — 테디 베어 — 샴페인 상자 — 미니 장미 식물 — 컵케이크 선물 상자 그리고 비디오 튜토리얼 링크로, 이 프로젝트들을 만드는 방법을 더욱 쉽게 배울 수 있어요. 이 파일들은 Silhouette Studio, Cricut Design Space, 그리고 이러한 파일 유형을 사용하는 다른 커팅 소프트웨어에서 사용하도록 설계되었어요. 이 디자인은 SVG 형식으로 제공됩니다. 그럼 무엇을 기다리고 계신가요? 지금 당신의 Dolce Favor Crate를 주문하세요!\n\n![Dolce Favor Crate 이미지 0](/assets/img/2024-06-19-DolceFavorCrate_0.png)\n\n![Dolce Favor Crate 이미지 1](/assets/img/2024-06-19-DolceFavorCrate_1.png)\n\n<div class=\"content-ad\"></div>\n\n\n![Image 1](/assets/img/2024-06-19-DolceFavorCrate_2.png)\n\n![Image 2](/assets/img/2024-06-19-DolceFavorCrate_3.png)\n\n![Image 3](/assets/img/2024-06-19-DolceFavorCrate_4.png)\n\nPhoto by 3D SVG Crafts on Creative Fabrica\n\n\n<div class=\"content-ad\"></div>\n\n면책 공지: 본 문서에는 제휴 링크가 포함되어 있습니다. 이는 해당 링크를 통해 구매를 하실 경우 추가 비용 없이 수수료를 받을 수 있음을 의미합니다.","ogImage":{"url":"/assets/img/2024-06-19-DolceFavorCrate_0.png"},"coverImage":"/assets/img/2024-06-19-DolceFavorCrate_0.png","tag":["Tech"],"readingTime":2},{"title":"Raspberry Pi 5 비디오 스트림 지연 시간 비교 UDP, TCP, RTSP, 그리고 WebRTC","description":"","date":"2024-06-19 06:05","slug":"2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC","content":"\n\n라즈베리 파이 5를 위한 최적의 라이브 스트리밍 옵션을 발견해보세요. 비디오 라이브 스트림 지연 시간을 테스트하고 목록 중에서 최고를 선택하겠습니다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_0.png)\n\n라즈베리 파이와 관련된 많은 프로젝트는 \"눈\", 다시 말해 카메라가 필요합니다. 로봇이나 원격 제어 자동차와 같은 것을 조종하기 위해서죠.\n\n본문에서는 비디오 라이브 스트리밍의 지연 시간을 테스트할 것입니다. 궁극적으로, 우리는 200ms 정도의 지연을 가진 솔루션을 갖게 될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n비디오 형식의 기사를 실시간으로 시청하는 것이 더 좋습니다:\n\n왜 영상 스트림의 레이턴시가 중요한가요?\n\n물론, 그것은 작업에 따라 다릅니다. 창문 밖에있는 새를 녹음한다면 레이턴시는 중요하지 않습니다. 아니면 아름다운 폭포 영상을 시청할 때도요.\n\n그러나 FPV 드론 조종, 레이싱 카, 또는 원격 제어 박싱 로봇을 조정할 때 레이턴시는 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사는 각 프로토콜이 작동하는 방식이나 이러한 지연이 왜 발생하는지에 대한 내용은 아닙니다.\n\n이 기사는 우리의 옵션을 검토하고 최소한의 산란 없이 구현하는 방법을 살펴볼 것입니다. 심층적인 프로그래밍 지식이 없는 사람도 설정하고 사용할 수 있습니다.\n\n# 하드웨어\n\n하드웨어에 대해 말할 것이 별로 없습니다. 가능한 한 간단합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_1.png)\n\n- 라즈베리 파이 5\n- 카메라 케이블\n- 카메라 모듈 3 (와이드 에디션)\n\n운영 체제로는 최신 공식 Debian Bookworm 포트를 사용하고 있습니다. 사용자 지정 설정은 없으며 모든 것은 공식 라즈베리 스토어와 라즈베리 파이 이미저에서 찾을 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_2.png)\n\n\n<div class=\"content-ad\"></div>\n\n공식 라즈베리 카메라 문서로 시작해서 네트워크 스트림 권장 사항을 시도해 봅시다.\n\n![image](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_3.png)\n\n[라즈베리 파이 카메라 소프트웨어 문서](https://www.raspberrypi.com/documentation/computers/camera_software.html)에 접속해 봅시다.\n\n왼쪽 메뉴에 rpicam-vid 아이템이 있습니다. 해당 항목을 누르면 페이지가 필요한 정보로 스크롤됩니다. '네트워크 스트리밍' 섹션으로 조금 내려가서 UDP 스트림을 시도해 봅시다.\n\n<div class=\"content-ad\"></div>\n\n두 개의 터미널을 사용할 거에요. 하나는 SSH를 통해 라즈베리 파이에 연결하고, 다른 하나는 로컬 머신에서 명령을 실행할 거에요.\n\n# Raspberry PI에서 네이티브 코덱을 사용한 UDP 비디오 스트림\n\nhttps://www.raspberrypi.com/documentation/computers/camera_software.html#udp\n\n라즈베리 파이에서 스트림을 시작하는 명령어는 다음과 같아요:\n\n<div class=\"content-ad\"></div>\n\n```js\nrpicam-vid -t 0 --width 1280 --height 720 --framerate 30 --inline -o udp://노트북_IP_여기에:5555\n```\n\n라즈베리 파이의 LAPTOP_IP_HERE를 노트북의 IP 주소로 대체해야 합니다.\n\n포트는 임의로 설정할 수 있습니다. 여기서는 5555를 사용했습니다.\n\n위와 같이 라즈베리 파이가 몇 프레임을 노트북으로 보내주는 것을 볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_4.png\" />\n\n비디오를 재생하려면 노트북에서 다음 명령어를 실행할 수 있어요:\n\n```js\nffplay udp://RASPBERRY_PI_IP_HERE:5555 -fflags nobuffer -flags low_delay -framedrop\n```\n\n이제 성능을 확인해 볼 시간이에요.\n\n<div class=\"content-ad\"></div>\n\n실시간으로 타이머를 기록하고 지역 네트워크를 통해 스트림을 전송하는 카메라가 있습니다.\n\n![image](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_5.png)\n\nUDP 비디오 전송 방식은 3,400밀리초의 지연이 있다는 것을 알 수 있습니다.\n\n큰 지연입니다. 예를 들어, 초속 40마일(약 64킬로미터)로 이동하는 차량은 3.4초 동안 66.49야드(60미터)를 이동합니다.\n\n<div class=\"content-ad\"></div>\n\n여기 축구장에서 66야드가 어떻게 보이는지에 대한 내용이에요. 정말 인상적죠.\n\n![66 yards on a football field](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_6.png)\n\n드론과 같은 고속 장치를 제어할 때 신뢰할 수 있는 것은 아닙니다.\n\n# Raspberry PI 5 TCP 비디오 스트림 네이티브 코덱\n\n<div class=\"content-ad\"></div>\n\n라즈베리 파이에서 스트리밍하는 명령어는 다음과 같습니다:\n\n```js\nrpicam-vid -t 0 --width 1280 --height 720 --framerate 30 --inline --listen -o tcp://0.0.0.0:5556\n```\n\n라즈베리 파이는 자체 포트(5556으로 설정함)로 스트리밍을 생성하며, 클라이언트는 연결하여 스트림을 받을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n보시다시피, 일부 프레임을 보내고 수신자가 스트림을 받을 때까지 멈춰있습니다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_7.png)\n\n노트북에서 스트림을 표시하려면 다음을 사용할 수 있습니다:\n\n```js\nffplay tcp://라즈베리파이_IP_여기에:5556 -vf \"setpts=N/30\" -fflags nobuffer -flags low_delay -framedrop\n```\n\n<div class=\"content-ad\"></div>\n\n이 TCP 비디오 스트리밍 방법은 UDP보다 훨씬 나은 반초의 지연만 있습니다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_8.png)\n\n이 지연을 초당 40마일 주행하는 자동차에 적용해보겠습니다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_9.png)\n\n<div class=\"content-ad\"></div>\n\n5 초 동안, 자동차는 10야드(또는 9미터)만 이동합니다.\n\n# Raspberry PI 5 RTSP 비디오 스트림 네이티브 코덱\n\n이제 RTSP 스트림을 테스트해 보겠습니다.\n\n문서에서 제공된 명령어:\n\n<div class=\"content-ad\"></div>\n\n```js\nrpicam-vid -t 0 --inline -o - | cvlc stream:///dev/stdin --sout '#rtp{sdp=rtsp://:8554/stream1}' :demux=h264\n```\n\n그리고.....\n\n![image](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_10.png)\n\n...... 네. 작동하지 않아요.\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\n# Raspberry PI 5에서 libav 코덱(mpegts)을 사용한 TCP 비디오 스트리밍\n\nhttps://www.raspberrypi.com/documentation/computers/camera_software.html#network-streaming-with-libav\n\n이것은 다른 비디오 코덱이며, 지연에 영향을 줄 수 있습니다.\n\nRaspberry PI에서 실행할 명령어:\n\n<div class=\"content-ad\"></div>\n\n```js\nrpicam-vid -t 0 --width 1280 --height 720 --framerate 30 --codec libav --libav-format mpegts --libav-audio -o \"tcp://0.0.0.0:1234?listen=1\"\n```\n\n노트북에서 재생하는 명령어:\n\n```js\nffplay tcp://라즈베리파이IP주소:1234 -vf \"setpts=N/30\" -fflags nobuffer -flags low_delay -framedrop\n```\n\n의외로 LibAv는 큰 딜레이가 있습니다 — 약 10.5초가 됩니다. 기본 코덱과 TCP로는 0.5초였으나, 이제 10.5초가 소요됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_11.png)\n\n차량에 적용하면 그 지연 시간으로 인해 차량이 필드 밖으로 멀리 나갈 것을 볼 수 있습니다. 200야드 또는 190미터입니다. 농담이 아닙니다.\n\n![Image](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_12.png)\n\n# Raspberry PI 5 UDP 비디오 스트림과 libav 코덱 (mpegts)\n\n\n<div class=\"content-ad\"></div>\n\n라즈베리 파이에서 실행해야 하는 명령어:\n\n```js\nrpicam-vid -t 0 --width 1280 --height 720 --framerate 30 --codec libav --libav-format mpegts --libav-audio  -o \"udp://REPLACE_WITH_LAPTOP_IP:5555\"\n```\n\n라이플랩을 위한 플레이어:\n\n```js\nffplay tcp://RASPBERRY_PI_IP_HERE:1234 -vf \"setpts=N/30\" -fflags nobuffer -flags low_delay -framedrop\n```\n\n<div class=\"content-ad\"></div>\n\n이제 UDP에 대한 지연 시간은 반으로 줄었습니다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_13.png)\n\n이 모든 정보를 축구장에 추가합시다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_14.png)\n\n<div class=\"content-ad\"></div>\n\n이 결과들이 정말 이상해요. 원시 코덱을 사용하면 UDP에서는 큰 지연이 있고 TCP에서는 작은 지연이 있었고, LibAV를 사용하면 그 반대로 되었어요.\n\n하지만 여전히 0.5초보다 빠른 속도를 내볼 수 있어요.\n\n# Raspberry PI 5 MediaMTX 설정\n\n마침내, 우리는 Raspberry PI에서 스트림 지연 우승자에 가까워졌어요: MediaMTX입니다. 이 소프트웨어는 이전 비디오에서 언급된 모든 프로토콜과 몇 가지 더 사용하여 스트림을 전송할 수 있어요. 설정부터 시작해봐요.\n\n<div class=\"content-ad\"></div>\n\n설치하려면 정말 간단한 단계를 따라야 해요:\n\n- 먼저 GitHub의 릴리스 페이지를 열어주세요.\n- 두 번째로, ARM64 아카이브 링크를 복사해주세요. 적절한 버전을 선택하는 것이 중요해요.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_15.png)\n\n- 세 번째로, Raspberry PI에 해당 폴더를 생성해주세요.\n\n<div class=\"content-ad\"></div>\n\n```sh\nmkdir mediamtx && cd mediamtx\n```\n\n다음으로, GitHub에서 최신 링크를 찾아 WGET 명령어를 사용하여 다운로드합니다.\n\n```sh\nwget https://github.com/bluenviron/mediamtx/releases/download/v1.7.0/mediamtx_v1.7.0_linux_arm64v8.tar.gz\n```\n\n그 다음, 동일한 폴더에 압축을 푸세요.\n\n<div class=\"content-ad\"></div>\n\n```js\ntar -xvzf mediamtx_v1.7.0_linux_arm64v8.tar.gz\n```\n\n- 여섯 번째로, YML 구성 파일을 편집하려면 엽니다.\n\n```js\nnano mediamtx.yml\n```\n\n- 일곱 번째로, 아래로 스크롤하고 이 구성을 붙여넣습니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\ncam1:\n    runOnInit: bash -c 'rpicam-vid -t 0 --camera 0 --nopreview --codec yuv420 --width 1280 --height 720 --inline --listen -o - | ffmpeg -f rawvideo -pix_fmt yuv420p -s:v 1280x720 -i /dev/stdin -c:v libx264 -preset ultrafast -tune zerolatency -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH'\n    runOnInitRestart: yes\n```\n\n간단히 말해서, MediaMTX 소프트웨어는 이 명령어를 bash에서 실행할 겁니다.\n\n그 다음 RPICAM-VID 명령어에게 (이전에 다뤘던 것과 동일하게) 스트림을 FFMPEG로 보내도록 요청할 겁니다.\n\nFFMPEG은 그것을 RTSP 프로토콜을 통해 로컬로 MediaMTX로 보낼 겁니다.\n\n<div class=\"content-ad\"></div>\n\n구성을 저장하고 MediaMTX를 실행할 수 있어요.\n\n```js\n./mediamtx\n```\n\n처음 실행 시 프로토콜 및 사용 가능한 포트에 대한 유용한 정보가 표시될 거예요.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_16.png)\n\n<div class=\"content-ad\"></div>\n\n# Raspberry PI 5 RTSP 비디오 스트림 및 mediaMTX\n\nVLC 플레이어 및 RTSP 스트림으로 시도해 봅시다.\n\n노트북에서 다음 명령을 사용하여 vlc 플레이어를 실행할 수 있습니다:\n\n```js\nvlc rtsp://라즈베리파이_IP_주소_여기에:8554/cam1\n```\n\n<div class=\"content-ad\"></div>\n\n당신은 개발자이다. 위의 텍스트를 친근하게 한국어로 번역해주시겠어요?\n\n잠시 후에는 스트림이 표시됩니다.\n\n![stream](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_17.png)\n\n이 유형의 스트림은 1.3초의 지연이 있습니다. 이 번호를 축구장에 추가해 봅시다.\n\n![football field](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_18.png)\n\n<div class=\"content-ad\"></div>\n\n# Raspberry PI 5 WebRTC 비디오 스트림과 mediaMTX\n\n드디어, 당첨에 한 발짝 더 다가갔습니다. 콘솔로 돌아가서 WebRTC용 포트를 확보해 봅시다. 제 경우에는 8889번 포트를 사용하고 있습니다.\n\n![이미지](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_19.png)\n\n이를 재생하려면, 브라우저에서 이 스트림을 열어보세요:\n\n<div class=\"content-ad\"></div>\n\n```js\nhttp://RASPBERRY_PI_IP_HERE:8889/cam1\n```\n\n금방 스트림이 제공될 예정이에요. \n\n전체 화면으로 변경해보고, 지연 시간을 확인해 보세요.\n\n![Raspberry Pi Video Stream Latencies Comparing UDP, TCP, RTSP, and WebRTC](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_20.png)\n\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 변경하세요.\n\n<div class=\"content-ad\"></div>\n\n여기서 모든 결과가 하나의 표에 있습니다.\n\n![표](/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_22.png)\n\nFPV 드론과 함께 스트림을 사용할 예정이라면, 200밀리초보다 10배 낮은 지연 시간이 필요합니다. 약 20-30밀리초 정도어야 합니다.\n\n제 필요성에 따라 200밀리초의 지연은 무의미하며, MediaMTX를 사용하여 계획을 실행할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n더 낮은 지연을 원하신다면 WebRTC 스트림 조정이나 프레임 속도 감소, 그리고 다른 매개변수 조작을 시도해보세요.\n\n이 글이 낮은 지연 라이브 스트림을 갖춘 흥미로운 프로젝트를 구축하는 데 도움이 되기를 바랍니다.\n\nYouTube 채널의 댓글에서 의견을 남겨주세요. 또한 이와 유사한 정보가 필요하다면 말씀해주세요!\n\n읽어주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_0.png"},"coverImage":"/assets/img/2024-06-19-RaspberryPi5VideoStreamLatenciesComparingUDPTCPRTSPandWebRTC_0.png","tag":["Tech"],"readingTime":10},{"title":"시행 착오 내 스티커 여행","description":"","date":"2024-06-19 06:02","slug":"2024-06-19-TrialandErrorMyStickerJourney","content":"\n\n## DIY\n\n저는 스티커를 만드는 것을 한 해 동안 하고 있는데, 색다른 여정이었어요. 여러 번의 성공과 실패를 거쳐 왔죠. 위에서 볼 수 있는 것처럼, 제가 만들어온 다양한 스티커들이 있어요. 디지털 일러스트를 처음 해보았기 때문에, 익숙해지는 데 시간이 걸렸어요.\n\n새로운 것을 창조하고 발전시키는 데는 시간과 많은 인내가 필요해요. 아이디어를 떠오르게 하고 색상을 즐기기 위해 스케치북을 사용해요. 일상 속에서 긍정적인 것을 전하고 싶었기 때문에 다음은 다포이스(Dopis)를 생각해냈어요. 그들은 우리의 도파민을 높여주고 우울할 때 우리를 돕는 작은 외계인들이에요.\n\n그런 다포이스 스티커를 만들어보려고 디지털로 실험하기 시작했어요. 종이에 그린 내용을 컴퓨터 화면으로 옮기는 것이 쉽지 않았지만, 결국 성공했어요.\n\n<div class=\"content-ad\"></div>\n\n물론, 디지턈 제품만큼 어려움이 많았죠. 스티커 커팅 기계와 프린터, 스티커 용지와 함께 다뤄야 했는데, 모두가 조심스럽게 다뤄야 하는 것들이었죠. 배우는 유일한 방법은 다양한 것을 시도해보고 실험하는 것입니다. 적지 몇 장을 망치거나 여러 번 잉크를 낭비하더라도 돼요.\n\n요약하자면, 이런 것들을 고려하는 것이 중요하다고 생각해요.\n\n- 불완전한 커터와 프린터를 받아들이세요. 이 말은 정말 사랑 가득한 마음으로 하는 말입니다. 그들도 할 수 없는 상황이라구요. 커터 씨와 프린터 아가씨에게 답답해할 때 해결되지 않아요. 그래서 지금부터 긴장을 늦추고 계획을 세우세요. 마지막 순간에 모든 것이 순조롭게 처리될 걸 기대하지 마세요. 이 아이들은 시간과 사랑이 필요해요.\n- 개선을 하되, 창작물에 칭찬도 해주세요. 당연히 계속해서 개선점을 발견하고 있지만, 지금까지 이뤄낸 것들을 소중히 여기는 것이 중요한 것 같아요. 과정은 계속해서 나아지는 것 뿐만 아니라 쉬어가거나 한발자국 물러서서 이룬 것에 기뻐할 줄 아는 것도 중요해요.\n- 서두르면 결과가 좋지 않아져요. 종종 한번에 모든 걸 해결하고 싶어하지만, 시간을 갖고 쉬는 것이 더 나은 결과를 얻을 수 있게 도와줘요. 모든 것을 한번에 해결하려고 자기 자신을 밀어붙이지 마세요. 메모를 하고 나중에 작업을 돌아가보세요. 이렇게 하면 작업에 가해지는 압박이 줄어들어요.\n- 공유가 사랑이에요. 제 스티커들을 가장 소중한 친구들, 가족, 그리고 길을 가는 중에서 만난 멋진 사람들에게 나누어 주었어요. 그렇게 하면 좋은 생각과 기운을 함께 전달할 수 있어요. 때로는 기대 없이 주는 것도 있어야 해요. 사랑과 기쁨을 퍼뜨려 보세요.\n- 창의적인 마음을 지원하세요. 저는 정기적으로 소상공인과 아티스트를 지원하고 있어요. 이렇게 많은 재능이 존재하다는 것이 기쁘고요. 창의력은 소중히 여기고 지원해야 할 것이며, 우리 사이에서도 서로 지원해야 해요. 남들과 비교하지 않고 자신만의 성장과 과정을 존중하기 시작했어요.\n\n이것이 제 최근 창작물인 Dopis와 그와 관련된 다른 일러스트입니다.\n\n<div class=\"content-ad\"></div>\n\n사랑하는 일을 하는 것은 만족감과 성취감을 느끼게 해줘요. 현재는 취미에 불과할지 몰라도, 언젠가는 작은 사업으로 성장할 수도 있고 그렇지 않을 수도 있어요. 하지만, 지금 당장이 중요한 거죠.\n\n당신에게 기쁨을 주는 현재의 활동은 무엇인가요?\n\n## 또 다른 스티커 이야기?","ogImage":{"url":"/assets/img/2024-06-19-TrialandErrorMyStickerJourney_0.png"},"coverImage":"/assets/img/2024-06-19-TrialandErrorMyStickerJourney_0.png","tag":["Tech"],"readingTime":2},{"title":"ESP32에서의 WIFI 스팸 전송기","description":"","date":"2024-06-19 06:01","slug":"2024-06-19-WIFISpammeronESP32","content":"\n\n안녕하세요 여러분! 오늘은 제 최신 프로젝트인 esp32에서 동작하는 wifi 스팸 전송기에 대해 이야기하려고 해요. 이 프로젝트에 대한 자세한 설명과 만드는 방법에 대해 알려드릴 거에요. 이 기기는 재미있는 이름의 wifi 핫스팟을 많이 생성하고 정기적으로 업데이트하는 기능을 갖추고 있어요.\n\n이 프로젝트는 제가 esp32로 진행한 첫 번째 프로젝트에요. 즐거운 시간을 보냈고, 여러분도 즐겁게 활용할 수 있길 바라요!\n\n자, 시작해봅시다!\n\n이 프로젝트를 위해서는 esp32 보드, microUSB to USB 케이블 (esp32에 코드를 업로드하기 위해), 제 코드, 그리고 필수 모듈이 설치된 Arduino 소프트웨어가 필요해요.\n\n<div class=\"content-ad\"></div>\n\n저기서 보드를 얻었어요\n\n# 소개\n\n## ESP32란?\n\nESP32은 통합 Wi-Fi 및 블루투스 기능을 갖춘 저렴하고 저전력 시스템 온 칩 (SoC) 마이크로컨트롤러입니다. ESP32에는 520KB의 SRAM이 탑재되어 있으며, 플래시 메모리 용량은 다양할 수 있습니다 (일반적으로 4MB). 즉, 매우 흥미로운, 저렴하고 멋진 제품이에요!\n\n<div class=\"content-ad\"></div>\n\nESP32를 사용하여 C/C++, Python, JavaScript, Lua, Rust와 같은 다양한 언어로 프로그래밍할 수 있지만 이 프로젝트에서는 Arduino IDE에서 Arduino를 선택했습니다.\n\n# Arduino 및 모듈 설치하기\n\nArduino 소프트웨어를 설치하세요(소유하고 있지 않은 경우), Boards Manager(도구`보드`보드 관리자)로 이동하고 esp32를 검색하세요. 두 번째 것을 다운로드하세요.\n\n![이미지](/assets/img/2024-06-19-WIFISpammeronESP32_0.png)\n\n<div class=\"content-ad\"></div>\n\n# 코드를 깜빡이기\n\n이후에는 내 GitHub로 가서 코드를 다운로드하고 아두이노 프로그램에서 열어주세요. ESP32 Dev 모듈(도구 '보드')을 선택하고 확인을 누르세요.\n\n이 작업은 코드에서 오류를 확인합니다.\n\n![이미지](/assets/img/2024-06-19-WIFISpammeronESP32_1.png)\n\n<div class=\"content-ad\"></div>\n\n여기서 오류를 받지 않아야 합니다. 그러나 오류가 발생하면 언제든지 저에게 연락해주세요.\n\n이제 노트북에 ESP32와 케이블을 연결하고 업로드를 클릭하세요!\n\n그게 다예요! 이제 잠시 기다렸다가 Wifi 네트워크를 확인해보세요!\n\n![이미지](/assets/img/2024-06-19-WIFISpammeronESP32_2.png)\n\n<div class=\"content-ad\"></div>\n\n축하해요! 잘 했어요!\n\n# 결론\n\n이 프로젝트를 함께 해 주시고 새로운 것을 많이 배워서 즐거우셨기를 바랍니다. 문제가 있었거나 멋진 아이디어가 있다면 언제든지 연락주세요!\n\n더 많은 흥미로운 콘텐츠를 보려면 제 Medium과 GitHub를 팔로우하지 않는 것을 잊지 마세요!\n\n<div class=\"content-ad\"></div>\n\n시간을 내어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-19-WIFISpammeronESP32_0.png"},"coverImage":"/assets/img/2024-06-19-WIFISpammeronESP32_0.png","tag":["Tech"],"readingTime":2},{"title":"Web Wise 내가 직접 웹사이트를 만들 수 있을까요 장단점 및 현실","description":"","date":"2024-06-19 06:01","slug":"2024-06-19-WebWiseCanICreateMyOwnWebsiteProsConsandRealities","content":"\n\n## 장 3: DIY 웹사이트 빌더 탐험\n\n# 시작: DIY 웹사이트 딜레마\n\n그래서, 당신은 단답을 내리기로 하고 비즈니스를 위한 웹사이트를 만들기로 결정했습니다. Wix, Shopify, Squarespace 및 GoDaddy와 같은 DIY 웹사이트 빌더에 대해 들어보았지만, \"저렴하게 프로페셔널하게 나만의 웹사이트를 만들 수 있을까?\" 라는 의문이 듭니다. DIY 웹사이트 빌더의 멋진 세계를 탐험해보고, 그들이 과연 그 임무를 수행할 수 있는지 확인해보죠.\n\n# DIY 웹사이트 빌더의 매력\n\n<div class=\"content-ad\"></div>\n\n## 쉽게 설정하기\n\nDIY 웹사이트 빌더는 간편하게 사용할 수 있도록 설계되었습니다. Wix나 Squarespace와 같은 플랫폼은 당신이 아침 커피를 내리는 시간만큼이면 웹사이트를 즉시 구축할 수 있다고 약속합니다. 드래그 앤 듭 기능을 갖춘 사용자 친화적인 인터페이스를 제공하여, 마지막으로 습득한 기술이 비디오 테이프 레코더의 프로그래밍이라면 접근하기 쉽습니다.\n\n## 예산 친화적인 옵션\n\n\"웹사이트 개발 비용\"이라는 구문이 당신을 두렵게 만든다면, DIY 웹사이트 빌더는 치료제가 될 수 있습니다. 이들은 종종 무료 또는 저렴한 요금제를 제공하며, 비즈니스가 성장함에 따라 업그레이드할 수 있습니다. 특히 스타트업 또는 자금을 지켜보는 소기업에게 매력적일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 사용자 정의 및 템플릿\n\n이러한 플랫폼들은 귀하의 웹사이트가 멋지고 전문적으로 보이도록 디자인된 다양한 템플릿을 제공합니다. 몇 가지 조정을 통해 브랜드에 맞게 이러한 템플릿을 사용자 정의할 수 있습니다. 게다가, 코드 한 줄도 알 필요가 없습니다. 그냥 클릭하고 타이핑하면 완성! 당신의 웹사이트가 만들어집니다.\n\n![웹사이트](/assets/img/2024-06-19-WebWiseCanICreateMyOwnWebsiteProsConsandRealities_0.png)\n\n# 현실 점검: 장단점\n\n<div class=\"content-ad\"></div>\n\n장점:\n\n- 사용자 친화적: 코딩 스킬이 없어도 괜찮아요! DIY 빌더는 디지털 색칠책만큼 직관적입니다.\n- 가격이 저렴: 무료 또는 저렴한 기본 요금제로 웹사이트를 만들 수 있어요. 할머니의 가문의 가마솥을 전당해야 할 필요가 없어요.\n- 빠른 실행: \"URL\"이라고 말하는 것보다 더 빨리 사이트를 공개할 수 있어요.\n\n단점:\n\n- 유연성이 제한적: 이러한 플랫폼은 기본 사이트에는 좋지만, 고급 기능이 필요한 경우에는 한계에 부딪힐 수 있어요. 복잡한 예약 시스템이나 사용자 정의된 전자상거래 기능을 통합하려면 전문가들을 찾아야 할 수도 있어요.\n- 일반적인 템플릿: 템플릿은 정제되어 있지만, 조금 쿠키 자르듯 보일 수도 있어요. 독특하고 눈에 띄는 디자인을 원한다면 다소 제약을 느낄 수도 있어요.\n- 확장성 문제: 비즈니스가 성장함에 따라 웹사이트도 성장해야 해요. DIY 빌더는 확장성과 사용자 정의 측면에서 한계가 있어 비용이 많이 들어가는 더 강력한 플랫폼으로의 이주가 필요할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n# 기말고사 불러오는 시기: 웹 디자이너와 개발자\n\n만약 DIY 빌더로는 처리할 수 없는 사용자 정의 CRM 통합 또는 복잡한 제품 카탈로그와 같은 기능을 꿈꾸게 된다면, 전문가를 고용하는 것을 고려해볼 시간일지도 모릅니다. 웹 디자이너나 개발자는 비즈니스 요구 사항을 충족하고 더 나아가 사이트가 기능적일 뿐만 아니라 확장 가능하고 독특하다는 것을 보장하는 웹사이트를 완전히 처음부터 만드는 데 도움을 줄 수 있습니다.\n\n# 결론: DIY 또는 DIY 아님\n\n웹사이트를 DIY하거나 전문가를 고용할지 결정하는 것은 비즈니스의 독특한 요구 사항과 성장 계획에 달려 있습니다. DIY 빌더는 환상적인 시작점이지만 필요할 때 전문가 도움을 찾기를 두려워하지 마세요.\n\n<div class=\"content-ad\"></div>\n\n다음 장에서 비즈니스 웹사이트 디자인 세계로 깊이 들어가는 것을 기대해주세요!","ogImage":{"url":"/assets/img/2024-06-19-WebWiseCanICreateMyOwnWebsiteProsConsandRealities_0.png"},"coverImage":"/assets/img/2024-06-19-WebWiseCanICreateMyOwnWebsiteProsConsandRealities_0.png","tag":["Tech"],"readingTime":3},{"title":"작은 머신러닝  XGBoost 회귀","description":"","date":"2024-06-19 05:58","slug":"2024-06-19-TinyMLXGBoostRegression","content":"\n\n수학적 기초부터 엣지 구현까지\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 연구 그룹: Conecta.ai (ufrn.br)\n\n![이미지](/assets/img/2024-06-19-TinyMLXGBoostRegression_0.png)\n\n<div class=\"content-ad\"></div>\n\n## 요약\n\n### 1 - XGBoost 회귀 이론\n\n보완적으로, 부스팅은 일련의 모델 집합 𝑡가 순차적으로 훈련되는 앙상블 접근 방식을 나타냅니다. 각 모델 𝑡는 이전 모델, 𝑡−1에서 발견된 결함을 보정하는 목적으로 설계되었습니다.\n\n타겟 값 yᵢ와 샘플 xᵢ에 대한 모델 𝑡의 예측 ŷᵢᵗ을 고려하고, 평균 제곱 오차 (MSE) 등의 일반적인 오류 함수 l로 나타내고, 총 샘플 수를 n으로 표시할 때, 반복 t에서의 모델의 오류(또는 손실)는 다음과 같이 정의됩니다:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-TinyMLXGBoostRegression_1.png\" />\n\n모델이 단계적으로 구축되었다는 것을 관찰할 수 있습니다. t 단계에서의 예측은 t-1 단계에서의 예측에 새 모델 fₜ의 예측을 더한 결과입니다:\n\n<img src=\"/assets/img/2024-06-19-TinyMLXGBoostRegression_2.png\" />\n\n우리는 모델의 복잡성을 조절하는 데 기여하는 정규화항을 도입할 것이며(나중에 이 항의 구체적인 기능이 명확해질 것입니다).\n\n<div class=\"content-ad\"></div>\n\nXGBoost의 기본 개념은 각 트리의 포함이 전략적이라는 것을 전제로 합니다: 목표는 항상 오차를 최소화하는 최적의 트리를 구축하는 것입니다. 이를 위해, 우리는 함수 L을 최적화 문제로 다룰 것이며, 결국 L을 최소화하는 fₜ를 결정하려고 합니다. 그러나 이 작업의 복잡성은 오차 함수 l을 선택하는 데 따라 다를 수 있습니다.\n\n따라서 우리는 이 함수를 Taylor 전개를 통해 간소화하기로 결정했습니다. 어떤 무한 차별화 가능한 함수도 다음 형식으로 표현할 수 있다는 것이 널리 인정받았습니다:\n\n![수식](/assets/img/2024-06-19-TinyMLXGBoostRegression_3.png)\n\n중간 단계에서 시리즈를 자르면 함수의 근사치를 얻을 수 있습니다. 현재 상황에서는 확장을 둘째 차수에서 중지하기로 선택했습니다.\n\n<div class=\"content-ad\"></div>\n\n![image1](/assets/img/2024-06-19-TinyMLXGBoostRegression_4.png)\n\ngᵢ (gradient)와 hᵢ (Hessian)로 도함수를 대체할 것입니다:\n\n![image2](/assets/img/2024-06-19-TinyMLXGBoostRegression_5.png)\n\n만약 이 방정식을 최소화하는 fₜ를 찾는 것이 목적이라면, 상수항인 l은 필요하지 않습니다. 따라서 l을 버리면 다음과 같이 됩니다:\n\n<div class=\"content-ad\"></div>\n\n\n![링크 텍스트](/assets/img/2024-06-19-TinyMLXGBoostRegression_6.png)\n\nXGBoost의 주목할만한 특성 중 하나는 손실 함수가 두 번 미분 가능해야 한다는 요구사항입니다. 특정 문제에 대해 사용자 정의 오류 함수를 이용하여 XGBoost를 적용하려는 경우, 오류 계산 뿐만 아니라 그레이디언트(일차 도함수) 및 헤시안(이차 도함수)에 대한 정보도 필요하다는 점을 명심하는 것이 중요합니다.\n\n## 1.1 — 의사 결정 트리\n\n의사 결정 트리의 작동을 고려할 때, 방정식 L을 다시 쓸 필요가 있습니다. 각 샘플 xᵢ가 leaf j와 연관되어 있음을 알 수 있습니다. 따라서 각 leaf에 대해 샘플이 포함된 집합 인덱스 Iⱼ를 만들 수 있습니다. \n\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_7.png)\n\nIⱼ가 정의되어 있으며, Iⱼ에 속하는 각 인덱스 i에 대해 샘플 xᵢ가 통과한 결정 경로 q는 잎 j로 이어진다.\n\n또한, 모델이 샘플 xᵢ에 대해 응답하는 것이 xᵢ가 속한 잎에서 관련된 가중치임을 알 수 있습니다:\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_8.png)\n\n\n<div class=\"content-ad\"></div>\n\n그 결과, 방정식의 일부 용어를 다시 정의할 수 있습니다:\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_9.png)\n\n대체를 수행하면 다음과 같이 얻을 수 있습니다:\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_10.png)\n\n<div class=\"content-ad\"></div>\n\n정규화 항도 확장할 거에요:\n\n![](/assets/img/2024-06-19-TinyMLXGBoostRegression_11.png)\n\n## 1.2 — 예측 오류 최적화\n\n나무의 모든 리프를 고려하는 대신에, 특정 리프에 초점을 맞출 거에요. 이 리프는 j로 표시돼요.\n\n<div class=\"content-ad\"></div>\n\n\n![Image 1](/assets/img/2024-06-19-TinyMLXGBoostRegression_12.png)\n\nThe objective is to find the set of weights w that minimizes L. This may seem challenging at first glance, but let’s analyze it more closely.\n\n![Image 2](/assets/img/2024-06-19-TinyMLXGBoostRegression_13.png)\n\nAs previously noted, our error function for a leaf is quadratic, implying that the minimum is determined by the inflection point of the curve, where the first derivative is equal to zero.\n\n\n<div class=\"content-ad\"></div>\n\n<table>\n  <tr>\n    <td><img src=\"/assets/img/2024-06-19-TinyMLXGBoostRegression_14.png\" /></td>\n  </tr>\n</table>\n\nwᵈ를 고립시키면 다음과 같이 됩니다:\n\n<table>\n  <tr>\n    <td><img src=\"/assets/img/2024-06-19-TinyMLXGBoostRegression_15.png\" /></td>\n  </tr>\n</table>\n\n이제 임의의 리프에 대해 최적 가중치를 제공하는 식을 확인했습니다. 따라서 L에 대한 우리의 식에 이 식을 대입함으로써 우리는 다음을 얻습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_16.png)\n\n이전 방정식은 각 새 트리의 각 분리를 평가하는 데 사용됩니다. 엔트로피나 지니 계수가 전통적으로 의사결정 트리 구성에 사용되는 방법과 마찬가지로 분리에서 양쪽 노드인 왼쪽 노드와 오른쪽 노드가 생성됩니다. 분할별 이득은 새로운 리프인 Lₗ(왼쪽)과 Lᵣ(오른쪽)의 합을 이전 오차인 Lₜ에서 뺀 것으로 정의됩니다. (우리가 Leaf가 하나만 분석하므로 T=1이라고 가정합니다.)\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_17.png)\n\n\n<div class=\"content-ad\"></div>\n\n## 1.3 — 하이퍼파라미터 튜닝\n\n이러한 방정식을 이해하면 XGBoost의 하이퍼파라미터와 기능을 더 잘 이해할 수 있습니다.\n\nreg_lambda: 이 파라미터는 잎의 가중치에 영향을 미치며, 값이 클수록 가중치의 절대값이 작아집니다. 이러한 이유로 𝜆은 모델의 복잡성을 제어하는 매개변수로, 가중치가 너무 커지는 것을 방지합니다. 보다 정확히는 L2 정규화입니다.\n\n![이미지](/assets/img/2024-06-19-TinyMLXGBoostRegression_18.png)\n\n<div class=\"content-ad\"></div>\n\n- reg_alpha: 분모를 제로에 가깝게 만들어서 중요성이 적은 트리 또는 분할을 제외하는 효과가 있습니다. 유도된 값의 모듈리(0보다 작을 때 -1, 0보다 클 때 1)의 행동으로 인해 가중 함수가 두 가지 경우로 나누어짐을 언급해야 합니다.\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_19.png)\n\n- gamma: 𝛾는 분할이 발생하는 최솟값으로, 𝛾보다 낮은 값은 결과적으로 부정적인 이득이 발생하여 실제 결과를 악화시킬 수 있으므로 고려되지 않습니다.\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_20.png)\n\n<div class=\"content-ad\"></div>\n\n- learning_rate: 문 개선을 위해 각 가중치에 0에서 1 사이의 값을 곱하여 나무의 개별적인 중요성을 감소시키고 학습 과정을 늦춰 미래 나무의 포함 여지를 늘립니다.\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_21.png)\n\n여기서 η는 트리 ft의 전체 예측에 미치는 영향을 직접 조절하며 가중치 계산 방식을 수정하지 않습니다.\n\n- max_delta_step: 각 반복의 최대 절대 가중치를 상수 𝛿로 제한하여 가중치의 부호를 항상 보존합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image 1](/assets/img/2024-06-19-TinyMLXGBoostRegression_22.png)\n\n- max_child_weight: 자식 노드마다 ℎ의 합이 이 매개변수로 설정된 값보다 크기 때문에 분할이 수행됩니다. ℎ는 오차 함수(𝑙)의 도함수에 의해 결정됩니다. 따라서 ℎ의 값이 낮을 때는 해당 리프가 이미 충분히 \"순수\"하며 더 이상 분할할 필요가 없다는 것을 나타냅니다.\n\n![Image 2](/assets/img/2024-06-19-TinyMLXGBoostRegression_23.png)\n\n여기서 Python 구현에 사용 가능한 매개변수 전체 목록을 찾을 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n# 2— TinyML 구현\n\n위 예제를 통해 ESP32, Arduino, Raspberry 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에서 머신러닝 알고리즘을 구현할 수 있습니다.\n\n2.0 — requirements.txt 파일에 나열된 라이브러리 설치\n\n```js\n!pip install -r requirements.txt\n```\n\n<div class=\"content-ad\"></div>\n\n2.1 — 라이브러리 가져오기\n\n```js\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import RandomizedSearchCV\nimport m2cgen as m2c\nimport numpy as np\nfrom scipy.stats import uniform, randint\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom xgboost import plot_tree\n```\n\n2.2— 데이터셋 로드\n\n당뇨병 데이터셋은 Bradley Efron, Trevor Hastie, Iain Johnstone 및 Robert Tibshirani가 스탠포드 대학에서 만들었습니다. 그들의 당뇨병 진행 예측 연구에 사용되었습니다.\n\n<div class=\"content-ad\"></div>\n\n- 데이터셋은 임상 및 인구 통계 변수인 열 개의 기준 변수로 구성되어 있습니다:\n\n1. 나이\n\n2. 성별\n\n3. 체질량 지수 (BMI)\n\n<div class=\"content-ad\"></div>\n\n4. 평균 혈압\n\n5. S1 — TC, T-세포 (백혈구의 일종)\n\n6. S2 — LDL, 저밀도 리포닛\n\n7. S3 — HDL, 고밀도 리포닛\n\n<div class=\"content-ad\"></div>\n\n8. S4 - TCH, 총 콜레스테롤\n\n9. S5 - LTG, 혈청 트리글리세리드 수준의 로그 가능성\n\n10. S6 - 포도당, 혈당 수준\n\n- 데이터셋에는 442개의 인스턴스(환자)가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 대상 변수는 기준선 이후 1년 후의 질병 진행의 양을 양적으로 측정한 것입니다. 데이터 집합에 명시적으로 언급되지 않은 요소를 기반으로 질병 진행을 표현합니다. 이는 연속 변수입니다.\n\n```python\n# 데이터셋 불러오기\ndata = load_diabetes() # 데이터 불러오기\n\n# DataFrame 생성\ndf_diabetes = pd.DataFrame(data.data, columns=data.feature_names)\n\n# 대상 변수를 DataFrame에 추가\ndf_diabetes['target'] = data.target\n\n# NaN 값 제거\ndf = df_diabetes.dropna(axis='rows') # NaN 값 제거\n\n# DataFrame 표시\ndf_diabetes.head()\n```\n\n![이미지](/assets/img/2024-06-19-TinyMLXGBoostRegression_24.png)\n\n```python\ndf_diabetes.info()\n```\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_25.png)\n\n```js\ndf_diabetes.describe()\n```\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_26.png)\n\n2.3— Exploratory Data Analysis\n\n\n<div class=\"content-ad\"></div>\n\n```js\nsns.pairplot(df_diabetes)\n```\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_27.png)\n\n2.4— 데이터를 학습 및 테스트 세트로 분할\n\n```js\ndf = df_diabetes.iloc[:100,0:10]\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nX=df.to_numpy()\n\ny=df_diabetes.iloc[:100,-1}\n```\n\n```js\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n```\n\n2.5 — Create the regressor model\n\n```js\nmodel = xgb.XGBRegressor(objective=\"reg:linear\", random_state=42)\n```\n\n<div class=\"content-ad\"></div>\n\n2.6 — 모델 훈련\n\n```js\nmodel.fit(X_train, y_train)\n```\n\n2.7 — 모델 최적화\n\nRandomizedSearchCV는 scikit-learn 라이브러리에서 제공하는 함수로, 머신 러닝 모델의 하이퍼파라미터 튜닝을 위해 교차 검증을 통해 주로 사용됩니다. 이 기술은 하이퍼파라미터의 폭넓은 탐색 영역을 다룰 때 유용하며, 가장 효과적인 값을 결정하는 데 도움이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n단계별 설명\n\n1. 매개변수 공간 정의:\n\nRandomizedSearchCV를 활용하기 전에, 모델의 하이퍼파라미터를 위한 탐색 공간을 지정해야 합니다. 특정 값의 그리드를 제공하는 대신, 각 하이퍼파라미터에 대해 분포를 정의합니다.\n\n2. 무작위 샘플링:\n\n<div class=\"content-ad\"></div>\n\nGridSearchCV와 같이 모든 가맹 별로 동시에 평가하는 것이 아니라, RandomizedSearchCV는 평가를 위해 일정한 조합을 무작위로 선택합니다. 이는 큰 탐색 공간을 다룰 때 유리합니다.\n\n3. 모델 훈련:\n\n랜덤으로 선택된 각 하이퍼파라미터 집합에 대해 RandomizedSearchCV는 교차 검증을 사용하여 모델을 훈련합니다. 데이터는 폴드로 나누어지며, 모델은 일부 폴드에서 훈련되고 나머지 폴드에서 평가됩니다.\n\n4. 성능 평가:\n\n<div class=\"content-ad\"></div>\n\n성능은 특정 메트릭(예: 정확도, F1 점수)을 사용하여 측정됩니다. 목표는 주어진 문제에 따라 이 메트릭을 최대화하거나 최소화하는 하이퍼파라미터를 찾는 것입니다(예: 분류 문제에서 정확도를 최대화).\n\n5. 최적 모델 선택:\n\n랜덤 서치를 완료하면 RandomizedSearchCV가 교차 검증 중 가장 우수한 평균 성능을 보인 하이퍼파라미터 세트를 반환합니다.\n\nRandomizedSearchCV를 사용하면 대규모 탐색 공간을 다룰 때 특히 모든 가능한 조합을 평가하는 그리드 서치(GridSearchCV)와 비교하여 계산 시간을 단축할 수 있습니다. 이 효율성은 모든 가능한 조합을 평가하는 대신 하이퍼파라미터 공간의 무작위 샘플을 탐색하는 데서 비롯됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nparams = {\n    \"colsample_bytree\": uniform(0.7, 0.3),\n    \"gamma\": uniform(0, 0.5),\n    \"learning_rate\": uniform(0.03, 0.3), # 기본값 0.1 \n    \"max_depth\": randint(2, 6), # 기본값 3\n    \"n_estimators\": randint(100, 150), # 기본값 100\n    \"subsample\": uniform(0.6, 0.4)\n}\n\nbest_model = RandomizedSearchCV(model, param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n\nbest_model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)]\n```\n\n![이미지](/assets/img/2024-06-19-TinyMLXGBoostRegression_28.png)\n\n```js\ndef report_best_scores(results, n_top=3):\n    for i in range(1, n_top + 1):\n        candidates = np.flatnonzero(results['rank_test_score'] == i)\n        for candidate in candidates:\n            print(\"순위 {0}인 모델\".format(i))\n            print(\"평균 검증 점수: {0:.3f} (표준편차: {1:.3f})\".format(\n                results['mean_test_score'][candidate],\n                results['std_test_score'][candidate]))\n            best_params = results['params'][candidate]\n            print(\"찾은 최적의 매개변수:\")\n            for param, value in best_params.items():\n                print(\"  {0}: {1}\".format(param, value))\n            print(\"\")\n```\n\n```js\nreport_best_scores(best_model.cv_results_, 1)\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-19-TinyMLXGBoostRegression_29.png)\n\n```js\nmodel =  xgb.XGBRegressor(objective=\"reg:linear\", max_depth= 5, learning_rate= 0.29302969102852483, gamma = 0.38122934287034527)\nmodel.fit(X_train, y_train)\n```\n\n2.8 — Visualization\n\n```js\nfig, ax = plt.subplots(figsize=(20, 10))\nplot_tree(model, num_trees=0, ax=ax)\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_30.png)\n\n2.9— 훈련 데이터로 모델 평가\n\n```js\nscore = model.score(X_train, y_train)\ntraining_predict = model.predict(X_train)\nmse = mean_squared_error(y_train, training_predict)\n\nprint(\"R-squared:\", score)\nprint(\"MSE: \", mse)\nprint(\"RMSE: \", mse**(1/2.0))\n```\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_31.png)\n\n\n<div class=\"content-ad\"></div>\n\n```js\nx_ax = range(len(y_train))\nplt.plot(x_ax, y_train, label=\"원본\")\nplt.plot(x_ax, training_predict, label=\"예측된 값\")\nplt.title(\"훈련 및 예측된 데이터\")\nplt.xlabel('X축')\nplt.ylabel('Y축')\nplt.legend(loc='best', fancybox=True, shadow=True)\nplt.grid(True)\nplt.show()\n```\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_32.png)\n\n2.10— 테스트 데이터로 모델 평가\n\n```js\nscore = model.score(X_test, y_test)\ntest_predict = model.predict(X_test)\nmse = mean_squared_error(y_test, test_predict)\n\nprint(\"R-squared:\", score)\nprint(\"MSE: \", mse)\nprint(\"RMSE: \", mse**(1/2.0))\n```\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-TinyMLXGBoostRegression_33.png\" />\n\n```js\nx_ax = range(len(y_test))\nplt.plot(x_ax, y_test, label=\"original\")\nplt.plot(x_ax, test_predict, label=\"predicted\")\nplt.title(\"Testing and predicted data\")\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.legend(loc='best',fancybox=True, shadow=True)\nplt.grid(True)\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-19-TinyMLXGBoostRegression_34.png\" />\n\n2.11 — 테스트 데이터를 사용하여 모델 평가하기\n\n\n<div class=\"content-ad\"></div>\n\n```js\ncode = m2c.export_to_c(model)\nprint(code)\n```\n\n![Image](/assets/img/2024-06-19-TinyMLXGBoostRegression_35.png)\n\n2.12 — 템플릿을 .h 파일에 저장합니다.\n\n```js\nwith open('./XGBRegressor.h', 'w') as file:\n    file.write(code)\n```\n\n<div class=\"content-ad\"></div>\n\n2.13 — 모델 배포\n\n이 예제를 통해 ESP32, 아두이노, 아두이노 Portenta H7 with Vision Shield, 라즈베리 파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에서 머신 러닝 알고리즘을 구현할 수 있습니다.\n\n2.13.1 — 완성된 아두이노 스케치\n\n```js\n#include \"XGBRegressor.h\"\n\n\nvoid setup() {\n  Serial.begin(115200);\n}\n\nvoid loop() {\n  double X_1[] = { 2.71782911e-02,  5.06801187e-02,  1.75059115e-02,\n                  -3.32135761e-02, -7.07277125e-03,  4.59715403e-02,\n                  -6.54906725e-02,  7.12099798e-02, -9.64332229e-02,\n                  -5.90671943e-02};\n  double result_1 = score(X_1);\n  Serial.print(\"입력 X1로 예측 결과 (실제 값 = 69):\");\n  Serial.println(String(result_1, 7));\n  delay(2000);\n}\n```\n\n<div class=\"content-ad\"></div>\n\n3.12 — 결과\n\n![image](/assets/img/2024-06-19-TinyMLXGBoostRegression_36.png)\n\n전체 프로젝트: [TinyML/14_XGBRegression at main · thommaskevin/TinyML](github.com)\n\n## 만약 마음에 드셨다면, 제 커피 한 잔 사주세요 ☕️💰 (Bitcoin)\n\n<div class=\"content-ad\"></div>\n\n```plaintext\n코드: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n![Image](/assets/img/2024-06-19-TinyMLXGBoostRegression_37.png)\n```","ogImage":{"url":"/assets/img/2024-06-19-TinyMLXGBoostRegression_0.png"},"coverImage":"/assets/img/2024-06-19-TinyMLXGBoostRegression_0.png","tag":["Tech"],"readingTime":14},{"title":"아두이노와 얼굴 인식 프로젝트 아이디어 초기 컨셉","description":"","date":"2024-06-19 05:56","slug":"2024-06-19-ArduinoandFaceRecognitionProjectIdeaInitialConcept","content":"\n\n저자: [언젠가 밝히겠어요 :D]\n\n공항과 같은 많은 장소에서 얼굴 인식을 기반으로 한 인증을 목격했어요. 일반적으로 이러한 종류의 입장 방법을 통한 프로세스는 훨씬 더 빠르고 혼잡하지 않으며 덜 짜증이 나요. 그래서, 저는 현재 프로젝트의 초기 단계에 있어요. 처음에는 아두이노 Uno R3에서 간단한 모델 실행을 지원하는 TinyML에 대한 아이디어가 있었지만, 아두이노 Uno R3에서 그런 머신 러닝이 가능한지 확신이 없어서 그 아이디어를 제쳤어요. 지금까지의 로드맵은 다음과 같아요.\n\n로드맵 —\n\n- Python, Deepface 및 OpenCV를 사용하여 얼굴 인식을 작동시키기.\n- 유효한 결과를 아두이노 마이크로컨트롤러에 연결하기.\n- 아마도 Python 기반 접근 방법을 사용하여 아두이노 보드를 제어하기.\n- 이에 대한 비디오를 만들기.\n- GitHub에 올리기.\n- 나머지 휴가를 즐기기!\n\n<div class=\"content-ad\"></div>\n\n앞으로의 계획 —\n\n- 유니티에 이런 것을 통합해보려고 합니다. 비주얼 노벨 게임에서 NPC와 대화할 때 만드는 표정이 이야기를 변경할 수도 있겣죠.\n- 일관성 있게 유지하고 적어도 파이썬을 이용한 기계 학습을 배우는 것을 계속해봐요.\n- 여유로운 시간을 즐겨요!","ogImage":{"url":"/assets/img/2024-06-19-ArduinoandFaceRecognitionProjectIdeaInitialConcept_0.png"},"coverImage":"/assets/img/2024-06-19-ArduinoandFaceRecognitionProjectIdeaInitialConcept_0.png","tag":["Tech"],"readingTime":1}],"page":"87","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true}