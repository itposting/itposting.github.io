{"pageProps":{"posts":[{"title":"TailsOS 세상에서 사라지고 싶다면 사용할 운영 체제","description":"","date":"2024-06-20 14:25","slug":"2024-06-20-TailsOSAnOperatingSystemIWouldUseIfIWantedToDisappearFromTheWorld","content":"\n\n에드워드 스노든에 대해서 들어보셨나요?\n\n스노든은 미국 역사상 가장 중요한 고발자 중 하나로 기록될 것입니다.\n\n그는 NSA와 통신 회사 및 유럽 정부들이 협력하여 운영한 광범위한 글로벌 감시 프로그램을 폭로한 사람입니다.\n\n이제 그에 대해 알게 되었으니, 이 모든 기간 동안 인터넷상에서 익명으로 유지하는 방법에 대해 알고 계신가요?\n\n<div class=\"content-ad\"></div>\n\n여기 그의 말로 번역한 것입니다:\n\n“T\nor & Tails” — 예!\n\n## TailsOS란 무엇인가요?\n\nTailsOS는 감시와 검열에 대처하는 Debian 기반의 휴대용 운영 체제입니다.\n\n<div class=\"content-ad\"></div>\n\n누구든지 자신의 신원을 숨기고, 검열을 피하며 안전하게 소통하고 싶어하는 사람을 위해 설계되었습니다.\n\n이에는 다음이 포함됩니다:\n\n- 활동가\n- 저널리스트\n- 가정 폭력 생존자\n- 또는 직장이나 일상에서 추가적인 개인 정보 보호를 원하는 모든 사람\n\n# Tails의 장점은 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n\"테일즈는 The 'Amnesic' Incognito Live System의 약자입니다.\n\nUSB 스틱이나 DVD를 사용하여 컴퓨터의 원래 운영 체제와 독립적으로 실행되도록 설계된 운영 체제입니다.\n\n일반적인 운영 체제에서는 수행한 작업들이 컴퓨터에 자취를 남깁니다.\n\n이러한 자취에는 —\"\n\n<div class=\"content-ad\"></div>\n\n- 은익 모드에서 브라우저에서 열린 링크\n- 삭제된 파일\n- 비밀번호 관리자에 저장된 비밀번호\n- 연결된 네트워크\n\n하지만 Tails에는 해당되지 않습니다.\n\n작동 방식은 다음과 같습니다:\n\n- 본인 또는 다른 사람의 컴퓨터를 다시 시작합니다.\n- TailsOS를 포함한 USB 드라이브/ DVD로 컴퓨터를 부팅합니다.\n- 컴퓨터에서 작업을 수행합니다.\n- 작업을 마치고 컴퓨터를 종료하면 트레이스가 전혀 남지 않고 모든 작업이 자동으로 삭제됩니다!\n\n<div class=\"content-ad\"></div>\n\n테일즈는 하드 디스크에 아무것도 쓰지 않고 컴퓨터의 메모리에서만 실행됩니다.\n\n이 메모리는 컴퓨터를 종료할 때 완전히 지워집니다.\n\n하지만 컴퓨터가 꺼진 후에 메모리(RAM)에 있는 데이터는 빠르게 사라지지만 종료 후 몇 분 동안 그대로 남을 수 있다는 사실을 알고 계셨나요?\n\n메모리에 중요한 데이터가 남아 있는 상태에서 공격자가 컴퓨터에 접근한다면 세션에서 중요한 데이터를 복구할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n치명적인 것으로 알려진 것이 있습니다. \n\n테일즈는 이러한 종류의 사이버공격으로부터 당신을 보호합니다. 종료할 때 램 데이터를 임의 데이터로 덮어씌움으로써 이를 방지합니다.\n\n이로써 해당 컴퓨터에서의 세션에 대한 모든 흔적을 지우게 됩니다.\n\n# 인터넷 상에서의 흔적에 대해서는 어떻게 생각하세요?\n\n<div class=\"content-ad\"></div>\n\n테일즈 OS는 모든 통신에 Tor 네트워크를 사용합니다.\n\nTor는 세계 각지에 위치한 서로 다른 업체가 소유한 3개의 릴레이 서버를 통해 연결을 암호화하고 익명화합니다.\n\n당신이 있는 나라에서 Tor가 차단되거나 사용하기 위험할 때도 Tor 브릿지를 사용하여 Tor 네트워크에 연결되었다는 사실을 숨길 수 있습니다.\n\n# 몇 가지 더 멋진 (그리고 안전한) 기능\n\n<div class=\"content-ad\"></div>\n\n- 지속적인 저장: 부팅 가능한 USB 스틱에서 파일을 암호화하여 보관하고 싶은 파일이 사라지지 않도록 안전하게 보관할 수 있습니다.\n- Tor 브라우저와 uBlock: 통합 광고 차단 기능으로 안전한 탐색 경험을 제공합니다.\n- Thunderbird: 암호화된 이메일을 보내고 받을 수 있게 합니다.\n- KeePassXC: 강력한 비밀번호 생성 및 저장을 지원합니다.\n- LibreOffice: MS Office와 유사한 포괄적인 오피스 스위트입니다.\n- OnionShare: Tor 네트워크를 통해 파일을 공유할 수 있게 해줍니다.\n- Metadata Cleaner 및 mat2: 공유하거나 저장하는 파일에서 메타데이터를 제거하는 데 도움을 줍니다.\n- Electrum: 사용하기 쉬운 비트코인 클라이언트/지갑입니다.\n- GNOME 스크린 키보드: 온스크린 키보드를 제공하여 키로거로부터 보호합니다.\n- Kleopatra: 인증서 관리자 및 범용 암호화 GUI로 사용됩니다.\n- GtkHash: 파일 무결성 확인을 위한 체크섬 계산을 가능하게 합니다.\n- Aircrack-ng: 무선 네트워크 감사에 사용됩니다.\n- Pidgin 및 OTR: 안전한 통신을 위한 암호화 메시징을 지원합니다.\n\n그리고 그 밖에 많은 기능들이 있습니다!\n\n# 하지만 설치와 사용이 쉬울까요?\n\n네! TailsOS를 설치하고 실행하는 것은 매우 쉽습니다.\n\n<div class=\"content-ad\"></div>\n\n얼마나 쉬웠나요?\n\n![image 0](/assets/img/2024-06-20-TailsOSAnOperatingSystemIWouldUseIfIWantedToDisappearFromTheWorld_0.png)\n\n![image 1](/assets/img/2024-06-20-TailsOSAnOperatingSystemIWouldUseIfIWantedToDisappearFromTheWorld_1.png)\n\nTailsOS 다운로드 페이지를 열고 컴퓨터에서 실행하는 데 20분이 걸렸어요.\n\n<div class=\"content-ad\"></div>\n\n# 잘못 될 수 있는 일들\n\n테일즈는 개인정보 보호를 위해 정말 잘 설계되었지만 완벽하지는 않아요.\n\n여전히 익명성이 노출될 수 있어요 만약에:\n\n- 날짜, 시간, 위치 및 장치 정보와 같은 메타데이터가 포함된 파일을 공유한다면.\n- 여러 목적으로 동시에 Tails를 사용하는 경우, 공격자가 당신의 다른 활동을 연관시킬 수 있어요.\n- 사용 중인 Tor 회로에서 세 개의 릴레이를 모두 제어하는 공격자를 만나면, 그들이 당신을 식별할 가능성이 있어요.\n- compromise된 운영 체제에서 Tails를 설치하는 경우, 손상된 설치로 이어질 수 있어요.\n- 기기에 하드웨어 변경이 있는 경우, 당신의 신원을 노출시킬 수 있어요.\n- compromise된 BIOS 또는 펌웨어가 있는 컴퓨터에서 Tails를 실행하는 경우, 보안 침해를 초래할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n여기 내 개인 정보를 보호해주는 휴대용 운영 체제입니다.\n\n만약 여러분도 비슷한 것을 사용 중이라면 댓글로 알려주세요! 여러분이 인터넷에서 개인 정보 보호와 보안을 위해 취하는 다른 조치들도 궁금해요.\n\n![TailsOS](/assets/img/2024-06-20-TailsOSAnOperatingSystemIWouldUseIfIWantedToDisappearFromTheWorld_2.png)\n\n## 아래에서 내 Substack 뉴스레터를 구독하세요:","ogImage":{"url":"/assets/img/2024-06-20-TailsOSAnOperatingSystemIWouldUseIfIWantedToDisappearFromTheWorld_0.png"},"coverImage":"/assets/img/2024-06-20-TailsOSAnOperatingSystemIWouldUseIfIWantedToDisappearFromTheWorld_0.png","tag":["Tech"],"readingTime":4},{"title":"구름을 들어봤어요","description":"","date":"2024-06-20 14:24","slug":"2024-06-20-EverHeardOfTheCloud","content":"\n\n안녕하세요, 클라우드 열정가👋🏼💜\n\n![image](/assets/img/2024-06-20-EverHeardOfTheCloud_0.png)\n\n잠깐만요!\n\n혹시 클라우드 열정가가 아니신가요? 이 글을 우연히 발견하셨거나 왜 이 글을 아직도 읽고 계신지 이해가 안 가시는 분 일 수도 있겠네요.\n\n<div class=\"content-ad\"></div>\n\n그럼요 (손을 비벼들며 악의적인 웃음을 짓습니다), 만약 그렇다면, 구름이란 무엇인지 알려드릴게요.😌\n\n당신이 머릿속으로 그리는 것이 바로 “푸른 하늘”, 맞죠?\n\n아닙니다. 전혀 그렇지 않아요.\n\n오늘날의 디지턀 시대에 있어서, 구름이란 하늘의 한 곳뿐만이 아니라, 우리의 삶과 일하는 방식을 혁신하는 강력한 기술입니다.\n\n<div class=\"content-ad\"></div>\n\nWhatsApp부터 Instagram, Twitter (죄송해요, X🌚)까지 LinkedIn, Slack, TikTok, Discord...인터넷에 액세스하는 모든 것이 클라우드를 사용합니다.\n\n클라우드는 원격 서버에 비유될 수 있으며 데이터를 저장, 관리 및 처리하여 인터넷 연결만 있다면 어디서든 정보 및 응용프로그램에 쉽게 액세스할 수 있습니다. 심지어 화장실에서도요 (물론 인터넷 연결이 있는 경우).\n\n클라우드를 통해 보다 쉬운 협업, 유연성 및 비용 효율성이 가능해지며, 이로써 전 세계적으로 산업별 혁신을 촉진하고 혜택을 줍니다.\n\n그래서 여러분... 클라우드를 활용한 컴퓨팅의 미래로 여러분을 초대합니다! 🚀","ogImage":{"url":"/assets/img/2024-06-20-EverHeardOfTheCloud_0.png"},"coverImage":"/assets/img/2024-06-20-EverHeardOfTheCloud_0.png","tag":["Tech"],"readingTime":1},{"title":"리눅스의 Debian 또는 다른 리눅스에서 명령 줄을 사용하여 NerdFont또는 다른 글꼴을 설치해 보세요","description":"","date":"2024-06-20 14:23","slug":"2024-06-20-InstallNerdFontoranyfontsusingthecommandlineinDebianorotherLinux","content":"\n\n\n![이미지](/assets/img/2024-06-20-InstallNerdFontoranyfontsusingthecommandlineinDebianorotherLinux_0.png)\n\n요즘 LazyVim을 설치하고 있는데 NerdFonts를 설치해야 해요. 인터넷에서 알아보니 터미널을 사용해서 편하게 설치할 수 있다는 걸 알게 됐어요. 아래는 설치 방법입니다.\n\n- NerdFonts 웹사이트에 들어가서 원하는 글꼴을 다운로드 섹션에서 선택하세요.\n- 다운로드 버튼을 마우스 오른쪽 버튼으로 클릭하고 링크 주소 복사를 선택하세요 (브라우저에 따라 조금 다르지만 글꼴 링크를 얻는 건 중요합니다).\n- 터미널을 열어주세요.\n- 아래 명령어를 복사하신후 방금 복사한 링크로 업데이트해주세요.\n\n```js\nwget -P ~/.local/share/fonts https://github.com/ryanoasis/nerd-fonts/releases/download/v3.0.2/JetBrainsMono.zip \\\n&& cd ~/.local/share/fonts \\\n&& unzip JetBrainsMono.zip \\\n&& rm JetBrainsMono.zip \\\n&& fc-cache -fv\n```\n\n<div class=\"content-ad\"></div>\n\n그것이에요. 그것은 글꼴을 다운로드하고 설치할 것입니다.\n\n그런 다음, 효과를 보기 위해 LazyVim을 다시로드할 수 있어요.\n\n이 게시물이 유용했기를 바래요. 건배!","ogImage":{"url":"/assets/img/2024-06-20-InstallNerdFontoranyfontsusingthecommandlineinDebianorotherLinux_0.png"},"coverImage":"/assets/img/2024-06-20-InstallNerdFontoranyfontsusingthecommandlineinDebianorotherLinux_0.png","tag":["Tech"],"readingTime":1},{"title":"명령 줄 정복하기 필수 리눅스 CLI 명령어 9가지","description":"","date":"2024-06-20 14:22","slug":"2024-06-20-ConquertheCommandLine9EssentialLinuxCLICommands","content":"\n\n리눅스 명령줄 인터페이스(CLI)는 처음 보는 사람에게는 어렵게 보일 수 있습니다. 암호화된 텍스트와 깜박이는 커서가 기술 마법사들을 위해 예약된 것처럼 보입니다. 그러나 걱정하지 마세요! 이 복잡해 보이는 외부 아래에는 잠재력 가득한 강력한 도구가 숨어 있습니다. 필수 명령어 몇 가지만 습득하면 시스템을 쉽게 탐색하고 파일을 효율적으로 관리하며 작업을 자동화할 수 있습니다. 이 안내서는 여러분을 당혹스러운 초보자에서 숙련된 CLI 닌자로 변몽해주는 20가지 기본 리눅스 CLI 명령어로 여러분을 장비시킵니다.\n\n- pwd: 현재 위치 스카우트\n\n리눅스 시스템의 디렉토리 미로에 잃혀진 적이 있나요? pwd (print working directory)가 신뢰할 수 있는 스카우트처럼 도와줍니다. 이 명령은 즉시 현재 디렉토리의 절대 경로를 표시하여 방대한 파일 시스템 내에서 위치를 명확히 알 수 있게 해줍니다. 예를 들어 다운로드 폴더에서 문서를 작업 중이라고 상상해보세요. 터미널에 pwd를 입력하면 \"/home/사용자명/Downloads\"와 같은 내용이 나타납니다. 디지털 세계에서의 현재 위치가 엿보이는 것이죠.\n\n- cd: 정확히 이동하는 디렉토리 미로\n\n<div class=\"content-ad\"></div>\n\n복잡한 디렉터리 미로를 탐험하는 것은 cd(디렉터리 변경)로 간단합니다. 이 명령어와 목표 디렉터리 경로를 가지고 있으면 파일 시스템의 계층 구조를 순찰하며 원하는 위치로 정확하게 이동할 수 있습니다. 마치 마법의 순간이동 장치 같은 느낌이죠 – cd Documents를 입력하여 즉시 Documents 폴더로 전환하거나, /usr/local/bin을 입력하여 실행 가능한 프로그램을 포함한 시스템 디렉토리로 이동할 수 있습니다.\n\n- ls: 보물 지도처럼 디렉터리 내용 공개\n\n현재 디렉터리의 내용이 궁금한가요? ls(list)만큼 좋은 대답은 없습니다. 이 다재다능한 명령어는 보물 지도처럼 작용하여 현재 위치에 있는 파일 및 하위 디렉터리 목록을 공개합니다. 홈 디렉터리에서 ls를 입력하면 \"resume.docx\"와 \"Pictures\", \"Music\"과 같은 폴더가 파일 목록을 보여줄 수 있습니다. 그렇게 함으로써 저장된 내용에 대한 빠른 개요를 얻을 수 있습니다.\n\n- mkdir: 새 디렉터리 생성 — 디지털 요새 구축\n\n<div class=\"content-ad\"></div>\n\n파일 시스템의 조직적 경계를 확장하는 것은 mkdir (make directory)를 사용하면 간단합니다. 이 명령어를 사용하면 새 디렉토리를 만들어 파일과 프로젝트를 보관할 구조적인 계층을 만들 수 있습니다. 디지털 요새를 건설하는 것과 같습니다. mkdir projects를 사용하여 작업용 새 폴더를 만든 다음 mkdir projects/webdev를 사용하여 웹 개발 프로젝트를 위한 하위 폴더를 만들어보세요.\n\n- touch: 빈 파일 생성 — 플레이스홀더 마법\n\ntouch를 사용하면 빈 파일을 손쉽게 생성할 수 있습니다. 이 명령어는 디지털 완드와 같이 작동하여 빈 파일을 만들어냅니다. 이 파일들은 미래 콘텐츠를 위한 플레이스홀더로 사용하거나 조직적 목적을 위한 표식으로도 활용할 수 있습니다. 새 프로젝트를 계획 중이지만 아직 콘텐츠가 준비되지 않았다면 touch README.md를 사용하여 아직 내용을 작성하지 않아도 프로젝트 readme를 위한 빈 파일을 만들어보세요.\n\n- cp: 복제 마법 — 파일 복제의 기술\n\n<div class=\"content-ad\"></div>\n\n파일 복제는 cp (복사)로 아주 간단합니다. 이 명령은 복제의 마스터로 파일 또는 전체 디렉토리를 매끄럽게 복제하여 백업, 배포 또는 여러분의 편의를 위해 복사본을 만들 수 있습니다. 다른 채용 지원을 위해 이력서 복사본이 필요하다고 상상해보세요. cp resume.docx backup_resume.docx를 사용하여 다른 이름으로 복제본을 만들어보세요.\n\n- mv: 이름 변경 및 이동 - 두 마리 트릭 포니\n\n파일 이름 바꾸기와 디렉토리 간 이동은 mv (이동/이름 바꾸기)로 아주 간단합니다. 이 다재다능한 명령은 두 마리 트릭 포니처럼 작동하여 파일에 새로운 이름을 부여하거나 파일을 파일 시스템 내에서 더 적합한 위치로 옮길 수 있습니다. \"report_draft.docx\"란 이름의 문서를 작업 중이라면 mv report_draft.docx final_report.docx를 사용하여 이름을 변경하세요. 다른 폴더로 이동해야 한다면 mv final_report.docx /home/username/Documents를 사용하여 이동하세요.\n\n- cat: 파일 내용 공개 - 텍스트 보관소 내부 엿보기\n\n<div class=\"content-ad\"></div>\n\n텍스트 파일 내용을 별도의 편집기를 열지 않고 엿보고 싶나요? cat (concatenate)이 여러분의 동반자가 될 거예요. 이 명령은 열고자 하는 파일의 텍스트 보관고를 열고 해당 내용을 원시 상태 그대로 터미널 화면에 표시해줍니다. important_message.txt라는 파일의 내용을 읽고 싶다면 cat important_message.txt를 사용하세요.\n\n- grep: 텍스트의 심층을 탐험하라 — 텍스트 탐정\n\n파일 내에서 특정 텍스트 단편을 발굴하는 것은 grep(global search for regular expression)를 통해 가능한 강력한 작업입니다. 이 명령은 파일을 한 줄씩 꼼꼼히 살펴가며 지정한 패턴의 인스턴스를 찾아내는데, 당신을 텍스트 탐정으로 변신시켜줍니다. 마치 여러분이 파일을 뒤져가는 듯한 생각이 들지 않나요?","ogImage":{"url":"/assets/img/2024-06-20-ConquertheCommandLine9EssentialLinuxCLICommands_0.png"},"coverImage":"/assets/img/2024-06-20-ConquertheCommandLine9EssentialLinuxCLICommands_0.png","tag":["Tech"],"readingTime":3},{"title":"Docker 컨테이너의 심층 탐구  아키텍처와 기능","description":"","date":"2024-06-20 14:21","slug":"2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures","content":"\n\n\n![Container Architecture](/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_0.png)\n\n# 개요\n\n컨테이너는 코드와 모든 의존성을 포장하여 응용 프로그램이 한 컴퓨팅 환경에서 다른 환경으로 빠르고 신뢰성 있게 실행되도록 하는 표준 소프트웨어 단위입니다. VM과의 주요 차이점은 컨테이너가 자체 완전한 OS를 필요로하지 않는다는 것입니다. 사실, 동일 호스트의 모든 컨테이너는 호스트의 OS를 공유합니다. 이로써 CPU, RAM 및 저장소와 같은 대규모 시스템 리소스가 확보됩니다.\n\n![Container Features](/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_1.png)\n\n\n<div class=\"content-ad\"></div>\n\n컨테이너는 시작 속도가 빠르고 매우 휴대적입니다. 노트북에서 클라우드로 컨테이너 워크로드를 이동하고, 그리고 VM이나 데이터 센터의 베어 메탈로 이동하는 것도 쉽습니다.\n\n마이크로소프트는 윈도우 플랫폼에 Docker와 컨테이너 기술을 도입하기 위해 매우 노력했습니다. 그러나, 윈도우 컨테이너를 개발하는 데 모든 노력을 기울였지만, 대부분의 컨테이너는 Linux 컨테이너입니다. 이는 Linux 컨테이너가 더 작고 빠르기 때문이며, 대부분의 도구가 Linux용으로 제공되기 때문입니다.\n\n# Docker 기술\n\n대부분의 사람들이 Docker에 대해 이야기할 때, 그들은 컨테이너를 실행하는 기술을 의미합니다. 그러나 Docker 기술이라고 언급할 때 주의해야 할 적어도 세 가지 사항이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 런타임\n- 데몬 (엔진)\n- 오케스트레이터\n\n![Diagram](/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_2.png)\n\n이 다이어그램을 살펴보겠습니다:\n\n- 런타임은 가장 낮은 수준에서 작동하며 컨테이너의 시작 및 중지를 담당합니다(이 과정에는 namespaces 및 cgroups와 같은 모든 OS 구성요소를 작성하는 것이 포함됩니다).\n- 하위 수준 런타임은 runc라고 하며 Open Containers Initiative (OCI) 런타임 사양의 참조 구현입니다. 그 역할은 기저 OS와 상호 작용하고 컨테이너를 시작 및 중지하는 것입니다. Docker 노드의 모든 컨테이너는 runc의 인스턴스에 의해 생성되고 시작되었습니다.\n- 상위 수준 런타임은 containerd라고 합니다. 이것은 이미지를 가져오고 runc 인스턴스를 관리하는 등 전체 컨테이너 라이프사이클을 관리합니다.\n- 전형적인 Docker 설치에는 runc에게 컨테이너의 시작 및 중지를 지시하는 단일 장기 프로세스인 containerd 프로세스가 있습니다. runc는 장기 프로세스가 아니며 컨테이너가 시작되자마자 종료됩니다.\n- Docker 데몬 (dockerd)은 containerd 상위에 있으며 Docker API 노출, 이미지 관리, 볼륨 관리, 네트워크 관리 등과 같은 상위 수준 작업을 수행합니다. Docker 데몬의 주요 역할 중 하나는 하위 수준을 추상화하는 사용하기 쉬운 표준 인터페이스를 제공하는 것입니다.\n- Docker는 또한 Docker를 실행하는 노드 클러스터를 관리하기 위한 기본 지원을 제공합니다. 이 클러스터들을 Docker Swarm이라고 하며 해당 기술은 Docker Swarm입니다. Docker Swarm은 사용하기 쉽고 많은 회사가 실제 제품에서 사용하고 있습니다. Kubernetes보다 간단하게 설치하고 관리할 수 있지만, Kubernetes의 고급 기능과 생태계를 많이 포함하지는 않습니다.\n\n<div class=\"content-ad\"></div>\n\n# 도커 CLI 명령을 실행할 때 무슨 일이 벌어지나요\n\n도커를 설치하면 두 가지 주요 구성 요소를 얻게 됩니다:\n\n- 도커 클라이언트\n- 도커 엔진 (가끔 \"도커 데몬\"이라고도 함)\n\n엔진은 컨테이너를 실행하는 데 필요한 런타임, API 및 기타 모든 것을 구현합니다. 기본적인 리눅스 설치에서 클라이언트는 /var/run/docker.sock에있는 로컬 IPC/Unix 소켓을 통해 데몬과 통신합니다. 윈도우에서는 npipe:////./pipe/docker_engine을 통해 통신합니다.\n\n<div class=\"content-ad\"></div>\n\n\"Docker run\"과 같은 명령을 Docker CLI에 입력할 때:\n\n![image](/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_3.png)\n\n1. Docker 클라이언트는 이를 적절한 API 데이터로 변환하여 Docker 데몬이 노출한 API 엔드포인트에 POST합니다. API는 데몬에 구현되어 있으며 로컬 소켓(리눅스 및 Windows에 대해 앞서 언급한 것과 같이) 또는 네트워크를 통해 노출될 수 있습니다.\n\n2. 데몬이 새 컨테이너를 생성하는 명령을 받으면, containerd에 요청합니다. 더 이상 데몬에는 컨테이너를 생성하는 코드가 포함되어 있지 않습니다! 데몬은 gRPC를 통해 CRUD 스타일 API를 통해 containerd와 통신합니다.\n\n<div class=\"content-ad\"></div>\n\n3. 이름에서 알 수 있듯이 containerd는 실제로 컨테이너를 만들 수 없어요. 그 작업은 runc가 처리해요. containerd는 필요한 Docker 이미지를 OCI 번들로 변환하고 이를 사용하여 새 컨테이너를 만들도록 runc에 알려줍니다.\n\n4. runc은 OS 커널과 상호작용하여 컨테이너를 만들기 위해 필요한 모든 구성요소(네임스페이스, cgroups 등)를 모아냅니다. 컨테이너 프로세스는 runc의 하위 프로세스로 시작되며 시작되자마자 runc는 종료됩니다.\n\n데몬으로부터 컨테이너 시작 및 관리 로직 및 코드를 모두 제거함으로써 전체 컨테이너 런타임이 Docker 데몬으로부터 분리되었습니다. 때로는 이를 \"데몬 없는 컨테이너\"라고 부르며, Docker 데몬을 유지보수 및 업그레이드할 때 실행 중인 컨테이너에 영향을주지 않도록 합니다.\n\n이전 모델에서는 모든 컨테이너 런타임 로직이 데몬에 구현된 곳에서 데몬을 시작하고 중지하면 호스트의 모든 실행 중인 컨테이너가 제거되었습니다. 이것은 프로덕션 환경에서 큰 문제였어요.\n\n<div class=\"content-ad\"></div>\n\n# 네임스페이스, cgroups 및 쉼은 무엇인가요?\n\n**쉼**\n\n위 다이어그램에서 쉼이라는 구성 요소를 주목했을 것입니다.\n\n쉼은 데몬 없는 컨테이너의 구현에 필수적입니다 - 데몬 업그레이드와 같은 작업을 위해 실행 중인 컨테이너와 데몬을 분리하는 것을 방금 언급한 것입니다.\n\n<div class=\"content-ad\"></div>\n\n우리는 이전에 containerd가 새로운 컨테이너를 만들 때 runc를 사용한다고 언급했습니다. containerd는 생성되는 각 컨테이너에 대해 runc의 새로운 인스턴스를 포크합니다. 그러나 각 컨테이너가 생성되면 runc 프로세스가 종료됩니다. 이는 수백 개의 컨테이너를 실행할 수 있지만 수백 개의 runc 인스턴스를 실행할 필요가 없다는 것을 의미합니다. 컨테이너의 부모인 runc 프로세스가 종료되면 관련된 containerd-shim 프로세스가 컨테이너의 부모가 됩니다.\n\n컨테이너의 부모인 shim이 수행하는 책임 중 일부는 다음과 같습니다:\n\n- 데몬이 다시 시작되어도 컨테이너가 파이프가 닫히는 등의 이유로 종료되지 않도록 STDIN 및 STDOUT 스트림을 열어두는 것\n- 컨테이너의 종료 상태를 데몬에 다시 보고하는 것.\n\n네임스페이스\n\n<div class=\"content-ad\"></div>\n\n커널 네임스페이스는 컨테이너를 구축하는 데 사용되는 주요 기술입니다. 이 기술은 하이퍼바이저가 물리 자원(예: CPU 및 디스크)을 가상화하는 방식과 같이 운영 체제 구성 요소인 프로세스 트리와 파일 시스템을 가상화합니다.\n\n컨테이너 모델에서 네임스페이스는 가상 프로세스 트리, 가상 파일 시스템 및 가상 네트워크 인터페이스와 같은 것들을 묶어 가상 운영 체제를 생성합니다. 각 가상 운영 체제는 컨테이너라고 불리며 일반적인 운영 체제와 똑같이 보이고 느껴집니다.\n\n이 가상 운영 체제(\"컨테이너\")를 사용하면 동일한 호스트에서 여러 웹 서버를 포트 충돌 없이 실행할 수 있는 멋진 기능을 제공합니다. 또한 동일한 호스트에서 여러 앱을 실행하면서 공유 구성 파일 및 라이브러리 간의 충돌 문제를 피할 수 있습니다.\n\n![image](/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_4.png)\n\n<div class=\"content-ad\"></div>\n\n리눅스의 도커는 현재 다음 커널 네임스페이스를 활용합니다:\n\n- 프로세스 ID (pid)\n- 네트워크 (net)\n- 파일 시스템/마운트 (mnt)\n- 프로세스 간 통신 (ipc)\n- 사용자 (user)\n- UTS (uts)\n\n그러나 가장 중요한 것은 컨테이너가 네임스페이스의 조직화된 모음이라는 점을 이해하는 것입니다. 예를 들어, 각 컨테이너는 자체 pid, net, mnt, ipc, uts 및 아마도 사용자 네임스페이스를 갖습니다. 실제로 이러한 네임스페이스의 조직화된 모음을 우리는 \"컨테이너\"라고 부릅니다.\n\n호스트는 \"루트 네임스페이스\"라고 하는 자체 네임스페이스 모음을 갖고 있습니다. 각 컨테이너에는 격리된 네임스페이스 모음이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_5.png\" />\n\n지배 그룹 (cgroups)\n\n네임스페이스가 격리에 관한 것이라면, 제어 그룹(cgroups)은 제한에 관한 것입니다. 컨테이너를 호텔의 객실과 유사하다고 생각해보세요. 각각의 객실은 격리되어 있는 것처럼 보일 수 있지만, 모든 객실은 공통의 인프라 자원을 공유합니다. 즉, 수도 공급, 전기 공급, 수영장, 체육관, 엘리베이터, 조식 바와 같은 것들입니다.\n\nCgroups를 사용하면 (호텔 비유를 계속 사용할 때) 단일 컨테이너가 모든 물을 사용하거나 조식 바에서 모든 음식을 다 먹는 것을 막을 수 있습니다. 실제 세계에서 호텔 비유가 아닌 컨테이너는 서로 격리되어 있지만 CPU, RAM, 네트워크 및 디스크 I/O와 같은 공통의 리소스를 공유합니다. Cgroups를 사용하면 단일 컨테이너가 모든 리소스를 소비하고 서비스 거부(DoS) 공격을 유발하지 못하게 제한을 설정할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 보안 계층 개요\n\n모든 좋은 컨테이너 플랫폼은 이름 공간과 cgroups를 사용하여 컨테이너를 구축합니다. 최상의 컨테이너 플랫폼은 기능(Capabilities), SELinux 및 AppArmor와 같은 의무적 접근 제어 시스템, 그리고 seccomp과 같은 다른 리눅스 보안 기술과 통합됩니다. 당연히 Docker도 이러한 기술들과 통합됩니다.\n\n![이미지](/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_6.png)\n\n이미 지네임스페이스와 cgroups에 대해 논의했지만, 살펴볼 사항이 더 많습니다. 더 자세히 알아보고 싶다면 제공된 출처를 사용해보세요.\n\n<div class=\"content-ad\"></div>\n\n소스: What is a Container? | Docker\nNigel Poulton의 \"Docker Deep Dive\"","ogImage":{"url":"/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_0.png"},"coverImage":"/assets/img/2024-06-20-DeepDiveintoDockerContainersArchitectureandFeatures_0.png","tag":["Tech"],"readingTime":6},{"title":"유닉스 리눅스 wc 도구 만들기 최종 파트 표준 입력 지원 추가하기","description":"","date":"2024-06-20 14:20","slug":"2024-06-20-BuildingUnixLinuxwcToolFinalPartAddingSupportforStandardInput","content":"\n\n<img src=\"/assets/img/2024-06-20-BuildingUnixLinuxwcToolFinalPartAddingSupportforStandardInput_0.png\" />\n\n지금까지 시리즈의 이전 부분을 읽지 않으셨다면, 먼저 읽어보시는 것을 권장합니다 :)\n\n1. Part I: 이 부분에서는 wccommand의 기본 구성, 파일 크기 계산만을 지원하는 데 중점을 뒀습니다.\n   \n2. Part II: Part II에서는 라인 카운터 플래그를 지원하도록 추가하는 데 중점을 뒀습니다.\n\n<div class=\"content-ad\"></div>\n\n3. Part III: 이번 글은 최신 글로, 단어 카운터 플래그를 지원하는 데 초점을 맞추었습니다.\n\n이제 현재 목표로 돌아가 봅시다. 이 목표에는 두 단계가 있습니다:\n\n- 기본 옵션을 지원하는 것, 즉 어떤 옵션이 제공되지 않았을 때입니다. 이는 -c, -l 및 -w 옵션과 동등합니다.\n\n```js\ngo run main test.txt\n// 결과: 7145   58164  342190 test.txt\n```\n\n<div class=\"content-ad\"></div>\n\n- 입력 파일 이름이 지정되지 않은 경우 표준 입력에서 읽어 들일 수 있는 지원 추가\n\n```js\ncat test.txt | go run main.go -l\n// 결과: 7145\n```\n\n## 1. 기본 옵션 지원\n\n파일 내 라인 수, 단어 수 등을 얻는 서로 다른 로직을 처리하는 함수가 이미 있었습니다. 이 목표를 달성하기 위한 접근 방법은 ProcessFile 함수에 콜백 함수를 전달하여 파일의 바이트 수, 파일 내 라인 수 및 파일 내 단어 수를 얻는 데 책임이 있는 세 가지 함수를 호출하고 그 결과를 출력하는 것이었습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nProcessFile(args[0], func(s string) {\n    byteNumber := getByteNumber(&s, nil)\n    lineNumber := getNumberOfLines(&s, nil)\n    wordNumber := countWords(s)\n\n    fmt.Println(byteNumber, lineNumber, wordNumber, s)\n})\n```\n\n## 2. 표준 입력 지원\n\n이 목표를 달성하는 것은 조금 복잡했습니다. 이전 구현에서 빈 플래그를 가져올 수 없는 이유를 알아내려고 몇 시간을 보냈습니다.\n\n다음 코드를 고려해보겠습니다. 이 코드는 파일의 바이트 수를 얻는 데 사용되는 c 플래그를 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nbyteNumber := flag.String(byteNumberFlag, \"\", \"파일 바이트 수를 얻는 플래그\")\n```\n\n만약 플래그에 어떤 인자도 전달하지 않는다면, 해당 플래그의 기본값을 빈 문자열로 설정했기 때문에 빈 문자열이 반환될 것으로 생각했습니다. 그러나 실제 상황은 다릅니다. 파싱 로직에서, 플래그에 인자가 없는 경우 flag.Parse는 자동으로 도움말 플래그가 있는 경우 해당 플래그를 반환하거나, 2의 종료 상태를 갖는 패닉을 발생시키도록 구현되어 있습니다.\n\n이 문제에 직면하여, 파싱하기 전에 인수에 액세스할 다른 방법을 찾았습니다. 표준 라이브러리인 os의 도움을 통해 예상보다 쉽게 해결했습니다. 접근 방식은 다음과 같습니다:\n\n- 입력 파일을 스캔하고 해당 내용을 반환합니다.\n- 전달된 인수를 가져옵니다.\n- 전달된 인수의 길이를 확인합니다.\n- 길이가 하나인 경우, 다른 플래그와 비교합니다.\n- 각 플래그에 대해 해당 함수를 실행합니다.\n\n<div class=\"content-ad\"></div>\n\n```go\n// 명령줄 인수 가져오기\nargs := os.Args[1:]\n\nif len(args) == 1 { // 정확히 하나의 인수가 제공되었는지 확인\n    // 플래그의 \"-\" 문자를 피하기 위해 단일 인수의 마지막 문자를 가져와서 플래그를 결정\n    flag_ := args[0][len(args[0])-1:]\n\n    // 플래그 값에 따라 다른 경우 처리\n    switch flag_ {\n    case byteNumberFlag: // 바이트 수 세는 경우\n        // 표준 입력에서 읽기\n        stdin := handleStandardInput()\n        fmt.Println(getByteNumber(nil, &stdin))\n    case linesCounterFlag: // 줄 수 세는 경우\n        stdin := handleStandardInput()\n        fmt.Println(getNumberOfLines(nil, &stdin))\n    case wordsCounterFlag: // 단어 수 세는 경우\n        stdin := handleStandardInput()\n        wordsSlice := strings.Fields(stdin)\n        fmt.Println(len(wordsSlice))\n    case characterCounterFlag: // 문자 수 세는 경우\n        stdin := handleStandardInput()\n        // 입력의 UTF-8 룬 수 세기\n        runes := utf8.RuneCountInString(stdin)\n        fmt.Println(runes)\n    default: // 파일 처리의 기본 경우\n        ProcessFile(args[0], func(s string) {\n            byteNumber := getByteNumber(&s, nil)\n            lineNumber := getNumberOfLines(&s, nil)\n            wordNumber := countWords(s)\n\n            // 바이트, 줄, 단어 수를 문자열과 함께 출력\n            fmt.Println(byteNumber, lineNumber, wordNumber, s)\n        })\n    }\n    return // 인수 처리 후 종료\n}\n```\n\n참고: 이 마지막 단계를 작동하도록 도우미 함수에 일부 변경을 가했습니다.\n\n읽어주셔서 감사합니다! 다음 도전에 주목해주세요. 이 도전의 전체 소스 코드는 여기에서, 도전 설명은 여기에서 찾을 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-BuildingUnixLinuxwcToolFinalPartAddingSupportforStandardInput_0.png"},"coverImage":"/assets/img/2024-06-20-BuildingUnixLinuxwcToolFinalPartAddingSupportforStandardInput_0.png","tag":["Tech"],"readingTime":4},{"title":"시스템디 systemd를 사용하여 리눅스 서비스 만들기","description":"","date":"2024-06-20 14:19","slug":"2024-06-20-CreatingaLinuxservicewithsystemd","content":"\n\n\n![이미지](/assets/img/2024-06-20-CreatingaLinuxservicewithsystemd_0.png)\n\n웹 애플리케이션을 작성하는 동안, 계산이 많이 드는 작업을 비동기식 작업자 스크립트로 옮기거나 나중에 작업을 예약하거나, 심지어 클라이언트와 직접 통신하기 위해 소켓을 수신하는 데몬을 작성해야 하는 경우가 종종 있습니다.\n\n가끔 더 나은 도구가 있을 수도 있지만—항상 기존 소프트웨어를 먼저 사용하는 것을 고려하십시오—직접 서비스를 작성함으로써 제약사항에 바인딩되어 있을 때 얻을 수 없는 유연성을 얻을 수 있습니다.\n\n멋진 점은 리눅스 서비스를 만들기가 상당히 쉽다는 것입니다: 원하는 프로그래밍 언어로 장기 실행 프로그램을 작성하고, systemd를 사용하여 서비스로 변환하십시오.\n\n\n<div class=\"content-ad\"></div>\n\n# 프로그램\n\nPHP를 사용하여 작은 서버를 만들어 봅시다. 놀라실 거예요, 하지만 상당히 잘 작동합니다. UDP 포트 10000에서 수신 대기하고, 받은 메시지를 ROT13 변환하여 반환할 거에요.\n\n시작해 볼까요?\n\n```js\n$ php server.php\n```\n\n<div class=\"content-ad\"></div>\n\n그리고 다른 터미널에서 테스트해보세요:\n\n```js\n$ nc -u 127.0.0.1 10000\nHello, world!\nUryyb, jbeyq!\n```\n\n와우, 잘 작동하네요. 이제 우리는 이 스크립트가 항상 실행되도록 하고, 실패(예기치 않은 종료)할 경우 다시 시작되며 서버 재부팅 후에도 살아남을 수 있기를 원합니다. 그럴 때 systemd가 필요합니다.\n\n# 서비스로 변경\n\n<div class=\"content-ad\"></div>\n\n/etc/systemd/system/rot13.service이라는 파일을 만들어보겠습니다:\n\n```js\n[Unit]\nDescription=ROT13 데모 서비스\nAfter=network.target\nStartLimitIntervalSec=0\n\n[Service]\nType=simple\nRestart=always\nRestartSec=1\nUser=여러분의_사용자이름\nExecStart=/usr/bin/env php /스크립트/경로/server.php\n\n[Install]\nWantedBy=multi-user.target\n```\n\n다음을 수행해야 합니다:\n- User= 뒤에 실제 사용자 이름 설정하기\n- ExecStart=에 스크립트의 적절한 경로 설정하기\n\n<div class=\"content-ad\"></div>\n\n그게 다에요. 이제 서비스를 시작할 수 있어요:\n\n```js\n$ systemctl start rot13\n```\n\n그리고 부팅 시 자동으로 시작되도록 설정할 수 있어요:\n\n```js\n$ systemctl enable rot13\n```\n\n<div class=\"content-ad\"></div>\n\n# 더 나아가기\n\n이제 서비스가 (아마도) 작동되므로 구성 옵션을 조금 더 심층적으로 탐색하여 항상 예상대로 작동하는지 확인하는 것이 중요할 수 있습니다.\n\n## 올바른 순서로 시작하기\n\nAfter= 지시문이 무엇을 하는 지 궁금해할 수도 있습니다. 이는 단순히 서비스가 네트워크가 준비되자마자 시작되어야 한다는 것을 의미합니다. 만약 프로그램이 MySQL 서버가 가동되고 작동 중인 것을 기대한다면 다음을 추가해야 합니다:\n\n<div class=\"content-ad\"></div>\n\n\n## 종료 시 재시작\n\n기본적으로 systemd는 프로그램이 어떤 이유로든 종료되면 서비스를 다시 시작하지 않습니다. 일반적으로 항상 사용 가능해야 하는 서비스에 대해 원하는 동작이 아니므로 종료 시 항상 다시 시작하도록 지시합니다:\n\n```js\nRestart=always\n``` \n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 바꿀 수도 있어요.\n\n<div class=\"content-ad\"></div>\n\n저는 개인적으로 이 부분에 두 번 이상 빠져들었어요. 기본적으로 우리가 하는 것처럼 Restart=always를 설정하면 systemd가 서비스가 10초 간격 내에 5번 이상 시작하지 못하면 다시 시작하는 것을 포기합니다. 영원히요.\n\n이에 대한 두 가지 [Unit] 구성 옵션이 있어요:\n\n```js\nStartLimitBurst=5\nStartLimitIntervalSec=10\n```\n\n또한 RestartSec 지시문은 결과에 영향을 줍니다: 3초 후에 다시 시작하도록 설정하면 10초 내에 5번의 실패한 재시도에 도달할 수 없어요.\n\n<div class=\"content-ad\"></div>\n\n항상 작동하는 간단한 해결책은 StartLimitIntervalSec=0로 설정하는 것입니다. 그렇게 하면 systemd가 서비스를 영원히 다시 시작하려고 시도할 것입니다.\n\n그러나 너무 많은 스트레스를 서버에 가하지 않기 위해 RestartSec를 적어도 1초로 설정하는 것이 좋습니다.\n\n대안으로는 기본 설정을 그대로 두고 StartLimitAction=reboot를 사용하여 시작 제한이 도달했을 때 systemd에 서버를 다시 시작하도록 요청할 수 있습니다.\n\n# 정말 그게 다인가요?\n\n<div class=\"content-ad\"></div>\n\n요즘에는 RHEL/CentOS, Fedora, Ubuntu, Debian 등에서 systemd가 기본 init 시스템으로 사용되고 있으므로, 아마도 귀하의 서버는 홈브류 서비스를 호스팅할 준비가 되어 있을 겁니다!","ogImage":{"url":"/assets/img/2024-06-20-CreatingaLinuxservicewithsystemd_0.png"},"coverImage":"/assets/img/2024-06-20-CreatingaLinuxservicewithsystemd_0.png","tag":["Tech"],"readingTime":3},{"title":"제목 Debian12에서 자체 호스팅 Kubernetes 스택 만들기 및 kube-prometheus-stack로 모니터링하기","description":"","date":"2024-06-20 14:13","slug":"2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack","content":"\n\n아래는 가정에서 Debian12 서버에서 Proxmox에 세 개 노드 Kubernetes 클러스터를 구축하는 지침입니다.\n\n이 문서의 목적은 저희가 집에서 실행 중인 도커 서비스를 도커에서 Kubernetes 클러스터로 옮기고 kube-Prometheus-stack을 사용하여 전체 시스템을 모니터링하고 경보를 설정하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이 가이드는 저에게 도움이 되었고, 웹의 다양한 위치에서 뽑았습니다 (모든 참고자료는 아래에 있습니다).\n\n# 3 노드 클러스터 구축하기\n\n## 소개\n\n모든 것은 어디선가 시작되어야 하며, Kubernetes로 테스트/실행할 환경을 갖고 있는 것은 좋은 생각입니다. 하이퍼스케일러와 같은 타사 업체들은 인그레스와 영구 저장소가 모두 설정된 환경을 제공해줄 것입니다. 하지만 아래 정보는 Debian 12를 사용하여 로컬 베어 메탈 테스트 환경을 만드는 데 사용됩니다. 제 경우에는 Proxmox에서 가상 플랫폼을 사용하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n안녕하세요!\n\n위의 내용을 한국어로 번역해 드리겠습니다.\n\n참고:\n\n이 작업은 이상적으로는 Ansible 코드로 실행되어야 하지만, 저는 아직 Ansible 코드를 작성하는 데 시간을 들이지 못해 수동 단계를 여기에 남겼습니다.\n\n## 빌드\n\n## 요구 사항\n\n도움이 되었기를 바랍니다. 추가로 도와드릴 내용이 있으면 언제든지 말씀해 주세요.\n\n<div class=\"content-ad\"></div>\n\n3대의 서버가 구축되어 실행 중이며 다음과 같은 사양을 갖추고 있습니다.\n\n| 항목 | 설명 | 비고 |\n|---|---|---|\n| OS | Debian 12 | |\n| CPU/vCPU | 4 | 최소 2 |\n| RAM | 4GB | 최소 2GB |\n| 디스크 | 100GB | 최소 20GB |\n| IP | 정적 | DHCP 예약 |\n| 기타 | 각 노드는 다른 노드의 IP에 핑을 보낼 수 있습니다. |\n\n## 서버 설정\n\n이 환경에서는 다음과 같이 3대의 서버가 설정되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\nMaster Node - kube-master - 10.10.0.100 \nWorker Node 1 - kube-worker01 - 10.10.0.101 \nWorker Node 2 - kube-worker02 - 10.10.0.102\n\n\n## 기본 OS 설정\n\n다음 명령어는 기본 OS 설정을하고 로컬 DNS와 통신하는 데 사용됩니다.\n\n외부 DNS 설정이있는 경우이를 사용하십시오. 이것은 테스트 환경이므로 서버가 어느 정도 자립 할 수 있도록하려고합니다.\n\n<div class=\"content-ad\"></div>\n\n## sudo 설치\n\nDebian 12에는 기본으로 sudo가 설치되어 있지 않습니다. 다음 단계를 따라 설치하고 사용자를 sudo 그룹에 추가하세요.\n\n```js\nsu -\napt install sudo\nusermod -aG sudo <사용자명>\n```\n\n## 호스트 이름 설정\n\n<div class=\"content-ad\"></div>\n\n```js\nkube-master - sudo hostnamectl set-hostname \"kube-master.local\" kube \nworker01 - sudo hostnamectl set-hostname \"kube-worker01.local\" kube \nworker02 - sudo hostnamectl set-hostname \"kube-worker02.local\"\n```\n\nSet /etc/hosts\n\nOn all three nodes run\n\n```js\nsudo nano /etc/hosts\n```\n\n<div class=\"content-ad\"></div>\n\n파일 끝에 다음을 추가해주세요\n\n```js\n10.10.0.100    kube-master.local    kube-master\n10.10.0.101    kube-worker01.local    kube-worker01\n10.10.0.102    kube-worker02.local    kube-worker02\n```\n\n## Swap 비활성화\n\nKubernetes는 Linux 스왑을 선호하지 않습니다. 모든 노드에서 스왑을 비활성화해주세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nsudo swapoff -a\nsudo sed -i '/ swap / s/^\\(.*\\)$/#\\1/g' /etc/fstab\n```\n\n## 방화벽\n\nUFW 또는 FirewallD가 기본적으로 설치되어 있지 않거나 활성화되어 있지 않습니다. 테스트 환경에서 실행하지 않았으므로 방화벽/UFW를 실행하려면 다음 명령을 실행하십시오. 이 가이드의 나머지 부분은 방화벽에 대해 다루지 않을 것입니다.\n\n마스터 노드에서 실행하세요.\n\n<div class=\"content-ad\"></div>\n\n```bash\nsudo ufw allow 6443/tcp\nsudo ufw allow 2379/tcp\nsudo ufw allow 2380/tcp\nsudo ufw allow 10250/tcp\nsudo ufw allow 10251/tcp\nsudo ufw allow 10252/tcp\nsudo ufw allow 10255/tcp\nsudo ufw reload\n```\n\nWorker Nodes,\n\n```bash\nsudo ufw allow 10250/tcp\nsudo ufw allow 30000:32767/tcp\nsudo ufw reload\n```\n\n## Containerd 설치하기\n\n<div class=\"content-ad\"></div>\n\nContainerd는 Kubernetes의 컨테이너 지원을 제공해요.\n\n이 명령어들은 모든 3개의 노드에서 실행되어야 해요.\n\n다음과 같은 커널 매개변수를 설정하세요\n\n```js\ncat <<EOF | sudo tee /etc/modules-load.d/containerd.conf\noverlay\nbr_netfilter\nEOF\n```\n\n<div class=\"content-ad\"></div>\n\n```shell\nsudo modprobe overlay\nsudo modprobe br_netfilter\ncat <<EOF | sudo tee /etc/sysctl.d/99-kubernetes-k8s.conf\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nEOF\n```\n\n위 변경 사항을 적용하세요.\n\n```shell\nsudo sysctl --system\n```\n\ncontainerd 패키지를 설치하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nsudo apt update\nsudo apt -y install containerd\n```\n\nKubernetes를 containerd를 사용하도록 설정합니다.\n\n```js\ncontainerd config default | sudo tee /etc/containerd/config.toml >/dev/null 2>&1\n```\n\n마지막 명령어로 생성된 config.toml을 systemd를 사용하도록 수정하세요.\n\n<div class=\"content-ad\"></div>\n\n```sh\nsudo nano /etc/containerd/config.toml\n```\n\n아래와 같이 변경해주세요.\n\n```sh\n‘SystemdCgroup = false’\n```\n\n<div class=\"content-ad\"></div>\n\n\n시스템디C그룹 = true\n\n\n저장하고 나가기\n\n컨테이너디 다시 시작 및 활성화\n\n\nsudo systemctl restart containerd\nsudo systemctl enable containerd\n\n\n<div class=\"content-ad\"></div>\n\n# Kubernetes 설정\n\n모든 노드에서 실행하세요\n\n## 리포지토리 추가\n\nKubernetes 패키지는 기본 리포지토리에 포함되어 있지 않으므로 추가해야 합니다\n\n<div class=\"content-ad\"></div>\n\n```js\n에코 \"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] <https://pkgs.k8s.io/core:/stable:/v1.28/deb/> /\" | sudo tee /etc/apt/sources.list.d/kubernetes.list\ncurl -fsSL <https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key> | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg\n```\n\n## Kube 도구 설치\n\n```js\nsudo apt update\nsudo apt install kubelet kubeadm kubectl -y\nsudo apt-mark hold kubelet kubeadm kubectl\n```\n\n# Kubernetes 클러스터 설치\n\n<div class=\"content-ad\"></div>\n\n과거에는 kubelet이 명령줄 옵션을 허용했지만, 이러한 기능이 제거되었고 이제 YAML 파일을 사용하여 입력 옵션을 제공합니다.\n\n마스터 노드에서만 실행하도록 설정해주세요.\n\n## kubelet.yaml 파일 생성\n\n홈 폴더에 파일을 생성하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\n나노 kubelet.yaml\n```\n\n다음 내용 추가\n\n```js\napiVersion: kubeadm.k8s.io/v1beta3\nkind: InitConfiguration\n---\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: \"1.28.0\" \ncontrolPlaneEndpoint: \"k8s-master\"\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n```\n\n참고:\n\n<div class=\"content-ad\"></div>\n\n라인 kubernetesVersion: \"1.28.0\"에는 더 최근 버전이 있을 수 있습니다. 1.30.0으로 시도해 봤지만 kube 패키지가 충분히 최신 상태가 아니라는 메시지를 받았습니다.\n\n## Kubernetes Cluster 초기화\n\n다음 명령어는 마스터 Kubernetes 노드를 설정합니다.\n\n마스터 노드에서만 실행하세요\n\n<div class=\"content-ad\"></div>\n\n```sh\nsudo kubeadm init --config kubelet.yaml\n```\n\n위와 같이 출력이 나와야 합니다.\n\n이와 유사한 출력은 마스터 노드에 성공적으로 제어 평면이 설치되었음을 확인합니다.\n\n참고:\n\n<div class=\"content-ad\"></div>\n\n## Kubectl 액세스 설정\n\n친구야, Kubernetes 제어 평면에 kubectl 명령어 액세스를 활성화하기 위해 다음 설정을 완료해야 돼.\n\n마스터 노드에서만 실행해.\n\n<div class=\"content-ad\"></div>\n\n루트(root)로 실행하지 마세요\n\n```js\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n## Kubectl 명령어 테스트\n\nkubectl 명령어를 테스트할 수 있습니다\n\n<div class=\"content-ad\"></div>\n\n마스터 노드에서만 실행되요 :)\n\n```js\nkubectl get nodes\nkubectl cluster-info\n```\n\n비슷한 출력이 표시돼요\n\n```js\nNAME                          STATUS   ROLES           AGE   VERSION\nk8s-master.safewebbox.com     Ready    control-plane   24h   v1.28.11\n```\n\n<div class=\"content-ad\"></div>\n\n그리고\n\n```js\nKubernetes 제어 평면은 <https://k8s-master:6443>에서 실행 중입니다.\nCoreDNS는 <https://k8s-master:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy>에서 실행 중입니다.\n```\n\n## 워커 노드를 클러스터에 연결\n\n이전에 마스터 노드에서 kubeadm init 명령을 실행했을 때 고유한 문자열이 포함된 kubectl join 명령이 제공되었습니다. 이 kubeadm join 명령이 지금 사용될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## Join Command\n\n워커 노드 01과 02에서 실행하세요\n\n참고\n\n당신의 명령어는 다를 것입니다. 이것을 그대로 복사하지 마세요. 이것은 마스터 노드에서의 출력을 예로 든 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nsudo kubeadm k8s-master:6443에 가입 --token 21nm87.x1lgd4jf0lqiiiau \\\\\n--discovery-token-ca-cert-hash sha256:28b503f1f2a2592678724c482776f04b445c5f99d76915552f14e68a24b78009\n```\n\n성공 메시지는 다음과 같이 표시됩니다.\n\n# 테스트 워커 노드가 올바르게 가입되었습니다.\n\n마스터 노드에서 실행하기\n\n<div class=\"content-ad\"></div>\n\n```js\nkubectl get nodes\n```\n\n위 명령어를 입력하면 다음과 유사한 출력이 반환됩니다.\n\n```js\nNAME                          STATUS   ROLES           AGE   VERSION\nk8s-master.safewebbox.com     Ready    control-plane   24시간   v1.28.11\nk8s-worker01.safewebbox.com   Ready    <none>          23시간   v1.28.11\nk8s-worker02.safewebbox.com   Ready    <none>          23시간   v1.28.11\n```\n\n# Pod Networking\n\n\n<div class=\"content-ad\"></div>\n\n친구야, \n팟 네트워킹, 프록시 등을 돕기 위해 calico를 설치해야 해요.\n\n## Calico 설치\n\n마스터 노드에서 실행하세요.\n\n```js\nkubectl apply -f <https://raw.githubusercontent.com/projectcalico/calico/v3.26.1/manifests/calico.yaml>\n```\n\n<div class=\"content-ad\"></div>\n\n## Calico 설치 확인\n\n마스터 노드에서 실행\n\n다음 명령을 실행하여 Calico를 위한 설정된 팟(컨테이너)을 확인하세요.\n\n```js\nkubectl get pods -n kube-system\n```\n\n<div class=\"content-ad\"></div>\n\n모든 파드의 실행 상태를 확인하려면 약 5분이 소요될 수 있습니다. 아래 명령어를 실행해 주세요.\n\n```js\nwatch kubectl get pods -n kube-system\n```\n\n이 명령어는 변경 사항이 있을 때 명령어의 출력을 업데이트해 줍니다.\n\n모든 파드가 실행 중일 때 준비됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n이름                                                준비됨   상태    재시작      나이\n**calico-kube-controllers-7ddc4f45bc-sfjh5            1/1     실행중   0             24시간\ncalico-node-r5x4f                                   1/1     실행중   0             24시간\ncalico-node-wqmdq                                   1/1     실행중   0             24시간\ncalico-node-x6r45                                   1/1     실행중   0**             24시간\ncoredns-5dd5756b68-2mkb7                            1/1     실행중   0             24시간\ncoredns-5dd5756b68-l4b7j                            1/1     실행중   0             24시간\netcd-k8s-master.safewebbox.com                      1/1     실행중   0             24시간\nkube-apiserver-k8s-master.safewebbox.com            1/1     실행중   0             24시간\nkube-controller-manager-k8s-master.safewebbox.com   1/1     실행중   3 (23시간 전)   24시간\nkube-proxy-5t2sj                                    1/1     실행중   0             24시간\nkube-proxy-89ldw                                    1/1     실행중   0             24시간\nkube-proxy-ckwl2                                    1/1     실행중   0             24시간\nkube-scheduler-k8s-master.safewebbox.com            1/1     실행중   3 (23시간 전)   24시간\n\n\n## 노드 확인\n\n마스터 노드에서 실행\n\n실행\n\n\n<div class=\"content-ad\"></div>\n\n```js\nkubectl get node\n```\n\n```js\n이름                         상태     역할            시간    버전\nk8s-master.safewebbox.com    준비     컨트롤 플레인    24시간 v1.28.11\nk8s-worker01.safewebbox.com  준비     <없음>          24시간 v1.28.11\nk8s-worker02.safewebbox.com  준비     <없음>          24시간 v1.28.11\n```\n\n# 원격 Kubernetes 클러스터에 로컬 액세스 설정하기\n\n## 사전 요구 사항\n\n<div class=\"content-ad\"></div>\n\n이 여정을 시작하기 전에 다음 사전 조건들을 갖추었는지 확인해주세요:\n\n- 실행 중인 쿠버네티스 클러스터: 원격 쿠버네티스 클러스터가 kubeadm을 사용하여 배포되어 운영 중인지 확인하세요.\n- 로컬에 kubectl 설치: 로컬 머신에 쿠버네티스 명령줄 도구인 kubectl을 설치하세요.\n- 로컬 머신에서 kube-master.local 서버로의 SSH 접근\n\n## 로컬 서버 설정\n\n로컬 머신에서\n\n<div class=\"content-ad\"></div>\n\n로컬 홈 폴더 아래에 .kube라는 폴더를 만들어 주세요.\n\n```bash\ncd\nmkdir .kube\n```\n\n## 클러스터 구성 가져오기\n\n로컬 머신에서\n\n<div class=\"content-ad\"></div>\n\n파일 admin.conf을 /etc/kubernetes/ 디렉토리에서 kube-master.local 서버로 가져와야 합니다.\n\nkube-master.local 서버의 원격 사용자가 user1이라고 가정하고 로컬 사용자가 해당 사용자로 kube-master.local에 ssh 할 수 있다면 다음 명령어를 사용해야 합니다.\n\n```js\nscp user1@kube-master.local:/etc/kubernetes/admin.conf .kube/config\n```\n\n참고:\n\n<div class=\"content-ad\"></div>\n\n이 방법을 사용하면 로컬 머신을 사용하는 모든 사용자가 구성 파일을 가져와야 합니다.\n\n## .kube/config 확인\n\n로컬 머신에서\n\n구성 파일이 올바르게 보이는지 확인하세요\n\n<div class=\"content-ad\"></div>\n\n```yaml\napiVersion: v1\nclusters:\n- cluster:\n    server: https://k8s-master:6443\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubernetes-admin\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\nkind: Config\npreferences: {}\nusers:\n- name: kubernetes-admin\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDQVF8NC9FQS9FQURHQ0NBZ0VHQmJhbEJnVzJzZ0pzSERFUEhBdmrvUW9zYUM4bS9BTkJ3SUlxbnhBQVFWXjQKR0VBR01CRUdKQVNVQ0NRUWdVRHFKV3AwOUJMUWpRaXhxTU93WkljNW5kUU42MVl6TVJqVDlnREVzZUVJdEM0UkdBaktnZVFMUgpVZnlVeEIzVk1WOWJXRkpSRWh6UkVaUllXbDZiR0Y2YjJ4cGJteGhZMlJ2SUY5cmRYbDFZaTVZX2djaENjODBRakp0ClI5R1o2eG1KRXQ3R0cvaVd0WmMwRWdzY0d4Y00vM21jc1RuVFFJU1VUYkc2RUN0WTR6VEtxOW93bDBiTFJiYW1wbjRBUHMKZmxIcEt4ZFZYVDRNWGpGUHhnYWtaQkpIT01Iam5TWGlDRVdRcXE3WDdOYUdsS3ptN1FXX2tWeWw2Sjh3VHluNkJFbVd2cgp6SjIvUmdTc2J3TjU2V2JaSkJKUzFwTWJ5NCtpdG00OEVZdG1YaDduZW8vdGI2dURYNGJaeU85Ujgwb2I0YXNPM1pVcHoKTENHaFN3bUQ4ekRNNnpVSG1ubnNkMlRJVk42TDhYZXFqMVRBR0lJUVQ2TE02c0J6K1dxV1ppZjV6QU9VQ3pVSEFhCnbvNFNmVWlsbGc2NVVSVmNkbDZTaGZuN0ZpdjJOSGFiRW9aQnF3cG45bHZWYnkyNERhVDIvbFhQbDA0QkNpMWFDUk4KdEw4Z1FlbDBtTkhicGwrd3pFRno2b2hkN25ucGpHWHoxSW44Z3RwdnNnWWVnOGszbEd5NFgxTVJjM0krMFN6QmdrbAp6cUdaTVFqVnBzdkJkMzJSWTcxNmRlV3FJSEVEV1UyMjRBZmRoM3BRd0xHbUEyd1dEQjBHT3preUNYcTFFQWtMN2JICmJDcVdWcktOVTNpOGw5SktXQ2tML3dhMEdMOTNJMnNIVURRWHlXQmc0WUlvWTdPYURnOFB4bHlEbitqQlozb2RvTEIKalVXdmVYMjJ5TzMzT3BZVFN0cUErMDdIZjBiY0NmVVhCbnVTr1M2YUxMUDVkajQyb3BFbWttOGhxMUZUcTRRZwpHckpLMWtvR3lFdWVsM2VMMW01Qi9WL3RReWtZY1cwb0c3UVNudHIzY1RLcE1GSXFyQk81aTB0bmFzb3QzK3V3ClBWZVVGMmM3cG5hTnI0QmxsbzF2eE42T2dHczFNcndUb2lGSW1YK2NTMmZNL1NQckV3NUN4R0V6LzRYNDJGNFVCR25pCld0bzRWdFM3VUIyUmVvRDNZZUJaYkFNdnRYRExvT0QzNnczcTBtMllTWGorVU5WUjBYTk1aZ2tCQzdITWN2L29SQUkKS3I1VkpDM2ZRUGNjWURGcmVBd0tLb3hNdGd0SUpZMlBhZityaEV4cVZjYVJzQmZPMEVabGJPVTd1Mk5vMFQrUgp0Qlpnc29JdkozZFlUZktsZkZaNXg1NlE0Nk8rVWM4WC9kS1BzWkYweTVSNU9jWFFESmZkc3JGeWxRcWxzWmd3CmpiVEU5Qkhlb3p6cUR4V254Y1k2ZWNHcjFkeXpURE5yU2laekxHcHYwb1hwL3krajU2ZHRZbUJtUVJvUUFrN2kBWR7blEwcEt1eEkvNTZzNVlPcjRaZml2eThqbApmNDRMWEMraStSWWRRdWIzQ1NGQ0l3VVA1WE9VSFRPYk5HRkd3PS0tLS0tRU5EIFJTQSBQUklWQVRFIEtFWS0tLS0tCgLwRG9jdW1lbnQ=\n    client-key-data: LS0tLS1CRUdJTiBSU0EgUFJJVkFUREPLDd5OHjRFAErlk;sdjgghjkl;sjkl;dfhgjwlk;sjkl;dfghjkl;sdfghkl;sdghjkl;lsdfgjkl;sdfghklsdafgjhkjldfhgjlksdfghjlk;sdfghjlk;sdfgsFWlWaXpQdVjRUdjgMmR6YWV5Q2hh\n```\n\n## kubectl 설정 업데이트\n\n로컬 머신에서\n\n내보내기 설정\n\n<div class=\"content-ad\"></div>\n\n\nexport KUBECONFIG=~/.kube/config\n\n\n## kubectl 명령어 테스트\n\n로컬 머신에서\n\n다음 명령어를 로컬 사용자(user1)로 실행하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nkubectl config view\n```\n\n비슷한 내용이 표시될 것입니다.\n\n```js\napiVersion: v1\nclusters:\n- cluster:\ncertificate-authority-data: DATA+OMITTED\nserver: <https://k8s-master:6443>\nname: kubernetes\ncontexts:\n- context:\ncluster: kubernetes\nuser: kubernetes-admin\nname: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\nkind: Config\npreferences: {}\nusers:\n- name: kubernetes-admin\nuser:\nclient-certificate-data: DATA+OMITTED\nclient-key-data: DATA+OMITTED\n```\n\n## Lens 설정\n\n\n<div class=\"content-ad\"></div>\n\n## 렌즈란 무엇인가요?\n\n렌즈는 Mirantis에서 개발한 크로스 플랫폼 GUI로, Kubernetes 클러스터를 보고 상호 작용하는 데 사용됩니다. Kubernetes를 학습하는 동안 (테스트) 클러스터 내에서 무슨 일이 벌어지고 있는지 확인하는 데 매우 유용합니다.\n\nhttps://k8slens.dev/\n\n## 렌즈 실행하기\n\n<div class=\"content-ad\"></div>\n\n로컬 머신에서\n\n선호하는 플랫폼에 Lens를 설치하세요\n\nLens 설정을 실행하세요\n\nLens 클라우드 계정 설정\n\n<div class=\"content-ad\"></div>\n\n## Lens에 Kubernetes 클러스터 추가하기\n\n로컬 머신에서\n\n렌즈를 열면, 파일 → 클러스터 추가를 클릭해주세요.\n\n.kube/config 파일의 내용을 붙여넣어주세요.\n\n<div class=\"content-ad\"></div>\n\n```yaml\napiVersion: v1\nclusters:\n- cluster:sgsOQVFFTEJRQXdGVEVUTUJFR0EffhssdfghfhsdfgsgGN6QWVGdzB5TkRBMk1UZ3hNREEyTkRWYUZ3MHpOREEyTVRZeE1ERXhORFZhTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUNybmJsem12dnV6UmVDYnUrSThHQ2VleWk3Tkc0eGFlQnNrcTlzUDBYM3ptUW1WZDlsQkdoNzRmeEEKSkRJOGJJSFArK2I2RTJJSW9OMXo4ODFqWXNSNkVpc0UzMkFpUmVyM2FHbEVtM2Z5N29VY1VGcFVxUG9ZYldzQQpUZlhWTlRHWVJBZmRhL25JZU4vbVZQZmNYU215WWoreEpKSnJwQzlaZDk3UzY4NzF3KzFhRTBmNnhUN1YrU2EwCjhGWTZpem5udWowVU5sQWpRcG9HL2xWdTZaYUlvR1Npdm1rT0NWLzNtaFpKZ1FEVFJpb2dsUG9rTGNkeFNHcm8KR0dHL3dJMXB0b2JJMVA1cXUyVmQrY3pIQmtMOXhodm1jMHVoa2dvTmhIMVowa2MxbERBSlk5clRtT0ZBMVNuMQphL00yWTNFS1BJNFgwdjF2UFEwSzNoeWVhbDV4QWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJUVHY2SWxTQU5CZVBuU3llM0hTZVRvRVdDTDZqQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQkx1MW5nVDd6dApwZWZMMDVSRERQbEljWWd6NWVjcU9hb2FzMkd5SEtkZHhXK1IwdDRXanZIUVFoS3pzOE5JVW1GcTlndm80dUxECkx6dDRGTWFOL3RhUEsyM0pPVUp1RDhjNE1TdmpZenZCK2NOb2FIQThjWmRodXBIYy9ydzFJQUhaSWxaZ3M1NjEKK0VVUzlwNDd6cU1BbHQ1QmxBREwreGxLUExuZEdzSzhBTVJRMVAzVkNxS1QyN2dieEZnRFYwU3VWRDRoUEF4UApZaVRKWkhTaTVpbTg1RFFsSTdiQ0hseTIyblg3UXZuRjNCNngvWjl5YjdjSUJYZXZpcEhTaHFGVUlrOXFCeFE2CjE0dnFGVHZFYVZRU1FxcEgyZUh1R21WbXJYekpjMytUWENzQ1BENjd0aGUxZGdMblBEaGRTWDcvY1JBS0NWa0gKaVMwMHBBUUducWM2Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K\n    server: <https://k8s-master:6443>\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubernetes-admin\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes\nkind: Config\npreferences: {}\nusers:\n- name: kubernetes-admin\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDfhjldfhjdfghjkl;dghjkl;szdg;hjzg;hjzdg;hjklzgZ0F3SUJBZ0lJSlFqYzlrb2hqZHN3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBMk1UZ3hNREEyTkRWYUZ3MHlOVEEyTVRneE1ERXhORGRhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQXQ5c2dNeGt3Z0h1UTYrcU0KTTZ2VmlBY2Vmd1BCK0NGZzRkeVltelYxcEsrOEdBRWZ2Qjg1bmNhT1lVZzNPZHVPZXQ4V2JBcnBXM3JqZXVIRgpXQzlvd2hBRTVEeGNEK1h0TlZVaVZpelB1VkxMOEZ0REtCb1hwV3h5SFdIK2lNNkZFRmVrbVdiVDFlY3NJaXVMCkFlNWN3QkUrNitFa2VxUUtpWC9VdE9mNDlGaVJtdmhaS1BCYVlsZ1pjREdFYTVoeDNRM3JxYjcxYVB4Z0w3YUQKdURGNnpSRE5NUkt4VVZ1TjFROFJIei9Ia1FvNVNaUE1Lc1JtYzJ6MHpHN3gwWEVVM0s2cXA4UjJmMEFaT25LegpjdWFITkp3MFV2T25nYlpESUxQYTlXQ3dFclJKb2xxa0E2Zk1tRFRWY2dtYllYN0ZIWFMrZkg1YXB4engvK0Y4CkhDazlBUUlEQVFBQm8xWXdWREFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RBWURWUjBUQVFIL0JBSXdBREFmQmdOVkhTTUVHREFXZ0JUVHY2SWxTQU5CZVBuU3llM0hTZVRvRVdDTDZqQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQkx1MW5nVDd6dApwZWZMMDVSRERQbEljWWd6NWVjcU9hb2FzMkd5SEtkZHhXK1IwdDRXanZIUVFoS3pzOE5JVW1GcTlndm80dUxECkx6dDRGTWFOL3RhUEsyM0pPVUp1RDhjNE1TdmpZenZCK2NOb2FIQThjWmRodXBIYy9ydzFJQUhaSWxaZ3M1NjEKK0VVUzlwNDd6cU1BbHQ1QmxBREwreGxLUExuZEdzSzhBTVJRMVAzVkNxS1QyN2dieEZnRFYwU3VWRDRoUEF4UApZaVRKWkhTaTV\n\n<div class=\"content-ad\"></div>\n\n## 뷰\n\n초기 뷰는 다음과 같이 보입니다.\n\n참고:\n\n통계는 즉시 표시되지 않지만 Prometheus 설정이 설치되면 이 데이터가 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n```\n![Image](/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_1.png)\n\n# 쿠버네티스 로드 밸런싱을 위해 MetaLB 설치\n\n하이퍼스케일러 또는 제공된 버전의 Kubernetes와 자체 호스팅/온프렘 Kubernetes 설치의 주요 차이점은 간단합니다. Kubernetes 서비스 모델은 인그레스 포인트, 로드 밸런서, 지속적인 데이터 및 기타 여러 가지를 포함한 전체 설정을 제공할 것입니다.\n\n하지만 자체 호스팅된 구성에서는 이러한 것들을 설정해주어야 합니다.\n\n\n<div class=\"content-ad\"></div>\n\n이 지침은 MetaLB를 인그레스 포인트로 설정하고 사용하는 방법을 다룹니다. 이것은 basically 서비스(nginx, haproxy, grafana, prmetheus 등)가 쿠버네티스에서 MetaLB를 사용하여 인터넷/외부에서 액세스할 수 있도록 설정하는 것을 의미합니다.\n\n# MetaLB란 무엇인가요?\n\nchatGPT의 말을 인용하면,\n\nMetaLB는 클라우드 환경이 아닌 베어메탈에서 실행되는 Kubernetes 클러스터용 로드 밸런서 구현체입니다(클라우드 환경에서는 일반적으로 클라우드 제공업체가 로드 밸런서를 제공합니다). MetaLB는 온프레미스 Kubernetes 환경 내에서 로드 밸런서를 생성할 수 있는 필수 구성 요소를 제공하여 클라우드 기반 로드 밸런서가 작동하는 방식과 유사하게 클러스터 외부에 서비스를 노출할 수 있도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n# MetalLB의 주요 기능\n\n- 베어 메탈 클러스터용 로드 밸런서: MetalLB는 베어 메탈 하드웨어에서 실행되거나 로드 밸런서 지원이 없는 환경에서 Kubernetes 클러스터에서 LoadBalancer 유형 서비스를 사용할 수 있게 해줍니다.\n- 다중 프로토콜 지원: MetalLB는 Layer 2(데이터 링크 계층) 및 BGP(Border Gateway Protocol) 모두를 지원하여 네트워크 내에서 IP 주소를 어떻게 관리하고 경유할지에 대한 유연성을 제공합니다.\n- 구성 유연성: MetalLB를 사용자 고유의 네트워크 요구에 맞게 구성할 수 있습니다. 주소 풀 지정, 로드 밸런서의 동작 정의 등이 포함됩니다.\n- Kubernetes 통합: MetalLB는 Kubernetes와 완벽하게 통합되어 있습니다. LoadBalancer 유형의 서비스 생성을 수신하고 미리 구성된 풀에서 해당 서비스에 IP 주소를 할당합니다.\n\n# MetalLB 작동 방식\n\n- Layer 2 모드: 이 모드에서 MetalLB는 ARP(Address Resolution Protocol)를 사용하여 IP 주소를 로컬 네트워크에 알리게 합니다. 이를 통해 Kubernetes 서비스 IP가 네트워크에서 로컬 IP처럼 보이도록 합니다.\n- BGP 모드: BGP 모드에서 MetalLB는 BGP 프로토콜을 사용하여 서비스의 IP 주소를 네트워크 라우터에 광고합니다. 이를 통해 더 고급 라우팅 구성이 가능하며 대규모 및 복잡한 네트워크 환경에 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n# 전형적인 사용 사례\n\n- 설치: MetaLB를 Kubernetes 클러스터에 설치하려면 필요한 매니페스트를 적용하거나 Helm과 같은 패키지 관리자를 사용하십시오.\n- 구성: MetaLB를 구성하려면 주소 풀과 운영 모드(Layer 2 또는 BGP)를 정의하는 ConfigMap을 만듭니다.\n- 서비스 생성: LoadBalancer 유형의 Kubernetes 서비스를 만들 때, MetaLB는 풀에서 IP 주소를 할당하고 접근 가능하게 만듭니다.\n\n# 전제 조건\n\n## IP 서브넷\n\n<div class=\"content-ad\"></div>\n\n설정 중에는 네트워크에서 액세스할 수 있는 IP 주소 범위가 필요합니다.\n\n이 지침에서는 내부 LAN의 10 IP 범위를 사용할 것입니다.\n\n```js\n10.10.0.240-10.10.0.250\n```\n\n## 쿠버네티스 클러스터 설정\n\n<div class=\"content-ad\"></div>\n\n여기에서 해당 작업에 대한 지침을 찾을 수 있습니다.\n\n**Kubernetes 3 노드 클러스터 구축 방법**\n\n### 테스트 배포\n\nKubernetes 외부의 인그레스가 올바르게 작동하는지 테스트하기 위해 테스트 nginx 서비스를 설정합니다.\n\n<div class=\"content-ad\"></div>\n\n## NginX 배포 생성\n\n배포를 생성합니다.\n\n```js\nkubectl create deploy nginx --image=nginx:1.20\n```\n\n다음과 같이 배포, 레플리카셋 및 파드를 나열합니다.\n\n<div class=\"content-ad\"></div>\n\n```yaml\nkubectl get deploy,rs,po\n```\n\n예상 출력은\n\n```yaml\nkubectl get deploy,rs,po\n```\n\n```yaml\nNAME                    READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/nginx   1/1     1            1           39sNAME                               DESIRED   CURRENT   READY   AGE\nreplicaset.apps/nginx-6d777db949   1         1         1       38sNAME                         READY   STATUS    RESTARTS   AGE\npod/nginx-6d777db949-sr8x6   1/1     Running   0          38s\n```\n\n<div class=\"content-ad\"></div>\n\nNginx 배포를 확장하려면\n\n```bash\nkubectl scale deploy/nginx --replicas=3\n```\n\nNginx 배포를 3개 복제본으로 확장한 후, 예상 출력은\n\n```bash\nkubectl get deploy,rs,po\n```\n\n<div class=\"content-ad\"></div>\n\n\n**이름                    준비 상태   최신 상태   이용 가능   나이**\ndeployment.apps/nginx   3/3        3           3           2분 8초\n\n이름                               원하는 상태   현재 상태   준비 상태   나이\nreplicaset.apps/nginx-6d777db949   3            3          3          2분 8초\n\n이름                         **준비 상태                        상태               다시 시작   나이**\npod/nginx-6d777db949-jttpw   1/1         실행 중       0          23초\npod/nginx-6d777db949-qmdk8   1/1         실행 중       0          23초\npod/nginx-6d777db949-sr8x6   1/1         실행 중       0          2분 8초\n\n\n위 배포에 대한 로드 밸런서 서비스를 생성해주세요\n\n\nkubectl expose deploy/nginx --type=LoadBalancer --port=80\n\n\n우리가 만든 nginx 서비스에 대해 설명해주세요\n\n\n<div class=\"content-ad\"></div>\n\n\n```js\nkubectl get svc\nkubectl describe svc/nginx\n```\n\n다음과 같은 결과가 예상됩니다.\n\n```js\n**kubectl get svc**\n```\n\n```js\nNAME         TYPE           CLUSTER-IP    **EXTERNAL-IP**   PORT(S)        AGE\nkubernetes   ClusterIP      10.96.0.1     **<none>**        443/TCP        28m\nnginx        LoadBalancer   10.103.19.189 **<pending>**     80:32019/TCP   5s\n**kubectl describe svc/nginx**\nName:                     nginx\nNamespace:                default\nLabels:                   app=nginx\nAnnotations:              <none>\nSelector:                 app=nginx\nType:                     LoadBalancer\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.103.19.189\nIPs:                      10.103.19.189\nPort:                     <unset>  80/TCP\nTargetPort:               80/TCP\nNodePort:                 <unset>  32019/TCP\nEndpoints:                192.168.145.193:80,192.168.145.194:80,192.168.72.129:80\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   <none>\n```\n\n<div class=\"content-ad\"></div>\n\nNginx 로드 밸런서 서비스의 외부 IP가 '보류 중'임을 알려드립니다. MetalLB 또는 유사한 로드 밸런서가 없는 경우 베어 메탈 K8s 클러스터에서 로드 밸런서 서비스는 외부 IP를 가져오지 못하므로 NodePort 서비스와 똑같이 작동하게 됩니다.\n\n이는 예상하지 못한 일일지도 모릅니다. MetalLB가 로컬 K8s 클러스터의 이 문제를 해결해 줄 것입니다.\n\nnginx 배포를 0으로 축소하세요.\n\n```shell\nkubectl scale deploy/nginx --replicas=0\n```\n\n<div class=\"content-ad\"></div>\n\nKubernetes NGINX 배포가 완료되었습니다. 이것은 나중에 사용될 것입니다.\n\n# MetalLB 설정\n\n참고:\n\nMetalLB에는 BGP 및 Layer2 모드가 있습니다. 이 안내서는 Layer2 모드를 설정합니다.\n\n<div class=\"content-ad\"></div>\n\n## 네임스페이스 생성\n\nMetaLB를 위한 네임스페이스를 만들어보세요.\n\n```js\nkubectl apply -fhttps://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/namespace.yaml\n```\n\n## 참고:\n\n<div class=\"content-ad\"></div>\n\nMetal LB의 내부 사용을 위해 일부 IP 주소를 할당해야 합니다. IP 주소가 이미 사용 중이지 않도록 확인해야 합니다.\n\n로드밸런서 서비스를 생성할 때마다 Kubernetes는 MetalLB 로드밸런서의 인스턴스를 생성합니다. Kubernetes는 구성 맵에 지정된 IP 주소 범위에서 사용 가능한 IP 주소를 선택하고 MetalLB 로드밸런서에 할당합니다. 그런 다음 MetalLB 로드밸런서는 우리의 응용 프로그램 배포를 위해 생성한 LB 서비스에 연결된 여러 Pod EndPoints를 로드 밸런싱합니다.\n\n## 구성 파일 생성\n\n로컬 머신에서\n\n<div class=\"content-ad\"></div>\n\n메탈로드밸런서 설정을 위한 YAML 파일을 생성하세요.\n\n```yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - **10.10.0.240-10.10.0.250**\n```\n\n<div class=\"content-ad\"></div>\n\n아래 섹션은 위의 사전 준비 섹션에서 선택한 IP 범위를 사용합니다.\n\n```js\naddresses:\n      - **10.10.0.240-10.10.0.250**\n```\n\n## 방화벽 설정\n\n<div class=\"content-ad\"></div>\n\n3 노드 클러스터는 로컬 방화벽을 사용하지 않습니다. 여기에 참고용으로 추가했습니다.\n\n```js\nsudo firewall-cmd --permanent --add-port=7472/tcp --zone=trusted\nsudo firewall-cmd --permanent --add-port=7472/udp --zone=trusted\nsudo firewall-cmd --permanent --add-port=7946/tcp --zone=trusted\nsudo firewall-cmd --permanent --add-port=7946/udp --zone=trusted\nsudo firewall-cmd --reload\nsudo firewall-cmd --list-all\n```\n\n위 포트는 Metal LB에서 사용하는 기본 포트입니다. 수정했다면 해당 포트를 변경해야 합니다.\n\n## 클러스터에 MetaLB 배포하기\n\n<div class=\"content-ad\"></div>\n\n로컬 머신에서\n\n```js\nkubectl apply -f **metal-lb-cm.ymlkubectl** apply -f <https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/metallb.yaml>\n```\n\nmetallb-system 네임스페이스 내에서 실행 중인 pod 목록을 나열해주세요.\n\n```js\nkubectl get pod -n metallb-system\n```\n\n<div class=\"content-ad\"></div>\n\n```js\n이름                        준비 상태   상태      재시작    시간\ncontroller-7fbf768f66-m66ph   1/1     실행 중   0          30초\nspeaker-hj669                 1/1     실행 중   0          30초\nspeaker-l9sbp                 1/1     실행 중   0          30초\nspeaker-q9jjf                 1/1     실행 중   0          30초\n```\n\n# MetaLB로 NginX 테스트 계속\n\nMetaLB를 설치한 후에 Nginx 테스트를 계속 진행하여 이 작동 방식을 확인하세요.\n\n## 레플리카 세트 확장하기\n\n<div class=\"content-ad\"></div>\n\nNginx 배포를 확장했습니다.\n\n```js\nkubectl scale deploy nginx --replicas=3\n```\n\n결과 출력:\n\n```js\ndeployment.apps/nginx scaled\n```\n\n<div class=\"content-ad\"></div>\n\n로드 밸런서 서비스를 설명하고 외부 IP가 할당되었는지 확인해보세요.\n\n```js\nkubectl expose deploy nginx --type=LoadBalancer --port=80\n```\n\n출력 결과\n\n```js\nservice/nginx가 노출되었습니다\n```\n\n<div class=\"content-ad\"></div>\n\n외부 IP가 할당되었는지 확인해 보세요\n\n```js\nkubectl get svc nginx\n```\n\n결과 값은 다음과 같아야 합니다\n\n```js\nNAME    TYPE           CLUSTER-IP    **EXTERNAL-IP**       PORT(S)        AGE\nnginx   LoadBalancer   10.102.5.84   **10.10.0.240**       80:31829/TCP   5s\n```\n\n<div class=\"content-ad\"></div>\n\n이번에는 서비스를 보면 MetaLB가 해당 서비스에 대해 범위/풀에서 IP를 할당했습니다.\n\n더 많은 세부 정보를 보려면 kubectl describe 명령을 사용해보세요.\n\n```js\nkubectl describe svc/nginx\n```\n\n```js\nName:                     nginx\nNamespace:                default\nLabels:                   app=nginx\nAnnotations:              <none>\nSelector:                 app=nginx\nType:                     LoadBalancer\nIP Family Policy:         SingleStack\nIP Families:              IPv4\nIP:                       10.102.5.84\nIPs:                      10.102.5.84\n**LoadBalancer Ingress:     110.10.0.240**\nPort:                     <unset>  80/TCP\nTargetPort:               80/TCP\nNodePort:                 <unset>  31829/TCP\n**Endpoints:                192.168.145.195:80,192.168.145.196:80,192.168.72.132:80**\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:\n  Type    Reason        Age   From                Message\n  ----    ------        ----  ----                -------\n  Normal  IPAllocated   31s   metallb-controller  Assigned IP \"192.168.254.240\"\n  Normal  nodeAssigned  16s   metallb-speaker     announcing from node \"master.tektutor.org\"\n```\n\n<div class=\"content-ad\"></div>\n\n위에서 볼 수 있듯이, nginx 로드밸런서 서비스는 metallb 구성 맵에서 언급한 범위의 ExternalIP로 할당되었습니다.\n\n이제 아래와 같이 서비스에 액세스할 수 있습니다.\n\n```js\ncurl <http://10.10.0.240>\n```\n\n표시\n\n<div class=\"content-ad\"></div>\n\n```js\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p><p>For online documentation and support please refer to\n<a href=\"http://nginx.org/\">nginx.org</a>.<br/>\nCommercial support is available at\n<a href=\"http://nginx.com/\">nginx.com</a>.</p><p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n```\n\n# 완료\n\n메타LB는 LoadBalancer로 정의된 서비스에 대해 외부 IP 주소를 할당합니다. ClusterIP와 달리, prometheus monitoring을 배포할 때 이를 기억하는 것이 중요합니다.\n\n# 쿠버네티스 프로메테우스 모니터링 스택 설치\n\n<div class=\"content-ad\"></div>\n\n3 노드 클러스터를 생성하고 Ingress를 위해 MetaLB를 클러스터에 설치하고 로컬 Linux 서버에서 클러스터에 원격 액세스를 설정했다면, 다음 단계는 모니터링을 배포하는 것입니다.\n\nPrometheus 커뮤니티는 HELM을 사용하여 전체 모니터링 스택을 배포합니다. 배포는 쿠버네티스 클러스터에 Prometheus, AlertManager 및 Grafana를 설치하고 이러한 서비스를 경고, 대시보드, API 엔드포인트로 채워서 즉시 전체적인 개요를 얻을 수 있도록 합니다.\n\n## 전제 조건\n\n## Helm\n\n<div class=\"content-ad\"></div>\n\nHelm이 설치되었습니다!\n\nHelm을 설치하는 자세한 내용은 여기에서 확인할 수 있어요.\n\n[https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/)\n\n## Helm이란 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n헬름은 쿠버네티스용 패키지 매니저로, 쿠버네티스 클러스터에 애플리케이션 및 서비스를 배포, 관리, 구성하는 데 사용됩니다. 헬름 차트를 사용하여 사용자가 복잡한 쿠버네티스 애플리케이션을 정의, 설치, 업그레이드할 수 있어 배포 프로세스를 단순화합니다.\n\n## 헬름의 주요 기능\n\n- 패키지 관리: 헬름은 사용자가 쿠버네티스 리소스를 차트로 패키징할 수 있도록 해 주는데, 이는 일련의 쿠버네티스 리소스를 설명하는 파일 모음입니다.\n- 버전 관리: 헬름 차트는 버전을 매길 수 있어 애플리케이션 업데이트와 롤백을 쉽게 관리할 수 있습니다.\n- 템플릿화: 헬름은 템플릿을 사용하여 쿠버네티스 리소스를 정의하는데, 동적이고 재사용 가능한 구성을 가능하게 합니다. 템플릿은 다양한 배포 환경을 수용할 수 있도록 매개변수화될 수 있습니다.\n- 릴리스 관리: 헬름은 차트의 인스턴스인 릴리스를 관리합니다. 이를 통해 쉽게 설치, 업그레이드, 롤백할 수 있습니다.\n- 의존성 관리: 헬름 차트는 다른 차트에 대한 의존성을 지정할 수 있어 복잡한 애플리케이션 스택을 단일 단위로 배포할 수 있습니다.\n\n## URL\n\n<div class=\"content-ad\"></div>\n\n서비스는 GitHub을 통해 제공됩니다.\n\n- <https://github.com/prometheus-community/helm-charts/tree/6f1bc9ed3f7eb9a8cb4711ca538fd0ddf71fcb96/charts/kube-prometheus-stack>\n- <https://github.com/prometheus-community/helm-charts/tree/6f1bc9ed3f7eb9a8cb4711ca538fd0ddf71fcb96>\n\n# Kube-Prometheus-stack 설치\n\n## 네임스페이스 생성\n\n<div class=\"content-ad\"></div>\n\n```bash\n# 모니터링 스택을 위한 네임스페이스 생성\n\nkubectl create ns monitoring\n```\n\n## 새로운 Helm 저장소 추가\n\nhelm을 사용하여 프로메테우스 스택을 위한 저장소를 추가해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nhelm repo add prometheus-community <https://prometheus-community.github.io/helm-charts>\n```\n\n```js\nhelm repo update\n```\n\n## values.yaml 편집\n\nHelm 설치에는 helm 패키지에 내장된 values.yaml 파일이 있습니다. 이 설치를 사용하면 기본값을 재정의할 수 있는 values.yaml 파일을 생성해야 합니다. 이 값을 install 명령어에 전달하여 기본값을 재정의할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n알림\n\n**기본 values.yaml 파일은 여기에서 찾을 수 있습니다: https://github.com/prometheus-community/helm-charts/blob/f5e395597054cc94ee7d9d92813552501c22266e/charts/kube-prometheus-stack/values.yaml#L4**\n\n```js\nnano values.yaml\n```\n\n다음을 추가하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nruleSelectorNilUsesHelmValues: false\nserviceMonitorSelectorNilUsesHelmValues: false\npodMonitorSelectorNilUsesHelmValues: false\nprobeSelectorNilUsesHelmValues: false\nscrapeConfigSelectorNilUsesHelmValues: false\n```\n\n```js\ngrafana:\n  service:\n    type: LoadBalancer\nprometheus:\n  service:\n    type: LoadBalancer\nalertmanager:\n  service:\n    type: LoadBalancer\n```\n\n마지막 세 개의 \"서비스\"인 그라파나, 프로메테우스, 알람매니저는 기본 설정인 ClusterIP를 재정의하여 외부 IP를 LoadBalancer로 설정했습니다. MetaLB를 사용하여 우리가 정의한 범위/풀에서 외부 IP를 이 서비스에 할당할 수 있습니다.\n\n## Helm 배포\n\n<div class=\"content-ad\"></div>\n\nkube-prometheus-stack을 Helm 업데이트 명령을 사용하여 배포하세요.\n\n```js\nhelm upgrade --install -f **values.yaml** kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring\n```\n\nKube-Prometheus 스택을 배포한 후에는 다음과 같은 기본 앱들을 얻습니다:\n\n- Grafana\n- Prometheus\n- Alert Manager.\n\n<div class=\"content-ad\"></div>\n\n# 배포 확인\n\n## 파드가 실행 중인지 확인\n\n```js\nkubectl get pod -n monitoring\n```\n\n반응이 있어야 해요\n\n<div class=\"content-ad\"></div>\n\n```js\n이름                                                        준비 상태    상태    재시작    시간\nalertmanager-kube-prometheus-stack-alertmanager-0           2/2         실행 중   0        21시간\nkube-prometheus-stack-grafana-76858ff8dd-nnh94              3/3         실행 중   0        21시간\nkube-prometheus-stack-kube-state-metrics-7f6967956d-tzrkm   1/1         실행 중   0        21시간\nkube-prometheus-stack-operator-79b45fdb47-ccqc6             1/1         실행 중   0        21시간\nkube-prometheus-stack-prometheus-node-exporter-bxbtc        1/1         실행 중   0        21시간\nkube-prometheus-stack-prometheus-node-exporter-j9gjg        1/1         실행 중   0        21시간\nkube-prometheus-stack-prometheus-node-exporter-r2fqw        1/1         실행 중   0        21시간\nprometheus-kube-prometheus-stack-prometheus-0               2/2         실행 중   0        21시간\n```\n\n만약 파드가 계속 생성 중이라면\n\n```js\nwatch kubectl get pod -n monitoring\n```\n\n위 명령을 사용해 주세요. 이 명령은 출력이 변경될 때마다 위의 결과를 업데이트합니다.\n\n<div class=\"content-ad\"></div>\n\n## 서비스 확인하기\n\n다음 명령어를 실행해 주세요\n\n```js\nkubectl get svc -n monitoring\n```\n\n출력 결과 확인해보세요 (좌우 스크롤 바 유의)\n\n<div class=\"content-ad\"></div>\n\n```js\n이 이름들은 존경스러운! \n\n각각의 접근 가능한 서비스는 외부 범위/풀에서 IP를 할당받아 TYPE = LoadBalancer로 지정되어야 합니다.\n\n## 서비스 모니터 적용\n\n서비스 모니터는 쿠버네티스에서 메트릭을 스크래핑하는 응용 프로그램을 정의합니다.\n```\n\n<div class=\"content-ad\"></div>\n\n아래와 같이 YAML 파일을 만들어주세요.\n\n\nnano servicemonitor.yaml\n\n\n다음 내용을 추가해주세요.\n\n```yaml\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n  name: prometheus-self\n  labels:\n    app: kube-prometheus-stack-prometheus\nspec:\n  endpoints:\n  - interval: 30s\n    port: web\n  selector:\n    matchLabels:\n      app: kube-prometheus-stack-prometheus\n```\n\n<div class=\"content-ad\"></div>\n\n아래와 같이 코드를 실행해주세요.\n\n```bash\nkubectl apply -f servicemonitor.yaml -n monitoring\n```\n\n예상 결과는 다음과 같습니다.\n\n```bash\nservicemonitor.monitoring.coreos.com/prometheus-self가 생성되었습니다.\n```\n\n<div class=\"content-ad\"></div>\n\n# 인터페이스 보기\n\n필요한 3가지 인터페이스가 설정되었으며 공개 인터페이스에 이용 가능합니다.\n\n## 프로메테우스\n\n### URL\n\n<div class=\"content-ad\"></div>\n\n10.10.0.243에서 확인부탁드립니다.\n\n## 홈페이지\n\n<img src=\"/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_2.png\" />\n\n## 사전 정의된 알림\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_3.png)\n\n# Alert Manager\n\n## URL\n\nhttp://10.10.0.242:9093\n\n\n<div class=\"content-ad\"></div>\n\n## 홈\n\n![이미지](/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_4.png)\n\n# 그라파나\n\n## URL\n\n<div class=\"content-ad\"></div>\n\nhttp://10.10.0.241\n\n## 기본 접근\n\n- 사용자 이름: admin\n- 비밀번호: prom-operator\n\n## 사전 설치된 경고 규칙\n\n<div class=\"content-ad\"></div>\n\n\n![PreInstalled Dashboards](/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_6.png)\n\n![PreInstalled Dashboards](/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_7.png)\n\n\n<div class=\"content-ad\"></div>\n\n# 시스로그를 위한 Promtail과 Loki 설치하기\n\n# Helm Repos 설치\n\nGrafana Helm 차트를 Helm cli에 추가하세요:\n\n```js\nhelm repo add grafana <https://grafana.github.io/helm-charts>\nhelm repo update\n```\n\n<div class=\"content-ad\"></div>\n\n# Loki 설치하기\n\n다음 명령어를 실행해주세요.\n\n```js\nhelm upgrade --install loki grafana/loki-distributed -n monitoring --set service.type=LoadBalancer\n```\n\n# 포드 확인\n\n<div class=\"content-ad\"></div>\n\n```js\nwatch kubectl get pods -n monitoring\n```\n\n원하는 출력\n\n```js\nNAME                                                        READY   STATUS    RESTARTS   AGE\nalertmanager-kube-prometheus-stack-alertmanager-0           2/2     Running   0          23시간\nkube-prometheus-stack-grafana-76858ff8dd-nnh94              3/3     Running   0          23시간\nkube-prometheus-stack-kube-state-metrics-7f6967956d-tzrkm   1/1     Running   0          23시간\nkube-prometheus-stack-operator-79b45fdb47-ccqc6             1/1     Running   0          23시간\nkube-prometheus-stack-prometheus-node-exporter-bxbtc        1/1     Running   0          23시간\nkube-prometheus-stack-prometheus-node-exporter-j9gjg        1/1     Running   0          23시간\nkube-prometheus-stack-prometheus-node-exporter-r2fqw        1/1     Running   0          23시간\n**loki-loki-distributed-distributor-b8448bd4b-2twdh           1/1     Running   0          3분15초\nloki-loki-distributed-gateway-9d8b76d6d-mvxps               1/1     Running   0          3분15초\nloki-loki-distributed-ingester-0                            1/1     Running   0          3분15초\nloki-loki-distributed-querier-0                             1/1     Running   0          3분15초\nloki-loki-distributed-query-frontend-6db884fbdd-zfs2s       1/1     Running   0          3분15초**\nprometheus-kube-prometheus-stack-prometheus-0               2/2     Running   0          23시간\n```\n\n시작할 때 변경 사항을 보기 위해 watch 명령어를 사용하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nwatch kubectl get pods -n monitoring\n```\n\n# 서비스 확인하기\n\n실행하세요\n\n```js\nkubectl get services -n monitoring\n```\n\n<div class=\"content-ad\"></div>\n\n예상 결과\n\n```js\nNAME                                             TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\nalertmanager-operated                            ClusterIP      None            <none>        9093/TCP,9094/TCP,9094/UDP      23h\nkube-prometheus-stack-alertmanager               LoadBalancer   10.108.18.33    10.10.0.242   9093:31456/TCP,8080:31493/TCP   23h\nkube-prometheus-stack-grafana                    LoadBalancer   10.105.8.65     10.10.0.241   80:31941/TCP    23h\nkube-prometheus-stack-kube-state-metrics         ClusterIP      10.97.4.3       <none>        8080/TCP        23h\nkube-prometheus-stack-operator                   ClusterIP      10.107.254.83   <none>        443/TCP         23h\nkube-prometheus-stack-prometheus                 LoadBalancer   10.108.245.2    10.10.0.243   9090:30518/TCP,8080:31169/TCP   23h\nkube-prometheus-stack-prometheus-node-exporter   ClusterIP      10.105.24.16    <none>        9100/TCP        23h\n**loki-loki-distributed-distributor                ClusterIP      10.102.78.123   <none>        3100/TCP,9095/TCP               4m9s\nloki-loki-distributed-gateway                    ClusterIP      10.97.122.135   <none>        80/TCP          4m9s\nloki-loki-distributed-ingester                   ClusterIP      10.110.15.213   <none>        3100/TCP,9095/TCP               4m9s\nloki-loki-distributed-ingester-headless          ClusterIP      None            <none>        3100/TCP,9095/TCP               4m9s\nloki-loki-distributed-memberlist                 ClusterIP      None            <none>        7946/TCP        4m9s\nloki-loki-distributed-querier                    ClusterIP      10.108.56.75    <none>        3100/TCP,9095/TCP               4m9s\nloki-loki-distributed-querier-headless           ClusterIP      None            <none>        3100/TCP,9095/TCP               4m9s\nloki-loki-distributed-query-frontend             ClusterIP      10.100.183.25   <none>        3100/TCP,9095/TCP,9096/TCP      4m9s\nloki-loki-distributed-query-frontend-headless    ClusterIP      None            <none>        3100/TCP,9095/TCP,9096/TCP      4m9s\npro**metheus-operated                              ClusterIP      None            <none>        9090/TCP        23h\n```\n\n# 그라파나에 Loki 추가하기\n\n그라파나의 홈 → 연결 → 데이터 소스로 이동하여 Loki 데이터 소스를 추가하세요.\n\n<div class=\"content-ad\"></div>\n\n로키를 데이터 소스로 선택하세요\n\n다음 URL을 사용하세요\n\n```js\n[http://loki-loki-distributed-query-frontend.monitoring:3100](http://loki-loki-distributed-query-frontend.monitoring:3100)\n```\n\n# 이 작업은 자동으로 수행됩니다\n\n<div class=\"content-ad\"></div>\n\n요고를 values.yaml에 추가하면 Loki를 자동으로 설정할 수 있을 것 같아요.\n\n```yaml\ngrafana:\n  sidecar:\n    datasources:\n      defaultDatasourceEnabled: true\n  additionalDataSources:\n    - name: Loki\n      type: loki\n      url: <http://loki-loki-distributed-query-frontend.monitoring:3100>\n```\n\n# Promtail 설치\n\nPromtail은 데이터를 Loki로 푸시합니다.\n\n<div class=\"content-ad\"></div>\n\nA values 파일이 promtail 구성에 필요합니다.\n\n```yaml\nnano promtail-values.yaml\n```\n\n다음을 추가하세요.\n\n```yaml\n---\nconfig:\nclients:\n- url: \"<http://loki-loki-distributed-gateway/loki/api/v1/push>\"\n---\n```\n\n<div class=\"content-ad\"></div>\n\n해당 명령을 실행해보세요:\n\n```js\nhelm upgrade --install promtail grafana/promtail -f promtail-values.yaml -n monitoring\n```\n\n# Pod 확인\n\n```js\nkubectl get pods -n monitoring\n```\n\n<div class=\"content-ad\"></div>\n\n원하는 표시\n\n```js\nNAME                                                        READY   STATUS    RESTARTS   AGE\nalertmanager-kube-prometheus-stack-alertmanager-0           2/2     Running   0          23h\nkube-prometheus-stack-grafana-76858ff8dd-nnh94              3/3     Running   0          23h\nkube-prometheus-stack-kube-state-metrics-7f6967956d-tzrkm   1/1     Running   0          23h\nkube-prometheus-stack-operator-79b45fdb47-ccqc6             1/1     Running   0          23h\nkube-prometheus-stack-prometheus-node-exporter-bxbtc        1/1     Running   0          23h\nkube-prometheus-stack-prometheus-node-exporter-j9gjg        1/1     Running   0          23h\nkube-prometheus-stack-prometheus-node-exporter-r2fqw        1/1     Running   0          23h\nloki-loki-distributed-distributor-b8448bd4b-2twdh           1/1     Running   0          22m\nloki-loki-distributed-gateway-9d8b76d6d-mvxps               1/1     Running   0          22m\nloki-loki-distributed-ingester-0                            1/1     Running   0          22m\nloki-loki-distributed-querier-0                             1/1     Running   0          22m\nloki-loki-distributed-query-frontend-6db884fbdd-zfs2s       1/1     Running   0          22m\nprometheus-kube-prometheus-stack-prometheus-0               2/2     Running   0          23h\n**promtail-25bjr                                              1/1     Running   0          3m21s\npromtail-5kmlt                                              1/1     Running   0          3m21s\npromtail-h9mrf                                              1/1     Running   0          3m21s**\n```\n\n변경 사항을 보면서 시작할 때 watch로 사용해보세요\n\n```js\nwatch kubectl get pods -n monitoring\n```\n\n<div class=\"content-ad\"></div>\n\n# 서비스 확인\n\n실행\n\n```js\nkubectl get services -n monitoring\n```\n\n예상 결과\n\n<div class=\"content-ad\"></div>\n\n```js\n이름                                               유형            클러스터 IP       외부 IP         포트       생성된 시간\nalertmanager-operated                            ClusterIP      없음            없음           9093/TCP,9094/TCP,9094/UDP      23시간\nkube-prometheus-stack-alertmanager               로드 밸런서     10.108.18.33    10.10.0.242    9093:31456/TCP,8080:31493/TCP   23시간\nkube-prometheus-stack-grafana                    로드 밸런서     10.105.8.65     10.10.0.241    80:31941/TCP    23시간\nkube-prometheus-stack-kube-state-metrics         ClusterIP      10.97.4.3       없음           8080/TCP        23시간\nkube-prometheus-stack-operator                   ClusterIP      10.107.254.83   없음           443/TCP         23시간\nkube-prometheus-stack-prometheus                 로드 밸런서     10.108.245.2    10.10.0.243    9090:30518/TCP,8080:31169/TCP   23시간\nkube-prometheus-stack-prometheus-node-exporter   ClusterIP      10.105.24.16    없음           9100/TCP        23시간\nloki-loki-distributed-distributor                ClusterIP      10.102.78.123   없음           3100/TCP,9095/TCP               24분\nloki-loki-distributed-gateway                    ClusterIP      10.97.122.135   없음           80/TCP          24분\nloki-loki-distributed-ingester                   ClusterIP      10.110.15.213   없음           3100/TCP,9095/TCP               24분\nloki-loki-distributed-ingester-headless          ClusterIP      없음            없음           3100/TCP,9095/TCP               24분\nloki-loki-distributed-memberlist                 ClusterIP      없음            없음           7946/TCP        24분\nloki-loki-distributed-querier                    ClusterIP      10.108.56.75    없음           3100/TCP,9095/TCP               24분\nloki-loki-distributed-querier-headless           ClusterIP      없음            없음           3100/TCP,9095/TCP               24분\nloki-loki-distributed-query-frontend             ClusterIP      10.100.183.25   없음           3100/TCP,9095/TCP,9096/TCP      24분\nloki-loki-distributed-query-frontend-headless    ClusterIP      없음            없음           3100/TCP,9095/TCP,9096/TCP      24분\nprometheus-operated                              ClusterIP      없음            없음           9090/TCP        23시간\n```\n\n# 결과\n\n이 결과를 통해\n\nGrafana를 열 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n해당 테이블 태그를 마크다운 형식으로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\n# 생각\n\n이것들은 조잡하고 대충 적은 메모입니다. 그러나, 나는 이 홈랩을 운영하는 방법으로 모든 것을 구현한 것이며, 다음 단계는 도커에서 실행 중인 것을 이 Kubernetes 클러스터로 마이그레이션하는 것입니다.\n\n# 참고 자료\n\n- https://www.linuxtechi.com/install-kubernetes-cluster-on-debian/\n- https://k21academy.com/docker-kubernetes/accessing-remote-kubeadm-cluster/\n- https://medium.com/tektutor/using-metal-lb-on-a-bare-metal-onprem-kubernetes-setup-6d036af1d20c\n- https://medium.com/israeli-tech-radar/how-to-create-a-monitoring-stack-using-kube-prometheus-stack-part-1-eff8bf7ba9a9\n- https://github.com/prometheus-community/helm-charts/tree/6f1bc9ed3f7eb9a8cb4711ca538fd0ddf71fcb96/charts/kube-prometheus-stack\n- https://docs.appsealing.com/guide/4.%20On-Premise/7.%20Logging_and_monitoring_with_Prometheus_Grafana_Loki.html#what-is-this-content-based-on","ogImage":{"url":"/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_0.png"},"coverImage":"/assets/img/2024-06-20-CreatingaSelfHostedKubernetesStackonDebian12andmonitoringwithkube-prometheus-stack_0.png","tag":["Tech"],"readingTime":44},{"title":"리눅스 Unix에서 예제를 활용한 AWK를 이용한 텍스트 처리","description":"","date":"2024-06-20 14:11","slug":"2024-06-20-TextProcessingwithAWKinLinuxUnixwithexamples","content":"\n\n\n![Image](/assets/img/2024-06-20-TextProcessingwithAWKinLinuxUnixwithexamples_0.png)\n\nawk은 패턴 스캔 및 처리를 위한 강력한 프로그래밍 언어이자 명령 줄 유틸리티입니다. 주로 텍스트 처리에 사용되며 데이터 추출 및 보고 도구로 사용됩니다. 본 안내서는 awk의 기본 개념을 이해하는 데 도움을 주고 Linux/Unix 환경에서 효과적으로 사용하는 방법을 보여줄 것입니다.\n\n# awk 소개\n\nawk은 창안자 Alfred Aho, Peter Weinberger, Brian Kernighan의 이름에서 따왔습니다. 사용자가 지정한 패턴과 작업을 적용하여 텍스트를 한 줄씩 처리합니다.\n\n\n<div class=\"content-ad\"></div>\n\n# 기본 구문\n\nawk의 기본 구문은 다음과 같습니다:\n\n\nawk '패턴 { 동작 }' 파일\n\n\n- 패턴: 일치시킬 조건을 지정합니다.\n- 동작: 패턴이 일치할 때 무엇을 할지 지정합니다.\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 Markdown 형식으로 변경할 수도 있어요.\n\n```js\necho \"text\" | awk 'pattern { action }'\n```\n\n# 주요 사용 사례 및 예시\n\ndata.txt라는 파일을 고려해보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nJohn Doe 30 180\nJane Smith 25 165\nAlice Johnson 35 170\nBob Brown 28 175\nCharlie White 32 160\n```\n\n<img src=\"/assets/img/2024-06-20-TextProcessingwithAWKinLinuxUnixwithexamples_1.png\" />\n\n## 1. Printing Specific Columns separated by space\n\nTo print the first names (1st field) and ages (3rd field) separated by space:\n\n<div class=\"content-ad\"></div>\n\n```js\nawk '{ print $1, $3 }' data.txt\n\n\n----- 출력 결과 -----\n\nJohn 30\nJane 25\nAlice 35\nBob 28\nCharlie 32\n```\n\n## 2. 특정 문자로 구분된 특정 열 출력\n\n이름(첫 번째 열)과 나이(세 번째 열)을 세미콜론으로 구분하여 출력하는 방법:\n\n```js\nawk '{ print $1 \";\" $3 }' data.txt\n\n\n----- 출력 결과 -----\n\nJohn;30\nJane;25\nAlice;35\nBob;28\nCharlie;32\n```\n\n<div class=\"content-ad\"></div>\n\n## 3. 조건에 따라 행 필터링하기\n\n네 번째 열이 169보다 큰 경우 모든 행 출력합니다.\n\n```js\nawk '$4 > 169' data.txt\n\n\n----- 결과 -----\n\nJohn Doe 30 180\nAlice Johnson 35 170\nBob Brown 28 175\n```\n\n## 4. 특정 단어를 포함하는 행 출력\n\n<div class=\"content-ad\"></div>\n\n\"John\"이라는 단어를 포함하는 줄을 출력합니다.\n\n```js\nawk '/John/' data.txt\n\n\n----- 출력결과 -----\n\nJohn Doe 30 180\nAlice Johnson 35 170\n```\n\n로그 파일을 처리하고 \"Error\" 또는 \"Warning\"과 같은 키워드를 포함하는 줄을 검색할 때 유용하게 사용할 수 있습니다.\n\n## 5. 열을 합산하기\n\n<div class=\"content-ad\"></div>\n\n각 줄의 3번째와 4번째 열의 합계를 출력합니다.\n\n```js\nawk '{ print $3 + $4 }' data.txt\n\n\n----- 결과 -----\n\n210\n190\n205\n203\n192\n```\n\n- 다른 방법 (변수 사용)\n\n```js\nawk '{ sum=$3+$4 ; print sum }' data.txt\n```\n\n<div class=\"content-ad\"></div>\n\n## 6. 합계 값\n\n세 번째 열의 값을 합산하고 총합을 출력합니다.\n\n```js\nawk '{ sum+=$3 } END { print sum }' data.txt\n\n\n----- 출력 결과 -----\n\n150\n```\n\n## 7. 평균 계산\n\n<div class=\"content-ad\"></div>\n\n평균 연령을 계산하려면 (세 번째 필드):\n\n```js\nawk '{ sum += $3; count++ } END { print sum / count }' data.txt\n\n\n## 8. 라인 번호 출력\n\n각 라인에 라인 번호를 추가하고 출력합니다.\n\n<div class=\"content-ad\"></div>\n\nawk '{print NR, $0}' data.txt\n\n----- 출력 -----\n\n1 John Doe 30 180\n2 Jane Smith 25 165\n3 Alice Johnson 35 170\n4 Bob Brown 28 175\n5 Charlie White 32 160\n\n## 9. 필드 수 출력\n\n각 줄의 필드 수를 출력합니다.\n\nawk '{ print \"Number of fields:\", NF }' data.txt\n\n----- 출력 -----\n\nNumber of fields: 4\nNumber of fields: 4\nNumber of fields: 4\nNumber of fields: 4\nNumber of fields: 4\n\n<div class=\"content-ad\"></div>\n\n## 10. 첫 번째 및 마지막 필드 인쇄\n\nawk '{ print $1, $NF }' data.txt\n\n\n----- 출력 -----\n\nJohn 180\nJane 165\nAlice 170\nBob 175\nCharlie 160\n\n## 11. 대문자로 필드 인쇄\n\n첫 번째 필드를 대문자로 출력\n\n<div class=\"content-ad\"></div>\n\nawk '{ print toupper($1) }' data.txt\n\n\n### 결과\n\nJOHN\nJANE\nALICE\nBOB\nCHARLIE\n\n## 12. 필드로부터 하위 문자열 추출\n\n2번째 필드에서 하위 문자열 추출: 1번째 문자부터 3번째 문자까지\n\nawk '{print substr($2,1,3)}' data.txt\n\n\n### 결과\n\nDoe\nSmi\nJoh\nBro\nWhi\n\n<div class=\"content-ad\"></div>\n\n## 13. 각 줄의 필드 길이 출력\n\n각 줄의 2번째 필드의 길이를 출력합니다.\n\nawk '{ print length($2) }' data.txt\n\n\n----- 출력 결과 -----\n\n3\n5\n7\n5\n5\n\n## 14. 사용자 정의 함수\n\n<div class=\"content-ad\"></div>\n\n보다 복잡한 작업을 위해 awk 스크립트 내에서 함수를 정의할 수 있어요:\n\nawk '\nfunction square(x) { return x * x }\n{ print $3, \" --> square :\" , square($3) }\n' data.txt\n\n\n----- 출력 -----\n\n30  --> square : 900\n25  --> square : 625\n35  --> square : 1225\n28  --> square : 784\n32  --> square : 1024\n\n# 결론\n\nawk는 여러 가지 방식으로 텍스트 파일을 조작하고 분석하는 데 도움이 되는 다재다능한 도구입니다. 데이터 추출, 계산 수행, 또는 텍스트 변환 등이 목적이라면 awk가 작업을 간소화하는 강력한 기능 세트를 제공합니다.\n\n<div class=\"content-ad\"></div>\n\nawk 명령어를 실험해보세요! 이를 통해 Linux/Unix에서 더 효율적인 텍스트 처리를 위한 워크플로에 효과적으로 통합할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-TextProcessingwithAWKinLinuxUnixwithexamples_0.png"},"coverImage":"/assets/img/2024-06-20-TextProcessingwithAWKinLinuxUnixwithexamples_0.png","tag":["Tech"],"readingTime":4},{"title":"이메일 OSINT","description":"","date":"2024-06-19 21:46","slug":"2024-06-19-EmailOSINT","content":"\n\n## 안녕하세요 여러분 !!!\n\n- 여러분의 이메일이나 비밀번호가 공개되어 있는지 궁금한 적이 있었나요?\n\n혹은 여러분의 데이터가 유출된 웹사이트, 패스트빈, 또는 텔레그램 그룹에 공개적으로 혹은 유료로 게시되었나요?\n\n그렇다면 계속 읽는 것이 도움이 될 것입니다. 저는 이에 대한 완벽한 도구를 소개하겠습니다. 또한 이 도구들은 OSINT, 사이버 보안 전문가, 해커, 그리고 그들의 동료들이 모두의 정보를 수집하고 이메일과 관련된 모든 정보를 수집하여 대상의 프로필을 작성하는 데 사용하는 도구입니다.\n\n<div class=\"content-ad\"></div>\n\n시작하기 전에, 알지 못하는 분들을 위해 온라인 안전을 유지할 수 있는 몇 가지 사이버-위생 도구와 주의사항을 공유하고 싶어요.\n\n# 복잡한 암호 및 2단계 인증 앱 사용하기!\n\n확실하게 말하자면, 최고 수준의 2단계 인증 앱을 사용하더라도, 웹사이트나 다른 보안 방법을 사용하는 경우에도 만약 누군가가 호스트 (예: 구글, 페이스북, 혹은 지역 가게)를 해킹한다면, 모든 노력이 물거품이 될 수 있어요. 그럼에도 불구하고, 포기하지 말아야 합니다. 왜냐하면 종종 한 계정을 해킹해 권한을 높이는 과정으로 시작하기 때문이에요.\n\n# 모든 계정에 같은 이메일 주소를 사용하는 것을 피해주세요.\n\n<div class=\"content-ad\"></div>\n\n왜요? 해커가 당신의 모든 계정에 대한 단일 이메일 주소를 가지고 있는 서버로 침입한다고 상상해봅시다. 오직 한 개의 이메일 주소 뿐이라면, 그가 이 주소와 연결된 모든 계정 및 데이터를 발견하기까지 시간 문제입니다. 이것은 무수히 많은 가능한 연결된 시나리오 중 하나에 불과합니다.\n\n# 가리기, 전달 및 임시 이메일 서비스 사용하기\n\n가령 가리기, 전달 또는 임시 이메일 서비스를 잘 활용하면 좋은 수준의 개인 정보 보호를 효과적으로 유지할 수 있습니다. 더불어 이들은 단일 이메일 주소에 대한 OSINT 또는 추적 도구를 강화할 수 있습니다. 다음은 몇 가지 옵션입니다. 더 많은 옵션이 필요하다면, 이메일 및 기타 도구에 대한 무수히 많은 도구 모음을 위한 마지막 링크를 클릭하세요. (진행 중인 내용)\n\n- 발행 전에 여러 링크를 삭제해야 해서 놓친 것이 있을 수 있습니다. 부족한 부분은 아래에서 찾아볼 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\nOOSINT [https://start.me/p/ME7aRA/oosint](https://start.me/p/ME7aRA/oosint)\n\n이메일 주소를 다룰 때 기억해야 할 몇 가지 기본 사항들입니다. 이제 OSINT 웹사이트와 앱으로부터 어떤 정보를 수집할 수 있는지 살펴볼 수 있습니다.\n\n# Epieos\n\n- [https://epieos.com](https://epieos.com)\n\n<div class=\"content-ad\"></div>\n\n간단한 웹사이트로 이메일 주소 또는 전화 번호에 관한 기본 정보를 수집합니다. Google, Email Checker(+200개 사이트), Skype, LinkedIn, Nike Run Club, Fitbit, GitHub, Duolingo, Asics Runkeeper, Adidas Runtastic, Strava, Vivino, Facebook, Proton Mail, Phone Checker, Etsy, Have I Been Pwned?, Dropbox, Foursquare, Flickr, Chess.com, Substack, Trello, Notion, Gravatar 등의 결과를 제공합니다.\n\n데이터를 수집할 때 유용한 도구이며, 무료 버전도 몇 초 안에 기본 결과를 제공합니다.\n\n- [가격 정보 보러가기](https://epieos.com/pricing)\n\n# Dehashed\n\n<div class=\"content-ad\"></div>\n\n- https://dehashed.com\n\n이 웹 사이트는 IP 주소, 이메일, 휴대전화 등과 관련된 정보를 찾는 데 이상적입니다. 무료 버전은 흐릿한 결과를 제공하지만 프로 버전은 합리적인 가격으로 완전한 가시성을 제공합니다. 탈락한 자격 증명을 확인하려는 개인 또는 비즈니스, 대상을 감시하는 프로페셔널 조사관 또는 윤리적 해커 등에 적합합니다. 전반적으로 이 분야에서 최고의 웹 사이트로 여겨집니다.\n\n- https://dehashed.com\n\n# IRBIS\n\n<div class=\"content-ad\"></div>\n\n- https://irbis.espysys.com\n\n이 플랫폼은 모바일 및 이메일을 포함한 다양한 채널에서 온라인 데이터를 수집하는 데 중요하고 포괄적인 소스를 제공합니다. 소셜 미디어 인텔리전스(SOCMINT)에 초점을 맞추며 사용자에게 다양한 정보 소스에 대한 액세스를 부여합니다. 구독료가 있지만, 새로 가입한 사용자는 대개 처음 계정을 열 때 무료 검색 크레딧을 받습니다. 온라인을 탐험할 때 들르고 싶은 곳입니다.\n\n# IntelX.io\n\n- https://intelx.io\n\n<div class=\"content-ad\"></div>\n\n이 플랫폼은 폭넓은 온라인 데이터 스크래핑 도구를 제공합니다. 무료 버전은 완전한 데이터셋을 제공하지는 않을 수 있지만, 위반 파일 이름을 노출하여 사용자가 추가적인 특정 검색을 수행할 수 있도록 합니다. 이 웹사이트는 이메일, 전화번호, 비트코인 지갑 등 다양한 소스에서 데이터를 추출할 수 있어서 중요한 대상 정보에 접근할 수 있도록 합니다.\n\n# 다른 유사한 웹사이트:\n\n- https://haveibeenpwned.com\n\n- https://www.voilanorbert.com\n\n<div class=\"content-ad\"></div>\n\n- [https://app.orbitly.io](https://app.orbitly.io)\n- [https://www.maltego.com](https://www.maltego.com)\n- [https://intel471.com/solutions/attack-surface-protection](https://intel471.com/solutions/attack-surface-protection)\n- [https://www.emailsherlock.com](https://www.emailsherlock.com)\n\n<div class=\"content-ad\"></div>\n\n## 또한, 이제는 터미널, 클라우드 인스턴스, 도커, CLI OS 또는 가상 머신에 이상적인 GitHub 도구들을 확인해보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# 블랙 타이거\n\n- https://github.com/VirusZzHkP/The-Black-Tiger\n\n블랙 타이거 도구는 다양한 영역의 OSINT에 초점을 맞추고 있습니다. 사람, 닉네임, 소셜 네트워크, 이메일, 전화 번호, 웹 페이지, 공개 IP 및 이미지를 포함합니다. 이 도구의 아이디어는 가장 고급 OSINT 기술을 한 곳에 수집하고 자동화해 효율적이고 편리하게 만드는 것이었습니다. 이 도구는 몇 번의 클릭으로 정보를 조직적으로 수집하고 제시합니다. 각 섹션은 특정 유형의 정보를 추출하기 위한 부분으로 나눠지지만, 이용 가능한 모든 데이터를 추출할 수도 있습니다.\n\n# 홀히\n\n<div class=\"content-ad\"></div>\n\n- [https://github.com/megadose/holehe](https://github.com/megadose/holehe)\n\n안녕하세요! \"Holehe\"는 특정 이메일 주소와 연결된 등록된 계정을 효율적으로 식별하기 위해 설계된 도구입니다. 이 도구는 해당 이메일이 Twitter, Instagram, Imgur 및 120개 이상의 다른 인기 웹사이트에 연결되어 있는지 확인할 수 있습니다. 이 도구는 이러한 플랫폼의 비밀번호를 잊었을 때의 정보를 검색합니다. 또한 Python 3에서 실행되도록 구축되어 최신 프로그래밍 환경과 호환됩니다.\n\n# Poastal\n\n- [https://github.com/jakecreps/poastal](https://github.com/jakecreps/poastal)\n\n<div class=\"content-ad\"></div>\n\n\"P\noastal\"은 어떤 이메일 주소에 대해 포괄적인 정보를 제공하는 필수적인 이메일 OSINT(Open Source Intelligence) 도구입니다. 이 강력한 도구를 사용하면 이메일 소유자의 이름을 알아낼 수 있고, 전달 가능 여부를 확인하며, 일회용으로 사용되거나 스팸으로 간주되는지 확인하고, Facebook, Twitter, Snapchat 등 여러 인기 플랫폼에 등록되어 있는지도 확인할 수 있습니다. 이는 이메일 주소와 관련된 중요한 정보를 수집하는 데 유용한 자원입니다.\n\n# GHunt\n\n- https://github.com/mxrch/GHunt\n\nG\nHunt (v2)는 효율적인 진화에 중점을 둔 최신 안전 구글 프레임워크입니다. 이 도구는 현재 OSINT(Open Source Intelligence)에 특화되어 있지만 다양한 구글 관련 용도로 적용할 수 있습니다. 이 도구의 특징은 CLI 사용 및 모듈, Python 라이브러리 통합, 원활한 작동을 위한 전체 비동기 지원, JSON 내보내기 기능 및 간결한 로그인 절차를 위한 편리한 브라우저 확장 프로그램을 포함하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# Seekr\n\n- https://github.com/seekr-osint/seekr\n\nSeekr은 사용자 친화적인 OSINT(Open Source Intelligence) 데이터를 수집하고 관리하기 위한 툴킷입니다. 선호하는 OSINT 도구를 모두 통합한 데스크톱 화면을 제공합니다. 백엔드는 Go로 개발되었으며 데이터베이스로 BadgerDB를 사용하여 다양한 데이터 수집, 조직 및 분석 기능을 제공합니다. Seekr은 연구원, 조사원 또는 정보 수집을 하는 개인에게 필요한 데이터를 찾고 관리하는 것을 간편하게 만들어줍니다. 여러분의 OSINT 작업을 어떻게 개선할 수 있는지 확인해 보세요!\n\n# 다른 옵션들...\n\n<div class=\"content-ad\"></div>\n\n더 많은 옵션을 원하시면 `https://start.me/p/ME7aRA/oosint`를 방문해보세요.\n\n# 아니면\n\n이제 왜 계정마다 동일한 이메일 주소를 사용하는 것을 피해야 하는지 알게 되셨죠. 이렇게 하면 불허한 접근과 잠재적인 데이터 유출 위험이 높아집니다. 일시적, 전달 및 마스킹 이메일 서비스를 활용하면 악의적인 목적에서 민감한 정보를 보호하기 위한 추가적인 방어층을 더할 수 있습니다. 온라인 보안과 개인정보 보호를 우선시하며 잠재적인 위험을 완화하기 위해 이러한 조치를 항상 고려하는 것이 중요합니다.\n\n# 아직 궁금한 점이 있으신가요? ¡\n\n<div class=\"content-ad\"></div>\n\n아래에, 아마 당신이 좋아할만한 것들이 있을 거에요! 😊","ogImage":{"url":"/assets/img/2024-06-19-EmailOSINT_0.png"},"coverImage":"/assets/img/2024-06-19-EmailOSINT_0.png","tag":["Tech"],"readingTime":6}],"page":"59","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}