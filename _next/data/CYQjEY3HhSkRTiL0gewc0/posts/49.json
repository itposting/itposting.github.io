{"pageProps":{"posts":[{"title":"라즈베리 파이 AI 키트를 사용한 비구조화 데이터 처리 - Hailo Edge AI","description":"","date":"2024-06-20 17:27","slug":"2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI","content":"\n\n비구조화된 데이터 처리, Raspberry Pi 5, Raspberry Pi AI-Kit, Milvus, Zilliz, 데이터, 이미지, 컴퓨터 비전, 딥 러닝, 파이썬\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_0.png)\n\n# 엣지에서 라이브 카메라 스트림에서 이미지를 감지, 표시 및 저장하기\n\nRaspberry Pi 5와 NVIDIA Jetson Orin Nano와 같은 장치의 성능 덕분에 소규모 예산으로도 Edge AI 사용 사례를 구축할 수 있습니다. 최근에 Raspberry Pi AI Kit이 RPI5 플랫폼용으로 출시되었으므로 한 번 사용해보기로 했습니다.\n\n<div class=\"content-ad\"></div>\n\nAI 키트는 초당 13 테라 오퍼레이션(TOPS)을 처리할 수 있는 신경망 추론 가속기를 추가합니다. 이것은 70달러에 구매할 수 있어서 정말 좋은 거죠. 이 M.2 Hat에 부착된 Hailo-8L M.2 Entry-Level 가속 모듈은 우리에게 AI 기능을 제공할 겁니다.\n\n첫 번째 데모에서는 제가 제공된 RPI5 Hailo AI Python 예제 중 하나를 수정하여 웹캠에서 실시간 이미지 감지를 수행한 다음 검출된 내용을 Slack 채널로 보내고 중요한 메타데이터를 Milvus로 벡터화했습니다.\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_1.png)\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_2.png)\n\n<div class=\"content-ad\"></div>\n\n# 라즈베리 파이 5에서 진행 중인 라이브 실행\n\n우리는 Hailo의 예제 RPI5 객체 탐지 프로그램을 사용 중입니다. 이 프로그램은 Slack, MiNio 및 Milvus로 보내기 위해 향상시켰습니다.\n\n따라서 예제 객체 탐지 프로그램을 사용 중인데, 먼저 Slack, Milvus, S3, TIMM, Sci-Kit Learn, Pytorch 및 UUID를 위한 내 라이브러리를 임포트하기 위해 일부 임포트를 추가했습니다. 나중에 사용할 몇 가지 상수를 설정했습니다. 그런 다음 Milvus 서버와 Slack 채널에 연결하고 GStreamer 루프를 시작했습니다. 시간을 확인하고 무언가를 감지한 경우 카메라 프레임을 파일에 저장하여 S3에 업로드하고 Slack 채널로 보냈습니다. 마지막으로 S3 경로, 파일 이름, 레이블 및 신뢰도의 중요한 메타데이터와 벡터화된 이미지를 추가했습니다. 각 항목에 대해 자동 생성된 ID를 받았습니다.\n\n우리의 이미지는 MinIO에 업로드되었습니다:\n\n<div class=\"content-ad\"></div>\n\n![image 1](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_3.png)\n\n우리는 또한 텍스트 메시지와 함께 #reports 슬랙 채널로 보냈습니다.\n\n![image 2](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_4.png)\n\n가장 중요한 것은 메타데이터와 벡터를 업로드했고 이미 매우 빠른 검색을 위해 사용 가능합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_5.png)\n\nNow, we can begin querying our vectors, and I will demonstrate how to do it using a Jupyter notebook.\n\n## Querying the Database and Displaying Images\n\n![image](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_6.png)\n\n\n<div class=\"content-ad\"></div>\n\n저는 이 데모 실행 화면을 녹화했으니, 실시간으로 무슨 일이 일어나는지 확인해 보실 수 있습니다.\n\n![Demo Screenshot](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_7.png)\n\n만약 하나를 구매하셔서 나의 데모를 복제하고 싶으시다면, 이 기사의 끝에 있는 단계들을 확인해 주세요.\n\n# 데모 패킹 목록\n\n<div class=\"content-ad\"></div>\n\nMinIO/S3, Milvus, Slack, Python, Boto3, OpenCV2, Pytorch, Sci-Kit Learn, TIMM, Hailo, YOLOv6n, Object Detection, Raspberry Pi AI Kit, Raspberry Pi 5 with 8GB RAM, logi webcam, resnet34, Torchvision, PyMilvus, Hailo8L M.2 module, M.2 M-Key Hat, Heat Sink.\n\n# 시작하기\n\n하드웨어를 추가한 후 (아래의 비디오 및 링크를 참조하세요), 라이브러리를 설치하고 재부팅하시면 준비가 된 것입니다.\n\n```js\ntspann@five:/opt/demo $ \nhailortcli fw-control identify\n\n장치에서 실행 중: 0000:01:00.0\n보드 식별 중\n제어 프로토콜 버전: 2\n펌웨어 버전: 4.17.0 (릴리스, 앱, 확장 컨텍스트 스위치 버퍼)\n로거 버전: 0\n보드 이름: Hailo-8\n장치 아키텍처: HAILO8L\n일련 번호: HLDDLBB241601635\n파트 번호: HM21LB1C2LAE\n제품 이름: HAILO-8L AI ACC M.2 B+M KEY MODULE EXT TMP\n\ntspann@five:/opt/demo $ \ndmesg | grep -i hailo\n\n[    3.155152] hailo: 모듈 초기화. 드라이버 버전 4.17.0\n[    3.155295] hailo 0000:01:00.0: Probing on: 1e60:2864...\n[    3.155301] hailo 0000:01:00.0: Probing: 장치 확장용 메모리 할당, 11600\n[    3.155321] hailo 0000:01:00.0: 장치 활성화 (0000 -> 0002)\n[    3.155327] hailo 0000:01:00.0: Probing: 장치 활성화됨\n[    3.155350] hailo 0000:01:00.0: Probing: 매핑된 바 0 - 0000000095e362ea 16384\n[    3.155357] hailo 0000:01:00.0: Probing: 매핑된 바 2 - 000000005e2b2b7e 4096\n[    3.155362] hailo 0000:01:00.0: Probing: 매핑된 바 4 - 000000008db50d03 16384\n[    3.155365] hailo 0000:01:00.0: Probing: 최대_desc_page_size를 4096로 강제 설정 (권장값은 16384)\n[    3.155375] hailo 0000:01:00.0: Probing: 64비트 dma 활성화\n[    3.155378] hailo 0000:01:00.0: Probing: 사용자 공간 할당 VDMA 버퍼 사용\n[    3.155382] hailo 0000:01:00.0: ASPM L0s 비활성화\n[    3.155385] hailo 0000:01:00.0: ASPM L0s 성공적으로 비활성화\n[    3.417111] hailo 0000:01:00.0: 펌웨어가 성공적으로 로드되었습니다\n[    3.427885] hailo 0000:01:00.0: Probing: 보드 1e60-2864 추가, /dev/hailo0\n```\n\n<div class=\"content-ad\"></div>\n\n\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_8.png)\n\n# 예제 코드\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_9.png)\n\n# 모델 동물원\n\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_10.png)\n\n동영상 안내\n\n# 추가 명령어\n\n```js\ngst-inspect-1.0 hailotools\nlspci | grep Hailo\nuname -a\nv4l2-ctl --list-formats-ext -d /dev/video0\nls /dev/video*\nffplay -f v4l2 /dev/video0\n```\n\n<div class=\"content-ad\"></div>\n\n# 자료\n\n- [Raspberry Pi AI Kit 제품](https://www.raspberrypi.com/products/ai-kit/)\n- [Raspberry Pi AI Kit 관련 문서](https://www.raspberrypi.com/documentation/accessories/ai-kit.html)\n\n보시는 것이 마음에 드셨다면, 어떻게 개선할 수 있는지 댓글로 알려주세요. 또 다음에 어떤 것을 보여드려야 할지도 알려주시면 감사하겠습니다. 프린스턴, 필라델피아, 뉴욕시에서의 밋업이나 유튜브에서 뵙기를 기대합니다.👋\n\n<div class=\"content-ad\"></div>\n\nMilvus로 오세요!\n\n매주 제 뉴스레터를 읽어보세요!\n\n더 많은 멋진 비구조화 데이터, AI 및 Vector Database 비디오를 보려면 Milvus 벡터 데이터베이스 비디오를 여기에서 확인하세요:\n\nhttps://www.linkedin.com/company/zilliz/\n\n<div class=\"content-ad\"></div>\n\nhttps://www.linkedin.com/in/timothyspann/\n\nhttps://milvusio.medium.com","ogImage":{"url":"/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_0.png"},"coverImage":"/assets/img/2024-06-20-UnstructuredDataProcessingwithaRaspberryPiAIKitHailoEdgeAI_0.png","tag":["Tech"],"readingTime":6},{"title":"최고의 직접 만든 생일 스프","description":"","date":"2024-06-20 17:25","slug":"2024-06-20-TheBestHomemadeBirthdaySoup","content":"\n\n## 음식과 이야기\n\n![생일날 만들었을 때 가장 좋은 홈메이드 수프](/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_0.png)\n\n오늘은 \"외로움 전염병\"에 대해 읽다가 있습니다. 저는 외로움을 전혀 느끼지 않은 것인지, 아니면 사실 대부분의 시간이 외로움을 느끼는 것인지 확신이 안 드는데요. 외로움은 우리가 혼자 있을 때만이 아니라(저는 혼자 있는 것을 좋아해요), 거부당한 느낌이든, 오해받은 느낌이든, 배제된 느낌이든 발생할 수 있어요. 이런 종류의 외로움은 우리 사랑하는 리틀 베어에게도 거의 닥쳤었지만, 제발, 그곰은 긍정적인 태도를 유지하고 있어요.\n\n리틀 베어를 아시나요? 그는 엘스 홀멜런드 미나릭(Elsie Holmelund Minarik)에 의해 창조되고, 모리스 센댁(Maurice Sendak)에 의해 살아있게 되었어요. 한 이야기에서 리틀 베어는 생일에 홀로 있게 되어요. 그는 어머니를 찾으며 그녀를 부르지만, 어머니는 없어요. 그리고 더 최악인 건, 생일 케이크도 없다는 거죠. 생일에 잊히거나 버려진다는 느낌은 우리 중 몇몇은 울게 할지도 몰라요. 하지만 리틀 베어는 그렇지 않아요:\n\n<div class=\"content-ad\"></div>\n\n작은 곰이 친구들이 올 것을 희망하며, 무엇이든 손에 있는 재료로 생일 수프를 만들기로 결심합니다.\n\n우리는 아들이 어렸을 때 많은 시간동안 이 이야기(그리고 모든 작은 곰 이야기)를 읽었습니다. 그래서 저녁에 \"당근과 콩, 감자로 어떤 종류의 수프를 만들 계획이라고 말했을 때, 배우자에게 작은 곰 이야기를 떠올리며 \"당근과 콩, 감자로 생일 수프를 만들 수 있어\" 라고 말했습니다. 나는 미소를 지었습니다. 오늘은 우리의 생일 중 아무것도 아니었지만, 난 여전히 생일 수프를 만들 것이었습니다.\n\n내가 그렇게 한 방법은 다음과 같습니다.\n\n# 최고의 생일 수프\n\n<div class=\"content-ad\"></div>\n\n리틀 베어처럼 시작을 했습니다. 손에 있는 재료부터 사용했어요.\n\n- 당근\n- 감자\n- 통조림 콩 (검은 콩, 핑토 콩, 가방조 콩)\n- 신선한 타임\n- 셀러리\n- 채소 육수\n- 채소 증류용 조미료\n- 건조한 허브와 양념\n- 소금\n- 버터\n- 크림\n\n육수가 하나밖에 없어서 채소 증류용 조미료가 필요했어요. 여분이 생기도록 해야 했거든요. 선택할 수 있는 다양한 통조림 콩 중에서 핑토 콩이 이번 수프에 가장 잘 어울릴 것 같아 골랐어요.\n\n일단 수프 냄비(우리는 '대야'라고 부르죠)에 육수를 붓고, 그 다음에 감자, 당근, 셀러리를 다져 넣었어요. 셀러리는 다른 야채보다 더 빨리 부드러워지기 때문에 나중에 조금씩 넣는 게 더 좋았을 텐데, 저는 서두르다 보니 한꺼번에 다 넣었죠. 😉\n\n<div class=\"content-ad\"></div>\n\n마지막으로 시간(Thyme)을 통째로 넣고, 싸늘한 세이지로 된 소량의 작은 언더플로우형(SAG), 그리고 탈머릭 작은 언더플로우도 넣었어요. 이 모든 것을 뚜껑을 덮고 끓였죠. 여기에 베이리프도 추가했어야 하는데, 깜빡했네요. 소금도 뿌려야 했어요.\n\n수프는 뚜껑을 덮은 채로 좋은 30분간 끓였고, 그 후로는 수프를 들여다보고 축축한 시간(Thyme)을 체에 걸러내었어요. 이제 콩과 두꺼운 버터 한 조각도 넣을 때가 왔어요. 이들을 추가한 뒤, 뚜껑을 벗고 몇 분 동안 계속 끓였어요.\n\n수프가 준비된 것 같아 보일 때, 불을 끄고 조금 식힌 뒤, 아름다운 크림 줄기를 휘젓었어요. 그리고 결국 소금도 뿌렸죠 (충분하지 않은 것 같아요).\n\n드디어 우리에게는 생일 수프가 준비되었어요. 지금 필요한 것과 정확히 맞는 최고의 생일 수프였어요. 여러분의 최고의 생일 수프에는 다른 재료가 들어갈 수도 있어요. 더 많은 정보를 위해서 냉장고와 식료품 저장실(pantry)을 확인해 보세요.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_1.png\" />\n\nDIY 프로젝트와 레시피는 자주 혼자서 즐기기 좋지만, 때로는 우리가 연결이 끊어지거나 잊힌 것처럼 느낄 때의 외로움을 해소해 주지 못할 수도 있어요. 그럴 때에는 생일 수프(또는 요리 과정)를 친구와 함께 나누는 것이 필요할지도 모르겠어요. 곰, 오리, 고양이와 함께 생일 수프를 즐겨보세요. 그들은 모두 생일 수프를 좋아해요.\n\n🥣\n\n💛 내 이야기 구독하기","ogImage":{"url":"/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_0.png"},"coverImage":"/assets/img/2024-06-20-TheBestHomemadeBirthdaySoup_0.png","tag":["Tech"],"readingTime":3},{"title":"간자시 꽃 머리 스크런치 만들기 안내","description":"","date":"2024-06-20 17:24","slug":"2024-06-20-KanzashiFlowerHairScrunchieTutorial","content":"\n\n🔍 지금 칸자시 꽃 헤어 스크런치 만들기 튜토리얼을 확인해보세요! 이 📁 소잉 패턴을 살펴보고 여기에서 🆓 무료 다운로드 혜택을 받아보세요. 함께 공예를 시작해봐요! 🚀\n\n밝은 색 조화로운 칸자시 스타일의 손톱으로 만든 아름다운 헤어 스크런치. 이 밝은 컬러의 칸자시 스타일 헤어 스크런치는 모든 헤어스타일에 아름다움을 더해주고 멋진 분위기를 조성합니다. 이 튜토리얼에는 사진과 상세한 지침이 포함되어 있어 여러분이 쉽게 직접 만들 수 있는 방법을 알려줄 거에요. 이 사랑스러운 헤어 스크런치(크기 2.7인치 (7cm))는 여러분과 여러분의 아기에게 모두 완벽하며 기쁜 선물이 될 거예요. 당신의 스타일을 돋보이게 하고 휴일을 화려하게 만들어줄 칸자시 꽃이 달린 헤어 스크런치. 이 칸자시 스크런치는 연한 색상으로 제작할 수도 있으며 어떤 의상에도 완벽하게 장식해줄 거예요. 간단한 관리 팁: 칸자시 액세서리의 아름다움을 유지하려면 빨거나 다리지 마세요. 적절한 관리로 많은 해 동안 그들의 빛을 유지할 수 있어요.\n\n![이미지](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_0.png)\n\n![이미지](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_1.png)\n\n<div class=\"content-ad\"></div>\n\n\n![Kanzashi Flower Hair Scrunchie Tutorial Part 2](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_2.png)\n\n![Kanzashi Flower Hair Scrunchie Tutorial Part 3](/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_3.png)\n\nPhoto by Hobby3DStudio on Creative Fabrica\n\nDisclaimer: This article contains affiliate links, which means we may earn a commission at no additional cost to you if you make a purchase through these links.\n","ogImage":{"url":"/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_0.png"},"coverImage":"/assets/img/2024-06-20-KanzashiFlowerHairScrunchieTutorial_0.png","tag":["Tech"],"readingTime":2},{"title":"라즈베리 파이를 위한 자체 Linux 이미지 만들기","description":"","date":"2024-06-20 17:22","slug":"2024-06-20-BuildyourownLinuxImagefortheRaspberryPi","content":"\n\n<img src=\"/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_0.png\" />\n\n라즈베리 파이와 유사한 싱글 보드 컴퓨터는 요즘 매우 인기가 많습니다. 그 가능성은 거의 무한합니다. 홈 서버부터 미디어 스테이션, IoT 프로젝트까지 모든 것이 가능합니다. 사용하기 쉽게 만드는 두 가지 요소는 아마도 거대한 커뮤니티와 Raspian과 같은 준비된 SD 카드 이미지일 것입니다. 웹에서 최신 이미지를 다운로드하고 SD 카드에 플래싱하는 것은 시작하는 가장 쉽고 빠른 방법입니다. Raspberry를 사용하거나 자체 프로젝트를 수행하고 싶을 경우에는 문제가 없습니다. 그러나 동일한 시스템을 다른 시스템이나 여러 시스템에 복제하려 한다면 복잡해집니다. 이미지의 크기와 보안을 신경 쓴다면 더 복잡해집니다. 안전한 리눅스 시스템의 솔루션을 제시할 수 있는 능력이 있다면 상상할 수 없습니다. 그러나 자신만의 이미지를 빌드하고 정확히 이미지에 무엇이 포함되어 있는지를 파악하는 것은 좋은 시작점입니다. 마지막으로 리눅스 작동 방식에 대해 좀 더 배우고, 스크래치에서 자신의 리눅스를 빌드했다고 말할 수 있는 것은 흥미로울 것입니다.\n\n이 첫 번째 기사에서는 깊이에 대해 다루지 않겠습니다. 전체 시스템을 이해하고 필요에 맞게 사용자 정의하고자 한다면 알아야 할 것이 훨씬 더 많습니다. 대신, 빠른 성공을 원하고 첫 번째 이미지를 빌드하는 것에 집중하겠습니다. 깊게 이해하고 싶다면 더 많은 기사를 기대해 주세요.\n\n# Yocto Project\n\n<div class=\"content-ad\"></div>\n\nYocto를 사용하여 자체 Linux 배포판을 빌드할 거에요.\n\n\"Yocto Project, 임베디드 Linux 배포판이 아니에요. 당신을 위해 커스텀한 배포판을 만들어줘요.\" 이 공식 웹사이트의 설명은 Yocto가 무엇인지 가장 잘 표현한 것 같아요. Yocto를 사용하면 자신만의 Linux 이미지를 만드는 데 도움이 되는 유용한 도구와 구성 요소의 모음으로 생각해야 해요. 대안이 있지만, Yocto는 아마도 가장 인기 있는 것 중 하나일 거에요.\n\nYocto Project의 다양한 부분을 자세히 살펴보려면 공식 웹사이트를 확인해보세요.\n\n첫 번째 이미지를 위해 접하게 되는 것은 메타 레이어와 BitBake입니다. 이 두 요소가 시스템의 핵심을 형성합니다.\n\n<div class=\"content-ad\"></div>\n\n# 메타 레이어\n\nYocto는 대부분 레시피와 구성 데이터를 포함하는 여러 가지 레이어 위에 구축됩니다. 레시피는 무엇이 어떻게 빌드되는지 설명하는 데 사용됩니다. 예를 들어, 리눅스 커널의 소스 코드를 다운로드하는 위치와 올바르게 컴파일하기 위해 어떤 명령어 및 도구를 사용해야 하는지가 포함되어 있습니다. 구성 데이터는 예를 들어, Raspberry Pi가 어떤 아키텍처를 사용하는지 설명하므로 레시피가 컴파일해야 하는 대상을 알 수 있습니다. 이것은 과소 평가일 수 있지만, 목표 시스템에 맞는 올바른 메타 레이어가 필요하다는 것을 알면 충분할 것입니다. 이 모든 것 안에 빌드 시스템에서 필요한 모든 것이 제공됩니다.\n\n# BitBake\n\nBitBake는 빌드를 위한 중앙 명령줄 도구입니다. 이것은 원래 OpenEmbedded 프로젝트의 일부였지만, 현재 Yocto 프로젝트와 OpenEmbedded 프로젝트에서 유지보수되는 독립적인 도구입니다.\n\n<div class=\"content-ad\"></div>\n\n# 빌드 시스템 설정\n\n이제 처음으로 자신만의 이미지를 설정하는 시간입니다. 빌드 환경을 설정하는 단계는 꽤 간단하지만 빌드가 완료될 때까지 시간이 걸립니다. Linux 이미지를 처음부터 빌드하는 것은 단점이 있습니다. 모든 것을 빌드해야 하며 이 과정은 CPU, RAM 및 HDD를 많이 사용합니다. 보통 컴퓨터에서 최대 8시간이 걸릴 수 있습니다. 하지만 걱정하지 마세요. 첫 번째 빌드가 완료되면 Yocto의 좋은 캐싱 알고리즘이 실행되어 새로운 요소와 변경된 요소만 빌드됩니다. 컴퓨터의 최소 무료 디스크 공간은 적어도 50GB여야 합니다. (참고: 저는 16 코어 AWS 클라우드 인스턴스에서 약 1시간 정도에 이 이미지를 빌드했습니다. 빌드 시간은 CPU 성능 및 다운로드 속도에 매우 의존적입니다. 클라우드에서 Yocto 이미지를 빌드하는 주제에 대해 자세한 내용은 후속 기사에서 다룰 수 있습니다.)\n\nYocto 프로젝트의 Mega Manual에서 빌드 시스템 호스트로 최종 테스트된 Linux 배포판 목록을 찾을 수 있습니다. 다른 배포판에서도 작동하지만 예상치 못한 문제가 발생할 수 있습니다. 이 기사의 모든 예제에서 나는 Ubuntu 18.04 LTS를 사용할 것입니다.\n\n첫 번째 단계는 Yocto의 선행 조건을 설치하는 것입니다. 이 명령어는 Ubuntu 또는 Debian에서 모든 패키지를 설치합니다. Mega Manual에서 다른 예제를 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 메타 레이어 가져오기\n\n모든 메타 레이어는 일반적으로 git을 통해 사용할 수 있습니다. 지금은 git이 무엇인지 알지 못해도 걱정하지 마세요. 우리는 지금 하나의 명령어만 사용할 것입니다. git clone 명령은 인터넷에서 저장소를 가져옵니다. 우리가 사용하는 -b dunfell 스위치는 가져올 버전을 지정합니다. 작성 시점에서 던펠(dunfell) 버전은 장기 지원을 받는 최신 버전입니다. 가장 최근 릴리스에 대한 개요는 https://wiki.yoctoproject.org/wiki/Releases를 참조하세요.\n\n어떤 메타 레이어도 가져오기 전에 우리는 yocto라는 프로젝트 폴더와 모든 메타 레이어를 담을 source 폴더를 만들 것입니다.\n\n```bash\nmkdir yocto\ncd yocto\nmkdir sources\n```\n\n<div class=\"content-ad\"></div>\n\n항상 필요한 메타 레이어는 poky입니다. yocto가 작동하는 데 필요한 모든 기본적인 것들이 포함되어 있어요. 아래의 git 명령어를 실행하여 가져올 수 있어요.\n\n```js\ngit clone git://git.yoctoproject.org/poky -b dunfell\n```\n\n라즈베리 파이를 위한 메타 레이어도 있어요. 라즈베리 파이를 실행하는 데 필요한 모든 정의가 포함되어 있는 멋지게 제작된 메타 레이어에요. 아래 명령어로 가져올 수 있어요.\n\n```js\ngit clone git://git.yoctoproject.org/meta-raspberrypi -b dunfell\n```\n\n<div class=\"content-ad\"></div>\n\n메타 레이어는 항상 어떤 메타 레이어에 의존하는지를 명시합니다. meta-raspberrypi의 readme에는 우리가 이미 가지고 있는 poky와 meta-openembedded이 필요하다고 나와 있습니다. 이 메타 레이어 자체는 여러 레이어로 나뉘어져 있습니다. 이 명령어를 통해 그 모든 레이어를 가져올 수 있습니다.\n\n```js\ngit clone https://git.openembedded.org/meta-openembedded -b dunfell\n```\n\n우리가 필요한 모든 메타 레이어입니다. 이제 프로젝트 폴더로 돌아가서 빌드 환경을 초기화해봅시다.\n\n```js\ncd ..\n. sources/poky/oe-init-build-env\n```\n\n<div class=\"content-ad\"></div>\n\n첫 번째 이미지를 생성할 준비가 거의 끝났어요. 두 개의 구성 파일을 편집하기만 하면 됩니다.\n\nconf 폴더에 있는 bblayers.conf 파일은 사용할 메타 레이어의 모든 경로가 들어 있어요.\n\n```js\nnano conf/bblayers.conf\n```\n\n마지막으로, conf 폴더에 있는 local.conf 파일은 몇 가지 기본 구성 및 우리에게 가장 중요한 빌드할 기기의 이름이 포함되어 있어요. 만약 라즈베리 파이 4를 위해 빌드하려면 raspberrypi4를 사용하고, 라즈베리 파이 3을 위해 빌드하려면 raspberrypi3를 사용하세요. 이게 Yocto를 사용하는 큰 이점 중 하나에요. 다른 시스템을 위해 동일한 이미지를 빌드하려면 한 줄의 구성만 바꾸면 돼요.\n\n<div class=\"content-ad\"></div>\n\n```js\nnano conf/local.conf\n[...]\nMACHINE ?= \"raspberrypi4\"\n[...]\n```\n\n위 모든 단계를 완료했으므로 이제 실제 빌드를 시작하고 완료될 때까지 기다리면서 커피를 한 잔 이상 마실 시간입니다.\n\n```js\nbitbake core-image-base\n```\n\n축하합니다! 라즈베리 파이를 위한 첫 번째 Linux 이미지를 빌드했습니다. 완성된 이미지는 tmp/deploy/images/repberrypi4/core-image-base-raspberrypi4.wic.bz2 경로에 있습니다. 이 파일은 압축되어 있습니다. 압축을 해제하려면 bzip2 명령 또는 7zip과 같은 도구를 사용하세요. \n\n<div class=\"content-ad\"></div>\n\n```js\nbzip2 -d -f tmp/deploy/images/raspberrypi4/core-image-base-raspberrypi4.wic.bz2\n```\n\n우리는 다른 라스비안 이미지처럼 SD 카드에 플래시만 하면 바로 부팅할 수 있어요. https://www.raspberrypi.org/documentation/installation/installing-images/\n\n![Image](/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_1.png)\n\n기본적으로 사용자 이름은 root이고 비밀번호는 비어 있어요.\n\n<div class=\"content-ad\"></div>\n\n# 다음 단계\n\n이 이정표를 달성하여 자랑스러워하는 것을 기대합니다. Yocto는 강력한 도구이며 더 많은 것을 배울 수 있습니다. 더 많은 정보를 얻고 싶다면 저를 팔로우해 다음 Yocto 관련 글을 놓치지 않도록 하세요.\n\n그동안 당신이 Yocto에 대해 계속 학습하고자 한다면, 스스로 학습을 계속하기 위한 시작점을 제공하겠습니다. 이미지에 추가 소프트웨어가 필요하다면, 먼저 OpenEmbedded Layer Index에서 시작해보세요. 거기서 소프트웨어 레시피가 포함된 메타 레이어를 검색할 수 있습니다. 그 레이어를 다운로드하여 bblayers.conf에 추가하고, 이미 존재하지 않은 경우에만 추가하세요. 그런 다음 레시피 이름을 local.conf 파일의 IMAGE_INSTALL_append에 추가하세요.\n\n```js\nIMAGE_INSTALL_append = \" nano\"\n```  \n\n<div class=\"content-ad\"></div>\n\n이미지를 다시 빌드하고 플래시하세요. 그러면 준비 끝!","ogImage":{"url":"/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-20-BuildyourownLinuxImagefortheRaspberryPi_0.png","tag":["Tech"],"readingTime":6},{"title":"주말 AI 프로젝트 라즈베리 파이에서 음성 인식, PTT 및 대규모 액션 모델 사용하기","description":"","date":"2024-06-20 17:19","slug":"2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi","content":"\n\n![2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0](/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0.png)\n\n2024년 초에는 거의 모든 기술 리뷰어가 Rabbit R1에 대해 썼어요. 이 제품은 가격이 $199인 첫 번째 휴대용 \"AI 어시스턴트\" 입니다. 작성자들에 따르면 \"신경 기호 프로그래밍\"과 LAM (\"대규모 액션 모델\")을 사용하여 다양한 작업을 수행합니다. 그런데 어떻게 작동할까요? 자신의 프로토 타입을 만드는 것이 가장 좋은 방법이죠!\n\n이전에 Rabbit R1에 대해 듣지 못한 독자들은 이와 유사한 많은 YouTube 리뷰를 찾을 수 있습니다. 이 글은 Rabbit R1을 어떻게 만들 수 있는가에 대한 흥미로운 분석을 한 Nabil Alouani의 게시물에 영감을 받았습니다.\n\n<div class=\"content-ad\"></div>\n\n저는 파이썬 코드에서 비슷한 아이디어를 구현하고, 실제 라즈베리 파이 하드웨어에서 어떻게 작동하는지 그리고 어떤 종류의 문제를 해결해야 하는지 살펴볼 것입니다.\n\n시작하기 전에 한 가지 알림: 저는 Rabbit 팀이나 그 판매와 관련이 없습니다.\n\n## 구성 요소\n\n이 글에서는 여러 구성 요소를 포함한 AI 어시스턴트를 만들 것입니다.\n\n<div class=\"content-ad\"></div>\n\n- 마이크와 Push-to-Talk (PTT) 버튼\n- 자동 음성 인식 (ASR), 녹음된 오디오 데이터를 텍스트로 변환할 수 있습니다.\n- 장치에 로컬로 실행되는 작은 언어 모델. 이 모델은 ASR에서 인식한 텍스트에서 작업을 구문 분석할 것입니다.\n- 작업이 로컬 모델에서 알 수 없는 경우 장치가 공용 API를 호출합니다. 여기에서 두 가지 옵션이 제공됩니다: 키를 가진 사람들을 위해 OpenAI API를 사용할 것이고, 무료 솔루션을 원하는 사람들을 위해 LLaMA 모델을 사용할 것입니다.\n- 결과(로컬 모델의 작업 또는 “큰” 모델에서의 텍스트 응답)는 장치 화면에 표시됩니다.\n\n이 기사의 코드는 라즈베리 파이용으로 작성되었지만, 일반 PC에서도 테스트할 수 있습니다. 그럼, 시작해봅시다!\n\n## 하드웨어\n\n이 프로젝트에는 리눅스가 실행되는 싱글 보드 컴퓨터인 라즈베리 파이 4를 사용할 것입니다. 라즈베리 파이에는 다양한 하드웨어를 연결할 수 있도록 여러 개의 GPIO (일반 목적 입출력) 핀이 있습니다. 휴대 가능하며 5V DC 전원만 필요합니다. 또한 128x64 OLED 디스플레이와 버튼을 연결할 것이며, 연결 다이어그램은 다음과 같습니다:\n\n\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_1.png)\n\n이 글을 쓰는 시점에 라즈베리파이 모델마다 (RPi 5는 더 빠르지만 더 비싸다) 및 RAM 크기에 따라 약 $80-120 정도의 비용이 듭니다 (최소 4GB RAM이 필요함). 디스플레이, 버튼 및 와이어 세트는 아마존에서 $10-15 정도로 구매할 수 있습니다. 소리 녹음을 위해서는 USB 마이크로폰이면 됩니다. 라즈베리파이 설정은 간단합니다. 이에 대한 충분한 자습서가 있습니다. 언급해야 할 점은 Raspbian의 32비트 및 64비트 버전이 모두 사용 가능하다는 것입니다. 대부분의 현대적인 Python 라이브러리는 더 이상 32비트 버전으로 제공되지 않기 때문에 64비트 버전이 필요합니다.\n\n이제 소프트웨어 부분에 대해 이야기해 봅시다.\n\n## Push-to-Talk (PTT)\n\n\n<div class=\"content-ad\"></div>\n\n라즈베리 파이에서 푸시투톡 모드를 구현하는 것은 비교적 간단합니다. 배선 다이어그램에서 볼 수 있듯이 PTT(푸시투톡) 버튼은 핀 중 하나에 연결되어 있습니다 (우리의 경우 핀 21번). 그 값을 읽으려면 먼저 GPIO 라이브러리를 가져와 핀을 구성해야 합니다:\n\n```js\ntry:\n    import RPi.GPIO as gpio\nexcept (RuntimeError, ImportError):\n    gpio = None\n\nbutton_pin = 21\ngpio.setup(button_pin, gpio.IN, pull_up_down=gpio.PUD_UP)\n```\n\n여기서 저는 핀 21을 “input(입력)”으로 설정하고 pull-up 저항을 활성화했습니다. \"pull-up(풀업)\"이란 버튼이 눌리지 않을 때 입력이 내부 저항을 통해 \"전원\"에 연결되어 있고, 그 값은 \"1\"인 상태를 의미합니다. 버튼이 눌리면 입력 값은 \"0\"이 됩니다 (따라서 Python 코드에서의 값은 반대로 됩니다: 버튼이 눌리지 않으면 \"1\", 눌리면 \"0\"이 됩니다).\n\n입력 핀이 구성되면, 그 값을 읽기 위해 필요한 코드는 한 줄뿐입니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nvalue = gpio.input(button_pin)\n```\n\n코딩을 좀 더 편리하게 하기 위해, 마지막 버튼 상태를 기억할 수 있는 GPIOButton 클래스를 만들었어요. 상태를 비교해서 버튼이 눌리거나 놓였는지 쉽게 감지할 수 있게 돼요.\n\n```js\nclass GPIOButton:\n    def __init__(self, pin_number: int):\n        self.pin = pin_number\n        self.is_pressed = False\n        self.is_pressed_prev = False\n        if gpio is not None:\n            gpio.setup(self.pin, gpio.IN, pull_up_down=gpio.PUD_UP)\n\n    def update_state(self):\n        \"\"\" Update button state \"\"\"\n        self.is_pressed_prev = self.is_pressed\n        self.is_pressed = self._pin_read(self.pin) == 0\n\n    def is_button_pressed(self) -> bool:\n        \"\"\" Button was pressed by user \"\"\"\n        return self.is_pressed and not self.is_pressed_prev\n\n    def is_button_hold(self) -> bool:\n        \"\"\" Button still pressed by user \"\"\"\n        return self.is_pressed and self.is_pressed_prev\n\n    def is_button_released(self) -> bool:\n        \"\"\" Button released by user \"\"\"\n        return not self.is_pressed and self.is_pressed_prev\n\n    def reset_state(self):\n        \"\"\" Clear the button state \"\"\"\n        self.is_pressed = False\n        self.is_pressed_prev = False\n\n    def _pin_read(self, pin: int) -> int:\n        \"\"\" Read pin value \"\"\"\n        return gpio.input(pin) if gpio is not None else 0\n```\n\n이 방식을 통해 라즈베리 파이가 없는 사용자들을 위해 “가상 버튼”을 만들 수도 있어요. 예를 들어, 이 “버튼”은 애플리케이션이 시작된 후 처음 5초 동안 눌린 상태일 수 있어요:\n\n<div class=\"content-ad\"></div>\n\n```python\nclass VirtualButton(GPIOButton):\n    def __init__(self, delay_sec: int):\n        super().__init__(pin_number=-1)\n        self.start_time = time.monotonic()\n        self.delay_sec = delay_sec\n\n    def update_state(self):\n        \"\"\" Update button state: button is pressed first N seconds \"\"\"\n        self.is_pressed_prev = self.is_pressed\n        self.is_pressed = time.monotonic() - self.start_time < self.delay_sec\n```\n\n가상 버튼을 사용하면 해당 코드를 Windows, Mac 또는 Linux PC에서 쉽게 테스트할 수 있습니다.\n\n## 소리 녹음 및 음성 인식\n\nPTT(푸시 투 토크) 버튼을 사용하여 소리를 녹음할 수 있습니다. 이를 위해 Python 사운드카드 라이브러리를 사용할 것입니다. 0.5초씩 오디오를 녹음하며, 이 정확도는 우리의 작업에 충분히 적합합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nimport soundcard as sc\n\n\nclass SoundRecorder:\n    \"\"\" 사운드 레코더 클래스 \"\"\"\n    SAMPLE_RATE = 16000\n    BUF_LEN_SEC = 60\n    CHUNK_SIZE_SEC = 0.5\n    CHUNK_SIZE = int(SAMPLE_RATE*CHUNK_SIZE_SEC)\n\n    def __init__(self):\n        self.data_buf: np.array = None\n        self.chunks_num = 0\n\n    def get_microphone(self):\n        \"\"\" 기본 마이크 가져오기 \"\"\"\n        mic = sc.default_microphone()\n        logging.debug(f\"녹음 장치: {mic}\")\n        return mic.recorder(samplerate=SoundRecorder.SAMPLE_RATE)\n\n    def record_chunk(self, mic: Any) -> np.array:\n        \"\"\" 새로운 데이터 청크 녹음하기 \"\"\"\n        return mic.record(numframes=SoundRecorder.CHUNK_SIZE)\n\n    def start_recording(self, chunk_data: np.array):\n        \"\"\" 새로운 문구 녹음 시작하기 \"\"\"\n        self.chunks_num = 0\n        self.data_buf = np.zeros(SoundRecorder.SAMPLE_RATE * SoundRecorder.BUF_LEN_SEC, dtype=np.float32)\n        self._add_to_buffer(chunk_data)\n\n    def continue_recording(self, chunk_data: np.array):\n        \"\"\" 문구 녹음 계속하기 \"\"\"\n        self.chunks_num += 1\n        self._add_to_buffer(chunk_data)\n\n    def get_audio_buffer(self) -> Optional[np.array]:\n        \"\"\" 오디오 버퍼 가져오기 \"\"\"\n        if self.chunks_num > 0:\n            logging.debug(f\"오디오 길이: {self.chunks_num*SoundRecorder.CHUNK_SIZE_SEC}s\")\n            return self.data_buf[:self.chunks_num*SoundRecorder.CHUNK_SIZE]\n        return None\n\n    def _add_to_buffer(self, chunk_data: np.array):\n        \"\"\" 버퍼에 새 데이터 추가하기 \"\"\"\n        ind_start = self.chunks_num*SoundRecorder.CHUNK_SIZE\n        ind_end = (self.chunks_num + 1)*SoundRecorder.CHUNK_SIZE\n        self.data_buf[ind_start:ind_end] = chunk_data.reshape(-1)\n```\n\nPTT 버튼과 사운드 레코더로 “스마트 어시스턴트” 파이프라인의 첫 부분을 구현할 수 있습니다:\n\n```js\nptt = GPIOButton(pin_number=button_pin)\n\nrecorder = SoundRecorder()\nwith recorder.get_microphone() as mic:\n    while True:\n        new_chunk = recorder.record_chunk(mic)\n        ptt.update_state()\n\n        if ptt.is_button_pressed():\n            # 녹음 시작\n            recorder.start_recording(new_chunk)\n        elif ptt.is_button_hold():\n            recorder.continue_recording(new_chunk)\n        elif ptt.is_button_released():\n            buffer = recorder.get_audio_buffer()\n            if buffer is not None:\n                # 녹음 종료\n                # ...\n\n            # 새 문구를 위해 준비\n            ptt.reset_state()\n```\n\n전체 코드는 기사의 끝에 제공되지만, 이 부분만으로 아이디어를 이해할 수 있습니다. 여기서는 무한한 “메인” 루프가 있습니다. 마이크는 항상 활성화되어 있지만, 녹음은 버튼이 눌릴 때만 시작됩니다. PTT 버튼이 놓일 때, 오디오 버퍼를 음성 인식에 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nASR(Automatic Speech Recognition)은 이미 이전 게시물에서 설명했습니다:\n\n이 텍스트를 간결하게 만들기 위해 코드를 다시 반복하지 않겠습니다. 독자들께서 스스로 이전 부분을 확인하시기 바랍니다.\n\n## 디스플레이\n\n이 프로젝트에서는 Amazon에서 $3-5에 구매할 수 있는 작은 1.4인치 128x64 OLED 디스플레이를 사용했습니다. 코드는 이미 이전 게시물에서 제시되었습니다. 저는 단지 작은 리팩토링을 수행하고 모든 메서드를 OLEDDisplay 클래스에 넣었습니다:\n\n<div class=\"content-ad\"></div>\n\n```python\nclass OLEDDisplay:\n    \"\"\" I2C OLED 화면에 정보 표시 \"\"\"\n    def __init__(self):\n        self.pixels_size = (128, 64)\n        ...\n        self.app_logo = Image.open(\"bunny.png\").convert('1')\n        if adafruit_ssd1306 is not None and i2c is not None:\n            self.oled = adafruit_ssd1306.SSD1306_I2C(self.pixels_size[0],\n                                                     self.pixels_size[1],\n                                                     i2c)\n        else:\n            self.oled = None        \n\n    def add_line(self, text: str):\n        \"\"\" 스크롤링되는 새로운 라인 추가 \"\"\"\n\n    def add_tokens(self, text: str):\n        \"\"\" 추가 줄바꿈 여부에 따라 새로운 토큰 추가 \"\"\"\n\n    def draw_record_screen(self, text: str):\n        \"\"\" 로고와 텍스트를 그림 \"\"\"\n        logging.debug(f\"Draw_record_screen: \\033[0;31m{text}\\033[0m\")\n        if self.oled is None:\n            return\n\n        image = Image.new(\"1\", self.pixels_size)\n        img_pos = (self.pixels_size[0] - self.image_logo.size[0])//2\n        image.paste(self.image_logo, (img_pos, 0))\n        draw = ImageDraw.Draw(image)\n        text_size = self._get_text_size(text)\n        txt_pos = (self.pixels_size[0]//2 - text_size[0]//2,\n                   self.pixels_size[1] - text_size[1])\n        draw.text(txt_pos, text, font=self.font, fill=255, align=\"center\")\n\n        self._draw_image(image)\n\n    def _get_text_size(self, text):\n        \"\"\" 텍스트 크기 가져오기 \"\"\"\n        _, descent = self.font.getmetrics()\n        text_width = self.font.getmask(text).getbbox()[2]\n        text_height = self.font.getmask(text).getbbox()[3] + descent\n        return (text_width, text_height)\n\n    def _draw_image(self, image: Image):\n        \"\"\" 디스플레이에 이미지 그리기 \"\"\"\n``` \n\n또한 PTT 버튼이 눌렸는지 여부를 나타내는 \"rabbit\" 로고와 텍스트를 표시하는 draw_record_screen 메서드를 추가했습니다. 텍스트는 다른 상태 메시지에도 유용합니다. 라즈베리 파이에 연결된 디스플레이는 다음과 같이 보입니다:\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*o863KNDptmNqkTmz1kBamw.gif\" />\n\n깜박임은 비디오 녹화의 부작용이며, 인간 눈에는 보이지 않습니다. 미술가가 아니라서 제 그림 실력이 죄송합니다 ;)\n\n<div class=\"content-ad\"></div>\n\n지난 글에서 언급한 것처럼 이 코드는 라즈베리 파이 없이 일반 PC에서 테스트할 수 있어요. 이 경우 oled 변수가 None이 되며 표준 logging.debug 출력만 사용하게 됩니다.\n\n## 대형 액션 모델\n\n이제 재밌는 부분에 다가가고 있어요 — LLMs와 놀아보죠. 우리 AI 어시스턴트의 논리는 간단해요:\n\n- 마이크로폰에서 문구를 가져옵니다.\n- 이 문구를 장치 내에서 실행되는 작은 언어 모델로 구문 분석합니다.\n- 문구가 특정 작업에 해당하는 경우, 어시스턴트가 해당 작업을 수행합니다 (예: 스마트 LED 전구에 명령을 보내어 등을 켤 수 있습니다). 작업이 알려지지 않은 경우에만 어시스턴트가 \"큰\" 모델에 도움을 요청합니다.\n\n<div class=\"content-ad\"></div>\n\n장치에서 모델을 로컬에서 실행하는 것은 간단한 이유로 매우 중요합니다: 클라우드 API는 무료가 아닙니다. 예를 들어, 이 글을 쓰는 시점에서, Rabbit R1의 가격은 $199이며, 그들의 웹사이트에서 약속한 대로 \"구독이 필요하지 않습니다.\" 가능한 한 많은 작업을 로컬에서 실행하는 것이 가능하게 만드는 것이 중요합니다. 저희의 스마트 어시스턴트에게도 같은 방식을 사용할 것입니다.\n\n장난감 예시로, 하나의 작업만 있는 경우를 가정해보겠습니다. 저희의 스마트 어시스턴트는 불을 켜고 끌 수밖에 없다고 가정해봅시다. 이 작업을 감지하기 위한 가능한 LLM 프롬프트는 다음과 같이 보일 수 있습니다:\n\n```js\n당신은 사용자 어시스턴트입니다.\n사용자가 불을 켜고 싶다면 라이트 온리를 작성하십시오.\n사용자가 불을 끄고 싶다면 라이트 오프만 작성하십시오.\n다른 경우에는 알 수 없음이라고만 작성하십시오.\n예시.\n사용자: 불을 켜주세요. 어시스턴트: 라이트 온.\n사용자: 불을 끄세요. 어시스턴트: 라이트 오프.\n사용자: 문을 열어주세요. 어시스턴트: 알 수 없음.\n이제 다음 사용자 텍스트를 읽으세요. 간단한 답변만 작성하십시오.\n사용자: {질문}\n어시스턴트:\n```\n\n실제 사용 사례에서는 많은 작업이 있을 수 있고, 사용자 요청에 가장 잘 맞는 프롬프트를 얻기 위해 작은 RAG 데이터베이스가 사용되지만, 테스트를 위해서는 충분합니다.\n\n<div class=\"content-ad\"></div>\n\n라즈베리 파이에서 언어 모델을 사용하려면 LLM 클래스를 만들어 봅시다. 또한 3가지 가능한 동작을 포함한 LLMAction 클래스를 만들었습니다:\n\n```js\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\nfrom langchain.prompts import PromptTemplate\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain_community.llms import LlamaCpp\n\nclass LLMAction:\n    \"\"\" 가능한 동작 \"\"\"\n    UNKNOWN = 0\n    LIGHTS_ON = 1\n    LIGHTS_OFF = 2\n\n    @staticmethod\n    def get_action(response: str) -> int:\n        \"\"\" 텍스트 응답에서 동작을 가져옵니다 \"\"\"\n        \n        actions = [(LLMAction.LIGHTS_ON, \"LIGHT ON\"),\n                   (LLMAction.LIGHTS_OFF, \"LIGHT OFF\")]\n        for action, action_text in actions:\n            if action_text.lower() in response.lower():\n                return action\n        return LLMAction.UNKNOWN\n\nclass LLM:\n    \"\"\" LLM 상호작용 \"\"\"\n    def __init__(self):\n        self.model_file = \"...\"\n        self.llm = LlamaCpp(\n            model_path=self.model_file,\n            temperature=0.1,\n            max_tokens=8,\n            n_gpu_layers=0,\n            n_batch=256,\n            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n            verbose=True,\n        )\n\n    def get_action_code(self, question: str) -> int:\n        \"\"\" LLM에게 질문하고 동작 코드를 반환합니다 \"\"\"\n        res_str = self._inference(question)\n        return LLMAction.get_action(res_str)\n\n    def _inference(self, question: str) -> str:\n        \"\"\" LLM에게 질문합니다 \"\"\"\n        template = self._get_prompt_template()\n        prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n        chain = prompt | self.llm | StrOutputParser()\n        resp = chain.invoke({\"question\": question}, config={}).strip()\n        return resp\n      \n    def _get_prompt_template(self) -> str:\n        \"\"\" 다른 모델에 대한 프롬프트를 가져옵니다 \"\"\"\n        if \"tinyllama\" in self.model_file:\n            return \"\"\"<|system|>\n                사용자 보조 기능입니다. 사용자가 빛을 켜려면 LIGHT ON이라고만 적어주세요. \n                빛을 끄려면 LIGHT OFF라고만 적어주세요. 다른 경우에는 I DON'T KNOW이라고만 적어주세요.\n                예시.\n                사용자: 불을 켜줘. 보조 기능: \"LIGHT ON\". \n                사용자: 불을 끄어줘. 보조 기능: \"LIGHT OFF\".\n                사용자: 문을 열어줘. 보조 기능: \"I DON'T KNOW\".\n                이제 이 사용자 질문에 답해주세요. LIGHT ON, LIGHT OFF 또는 I DON'T KNOW 중에 선택해 적어주세요.\n                </s>\n                <|user|>\n                {question}</s>\n                <|assistant|>\"\"\"\n        ...\n```\n\n여기서 LlamaCpp를 사용하여 언어 모델을 로드하고 응답을 얻기 위한 _inference 메서드를 만들었습니다. 서로 다른 모델은 서로 다른 프롬프트 구문을 갖기 때문에, 모델 이름에 따라 다른 프롬프트를 선택합니다. LlamaCpp 라이브러리는 라즈베리 파이에 쿠다 GPU가 없어도 작동할 수 있고 평범한 C/C++로 작성되어 있어 우리의 작업에 탁월합니다.\n\n어떤 모델을 사용해야 할까요? 라즈베리 파이는 계산 자원이 제한적이기 때문에 답은 그리 쉽지 않습니다. GPU가 없고 CPU 추론 속도가 느립니다. 실제로 라즈베리 파이에서 모델을 실행할 때, 1–2B 모델에만 제한됩니다. 그 외에는 추론에 너무 많은 시간이 걸립니다. \"작은 대형 언어 모델\"은 모순적으로 들릴 수 있지만, 우리의 경우 선택지가 매우 제한적입니다. HuggingFace에서 라즈베리 파이에 적합한 1B Tiny Vicuna, 1.1B Tiny Llama, 그리고 2.7B Phi-2 모델을 찾을 수 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n가장 좋은 작은 모델을 찾기 위해 작은 벤치마크를 만들어 봅시다. 우리의 3가지 액션을 테스트하기 위해 4개씩 총 12개의 문구를 만들었습니다.\n\n```python\nqa_pairs = [(\"Switch on the light\", LLMAction.LIGHTS_ON),\n            (\"Switch on the light please\", LLMAction.LIGHTS_ON),\n            (\"Turn on the light\", LLMAction.LIGHTS_ON),\n            (\"Turn on the light please\", LLMAction.LIGHTS_ON),\n            (\"Switch off the light\", LLMAction.LIGHTS_OFF),\n            (\"Switch off the light please\", LLMAction.LIGHTS_OFF),\n            (\"Turn off the light\", LLMAction.LIGHTS_OFF),\n            (\"Turn off the light please\", LLMAction.LIGHTS_OFF),\n            (\"Buy me the ticket\", LLMAction.UNKNOWN),\n            (\"Where is the nearest library?\", LLMAction.UNKNOWN),\n            (\"What is the weather today?\", LLMAction.UNKNOWN),\n            (\"Give me a receipt of an apple pie\", LLMAction.UNKNOWN)]\n```\n\n코드를 실행하기 전에 huggingface-cli 도구를 사용하여 모델을 다운로드해야 합니다:\n\n```python\nhuggingface-cli download afrideva/Tiny-Vicuna-1B-GGUF tiny-vicuna-1b.q4_k_m.gguf --local-dir . --local-dir-use-symlinks False\nhuggingface-cli download TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\nhuggingface-cli download TheBloke/phi-2-GGUF phi-2.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\nhuggingface-cli download TheBloke/Llama-2-7b-Chat-GGUF llama-2-7b-chat.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n```\n\n<div class=\"content-ad\"></div>\n\n여기, 더 나은 성능을 위해 7B Llama-2 모델을 \"참조\"로 다운로드했습니다.\n\n라즈베리 파이 4에서의 시험 결과는 다음과 같습니다:\n\n```js\nTiny Vicuna 1B: 정확도: 66%, 평균 응답 시간: 4.2초\nTiny Llama 1.1B: 정확도: 0%, 평균 응답 시간: 4.9초\nPhi-2 2.7B: 정확도: 75%, 평균 응답 시간: 24.6초\nLlama-2 7B: 정확도: 83%, 평균 응답 시간: 19.3초\n```\n\n결과는 흥미로웠습니다. 첫째, Tiny Llama 모델의 0% 정확도에 놀랐습니다. 여전히 응답을 제공할 수는 있었지만 정확하지 않았습니다. 예를 들어, Tiny Llama는 \"불을 켜라\"라는 문구에 \"사용자: 불 켜기\"라는 답변을 할 수 있고, 이는 \"어느 정도\" 정확하며 핵심 문구를 쉽게 찾을 수 있습니다. 둘째, 7B Llama-2가 2.7B Phi-2보다 더 빠르게 작동하는 것을 보는 것이 흥미로웠습니다. 셋째, 모델들에게 가장 \"어려웠던\" 것은 마지막 질문 그룹이었습니다. 거의 모든 모델이 \"모르겠다.\" 대신에 스스로 답을 만들려고 시도했습니다. 재미있게도 \"작은\" 모델뿐만 아니라 Google Bard도 이 실수를 범했습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_2.png\" />\n\n어쨌든 라즈베리 파이에서 1-2B 모델을 사용할 수 있지만 두 가지 문제점이 있습니다. 첫째, 라즈베리 파이 4가 충분히 빠르지 않다는 것을 알 수 있습니다. 모델은 작동하지만 추론하는 데 4초는 다소 느립니다. 라즈베리 파이 5는 거의 2배 빠를 것으로 예상되지만, 심지어 2초도 상당한 지연입니다. 둘째, 작은 LLM은 종종 충분히 정확하지 않습니다. 우리의 프로토타입에는 문제가 되지 않지만, 생산 장치의 경우 세밀한 조정이 필요할 것입니다.\n\n테스트 결과를 얻은 후 Rabbit R1 개발자들이 LLM을 구현한 방법을 생각해 보는 것도 흥미롭습니다. R1 설명에서 \"500ms\" 응답 시간을 본 적이 있습니다. 결과에서 볼 수 있듯이 이 시간 제한은 정말 도전적입니다. 당연히 실제 답변을 모르지만, 몇 가지 교육된 추측을 할 수 있습니다.\n\n- 사용자 조작에만 초점을 맞춘 작은 0.1-0.5B 언어 모델을 만들어 실제 데이터셋에서 학습했을 것입니다.\n- 더 빠른 처리를 위해 별도의 칩을 사용했을 것입니다. \"Intel Neural Compute Stick\"과 같은 장치들이 여러 년 동안 알려져 왔으며, 현대의 coprocessors가 LLM 계산을 수행할 수 있는 수단이 있을지도 모릅니다 (이 방법은 새로운 것은 아닙니다; 저와 같은 세대의 사람들은 Intel 8087 수학 coprocessors를 기억할 수 있습니다.).\n- LLM 이외에도 더 많이 사용할 수 있습니다. 텍스트 파싱은 \"클래식\" 파이썬 도구인 정규 표현식, 코딩된 규칙 등을 사용하여 수행할 수 있으며, 모든 방법을 결합하는 것이 유익할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n마지막으로 Rabbit R1은 꽤 좋은 MediaTek MT6765 옥타코어 프로세서를 갖추고 있으며 몇 가지 테스트에서 Raspberry Pi 4보다 상당히(4-8배) 빠르다고 명시되어 있습니다. 따라서 이 CPU에서는 심지어 1B 모델이 충분히 빠르게 작동할 수도 있습니다.\n\n## 클라우드 모델\n\n이전에 토론한 대로 로컬 모델이 답을 알지 못하는 경우 \"모르겠어요\"라는 응답을 반환하고 이 경우 질문을 \"큰 동생\"에게 전달할 것입니다. 시작해봅시다!\n\n라즈베리 파이에서 클라우드 모델을 사용하는 것은 간단합니다. OpenAILLM 클래스를 생성하고, 이름에서 알 수 있듯이 OpenAI API를 사용할 것입니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom langchain_openai import OpenAI\n\nOPENAI_BASE_URL = \"...\"\nOPENAI_API_KEY = \"여기에 키를 입력하세요\"\n\nclass OpenAILLM:\n    \"\"\" OpenAI API Handler \"\"\"\n    def __init__(self):\n        self.llm = OpenAI(openai_api_key=OPENAI_API_KEY,\n                          base_url=OPENAI_BASE_URL)\n        self.template = \"\"\"도와드리는 어시스턴트입니다.\n                           질문에 대한 간단한 답변을 작성해주세요.\n                           질문: {question}\n                           답변:\"\"\"\n\n    def inference(self, question: str, callback: Callable):\n        \"\"\" OpenAI 모델에 질문하기 \"\"\"\n        prompt = PromptTemplate(template=self.template,\n                                input_variables=[\"question\"])\n\n        chain = prompt | self.llm | StrOutputParser()\n        for token in chain.stream({\"question\": question}):\n            callback(token)\n```\n\n여기서 OLED 디스플레이를 업데이트하기 위해 스트리밍 모드와 콜백 핸들러를 사용했기 때문에 답변은 토큰 단위로 즉시 표시됩니다.\n\n코드에서 OPENAI_API_KEY 변수를 볼 수 있습니다. OpenAI 구독이 없는 경우 어떻게 할 수 있을까요? LlamaCPP는 훌륭한 라이브러리이며 이를 해결해 줍니다. 이것을 통해 로컬 인스턴스로 OpenAI API를 모사할 수 있어서 다른 PC에서 실행할 수 있습니다. 예를 들어, 다음 명령을 사용하여 데스크탑에서 7B Llama-2 모델을 실행할 수 있습니다:\n\n```js\npython3 -m llama_cpp.server --model llama-2-7b-chat.Q4_K_M.gguf --n_ctx 16192 --host 0.0.0.0 --port 8000\n```\n\n<div class=\"content-ad\"></div>\n\n그런 다음 코드에서 OPENAI_BASE_URL을 \"http://192.168.1.10:8000/v1\"과 같은 것으로 조정하면 됩니다. 흥미롭게도 OpenAI 라이브러리는 여전히 키가 필요합니다(키가 비어 있으면 내부적으로 확인하도록 되어 있습니다), 그러나 일반적인 숫자 \"42\"도 충분합니다 ;)\n\n그런데 우리의 프로토타입에서는 먼저 로컬 모델을 사용하여 클라우드 비용을 줄이지만, OpenAI 키를 가지고 있고 가격에 신경 쓰지 않는 독자들은 API 호출을 사용하여 로컬 작업을 분석할 수도 있습니다. 무료는 아니지만 더 빠르고 정확할 것입니다. 이 경우 LLM 클래스를 LlamaCPP 모델 대신 OpenAI로 작업 프롬프트를 보낼 수 있도록 약간 수정할 수 있습니다.\n\n## 결과\n\n마지막으로, 모든 부분을 결합할 때가 왔습니다! 최종 코드는 다음과 같이 보입니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nif __name__ == \"__main__\":\n    display = OLEDDisplay()\n    display.add_line(\"자동 음성 인식 초기화 중...\")    \n    asr = ASR()\n\n    display.add_line(\"GPT 모델 초기화 중...\")\n    llm = LLM()\n\n    ptt = GPIOButton(pin_number=button_pin)\n    if gpio is None:\n        ptt = VirtualButton(delay_sec=5)\n\n    def on_recording_finished(audio_buffer: np.array):\n        \"\"\" 녹음이 완료되었으며 오디오 데이터를 처리합니다 \"\"\"\n        question = asr.transcribe(audio_buffer)\n        display.add_line(f\"> {question}\\n\")\n\n        # 처리\n        action = llm.get_action_code(question)\n        if action != LLMAction.UNKNOWN:\n            process_action(action)\n        else:\n            process_unknown(question)\n\n        display.add_line(\"\\n5초 후에 다시 이동합니다...\\n\")\n        time.sleep(5)\n\n    def process_action(action: int):\n        \"\"\" 더미 작업을 처리합니다 \"\"\"\n        ...\n\n    def process_unknown(question: str):\n        \"\"\" OpenAI에 질문합니다 \"\"\"\n        display.add_line(\"\\n\")\n        # 대답을 스트리밍\n        openai_llm = OpenAILLM()\n        openai_llm.inference(question=question,\n                             callback=display.add_tokens)\n\n      # 메인 루프\n      recorder = SoundRecorder()\n      with recorder.get_microphone() as mic:\n          ptt.reset_state()\n          display.draw_record_screen(\"PTT 준비됨\")\n          while True:\n              new_chunk = recorder.record_chunk(mic)\n              ptt.update_state()\n\n              if ptt.is_button_pressed():\n                  display.draw_record_screen(\"PTT 활성화\")\n                  recorder.start_recording(new_chunk)\n              elif ptt.is_button_hold():\n                  recorder.continue_recording(new_chunk)\n              elif ptt.is_button_released():\n                  display.draw_record_screen(\"잠시 기다려주세요...\")\n                  buffer = recorder.get_audio_buffer()\n                  on_recording_finished(buffer)\n\n                  # 다시 준비\n                  ptt.reset_state()\n                  display.draw_record_screen(\"PTT 준비됨\")\n```\n\n\n실제로는 이렇게 동작합니다.\n\n로컬 동작을 실행하는 중:\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*Qmwb-hB7Hyd4dCxd37e8-w.gif\" />\n\n<div class=\"content-ad\"></div>\n\n여기서, 나는 더미 작업을 사용 중이에요; 스마트 램프에 연결하거나 라즈베리 파이에 릴레이 쉴드를 사용하는 것은 이 기사의 범위를 벗어날 것입니다.\n\n원격 LLM에서 답변을 받는 중입니다:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*8jaqi_8ld923YcuZNO6iuQ.gif)\n\n여기서, 저는 데스크톱에서 실행되는 LLaMA-2 모델을 OpenAI 대체재로 사용하고 있어요. 이 모델은 라즈베리 파이에서 로컬로 실행되는 모델과 비교해서 응답이 훨씬 빠르다는 것을 알 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n## 결론\n\n이번 \"주말\" 프로젝트에서는 라즈베리 파이를 기반으로 한 스마트 어시스턴트를 만들었습니다. 이 스마트 어시스턴트는 다양한 기능을 수행할 수 있습니다:\n\n- 푸시 투 토크 버튼과 음성 인식을 사용할 수 있습니다.\n- 다양한 사용자 동작을 감지할 수 있는 로컬 언어 모델을 실행할 수 있습니다.\n- 만약 사용자의 요청이 로컬 LLM에 알려지지 않은 경우 더 강력한 원격 모델을 요청할 수 있습니다. 이 경우 OpenAI API나 호환 가능한 로컬 서버를 사용할 수 있습니다.\n\n우리는 이와 같은 프로젝트를 만드는 데 많은 도전이 있다는 것을 알 수 있습니다. 대규모 언어 모델은 많은 계산 능력이 필요하며, 휴대용 장치에는 도전적입니다. 좋은 결과를 얻기 위해서는 조정된 모델 뿐만 아니라 그 모델을 빠르게 실행할 충분히 강력한 하드웨어도 필요합니다 (20초의 지연 후에 \"스마트 어시스턴트\" 응답을 받은 사용자는 아무도 관심을 갖지 않을 것입니다). 클라우드 API는 빠릅니다만 무료가 아니며, 하드웨어 비용, 계산 속도, 판매 가격 및 클라우드 비용 사이의 균형을 찾는 것은 까다로울 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n만약 이 이야기를 즐기셨다면 Medium에 구독해 주시고, 새로운 기사가 발행될 때 알림을 받으며 다른 저자들의 수천 개 이야기에 완전한 액세스 권한을 얻을 수 있습니다. 또한 LinkedIn을 통해 연락하실 수도 있습니다. 이와 함께 이와 다른 게시물의 전체 소스 코드를 받고 싶다면 Patreon 페이지를 방문해주세요.\n\n언어 모델과 자연어 처리에 관심이 있는 분들은 다른 기사들을 읽어보시기를 환영합니다:\n\n- 주말 AI 프로젝트 (제1부): 라즈베리 파이에서 음성 인식 및 LLaMA-2 GPT 실행\n- 모든 사람을 위한 LLMs: LangChain 및 MistralAI 7B 모델을 Google Colab에서 실행\n- 모든 사람을 위한 LLMs: LLaMA-13B 모델 및 LangChain을 Google Colab에서 실행\n- 모든 사람을 위한 LLMs: Google Colab에서 HuggingFace 텍스트 생성 추론 실행\n- 절대 초보자를 위한 자연어 처리\n- 16, 8 및 4비트 부동 소수점 형식 - 어떻게 동작하는가?\n\n읽어 주셔서 감사합니다.","ogImage":{"url":"/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-20-AWeekendAIProjectUsingSpeechRecognitionPTTandaLargeActionModelonaRaspberryPi_0.png","tag":["Tech"],"readingTime":23},{"title":"NGINX LXC에 Proxy Manager 설치하기 - V2, Debian","description":"","date":"2024-06-20 17:18","slug":"2024-06-20-NGINXInstallingProxyManagerinLXCV2Debian","content":"\n\n이 문서는 아래 링크에서 확인할 수 있는 이전 버전의 업데이트입니다. 작년에는 이전 가이드에서 사용했던 설치 스크립트가 Debian 및 Ubuntu를 지원하도록 업데이트되었습니다. Alpine Linux를 사용하려면 이전 가이드를 따르세요:\n\n지금은 Alpine을 참지 못해요. 사용 용도는 있을 텐데, 저는 Debian에서 더 편안해요. 따라서 Alpine 설정을 Debian으로 변경하고 프로세스를 문서화하기로 결정했어요.\n\n참고: 이 가이드를 따르기 위해 나와 같이 기존 설치가 필요하지 않아요.\n\nNginx Proxy Manager에 대한 자세한 정보나 역방향 프록시가 무엇인지 알고 싶다면 이전 가이드를 참조하세요.\n\n<div class=\"content-ad\"></div>\n\n요구 사항:\n\n- Proxmox 설정 및 접근 가능\n- LXC 생성에 대한 기본 지식\n- 인터넷 액세스\n- 정적 IP 주소 설정을 위한 라우터 관리 패널 액세스\n\n새 컨테이너 생성:\n\n이 프로세스의 첫 번째 단계는 제가 이주하거나 새롭게 설치하는 경우와 상관없이 컨테이너를 만드는 것입니다. 이를 수행하는 방법은 가이드의 \"컨테이너 생성\" 섹션을 참조하면 됩니다. Debian 또는 Ubuntu 컨테이너를 생성할 수 있습니다. 사용자 편의를 위해 Debian을 사용하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 Markdown 형식으로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nsh -c \"$(wget --no-cache -qO- https://raw.githubusercontent.com/ej52/proxmox/main/install.sh)\" -s --app nginx-proxy-manager\n```\n\n아주 빨리 다음과 같은 화면이 표시됩니다:\n\n<img src=\"/assets/img/2024-06-20-NGINXInstallingProxyManagerinLXCV2Debian_1.png\" />\n\n설치 프로그램이 작업을 수행하도록 해주세요... 이 작업은 몇 분 정도 소요될 수 있으니 이 기회에 물 한 잔 마시는 것으로 하루를 시작하는 것을 상기해보세요.\n\n<div class=\"content-ad\"></div>\n\n설치 프로그램이 완료되면 다음과 같은 화면이 나타날 것입니다:\n\n![이미지](/assets/img/2024-06-20-NGINXInstallingProxyManagerinLXCV2Debian_2.png)\n\n완벽합니다! 설치가 완료되었습니다! 이 설치 스크립트에 뛰어난 작업을 한 @github/ej52님에게 큰 박수를 보냅니다.\n\n프록시 매니저 구성중:\n\n<div class=\"content-ad\"></div>\n\n프록시 관리자 설정은 이전 버전과 비슷합니다. 이전 버전의 프록시 관리자를 사용 중이라면, 모든 것을 옮기기 시작하려면 여기서 시작해야 합니다. 안타깝게도 이 과정을 간단하게 처리할 방법은 없습니다 (가져오기/내보내기 기능이 있으면 좋을텐데요). 따라서 물을 한 모금 마시고, 모두 수동으로 해야 합니다!\n\n이 가이드를 사용하여 프록시 호스트와 SSL 인증서를 만드세요.\n\n참고: 모든 프록시 호스트를 이동한 후에 WAN의 HTTP 및 HTTPS 포트로 포트 포워딩을 업데이트해야 합니다. 서비스 다운타임을 최소화하기 위해 호스트를 옮긴 후에 이 작업을 수행하세요.\n\n프록시 관리자 업데이트 중:\n\n<div class=\"content-ad\"></div>\n\n프록시 관리자를 업데이트하려면 설치 스크립트를 실행하면 됩니다!\n\nTailscale로 전역 액세스를 어떻게 하나요?\n\n아직 가능합니다! 실제로 Tailscale이 데비안을 공식적으로 지원하기 때문에 이제는 더 쉽습니다! 해당 가이드를 업데이트하는 중이지만 그 사이에 Tailscale 웹 사이트에서 설치 파일을 다운로드하고 이 가이드를 따라 전역 액세스를 설정할 수 있습니다.\n\n추가 고려 사항:\n\n<div class=\"content-ad\"></div>\n\n이번에도 반복되지만, 로컬 네트워크에서 세계로 노출하는 것은 매우 위험합니다. 반대 프록시 뒤에 있더라도 외부 트래픽을 내부 네트워크로 유입하는 것은 서버가 해킹되거나 더 나아가 개인 기기가 침해당할 수 있습니다. 경고드립니다.\n\n다행히도 Crowdsec를 설치하여 반대 프록시를 더 안전하게 설정할 수 있습니다. Crowdsec는 악성 트래픽을 자동으로 감지하고 차단합니다. 또한 차단된 악성 행위자의 공개 목록을 유지하므로 이러한 IP 주소가 서비스에 도달하기도 전에 차단됩니다! 곧 자세히 알려드리겠습니다 :)\n\n참고 사항:\n\n본 가이드는 본격적인 또는 비즈니스 환경에서의 설정을 위한 것이 아닙니다. 공개 또는 본격적인 환경 설정에 대해 자체적인 연구를 먼저 진행해주시기 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n저는 IT 전문가가 아닙니다. 기술 지원은 제가 할 수 없어요. 대학생이고 서버를 가지고 있는데, 시스템에 실행하는 모든 명령에 대해서는 본인이 책임을 져야 합니다.\n\n질문이 있으시면 댓글을 남겨주세요. 즐기세요!","ogImage":{"url":"/assets/img/2024-06-20-NGINXInstallingProxyManagerinLXCV2Debian_0.png"},"coverImage":"/assets/img/2024-06-20-NGINXInstallingProxyManagerinLXCV2Debian_0.png","tag":["Tech"],"readingTime":3},{"title":"꽃 다발의 마법과 아름다움","description":"","date":"2024-06-20 17:17","slug":"2024-06-20-TheMagicandBeautyOfFloralArrangements","content":"\n\n자연주의 예술가로서, 저의 작업 방식 중 하나는 자연의 풍부함을 공영에 활용하는 것입니다.\n\n많은 꽃들은 신비주의와 숨겨진 의미와 연관되어 있습니다. 현재에도 사용되는 꽃의 언어가 있습니다. 꽃의 언어는 저를 크게 영감을 주는데, 계절마다 건조한 화환을 만들 때에는 빅토리아 시대의 책에 정의된 의미보다는 직감과 꽃 자체가 선택하는 것을 따릅니다.\n\n![이미지](/assets/img/2024-06-20-TheMagicandBeautyOfFloralArrangements_0.png)\n\n건조 화환을 만드는 것은 신선한 화환을 만드는 것과 비슷하지만 몇 가지의 어려움과 혜택이 있습니다. 건조 화환은 적절히 관리할 경우 최대 2년까지 가질 수 있습니다. 신선한 화환은 가장 이상적인 조건에서 2주간 가질 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 드라이 꽃다발을 만드는 데는 신선한 꽃다발보다 더 많은 식물 재료가 필요합니다. 줄기, 잎, 그리고 꽃들은 건조될수록 작아지곤 합니다. 원래 색상을 유지하는 꽃들도 있지만, 실험은 재미있는 부분 중 하나입니다.\n\n![꽃다발](/assets/img/2024-06-20-TheMagicandBeautyOfFloralArrangements_1.png)\n\n건조된 꽃다발을 만들려면 주변을 둘러보아서 풍부하게 자라는 꽃과 식물을 찾아보세요. 저희 정원에는 주로 치료용 허브와 살충제 친화적인 식물들을 기르고 있어서 이와 같은 프로젝트에 주로 사용합니다.\n\n저는 이 꽃다발을 건조한 후에 자주 불태우곤 합니다. 허브의 연기는 치료 특성(그리고 마법적인 특성)을 가질 뿐만 아니라, 모기를 쫓아내는 데에도 큰 도움이 됩니다. 그러나 만족스럽지 않고 위험하거나 피부 접촉 시 바르거나 불태울 때 위험할 수 있는 유독한 식물은 피해 주십시오.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-20-TheMagicandBeautyOfFloralArrangements_2.png)\n\n라벤더, 장미, 말린 양귀비 머리, 피버휴, 그리고 약초는 모두 화환의 멋진 중앙을 이룹니다. 주변에는 레몬밤, 세이지(정원 세이지 또는 다른 종류), 아르테미시아, 심지어 민트의 장독을 추가합니다. 전체적으로 직경이 줄어들 것을 염두에 두어 더 많은 초목과 꽃을 추가하고 천연 섬유 또는 끈으로 꽉 조이세요.\n\n마지막으로, 화환은 한 달 정도 말려야 합니다. 그것들을 거꾸로 매달거나 그늘진 건조한 곳에 판지 위에 눕혀 놓습니다. 이 장채 부분은 직사광선이 들어오지 않지만 다른 화환과 약초를 실내에서 말리기도 합니다.\n\n![Image](/assets/img/2024-06-20-TheMagicandBeautyOfFloralArrangements_3.png)\n\n\n<div class=\"content-ad\"></div>\n\n이것은 정말 간단한 공예로 시간(그리고 약간의 끈)만 들 뿐이에요. 회색과 흐린 겨울 달들을 이겨내게 도와주고 생일의 친구들, 벨타인 같은 계절적인 휴일, 그리고 물론 어머니의 날에 사려 깊은 선물로 준비하기 좋아요.","ogImage":{"url":"/assets/img/2024-06-20-TheMagicandBeautyOfFloralArrangements_0.png"},"coverImage":"/assets/img/2024-06-20-TheMagicandBeautyOfFloralArrangements_0.png","tag":["Tech"],"readingTime":2},{"title":"지루한 피부를 위한 요거트, 꿀, 황색향으로 하는 허브 페이스 마스크","description":"","date":"2024-06-20 17:16","slug":"2024-06-20-HerbalFaceMaskforOilySkinwithYogurtHoneyTurmeric","content":"\n\n<img src=\"/assets/img/2024-06-20-HerbalFaceMaskforOilySkinwithYogurtHoneyTurmeric_0.png\" />\n\n안녕하세요!\n오늘은 강력한 요거트, 꿀, 그리고 황색 인도 소나무로 디자인된 간단하고 프로페셔널급 얼굴 마스크를 만들어 볼 겁니다.\n\n## 재료\n\n요거트(1 ps):\n\n<div class=\"content-ad\"></div>\n\n지나치게 많은 기름을 조절하는 천연 발효산의 원천.\n\n꿀 (1 tps):\n\n여드름과 기름기를 줄이는 항균 특성.\n\n허브 분말 (1/2 tps):\n\n<div class=\"content-ad\"></div>\n\n발가락 사이의 모금 간격을 자유롭게 조절하거나, 필요에 따라 매개 변수를 추가하거나 제거하여 표를 Markdown 형식으로 변경할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\"Mixture을 깨끗하고 건조한 피부에 고르게 발라주세요. 재료가 마법을 발휘할 수 있도록 10~15분간 그대로 두세요.\n\n세척: 따뜻한 물로 부드럽게 씻은 다음 가볍게 털어서 피부를 말려주세요. 상쾌하고 시원한 느낌이 올 거예요.\n\n# 주의사항\n\n우유색의 강한 염색 능력을 가진 황색 향료에 주의하세요. 옷에 닿지 않도록 주의하고 표면에 자국을 남기지 않도록 조심하세요. 필요하다면 옷을 입고 쉽게 닦을 수 있는 곳에 마스크를 사용하세요.\"\n\n<div class=\"content-ad\"></div>\n\n## 혜택\n\n요거트:\n과잉 오일을 조절하고 자연스러운 광채를 제공합니다.\n\n꿀:\n여드름을 방지하고 기름기 없이 촉촉하게 보습합니다.\n\n우유 황금 가루:\n염증을 줄이고 광채를 더해줍니다.\n\n<div class=\"content-ad\"></div>\n\n## 과학적인 통찰\n\n증가하는 증거들이 노견살의 활성 성분 큐커민이 다양한 피부 질환을 치료하는 데 잠재적인 의학적 용도가 있다는 것을 보여줍니다. 체계적인 검토는 큐커민을 피부에 외용하거나 내부적으로 복용하여 피부 건강과 기능을 규제하는 증거를 살펴보았습니다.\n\n따라서 이 스파 스타일의 치료를 위해 쉽게 만들 수 있는 이 가루를 당신의 일일 루틴에 포함시키세요. 이것은 지성 피부와 관련된 문제에 대처하기에 이상적입니다.\n\n저는 여러분과 자연 치료법에 대한 제안을 공유하려고 합니다. 이 기사를 좋아하셨다면, 새로운 제안을 받아보기 위해 구독하고 알림을 받지 않도록 잊지 마세요.","ogImage":{"url":"/assets/img/2024-06-20-HerbalFaceMaskforOilySkinwithYogurtHoneyTurmeric_0.png"},"coverImage":"/assets/img/2024-06-20-HerbalFaceMaskforOilySkinwithYogurtHoneyTurmeric_0.png","tag":["Tech"],"readingTime":2},{"title":"프록시목스Proxmox LXC에 포토프리즘Photoprism 설치하기","description":"","date":"2024-06-20 17:14","slug":"2024-06-20-ProxmoxInstallingPhotoprisminLXC","content":"\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_0.png)\n\nPhotoprism은 AI 기반의 멋진 사진 관리 서비스로, 여러분의 사진을 색인화, 보기 및 공유할 수 있습니다. 해당 기능에 대해 자세히 알아볼 수 있는 공식 웹사이트가 있습니다. 오늘은 가정 환경에서 Proxmox의 LXC 컨테이너에 이를 설치해 보겠습니다.\n\n## 요구 사항:\n\n- Proxmox가 완전히 설치되고 구성되어 있으며 GUI에 액세스할 수 있어야 합니다.\n- 정적 IP 주소를 설정하고 정적 IP, DHCP 범위에 대한 기본적인 지식이 있는 라우터 제어 패널에 액세스해야 합니다.\n- 사진 및 섬네일에 충분한 스토리지 공간이 있어야 합니다. (대부분의 컬렉션은 총 200GB까지 용량을 차지할 수 있다고 알려져 있습니다. 이 강좌에서는 NAS의 네트워크 공유를 사용할 것이지만, 원하는 경우 로컬 디스크의 폴더를 사용할 수도 있습니다.)\n- 터미널에 대한 기본 지식이 필요합니다. (파일을 열고 저장하는 등)\n- Proxmox 컨테이너에 대한 기본 지식이 필요합니다. (LXC 템플릿 다운로드, 컨테이너 설정 등)\n\n<div class=\"content-ad\"></div>\n\n## 컨테이너 생성:\n\n다음 리소스를 사용하여 컨테이너를 생성하세요:\n\n- 선택한 호스트 이름 (컨테이너 이름)을 가진 관리자 권한이 있는 컨테이너를 만듭니다.\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_1.png)\n\n<div class=\"content-ad\"></div>\n\n-  당신이 좋아하는 리눅스 플레이버는 무엇인가요? 저는 여기서 Debian 11을 사용했어요.\n- ~16GB의 루트 저장공간입니다. (사진을 저장하기에는 절대 충분하지 않아요. 외부 저장공간을 꼭 사용하시길 강력히 추천드려요. 제 개인 NAS에서 저장 공간을 사용하겠습니다.)\n\n![첨부된 이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_2.png)\n\n- 시스템의 모든 코어를 사용하세요 (4~8개가 좋습니다).\n\n![첨부된 이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_3.png)\n\n<div class=\"content-ad\"></div>\n\n- 8GB RAM 이상, 4GB 스왑 이상이 필요합니다.\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_4.png)\n\n- DHCP IPv4 주소를 선택하시고, 나중에 라우터에서 설정할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_5.png)\n\n<div class=\"content-ad\"></div>\n\n- 나머지는 기본값으로 둔 채로 컨테이너를 시작하지 마세요.\n- 컨테이너 측면 표시줄의 옵션으로 이동하여 다음을 활성화하세요:\n\n```js\nnesting=1\nSMB/CIFS=1 # 외부 공유를 사용하는 경우에만 선택적으로 필요\n```\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_6.png)\n\n- 이제 컨테이너를 시작하세요.\n\n<div class=\"content-ad\"></div>\n\n## IP 주소 설정하기:\n\n정적 IP 주소를 설정하면 서비스에 더 쉽게 액세스할 수 있습니다.\n\n이 단계는 라우터마다 다를 수 있습니다. 제어 패널에 로그인해야 합니다. 일반적으로 192.168.xxx.1을 통해 액세스할 수 있습니다. 그리고 컨테이너에 정적 IP 주소를 추가하셔야 합니다. 정적 IP 할당이 DHCP 할당 범위와 겹치지 않도록 주의하셔야 합니다. 일반적으로 정적 IP에는 192.168.xxx.1~192.168.xxx.50을 추천합니다.\n\n참고: 만약 컨테이너가 라우터 장치 목록에 나타나지 않으면, 컨테이너로 돌아가 apt update를 실행하고 라우터 화면을 새로고침하세요.\n\n<div class=\"content-ad\"></div>\n\n대부분 인기있는 라우터에 대해 이 작업을 하는 방법을 다루는 YouTube 동영상이 많이 있습니다. 이 작업을 완료한 후 컨테이너를 다시 부팅하십시오. Proxmox를 다시 부팅할 필요는 없습니다.\n\n## 스토리지 설정:\n\n이전에 언급했던 대로 16Gb의 부팅 디스크 공간은 대량의 섬네일이나 사진을 저장하기에 부족합니다. Proxmox 호스트 디스크에 충분한 공간이 있고 lvm 스토리지로 적절히 구성된 경우, 부팅 디스크에 200-300GB의 스토리지를 추가하고 계속 진행할 수 있습니다.\n\n저는 컨테이너 부팅 디스크에 파일을 저장하는 것을 좋아하지 않으며 가능한 한 작게 유지합니다. Proxmox 호스트 디스크가 가득 차는 경우... 복구는 가능하지만 절대로 처지고 싶지 않은 상황입니다.\n\n<div class=\"content-ad\"></div>\n\n이 경우에는 NAS가 있어서 192.168.xxx.yy에 위치한 appdata라는 SMB 공유 폴더를 노출시킵니다.\n\n필요한 패키지를 설치하십시오:\n\n```js\napt install cifs-utils\n```\n\n마운트 폴더를 생성하세요:\n\n<div class=\"content-ad\"></div>\n\n```js\r\n/media/appdata를 만들기\r\n```\n\nSMB 자격 증명 파일을 만들기:\n\n```js\r\n/root/.smb에 nano 사용\r\n```\n\n다음과 같이 자격 증명을 파일에 추가하세요:\n\n<div class=\"content-ad\"></div>\n\n```js\n사용자 이름=당신의_사용자_이름\n비밀번호=당신의_비밀번호\n```\n\nfstab 설정하기:\n\n```js\nnano /etc/fstab\n```\n\n다음 줄을 추가하십시오:\n설정에 맞게 192.168.xxx.yy/appdata를 변경하십시오.\n\n<div class=\"content-ad\"></div>\n\n```js\n//192.168.xxx.yy/appdata /media/appdata cifs credentials=/root/.smb,uid=0,gid=0,dir_mode=0777,file_mode=0777,users,rw,iocharset=utf8,noperm 0 0\n```\n\n이제 `mount -a`를 실행하여 공유를 마운트하세요.\n\n## Photoprism 설치:\n\n이제 컨테이너와 저장소가 설정되었으므로 Photoprism을 설치할 준비가 되었습니다.\n\n<div class=\"content-ad\"></div>\n\n기존 패키지를 업데이트하세요:\n\n```bash\napt update && apt upgrade\n```\n\n필요한 패키지를 설치하세요:\n\n```bash\napt install -y gcc g++ git gnupg make zip unzip ffmpeg exiftool darktable libpng-dev libjpeg-dev libtiff-dev imagemagick libheif-examples\n```\n\n<div class=\"content-ad\"></div>\n\nNode.js 설치하기:\n\n```js\nwget https://deb.nodesource.com/setup_18.x -O node_setup.sh\nchmod +x node_setup.sh\n./node_setup.sh\napt install -y nodejs\nrm node_setup.sh\n```\n\nGoLang 설치하기:\n본 안내서 작성 시점에서 1.20.6 버전이 최신입니다. 최신 버전을 확인하려면 웹 사이트를 방문하여 URL을 변경해 주세요.\n\n```js\nwget https://golang.org/dl/go1.20.6.linux-amd64.tar.gz\nrm -rf /usr/local/go\ntar -C /usr/local -xzf go1.20.6.linux-amd64.tar.gz\nln -s /usr/local/go/bin/go /usr/local/bin/go\nrm go1.20.6.linux-amd64.tar.gz\n```\n\n<div class=\"content-ad\"></div>\n\n텐서플로우 설치:\n이 버전은 AVX2 호환 CPU용입니다 (현대적인 CPU 대부분이 해당됩니다). Photoprism 웹사이트에서 단순히 AVX 용이나 AVX를 지원하지 않는 CPU 용 버전을 찾을 수 있습니다.\n\n```js\nwget https://dl.photoprism.org/tensorflow/linux/libtensorflow-linux-avx2-1.15.2.tar.gz\nsudo tar -C /usr/local -xzf libtensorflow-linux-avx2-1.15.2.tar.gz\nsudo ldconfig\nrm libtensorflow-linux-avx2-1.15.2.tar.gz\n```\n\nPhotoprism 다운로드 및 설치:\nPhotoprism을 빌드하는 과정에서 많은 메모리가 사용될 수 있습니다. 여기서처럼 컨테이너를 구성한 경우 오류가 발생하지 않아야 합니다. 메모리 부족(OOM) 오류가 발생하면 이를 확인하고 각 make 단계를 개별적으로 실행하세요.\n\n```js\nmkdir -p /opt/photoprism/bin\ngit clone https://github.com/photoprism/photoprism.git\ncd photoprism\ngit checkout release\nmake all\n./scripts/build.sh prod /opt/photoprism/bin/photoprism\ncp -a assets/ /opt/photoprism/assets/\n```\n\n<div class=\"content-ad\"></div>\n\n## 구성:\n\nPhotoprism의 작업 디렉토리를 만들고 구성 파일을 추가하세요.\n전체 구성 옵션은 여기를 참조하세요.\n\n```js\nmkdir /var/lib/photoprism\nnano /var/lib/photoprism/.env\n```\n\n다음을 구성 파일에 추가하세요:\n기본 SQLite 데이터베이스를 작은 컬렉션 이외의 것에는 권장하지 않습니다. 이를 위해 MariaDB를 사용하는 것을 고려해보세요. MariaDB를 설치하는 방법에 대한 별도 가이드가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n저장 요소를 변경하려면 Photoprism 저장 경로를 마운트된 폴더로 변경해야 합니다. 저의 경우에는 /media/appdata가 될 것입니다.\n\n```js\n# 초기 admin 사용자의 비밀번호\nPHOTOPRISM_AUTH_MODE=\"password\"\nPHOTOPRISM_ADMIN_PASSWORD=\"photoprism\"\n\n# Photoprism 저장 디렉터리\nPHOTOPRISM_STORAGE_PATH=\"/var/lib/photoprism\"\nPHOTOPRISM_ORIGINALS_PATH=\"/var/lib/photoprism/photos/Originals\"\nPHOTOPRISM_IMPORT_PATH=\"/var/lib/photoprism/photos/Import\"\n\n# SQLite 대신 MariaDB/MySQL을 사용하는 경우 아래 주석 해제 (기본 설정값)\n# PHOTOPRISM_DATABASE_DRIVER=\"mysql\"\n# PHOTOPRISM_DATABASE_SERVER=\"MYSQL_IP_HERE:PORT\"\n# PHOTOPRISM_DATABASE_NAME=\"DB_NAME\"\n# PHOTOPRISM_DATABASE_USER=\"USER_NAME\"\n# PHOTOPRISM_DATABASE_PASSWORD=\"PASSWORD\"\n```\n\nPhotoprism 서비스 설정:\nPhotoprism이 부팅될 때 시작되도록 설정합니다.\n\n서비스 정의 파일 생성:\n\n<div class=\"content-ad\"></div>\n\n```js\nnano /etc/systemd/system/photoprism.service\n```\n\n서비스 파일에 다음을 추가하세요:\n\n```js\n[Unit]\nDescription=PhotoPrism 서비스\nAfter=network.target\nStartLimitIntervalSec=500\nStartLimitBurst=5\n\n[Service]\nType=simple\nRestart=on-failure\nRestartSec=5s\nWorkingDirectory=/opt/photoprism\nEnvironmentFile=/var/lib/photoprism/.env\nExecStart=/opt/photoprism/bin/photoprism up\nExecStop=/opt/photoprism/bin/photoprism down\n\n[Install]\nWantedBy=multi-user.target\n```\n\n이제 데몬을 다시로드하고 서비스를 시작하세요!\n\n<div class=\"content-ad\"></div>\n\n```js\nsystemctl daemon-reload\nsystemctl start photoprism\nsystemctl enable photoprism\n```\n\n서비스 상태를 확인하세요:\n\n```js\nsystemctl status photoprism\n```\n\n모든 것이 잘 실행됐다면 (활성화된 상태는 녹색으로 표시됩니다):\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_7.png)\n\n지금은 이전에 설정한 IP 주소와 포트 2342를 통해 서버에 액세스할 수 있어야 합니다.\n\n```js\nhttp://YOUR-IP:2342\n```\n\n## 크레딧:\n\n\n<div class=\"content-ad\"></div>\n\n포토프리즘 설치는 아래 안내서를 기반으로 진행되었고, 제게는 너무나 귀중한 정보입니다. 문제 해결이 필요할 때 대비하여 읽어보는 것을 고려해보세요.\n\n고지사항:\n\n이 문서는 프로덕션 또는 비즈니스 환경에서의 설정을 위한 안내서가 아니며, 공개 인터넷에 노출할 준비가 된 상태가 아닙니다.\n\n저는 IT 전문가가 아닙니다. 기술 지원도 제공하지 않습니다. 서버를 가진 대학생입니다. 시스템에서 실행하는 모든 명령어에 대한 최종 책임은 여러분에게 있습니다.\n\n<div class=\"content-ad\"></div>\n\n질문이 있으면 댓글을 남겨주세요. 즐거운 시간 보내세요!","ogImage":{"url":"/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_0.png"},"coverImage":"/assets/img/2024-06-20-ProxmoxInstallingPhotoprisminLXC_0.png","tag":["Tech"],"readingTime":8},{"title":"여행가방 이야기","description":"","date":"2024-06-20 17:12","slug":"2024-06-20-TheStoryoftheTravelingBag","content":"\n\n## 예술 | 창의력 | 공예 | 바느질\n\n![여행가방](/assets/img/2024-06-20-TheStoryoftheTravelingBag_0.png)\n\n이 가방이 있는데, 이건 그냥 평범한 가방이 아니에요. 이 세상 많은 것을 경험했어요.\n\n나는 이를 여행가방이라고 부르죠.\n\n<div class=\"content-ad\"></div>\n\n제가 정확히 어디서 구매했는지는 정확히 기억이 나지 않지만 쇼핑을 한 곳은 쇼핑몰이었고 부모님과 함께 여행 중이었습니다. 제가 반드시 16세에서 19세 사이에 있었을 때였고, 백화점에서 옷걸이에 걸려 있는 것을 아직도 기억합니다.\n\n왜 그 가방을 선택했는지 정확히는 모르겠습니다. 멋진 패턴이나 안쪽에 반전할 수 있는 다른 패턴이 있어서 그랬을 수도 있습니다. 아니면 그냥 제 돈을 쓸 수 있는 즐거움이 크게 작용했을 수도 있습니다.\n\n어떤 이유에서든, 그 가방에 매료되었고, 이 가방은 분명히 제 가장 소중한 소유물 중 하나입니다. 거의 30년이 지난 지금까지도 함께 있습니다! 우리가 2017년에 모든 것을 판매해서 만큼을 전 세계를 여행하는 큰 변화를 겪을 때도 살아남았고, 제 파트너와 함께 많은 나라를 여행하기도 했습니다.\n\n![여행가방 이야기](/assets/img/2024-06-20-TheStoryoftheTravelingBag_1.png)\n\n<div class=\"content-ad\"></div>\n\n한동안 지나면서 가방이 부패하기 시작했습니다. 우리는 절대적으로 모든 것에 사용하고 있는데, 평범한 면으로 만들어진 것이기 때문에 그럴 만하죠. 먼저, 스트랩이 풀어지기 시작했어요 - 그건 쉽게 해결할 수 있었어요. 어느 날 시장에서 스트랩 소재를 발견하고 새로운 것을 손으로 봉제할 수 있었습니다. 기존 스트랩을 바로 끊기보다는 짧게 잘랐다가 새로운 스트랩에 봉제했어요. 또한 카라비너으로 가방에 뭔가를 걸고 싶을 때 루프를 추가했어요, 예를 들어 물병 등.\n\n저는 스트랩을 가방에 직접 봉합함으로써 스트랩과 가방이 만나는 부분이 약해진 지점을 보강했습니다.\n\n우리가 터키 이스탄불에 있을 때, 저희는 꿈같은 수공예 상점을 우연히 만났어요. 그 상점에서 본 물건들은 정말 대단했고, 그날 찍은 영상을 공유하고 싶었어요. 어떤 창의적인 사람이라도 천국에 갔다온 듯한 느낌을 받았을 거예요.\n\n안타깝게도 우리에겐 많은 돈이 없어서 심각하게 쇼핑은 안 하고 둘러보기만 했지만, 눈여겨본 것 중 하나는 패치들이었어요. 그때쯤이면 내 사랑하는 가방에 구멍이 나기 시작했고, 사용하는 데 조심해야 했어요. 언젠가는 수리할 수 없을 정도로 찢어질까 걱정하는데, 무엇보다도 채소나 운반품 등이 바닥으로 떨어질까 걱정했습니다.\n\n<div class=\"content-ad\"></div>\n\n그 순간 나는 패치들이 가방의 구멍들을 메울 수 있는 필요한 것이라는 것을 깨달았어요. 그 가방을 어떻게든 구할 수 있기를 간절히 바랬죠.\n\n우리는 주로 같은 패치들로 이뤄진 10개 패치 세트만 구매할 수 있었어요. 그래도 패키지는 저렴했어요. 한 세트에 대략 $2-3 정도였죠. 나는 멋진 버섯, 설탕 두개골, 그리고 벌 한 마리 패키지를 사게 되었어요. 나는 벌 패치만 따로 사진이 있고, 다른 패치들은 가방에 붙어 있을 거에요.\n\n![bee](/assets/img/2024-06-20-TheStoryoftheTravelingBag_2.png)\n\n또한 그 날에 자수실을 구입해서 가방 상단을 강화하는 데 사용했고, 장식적으로 나선 모양을 만드는 데도 사용했어요. 그 때는 결국 전체 가방을 자수할 것이라고 생각했어요. 하지만, 얼마나 많은 노력이 필요한지 깨달은 후에, 그 꿈은 길지 않게 사라지게 되었어요.\n\n<div class=\"content-ad\"></div>\n\n그러나 아래에서 확인할 수 있듯이 몇 가지 자수 작업을 한 것 같아요. 가방의 약한 부분을 강화하는 데 효과가 있었어요.\n\n![image](/assets/img/2024-06-20-TheStoryoftheTravelingBag_3.png)\n\n이제는 가방에 다른 부분들을 봉제하기도 시작했어요. 네팔에서 얻은 낡은 티셔츠가 있었는데, 그것을 가방에 있는 원하는 부분을 자르고, 그것을 봉았어요. 우리가 2019년에 카리브해의 식물원에서 봉사를 한 봉사복도 있었는데, 그옷에서 패치를 자르고, 가방에 봉았어요.\n\n저는 이 가방을 우리의 여행과 경험의 대표로 만들고 싶다는 것을 깨달았어요. 그래서 우리가 방문한 나라들에서 패치를 찾아 추가하기 시작했어요. 또한 캐나다 패치를 가지고 다니고 있었는데, 봉제할 곳이 필요했고, 마침 이제 그 곳이 생겼어요.\n\n<div class=\"content-ad\"></div>\n\n조금씩, 시간을 들여 가며, 다가오는 멸망으로부터 가방을 살리기 위해 필사적인 노력을 했습니다.\n\n2022년에 만든 가방을 보세요. 가장자리 주위에 자수 실이 더 잘 보이고, 또한 티셔츠의 다른 조각들을 이어 붙이는 데도 사용했어요. 맞아요, 1996년 네팔에서 받은 티를 입었던 거죠. 나를 향수로 그리게 만들어.\n\n지금 가방에 있는 파란색이 어디서 왔는지 궁금할 텐데, 그것은 우간다에서 도색을 하다 우리가 가방을 들고 작업하고 있을 때 직원 중 한 명이 가방 옆에 컨테이너에 파란색 페인트를 엎었을 때 생긴 것이에요. 우리는 바로 알아차리지 못했는데, 알아차린 때에는 이미 절반 정도 말랐더라고요.\n\n그래, 결정했습니다. 결국 이 가방은 창의적인 가방이니까요, 우리는 벽화 화가니까 말이죠. 테마에 딱 맞는 가방인 거 같네요!\n\n<div class=\"content-ad\"></div>\n\n그 가방은 꽤 오랫동안 이런 식으로 존재했어요. 하지만 상상할 수 있겠지만, 벌어진 곳들이 점점 더 더러워지고 얇아지고 있다는 걸 알았어요. 이 가방을 완전히 살리고 싶다면 더 많은 패치를 구하고 생산량을 늘려야 한다는 걸 알았죠.\n\n그리고 2023년 캐나다로 돌아왔을 때, 가족과 친구를 만나고 재정 문제를 정리하러 다시 방문했어요. 몇 달 동안만 돌아올 계획이었는데, 여행에서 좀 더 긴 휴식이 필요하다고 깨달았어요. 이제 거의 1년 동안 돌아와 있다는 사실에 놀라고 있어요.\n\n어느 날, 크리스의 엄마를 만나러 갔는데 갑자기 영감이 떠올랐어요. 그녀는 바느질을 잘하시고 다양한 것들을 만드시는데요 — 퀼트, 앞치마 등이죠. 그녀가 패브릭 조각이 좀 있을 거라고 생각했고, 그걸 이용해서 가방에 덧대면 더 견고해질 수 있지 않을까 생각했어요.\n\n패브릭을 다룬다면, 얼마나 어처구니 없는 질문인지 아실 거예요. 그녀는 나를 바느질 방으로 데려가 데스크 서랍 가득한 패브릭 조각을 보여주었어요.\n\n<div class=\"content-ad\"></div>\n\n저는 황야에 있었어요.\n\n서랍을 헤집어서 원하는 패턴을 골라내고, 가방에 원하는 부분을 자르고, 그리고 바쁘게 그것들을 바느질로 달았어요. 지그재그 스티치를 사용해서 가방에 직접 달았는데, 모양이 어떻게 되었는지는 크게 신경쓰지 않았어요. 제 주요 목표는 가방을 강화하는 것이었기 때문에 완벽함에 대해서는 걱정하지 않았어요.\n\n몇 시간 후, 지하실에서 나와서 제 작품을 보여주었어요. 그녀가 바느질에서 얼마나 정교한지 알고 있기 때문에, 정말로 무엇을 생각했을지 궁금하기도 해요 — 하지만 그녀는 그것을 좋아했다고 말했어요.\n\n하나 또는 두 개의 장점은 분명히 더 다채롭게 보이긴 해요!\n\n<div class=\"content-ad\"></div>\n\n여러분들도 보시다시피, 우리가 방문한 장소들의 다른 패치들을 발견하여 믹스에 추가했습니다. 시간이 흐를수록 이를 계속 추가하고, 우리의 여행 이야기를 담은 패치워크가 되길 바랍니다.\n\n![이미지](/assets/img/2024-06-20-TheStoryoftheTravelingBag_4.png)\n\n요즘 가방은 훨씬 더 강해 졌고, 시간의 시험을 견디리라는 것을 알게 되었습니다. 어떻게 그리고 왜 나에게 가장 소중한 소지품 중 하나가 되었는지는 아직도 잘 모르지만, 앞으로도 많은 해 동안 사용할 기대가 되네요.\n\n이 이야기는 다른 'Share Your Creativity' 작가, Chloe ~ Calendula Craft와 그녀의 기억을 담은 퀼트를 만드는 기사에서 영감을 받았습니다.\n\n<div class=\"content-ad\"></div>\n\n창의력을 공유하고 싶다면, 제 출판물에 창의적인 글을 제출해보는 것을 고려해보세요:\n\n![TheStoryoftheTravelingBag](/assets/img/2024-06-20-TheStoryoftheTravelingBag_5.png)\n\n제 글이 마음에 들고 더 읽고 싶다면, 저를 팔로우하고 여기에서 이메일로 제 글을 받아보실 수 있도록 가입해주세요. 또한 Patreon이나 Ko-Fi 링크를 통해 팁을 보내주시면 저희가 매우 기쁠 것입니다:)\n\n2017년부터 우리는 유목민의 삶을 살아왔어요! 아래 링크를 클릭해 우리의 여정에 동행해보세요:\n\n<div class=\"content-ad\"></div>\n\n웹사이트 | 인스타그램 | 페이스북 | 링크드인 | 패트리언 | 유튜브 | 미디엄 | 트위터 | 코-피 | 언스플래시","ogImage":{"url":"/assets/img/2024-06-20-TheStoryoftheTravelingBag_0.png"},"coverImage":"/assets/img/2024-06-20-TheStoryoftheTravelingBag_0.png","tag":["Tech"],"readingTime":5}],"page":"49","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}