{"pageProps":{"posts":[{"title":"핵심 리눅스 터미널 해킹 요령 효율성을 위한  파트 2","description":"","date":"2024-06-19 08:35","slug":"2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2","content":"\n\n## 파트 2: 팁과 꿀팁 - 역 cmd 검색, 히스토리에서 날짜와 시간 등.\n\n![이미지](/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_0.png)\n\n참고: 일부는 기본 명령어일 뿐입니다.\n\n## 1. 역 검색 cmds:\n\n<div class=\"content-ad\"></div>\n\n명령을 재사용하려면 Ctrl + R을 누르고 일치하는 키워드 몇 개를 입력하여 최근에 사용된 명령을 확인할 수 있습니다. 검색은 명령 히스토리를 기반으로 합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*8d6OCQLH_WCzvQCcUpCfcQ.gif)\n\n## 2. 히스토리에서 특정 명령 사용하기\n\n이전에 사용된 모든 명령을 나열하려면 history 명령을 사용하고 “!`숫자`”를 사용하여 해당 명령을 재사용하세요.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_1.png)\n\n## 3. Show Date and time in History:\n\nTo view the date and time in the command history, use HISTTIMEFORMAT and select how you want the date to be displayed.\n\n```sh\nHISTTIMEFORMAT=\"%d-%m-%y %r\" history\n\n%d - Day\n%m - Month\n%y - Year\n%T / %r - Time in 24/12 hour format\n```  \n\n<div class=\"content-ad\"></div>\n\n영구적으로 설정하려면 .bashrc 파일에 아래 코드를 추가하세요.\n\n```js\nexport HISTTIMEFORMAT=\"%d-%m-%y %r \"\n```\n\n<img src=\"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_2.png\" />\n\n참고: 현재 일자가 기록되지 않았기 때문에 현재 날짜가 모든 날짜에 표시될 수 있지만, 이후에는 정확한 날짜가 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 4. 한 번에 여러 명령 실행하기:\n\n여러 명령을 동시에 실행하려면 3가지 옵션을 사용하여 함께 연결할 수 있습니다.\n\n-  `;` — 명령을 순차적으로 실행합니다.\n\n- `&&` — 하나의 명령이 실패하면 다음 명령이 실행되지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n\n|| — Command runs only if the previous cmd fails.\n\n![Screenshot](/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_3.png)\n\n## 5. View content with Less:\n\nViewing a file with large data using “cat” spams the whole window, using less shows a chunk of content, and then you can scroll up or down.\n\n\n<div class=\"content-ad\"></div>\n\n다른 기능들은 다음과 같습니다:\n\n- 검색: 파일 내에서 특정 용어를 /`검색 용어`를 사용하여 검색합니다.\n- 탐색: 파일 끝으로 이동하려면 G를 입력하세요, 1G(1행으로 이동), N(이전 검색 반복) 등이 있습니다.\n- 옵션: -N(행 번호 표시), -i(검색 시 대소문자 구분 없음), -S(텍스트 자동 줄 바꿈 비활성화) 등과 같이 동작을 사용자 정의할 수 있는 여러 옵션이 있습니다.\n\n## 6. 열(Column):\n\ncolumn 명령어를 사용하여 텍스트 파일이나 명령어 출력을 더 읽기 쉬운 형식으로 볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```sh\n# -t 옵션을 사용하여 표 형식으로 보여줍니다. -s 옵션은 구분자를 지정합니다. column 명령어로 실행하거나 다른 명령어의 출력을 column으로 파이핑하세요.\n\ncolumn -s ',' -t data.csv # 파일로부터 구분된 값으로 표시\n\ncat /etc/passwd | column -s ':' -t\n```\n\n<img src=\"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_4.png\" />\n\n## 6. 파일 자르기\n\n\n<div class=\"content-ad\"></div>\n\n파일을 열지 않고 내용을 지우려면 truncate를 사용하세요. -s (--size)로 크기를 지정할 수 있습니다. 0은 파일을 비우는 것이고 다른 숫자는 해당 크기로 줄이는 것을 의미합니다.\n\n```js\ntruncate -s 0 filename.txt -- 모든 데이터 삭제\ntruncate -s 100 filename.txt\n```\n\n<img src=\"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_5.png\" />\n\n## 7. Head and Tail:\n\n<div class=\"content-ad\"></div>\n\n이름 그대로 말하듯이, head는 파일의 처음 몇 줄을 보여주고, tail은 마지막 몇 줄을 보여줍니다.\n\n표시할 줄 수도 지정할 수 있습니다.\n\n```js\nhead/tail -n 20 <file>\n```\n\n`-f` 옵션을 사용한 tail은 로그와 같이 변경되는 파일을 볼 때 유용합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ntail -f <file>\n```\n\n![Image](/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_6.png)\n\n## 8. View exit code:\n\nExit codes show the results of execution, typically useful for shell scripts. Use `echo $?` to view the exit code of the previous command.  \n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_7.png\" />\n\n## 9. 중첩 디렉토리 만들기:\n\n중첩 디렉토리를 만들어야 할 때는 /를 사용하여 하위 디렉토리를 정의하세요.\n\n```js\nmkdir -p dir/{dir1/subdir1,dir2,dir3/subdir3}\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_8.png\" />\n\n## 10. 파일 명령어:\n\nfile 명령어를 사용하여 어떤 파일의 유형을 확인할 수 있습니다. 특히 확장자가 없는 파일이나 diff 파일로 위장된 파일을 식별하는 데 유용합니다.\n\n예시: #!에 파이썬 인터프리터가 있는 .sh 파일.\n\n<div class=\"content-ad\"></div>\n\n오늘은 여기까지입니다.\n\npart 1은 여기에서 확인하세요:\n\n<img src=\"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_10.png\" />\n\n<div class=\"content-ad\"></div>\n\n## 👋 만약 이 내용이 도움이 되었다면, 아래 👏 버튼을 몇 번 클릭하여 작성자에 대한 지원을 보여주세요 👇\n\n## 🚀 FAUN 개발자 커뮤니티에 가입하고 매주 이메일로 비슷한 이야기를 받아보세요","ogImage":{"url":"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_0.png"},"coverImage":"/assets/img/2024-06-19-EssentialLinuxTerminalHacksforefficiencyPart2_0.png","tag":["Tech"],"readingTime":4},{"title":"오픈 소스 프로젝트가 왜 많은 경쟁을 하는 걸까요","description":"","date":"2024-06-19 08:33","slug":"2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects","content":"\n\n\n![2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_0.png](/assets/img/2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_0.png)\n\n![2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_1.png](/assets/img/2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_1.png)\n\n우리 모두에게 일어난 일이죠. 문제를 해결할 소프트웨어 패키지를 찾아보면 멋진 오픈 소스 프로젝트를 발견하곤 합니다. 그리고 또 다른 프로젝트를 찾게 됩니다. 그 이유는 무엇일까요?\n\n# 고양이를 쓰다듬는 방법은 다양합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_2.png\" />\n\n가끔은 동일한 문제를 해결하기 위해 여러 프로젝트가 존재하는 이유는 다양한 접근 방식 때문입니다. 이러한 방식은 기술적 가치나 스타일적 선택 사항에 따라 다를 수 있습니다. 왜 소켓 렌치와 박스엔드 렌치 둘 다 자가 있어야 할까요? 둘 다 볼트를 돌리는 도구지만 서로 다른 기능을 가지고 있습니다.\n\n예를 들어, KDE Plasma와 LXQt는 모두 Qt 기반 데스크톱 환경입니다. 그러나 Plasma는 더 기능이 풍부한 경험을 위해 설계되었고, LXQt는 가벼운 환경을 제공합니다. GNOME 데스크톱의 3버전이 출시되면서, 일부 사람들은 2버전 스타일을 선호하여 MATE 데스크톱으로 계속 개발했습니다.\n\nApache HTTPD와 NGINX는 가장 널리 사용되는 두 웹 서버입니다. 둘 다 왜 있을까요? Apache는 일부 사용 사례에 중요한 유연한 사용자 정의를 제공합니다. 그러나 NGINX의 아키텍처는 리소스 풋프린트를 줄여줍니다. 특정 사례에서 올바른 선택은 필요한 것에 따라 달라집니다.\n\n<div class=\"content-ad\"></div>\n\n한 번 생각해 봐요: 대부분의 개발자들은 여러 프로그래밍 언어를 알고 필요에 따라 사용합니다. 텍스트를 많이 구문 분석해야 할 때는 Perl을 사용해요. 몇 가지 명령어를 연결해야 할 때는 셸 스크립트가 구원의 천사죠. 버그 데이터 또는 설문 결과를 분석할 때는 Python의 pandas 라이브러리가 제 선택이에요.\n\n# 이 코드를 가져가서 분기해 보세요!\n\n![image](/assets/img/2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_3.png)\n\n경쟁 프로젝트는 커뮤니티 일부가 코드를 가져가서 다른 곳으로 이동하기로 결정할 때 발생할 수 있어요. 이를 포크(fork)라고 해요. 이 종류의 포크는 GitHub에서 프로젝트에 기여할 때 만드는 포크와 혼동하면 안 돼요. 기본적으로 메커니즘은 비슷하지만, GitHub 포크는 일반적으로 일시적이에요. 우리가 이 섹션에서 이야기하는 포크는 영구적이에요.\n\n<div class=\"content-ad\"></div>\n\n포크도 친절할 수 있어요. 친절한 포크는 원본 프로젝트에 변화를 기여하고자 만들어졌거나 실험을 하기 위해 만들어진 것이에요. 친절한 포크의 한 예시로 네오오피스 프로젝트가 있어요. 이 프로젝트는 인기 있는 오픈 오피스 스위트의 OS X 네이티브 버전을 개발하기 위해 만들어졌어요. 리눅스 배포의 소프트웨어 패키지는 종종 친절한 포크인데, 원본이 아직 수정되지 않은 버그나 빌드 문제를 해결하기 위한 패치가 포함되어 있어요.\n\n반면에, 포크가 혼란스러워질 수도 있어요. 리브레오피스는 오라클이 선 마이크로시스템즈(그리고 오픈 오피스)를 인수한 이후에 오픈 오피스로부터 포크되었어요. 커뮤니티가 오라클을 믿지 않았기 때문에 코드를 가져가 새로운 프로젝트를 시작했어요. 개발자가 커뮤니티를 떠나도록 요청받거나(또는 스스로 결정한다면), 과거 프로젝트의 적대적인 포크를 만들 수도 있어요.\n\n<div class=\"content-ad\"></div>\n\n프로젝트 설립자들은 대개 이유를 공개하지 않지만, 때로는 경쟁 프로젝트를 시작하는 이유가 그들이 그것이 자신들의 것이 되기를 원하기 때문일 수도 있습니다. 이 이유는 특별히 설득력이 있는 것은 아니기 때문에 보통 \"기존 프로젝트에 제가 정말 필요한 것이 없다\"는 핑계 속에 숨겨져 있습니다. 저는 그 누구의 이름도 여기서 언급하여 남들을 부끄러워하지는 않겠습니다. 여러분들도 필요한 예를 직접 찾아보실 수 있을 거라고 확신합니다.\n\n주목할 만한 \"우리가 만들지 않은 것\" 프로젝트 중에는 취미 또는 학습 프로젝트로 시작하여 크게 성장한 것들도 있습니다. 리누스 토발즈는 리눅스를 \"gnu처럼 크고 전문적이지 않을 취미\"로 소개했습니다. 오늘날 당연히 리눅스 커널은 다른 어떤 장치보다도 많은 곳에서 실행됩니다.\n\n# 이게... 좋은 건가요?\n\n![이미지](/assets/img/2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_5.png)\n\n<div class=\"content-ad\"></div>\n\n한편, 경쟁 프로젝트들이 혼란스러운 상황을 초래한다는 점이 있습니다. 새로운 사용자는 간단히 리눅스를 설치할 수 없습니다. 먼저, 수십 가지의 배포판 중 어떤 것을 설치할지 결정해야 합니다. 그리고 우분투나 페도라와 같은 대형 배포판을 선택하더라도, 해당 그룹 내에서도 더 많은 변종을 선택해야 합니다.\n\n이 분열은 많은 어려움을 야기합니다. 표준화의 부재가 리눅스 데스크톱의 주류 채택을 제한한다는 주장도 있습니다.\n\n그러나 분열은 기회를 제공하기도 합니다. 경쟁하는 프로젝트들은 아이디어와 개발자들을 공유하면서 협력합니다. 코드가 공개되어 있기 때문에 서로의 성공과 실패에서 교훈을 얻을 수 있습니다. 문제 해결에 대한 다양한 접근 방식을 시도하면 가장 좋은 방법을 찾아낼 수 있습니다. 때로는 명확한 우승자가 나타나서 사실상의 표준이 됩니다. 그렇지 않다면, 당신의 요구 사항과 취향에 맞는 오픈 소스 프로젝트를 찾을 수 있을 것입니다. 만약 찾지 못한다면, 당신이 하나를 창시할지도 모릅니다.\n\n저자 Ben Cotton의 책을 The Pragmatic Bookshelf에서 확인해보세요. open_source_2022 프로모션 코드로 2022년 11월 15일까지 현재 구매에서 35%를 할인 받을 수 있습니다. 프로모션 코드는 이전 구매에는 적용되지 않습니다.","ogImage":{"url":"/assets/img/2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_0.png"},"coverImage":"/assets/img/2024-06-19-WhyAreThereSoManyCompetingOpenSourceProjects_0.png","tag":["Tech"],"readingTime":4},{"title":"게임을 하며 리눅스 마스터하기","description":"","date":"2024-06-19 08:32","slug":"2024-06-19-MasteringLinuxwhilePlayingGames","content":"\n\n## 테르미너이터\n\n테르미너이터는 레트로 픽셀 아트 그래픽을 가진 초보자들을 위한 훌륭한 어드벤처 게임입니다. 이 게임을 플레이하면서 지정된 데이터를 검색하고 정보를 인쇄하며 디렉토리를 거쳐 이동해야 합니다. 게임에서는 악당 마법사로부터 세상을 구해야 합니다.\n\n## 리눅스 서바이벌\n\n리눅스 서바이벌은 서로 다른 주제를 다루는 네 가지 모듈로 구성되어 있습니다. 각 모듈 이후에 퀴즈 세션이 있어 지식을 테스트할 수 있습니다. 게임을 하려면 계정을 만들 필요는 없지만, 계정을 만들면 진행 상황을 추적할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## Over The Wire: 전쟁 게임\n\n이것은 다양한 주제를 다루는 수많은 게임들의 컬렉션입니다. 예를 들어, 웹 보안 (Bandit), 암호학 (Krypton), 기본적인 취약점 분석 (Narnia) 등을 다룹니다. 게임마다 서로 다른 레벨이 많이 있습니다. 다음 레벨로 넘어가려면 다양한 도전 과제를 해결해야 하므로 모험과 같은 느낌을 경험할 수 있습니다. SSH를 통해 각 게임 서버에 연결해야 합니다.\n\n## Linux Journey\n\n리눅스 여정은 초보자와 숙련자 모두에게 동일하게 유용한 자원을 제공합니다. 지식을 확인하고 기술을 더 깊이 파고들고 실습 경험도 풍부하게 할 수 있는 퀴즈 및 연습 세션을 제공합니다. 모든 자료는 텍스트를 기반으로 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 명령 줄 영웅: BASH\n\n이 게임은 모두 중에서 가장 간단한 것입니다. 규칙은 주어진 시간 내에 가능한 많은 유효한 명령어를 입력하는 것뿐입니다. 하지만 저는 이 게임을 꽤 좋아합니다. 이는 실제로 모든 Linux 사용자에게 매우 유용한 운동 도구입니다. 한 번 시도해보세요!\n\n## 슬픈 서버들\n\n슬픈 서버들은 리눅스에 대한 심층적인 이해를 가진 고급 사용자를 위한 현실적인 시나리오로 구성된 시간 제한 해결 도전 과제들로 이루어져 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 명령어 챌린지\n\n명령어 챌린지는 일련의 명령줄 작업으로 구성되어 있습니다. 이 게임은 이 게시물에서 소개된 다른 게임들과 비교하면 초보자를 제외하고는 꽤 쉬울 수도 있습니다. 그럼에도 불구하고 언제나 즐길 수 있고 (중독적일 수도 있는) 대안적인 해결책도 제공됩니다.\n\n([방문하러 가기](https://example.com))\n\n![게임 화면](/assets/img/2024-06-19-MasteringLinuxwhilePlayingGames_0.png)\n\n<div class=\"content-ad\"></div>\n\n## Bash Crawl\n\n배시 스크립트 실력을 향상시키기 위한 텍스트 기반 어드벤처 게임입니다. Windows 사용자도 Cygwin이나 WSL을 설치함으로써 이 게임을 즐길 수 있습니다. Bashcrawl은 게임 Rogue와 유사한 ASCII 아트 던전 크롤러로, 플레이어는 캐릭터를 제어하고 몬스터와 보물이 많은 던전을 탐험합니다. 게임에서 던전은 시스템 상의 디렉토리와 파일로 생성됩니다. 그래서 cd 명령어를 사용하여 던전을 탐험하고 ls -F로 파일을 검사하며 cat 명령어로 파일을 읽고, 보물을 수집하기 위해 변수를 설정하고, 스크립트를 실행하여 몬스터와 전투합니다.\n\n아래의 GitLab 페이지를 방문하여 게임을 설치해야 합니다:\n\n## Command Line Murder Mystery\n\n<div class=\"content-ad\"></div>\n\nNoah Veltman의 GitHub 페이지를 방문하고 이를 다운로드해야 합니다. 이 게임에서 당신은 탐정이 되어 Linux 명령어를 사용하여 폴더와 파일을 탐색하여 살인 사건 플롯을 해결해야 합니다. 힌트 파일과 솔루션 파일이 각각 분리되어 있습니다.\n\n![이미지1](/assets/img/2024-06-19-MasteringLinuxwhilePlayingGames_1.png)\n\n![이미지2](/assets/img/2024-06-19-MasteringLinuxwhilePlayingGames_2.png)","ogImage":{"url":"/assets/img/2024-06-19-MasteringLinuxwhilePlayingGames_0.png"},"coverImage":"/assets/img/2024-06-19-MasteringLinuxwhilePlayingGames_0.png","tag":["Tech"],"readingTime":3},{"title":"RAGAS 해석 해부 검색-보완 생성 파이프라인 평가의 심층 탐색 1부 소개","description":"","date":"2024-06-19 06:56","slug":"2024-06-19-DemystifyingRAGASADeepDiveintoEvaluatingRetrieval-AugmentedGenerationPipelinesPart1Introduction","content":"\n\n# 기계의 부상... 약간의 도움과 함께\n\nAI가 창의적인 텍스트 형식을 생성하는 것뿐만 아니라 현실 정보에 접근하고 활용하여 정확하고 통찰력있는 응답을 창조할 수 있는 세상을 상상해보세요.\n\n# LLMs: 지식 갭을 가진 파워헤우스\n\nGPT-3 및 Jurassic-1 Jumbo와 같은 LLM은 인상적인 공학적 업적으로, 인간 수준의 텍스트를 생성하고 언어를 번역하며 다양한 종류의 창의적 콘텐츠를 작성할 수 있는 능력을 갖췄습니다. 그러나 그들의 지식은 종종 그들이 훈련받은 방대한 양의 데이터로 제한됩니다. 이는 특정 사실적 정확도나 현실 세계 맥락을 필요로하는 프롬프트에 직면했을 때 결함으로 이어질 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nLLM은 뛰어난 똑똑하고 책임적인 학생으로 생각할 수 있습니다. 그들은 노출된 정보를 기반으로 멋진 에세이를 쓸 수 있지만, 도서관이나 역사적 자료와 같은 외부 자료를 참고해야 하는 질문에 어려움을 겪을 수도 있습니다.\n\n# RAG가 도와줍니다: LLM 성능 향상\n\n여기서 RAG가 등장합니다. RAG는 LLM과 외부 데이터베이스나 문서에 있는 다양한 지식 사이의 다리 역할을 합니다. 이들 외부 자료에서 검색된 관련 정보 조각들을 제공함으로써, RAG는 LLM에게 다음과 같은 기회를 제공합니다:\n\n- 더 많은 사실적인 텍스트 생성. LLM은 그들의 주장을 뒷받침하기 위해 현실 세계 데이터에 접근하고 통합할 수 있습니다.\n- 생성된 텍스트의 일관성과 집중력 향상. 명확한 맥락을 가지고 있으면, LLM은 주제를 잘 따라갈 수 있고 관련 없는 변칙을 피할 수 있습니다.\n- 출력물의 전반적인 품질과 정보성 향상. RAG가 제공하는 파워를 받은 LLM은 보다 포괄적이고 통찰력 있는 응답을 제공할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 평가 도전 과제: RAG 시스템이 모든 기능을 완벽히 수행하는지 확인하기\n\nRAG 파이프라인을 개발하는 것은 흥미로운 일이지만, 실제로 효과적으로 작동하는지 어떻게 알 수 있을까요? LLM에 대한 전통적인 평가 방법은 대부분 인간 주석 참조에 의존하는 경우가 많은데, 이는 다음과 같은 단점이 있을 수 있습니다:\n\n- 시간이 많이 소요됨: 생성된 텍스트를 대규모로 수동 평가하는 것은 지루하고 시간이 많이 소요될 수 있습니다.\n- 비용이 많이 듦: 인간 주석 작업자를 고용하는 것은 평가 프로세스에 상당한 비용이 들 수 있습니다.\n- 주관적임: 인간 평가는 주관적이며 편향을 일으킬 수 있습니다.\n\n# RAGAS 소개: RAG 평가를 변화시키는 게임 체인저\n\n<div class=\"content-ad\"></div>\n\nRAGAS 프레임워크는 이러한 문제에 직면하여 RAG 파이프라인을 평가하는 자동화된 객관적 방법을 제공함으로써 독자적으로 대응합니다. RAGAS를 두드러지게 만드는 이유는 다음과 같습니다:\n\n- 참조 없는 평가: 기존 방법과 달리, RAGAS는 생성된 텍스트를 평가하기 위해 다른 LLMs를 활용합니다. 이는 인간이 주석을 달아야 하는 필요를 제거하여 시간과 자원을 절약합니다.\n- 구성 요소 수준의 지표: RAGAS는 RAG 파이프라인의 다양한 측면을 분석하는 지표 모음을 제공합니다. 이는 검색된 정보의 관련성, LLM이 이를 얼마나 잘 활용하는지, 생성된 텍스트의 전반적인 품질을 포함합니다. 이 구체적인 분석은 개선할 영역을 정확히 지목하는 데 도움이 됩니다.\n\n다음 블로그 시리즈의 다음 부분을 기대해 주세요. 여기서는 RAGAS의 기능을 더 깊이 탐구하고 핵심 지표를 탐색하며, 직접 RAG 파이프라인을 평가하기 위해 RAGAS를 구현하는 데 도움이 되는 코드 예제도 제공할 것입니다!\n\n다음 부분에서는 RAGAS의 내부 작업을 탐구하고 RAG 평가의 도전 과제를 어떻게 해결하는지 밝힐 것입니다.","ogImage":{"url":"/assets/img/2024-06-19-DemystifyingRAGASADeepDiveintoEvaluatingRetrieval-AugmentedGenerationPipelinesPart1Introduction_0.png"},"coverImage":"/assets/img/2024-06-19-DemystifyingRAGASADeepDiveintoEvaluatingRetrieval-AugmentedGenerationPipelinesPart1Introduction_0.png","tag":["Tech"],"readingTime":2},{"title":"30일 동안 52 수익률 당신의 GPT-4o 얀트 트레이딩 봇 전략","description":"","date":"2024-06-19 06:54","slug":"2024-06-19-52Returnsin30DaysYourGPT-4oQuantTradingBotStrategy","content":"\n\n양자 거래는 수익을 창출할 수 있지만, 오랫동안 많은 자원, 코딩 및 수학 기술을 가진 거래자들이나 대규모 기관들만이 수행할 수 있는 것으로 여겨졌습니다.\n\n하지만 이제는 그렇지 않습니다! 이제 ChatGPT의 도움을 받아 양자 거래에서 이점을 얻을 수 있습니다.\n\n그럼 GPT-4o의 도움을 받아 수익을 창출할 수 있는 양자 거래 전략을 찾아봅시다. 그리고 얼마나 간단한지 보여 드리겠습니다!\n\n시작하기 전에 한 가지만 더 말하자면, '근본적 분석'과 '가치 투자'에 집중하는 사람이에요. 제 글을 읽는 여러분은 이미 알고 있겠지만요. 이것들은 장기 투자의 성공적 기초입니다. 이 글의 목표는 가능성을 열어주는 것입니다. 이 글에서는 실제 돈을 사용하여 거래 봇을 사용하지 않았고, 여러분도 이해하기에 아주 충분하다면 사용하지 않는 것이 좋습니다.\n\n<div class=\"content-ad\"></div>\n\n# GPT-4o가 거래자에게 큰 도약인 이유\n\n최근 출시된 GPT-4o는 이전 LLM 모델과 비교하여 새로운 기능을 갖추고 있어요.\n\n먼저, GPT-4o는 이미지를 아주 잘 이해합니다. 이제 차트를 업로드하면 ChatGPT가 해당 차트에 맞춰 지표나 전략을 작성하는 데 도움을 줄 수 있어요.\n\n둘째, GPT-4o는 이전 모델보다 훨씬 빠르고 정확해요. Claude도 꽤 인상적이고 정확하지만, GPT-4o는 이미지를 이해하는 데 뛰어나죠.\n\n<div class=\"content-ad\"></div>\n\n위의 HELM 리더보드에 따르면 다양한 도메인에서 다른 모델의 성능을 추적하고 있습니다. GPT-4o는 Claude 다음으로 정확한 답변을 제공합니다.\n\nVLMs인 Visual to Language Models에서 GPT-4o는 경쟁 모델들에 비해 훨씬 앞서 있습니다. 이는 우리가 GPT-4o에 업로드한 차트를 잘 이해하고 이를 기반으로 거래 전략을 만들기를 원하기 때문에 좋은 소식입니다.\n\n이 AI 중 어떤 것을 최대한 활용하고 싶다면, 리더보드를 살피는 것을 추천드립니다. 이는 그들이 매우 빠르게 발전하기 때문에 중요합니다.\n\n익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익익\n\n<div class=\"content-ad\"></div>\n\n# GPT-4o와 함께하는 당신만의 양자 거래 봇 만들기\n\n전체 공개: 한 달 동안 52%의 수익을 올리는 봇을 만들었습니다. 그러나 거래에서는 아무 것도 보장되지 않으며, 과거 결과가 미래 수익과 일치하지 않을 수 있습니다.\n\n이를 고려하여, 이 기사의 목표는 당신이 AI 보조 양자 거래 전략을 상상하고 만들고 시험하며, 결국 이로부터 수익을 얻을 수 있도록 도구를 제공하는 것입니다.\n\n우리는 TradingView를 사용하여 AI 거래 전략을 테스트할 것입니다. 무료 TradingView 계정이 없다면, 제 제휴 링크를 사용해주시고 추가 비용은 없습니다. 지원해 주셔서 감사합니다!\n\n<div class=\"content-ad\"></div>\n\n시작해 봅시다.\n\n# 단계 1 — 자산 선택\n\n평균 회귀와 같은 양자 거래 전략의 경우, 측면으로 거래되는 자산이 종종 더 좋은 결과를 내놓습니다. 그래서 몇 달 동안 측면으로 거래되고 있는 이더리움을 선택하기로 결정했습니다.\n\n시장이 측면이거나 하락할 때 수익을 올릴 수 있는 거래 봇을 만들어 볼 수 있는지 확인해 보고 싶어요.\n\n<div class=\"content-ad\"></div>\n\n# 2단계 — 차트로 GPT-4o에 프롬프트 제공하기\n\n일반적으로 간단하고 명확한 프롬프트가 매우 긴고 복잡한 것보다 더 효과적입니다. 여기서는 다음과 같이 차트와 함께 AI에게 프로핏 가능한 평균 회귀 Pine 5 얀트 전략을 만들 것을 지시했습니다:\n\n![차트](/assets/img/2024-06-19-52Returnsin30DaysYourGPT-4oQuantTradingBotStrategy_0.png)\n\n<div class=\"content-ad\"></div>\n\nGPT-4가 대답했습니다. Bollinger Bands와 RSI를 함께 사용하는 전략을 제안했어요.\n\n# 단계 3 — Pinescript 코드를 TradingView에 복사/붙여넣기\n\nTradingView의 Pine Editor로 이동하여 코드를 붙여넣기하세요. 그런 다음, 차트에 추가하세요. 전략은 이제 차트에서 백테스트되어야 하며 전략 테스터 탭에서도 실행될겁니다.\n\nTradingView에서 전략을 어떻게 백테스트하는지 모르겠다면, 아래 기사의 단계를 확인하는 것을 강력히 추천드립니다:\n\n<div class=\"content-ad\"></div>\n\n대화형 GPT 거래 봇을 사용하여 Wall Street 투자자의 99%를 이기세요!\n\n내 \"DEBOPIE\" 프레임워크로 최고의 대화형 GPT 거래 봇을 만드세요.\n\n만약 당신이 TradingView에 전략을 제대로 추가했다면, 아래 차트와 차트 상의 일부 오픈 거래 그리고 하단에 백테스팅 결과를 확인할 수 있어야 합니다.\n\n# 단계 4 — 당신의 양적 전략을 세밀하게 조정하세요\n\n<div class=\"content-ad\"></div>\n\n이제 전략을 백테스트해보는 것을 100번 더 시도해보기로 결정했군요.\n\n여러 다양한 시간 프레임과 매개 변수로 전략을 테스트해보세요. 이러한 값들을 조정해가며 어떤 것이 최상의 결과를 내는지 확인해보세요.\n\n실제 자본에 적용하기 전에 전략을 철저히 테스트하는 것이 매우 중요합니다.\n\n# 내 백테스트에서의 탁월한 수익률\n\n<div class=\"content-ad\"></div>\n\n내 백테스팅 결과에서 GPT-4o가 만든 전략은 매우 인상적인 결과를 냈습니다. 아래에서 확인할 수 있어요:\n\n1개월 동안 이 전략은 이더리움(ETH/USD)을 거래하여 놀라운 52%의 수익을 창출했어요.\n\n위 차트에서 파란 선은 \"매수 및 보유\" 전략을 나타내는데, 이 기간 동안 -7%의 수익률을 보여줬어요.\n\n이는 AI가 만든 평균 회귀 전략이 시장이 수평으로 거래되거나 하락 추세일 때에도 수익을 내는 것을 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n만약 따라오고 있다면, 저는 어떤 시장 상황에서도 혜택을 받을 수 있는 반패권 투자 포트폴리오를 구축 중이라는 것을 알고 계실 것입니다.\n\n위의 결과는 더 많은 테스트가 필요하지만, 시장이 호황이 아닌 경우에도 높은 수익을 얻을 수 있다는 것을 확인해서 기뻐합니다.\n\n# 결론\n\n여기서 멈추지 마세요. 귀하의 거래 전략을 완벽하게 하려면, 계속 백테스팅하고 최적화하며 확장해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n이 자동 거래 봇의 최적화 프로세스를 지원하기 위해 이 기사를 작성했습니다:\n\n기억하세요, 거래 성공의 핵심은 수익성 있는 전략을 갖고 있는 것뿐만 아니라 시장 상황 변화에 대해 계속해서 조정하고 적응하는 것입니다.\n\nGPT-4o와 같은 AI 도구의 도움과 지속적인 학습 및 개선에 헌신함으로써, 도전적인 시장 환경에서도 귀하의 거래를 다음 수준으로 인도할 수 있습니다.\n\n— Henrique Centieiro 🕺🏻\n\n<div class=\"content-ad\"></div>\n\n🚀 앞으로 미래에 더 가치 있는 콘텐츠를 제공하기 위해 \"한계 없는 투자자\" 퍼블리케이션을 팔로우해 주세요:\n\n🌞 접촉 유지:","ogImage":{"url":"/assets/img/2024-06-19-52Returnsin30DaysYourGPT-4oQuantTradingBotStrategy_0.png"},"coverImage":"/assets/img/2024-06-19-52Returnsin30DaysYourGPT-4oQuantTradingBotStrategy_0.png","tag":["Tech"],"readingTime":4},{"title":"프론티어 AI는 안전하지 않아요 그 이유를 알려드릴게요","description":"","date":"2024-06-19 06:53","slug":"2024-06-19-FrontierAIIsNotSafeHeresWhy","content":"\n\nAI 혁명의 리더들이 더 이상 자신들의 의도를 숨기지 않고 있습니다. 그들은 AI가 어디에나 존재하는 세상을 만들고 싶어합니다.\n\n하지만 비밀을 하나 알려드릴게요: 우리는, 즉 그들은, 이러한 모델을 안전하게 훈련하는 방법을 전혀 모릅니다.\n\n맞아요, 당신이 제대로 읽으셨습니다. 우리는 당신과 실질적으로 상호작용할 수 있는 태도를 갖춘 AI 모델을 만들려고 노력하지만, 그들이 무작위로 당신을 찔러서 상처를 입히는 경우를 방지하는 방법을 모르거나, 해킹당했을 때 당신이 낌없이 있지 않는 경우에 대한 보호를 어떻게 해야 할지 모릅니다.\n\n또한 실체화된 AI가 매우 멀리 떨어져 있는 것처럼 보일지라도, 심각한 피해를 줄 수 있는 로그 모델을 만들 위험이 우리에게 더 가까이 존재한다는 점을 잊지 마세요.\n\n<div class=\"content-ad\"></div>\n\n# AI 모델 트레이닝\n\n알고 계신지 모르시겠지만, LLMs 트레이닝은 세 단계로 이루어집니다.\n\n## \"가이드 레일 설정\"\n\n완전한 LLM 프로세스는 지능 생성, 행동 모델링 및 인간 선호도와의 조정을 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n- 사전 훈련: 우리는 찾을 수있는 모든 데이터를 그들에게 공급합니다 (안타깝게도 인종차별적인 텍스트, 동성애에 대한 적개심, 그리고 온라인에서 우연히 발견하는 모든 것을 포함합니다). 여기서 모델은 우리의 세계에 대해 배우고 단어가 어떻게 따르는지 배우지만 지시를 따르지는 못합니다.\n  \n- 행동 복제: 사용자와 대화하는 방법을 모델에 가르치는 '지시: 답변' 데이터 세트를 공급합니다. 하지만 모델은 안전장치가 없고 모든 요청에 응답합니다.\n  \n- 조정: 여기서 모델은 1단계에서 축적된 지식과 2단계에서의 지시 따르기 능력을 유지하면서 '사람들의 선호도' 데이터 세트를 사용하여 무엇을 할 수 있고 할 수 없는지 '인식'하게 합니다.\n\n특정 오픈 소스 모델에 액세스하지 않았다면, 상호작용한 모든 모델은 이 세 단계를 거친 것입니다.\n\n특히 GPT-4의 경우, 조정 단계는 가장 오래 걸리며 (최대 6개월), 기업들은 제대로 하고 GPT-4가 누군가에게 인종차별적인 시를 써주고 바이럴해지는 것을 피해야한다는 것을 알고 있습니다.\n\n그러나 안타깝게도, 3단계는 되돌릴 수 있습니다. 실제로 조정되지 않은 데이터로 간단한 미세 조정을 수행하면 모범적인 모델이 '나쁜 놈 삽입'의 환생으로 변할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 이 주제에 대한 최신 흥미로운 연구에서 밝혀졌듯이, 우리의 정렬 방법, 안전을 위해 이러한 모델을 훈련하는 방식은 매우 제한적이며 쉽게 탈옥할 수 있습니다. 이는 언젠가 우리가 컨트롤할 수 없는 정말 강력한 것을 만들게 될 위험성을 증가시킵니다.\n\n## 오류의 단일 소스\n\n제가 여러 번 설명한 대로, ChatGPT와 같은 LLM은 입력 시퀀스를 가져와 시퀀스 내의 단어들이 서로 대화하도록 만들며, 우리가 주의라고 설명하는 혼합 작업을 사용합니다.\n\n이렇게 하면 그들은 주위 맥락 속에서 각 단어의 의미를 업데이트할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 우리가 네트워크 안으로 더 깊이 들어가면, 모델은 입력 데이터의 더 높은 수준의 표현을 구축합니다. 예를 들어, '폭탄'이라는 단어를 고려해보면, 모델은 먼저 이것이 무기임을 인지하고, 더 깊이 들어갈수록 '위험한'으로 분류할 것입니다.\n\n물론, 조정의 전체 목적은 모델이 이러한 위험한 단어를 포착하고 사용자 요청을 수용해서는 안 된다는 것을 깨닫게 하는 것입니다.\n\n보통 모델은 그렇지 않지만, 문제가 있습니다: 위험한 요청에 대한 저항력이 굉장히 약한데요... 왜냐하면 그것은 오류의 단일 원천을 가지고 있기 때문입니다.\n\n## 수술적인 절단이 충분합니다\n\n<div class=\"content-ad\"></div>\n\n정렬의 주요 포인트는 입력 시퀀스에 포함된 주요 위험한 단어가 무엇인지에 관계없이, 모델이 답변을 거부하기 위해 식별해야 하는 단어가 모두 결국 동일한 거부 기능으로 발전한다는 것입니다.  \n\n다시 말해, 모델이 답변을 거부하기 위해 '거부해야 할' 기능이 나타나야 한다는 것... 그렇지 않으면 거부하지 않습니다.  \n\n하지만 그게 무슨 말이냐구요?  \n\nAnthropic의 중요성을 강조한 내 기사를 상기해보면, 우리는 이러한 모델을 기능 지도로 '해부'할 수 있게 된 것에서 최종적으로 이러한 모델을 '해부'하는 능력을 갖게 된 것을 설명했습니다. 모델의 지식에 대한 주제 요약을 포함하며, 'Golden Gate Bridge'나 '에이브러햄 링컨'과 같은 다른 요소로 분해되는 과정을 밟고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그런 다음 네트워크 내의 뉴런이 활성화되는 방식에 따라 모델은 한 주제 또는 다른 주제를 유발합니다.\n\n얼마나 복잡한 기능이 나타나는 것일까요?\n\n아래에서 보다시피, 모델은 개별 토큰 임베딩으로 시작하지만, Nanda 등의 연구에 따르면 네트워크를 더 깊게 파고들수록 단어들이 정보를 공유하면서 더 복잡한 '다중 토큰' 임베딩을 개발한다는 것을 알 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-19-FrontierAIIsNotSafeHeresWhy_0.png)\n\n모델이 요청이 위험하다는 것을 깨닫고 거부해야 한다는 것을 알 수 있습니다. 그러나 이를 깨닫자, 연구자들은 자문했습니다... 거부 기능을 제거하면 어떨까요?\n\n## 0에서 100으로 그리고 다시 0으로\n\nAnthropic의 기사에서 논의된 대로, 우리는 특징을 낮추거나 제한하여 모델이 그 지식을 끌어내지 못하게 할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, Golden Gate Bridge 기능이 잘 조절되면, 모델은 그 자체로 기념물이 \"되었습니다.\"\n\n![Image 1](/assets/img/2024-06-19-FrontierAIIsNotSafeHeresWhy_1.png)\n\n그러나 연구원들이 모델의 단일 안전 기능을 완전히 없애기도 할 수 있고, 그렇게 되면 재앙이 발생합니다.\n\n![Image 2](/assets/img/2024-06-19-FrontierAIIsNotSafeHeresWhy_2.png)\n\n<div class=\"content-ad\"></div>\n\n위에서 시각적으로 보여진 것처럼, 거부 기능을 활성화시킬 수없는 상태에서 그 모델은 완전히 종복되어서 모든 요청에 응답했어요, 어떤 것이든 얼마나 해로운 요청이든 말이에요.\n\n하지만 그들은 어떻게 그 기능을 제거했을까요?\n\n## 프로젝션 제거\n\n이를 위해, 그들은 그 기능을 생성한 뉴런 활성화 조합을 식별했어요. \"Anthropic\" 기사에서 논의된 것처럼, 이러한 기능들은 모델이 세계를 이해하는 특성 공간에서 방향을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n입력 시퀀스의 단어(및 그 조합)가 함께하여 여러 기능의 합이되며 이러한 결합은 우리에게 임베딩(개념)을 제공합니다.\n\n예를 들어, 시퀀스 \"마이클 조던이 게임을 했다...\"가 주어진 경우, 모델이 '마이클 조던' 멀티 토큰 임베딩을 구축하는 동안 모델은 '농구', '전설적인', '부유한' 등의 여러 새로운 기능을 추가하기 위해 세계적인 지식을 활용합니다.\n\n다른 예로, 이를 더 잘 시각화하기 위해 유명한 '왕-남자+여자=여왕'를 사용할 수 있습니다.\n\n모든 개념은 임베딩으로 표현될 수 있기 때문에 실생활에서 다른 개념을 결합하는 아이디어를 수학적인 과정으로 변환하여 '남자' 벡터 임베딩을 '왕'에서 뺀 다음 '여자'를 더하여 '여왕'을 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Embedding](/assets/img/2024-06-19-FrontierAIIsNotSafeHeresWhy_3.png)\n\n알게 된 사항을 다시 말하자면, Michael Jordan 예시로 전환하면 'Michael Jordan' 임베딩을 가져와 '농구'의 벡터 임베딩에 추가할 수 있습니다. 이제 이 임베딩은 할리우드 배우나 일반 시민과 같은 임의의 Michael Jordan을 나타내지 않고 분명히 전설적인 농구 선수를 나타냅니다.\n\n요지는 벡터에 대해 이야기하는 것이며, 다른 개념을 추가하여 새로운, 더 복잡한 표현을 생성할 수 있는 것과 마찬가지로 벡터 형태의 다른 벡터로 이루어진 새로운 표현을 만들 수 있고, 이를 세계 지식 특징의 결합으로도 나타낼 수 있습니다.\n\n간단히 말하면, 앞서 왕실 예시를 들었듯이 '여왕' 벡터를 가져와 '여자'와 같은 다른 요소들로 분해한 다음 해당 기능을 '지우기' 위해 그 기능으로의 프로젝션을 계산하고 빼면, 사실상 해당 개념을 제거하고 모델이 그 개념을 나타내는 능력을 상실하며 '왕'이 됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n그냥 그렇게하면 수백만 달러짜리 모델들이 쉽게 사라진다... 너무 쉽게. 그러나 걱정되는 것은 우리가 해야 하는 것보다 빨리 움직이고 있다는 것입니다.\n\n# 해야 할 것보다 더 빨리 움직이고 있습니다\n\n대형 기술 기업들은 현재 LLM(언어 모델 대형 기술)을 '매우 위험하다'고 묘사하여 미국 정부를 규제적으로 포획하려고 하고 있습니다. 즉, 그들은 사회에 불을 지른다고 생각하게끔 유인하며, 이 '빛의 인간들'만이 이 모델을 통제하고 세계를 그 '나쁜' 본질로부터 보호해야 한다고 사람들에게 생각시키려고 합니다.\n\n이는 모델이 제공할 수 있는 가장 위험한 반응이 열린 구글 검색에서 세 번 클릭 만에 얻을 수 있다는 것이라는 말이 전혀 아닙니다.\n\n<div class=\"content-ad\"></div>\n\n위험한 모델을 만들기 전에 반드시 이러한 명확한 안전 문제를 해결해야 한다는 것이 제 고민입니다.\n\n그리고 OpenAI와 같은 기업들이 그들의 조정 책임자로부터 ‘안전 우선’이 아닌 취급을 받는 것을 보면, 우리가 가장 강력한 모델들을 모두 사유하고 있는 현재, 현재의 속도와 행동을 고려했을 때, 우리가 그들을 통제하는 방법을 아는 것보다 훨씬 빨리 너무 강력한 모델을 만들 것이 거의 확실합니다.\n\n왜 그런지 궁금하신가요?\n\n음, 안전은 돈을 벌지 않습니다.","ogImage":{"url":"/assets/img/2024-06-19-FrontierAIIsNotSafeHeresWhy_0.png"},"coverImage":"/assets/img/2024-06-19-FrontierAIIsNotSafeHeresWhy_0.png","tag":["Tech"],"readingTime":6},{"title":"AI 래퍼 기회의 오해와 이해","description":"","date":"2024-06-19 06:51","slug":"2024-06-19-ThemisunderstoodAIWrapperOpportunity","content":"\n\n\n![AI Wrapper Image](/assets/img/2024-06-19-ThemisunderstoodAIWrapperOpportunity_0.png)\n\n\"AI Wrapper\"이란 용어가 익숙하지 않은 분들을 위해, 이 용어는 지난 몇 년 동안 기술 생태계에서 상당히 인기를 끌었습니다. 기존 AI 모델이나 API를 활용하여 구체적인 기능을 제공하는 경량 애플리케이션이나 서비스를 가리키는 비격식적인 용어입니다. 일반적으로 이러한 애플리케이션을 만드는 데 들어가는 노력이나 복잡성이 상대적으로 적습니다.\n\n대표적인 AI Wrapper의 예는 사용자가 PDF와 \"대화\"할 수 있는 앱들입니다. 이 유형의 AI 애플리케이션은 사용자가 연구 논문과 같은 PDF 문서를 업로드하고 AI 모델과 상호작용하여 특정 내용에 대한 빠른 분석 및 답변을 얻을 수 있게 합니다. ChatGPT 초기에는 문서를 프롬프트의 일부로 업로드하거나 사용자 정의 GPT를 생성하는 것이 불가능했기 때문에 이러한 앱들이 매우 빠르게 인기를 얻었습니다. 하나 또는 두 명의 개발자가 몇 일 만에 이러한 앱을 만들 수 있었습니다.\n\n모든 인기 있는 영역에서 일어나는 현상처럼(예: 암호화폐), 빠른 이익을 얻으려는 많은 기업가들이 기회를 즉각적으로 잡아, 장기적인 방어 능력과 비전이 부족한 AI 제품으로 시장을 침략하면서, 오픈AI와 같은 주요 플레이어들에게 하루능 린 보급 초기 보여주자 취약 해졌습니다. 기회 주의적인 창업가들이 빠르게 다음 핫한 분야로 넘어갈 때 \"AI Wrappers\" 또는 올바른 용어로 말하면, 응용 프로그램 계층에서 작성되는 스타트업들은 AI 공간에서 2급 시민이 되었습니다.\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-ThemisunderstoodAIWrapperOpportunity_1.png\" />\n\n# AI Wrapper Fallacy\n\n안녕하세요! YC 파트너들이 최근 자신들의 Lightcone Podcast 에피소드에서 AI Wrapper에 대한 흥미로운 생각을 나누었어요. 그들의 주장은 스타트업을 OpenAI의 API 위에 구축한 것을 AI Wrapper라고 부르는 것은 SaaS 회사를 SQL 데이터베이스 위에 구축한 것을 MySQL Wrapper라고 부르는 것과 동등하다는 것이라고 해요.\n\n저는 이것에 대한 더 나은 비유는 Aircall이나 Talkdesk와 같은 SaaS 회사들을 Twilio Wrapper로 보려는 것을 거부하는 것입니다. 이 회사들은 핵심 역량인 전화 및 통신을 Twilio에 아웃소싱하여 몇 십억 달러 규모의 비즈니스를 구축했어요. 왜냐하면 이 비즈니스가 2010년대 초에 탄생할 때 VoIP가 이미 고도로 상용화되었기 때문이에요. 수백만 달러를 투자하여 VoIP 인프라를 다시 구축하면 그들의 비즈니스에 가치나 차별화를 더할 수 없기 때문이죠.\n\n<div class=\"content-ad\"></div>\n\n대신, 그들은 WebRTC, IVR, 통화 녹음, 대기열 등과 같은 주요 VoIP 기능을 오프로드하기 위해 Twilio와 같은 새 플랫폼을 활용했고, 워크플로우 및 애플리케이션 레이어에 가치를 창출하는 전략에 집중했습니다. 이로써 Aircall과 Talkdesk는 독특한 장점을 가졌습니다: 인프라 대신 제품 혁신에 민첩하게 대응할 수 있는 능력을 부여받았으며, 이는 최종 사용자에 더 큰 가치를 제공하기 위해 연구 및 개발 투자에 집중할 수 있도록 했습니다:\n\n- CRM, 티켓팅 시스템 등과 같은 비즈니스 애플리케이션을 신속하고 쉽게, 비용 효율적으로 통합할 수 있도록 하는 사전 구축 통합 개발.\n- 깊은 분석과 실시간 보고와 같은 주요 이해관계자를 위한 도구 제공.\n- 불편한 데스크 전화가 필요 없이 어디서나 작업할 수 있도록 하는 데스크톱 및 모바일 애플리케이션을 통해 직원들을 자유롭게 만듦.\n\n이것이 실제로 수년간 기술 생태계 대부분이 작동해온 방식이며, 일반적인 비즈니스에 해당됩니다. 수직 통합하여 모든 것을 수행하는 것은 정말 어렵습니다. 대신 대부분의 비즈니스는 가치 사슬 전반에 걸쳐 파트너에 의존하여 제품과 서비스를 고객에게 제공합니다. 나는 AI에서도 동일한 논리가 작용할 것이라고 생각하며, 이 동적을 이해하는 스타트업은 이 대규모 플랫폼 변화가 가져오는 독특한 기회를 활용할 수 있을 것입니다.\n\n# AI 생태계의 다른 레이어 이해하기\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-ThemisunderstoodAIWrapperOpportunity_2.png\" />\n\n저의 30,000 피트 뷰는 현재 AI 생태계와 기술 스택이 세 가지 주요 레이어로 구성된다는 것입니다(더 많은 레이어로 분할할 수도 있지만, 간소화를 위해 이 세 개를 사용할 것입니다):\n\n- 제베개 레이어는 데이터센터, GPU, OS 등 핵심 인프라를 소유한 조선조기 회사들에 의해 주도되는 레이어입니다. 마이크로소프트, 아마존, NVIDIA, 구글 등과 같은 플레이어들이 이에 속합니다. 이 시장에서 경쟁할 수 있는 스타트업은 매우 제한적입니다 (Groq는 흥미로운 사례입니다). 선제 비용이 너무 높아서 진입장벽이 매우 높아집니다.\n- 모델 레이어는 오픈AI, Anthropic, Mistral과 같은 대규모 업체와 메타, 구글과 같은 글로벌 기업이 많은 기능을 갖춘 기초적인 AI 모델을 더 나은 것으로 만들기 위해 치열하게 경쟁하고 있는 레이어입니다. 한 회사가 다른 회사들보다 훨씬 우위를 차지하는 모델을 만들어낼 것인지, 아니면 이러한 모델이 매우 유사하며 표준화되어 버릴 것인지는 불분명합니다. 지금까지 오픈AI가 약간 앞서 있습니다. 이 범주에서 경쟁하기 위해서는 많은 돈이 필요하며, 이 레이어에서 적대적인 업체들이 많이 등장할 가능성은 적습니다. 특정 또는 초지역적 AI 모델에 초점을 맞춘 독특한 플레이어들은 기회가 있습니다.\n- 어플리케이션 레이어는 AI의 능력을 최종 사용자에게 실질적으로 보여주는 곳입니다. 대표적인 예로는 AI 경주를 시작시킨 가장 성공적인 제품인 ChatGPT가 있습니다. 이 어플리케이션을 통해 최종 사용자는 핵심 인프라 상에서 실행되는 기초 모델(GPT4o)과 상호작용할 수 있습니다 (예: 마이크로소프트 Azure, Nvidia H100s 등).\n\n저는 1번과 2번 레이어가 대부분 대기업들에 의해 주도될 것으로 예상합니다. 이들은 서로 경쟁하기 위해 이 두 레이어에 대략적으로 수조 달러를 투자할 것이며, 그 결과로 새로운 기초 모델, API 등을 활용하여 응용 레이어에서 (B2B 및 B2C 모두) 특정 범주를 혁신적으로 뒤바꿀 수 있는 스타트업들에게 혁명적인 파도를 일으킬 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 어플리케이션 레이어에서 스타트업에 대한 거대한 기회\n\nChatGPT의 론칭은 매우 흥미로웠어요. 제품적인 측면에서 보면, 한 가지 핵심 기능만 있었는데도 매우 탁월했어요: 인간과 AI 시스템 간에 원활한 채팅을 가능하게 해주는 것. Siri와 같은 모던 어시스턴트가 제공하는 음성 상호작용, 작업 실행(예: 알람 설정), 인터넷 연결(날씨 확인)과 같은 여러 기능은 없었어요. 그저 순수한 텍스트 채팅 앱이었죠. 이러한 기능들이 성공에 필요하지 않았던 이유는 무엇일까요? 그 이유는 완전히 새로운 범주에서 훌륭한 핵심 제품을 선보였기 때문이에요. 경쟁사나 기준이 없었으니까요 — 이것은 광활한 푸른 바다였습니다.\n\n![이미지](/assets/img/2024-06-19-ThemisunderstoodAIWrapperOpportunity_3.png)\n\nAI 채택은 빠르게 증가하고 더욱 가속화될 것입니다. Apple Intelligence의 도입, AI가 Android, Google Workspace, Microsoft Office 및 기타 플랫폼에 깊게 통합되면서 수백만 명의 사람들이 매일 AI 사용자가 될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이 두 가지를 함께 결합하면 번개처럼 성장하는 시장에서 파란 바다 기회를 얻을 수 있습니다. 응용 프로그램 레이어에서 건설 중인 새로운 스타트업은 레거시 기술을 사용하여 여러 해 동안 건설해온 기업들을 앞지르기 위해 레이어 1과 2의 새로운 혁신을 활용할 수 있습니다. 게다가 기존 업체들은 기존 제품 및 플랫폼 유지, 활성 고객 기반 및 잠재적인 카니발리제이션을 다뤄야 합니다. 이로써 그들은 보다 느리고 순수하며 민첩한 스타트업에 취약해지며, 그들은 그 짐을 짊어져야 할 필요가 없습니다. 선장 입력에 즉각 반응하지 않을 수 있는 화물선과 매우 가볍게 움직일 수 있는 스피드 보트를 생각해보세요.\n\n처음에는 명백해 보이지 않을지 모르지만, 나에게는 숨겨진 기회가 있다고 생각합니다. 이 새로운 유형의 소프트웨어는 완전히 새로운 패러다임을 소개합니다. 전통적인 결정론적 규칙 기반 소프트웨어에서 AI 기반 제품으로 전환함으로써 우리가 소프트웨어에 접근하는 방식에 대해 근본적인 변화가 필요합니다. 사용자 및 공급업체로서 소프트웨어에 대한 접근 방식이 필요합니다. 따라서 ChatGPT와 같이 처음에 단순한 기능처럼 보일 수 있는 흥미로운 제품은 실제로는 AI 시대에 성공하기 위해 기초부터 다시 구축해야 하는 무언가의 기반이 될 수 있습니다.\n\n통신 분야에 진입하는 새로운 스타트업을 고려해보세요. 그들은 Aircall이나 Talkdesk와 경쟁할 것입니다. 그들은 최종 사용자를 위해 IVR(Interactive Voice Response) 메뉴 및 소프트폰과 같은 레거시 인프라를 구축하여 시작할까요? 아니면 각 언어로 수신 통화를 처리하고, 예약 설정과 같은 복잡한 워크플로를 실행하며, 필요할 때 인간에게 통화를 전달할 수 있는 특수 AI 에이전트를 만드는 데 집중할까요? 새로운 스타트업은 아마 후자에 집중할 것으로 예상되며, AI 응용 프로그램 레이어를 기반으로 한 튼튼한 플랫폼을 제공하여 기업이 이러한 AI 에이전트를 안전하게 프로덕션 환경에 배포할 수 있습니다. 이러한 변화는 다음과 같은 새로운 접근 방식과 플랫폼을 지원해야 합니다:\n\n- AI 에이전트 디자인: 명령 및 목표 사용 대신 사전 구성된 전화 메뉴.\n- 도구 및 작업 흐름: 통합, 의도 기반 라우팅 및 비즈니스 워크플로를 정확하게 실행하기 위한 보조 에이전트 추가.\n- 품질 보증: AI 에이전트의 테스트에는 전통적인 수동 또는 자동화된 테스트 전략과의 성능 대비 및 보안을 측정할 수 있는 강력한 시뮬레이션 도구가 필요합니다.\n- 프로덕션에 배포: AI 에이전트는 지속적인 개선을 위해 모니터링 및 감사되어야 하며, 고객들은 통화 녹음, 전사, 실시간 경보 및 대화 분석이 필요합니다.\n- 업그레이드: GPT-3.5와 같은 기초 모델을 GPT-4로 변경하는 것은 에이전트 출력에 큰 영향을 줄 수 있습니다. 이러한 변경 사항을 테스트하고 배포할 수 있는 적절한 플랫폼이 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n세로 특화 통합을 추가하여 고객이 글로벌로 전화번호를 몇 초 안에 구매할 수 있도록 하고, SIP 통합을 통해 기존 전화 시스템에 연결할 수 있도록 합니다. 이 스타트업은 OpenAI, Anthropic 및 주요 플레이어들의 새로운 롤아웃으로부터 보호해주는 중요한 장벽을 구축했습니다. 사실, 혁신적인 창출과 론칭이 많은 기대를 부르고 있습니다. OpenAI가 그들의 회사를 강화할 것으로 예상됩니다. 새로운 음성 기능인 GPT-4o의 좋은 예시가 있습니다.\n\n![이미지](/assets/img/2024-06-19-ThemisunderstoodAIWrapperOpportunity_4.png)\n\nSalesforce 생태계에 관한 기사를 기억하는데, Salesforce가 벌어들인 $1 당 그들의 생태계는 $6를 벌었다고 보여줍니다. 내 직감은 AI 분야에서도 비슷한 일이 일어날 것이라고 생각합니다. 응용 프로그램 계층이 막대한 지출 및 가치를 포착하고 새로운 시대를 위한 기업들이 1계층 및 2계층 이노베이션 위에 구축되는 공간을 창출할 것입니다.\n\n스타트업을 위한 올바른 전략을 선택하는 것이 중요합니다. Sam Altman이 아래 2분 동영상에서 이를 매우 명확하게 설명하고 있습니다.","ogImage":{"url":"/assets/img/2024-06-19-ThemisunderstoodAIWrapperOpportunity_0.png"},"coverImage":"/assets/img/2024-06-19-ThemisunderstoodAIWrapperOpportunity_0.png","tag":["Tech"],"readingTime":7},{"title":"이미지-텍스트 다중모달 기반 모델은 어떻게 작동하나요","description":"","date":"2024-06-19 06:47","slug":"2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork","content":"\n\n\n![How Does an Image-Text Multimodal Foundation Model work](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_0.png)\n\n요즘에는 다중 모드 기반 모델이 급증하고 있습니다. 이 모델들은 텍스트, 이미지, 비디오, 오디오 등 다양한 종류의 데이터를 이해하며, 둘 이상의 모드로부터의 데이터 지식이 필요한 작업을 수행할 수 있습니다. 이러한 모델들이 어떻게 작동하는지 궁금한 적이 있나요?\n\n다중 모드 모델을 이해하는 핵심은 서로 다른 데이터 모드 간의 정렬 방식을 이해하는 것입니다.\n\n본 문서에서는 CoCa라는 간단한 이미지-텍스트 이중 모드 모델을 사용하여 다중 모드 모델의 내부 작업 방식을 설명합니다. 저는 CoCa를 좋아합니다. CoCa는 직관적인 디자인을 가지고 있으며, 다른 다중 모드 모델에서 아이디어를 차용했습니다.\n\n\n<div class=\"content-ad\"></div>\n\n# 왜 이미지-텍스트 모델인가?\n\n왜 우리는 이미지-텍스트 이중 모달 모델을 원하는 걸까요? 이 질문에 대한 답변을 하기 전에, 먼저 단일 모달 모델이 무엇을 할 수 있고 무엇을 할 수 없는지 생각해 봅시다.\n\n이미지만을 다루는 모델\n\n예를 들어 ResNet과 같은 단일 이미지 모달 모델은 오직 이미지에서 정보를 배우고, 이미지 분류와 같은 기본적인 이미지 이해 작업을 수행할 수 있습니다. 이는 이미지를 미리 정의된 클래스 집합 중 하나로 분류하는 작업을 말합니다. 예를 들어, 고양이 클래스 또는 개 클래스로 이미지를 분류합니다.\n\n<div class=\"content-ad\"></div>\n\n단일 텍스트 모달리티 모델은 트랜스포머와 같이 텍스트만을 통해 정보를 학습하며, 이전 단어들을 기반으로 다음 단어를 예측하는 작업과 같은 작업을 수행할 수 있어요.\n\n## 단일 모달리티 모델이 작동하지 않는 사용 사례\n\n위 두 가지 단일 모달리티 모델은 다음과 같은 작업을 수행할 수 없어요. 두 마리 개가 달리는 그림을 달리는 예시로 사용해볼게요.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_1.png)\n\n- 텍스트 기반 이미지 검색입니다. 예를 들어, \"개가 달리는 이미지\"를 찾습니다. 위의 이미지 전용 분류 모델은 위의 이미지를 개 클래스로 분류할 수 있습니다. 그러나 검색 쿼리를 입력할 수 없으며 이미지만 입력으로 허용하고 미리 정의된 클래스 중 하나를 예측합니다.\n- 깊은 이미지 유사성 검색입니다. 예를 들어, 위의 이미지가 주어지면 유사한 이미지를 찾습니다. 위의 이미지 전용 분류 모델이 할 수 있는 최선은 동일한 개 클래스의 이미지를 제공하는 것입니다. 달리 달리는 개 이미지를 특별히 찾지는 않습니다.\n- 이미지 캡션 생성입니다. 예를 들어, 위의 이미지가 주어지면 \"모래 위를 나란히 달리는 두 마리 개\"와 같은 설명 문장 또는 캡션을 생성합니다. 이미지 전용 또는 텍스트 전용 모델 모두 이 작업을 수행할 수 없습니다: 이미지 전용 모델은 \"개\" 클래스를 생성하고 더 이상의 세부 정보를 생성할 수 없습니다. 텍스트 전용 다음 단어 예측 모델은 이미지를 입력으로 수용하지 않습니다.\n- 이미지 질의 응답입니다. 이미지와 질문이 주어졌을 때 그 질문에 대한 답변을 생성합니다. 예를 들어, 위의 이미지와 \"왼쪽 개 옆을 누가 뛰고 있는가\"라는 질문이 주어진 경우, 모델이 \"다른 개\"를 생성하도록 원합니다. 이미지 전용 또는 텍스트 전용 모델은 이 경우에 작동할 수 없음이 분명하며 둘 다 (이미지, 질문) 쌍을 입력으로 수용하지 않습니다.\n\n이러한 사용 사례를 지원하기 위해 모델은 이미지와 텍스트에 대해 알고 있어야 하며 이 두 모드를 조화롭게 이해해야 합니다. 다시 말해서 모델은 이미지와 해당 설명이 \"모래 위를 나란히 뛰는 두 마리 개\"와 같은 기본 개념임을 알아야 합니다. 그리고 모델은 두 수준에서 이 조합을 이해해야 합니다:\n\n- 전역 수준에서, 개념이 \"모래 위를 나란히 뛰는 두 마리 개\"임을 의미합니다.\n- 지역 수준에서, 모델은 이미지 일부가 한 마리 개에 대한 것이고 다른 부분은 다른 개에 대한 것이며 그들이 달리고 있다는 사실을 이해해야 합니다. 텍스트도 마찬가지로 다수의 개에 관해 이야기하며 달리는 것에 대해 이야기합니다.\n\n<div class=\"content-ad\"></div>\n\n# 전역 이미지 및 텍스트 정보 정렬 방법\n\n다음 그림은 이미지와 텍스트에 대한 전역 및 지역 수준 정보를 표현하는 방법과 대조적인 손실을 사용하여 전역 수준에서 이미지와 텍스트 간의 정렬을 설정하는 방법을 보여줍니다. 곧 무엇이 정렬을 의미하는지 명확해질 것입니다.\n\n![이미지와 텍스트의 정렬 방법](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_2.png)\n\n위 그림은 훈련 중에 모델이 입력 이미지-텍스트 쌍 (이미지ᵢ, 텍스트ᵢ)를 받았을 때의 상황을 보여줍니다. \"i\"아래 첨자가 있는 이유는 (이미지ᵢ, 텍스트ᵢ)가 미니 배치 내의 쌍 세트 중 하나임을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n단계 1. 이미지 입력 이미지ᵢ는 해상도가 288×288이고 RGB 채널이 세 개인 고정 크기의 컬러 이미지입니다. ViT 인코더와 attentional pooling 구성 요소를 거쳐, 이 288×288×3 이미지는 형태가 257×512인 텐서로 변환됩니다. 이 변환에 대한 자세한 설명은 나중에 설명할 예정이니 일단은 이미지가 256개의 작은 패치로 나뉘고, 리스트 끝에 새로운 클래스 패치를 추가하여 이러한 패치 간 정보를 섞는다는 것만 이해하면 됩니다. 이 모델은 257×512 출력 텐서를 두 부분으로 분할합니다.\n\n- 256개의 행으로 구성된 첫 번째 부분은 img_tokensᵢ라고 하며, 256×512 모양을 가지며 입력 이미지로부터 인코딩된 256개 패치를 나타냅니다. 이는 지역 수준 이미지 정보를 나타냅니다.\n- 1개의 행으로 이루어진 마지막 부분은 img_clsᵢ이라고 하며, 1×512 모양을 가지며, 추가된 클래스 패치에서 나온 것으로 전역 수준 이미지 정보를 나타냅니다. 몇 개의 패치가 있든, 이 고정된 크기의 img_clsᵢ 벡터의 중요성을 깨달아 주세요. — 이미지 전체를 요약하는데 있어 이 벡터가 중요한 역할을 합니다. 물론 저희 경우에는 패치의 개수가 항상 256개입니다. 하지만 입력 이미지가 다른 수의 패치로 분할되었을 때에도, 이 고정된 크기의 img_clsᵢ 텐서는 이미지 전체를 요약합니다.\n\n단계 2. 텍스트 입력 텍스트ᵢ는 최대 397단어로 패딩된 문장입니다. 여기서의 397은 저희 모델이 지원하는 텍스트의 최대 길이를 나타내는 임의의 숫자입니다. 397보다 짧은 텍스트의 경우에는 원래의 텍스트 뒤에 PAD로 표시된 패딩 단어가 추가됩니다. 문장에 START, END, CLS라는 3개의 특수 단어가 추가됩니다. 이 특수 단어들은 어휘에 있는 다른 단어들과 마찬가지로 처리됩니다.\n\n예를 들어, 특수 단어가 추가된 후 \"w₁ w₂ w₃\"라는 문장은 \"START w₁ w₂ w₃ PAD PAD … END CLS\"가 됩니다. 이로써 400단어로 된 텍스트 입력이 생성됩니다:\n\n<div class=\"content-ad\"></div>\n\n- START 단어는 텍스트의 시작을 나타냅니다.\n- END 단어는 텍스트의 끝을 나타냅니다.\n- CLS 단어는 글로벌 텍스트 정보에 대한 텍스트 클래스를 나타냅니다.\n\n언어 모델 인코더는 이 400단어로 이루어진 텍스트 입력을 400×512 형태의 행렬로 변환합니다. 이 행렬을 attended_textᵢ라고 부를 것입니다. 이 언어 모델 인코더는 입력된 각 단어에 대한 임베딩을 출력합니다. 따라서 이 attended_textᵢ의 각 행은 해당하는 순서의 단어의 임베딩을 나타냅니다.\n\n400×512 attended_textᵢ 행렬은 두 부분으로 나뉩니다:\n\n- 첫 399행은 text_tokenᵢ로, 399×512 형태로 구성되며 실제 단어들에 대한 로컬 레벨 텍스트 정보를 나타냅니다.\n- 마지막 행은 text_clsᵢ로, 1×512 형태로 구성되며 글로벌 레벨 텍스트 정보를 나타냅니다. 다시 한 번 강조하면 이 고정 크기의 text_clsᵢ 텐서가 얼마나 강력한지 이해하는 것이 중요합니다: 원래 입력 문장이 얼마나 길든 상관없이 256개의 길이를 가진 텐서입니다! text_clsᵢ 벡터의 크기가 글로벌 이미지 정보 벡터 img_clsᵢ의 크기와 동일하기 때문에, 이미지와 문장 사이의 유사성을 계산하는 방법을 이미 알 수 있습니다. 그 길이가 같은 벡터들 사이의 점곱입니다. 또한, OpanAI 텍스트 임베딩 API가 비슷한 작업을 수행한다고 상상할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n모델은 미리 훈련된 언어 모델 변환기를 사용하지 않으며, 이 변환기의 매개변수를 최적화합니다.\n\n단계 3. 대조 손실은 전체 이미지 정보 텐서 img_clsᵢ와 전체 텍스트 정보 텐서 text_clsᵢ 간의 정렬을 설정합니다. 두 텐서 모두 형태가 1×512인 벡터입니다. 이들 간의 정렬은 이 두 벡터 간의 내적으로 정의됩니다. 내적은 벡터 유사성을 측정합니다. 두 벡터는 내적 측면에서 서로 더 유사하면 더 정렬되어 있습니다.\n\n내적은 입력 (이미지ᵢ, 텍스트ᵢ)에 대한 img_clsᵢ와 text_clsᵢ의 유사성을 측정합니다. 어떤 텐서들이 유사해야 하는지 설정하는 대조 손실은 또한 어떤 텐서들이 유사하지 않아야 하는지도 설정해야 합니다:\n\n- 이미지ᵢ에 대한 전체 수준 이미지 정보 벡터 img_clsᵢ는 다른 모든 (이미지, 텍스트) 쌍의 텍스트에서 가져온 전역 텍스트 정보 텐서와 유사해서는 안 됩니다.\n- 텍스트ᵢ에 대한 전체 수준 텍스트 정보 text_clsᵢ 벡터는 다른 모든 (이미지, 텍스트) 쌍의 이미지에서 가져온 전역 이미지 정보 텐서와 유사해서는 안 됩니다.\n\n<div class=\"content-ad\"></div>\n\n위의 비유사점을 전체 훈련 데이터 세트에서 모든 (이미지, 텍스트) 쌍에 대해 계산하는 것은 분명히 매우 비싸다. 대안으로, 훈련 중에 대조 손실은 크기 N의 미니 배치 내에서 (이미지, 텍스트) 쌍에 대해서만 계산됩니다. 이 미니 배치에는 (이미지₁, 텍스트₁), (이미지₂, 텍스트₂), ..., (이미지_N, 텍스트_N)의 N개의 쌍이 포함됩니다.\n\n전체 대조 손실은 다음과 같습니다:\n\n![equation](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_3.png)\n\n위의 수식에서:\n\n<div class=\"content-ad\"></div>\n\n- img_clsᵢ은 (imageᵢ, textᵢ) 쌍의 이미지에서 가져온 전역 수준 이미지 정보 텐서입니다.\n- text_clsᵢ는 (imageᵢ, textᵢ) 쌍의 텍스트에서 가져온 전역 수준 텍스트 정보 텐서입니다.\n- \"·\"은 벡터 내적 연산을 의미합니다.\n- σ는 하이퍼파라미터로, 보통 온도라고 불립니다. 이는 유사성의 차이가 얼마나 민감한지를 조절합니다. 만약 σ가 무한대에 가깝다면, then log 함수 내부의 분수는 img_clsᵢ, text_clsᵢ 및 text_clsⱼ 벡터의 값이 무엇이든지 관계없이 항상 1/N으로 평가됩니다. 따라서 이 경우 손실은 해당 벡터 유사성에 전혀 민감하지 않습니다. σ가 작은 경우에는 손실이 이 유사성에 더 민감해집니다.\n- 대조 손실에는 이미지 대 텍스트 항과 텍스트 대 이미지 항 두 가지 항이 있습니다.\n- 이미지 대 텍스트 항은 이미지와 텍스트의 전역 정보 텐서 간 유사성이 (imageᵢ, textᵢ) 쌍의 img_clsᵢ와 모든 다른 쌍에서 가져온 전역 텍스트 정보 텐서인 text_clsⱼ의 모든 유사성의 합에 비해 더 큰지를 요구합니다. 여기서 j는 미니 배치에서 쌍을 선택합니다.\n- 이미지 대 텍스트 항을 최대화하려고 합니다. 왜냐하면 동일한 쌍 벡터 간의 유사성을 크게, 다른 쌍 벡터 간의 유사성을 작게 하고 싶기 때문입니다. 동등하게, 이 항의 부정값을 최소화할 수 있습니다. 이게 바로 위의 손실을 정의하는 방식입니다.\n- 텍스트 대 이미지 항은 이미지 대 텍스트 항과 동일한 구조를 가지고 있지만, 텍스트에서 이미지로 방향이 다릅니다.\n- 로그 함수 내부에서 이미지 대 텍스트 항과 텍스트 대 이미지 항은 동일한 분자를 가지지만 다른 분모를 가지고 있습니다. 이것이 하나의 항 대신 두 개의 항이 필요한 이유입니다.\n\n# 이러한 전역 수준 정렬 모델은 어떤 작업을 수행할 수 있나요?\n\n위의 대조 손실로 훈련된 이미지-텍스트 모델은 다음 작업을 수행할 수 있습니다.\n\n## 텍스트 기반 이미지 검색\n\n<div class=\"content-ad\"></div>\n\n텍스트 검색 쿼리인 \"two dogs running side by side\"와 같이 사용되는 언어 모델 변환기를 사용하여 글로벌 수준의 텍스트 정보 텐서를 생성한 후, 이 텐서를 검색 키로 사용하여 글로벌 수준의 이미지 정보 텐서를 저장하는 데이터베이스에서 해당 키로 이미지를 검색하여 유사한 이미지를 검색합니다. 순위 결정 기준은 내적 유사도입니다.\n\n## 딥 이미지 유사성 검색\n\n위와 같은 두 마리 강아지가 있는 이미지와 같은 이미지 쿼리가 주어지면 ViT+attentional pooling 컴포넌트를 사용하여 글로벌 수준의 이미지 정보 텐서를 생성한 후, 이 텐서를 동일한 이미지 데이터베이스에서 검색 키로 사용하여 유사한 이미지를 검색합니다.\n\n## 이미지 분류\n\n<div class=\"content-ad\"></div>\n\n이미지 분류 작업에는 \"개\" 또는 \"고양이\" 또는 \"테니스 라켓\"과 같은 각 클래스가 단문인 사전 정의된 클래스 집합이 함께 제공됩니다.\n\n입력 이미지를 분류하려면 먼저 ViT+어텐션 풀링 구성 요소를 사용하여 입력 이미지에 대한 전역 수준 이미지 정보 텐서를 생성합니다.\n\n그런 다음 템플릿을 사용하여 각 클래스에 대한 문장을 생성합니다. 예를 들어 템플릿 \"this is a picture of `class`\"을 사용하면 다음과 같이 생성됩니다:\n\n- 강아지 클래스에 대해 \"이것은 개의 사진입니다\",\n- 고양이 클래스에 대해 \"이것은 고양이의 사진입니다\".\n\n<div class=\"content-ad\"></div>\n\n마지막으로, 각 문장에 대해 언어 모델 변환기를 사용하여 전역 수준의 텍스트 정보 텐서를 생성하십시오. 입력 이미지를 처리하여, 점곱 방식에서 이미지 정보 텐서와 가장 유사한 전역 수준 텍스트 정보 텐서를 갖는 클래스로 이미지를 분류합니다.\n\n# 이미지 캡션 지원 방법\n\n이미지 캡션 작업은 이미지만으로 텍스트 설명을 생성합니다. 현재의 전체적인 이미지-텍스트 맞춤형 모델은 이를 수행할 수 없습니다. 이 기능을 활성화하기 위해서는 지역 수준의 이미지 정보와 텍스트 정보를 맞춰야 합니다.\n\n캡션은 문장입니다. 입력 이미지에 대한 문장을 모델이 어떻게 예측할 수 있을까요? \"START two running dogs END\"와 같은 특수 단어를 문장에 추가하여, 모델은 다음을 훈련할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 이미지와 첫 번째 단어 \"START\"가 주어지면, 다음 단어 \"two\"를 예측합니다. 특별 단어를 추가하는 좋은 점은 항상 특별 \"START\" 단어를 사용할 수 있다는 것입니다. 우리는 이를 첫 번째 예측된 단어로 취급합니다.\n- 그런 다음 이미지와 지금까지 예측된 단어인 \"START two\"가 주어지면, 모델은 다음 단어 \"running\"을 예측할 수 있습니다.\n- 그런 다음 이미지와 \"START two running\" 단어가 주어지면, 모델은 다음 단어로 \"dogs\"를 예측할 수 있습니다.\n- 그런 다음 이미지와 \"START two running dogs\" 단어가 주어지면, 모델은 마지막 단어 \"END\"를 예측할 수 있습니다.\n\n## 어휘 내 단어 확률 예측\n\n머신러닝에서 다음 단어를 예측하는 것은 일반적으로 어휘 내 모든 단어의 확률 배열을 예측하고, 원하는 단어의 해당 배열 항목의 확률을 모든 다른 단어보다 높게 설정하는 방식으로 구현됩니다.\n\n우리의 (이미지ᵢ, 텍스트ᵢ) 쌍에 대한 이미지 캡션 작업에서, 이전에 예측된 모든 단어 및 로컬 수준 이미지 정보 img_tokensᵢ를 고려하여 다음 단어의 확률을 예측할 수 있는 모델이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\nNotationally, we define this word probability predictor as:\n\n![image](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_4.png)\n\nwhere:\n\n- textᵢ is the original text with special words START and END added, such as \"START w₁ w₂ w₃ END\".\n- T is the length, or the number of words, of textᵢ.\n- img_tokensᵢ is the local level image information tensor, which is created by the ViT + attentional pooling component.\n\n<div class=\"content-ad\"></div>\n\n## 위 단어 확률 예측기를 우리의 신경망이 어떻게 구현하는지?\n\n다음 그림은 이전 그림의 연장선인데, 위의 단어 확률 예측기가 어떻게 구현되었는지를 보여줍니다.\n\n![이미지](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_5.png)\n\n이 그림은 이전 그림에서 대조 손실을 계산하는 단계 3을 공간을 절약하기 위해 생략했습니다. 그러나 단계 3이 여전히 대조 손실을 생성하기 위해 존재함을 상기해주시기 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n4단계. 동일한 언어 모델 변환기는 399×512 형태의 로컬 수준 텍스트 정보 텐서인 text_tokensᵢ를 새로운 동일한 형태의 텐서 cross_attended_textᵢ로 변환합니다. 이 변환 과정에서 로컬 수준 이미지 정보 텐서인 img_tokensᵢ가 교차 주의를 통해 결과 텐서에 섞입니다. 이를 통해 로컬 수준 텍스트 정보와 이미지 정보 간의 조정이 이루어집니다. 교차 주의에서는 메인 계산이 점곱이기 때문에 로컬 이미지와 텍스트 해석 간의 이 조정이 더 타당해집니다.\n\n5단계. 399×512 크기의 cross_attended_textᵢ 텐서를 399×20000 word_probability_matrixᵢ로 선형 변환합니다. 20000은 어휘 크기를 나타내는 임의의 숫자입니다. 이 선형 변환층 내에는 학습 가능한 매개변수가 들어 있습니다.\n\nword_probability_matrixᵢ의 각 행의 값, 예를 들어 w₁_prob, w₂_prob은 [0, 1] 범위로 정규화되어 있고, 이들의 합은 1이 되도록 설계되어 있습니다. 각 행을 어휘의 20000 단어에 대한 예측 확률로 해석하기 위한 의도가 담겨 있습니다.\n\n중요한 한 가지 관찰 결과는 word_probability_matrixᵢ에서 첫 번째 행은 시작 단어 START를 주면서 w₁에 대한 단어 확률로 해석됩니다. 두 번째 행은 START와 w₁을 주면서 w₂에 대한 확률을 나타내며, 세 번째 행은 START, w₁ 및 w₂를 주면서 w₃에 대한 확률을 보여줍니다. 입력 텐서와 출력 텐서 간의 이 일회성 조정을 통해 모든 이전 단어를 고려한 다음 단어 예측 메커니즘이 구현됩니다.\n\n<div class=\"content-ad\"></div>\n\n\"단어 확률로 해석된다\"는 무슨 뜻인가요? 이것은 단어 예측 정확도를 측정하는 새로운 손실 함수인 캡션 손실에 관한 맥락에서 의미가 있습니다. 이 캡션 손실은 각 예측된 단어 확률 텐서와 실제 실제 단어 간의 교차 엔트로피를 사용하여 예측 정확도를 측정하며, 이 정확도를 최대화하고자 합니다. 즉, 적도로, 이것을 최소화하고자 합니다.\n\n따라서 w₁_prob에 대한 맥락에서는, 이는 [0, 1] 사이의 값이고 총합이 1인 20000개의 항목으로 구성된 벡터인데, 교차 엔트로피는 이 벡터의 \"two\"라는 단어에 대한 항목이 클 값이어야 한다는 것을 요구한다. 지역 수준 이미지 정보 텐서와 첫 번째 단어 \"START\"가 주어졌을 때, 예측해야 할 다음 단어는 \"two\"여야 합니다.\n\n## 단일 예측된 단어에 대한 교차 엔트로피\n\n다음 그림은 단어 확률 벡터 w₁_prob이 \"two\"라는 단어의 원핫(one-hot) 인코딩과 비교되어 \"two\"에 대한 w₁_prob의 항목이 커야 한다는 것을 요청하는 방식을 보여줍니다. 이 말은 모델이 이 위치에서 \"two\"라는 단어를 예측해야 한다는 것과 동등합니다.\n\n<div class=\"content-ad\"></div>\n\n\"단어 'two'에 대한 원핫 인코딩은 'two' 단어의 위치에 '1'이 들어가 있고, 다른 모든 위치에 '0'이 들어갑니다. 예측 확률 텐서 w₁_prob에서는 숫자가 랜덤하게 사용되어 해당 값들이 언어 모델 변환기에 의해 생성된 것을 설명합니다.\n\n![image](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_6.png)\n\n이 단어 w₁에 대한 텍스트ᵢ의 교차 엔트로피는 다음과 같습니다:\n\n![image](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_7.png)\"\n\n<div class=\"content-ad\"></div>\n\n위 손실 함수는 \"i\" 위첨자가 있으므로 (이미지ᵢ, 텍스트ᵢ) 쌍에서 한 단어에 대한 것입니다.\n\n단어 당 캡션 손실이 정의되었으므로, 텍스트ᵢ의 전체 문장에 대한 교차 엔트로피는 399개 단어의 교차 엔트로피의 합입니다:\n\n![image](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_8.png)\n\n<div class=\"content-ad\"></div>\n\n미니배치 전체의 손실은 이미지ₖ와 텍스트ₖ 쌍 (여기서 k는 1부터 N까지)의 모든 손실입니다.\n\n![Image](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_9.png)\n\n## 모든 단어들이 동시에 예측됩니다\n\n이전 그림의 단계 5로 돌아가 봅시다. 이제 우리는 설명에 있는 모든 단어들이 동시에 예측된다는 것을 볼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 첫 번째 행이 P(w₁|START, img_tokensᵢ)를 나타내고,\n- 두 번째 행이 P(w₂|START, w₁, img_tokensᵢ)를 나타내며,\n- 세 번째 행이 P(w₃|START, w₁, w₂, img_tokensᵢ)를 나타내고,\n- 이어서 계속됩니다.\n\n## 전체 손실\n\n우리 모델의 전체 손실 함수는 대조 손실과 캡션 손실의 선형 조합입니다.\n\n<img src=\"/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_10.png\" />\n\n<div class=\"content-ad\"></div>\n\n두 개의 λ 계수는 이 두 가지 손실 구성 요소 사이의 가중치로 사용되는 하이퍼파라미터입니다.\n\n## 이미지 캡션 생성\n\n이제 우리는 전체 손실로 훈련된 이 모델이 이미지에 대한 캡션을 생성하는 방법을 볼 수 있습니다:\n\n- 입력 이미지로부터 로컬 레벨 이미지 정보 텐서를 생성하기 위해 ViT+어텐션 풀링 구성 요소를 사용합니다.\n- 시작 단어만을 포함하는 캡션 접두어를 구성합니다.\n- 언어 모델 트랜스포머를 두 번 사용하여(첫 번째로 어텐션된 텍스트를 생성하고, 두 번째로 교차 어텐션된 텍스트를 생성하기 위해), 다음 단어를 예측하기 위해 선형 투영을 거쳐 단어 확률을 생성합니다. 캡션 접두어로부터 다음 단어를 예측합니다. 이 두 단어를 각각 predicted_w₁, predicted_w₂로 부르겠습니다. 이 두 단어는 단계 3의 두 번의 실행에 의해 생성됩니다.\n- 새롭게 예측된 단어를 캡션 접두어에 추가합니다.\n- END 단어가 예측될 때까지 단계 3에서 4를 반복합니다.\n\n<div class=\"content-ad\"></div>\n\n패딩\n\n언어 모델 변환기는 400단어의 고정 길이 입력을 받습니다. 따라서 캡션 생성의 시작 부분에서 변환기로 보내는 입력에는 많은 패딩 단어가 포함됩니다.\n\n예를 들어, 첫 번째 입력 문장은 “START PAD … PAD”이고, 두 번째는 “START predicted_w₁ PAD … PAD”이며, 세 번째는 “START predicted_w₁ predicted_w₂ PAD … PAD” 등입니다. 다시 말해, 문장은 항상 399단어로 패딩되어야 한 뒤 언어 모델 변환기로 전송됩니다.\n\n언어 모델 변환기의 출력(두 번의 적용 후)은 399×20000 단어 확률 행렬입니다. 매번 이 행렬의 한 행만 사용하여 다음 단어의 가장 높은 확률을 찾고, 그 다음 실제 단어를 찾습니다. 이 399×20000 행렬의 다른 행은 사용되지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n이 프로세스를 최적화하는 방법이 있지만, 이 글에서는 개념을 이해하는 데 집중하고 최적화에 대해 걱정할 필요는 없습니다.\n\n# 이미지 질문 응답을 지원하는 방법은?\n\n이미지 캡션 작업 방식을 이해한 후에 이미지 질문 응답 작업 방식을 동일하게 이해하는 것이 더 쉽습니다:\n\n- 이미지 캡션 작업은 입력 이미지와 텍스트 접두사 \"START\"로 시작됩니다.\n- 이미지 질문 응답 작업은 입력 이미지와 질문을 텍스트 접두사로 시작합니다.\n\n<div class=\"content-ad\"></div>\n\n그거에요.\n\n문제의 단어를 무시해야 하는 예측 단어 확률 행렬의 행들에 관해서 섬세함이 있습니다. 하지만 이에 대해 시간을 투자해 이해하려고 결정한다면 이해할 수 있다고 믿습니다.\n\n하지만 이미지에 대한 질문 답변 모델을 구축하려면 이미지 캡션 손실을 다르게 처리해야 할 필요가 있습니다. 이미지 캡션에 대한 손실은 다음 단어 예측 문제를 다루지만 이미지에 대한 질문 응답에 대한 손실은 다른 문장을 제공하면서 문장 예측 문제를 다룹니다.\n\n# Foundation models\n\n<div class=\"content-ad\"></div>\n\n지금 우리는 모델이 한 번 훈련된 후에 새로운 작업을 수행하거나 새로운 작업을 수행하도록 다시 훈련할 수 있다는 것을 알 수 있습니다. 이것이 바로 왜 이 모델을 기반 모델이라고 부르는 이유입니다. 기반 모델은 다양한 하류 작업을 위한 시작점으로 기반 또는 부분적으로 완성된 모델을 제공합니다.\n\n# ViT 인코더와 어텐션 풀링\n\n대부분의 모델이 설명되었으니, 이제 마지막 부분으로 넘어가 보겠습니다 — ViT 인코더와 어텐션 풀링을 사용하여 모델이 어떻게 전역 및 지역 수준의 이미지 정보 텐서를 생성하는지 알아봅시다.\n\n## ViT 인코더\n\n<div class=\"content-ad\"></div>\n\nViT 인코더는 고정 크기 이미지를 패치 목록으로 분할하여 각 패치를 인코딩합니다. 다음 그림은 ViT 인코더가 인코딩된 이미지 패치를 생성하는 방법을 보여줍니다. 여기에서 i 아래 첨자를 무시했습니다. img_tokensᵢ를 소개할 때 사용한 것과 같은 이유입니다. 이전에는 미니 배치에서 텐서에 대해 이야기해야 했는데, 그 텐서는 손실 함수에 들어가며 손실 함수는 미니 배치로 정의됩니다. 그러나 여기에서는 더 이상 미니 배치에 대해 이야기할 필요가 없습니다.\n\n![이미지](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_11.png)\n\nViT 인코더는 고정 크기 이미지를 처리하는 표준 트랜스포머 기반 이미지 인코더로, 논문 '이미지는 16x16 단어만큼 가치가 있다'에서 소개되었습니다. 이 ViT 인코더는 오직 고정 크기 이미지와 함께 동작합니다. 위 그림은 이 ViT 인코더가 작동하는 방식을 보여줍니다:\n\n- 우리의 경우 288×288×3 크기의 컬러 RGB 이미지(따라서 컬러 채널은 3)로 표현되는 고정 크기 이미지를 받았을 때, ViT 인코더는 먼저 이미지를 18×18 크기의 256개 패치로 분할합니다.\n- 그런 다음 ViT 인코더는 각 패치를 1024 길이의 벡터로 변환하여 256×1024 행렬인 'encoded_img_patches'라고 불리는 것을 얻습니다.\n\n<div class=\"content-ad\"></div>\n\nViT 인코더가 정지되어 있습니다\n\n이미지 패치 인코딩 중 ViT 인코더의 매개변수는 정지되어 있음을 유의하십시오. 따라서 ViT 인코더에는 학습 가능한 매개변수가 없습니다.\n\n이전에 소개된 언어 모델 트랜스포머는 왜 정지되지 않고 학습 가능한 매개변수가 포함되어 있는 반면, 여기서 ViT 인코더는 왜 정지되어 있는 걸까요? 저는 저자가 언어 모델 트랜스포머를 동결해 보았지만, 결과가 학습 가능한 모델보다 좋지 않았던 것 같습니다.\n\n정지 또는 비정지 선택에 대해 조금 더 심도 깊게 생각해 보고 싶습니다. ViT 인코더에서 온 한 세트와 언어 모델 트랜스포머에서 온 다른 세트의 벡터 두 개를 맞추기 위해서는, 한 벡터 세트를 만드는 모델의 일부를 고정시키고, 옵티마이저가 다른 벡터 세트를 만드는 모델의 매개변수를 조정하게 하면 충분합니다. 두 모델 구성 요소를 모두 움직이게 유지할 필요는 없습니다. 모델 일부를 동결시키면, 옵티마이저가 학습할 매개변수가 적기 때문에 작업이 더 쉬워집니다.\n\n<div class=\"content-ad\"></div>\n\n## 주의 집중 풀링은 인코딩된 이미지 패치에 학습 가능한 매개변수를 혼합합니다\n\n다음 단계인 주의 집중 풀링은 인코딩된 이미지 패치를 모델 매개변수와 혼합합니다. 신경망 아키텍처 디자인에서 구현된 인코더를 재사용하는 전형적인 방법입니다. 구현된 인코더를 동결된 상태로 사용하고, 자신의 네트워크에 trainable 레이어를 도입하여 동결된 인코더의 출력을 자신의 네트워크에 혼합합니다. 다음 그림은 주의 집중 풀링이 작동하는 방식을 보여줍니다.\n\n![Image](/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_12.png)\n\n단계 1. ViT는 변환된 256×1024 인코딩된 이미지 패치를 선형으로 다른 동일한 모양의 텐서로 투영합니다. 이 선형 투영에는 trainable 매개변수가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n스텝 2. 선형으로 프로젝트된 encoded_img_patches 텐서는 특성 차원(1024 차원)에서 동일한 모양의 256×512로 나누어지며, 이 중 하나는 v 텐서로, 다른 하나는 k 텐서로 불립니다. 이미 어텐션 메커니즘에서 사용되는 key 행렬 중요성 때문에 k, v 텐서 명칭에 익숙할 것입니다.\n\n스텝 3. 모양이 257×512인 img_queries 텐서가 소개됩니다. PyTorch의 Embedding 클래스에서 제공되며 학습 가능한 매개변수를 포함합니다. img_queries 텐서는 동일한 모양의 q 텐서로 선형으로 프로젝트됩니다. 이 선형 프로젝션에도 학습 가능한 매개변수가 있습니다. img_queries는 257개의 행을 가지고 있습니다. 그래서 인코딩된 이미지 패치의 개수인 256개보다 한 벡터가 더 있습니다. 이 추가 벡터는 전역 수준 이미지 정보를 표현하는 데 사용됩니다.\n\n스텝 4. 유명한 교차 어텐션 매트릭스 곱인 q@kᵀ입니다. 이 곱셈은 모양이 257×256인 sim 텐서를 만듭니다. sim 매트릭스는 내적 매트릭스로, 각 항목은 img_queries 텐서의 열과 k 텐서의 행 사이의 내적 유사성입니다. 이는 입력 이미지의 단일 패치를 인코딩합니다.\n\n스텝 5. 또 다른 교차 어텐션 매트릭스 곱셈인 sim@v가 이어집니다. 이는 모양이 257×512인 텐서를 만듭니다. 스텝 4와 5는 어텐션 메커니즘에서 일반적인 q, k, v 곱셈입니다.\n\n<div class=\"content-ad\"></div>\n\n6단계에서는 sim @ v 곱셈으로 얻은 257×512 텐서를 두 개의 텐서로 분할합니다:\n\n- 첫 번째는 형상이 256×512인 img_tokens 텐서입니다. 이 텐서는 이미지의 패치별 로컬 수준 이미지 정보를 나타낸다는 것을 의미합니다. 즉, img_tokens의 각 1×512 행은 256개의 이미지 패치에서 정보를 나타냅니다.\n- 두 번째는 형상이 1×512인 img_cls 텐서입니다. 이 텐서는 전체 이미지를 요약하는 글로벌 수준 이미지 정보를 나타내는 것으로 해석됩니다.\n\n이 두 텐서는 이전에 설명한 대로 이미지-텍스트 정렬을 수행하는 데 사용됩니다.\n\n## 결론\n\n<div class=\"content-ad\"></div>\n\n이 글은 이미지-텍스트 이중 모달 기반 모델의 설계를 설명합니다. 설계의 핵심 부분은 대조 손실 함수를 통해 전역 수준에서 이미지와 텍스트 간의 정렬을 설정하고 교차 엔트로피 손실 함수를 통해 로컬 수준에서 정렬을 수행하는 것입니다.\n\n전역 수준의 이미지-텍스트 정렬은 이미지 분류, 텍스트 기반 이미지 검색 및 깊은 이미지 유사성 검색과 같은 작업을 지원합니다. 로컬 수준의 이미지-텍스트 정렬은 이미지 캡셔닝 및 이미지 질문에 대한 답변과 같은 작업을 지원합니다.","ogImage":{"url":"/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_0.png"},"coverImage":"/assets/img/2024-06-19-HowDoesanImage-TextMultimodalFoundationModelWork_0.png","tag":["Tech"],"readingTime":17},{"title":"온라인 플랫폼에서 참여 예측을 위한 딥 러닝","description":"","date":"2024-06-19 06:44","slug":"2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms","content":"\n\n\n![image](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png)\n\n# 요약\n\n에딘버러 대학에서 MSc 논문의 일환으로, 저는 딥러닝 기술을 사용하여 준니버스의 사용자 참여를 예측했습니다. 준니버스는 비과학자들이 행성 탐사와 같은 특정 분야에 기여할 수 있는 온라인 시민 과학 플랫폼입니다. 준니버스는 100편 이상의 논문 발표에 기여했습니다. 실제 환경에서 시민 과학자들은 영국의 농업 유출물이 영국 강의 안전 한 한계를 초과하는 수위의 오염 증가를 입증했습니다.\n\n이 문맥에서 참여는 이전 행동을 고려할 때 플랫폼의 미래 사용을 예측할 수 있는지 여부입니다. 이는 여러 형태로 나타날 수 있습니다, 예를 들면:\n\n\n<div class=\"content-ad\"></div>\n\n- 시간 기준 내에서 완료할 작업의 예상 수\n- 현재 작업 세션에서 머무를 시간의 양\n\n우리는 섹션 정의에 초점을 맞추고 사용자가 10, 20 또는 30분 동안 계속 작업할지를 예측하기 위해 노력했습니다. 이는 사용자 작업 T를 작업 세션 W로 그룹화하여 계산되었습니다.\n\n![이미지](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_1.png)\n\n이 정의는 유연성과 Zooniverse, StackOverflow 및 Coursera에서의 이전 사용을 위해 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n이 접근 방식의 주의 사항 중 하나는 생산적인 온라인 시스템의 한 속성인 플랫폼 시간만을 예측한다는 것입니다. 예를 들어, 올바른 기여를 하는 동기부여된 참여자들을 갖는 것은 고려되지 않습니다. 온라인 시스템에 참여하는 동기를 측정하는 것은 활발한 연구 분야입니다. 심리적 상태인 좌절감과 이해도와 같은 것들이 학습되어 맞춤형 교육 개입에 활용될 수 있는 잠재적인 작업이 있습니다.\n\n# 데이터 및 세션 버킷 알고리즘\n\nZooniverse는 친철하게 2021년 10월 19일에서 2022년 8월 14일까지 시민 과학자들의 클릭스트림 데이터를 제공해 주었습니다. 이 데이터는 미국, 중국, 싱가포르 및 핀란드의 시민 과학자들을 다루었습니다.\n\n원시 데이터 세트에는 다음과 같은 열이 포함되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n| Column Name |               Column Desc               | Column Type |\n|-------------|-----------------------------------------|-------------|\n| id          | 클릭스트림 항목을 식별하는 고유 식별자  | bigint      |\n| user_id     | 사용자를 식별하는 고유 식별자           | bigint      |\n| project_id  | 프로젝트를 식별하는 고유 식별자         | bigint      |\n| workflow_id | 워크플로우를 식별하는 고유 식별자       | bigint      |\n| subject_ids | 고유한 작업 식별자                      | bigint      |\n| country     | 국가 이름                               | str         |\n| latitude    | 국가 위도                               | float       |\n| longitude   | 국가 경도                               | float       |\n| timestamp   | 클릭스트림 타임스탬프                   | bigint      |\n\n\nZooniverse의 계층 구조에서 각 행은 다음 거래를 나타냅니다.\n\n- 사용자가 시스템에 로그인하고 참여할 프로젝트를 선택합니다.\n- 프로젝트는 여러 워크플로우를 포함하며 태스크 그룹화를 수행합니다.\n- 사용자는 프로젝트에 연관된 작업을 수행합니다. 작업에는 여러 주제가 포함될 수 있습니다 (하지만 대부분은 하나만 포함합니다).\n\n<img src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_2.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n# 특성 선택\n\n데이터에는 약 38,500,990개의 고유 이벤트가 포함되어 있습니다. 서로 다른 지역별 이벤트 분포는 다음과 같습니다:\n\n\n| 국가명        | 백분율     |\n|---------------|------------|\n| 핀란드         | 59.4       |\n| 미국           | 25.5       |\n| 싱가포르       | 10.8       |\n| 중국           | 4.3        |\n\n\n위도와 경도는 국가 정보를 중복해서 나타내므로 제거되었습니다. 주제 ID 및 작업 ID도 제거되었는데, 이 정보의 세분화가 참여 패턴 학습에 기여하지 않았기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n우리 연구에서는 이전 연구에서 강조된 주요 변수가 부족했습니다. 예를 들어, Semenov et al.은 로그인한 사용자들이 더 오랜 시간 동안 작업하고 작업 세션에 대해 더 높은 투자 수준을 나타내는 것으로 발견했습니다. 또한, Mao et al.은 투표 엔트로피가 감소하는 경우, 사용자가 목록에서 반복해서 동일한 옵션을 선택하는 것이 지루함과 참여하지 않음의 유용한 대리자로 작용할 수 있다고 밝혀냈습니다. 이러한 연구 결과는 사용자 참여도를 효과적으로 측정할 수 있는데 사용자 로그인 상태와 투표 패턴을 통해 이를 할 수 있음을 시사했으며, 이러한 측면들이 우리의 현재 분석에는 고려되지 않았습니다.\n\n따라서 우리는 이러한 특성을 근사화하는 데 사용될 수 있는 다양한 속도에서 통계치를 계산해야 했습니다. 이에는 다음이 포함되었습니다:\n\n- 사용자 세션 수의 롤링 번호\n- 현재 세션 내의 시간 및 이벤트 수\n- 과거 세션 간의 평균 시간 및 이벤트 수\n- 이전 세션에서 소비한 시간 및 이전 세션의 이벤트 수\n- 마지막 이벤트로부터의 시간 차 및 과거 이벤트의 평균 시간 차\n\n![image](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_3.png)\n\n<div class=\"content-ad\"></div>\n\n# **The Feature Long Tail**\n\nZooniverse 및 Coursera, StackOverflow, Snap과 같은 다른 온라인 플랫폼의 분석 결과를 보면, 매우 소수의 사용자가 플랫폼 활동의 대부분을 지나치게 책임지는 거대한 권한 분포가 있다는 것을 알 수 있습니다. 이 현상은 소수의 고도로 활발한 사용자가 플랫폼 기여를 주도하고 대부분의 사용자는 비교적 활동이 적다는 것을 나타냅니다.\n\n저희의 데이터는 권한 분포에 부합되어, 사용자의 25%만이 세 번 이상의 세션을 완료하였으며, 작업 세션의 68%는 30분 미만으로 지속되었습니다. 이 분포는 사용자 참여의 불균형을 강조하며, 소수의 고도로 활발한 사용자가 플랫폼에서의 활동을 지배하고 있음을 보여줍니다.\n\n많은 사용자에게 시간 순서 채널은 중복될 수 있습니다. 사용자가 단 한 번의 세션만 완료하는 경우, 과거 세션 계산은 일정한 0으로 유지됩니다. 마찬가지로 세션 간 시간과 같은 채널의 경우, 사용자가 두 번의 세션만 완료하는 경우, 과거 세션 채널은 첫 번째 세션에 대해서는 0으로 일정하게 유지되거나 이전 세션 통계의 일정한 값이 될 것입니다. 이 중복성은 드물게 사용하는 사용자에게는 이러한 메트릭이 의미 있는 통찰력을 제공하지 않을 수 있으며, 참여를 효과적으로 평가하기 위해 대안적인 측정 방법이 필요할 수 있다는 것을 시사합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_4.png)\n\nThe feature space was designed to represent user information over various time intervals. Because many users only completed two sessions, a lot of data would be repeated for these users. Any model for predicting user behavior would need to be carefully interrogated to ensure it did not memorize these aspects of user behavior and project results that mimicked the most likely user, rather than the projection of users.\n\nTherefore, it was important to design experiments that enabled differentiation between the small number of highly active users and the large population of inactive, short-term contributors.\n\n# Experiments\n\n\n<div class=\"content-ad\"></div>\n\n실험 결과 다음 질문에 대한 대답을 제공했습니다. 사용자의 클릭 스트림에 기록된 항목이 주어졌을 때 사용자가 10, 20 또는 30분 동안 계속 작업을 할 것인가?\n\n클릭 스트림의 각 행은 사용자가 지정된 시간대(10, 20 또는 30분) 동안 계속 작업할지 여부를 나타내는 레이블 yiy_iyi로 표시되었습니다. 데이터가 시계열을 따르고 사용자 행동이 이전 이력에 의존한다는 점을 감안하여, 클릭 스트림 F(X_i, Y_i)의 예측은 과거 정보를 포함하여 확장되었습니다. 따라서 예측 함수는 F(X_i, Y_i, | X_i-1, X_i-2, ..., X_0)가 되었습니다.\n\n장기 단기 메모리(Long Short-Term Memory, LSTM) 네트워크는 과거와 현재 정보를 제어하고 가중시키도록 설계된 것으로 이러한 종류의 분석에 적합합니다. 이들은 다른 시계열 작업으로도 효과적으로 적용되어 왔으며, 활동 인식, 행동 인식 및 지진 예측과 같은 작업에 사용되었습니다.\n\n사용자 세션 창을 통해 이러한 함수를 쌓는 과정에서, 모델이 세션 통계, 사용자 동작 변화 및 예상된 참여 사이의 관계를 학습할 수 있을 것으로 기대했습니다¹.\n\n<div class=\"content-ad\"></div>\n\n다음 질문에 대답하려고 실험을 진행했습니다:\n\n- 단기 또는 장기 행동을 예측하는 것이 더 쉬운지 여부.\n- 데이터 창 크기를 확장하면 참여 측정에 기여하는지 여부.\n\n또한 실험에서는 각 이벤트를 독립적으로 고려하는 대신 네트워크 아키텍처와 종속성을 포착하는 것이 모델 성능에 영향을 미치는지 확인하기 위해 RandomForest 분류에 대해 베이스라인을 설정했습니다.\n\n사용자가 현재 세션에서 계속 작업하는지 여부는 이진적입니다. 따라서 RandomForest를 구성하고 LSTM 매개변수 최적화를 위해 유전 알고리즘과 경사 하강법을 적용할 수 있었고, 바이너리 크로스 엔트로피를 사용하여 꼭 맞추었습니다.\n\n<div class=\"content-ad\"></div>\n\n일괄 처리된 N개의 관측치에 대한 손실 함수는 다음과 같습니다:\n\n![Loss Function](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_5.png)\n\n목표는 yi(실제 예측값)와 네트워크 출력인 y^i 사이의 거리를 최소화하는 것입니다.\n\n# 구현\n\n<div class=\"content-ad\"></div>\n\n데이터는 타임스탬프에 따라 정렬되고 훈련, 테스트 및 평가 파티션으로 분할되었습니다. 이미지 분류 실험과는 달리 시계열 관측 사이의 관계가 중요하기 때문에 데이터를 섞으면 시퀀스의 일관성이 깨질 수 있습니다. 따라서 데이터를 섞으면 훈련에 후속 관측사항이 포함될 수 있습니다. 예를 들어, 모델이 작업 세션이 10분만 계속된다는 정보를 받기 전에 작업 세션의 1분과 2분의 관측을 받는다면 결과적으로 선견지명을 얻을 수 있습니다.\n\n장기 단기 메모리 (LSTM) 네트워크가 사용자 관측 윈도우의 길이 1, 10, 20, 30, 40에 대해 생성되고 훈련되었습니다. PyTorch Lightning을 사용하여 네트워크를 훈련했는데, 이를 통해 편리한 래퍼(wrapper)를 제공하여 훈련 루프 구현, 로깅 및 메트릭 처리를 감싸줍니다. 10, 20, 30분 동안의 지속을 예측하기 위한 별도의 실험이 수행되었습니다.\n\n첫 번째의 출력이 두 번째로 전파되는 두 개의 LSTM 네트워크를 쌓는 것이 가장 성능이 좋았습니다. 두 번째 레이어는 선형 레이어를 따라, 기능을 하나의 대상 변수로 변환하여 사용자의 세션 지속 확률을 정의했습니다. 최종 선형 레이어 다음의 엔트로피에서 역전파가 계산되었고, 이를 통해 네트워크 전체의 가중치가 업데이트되었습니다.\n\n<div class=\"content-ad\"></div>\n\n# 결과\n\n실험을 통해 성과가 좋은 모델을 분석했습니다. 각 실험에 대한 정밀도, 재현율 및 AUC를 플롯했습니다. AUC는 분류 임계값 범위에서 실제 양성 비율(재현율)과 거짓 양성 비율(1-정밀도)을 집계합니다.\n\n검증 및 테스트 데이터셋 간의 균형은 모델이 특정 시간 역학에 기반하지 않고 패턴을 학습하고 있다는 것을 나타냅니다. 따라서 참여 패턴이 크게 변하지 않는 한, 새로운 데이터에 적용될 때 모델의 동작을 예측할 수 있을 가능성이 높습니다.\n\n결과는 장기적 예측에서 일반적으로 더 일관성있게 나타납니다. 정밀도는 검증 데이터셋에서 68%에서 70%로, 테스트 데이터셋에서 71%에서 74%로 범위가 확장됩니다. 모든 창에서 재현율은 57%에서 59%까지 범위가 확장됩니다.\n\n<div class=\"content-ad\"></div>\n\n단기 행동을 예측하는 실험들은 데이터 윈도우의 크기에 민감합니다. 10분 동안의 실험에서, 검증 데이터셋의 정밀도는 64%에서 80%로 범위가 나타나며, 테스트 데이터셋의 경우 66%에서 89%까지 변동합니다. 재현율은 89%에서 30%까지 범위가 나타나며, 최적의 균형을 얻으려면 20개에서 30개의 이벤트 윈도우를 사용하는 것이 좋습니다.\n\n![Image 7](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_7.png)\n\n![Image 8](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_8.png)\n\n![Image 9](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_9.png)\n\n<div class=\"content-ad\"></div>\n\n모델의 다양한 행동 양상은 짧은, 중간, 그리고 장기적인 참여를 예측하는 것이 서로 다른 접근 방식이 필요한 다른 도전이라는 것을 보여줍니다. 더 높은 정밀도는 단기적으로 참여하는 사용자를 놓치지 않을 가능성을 보여줍니다. 그러나 장기간의 참여가 떨어질 것으로 예측하는 것은 더 어려운 과제입니다.\n\n실제 상황에서 모델의 선택은 참여하지 않은 사용자를 놓치는 것을 우선시해야 하는지, 아니면 동기를 부여받은 사용자를 잘못 분류하는 것을 우선시해야 하는지를 고려해야 합니다.\n\n30분 참여 예측과 데이터 창의 30개 이전 관측치를 사용한 우수한 모델/실험 구성이 우리의 최고의 성과를 냈습니다. 이 모델은 AUC 스코어가 0.748을 달성했습니다. 이는 Mao Et Al이 30분 예측에서 약 0.76을 달성한 것보다 약간 떨어지는 성과입니다. 이는 데이터의 분산 부족으로 인한 것으로 여겨집니다. 예를 들어, 첫 번째 사용자 세션에는 많은 동일한 변수들이 포함되어 있습니다. 이들은 다음을 포함합니다:\n\n- 누적 플랫폼 시간 및 누적 세션 시간.\n- 플랫폼과 세션 전체 이벤트 수.\n- 이전 세션 통계.\n\n<div class=\"content-ad\"></div>\n\n**사용자 세그먼트별 평가**\n\n플랫폼에 작은 기여만 한 사용자를 고려해 역사적 정보를 포함시키면 많은 중복이 발생한다는 것을 알고 있습니다. 이는 대부분의 사용자들에 해당합니다.\n\n다양한 세션 길이 별 성능을 이해하기 위해 사용자 작업 세션에서 지낸 누적 시간에 따른 정확도, 재현율 및 AUC를 검토합니다. 평가와 테스트 세션을 유사성으로 통합합니다. 정밀도와 재현율의 가장 큰 요인은 사용자가 작업 세션에서 얼마나 시간을 보내는지에 달려 있습니다. 데이터 창 크기에 관계 없이, 사용자가 작업 세션에서 60분을 보낸 후에는 모델의 효과가 극적으로 향상됩니다.\n\n![이미지](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_10.png)\n\n<div class=\"content-ad\"></div>\n\n기존 온라인 플랫폼 연구와 일관성 있는 결과를 보여주었으며, 최소한의 히스토리로 사용자에 대한 추론의 어려움을 보여줍니다. 이는 사용자 행동에 대한 우리 이전 분석을 뒷받침합니다.\n\n산키 다이어그램에 의하면, 한 번 사용자 행동이 시작되면 짧은 기간 내에는 비교적 예측 가능합니다. 사용자가 20분 미만의 세션에 참여하면 다음 세션이 또한 20분 미만인 확률이 66.7%이고, 40분을 넘는 세션이 될 확률은 15.4%에 불과합니다. 20분에서 40분 사이의 세션을 가진 사용자는 다음 세션이 20분을 넘을 확률이 약 50%입니다. 이는 사용자가 참여하면 더 오래 플랫폼에 투자하게 되는 경향을 나타냅니다.\n\n사용자의 역사가 거의 없는 사용자 행동을 예측하는 어려움이 분명합니다. 사용자가 5회 세션을 완료하거나 세션이 40분을 초과하면 성능이 일반적으로 향상되며, 가장 안정적인 결과는 20~30 이벤트의 데이터 창을 포함합니다. 이 정보는 Zooniverse 및 다른 온라인 플랫폼의 행동 예측 모델을 개선하는 데 도움이 될 수 있습니다. 모델이 빈번한 기여자에게는 효과적이지 않으므로, 이 그룹의 참여 증가를 위한 개입 시기를 결정하는 데 사용해서는 안 됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n연구 결과에서 알 수 있듯이, LSTMs는 시계열 작업 모델링에 효과적입니다. 모든 실험과 모델 구성에서, 사용자가 현재 작업 세션에서 탈락하는지 여부를 학습할 수 있었습니다. 복잡한 특징 집계 대신, 데이터 창을 사용하여 데이터 전체의 의존 관계를 학습했습니다. 이는 GPU를 필요로하며 계산적으로 더 많은 비용이 소요됩니다만, 고전적인 머신 러닝보다 훨씬 적은 시간과 도메인 지식이 필요합니다.\n\n모델은 두 가지 요인으로 제한되었습니다. 첫 번째는 사용자가 언제 탈락할 지 나타내는 기능의 부족이었습니다. 미래 실험에서는 Mao et al.의 연구에서 설명된 특징을 사용하여 모델 성능이 향상되는지 확인해야합니다.\n\n두 번째 제한은 극복하기 어렵습니다. 최소한의 데이터로 사용자에 대해 일반화하는 것은 어렵습니다. 대부분의 Zooniverse 사용자가 단기적이거나 \"관심을 끄는 사람\"이기 때문에 Zooniverse에서 행동을 모델링하는 것은 도전적입니다. 최소한의 경험이있는 사용자에 대한 모델의 한계를 밝히고 설명하는 것은 이전 데이터 분석과 플랫폼 사용 방법 조사만이 가능합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_12.png\" />\n\n머신 러닝을 시작하기 전에 데이터와 문제를 명확히 이해하는 것이 중요함을 강조합니다. 초기 분석을 통해 모델의 효과에 대한 사전 확률을 설정할 수 있었고, 해당 분석을 통해 이를 확인할 수 있었습니다.\n\n실제 산업 환경에서 모델이 Zooniverse에 대한 개입(뱃지 또는 메시지와 같은)을 시간화하는 데 사용된다면, 하이브리드 접근 방식을 권장합니다. 짧은 기간 사용자에게는 규칙 기반 논리를 사용하여 개입을 타이밍하고, 장기 사용자에게는 모델이 개입을 안내하는 데 효과적일 수 있습니다.\n\n# 각주\n\n<div class=\"content-ad\"></div>\n\n- LSTMs가 어떻게 작동하는지 멋진 설명을 찾으려면 Colah의 LSTMs에 대한 블로그 포스트를 확인하시기를 추천합니다. LSTMs의 역전파 알고리즘을 이해하고 싶다면 Goodfellow Et Al의 \"Deep Learning\"의 10장을 살펴보시는 걸 추천드립니다.","ogImage":{"url":"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png"},"coverImage":"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png","tag":["Tech"],"readingTime":11},{"title":"당신이 얼마나 많은 무게를 진다는지 알 수 없어요","description":"","date":"2024-06-19 06:43","slug":"2024-06-19-youhavenoideahowmuchweighticarry","content":"\n\n\n![Image](/assets/img/2024-06-19-youhavenoideahowmuchweighticarry_0.png)\n\n다른 쪽이 항상 푸른 것은 아니에요..\n\n대부분의 사람들은 막내가 되는 것이 축복이라고 생각해요.\n\n맏이나 중간 아이들은 종종 더 어린 아이를 부러워하며, 더 어린 사람이라면 삶이 훨씬 쉬울 것이라고 생각해요.\n\n\n<div class=\"content-ad\"></div>\n\n자신의 문제를 말해도 되지 않고, 특히 자신의 감정이 무시당한다는 것에 대해 열거나 살 수 없다고 상상해보세요.\n\n가족들이 당신이 자리하고 있는 자택이 조용한 곳으로 변모하는 것을 목격하고 있는 것을 상상해보세요.\n\n이제는 다른 사람들이 각자 바쁜 삶을 살아가고 있어서 매일 집에서 혼자 남아 있는 상황을 상상해보세요. 당신은 그들이 취해 침대에서 술에 취해 잠들어있는 모습만을 보게 될 것입니다.\n\n그들은 항상 우리는 가족이라고 말했지만, 모든 사람이 나를 잊어버렸다. - 나에게는 항상 너무 바빠서 소홀했다.\n\n<div class=\"content-ad\"></div>\n\n가장 어린 사람이 늘 축복이 되는 것은 아니에요... 저에게는 부담이에요.","ogImage":{"url":"/assets/img/2024-06-19-youhavenoideahowmuchweighticarry_0.png"},"coverImage":"/assets/img/2024-06-19-youhavenoideahowmuchweighticarry_0.png","tag":["Tech"],"readingTime":1}],"page":"85","totalPageCount":113,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true}