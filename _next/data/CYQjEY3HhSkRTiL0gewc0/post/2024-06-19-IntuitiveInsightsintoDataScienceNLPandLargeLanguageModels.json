{"pageProps":{"post":{"title":"데이터 과학, NLP 및 대형 언어 모델에 대한 직관적인 통찰력","description":"","date":"2024-06-19 04:02","slug":"2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels","content":"\n\n## 데이터 과학, 기계 학습, 자연어 처리 및 대형 언어 모델의 핵심 간소화\n\n![이미지](/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_0.png)\n\n- 소개\n- 섹션 1: 데이터 과학과 기계 학습의 직관\n  - 데이터 과학이란 무엇인가?\n  - 기계 학습의 기본\n- 섹션 2: 자연어 처리(NLP) 이해\n  - NLP란 무엇인가?\n  - 주요 NLP 작업\n  - NLP 모델의 진화\n- 섹션 3: 대형 언어 모델(LLMs) 소개\n  - LLMs란 무엇인가?\n  - 주요 특성\n  - 트랜스포머\n  - 인기 있는 LLMs\n- 섹션 4: 주요 개념 심층 탐구\n  - 임베딩\n  - 유사성 측정\n  - 파인튜닝\n  - 프롬프트 엔지니어링\n  - 에이전트\n- 결론\n- 참고 및 추가 독서\n\n# 소개\n\n<div class=\"content-ad\"></div>\n\n저희 초보자를 위한 데이터 과학, 기계 학습 및 관련 개념 안내에 오신 것을 환영합니다. 이 글은 검색 증강 생성 (RAG)과 같은 고급 주제를 더 잘 이해하기 위해 필요한 기본 지식을 제공합니다. 이 분야에 처음 접하셨거나 간단한 짧은 복습이 필요한 경우라면, 이 가이드를 통해 중요한 개념을 쉽고 직관적인 방법으로 이해하는 데 도움이 됩니다.\n\n# 섹션 1: 데이터 과학과 기계 학습의 직관\n\n## 데이터 과학이란?\n\n데이터 과학은 통계, 컴퓨터 과학 및 영역 지식을 결합하여 데이터에서 통찰을 추출하는 분야입니다. 범죄를 해결하는 대신에, 데이터 과학자는 데이터 내에 숨겨진 패턴과 트렌드를 발견합니다. 데이터 과학자는 조직이 정보에 기반한 결정을 내릴 수 있도록 데이터를 수집, 정제, 분석하고 시각화합니다.\n\n<div class=\"content-ad\"></div>\n\n## 기계 학습의 기본 사항\n\n기계 학습은 데이터 과학의 하위 집합으로, 우리는 컴퓨터에게 데이터에서 배우도록 가르칩니다. 명시적으로 프로그램 규칙을 작성하는 대신 컴퓨터에게 데이터를 공급하고 자체적으로 패턴을 찾게 합니다.\n\n- 피쳐와 레이블: 피쳐는 입력 변수(나이, 키 등)이고, 레이블은 출력 변수(누군가의 몸무게 예측과 같은)입니다.\n- 학습과 테스트: 데이터를 학습 및 테스트 세트로 나눕니다. 학습 세트는 모델을 가르치는 데 사용되고, 테스트 세트는 그 성능을 평가하는 데 사용됩니다.\n\n기계 학습의 종류:\n\n<div class=\"content-ad\"></div>\n\n- 지도 학습: 모델이 라벨이 붙은 데이터에서 학습합니다. (예: 과거 데이터를 기반으로 한 집 값 예측)\n- 비지도 학습: 모델이 라벨이 없는 데이터에서 패턴을 찾습니다. (예: 고객을 다른 세그먼트로 클러스터링하는 것)\n- 강화 학습: 모델이 시행착오를 통해 학습하며 올바른 행동에 대해 보상을 받습니다. (예: 로봇에 미로를 탐험시키는 것)\n\n## 섹션 2: 자연어 처리(NLP) 이해하기\n\n### NLP란 무엇인가요?\n\n자연어 처리(NLP)는 컴퓨터와 사람 간의 상호 작용에 초점을 맞춘 인공지능 분야입니다. 이는 컴퓨터에게 사람의 언어를 이해하고 생성할 수 있도록 가르치는 것을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n## 중요한 NLP 작업\n\n토큰화: 텍스트를 개별 단어나 토큰으로 분리하는 작업입니다.\n어간 추출과 표제어 추출: 단어를 그들의 기본 형태나 어간으로 줄이는 작업입니다 (예: \"running\"을 \"run\"으로).\n개체명 인식 (NER): 텍스트에서 이름, 날짜, 위치 같은 엔티티를 식별하는 작업입니다.\n품사 태깅 (POS): 문장 내 각 단어에 명사, 동사와 같은 품사를 할당하는 작업입니다.\n\n## NLP 모델의 진화\n\n전통적인 모델: 초기 NLP 모델은 n-그램과 TF-IDF와 같은 기법을 사용했으며, 이는 주로 수동 제작된 규칙과 통계적 방법에 의존했습니다.\n현대적인 모델: 요즘 NLP는 딥러닝을 활용합니다. Word2Vec와 GloVe와 같은 모델은 단어 임베딩을 만들어냅니다 (단어의 벡터 표현), 반면에 BERT와 GPT는 문맥을 더 효과적으로 이해하기 위해 트랜스포머를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n# 섹션 3: 대규모 언어 모델 (LLM) 소개\n\n## LLM이란?\n\n대규모 언어 모델(LLM)은 방대한 양의 텍스트 데이터로 훈련된 고급 모델입니다. 이러한 모델은 놀라운 정확도로 텍스트를 생성하고 이해할 수 있습니다.\n\n## 주요 특성\n\n<div class=\"content-ad\"></div>\n\n문맥 이해력: 이전 모델과는 달리 LLM은 단어가 사용된 문맥을 이해하여 더 정확한 결과를 제공합니다.\n다재다능함: 번역부터 텍스트 생성까지 다양한 작업을 수행할 수 있습니다.\n\n## 트랜스포머\n\n트랜스포머는 대부분의 현대 LLM의 중추를 이룹니다. 자기 주의 메커니즘(self-attention)을 도입하여 문장에서 다양한 단어의 중요성을 가중 평가하여 예측을 수행할 수 있게 했습니다.\n\n자기 주의 메커니즘: 이것은 모델이 입력 텍스트의 관련 부분에 집중하여 문맥을 더 잘 이해할 수 있게 합니다.\n혜택: 트랜스포머는 고도로 병렬화되며 RNN(순환 신경망)과 같은 이전 아키텍처보다 텍스트의 장거리 종속성을 더 잘 처리할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 인기있는 LLMs\n\nGPT (Generative Pre-trained Transformer): 일관된 문맥과 관련된 텍스트를 생성하는 능력으로 유명합니다.\n\nBERT (Bidirectional Encoder Representations from Transformers): 문장 속 단어들의 문맥을 이해하는 데 능숙하여, 질문응답 및 감성 분석과 같은 작업에 탁월합니다.\n\nT5 (Text-To-Text Transfer Transformer): 모든 NLP 작업을 텍스트 대 텍스트 형식으로 변환하므로, 다양한 응용 분야에 대해 매우 다재다능하고 효과적입니다.\n\n<div class=\"content-ad\"></div>\n\n# 섹션 4: 주요 개념 심층 탐색\n\n## 임베딩\n\n임베딩은 단어나 문장의 의미와 맥락을 포착한 수치적 표현입니다. 비슷한 단어들이 가까이 모여 있는 다차원 공간에서의 좌표로 생각해보세요.\n\n![임베딩 이미지](/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_1.png)\n\n<div class=\"content-ad\"></div>\n\n어떻게 사용되나요: 임베딩은 유사도 측정, 클러스터링, 및 분류와 같은 다양한 NLP 작업에 사용됩니다.\n\n## 유사성 측정\n\n유사성 측정은 두 개의 텍스트가 얼마나 비슷한지를 결정하는 데 도움을 줍니다. 일반적인 측정 방법으로는 다음이 있습니다:\n\n코사인 유사도: 두 벡터 사이의 각도의 코사인을 측정합니다. 벡터가 같은 방향을 가리킨다면 코사인 유사도는 1입니다.\n유클리드 거리: 공간에서 두 점 사이의 직선 거리를 측정합니다. 작은 거리는 더 높은 유사성을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n## 세밀한 조정\n\n세밀한 조정은 사전 훈련된 모델을 가져와서 작은 과제별 데이터 세트를 사용하여 특정 작업에 적응하는 과정입니다. 이를 통해 모델은 사전 훈련 중에 얻은 방대한 지식을 활용하면서 새로운 작업에 특화됩니다.\n\n사전 훈련 대 세밀한 조정: 사전 훈련은 일반 교육과 같으며, 세밀한 조정은 특정 작업을 위한 전문 훈련과 같습니다.\n실제 예시: 감성 분석을 위한 BERT 세밀한 조정 또는 사용자 지정 텍스트 생성을 위한 GPT 세밀한 조정.\n\n## 프롬프트 엔지니어링\n\n<div class=\"content-ad\"></div>\n\n프롬프트 엔지니어링은 언어 모델로부터 원하는 결과를 얻기 위한 입력을 만드는 것을 의미합니다. 가장 좋은 성능을 얻기 위해 질문이나 지시 사항을 제공하는 올바른 방법을 찾는 것이 중요합니다.\n\n프롬프트 유형: 직접적인 질문, 지시 사항 또는 예시.\n효과적인 프롬프트 디자인: 명확하고 구체적인 언어를 사용하고, 문맥을 제공하며 때로는 모델을 안내할 예시를 포함합니다.\n\n## 에이전트\n\n에이전트는 NLP 및 기타 AI 기술을 사용하여 자율적으로 작업을 수행하는 시스템입니다.\n\n<div class=\"content-ad\"></div>\n\n에이전트 유형: 챗봇, 가상 어시스턴트, 추천 시스템.\n에이전트 구축: 상호 작용 흐름 설계, 관련 데이터에 대한 교육, 사용자와 상호 작용할 수 있는 환경에 배포 포함됩니다.\n도전 과제: 정확성 보장, 모호한 입력 처리, 대화에서 맥락 유지하기.\n\n# 결론\n\nRAG와 같은 고급 주제로 물들기 전에 데이터 과학, 기계 학습, NLP 및 LLMs의 기본을 이해하는 것이 중요합니다. 이러한 기본 개념은 RAG가 어떻게 작동하는지와 그 중요성을 이해하는 데 필요한 배경을 제공합니다.\n\n# 참고 자료 및 추가 독서\n\n<div class=\"content-ad\"></div>\n\n일반 데이터 과학 및 기계 학습:\n\n- [스탠포드 대학의 데이터 과학 입문](https://datascience.stanford.edu/) \n- [구글의 기계 학습 총정리](https://developers.google.com/machine-learning/crash-course)\n- [분류 모델이 작동하는 방식 이해하기](https://towardsdatascience.com/classification-lets-understand-the-basics-78baa6fbff48)\n\n자연어 처리 (NLP):\n\n- [파이썬에서의 강력한 자연어 처리 - spaCy 문서](https://spacy.io/usage/projects) \n- [Jalammar의 Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n- [스탠포드 대학의 NLP 강좌: 대화형 에이전트 구현하기](https://web.stanford.edu/class/cs224n/)\n\n<div class=\"content-ad\"></div>\n\n대형 언어 모델 (LLMs):\n\n- [OpenAI 블로그: GPT-3 공개](https://openai.com/news/)\n- [Google AI 블로그: BERT - 언어 이해를 위한 깊고 양방향 트랜스포머에 대한 프리 트레이닝 공개](https://blog.research.google/2018/11/open-sourcing-bert-state-of-art-pre.html)\n- [Colin Raffel 등에 의한 텍스트-투-텍스트 전송 트랜스포머 (T5)](https://arxiv.org/pdf/1910.10683)\n\n구체적인 개념:\n\n- [단어 임베딩 설명 - Towards Data Science](https://towardsdatascience.com/a-guide-to-word-embeddings-8a23817ab60f)\n- [코사인 유사도 - 위키백과](https://en.wikipedia.org/wiki/Cosine_similarity)\n- [트랜스포머로 파인 튜닝 - Hugging Face](https://huggingface.co/docs/transformers/en/training)\n- [대형 언어 모델을 위한 좋은 프롬프트 작성 방법 - Hugging Face](https://huggingface.co/docs/transformers/en/tasks/prompting)\n- [챗봇의 종류 - Chatbots Magazine](https://chatbotsmagazine.com/the-complete-beginner-s-guide-to-chatbots-8280b7b906ca)","ogImage":{"url":"/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_0.png","tag":["Tech"],"readingTime":6},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>데이터 과학, 기계 학습, 자연어 처리 및 대형 언어 모델의 핵심 간소화</h2>\n<p><img src=\"/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_0.png\" alt=\"이미지\"></p>\n<ul>\n<li>소개</li>\n<li>섹션 1: 데이터 과학과 기계 학습의 직관\n<ul>\n<li>데이터 과학이란 무엇인가?</li>\n<li>기계 학습의 기본</li>\n</ul>\n</li>\n<li>섹션 2: 자연어 처리(NLP) 이해\n<ul>\n<li>NLP란 무엇인가?</li>\n<li>주요 NLP 작업</li>\n<li>NLP 모델의 진화</li>\n</ul>\n</li>\n<li>섹션 3: 대형 언어 모델(LLMs) 소개\n<ul>\n<li>LLMs란 무엇인가?</li>\n<li>주요 특성</li>\n<li>트랜스포머</li>\n<li>인기 있는 LLMs</li>\n</ul>\n</li>\n<li>섹션 4: 주요 개념 심층 탐구\n<ul>\n<li>임베딩</li>\n<li>유사성 측정</li>\n<li>파인튜닝</li>\n<li>프롬프트 엔지니어링</li>\n<li>에이전트</li>\n</ul>\n</li>\n<li>결론</li>\n<li>참고 및 추가 독서</li>\n</ul>\n<h1>소개</h1>\n<div class=\"content-ad\"></div>\n<p>저희 초보자를 위한 데이터 과학, 기계 학습 및 관련 개념 안내에 오신 것을 환영합니다. 이 글은 검색 증강 생성 (RAG)과 같은 고급 주제를 더 잘 이해하기 위해 필요한 기본 지식을 제공합니다. 이 분야에 처음 접하셨거나 간단한 짧은 복습이 필요한 경우라면, 이 가이드를 통해 중요한 개념을 쉽고 직관적인 방법으로 이해하는 데 도움이 됩니다.</p>\n<h1>섹션 1: 데이터 과학과 기계 학습의 직관</h1>\n<h2>데이터 과학이란?</h2>\n<p>데이터 과학은 통계, 컴퓨터 과학 및 영역 지식을 결합하여 데이터에서 통찰을 추출하는 분야입니다. 범죄를 해결하는 대신에, 데이터 과학자는 데이터 내에 숨겨진 패턴과 트렌드를 발견합니다. 데이터 과학자는 조직이 정보에 기반한 결정을 내릴 수 있도록 데이터를 수집, 정제, 분석하고 시각화합니다.</p>\n<div class=\"content-ad\"></div>\n<h2>기계 학습의 기본 사항</h2>\n<p>기계 학습은 데이터 과학의 하위 집합으로, 우리는 컴퓨터에게 데이터에서 배우도록 가르칩니다. 명시적으로 프로그램 규칙을 작성하는 대신 컴퓨터에게 데이터를 공급하고 자체적으로 패턴을 찾게 합니다.</p>\n<ul>\n<li>피쳐와 레이블: 피쳐는 입력 변수(나이, 키 등)이고, 레이블은 출력 변수(누군가의 몸무게 예측과 같은)입니다.</li>\n<li>학습과 테스트: 데이터를 학습 및 테스트 세트로 나눕니다. 학습 세트는 모델을 가르치는 데 사용되고, 테스트 세트는 그 성능을 평가하는 데 사용됩니다.</li>\n</ul>\n<p>기계 학습의 종류:</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>지도 학습: 모델이 라벨이 붙은 데이터에서 학습합니다. (예: 과거 데이터를 기반으로 한 집 값 예측)</li>\n<li>비지도 학습: 모델이 라벨이 없는 데이터에서 패턴을 찾습니다. (예: 고객을 다른 세그먼트로 클러스터링하는 것)</li>\n<li>강화 학습: 모델이 시행착오를 통해 학습하며 올바른 행동에 대해 보상을 받습니다. (예: 로봇에 미로를 탐험시키는 것)</li>\n</ul>\n<h2>섹션 2: 자연어 처리(NLP) 이해하기</h2>\n<h3>NLP란 무엇인가요?</h3>\n<p>자연어 처리(NLP)는 컴퓨터와 사람 간의 상호 작용에 초점을 맞춘 인공지능 분야입니다. 이는 컴퓨터에게 사람의 언어를 이해하고 생성할 수 있도록 가르치는 것을 의미합니다.</p>\n<div class=\"content-ad\"></div>\n<h2>중요한 NLP 작업</h2>\n<p>토큰화: 텍스트를 개별 단어나 토큰으로 분리하는 작업입니다.\n어간 추출과 표제어 추출: 단어를 그들의 기본 형태나 어간으로 줄이는 작업입니다 (예: \"running\"을 \"run\"으로).\n개체명 인식 (NER): 텍스트에서 이름, 날짜, 위치 같은 엔티티를 식별하는 작업입니다.\n품사 태깅 (POS): 문장 내 각 단어에 명사, 동사와 같은 품사를 할당하는 작업입니다.</p>\n<h2>NLP 모델의 진화</h2>\n<p>전통적인 모델: 초기 NLP 모델은 n-그램과 TF-IDF와 같은 기법을 사용했으며, 이는 주로 수동 제작된 규칙과 통계적 방법에 의존했습니다.\n현대적인 모델: 요즘 NLP는 딥러닝을 활용합니다. Word2Vec와 GloVe와 같은 모델은 단어 임베딩을 만들어냅니다 (단어의 벡터 표현), 반면에 BERT와 GPT는 문맥을 더 효과적으로 이해하기 위해 트랜스포머를 사용합니다.</p>\n<div class=\"content-ad\"></div>\n<h1>섹션 3: 대규모 언어 모델 (LLM) 소개</h1>\n<h2>LLM이란?</h2>\n<p>대규모 언어 모델(LLM)은 방대한 양의 텍스트 데이터로 훈련된 고급 모델입니다. 이러한 모델은 놀라운 정확도로 텍스트를 생성하고 이해할 수 있습니다.</p>\n<h2>주요 특성</h2>\n<div class=\"content-ad\"></div>\n<p>문맥 이해력: 이전 모델과는 달리 LLM은 단어가 사용된 문맥을 이해하여 더 정확한 결과를 제공합니다.\n다재다능함: 번역부터 텍스트 생성까지 다양한 작업을 수행할 수 있습니다.</p>\n<h2>트랜스포머</h2>\n<p>트랜스포머는 대부분의 현대 LLM의 중추를 이룹니다. 자기 주의 메커니즘(self-attention)을 도입하여 문장에서 다양한 단어의 중요성을 가중 평가하여 예측을 수행할 수 있게 했습니다.</p>\n<p>자기 주의 메커니즘: 이것은 모델이 입력 텍스트의 관련 부분에 집중하여 문맥을 더 잘 이해할 수 있게 합니다.\n혜택: 트랜스포머는 고도로 병렬화되며 RNN(순환 신경망)과 같은 이전 아키텍처보다 텍스트의 장거리 종속성을 더 잘 처리할 수 있습니다.</p>\n<div class=\"content-ad\"></div>\n<h2>인기있는 LLMs</h2>\n<p>GPT (Generative Pre-trained Transformer): 일관된 문맥과 관련된 텍스트를 생성하는 능력으로 유명합니다.</p>\n<p>BERT (Bidirectional Encoder Representations from Transformers): 문장 속 단어들의 문맥을 이해하는 데 능숙하여, 질문응답 및 감성 분석과 같은 작업에 탁월합니다.</p>\n<p>T5 (Text-To-Text Transfer Transformer): 모든 NLP 작업을 텍스트 대 텍스트 형식으로 변환하므로, 다양한 응용 분야에 대해 매우 다재다능하고 효과적입니다.</p>\n<div class=\"content-ad\"></div>\n<h1>섹션 4: 주요 개념 심층 탐색</h1>\n<h2>임베딩</h2>\n<p>임베딩은 단어나 문장의 의미와 맥락을 포착한 수치적 표현입니다. 비슷한 단어들이 가까이 모여 있는 다차원 공간에서의 좌표로 생각해보세요.</p>\n<p><img src=\"/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_1.png\" alt=\"임베딩 이미지\"></p>\n<div class=\"content-ad\"></div>\n<p>어떻게 사용되나요: 임베딩은 유사도 측정, 클러스터링, 및 분류와 같은 다양한 NLP 작업에 사용됩니다.</p>\n<h2>유사성 측정</h2>\n<p>유사성 측정은 두 개의 텍스트가 얼마나 비슷한지를 결정하는 데 도움을 줍니다. 일반적인 측정 방법으로는 다음이 있습니다:</p>\n<p>코사인 유사도: 두 벡터 사이의 각도의 코사인을 측정합니다. 벡터가 같은 방향을 가리킨다면 코사인 유사도는 1입니다.\n유클리드 거리: 공간에서 두 점 사이의 직선 거리를 측정합니다. 작은 거리는 더 높은 유사성을 나타냅니다.</p>\n<div class=\"content-ad\"></div>\n<h2>세밀한 조정</h2>\n<p>세밀한 조정은 사전 훈련된 모델을 가져와서 작은 과제별 데이터 세트를 사용하여 특정 작업에 적응하는 과정입니다. 이를 통해 모델은 사전 훈련 중에 얻은 방대한 지식을 활용하면서 새로운 작업에 특화됩니다.</p>\n<p>사전 훈련 대 세밀한 조정: 사전 훈련은 일반 교육과 같으며, 세밀한 조정은 특정 작업을 위한 전문 훈련과 같습니다.\n실제 예시: 감성 분석을 위한 BERT 세밀한 조정 또는 사용자 지정 텍스트 생성을 위한 GPT 세밀한 조정.</p>\n<h2>프롬프트 엔지니어링</h2>\n<div class=\"content-ad\"></div>\n<p>프롬프트 엔지니어링은 언어 모델로부터 원하는 결과를 얻기 위한 입력을 만드는 것을 의미합니다. 가장 좋은 성능을 얻기 위해 질문이나 지시 사항을 제공하는 올바른 방법을 찾는 것이 중요합니다.</p>\n<p>프롬프트 유형: 직접적인 질문, 지시 사항 또는 예시.\n효과적인 프롬프트 디자인: 명확하고 구체적인 언어를 사용하고, 문맥을 제공하며 때로는 모델을 안내할 예시를 포함합니다.</p>\n<h2>에이전트</h2>\n<p>에이전트는 NLP 및 기타 AI 기술을 사용하여 자율적으로 작업을 수행하는 시스템입니다.</p>\n<div class=\"content-ad\"></div>\n<p>에이전트 유형: 챗봇, 가상 어시스턴트, 추천 시스템.\n에이전트 구축: 상호 작용 흐름 설계, 관련 데이터에 대한 교육, 사용자와 상호 작용할 수 있는 환경에 배포 포함됩니다.\n도전 과제: 정확성 보장, 모호한 입력 처리, 대화에서 맥락 유지하기.</p>\n<h1>결론</h1>\n<p>RAG와 같은 고급 주제로 물들기 전에 데이터 과학, 기계 학습, NLP 및 LLMs의 기본을 이해하는 것이 중요합니다. 이러한 기본 개념은 RAG가 어떻게 작동하는지와 그 중요성을 이해하는 데 필요한 배경을 제공합니다.</p>\n<h1>참고 자료 및 추가 독서</h1>\n<div class=\"content-ad\"></div>\n<p>일반 데이터 과학 및 기계 학습:</p>\n<ul>\n<li><a href=\"https://datascience.stanford.edu/\" rel=\"nofollow\" target=\"_blank\">스탠포드 대학의 데이터 과학 입문</a></li>\n<li><a href=\"https://developers.google.com/machine-learning/crash-course\" rel=\"nofollow\" target=\"_blank\">구글의 기계 학습 총정리</a></li>\n<li><a href=\"https://towardsdatascience.com/classification-lets-understand-the-basics-78baa6fbff48\" rel=\"nofollow\" target=\"_blank\">분류 모델이 작동하는 방식 이해하기</a></li>\n</ul>\n<p>자연어 처리 (NLP):</p>\n<ul>\n<li><a href=\"https://spacy.io/usage/projects\" rel=\"nofollow\" target=\"_blank\">파이썬에서의 강력한 자연어 처리 - spaCy 문서</a></li>\n<li><a href=\"https://jalammar.github.io/illustrated-transformer/\" rel=\"nofollow\" target=\"_blank\">Jalammar의 Illustrated Transformer</a></li>\n<li><a href=\"https://web.stanford.edu/class/cs224n/\" rel=\"nofollow\" target=\"_blank\">스탠포드 대학의 NLP 강좌: 대화형 에이전트 구현하기</a></li>\n</ul>\n<div class=\"content-ad\"></div>\n<p>대형 언어 모델 (LLMs):</p>\n<ul>\n<li><a href=\"https://openai.com/news/\" rel=\"nofollow\" target=\"_blank\">OpenAI 블로그: GPT-3 공개</a></li>\n<li><a href=\"https://blog.research.google/2018/11/open-sourcing-bert-state-of-art-pre.html\" rel=\"nofollow\" target=\"_blank\">Google AI 블로그: BERT - 언어 이해를 위한 깊고 양방향 트랜스포머에 대한 프리 트레이닝 공개</a></li>\n<li><a href=\"https://arxiv.org/pdf/1910.10683\" rel=\"nofollow\" target=\"_blank\">Colin Raffel 등에 의한 텍스트-투-텍스트 전송 트랜스포머 (T5)</a></li>\n</ul>\n<p>구체적인 개념:</p>\n<ul>\n<li><a href=\"https://towardsdatascience.com/a-guide-to-word-embeddings-8a23817ab60f\" rel=\"nofollow\" target=\"_blank\">단어 임베딩 설명 - Towards Data Science</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Cosine_similarity\" rel=\"nofollow\" target=\"_blank\">코사인 유사도 - 위키백과</a></li>\n<li><a href=\"https://huggingface.co/docs/transformers/en/training\" rel=\"nofollow\" target=\"_blank\">트랜스포머로 파인 튜닝 - Hugging Face</a></li>\n<li><a href=\"https://huggingface.co/docs/transformers/en/tasks/prompting\" rel=\"nofollow\" target=\"_blank\">대형 언어 모델을 위한 좋은 프롬프트 작성 방법 - Hugging Face</a></li>\n<li><a href=\"https://chatbotsmagazine.com/the-complete-beginner-s-guide-to-chatbots-8280b7b906ca\" rel=\"nofollow\" target=\"_blank\">챗봇의 종류 - Chatbots Magazine</a></li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}