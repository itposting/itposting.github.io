{"pageProps":{"post":{"title":"작은 기계 학습 - 포아송 회귀","description":"","date":"2024-06-20 16:45","slug":"2024-06-20-TinyMLPoissonRegression","content":"\n\n수학적 기초부터 엣지 구현까지\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 Research group: Conecta.ai (ufrn.br)\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_0.png)\n\n<div class=\"content-ad\"></div>\n\n## 요약\n\n# 1 — 포아송 회귀 이론\n\n포아송 회귀 모형은 결과가 발생 횟수인 이벤트를 묘사하는 데 사용됩니다: 무양한 정수 값의 이산 데이터로, 어떤 일이 어느 기간 동안 몇 번 발생하는지나 슈퍼마켓 대기 줄에 있는 사람 수와 같이 무양한 것을 계산합니다.\n\n계수 데이터는 비율 데이터로도 표현될 수 있으며, 어떤 일이 특정 기간 내에 몇 번 발생하는지를 순수한 개수로 표현할 수 있습니다. 예를 들어, 하루에 세 끼 식사를 합니다.\n\n<div class=\"content-ad\"></div>\n\nPoisson 회귀는 카운트 데이터와 비율 데이터를 분석하는 데 도움이 되며, 특정 응답 변수 Y에 영향을 미치는 설명 변수가 무엇인지를 확인할 수 있습니다. 예를 들어, 슈퍼마켓은 포아송 회귀를 사용하여 대기줄에 있는 사람 수를 더 잘 이해하고 예측할 수 있습니다.\n\n포아송 분포는 특정 시간 동안 이벤트 또는 이벤트 Y가 발생할 확률을 모델링하며, 이때 발생하는 Y는 이전 Y의 발생 시기에 영향을 받지 않는다고 가정합니다. 이를 수학적으로 표현하면 다음과 같습니다:\n\n\\[P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\]\n\n여기서 y = 0,1,2,⋯.\n\n<div class=\"content-ad\"></div>\n\n여기서 μ는 노출 단위당 이벤트가 발생할 평균 횟수입니다. Poisson 분포 매개 변수로도 언급됩니다. 노출은 시간, 공간, 인구 규모, 거리 또는 면적이 될 수 있지만 일반적으로 시간으로 가정되며, (t)로 표시됩니다. 노출 값이 제공되지 않으면 1로 가정됩니다.\n\n## 1.1 — 가정\n\nPoisson 회귀는 통계 모델과 마찬가지로 모델 사용 및 결과 해석 시 고려해야 할 특정 가정이 있습니다. 다음은 Poisson 회귀의 주요 가정입니다:\n\nA. 관측치의 독립성: 관측치는 서로 독립적이어야 합니다. 이것은 한 관측치에서 이벤트의 발생이 다른 관측치에서 이벤트의 발생에 영향을 미치지 않아야 함을 의미합니다. 관측치 간의 의존성이 있으면 편향된 매개변수 추정치와 잘못된 추론으로 이어질 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nB. 매개변수의 선형성: 독립 변수와 포아송 분포의 로그 변환된 평균 간의 관계는 선형이어야 합니다. 이 가정은 각 독립 변수가 종속 변수에 미치는 효과가 독립 변수의 다른 값에 걸쳐 일정함을 의미합니다.\n\nC. 오버디스퍼전스의 부재: 포아송 회귀는 종속 변수의 분산이 평균과 동일하다는 것을 가정합니다. 그러나 현실 세계에서는 분산이 평균을 초과하는 오버디스퍼전스라고 알려진 상황을 자주 만납니다. 만약 오버디스퍼전스가 존재한다면, 비효율적인 매개변수 추정과 과소평가된 표준 오차로 이어질 수 있습니다.\n\nD. 모델의 올바른 명세: 모델에 모든 관련 독립 변수를 포함하고 모델의 기능적 형태를 올바르게 명세하는 것이 중요합니다. 중요한 변수를 빠뜨리거나 잘못된 기능적 형태를 사용하는 경우 편향된 매개변수 추정과 부정확한 예측을 유발할 수 있습니다.\n\nE. 계수 데이터: 포아송 회귀는 발생 이벤트 수를 나타내는 종속 변수가 고정된 시간 또는 공간 단위 내에 발생하는 경우에 대한 계수 데이터를 모델링하는 데 적합합니다. 비계수 데이터에 포아송 회귀를 사용하는 것은 모델의 기본 가정을 위반하고 신뢰할 수 없는 결과를 초래할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nF. 다중공선성 없음: 독립 변수들 간에 다중공선성이 없어야 합니다. 다중공선성은 두 개 이상의 독립 변수가 높은 상관 관계를 가질 때 발생하며, 종속 변수에 대한 개별적인 영향을 추정하기 어렵게 만듭니다. 높은 다중공선성은 표준 오차를 과대폭으로 증폭시키고 추정 매개변수를 불안정하게 만들 수 있습니다.\n\nG. 이상치 없음: 데이터의 이상치는 매개변수 추정치에 불필요한 영향을 미치고 모형의 전체적인 적합도에 영향을 줄 수 있습니다. 회귀 결과의 타당성을 보장하기 위해 이상치를 식별하고 적절히 처리하는 것이 중요합니다.\n\n## 1.2— 모형\n\nGeneralized Linear Models(GLM)은 반응 변수가 정규 분포가 아닌 분포를 따르는 모형입니다. 이는 반응 변수가 Yes, No와 같이 범주형이며 −∞부터 +∞까지 범위가 아닌 모형에서 선형 회귀 모형과 대조적입니다.\n\n<div class=\"content-ad\"></div>\n\n따라서, 응답과 예측 변수 간의 관계가 선형일 필요는 없을 수 있습니다. 일반화 선형 모형에서는:\n\n![image](/assets/img/2024-06-20-TinyMLPoissonRegression_2.png)\n\n여기서 g(⋅)는 선택한 링크 함수를 나타냅니다.\n\n포아송 회귀 모형은 카운트 데이터 및 분할표를 모델링하는 데 사용되는 일반화 선형 모형입니다. 출력인 Y(카운트)는 포아송 분포를 따르는 값입니다. 이는 예상 값(평균)의 로그를 전제로 하며, 이를 일부 알려지지 않은 매개변수로 선형 형태로 모델링할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n비선형 관계를 선형 형태로 변환하기 위해 링크 함수가 사용됩니다. 이 함수는 포아송 회귀의 로그입니다. 이로 인해 포아송 회귀 모델은 종종 로그-선형 모델이라고도 불립니다. 포아송 회귀 모델의 일반적인 수학적 형태는 다음과 같습니다:\n\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_3.png\" />\n\n\n여기서 μi는 반응 변수 Yi의 기대값입니다.\n\n계수 α와 β는 수치이며, 여기서 α는 절편을 나타내며 때로는 α는 β0으로도 표시됩니다. x는 예측 변수 또는 설명 변수입니다.\n\n<div class=\"content-ad\"></div>\n\n한 개의 예측 변수(predictor variable)와 한 개의 응답 변수(response variable)를 갖는 방정식을 고려해 봅시다:\n\n![equation1](/assets/img/2024-06-20-TinyMLPoissonRegression_4.png)\n\n이는 다음과 동일합니다:\n\n![equation2](/assets/img/2024-06-20-TinyMLPoissonRegression_5.png)\n\n<div class=\"content-ad\"></div>\n\n포아송 회귀 모형에서 설명변수는 수치값 또는 범주값의 조합을 가질 수 있습니다.\n\n포아송 분포와 포아송 회귀의 가장 중요한 특징 중 하나는 등분산성입니다. 이는 분포의 평균과 분산이 같음을 의미합니다.\n\n평균을 μ라고 가정해보겠습니다. 포아송 회귀에서는 평균과 분산이 다음과 같이 관련되어 있습니다:\n\n![equation](/assets/img/2024-06-20-TinyMLPoissonRegression_6.png)\n\n<div class=\"content-ad\"></div>\n\n여기서 σ²은 분산 파라미터를 나타냅니다. 포아송 모델이 완전히 적합되려면 분산이 평균과 동일해야 합니다(var(Y) = E(Y)) 즉, σ² 값은 1이 되어야 합니다.\n\n분산이 평균보다 클 때에는 이를 초과분산(overdispersion)이라고 하며, σ² 값이 1보다 큽니다. 반면 σ² 값이 1보다 작을 때에는 이를 미달분산(underdispersion)이라고 합니다.\n\n## 1.3 — 계수 추정\n\n포아송 회귀에서는 모델 파라미터를 추정하여 독립 변수와 종속 계수 변수 간의 최적 관계를 찾습니다. 이 추정은 주로 최대 우도법을 사용하여 수행됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 1.3.1 — 최대 우도 방법 (Maximum Likelihood Method, MLM)\n\n최대 우도 방법은 통계 모델의 매개 변수를 추정하기 위한 널리 사용되는 통계 기법입니다. 이 방법은 관측된 데이터의 우도를 극대화하는 매개 변수 값을 찾습니다. 즉, 우리는 제안된 모델에 의해 생성되었을 가능성이 가장 높은 관측된 데이터를 만드는 매개 변수를 찾습니다.\n\n포아송 회귀 분석에서 우도 함수는 각 개별 관측을 위한 관측된 횟수를 관측 확률의 곱으로 정의됩니다. 형식적으로, 우도 함수 L(β0, β1,…, βp)는 다음과 같이 주어집니다:\n\n<div class=\"content-ad\"></div>\n\n여기에 있습니다:\n\n- n은 총 관측값의 수입니다.\n- yi는 i번째 관측값의 관측된 수입니다.\n- μi는 i번째 관측값에 해당하는 이론적 평균으로, 로그 링크 함수에 의해 주어집니다.\n\n파라미터 추정의 목표는 우도 함수를 최대화하는 계수 β0, β1,..., βp의 값을 찾는 것입니다. 다시 말해, 우리는 관측된 데이터가 포아송 회귀 모델에 의해 생성되었을 가능성이 가장 높은 매개변수를 찾습니다.\n\n# 2 — TinyML 구현\n\n<div class=\"content-ad\"></div>\n\n위의 예시를 통해 ESP32, Arduino, Arduino Portenta H7 with Vision Shield, Raspberry 및 다른 다양한 마이크로컨트롤러 또는 IoT 기기에서 머신러닝 알고리즘을 구현할 수 있습니다.\n\n2.0 — requirements.txt 파일에 나열된 라이브러리를 설치하세요\n\n```js\n!pip install -r requirements.txt\n```\n\n2.1 — 라이브러리 가져오기\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import PoissonRegressor\nfrom sklearn.metrics import (\n    mean_absolute_error,\n    mean_poisson_deviance,\n    mean_squared_error,\n)\n\nimport m2cgen as m2c\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom matplotlib import pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n\n2.2 — 데이터셋 로드\n\n“차량 속성 및 배출 데이터셋”은 2000년에 제조된 다양한 차량에 대한 포괄적인 정보를 포함하고 있습니다. 이 데이터셋에는 제조사, 모델, 차량 클래스, 엔진 크기, 실린더 수, 변속기 유형 및 연료 유형과 같은 세부 정보가 포함되어 있습니다. 또한 연료 소비 및 이산화탄소 배출에 대한 범위를 제공하여 각 차량의 환경 영향에 대한 통찰을 제공합니다. 이 데이터셋은 소형부터 중형까지 다양한 차종을 포함하며, 전통적인 모델부터 고성능 모델까지 모두 포함하고 있습니다. 이 정보를 통해 분석가와 연구자는 차량 특성, 연료 효율성 및 배출 추세를 연구할 수 있습니다. 이 데이터셋은 자동차 산업 환경을 이해하고 환경 지속 가능성 및 교통 정책에 대한 논의에 정보를 제공하는 소중한 자료원으로 사용됩니다.\n\n링크: https://www.kaggle.com/datasets/krupadharamshi/fuelconsumption/data\n\n\n<div class=\"content-ad\"></div>\n\n```python\ndf = pd.read_csv('./data/FuelConsumption.csv')\ndf.head()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_8.png\" />\n\n```python\ndf.info()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_9.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n```js\ndf.describe()\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_10.png)\n\n2.3 — 데이터 정리\n\n```js\n# 1. 결측값이 있는 행 제거\ndf.dropna(inplace=True)\n# 2. 중복값 제거\ndf.drop_duplicates(inplace=True)\n```\n\n<div class=\"content-ad\"></div>\n\n\n# 데이터 프레임 정리 후에 결과 표시\ndf.describe()\n\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_11.png)\n\n2.4 — 탐색적 데이터 분석\n\n```python\nsns.pairplot(df[['ENGINE SIZE','CYLINDERS','FUEL CONSUMPTION','COEMISSIONS ']])\nplt.savefig('.\\\\figures\\\\pairplot.png', dpi=300, bbox_inches='tight')\n```\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_12.png\" />\n\n```js\ncorr = df[['ENGINE SIZE','CYLINDERS','FUEL CONSUMPTION','COEMISSIONS ']].corr('spearman')\n```\n\n```js\n# 그림 크기 조절\nplt.figure(figsize=(18,10))\n# 히트맵 생성을 위한 기존 코드\nheatmap = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap='coolwarm')\n# 히트맵에 값 추가\nfor i in range(len(corr.columns)):\n    for j in range(len(corr.columns)):\n        plt.text(j + 0.5, i + 0.5, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', color='black', fontsize=18)\n\nplt.xticks(fontsize=20, rotation=45)\nplt.yticks(fontsize=20, rotation=0)\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(labelsize=20)\n\nplt.savefig('.\\\\figures\\\\heatmap.png', dpi=300, bbox_inches='tight')\n\n# 히트맵 표시\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_13.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n2.5— 훈련 및 테스트 데이터로 분할하기\n\n```js\nX=df[['엔진 크기','실린더', 'CO2 배출량']]\ny=df[['연료 소비']]\n```\n\n```js\n# 데이터를 훈련 세트와 테스트 세트로 분할하기\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n```\n\n2.6 — 회귀 모델 생성하기\n\n<div class=\"content-ad\"></div>\n\n```js\ndef score_estimator(y_pred , y_true):\n\n    print(\n        \"MSE: %.3f\"\n        % mean_squared_error(\n            y_true, y_pred\n        )\n    )\n    print(\n        \"MAE: %.3f\"\n        % mean_absolute_error(\n            y_true, y_pred, \n        )\n    )\n\n    # 푸아송 손실을 계산할 때, 유효하지 않은 비 양수 예측을 무시합니다.\n    mask = y_pred > 0\n    if (~mask).any():\n        n_masked, n_samples = (~mask).sum(), mask.shape[0]\n        print(\n            \"경고: 추정자가 푸아송 손실을 계산할 때, %s개의 샘플 중 %s개의 비 유효한, 비 양수 예측 값이 있습니다. 이러한 예측 값은 푸아송 손실을 계산할 때 무시됩니다.\"\n            % (n_samples, n_masked)\n        )\n\n    print(\n        \"평균 푸아송 손실: %.3f\"\n        % mean_poisson_deviance(\n            y_true ,\n            y_pred  \n        )\n    )\n```\n\n```js\nmodel = PoissonRegressor(alpha=1e-12)\n```\n\n2.7 — 모델 학습\n\n```js\nmodel.fit(X_train, y_train)\n```\n\n<div class=\"content-ad\"></div>\n\n2.8 — 모델 평가\n\n```js\ny_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)\n```\n\n```js\n# 잔차 계산\ntrain_residuals = y_train.values.reshape(1,-1).tolist()[0] - y_train_pred\n# 잔차의 평균과 표준 편차 계산\ntrain_residuals_mean = np.mean(train_residuals)\ntrain_residuals_std = np.std(train_residuals)\n# 잔차 계산\ntest_residuals = y_test.values.reshape(1,-1).tolist()[0] - y_test_pred\n# 잔차의 평균과 표준 편차 계산\ntest_residuals_mean = np.mean(test_residuals)\ntest_residuals_std = np.std(test_residuals)\n\n\n# 잔차 시각화\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(y_train_pred, train_residuals, c='blue', marker='o', label=f'학습 데이터')\nplt.axhline(y=0, color='r', linestyle='-')\nplt.axhline(y=train_residuals_mean, color='k', linestyle='--', label=f'평균: {train_residuals_mean:.3f}')\nplt.axhline(y=train_residuals_mean + 2 * train_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*train_residuals_std:.2f}')\nplt.axhline(y=train_residuals_mean - 2 * train_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*train_residuals_std:.2f}')  \nplt.xlabel('예측 값')\nplt.ylabel('잔차')\nplt.title('잔차 대 예측 값 (학습 데이터)')\nplt.legend(loc='upper left')\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.scatter(y_test_pred, test_residuals, c='green', marker='s', label=f'테스트 데이터')\nplt.axhline(y=0, color='r', linestyle='-')\nplt.axhline(y=test_residuals_mean, color='k', linestyle='--', label=f'평균: {test_residuals_mean:.3f}')\nplt.axhline(y=test_residuals_mean + 2 * test_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*test_residuals_std:.2f}')\nplt.axhline(y=test_residuals_mean - 2 * test_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*test_residuals_std:.2f}')  \nplt.xlabel('예측 값')\nplt.ylabel('잔차')\nplt.title('잔차 대 예측 값 (테스트 데이터)')\nplt.legend(loc='upper left')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n# 정규성 확인\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.hist(train_residuals, bins=20, color='blue', alpha=0.6)\nplt.title('잔차 히스토그램 (학습 데이터)')\nplt.xlabel('잔차')\nplt.ylabel('빈도')\nplt.axvline(x=train_residuals_mean, color='k', linestyle='--', label=f'평균: {train_residuals_mean:.3f}')\nplt.axvline(x=train_residuals_mean + 2 * train_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*train_residuals_std:.3f}')\nplt.axvline(x=train_residuals_mean - 2 * train_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*train_residuals_std:.3f}')  \nplt.legend(loc='upper right')\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.hist(test_residuals, bins=20, color='green', alpha=0.6)\nplt.title('잔차 히스토그램 (테스트 데이터)')\nplt.xlabel('잔차')\nplt.ylabel('빈도')\nplt.axvline(x=test_residuals_mean, color='k', linestyle='--', label=f'평균: {test_residuals_mean:.3f}')\nplt.axvline(x=test_residuals_mean + 2 * test_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*test_residuals_std:.3f}')\nplt.axvline(x=test_residuals_mean - 2 * test_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*test_residuals_std:.3f}')  \nplt.legend(loc='upper right')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! 요청하신 내용을 한국어로 번역해 드리겠습니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_15.png)\n\n2.8.1 — 훈련 데이터로 모델 평가하기\n\n```js\nprint(\"PoissonRegressor 평가:\")\nscore_estimator(y_train_pred, y_train)\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_16.png)\n\n<div class=\"content-ad\"></div>\n\n```js\nplt.plot(y_train.values, label=\"원본\")\nplt.plot(y_train_pred, label=\"예측\")\nplt.legend(loc='best', fancybox=True, shadow=True)\nplt.grid()\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_17.png)\n\n2.8.2 — 테스트 데이터로 모델 평가\n\n```js\nprint(\"PoissonRegressor 평가:\")\nscore_estimator(y_test_pred, y_test)\n```\n\n<div class=\"content-ad\"></div>\n\n![2024-06-20-TinyMLPoissonRegression_18.png](/assets/img/2024-06-20-TinyMLPoissonRegression_18.png)\n\n```js\nplt.plot(y_test.values, label=\"original\")\nplt.plot(y_test_pred, label=\"predicted\")\nplt.legend(loc='best', fancybox=True, shadow=True)\nplt.grid()\n```\n\n![2024-06-20-TinyMLPoissonRegression_19.png](/assets/img/2024-06-20-TinyMLPoissonRegression_19.png)\n\n2.9 — Microcontroller에 구현될 모델 얻기\n\n<div class=\"content-ad\"></div>\n\n```js\ncode = m2c.export_to_c(model)\nprint(code)\n```\n\n```js\n#include <math.h>\ndouble score(double *input)\n{\n    return exp(1.7347124654302846 + input[0] * 0.011406244946132144 + input[1] * 0.01010646886054758 + input[2] * 0.0028201461971878914);\n}\n```\n\n2.10— .h 파일에 템플릿 저장\n\n```js\nwith open('./PoissonRegressor.h', 'w') as file:\n    file.write(code)\n```\n\n<div class=\"content-ad\"></div>\n\n## 2.11 — 모델 배포\n\n2.11.1 — 아두이노 스케치 완성\n\n```js\n#include \"PoissonRegressor.h\"\n\nEloquent::ML::Port::PoissonRegressor PoissonRegressor;\n\nvoid setup()\n{\n  Serial.begin(115200);\n}\n\nvoid loop()\n{\n  float X_1[] = {6., 2.7, 5.1, 1.6};\n  int result_1 = PoissonRegressor.predict(X_1);\n  Serial.print(\"X1을 입력으로 한 예측 결과(실제 값 = 1):\");\n  Serial.println(result_1);\n  delay(2000);\n\n  float X_2[] = {4.8, 3.1, 1.6, 0.2};\n  int result_2 = PoissonRegressor.predict(X_2);\n  Serial.print(\"X2을 입력으로 한 예측 결과(실제 값 = 0):\");\n  Serial.println(result_2);\n  delay(2000);\n}\n```\n\n2.12 — 결과\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_20.png)\n\n전체 프로젝트: TinyML/15_Poisson_Regressor at main · thommaskevin/TinyML (github.com)\n\n## 만약 마음에 드신다면 제게 커피 한 잔 사주세요 ☕️💰 (Bitcoin)\n\n코드: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-20-TinyMLPoissonRegression_21.png)\n","ogImage":{"url":"/assets/img/2024-06-20-TinyMLPoissonRegression_0.png"},"coverImage":"/assets/img/2024-06-20-TinyMLPoissonRegression_0.png","tag":["Tech"],"readingTime":15},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>수학적 기초부터 엣지 구현까지</p>\n<h1>소셜 미디어:</h1>\n<p>👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 Research group: Conecta.ai (ufrn.br)</p>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_0.png\" alt=\"이미지\"></p>\n<div class=\"content-ad\"></div>\n<h2>요약</h2>\n<h1>1 — 포아송 회귀 이론</h1>\n<p>포아송 회귀 모형은 결과가 발생 횟수인 이벤트를 묘사하는 데 사용됩니다: 무양한 정수 값의 이산 데이터로, 어떤 일이 어느 기간 동안 몇 번 발생하는지나 슈퍼마켓 대기 줄에 있는 사람 수와 같이 무양한 것을 계산합니다.</p>\n<p>계수 데이터는 비율 데이터로도 표현될 수 있으며, 어떤 일이 특정 기간 내에 몇 번 발생하는지를 순수한 개수로 표현할 수 있습니다. 예를 들어, 하루에 세 끼 식사를 합니다.</p>\n<div class=\"content-ad\"></div>\n<p>Poisson 회귀는 카운트 데이터와 비율 데이터를 분석하는 데 도움이 되며, 특정 응답 변수 Y에 영향을 미치는 설명 변수가 무엇인지를 확인할 수 있습니다. 예를 들어, 슈퍼마켓은 포아송 회귀를 사용하여 대기줄에 있는 사람 수를 더 잘 이해하고 예측할 수 있습니다.</p>\n<p>포아송 분포는 특정 시간 동안 이벤트 또는 이벤트 Y가 발생할 확률을 모델링하며, 이때 발생하는 Y는 이전 Y의 발생 시기에 영향을 받지 않는다고 가정합니다. 이를 수학적으로 표현하면 다음과 같습니다:</p>\n<p>[P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}]</p>\n<p>여기서 y = 0,1,2,⋯.</p>\n<div class=\"content-ad\"></div>\n<p>여기서 μ는 노출 단위당 이벤트가 발생할 평균 횟수입니다. Poisson 분포 매개 변수로도 언급됩니다. 노출은 시간, 공간, 인구 규모, 거리 또는 면적이 될 수 있지만 일반적으로 시간으로 가정되며, (t)로 표시됩니다. 노출 값이 제공되지 않으면 1로 가정됩니다.</p>\n<h2>1.1 — 가정</h2>\n<p>Poisson 회귀는 통계 모델과 마찬가지로 모델 사용 및 결과 해석 시 고려해야 할 특정 가정이 있습니다. 다음은 Poisson 회귀의 주요 가정입니다:</p>\n<p>A. 관측치의 독립성: 관측치는 서로 독립적이어야 합니다. 이것은 한 관측치에서 이벤트의 발생이 다른 관측치에서 이벤트의 발생에 영향을 미치지 않아야 함을 의미합니다. 관측치 간의 의존성이 있으면 편향된 매개변수 추정치와 잘못된 추론으로 이어질 수 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>B. 매개변수의 선형성: 독립 변수와 포아송 분포의 로그 변환된 평균 간의 관계는 선형이어야 합니다. 이 가정은 각 독립 변수가 종속 변수에 미치는 효과가 독립 변수의 다른 값에 걸쳐 일정함을 의미합니다.</p>\n<p>C. 오버디스퍼전스의 부재: 포아송 회귀는 종속 변수의 분산이 평균과 동일하다는 것을 가정합니다. 그러나 현실 세계에서는 분산이 평균을 초과하는 오버디스퍼전스라고 알려진 상황을 자주 만납니다. 만약 오버디스퍼전스가 존재한다면, 비효율적인 매개변수 추정과 과소평가된 표준 오차로 이어질 수 있습니다.</p>\n<p>D. 모델의 올바른 명세: 모델에 모든 관련 독립 변수를 포함하고 모델의 기능적 형태를 올바르게 명세하는 것이 중요합니다. 중요한 변수를 빠뜨리거나 잘못된 기능적 형태를 사용하는 경우 편향된 매개변수 추정과 부정확한 예측을 유발할 수 있습니다.</p>\n<p>E. 계수 데이터: 포아송 회귀는 발생 이벤트 수를 나타내는 종속 변수가 고정된 시간 또는 공간 단위 내에 발생하는 경우에 대한 계수 데이터를 모델링하는 데 적합합니다. 비계수 데이터에 포아송 회귀를 사용하는 것은 모델의 기본 가정을 위반하고 신뢰할 수 없는 결과를 초래할 수 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>F. 다중공선성 없음: 독립 변수들 간에 다중공선성이 없어야 합니다. 다중공선성은 두 개 이상의 독립 변수가 높은 상관 관계를 가질 때 발생하며, 종속 변수에 대한 개별적인 영향을 추정하기 어렵게 만듭니다. 높은 다중공선성은 표준 오차를 과대폭으로 증폭시키고 추정 매개변수를 불안정하게 만들 수 있습니다.</p>\n<p>G. 이상치 없음: 데이터의 이상치는 매개변수 추정치에 불필요한 영향을 미치고 모형의 전체적인 적합도에 영향을 줄 수 있습니다. 회귀 결과의 타당성을 보장하기 위해 이상치를 식별하고 적절히 처리하는 것이 중요합니다.</p>\n<h2>1.2— 모형</h2>\n<p>Generalized Linear Models(GLM)은 반응 변수가 정규 분포가 아닌 분포를 따르는 모형입니다. 이는 반응 변수가 Yes, No와 같이 범주형이며 −∞부터 +∞까지 범위가 아닌 모형에서 선형 회귀 모형과 대조적입니다.</p>\n<div class=\"content-ad\"></div>\n<p>따라서, 응답과 예측 변수 간의 관계가 선형일 필요는 없을 수 있습니다. 일반화 선형 모형에서는:</p>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_2.png\" alt=\"image\"></p>\n<p>여기서 g(⋅)는 선택한 링크 함수를 나타냅니다.</p>\n<p>포아송 회귀 모형은 카운트 데이터 및 분할표를 모델링하는 데 사용되는 일반화 선형 모형입니다. 출력인 Y(카운트)는 포아송 분포를 따르는 값입니다. 이는 예상 값(평균)의 로그를 전제로 하며, 이를 일부 알려지지 않은 매개변수로 선형 형태로 모델링할 수 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>비선형 관계를 선형 형태로 변환하기 위해 링크 함수가 사용됩니다. 이 함수는 포아송 회귀의 로그입니다. 이로 인해 포아송 회귀 모델은 종종 로그-선형 모델이라고도 불립니다. 포아송 회귀 모델의 일반적인 수학적 형태는 다음과 같습니다:</p>\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_3.png\">\n<p>여기서 μi는 반응 변수 Yi의 기대값입니다.</p>\n<p>계수 α와 β는 수치이며, 여기서 α는 절편을 나타내며 때로는 α는 β0으로도 표시됩니다. x는 예측 변수 또는 설명 변수입니다.</p>\n<div class=\"content-ad\"></div>\n<p>한 개의 예측 변수(predictor variable)와 한 개의 응답 변수(response variable)를 갖는 방정식을 고려해 봅시다:</p>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_4.png\" alt=\"equation1\"></p>\n<p>이는 다음과 동일합니다:</p>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_5.png\" alt=\"equation2\"></p>\n<div class=\"content-ad\"></div>\n<p>포아송 회귀 모형에서 설명변수는 수치값 또는 범주값의 조합을 가질 수 있습니다.</p>\n<p>포아송 분포와 포아송 회귀의 가장 중요한 특징 중 하나는 등분산성입니다. 이는 분포의 평균과 분산이 같음을 의미합니다.</p>\n<p>평균을 μ라고 가정해보겠습니다. 포아송 회귀에서는 평균과 분산이 다음과 같이 관련되어 있습니다:</p>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_6.png\" alt=\"equation\"></p>\n<div class=\"content-ad\"></div>\n<p>여기서 σ²은 분산 파라미터를 나타냅니다. 포아송 모델이 완전히 적합되려면 분산이 평균과 동일해야 합니다(var(Y) = E(Y)) 즉, σ² 값은 1이 되어야 합니다.</p>\n<p>분산이 평균보다 클 때에는 이를 초과분산(overdispersion)이라고 하며, σ² 값이 1보다 큽니다. 반면 σ² 값이 1보다 작을 때에는 이를 미달분산(underdispersion)이라고 합니다.</p>\n<h2>1.3 — 계수 추정</h2>\n<p>포아송 회귀에서는 모델 파라미터를 추정하여 독립 변수와 종속 계수 변수 간의 최적 관계를 찾습니다. 이 추정은 주로 최대 우도법을 사용하여 수행됩니다.</p>\n<div class=\"content-ad\"></div>\n<h2>1.3.1 — 최대 우도 방법 (Maximum Likelihood Method, MLM)</h2>\n<p>최대 우도 방법은 통계 모델의 매개 변수를 추정하기 위한 널리 사용되는 통계 기법입니다. 이 방법은 관측된 데이터의 우도를 극대화하는 매개 변수 값을 찾습니다. 즉, 우리는 제안된 모델에 의해 생성되었을 가능성이 가장 높은 관측된 데이터를 만드는 매개 변수를 찾습니다.</p>\n<p>포아송 회귀 분석에서 우도 함수는 각 개별 관측을 위한 관측된 횟수를 관측 확률의 곱으로 정의됩니다. 형식적으로, 우도 함수 L(β0, β1,…, βp)는 다음과 같이 주어집니다:</p>\n<div class=\"content-ad\"></div>\n<p>여기에 있습니다:</p>\n<ul>\n<li>n은 총 관측값의 수입니다.</li>\n<li>yi는 i번째 관측값의 관측된 수입니다.</li>\n<li>μi는 i번째 관측값에 해당하는 이론적 평균으로, 로그 링크 함수에 의해 주어집니다.</li>\n</ul>\n<p>파라미터 추정의 목표는 우도 함수를 최대화하는 계수 β0, β1,..., βp의 값을 찾는 것입니다. 다시 말해, 우리는 관측된 데이터가 포아송 회귀 모델에 의해 생성되었을 가능성이 가장 높은 매개변수를 찾습니다.</p>\n<h1>2 — TinyML 구현</h1>\n<div class=\"content-ad\"></div>\n<p>위의 예시를 통해 ESP32, Arduino, Arduino Portenta H7 with Vision Shield, Raspberry 및 다른 다양한 마이크로컨트롤러 또는 IoT 기기에서 머신러닝 알고리즘을 구현할 수 있습니다.</p>\n<p>2.0 — requirements.txt 파일에 나열된 라이브러리를 설치하세요</p>\n<pre><code class=\"hljs language-js\">!pip install -r requirements.<span class=\"hljs-property\">txt</span>\n</code></pre>\n<p>2.1 — 라이브러리 가져오기</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> sklearn.model_selection <span class=\"hljs-keyword\">import</span> train_test_split\n<span class=\"hljs-keyword\">from</span> sklearn.linear_model <span class=\"hljs-keyword\">import</span> PoissonRegressor\n<span class=\"hljs-keyword\">from</span> sklearn.metrics <span class=\"hljs-keyword\">import</span> (\n    mean_absolute_error,\n    mean_poisson_deviance,\n    mean_squared_error,\n)\n\n<span class=\"hljs-keyword\">import</span> m2cgen <span class=\"hljs-keyword\">as</span> m2c\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> seaborn <span class=\"hljs-keyword\">as</span> sns\n\n<span class=\"hljs-keyword\">from</span> matplotlib <span class=\"hljs-keyword\">import</span> pyplot <span class=\"hljs-keyword\">as</span> plt\n\n<span class=\"hljs-keyword\">import</span> warnings\nwarnings.filterwarnings(<span class=\"hljs-string\">'ignore'</span>)\n</code></pre>\n<p>2.2 — 데이터셋 로드</p>\n<p>“차량 속성 및 배출 데이터셋”은 2000년에 제조된 다양한 차량에 대한 포괄적인 정보를 포함하고 있습니다. 이 데이터셋에는 제조사, 모델, 차량 클래스, 엔진 크기, 실린더 수, 변속기 유형 및 연료 유형과 같은 세부 정보가 포함되어 있습니다. 또한 연료 소비 및 이산화탄소 배출에 대한 범위를 제공하여 각 차량의 환경 영향에 대한 통찰을 제공합니다. 이 데이터셋은 소형부터 중형까지 다양한 차종을 포함하며, 전통적인 모델부터 고성능 모델까지 모두 포함하고 있습니다. 이 정보를 통해 분석가와 연구자는 차량 특성, 연료 효율성 및 배출 추세를 연구할 수 있습니다. 이 데이터셋은 자동차 산업 환경을 이해하고 환경 지속 가능성 및 교통 정책에 대한 논의에 정보를 제공하는 소중한 자료원으로 사용됩니다.</p>\n<p>링크: <a href=\"https://www.kaggle.com/datasets/krupadharamshi/fuelconsumption/data\" rel=\"nofollow\" target=\"_blank\">https://www.kaggle.com/datasets/krupadharamshi/fuelconsumption/data</a></p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-python\">df = pd.read_csv(<span class=\"hljs-string\">'./data/FuelConsumption.csv'</span>)\ndf.head()\n</code></pre>\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_8.png\">\n<pre><code class=\"hljs language-python\">df.info()\n</code></pre>\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_9.png\">\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">df.<span class=\"hljs-title function_\">describe</span>()\n</code></pre>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_10.png\" alt=\"이미지\"></p>\n<p>2.3 — 데이터 정리</p>\n<pre><code class=\"hljs language-js\"># <span class=\"hljs-number\">1.</span> 결측값이 있는 행 제거\ndf.<span class=\"hljs-title function_\">dropna</span>(inplace=<span class=\"hljs-title class_\">True</span>)\n# <span class=\"hljs-number\">2.</span> 중복값 제거\ndf.<span class=\"hljs-title function_\">drop_duplicates</span>(inplace=<span class=\"hljs-title class_\">True</span>)\n</code></pre>\n<div class=\"content-ad\"></div>\n<h1>데이터 프레임 정리 후에 결과 표시</h1>\n<p>df.describe()</p>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_11.png\" alt=\"이미지\"></p>\n<p>2.4 — 탐색적 데이터 분석</p>\n<pre><code class=\"hljs language-python\">sns.pairplot(df[[<span class=\"hljs-string\">'ENGINE SIZE'</span>,<span class=\"hljs-string\">'CYLINDERS'</span>,<span class=\"hljs-string\">'FUEL CONSUMPTION'</span>,<span class=\"hljs-string\">'COEMISSIONS '</span>]])\nplt.savefig(<span class=\"hljs-string\">'.\\\\figures\\\\pairplot.png'</span>, dpi=<span class=\"hljs-number\">300</span>, bbox_inches=<span class=\"hljs-string\">'tight'</span>)\n</code></pre>\n<div class=\"content-ad\"></div>\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_12.png\">\n<pre><code class=\"hljs language-js\">corr = df[[<span class=\"hljs-string\">'ENGINE SIZE'</span>,<span class=\"hljs-string\">'CYLINDERS'</span>,<span class=\"hljs-string\">'FUEL CONSUMPTION'</span>,<span class=\"hljs-string\">'COEMISSIONS '</span>]].<span class=\"hljs-title function_\">corr</span>(<span class=\"hljs-string\">'spearman'</span>)\n</code></pre>\n<pre><code class=\"hljs language-js\"># 그림 크기 조절\nplt.<span class=\"hljs-title function_\">figure</span>(figsize=(<span class=\"hljs-number\">18</span>,<span class=\"hljs-number\">10</span>))\n# 히트맵 생성을 위한 기존 코드\nheatmap = sns.<span class=\"hljs-title function_\">heatmap</span>(corr, xticklabels=corr.<span class=\"hljs-property\">columns</span>, yticklabels=corr.<span class=\"hljs-property\">columns</span>, cmap=<span class=\"hljs-string\">'coolwarm'</span>)\n# 히트맵에 값 추가\n<span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-title function_\">len</span>(corr.<span class=\"hljs-property\">columns</span>)):\n    <span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-title function_\">range</span>(<span class=\"hljs-title function_\">len</span>(corr.<span class=\"hljs-property\">columns</span>)):\n        plt.<span class=\"hljs-title function_\">text</span>(j + <span class=\"hljs-number\">0.5</span>, i + <span class=\"hljs-number\">0.5</span>, f<span class=\"hljs-string\">\"{corr.iloc[i, j]:.2f}\"</span>, ha=<span class=\"hljs-string\">'center'</span>, va=<span class=\"hljs-string\">'center'</span>, color=<span class=\"hljs-string\">'black'</span>, fontsize=<span class=\"hljs-number\">18</span>)\n\nplt.<span class=\"hljs-title function_\">xticks</span>(fontsize=<span class=\"hljs-number\">20</span>, rotation=<span class=\"hljs-number\">45</span>)\nplt.<span class=\"hljs-title function_\">yticks</span>(fontsize=<span class=\"hljs-number\">20</span>, rotation=<span class=\"hljs-number\">0</span>)\ncbar = heatmap.<span class=\"hljs-property\">collections</span>[<span class=\"hljs-number\">0</span>].<span class=\"hljs-property\">colorbar</span>\ncbar.<span class=\"hljs-property\">ax</span>.<span class=\"hljs-title function_\">tick_params</span>(labelsize=<span class=\"hljs-number\">20</span>)\n\nplt.<span class=\"hljs-title function_\">savefig</span>(<span class=\"hljs-string\">'.\\\\figures\\\\heatmap.png'</span>, dpi=<span class=\"hljs-number\">300</span>, bbox_inches=<span class=\"hljs-string\">'tight'</span>)\n\n# 히트맵 표시\nplt.<span class=\"hljs-title function_\">show</span>()\n</code></pre>\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_13.png\">\n<div class=\"content-ad\"></div>\n<p>2.5— 훈련 및 테스트 데이터로 분할하기</p>\n<pre><code class=\"hljs language-js\">X=df[[<span class=\"hljs-string\">'엔진 크기'</span>,<span class=\"hljs-string\">'실린더'</span>, <span class=\"hljs-string\">'CO2 배출량'</span>]]\ny=df[[<span class=\"hljs-string\">'연료 소비'</span>]]\n</code></pre>\n<pre><code class=\"hljs language-js\"># 데이터를 훈련 세트와 테스트 세트로 분할하기\nX_train, X_test, y_train, y_test = <span class=\"hljs-title function_\">train_test_split</span>(X, y, test_size=<span class=\"hljs-number\">0.3</span>, random_state=<span class=\"hljs-number\">42</span>)\n</code></pre>\n<p>2.6 — 회귀 모델 생성하기</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">score_estimator</span>(y_pred , y_true):\n\n    <span class=\"hljs-title function_\">print</span>(\n        <span class=\"hljs-string\">\"MSE: %.3f\"</span>\n        % <span class=\"hljs-title function_\">mean_squared_error</span>(\n            y_true, y_pred\n        )\n    )\n    <span class=\"hljs-title function_\">print</span>(\n        <span class=\"hljs-string\">\"MAE: %.3f\"</span>\n        % <span class=\"hljs-title function_\">mean_absolute_error</span>(\n            y_true, y_pred, \n        )\n    )\n\n    # 푸아송 손실을 계산할 때, 유효하지 않은 비 양수 예측을 무시합니다.\n    mask = y_pred > <span class=\"hljs-number\">0</span>\n    <span class=\"hljs-keyword\">if</span> (~mask).<span class=\"hljs-title function_\">any</span>():\n        n_masked, n_samples = (~mask).<span class=\"hljs-title function_\">sum</span>(), mask.<span class=\"hljs-property\">shape</span>[<span class=\"hljs-number\">0</span>]\n        <span class=\"hljs-title function_\">print</span>(\n            <span class=\"hljs-string\">\"경고: 추정자가 푸아송 손실을 계산할 때, %s개의 샘플 중 %s개의 비 유효한, 비 양수 예측 값이 있습니다. 이러한 예측 값은 푸아송 손실을 계산할 때 무시됩니다.\"</span>\n            % (n_samples, n_masked)\n        )\n\n    <span class=\"hljs-title function_\">print</span>(\n        <span class=\"hljs-string\">\"평균 푸아송 손실: %.3f\"</span>\n        % <span class=\"hljs-title function_\">mean_poisson_deviance</span>(\n            y_true ,\n            y_pred  \n        )\n    )\n</code></pre>\n<pre><code class=\"hljs language-js\">model = <span class=\"hljs-title class_\">PoissonRegressor</span>(alpha=<span class=\"hljs-number\">1e-12</span>)\n</code></pre>\n<p>2.7 — 모델 학습</p>\n<pre><code class=\"hljs language-js\">model.<span class=\"hljs-title function_\">fit</span>(X_train, y_train)\n</code></pre>\n<div class=\"content-ad\"></div>\n<p>2.8 — 모델 평가</p>\n<pre><code class=\"hljs language-js\">y_train_pred = model.<span class=\"hljs-title function_\">predict</span>(X_train)\ny_test_pred = model.<span class=\"hljs-title function_\">predict</span>(X_test)\n</code></pre>\n<pre><code class=\"hljs language-js\"># 잔차 계산\ntrain_residuals = y_train.<span class=\"hljs-property\">values</span>.<span class=\"hljs-title function_\">reshape</span>(<span class=\"hljs-number\">1</span>,-<span class=\"hljs-number\">1</span>).<span class=\"hljs-title function_\">tolist</span>()[<span class=\"hljs-number\">0</span>] - y_train_pred\n# 잔차의 평균과 표준 편차 계산\ntrain_residuals_mean = np.<span class=\"hljs-title function_\">mean</span>(train_residuals)\ntrain_residuals_std = np.<span class=\"hljs-title function_\">std</span>(train_residuals)\n# 잔차 계산\ntest_residuals = y_test.<span class=\"hljs-property\">values</span>.<span class=\"hljs-title function_\">reshape</span>(<span class=\"hljs-number\">1</span>,-<span class=\"hljs-number\">1</span>).<span class=\"hljs-title function_\">tolist</span>()[<span class=\"hljs-number\">0</span>] - y_test_pred\n# 잔차의 평균과 표준 편차 계산\ntest_residuals_mean = np.<span class=\"hljs-title function_\">mean</span>(test_residuals)\ntest_residuals_std = np.<span class=\"hljs-title function_\">std</span>(test_residuals)\n\n\n# 잔차 시각화\nplt.<span class=\"hljs-title function_\">figure</span>(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">5</span>))\n\nplt.<span class=\"hljs-title function_\">subplot</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>)\nplt.<span class=\"hljs-title function_\">scatter</span>(y_train_pred, train_residuals, c=<span class=\"hljs-string\">'blue'</span>, marker=<span class=\"hljs-string\">'o'</span>, label=f<span class=\"hljs-string\">'학습 데이터'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=<span class=\"hljs-number\">0</span>, color=<span class=\"hljs-string\">'r'</span>, linestyle=<span class=\"hljs-string\">'-'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=train_residuals_mean, color=<span class=\"hljs-string\">'k'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'평균: {train_residuals_mean:.3f}'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=train_residuals_mean + <span class=\"hljs-number\">2</span> * train_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'+2 표준 편차: {2*train_residuals_std:.2f}'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=train_residuals_mean - <span class=\"hljs-number\">2</span> * train_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'-2 표준 편차: {-2*train_residuals_std:.2f}'</span>)  \nplt.<span class=\"hljs-title function_\">xlabel</span>(<span class=\"hljs-string\">'예측 값'</span>)\nplt.<span class=\"hljs-title function_\">ylabel</span>(<span class=\"hljs-string\">'잔차'</span>)\nplt.<span class=\"hljs-title function_\">title</span>(<span class=\"hljs-string\">'잔차 대 예측 값 (학습 데이터)'</span>)\nplt.<span class=\"hljs-title function_\">legend</span>(loc=<span class=\"hljs-string\">'upper left'</span>)\nplt.<span class=\"hljs-title function_\">grid</span>(<span class=\"hljs-title class_\">True</span>)\n\nplt.<span class=\"hljs-title function_\">subplot</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)\nplt.<span class=\"hljs-title function_\">scatter</span>(y_test_pred, test_residuals, c=<span class=\"hljs-string\">'green'</span>, marker=<span class=\"hljs-string\">'s'</span>, label=f<span class=\"hljs-string\">'테스트 데이터'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=<span class=\"hljs-number\">0</span>, color=<span class=\"hljs-string\">'r'</span>, linestyle=<span class=\"hljs-string\">'-'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=test_residuals_mean, color=<span class=\"hljs-string\">'k'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'평균: {test_residuals_mean:.3f}'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=test_residuals_mean + <span class=\"hljs-number\">2</span> * test_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'+2 표준 편차: {2*test_residuals_std:.2f}'</span>)\nplt.<span class=\"hljs-title function_\">axhline</span>(y=test_residuals_mean - <span class=\"hljs-number\">2</span> * test_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'-2 표준 편차: {-2*test_residuals_std:.2f}'</span>)  \nplt.<span class=\"hljs-title function_\">xlabel</span>(<span class=\"hljs-string\">'예측 값'</span>)\nplt.<span class=\"hljs-title function_\">ylabel</span>(<span class=\"hljs-string\">'잔차'</span>)\nplt.<span class=\"hljs-title function_\">title</span>(<span class=\"hljs-string\">'잔차 대 예측 값 (테스트 데이터)'</span>)\nplt.<span class=\"hljs-title function_\">legend</span>(loc=<span class=\"hljs-string\">'upper left'</span>)\nplt.<span class=\"hljs-title function_\">grid</span>(<span class=\"hljs-title class_\">True</span>)\n\nplt.<span class=\"hljs-title function_\">tight_layout</span>()\nplt.<span class=\"hljs-title function_\">show</span>()\n\n\n\n# 정규성 확인\nplt.<span class=\"hljs-title function_\">figure</span>(figsize=(<span class=\"hljs-number\">10</span>, <span class=\"hljs-number\">5</span>))\n\nplt.<span class=\"hljs-title function_\">subplot</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>)\nplt.<span class=\"hljs-title function_\">hist</span>(train_residuals, bins=<span class=\"hljs-number\">20</span>, color=<span class=\"hljs-string\">'blue'</span>, alpha=<span class=\"hljs-number\">0.6</span>)\nplt.<span class=\"hljs-title function_\">title</span>(<span class=\"hljs-string\">'잔차 히스토그램 (학습 데이터)'</span>)\nplt.<span class=\"hljs-title function_\">xlabel</span>(<span class=\"hljs-string\">'잔차'</span>)\nplt.<span class=\"hljs-title function_\">ylabel</span>(<span class=\"hljs-string\">'빈도'</span>)\nplt.<span class=\"hljs-title function_\">axvline</span>(x=train_residuals_mean, color=<span class=\"hljs-string\">'k'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'평균: {train_residuals_mean:.3f}'</span>)\nplt.<span class=\"hljs-title function_\">axvline</span>(x=train_residuals_mean + <span class=\"hljs-number\">2</span> * train_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'+2 표준 편차: {2*train_residuals_std:.3f}'</span>)\nplt.<span class=\"hljs-title function_\">axvline</span>(x=train_residuals_mean - <span class=\"hljs-number\">2</span> * train_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'-2 표준 편차: {-2*train_residuals_std:.3f}'</span>)  \nplt.<span class=\"hljs-title function_\">legend</span>(loc=<span class=\"hljs-string\">'upper right'</span>)\nplt.<span class=\"hljs-title function_\">grid</span>(<span class=\"hljs-title class_\">True</span>)\n\nplt.<span class=\"hljs-title function_\">subplot</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)\nplt.<span class=\"hljs-title function_\">hist</span>(test_residuals, bins=<span class=\"hljs-number\">20</span>, color=<span class=\"hljs-string\">'green'</span>, alpha=<span class=\"hljs-number\">0.6</span>)\nplt.<span class=\"hljs-title function_\">title</span>(<span class=\"hljs-string\">'잔차 히스토그램 (테스트 데이터)'</span>)\nplt.<span class=\"hljs-title function_\">xlabel</span>(<span class=\"hljs-string\">'잔차'</span>)\nplt.<span class=\"hljs-title function_\">ylabel</span>(<span class=\"hljs-string\">'빈도'</span>)\nplt.<span class=\"hljs-title function_\">axvline</span>(x=test_residuals_mean, color=<span class=\"hljs-string\">'k'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'평균: {test_residuals_mean:.3f}'</span>)\nplt.<span class=\"hljs-title function_\">axvline</span>(x=test_residuals_mean + <span class=\"hljs-number\">2</span> * test_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'+2 표준 편차: {2*test_residuals_std:.3f}'</span>)\nplt.<span class=\"hljs-title function_\">axvline</span>(x=test_residuals_mean - <span class=\"hljs-number\">2</span> * test_residuals_std, color=<span class=\"hljs-string\">'g'</span>, linestyle=<span class=\"hljs-string\">'--'</span>, label=f<span class=\"hljs-string\">'-2 표준 편차: {-2*test_residuals_std:.3f}'</span>)  \nplt.<span class=\"hljs-title function_\">legend</span>(loc=<span class=\"hljs-string\">'upper right'</span>)\nplt.<span class=\"hljs-title function_\">grid</span>(<span class=\"hljs-title class_\">True</span>)\n\nplt.<span class=\"hljs-title function_\">tight_layout</span>()\nplt.<span class=\"hljs-title function_\">show</span>()\n</code></pre>\n<div class=\"content-ad\"></div>\n<p>안녕하세요! 요청하신 내용을 한국어로 번역해 드리겠습니다.</p>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_15.png\" alt=\"이미지\"></p>\n<p>2.8.1 — 훈련 데이터로 모델 평가하기</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"PoissonRegressor 평가:\"</span>)\n<span class=\"hljs-title function_\">score_estimator</span>(y_train_pred, y_train)\n</code></pre>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_16.png\" alt=\"이미지\"></p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">plt.<span class=\"hljs-title function_\">plot</span>(y_train.<span class=\"hljs-property\">values</span>, label=<span class=\"hljs-string\">\"원본\"</span>)\nplt.<span class=\"hljs-title function_\">plot</span>(y_train_pred, label=<span class=\"hljs-string\">\"예측\"</span>)\nplt.<span class=\"hljs-title function_\">legend</span>(loc=<span class=\"hljs-string\">'best'</span>, fancybox=<span class=\"hljs-title class_\">True</span>, shadow=<span class=\"hljs-title class_\">True</span>)\nplt.<span class=\"hljs-title function_\">grid</span>()\n</code></pre>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_17.png\" alt=\"이미지\"></p>\n<p>2.8.2 — 테스트 데이터로 모델 평가</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"PoissonRegressor 평가:\"</span>)\n<span class=\"hljs-title function_\">score_estimator</span>(y_test_pred, y_test)\n</code></pre>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_18.png\" alt=\"2024-06-20-TinyMLPoissonRegression_18.png\"></p>\n<pre><code class=\"hljs language-js\">plt.<span class=\"hljs-title function_\">plot</span>(y_test.<span class=\"hljs-property\">values</span>, label=<span class=\"hljs-string\">\"original\"</span>)\nplt.<span class=\"hljs-title function_\">plot</span>(y_test_pred, label=<span class=\"hljs-string\">\"predicted\"</span>)\nplt.<span class=\"hljs-title function_\">legend</span>(loc=<span class=\"hljs-string\">'best'</span>, fancybox=<span class=\"hljs-title class_\">True</span>, shadow=<span class=\"hljs-title class_\">True</span>)\nplt.<span class=\"hljs-title function_\">grid</span>()\n</code></pre>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_19.png\" alt=\"2024-06-20-TinyMLPoissonRegression_19.png\"></p>\n<p>2.9 — Microcontroller에 구현될 모델 얻기</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">code = m2c.<span class=\"hljs-title function_\">export_to_c</span>(model)\n<span class=\"hljs-title function_\">print</span>(code)\n</code></pre>\n<pre><code class=\"hljs language-js\">#include &#x3C;math.<span class=\"hljs-property\">h</span>>\ndouble <span class=\"hljs-title function_\">score</span>(<span class=\"hljs-params\">double *input</span>)\n{\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-title function_\">exp</span>(<span class=\"hljs-number\">1.7347124654302846</span> + input[<span class=\"hljs-number\">0</span>] * <span class=\"hljs-number\">0.011406244946132144</span> + input[<span class=\"hljs-number\">1</span>] * <span class=\"hljs-number\">0.01010646886054758</span> + input[<span class=\"hljs-number\">2</span>] * <span class=\"hljs-number\">0.0028201461971878914</span>);\n}\n</code></pre>\n<p>2.10— .h 파일에 템플릿 저장</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">with</span> <span class=\"hljs-title function_\">open</span>(<span class=\"hljs-string\">'./PoissonRegressor.h'</span>, <span class=\"hljs-string\">'w'</span>) <span class=\"hljs-keyword\">as</span> <span class=\"hljs-attr\">file</span>:\n    file.<span class=\"hljs-title function_\">write</span>(code)\n</code></pre>\n<div class=\"content-ad\"></div>\n<h2>2.11 — 모델 배포</h2>\n<p>2.11.1 — 아두이노 스케치 완성</p>\n<pre><code class=\"hljs language-js\">#include <span class=\"hljs-string\">\"PoissonRegressor.h\"</span>\n\n<span class=\"hljs-title class_\">Eloquent</span>::<span class=\"hljs-attr\">ML</span>::<span class=\"hljs-title class_\">Port</span>::<span class=\"hljs-title class_\">PoissonRegressor</span> <span class=\"hljs-title class_\">PoissonRegressor</span>;\n\n<span class=\"hljs-keyword\">void</span> <span class=\"hljs-title function_\">setup</span>(<span class=\"hljs-params\"></span>)\n{\n  <span class=\"hljs-title class_\">Serial</span>.<span class=\"hljs-title function_\">begin</span>(<span class=\"hljs-number\">115200</span>);\n}\n\n<span class=\"hljs-keyword\">void</span> <span class=\"hljs-title function_\">loop</span>(<span class=\"hljs-params\"></span>)\n{\n  float <span class=\"hljs-variable constant_\">X_1</span>[] = {<span class=\"hljs-number\">6.</span>, <span class=\"hljs-number\">2.7</span>, <span class=\"hljs-number\">5.1</span>, <span class=\"hljs-number\">1.6</span>};\n  int result_1 = <span class=\"hljs-title class_\">PoissonRegressor</span>.<span class=\"hljs-title function_\">predict</span>(<span class=\"hljs-variable constant_\">X_1</span>);\n  <span class=\"hljs-title class_\">Serial</span>.<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"X1을 입력으로 한 예측 결과(실제 값 = 1):\"</span>);\n  <span class=\"hljs-title class_\">Serial</span>.<span class=\"hljs-title function_\">println</span>(result_1);\n  <span class=\"hljs-title function_\">delay</span>(<span class=\"hljs-number\">2000</span>);\n\n  float <span class=\"hljs-variable constant_\">X_2</span>[] = {<span class=\"hljs-number\">4.8</span>, <span class=\"hljs-number\">3.1</span>, <span class=\"hljs-number\">1.6</span>, <span class=\"hljs-number\">0.2</span>};\n  int result_2 = <span class=\"hljs-title class_\">PoissonRegressor</span>.<span class=\"hljs-title function_\">predict</span>(<span class=\"hljs-variable constant_\">X_2</span>);\n  <span class=\"hljs-title class_\">Serial</span>.<span class=\"hljs-title function_\">print</span>(<span class=\"hljs-string\">\"X2을 입력으로 한 예측 결과(실제 값 = 0):\"</span>);\n  <span class=\"hljs-title class_\">Serial</span>.<span class=\"hljs-title function_\">println</span>(result_2);\n  <span class=\"hljs-title function_\">delay</span>(<span class=\"hljs-number\">2000</span>);\n}\n</code></pre>\n<p>2.12 — 결과</p>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_20.png\" alt=\"이미지\"></p>\n<p>전체 프로젝트: TinyML/15_Poisson_Regressor at main · thommaskevin/TinyML (github.com)</p>\n<h2>만약 마음에 드신다면 제게 커피 한 잔 사주세요 ☕️💰 (Bitcoin)</h2>\n<p>코드: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn</p>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_21.png\" alt=\"image\"></p>\n</body>\n</html>\n"},"__N_SSG":true}