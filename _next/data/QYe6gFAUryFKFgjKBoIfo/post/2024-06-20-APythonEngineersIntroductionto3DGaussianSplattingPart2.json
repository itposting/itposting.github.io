{"pageProps":{"post":{"title":"파이썬 엔지니어를 위한 3D 가우시안 스플래팅 소개 파트 2","description":"","date":"2024-06-20 19:11","slug":"2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2","content":"\n\n## 3D 가우시안 스플래팅 내에서 가우시안 함수가 어떻게 사용되는지 이해하고 코딩하기\n\n이제 가우시안에 대해 이야기해보겠습니다! 모두가 좋아하는 분포입니다. 지금부터 함께하는 분들을 위해, 카메라의 위치를 이용하여 3D 점을 2D로 변환하는 방법에 대해 part 1에서 다룬 바 있습니다. 이 글에서는 가우시안 스플래팅의 가우시안 부분을 다룰 것입니다. 우리는 GitHub에서 part_2.ipynb를 사용할 것입니다.\n\n여기서 우리가 만들게 될 약간의 변경사항은, 이전 글에서 보여준 것과는 다른 내부 매트릭스를 활용하는 원근 투영을 사용할 것이라는 것입니다. 그러나 2D로 점을 투영할 때 두 방법은 동등하며, 저는 part 1에서 소개된 첫 번째 방법이 이해하기 쉽다고 생각합니다. 그러나 가능한한 저자의 코드를 파이썬으로 복제하기 위해 저희는 방법을 변경할 것입니다. 구체적으로 우리의 \"내부\" 매트릭스는 이곳에 표시된 OpenGL 투영 매트릭스에 의해 이제 제공되며, 곱셈의 순서는 이제 points @ external.transpose() @ internal으로 변경될 것입니다.\n\n<img src=\"/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_0.png\" />\n\n<div class=\"content-ad\"></div>\n\n호기심이 있는 분들을 위해 새로운 내부 매트릭스에 대해 알고 싶은 경우(그렇지 않으면 이 단락을 건너뛰어도 괜찮아요) r과 l은 오른쪽과 왼쪽 측면의 클리핑 평면이며, 사진의 너비에 관한 시야에 포함될 수 있는 지점을 기본적으로 나타내고 있습니다. t와 b는 상단과 하단 클리핑 평면이고, N은 가까운 클리핑 평면(투영될 점들이 있는 곳)이며, f는 먼 클리핑 평면입니다. 더 자세한 정보는 scratchapixel의 챕터들이 여기에서 매우 유익하다고 생각합니다(https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix.html). 이것은 또한 점들을 정규화된 장치 좌표( -1과 1 사이)로 반환하며, 이를 픽셀 좌표로 투영합니다. 이론에서 벗어나서 우리의 작업은 같습니다, 3D에서 점을 가져와 2D 이미지 평면으로 투영하는 것입니다. 그러나 이 튜토리얼의 이 부분에서는 이제 포인트 대신 가우시안 함수를 사용합니다.\n\n```js\ndef getIntinsicMatrix(\n    focal_x: torch.Tensor,\n    focal_y: torch.Tensor,\n    height: torch.Tensor,\n    width: torch.Tensor,\n    znear: torch.Tensor = torch.Tensor([100.0]),\n    zfar: torch.Tensor = torch.Tensor([0.001]),,\n) -> torch.Tensor:\n    \"\"\"\n    내부 퍼스펙티브 투영 매트릭스 가져오기\n    \n    znear: 사용자가 지정한 가까운 평면\n    zfar: 사용자가 지정한 먼 평면\n    fovX: 초점 길이에서 계산된 x의 시야\n    fovY: 초점 길이에서 계산된 y의 시야\n    \"\"\"\n    fovX = torch.Tensor([2 * math.atan(width / (2 * focal_x))])\n    fovY = torch.Tensor([2 * math.atan(height / (2 * focal_y))])\n    \n    tanHalfFovY = math.tan((fovY / 2))\n    tanHalfFovX = math.tan((fovX / 2))\n\n    top = tanHalfFovY * znear\n    bottom = -top\n    right = tanHalfFovX * znear\n    left = -right\n    P = torch.zeros(4, 4)\n    z_sign = 1.0\n\n    P[0, 0] = 2.0 * znear / (right - left)\n    P[1, 1] = 2.0 * znear / (top - bottom)\n    P[0, 2] = (right + left) / (right - left)\n    P[1, 2] = (top + bottom) / (top - bottom)\n    P[3, 2] = z_sign\n    P[2, 2] = z_sign * zfar / (zfar - znear)\n    P[2, 3] = -(zfar * znear) / (zfar - znear)\n    return P\n```\n\n3D 가우시안 splat은 x, y, z 좌표 및 관련 공분산 행렬로 구성됩니다. 저자들이 언급한 대로: \"명백한 접근 방식은 공분산 행렬 Σ를 직접 최적화하여 빛의 필드를 나타내는 3D 가우시안을 얻는 것일 것입니다. 그러나, 공분산 행렬은 양의 준정치일 때만 물리적인 의미를 갖습니다. 우리가 모든 매개변수를 최적화하기 위해 사용하는 경사 하강법은 이러한 유효한 행렬을 생성하기가 쉽지 않으며, 업데이트 단계와 그래디언트는 쉽게 유효하지 않은 공분산 행렬을 만들어냅니다.\"\n\n그래서 저자들은 항상 양의 준정부 공분산 행렬을 생성할 수 있는 공분산 행렬의 분해를 사용합니다. 특히, 3개의 \"크기\" 매개변수와 4개의 쿼터니언을 사용하여 3x3 회전 행렬(R)로 변환합니다. 그런 다음 공분산 행렬은 다음과 같이 주어집니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_1.png)\n\n쿼터니온 벡터를 회전 행렬로 변환하기 전에 정규화해야만 유효한 회전 행렬을 얻을 수 있습니다. 따라서 저희 구현에서 가우스 포인트는 다음 매개변수로 구성됩니다. 좌표 (3x1 벡터), 쿼터니온 (4x1 벡터), 스케일 (3x1 벡터) 및 불투명도(스플래팅이 얼마나 투명한지를 나타내는 최종 float 값)입니다. 이제 모든게 갖춰졌네요! 이 11개의 매개변수를 최적화하여 우리의 씬을 만들 수 있습니다 — 간단하지요!\n\n하지만 실제로는 조금 복잡합니다. 고등학교 수학을 기억한다면 특정 지점에서의 가우시안의 세기는 아래의 방정식으로 주어집니다:\n\n![이미지](/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_2.png)\n\n\n<div class=\"content-ad\"></div>\n\n하지만, 우리는 이미지 평면인 2D에서 3D 가우시안의 강도에 중점을 두고 있습니다. 하지만 여러분은 아마 \"우리는 2D로 점을 투영하는 방법을 알고 있다고?\" 할 수 있겠지만요! 그럼에도 불구하고, 아직 2D로 공분산 행렬을 투영하는 방법에 대해 다루지 않았기 때문에, 만약 우리가 2D 공분산 행렬의 역행렬을 찾지 않았다면 이 무슨 얘기인지 알 수 없겠죠.\n\n이제 재미있는 부분입니다(어떻게 보느냐에 따라 다를 수 있습니다). 3D 가우시안 스플래팅 저자들의 논문인 EWA Splatting은 3D 공분산 행렬을 2D로 투영하는 정확한 방법을 보여줍니다. 그러나 이것은 알려진 야코비안 아핀 변환 행렬의 지식을 전제로 한다는 것에 유념해야 합니다. 아래에서 계산하는 것처럼. 어려운 개념을 풀어갈 때 가장 도움이 되는 것은 코드이므로, 3D 공분산 행렬에서 2D로 전환하는 방법을 실제로 어떻게 하는 지 보여주기 위해 아래에 일부 코드를 제공했습니다.\n\n```js\ndef compute_2d_covariance(\n    points: torch.Tensor,\n    external_matrix: torch.Tensor,\n    covariance_3d: torch.Tensor,\n    tan_fovY: torch.Tensor,\n    tan_fovX: torch.Tensor,\n    focal_x: torch.Tensor,\n    focal_y: torch.Tensor,\n) -> torch.Tensor:\n    \"\"\"\n    각 가우시안의 2D 공분산 행렬 계산\n    \"\"\"\n    points = torch.cat(\n        [points, torch.ones(points.shape[0], 1, device=points.device)], dim=1\n    )\n    points_transformed = (points @ external_matrix)[:, :3]\n    limx = 1.3 * tan_fovX\n    limy = 1.3 * tan_fovY\n    x = points_transformed[:, 0] / points_transformed[:, 2]\n    y = points_transformed[:, 1] / points_transformed[:, 2]\n    z = points_transformed[:, 2]\n    x = torch.clamp(x, -limx, limx) * z\n    y = torch.clamp(y, -limy, limy) * z\n\n    J = torch.zeros((points_transformed.shape[0], 3, 3), device=covariance_3d.device)\n    J[:, 0, 0] = focal_x / z\n    J[:, 0, 2] = -(focal_x * x) / (z**2)\n    J[:, 1, 1] = focal_y / z\n    J[:, 1, 2] = -(focal_y * y) / (z**2)\n\n    # 초기에 원근 투영을 위해 설정한 대로 전치함\n    # 이제 우리가 다시 변환하는 것이므로\n    W = external_matrix[:3, :3].T\n\n    return (J @ W @ covariance_3d @ W.T @ J.transpose(1, 2))[:, :2, :2]\n```\n\n먼저, tan_fovY와 tan_fovX는 시야각의 반을 나타내는 tangent 값입니다. 이러한 값들을 사용하여 투영을 클램핑하여 화면 바깥으로 너무 많이 벗어났을 때 렌더에 영향을 미치지 않도록 합니다. 우리는 초기 순방향 변환으로부터 주어진 3D에서 2D로의 변환으로부터 야코비안을 유도할 수 있지만, 여러분이 귀찮을 일을 덜어드리기 위해 위에서 기대할 수 있는 유도를 보여드릴게요. 마지막으로, 우리가 회전 행렬을 변환하면서 처음에 전치했습니다만, 최종 공분산 계산을 반환하기 전에 다시 전치해야 합니다. EWA 스플래팅 논문에 따르면, 우리는 2D 이미지 평면에만 관심이 있으므로 세 번째 행과 열은 무시할 수 있습니다. 처음부터 그렇게 할 수 없었던 이유에 대해 궁금할 수도 있습니다. 대부분의 경우, 이는 완벽한 구로 표현되지 않을 것이기 때문에 각도에 따라 공분산 행렬 매개변수가 달라지기 때문입니다! 이제 올바른 관점으로 변환했으므로, 공분산 z축 정보는 쓸모없으며 버릴 수 있게 되었습니다.\n\n<div class=\"content-ad\"></div>\n\n주어진 2D 공분산 행렬이 있으면 이미지의 임의의 픽셀에 각 가우시안이 미치는 영향을 계산할 수 있게 되었습니다. 이제 역 공분산 행렬을 찾아야 합니다. 선형 대수학에서 다시 상기해보면 2x2 행렬의 역행렬을 찾으려면 행렬식을 찾고 일부 용어를 재배열하면 됩니다. 이 코드를 통해 해당 프로세스를 안내해드릴게요.\n\n```js\ndef compute_inverted_covariance(covariance_2d: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    역 공분산 행렬 계산\n\n    2x2 행렬의 경우\n    다음과 같이 주어질 때\n    [[a, b],\n     [c, d]]\n     행렬식은 ad - bc입니다.\n\n    역행렬을 구하려면 다음과 같이 용어를 재배열하고\n    행렬식의 역수를 곱하면 됩니다\n    [[d, -b],\n     [-c, a]] * (1 / 행렬식)\n    \"\"\"\n    행렬식 = (\n        covariance_2d[:, 0, 0] * covariance_2d[:, 1, 1]\n        - covariance_2d[:, 0, 1] * covariance_2d[:, 1, 0]\n    )\n    행렬식 = torch.clamp(행렬식, min=1e-3)\n    역_공분산 = torch.zeros_like(covariance_2d)\n    역_공분산[:, 0, 0] = covariance_2d[:, 1, 1] / 행렬식\n    역_공분산[:, 1, 1] = covariance_2d[:, 0, 0] / 행렬식\n    역_공분산[:, 0, 1] = -covariance_2d[:, 0, 1] / 행렬식\n    역_공분산[:, 1, 0] = -covariance_2d[:, 1, 0] / 행렬식\n    return 역_공분산\n```\n\n그리고 이제 이미지의 모든 픽셀에 대해 픽셀 강도를 계산할 수 있습니다. 그러나 이렇게 하는 것은 굉장히 느리고 불필요합니다. 예를 들어, (0,0)에서 스플래시가 (1000,1000)의 픽셀에 어떤 영향을 미치는지 계산하는 데 계산 시간을 낭비할 필요가 없습니다. 공분산 행렬이 거대하지 않다면 말이죠. 따라서 저자들은 각 스플래시마다 \"반경\"이라고 부르는 값을 계산하기로 결정했습니다. 아래 코드에서 볼 수 있듯이 각 축을 따라 고유값을 계산합니다(고유값은 변화를 나타냅니다). 그런 다음 가장 큰 고유값의 제곱근을 취하여 표준 편차를 얻고 3.0을 곱합니다. 이것은 분포의 99.7%를 3표준 편차 내에 포함시킵니다. 이 반경을 사용하면 스플래시가 닿는 x 및 y 값의 최솟값과 최댓값을 파악할 수 있습니다. 렌더링할 때 이러한 경계 내의 픽셀에 대해만 스플래시 강도를 계산하며 불필요한 계산을 피합니다. 상당히 똑똑한 방법이죠?\n\n```js\ndef compute_extent_and_radius(covariance_2d: torch.Tensor):\n    mid = 0.5 * (covariance_2d[:, 0, 0] + covariance_2d[:, 1, 1])\n    det = covariance_2d[:, 0, 0] * covariance_2d[:, 1, 1] - covariance_2d[:, 0, 1] ** 2\n    intermediate_matrix = (mid * mid - det).view(-1, 1)\n    intermediate_matrix = torch.cat(\n        [intermediate_matrix, torch.ones_like(intermediate_matrix) * 0.1], dim=1\n    )\n\n    max_values = torch.max(intermediate_matrix, dim=1).values\n    lambda1 = mid + torch.sqrt(max_values)\n    lambda2 = mid - torch.sqrt(max_values)\n    # 이제 고유값을 갖고 있으므로 최대 반경을 계산할 수 있습니다\n    max_radius = torch.ceil(3.0 * torch.sqrt(torch.max(lambda1, lambda2)))\n\n    return max_radius\n```\n\n<div class=\"content-ad\"></div>\n\n위의 모든 단계를 거쳐 우리는 그것을 렌더 단계에서 사용할 수 있는 전처리된 장면을 얻습니다. 간단히 말해 이제 2D에서의 포인트, 해당 포인트와 관련된 색, 2D에서의 공분산, 2D에서의 역공분산, 정렬된 깊이 순서, 각 스플랫에 대한 최소 x, 최소 y, 최대 x, 최대 y 값, 그리고 관련 투명도를 가지게 되었어요. 이러한 모든 구성 요소를 갖고 이미지 렌더링으로 넘어 갈 수 있습니다!\n\n- Kerbl, Bernhard, et al. “3d gaussian splatting for real-time radiance field rendering.” ACM Transactions on Graphics 42.4 (2023): 1–14.\n- Zwicker, Matthias, et al. “EWA splatting.” IEEE Transactions on Visualization and Computer Graphics 8.3 (2002): 223–238.","ogImage":{"url":"/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_0.png"},"coverImage":"/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_0.png","tag":["Tech"],"readingTime":9},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>3D 가우시안 스플래팅 내에서 가우시안 함수가 어떻게 사용되는지 이해하고 코딩하기</h2>\n<p>이제 가우시안에 대해 이야기해보겠습니다! 모두가 좋아하는 분포입니다. 지금부터 함께하는 분들을 위해, 카메라의 위치를 이용하여 3D 점을 2D로 변환하는 방법에 대해 part 1에서 다룬 바 있습니다. 이 글에서는 가우시안 스플래팅의 가우시안 부분을 다룰 것입니다. 우리는 GitHub에서 part_2.ipynb를 사용할 것입니다.</p>\n<p>여기서 우리가 만들게 될 약간의 변경사항은, 이전 글에서 보여준 것과는 다른 내부 매트릭스를 활용하는 원근 투영을 사용할 것이라는 것입니다. 그러나 2D로 점을 투영할 때 두 방법은 동등하며, 저는 part 1에서 소개된 첫 번째 방법이 이해하기 쉽다고 생각합니다. 그러나 가능한한 저자의 코드를 파이썬으로 복제하기 위해 저희는 방법을 변경할 것입니다. 구체적으로 우리의 \"내부\" 매트릭스는 이곳에 표시된 OpenGL 투영 매트릭스에 의해 이제 제공되며, 곱셈의 순서는 이제 points @ external.transpose() @ internal으로 변경될 것입니다.</p>\n<img src=\"/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_0.png\">\n<div class=\"content-ad\"></div>\n<p>호기심이 있는 분들을 위해 새로운 내부 매트릭스에 대해 알고 싶은 경우(그렇지 않으면 이 단락을 건너뛰어도 괜찮아요) r과 l은 오른쪽과 왼쪽 측면의 클리핑 평면이며, 사진의 너비에 관한 시야에 포함될 수 있는 지점을 기본적으로 나타내고 있습니다. t와 b는 상단과 하단 클리핑 평면이고, N은 가까운 클리핑 평면(투영될 점들이 있는 곳)이며, f는 먼 클리핑 평면입니다. 더 자세한 정보는 scratchapixel의 챕터들이 여기에서 매우 유익하다고 생각합니다(<a href=\"https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix.html\" rel=\"nofollow\" target=\"_blank\">https://www.scratchapixel.com/lessons/3d-basic-rendering/perspective-and-orthographic-projection-matrix/opengl-perspective-projection-matrix.html</a>). 이것은 또한 점들을 정규화된 장치 좌표( -1과 1 사이)로 반환하며, 이를 픽셀 좌표로 투영합니다. 이론에서 벗어나서 우리의 작업은 같습니다, 3D에서 점을 가져와 2D 이미지 평면으로 투영하는 것입니다. 그러나 이 튜토리얼의 이 부분에서는 이제 포인트 대신 가우시안 함수를 사용합니다.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">getIntinsicMatrix</span>(\n    <span class=\"hljs-attr\">focal_x</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">focal_y</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">height</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">width</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">znear</span>: torch.<span class=\"hljs-property\">Tensor</span> = torch.<span class=\"hljs-title class_\">Tensor</span>([<span class=\"hljs-number\">100.0</span>]),\n    <span class=\"hljs-attr\">zfar</span>: torch.<span class=\"hljs-property\">Tensor</span> = torch.<span class=\"hljs-title class_\">Tensor</span>([<span class=\"hljs-number\">0.001</span>]),,\n) -> torch.<span class=\"hljs-property\">Tensor</span>:\n    <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n    내부 퍼스펙티브 투영 매트릭스 가져오기\n    \n    znear: 사용자가 지정한 가까운 평면\n    zfar: 사용자가 지정한 먼 평면\n    fovX: 초점 길이에서 계산된 x의 시야\n    fovY: 초점 길이에서 계산된 y의 시야\n    \"</span><span class=\"hljs-string\">\"\"</span>\n    fovX = torch.<span class=\"hljs-title class_\">Tensor</span>([<span class=\"hljs-number\">2</span> * math.<span class=\"hljs-title function_\">atan</span>(width / (<span class=\"hljs-number\">2</span> * focal_x))])\n    fovY = torch.<span class=\"hljs-title class_\">Tensor</span>([<span class=\"hljs-number\">2</span> * math.<span class=\"hljs-title function_\">atan</span>(height / (<span class=\"hljs-number\">2</span> * focal_y))])\n    \n    tanHalfFovY = math.<span class=\"hljs-title function_\">tan</span>((fovY / <span class=\"hljs-number\">2</span>))\n    tanHalfFovX = math.<span class=\"hljs-title function_\">tan</span>((fovX / <span class=\"hljs-number\">2</span>))\n\n    top = tanHalfFovY * znear\n    bottom = -top\n    right = tanHalfFovX * znear\n    left = -right\n    P = torch.<span class=\"hljs-title function_\">zeros</span>(<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">4</span>)\n    z_sign = <span class=\"hljs-number\">1.0</span>\n\n    P[<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>] = <span class=\"hljs-number\">2.0</span> * znear / (right - left)\n    P[<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>] = <span class=\"hljs-number\">2.0</span> * znear / (top - bottom)\n    P[<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">2</span>] = (right + left) / (right - left)\n    P[<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>] = (top + bottom) / (top - bottom)\n    P[<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>] = z_sign\n    P[<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>] = z_sign * zfar / (zfar - znear)\n    P[<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>] = -(zfar * znear) / (zfar - znear)\n    <span class=\"hljs-keyword\">return</span> P\n</code></pre>\n<p>3D 가우시안 splat은 x, y, z 좌표 및 관련 공분산 행렬로 구성됩니다. 저자들이 언급한 대로: \"명백한 접근 방식은 공분산 행렬 Σ를 직접 최적화하여 빛의 필드를 나타내는 3D 가우시안을 얻는 것일 것입니다. 그러나, 공분산 행렬은 양의 준정치일 때만 물리적인 의미를 갖습니다. 우리가 모든 매개변수를 최적화하기 위해 사용하는 경사 하강법은 이러한 유효한 행렬을 생성하기가 쉽지 않으며, 업데이트 단계와 그래디언트는 쉽게 유효하지 않은 공분산 행렬을 만들어냅니다.\"</p>\n<p>그래서 저자들은 항상 양의 준정부 공분산 행렬을 생성할 수 있는 공분산 행렬의 분해를 사용합니다. 특히, 3개의 \"크기\" 매개변수와 4개의 쿼터니언을 사용하여 3x3 회전 행렬(R)로 변환합니다. 그런 다음 공분산 행렬은 다음과 같이 주어집니다.</p>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_1.png\" alt=\"이미지\"></p>\n<p>쿼터니온 벡터를 회전 행렬로 변환하기 전에 정규화해야만 유효한 회전 행렬을 얻을 수 있습니다. 따라서 저희 구현에서 가우스 포인트는 다음 매개변수로 구성됩니다. 좌표 (3x1 벡터), 쿼터니온 (4x1 벡터), 스케일 (3x1 벡터) 및 불투명도(스플래팅이 얼마나 투명한지를 나타내는 최종 float 값)입니다. 이제 모든게 갖춰졌네요! 이 11개의 매개변수를 최적화하여 우리의 씬을 만들 수 있습니다 — 간단하지요!</p>\n<p>하지만 실제로는 조금 복잡합니다. 고등학교 수학을 기억한다면 특정 지점에서의 가우시안의 세기는 아래의 방정식으로 주어집니다:</p>\n<p><img src=\"/assets/img/2024-06-20-APythonEngineersIntroductionto3DGaussianSplattingPart2_2.png\" alt=\"이미지\"></p>\n<div class=\"content-ad\"></div>\n<p>하지만, 우리는 이미지 평면인 2D에서 3D 가우시안의 강도에 중점을 두고 있습니다. 하지만 여러분은 아마 \"우리는 2D로 점을 투영하는 방법을 알고 있다고?\" 할 수 있겠지만요! 그럼에도 불구하고, 아직 2D로 공분산 행렬을 투영하는 방법에 대해 다루지 않았기 때문에, 만약 우리가 2D 공분산 행렬의 역행렬을 찾지 않았다면 이 무슨 얘기인지 알 수 없겠죠.</p>\n<p>이제 재미있는 부분입니다(어떻게 보느냐에 따라 다를 수 있습니다). 3D 가우시안 스플래팅 저자들의 논문인 EWA Splatting은 3D 공분산 행렬을 2D로 투영하는 정확한 방법을 보여줍니다. 그러나 이것은 알려진 야코비안 아핀 변환 행렬의 지식을 전제로 한다는 것에 유념해야 합니다. 아래에서 계산하는 것처럼. 어려운 개념을 풀어갈 때 가장 도움이 되는 것은 코드이므로, 3D 공분산 행렬에서 2D로 전환하는 방법을 실제로 어떻게 하는 지 보여주기 위해 아래에 일부 코드를 제공했습니다.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">compute_2d_covariance</span>(\n    <span class=\"hljs-attr\">points</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">external_matrix</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">covariance_3d</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">tan_fovY</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">tan_fovX</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">focal_x</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n    <span class=\"hljs-attr\">focal_y</span>: torch.<span class=\"hljs-property\">Tensor</span>,\n) -> torch.<span class=\"hljs-property\">Tensor</span>:\n    <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n    각 가우시안의 2D 공분산 행렬 계산\n    \"</span><span class=\"hljs-string\">\"\"</span>\n    points = torch.<span class=\"hljs-title function_\">cat</span>(\n        [points, torch.<span class=\"hljs-title function_\">ones</span>(points.<span class=\"hljs-property\">shape</span>[<span class=\"hljs-number\">0</span>], <span class=\"hljs-number\">1</span>, device=points.<span class=\"hljs-property\">device</span>)], dim=<span class=\"hljs-number\">1</span>\n    )\n    points_transformed = (points @ external_matrix)[:, :<span class=\"hljs-number\">3</span>]\n    limx = <span class=\"hljs-number\">1.3</span> * tan_fovX\n    limy = <span class=\"hljs-number\">1.3</span> * tan_fovY\n    x = points_transformed[:, <span class=\"hljs-number\">0</span>] / points_transformed[:, <span class=\"hljs-number\">2</span>]\n    y = points_transformed[:, <span class=\"hljs-number\">1</span>] / points_transformed[:, <span class=\"hljs-number\">2</span>]\n    z = points_transformed[:, <span class=\"hljs-number\">2</span>]\n    x = torch.<span class=\"hljs-title function_\">clamp</span>(x, -limx, limx) * z\n    y = torch.<span class=\"hljs-title function_\">clamp</span>(y, -limy, limy) * z\n\n    J = torch.<span class=\"hljs-title function_\">zeros</span>((points_transformed.<span class=\"hljs-property\">shape</span>[<span class=\"hljs-number\">0</span>], <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">3</span>), device=covariance_3d.<span class=\"hljs-property\">device</span>)\n    J[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>] = focal_x / z\n    J[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">2</span>] = -(focal_x * x) / (z**<span class=\"hljs-number\">2</span>)\n    J[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>] = focal_y / z\n    J[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>] = -(focal_y * y) / (z**<span class=\"hljs-number\">2</span>)\n\n    # 초기에 원근 투영을 위해 설정한 대로 전치함\n    # 이제 우리가 다시 변환하는 것이므로\n    W = external_matrix[:<span class=\"hljs-number\">3</span>, :<span class=\"hljs-number\">3</span>].<span class=\"hljs-property\">T</span>\n\n    <span class=\"hljs-keyword\">return</span> (J @ W @ covariance_3d @ W.<span class=\"hljs-property\">T</span> @ J.<span class=\"hljs-title function_\">transpose</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>))[:, :<span class=\"hljs-number\">2</span>, :<span class=\"hljs-number\">2</span>]\n</code></pre>\n<p>먼저, tan_fovY와 tan_fovX는 시야각의 반을 나타내는 tangent 값입니다. 이러한 값들을 사용하여 투영을 클램핑하여 화면 바깥으로 너무 많이 벗어났을 때 렌더에 영향을 미치지 않도록 합니다. 우리는 초기 순방향 변환으로부터 주어진 3D에서 2D로의 변환으로부터 야코비안을 유도할 수 있지만, 여러분이 귀찮을 일을 덜어드리기 위해 위에서 기대할 수 있는 유도를 보여드릴게요. 마지막으로, 우리가 회전 행렬을 변환하면서 처음에 전치했습니다만, 최종 공분산 계산을 반환하기 전에 다시 전치해야 합니다. EWA 스플래팅 논문에 따르면, 우리는 2D 이미지 평면에만 관심이 있으므로 세 번째 행과 열은 무시할 수 있습니다. 처음부터 그렇게 할 수 없었던 이유에 대해 궁금할 수도 있습니다. 대부분의 경우, 이는 완벽한 구로 표현되지 않을 것이기 때문에 각도에 따라 공분산 행렬 매개변수가 달라지기 때문입니다! 이제 올바른 관점으로 변환했으므로, 공분산 z축 정보는 쓸모없으며 버릴 수 있게 되었습니다.</p>\n<div class=\"content-ad\"></div>\n<p>주어진 2D 공분산 행렬이 있으면 이미지의 임의의 픽셀에 각 가우시안이 미치는 영향을 계산할 수 있게 되었습니다. 이제 역 공분산 행렬을 찾아야 합니다. 선형 대수학에서 다시 상기해보면 2x2 행렬의 역행렬을 찾으려면 행렬식을 찾고 일부 용어를 재배열하면 됩니다. 이 코드를 통해 해당 프로세스를 안내해드릴게요.</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">compute_inverted_covariance</span>(<span class=\"hljs-attr\">covariance_2d</span>: torch.<span class=\"hljs-property\">Tensor</span>) -> torch.<span class=\"hljs-property\">Tensor</span>:\n    <span class=\"hljs-string\">\"\"</span><span class=\"hljs-string\">\"\n    역 공분산 행렬 계산\n\n    2x2 행렬의 경우\n    다음과 같이 주어질 때\n    [[a, b],\n     [c, d]]\n     행렬식은 ad - bc입니다.\n\n    역행렬을 구하려면 다음과 같이 용어를 재배열하고\n    행렬식의 역수를 곱하면 됩니다\n    [[d, -b],\n     [-c, a]] * (1 / 행렬식)\n    \"</span><span class=\"hljs-string\">\"\"</span>\n    행렬식 = (\n        covariance_2d[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>] * covariance_2d[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>]\n        - covariance_2d[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>] * covariance_2d[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>]\n    )\n    행렬식 = torch.<span class=\"hljs-title function_\">clamp</span>(행렬식, min=<span class=\"hljs-number\">1e-3</span>)\n    역_공분산 = torch.<span class=\"hljs-title function_\">zeros_like</span>(covariance_2d)\n    역_공분산[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>] = covariance_2d[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>] / 행렬식\n    역_공분산[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>] = covariance_2d[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>] / 행렬식\n    역_공분산[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>] = -covariance_2d[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>] / 행렬식\n    역_공분산[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>] = -covariance_2d[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">0</span>] / 행렬식\n    <span class=\"hljs-keyword\">return</span> 역_공분산\n</code></pre>\n<p>그리고 이제 이미지의 모든 픽셀에 대해 픽셀 강도를 계산할 수 있습니다. 그러나 이렇게 하는 것은 굉장히 느리고 불필요합니다. 예를 들어, (0,0)에서 스플래시가 (1000,1000)의 픽셀에 어떤 영향을 미치는지 계산하는 데 계산 시간을 낭비할 필요가 없습니다. 공분산 행렬이 거대하지 않다면 말이죠. 따라서 저자들은 각 스플래시마다 \"반경\"이라고 부르는 값을 계산하기로 결정했습니다. 아래 코드에서 볼 수 있듯이 각 축을 따라 고유값을 계산합니다(고유값은 변화를 나타냅니다). 그런 다음 가장 큰 고유값의 제곱근을 취하여 표준 편차를 얻고 3.0을 곱합니다. 이것은 분포의 99.7%를 3표준 편차 내에 포함시킵니다. 이 반경을 사용하면 스플래시가 닿는 x 및 y 값의 최솟값과 최댓값을 파악할 수 있습니다. 렌더링할 때 이러한 경계 내의 픽셀에 대해만 스플래시 강도를 계산하며 불필요한 계산을 피합니다. 상당히 똑똑한 방법이죠?</p>\n<pre><code class=\"hljs language-js\">def <span class=\"hljs-title function_\">compute_extent_and_radius</span>(<span class=\"hljs-attr\">covariance_2d</span>: torch.<span class=\"hljs-property\">Tensor</span>):\n    mid = <span class=\"hljs-number\">0.5</span> * (covariance_2d[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>] + covariance_2d[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>])\n    det = covariance_2d[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>] * covariance_2d[:, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>] - covariance_2d[:, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>] ** <span class=\"hljs-number\">2</span>\n    intermediate_matrix = (mid * mid - det).<span class=\"hljs-title function_\">view</span>(-<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)\n    intermediate_matrix = torch.<span class=\"hljs-title function_\">cat</span>(\n        [intermediate_matrix, torch.<span class=\"hljs-title function_\">ones_like</span>(intermediate_matrix) * <span class=\"hljs-number\">0.1</span>], dim=<span class=\"hljs-number\">1</span>\n    )\n\n    max_values = torch.<span class=\"hljs-title function_\">max</span>(intermediate_matrix, dim=<span class=\"hljs-number\">1</span>).<span class=\"hljs-property\">values</span>\n    lambda1 = mid + torch.<span class=\"hljs-title function_\">sqrt</span>(max_values)\n    lambda2 = mid - torch.<span class=\"hljs-title function_\">sqrt</span>(max_values)\n    # 이제 고유값을 갖고 있으므로 최대 반경을 계산할 수 있습니다\n    max_radius = torch.<span class=\"hljs-title function_\">ceil</span>(<span class=\"hljs-number\">3.0</span> * torch.<span class=\"hljs-title function_\">sqrt</span>(torch.<span class=\"hljs-title function_\">max</span>(lambda1, lambda2)))\n\n    <span class=\"hljs-keyword\">return</span> max_radius\n</code></pre>\n<div class=\"content-ad\"></div>\n<p>위의 모든 단계를 거쳐 우리는 그것을 렌더 단계에서 사용할 수 있는 전처리된 장면을 얻습니다. 간단히 말해 이제 2D에서의 포인트, 해당 포인트와 관련된 색, 2D에서의 공분산, 2D에서의 역공분산, 정렬된 깊이 순서, 각 스플랫에 대한 최소 x, 최소 y, 최대 x, 최대 y 값, 그리고 관련 투명도를 가지게 되었어요. 이러한 모든 구성 요소를 갖고 이미지 렌더링으로 넘어 갈 수 있습니다!</p>\n<ul>\n<li>Kerbl, Bernhard, et al. “3d gaussian splatting for real-time radiance field rendering.” ACM Transactions on Graphics 42.4 (2023): 1–14.</li>\n<li>Zwicker, Matthias, et al. “EWA splatting.” IEEE Transactions on Visualization and Computer Graphics 8.3 (2002): 223–238.</li>\n</ul>\n</body>\n</html>\n"},"__N_SSG":true}