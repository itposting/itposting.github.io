{"pageProps":{"post":{"title":"주식 예측에서 머신러닝이 실패하는 주요 이유 파트 01","description":"","date":"2024-06-23 19:47","slug":"2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01","content":"\n\n이 블로그 시리즈에서는 머신 러닝이 주식 가격을 예측하는 데 실패하는 이유 또는 일반적으로 머신 러닝 기반 투자 펀드가 실패하는 이유에 대해 논의하려 합니다. 이 블로그의 내용은 Marcos Lopez de Prado의 \"금융 머신 러닝 발전\"이라는 책에서 가져왔습니다. 이 책은 금융에 관심 있는 모든 사람들에게 필독서입니다. 이 책은 금융 데이터를 처리하는 동안 머신 러닝 실무자들이 범한 모든 실수를 언급합니다. 이 블로그를 통해 이 책에서의 학습 내용을 요약하려고 합니다.\n\n- Reason 1 : 메모리 vs 정상성 트레이드 오프 :\n\n주식의 가격을 예측하고 싶다고 가정해 봅시다. ARMA와 같은 모든 전통적인 방법이 정상성 데이터에 작용한다는 것을 알고 있습니다. 일반적으로 정상 데이터는 일련의 시리즈 전체에서 일정한 평균과 일정한 분산을 의미합니다. 데이터를 정상으로 만들기 위해 시계열 데이터에서 차분을 수행합니다. 1차 차분은 현재 주가 값을 이전 값에서 뺀 것을 의미합니다.\n\n![Image](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png)\n\n<div class=\"content-ad\"></div>\n\n차이를 만들면 데이터가 정체성을 띄게 됩니다. 그러나 1차 차이를 구할 때는 데이터의 모든 과거적인 패턴을 잃어버리게 됩니다(그림 참조). 이로 인해 그 데이터의 내용을 잃게 됩니다. 그리고 기억력은 모델의 예측 능력을 결정하는 중요한 요소입니다. 데이터를 정체성을 갖도록 만드는 중간 과정에서 기억력을 잃게 됩니다. 이런 실수가 학술 논문이나 업무 현장에서 많이 발생합니다. 그렇다면 어떻게 데이터를 정체성을 갖게 하면서도 정보를 완전히 잃지 않을 수 있을까요? 그 대답은 없습니다. 따라서 더 많이 정체성을 갖도록 만드는 경우에는 더 많은 기억력을 잃게 됩니다. 릴라이언스의 과거 가격을 통해 이러한 경우를 이해해봅시다.\n\n![image](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_1.png)\n\n위 그래프에서 보듯이 데이터를 정체성을 갖도록 만들면 가격이 시간에 따라 어떻게 변동하는지에 대한 정보를 모두 잃고 따라서 그 기억력도 잃게 됩니다. 그리고 이에 따라 그런 데이터로 만든 모델의 예측 능력도 잃게 됩니다. 그렇다면 어떻게 해야 할까요? 부분적인 정체성을 달성하면서 부분적인 기억력을 잃지 않도록 하는 방법을 찾아야 합니다. 그렇게 되면 분수 차이화라는 개념이 등장합니다. 분수 차이화에서는 1차 차이화 대신 어떤 분수 값을 사용하여 차이화를 수행하게 되어 모든 정보를 완전히 잃지 않습니다. 그렇다면 분수 차이화를 어떻게 수행할까요? 함께 살펴봅시다.\n\n![image](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_2.png)\n\n<div class=\"content-ad\"></div>\n\n위에서 보시다시피 주문 차이를 확장했습니다. 이제 만약 d=0.3의 값을 넣으면 0.2의 분수 차이 값이 나올 것입니다. 이것은 무한급수이므로 어떤 지점까지 값을 취할 수 있고, 그 이후에는 시리즈를 잘라내도 괜찮습니다. 왜냐하면 B^n 계수 값이 높아질수록 거의 제로에 가까워질 것이기 때문입니다. 아래 그래프는 일정 지점 이후에 서로 다른 d 값에 대한 B^n 계수를 보여줍니다.\n\n이제 동일한 플롯을 동일한 차수의 분수 차이로 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n상단 차트에서 확인할 수 있듯이, 차분의 순서를 증가할수록 점점 더 많은 메모리를 잃고 더욱 안정화됩니다. 차분이 0일 때는 모든 메모리를 가지고 있지만, 시리즈는 안정적이지 않고 차분이 1일 때는 시리즈가 메모리를 가지고 있지 않지만 완전히 안정화됩니다. 그래서 우리는 어느 정도의 메모리를 잃으면서 데이터를 의미 있는 확률로 안정화할지 교환해야 합니다. 그래서 이제 d값을 어떻게 찾아야 할까요?\n\n시계열의 안정성을 위한 ADF(Augmented Dickey-Fuller) 검정이 관련됩니다. ADF 검정은 시리즈가 안정적인지 여부를 테스트하는 데 사용됩니다. 다양한 d 값에 대해 ADF 검정을 수행한 후, 아래 빨간색 선 그래프는 다양한 d 값에 대한 검정 통계 값입니다. 검정 통계 값이 수평선보다 낮다면 해당 시리즈가 안정적이라고 할 수 있습니다. 따라서 아래 차트에서 d=0.4가 시리즈를 안정화시키는 데 충분하다고 할 수 있습니다. 그래서 시리즈에서 최소한의 메모리 손실로 안정화된 시리즈를 얻으려면 d=0.4를 사용할 수 있습니다.\n\n2. 이유 2: 비효율적인 샘플링\n\n<div class=\"content-ad\"></div>\n\n다른 많은 실무자와 학술 논문 작성자들이 하는 또 다른 흔한 실수는 데이터 샘플링이 비효율적인 것입니다. 대부분의 경우 그들은 데이터를 시간 간격마다 샘플링합니다. 예를 들어, 5분마다 또는 10분마다 데이터를 샘플링합니다. 시간 프레임에 기반한 데이터 샘플링 시 주요 문제점이 있습니다.\n\n- 시장이 정규시간 간격에 맞춰 정보를 처리하지 않기 때문에 문제가 발생합니다. 예를 들어 시장은 오픈할 때보다 정오에 활동성이 높으므로, 높은 활동성 시간 동안 정보를 과소샘플링하고 낮은 활동성 시간 동안 정보를 과대샘플링합니다.\n- 시간 샘플링된 데이터는 연쇄상관, 이분산성 및 수익의 비정상성과 같은 부정적인 통계적 특성을 보입니다.\n\n이 문제를 극복하기 위해 다양한 바(bar)가 정의될 것입니다. \n\n- 틱 바(Tick bar): 타임스탬프, 거래량, 오픈 가격, 종가 등의 모든 변수를 일정 거래 횟수 이후 추출합니다. 예를 들어, 1000 거래가 이루어진 후 모든 변수를 샘플링합니다. Mandelbrot 및 Taylor [1967]은 거래 횟수에 따른 샘플링이 우수한 통계적 특성을 보인다는 것을 처음으로 깨달았습니다: \"고정된 거래 횟수에 따른 가격 변동이 가우시안 분포를 가질 수 있습니다.\"\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_6.png)\n\n![이미지](/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_7.png)\n\n- 볼륨 바: 틱 바는 주문 조각화(쪼개짐) 문제가 있습니다. 예를 들어, 어떤 가격에 어떤 가격에 10주를 매도하는 경우, 10주를 사 실 때 1틱으로 기록됩니다. 하지만 만약 1주를 10번 사면 10개의 거래로 기록됩니다. 이 문제를 해결하기 위해 일정 거래량이 발생한 후 정보를 샘플링합니다. 이것이 볼륨 바라고 알려져 있습니다.\n- 달러 바: 달러 바는 일정 거래가 발생한 후 정보를 샘플링하여 형성됩니다. 예를 들어, $5000의 거래가 발생한 후에 정보를 샘플링합니다. \"값\"은 반드시 $로만 측정되는 것은 아니고, Rs, 유로 등이 될 수 있습니다. 달러 바가 필요한 이유는 무엇일까요? 특정 기간 동안 100%의 평가 상승을 보인 주식을 분석하려고 할 때, 그 기간 끝에 $1,000가치의 그 주식을 판매하려면, 그 주식을 $1,000가치 살 때와는 반의 주식을 거래해야 합니다. 다시 말해, 거래된 주식 수는 실제 교환된 가치에 따라 결정됩니다. 그러므로, 주요 가격 변동이 있는 분석에 관여할 때, 거래된 값의 관점에서 바를 샘플링하는 것이 의미가 있습니다. 또 다른 주장은 보너스 주식, 주식 분할로 주식 수가 자주 변경되므로 거래량보다는 가격을 기준으로 샘플링하는 것이 더 합리적이라는 점입니다.\n\n다음 파트에서는 정보 주도의 일부 고급 정보 바에 대해 이야기해보겠습니다. 즉, 시장에 새로운 정보가 들어오면 정보를 샘플링하는 것을 의미합니다. 다음 블로그 시리즈에서 정보 주도형 바에 대해 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n이 블로그를 좋아하신다면 꼭 의겢이나 좋아요를 클릭해 주세요!\n\n참고:\n\n1) Marcos López de Prado의 금융 기계 학습 발전","ogImage":{"url":"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png"},"coverImage":"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png","tag":["Tech"],"readingTime":5},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>이 블로그 시리즈에서는 머신 러닝이 주식 가격을 예측하는 데 실패하는 이유 또는 일반적으로 머신 러닝 기반 투자 펀드가 실패하는 이유에 대해 논의하려 합니다. 이 블로그의 내용은 Marcos Lopez de Prado의 \"금융 머신 러닝 발전\"이라는 책에서 가져왔습니다. 이 책은 금융에 관심 있는 모든 사람들에게 필독서입니다. 이 책은 금융 데이터를 처리하는 동안 머신 러닝 실무자들이 범한 모든 실수를 언급합니다. 이 블로그를 통해 이 책에서의 학습 내용을 요약하려고 합니다.</p>\n<ul>\n<li>Reason 1 : 메모리 vs 정상성 트레이드 오프 :</li>\n</ul>\n<p>주식의 가격을 예측하고 싶다고 가정해 봅시다. ARMA와 같은 모든 전통적인 방법이 정상성 데이터에 작용한다는 것을 알고 있습니다. 일반적으로 정상 데이터는 일련의 시리즈 전체에서 일정한 평균과 일정한 분산을 의미합니다. 데이터를 정상으로 만들기 위해 시계열 데이터에서 차분을 수행합니다. 1차 차분은 현재 주가 값을 이전 값에서 뺀 것을 의미합니다.</p>\n<p><img src=\"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_0.png\" alt=\"Image\"></p>\n<div class=\"content-ad\"></div>\n<p>차이를 만들면 데이터가 정체성을 띄게 됩니다. 그러나 1차 차이를 구할 때는 데이터의 모든 과거적인 패턴을 잃어버리게 됩니다(그림 참조). 이로 인해 그 데이터의 내용을 잃게 됩니다. 그리고 기억력은 모델의 예측 능력을 결정하는 중요한 요소입니다. 데이터를 정체성을 갖도록 만드는 중간 과정에서 기억력을 잃게 됩니다. 이런 실수가 학술 논문이나 업무 현장에서 많이 발생합니다. 그렇다면 어떻게 데이터를 정체성을 갖게 하면서도 정보를 완전히 잃지 않을 수 있을까요? 그 대답은 없습니다. 따라서 더 많이 정체성을 갖도록 만드는 경우에는 더 많은 기억력을 잃게 됩니다. 릴라이언스의 과거 가격을 통해 이러한 경우를 이해해봅시다.</p>\n<p><img src=\"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_1.png\" alt=\"image\"></p>\n<p>위 그래프에서 보듯이 데이터를 정체성을 갖도록 만들면 가격이 시간에 따라 어떻게 변동하는지에 대한 정보를 모두 잃고 따라서 그 기억력도 잃게 됩니다. 그리고 이에 따라 그런 데이터로 만든 모델의 예측 능력도 잃게 됩니다. 그렇다면 어떻게 해야 할까요? 부분적인 정체성을 달성하면서 부분적인 기억력을 잃지 않도록 하는 방법을 찾아야 합니다. 그렇게 되면 분수 차이화라는 개념이 등장합니다. 분수 차이화에서는 1차 차이화 대신 어떤 분수 값을 사용하여 차이화를 수행하게 되어 모든 정보를 완전히 잃지 않습니다. 그렇다면 분수 차이화를 어떻게 수행할까요? 함께 살펴봅시다.</p>\n<p><img src=\"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_2.png\" alt=\"image\"></p>\n<div class=\"content-ad\"></div>\n<p>위에서 보시다시피 주문 차이를 확장했습니다. 이제 만약 d=0.3의 값을 넣으면 0.2의 분수 차이 값이 나올 것입니다. 이것은 무한급수이므로 어떤 지점까지 값을 취할 수 있고, 그 이후에는 시리즈를 잘라내도 괜찮습니다. 왜냐하면 B^n 계수 값이 높아질수록 거의 제로에 가까워질 것이기 때문입니다. 아래 그래프는 일정 지점 이후에 서로 다른 d 값에 대한 B^n 계수를 보여줍니다.</p>\n<p>이제 동일한 플롯을 동일한 차수의 분수 차이로 살펴보겠습니다.</p>\n<div class=\"content-ad\"></div>\n<p>상단 차트에서 확인할 수 있듯이, 차분의 순서를 증가할수록 점점 더 많은 메모리를 잃고 더욱 안정화됩니다. 차분이 0일 때는 모든 메모리를 가지고 있지만, 시리즈는 안정적이지 않고 차분이 1일 때는 시리즈가 메모리를 가지고 있지 않지만 완전히 안정화됩니다. 그래서 우리는 어느 정도의 메모리를 잃으면서 데이터를 의미 있는 확률로 안정화할지 교환해야 합니다. 그래서 이제 d값을 어떻게 찾아야 할까요?</p>\n<p>시계열의 안정성을 위한 ADF(Augmented Dickey-Fuller) 검정이 관련됩니다. ADF 검정은 시리즈가 안정적인지 여부를 테스트하는 데 사용됩니다. 다양한 d 값에 대해 ADF 검정을 수행한 후, 아래 빨간색 선 그래프는 다양한 d 값에 대한 검정 통계 값입니다. 검정 통계 값이 수평선보다 낮다면 해당 시리즈가 안정적이라고 할 수 있습니다. 따라서 아래 차트에서 d=0.4가 시리즈를 안정화시키는 데 충분하다고 할 수 있습니다. 그래서 시리즈에서 최소한의 메모리 손실로 안정화된 시리즈를 얻으려면 d=0.4를 사용할 수 있습니다.</p>\n<ol start=\"2\">\n<li>이유 2: 비효율적인 샘플링</li>\n</ol>\n<div class=\"content-ad\"></div>\n<p>다른 많은 실무자와 학술 논문 작성자들이 하는 또 다른 흔한 실수는 데이터 샘플링이 비효율적인 것입니다. 대부분의 경우 그들은 데이터를 시간 간격마다 샘플링합니다. 예를 들어, 5분마다 또는 10분마다 데이터를 샘플링합니다. 시간 프레임에 기반한 데이터 샘플링 시 주요 문제점이 있습니다.</p>\n<ul>\n<li>시장이 정규시간 간격에 맞춰 정보를 처리하지 않기 때문에 문제가 발생합니다. 예를 들어 시장은 오픈할 때보다 정오에 활동성이 높으므로, 높은 활동성 시간 동안 정보를 과소샘플링하고 낮은 활동성 시간 동안 정보를 과대샘플링합니다.</li>\n<li>시간 샘플링된 데이터는 연쇄상관, 이분산성 및 수익의 비정상성과 같은 부정적인 통계적 특성을 보입니다.</li>\n</ul>\n<p>이 문제를 극복하기 위해 다양한 바(bar)가 정의될 것입니다.</p>\n<ul>\n<li>틱 바(Tick bar): 타임스탬프, 거래량, 오픈 가격, 종가 등의 모든 변수를 일정 거래 횟수 이후 추출합니다. 예를 들어, 1000 거래가 이루어진 후 모든 변수를 샘플링합니다. Mandelbrot 및 Taylor [1967]은 거래 횟수에 따른 샘플링이 우수한 통계적 특성을 보인다는 것을 처음으로 깨달았습니다: \"고정된 거래 횟수에 따른 가격 변동이 가우시안 분포를 가질 수 있습니다.\"</li>\n</ul>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_6.png\" alt=\"이미지\"></p>\n<p><img src=\"/assets/img/2024-06-23-majorreasonswhymachinelearningfailsinstockpredictionpart-01_7.png\" alt=\"이미지\"></p>\n<ul>\n<li>볼륨 바: 틱 바는 주문 조각화(쪼개짐) 문제가 있습니다. 예를 들어, 어떤 가격에 어떤 가격에 10주를 매도하는 경우, 10주를 사 실 때 1틱으로 기록됩니다. 하지만 만약 1주를 10번 사면 10개의 거래로 기록됩니다. 이 문제를 해결하기 위해 일정 거래량이 발생한 후 정보를 샘플링합니다. 이것이 볼륨 바라고 알려져 있습니다.</li>\n<li>달러 바: 달러 바는 일정 거래가 발생한 후 정보를 샘플링하여 형성됩니다. 예를 들어, $5000의 거래가 발생한 후에 정보를 샘플링합니다. \"값\"은 반드시 $로만 측정되는 것은 아니고, Rs, 유로 등이 될 수 있습니다. 달러 바가 필요한 이유는 무엇일까요? 특정 기간 동안 100%의 평가 상승을 보인 주식을 분석하려고 할 때, 그 기간 끝에 $1,000가치의 그 주식을 판매하려면, 그 주식을 $1,000가치 살 때와는 반의 주식을 거래해야 합니다. 다시 말해, 거래된 주식 수는 실제 교환된 가치에 따라 결정됩니다. 그러므로, 주요 가격 변동이 있는 분석에 관여할 때, 거래된 값의 관점에서 바를 샘플링하는 것이 의미가 있습니다. 또 다른 주장은 보너스 주식, 주식 분할로 주식 수가 자주 변경되므로 거래량보다는 가격을 기준으로 샘플링하는 것이 더 합리적이라는 점입니다.</li>\n</ul>\n<p>다음 파트에서는 정보 주도의 일부 고급 정보 바에 대해 이야기해보겠습니다. 즉, 시장에 새로운 정보가 들어오면 정보를 샘플링하는 것을 의미합니다. 다음 블로그 시리즈에서 정보 주도형 바에 대해 살펴보겠습니다.</p>\n<div class=\"content-ad\"></div>\n<p>이 블로그를 좋아하신다면 꼭 의겢이나 좋아요를 클릭해 주세요!</p>\n<p>참고:</p>\n<ol>\n<li>Marcos López de Prado의 금융 기계 학습 발전</li>\n</ol>\n</body>\n</html>\n"},"__N_SSG":true}