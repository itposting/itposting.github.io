{"pageProps":{"post":{"title":"NLP 분석을 위한 Youtube 댓글 스크래핑 방법","description":"","date":"2024-06-22 16:44","slug":"2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis","content":"\n\n![image](/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_0.png)\n\n간단한 NLP 프로젝트를 시도해보고자 했는데, 유튜브 동영상에서 댓글을 가져와 분석해보려고 합니다.\n\n사실 향수에 대해 연구 중이었는데, 인스타그램을 무심코 스크롤하다가 향수 광고에 끌려들어가게 되었습니다. 그렇게해서 향수 리뷰 동영상들을 찾게 되었고, Demi Rawling의 향수 리뷰 동영상을 발견하게 되었습니다... (너무 핫하네요).\n\n유튜브 링크 - https://youtu.be/oJqc2tLMObg\n\n<div class=\"content-ad\"></div>\n\n이 동영상은 탑 10 톰 포드 향수에 관한 것입니다. 다소 오래된 동영상이긴 하지만(4년 전 영상입니다)\n\n먼저, 만약 설치되어 있지 않다면 이곳에서 ChromeDriver를 설치해주세요. 저는 VS Code에서 실행을 시도해봤어요. 필요한 라이브러리는 다음과 같아요...\n\n```js\nimport sys\nimport time\nimport pandas as pd\nfrom datetime import datetime\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\n```\n\n그런 다음 스크래핑 부분이 나옵니다...\n\n<div class=\"content-ad\"></div>\n\n```python\nimport pandas as pd\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nimport time\nimport sys\nfrom datetime import datetime\n\n# WebDriver를 초기화하고 성능을 향상시키기 위한 옵션 설정\noptions = webdriver.ChromeOptions()\noptions.add_argument(\"--headless\")  # 헤드리스 모드로 실행\noptions.add_argument(\"--disable-gpu\")  # GPU 렌더링 비활성화\noptions.add_argument(\"--no-sandbox\")  # OS 보안 모델 우회\noptions.add_argument(\"--disable-dev-shm-usage\")  # 제한된 리소스 문제 극복\noptions.add_argument(\"--start-maximized\")  # 창 최대화\n\ndriver = webdriver.Chrome(options=options)\n\ndata = []\nyoutube_video_url = \"https://youtu.be/oJqc2tLMObg\"\nwait = WebDriverWait(driver, 30) \n\n# YouTube 비디오 URL 열기\ndriver.get(youtube_video_url)\nprint(\"YouTube URL을 열었습니다.\")\n\n# 댓글을 로드하기 위해 스크롤 다운\nfor item in range(150):  # 여기에 스크롤 횟수 정의\n    try:\n        body = wait.until(EC.visibility_of_element_located((By.TAG_NAME, \"body\")))\n        body.send_keys(Keys.END)\n        sys.stdout.write(f\"\\r{item + 1}번 스크롤 중\")\n        sys.stdout.flush()\n        time.sleep(1.5)  # 로딩을 위한 시간 증가\n    except Exception as e:\n        print(f\"스크롤 중 예외 발생: {e}\")\n        break\n\n# 댓글 추출\ntry:\n    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#contents #contents\")))\n    comments = driver.find_elements(By.CSS_SELECTOR, \"#content #content-text\")\n    print(f\"\\n{len(comments)}개의 댓글 요소를 찾았습니다.\")\n\n    user_id = 1  # 고유한 사용자 ID 초기화\n    for comment in comments:\n        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n        data.append({\"사용자 ID\": user_id, \"댓글\": comment.text, \"타임스탬프\": timestamp})\n        user_id += 1\n\n    # 중복 제거\n    data = [dict(t) for t in {tuple(d.items()) for d in data}]\n    print(f\"캡처된 댓글 수: {len(data)}\")\nexcept Exception as e:\n    print(f\"댓글 추출 중 예외 발생: {e}\")\n\ndriver.quit()\n\n# DataFrame 생성\ndf = pd.DataFrame(data, columns=[\"사용자 ID\", \"댓글\", \"타임스탬프\"])\n\n# DataFrame 표시\nprint(df)\n\n# DataFrame을 CSV 파일로 저장 (선택 사항)\ndf.to_csv(\"youtube_comments.csv\", index=False)\n``` \n\n여기서 댓글을 스크래핑하기 위해 스크롤 수를 사용했어요. 댓글 수의 최대값으로 변환할 수도 있지만, 현재 이 방법이 가장 잘 작동합니다.\n\n그래서 이 몇 가지 가정과 제약들이 있어요.\n\n가정과 제약사항: 각 댓글의 사용자 이름을 스크래핑하여 하나의 작성자가 여러 번 댓글을 작성했을 때 합칠 수 있도록 시도했지만 크롬 드라이버에서 많은 시간이 소요되고 있는 것을 고려하여 무모하게 반복된 댓글이 작성되지는 않았을 것이라고 가정하고, 추출된 날짜를 추가한 각 댓글을 고유한 것으로 간주했어요.\n\n\n<div class=\"content-ad\"></div>\n\n크롬 드라이버를 헤드리스 모드로 실행하여 응답 속도를 높였어요. 코드에서 주석 처리하고 실행해보셔도 돼요. 만약 더 빠른 스크래핑 방법을 찾으시면 댓글로 알려주세요. François St-Amant의 코드를 참고했어요.\n\n링크 — [여기](https://towardsdatascience.com/how-to-scrape-youtube-comments-with-python-61ff197115d)\n\n```python\nimport pandas as pd\ndf = pd.DataFrame(data, columns=['comment'])\ndf.head()\n```\n\n![이미지](/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_1.png)\n\n<div class=\"content-ad\"></div>\n\n지금은 Perplexity.ai와 함께 이 동영상에서 언급된 향수 목록을 두 번째 데이터프레임으로 가지고 있어요. 이 목록은 수동으로 가져왔지만 파이썬을 사용하여 동영상을 구문 분석하여 수행할 수도 있지만 그것은 다른 날을 위해 저장합시다. 또한 이에 대한 YouTube 동영상 요약기를 확인할 수도 있는데, 이것은 제 친구 Priyanshu Shukla가 만들었어요 – https://medium.com/@priyanshu-shkl7/implementing-generative-ai-into-your-apps-web-scraping-with-genai-f08711a404cb\n\n![이미지](/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_2.png)\n\n이제 NLP 부분으로 넘어가볼게요. 간단히 말씀드리면, 댓글 내에서 언급된 Tom Ford의 다양한 향수들을 얻으려고 노력 중이에요. 기본적으로 언급에 따라 각 향수를 지정하고 활동이 가장 많은 순서대로 정렬 중이에요.\n\n이를 달성하기 위해 다양한 방법이 있지만, 저는 NLTK(Natural Language Toolkit)를 사용했어요. NLTK는 파이썬에서 인간의 언어 데이터를 처리하는 강력한 라이브러리예요. 이는 자연어 처리(NLP) 작업에 널리 사용되며, 의미론적 키워드 일치 및 감성 분석과 같은 작업에 적합해요.\n\n<div class=\"content-ad\"></div>\n\nHuggingFace에서 제공하는 최고의 sentence transformers 중 하나를 사용하여 의미론적 문자열 매칭을 수행하거나 사용할 수 있습니다. 또한, 동일한 작업을 수행하기 위해 사용 가능한 LLM들을 사용할 수도 있지만 대규모 데이터셋에 대한 프로덕션 배포의 경우 sentence transformers가 가장 적합할 것입니다.\n\n```python\n!pip install nltk\nimport nltk\nnltk.download('vader_lexicon')\n```\n\n```python\nimport pandas as pd\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\ndef calculate_sentiment_scores(comments, perfumes):\n    sentiment_scores = {str(perfume): [] for perfume in perfumes}\n    \n    sid = SentimentIntensityAnalyzer()\n    \n    for _, row in comments.iterrows():\n        comment = str(row['Comment'])\n        user_id = row['User ID']\n        sentiment_dict = sid.polarity_scores(comment)\n        \n        compound_score = sentiment_dict['compound']\n        \n        for perfume in perfumes:\n            if str(perfume).lower() in comment.lower():\n                sentiment_scores[str(perfume)].append((user_id, comment, compound_score))\n    \n    return sentiment_scores\n\n# Load the comments DataFrame\ndf_comments = df\n\n# Load the perfumes DataFrame\ndf_perfumes = df2\n\n# Extract perfumes from df_perfumes\nperfumes = df2.iloc[:, 0].tolist()\n\n# Calculate sentiment scores for each perfume in the comments\nsentiment_scores = calculate_sentiment_scores(df_comments, perfumes)\n\n# Create a new DataFrame with 'user_id', 'comment', 'perfume', and 'sentiment_score' columns\ndata = []\nfor perfume, user_comment_list in sentiment_scores.items():\n    for user_id, comment, sentiment_score in user_comment_list:\n        data.append([user_id, comment, perfume, sentiment_score])\n\ndf_result = pd.DataFrame(data, columns=['user_id', 'comment', 'perfume', 'sentiment_score'])\n\n# Print the resulting DataFrame\nprint(\"User Comments with Sentiment Scores:\")\ndf_result\n```\n\n![YouTube Comments](/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_3.png)\n\n\n<div class=\"content-ad\"></div>\n\n위에서 보듯이, 각 댓글에는 때때로 하나 이상의 향수가 언급되어서 각 향수에 대한 점수가 계산됩니다. 그래서 \"나는 블랙 오키드를 소유하고 있다\"는 댓글은 Beau de jour를 가지고 있습니다. 그래서 Beau de jour와 black orchid 각각 한 번씩 나타납니다.\n\n하지만 이에 더해, 만일 우리가 이 감정 분석과 키워드 일치를 확인해야 한다면, 이를 위해 Tableau로 간단한 대시보드를 구축했습니다. Tableau 대시보드를 사용하면 빠르게 향수들과 그들의 감정 점수를 필터링할 수 있습니다.\n\n[![테이블로 대시보드](/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_4.png)](https://public.tableau.com/views/YoutubeSentimentAnalysis/YoutubeComments-NLPAnalysis?:language=en-GB&:sid=&:display_count=n&:origin=viz_share_link)\n\n<div class=\"content-ad\"></div>\n\n어떤 생각이든 자유롭게 공유해 주시고, 댓글을 남기셔서 제 소식을 받아보세요! 읽어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_0.png"},"coverImage":"/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_0.png","tag":["Tech"],"readingTime":7},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_0.png\" alt=\"image\"></p>\n<p>간단한 NLP 프로젝트를 시도해보고자 했는데, 유튜브 동영상에서 댓글을 가져와 분석해보려고 합니다.</p>\n<p>사실 향수에 대해 연구 중이었는데, 인스타그램을 무심코 스크롤하다가 향수 광고에 끌려들어가게 되었습니다. 그렇게해서 향수 리뷰 동영상들을 찾게 되었고, Demi Rawling의 향수 리뷰 동영상을 발견하게 되었습니다... (너무 핫하네요).</p>\n<p>유튜브 링크 - <a href=\"https://youtu.be/oJqc2tLMObg\" rel=\"nofollow\" target=\"_blank\">https://youtu.be/oJqc2tLMObg</a></p>\n<div class=\"content-ad\"></div>\n<p>이 동영상은 탑 10 톰 포드 향수에 관한 것입니다. 다소 오래된 동영상이긴 하지만(4년 전 영상입니다)</p>\n<p>먼저, 만약 설치되어 있지 않다면 이곳에서 ChromeDriver를 설치해주세요. 저는 VS Code에서 실행을 시도해봤어요. 필요한 라이브러리는 다음과 같아요...</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">import</span> time\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> datetime <span class=\"hljs-keyword\">import</span> datetime\n<span class=\"hljs-keyword\">from</span> selenium <span class=\"hljs-keyword\">import</span> webdriver\n<span class=\"hljs-keyword\">from</span> selenium.<span class=\"hljs-property\">webdriver</span>.<span class=\"hljs-property\">common</span>.<span class=\"hljs-property\">keys</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">Keys</span>\n<span class=\"hljs-keyword\">from</span> selenium.<span class=\"hljs-property\">webdriver</span>.<span class=\"hljs-property\">common</span>.<span class=\"hljs-property\">by</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">By</span>\n<span class=\"hljs-keyword\">from</span> selenium.<span class=\"hljs-property\">webdriver</span>.<span class=\"hljs-property\">support</span>.<span class=\"hljs-property\">ui</span> <span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">WebDriverWait</span>\n<span class=\"hljs-keyword\">from</span> selenium.<span class=\"hljs-property\">webdriver</span>.<span class=\"hljs-property\">support</span> <span class=\"hljs-keyword\">import</span> expected_conditions <span class=\"hljs-keyword\">as</span> <span class=\"hljs-variable constant_\">EC</span>\n</code></pre>\n<p>그런 다음 스크래핑 부분이 나옵니다...</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> selenium <span class=\"hljs-keyword\">import</span> webdriver\n<span class=\"hljs-keyword\">from</span> selenium.webdriver.common.keys <span class=\"hljs-keyword\">import</span> Keys\n<span class=\"hljs-keyword\">from</span> selenium.webdriver.common.by <span class=\"hljs-keyword\">import</span> By\n<span class=\"hljs-keyword\">from</span> selenium.webdriver.support.ui <span class=\"hljs-keyword\">import</span> WebDriverWait\n<span class=\"hljs-keyword\">from</span> selenium.webdriver.support <span class=\"hljs-keyword\">import</span> expected_conditions <span class=\"hljs-keyword\">as</span> EC\n<span class=\"hljs-keyword\">import</span> time\n<span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">from</span> datetime <span class=\"hljs-keyword\">import</span> datetime\n\n<span class=\"hljs-comment\"># WebDriver를 초기화하고 성능을 향상시키기 위한 옵션 설정</span>\noptions = webdriver.ChromeOptions()\noptions.add_argument(<span class=\"hljs-string\">\"--headless\"</span>)  <span class=\"hljs-comment\"># 헤드리스 모드로 실행</span>\noptions.add_argument(<span class=\"hljs-string\">\"--disable-gpu\"</span>)  <span class=\"hljs-comment\"># GPU 렌더링 비활성화</span>\noptions.add_argument(<span class=\"hljs-string\">\"--no-sandbox\"</span>)  <span class=\"hljs-comment\"># OS 보안 모델 우회</span>\noptions.add_argument(<span class=\"hljs-string\">\"--disable-dev-shm-usage\"</span>)  <span class=\"hljs-comment\"># 제한된 리소스 문제 극복</span>\noptions.add_argument(<span class=\"hljs-string\">\"--start-maximized\"</span>)  <span class=\"hljs-comment\"># 창 최대화</span>\n\ndriver = webdriver.Chrome(options=options)\n\ndata = []\nyoutube_video_url = <span class=\"hljs-string\">\"https://youtu.be/oJqc2tLMObg\"</span>\nwait = WebDriverWait(driver, <span class=\"hljs-number\">30</span>) \n\n<span class=\"hljs-comment\"># YouTube 비디오 URL 열기</span>\ndriver.get(youtube_video_url)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"YouTube URL을 열었습니다.\"</span>)\n\n<span class=\"hljs-comment\"># 댓글을 로드하기 위해 스크롤 다운</span>\n<span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">150</span>):  <span class=\"hljs-comment\"># 여기에 스크롤 횟수 정의</span>\n    <span class=\"hljs-keyword\">try</span>:\n        body = wait.until(EC.visibility_of_element_located((By.TAG_NAME, <span class=\"hljs-string\">\"body\"</span>)))\n        body.send_keys(Keys.END)\n        sys.stdout.write(<span class=\"hljs-string\">f\"\\r<span class=\"hljs-subst\">{item + <span class=\"hljs-number\">1</span>}</span>번 스크롤 중\"</span>)\n        sys.stdout.flush()\n        time.sleep(<span class=\"hljs-number\">1.5</span>)  <span class=\"hljs-comment\"># 로딩을 위한 시간 증가</span>\n    <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"스크롤 중 예외 발생: <span class=\"hljs-subst\">{e}</span>\"</span>)\n        <span class=\"hljs-keyword\">break</span>\n\n<span class=\"hljs-comment\"># 댓글 추출</span>\n<span class=\"hljs-keyword\">try</span>:\n    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, <span class=\"hljs-string\">\"#contents #contents\"</span>)))\n    comments = driver.find_elements(By.CSS_SELECTOR, <span class=\"hljs-string\">\"#content #content-text\"</span>)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"\\n<span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(comments)}</span>개의 댓글 요소를 찾았습니다.\"</span>)\n\n    user_id = <span class=\"hljs-number\">1</span>  <span class=\"hljs-comment\"># 고유한 사용자 ID 초기화</span>\n    <span class=\"hljs-keyword\">for</span> comment <span class=\"hljs-keyword\">in</span> comments:\n        timestamp = datetime.now().strftime(<span class=\"hljs-string\">\"%Y-%m-%d %H:%M:%S\"</span>)\n        data.append({<span class=\"hljs-string\">\"사용자 ID\"</span>: user_id, <span class=\"hljs-string\">\"댓글\"</span>: comment.text, <span class=\"hljs-string\">\"타임스탬프\"</span>: timestamp})\n        user_id += <span class=\"hljs-number\">1</span>\n\n    <span class=\"hljs-comment\"># 중복 제거</span>\n    data = [<span class=\"hljs-built_in\">dict</span>(t) <span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> {<span class=\"hljs-built_in\">tuple</span>(d.items()) <span class=\"hljs-keyword\">for</span> d <span class=\"hljs-keyword\">in</span> data}]\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"캡처된 댓글 수: <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(data)}</span>\"</span>)\n<span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"댓글 추출 중 예외 발생: <span class=\"hljs-subst\">{e}</span>\"</span>)\n\ndriver.quit()\n\n<span class=\"hljs-comment\"># DataFrame 생성</span>\ndf = pd.DataFrame(data, columns=[<span class=\"hljs-string\">\"사용자 ID\"</span>, <span class=\"hljs-string\">\"댓글\"</span>, <span class=\"hljs-string\">\"타임스탬프\"</span>])\n\n<span class=\"hljs-comment\"># DataFrame 표시</span>\n<span class=\"hljs-built_in\">print</span>(df)\n\n<span class=\"hljs-comment\"># DataFrame을 CSV 파일로 저장 (선택 사항)</span>\ndf.to_csv(<span class=\"hljs-string\">\"youtube_comments.csv\"</span>, index=<span class=\"hljs-literal\">False</span>)\n</code></pre>\n<p>여기서 댓글을 스크래핑하기 위해 스크롤 수를 사용했어요. 댓글 수의 최대값으로 변환할 수도 있지만, 현재 이 방법이 가장 잘 작동합니다.</p>\n<p>그래서 이 몇 가지 가정과 제약들이 있어요.</p>\n<p>가정과 제약사항: 각 댓글의 사용자 이름을 스크래핑하여 하나의 작성자가 여러 번 댓글을 작성했을 때 합칠 수 있도록 시도했지만 크롬 드라이버에서 많은 시간이 소요되고 있는 것을 고려하여 무모하게 반복된 댓글이 작성되지는 않았을 것이라고 가정하고, 추출된 날짜를 추가한 각 댓글을 고유한 것으로 간주했어요.</p>\n<div class=\"content-ad\"></div>\n<p>크롬 드라이버를 헤드리스 모드로 실행하여 응답 속도를 높였어요. 코드에서 주석 처리하고 실행해보셔도 돼요. 만약 더 빠른 스크래핑 방법을 찾으시면 댓글로 알려주세요. François St-Amant의 코드를 참고했어요.</p>\n<p>링크 — <a href=\"https://towardsdatascience.com/how-to-scrape-youtube-comments-with-python-61ff197115d\" rel=\"nofollow\" target=\"_blank\">여기</a></p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\ndf = pd.DataFrame(data, columns=[<span class=\"hljs-string\">'comment'</span>])\ndf.head()\n</code></pre>\n<p><img src=\"/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_1.png\" alt=\"이미지\"></p>\n<div class=\"content-ad\"></div>\n<p>지금은 Perplexity.ai와 함께 이 동영상에서 언급된 향수 목록을 두 번째 데이터프레임으로 가지고 있어요. 이 목록은 수동으로 가져왔지만 파이썬을 사용하여 동영상을 구문 분석하여 수행할 수도 있지만 그것은 다른 날을 위해 저장합시다. 또한 이에 대한 YouTube 동영상 요약기를 확인할 수도 있는데, 이것은 제 친구 Priyanshu Shukla가 만들었어요 – <a href=\"https://medium.com/@priyanshu-shkl7/implementing-generative-ai-into-your-apps-web-scraping-with-genai-f08711a404cb\" rel=\"nofollow\" target=\"_blank\">https://medium.com/@priyanshu-shkl7/implementing-generative-ai-into-your-apps-web-scraping-with-genai-f08711a404cb</a></p>\n<p><img src=\"/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_2.png\" alt=\"이미지\"></p>\n<p>이제 NLP 부분으로 넘어가볼게요. 간단히 말씀드리면, 댓글 내에서 언급된 Tom Ford의 다양한 향수들을 얻으려고 노력 중이에요. 기본적으로 언급에 따라 각 향수를 지정하고 활동이 가장 많은 순서대로 정렬 중이에요.</p>\n<p>이를 달성하기 위해 다양한 방법이 있지만, 저는 NLTK(Natural Language Toolkit)를 사용했어요. NLTK는 파이썬에서 인간의 언어 데이터를 처리하는 강력한 라이브러리예요. 이는 자연어 처리(NLP) 작업에 널리 사용되며, 의미론적 키워드 일치 및 감성 분석과 같은 작업에 적합해요.</p>\n<div class=\"content-ad\"></div>\n<p>HuggingFace에서 제공하는 최고의 sentence transformers 중 하나를 사용하여 의미론적 문자열 매칭을 수행하거나 사용할 수 있습니다. 또한, 동일한 작업을 수행하기 위해 사용 가능한 LLM들을 사용할 수도 있지만 대규모 데이터셋에 대한 프로덕션 배포의 경우 sentence transformers가 가장 적합할 것입니다.</p>\n<pre><code class=\"hljs language-python\">!pip install nltk\n<span class=\"hljs-keyword\">import</span> nltk\nnltk.download(<span class=\"hljs-string\">'vader_lexicon'</span>)\n</code></pre>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">from</span> nltk.sentiment <span class=\"hljs-keyword\">import</span> SentimentIntensityAnalyzer\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">calculate_sentiment_scores</span>(<span class=\"hljs-params\">comments, perfumes</span>):\n    sentiment_scores = {<span class=\"hljs-built_in\">str</span>(perfume): [] <span class=\"hljs-keyword\">for</span> perfume <span class=\"hljs-keyword\">in</span> perfumes}\n    \n    sid = SentimentIntensityAnalyzer()\n    \n    <span class=\"hljs-keyword\">for</span> _, row <span class=\"hljs-keyword\">in</span> comments.iterrows():\n        comment = <span class=\"hljs-built_in\">str</span>(row[<span class=\"hljs-string\">'Comment'</span>])\n        user_id = row[<span class=\"hljs-string\">'User ID'</span>]\n        sentiment_dict = sid.polarity_scores(comment)\n        \n        compound_score = sentiment_dict[<span class=\"hljs-string\">'compound'</span>]\n        \n        <span class=\"hljs-keyword\">for</span> perfume <span class=\"hljs-keyword\">in</span> perfumes:\n            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">str</span>(perfume).lower() <span class=\"hljs-keyword\">in</span> comment.lower():\n                sentiment_scores[<span class=\"hljs-built_in\">str</span>(perfume)].append((user_id, comment, compound_score))\n    \n    <span class=\"hljs-keyword\">return</span> sentiment_scores\n\n<span class=\"hljs-comment\"># Load the comments DataFrame</span>\ndf_comments = df\n\n<span class=\"hljs-comment\"># Load the perfumes DataFrame</span>\ndf_perfumes = df2\n\n<span class=\"hljs-comment\"># Extract perfumes from df_perfumes</span>\nperfumes = df2.iloc[:, <span class=\"hljs-number\">0</span>].tolist()\n\n<span class=\"hljs-comment\"># Calculate sentiment scores for each perfume in the comments</span>\nsentiment_scores = calculate_sentiment_scores(df_comments, perfumes)\n\n<span class=\"hljs-comment\"># Create a new DataFrame with 'user_id', 'comment', 'perfume', and 'sentiment_score' columns</span>\ndata = []\n<span class=\"hljs-keyword\">for</span> perfume, user_comment_list <span class=\"hljs-keyword\">in</span> sentiment_scores.items():\n    <span class=\"hljs-keyword\">for</span> user_id, comment, sentiment_score <span class=\"hljs-keyword\">in</span> user_comment_list:\n        data.append([user_id, comment, perfume, sentiment_score])\n\ndf_result = pd.DataFrame(data, columns=[<span class=\"hljs-string\">'user_id'</span>, <span class=\"hljs-string\">'comment'</span>, <span class=\"hljs-string\">'perfume'</span>, <span class=\"hljs-string\">'sentiment_score'</span>])\n\n<span class=\"hljs-comment\"># Print the resulting DataFrame</span>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"User Comments with Sentiment Scores:\"</span>)\ndf_result\n</code></pre>\n<p><img src=\"/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_3.png\" alt=\"YouTube Comments\"></p>\n<div class=\"content-ad\"></div>\n<p>위에서 보듯이, 각 댓글에는 때때로 하나 이상의 향수가 언급되어서 각 향수에 대한 점수가 계산됩니다. 그래서 \"나는 블랙 오키드를 소유하고 있다\"는 댓글은 Beau de jour를 가지고 있습니다. 그래서 Beau de jour와 black orchid 각각 한 번씩 나타납니다.</p>\n<p>하지만 이에 더해, 만일 우리가 이 감정 분석과 키워드 일치를 확인해야 한다면, 이를 위해 Tableau로 간단한 대시보드를 구축했습니다. Tableau 대시보드를 사용하면 빠르게 향수들과 그들의 감정 점수를 필터링할 수 있습니다.</p>\n<p><a href=\"https://public.tableau.com/views/YoutubeSentimentAnalysis/YoutubeComments-NLPAnalysis?:language=en-GB&#x26;:sid=&#x26;:display_count=n&#x26;:origin=viz_share_link\" rel=\"nofollow\" target=\"_blank\"><img src=\"/assets/img/2024-06-22-ScrapingYoutubeCommentsforNLPAnalysis_4.png\" alt=\"테이블로 대시보드\"></a></p>\n<div class=\"content-ad\"></div>\n<p>어떤 생각이든 자유롭게 공유해 주시고, 댓글을 남기셔서 제 소식을 받아보세요! 읽어 주셔서 감사합니다!</p>\n</body>\n</html>\n"},"__N_SSG":true}