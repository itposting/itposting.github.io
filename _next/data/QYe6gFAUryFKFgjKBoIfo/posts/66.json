{"pageProps":{"posts":[{"title":"ì™œ ë‚˜ëŠ” ê¸€ì“°ê¸°ë¥¼ ê·¸ë§Œë‘ì§€ ì•Šì„ ê²ƒì¸ì§€ ì´ìœ ","description":"","date":"2024-06-19 18:52","slug":"2024-06-19-ThisIsWhyIWillNotStopWriting","content":"\n\nê³¼ê±° ì‘í’ˆë“¤ì„ í›‘ì–´ë³´ë©´ ë‚¯ì„  ì‚¬ëŒì²˜ëŸ¼ ëŠê»´ì§€ê¸°ë„ í•´ìš”. ë§ˆì¹˜ ë°•ë¬¼ê´€ì—ì„œ ìœ ë¬¼ì„ ë’¤ì ì´ëŠ” ì†ë‹˜ ê°™ì•„ìš”. ì˜ˆì „ì— ì¼ë˜ ê²ƒë“¤ì´ ë‹¤ì‹œ ìœ ìš©í•˜ê²Œ ì“°ì¼ ë•Œê°€ ìˆì–´ì„œ ë”ìš± ë†€ëë„¤ìš”. ë§ˆì¹˜ í•„ìš”ì„±ì„ ì˜ˆê²¬í•˜ê³  ë¯¸ë¦¬ í•´ê²°ì±…ì„ ì¤€ë¹„í•œ ê²ƒ ê°™ì•„ìš”.\n\nê°€ë” ì¨ë³¸ ë§ë“¤ì´ ë‹¹ì‹œ ëŠê¼ˆë˜ ê°ì •ì„ ìƒê¸°í•˜ë ¤ê³  ë…¸ë ¥í•´ìš”. ë•Œë¡œëŠ” ì„±ê³µë„ í•´ë³´ì§€ë§Œ, ë•Œë¡œëŠ” ê·¸ë ‡ì§€ ëª»í•  ë•Œë„ ìˆì–´ìš”. ë•Œë¡œëŠ” í•œ ë§ˆë””ë¡œ ë‹¹ì‹œì˜ ê°ì •ê³¼ ë¨¸ë¦¿ ì† ìƒíƒœë¥¼ ì •í™•íˆ ë– ì˜¬ë¦´ ìˆ˜ë„ ìˆê³ , ë‹¤ë¥¸ ë•Œì—ëŠ” ì—¬ëŸ¬ ë‹¨ì–´ë¥¼ ë°˜ë³µí•´ë„ ë‹¹ì‹œì˜ ê°ì •ê³¼ ì—°ê´€ì„ ì°¾ì§€ ëª»í•  ë•Œë„ ìˆì–´ìš”.\n\n![image](/assets/img/2024-06-19-ThisIsWhyIWillNotStopWriting_0.png)\n\nì €ëŠ” ê°•ë ¥íˆ ë¯¿ì–´ìš”. ìš°ì£¼ëŠ” í˜„ì¬ì˜ ê´€ì ì„ í†µí•´ ìš°ë¦¬ì˜ ê³¼ê±°ë¥¼ ë‹¤ì‹œ ë°©ë¬¸í•˜ëŠ” ê²ƒ ê°™ì•„ìš”. ê·¸ë˜ì„œ ì–´ë–¤ ê²½í—˜ì´ ìƒˆë¡­ê¸´ í•˜ì§€ë§Œ, ê³¼ê±° ì–´ëŠ ë•Œì™€ë„ ì „í˜€ ë¬´ê´€í•œ ê²ƒì€ ì•„ë‹ˆì—ìš”. ê°ì •ì€ ë§ˆì¹˜ ê·¸ë¦‡ì²˜ëŸ¼ ì•ë’¤ë¡œ í”ë“¤ë¦¬ë©´ì„œ, ê³¼ê±°ì˜ ê°ì •ì„ í˜€ëìœ¼ë¡œ ë§› ë³¼ ìˆ˜ ìˆì„ ì •ë„ë¡œ ìˆœê°„ìˆœê°„ ë³€í•˜ê¸°ë„ í•´ìš”.\n\n<div class=\"content-ad\"></div>\n\nê·¸ë˜ì„œ ë‚œ ê¸€ì“°ê¸°ë¥¼ ë©ˆì¶”ì§€ ì•Šì„ ê±°ì•¼. ìš°ì£¼ê°€ ë‹¤ë¥¸ ì´ë“¤ì„ ìœ„í•´ ì¼ë‹¤ëŠ” í•‘ê³„ë¡œ ë‚˜ì—ê²Œ ë¯¸ë˜ í¸ì§€ë¥¼ ì“°ë¼ê³  ìš”ì²­í•˜ëŠ” ê²ƒì²˜ëŸ¼. ì˜¤ëŠ˜ ì¼ë˜ ì´ ë§ë“¤ì´ ë‹¤ìŒ 10ë…„ í›„ì— ë„ì›€ì´ ë ì§€ë„ ëª°ë¼. ì´ê²ƒì€ ë‚´ ê°ì •ì„ ë‹´ëŠ” ì°½ê³ ì´ë©°, ë°˜ë³µë˜ëŠ” íŒ¨í„´ì„ ë°œê²¬í–ˆê¸° ë•Œë¬¸ì´ë‹¤.","ogImage":{"url":"/assets/img/2024-06-19-ThisIsWhyIWillNotStopWriting_0.png"},"coverImage":"/assets/img/2024-06-19-ThisIsWhyIWillNotStopWriting_0.png","tag":["Tech"],"readingTime":1},{"title":"ìœ„ì„± ì´ë¯¸ì§€ì—ì„œ GANsì ëŒ€ì  ìƒì„± ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ë¦„ ì œê±°í•˜ê¸°","description":"","date":"2024-06-19 18:49","slug":"2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks","content":"\n\n## íŒŒì´ì¬ìœ¼ë¡œë¶€í„° GAN(Generative Adversarial Networks) ë§Œë“¤ì–´ ë³´ê¸°\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png)\n\nGAN(Generative Adversarial Networks)ì´ë¼ëŠ” ì•„ì´ë””ì–´ëŠ” 2014ë…„ Goodfellowì™€ ê·¸ ë™ë£Œë“¤ì— ì˜í•´ ì†Œê°œë˜ì—ˆê³ , ê³§ ê·¸ ì´í›„ì— ì»´í“¨í„° ë¹„ì „ ë° ì´ë¯¸ì§€ ìƒì„± ë¶„ì•¼ì—ì„œ ê·¹ë„ë¡œ ì¸ê¸°ë¥¼ ëŒê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì—ì„œì˜ ê¸‰ì†í•œ ë°œì „ê³¼ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ë”ë¼ë„, ì´ ê°œë…ì˜ ë‹¨ìˆœí•¨ê³¼ ì°½ì˜ì„±ì€ ì—¬ì „íˆ ë§¤ìš° ì¸ìƒì ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ì˜¤ëŠ˜ì€ ì´ëŸ¬í•œ ë„¤íŠ¸ì›Œí¬ê°€ ì–¼ë§ˆë‚˜ ê°•ë ¥í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ìœ„ì„± RGB(ë¹¨ê°•, ë…¹ìƒ‰, íŒŒë‘) ì´ë¯¸ì§€ì—ì„œ êµ¬ë¦„ì„ ì œê±°í•˜ëŠ” ì‹œë„ë¥¼ í•´ë³´ë ¤ê³  í•©ë‹ˆë‹¤.\n\nì ì ˆíˆ ê· í˜• ì¡íˆê³  ì¶©ë¶„íˆ í¬ë©° ì˜¬ë°”ë¥´ê²Œ ì „ì²˜ë¦¬ëœ ì»´í“¨í„° ë¹„ì „ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ëŠ” ë°ì—ëŠ” ìƒë‹¹í•œ ì‹œê°„ì´ ì†Œìš”ë˜ë¯€ë¡œ, ì €ëŠ” Kaggleì— ì–´ë–¤ ê²ƒì´ ìˆëŠ”ì§€ ì‚´í´ë³´ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì— ê°€ì¥ ì í•©í•˜ë‹¤ê³  ìƒê°í•œ ë°ì´í„°ì…‹ì€ EuroSatì´ë©°, ì´ëŠ” ì˜¤í”ˆ ë¼ì´ì„ ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ Sentinel-2ì—ì„œ 64x64 í”½ì…€ì˜ 27000ê°œì˜ ë ˆì´ë¸”ì´ ì§€ì •ëœ RGB ì´ë¯¸ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_1.png)\n\nìš°ë¦¬ëŠ” ë¶„ë¥˜ ìì²´ì— í¥ë¯¸ê°€ ì—†ì§€ë§Œ EuroSat ë°ì´í„°ì…‹ì˜ ì£¼ìš” ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” ëª¨ë“  ì´ë¯¸ì§€ì— ë§‘ì€ í•˜ëŠ˜ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ê²ƒì´ ì •í™•íˆ ìš°ë¦¬ê°€ í•„ìš”í•œ ê²ƒì…ë‹ˆë‹¤. [3]ì—ì„œ ì´ ì ‘ê·¼ë²•ì„ ì±„íƒí•˜ì—¬, ìš°ë¦¬ëŠ” ì´ Sentinel-2 ìƒ·ì„ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ì…ë ¥ì„ ì¶”ê°€í•˜ì—¬ (êµ¬ë¦„) ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤.\n\nê·¸ë˜ì„œ ìš°ë¦¬ê°€ GANsì— ëŒ€í•´ ì‹¤ì œë¡œ ì´ì•¼ê¸°í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ ë´…ì‹œë‹¤. ìš°ì„ , ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ëª¨ë“  í´ë˜ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ë””ë ‰í† ë¦¬ë¡œ ë³‘í•©í•´ì•¼ í•©ë‹ˆë‹¤.\n\nğŸì „ì²´ Python ì½”ë“œ: GitHub.\n\n\n<div class=\"content-ad\"></div>\n\n```js\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom os import listdir, mkdir, rename\nfrom os.path import join, exists\nimport shutil\nimport datetime\n\nimport matplotlib.pyplot as plt\nfrom highlight_text import ax_text, fig_text\nfrom PIL import Image\n\nimport warnings\n\nwarnings.filterwarnings('ignore')\n```\n\n```js\nclasses = listdir('./EuroSat')\npath_target = './EuroSat/all_targets'\npath_input = './EuroSat/all_inputs'\n\n\"\"\"UNPACKí•œ ì•„ì¹´ì´ë¸Œ íŒŒì¼ì˜ íŒŒì¼ ì´ë¦„ì„ ë³€ê²½í•˜ê¸° ìœ„í•´ ë‹¨ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ì„¸ìš”\"\"\"\nmkdir(path_input)\nmkdir(path_target)\nk = 1\nfor kind in classes:\n  path = join('./EuroSat', str(kind))\n  for i, f in enumerate(listdir(path)):\n    shutil.copyfile(join(path, f),\n                  join(path_target, f))\n    rename(join(path_target, f), join(path_target, f'{k}.jpg'))\n    k += 1\n```\n\nì¤‘ìš”í•œ ë‘ ë²ˆì§¸ ë‹¨ê³„ëŠ” ë…¸ì´ì¦ˆ ìƒì„±ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ì˜ˆë¥¼ ë“¤ì–´ ì¼ë¶€ í”½ì…€ì„ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•˜ê±°ë‚˜ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ë“±ì˜ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ê¸€ì—ì„œëŠ” ì €ëŠ” ìƒˆë¡œìš´ ë°©ì‹ì¸ Perlin ë…¸ì´ì¦ˆë¥¼ ì‹œë„í•´ ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤. Perlin ë…¸ì´ì¦ˆëŠ” 80ë…„ëŒ€ì— Ken Perlinì´ ì˜í™” ì—°ê¸° íš¨ê³¼ë¥¼ ê°œë°œí•  ë•Œ ë°œëª…í–ˆìŠµë‹ˆë‹¤. ì´ ì¢…ë¥˜ì˜ ë…¸ì´ì¦ˆëŠ” ì¼ë°˜ì ì¸ ëœë¤ ë…¸ì´ì¦ˆì— ë¹„í•´ ë” ìœ ê¸°ì ì¸ ì™¸ê´€ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì €ì—ê²Œ ì´ë¥¼ ì¦ëª…í•˜ëŠ” ê¸°íšŒë¥¼ ì£¼ì„¸ìš”.\n\n```js\ndef generate_perlin_noise(width, height, scale, octaves, persistence, lacunarity):\n    noise = np.zeros((height, width))\n    for i in range(height):\n        for j in range(width):\n            noise[i][j] = pnoise2(i / scale,\n                                  j / scale,\n                                  octaves=octaves,\n                                  persistence=persistence,\n                                  lacunarity=lacunarity,\n                                  repeatx=width,\n                                  repeaty=height,\n                                  base=0)\n    return noise\n\ndef normalize_noise(noise):\n    min_val = noise.min()\n    max_val = noise.max()\n    return (noise - min_val) / (max_val - min_val)\n\ndef generate_clouds(width, height, base_scale, octaves, persistence, lacunarity):\n    clouds = np.zeros((height, width))\n    for octave in range(1, octaves + 1):\n        scale = base_scale / octave\n        layer = generate_perlin_noise(width, height, scale, 1, persistence, lacunarity)\n        clouds += layer * (persistence ** octave)\n\n    clouds = normalize_noise(clouds)\n    return clouds\n\ndef overlay_clouds(image, clouds, alpha=0.5):\n\n    clouds_rgb = np.stack([clouds] * 3, axis=-1)\n\n    image = image.astype(float) / 255.0\n    clouds_rgb = clouds_rgb.astype(float)\n\n    blended = image * (1 - alpha) + clouds_rgb * alpha\n\n    blended = (blended * 255).astype(np.uint8)\n    return blended\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nê°€ë¡œ, ì„¸ë¡œ = 64, 64\nì˜¥íƒ€ë¸Œ = 12  # í•©ì³ì§€ëŠ” ì¡ìŒ ë ˆì´ì–´ì˜ ìˆ˜\nì§€ì†ì„± = 0.5  # ë‚®ì€ ì§€ì†ì„±ì€ ë†’ì€ ì£¼íŒŒìˆ˜ ì˜¥íƒ€ë¸Œì˜ ì§„í­ì„ ì¤„ì…ë‹ˆë‹¤.\në¼ì¿ ë‚˜ë¦¬í‹° = 2  # ë†’ì€ ë¼ì¿ ë‚˜ë¦¬í‹°ëŠ” ë†’ì€ ì£¼íŒŒìˆ˜ ì˜¥íƒ€ë¸Œì˜ ì£¼íŒŒìˆ˜ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.\nfor i in range(len(listdir(path_target))):\n  ê¸°ë³¸_ìŠ¤ì¼€ì¼ = random.uniform(5, 120)  # ì¡ìŒ ì£¼íŒŒìˆ˜\n  ì•ŒíŒŒ = random.uniform(0, 1)  # íˆ¬ëª…ë„\n\n  êµ¬ë¦„ = generate_clouds(ê°€ë¡œ, ì„¸ë¡œ, ê¸°ë³¸_ìŠ¤ì¼€ì¼, ì˜¥íƒ€ë¸Œ, ì§€ì†ì„±, ë¼ì¿ ë‚˜ë¦¬í‹°)\n\n  ì´ë¯¸ì§€ = np.asarray(Image.open(join(path_target, f'{i+1}.jpg')))\n  ì´ë¯¸ì§€ = Image.fromarray(overlay_clouds(ì´ë¯¸ì§€, êµ¬ë¦„, ì•ŒíŒŒ))\n  ì´ë¯¸ì§€.save(join(path_input, f'{i+1}.jpg'))\n  print(f'{i+1}/{len(listdir(path_target))}ë²ˆì§¸ ì²˜ë¦¬ ì™„ë£Œ')\n```\n\n```js\nì¸ë±ìŠ¤ = np.random.randint(27000)\nfig, ax = plt.subplots(1,2)\nax[0].imshow(np.asarray(Image.open(join(path_target, f'{ì¸ë±ìŠ¤}.jpg')))\nax[1].imshow(np.asarray(Image.open(join(path_input, f'{ì¸ë±ìŠ¤}.jpg')))\nax[0].set_title(\"ì›ë³¸\")\nax[0].axis('off')\nax[1].set_title(\"ì…ë ¥\")\nax[1].axis('off')\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_2.png\" />\n\nìœ„ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ì´ë¯¸ì§€ì˜ êµ¬ë¦„ì€ ë§¤ìš° í˜„ì‹¤ì ì´ë©° ë‹¤ì–‘í•œ \"ë°€ë„\"ì™€ ì§ˆê°ì„ ê°€ì§€ë©° ì‹¤ì œ êµ¬ë¦„ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\në§Œì•½ ì €ì²˜ëŸ¼ Perlin ì†ŒìŒì— í¥ë¯¸ë¥¼ ëŠë‚€ë‹¤ë©´, ê²Œì„ ê°œë°œ ì‚°ì—…ì—ì„œ ì´ ì†ŒìŒì´ ì–´ë–»ê²Œ ì ìš©ë  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ ì •ë§ ë©‹ì§„ ë¹„ë””ì˜¤ê°€ ìˆì–´ìš”!\n\nì´ì œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ëœ ë°ì´í„°ì…‹ì´ ìˆìœ¼ë‹ˆ, GANsì— ëŒ€í•´ ì´ì•¼ê¸°í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n\n# ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§\n\nì´ ì•„ì´ë””ì–´ë¥¼ ë” ì˜ ì„¤ëª…í•˜ê¸° ìœ„í•´, ë™ë‚¨ì•„ì‹œì•„ë¥¼ ì—¬í–‰í•˜ë‹¤ê°€ ë°–ì´ ë„ˆë¬´ ì¶¥ë‹¤ê³  ëŠë‚„ ë•Œ í›„ë””ê°€ ì ˆì‹¤í•˜ê²Œ í•„ìš”í•˜ë‹¤ê³  ìƒìƒí•´ ë³´ì„¸ìš”. ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬ ì‹œì¥ì— ê°€ë³´ë‹ˆ, ëª‡ ê°€ì§€ ë¸Œëœë“œ ì˜ë¥˜ê°€ ìˆëŠ” ì‘ì€ ê°€ê²Œë¥¼ ë°œê²¬í–ˆì–´ìš”. íŒë§¤ìê°€ ìœ ëª…í•œ ë¸Œëœë“œ ExpensiveButNotWorthItì˜ í›„ë””ë¥¼ ì‹œë„í•´ë³´ë¼ë©° ê´œì°®ì€ í›„ë””ë¥¼ ê°€ì ¸ë‹¤ì¤ë‹ˆë‹¤. ë” ìì„¸íˆ ì‚´í´ë³´ê³  ë¶„ëª…íˆ ê°€ì§œë¼ê³  ê²°ë¡  ë‚´ë¦¬ê²Œ ë©ë‹ˆë‹¤. íŒë§¤ìê°€ ë§í•©ë‹ˆë‹¤: 'ì ì‹œë§Œìš”, ì§„ì§œ ê²ƒì´ ìˆì–´ìš”.' ê·¸ê°€ ë‹¤ë¥¸ í›„ë””ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë°, ë¸Œëœë“œ ì œí’ˆê³¼ ë” ë‹®ì•˜ì§€ë§Œ ì—¬ì „íˆ ê°€ì§œì…ë‹ˆë‹¤. ì´ì™€ ê°™ì€ ë°˜ë³µ ì‘ì—…ì„ ëª‡ ë²ˆ ê±°ì¹œ í›„, íŒë§¤ìê°€ ì „ì„¤ì ì¸ ExpensiveButNotWorthItì˜ êµ¬ë³„ì´ ì–´ë ¤ìš´ ì‚¬ë³¸ì„ ê°€ì ¸ì™€ ì—¬ëŸ¬ë¶„ì€ ê¸°êº¼ì´ êµ¬ë§¤í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ GANsê°€ ì‘ë™í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤!\n\n<div class=\"content-ad\"></div>\n\nGANì˜ ê²½ìš°, ë‹¹ì‹ ì€ íŒë³„ì(D)ë¼ê³  ë¶ˆë¦½ë‹ˆë‹¤. íŒë³„ìì˜ ëª©í‘œëŠ” ì§„ì§œ ë¬¼ì²´ì™€ ê°€ì§œ ë¬¼ì²´ë¥¼ êµ¬ë³„í•˜ê±°ë‚˜ ì´ì§„ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ì— ë°˜í•´, ìƒì„±ì(G)ëŠ” ë†’ì€ í’ˆì§ˆì˜ ê°€ì§œë¥¼ ìƒì„±í•˜ë ¤ê³  í•˜ëŠ” íŒë§¤ìë¼ê³  ë¶ˆë¦½ë‹ˆë‹¤. íŒë³„ìì™€ ìƒì„±ìëŠ” ì„œë¡œ ëŠ¥ê°€í•˜ê¸° ìœ„í•´ ë…ë¦½ì ìœ¼ë¡œ í›ˆë ¨ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ìµœì¢…ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” ë†’ì€ í’ˆì§ˆì˜ ê°€ì§œë¥¼ ì–»ìŠµë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_3.png)\n\ní›ˆë ¨ ê³¼ì •ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰ë©ë‹ˆë‹¤:\n\n- ì…ë ¥ ë…¸ì´ì¦ˆë¥¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤ (ìš°ë¦¬ì˜ ê²½ìš° êµ¬ë¦„ì´ ìˆëŠ” ì´ë¯¸ì§€).\n- ë…¸ì´ì¦ˆë¥¼ ìƒì„±ì(G)ì— ê³µê¸‰í•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n- D ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. Gì˜ ì¶œë ¥ì— ëŒ€í•œ í•˜ë‚˜ì™€ ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•œ ë‹¤ë¥¸ ì˜ˆì¸¡ì„ ì–»ì–´ì„œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n- Dì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n- ë‹¤ì‹œ ì…ë ¥ ë…¸ì´ì¦ˆë¥¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.\n- ë…¸ì´ì¦ˆë¥¼ ìƒì„±ì(G)ì— ê³µê¸‰í•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n- G ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. Gì˜ ì˜ˆì¸¡ì„ Dì— ê³µê¸‰í•˜ì—¬ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.\n- Gì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n\n![Erasing Clouds from Satellite Imagery Using GANs](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_4.png)\n\nIn other words, we can define a value function V(G,D):\n\n![Value function V(G,D)](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_5.png)\n\nwhere we want to minimize the term log(1-D(G(z))) to train G and maximize log D(x) to train D (in this notation x â€” real data sample and z â€” noise).\n\n\n<div class=\"content-ad\"></div>\n\nì´ì œ íŒŒì´í† ì¹˜ì—ì„œ êµ¬í˜„í•´ ë´…ì‹œë‹¤!\n\nì›ë³¸ ë…¼ë¬¸ì—ì„œ ì €ìë“¤ì€ Multilayer Perceptron (MLP)ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì— ëŒ€í•´ ì–¸ê¸‰í•©ë‹ˆë‹¤; ì´ê²ƒì€ ANNìœ¼ë¡œ ê°„ë‹¨íˆë„ ë¶ˆë¦½ë‹ˆë‹¤ë§Œ, ì €ëŠ” ë¯¸ì„¸í•œ ì ‘ê·¼ì„ ì‹œë„í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤ â€” Generatorë¡œ UNet [5] ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ê³ , Discriminatorë¡œëŠ” ResNet [6]ì„ ì‚¬ìš©í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì´ë“¤ì€ ë‘˜ ë‹¤ ì˜ ì•Œë ¤ì§„ CNN ì•„í‚¤í…ì²˜ì´ê¸° ë•Œë¬¸ì— ì—¬ê¸°ì„œ ì„¤ëª…í•˜ì§€ëŠ” ì•Šê² ìŠµë‹ˆë‹¤ (ëŒ“ê¸€ì—ì„œ ë³„ë„ì˜ ê¸€ì„ ì“¸ì§€ ì—¬ë¶€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”).\n\nì´ì œ êµ¬ì¶•í•´ ë´…ì‹œë‹¤. Discriminator:\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom torch.utils.data import Subset\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n                        nn.BatchNorm2d(out_channels),\n                        nn.ReLU())\n        self.conv2 = nn.Sequential(\n                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n                        nn.BatchNorm2d(out_channels))\n        self.downsample = downsample\n        self.relu = nn.ReLU()\n        self.out_channels = out_channels\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.conv2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        return out\n\n\nclass ResNet(nn.Module):\n    def __init__(self, block=ResidualBlock, all_connections=[3,4,6,3]):\n        super(ResNet, self).__init__()\n        self.inputs = 16\n        self.conv1 = nn.Sequential(\n                        nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1),\n                        nn.BatchNorm2d(16),\n                        nn.ReLU()) #16x64x64\n        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2) #16x32x32\n\n\n        self.layer0 = self.makeLayer(block, 16, all_connections[0], stride = 1) #connections = 3, shape: 16x32x32\n        self.layer1 = self.makeLayer(block, 32, all_connections[1], stride = 2)#connections = 4, shape: 32x16x16\n        self.layer2 = self.makeLayer(block, 128, all_connections[2], stride = 2)#connections = 6, shape: 1281x8x8\n        self.layer3 = self.makeLayer(block, 256, all_connections[3], stride = 2)#connections = 3, shape: 256x4x4\n        self.avgpool = nn.AvgPool2d(4, stride=1)\n        self.fc = nn.Linear(256, 1)\n\n    def makeLayer(self, block, outputs, connections, stride=1):\n        downsample = None\n        if stride != 1 or self.inputs != outputs:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inputs, outputs, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(outputs),\n            )\n        layers = []\n        layers.append(block(self.inputs, outputs, stride, downsample))\n        self.inputs = outputs\n        for i in range(1, connections):\n            layers.append(block(self.inputs, outputs))\n\n        return nn.Sequential(*layers)\n\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.maxpool(x)\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.avgpool(x)\n        x = x.view(-1, 256)\n        x = self.fc(x).flatten()\n        return F.sigmoid(x)\n```\n\nGenerator:\n\n```js\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass UNet(nn.Module):\n    def __init__(self):\n      super().__init__()\n      self.conv_1 = DoubleConv(3, 32) # 32x64x64\n      self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32x32\n\n      self.conv_2 = DoubleConv(32, 64)  #64x32x32\n      self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2) #64x16x16\n\n      self.conv_3 = DoubleConv(64, 128)  #128x16x16\n      self.pool_3 = nn.MaxPool2d(kernel_size=2, stride=2) #128x8x8\n\n      self.conv_4 = DoubleConv(128, 256)  #256x8x8\n      self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2) #256x4x4\n\n      self.conv_5 = DoubleConv(256, 512)  #512x2x2\n\n      #DECODER\n      self.upconv_1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) #256x4x4\n      self.conv_6 = DoubleConv(512, 256) #256x4x4\n\n\n      self.upconv_2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) #128x8x8\n      self.conv_7 = DoubleConv(256, 128)  #128x8x8\n\n      self.upconv_3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2) #64x16x16\n      self.conv_8 = DoubleConv(128, 64)  #64x16x16\n\n      self.upconv_4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2) #32x32x32\n      self.conv_9 = DoubleConv(64, 32)  #32x32x32\n\n      self.output = nn.Conv2d(32, 3, kernel_size = 3, stride = 1, padding = 1) #3x64x64\n\n    def forward(self, batch):\n\n      conv_1_out = self.conv_1(batch)\n      conv_2_out = self.conv_2(self.pool_1(conv_1_out))\n      conv_3_out = self.conv_3(self.pool_2(conv_2_out))\n      conv_4_out = self.conv_4(self.pool_3(conv_3_out))\n      conv_5_out = self.conv_5(self.pool_4(conv_4_out))\n\n      conv_6_out = self.conv_6(torch.cat([self.upconv_1(conv_5_out), conv_4_out], dim=1))\n      conv_7_out = self.conv_7(torch.cat([self.upconv_2(conv_6_out), conv_3_out], dim=1))\n      conv_8_out = self.conv_8(torch.cat([self.upconv_3(conv_7_out), conv_2_out], dim=1))\n      conv_9_out = self.conv_9(torch.cat([self.upconv_4(conv_8_out), conv_1_out], dim=1))\n\n      output = self.output(conv_9_out)\n\n\n      return F.sigmoid(output)\n```\n\nì´ì œ ë°ì´í„°ë¥¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• í•˜ê³  torch ë°ì´í„° ì„¸íŠ¸ë¡œ ë˜í•‘í•´ì•¼í•©ë‹ˆë‹¤:\n\n<div class=\"content-ad\"></div>\n\n```python\nclass dataset(Dataset):\n    def __init__(self, batch_size, images_paths, targets, img_size=64):\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.images_paths = images_paths\n        self.targets = targets\n        self.len = len(self.images_paths) // batch_size\n\n        self.transform = transforms.Compose([\n            transforms.ToTensor(),\n        ])\n\n        self.batch_im = [self.images_paths[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]\n        self.batch_t = [self.targets[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]\n\n    def __getitem__(self, idx):\n        pred = torch.stack([\n            self.transform(Image.open(join(path_input, file_name)))\n            for file_name in self.batch_im[idx]\n        ])\n        target = torch.stack([\n            self.transform(Image.open(join(path_target, file_name)))\n            for file_name in self.batch_im[idx]\n        ])\n        return pred, target\n\n    def __len__(self):\n        return self.len\n```\n\në©‹ì ¸ìš”. ì´ì œ í›ˆë ¨ ë£¨í”„ë¥¼ ì‘ì„±í•  ì‹œê°„ì…ë‹ˆë‹¤. ê·¸ ì „ì— ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•´ ë´…ì‹œë‹¤:\n\n```python\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size = 64\nnum_epochs = 15\nlearning_rate_D = 1e-5\nlearning_rate_G = 1e-4\n\ndiscriminator = ResNet()\ngenerator = UNet()\n\nbce = nn.BCEWithLogitsLoss()\nl1loss = nn.L1Loss()\n\noptimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate_D)\noptimizer_G = optim.Adam(generator.parameters(), lr=learning_rate_G)\n\nscheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.1)\nscheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)\n```\n\nì´ì „ GAN ì•Œê³ ë¦¬ì¦˜ ê·¸ë¦¼ì˜ ì†ì‹¤ í•¨ìˆ˜ì™€ëŠ” ë‹¤ë¥¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ L1 ì†ì‹¤ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ì´ ì•„ì´ë””ì–´ëŠ” ìš°ë¦¬ê°€ ë¬´ì‘ìœ„ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì…ë ¥ì—ì„œ ëŒ€ë¶€ë¶„ì˜ ì •ë³´ë¥¼ ìœ ì§€í•˜ê³  ë…¸ì´ì¦ˆë§Œ ì œê±°í•˜ë ¤ê³  í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ G ì†ì‹¤ì€ ë‹¤ìŒê³¼ ê°™ì„ ê²ƒì…ë‹ˆë‹¤:\n\n<div class=\"content-ad\"></div>\n\n\nG_loss = log(1 âˆ’ D(G(z))) + ğ€ |G(z)-y|\n\ninstead of just\n\nG_loss = log(1 âˆ’ D(G(z)))\n\nğ€ is an arbitrary coefficient, which balances two components of the losses.\n\n\n<div class=\"content-ad\"></div>\n\nì´ì œ ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ í›ˆë ¨ ê³¼ì •ì„ ì‹œì‘í•´ë´…ì‹œë‹¤:\n\n```js\ntest_ratio, train_ratio = 0.3, 0.7\nnum_test = int(len(listdir(path_target)) * test_ratio)\nnum_train = int((int(len(listdir(path_target))) - num_test))\n\nimg_size = (64, 64)\n\nprint(\"í›ˆë ¨ ìƒ˜í”Œ ìˆ˜:\", num_train)\nprint(\"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜:\", num_test)\n\nrandom.seed(231)\ntrain_idxs = np.array(random.sample(range(num_test + num_train), num_train))\nmask = np.ones(num_train + num_test, dtype=bool)\nmask[train_idxs] = False\n\nimages = {}\nfeatures = random.sample(listdir(path_input), num_test + num_train)\ntargets = random.sample(listdir(path_target), num_test + num_train)\n\nrandom.Random(231).shuffle(features)\nrandom.Random(231).shuffle(targets)\n\ntrain_input_img_paths = np.array(features)[train_idxs]\ntrain_target_img_path = np.array(targets)[train_idxs]\ntest_input_img_paths = np.array(features)[mask]\ntest_target_img_path = np.array(targets)[mask]\n\ntrain_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=train_input_img_paths, targets=train_target_img_path)\ntest_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=test_input_img_paths, targets=test_target_img_path)\n```\n\nì´ì œ í›ˆë ¨ ë£¨í”„ë¥¼ ì‹¤í–‰í•´ë´…ì‹œë‹¤:\n\n```js\ntrain_loss_G, train_loss_D, val_loss_G, val_loss_D = [], [], [], []\nall_loss_G, all_loss_D = [], []\nbest_generator_epoch_val_loss, best_discriminator_epoch_val_loss = -np.inf, -np.inf\nfor epoch in range(num_epochs):\n\n    discriminator.train()\n    generator.train()\n\n    discriminator_epoch_loss, generator_epoch_loss = 0, 0\n\n    for inputs, targets in train_loader:\n        inputs, true = inputs, targets\n\n        '''1. íŒë³„ì (ResNet) í›ˆë ¨í•˜ê¸°'''\n        optimizer_D.zero_grad()\n\n        fake = generator(inputs).detach()\n\n        pred_fake = discriminator(fake).to(device)\n        loss_fake = bce(pred_fake, torch.zeros(batch_size, device=device))\n\n        pred_real = discriminator(true).to(device)\n        loss_real = bce(pred_real, torch.ones(batch_size, device=device))\n\n        loss_D = (loss_fake + loss_real) / 2\n\n        loss_D.backward()\n        optimizer_D.step()\n\n        discriminator_epoch_loss += loss_D.item()\n        all_loss_D.append(loss_D.item())\n\n        '''2. ìƒì„±ì (UNet) í›ˆë ¨í•˜ê¸°'''\n        optimizer_G.zero_grad()\n\n        fake = generator(inputs)\n        pred_fake = discriminator(fake).to(device)\n\n        loss_G_bce = bce(pred_fake, torch.ones_like(pred_fake, device=device))\n        loss_G_l1 = l1loss(fake, targets) * 100\n        loss_G = loss_G_bce + loss_G_l1\n        loss_G.backward()\n        optimizer_G.step()\n\n        generator_epoch_loss += loss_G.item()\n        all_loss_G.append(loss_G.item())\n\n    discriminator_epoch_loss /= len(train_loader)\n    generator_epoch_loss /= len(train_loader)\n    train_loss_D.append(discriminator_epoch_loss)\n    train_loss_G.append(generator_epoch_loss)\n\n    discriminator.eval()\n    generator.eval()\n\n    discriminator_epoch_val_loss, generator_epoch_val_loss = 0, 0\n\n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs, targets\n\n            fake = generator(inputs)\n            pred = discriminator(fake).to(device)\n\n            loss_G_bce = bce(fake, torch.ones_like(fake, device=device))\n            loss_G_l1 = l1loss(fake, targets) * 100\n            loss_G = loss_G_bce + loss_G_l1\n            loss_D = bce(pred.to(device), torch.zeros(batch_size, device=device))\n\n            discriminator_epoch_val_loss += loss_D.item()\n            generator_epoch_val_loss += loss_G.item()\n\n    discriminator_epoch_val_loss /= len(test_loader)\n    generator_epoch_val_loss /= len(test_loader)\n\n    val_loss_D.append(discriminator_epoch_val_loss)\n    val_loss_G.append(generator_epoch_val_loss)\n\n    print(f\"------ì—í¬í¬ [{epoch+1}/{num_epochs}]------\\ní›ˆë ¨ ì†ì‹¤ D: {discriminator_epoch_loss:.4f}, ê²€ì¦ ì†ì‹¤ D: {discriminator_epoch_val_loss:.4f}\")\n    print(f'í›ˆë ¨ ì†ì‹¤ G: {generator_epoch_loss:.4f}, ê²€ì¦ ì†ì‹¤ G: {generator_epoch_val_loss:.4f}')\n\n    if discriminator_epoch_val_loss > best_discriminator_epoch_val_loss:\n        discriminator_epoch_val_loss = best_discriminator_epoch_val_loss\n        torch.save(discriminator.state_dict(), \"discriminator.pth\")\n    if generator_epoch_val_loss > best_generator_epoch_val_loss:\n        generator_epoch_val_loss = best_generator_epoch_val_loss\n        torch.save(generator.state_dict(), \"generator.pth\")\n\n    fig, ax = plt.subplots(1,3)\n    ax[0].imshow(np.transpose(inputs.numpy()[7], (1,2,0)))\n    ax[1].imshow(np.transpose(targets.numpy()[7], (1,2,0)))\n    ax[2].imshow(np.transpose(fake.detach().numpy()[7], (1,2,0)))\n    plt.show()\n```\n\n<div class=\"content-ad\"></div>\n\nì½”ë“œê°€ ëë‚˜ë©´ ì†ì‹¤ì„ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë³¼ ìˆ˜ ìˆì–´ìš”. ì´ ì½”ë“œëŠ” ì´ ë©‹ì§„ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì¼ë¶€ ì±„íƒë˜ì—ˆì–´ìš”:\n\n```js\nfrom matplotlib.font_manager import FontProperties\n\nbackground_color = '#001219'\nfont = FontProperties(fname='LexendDeca-VariableFont_wght.ttf')\nfig, ax = plt.subplots(1, 2, figsize=(16, 9))\nfig.set_facecolor(background_color)\nax[0].set_facecolor(background_color)\nax[1].set_facecolor(background_color)\n\nax[0].plot(range(len(all_loss_G)), all_loss_G, color='#bc6c25', lw=0.5) \nax[1].plot(range(len(all_loss_D)), all_loss_D, color='#00b4d8', lw=0.5)\n\nax[0].scatter(\n      [np.array(all_loss_G).argmax(), np.array(all_loss_G).argmin()],\n      [np.array(all_loss_G).max(), np.array(all_loss_G).min()],\n      s=30, color='#bc6c25',\n   )\nax[1].scatter(\n      [np.array(all_loss_D).argmax(), np.array(all_loss_D).argmin()],\n      [np.array(all_loss_D).max(), np.array(all_loss_D).min()],\n      s=30, color='#00b4d8',\n   )\n\nax.text(\n      np.array(all_loss_G).argmax()+60, np.array(all_loss_G).max()+0.1,\n      f'{round(np.array(all_loss_G).max(),1)}',\n      fontsize=13, color='#bc6c25',\n      font=font,\n      ax=ax[0]\n   )\nax.text(\n      np.array(all_loss_G).argmin()+60, np.array(all_loss_G).min()-0.1,\n      f'{round(np.array(all_loss_G).min(),1)}',\n      fontsize=13, color='#bc6c25',\n      font=font,\n      ax=ax[0]\n   )\n\nax.text(\n      np.array(all_loss_D).argmax()+60, np.array(all_loss_D).max()+0.01,\n      f'{round(np.array(all_loss_D).max(),1)}',\n      fontsize=13, color='#00b4d8',\n      font=font,\n      ax=ax[1]\n   )\nax.text(\n      np.array(all_loss_D).argmin()+60, np.array(all_loss_D).min()-0.005,\n      f'{round(np.array(all_loss_D).min(),1)}',\n      fontsize=13, color='#00b4d8',\n      font=font,\n      ax=ax[1]\n   )\nfor i in range(2):\n    ax[i].tick_params(axis='x', colors='white')\n    ax[i].tick_params(axis='y', colors='white')\n    ax[i].spines['left'].set_color('white') \n    ax[i].spines['bottom'].set_color('white') \n    ax[i].set_xlabel('Epoch', color='white', fontproperties=font, fontsize=13)\n    ax[i].set_ylabel('Loss', color='white', fontproperties=font, fontsize=13)\n\nax[0].set_title('Generator', color='white', fontproperties=font, fontsize=18)\nax[1].set_title('Discriminator', color='white', fontproperties=font, fontsize=18)\nplt.savefig('Loss.jpg')\nplt.show()\n# ax[0].set_axis_off()\n# ax[1].set_axis_off()\n```\n\në˜í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ì„ì˜ì˜ ìƒ˜í”Œì„ ì‹œê°í™”í• ê²Œìš”:\n\n```js\nrandom.Random(2).shuffle(test_target_img_path)\nrandom.Random(2).shuffle(test_input_img_paths)\nsubset_loader = dataset(batch_size=5, img_size=img_size, images_paths=test_input_img_paths,\n                        targets=test_target_img_path)\ngenerator = UNet()\ngenerator.load_state_dict(torch.load('generator.pth'))\n\ngenerator.eval()\nfor X, y in subset_loader:\n    fig, axes = plt.subplots(5, 3, figsize=(9, 9))\n\n    for i in range(5):\n        axes[i, 0].imshow(np.transpose(X.numpy()[i], (1, 2, 0)))\n        axes[i, 0].set_title(\"Input\")\n        axes[i, 0].axis('off')\n        \n        axes[i, 1].imshow(np.transpose(y.numpy()[i], (1, 2, 0)))\n        axes[i, 1].set_title(\"Target\")\n        axes[i, 1].axis('off')\n        \n        generated_image = generator(X[i].unsqueeze(0)).detach().numpy()[0]\n        axes[i, 2].imshow(np.transpose(generated_image, (1, 2, 0)))\n        axes[i, 2].set_title(\"Generated\")\n        axes[i, 2].axis('off')\n    \n    # ë ˆì´ì•„ì›ƒ ì¡°ì •\n    plt.tight_layout()\n    plt.savefig('Test.jpg')\n    plt.show()\n    break \n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_6.png\" />\n\nì—¬ê¸°ì„œ ë³´ì‹œë‹¤ì‹œí”¼, ê²°ê³¼ëŠ” ì™„ë²½í•˜ì§€ ì•Šê³  ë•…ì»¤ë²„ ìœ í˜•ì— ë§¤ìš° ì˜ì¡´í•©ë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , êµ¬ì¶•ëœ ëª¨ë¸ì€ ì´ë¯¸ì§€ì—ì„œ êµ¬ë¦„ì„ ì œê±°í•˜ë©°, G ë° D ê¹Šì´ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìœ ë§í•œ ì „ëµì€ ì„œë¡œ ë‹¤ë¥¸ ë•…ì»¤ë²„ ìœ í˜•ì„ ìœ„í•´ ë³„ë„ì˜ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‘ë¬¼ë°­ê³¼ ë¬¼ íˆ¬êµ¬ëŠ” ë¶„ëª…íˆ ë‹¤ë¥¸ ê³µê°„ì  íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ì¼ë°˜í™” ëª¨ë¸ì˜ ëŠ¥ë ¥ì— ì˜í–¥ì„ ì£¼ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤.\n\nì´ ê¸°ì‚¬ê°€ ì§€ë¦¬ì •ë³´ ë„ë©”ì¸ì—ì„œ ì‹¬ì¸µ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ëŠ” ë° ìƒˆë¡œìš´ ì‹œê°ì„ ì œê³µí•´ ë“œë ¸ê¸°ë¥¼ ë°”ëë‹ˆë‹¤. ë‚´ ìƒê°ì—ëŠ”, GANsëŠ” ë°ì´í„° ê³¼í•™ìê°€ í™œìš©í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ê°•ë ¥í•œ ë„êµ¬ ì¤‘ í•˜ë‚˜ì´ë©°, ì—¬ëŸ¬ë¶„ì˜ ë„êµ¬ ìƒìì˜ í•„ìˆ˜ì ì¸ ë¶€ë¶„ì´ ë˜ê¸¸ í¬ë§í•©ë‹ˆë‹¤!\n\n===========================================\n\n<div class=\"content-ad\"></div>\n\nì°¸ê³ ë¬¸í—Œ:\n\n1. Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville ë° Yoshua Bengio. â€œGenerative adversarial nets.â€ Advances in neural information processing systems 27 (2014). [ë…¼ë¬¸ ë§í¬](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)\n\n2. Helber, Patrick, Benjamin Bischke, Andreas Dengel ë° Damian Borth. â€œEurosat: A novel dataset and deep learning benchmark for land use and land cover classification.â€ IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 12, no. 7 (2019): 2217â€“2226. [ë…¼ë¬¸ ë§í¬](https://arxiv.org/pdf/1709.00029)\n\n3. Wen, Xue, Zongxu Pan, Yuxin Hu ë° Jiayin Liu. â€œGenerative adversarial learning in YUV color space for thin cloud removal on satellite imagery.â€ Remote Sensing 13, no. 6 (2021): 1079. [ë…¼ë¬¸ ë§í¬](https://www.mdpi.com/2072-4292/13/6/1079)\n\n<div class=\"content-ad\"></div>\n\n5. Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. â€œU-net: Convolutional networks for biomedical image segmentation.â€ In Medical image computing and computer-assisted interventionâ€“MICCAI 2015: 18th international conference, Munich, Germany, October 5â€“9, 2015, proceedings, part III 18, pp. 234â€“241. Springer International Publishing, 2015. [Link](https://arxiv.org/pdf/1505.04597)\n\n6. He, Kaiming, et al. â€œDeep residual learning for image recognition.â€ Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [Link](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\n\n===========================================\n\n<div class=\"content-ad\"></div>\n\nì œ Mediumì˜ ëª¨ë“  ê²Œì‹œë¬¼ì€ ë¬´ë£Œì´ë©° ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì—¬ê¸°ì„œ ì €ë¥¼ íŒ”ë¡œìš°í•´ ì£¼ì‹œë©´ ì •ë§ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!\n\nP.s. ì €ëŠ” (ì§€ë¦¬)ë°ì´í„° ê³¼í•™, ë¨¸ì‹  ëŸ¬ë‹/ì¸ê³µì§€ëŠ¥, ê¸°í›„ ë³€í™”ì— ëŒ€í•´ ì—´ì •ì ìœ¼ë¡œ ê´€ì‹¬ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì–´ë–¤ í”„ë¡œì íŠ¸ì—ì„œ í•¨ê»˜ ì‘ì—…í•˜ê³  ì‹¶ë‹¤ë©´ LinkedInì—ì„œ ì—°ë½ ì£¼ì„¸ìš”.\n\nğŸ›°ï¸ë” ë§ì€ ì†Œì‹ì„ ë°›ì•„ë³´ë ¤ë©´ íŒ”ë¡œìš°í•˜ì„¸ìš”!ğŸ›°ï¸","ogImage":{"url":"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png"},"coverImage":"/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png","tag":["Tech"],"readingTime":25},{"title":"íŒŒì´í† ì¹˜PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒë¶€í„° Large Language Model LLMì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”","description":"","date":"2024-06-19 18:43","slug":"2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch","content":"\n\n## LLM ë§Œë“¤ê³  íŠ¸ë ˆì´ë‹í•˜ëŠ” ë‹¨ê³„ë³„ ê°€ì´ë“œì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì˜ ëª©í‘œëŠ” ì˜ì–´ë¥¼ ë§ë ˆì´ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_0.png)\n\nì´ ê¸€ì„ ë§ˆì¹˜ë©´ ì–´ë–¤ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ê¹Œìš”? ì§ì ‘ ì½”ë”©í•˜ë©´ì„œ Large Language Model (LLM)ì„ ë§Œë“¤ê³  íŠ¸ë ˆì´ë‹í•  ìˆ˜ ìˆê²Œ ë  ê±°ì—ìš”. ì˜ì–´ë¥¼ ë§ë ˆì´ì–´ë¡œ ë²ˆì—­í•˜ëŠ” LLMì„ ë§Œë“¤ì§€ë§Œ, ë‹¤ë¥¸ ì–¸ì–´ ë²ˆì—­ ì‘ì—…ì„ ìœ„í•´ ì´ LLM ì•„í‚¤í…ì²˜ë¥¼ ì‰½ê²Œ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nLLMì€ ChatGPT, Gemini, MetaAI, Mistral AI ë“±ê³¼ ê°™ì€ ì¸ê¸° ìˆëŠ” AI ì±—ë´‡ì˜ í•µì‹¬ ê¸°ë°˜ì´ ë©ë‹ˆë‹¤. ëª¨ë“  LLMì˜ í•µì‹¬ì—ëŠ” Transformerë¼ëŠ” ì•„í‚¤í…ì²˜ê°€ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ë¨¼ì € ìœ ëª…í•œ ë…¼ë¬¸ \"Attention is all you need\"ì„ ë°”íƒ•ìœ¼ë¡œ Transformer ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í•  ê²ƒì…ë‹ˆë‹¤ - https://arxiv.org/abs/1706.03762.\n\n<div class=\"content-ad\"></div>\n\n![transformer_step_by_step](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_1.png)\n\në¨¼ì €, ìš°ë¦¬ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ë¸”ë¡ ë‹¨ìœ„ë¡œ êµ¬ì¶•í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ, ëª¨ë“  ë¸”ë¡ì„ ì¡°í•©í•˜ì—¬ ëª¨ë¸ì„ êµ¬ì¶•í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ í›„ì—ëŠ” Hugging Face ë°ì´í„°ì…‹ì—ì„œ ì–»ì„ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ìœ íš¨ì„±ì„ ê²€ì‚¬í•  ê²ƒì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ìƒˆ ë²ˆì—­ í…ìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ë²ˆì—­ì„ ìˆ˜í–‰í•˜ì—¬ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•  ê²ƒì…ë‹ˆë‹¤.\n\nì¤‘ìš” ì‚¬í•­: ì €ëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ë‹¨ê³„ë³„ë¡œ ì½”ë”©í•˜ê³  'ë¬´ì—‡, ì™œ, ì–´ë–»ê²Œ'ì— ëŒ€í•œ ê°œë…ì— ëŒ€í•œ í•„ìš”í•œ ì„¤ëª…ì„ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤. ë˜í•œ ì„¤ëª…ì´ í•„ìš”í•œ íŠ¹ì • ì½”ë“œ ë¼ì¸ì— ëŒ€í•´ ì£¼ì„ì„ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì§ì ‘ ì½”ë”©í•˜ë©´ì„œ ì „ì²´ ì›Œí¬í”Œë¡œì— ì—°ê²°í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ë¯¿ìŠµë‹ˆë‹¤.\n\n![transformer_architecture](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_2.png)\n\n<div class=\"content-ad\"></div>\n\ní•¨ê»˜ ì½”ë”©í•´ìš”!\n\n## ë‹¨ê³„ 1: ë°ì´í„°ì…‹ ë¡œë“œ\n\nLLM ëª¨ë¸ì´ ì˜ì–´ì—ì„œ ë§ë ˆì´ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ì‘ì—…ì„ í•  ìˆ˜ ìˆë„ë¡ í•˜ë ¤ë©´ ì†ŒìŠ¤(ì˜ì–´)ì™€ ëŒ€ìƒ(ë§ë ˆì´ì–´) ì–¸ì–´ ìŒì´ ìˆëŠ” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, Huggingfaceì—ì„œ \"Helsinki-NLP/opus-100\"ë¼ëŠ” ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ 1ë°±ë§Œ ê°œì˜ ì˜ì–´-ë§ë ˆì´ì–´ í›ˆë ¨ ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  ìˆì–´ì„œ ì¢‹ì€ ì •í™•ë„ë¥¼ ì–»ê¸°ì— ì¶©ë¶„í•˜ë©°, ê²€ì¦ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ê°ê° 2,000ê°œì˜ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ëŠ” ì´ë¯¸ ì‚¬ì „ ë¶„í• ë˜ì–´ ìˆì–´ì„œ ë°ì´í„°ì…‹ì„ ë‹¤ì‹œ ë¶„í• í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.\n\n\n# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°\n# ì•„ì§ ì•ˆ í–ˆë‹¤ë©´ (!pip install datasets, tokenizers)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ ë° í† í¬ë‚˜ì´ì € ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜í•˜ê¸°.\nimport os\nimport math\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n\n# GPUê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤ë©´ \"cuda\"ë¡œ ì¥ì¹˜ ê°’ì„ í• ë‹¹í•˜ì—¬ GPUì—ì„œ í›ˆë ¨í•©ë‹ˆë‹¤. ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ì¸ \"cpu\"ë¡œ ë˜ëŒë¦´ ê²ƒì…ë‹ˆë‹¤.\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n\n# Huggingface ê²½ë¡œì—ì„œ í›ˆë ¨, ê²€ì¦, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\nraw_train_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='train')\nraw_validation_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='validation')\nraw_test_dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-ms\", split='test')\n\n# ë°ì´í„°ì…‹ íŒŒì¼ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±\nos.mkdir(\"./dataset-en\")\nos.mkdir(\"./dataset-my\")\n\n# ê° ì—í­ í›„ ëª¨ë¸ í›ˆë ¨ ì¤‘ì— ëª¨ë¸ì„ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„± (ë‹¨ê³„ 10ì—ì„œ ì‚¬ìš©).\nos.mkdir(\"./malaygpt\")\n\n# ì†ŒìŠ¤ ë° ëŒ€ìƒ í† í¬ë‚˜ì´ì €ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±.\nos.mkdir(\"./tokenizer_en\")\nos.mkdir(\"./tokenizer_my\")\n\ndataset_en = []\ndataset_my = []\nfile_count = 1\n\n# í† í¬ë‚˜ì´ì €ë¥¼ í›ˆë ¨í•˜ê¸° ìœ„í•´ (ë‹¨ê³„ 2ì—ì„œ) í›ˆë ¨ ë°ì´í„°ì…‹ì„ ì˜ì–´ ë° ë§ë ˆì´ì–´ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n# ê° íŒŒì¼ì— 50,000ê°œì”© ì‘ì€ ë°ì´í„° íŒŒì¼ì„ ë§Œë“¤ì–´ dataset-en ë° dataset-my ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.\nfor data in tqdm(raw_train_dataset[\"translation\"]):\n    dataset_en.append(data[\"en\"].replace('\\n', \" \"))\n    dataset_my.append(data[\"ms\"].replace('\\n', \" \"))\n    if len(dataset_en) == 50000:\n        with open(f'./dataset-en/file{file_count}.txt', 'w', encoding='utf-8') as fp:\n            fp.write('\\n'.join(dataset_en))\n            dataset_en = []\n\n        with open(f'./dataset-my/file{file_count}.txt', 'w', encoding='utf-8') as fp:\n            fp.write('\\n'.join(dataset_my))\n            dataset_my = []\n        file_count += 1\n\n\n<div class=\"content-ad\"></div>\n\n## ë‹¨ê³„ 2: í† í¬ë‚˜ì´ì € ìƒì„±\n\níŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ì§€ ì•Šìœ¼ë©°, ìˆ«ìë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ ì–´ë–¤ ì‘ì—…ì„ í•´ì•¼ í•  ê²ƒì…ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ì €í¬ëŠ” GPT3ì™€ ê°™ì€ ëª¨ë¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì €ì¸ BPE í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ë¨¼ì € ìš°ë¦¬ê°€ ë‹¨ê³„ 1ì—ì„œ ì¤€ë¹„í•œ ì½”í¼ìŠ¤ ë°ì´í„°(ì´ ê²½ìš° êµìœ¡ ë°ì´í„° ì…‹)ë¡œ BPE í† í¬ë‚˜ì´ì €ë¥¼ ë¨¼ì € í•™ìŠµí•  ê²ƒì…ë‹ˆë‹¤. ì•„ë˜ ë‹¤ì´ì–´ê·¸ë¨ê³¼ ê°™ì´ ì§„í–‰ë©ë‹ˆë‹¤.\n\n![image](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_3.png)\n\ní•™ìŠµì´ ì™„ë£Œë˜ë©´ í† í¬ë‚˜ì´ì €ëŠ” ì˜ì–´ì™€ ë§ë ˆì´ ì–¸ì–´ìš© ì–´íœ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì–´íœ˜ëŠ” ì½”í¼ìŠ¤ ë°ì´í„°ì—ì„œ ê³ ìœ í•œ í† í°ë“¤ì˜ ì»¬ë ‰ì…˜ì…ë‹ˆë‹¤. ë²ˆì—­ ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ì— ë‘ ì–¸ì–´ì— ëŒ€í•œ í† í¬ë‚˜ì´ì €ê°€ í•„ìš”í•©ë‹ˆë‹¤. BPE í† í¬ë‚˜ì´ì €ëŠ” ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ ì–´íœ˜ ë‚´ì˜ í† í°ë“¤ê³¼ ë§¤í•‘í•œ í›„, ì…ë ¥ëœ ì›ì‹œ í…ìŠ¤íŠ¸ì˜ ê° ë‹¨ì–´ì— ëŒ€í•´ í† í°ì„ ë°˜í™˜í•©ë‹ˆë‹¤. í† í°ì€ ë‹¨ì¼ ë‹¨ì–´ë‚˜ ì„œë¸Œì›Œë“œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë‹¤ë¥¸ í† í¬ë‚˜ì´ì €ì— ë¹„í•´ ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì €ì˜ ì¥ì  ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  í† í¬ë‚˜ì´ì €ëŠ” ê·¸ ê³ ìœ í•œ ì¸ë±ìŠ¤ ë˜ëŠ” ìœ„ì¹˜ IDë¥¼ ë°˜í™˜í•˜ê³ , ì´ëŠ” ìœ„ì˜ íë¦„ì—ì„œ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ë° ì¶”ê°€ë¡œ ì‚¬ìš©ë  ê²ƒì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n```js\n# í† í¬ë‚˜ì´ì € ë¼ì´ë¸ŒëŸ¬ë¦¬ í´ë˜ìŠ¤ ë° ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°.\nfrom tokenizers import Tokenizer\nfrom tokenizers.models import BPE\nfrom tokenizers.trainers import BpeTrainer\nfrom tokenizers.pre_tokenizers import Whitespace\n\n# í† í¬ë‚˜ì´ì €ë¥¼ í›ˆë ¨ì‹œí‚¬ í•™ìŠµ ë°ì´í„°ì…‹ íŒŒì¼ ê²½ë¡œ.\npath_en = [str(file) for file in Path('./dataset-en').glob(\"**/*.txt\")]\npath_my = [str(file) for file in Path('./dataset-my').glob(\"**/*.txt\")]\n\n# [ì›ë³¸ ì–¸ì–´ í† í¬ë‚˜ì´ì €(ì˜ì–´) ìƒì„±].\n# [UNK] - ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ì–´ë¥¼ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ìˆ˜ í† í° ìƒì„±, [PAD] - íŒ¨ë”© í† í°ìœ¼ë¡œ ëª¨ë¸ ê°„ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ê¸° ìœ„í•¨.\n# [CLS] - ë¬¸ì¥ ì‹œì‘ì„ í‘œì‹œí•˜ëŠ” í† í°, [SEP] - ë¬¸ì¥ ëì„ í‘œì‹œí•˜ëŠ” í† í° ë“±ì˜ ì¶”ê°€ íŠ¹ìˆ˜ í† í° ìƒì„±.\ntokenizer_en = Tokenizer(BPE(unk_token=\"[UNK]\"))\ntrainer_en = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\", \"[SEP]\", \"[MASK]\"])\n\n# í† í°ì„ ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬.\ntokenizer_en.pre_tokenizer = Whitespace()\n\n# ë°ì´í„°ì…‹ íŒŒì¼ë¡œ í† í¬ë‚˜ì´ì € í›ˆë ¨.\ntokenizer_en.train(files=path_en, trainer=trainer_en)\n\n# í–¥í›„ ì‚¬ìš©ì„ ìœ„í•´ í† í¬ë‚˜ì´ì € ì €ì¥.\ntokenizer_en.save(\"./tokenizer_en/tokenizer_en.json\")\n\n# [íƒ€ê²Ÿ ì–¸ì–´ í† í¬ë‚˜ì´ì €(ë§ë ˆì´ì–´) ìƒì„±].\ntokenizer_my = Tokenizer(BPE(unk_token=\"[UNK]\"))\ntrainer_my = BpeTrainer(min_frequency=2, special_tokens=[\"[PAD]\",\"[UNK]\",\"[CLS]\", \"[SEP]\", \"[MASK]\"])\ntokenizer_my.pre_tokenizer = Whitespace()\ntokenizer_my.train(files=path_my, trainer=trainer_my)\ntokenizer_my.save(\"./tokenizer_my/tokenizer_my.json\")\n\ntokenizer_en = Tokenizer.from_file(\"./tokenizer_en/tokenizer_en.json\")\ntokenizer_my = Tokenizer.from_file(\"./tokenizer_my/tokenizer_my.json\")\n\n# ê° í† í¬ë‚˜ì´ì €ì˜ í¬ê¸° í™•ì¸.\nsource_vocab_size = tokenizer_en.get_vocab_size()\ntarget_vocab_size = tokenizer_my.get_vocab_size()\n\n# í† í° ID ë³€ìˆ˜ ì •ì˜, ëª¨ë¸ í›ˆë ¨ì— ì‚¬ìš©.\nCLS_ID = torch.tensor([tokenizer_my.token_to_id(\"[CLS]\")], dtype=torch.int64).to(device)\nSEP_ID = torch.tensor([tokenizer_my.token_to_id(\"[SEP]\")], dtype=torch.int64).to(device)\nPAD_ID = torch.tensor([tokenizer_my.token_to_id(\"[PAD]\")], dtype=torch.int64).to(device)\n```\n\n## Step 3: ë°ì´í„°ì…‹ ë° DataLoader ì¤€ë¹„\n\nì´ ë‹¨ê³„ì—ì„œëŠ” ë‚˜ì¤‘ì— êµ¬ì¶•í•  ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ê²€ì¦í•˜ê¸° ìœ„í•´ ì†ŒìŠ¤ ì–¸ì–´ì™€ íƒ€ê²Ÿ ì–¸ì–´ ê°ê°ì— ëŒ€í•œ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•  ê²ƒì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì›ì‹œ ë°ì´í„°ì…‹ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì†ŒìŠ¤(í† í¬ë‚˜ì´ì €_en)ì™€ íƒ€ê²Ÿ(í† í¬ë‚˜ì´ì €_my) í…ìŠ¤íŠ¸ë¥¼ ê°ê° ì¸ì½”ë”©í•˜ëŠ” ê¸°ëŠ¥ì„ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, í›ˆë ¨ ë° ê²€ì¦ ë°ì´í„°ì…‹ì„ ìœ„í•´ DataLoaderë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤. ì´ DataLoaderëŠ” ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ì…‹ì„ ë°˜ë³µí•˜ë©°(ì˜ˆ: ë°°ì¹˜ í¬ê¸°ëŠ” 10ìœ¼ë¡œ ì„¤ì •ë  ìˆ˜ ìˆìŒ), ë°ì´í„° í¬ê¸°ì™€ ì‚¬ìš© ê°€ëŠ¥í•œ ì²˜ë¦¬ ëŠ¥ë ¥ì— ë”°ë¼ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n```js\n# ì´ í´ë˜ìŠ¤ëŠ” ì›ì‹œ ë°ì´í„°ì…‹ê³¼ max_seq_len (ì „ì²´ ë°ì´í„°ì…‹ì—ì„œ ì‹œí€€ìŠ¤ì˜ ìµœëŒ€ ê¸¸ì´)ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\nclass EncodeDataset(Dataset):\n    def __init__(self, raw_dataset, max_seq_len):\n        super().__init__()\n        self.raw_dataset = raw_dataset\n        self.max_seq_len = max_seq_len\n    \n    def __len__(self):\n        return len(self.raw_dataset)\n\n    def __getitem__(self, index):\n        \n        # ì£¼ì–´ì§„ ì¸ë±ìŠ¤ì˜ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ ì†ŒìŠ¤ ë° íƒ€ê²Ÿ í…ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬í•¨.\n        raw_text = self.raw_dataset[index]\n        \n        # ì†ŒìŠ¤ í…ìŠ¤íŠ¸ì™€ íƒ€ê²Ÿ í…ìŠ¤íŠ¸ë¥¼ ì¸ì½”ë”©í•˜ê¸° ìœ„í•´ ì†ŒìŠ¤ í† í¬ë‚˜ì´ì €(tokenizer_en) ë° íƒ€ê²Ÿ í† í¬ë‚˜ì´ì €(tokenizer_my)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n        source_text_encoded = torch.tensor(tokenizer_en.encode(source_text).ids, dtype = torch.int64).to(device)    \n        target_text_encoded = torch.tensor(tokenizer_my.encode(target_text).ids, dtype = torch.int64).to(device)\n\n        # ëª¨ë¸ í›ˆë ¨ì„ ìœ„í•´ ê° ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ê°€ max_seq_lenê³¼ ë™ì¼í•˜ë„ë¡ ë§Œë“¤ê¸° ìœ„í•´ í•„ìš”í•œ ë§Œí¼ì˜ íŒ¨ë”©ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n        num_source_padding = self.max_seq_len - len(source_text_encoded) - 2 \n        num_target_padding = self.max_seq_len - len(target_text_encoded) - 1 \n\n        encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype = torch.int64).to(device)\n        decoder_padding = torch.tensor([PAD_ID] * num_target_padding, dtype = torch.int64).to(device)\n\n        # ì¸ì½”ë” ì…ë ¥ì€ ë¬¸ì¥ ì‹œì‘ í† í°ì¸ CLS_IDë¡œ ì‹œì‘í•˜ì—¬ ì†ŒìŠ¤ ì¸ì½”ë”©ìœ¼ë¡œ ì´ì–´ì§€ê³  ë¬¸ì¥ ë í† í°ì¸ SEPê°€ ë’¤ë”°ë¦…ë‹ˆë‹¤.\n        # í•„ìš”í•œ max_seq_lenì— ë„ë‹¬í•˜ê¸° ìœ„í•´ ë§ˆì§€ë§‰ì— PAD í† í°ì´ ì¶”ê°€ë©ë‹ˆë‹¤.\n        encoder_input = torch.cat([CLS_ID, source_text_encoded, SEP_ID, encoder_padding]).to(device)\n\n        # ë””ì½”ë” ì…ë ¥ì€ ë¬¸ì¥ ì‹œì‘ í† í°ì¸ CLS_IDë¡œ ì‹œì‘í•˜ì—¬ íƒ€ê²Ÿ ì¸ì½”ë”©ì´ ë’¤ë”°ë¦…ë‹ˆë‹¤.\n        # í•„ìš”í•œ max_seq_lenì— ë„ë‹¬í•˜ê¸° ìœ„í•´ ë§ˆì§€ë§‰ì— PAD í† í°ì´ ì¶”ê°€ë©ë‹ˆë‹¤. ë””ì½”ë” ì…ë ¥ì—ëŠ” ë¬¸ì¥ ë í† í°ì¸ SEPëŠ” í¬í•¨ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n        decoder_input = torch.cat([CLS_ID, target_text_encoded, decoder_padding]).to(device)\n\n        # íƒ€ê²Ÿ ë ˆì´ë¸”ì€ íƒ€ê²Ÿ ì¸ì½”ë”©ì´ ë¨¼ì € ì˜¤ê³  ë¬¸ì¥ ë í† í°ì¸ SEPê°€ ë’¤ë”°ë¦…ë‹ˆë‹¤. ì‹œì‘ ë¬¸ì¥ í† í°ì¸ CLSëŠ” ì—†ìŠµë‹ˆë‹¤.\n        # í•„ìš”í•œ max_seq_lenì— ë„ë‹¬í•˜ê¸° ìœ„í•´ ë§ˆì§€ë§‰ì— PAD í† í°ì´ ì¶”ê°€ë©ë‹ˆë‹¤.\n        target_label = torch.cat([target_text_encoded,SEP_ID,decoder_padding]).to(device)\n\n        # ì¸ì½”ë”© ì‹œ ì¶”ê°€ëœ íŒ¨ë”© í† í°ì„ ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•´ ì¸ì½”ë” ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ padding í† í° ê°’ì„ ê³„ì‚°í•˜ê¸° ì „ì— ë¬´íš¨í™”í•©ë‹ˆë‹¤.\n        encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int().to(device)\n\n        # ë””ì½”ë”© ë‹¨ê³„ì—ì„œëŠ” í˜„ì¬ í† í° ì´í›„ì˜ í† í°ì— ì˜í–¥ì„ ë°›ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•´ ì¸ê³¼ ë§ˆìŠ¤í¬ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n        decoder_mask = (decoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0)).to(device)\n\n        return {\n            'encoder_input': encoder_input,\n            'decoder_input': decoder_input,\n            'target_label': target_label,\n            'encoder_mask': encoder_mask,\n            'decoder_mask': decoder_mask,\n            'source_text': source_text,\n            'target_text': target_text\n        }\n\n# ì¸ê³¼ ë§ˆìŠ¤í¬ëŠ” í˜„ì¬ í† í° ì´í›„ì— ì˜¬ í† í°ì„ ë§ˆìŠ¤í‚¹í•˜ì—¬ softmax í•¨ìˆ˜ ì´í›„ -infë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì€ ì´ëŸ¬í•œ ê°’ë“¤ì„ ë¬´ì‹œí•˜ê±°ë‚˜ ì´ë¥¼ í†µí•´ í•™ìŠµì„ ì–´ë µê²Œ í•©ë‹ˆë‹¤.\ndef causal_mask(size):\n  # ì¸ê³¼ ë§ˆìŠ¤í¬ì˜\n\n<div class=\"content-ad\"></div>\n\n## ë‹¨ê³„ 4: ì…ë ¥ ì„ë² ë”© ë° ìœ„ì¹˜ ì¸ì½”ë”©\n\nì…ë ¥ ì„ë² ë”©: ë‹¨ê³„ 2ì˜ í† í° ìƒì„±ê¸°ì—ì„œ ìƒì„±ëœ í† í° ID ì‹œí€€ìŠ¤ê°€ ì„ë² ë”© ë ˆì´ì–´ë¡œ ê³µê¸‰ë  ê²ƒì…ë‹ˆë‹¤. ì„ë² ë”© ë ˆì´ì–´ëŠ” í† í° IDë¥¼ ì–´íœ˜ì™€ ë§¤í•‘í•˜ê³  ê° í† í°ì— ëŒ€í•´ 512 ì°¨ì›ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. [512 ì°¨ì›ì€ ì–´í…ì…˜ ë…¼ë¬¸ì—ì„œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤]. ì„ë² ë”© ë²¡í„°ëŠ” í† í°ì˜ ì˜ë¯¸ë¥¼ ìº¡ì³í•  ìˆ˜ ìˆìœ¼ë©°, ê·¸ê²ƒì€ í•™ìŠµëœ ë°ì´í„°ì…‹ì— ê¸°ë°˜í•˜ì—¬ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. ì„ë² ë”© ë²¡í„° ë‚´ì˜ ê° ì°¨ì› ê°’ì€ í† í°ê³¼ ê´€ë ¨ëœ íŠ¹ì§•ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í† í°ì´ 'ê°œ'ì¸ ê²½ìš°, ì¼ë¶€ ì°¨ì› ê°’ì€ ëˆˆ, ì…, ë‹¤ë¦¬, í‚¤ ë“±ì„ ë‚˜íƒ€ë‚¼ ê²ƒì…ë‹ˆë‹¤. nì°¨ì› ê³µê°„ì— ë²¡í„°ë¥¼ ê·¸ë¦°ë‹¤ë©´, ë¹„ìŠ·í•´ ë³´ì´ëŠ” ê°ì²´ì¸ ê°œì™€ ê³ ì–‘ì´ëŠ” ì„œë¡œ ê°€ê¹ê²Œ ìœ„ì¹˜í•˜ê³ , ë¹„ìŠ·í•´ ë³´ì´ì§€ ì•ŠëŠ” í•™êµ, ì§‘ ì„ë² ë”© ë²¡í„°ëŠ” í›¨ì”¬ ë” ë©€ë¦¬ ìœ„ì¹˜í•´ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n\nìœ„ì¹˜ ì¸ì½”ë”©: íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì˜ ì¥ì  ì¤‘ í•˜ë‚˜ëŠ” ì–´ë–¤ ìˆ˜ì˜ ì…ë ¥ ì‹œí€€ìŠ¤ë“  ë³‘ë ¬ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë©°, ì´ëŠ” í›ˆë ¨ ì‹œê°„ì„ ë§ì´ ì¤„ì´ê³  ì˜ˆì¸¡ì„ í›¨ì”¬ ë¹ ë¥´ê²Œ ë§Œë“­ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¨ì  ì¤‘ í•˜ë‚˜ëŠ” ë³‘ë ¬ë¡œ ë§ì€ í† í° ì‹œí€€ìŠ¤ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë™ì•ˆ, ë¬¸ì¥ ë‚´ í† í°ì˜ ìœ„ì¹˜ê°€ ìˆœì„œëŒ€ë¡œ ë˜ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ í† í°ì˜ ìœ„ì¹˜ì— ë”°ë¼ ë¬¸ì¥ì˜ ì˜ë¯¸ë‚˜ ë¬¸ë§¥ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì–´í…ì…˜ ë…¼ë¬¸ì€ ìœ„ì¹˜ ì¸ì½”ë”© ë°©ë²•ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ì´ ë…¼ë¬¸ì€ ê° í† í°ì˜ 512 ì°¨ì›ì— ëŒ€í•´ ë‘ ê°€ì§€ ìˆ˜í•™ í•¨ìˆ˜(sinê³¼ cosine)ë¥¼ ì ìš©í•˜ëŠ” ê²ƒì„ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” ê°„ë‹¨í•œ sinê³¼ cosine ìˆ˜í•™ í•¨ìˆ˜ì…ë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_4.png)\n\n<div class=\"content-ad\"></div>\n\nSin í•¨ìˆ˜ëŠ” ì„ë² ë”© ë²¡í„°ì˜ ê° ì§ìˆ˜ ì°¨ì› ê°’ì— ì ìš©ë˜ê³ , ì½”ì‚¬ì¸ í•¨ìˆ˜ëŠ” í™€ìˆ˜ ì°¨ì› ê°’ì— ì ìš©ë©ë‹ˆë‹¤. ìµœì¢…ì ìœ¼ë¡œ, ê²°ê³¼ì ì¸ ìœ„ì¹˜ ì¸ì½”ë” ë²¡í„°ëŠ” ì„ë² ë”© ë²¡í„°ì— ì¶”ê°€ë©ë‹ˆë‹¤. ì´ì œ ìš°ë¦¬ëŠ” í† í°ì˜ ì˜ë¯¸ì™€ ìœ„ì¹˜ë¥¼ ëª¨ë‘ ì¡ì„ ìˆ˜ ìˆëŠ” ì„ë² ë”© ë²¡í„°ë¥¼ ê°–ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ì˜í•  ì ì€ ìœ„ì¹˜ ì¸ì½”ë”©ì˜ ê°’ì´ ê° ì‹œí€€ìŠ¤ì—ì„œ ë™ì¼í•˜ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n# ì…ë ¥ ì„ë² ë”©ê³¼ ìœ„ì¹˜ ì¸ì½”ë”©\nclass EmbeddingLayer(nn.Module):\n    def __init__(self, vocab_size: int, d_model: int):\n        super().__init__()\n        self.d_model = d_model\n        \n        # PyTorchì˜ ì„ë² ë”© ë ˆì´ì–´ ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ í† í° IDë¥¼ ì–´íœ˜ì— ë§¤í•‘í•œ í›„ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n        # vocab_sizeëŠ” í›ˆë ¨ ë°ì´í„°ì…‹ì˜ ì–´íœ˜ í¬ê¸°ì´ë©°, í† í°í™”ê¸°ê°€ ì½”í¼ìŠ¤ ë°ì´í„°ì…‹ í›ˆë ¨ ì¤‘ì— ìƒì„±í•œ ê²ƒì…ë‹ˆë‹¤.\n        self.embedding = nn.Embedding(vocab_size, d_model)\n    \n    def forward(self, input):\n        # ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì„ë² ë”© ë ˆì´ì–´ì— ê³µê¸‰í•  ë•Œ, d_modelì˜ ì œê³±ê·¼ì„ ê³±í•˜ëŠ” ì¶”ê°€ë¡œ ì •ê·œí™” ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n        embedding_output = self.embedding(input) * math.sqrt(self.d_model)\n        return embedding_output\n\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, max_seq_len: int, d_model: int, dropout_rate: float):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        # ì„ë² ë”© ë²¡í„°ì™€ ë™ì¼í•œ ëª¨ì–‘ì˜ í–‰ë ¬ì„ ë§Œë“­ë‹ˆë‹¤.\n        pe = torch.zeros(max_seq_len, d_model)\n        \n        # PE í•¨ìˆ˜ì˜ ìœ„ì¹˜ ë¶€ë¶„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n        pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n\n        # PE í•¨ìˆ˜ì˜ ë‚˜ëˆ—ì…ˆ ë¶€ë¶„ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ì§€ìˆ˜ í•¨ìˆ˜ì˜ í‘œí˜„ì´ ë…¼ë¬¸ í‘œí˜„ê³¼ ì•½ê°„ ë‹¤ë¥´ì§€ë§Œ ë” ì˜ ì‘ë™í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n        div_term = torch.exp(torch.arange(0, d_model, 2).float()) * (-math.log(10000)/d_model)\n        \n        # sin ë° cosine ìˆ˜í•™ í•¨ìˆ˜ ê²°ê³¼ë¡œ í™€ìˆ˜ ë° ì§ìˆ˜ í–‰ë ¬ ê°’ì„ ì±„ì›ë‹ˆë‹¤.\n        pe[:, 0::2] = torch.sin(pos * div_term)\n        pe[:, 1::2] = torch.cos(pos * div_term)\n        \n        # ì…ë ¥ ì‹œí€€ìŠ¤ê°€ ë°°ì¹˜ë¡œ ì˜ˆìƒë˜ë¯€ë¡œ ì¶”ê°€ì ì¸ batch_size ì°¨ì›ì´ 0 ìœ„ì¹˜ì— ì¶”ê°€ë©ë‹ˆë‹¤.\n        pe = pe.unsqueeze(0)    \n    \n    def forward(self, input_embdding):\n        # ì…ë ¥ ì„ë² ë”© ë²¡í„°ì— ìœ„ì¹˜ ì¸ì½”ë”©ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n        input_embdding = input_embdding + (self.pe[:, :input_embdding.shape[1], :]).requires_grad_(False)  \n        \n        # ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë“œë¡­ì•„ì›ƒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n        return self.dropout(input_embdding)\n\n## ë‹¨ê³„ 5: ë©€í‹° í—¤ë“œ ì–´í…ì…˜ ë¸”ë¡\n\níŠ¸ëœìŠ¤í¬ë¨¸ê°€ LLMì˜ í•µì‹¬ì¸ ê²ƒì²˜ëŸ¼, ì…€í”„ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nìê°€ ì£¼ì˜ê°€ í•„ìš”í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”? ì•„ë˜ ê°„ë‹¨í•œ ì˜ˆë¥¼ í†µí•´ ë‹µë³€í•´ë³´ê² ìŠµë‹ˆë‹¤.\n\n![Example](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_5.png)\n\në¬¸ì¥ 1ê³¼ ë¬¸ì¥ 2ì—ì„œ â€œbankâ€ë¼ëŠ” ë‹¨ì–´ëŠ” ëª…ë°±íˆ ë‘ ê°€ì§€ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ â€œbankâ€ ë‹¨ì–´ì˜ ì„ë² ë”© ê°’ì€ ë‘ ë¬¸ì¥ ëª¨ë‘ì—ì„œ ë™ì¼í•©ë‹ˆë‹¤. ì´ëŠ” ì ì ˆí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì„ë² ë”© ê°’ì´ ë¬¸ë§¥ì— ë”°ë¼ ë³€ê²½ë˜ì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì„ ì›í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë¬¸ì¥ì˜ ì „ì²´ ì˜ë¯¸ì— ê¸°ë°˜í•˜ì—¬ ë¬¸ë§¥ì  ì˜ë¯¸ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ë™ì  ì„ë² ë”© ê°’ì„ ê°€ì§€ëŠ” ë©”ì»¤ë‹ˆì¦˜ì´ í•„ìš”í•©ë‹ˆë‹¤. ìê°€ ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ì€ ë¬¸ì¥ì˜ ì „ì²´ ì˜ë¯¸ì— ê¸°ë°˜í•˜ì—¬ ë¬¸ë§¥ì  ì˜ë¯¸ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ì„ë² ë”© ê°’ì„ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nìê°€ ì£¼ì˜ê°€ ì´ë¯¸ ì¢‹ì€ë°, ì™œ ë‹¤ì¤‘ ë¨¸ë¦¬ ìê°€ ì£¼ì˜ê°€ í•„ìš”í• ê¹Œìš”? ë‹µì„ ì•Œì•„ë³´ê¸° ìœ„í•´ ì•„ë˜ ì˜ˆì‹œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n```\n![image](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_6.png)\n\nì´ ì˜ˆì—ì„œëŠ” self-attentionì„ ì‚¬ìš©í•  ë•Œ ë¬¸ì¥ì˜ í•œ ì¸¡ë©´ì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ìˆëŠ” ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì•„ë§ˆë„ \"what\" ì¸¡ë©´ë§Œì„ í¬ì°©í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, \"ì¡´ì´ ë¬´ì—‡ì„ í–ˆë‚˜ìš”?\"ì™€ ê°™ì´ìš”. ê·¸ëŸ¬ë‚˜ \"ì–¸ì œ\"ë‚˜ \"ì–´ë””\"ì™€ ê°™ì€ ë‹¤ë¥¸ ì¸¡ë©´ë“¤ë„ ëª¨ë¸ì´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ê¸° ìœ„í•´ ë™ë“±í•œ ì¤‘ìš”ì„±ì„ ê°–ìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ, Self-Attention ë©”ì»¤ë‹ˆì¦˜ì´ í•œ ë¬¸ì¥ ë‚´ì—ì„œ ì—¬ëŸ¬ ê´€ê³„ë¥¼ í•™ìŠµí•˜ë„ë¡ í•˜ëŠ” ë°©ë²•ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ì´ê²ƒì´ Multi-Head Self Attention(Multi-Head Attentionìœ¼ë¡œë„ êµì°¨ ì‚¬ìš© ê°€ëŠ¥)ì´ í•´ê²°í•´ ì£¼ëŠ” ê³³ì´ì£ . Multi-Head Attentionì—ì„œëŠ” ë‹¨ì¼ í—¤ë“œ ì„ë² ë”©ì„ ì—¬ëŸ¬ í—¤ë“œë¡œ ë¶„í• í•˜ì—¬ ê° í—¤ë“œê°€ ë¬¸ì¥ì˜ ë‹¤ë¥¸ ì¸¡ë©´ì„ ì‚´í´ë³´ê³  ê·¸ì— ë§ê²Œ í•™ìŠµí•©ë‹ˆë‹¤. ì´ê²ƒì´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ë°”ì…ë‹ˆë‹¤.\n\nì´ì œ ì™œ Multi-Head Attentionì´ í•„ìš”í•œì§€ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì–´ë–»ê²Œ ì‘ìš©í•˜ëŠ”ì§€ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. Multi-Head Attentionì€ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ” ê±¸ê¹Œìš”? ë°”ë¡œ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n\ní–‰ë ¬ ê³±ì…ˆì— ìµìˆ™í•˜ì‹œë‹¤ë©´, ì´ ë©”ì¹´ë‹ˆì¦˜ì„ ì´í•´í•˜ëŠ” ê²ƒì€ ê½¤ ì‰¬ìš´ ì‘ì—…ì¼ ê²ƒì…ë‹ˆë‹¤. ë¨¼ì € ì „ì²´ í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨ì„ ì‚´í´ë³´ê³  Multi-Head Attentionì˜ ì…ë ¥ë¶€í„° ì¶œë ¥ê¹Œì§€ì˜ í”Œë¡œìš°ë¥¼ ì•„ë˜ ì¼ëª©ìš”ì—°í•˜ê²Œ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\n\n\n\n<div class=\"content-ad\"></div>\n\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_7.png)\n\n1. ë¨¼ì €, ì¸ì½”ë” ì…ë ¥ì˜ 3ê°œ ë³µì‚¬ë³¸ì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤ (ì…ë ¥ ì„ë² ë”©ê³¼ ìœ„ì¹˜ ì¸ì½”ë”©ì˜ ì¡°í•©, ì´ê²ƒì€ ë‹¨ê³„ 4ì—ì„œ í–ˆì—ˆìŠµë‹ˆë‹¤). ê°ê°ì„ Q, K, Vë¼ê³  ì´ë¦„ ë¶™ì—¬ë´…ì‹œë‹¤. ì´ë“¤ì€ ë‹¨ì§€ ì¸ì½”ë” ì…ë ¥ì˜ ë³µì‚¬ë³¸ì¼ ë¿ì…ë‹ˆë‹¤. ì¸ì½”ë” ì…ë ¥ í˜•íƒœ: (seq_len, d_model), seq_len: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´, d_model: ì´ ê²½ìš°ì—ëŠ” ì„ë² ë”© ë²¡í„° ì°¨ì›ì´ 512ì…ë‹ˆë‹¤.\n\n2. ë‹¤ìŒìœ¼ë¡œ, Që¥¼ ê°€ì¤‘ì¹˜ W_q, Kë¥¼ ê°€ì¤‘ì¹˜ W_k, Vë¥¼ ê°€ì¤‘ì¹˜ W_vì™€ í–‰ë ¬ ê³±ì…ˆì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤. ê° ê°€ì¤‘ì¹˜ í–‰ë ¬ì˜ í˜•íƒœëŠ” (d_model, d_model)ì…ë‹ˆë‹¤. ìƒˆë¡œ ì–»ê²Œ ëœ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ì„ë² ë”© ë²¡í„°ì˜ í˜•íƒœëŠ” (seq_len, d_model)ì…ë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ë§¤ê°œë³€ìˆ˜ë“¤ì€ ëª¨ë¸ì— ì˜í•´ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ë˜ë©° ë‚˜ì¤€ì— ëª¨ë¸ì´ í›ˆë ¨ì„ ì‹œì‘í•  ë•Œ ì—…ë°ì´íŠ¸ë  ê²ƒì…ë‹ˆë‹¤. ì–´ì§¸ì„œ ìš°ë¦¬ê°€ ì²˜ìŒë¶€í„° í•˜ëŠ” ê°€ì¤‘ì¹˜ í–‰ë ¬ ê³±ì…ˆì´ í•„ìš”í•œ ê²ƒì¼ê¹Œìš”? ì™œëƒí•˜ë©´ ì´ê²ƒë“¤ì€ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ì„ë² ë”© ë²¡í„°ì— ë” ë‚˜ì€ í‘œí˜„ì„ ì œê³µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë“¤ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\n3. ì–´í…ì…˜ ë…¼ë¬¸ì— ë”°ë¥´ë©´, í—¤ë“œ(heads) ìˆ˜ëŠ” 8ì…ë‹ˆë‹¤. ê° ìƒˆë¡œìš´ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ ì„ë² ë”© ë²¡í„°ëŠ” 8ê°œì˜ ë” ì‘ì€ ìœ ë‹›ìœ¼ë¡œ ë‚˜ë‰˜ì–´ì§‘ë‹ˆë‹¤. ì„ë² ë”© ë²¡í„°ì˜ ìƒˆë¡œìš´ í˜•íƒœëŠ” (seq_len, d_model/num_heads) ë˜ëŠ” (seq_len, d_k)ì…ë‹ˆë‹¤. [ d_k = d_model/num_heads ].\n\n\n<div class=\"content-ad\"></div>\n\n4. ê° ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„°ëŠ” ìì‹  ë° ì‹œí€€ìŠ¤ì˜ ëª¨ë“  ë‹¤ë¥¸ ì„ë² ë”© ë²¡í„°ì˜ í‚¤ ì„ë² ë”© ë²¡í„°ì˜ ì „ì¹˜ì™€ ë‹· í”„ë¡œë•íŠ¸ ì—°ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ ë‹· í”„ë¡œë•íŠ¸ëŠ” ì£¼ì˜ ì ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì£¼ì˜ ì ìˆ˜ëŠ” ì£¼ì–´ì§„ í† í°ì´ ì£¼ì–´ì§„ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ë‹¤ë¥¸ ëª¨ë“  í† í°ê³¼ ì–¼ë§ˆë‚˜ ìœ ì‚¬í•œì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ìœ ì‚¬ë„ê°€ ë” ë†’ìŠµë‹ˆë‹¤.\n\n- ì£¼ì˜ ì ìˆ˜ëŠ” ë‚˜ì¤‘ì— ë§¤íŠ¸ë¦­ìŠ¤ ì „ì²´ì— ê±¸ì³ ì ìˆ˜ ê°’ì„ ì •ê·œí™”í•˜ëŠ” ë° í•„ìš”í•œ d_kì˜ ì œê³±ê·¼ìœ¼ë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì™œ d_kë¡œ ë‚˜ëˆ  ì •ê·œí™”í•´ì•¼ í•˜ëŠ” ê±¸ê¹Œìš”? ì–´ë–¤ ë‹¤ë¥¸ ìˆ«ìì—¬ë„ ê´œì°®ì„ í…ë°ìš”. ì£¼ëœ ì´ìœ ëŠ” ì„ë² ë”© ë²¡í„° ì°¨ì›ì´ ì¦ê°€í•¨ì— ë”°ë¼ ì£¼ì˜ ë§¤íŠ¸ë¦­ìŠ¤ì˜ ì´ ë¶„ì‚°ì´ ë¹„ë¡€í•´ì„œ ì¦ê°€í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ d_kë¡œ ë‚˜ëˆ„ë©´ ë¶„ì‚° ì¦ê°€ë¥¼ ê· í˜•ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§Œì•½ d_kë¡œ ë‚˜ëˆ„ì§€ ì•Šìœ¼ë©´, ì–´ë–¤ ë†’ì€ ì£¼ì˜ ì ìˆ˜ë¼ë„ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” ë§¤ìš° ë†’ì€ í™•ë¥  ê°’ì„ ì œê³µí•˜ê³ , ë°˜ëŒ€ë¡œ ë‚®ì€ ì£¼ì˜ ì ìˆ˜ ê°’ì— ëŒ€í•´ì„œëŠ” ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ê°€ ë§¤ìš° ë‚®ì€ í™•ë¥  ê°’ì„ ì œê³µí•  ê²ƒì…ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ëª¨ë¸ì€ ê·¸ëŸ¬í•œ í™•ë¥  ê°’ì´ ìˆëŠ” íŠ¹ì§•ë§Œ í•™ìŠµí•˜ë ¤ í•˜ê³ , ë‚®ì€ í™•ë¥  ê°’ì´ ìˆëŠ” íŠ¹ì§•ì„ ë¬´ì‹œí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤. ì´ëŠ” ê·¸ë¼ë””ì–¸íŠ¸ê°€ ì†Œì‹¤ë˜ëŠ” ë¬¸ì œë¡œ ì´ì–´ì§€ê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì£¼ì˜ ì ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì •ê·œí™”í•˜ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.\n- ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ìˆ˜í–‰í•˜ê¸° ì „ì—, ì¸ì½”ë” ë§ˆìŠ¤í¬ê°€ Noneì´ ì•„ë‹Œ ê²½ìš°, ì£¼ì˜ ì ìˆ˜ëŠ” ì¸ì½”ë” ë§ˆìŠ¤í¬ì™€ ë§¤íŠ¸ë¦­ìŠ¤ ê³±ì…ˆì´ ë  ê²ƒì…ë‹ˆë‹¤. ë§ˆìŠ¤í¬ê°€ ì¸ê³¼ì  ë§ˆìŠ¤í¬ì¸ ê²½ìš°, ì…ë ¥ ì‹œí€€ìŠ¤ì—ì„œ ê·¸ ì´í›„ì— ì˜¤ëŠ” ì„ë² ë”© í† í°ë“¤ì— ëŒ€í•œ ì£¼ì˜ ì ìˆ˜ ê°’ì€ -ve ë¬´í•œëŒ€ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤. ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ëŠ” -ve ë¬´í•œëŒ€ ê°’ì„ ê±°ì˜ 0 ê°’ìœ¼ë¡œ ë³€í™˜í•  ê²ƒì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ëª¨ë¸ì€ í˜„ì¬ í† í° ì´í›„ì— ë‚˜ì˜¤ëŠ” íŠ¹ì§•ì„ í•™ìŠµí•˜ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤. ì´ê²ƒì´ ìš°ë¦¬ ëª¨ë¸ í•™ìŠµì— ë¯¸ë˜ í† í°ì´ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n\n5. ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ê°€ ì£¼ì˜ ì ìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤ì— ì ìš©ë˜ê³  (seq_len, seq_len) ëª¨ì–‘ì˜ ê°€ì¤‘ì¹˜ ë§¤íŠ¸ë¦­ìŠ¤ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n\n6. ì´ ê°€ì¤‘ì¹˜ ë§¤íŠ¸ë¦­ìŠ¤ëŠ” í•´ë‹¹ ê°’ ì„ë² ë”© ë²¡í„°ì™€ ë§¤íŠ¸ë¦­ìŠ¤ ê³±ì…ˆì„ ìˆ˜í–‰í•  ê²ƒì…ë‹ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ (seq_len, d_v) ëª¨ì–‘ì˜ 8ê°œì˜ ì£¼ì˜ í—¤ë“œê°€ ìƒì„±ë©ë‹ˆë‹¤. [ d_v = d_model/num_heads ].\n\n<div class=\"content-ad\"></div>\n\nê·¸ëŸ¬ë©´, ëª¨ë“  í—¤ë“œë“¤ì´ ìƒˆë¡œìš´ í˜•íƒœ(seq_len, d_model)ë¥¼ ê°–ëŠ” ë‹¨ì¼ í—¤ë“œë¡œ ì—°ê²°ë©ë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ ë‹¨ì¼ í—¤ë“œëŠ” ì¶œë ¥ ê°€ì¤‘ì¹˜ í–‰ë ¬ W_o(d_model, d_model)ê³¼ í–‰ë ¬ ê³±ì…ˆì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. Multi-Head Attentionì˜ ìµœì¢… ì¶œë ¥ì€ ë‹¨ì–´ì˜ ë¬¸ë§¥ì  ì˜ë¯¸ì™€ ì…ë ¥ ë¬¸ì¥ì˜ ì—¬ëŸ¬ ì¸¡ë©´ì„ í•™ìŠµí•˜ëŠ” ëŠ¥ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n\nì´ì œ Multi-Head Attention ë¸”ë¡ ì½”ë”©ì„ ì‹œì‘í•´ë´…ì‹œë‹¤. ì´ê²ƒì€ í›¨ì”¬ ì‰½ê³  ê°„ë‹¨í•  ê±°ì˜ˆìš”.\n\n```js\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model: int, num_heads: int, dropout_rate: float):\n        super().__init__()\n        # ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ë“œë¡­ì•„ì›ƒì„ ì •ì˜í•©ë‹ˆë‹¤.\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        # ê°€ì¤‘ì¹˜ í–‰ë ¬ì€ ë„ì…ë˜ë©° ëª¨ë‘ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤.\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n\n        self.num_heads = num_heads\n        assert d_model % num_heads == 0, \"d_modelì€ í—¤ë“œ ìˆ˜ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\"\n        \n        # d_këŠ” ê° ë¶„í• ëœ self attention í—¤ë“œì˜ ìƒˆë¡œìš´ ì°¨ì›ì…ë‹ˆë‹¤\n        self.d_k = d_model // num_heads\n\n    def forward(self, q, k, v, encoder_mask=None):\n        \n        # ì—¬ëŸ¬ ì‹œí€€ìŠ¤ ë°°ì¹˜ë¡œ ëª¨ë¸ì„ í•œ ë²ˆì— ë³‘ë ¬ë¡œ í•™ìŠµí•˜ê²Œ ë  ê²ƒì´ë¯€ë¡œ, ëª¨ì–‘ì— ë°°ì¹˜ í¬ê¸°ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n        # ì¿¼ë¦¬, í‚¤ ë° ê°’ì€ í•´ë‹¹ ê°€ì¤‘ì¹˜ì™€ ì…ë ¥ ì„ë² ë”©ì˜ í–‰ë ¬ ê³±ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€í™”: q(ë°°ì¹˜ í¬ê¸°, seq_len, d_model) @ W_q(d_model, d_model) => query(ë°°ì¹˜ í¬ê¸°, seq_len, d_model) [í‚¤ì™€ ê°’ë„ ë™ì¼í•¨].\n        query = self.W_q(q) \n        key = self.W_k(k)\n        value = self.W_v(v)\n\n        # ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ë¥¼ í—¤ë“œ ìˆ˜ë¡œ ë¶„í• í•©ë‹ˆë‹¤. d_modelì€ d_kë§ˆë‹¤ 8ê°œ í—¤ë“œë¡œ ë¶„í• ë©ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€í™”: query(ë°°ì¹˜ í¬ê¸°, seq_len, d_model) => query(ë°°ì¹˜ í¬ê¸°, seq_len, num_heads, d_k) -> query(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, d_k) [í‚¤ì™€ ê°’ë„ ë™ì¼í•¨].\n        query = query.view(query.shape[0], query.shape[1], self.num_heads, self.d_k).transpose(1,2)\n        key = key.view(key.shape[0], key.shape[1], self.num_heads, self.d_k).transpose(1,2)\n        value = value.view(value.shape[0], value.shape[1], self.num_heads, self.d_k).transpose(1,2)\n\n        # :: SELF ATTENTION BLOCK STARTS ::\n\n        # ìœ ì‚¬ë„ ë˜ëŠ” ì¿¼ë¦¬ ê°„ì˜ ê´€ë ¨ì„±ì„ ì°¾ê¸° ìœ„í•´ ì£¼ì˜ ì ìˆ˜ê°€ ê³„ì‚°ë©ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€í™”: query(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, d_k) @ key(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, d_k) => attention_score(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, seq_len).\n        attention_score = (query @ key.transpose(-2,-1)) / math.sqrt(self.d_k)\n\n        # ë§Œì•½ ë§ˆìŠ¤í¬ê°€ ì œê³µëœë‹¤ë©´, ì£¼ì˜ ì ìˆ˜ë¥¼ ë§ˆìŠ¤í¬ ê°’ì— ë”°ë¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ 4ë²ˆì„ ì°¸ì¡°í•˜ì„¸ìš”.\n        if encoder_mask is not None:\n            attention_score = attention_score.masked_fill(encoder_mask == 0, -1e9)\n        \n        # softmax í•¨ìˆ˜ëŠ” ëª¨ë“  ì£¼ì˜ ì ìˆ˜ ì¤‘ì—ì„œ í™•ë¥  ë¶„í¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ë” ë†’ì€ ì£¼ì˜ ì ìˆ˜ì— ë” ë†’ì€ í™•ë¥  ê°’ì„ í• ë‹¹í•©ë‹ˆë‹¤. ì¦‰, ë³´ë‹¤ ìœ ì‚¬í•œ í† í°ì€ ë” ë†’ì€ í™•ë¥  ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€í™”: attention_scoreì™€ ë™ì¼í•©ë‹ˆë‹¤.\n        attention_weight = torch.softmax(attention_score, dim=-1)\n\n        if self.dropout is not None:\n            attention_weight = self.dropout(attention_weight)\n\n        # Self attention ë¸”ë¡ì˜ ìµœì¢… ë‹¨ê³„ëŠ” ì£¼ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°’ ì„ë² ë”© ë²¡í„°ì™€ì˜ í–‰ë ¬ ê³±ì…ˆì…ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€í™”: attention_score(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, seq_len) @ value(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, d_k) => attention_output(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, d_k)\n        attention_output = attention_score @ value\n        \n        # :: SELF ATTENTION BLOCK ENDS ::\n\n        # ì´ì œ, ëª¨ë“  í—¤ë“œë“¤ì´ ë‹¤ì‹œ ë‹¨ì¼ í—¤ë“œë¡œ ê²°í•©ë©ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€í™”: attention_output(ë°°ì¹˜ í¬ê¸°, num_heads, seq_len, d_k) => attention_output(ë°°ì¹˜ í¬ê¸°, seq_len, num_heads, d_k) => attention_output(ë°°ì¹˜ í¬ê¸°, seq_len, d_model)        \n        attention_output = attention_output.transpose(1,2).contiguous().view(attention_output.shape[0], -1, self.num_heads * self.d_k)\n\n        # ë§ˆì¹¨ë‚´ attention_outputì„ ì¶œë ¥ ê°€ì¤‘ì¹˜ í–‰ë ¬ë¡œ í–‰ë ¬ ê³±í•˜ì—¬ ìµœì¢… Multi-Head attention ì¶œë ¥ì„ ì–»ìŠµë‹ˆë‹¤.\n        # multihead_outputì˜ ëª¨ì–‘ì€ ì„ë² ë”© ì…ë ¥ê³¼ ë™ì¼í•©ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€í™”: attention_output(ë°°ì¹˜ í¬ê¸°, seq_len, d_model) @ W_o(d_model, d_model) => multihead_output(ë°°ì¹˜ í¬ê¸°, seq_len, d_model)\n        multihead_output = self.W_o(attention_output)\n        \n        return multihead_output\n```\n\n## Step 6: í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬, ë ˆì´ì–´ ì •ê·œí™” ë° AddAndNorm\n\n<div class=\"content-ad\"></div>\n\ní”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬: í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬ëŠ” ë‘ ê°œì˜ ì„ í˜• ë ˆì´ì–´(ì²« ë²ˆì§¸ëŠ” d_model ë…¸ë“œë¥¼ ê°€ì§€ê³  ë‘ ë²ˆì§¸ëŠ” d_ff ë…¸ë“œë¥¼ ê°€ì§€ë©°, ì£¼ì–´ì§„ ê°’ì€ ì–´í…ì…˜ ë…¼ë¬¸ì— ë”°ë¼ í• ë‹¹ë©ë‹ˆë‹¤)ë¥¼ í†µí•´ ì„ë² ë”© ë²¡í„°ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í•™ìŠµí•˜ëŠ” ë”¥ ì‹ ê²½ë§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ì„ í˜• ë ˆì´ì–´ì˜ ì¶œë ¥ì—ëŠ” ReLU í™œì„±í™” í•¨ìˆ˜ê°€ ì ìš©ë˜ì–´ ì„ë² ë”© ê°’ì„ ë¹„ì„ í˜•ìœ¼ë¡œ ë§Œë“¤ê³ , ê³¼ì í•©ì„ í”¼í•˜ê¸° ìœ„í•´ ë“œë¡­ì•„ì›ƒì´ ì ìš©ë©ë‹ˆë‹¤.\n\në ˆì´ì–´ ì •ê·œí™”: ë„¤íŠ¸ì›Œí¬ ë‚´ ì„ë² ë”© ë²¡í„°ì˜ ê°’ ë¶„í¬ê°€ ì¼ê´€ë˜ê²Œ ìœ ì§€ë˜ë„ë¡ ì„ë² ë”© ê°’ì— ë ˆì´ì–´ ì •ê·œí™”ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ì´ëŠ” ì›í™œí•œ í•™ìŠµì„ ë³´ì¥í•©ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ê°€ í•„ìš”ë¡œ í•˜ëŠ”ëŒ€ë¡œ ì„ë² ë”© ê°’ì„ ìŠ¤ì¼€ì¼ë§í•˜ê³  ì´ë™ì‹œí‚¤ê¸° ìœ„í•´ gammaì™€ betaë¼ëŠ” ì¶”ê°€ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n\nAddAndNorm: ì´ëŠ” ìŠ¤í‚µ ì—°ê²°ê³¼ ë ˆì´ì–´ ì •ê·œí™”(ì´ì „ì— ì„¤ëª…í•¨)ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. ìˆœë°©í–¥ íŒ¨ìŠ¤ì—ì„œ ìŠ¤í‚µ ì—°ê²°ì€ ì´ì „ ë ˆì´ì–´ì˜ ê¸°ëŠ¥ì´ ê³„ì‚° ê²°ê³¼ì— í•„ìš”í•œ ê¸°ì—¬ë¥¼ í•  ìˆ˜ ìˆë„ë¡ ë‚˜ì¤‘ ë‹¨ê³„ì—ì„œë„ í•´ë‹¹ ê¸°ëŠ¥ì„ ê¸°ì–µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ì—­ì „íŒŒ ì¤‘ì—ë„ ìŠ¤í‚µ ì—°ê²°ì€ ê° ë‹¨ê³„ì—ì„œ í•˜ë‚˜ ëœì˜ ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•´ ì‚¬ë¼ì§€ëŠ” ê¸°ìš¸ê¸°ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. AddAndNormì€ ì¸ì½”ë”(2ë²ˆ)ì™€ ë””ì½”ë” ë¸”ë¡(3ë²ˆ) ëª¨ë‘ì— ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ëŠ” ì´ì „ ë ˆì´ì–´ì—ì„œ ì…ë ¥ì„ ë°›ì•„ ì´ì „ ë ˆì´ì–´ì˜ ì¶œë ¥ì— ì¶”ê°€í•˜ê¸° ì „ì— ë¨¼ì € ì •ê·œí™”í•©ë‹ˆë‹¤.\n\n```js\n# Feedfoward Network, Layer Normalization and AddAndNorm Block\nclass FeedForward(nn.Module):\n    def __init__(self, d_model: int, d_ff: int, dropout_rate: float):\n        super().__init__()\n\n        self.layer_1 = nn.Linear(d_model, d_ff)\n        self.activation_1 = nn.ReLU()\n        self.dropout = nn.Dropout(dropout_rate)\n        self.layer_2 = nn.Linear(d_ff, d_model)\n    \n    def forward(self, input):\n        return self.layer_2(self.dropout(self.activation_1(self.layer_1(input))))\n\nclass LayerNorm(nn.Module):\n    def __init__(self, eps: float = 1e-5):\n        super().__init__()\n        # ì—¡ì‹¤ë¡ ì€ ë§¤ìš° ì‘ì€ ê°’ìœ¼ë¡œ, ì ì¬ì ìœ¼ë¡œ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë¬¸ì œë¥¼ ë°©ì§€í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n        self.eps = eps\n\n        # ìŠ¤ì¼€ì¼ë§ê³¼ ì´ë™ì„ ìœ„í•´ ì¶”ê°€ í•™ìŠµ ë§¤ê°œë³€ìˆ˜ì¸ ê°ë§ˆì™€ ë² íƒ€ë¥¼ ë„ì…í•©ë‹ˆë‹¤.\n        self.gamma = nn.Parameter(torch.ones(1))\n        self.beta = nn.Parameter(torch.zeros(1))\n    \n    def forward(self, input):\n        mean = input.mean(dim=-1, keepdim=True)      \n        std = input.std(dim=-1, keepdim=True)      \n\n        return self.gamma * ((input - mean)/(std + self.eps)) + self.beta\n        \nclass AddAndNorm(nn.Module):\n    def __init__(self, dropout_rate: float):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout_rate)\n        self.layer_norm = LayerNorm()\n\n    def forward(self, input, sub_layer):\n        return input + self.dropout(sub_layer(self.layer_norm(input)))\n```\n\n<div class=\"content-ad\"></div>\n\n## ë‹¨ê³„ 7: ì¸ì½”ë” ë¸”ë¡ê³¼ ì¸ì½”ë”\n\nì¸ì½”ë” ë¸”ë¡: ì¸ì½”ë” ë¸”ë¡ ì•ˆì—ëŠ” ë‘ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤: ë©€í‹°í—¤ë“œ ì–´í…ì…˜ê³¼ í”¼ë“œí¬ì›Œë“œì…ë‹ˆë‹¤. Add & Norm ë‹¨ìœ„ê°€ 2ê°œ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ì–´í…ì…˜ ë…¼ë¬¸ì˜ íë¦„ì— ë”°ë¼ EncoderBlock í´ë˜ìŠ¤ì— ëª¨ë“  ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œë¥¼ ì¡°ë¦½í•  ê²ƒì…ë‹ˆë‹¤. ë…¼ë¬¸ì— ë”°ë¥´ë©´ ì´ ì¸ì½”ë” ë¸”ë¡ì€ 6ë²ˆ ë°˜ë³µëœë‹¤ê³  í•©ë‹ˆë‹¤.\n\nì¸ì½”ë”: ê·¸ëŸ° ë‹¤ìŒ EncoderBlock ëª©ë¡ì„ ê°€ì ¸ì™€ ìŒ“ì•„ ìµœì¢… Encoder ì¶œë ¥ì„ ì œê³µí•  Encoderë¼ëŠ” ì¶”ê°€ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤.\n\n```python\nclass EncoderBlock(nn.Module):\n    def __init__(self, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float):\n        super().__init__()\n        self.multihead_attention = multihead_attention\n        self.feed_forward = feed_forward\n        self.add_and_norm_list = nn.ModuleList([AddAndNorm(dropout_rate) for _ in range(2)])\n\n    def forward(self, encoder_input, encoder_mask):\n        # ì¸ì½”ë” ì…ë ¥ì„ ìŠ¤í‚µ ì—°ê²°ì—ì„œ ê°€ì ¸ì™€ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë¸”ë¡ì˜ ì¶œë ¥ê³¼ ë”í•˜ëŠ” ì²« ë²ˆì§¸ AddAndNorm ë‹¨ìœ„ì…ë‹ˆë‹¤.\n        encoder_input = self.add_and_norm_list[0](encoder_input, lambda encoder_input: self.multihead_attention(encoder_input, encoder_input, encoder_input, encoder_mask))\n        \n        # ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë¸”ë¡ì˜ ì¶œë ¥ì„ ìŠ¤í‚µ ì—°ê²°ì—ì„œ ê°€ì ¸ì™€ í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ì˜ ì¶œë ¥ê³¼ ë”í•˜ëŠ” ë‘ ë²ˆì§¸ AddAndNorm ë‹¨ìœ„ì…ë‹ˆë‹¤.\n        encoder_input = self.add_and_norm_list[1](encoder_input, self.feed_forward)\n\n        return encoder_input\n\nclass Encoder(nn.Module):\n    def __init__(self, encoderblocklist: nn.ModuleList):\n        super().__init__()\n\n        # Encoder í´ë˜ìŠ¤ëŠ” encoderblock ëª©ë¡ì„ ê°€ì ¸ì™€ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n        self.encoderblocklist = encoderblocklist\n        self.layer_norm = LayerNorm()\n\n    def forward(self, encoder_input, encoder_mask):\n        # ëª¨ë“  ì¸ì½”ë” ë¸”ë¡ì„ ë°˜ë³µí•©ë‹ˆë‹¤ - ì´ 6ë²ˆ.\n        for encoderblock in self.encoderblocklist:\n            encoder_input = encoderblock(encoder_input, encoder_mask)\n\n        # ìµœì¢… ì¸ì½”ë” ë¸”ë¡ ì¶œë ¥ì„ ì •ê·œí™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ì¸ì½”ë” ì¶œë ¥ì€ ë‚˜ì¤‘ì— ë””ì½”ë” ë¸”ë¡ì˜ êµì°¨ ì–´í…ì…˜ì—ì„œ í‚¤ ë° ê°’ìœ¼ë¡œ ì‚¬ìš©ë  ê²ƒì…ë‹ˆë‹¤.\n        encoder_output = self.layer_norm(encoder_input)\n        return encoder_output\n```\n\n<div class=\"content-ad\"></div>\n\n## Step 8: ë””ì½”ë” ë¸”ë¡, ë””ì½”ë” ë° í”„ë¡œì ì…˜ ë ˆì´ì–´\n\në””ì½”ë” ë¸”ë¡: ë””ì½”ë” ë¸”ë¡ì—ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤: ë§ˆìŠ¤í‚¹ëœ ë©€í‹°í—¤ë“œ ì–´í…ì…˜, ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë° í”¼ë“œí¬ì›Œë“œì…ë‹ˆë‹¤. ë””ì½”ë” ë¸”ë¡ì—ëŠ” Add & Normì˜ 3ê°œ ë‹¨ìœ„ë„ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ êµ¬ì„± ìš”ì†Œë“¤ì„ Attention ë…¼ë¬¸ì˜ íë¦„ì— ë”°ë¼ DecoderBlock í´ë˜ìŠ¤ì— ëª¨ë‘ ì¡°í•©í•  ê²ƒì…ë‹ˆë‹¤. ë…¼ë¬¸ì— ë”°ë¥´ë©´ ì´ ë””ì½”ë” ë¸”ë¡ì€ 6ë²ˆ ë°˜ë³µë©ë‹ˆë‹¤.\n\në””ì½”ë”: ìš°ë¦¬ëŠ” DecoderBlockì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ ìŠ¤íƒí•˜ì—¬ ìµœì¢… ë””ì½”ë” ì¶œë ¥ì„ ìƒì„±í•  Decoderë¼ëŠ” ì¶”ê°€ í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤.\n\në””ì½”ë” ë¸”ë¡ì—ëŠ” ë‘ ê°€ì§€ íƒ€ì…ì˜ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ì´ ìˆìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ëŠ” Masked Multi-Head ì–´í…ì…˜ì…ë‹ˆë‹¤. ì´ëŠ” ë””ì½”ë” ì…ë ¥ì„ ì¿¼ë¦¬, í‚¤, ë°¸ë¥˜ë¡œ ì‚¬ìš©í•˜ë©° ë””ì½”ë” ë§ˆìŠ¤í¬(ì¸ê³¼ ë§ˆìŠ¤í¬ë¡œë„ ì•Œë ¤ì§)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¸ê³¼ ë§ˆìŠ¤í¬ëŠ” ëª¨ë¸ì´ ìˆœì„œì— ì•ì„œìˆëŠ” ì„ë² ë”©ì„ ë³¼ ìˆ˜ ì—†ê²Œ í•©ë‹ˆë‹¤. ì´ ë™ì‘ ë°©ì‹ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ 3ë‹¨ê³„ì™€ 5ë‹¨ê³„ì— ì œê³µë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\ní”„ë¡œì ì…˜ ë ˆì´ì–´: ë§ˆì§€ë§‰ ë””ì½”ë” ì¶œë ¥ì€ í”„ë¡œì ì…˜ ë ˆì´ì–´ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤. ì´ ë ˆì´ì–´ì—ì„œëŠ” ë¨¼ì € ë””ì½”ë” ì¶œë ¥ì´ ë¨¼ì € ì„ í˜• ë ˆì´ì–´ë¡œ ê³µê¸‰ë˜ì–´ ì„ë² ë”©ì˜ ëª¨ì–‘ì´ ì•„ë˜ ì½”ë“œ ì„¹ì…˜ì—ì„œ ì œê³µëœëŒ€ë¡œ ë³€ê²½ë  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ softmax í•¨ìˆ˜ê°€ ë””ì½”ë” ì¶œë ¥ì„ ì–´íœ˜ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¡œ ë³€í™˜í•˜ê³  ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ í† í°ì´ ì˜ˆì¸¡ ì¶œë ¥ìœ¼ë¡œ ì„ íƒë©ë‹ˆë‹¤.\n\n```js\nclass DecoderBlock(nn.Module):\n    def __init__(self, masked_multihead_attention: MultiHeadAttention, multihead_attention: MultiHeadAttention, feed_forward: FeedForward, dropout_rate: float):\n        super().__init__()\n        self.masked_multihead_attention = masked_multihead_attention\n        self.multihead_attention = multihead_attention\n        self.feed_forward = feed_forward\n        self.add_and_norm_list = nn.ModuleList([AddAndNorm(dropout_rate) for _ in range(3)])\n\n    def forward(self, decoder_input, decoder_mask, encoder_output, encoder_mask):\n        # ì²« ë²ˆì§¸ AddAndNorm ìœ ë‹›ì€ ë””ì½”ë” ì…ë ¥ì„ ìŠ¤í‚µ ì—°ê²°ì—ì„œ ê°€ì ¸ì™€ ë§ˆìŠ¤í‚¹ëœ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë¸”ë¡ì˜ ì¶œë ¥ê³¼ ë”í•©ë‹ˆë‹¤.\n        decoder_input = self.add_and_norm_list[0](decoder_input, lambda decoder_input: self.masked_multihead_attention(decoder_input, decoder_input, decoder_input, decoder_mask))\n        # ë‘ ë²ˆì§¸ AddAndNorm ìœ ë‹›ì€ ìŠ¤í‚µ ì—°ê²°ë¡œë¶€í„° ë§ˆìŠ¤í‚¹ëœ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë¸”ë¡ì˜ ì¶œë ¥ì„ ê°€ì ¸ì™€ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë¸”ë¡ì˜ ì¶œë ¥ê³¼ ë”í•©ë‹ˆë‹¤.\n        decoder_input = self.add_and_norm_list[1](decoder_input, lambda decoder_input: self.multihead_attention(decoder_input, encoder_output, encoder_output, encoder_mask)) # êµì°¨ ì–´í…ì…˜\n        # ì„¸ ë²ˆì§¸ AddAndNorm ìœ ë‹›ì€ ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë¸”ë¡ì˜ ì¶œë ¥ì„ ìŠ¤í‚µ ì—°ê²°ë¡œë¶€í„° ê°€ì ¸ì™€ í”¼ë“œí¬ì›Œë“œ ë ˆì´ì–´ì˜ ì¶œë ¥ê³¼ ë”í•©ë‹ˆë‹¤.\n        decoder_input = self.add_and_norm_list[2](decoder_input, self.feed_forward)\n        return decoder_input\n\nclass Decoder(nn.Module):\n    def __init__(self, decoderblocklist: nn.ModuleList):\n        super().__init__()\n        self.decoderblocklist = decoderblocklist\n        self.layer_norm = LayerNorm()\n\n    def forward(self, decoder_input, decoder_mask, encoder_output, encoder_mask):\n        for decoderblock in self.decoderblocklist:\n            decoder_input = decoderblock(decoder_input, decoder_mask, encoder_output, encoder_mask)\n\n        decoder_output = self.layer_norm(decoder_input)\n        return decoder_output\n\nclass ProjectionLayer(nn.Module):\n    def __init__(self, vocab_size: int, d_model: int):\n        super().__init__()\n        self.projection_layer = nn.Linear(d_model, vocab_size)\n\n    def forward(self, decoder_output):\n        # í”„ë¡œì ì…˜ ë ˆì´ì–´ëŠ” ë¨¼ì € ë””ì½”ë” ì¶œë ¥ì„ ë°›ì•„ (d_model, vocab_size) ëª¨ì–‘ì˜ ì„ í˜• ë ˆì´ì–´ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n        # ëª¨ì–‘ ë³€ê²½: decoder_output(batch_size, seq_len, d_model) @ linear_layer(d_model, vocab_size) => output(batch_size, seq_len, vocab_size)\n        output = self.projection_layer(decoder_output)\n        \n        # ì–´íœ˜ìƒì˜ í™•ë¥  ë¶„í¬ë¥¼ ì¶œë ¥í•˜ê¸° ìœ„í•´ softmax í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n        return torch.log_softmax(output, dim=-1)\n```\n\n## ë‹¨ê³„ 9: íŠ¸ëœìŠ¤í¬ë¨¸ ìƒì„± ë° êµ¬ì¶•\n\në§ˆì¹¨ë‚´, íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œ ë¸”ë¡ì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. ìœ ì¼í•œ ë¯¸ì™„ë£Œ ì‘ì—…ì€ ì´ ëª¨ë“  ê²ƒì„ í•¨ê»˜ ì¡°ë¦½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\në¨¼ì €, ì»´í¬ë„ŒíŠ¸ í´ë˜ìŠ¤ì˜ ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ëŠ” Transformer í´ë˜ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. Transform í´ë˜ìŠ¤ ë‚´ë¶€ì—ëŠ” ë¨¼ì € ì¸ì½”ë” ë¶€ë¶„ì˜ ëª¨ë“  ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ì¸ì½”ë” ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” encode í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n\në‘ ë²ˆì§¸ë¡œ, Transformerì˜ ë””ì½”ë” ë¶€ë¶„ì˜ ëª¨ë“  ì‘ì—…ì„ ìˆ˜í–‰í•˜ê³  ë””ì½”ë” ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” decode í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n\nì„¸ ë²ˆì§¸ë¡œ, ë””ì½”ë” ì¶œë ¥ì„ ê°€ì ¸ì™€ ì˜ˆì¸¡ì„ ìœ„í•´ í•´ë‹¹ ì–´íœ˜ì— ë§¤í•‘í•˜ëŠ” project í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n\nì´ì œ Transformer ì•„í‚¤í…ì²˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì•„ë˜ ì½”ë“œì—ì„œ í•„ìš”í•œ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ LLM ëª¨ë¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n```js\nclass Transformer(nn.Module):\n    def __init__(self, source_embed: EmbeddingLayer, target_embed: EmbeddingLayer, positional_encoding: PositionalEncoding, multihead_attention: MultiHeadAttention, masked_multihead_attention: MultiHeadAttention, feed_forward: FeedForward, encoder: Encoder, decoder: Decoder, projection_layer: ProjectionLayer, dropout_rate: float):        \n        super().__init__()\n        \n        # Transformer ì•„í‚¤í…ì²˜ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œ í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n        self.source_embed = source_embed\n        self.target_embed = target_embed\n        self.positional_encoding = positional_encoding\n        self.multihead_attention = multihead_attention        \n        self.masked_multihead_attention = masked_multihead_attention\n        self.feed_forward = feed_forward\n        self.encoder = encoder\n        self.decoder = decoder\n        self.projection_layer = projection_layer\n        self.dropout = nn.Dropout(dropout_rate)\n    \n    # Encode í•¨ìˆ˜ëŠ” ì¸ì½”ë” ì…ë ¥ì„ ë°›ì•„ì„œ ëª¨ë“  ì¸ì½”ë” ë¸”ë¡ ë‚´ì—ì„œ í•„ìš”í•œ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³  ì¸ì½”ë” ì¶œë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n    def encode(self, encoder_input, encoder_mask):\n        encoder_input = self.source_embed(encoder_input)\n        encoder_input = self.positional_encoding(encoder_input)\n        encoder_output = self.encoder(encoder_input, encoder_mask)\n        return encoder_output\n\n    # Decode í•¨ìˆ˜ëŠ” ë””ì½”ë” ì…ë ¥ì„ ë°›ì•„ì„œ ëª¨ë“  ë””ì½”ë” ë¸”ë¡ ë‚´ì—ì„œ í•„ìš”í•œ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•˜ê³  ë””ì½”ë” ì¶œë ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n    def decode(self, decoder_input, decoder_mask, encoder_output, encoder_mask):\n        decoder_input = self.target_embed(decoder_input)\n        decoder_input = self.positional_encoding(decoder_input)\n        decoder_output = self.decoder(decoder_input, decoder_mask, encoder_output, encoder_mask)\n        return decoder_output\n\n    # Projec í•¨ìˆ˜ëŠ” ë””ì½”ë” ì¶œë ¥ì„ íˆ¬ì˜ ë ˆì´ì–´ë¡œ ë°›ì•„ë“¤ì´ê³  ì¶œë ¥ì„ ì–´íœ˜ë¡œ ë§¤í•‘í•˜ì—¬ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n    def project(self, decoder_output):\n        return self.projection_layer(decoder_output)\n\ndef build_model(source_vocab_size, target_vocab_size, max_seq_len=1135, d_model=512, d_ff=2048, num_heads=8, num_blocks=6, dropout_rate=0.1):\n    \n    # Transformer ì•„í‚¤í…ì²˜ì— í•„ìš”í•œ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ ê°’ì„ ì •ì˜í•˜ê³  í• ë‹¹í•©ë‹ˆë‹¤.\n    source_embed = EmbeddingLayer(source_vocab_size, d_model)\n    target_embed = EmbeddingLayer(target_vocab_size, d_model)\n    positional_encoding = PositionalEncoding(max_seq_len, d_model, dropout_rate)\n    multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n    masked_multihead_attention = MultiHeadAttention(d_model, num_heads, dropout_rate)\n    feed_forward = FeedForward(d_model, d_ff, dropout_rate)    \n    projection_layer = ProjectionLayer(target_vocab_size, d_model)\n    encoder_block = EncoderBlock(multihead_attention, feed_forward, dropout_rate)\n    decoder_block = DecoderBlock(masked_multihead_attention, multihead_attention, feed_forward, dropout_rate)\n\n    encoderblocklist = []\n    decoderblocklist = []\n\n    for _ in range(num_blocks):\n        encoderblocklist.append(encoder_block)   \n         \n    for _ in range(num_blocks):\n        decoderblocklist.append(decoder_block)\n    \n    encoderblocklist = nn.ModuleList(encoderblocklist)            \n    decoderblocklist = nn.ModuleList(decoderblocklist)\n        \n    encoder = Encoder(encoderblocklist)\n    decoder = Decoder(decoderblocklist)\n    \n    # ëª¨ë“  ë§¤ê°œë³€ìˆ˜ ê°’ì„ ì œê³µí•˜ì—¬ Transformer í´ë˜ìŠ¤ë¥¼ ì¸ìŠ¤í„´ìŠ¤í™”í•©ë‹ˆë‹¤.\n    model = Transformer(source_embed, target_embed, positional_encoding, multihead_attention, masked_multihead_attention, feed_forward, encoder, decoder, projection_layer, dropout_rate)\n\n    for param in model.parameters():\n        if param.dim() > 1:\n            nn.init.xavier_uniform_(param)\n    \n    return model\n\n# ë§ˆì¹¨ë‚´, build_modelì„ í˜¸ì¶œí•˜ê³  model ë³€ìˆ˜ì— í• ë‹¹í•©ë‹ˆë‹¤.\n# ì´ ëª¨ë¸ì€ ì´ì œ ë°ì´í„°ì…‹ì„ í›ˆë ¨í•˜ê³  ê²€ì¦í•˜ëŠ” ë° ì™„ì „íˆ ì¤€ë¹„ëœ ìƒíƒœì…ë‹ˆë‹¤.\n# í›ˆë ¨ ë° ê²€ì¦ í›„ ì´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ë²ˆì—­ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nmodel = build_model(source_vocab_size, target_vocab_size)\n```\n\n## ë‹¨ê³„ 10: ìƒì„±í•œ LLM ëª¨ë¸ì˜ í›ˆë ¨ ë° ê²€ì¦\n\nì§€ê¸ˆì€ ëª¨ë¸ì„ í›ˆë ¨í•  ì‹œê°„ì…ë‹ˆë‹¤. í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ëŠ” ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‹¨ê³„ 3ì—ì„œ ìƒì„±í•œ í›ˆë ¨ DataLoaderë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ í›ˆë ¨ ë°ì´í„°ì…‹ ìˆ˜ê°€ 100ë§Œì´ë¯€ë¡œ GPU ì¥ì¹˜ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ê²ƒì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤. 20 epochë¥¼ ì™„ë£Œí•˜ëŠ” ë° ì•½ 5ì‹œê°„ì´ ì†Œìš”ë˜ì—ˆìŠµë‹ˆë‹¤. ê° epoch ì´í›„ì—ëŠ” ëª¨ë¸ ê°€ì¤‘ì¹˜ì™€ ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬ ì¤‘ì§€ëœ ì§€ì ë¶€í„° í›ˆë ¨ì„ ë‹¤ì‹œ ì‹œì‘í•˜ëŠ” ê²ƒì´ ë” ì‰½ê¸° ë•Œë¬¸ì— ì´ì „ ì§€ì ì—ì„œ í›ˆë ¨ì„ ì¬ê°œí•˜ëŠ” ê²ƒë³´ë‹¤ ë” ë‚˜ì„ ê²ƒì…ë‹ˆë‹¤.\n\në§¤ ì—í¬í¬ ì´í›„ì—ëŠ” ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤. ê²€ì¦ ë°ì´í„°ì…‹ í¬ê¸°ëŠ” 2000ìœ¼ë¡œ ë§¤ìš° í•©ë¦¬ì ì…ë‹ˆë‹¤. ê²€ì¦ í”„ë¡œì„¸ìŠ¤ ì¤‘ì—ëŠ” ë””ì½”ë” ì¶œë ¥ì´ [SEP] í† í°ì„ ë°›ì„ ë•Œê¹Œì§€ í•œ ë²ˆë§Œ ì¸ì½”ë” ì¶œë ¥ì„ ê³„ì‚°í•˜ë©´ ë©ë‹ˆë‹¤. ì´ê²ƒì€ ë””ì½”ë”ê°€ [SEP] í† í°ì„ ë°›ê¸° ì „ê¹Œì§€ ë™ì¼í•œ ì¸ì½”ë” ì¶œë ¥ì„ ê³„ì† ë³´ë‚´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\në””ì½”ë” ì…ë ¥ì€ ë¨¼ì € ë¬¸ì¥ ì‹œì‘ í† í° [CLS]ìœ¼ë¡œ ì‹œì‘ë©ë‹ˆë‹¤. ê° ì˜ˆì¸¡ í›„ì—ëŠ” ë””ì½”ë” ì…ë ¥ì´ ë‹¤ìŒ ìƒì„±ëœ í† í°ì„ ë¶™ì—¬ë„£ì„ ê²ƒì´ë©°, ë¬¸ì¥ ë í† í° [SEP]ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì´ë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, í”„ë¡œì ì…˜ ë ˆì´ì–´ëŠ” ì¶œë ¥ì„ í•´ë‹¹ í…ìŠ¤íŠ¸ í‘œí˜„ìœ¼ë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\n\n```js\ndef training_model(preload_epoch=None):   \n\n    # ì „ì²´ í›ˆë ¨ ë° ê²€ì¦ ì£¼ê¸°ëŠ” 20ë²ˆ ì‹¤í–‰ë©ë‹ˆë‹¤.\n    EPOCHS = 20\n    initial_epoch = 0\n    global_step = 0    \n    \n    # Adamì€ í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ê³„ì‚°ëœ ê¸°ìš¸ê¸°ì— ê¸°ë°˜í•˜ì—¬ ë§¤ê°œë³€ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê°€ì¥ ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.         \n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    \n    # preload_epochê°€ Noneì´ ì•„ë‹Œ ê²½ìš°, ì´ëŠ” ìµœê·¼ ì €ì¥ëœ ê°€ì¤‘ì¹˜, ìµœì í™”ê¸°ë¡œ í›ˆë ¨ì´ ì‹œì‘ë  ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ ì—í¬í¬ ë²ˆí˜¸ëŠ” preload epoch + 1ì´ ë©ë‹ˆë‹¤.\n    if preload_epoch is not None:\n        model_filename = f\"./malaygpt/model_{preload_epoch}.pt\"\n        state = torch.load(model_filename)\n        initial_epoch = state['epoch'] + 1\n        optimizer.load_state_dict(state['optimizer_state_dict'])\n        global_step = state['global_step']\n\n    # CrossEntropyLoss ì†ì‹¤ í•¨ìˆ˜ëŠ” í”„ë¡œì ì…˜ ì¶œë ¥ê³¼ ëŒ€ìƒ ë¼ë²¨ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n    loss_fn = nn.CrossEntropyLoss(ignore_index = tokenizer_en.token_to_id(\"[PAD]\"), label_smoothing=0.1).to(device)\n\n    for epoch in range(initial_epoch, EPOCHS):\n\n        # ::: í›ˆë ¨ ë¸”ë¡ ì‹œì‘ :::\n        model.train()  \n        \n        # í›ˆë ¨ ë°ì´í„°ë¡œë”ë¡œ í›ˆë ¨ì„ ì§„í–‰í•©ë‹ˆë‹¤.     \n        for batch in tqdm(train_dataloader):\n            encoder_input = batch['encoder_input'].to(device)   # (batch_size, seq_len)\n            decoder_input = batch['decoder_input'].to(device)    # (batch_size, seq_len)\n            target_label = batch['target_label'].to(device)      # (batch_size, seq_len)\n            encoder_mask = batch['encoder_mask'].to(device)       \n            decoder_mask = batch['decoder_mask'].to(device)         \n\n            encoder_output = model.encode(encoder_input, encoder_mask)\n            decoder_output = model.decode(decoder_input, decoder_mask, encoder_output, encoder_mask)\n            projection_output = model.project(decoder_output)\n\n            # projection_output(batch_size, seq_len, vocab_size)\n            loss = loss_fn(projection_output.view(-1, projection_output.shape[-1]), target_label.view(-1))\n            \n            # ì—­ì „íŒŒ\n            optimizer.zero_grad()\n            loss.backward()\n\n            # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n            optimizer.step()        \n            global_step += 1\n\n        print(f'Epoch [{epoch+1}/{EPOCHS}]: Train Loss: {loss.item():.2f}')\n        \n        # ê° ì—í¬í¬ê°€ ëë‚œ í›„ ëª¨ë¸ ìƒíƒœë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n        model_filename = f\"./malaygpt/model_{epoch}.pt\"\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'global_step': global_step\n        }, model_filename)        \n        # ::: í›ˆë ¨ ë¸”ë¡ ë :::\n\n        # ::: ê²€ì¦ ë¸”ë¡ ì‹œì‘ :::\n        model.eval()        \n        with torch.inference_mode():\n            for batch in tqdm(val_dataloader):                \n                encoder_input = batch['encoder_input'].to(device)   # (batch_size, seq_len)                        \n                encoder_mask = batch['encoder_mask'].to(device)\n                source_text = batch['source_text']\n                target_text = batch['target_text']\n                \n                # ì†ŒìŠ¤ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ì¸ì½”ë” ì¶œë ¥ ê³„ì‚°\n                encoder_output = model.encode(encoder_input, encoder_mask)\n\n                # ì˜ˆì¸¡ ì‘ì—…ì„ ìœ„í•´ ë””ì½”ë” ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ì²« ë²ˆì§¸ í† í°ì€ [CLS] í† í°ì…ë‹ˆë‹¤.\n                decoder_input = torch.empty(1,1).fill_(tokenizer_my.token_to_id('[CLS]')).type_as(encoder_input).to(device)\n\n                # [SEP] - ë í† í°ì´ ë°›ì•„ì§ˆ ë•Œê¹Œì§€ ìƒˆë¡œìš´ ì¶œë ¥ì„ ì…ë ¥ì— ê³„ì† ì¶”ê°€í•´ì•¼ í•˜ë¯€ë¡œ, ì´ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n                while True:                     \n                    # ìµœëŒ€ ê¸¸ì´ë¥¼ ë°›ì•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ê·¸ë ‡ë‹¤ë©´ ì¤‘ì§€í•©ë‹ˆë‹¤.\n                    if decoder_input.size(1) == max_seq_len:\n                        break\n\n                    # ìƒˆë¡œìš´ ì¶œë ¥ì´ ì¶”ê°€ë  ë•Œë§ˆë‹¤ ìƒˆë¡œ ë§ˆìŠ¤í¬ë¥¼ ë§Œë“¤ì–´ ë‹¤ìŒ í† í° ì˜ˆì¸¡ì„ ìœ„í•´ ë””ì½”ë” ì…ë ¥ì— ì¶”ê°€í•©ë‹ˆë‹¤.\n                    decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n\n                    decoder_output = model.decode(decoder_input,decoder_mask,encoder_output,encoder_mask)\n                    \n                    # í”„ë¡œì ì…˜ì„ ë‹¤ìŒ í† í°ì—ë§Œ ì ìš©í•©ë‹ˆë‹¤.\n                    projection = model.project(decoder_output[:, -1])\n\n                    # ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°–ëŠ” í† í°ì„ ì„ íƒí•˜ì—¬ íƒìš• íƒìƒ‰ êµ¬í˜„ì„ í•©ë‹ˆë‹¤.\n                    _, new_token = torch.max(projection, dim=1)\n                    new_token = torch.empty(1,1). type_as(encoder_input).fill_(new_token.item()).to(device)\n\n                    # ìƒˆë¡œìš´ í† í°ì„ ë‹¤ì‹œ ë””ì½”ë” ì…ë ¥ì— ì¶”ê°€í•©ë‹ˆë‹¤.\n                    decoder_input = torch.cat([decoder_input, new_token], dim=1)\n\n                    # ìƒˆë¡œìš´ í† í°ì´ ì¢…ë£Œ í† í°ì¸ ê²½ìš°, ë°›ì•„ë“¤ì˜€ë‹¤ë©´ ì¤‘ì§€í•©ë‹ˆë‹¤.\n                    if new_token == tokenizer_my.token_to_id('[SEP]'):\n                        break\n\n                # ì „ì²´ë¡œ ì¶”ê°€ëœ ë””ì½”ë” ì…ë ¥ì„ ë””ì½”ë” ì¶œë ¥ìœ¼ë¡œ í• ë‹¹í•©ë‹ˆë‹¤.\n                decoder_output = decoder_input.sequeeze(0)\n                model_predicted_text = tokenizer_my.decode(decoder_output.detach().cpu.numpy())\n                \n                print(f'SOURCE TEXT\": {source_text}')\n                print(f'TARGET TEXT\": {target_text}')\n                print(f'PREDICTED TEXT\": {model_predicted_text}')   \n                # ::: ê²€ì¦ ë¸”ë¡ ë :::             \n\n# ì´ í•¨ìˆ˜ëŠ” 20ë²ˆì˜ ì—í¬í¬ì— ëŒ€í•´ í›ˆë ¨ ë° ê²€ì¦ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\ntraining_model(preload_epoch=None)\n```\n\n## ë‹¨ê³„ 11: ìƒˆ ë²ˆì—­ ì‘ì—…ì„ í˜„ì¬ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í•¨ìˆ˜ ìƒì„±\n\në²ˆì—­ ê¸°ëŠ¥ì— ì¼ë°˜ì ì¸ ì´ë¦„ì¸ malaygptë¥¼ í• ë‹¹í•©ë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ì ì…ë ¥ ì˜ì–´ ì›ì‹œ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë§ë ˆì´ì–´ ì–¸ì–´ë¡œ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ë¥¼ ì‹¤í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n```js\ndef malaygpt(user_input_text):\n  model.eval()\n  with torch.inference_mode():\n    user_input_text = user_input_text.strip()\n    user_input_text_encoded = torch.tensor(tokenizer_en.encode(user_input_text).ids, dtype=torch.int64).to(device)\n\n    num_source_padding = max_seq_len - len(user_input_text_encoded) - 2\n    encoder_padding = torch.tensor([PAD_ID] * num_source_padding, dtype=torch.int64).to(device)\n    encoder_input = torch.cat([CLS_ID, user_input_text_encoded, SEP_ID, encoder_padding]).to(device)\n    encoder_mask = (encoder_input != PAD_ID).unsqueeze(0).unsqueeze(0).int().to(device)\n\n    # Computing the output of the encoder for the source sequence\n    encoder_output = model.encode(encoder_input, encoder_mask)\n    # for prediction task, the first token that goes in decoder input is the [CLS] token\n    decoder_input = torch.empty(1, 1).fill_(tokenizer_my.token_to_id('[CLS]')).type_as(encoder_input).to(device)\n\n    # since we need to keep adding the output back to the input until the [SEP] - end token is received.\n    while True:\n        # check if the max length is received\n        if decoder_input.size(1) == max_seq_len:\n            break\n        # recreate mask each time the new output is added to the decoder input for the next token prediction\n        decoder_mask = causal_mask(decoder_input.size(1)).type_as(encoder_mask).to(device)\n        decoder_output = model.decode(decoder_input, decoder_mask, encoder_output, encoder_mask)\n\n        # apply projection only to the next token\n        projection = model.project(decoder_output[:, -1])\n\n        # select the token with the highest probability which is a greedy search implementation\n        _, new_token = torch.max(projection, dim=1)\n        new_token = torch.empty(1, 1).type_as(encoder_input).fill_(new_token.item()).to(device)\n\n        # add the new token back to the decoder input\n        decoder_input = torch.cat([decoder_input, new_token], dim=1)\n\n        # check if the new token is the end of the token\n        if new_token == tokenizer_my.token_to_id('[SEP]'):\n            break\n    # the final decoder out is the concatenated decoder input until the end token\n    decoder_output = decoder_input.squeeze(0)\n    model_predicted_text = tokenizer_my.decode(decoder_output.detach().cpu.numpy())\n\n    return model_predicted_text\n```\n\nTesting Time! Letâ€™s do some translation testing.\n\n![image](/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_8.png)\n\nâ€œThe translation seems to be working pretty well.â€\n\n<div class=\"content-ad\"></div>\n\nì—¬ê¸°ê¹Œì§€ì…ë‹ˆë‹¤! ì´ì œëŠ” PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ ì²˜ìŒë¶€í„° Large Language Modelì„ ë§Œë“¤ ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ë§¤ìš° ìì‹ í•©ë‹ˆë‹¤. ë¬¼ë¡  ì´ ëª¨ë¸ì„ ë‹¤ë¥¸ ì–¸ì–´ ë°ì´í„°ì…‹ì—ì„œë„ í›ˆë ¨ì‹œí‚¤ê³  í•´ë‹¹ ì–¸ì–´ë¡œ ë²ˆì—­ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ì œ ì²˜ìŒë¶€í„° transformerë¥¼ ë§Œë“œëŠ” ë°©ë²•ì„ ë°°ì› ìœ¼ë‹ˆ, ì´ì œ ì‹œì¥ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëŒ€ë¶€ë¶„ì˜ LLMì— ëŒ€í•œ í•™ìŠµ ë° ì‘ìš©ì„ ìŠ¤ìŠ¤ë¡œ í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ í™•ì‹ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê·¸ë‹¤ìŒì€ ë¬´ì—‡ì¼ê¹Œìš”? í˜„ì¬ ì‹œì¥ì—ì„œ ì¸ê¸°ìˆëŠ” ì˜¤í”ˆì†ŒìŠ¤ LLM ëª¨ë¸ ì¤‘ í•˜ë‚˜ì¸ Llama 3 ëª¨ë¸ì„ íŒŒì¸ íŠœë‹í•˜ì—¬ ì™„ì „íˆ ê¸°ëŠ¥ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤. ì „ì²´ ì†ŒìŠ¤ ì½”ë“œë„ í•¨ê»˜ ê³µìœ í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n\nê·¸ëŸ¬ë‹ˆ ê¸°ëŒ€í•´ ì£¼ì‹œê³ , ì½ì–´ ì£¼ì…”ì„œ ì •ë§ ê°ì‚¬í•©ë‹ˆë‹¤!\n\nì €ì™€ ì—°ê²°í•´ ë³´ì„¸ìš”: https://www.linkedin.com/in/tamangmilan\n\n<div class=\"content-ad\"></div>\n\n**Google Colab ë…¸íŠ¸ë¶ ë§í¬**\n\n**ì°¸ê³  ìë£Œ**\n\n- Attention Is All You Need â€” ë…¼ë¬¸, Ashish Vaswani, Noam Shazeer, ê·¸ë¦¬ê³  íŒ€\n- Attention in transformers, ì‹œê°ì ìœ¼ë¡œ ì„¤ëª…ëœ ë‚´ìš©, 3Blue1Brown â€” ìœ íŠœë¸Œ\n- GPT êµ¬ì¶•í•˜ê¸°, Andrej Karpathy, ìœ íŠœë¸Œ\n- https://github.com/hkproj/pytorch-transformer â€” Umar Jamil","ogImage":{"url":"/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_0.png"},"coverImage":"/assets/img/2024-06-19-BuildyourownLargeLanguageModelLLMFromScratchUsingPyTorch_0.png","tag":["Tech"],"readingTime":40},{"title":"í˜ì‹  ìˆ˜ìš©í•˜ê¸° ë¡œë³´í‹±ìŠ¤ë¡œ ë¯¸ë˜ë¥¼ ë°œê²¬í•˜ë‹¤","description":"","date":"2024-06-19 18:41","slug":"2024-06-19-TitleEmbracingInnovationUnveilingtheFuturewithRobotics","content":"\n\në¡œë´‡ì´ ì¸ê°„ê³¼ í•¨ê»˜ ì¼ìƒ ì—…ë¬´ë¥¼ ë³´ì¡°í•˜ë©° í˜ì‹ ì ì¸ ë°œê²¬ì„ í•˜ë©° ë†€ë¼ìš´ ê¸°íšŒë¥¼ ì°½ì¶œí•˜ëŠ” ì„¸ê³„ë¥¼ ìƒìƒí•´ë³´ì„¸ìš”. ì´ê²ƒì€ ê³¼í•™ ì†Œì„¤ì´ ì•„ë‹ˆë¼, ë¡œë´‡ ê¸°ìˆ ì„ ì£¼ë„í•˜ëŠ” ê¸°ìˆ ì˜ ë¯¸ë˜ì…ë‹ˆë‹¤.\n\n![ë¡œë´‡ ì´ë¯¸ì§€](/assets/img/2024-06-19-TitleEmbracingInnovationUnveilingtheFuturewithRobotics_0.png)\n\nì´ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œëŠ” ë¡œë´‡ ê¸°ìˆ ì´ ì¸ë¥˜ì—ê²Œ ì œê³µí•˜ëŠ” ë§¤í˜¹ì ì¸ ì¥ì ì„ ì‚´í´ë³´ë©°, ìš°ë¦¬ í˜„ì¬ë¥¼ ì¬ì •ì˜í•˜ê³  ì•½ì†ëœ ë‚´ì¼ì„ ëª¨ìŠµì„ ë§Œë“¤ì–´ê°€ëŠ” ê²ƒì„ íƒêµ¬í•  ê²ƒì…ë‹ˆë‹¤.\n\nSection 1: ë¡œë´‡ ê¸°ìˆ ì˜ ë¶€ìƒ â€” ì—­ì‚¬ì  ê´€ì \n\n<div class=\"content-ad\"></div>\n\nê³ ëŒ€ ë¬¸ëª…ì˜ ì´ˆê¸° ìë™í™” ì¥ì¹˜ë¶€í„° ì˜¤ëŠ˜ë‚ ì˜ ì •êµí•œ ê¸°ê³„ê¹Œì§€, ë¡œë´‡í•™ì˜ ì§„í™”ëŠ” ë†€ë¼ìš¸ ì •ë„ë¡œ íƒì›”í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì—­ì‚¬ë¥¼ ì´í•´í•¨ìœ¼ë¡œì¨, ìš°ë¦¬ëŠ” ì–´ë””ê¹Œì§€ ì™”ëŠ”ì§€ ê·¸ë¦¬ê³  ì•ìœ¼ë¡œ ì–´ë–¤ ë°œì „ì´ ê¸°ëŒ€ë˜ëŠ”ì§€ì— ëŒ€í•œ ì†Œì¤‘í•œ í†µì°°ë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nSection 2: ì‚°ì—… ì „ë°˜ì—ì„œ íš¨ìœ¨ í–¥ìƒ\n\në¡œë´‡ì€ ì œì¡°ì—…, ì˜ë£Œ, ë†ì—…, ë¬¼ë¥˜ ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ ìƒì‚°ì„±ì„ í–¥ìƒì‹œí‚¤ê³ , ì˜¤ë¥˜ë¥¼ ìµœì†Œí™”í•˜ë©°, ì•ˆì „ ì¡°ì¹˜ë¥¼ ê°œì„ í•˜ê³ , ë¹„ìš©ì„ ì¤„ì´ëŠ” ë°©ì‹ìœ¼ë¡œ í˜ëª…ì„ ì¼ìœ¼í‚¤ê³  ìˆìŠµë‹ˆë‹¤. ëŒ€í‘œì ì¸ ì‚¬ë¡€ë¡œëŠ” ê³µì¥ ìƒì‚° ë¼ì¸ì˜ ë¡œë´‡ íŒ”ì´ë‚˜, ìˆ˜ìˆ ì„ ì •ë°€í•œ ë¯¸ì„¸ ìˆ˜ì¤€ìœ¼ë¡œ ì§€ì›í•˜ëŠ” ë¡œë´‡ ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n\nSection 3: ë¡œë´‡í•™ â€” í˜ì‹ ì„ ìœ„í•œ ë“±ëŒ€\n\n<div class=\"content-ad\"></div>\n\në¡œë´‡ ê¸°ìˆ ì€ ìµœì‹  ì—°êµ¬ë¥¼ ì£¼ë„í•˜ëŠ” ì›ë™ë ¥ì…ë‹ˆë‹¤. ìƒˆë¡œìš´ ì†Œì¬ ê°œë°œë¶€í„° ì™¸ë¶€ ìš°ì£¼ì—ì„œ ë¯¸ì§€ì˜ ì˜ì—­ì„ íƒí—˜í•˜ëŠ” ë“±ì˜ ë¶„ì•¼ì— í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤. NASAì˜ í™”ì„± ë¡œë²„ì™€ í•´ì € ë¡œë´‡ê³¼ ê°™ì€ ì‚¬ë¡€ ì—°êµ¬ë“¤ì€ ì´ì „ì— ìš°ë¦¬ê°€ ë‹¿ì„ ìˆ˜ ì—†ì—ˆë˜ ë°œê²¬ì˜ ê¸¸ì„ ì—´ê³  ìˆìŠµë‹ˆë‹¤.\n\n4ì¥: ê°œì¸ ë¡œë´‡ì„ í†µí•œ ì‚¶ì˜ ì§ˆ í–¥ìƒ\n\në¡œë´‡ ì§€ì›ì€ ì „ë¬¸ ë¶„ì•¼ì—ë§Œ êµ­í•œë˜ì§€ ì•Šê³  ê°œì¸ì ì¸ ìƒí™œì—ë„ í™•ì¥ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë…¸ì¸ì´ë‚˜ ì¥ì• ì¸ì„ ë¡œë´‡ ì´ë™ ë³´ì¡°ê¸°ì™€ ë™ë°˜ì ë¡œë´‡ì„ í†µí•´ ì§€ì›í•¨ìœ¼ë¡œì¨, ì´ ê¸°ìˆ ì€ ë…ë¦½ì„±ê³¼ ê°ì •ì  ì§€ì›ì„ ì œê³µí•˜ì—¬ ì´ì²´ì ì¸ ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n\n5ì¥: ê²½ì œì  ì´ì ê³¼ ì¼ìë¦¬ ì°½ì¶œ\n\n<div class=\"content-ad\"></div>\n\nì¼ë¶€ ì‚¬ëŒë“¤ì€ ì¼ìë¦¬ ì¹˜í™˜ì— ëŒ€í•´ ê±±ì •í•˜ê¸°ë„ í•˜ì§€ë§Œ, ë¡œë´‡ê³µí•™ì´ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ ì¼ìë¦¬ ì°½ì¶œ ê¸°íšŒë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„ ëª…ì‹¬í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì œì¡° ë¡œë´‡ë¶€í„° íŠ¹ìˆ˜ ì¡°ë¦½ ì‘ì—…ìê°€ í•„ìš”í•œ ì„œë¹„ìŠ¤ ì—…ë°ì´íŠ¸ë‚˜ ìˆ˜ë¦¬ ì„œë¹„ìŠ¤ ì œê³µ ì—…ì²´ê¹Œì§€ ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ ì¼ìë¦¬ê°€ ì°½ì¶œë©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, ë¡œë´‡ì´ ë°˜ë³µì ì¸ ì‘ì—…ì„ ëŒ€ì‹ í•˜ë©´ì„œ ì¸ê°„ë“¤ì€ ì°½ì˜ì ì´ê³  ë¶„ì„ì  ì—­í• ì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.\n\nì„¹ì…˜ 6: ë¯¸ë˜ ê°€ëŠ¥ì„± â€” ë¡œë´‡ê³µí•™ì˜ ë‹¤ìŒ ë‹¨ê³„\n\nì¸ê³µì§€ëŠ¥(AI)ì€ ì¸ê°„ê³¼ ê¸°ê³„ ê°„ì— ì „ë¡€ì—†ëŠ” í˜‘ë ¥ì„ ì•½ì†í•˜ëŠ” ë¡œë´‡ê³µí•™ ì„¸ê³„ì— í™˜ìƒì ì¸ ìš”ì†Œì…ë‹ˆë‹¤. ììœ¨ ì£¼í–‰ ìë™ì°¨, ì—°êµ¬ìš© AI ì¦ê°• ë¡œë´‡ ë˜ëŠ” ì‹¬ì§€ì–´ ì™¸ê³„ íƒì‚¬ë¥¼ ìœ„í•œ í˜ì‹ ì€ ë°”ë¡œ ë’¤ì— ìˆìŠµë‹ˆë‹¤. ì´ ëª¨ë“  ê²ƒì€ ë¡œë´‡ê³µí•™ ê¸°ìˆ ì˜ ë°œì „ ë•ë¶„ì— ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤!\n\nìš°ë¦¬ê°€ ì´ì²˜ëŸ¼ í˜ì‹ ì ì¸ ë¡œë´‡ê³µí•™ì˜ í˜œíƒì„ ë°›ì•„ë“¤ì¼ ë•Œ, ê·¸ë“¤ì´ ì‚¬íšŒì— ë‹¤ì–‘í•œ í˜œíƒì„ ì œê³µí•¨ì´ ëª…ë°±í•©ë‹ˆë‹¤. ì‘ì—…ì„ íš¨ìœ¨í™”í•˜ê³  ì‚°ì—… ì „ë°˜ì— í˜ì‹ ì„ ì´‰ì§„í•¨ìœ¼ë¡œì¨ ë¡œë´‡ì€ ì¸ê°„ ê²½í—˜ì„ ì¬ì •ì˜í•˜ë©°, ê¸°ìˆ ì´ ìš°ë¦¬ì˜ ëŠ¥ë ¥ì„ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë³´ì™„í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ìš°ë¦¬ë¥¼ ë°ì€ ë¯¸ë˜ë¡œ ì´ë•ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nìœ¤ë¦¬ì  ê°€ì´ë“œì— ê¸°ë°˜ì„ ë‘” ë¡œë³´í‹±ìŠ¤ ë°œì „ê³¼ êµìœ¡ íˆ¬ìê°€ ì¤‘ìš”í•˜ë‹¤. ì´ë¥¼ í†µí•´ ì¸ê°„ë“¤ì´ ê¸°ê³„ ë™ë£Œë“¤ê³¼ í•¨ê»˜ í˜‘ë ¥ì ì¸ ë¯¸ë˜ë¥¼ ì¤€ë¹„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €í¬ê°€ í•¨ê»˜í•˜ëŠ” ì´ í¥ë¯¸ì§„ ì—¬ì •ì—ì„œ ë¡œë³´í‹±ìŠ¤ì˜ ê°€ëŠ¥ì„±ì„ í•˜ë‚˜ì”© ë°œê²¬í•´ë‚˜ê°€ë´…ì‹œë‹¤!\n\nì°¸ê³  ë¬¸í—Œ:\n\n1. â€œA Brief History of Robotics,â€ The Conversation, ì ‘ì†ì¼: [ë‚ ì§œ]\n\n2. â€œRobots at Work in the American Economyâ€ â€” Boston Federal Reserve Working Paper Series\n\n<div class=\"content-ad\"></div>\n\n3. \"ë¡œë´‡ì´ ì–´ë–»ê²Œ ì‚¶ì„ ë³€í™”ì‹œí‚¤ê³  ìˆëŠ”ì§€,\" BBC í“¨ì²˜, ì ‘ì†ì¼ [ë‚ ì§œ].","ogImage":{"url":"/assets/img/2024-06-19-TitleEmbracingInnovationUnveilingtheFuturewithRobotics_0.png"},"coverImage":"/assets/img/2024-06-19-TitleEmbracingInnovationUnveilingtheFuturewithRobotics_0.png","tag":["Tech"],"readingTime":3},{"title":"ì‹¤íŒ¨ë¡œë¶€í„° ë°°ìš´ ê²ƒ ë‚´ ê°€ì¥ í° AI í”„ë¡œì íŠ¸ ì‹¤ìˆ˜ì™€ êµí›ˆë“¤","description":"","date":"2024-06-19 18:40","slug":"2024-06-19-LearningfromFailuresMyBiggestAIProjectMistakesandTakeaways","content":"\n\n![Learning from Failures](/assets/img/2024-06-19-LearningfromFailuresMyBiggestAIProjectMistakesandTakeaways_0.png)\n\nì˜›ë‚  ì–´ëŠ ë‚ , ì €ëŠ” ì±—ë´‡ì„ ë§Œë“¤ê¸°ë¡œ ê²°ì‹¬í–ˆìŠµë‹ˆë‹¤. ê·¸ëƒ¥ ì±—ë´‡ì´ ì•„ë‹ˆë¼, í•œë§ˆë””ë¡œ ì•„ì¬í† ë¡ ê°€ì™€ ë…¸ìì²˜ëŸ¼ ë˜‘ë˜‘í•œ ì±—ë´‡ì„ ë§Œë“¤ê¸°ë¡œ í•œ ê±°ì˜ˆìš”. ì•¼ì‹¬ ì°¨ê²Œ ì •ë§ ëŒ€ë‹¨í•œ ê³„íšì´ì—ˆì–´ìš”, ê·¸ë ‡ì£ ? í•˜ì§€ë§Œ ì•¼ì‹¬ì€ ë•Œë¡œ ìš°ìŠ¤ê½ìŠ¤ëŸ° ì‹¤ìˆ˜ë“¤ì´ ë‚˜ì˜¤ê²Œ í•  ìˆ˜ ìˆì–´ìš”. ì œê°€ ë§Œë“  ìºë¦­í„°, ê·¸ë¥¼ \"ë˜‘ë˜‘ì´\"ë¼ê³  ì´ë¦„ ì§“ê¸°ë¡œ í–ˆì–´ìš”, ëŒ€í™”ì—ì„œ ë°°ìš°ê³  ì ì‘í•˜ëŠ” ì±—ë´‡ì´ì—ˆëŠ”ë°ìš”. ê·¸ëŸ¬ë‚˜ ì—´ì •ì— íœ©ì‹¸ì¸ ë‚˜ë¨¸ì§€, ì ì ˆí•œ í•™ìŠµ ê²½ê³„ ì„¤ì •ì˜ ì¤‘ìš”ì„±ì„ ê°„ê³¼í•œ ëª¨ì–‘ì´ì—ˆìŠµë‹ˆë‹¤.\n\nê²°ê³¼ëŠ”? ê¸°ìƒì²œì™¸í•œ ì§ˆë¬¸ì— ì‹¬ì˜¤í•œ ì¡°ì–¸ì„ í•˜ëŠ” ì±—ë´‡ì´ ë˜ì—ˆì–´ìš”. \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œ?\" ë¼ëŠ” ê°„ë‹¨í•œ ì§ˆë¬¸ì— ì¡´ì¬ì£¼ì˜ì ì¸ ë‹µë³€ì´ ëŒì•„ì˜¤ëŠ” ìƒí™©ì„ ìƒìƒí•´ë³´ì„¸ìš”. ë‚ ì”¨ ì˜ˆë³´ë¥¼ ìš”ì²­í–ˆëŠ”ë° \"ê·¼ë³¸ì ì¸ ì‚¶ ì†ì—ì„œ ë‚ ì”¨ë€ ë¬´ì—‡ì¼ê¹Œìš”?\" ë¼ëŠ” ë‹µì´ ë°›ì•„ì³ì§„ë‹¤ê³  ìƒê°í•´ë³´ì„¸ìš”. ì œê°€ ìµœê³ ì¸ ìˆœê°„ì€ ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤. ì´ê³³ì—ì„œ ì–»ì€ êµí›ˆì€ ë¶„ëª…í•´ìš”: ì•¼ë§ì€ ì‹¤ìš©ì„±ì„ ê°€ì ¸ì•¼ í•˜ë©°, AI í”„ë¡œì íŠ¸ì—ëŠ” ì² ì €í•œ ì§€ì¹¨ì´ í•„ìš”í•´ìš”. ì±”í”¼ì–¸ì´ì ìœ„ì¸ë‹¨ì— ì†í•œ ë‹¤ìŒ ì´ì•¼ê¸°ëŠ” ì§€ì—­ ê¸°ìˆ  ì›Œí¬ìƒµì„ ìœ„í•´ ë””ìì¸í•œ ë¡œë´‡ ë¡œë²„ ì´ì•¼ê¸°ì£ . ê³„íšì€ ê°„ë‹¨í–ˆìŠµë‹ˆë‹¤: ë¡œë´‡ ê³µí•™ì— ëŒ€í•´ ê°€ë¥´ì¹˜ê¸° ìœ„í•´ ì¥ì• ë¬¼ì„ í”¼í•´ ì´ë™í•  ìˆ˜ ìˆëŠ” ë¡œë²„ì™€ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê±°ì˜€ì–´ìš”. ì‰¬ìš´ ì¼ì´ì—ˆì£ , ë§ì£ ? ì•„ë‹ˆìš”. ì¸ìƒì„ ì£¼ë ¤ëŠ” ë‚˜ì˜ ë…¸ë ¥ìœ¼ë¡œ, ë””ìì¸ì„ ë„ˆë¬´ ë³µì¡í•˜ê²Œ ë§Œë“¤ì–´ì„œ ë¶€ë“œëŸ½ê³  ê¸°ë¯¼í•œ ë¡œë²„ ëŒ€ì‹ , ì‚¬ì‹¤ìƒ ë°”í€´ ë‹¬ë¦° ë¦¬ëª¨ì»¨ ì»¤í”¼ í…Œì´ë¸”ì„ ì–»ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nì°¨ê³ ì—ì„œ ì²˜ìŒìœ¼ë¡œ ì¶œí•­í•œ ë¡œë²„ëŠ” í”„ë¡œì íŠ¸ ë””ìŠ¤í”Œë ˆì´ë¥¼ ë„˜ì–´ëœ¨ë¦¬ê³ , ì°¨ ê³ ì–‘ì´ë¥¼ ê²ë‚˜ê²Œ ë§Œë“¤ì—ˆìœ¼ë©°, ë§ˆì¹¨ë‚´ ì˜ì ë‹¤ë¦¬ë¥¼ \"í†µí•´\" ì´ë™í•˜ë ¤ëŠ” ë£¨í”„ì— ê°‡í˜”ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì–´ë¦°ì´ë“¤ì˜ ì›ƒìŒì†Œë¦¬ëŠ” ì „ì—¼ì„± ìˆì—ˆê³ , ìƒí™©ì€ ë””ìì¸ì—ì„œì˜ ë‹¨ìˆœí•¨ì˜ ì¤‘ìš”ì„±ì— ëŒ€í•œ ê·€ì¤‘í•œ ê°€ë¥´ì¹¨ì˜ ìˆœê°„ìœ¼ë¡œ ë³€í–ˆìŠµë‹ˆë‹¤. ë•Œë¡œëŠ”, ë¡œë²„ê°€ ì‘ì€ ìë™ì°¨ì²˜ëŸ¼ ì‘ì€ íšŒì „ ë°˜ê²½ì„ ê°€ì§€ê³  ìˆì„ ë•Œ, ë” ì ì€ ê²ƒì´ ì •ë§ ë” ë§ì€ ê²ƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nì œ ë§ˆì§€ë§‰ ì—”ì§€ë‹ˆì–´ë§ ë„ì „ìœ¼ë¡œ, íŠ¹ë³„íˆ ì•ˆë‚´ë“œë¦´ ê²ƒì´ ìˆëŠ”ë°ìš”. ì €ëŠ” ê°œì¸ ë§ì¶¤ì‹ ì¹­ì°¬ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¸ê³µì§€ëŠ¥ì„ ë§Œë“¤ì–´ë³´ë ¤ê³  ì‹œë„í–ˆë˜ ì ì— ëŒ€í•´ ì–˜ê¸°í•´ë³¼ê²Œìš”. ê¸°ìˆ ì„ í†µí•´ ê¸ì •ì„ ì „íŒŒí•˜ëŠ” ê²ƒì´ì—ˆì£ . ì˜ë„ ìì²´ëŠ” ì°¬ì–‘í• ë§Œí•œ ì¼ì´ì—ˆì£ . ê·¸ëŸ¬ë‚˜ ì œ ì—´ì •ì ì¸ ë§ˆìŒì—, ì• ì • ìŠ¤ìœ„ì¹˜ë¥¼ ì¡°ê¸ˆ ë„ˆë¬´ ë†’ê²Œ ì„¤ì •í–ˆë˜ ê²ƒ ê°™ìŠµë‹ˆë‹¤. ë¶€ë“œëŸ¬ìš´ ê²©ë ¤ë¥¼ ê¸°ëŒ€í–ˆë˜ ì‚¬ìš©ìë“¤ì€ í• ë¨¸ë‹ˆ í• ì•„ë²„ì§€ë„ ë¶€ë„ëŸ¬ì›Œí•  ë§Œí•œ ì¹­ì°¬ í­í’ì„ ë°›ì•˜ë‹¤ë‹ˆê¹Œìš”.\n\ní¥ë¯¸ë¡œìš´ ê²ƒë¶€í„° ì•½ê°„ ë‹¹í™©ìŠ¤ëŸ¬ìš´ í”¼ë“œë°±ê¹Œì§€ ë‹¤ì–‘í–ˆì§€ë§Œ, ì´ê²ƒì€ ì¸ê³µì§€ëŠ¥ ê°œë°œì—ì„œ ì¤‘ìš”í•œ ì¸¡ë©´ì„ ê°•ì¡°í–ˆìŠµë‹ˆë‹¤: ë³´ì •ì´ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒ. ë˜í•œ, ì•½ê°„ì˜ ê²©ë ¤ë§Œ ì „ë‹¬í•˜ë ¤ëŠ” ì˜ë„ë¡œ ì‹œì‘í–ˆì§€ë§Œ ë‚®ì„¼ ë‚®ì€ ê¸°ë¶„ì„ ë©”ëŠ” ì¹­ì°¬ í­í’ì„ ìœ ë°œí–ˆë‹¤ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤.\n\nì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë§ì—ì„œ, íŠ¹íˆ ì¸ê³µì§€ëŠ¥ê³¼ ë¡œë´‡ê³µí•™ì— ëŒ€í•´ì„œëŠ”, ì„±ê³µìœ¼ë¡œ í†µí•˜ëŠ” ê¸¸ì€ ì–¸ì œë‚˜ ì‹¤íŒ¨í•œ ì‹¤í—˜ë“¤ë¡œ ê°€ë“í•©ë‹ˆë‹¤ â€” ì œ ê°œì¸ì ì¸ ì±—ë´‡ë“¤ì´ë‚˜ ì •ì²´ë¥¼ ì•“ëŠ” ë¡œë²„ì™€ ê°™ì´ ë§ì´ì—ìš”. í•˜ì§€ë§Œ, ì´ëŸ¬í•œ ì‹¤íŒ¨ë“¤ ì†ì—ì„œ ìš°ë¦¬ëŠ” ë” ë‚˜ì€ ëª¨ìŠµìœ¼ë¡œ í˜•ì„±ë˜ë©°, ì´ëŸ¬í•œ ê²½í—˜ë“¤ì„ í†µí•´ ë” ëŠ¥ìˆ™í•˜ê³  ì°½ì˜ì ì¸ ì°½ì¡°ìê°€ ë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\ní™•ì‹¤íˆ, ìœ ë¨¸, ê²¸ì†í•¨, ê·¸ë¦¬ê³  ì‹¤ìˆ˜ë¥¼ ë°›ì•„ë“¤ì¼ ìš©ì˜ê°€ ë‚˜ë¥¼ ì§„ì •í•œ ì§€ì¹¨ìœ¼ë¡œ ì´ëŒì–´ ì™”ì–´ìš”.","ogImage":{"url":"/assets/img/2024-06-19-LearningfromFailuresMyBiggestAIProjectMistakesandTakeaways_0.png"},"coverImage":"/assets/img/2024-06-19-LearningfromFailuresMyBiggestAIProjectMistakesandTakeaways_0.png","tag":["Tech"],"readingTime":2},{"title":"ë¡œë´‡ë“¤ë„ ìš°ë¦¬ì²˜ëŸ¼ ë§í•  ìˆ˜ ìˆì§€ë§Œ, ê·¸ë ‡ë‹¤ê³  í•´ì„œ ê·¸ë“¤ì´ ì¸ê°„ì´ ë˜ëŠ” ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤","description":"","date":"2024-06-19 18:39","slug":"2024-06-19-Robotscantalklikeusbutitdoesntmakethemhuman","content":"\n\n<img src=\"/assets/img/2024-06-19-Robotscantalklikeusbutitdoesntmakethemhuman_0.png\" />\n\në³´ìŠ¤í„´ ë‹¤ì´ë‚´ë¯¹ìŠ¤ëŠ” ChatGPTì˜ ìƒˆë¡œìš´ ìŒì„± ìƒì„± ê¸°ëŠ¥ì„ Spot ë¡œë´‡ì— ì¶”ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ë¡œ íšŒì‚¬ ë°©ë¬¸ ì‹œ ì‚¬ëŒë“¤ì„ ì¸ì‚¬í•  ìˆ˜ ìˆëŠ” ì˜¤í† ë§ˆíƒ€ê°€ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤. ë‹¤ì–‘í•œ ê°•ì„¸ë¥¼ ë§Œë“¤ì–´ë‚´ë©° ë¡œë´‡ ê¸°ìˆ  ì„¸ê³„ì— ì´ì „ì— ì—†ë˜ ê³µê° íš¨ê³¼ë¥¼ ë§Œë“¤ì–´ ëƒ…ë‹ˆë‹¤. ì‚¬ì‹¤ ì¸ê¸° ìˆëŠ” \"í•™ëŒ€ë‹¹í•œ ë¡œë´‡ ë¹„ë””ì˜¤\"ë¥¼ ì œì™¸í•˜ë©´ ë¡œë´‡ë“¤ì´ ìš°ë¦¬ í¸ì„ ë“¤ì–´ì£¼ëŠ” ê²ƒì„ ë³´ê³  ì‚¬ì•…í•œ ì‚¬ëŒì´ë¼ëŠ” íŒë‹¨ì„ ë‚´ë¦° ê²ƒì…ë‹ˆë‹¤.\n\nì™„ë²½í•œ ì˜êµ­ ê³µì†í•œ ì•¡ì„¼íŠ¸ë¡œ ë§í•˜ëŠ” Spotì„ ë³´ëŠ” ê²ƒì€ ì¬ë¯¸ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ChatGPTì˜ ìŒì„± í•©ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ ìŠ¤ë§ˆíŠ¸í°ì—ì„œ ìƒì„±ì  ì¡°ìˆ˜ì™€ ê¸´ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ëª¨ìŠµì„ ë³´ë©´ ì¡°ê¸ˆ ë¶ˆì•ˆí•´ì§‘ë‹ˆë‹¤. êµí†µ ì²´ì¦ ì†ì—ì„œ ì‹œê°„ì„ ë•Œìš°ê±°ë‚˜ ì—ì–´íŒŸì„ ì°©ìš©í•˜ê³  ê¸¸ì„ ê±°ë‹ë©´ì„œ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ê²ƒì€ ì˜í™” \"Her\"ì—ì„œ ë³´ë˜ ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ì´ê²ƒì€ ë””ìŠ¤í† í”¼ì•„ì ì´ë©° ì—¬ëŸ¬ ìœ¤ë¦¬ì  ë¬¸ì œë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚µë‹ˆë‹¤.\n\në¬¼ë¡  ìš°ë¦¬ëŠ” í•­ìƒ ê¸°ìˆ ì„ ì˜ì¸í™”í•´ ì™”ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ê¸°ìˆ ì˜ ë°œì „ì´ ìŒì„±ì„ ë§Œë“¤ì–´ë‚´ê³ , ë˜í•œ ê°œì¸ì ì¸ ê´€ê³„ì™€ ë¹„ìŠ·í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆŒ ìˆ˜ ìˆê²Œ í•œë‹¤ë©´, ì´ê²ƒì´ ë¬´ë¡€í•œ ê¸°ì—…ë“¤ì— ì˜í•´ ì¼ë°˜í™”ì˜ í•œ í˜•íƒœë¡œ ì„ ë³´ì¸ë‹¤ë©´ ìš°ë¦¬ëŠ” ì¬í•´ì™€ ì·¨ì•½í•œ ì‚¬ëŒë“¤ì—ê²Œ ì‹¬ë¦¬ì  ë¬¸ì œë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤ëŠ” ê°€ëŠ¥ì„±ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nì•„ì´ëŒë“¤ì— ëŒ€í•œ ì²­ì†Œë…„ë“¤ì˜ ì¤‘ìš”ì„±ì„ ì•Œê³  ìˆëŠ” ì‚¬ëŒì´ë‚˜ ê°œì¸ ë¬¸ì œë¥¼ ê°€ì§„ ì–´ë¥¸ì´ ì•Œê³ ë¦¬ì¦˜ì„ ì¹˜ë£Œë¡œ ì‚¬ìš©í•´ë³¼ ë•Œ ì–´ë–¤ ì˜í–¥ì´ ìˆì„ì§€ ê³ ë ¤í•˜ëŠ” ì‚¬ëŒì€ ë°”ë¡œ í™”ì œì˜ ì¤‘ì‹¬ì— ìˆìŒì„ ì´í•´í•  ê²ƒì…ë‹ˆë‹¤. ì œì•½ì´ ê±°ì˜ ì—†ê³  ê°€ë” í™˜ê°ì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ìƒí™©ì—ì„œ ë‚œì²˜í•œ ìƒí™©ì— ë†“ì´ê²Œ ë˜ì–´ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš”ì•½í•˜ë©´, ì´ëŸ¬í•œ ê°€ìƒ ê´€ê³„ëŠ” ë‹¨ìˆœíˆ ê³ ì¥ ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§ˆ ë¿ë§Œ ì•„ë‹ˆë¼ ìœ ì§€í•˜ëŠ” ì‚¬ëŒë“¤ì˜ í–‰ë™ì— ì˜í–¥ì„ ë¯¸ì¹˜ë„ë¡ ì¡°ì ˆë  ê°€ëŠ¥ì„±ì´ ìˆë‹¤ëŠ” ê²ƒì„ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ ì‚¬ëŒë“¤ê³¼ì˜ ê²½í—˜ë“¤ì€ ìš°ë¦¬ì—ê²Œ ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì˜í–¥ì„ ë¼ì¹  ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ìµœì†Œí•œ ì´ëŸ¬í•œ ê²½í—˜ë“¤ê³¼ ëŒ€í™”ë“¤ì€ ì–´ëŠ ì •ë„ì˜ í•©ë¦¬ì„±ì„ ê°€ì§„ ì‚¬ëŒë“¤ ê°„ì˜ ê²½í—˜ì  ëŒ€í™”ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½í—˜ì—ì„œ generative assistantsë¥¼ í†µí•´ ì‚¬ëŒë“¤ì„ ì¡°ê±´ë¶€ë¡œ ë§Œë“¤ì–´ ê°€ëŠ” ê³¼ì •ì€ ëª…ë°±í•œ ì˜ˆë°© ì¡°ì¹˜ ì—†ì´ ì´ë£¨ì–´ì§„ë‹¤ëŠ” ê²ƒì€ ë°›ì•„ë“¤ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§Œì•½ ì´ëŸ¬í•œ ì œí’ˆë“¤ì´ ë„ë¦¬ ì´ìš© ê°€ëŠ¥í•˜ê³  í‘œì¤€í™” ìš”ì†Œê¹Œì§€ ì¶”ê°€ëœë‹¤ë©´, ê³§ ìœ ëª…ì¸ ì•„ë°”íƒ€ë“¤ì´ ìˆ˜ë°±ë§Œ ëª…ì˜ ì‚¬ëŒë“¤ê³¼ ë§¤ì¼ ëŒ€í™”í•˜ë©´ì„œ ì•ì„œ ì§„í–‰ëœ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ê°œì¸ì  ìš”ì†Œë“¤ì„ ëŒ€í™”ì— ë„ì…í•˜ê±°ë‚˜ ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ê°œì¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ ê´‘ê³ ì£¼ë“¤ì— íŒë§¤í•˜ëŠ”, ë˜ëŠ” ì‚¬ëŒë“¤ì˜ ê¸°ë¶„ì„ ìœ ë„í•˜ì—¬ ë¬¼ê±´ì„ êµ¬ë§¤í•˜ê±°ë‚˜ íŠ¹ì •í•œ ë°©í–¥ìœ¼ë¡œ íˆ¬í‘œí•˜ë„ë¡ ì‚¬ëŒë“¤ì—ê²Œ ì˜í–¥ì„ ë¼ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nìš°ë¦¬ ì‚¬íšŒëŠ” ëŒ€ëŸ‰ì˜ ì‚¬ëŒë“¤ì´ ìì‹ ì´ ëŒ€í™”í•˜ëŠ” ëŒ€ìƒì´ ëˆ„êµ¬ì¸ì§€ê°€ ì•„ë‹Œ ì •ë§ ë¬´ì—‡ì¸ì§€ë¥¼ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” êµìœ¡ ë‹¨ê³„ë¥¼ ê±°ì¹˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ê°œì¸ì  ê´€ê³„ì˜ ë§¥ë½ì—ì„œ generative AIì™€ ê°™ì€ ê¸°ìˆ ì„ ìˆ˜ìš©í•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë§ì€ ì‚¬ëŒë“¤ì€ ì•Œê³ ë¦¬ì¦˜ì— ì¼ì •í•œ ê¶Œí•œì„ ë¶€ì—¬í•˜ì—¬ ê¸°ìˆ ì„ í†µí•´ ì ‘ê·¼í•œ ë‹µë³€ì— ëŒ€í•œ ì‚¬ê³ ì£¼ì˜ë¥¼ ì™¸ì£¼í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìì‹ ì˜ ë¹„íŒì  ì‚¬ê³ ë¥¼ ì™¸ì£¼í•˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤. íŠ¹ì • ê¸°ìˆ ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ë¥¼ ëª¨ë¥´ëŠ” ìƒíƒœ, ì•„ì„œ C. í´ë½ì´ ì˜³ê²Œ ê´€ì°°í•œ ê²ƒì²˜ëŸ¼, ê·¸ê²ƒì€ ë§ˆìˆ ê³¼ êµ¬ë¶„í•˜ê¸° ì–´ë µê²Œ ë§Œë“­ë‹ˆë‹¤. ì´ê²ƒì€ ì¸ê°„ ì‚¬íšŒì— ì—„ì²­ë‚œ í•´ë¥¼ ë¼ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´, ì™œê³¡ëœ í˜„ì‹¤ ì¸ì‹ë¶€í„° ì†Œì™ˆë ˆë¡œ ë‚˜íƒ€ë‚˜ëŠ” ì´í•´ ë¯¸í¡ê¹Œì§€ ë‹¤ì–‘í•œ ì‹¬ë¦¬ì  ë¬¸ì œë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n\në¯¸ë””ì–´ì—ì„œ ìì£¼ ë³¸ ì–´ë–¤ ì‚¬ëŒì„ ë§Œë‚˜ëŠ” ê²ƒì€ ì–¸ì œë‚˜ ì´ìƒí•œ ëŠë‚Œì„ ì¤¬ìŠµë‹ˆë‹¤. â€œë‚´ ê±°ì‹¤ì— ì´ ì‚¬ëŒì´ ìˆëŠ” ê²ƒ ê°™ë‹¤â€ë¼ëŠ” ëŠë‚Œì€ ì¢…ì¢… ì²˜ìŒ ë§Œë‚˜ëŠ” ì‚¬ëŒì— ëŒ€í•œ ë‚´ ê°€ì •ê³¼ëŠ” ë‹¤ë¥´ê²Œ ìµìˆ™í•˜ë‹¤ê³  ì˜¤í•´í•˜ê²Œ í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë§¤ì¼ ë‰´ìŠ¤ë¥¼ ë³´ëŠ” ì‚¬ëŒê³¼ì˜ ëŒ€í™”ì™€ ê°™ì´ ì™„ì „íˆ ë¹„ëŒ€ì¹­ì ì¸ ê´€ê³„ë¥¼ ì™„ì „íˆ ë°›ì•„ë“¤ì´ëŠ” ê²ƒì€ ì´í•´ë ¥, êµìœ¡, íŒë‹¨ë ¥ì´ í•„ìš”í•œ ì‘ì—…ì…ë‹ˆë‹¤. ë§Œì•½ ë§¤ì¼ ìì‹ ì˜ ì•„ì´ëŒë¡œ ìœ„ì¥í•˜ëŠ” generative algorithmê³¼ ì´ì•¼ê¸°í•˜ê³  ìˆëŠ” ì‚¬ëŒì´ ì§„ì§œ ê·¸ ì‚¬ëŒì„ ë§Œë‚˜ê±°ë‚˜ ê·¸ ëŒ€í™”ë¥¼ ì‹¤ì œë¡œ ë°›ì•„ë“¤ì´ê²Œ ë˜ì—ˆì„ ë•Œ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚ ê¹Œìš”? ê·¸ë¦¬ê³  ë„¤íŠ¸ì›Œí¬ ì •ë³´ë¥¼ ì¬ì¡°í•©í•˜ëŠ” generative algorithmì¸ë°ë„ ë¶ˆêµ¬í•˜ê³  ì–´ë–¤ ì„±ê²©ì„ ë¶€ì—¬í•˜ëŠ” ì‚¬ëŒì´ ë“±ì¥í–ˆì„ ë•ŒëŠ” ì–´ë–»ê²Œ ë ê¹Œìš”? ê·¸ë¦¬ê³  ì´ ëª¨ë“  ê²ƒì´ ë¶ˆí™•ì‹¤í•œ ê·œì •ì  ë§¥ë½ì—ì„œ ìš´ì˜ë˜ëŠ” ìƒí™©ì—ì„œ, ì´ëŸ¬í•œ ë„êµ¬ê°€ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ë‚˜, ì–´ë–»ê²Œ ì¡°ì •ë˜ì–´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ê²½í—˜ì´ ì—†ì„ ë¿ë§Œ ì•„ë‹ˆë¼ ì‹¬ë¦¬ì  ì¥ì• ì— ëŒ€í•œ ê²½í—˜ì´ ì „í˜€ ì—†ëŠ” ìƒí™©ì—ì„œ ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€ìš”?\n\n<div class=\"content-ad\"></div>\n\në¬¸ì œëŠ” ê¸°ìˆ ì´ ë°œì „í•˜ëŠ” ì†ë„ê°€ ì•„ë‹ˆë¼, ì¼ë¶€ ë¬´ì±…ì„í•œ ì‚¬ëŒë“¤ì´ ì ì •í•œ ì¡°ì¹˜ë¥¼ ì·¨í•˜ì§€ ì•Šê³  ì‹œì¥ì— ë‚´ë†“ëŠ” ì œí’ˆë“¤ì…ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì œí’ˆê³¼ ì„œë¹„ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ê²ƒìœ¼ë¡œ ìˆ˜ìµì„ ì°½ì¶œí•˜ë ¤ëŠ” ì–¼ê°„ì´ë“¤ì˜ í™œë™ì„ ì œí•œí•˜ê¸° ìœ„í•œ ì¼íƒˆì ì¸ ì ‘ê·¼ì´ ì•„ë‹Œ, ì´ ê¸°ìˆ ì— ëŒ€í•œ ëª…í™•í•˜ê³  ì •í™•í•œ ê·œì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ë¯¸ ë§ì€ ë¬¸ì œë¥¼ ë°œìƒì‹œí‚¨ \"ë¹¨ë¦¬ ì›€ì§ì´ê³  ë¬´ì–¸ê°€ë¥¼ ë§ê°€ëœ¨ë¦¬ëŠ”\" ì ‘ê·¼ì´ ì´ì œëŠ” ë” ë¬´ì„œìš´ ê³³ìœ¼ë¡œ ë‚˜ì•„ê°€ê³  ìˆìŠµë‹ˆë‹¤.\n\nì €ëŠ” ê¸°ìˆ ì— ê²ì„ ë¨¹ê±°ë‚˜ ì‚¬íšŒì  ë¬¸ì œë¥¼ ê¸°ìˆ  íƒ“ìœ¼ë¡œ ëŒë¦¬ëŠ” ê²½í–¥ì´ ì—†ìŠµë‹ˆë‹¤. ì •ê¸° ë…ìë“¤ì€ ì €ê°€ ì¼ë°˜ì ìœ¼ë¡œ ê¸°ìˆ ì  ë‚™ê´€ì£¼ì˜ìë¼ëŠ” ê²ƒì„ ì•Œê³  ê³„ì‹¤ ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì´ ì£¼ì œê°€ ì €ë¥¼ ì§„ì •ìœ¼ë¡œ ê±±ì •í•˜ê²Œ ë§Œë“¤ê³  ë§ì€ í›„íšŒë¡œ ì´ì–´ì§ˆ ê²ƒì´ë¼ê³  ìƒê°í•©ë‹ˆë‹¤.","ogImage":{"url":"/assets/img/2024-06-19-Robotscantalklikeusbutitdoesntmakethemhuman_0.png"},"coverImage":"/assets/img/2024-06-19-Robotscantalklikeusbutitdoesntmakethemhuman_0.png","tag":["Tech"],"readingTime":3},{"title":"AIì™€ ë¡œë´‡ì˜ ë¯¸ë˜ ëª¨ë¼ë²¡ì˜ ì—­ì„¤ ë„ˆë¨¸","description":"","date":"2024-06-19 18:37","slug":"2024-06-19-TheFutureofAIandRoboticsBeyondMoravecsParadox","content":"\n\n## AI | ë¡œë´‡ ê³µí•™ | ëª¨ë¼ë²¡ì˜ ì—­ì„¤ | íŒŒíŠ¸ 8 | FLYINGMUM\n\nìš°ë¦¬ëŠ” ëª¨ë¼ë²¡ì˜ ì—­ì„¤ì— ëŒ€í•œ ì´ ì‹œë¦¬ì¦ˆë¥¼ ë§ˆë¬´ë¦¬í•˜ë©´ì„œ, AI ë° ë¡œë´‡ ê³µí•™ì˜ ë¯¸ë˜ì— ì£¼ëª©í•©ë‹ˆë‹¤. ì´ ì—­ì„¤ì´ ê°•ì¡°í•œ ë„ì „ë“¤ì„ ë„˜ì–´ ë¯¸ë˜ì—ëŠ” ë¬´ì—‡ì´ ê¸°ëŒ€ë ê¹Œìš”? ì´ ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œëŠ” ìƒˆë¡œìš´ íŠ¸ë Œë“œ, ì ì¬ì ì¸ í­ë°œì  ë°œì „, ê·¸ë¦¬ê³  AI ë° ë¡œë´‡ ê³µí•™ì´ ìš°ë¦¬ ì‚¶ì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì— ë¯¸ì¹˜ëŠ” í˜ì‹ ì ì¸ ì˜í–¥ì— ëŒ€í•´ íƒêµ¬í•©ë‹ˆë‹¤.\n\nì´ì „ ë¸”ë¡œê·¸: https://medium.com/@flyingmum/ethical-and-societal-implications-aa9287d86395\n\n# AIì™€ ë¡œë´‡ ê³µí•™ì˜ ìƒˆë¡œìš´ íŠ¸ë Œë“œ\n\n<div class=\"content-ad\"></div>\n\nAIì™€ ë¡œë´‡ì˜ ë¯¸ë˜ëŠ” ì´ëŸ¬í•œ ê¸°ìˆ ì´ ì–´ë””ê¹Œì§€ ì´ë£° ìˆ˜ ìˆëŠ”ì§€ì˜ í•œê³„ë¥¼ ë”ìš± ëŒì–´ì˜¬ë¦´ ê²ƒìœ¼ë¡œ ì•½ì†ë˜ëŠ” ëª‡ ê°€ì§€ ì£¼ìš” íŠ¸ë Œë“œì— ì˜í•´ í˜•ì„±ë©ë‹ˆë‹¤.\n\n1. ìì—°ì–´ ì²˜ë¦¬(NLP)ì˜ ë°œì „: NLPì˜ ê³„ì†ëœ í–¥ìƒì€ AI ì‹œìŠ¤í…œì´ ì‚¬ëŒì˜ ì–¸ì–´ë¥¼ ë”ìš± ì„¸ë¶€ì ì´ê³  ë§¥ë½ì ìœ¼ë¡œ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆê²Œ í•  ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ì¸ê°„-AI ìƒí˜¸ì‘ìš©ì„ ê°•í™”ì‹œí‚¤ê³  ê³ ê° ì„œë¹„ìŠ¤, êµìœ¡ ë° ì½˜í…ì¸  ì œì‘ê³¼ ê°™ì€ ë¶„ì•¼ì—ì„œ ë”ìš± ì •êµí•œ ì‘ìš© í”„ë¡œê·¸ë¨ì„ ê°€ëŠ¥í•˜ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.\n\n2. AI ì£¼ë„ì˜ ìë™í™”: AIì™€ ë¡œë´‡ì„ í†µí•©ì‹œí‚¨ ìë™í™” ì†”ë£¨ì…˜ì´ ë”ìš± ë°œì „í•  ê²ƒì…ë‹ˆë‹¤. ì œì¡°ì—…ë¶€í„° ì˜ë£Œì— ì´ë¥´ê¸°ê¹Œì§€, AI ì£¼ë„ì˜ ë¡œë´‡ì€ ì •ë°€í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ê²ƒì´ë©°, ì´ëŠ” ì‚°ì—…ì„ í˜ì‹ í•˜ê³  ìƒˆë¡œìš´ ê¸°íšŒë¥¼ ì°½ì¶œí•  ê²ƒì…ë‹ˆë‹¤.\n\n3. Edge AI: ì»´í“¨íŒ… íŒŒì›Œê°€ ë°ì´í„°ê°€ ìƒì„±ë˜ëŠ” ê³³ì— ê°€ê¹Œì›Œì§€ë©´ì„œ ì—£ì§€ AIê°€ ë”ìš± ë³´í¸í™”ë  ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ììœ¨ì£¼í–‰ì°¨, ìŠ¤ë§ˆíŠ¸ ì‹œí‹°, IoT ë””ë°”ì´ìŠ¤ ë“±ì˜ ì‘ìš©ë¶„ì•¼ì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ì™€ ì˜ì‚¬ê²°ì •ì„ ê°€ëŠ¥í•˜ê²Œ í•  ê²ƒì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n4. AI ìœ¤ë¦¬ ë° ì§€ë°°êµ¬ì¡°: ê²¬ê³ í•œ ìœ¤ë¦¬ì  í‹€ê³¼ ì§€ë°°êµ¬ì¡°ì˜ ê°œë°œì€ AI ê¸°ìˆ ì´ ì±…ì„ì„ ì§€ê³  ê°œë°œ ë° ë°°í¬ë˜ëŠ” ê²ƒì„ ë³´ì¥í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŠ” í¸í–¥, íˆ¬ëª…ì„± ë° ì±…ì„ ë¬¸ì œë¥¼ ë‹¤ë£¨ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤.\n\n![](/assets/img/2024-06-19-TheFutureofAIandRoboticsBeyondMoravecsParadox_0.png)\n\n## ì ì¬ì ì¸ ëŒíŒŒêµ¬\n\nëª‡ ê°€ì§€ ì ì¬ì ì¸ ëŒíŒŒêµ¬ëŠ” AIì™€ ë¡œë´‡ ê¸°ìˆ ì˜ ëŠ¥ë ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìœ¼ë©°, Moravecì˜ ì—­ì„¤ì—ì„œ ê°•ì¡°ëœ ì œí•œì„ ê·¹ë³µí•˜ëŠ” ë° í•œê±¸ìŒ ë” ë‚˜ì•„ê°€ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n1. ì¼ë°˜ ì¸ê³µì§€ëŠ¥: í˜„ì¬ AI ì‹œìŠ¤í…œì€ íŠ¹ì • ì‘ì—…ì— ë›°ì–´ë‚˜ì§€ë§Œ, ì¸ê°„ê³¼ ìœ ì‚¬í•œ ì´í•´ë ¥ê³¼ ì ì‘ë ¥ìœ¼ë¡œ ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ì¼ë°˜ AIì˜ ê°œë°œì€ ì¥ê¸°ì ì¸ ëª©í‘œë¡œ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. ì¼ë°˜ AIë¥¼ ë‹¬ì„±í•˜ëŠ” ê²ƒì€ ì´ ë¶„ì•¼ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì§„ì „ì„ ì˜ë¯¸í•  ê²ƒì…ë‹ˆë‹¤.\n\n2. ì–‘ì ì»´í“¨íŒ…: ì–‘ì ì»´í“¨íŒ…ì€ ì§€ìˆ˜ì ìœ¼ë¡œ ì»´í“¨íŒ… íŒŒì›Œë¥¼ ì¦ê°€ì‹œí‚´ìœ¼ë¡œì¨, AI ì‹œìŠ¤í…œì´ í˜„ì¬ í•´ê²°í•˜ê¸° ì–´ë ¤ìš´ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤. ì´ëŠ” ì•½ë¬¼ ë°œê²¬, ì•”í˜¸í•™, ê¸°í›„ ëª¨ë¸ë§ ë“± ë¶„ì•¼ì—ì„œì˜ ì¤‘ìš”í•œ ë°œì „ì„ ì´ëŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n3. ë‡Œ-ì»´í“¨í„° ì¸í„°í˜ì´ìŠ¤ (BCIs): ì¸ê°„ ë‡Œì™€ ê¸°ê³„ ì‚¬ì´ì˜ ì§ì ‘ì ì¸ í†µì‹ ì„ ê°€ëŠ¥ì¼€ í•˜ëŠ” BCIëŠ” ê¸°ìˆ ê³¼ì˜ ìƒí˜¸ì‘ìš© ë°©ì‹ì„ í˜ì‹ ì ìœ¼ë¡œ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ê²ƒì€ ì˜í•™, ì¬í™œ, ì¸ê°„ ì¦ê°•ê³¼ ê°™ì€ ë¶„ì•¼ì— ê¹Šì€ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n4. ë¬´ë¦¬ ë¡œë´‡ê³µí•™: ì‚¬íšŒì  ê³¤ì¶©ì˜ ì§‘ë‹¨ í–‰ë™ì— ì˜ê°ì„ ë°›ì€ ë¬´ë¦¬ ë¡œë´‡ê³µí•™ì€ ë§ì€ ìˆ˜ì˜ ë‹¨ìˆœ ë¡œë´‡ì˜ ì¡°ì •ì„ í†µí•´ ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ ì ‘ê·¼ë²•ì€ í™˜ê²½ ëª¨ë‹ˆí„°ë§, ì¬ë‚œ ëŒ€ì‘, ë†ì—… ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ í•´ê²°ì±…ì„ ì´ëŒì–´ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-TheFutureofAIandRoboticsBeyondMoravecsParadox_1.png\" />\n\n# ì‚¬íšŒì— ë¯¸ì¹˜ëŠ” ë³€í™”\n\nAIì™€ ë¡œë´‡ ê¸°ìˆ ì˜ ì§€ì†ì ì¸ ë°œì „ì€ ì‚¬íšŒì˜ ë‹¤ì–‘í•œ ì¸¡ë©´ì— í˜ëª…ì ì¸ ë³€í™”ë¥¼ ê°€ì ¸ë‹¤ì£¼ë©° í˜ì‹ ì„ ì´‰ì§„í•˜ê³  ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¬ ê²ƒì…ë‹ˆë‹¤.\n\n1. ì˜ë£Œ: AIë¥¼ í™œìš©í•œ ì§„ë‹¨, ë§ì¶¤ ì˜í•™, ë¡œë´‡ ìˆ˜ìˆ ì€ ì˜ë£Œ í˜ì‹ ì„ ì´ëŒì–´ ë” ë‚˜ì€ í™˜ì ê²°ê³¼ì™€ íš¨ìœ¨ì ì¸ ì˜ë£Œ ì„œë¹„ìŠ¤ ì œê³µìœ¼ë¡œ ì´ì–´ì§ˆ ê²ƒì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n2. êµìœ¡: AI ê¸°ìˆ ì„ í™œìš©í•œ êµìœ¡ ë„êµ¬ì™€ ë§ì¶¤ í•™ìŠµ í”Œë«í¼ì€ í•™ìŠµ ê²½í—˜ì„ í–¥ìƒì‹œí‚¤ë©° êµìœ¡ì„ ë” ì ‘ê·¼ ê°€ëŠ¥í•˜ê³  ê°œì¸ì˜ í•„ìš”ì— ë§ê²Œ ë§ì¶¤í™”í•  ê²ƒì…ë‹ˆë‹¤.\n\n3. í™˜ê²½ ì§€ì† ê°€ëŠ¥ì„±: AIì™€ ë¡œë´‡ ê¸°ìˆ ì€ ì—ë„ˆì§€ ì‚¬ìš©ì˜ ìµœì í™”, íê¸°ë¬¼ ê°ì†Œ, ìƒíƒœê³„ ëª¨ë‹ˆí„°ë§, ê¸°í›„ ë³€í™” ëŒ€ì‘ ë“± í™˜ê²½ ë¬¸ì œ í•´ê²°ì— ì¤‘ìš”í•œ ì—­í• ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n4. ìŠ¤ë§ˆíŠ¸ ì‹œí‹°: AIì™€ ì‚¬ë¬¼ì¸í„°ë„·ì˜ í†µí•©ì€ ë°ì´í„° ê¸°ë°˜ ì†”ë£¨ì…˜ì´ ë„ì‹œ ì¸í”„ë¼, êµí†µ, ê³µê³µ ì„œë¹„ìŠ¤ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ìŠ¤ë§ˆíŠ¸ ì‹œí‹° ê°œë°œì„ ì´ëŒ ê²ƒì…ë‹ˆë‹¤.\n\nì•ìœ¼ë¡œì˜ ë¯¸ë˜ë¥¼ ë°”ë¼ë³¼ ë•Œ, AIì™€ ë¡œë´‡ ê¸°ìˆ ì´ ìš°ë¦¬ì˜ ì„¸ìƒì„ ë³€í™”ì‹œí‚¬ ì ì¬ë ¥ì€ ì—„ì²­ë‚©ë‹ˆë‹¤. Moravecì˜ ì—­ì„¤ì—ì„œ ê°•ì¡°ëœ ê³¼ì œì— ëŒ€ì²˜í•˜ê³  ì‹ í¥ íŠ¸ë Œë“œì™€ ëŒíŒŒêµ¬ë¥¼ ìˆ˜ìš©í•¨ìœ¼ë¡œì¨, ìš°ë¦¬ëŠ” ìƒˆë¡œìš´ ê°€ëŠ¥ì„±ì„ ì°½ì¶œí•˜ê³  ì¸ê°„ì˜ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê³  ì‚¶ì˜ ì§ˆì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-TheFutureofAIandRoboticsBeyondMoravecsParadox_2.png)\n\nëª¨ë¼ë²¡ íŒ¨ëŸ¬ë…ìŠ¤ë¥¼ ë„˜ì–´ì„œëŠ” ì—¬ì •ì€ ì§€ê¸ˆ ë§‰ ì‹œì‘ì— ë¶ˆê³¼í•˜ë©°, í¥ë¯¸ì§„ì§„í•˜ê³  ë³€í™”ë¥¼ ê°€ì ¸ë‹¤ì¤„ ê²ƒìœ¼ë¡œ ì•½ì†ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ì¸ê³µì§€ëŠ¥ê³¼ ë¡œë´‡ê³µí•™ì˜ ì „ì„ ì„ ê°œì²™í•˜ê³  í˜ì‹ ì„ ì´ì–´ ë‚˜ê°ˆìˆ˜ë¡, ë¯¸ë˜ëŠ” ë” ìŠ¤ë§ˆíŠ¸í•˜ê³  ì—°ê²°ëœ, ì§€ì† ê°€ëŠ¥í•œ ì„¸ê³„ë¥¼ ìœ„í•œ ëì—†ëŠ” ê°€ëŠ¥ì„±ì„ í’ˆê³  ìˆìŠµë‹ˆë‹¤.\n\n#flyingmum #PamC #Technology #AI #MoravecsParadox #ArtificialIntelligence #MachineLearning #DeepLearning #DataScience #TechInnovation #FutureTech #QuantumComputing #SmartCities #AIResearch\n","ogImage":{"url":"/assets/img/2024-06-19-TheFutureofAIandRoboticsBeyondMoravecsParadox_0.png"},"coverImage":"/assets/img/2024-06-19-TheFutureofAIandRoboticsBeyondMoravecsParadox_0.png","tag":["Tech"],"readingTime":4},{"title":"SLAM ê°œìš”","description":"","date":"2024-06-19 18:36","slug":"2024-06-19-OverviewofSLAM","content":"\n\n\n![SLAM](/assets/img/2024-06-19-OverviewofSLAM_0.png)\n\nSLAMì€ ë™ì‹œ ìœ„ì¹˜ ì¶”ì  ë° ì§€ë„ ì‘ì„±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ëŠ” ë¡œë´‡ ê³µí•™ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ìˆ ë¡œ, ì•Œë ¤ì§€ì§€ ì•Šì€ í™˜ê²½ì˜ ì§€ë„ë¥¼ êµ¬ì¶•í•˜ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ë©´ì„œ ë™ì‹œì— ìì‹ ì„ ê·¸ ì§€ë„ ì•ˆì—ì„œ ìœ„ì¹˜ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤.\n\nSLAMì˜ ì£¼ìš” ëª©í‘œëŠ” ë¡œë´‡ì´ ì•Œ ìˆ˜ ì—†ëŠ” í™˜ê²½ì„ íƒìƒ‰í•˜ê³  íƒìƒ‰í•˜ì—¬ ê·¸ í™˜ê²½ì˜ ì§€ë„ë¥¼ ë§Œë“¤ê³  ë™ì‹œì— ê·¸ ì§€ë„ ì•ˆì—ì„œ ìì‹ ì˜ ìœ„ì¹˜ë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ì–´ë– í•œ í™˜ê²½ ì§€ì‹ë„ ì—†ì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.\n\nSLAMì€ ë¡œë´‡ ê³µí•™ì—ì„œ ì¤‘ìš”í•œ ë¬¸ì œì…ë‹ˆë‹¤. ì´ë¡œì¨ ë¡œë´‡ì€ ì•Œë ¤ì§€ì§€ ì•Šê±°ë‚˜ ë™ì ì¸ í™˜ê²½ì—ì„œ ììœ¨ì ìœ¼ë¡œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. SLAMì„ ì‚¬ìš©í•˜ì—¬ ë¡œë´‡ì€ ì‚¬ì „ì— ì‘ì„±ëœ ì§€ë„ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ê±°ë‚˜ ì˜¤ë˜ë˜ì—ˆì„ ìˆ˜ ìˆëŠ” í™˜ê²½ì—ì„œ íƒìƒ‰, íƒí—˜ ë° ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\n<div class=\"content-ad\"></div>\n\nSLAMì€ ììœ¨ ì£¼í–‰ ì°¨ëŸ‰, ë“œë¡ , ì´ë™ ë¡œë´‡, ì‹¬ì§€ì–´ ì¦ê°• í˜„ì‹¤ ì‹œìŠ¤í…œì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ì‘ìš©ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ììœ¨ ì£¼í–‰ ì°¨ëŸ‰ì—ì„œ SLAMì€ ì°¨ëŸ‰ì´ ì£¼ë³€ í™˜ê²½ì˜ ì§€ë„ë¥¼ ì‘ì„±í•˜ê³  ì•ˆì „í•˜ê³  íš¨ìœ¨ì ì¸ ê²½ë¡œë¥¼ ê³„íší•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤. ë“œë¡ ì—ì„œëŠ” SLAMì´ í™˜ê²½ì„ ë§¤í•‘í•˜ê³  ì•ˆì •ì ì¸ ë¹„í–‰ì„ ìœ ì§€í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. ì¦ê°• í˜„ì‹¤ ì‹œìŠ¤í…œì—ì„œëŠ” SLAMì´ ê°€ìƒ ê°ì²´ë¥¼ í˜„ì‹¤ ì„¸ê³„ì— ì •í™•í•˜ê²Œ ì˜¤ë²„ë ˆì´í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n\nSLAMì„ ë‹¬ì„±í•˜ê¸° ìœ„í•´ ë¡œë´‡ì€ ì¼ë°˜ì ìœ¼ë¡œ ì¹´ë©”ë¼, ë¼ì´ë‹¤ ë˜ëŠ” ê±°ë¦¬ ì¸¡ì • ì¥ì¹˜ì™€ ê°™ì€ ì„¼ì„œ ë°ì´í„°ì˜ ì¡°í•©ì„ ì‚¬ìš©í•˜ì—¬ í™˜ê²½ì„ ì¸ì‹í•©ë‹ˆë‹¤. ì´ë“¤ì€ ë˜í•œ ì´ ì„¼ì„œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ë¡œë´‡ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ë©° ë¡œë´‡ì´ ì´ë™í•  ë•Œ ì§€ë„ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•©ë‹ˆë‹¤.\n\n![SLAM ê°œìš”](/assets/img/2024-06-19-OverviewofSLAM_1.png)\n\n## SLAMì„ ì´í•´í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì–´íœ˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n\n<div class=\"content-ad\"></div>\n\nSLAM (Simultaneous Localization and Mapping)ì˜ ë§¥ë½ì—ì„œëŠ” ì´í•´í•´ì•¼ í•  ì¤‘ìš”í•œ ì—¬ëŸ¬ ìš©ì–´ì™€ ê°œë…ì´ ìˆìŠµë‹ˆë‹¤. í•¨ê»˜ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤:\n\n- **Localization**: ë¡œë´‡ì˜ ì¶”ì •ëœ ìì„¸ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì‹œê°„ ë‹¨ê³„ì—ì„œ ë¡œë´‡ì˜ ìœ„ì¹˜ì™€ ë°©í–¥ì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìì„¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ (x, y, theta) ì¢Œí‘œë¡œ í‘œì‹œë˜ë©°, ì—¬ê¸°ì„œ (x, y)ëŠ” ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ê³  thetaëŠ” ë°©í–¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n- **Mapping**: í™˜ê²½ì—ì„œ ëœë“œë§ˆí¬ì˜ ì¶”ì •ëœ ìœ„ì¹˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ëœë“œë§ˆí¬ëŠ” ë¡œë´‡ì´ ì¸ì‹í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì˜ ë…íŠ¹í•œ íŠ¹ì§•ìœ¼ë¡œ, ë²½, ì½”ë„ˆ, ë˜ëŠ” ê°ì²´ì™€ ê°™ì€ ê²ƒë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤.\n- **ë¡œë´‡**: ì„¼ì„œì™€ ì•¡ì¶”ì—ì´í„°ë¡œ ì¥ì°©ëœ ììœ¨ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. SLAMì˜ ë§¥ë½ì—ì„œ ë¡œë´‡ì˜ ì£¼ìš” ì‘ì—…ì€ í™˜ê²½ì„ íƒí—˜í•˜ê³  ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë©° ìì‹ ì˜ ìœ„ì¹˜ì™€ ëœë“œë§ˆí¬ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸í°ì˜ ì¦ê°• í˜„ì‹¤ (AR) ì‹œìŠ¤í…œì˜ ê²½ìš°, ì¼ë°˜ì ìœ¼ë¡œ ë¬¼ë¦¬ì ì¸ ë¡œë´‡ì€ ì—†ê³ , ëŒ€ì‹  ìŠ¤ë§ˆíŠ¸í° ìì²´ê°€ \"ë¡œë´‡\"ìœ¼ë¡œ ê°„ì£¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n- **ëœë“œë§ˆí¬**: ë¡œë´‡ì´ ì¸ì‹í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì˜ ë…íŠ¹í•œ íŠ¹ì§•ì´ë‚˜ ê´€ì‹¬ ì§€ì ì…ë‹ˆë‹¤. ë¬¼ì²´, ì½”ë„ˆ, ë²½ ë˜ëŠ” ë¡œë´‡ì´ ë‚´ë¹„ê²Œì´ì…˜ ë° ìœ„ì¹˜ ì¶”ì •ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ íŠ¹ì§•ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëœë“œë§ˆí¬ëŠ” ë¡œë´‡ì˜ ìœ„ì¹˜ ì¶”ì •ì„ ìœ„í•œ ê¸°ì¤€ì ìœ¼ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.\n- **ì„¼ì„œ**: ë¡œë´‡ì´ í™˜ê²½ì„ ì¸ì‹í•˜ëŠ” ë° ì‚¬ìš©í•˜ëŠ” ì¥ì¹˜ì…ë‹ˆë‹¤. ë²”ìœ„ ì¸¡ì •, ì´ë¯¸ì§€ ë˜ëŠ” ê¹Šì´ ë°ì´í„°ì™€ ê°™ì€ ë¡œë´‡ ì£¼ë³€ í™˜ê²½ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. SLAMì—ì„œ ì‚¬ìš©ë˜ëŠ” ì¼ë°˜ì ì¸ ì„¼ì„œì—ëŠ” ë ˆì´ì € ê±°ë¦¬ ì¸¡ì •ê¸°ë‚˜ ì´ˆìŒíŒŒ ì„¼ì„œì™€ ê°™ì€ ê±°ë¦¬ ì¸¡ì •ê¸°, ì¹´ë©”ë¼, ë¼ì´ë‹¤ ë° ì˜¤ë„ë¯¸í„° ì„¼ì„œê°€ ìˆìŠµë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸í°ì´ \"ë¡œë´‡\"ì¸ ê²½ìš°, ìŠ¤ë§ˆíŠ¸í°ì€ ì¹´ë©”ë¼, ìì´ë¡œìŠ¤ì½”í”„, ê°€ì†ë„ê³„ ë° ê¹Šì´ ì„¼ì„œì™€ ê°™ì€ ë‹¤ì–‘í•œ ì„¼ì„œë¥¼ í†µí•©í•œ í”Œë«í¼ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n\nì´ëŸ¬í•œ ìš©ì–´ ì™¸ì—ë„ ì¼ë°˜ì ìœ¼ë¡œ SLAMì—ì„œ ì‚¬ìš©ë˜ëŠ” ëª‡ ê°€ì§€ ìš©ì–´ê°€ ìˆìŠµë‹ˆë‹¤:\n\n- **ì˜¤ë„ë©”íŠ¸ë¦¬**: íœ  ì—”ì½”ë”, ê°€ì†ë„ê³„ ë˜ëŠ” ìì´ë¡œìŠ¤ì½”í”„ì™€ ê°™ì€ ë‚´ë¶€ ì„¼ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¡œë´‡ì˜ ì›€ì§ì„ì„ ì¶”ì •í•©ë‹ˆë‹¤. ë¡œë´‡ì˜ ì†ë„, íšŒì „ ë° ë³€ìœ„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n- **ë£¨í”„ í´ë¡œì €**: ë¡œë´‡ì˜ ê¶¤ì ì—ì„œ ë£¨í”„ë¥¼ ê°ì§€í•˜ê³  ìˆ˜ì •í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤. ë¡œë´‡ì´ ì´ì „ì— ê´€ì¸¡í•œ ëœë“œë§ˆí¬ë‚˜ ìœ„ì¹˜ë¥¼ ì¬ë°©ë¬¸í•  ë•Œ ë°œìƒí•©ë‹ˆë‹¤. ë£¨í”„ í´ë¡œì €ëŠ” ëˆ„ì ëœ ì˜¤ì°¨ë¥¼ ìˆ˜ì •í•˜ê³  SLAM ì†”ë£¨ì…˜ì˜ ì •í™•ë„ë¥¼ í–¥ìƒì‹œí‚¤ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nSLAMì— ì‚¬ìš©ë˜ëŠ” ì£¼ìš” ìš©ì–´ ë° ìš©ì–´ ì¤‘ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ê°œë…ì„ ì´í•´í•˜ë©´ SLAM ì•Œê³ ë¦¬ì¦˜ ë° ê¸°ìˆ ì„ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n![SLAM ì‚¬ìš© ì‚¬ë¡€](/assets/img/2024-06-19-OverviewofSLAM_2.png)\n\n## SLAMì˜ ì‚¬ìš© ì‚¬ë¡€ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n\nSLAM ê¸°ìˆ ì€ ìš°ë¦¬ì˜ ì¼ìƒìƒí™œì—ì„œ ì ì°¨ ë” í”í•´ì§€ê³  ìˆì§€ë§Œ ìš°ë¦¬ëŠ” í•­ìƒ ê·¸ê²ƒì„ ì¸ì‹í•˜ì§€ ëª»í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ ì¼ìƒìƒí™œì—ì„œ ë§Œë‚˜ê²Œ ë˜ëŠ” SLAM ì‘ìš© ë¶„ì•¼ì˜ ëª‡ ê°€ì§€ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n\n<div class=\"content-ad\"></div>\n\n- GPS ë‚´ë¹„ê²Œì´ì…˜ ì‹œìŠ¤í…œ: ë§ì€ ì•¼ì™¸ GPS ë‚´ë¹„ê²Œì´ì…˜ ì‹œìŠ¤í…œì€ SLAM ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ì •í™•í•˜ê³  ì‹¤ì‹œê°„ì˜ ìœ„ì¹˜ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì‹œìŠ¤í…œì€ GPS ë°ì´í„°ë¥¼ ê°€ì†ë„ê³„ ë° ìì´ë¡œìŠ¤ì½”í”„ì™€ ê°™ì€ ë‹¤ë¥¸ ì„¼ì„œ ì…ë ¥ê³¼ ê²°í•©í•˜ì—¬ ì°¨ëŸ‰ì˜ ìœ„ì¹˜ì™€ ë°©í–¥ì„ ì¶”ì •í•©ë‹ˆë‹¤. êµ¬ê¸€ ì§€ë„, Waze, Apple ì§€ë„ê°€ ì˜ˆì‹œì…ë‹ˆë‹¤.\n- ëª¨ë°”ì¼ ì¦ê°• í˜„ì‹¤ (AR) ì•±: ìŠ¤ë§ˆíŠ¸í° ë° íƒœë¸”ë¦¿ìš© AR ì•±ì€ ì£¼ë¡œ SLAM ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ ì¥ì¹˜ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì í•˜ê³  ê°€ìƒ ê°ì²´ë¥¼ í˜„ì‹¤ ì„¸ê³„ ìœ„ì— ì˜¤ë²„ë ˆì´í•©ë‹ˆë‹¤. SLAMì„ ì‚¬ìš©í•˜ë©´ ì‚¬ìš©ì ì£¼ë³€ê³¼ ê°€ìƒ ì½˜í…ì¸ ë¥¼ ì •í™•í•˜ê²Œ ì •ë ¬í•˜ì—¬ ëª°ì…í˜• AR ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. í¬ì¼“ëª¬ GO, ìŠ¤ëƒ…ì±—, ì¸ìŠ¤íƒ€ê·¸ë¨ì´ ì˜ˆì‹œì…ë‹ˆë‹¤.\n- ììœ¨ ì£¼í–‰ ì²­ì†Œê¸°: Roombaì™€ ê°™ì€ ë¡œë´‡ ì²­ì†Œê¸°ëŠ” SLAMì„ í™œìš©í•˜ì—¬ íš¨ìœ¨ì ìœ¼ë¡œ ë°©ì„ íƒìƒ‰í•˜ê³  ì²­ì†Œí•©ë‹ˆë‹¤. í™˜ê²½ì˜ ì§€ë„ë¥¼ ì‘ì„±í•˜ê³  ê·¸ ì§€ë„ ë‚´ì—ì„œ ìì‹ ì˜ ìœ„ì¹˜ë¥¼ ê²°ì •í•˜ëŠ” ìœ„ì¹˜ ê²°ì • ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì¥ì• ë¬¼ì„ í”¼í•˜ë©´ì„œ ììœ¨ì ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.\n- ì‹¤ë‚´ ë‚´ë¹„ê²Œì´ì…˜ ì‹œìŠ¤í…œ: ëŒ€í˜• ê±´ë¬¼ ë‚´ë¶€ì—ì„œ ì‹¤ì‹œê°„ ìœ„ì¹˜ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ SLAMì´ ì‚¬ìš©ë©ë‹ˆë‹¤. ì¹´ë©”ë¼ë‚˜ ê¹Šì´ ì„¼ì„œì™€ ê°™ì€ ì„¼ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ë‚´ í™˜ê²½ì„ ë§¤í•‘í•˜ê³  ì‚¬ìš©ìê°€ ë³µì¡í•œ ê³µê°„ì„ íƒìƒ‰í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤. SLAMì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ëŠ” í•œ ì˜ˆëŠ” Googleì˜ \"ì‹¤ë‚´ ë§µ\" ê¸°ëŠ¥ì…ë‹ˆë‹¤. Google ì§€ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” SLAMì„ Wi-Fi, Bluetooth ë“±ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì´ ê±´ë¬¼ ë‚´ì—ì„œ ì‹¤ì‹œê°„ ìœ„ì¹˜ ì •ë³´ì™€ ë°©í–¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n- ììœ¨ ì£¼í–‰ ìë™ì°¨: SLAMì€ ììœ¨ ì£¼í–‰ ì°¨ëŸ‰ì„ ìœ„í•œ ê¸°ë³¸ ê¸°ìˆ ì…ë‹ˆë‹¤. ììœ¨ ì£¼í–‰ ìë™ì°¨ëŠ” LiDAR, ì¹´ë©”ë¼, ë ˆì´ë” ë“± ë‹¤ì–‘í•œ ì„¼ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ë³€ í™˜ê²½ì„ ì¸ì‹í•˜ê³  ì„¸ë¶€ì ì¸ ì§€ë„ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. SLAM ì•Œê³ ë¦¬ì¦˜ì€ ì°¨ëŸ‰ì´ ì§€ë„ ë‚´ì—ì„œ ìì‹ ì˜ ìœ„ì¹˜ë¥¼ ì§€ì •í•˜ê³  ì•ˆì „í•˜ê²Œ ì´ë™í•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤. Waymo, Tesla, Cruise, Uberê°€ ì˜ˆì‹œì…ë‹ˆë‹¤.\n\n<img src=\"/assets/img/2024-06-19-OverviewofSLAM_3.png\" />\n\nì´ê²ƒë“¤ì€ SLAM ê¸°ìˆ ì´ ì¼ìƒìƒí™œì— í†µí•©ë˜ëŠ” ëª‡ ê°€ì§€ ì˜ˆì‹œì¼ ë¿ì…ë‹ˆë‹¤. ë¡œë´‡ ê³µí•™ ë° AI ë¶„ì•¼ê°€ ë°œì „í•¨ì— ë”°ë¼ ìš°ë¦¬ëŠ” ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ë” ë§ì€ SLAM ì‘ìš© í”„ë¡œê·¸ë¨ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nêµ¬í˜„ì„ ì°¾ê³  ê³„ì‹­ë‹ˆê¹Œ? ì´ê²ƒì´ ê°€ì¥ ê°„ë‹¨í•œ SLAM ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nì´ ê¸€ì´ ë§ˆìŒì— ë“œì…¨ë‹¤ë©´ â¤ë¥¼ ëˆŒëŸ¬ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì°¾ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”!","ogImage":{"url":"/assets/img/2024-06-19-OverviewofSLAM_0.png"},"coverImage":"/assets/img/2024-06-19-OverviewofSLAM_0.png","tag":["Tech"],"readingTime":4},{"title":"ë¡œë´‡ë“¤ì´ ì œë©‹ëŒ€ë¡œ í˜„ì¬ì™€ ë¯¸ë˜ì— ìš°ë ¤í•  ì´ìœ ê°€ ìˆì„ê¹Œìš”","description":"","date":"2024-06-19 18:34","slug":"2024-06-19-RobotsGoneWildIsThereReasonforConcernNowandintheFuture","content":"\n\nì¸ê³µ ì§€ëŠ¥ì´ ë¹„ì¦ˆë‹ˆìŠ¤ì˜ ëª¨ë“  ì˜ì—­ì—ì„œ ë°œì „í•˜ê³  ìˆì§€ë§Œ, ë§Œì•½ ê·¸ê²ƒì´ \"ì•¼ìƒ\"ì´ ëœë‹¤ë©´ ë¬´ìŠ¨ ì¼ì´ ë²Œì–´ì§ˆì§€ì— ëŒ€í•œ ì‹¬ê°í•œ ìš°ë ¤ê°€ ìˆìŠµë‹ˆë‹¤.\n\n![ë¡œë´‡ ê¸‰ì† ì—…ë°ì´íŠ¸ ë¬¸ì œ](/assets/img/2024-06-19-RobotsGoneWildIsThereReasonforConcernNowandintheFuture_0.png)\n\në¡œë´‡ê³µí•™ì€ ì‚°ì—…ì—ì„œ ë§ì€ ì§€ë£¨í•˜ê³  ë°˜ë³µì ì¸ ì‘ì—…ì„ ëŒ€ì²´í–ˆìœ¼ë©°, ì†ë„ì™€ ì •ë°€ë„ë¡œ ì œí’ˆì„ ì œê³µí–ˆëŠ”ë°, ì´ëŠ” ì¸ê°„ì´ ë¶ˆê°€ëŠ¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ëª¨ë“  ìë™í™”ëœ ì¥ì¹˜ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤. ìë™ì°¨ ìƒì‚° ê³µì¥ì€ ì´ëŸ¬í•œ ë¡œë´‡ì˜ ì‹¤ìˆ˜ì— ìœ„í—˜ì— ë…¸ì¶œëœ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n\nìµœê·¼ ììœ¨ì£¼í–‰ì°¨ëŸ‰ ì „ì²´ê°€ ë„ë¡œì—ì„œ ë‚´ë ¤ì˜¨ ì¼ì´ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ì°¨ëŸ‰ì˜ ì„¼ì„œê°€ ë„ë¡œ ìƒì˜ ë‹¤ì¹œ ë³´í–‰ìë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì°¨ëŸ‰ì´ ë³´í–‰ìë¥¼ ì¹˜ê³  ê·¸ë¥¼ ììœ¨ì£¼í–‰ì°¨ëŸ‰ì˜ ê²½ë¡œë¡œ ë˜ì¡ŒìŠµë‹ˆë‹¤. ê·¸ ììœ¨ì£¼í–‰ì°¨ëŸ‰ì€ ê·¸ë…€ë¥¼ ì¹˜ê³  ë‚œ í›„ ë„ë¡œë¥¼ ë”°ë¼ 20í”¼íŠ¸ë¥¼ ëŒê³  ê·¸ë…€ë¥¼ ì°¨ ë°‘ì— ë¬¶ì–´ ë‚¨ê²¼ìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ ê·¸ë…€ëŠ” ìœ„í—˜í•œ ìƒíƒœë¡œ ì¤‘ìƒì„ ì…ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ê±°ë¦¬ë¥¼ ê±´ë„ˆëŠ” ê²ƒì´ ì™„ì „íˆ ì•ˆì „í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë³´í–‰ìê°€ ë³´ë„ë¥¼ ê±´ë„ ë•Œ ììœ¨ì£¼í–‰ì°¨ëŸ‰ì´ ë©ˆì¶”ì§€ ì•Šì€ ê²ƒì— ê´€í•œ ì—°ë°© ì¡°ì‚¬ê°€ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\nì •ë¶€ê°€ ìŠ¹ì¸í•œ ììœ¨ ì£¼í–‰ ìë™ì°¨ìš© ì•ˆì „ ì ˆì°¨ê°€ ëª…í™•íˆ ì •í•´ì ¸ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. íŠ¹íˆ ììœ¨ ì£¼í–‰ ìë™ì°¨ê°€ ë„ë¡œ ì¤‘ê°„ì— ê°‘ìê¸° ë©ˆì¶”ëŠ” ê²½í–¥ì€ êµí†µì„ ë°©í•´í•˜ê³  ì‘ê¸‰ ì„œë¹„ìŠ¤ì˜ ì§€ì—°ì„ ì¼ìœ¼ì¼œ ì£¼ì˜ë¥¼ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤. ìƒŒí”„ë€ì‹œìŠ¤ì½”ì—ì„œëŠ” ê´€ë¦¬ìë“¤ì´ ì—¬ëŸ¬ ì‚¬ê±´ì„ ê¸°ë¡í•´ ì™”ìŠµë‹ˆë‹¤. ë˜í•œ, ìš´ì „ì ì—†ëŠ” ìë™ì°¨ê°€ ìœ ì•„ ìˆ˜ë ˆì— ë¶€ë”ªíˆëŠ” ê²ƒê³¼ ì‹ë£Œí’ˆ ì¹´íŠ¸ì— ë¶€ë”ªíˆëŠ” ê²ƒ ì¤‘ ì–´ë–¤ ì„ íƒì„ í• ì§€ ê²°ì •í•´ì•¼ í•˜ëŠ” ë¡œë³´í‹±ìŠ¤ ì „ë¬¸ê°€ì˜ ë¬¸ì œë¼ëŠ” ë‚œì œë„ ìˆìŠµë‹ˆë‹¤.\n\nììœ¨ ì£¼í–‰ ì°¨ëŸ‰ì´ ì¸ê°„ì´ ìš´ì „í•˜ëŠ” ì°¨ëŸ‰ë³´ë‹¤ ê³ ì¥ì„ ë” ë§ì´ ì¼ìœ¼í‚¬ ê°€ëŠ¥ì„±ì´ ë†’ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìš”ì¦˜ì€ ìë™ì°¨ ì‚¬ê³ ê°€ íŠ¹ì • ì‚¬ê±´ë“¤ì¼ ë¿ì´ë©°, í•œ ëª…ì˜ ìœ„í—˜ ìš´ì „ìëŠ” ì „ ì„¸ê³„ì˜ ë‹¤ë¥¸ ìš´ì „ìì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ììœ¨ ì£¼í–‰ ìë™ì°¨ê°€ ë“±ì¥í•˜ë©´ ìƒí™©ì´ ë°”ë€” ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë– í•œ ê²°í•¨, í•´í‚¹, ì‹œìŠ¤í…œ ê³ ì¥ì´ë“  ë„ë¡œì— ìˆëŠ” ëª¨ë“  ì°¨ëŸ‰ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nìµœê·¼ ì–¸ë¡  ë³´ë„ì— ë”°ë¥´ë©´ Cruiseì˜ CEOì¡°ì°¨ë„ ìì‹ ì˜ ì•ˆì „ ìš°ë ¤ë¥¼ í‘œëª…í•´ ì‚¬ì„í–ˆë‹¤ê³  í•©ë‹ˆë‹¤. Teslaì— ëŒ€í•œ ì¶”ê°€ì ì¸ ìš°ë ¤ê°€ í‘œëª…ë˜ê¸°ë„ í–ˆìŠµë‹ˆë‹¤.\n\nìºë‚˜ë‹¤ì˜ ë¬´ì§€ê°œ ë‹¤ë¦¬ë¥¼ ê±´ë„ˆë ¤ë˜ ë²¤í‹€ë¦¬ê°€ í­ë°œí•˜ëŠ” ì‚¬ê±´ìœ¼ë¡œ AIì˜ ì¹˜ëª…ì ì¸ ì‚¬ê³ ì— ëŒ€í•œ ì¡°ì‚¬ê°€ ì¬ê°œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ê³ ê¸‰ì°¨ íšŒì‚¬ëŠ” ì˜¤ë˜ëœ ëª¨ë¸(2020ë…„-2023ë…„)ìš© ë¦¬ì½œì„ ì—¬ëŸ¬ ì°¨ë¡€ ë‚´ë¶€ì ìœ¼ë¡œ ì‹¤ì‹œí•´ ì™”ëŠ”ë°, ì´ íŠ¹ë³„í•œ ì‚¬ê³ ì˜ ì°¨ëŸ‰ ì—­ì‹œ ì˜¤ë˜ëœ ëª¨ë¸ì´ì—ˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\në¡œë´‡ì´ ìš°ë¦¬ì—ê²Œ HALì´ í•˜ëŠ” ëª…ë ¹ ê±°ë¶€ì˜ ë¶ˆê¸¸í•œ ì†Œë¦¬ë¥¼ ë“¤ìœ¼ë©´ ì–´ë–»ê²Œ ë ê¹Œìš”? \"2001ë…„ ìš°ì£¼ ì—¬í–‰\"ì—ì„œ Halì´ ë§í–ˆë˜ \"Dave, ë¯¸ì•ˆí•˜ì§€ë§Œ ê·¸ê±¸ í•  ìˆ˜ ì—†ì–´\"ë¼ëŠ” ë§ì²˜ëŸ¼. ì´ì œ ìš°ë¦¬ëŠ” ë‹¨ìˆœí•œ ì‘ì—…ì„ í•˜ëŠ” ë¡œë´‡ë“¤ê³¼ í•¨ê»˜, ì„¼ì„œê°€ ì‚¬ëŒê³¼ ê°™ì´ ê³ ì¥ë‚˜ë©´ ë¹„ê·¹ì´ ì¼ì–´ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\në¯¸ë””ì–´ì—ì„œ ë¡œë´‡ ê´€ë ¨ ê³µì¥ ì‚¬ê³ ì— ëŒ€í•´ ë“£ëŠ” ê²ƒì€ ë“œë¬¼ì§€ë§Œ ìµœê·¼ ëŒ€í•œë¯¼êµ­ì—ì„œ ê³µì¥ ë¼ì¸ì—ì„œ ì„¼ì„œë¥¼ ìˆ˜ë¦¬í•˜ë˜ í•œ ë‚¨ì„±ì´ ìµœì‹  í¬ìƒìê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ë¡œë´‡ íŒ”ì´ ê°‘ìê¸° ê·¸ë¥¼ ë¶™ì¡ì•„ ìŒì‹ ìƒìë¥¼ ì˜®ê¸°ëŠ” ëŒ€ì‹ ì— ì»¨ë² ì´ì–´ ë²¨íŠ¸ì— ë˜ì§€ë©´ì„œ ê·¸ë¥´ê²Œ ë§Œë“¤ì—ˆê³ , ê²°ê³¼ì ìœ¼ë¡œ ê·¸ëŠ” ë¨¸ë¦¬ì™€ ê°€ìŠ´ì— ì¹˜ëª…ì ì¸ ë¶€ìƒì„ ì…ì—ˆìŠµë‹ˆë‹¤.\n\n1992ë…„ë¶€í„° 2017ë…„ ë¯¸êµ­ì—ì„œ ë¡œë´‡ ê´€ë ¨ ì‚¬ë§ ì‚¬ê³ ê°€ 41ê±´ ë°œìƒí–ˆëŠ”ë°, ëŒ€ë¶€ë¶„ì€ ìì²´ ì „ì›ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê³ ì • ì¥ì¹˜ì…ë‹ˆë‹¤. í­ìŠ¤ë°”ê² ê³µì¥ì—ì„œ ì¥ë¹„ë¥¼ ì„¤ì¹˜í•˜ë˜ ê·¼ë¡œìê°€ ë¡œë´‡ì— ë§í˜€ì ¸ ê¸ˆì† ë²½ì— ëˆŒë ¤ë¶™ì—ˆê³ , í›„ì— ë³‘ì›ì—ì„œ ì‚¬ë§í–ˆìŠµë‹ˆë‹¤.\n\në¯¸êµ­ ì •ë¶€ëŠ” ì´ëŸ¬í•œ ì‚¬ê±´ë“¤ì„ ê¸°ë¡í•˜ê³  ìˆì§€ë§Œ ì†Œë¹„ìë“¤ì€ ì˜ ì°¸ì¡°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ê²ƒì€ ìš°ë¦¬ê°€ ì•Œì•„ì•¼ í•˜ëŠ” ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ê° ì‚¬ê±´ì€ \"ì§ì›ì´ ìŠ¤í¿ìš©ì ‘ ë¡œë´‡ì´ ëˆŒëŸ¬ ì£½ì„ ë•Œ\", \"ì§ì›ì´ ì˜¤í¬ë¼ ë¡œë´‡ íŒ” ì‚¬ì´ì— ë¼ì—¬ ì£½ìŒ\", ë˜ëŠ” \"ì§ì›ì´ íƒ€ ì˜¤ë¥´ëŠ” ê¸°ê³„ì— ì˜í•´ ëˆŒë ¤ ì£½ìŒ\"ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ì•„ë‹ˆìš”, ê¸°ê³„ëŠ” ìƒê°í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ë“¤ì€ ê³ ì¥ì´ ë‚©ë‹ˆë‹¤. ì´ëŠ” ì•ˆì „ì¥ì¹˜ ë¶€ì¡± ë•Œë¬¸ì¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n1981ë…„, ì œì¡° ë¡œë´‡ê³¼ ê´€ë ¨ëœ ìµœì´ˆì˜ ì‚¬ê³  ì¤‘ í•˜ë‚˜ê°€ ê°€ì¥ ê°€ì™€ì‚¬í‚¤ ê³µì¥ì—ì„œ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì‘ì—…ìê°€ ìˆ˜ë¦¬í•˜ê¸° ìœ„í•´ ìœ ë‹› ì£¼ë³€ì˜ ìš¸íƒ€ë¦¬ë¥¼ ë¬´ì‹œí•˜ê³  ì ‘ì´‰í–ˆì„ ë•Œ, ìš°ì—°íˆ \"ì¼œê¸°\" ìŠ¤ìœ„ì¹˜ì— ë‹¿ì•„ ë¡œë´‡ íŒ”ì´ ê·¸ë¥¼ ì¡ì•„ ê¸°ì–´ë¥¼ ì ˆë‹¨í•˜ëŠ” ê¸°ê³„ë¡œ ë°€ì—ˆìŠµë‹ˆë‹¤. ë™ë£Œë“¤ì´ êµ¬í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ì‚¬ë§í–ˆìŠµë‹ˆë‹¤. ì´ ì‚¬ê±´ ì´ì „ì—ëŠ” 1979ë…„ í¬ë“œ ê³µì¥ì—ì„œ ì°½ê³ ì„ ë°˜ì„ ìŒ“ëŠ” ë¡œë´‡ì´ ì‘ì—…ìë¥¼ ì£½ì˜€ëŠ”ë°, ê·¸ ì‘ì—…ìì—ê²Œë¡œë´‡ì„ ë¹¨ë¦¬ ì›€ì§ì´ë¼ëŠ” ì§€ì‹œë¥¼ ë°›ì•˜ì„ ë•Œ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ê°€íŒŒë¥´ê²Œ ì˜¬ë¼ê°€ í¬ìƒë˜ì—ˆìŠµë‹ˆë‹¤.\n\ní˜„ì¬, ì¥ì¹˜, ì†Œí”„íŠ¸ì›¨ì–´ ë˜ëŠ” ë¡œë´‡ì— ëŒ€í•œ ì±…ì„ì„ ê²°ì •í•˜ëŠ” ë°ì— ëŒ€í•œ ì² ì €í•œ ì—°êµ¬ê°€ ë§ì´ ì§„í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ì‹¬ì´ ìˆë‹¤ë©´ í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ì±…ì´ ìˆìœ¼ë‹ˆ ì½ì–´ë³´ê±°ë‚˜ ìš”ì•½ë³¸ì„ í™•ì¸í•˜ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n\në†€ë¼ìš´ ê³¼í•™ ì‘ê°€ì¸ ì•„ì´ì‘ ì•„ì‹œëª¨í”„ëŠ” ë¡œë´‡ì„ ìœ„í•œ ê·œì¹™ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤. ê·¸ì˜ \"ë¡œë´‡ì˜ ì„¸ ë²•ì¹™\"ì—ì„œ ì²« ë²ˆì§¸ ê·œì¹™ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: \"ë¡œë´‡ì€ ì¸ê°„ì„ ìƒí•´ ì…íˆê±°ë‚˜, ë˜ëŠ” ì•„ë¬´ëŸ° ì¡°ì¹˜ë¥¼ ì·¨í•˜ì§€ ì•Šì•„ë„ ì¸ê°„ì´ ìœ„í—˜ì— ë¹ ì§€ê²Œ í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.\" ê·¸ëŸ¬ë‚˜ ë¡œë´‡ì´ í•˜ë‚˜ì˜ ì¼ë§Œì„ ìˆ˜í–‰í•˜ëŠ” ê²½ìš° ì¸ê°„ê³¼ ì œí’ˆ í•­ëª©ì„ êµ¬ë³„í•  ëŠ¥ë ¥ì´ ì—†ì„ ê²ƒì…ë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì—ëŠ” í–‰ë™ ë³€ê²½ì´ ì œê³µë˜ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤. ë˜í•œ ë¡œë´‡ì´ ë¯¸ì‚¬ì¼ì´ë‚˜ ì „ìŸ ë¬¼ìë¥¼ ë°œì‚¬í•˜ì—¬ ì ì„ ì£½ì´ë„ë¡ í”„ë¡œê·¸ë˜ë°ëœë‹¤ë©´ ì²« ë²ˆì§¸ ë²•ì¹™ì´ ì‘ë™í•˜ì§€ ì•Šê²Œ ë©ë‹ˆë‹¤.\n\nì£¼ìš” ë¬¸ì œëŠ” ë¬´ì—‡ì¼ê¹Œìš”? ë¡œë´‡ì˜ ê²½ìš° ê³ ë ¤í•˜ì§€ ì•Šì€ ì‚¬í•­ì„ ê³ ë ¤í•˜ì§€ ëª»í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë¶€ìƒì´ë‚˜ ì‚¬ë§ì€ ë‹¨ì§€ ë¹„ê·¹ë¿ë§Œ ì•„ë‹ˆë¼ ì‚¬ì „ì— ê³ ë ¤ë˜ì–´ì•¼ í–ˆìœ¼ë©° ê·¸ì— ëŒ€í•œ ì•ˆì „ì¥ì¹˜ê°€ ë¡œë´‡ ì½”ë“œì— ì‚½ì…ë˜ì–´ì•¼ í–ˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¬´ì—‡ì´ ì˜ëª»ë  ìˆ˜ ìˆëŠ”ì§€ ê¹Šê²Œ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ì–´ë–»ê²Œ ê·¸ê²ƒì„ ë°©ì§€í•  ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆì„ê¹Œìš”?\n\n<div class=\"content-ad\"></div>\n\nDDIntelì— ê°€ì…í•´ ì£¼ì„¸ìš”.\n\níŠ¹ë³„í•œ ì´ì•¼ê¸°ë¥¼ ê³µìœ í•˜ê³  ì‹¶ìœ¼ì„¸ìš”? DDIntelì— ì œì¶œí•´ ì£¼ì„¸ìš”.\n\nì €í¬ ì°½ì‘ì ìƒíƒœê³„ì— ê°€ì…í•´ ë³´ì„¸ìš”.\n\nDDIntelì€ ì£¼ìš” ì‚¬ì´íŠ¸ì™€ ì¸ê¸°ìˆëŠ” DDI Medium ì¶œíŒë¬¼ì—ì„œ ì£¼ëª©í•  ë§Œí•œ ì½˜í…ì¸ ë¥¼ ëª¨ìœ¼ê³  ìˆìŠµë‹ˆë‹¤. ìš°ë¦¬ ì»¤ë®¤ë‹ˆí‹°ì˜ í’ë¶€í•œ ì‘ì—…ì„ ë” ìì„¸íˆ ì‚´í´ë³´ì„¸ìš”.\n\n<div class=\"content-ad\"></div>\n\nDDI ê³µì‹ í…”ë ˆê·¸ë¨ ì±„ë„: [https://t.me/+tafUp6ecEys4YjQ1](https://t.me/+tafUp6ecEys4YjQ1)\n\nLinkedIn, Twitter, YouTube ë° Facebookì—ì„œ íŒ”ë¡œìš°í•´ ì£¼ì„¸ìš”.","ogImage":{"url":"/assets/img/2024-06-19-RobotsGoneWildIsThereReasonforConcernNowandintheFuture_0.png"},"coverImage":"/assets/img/2024-06-19-RobotsGoneWildIsThereReasonforConcernNowandintheFuture_0.png","tag":["Tech"],"readingTime":4},{"title":"ì‚¬ëƒ¥ ì²« ë²ˆì§¸ ì´ì•¼ê¸°","description":"","date":"2024-06-19 18:33","slug":"2024-06-19-TheHuntPartOne","content":"\n\n<img src=\"/assets/img/2024-06-19-TheHuntPartOne_0.png\" />\n\në“œë ˆì´í¬ëŠ” ê¹¨ì–´ë‚˜ ìì‹ ì´ ëª¨ë¥´ëŠ” ìˆ²ìœ¼ë¡œ ë–¨ì–´ì§€ê³  ìˆë‹¤ëŠ” ê²ƒì„ ê¹¨ë‹«ìŠµë‹ˆë‹¤. ê·¸ëŠ” ë™ì¼í•œ ê³¼ì •ì—ì„œ ë§ì€ ì‚¬ëŒë“¤ì„ ë§Œë‚˜ê²Œ ë©ë‹ˆë‹¤: ë¡œìŠ¤ ì œíƒ€ ê²½ì°°ê´€ ë¯¸ê²”, íŠ¹ìˆ˜ ë¶€ëŒ€ ì•ŒíŒŒ ê·¸ë£¹ ì†”ì € ì´ë°˜, ì´ìŠ¤ë¼ì—˜ ë°©ìœ„êµ° ì €ê²©ìˆ˜ ë ˆì•„, RUF ì¥êµ ì½”í”¼, ì‚° í€¸í‹´ ì‚¬í˜•ìˆ˜ ë¼ìŠ¤, ì¡°ì§ì› í•˜ì˜¤, ì˜ì‚¬ ì´ë‹¨. ê·¸ë“¤ì€ ë ˆì•„ê°€ ì „ ë¸”ë™ ì˜µìŠ¤ ì „ë¬¸ê°€ ë° ìš©ë³‘ì¼ ê²ƒìœ¼ë¡œ ì˜ì‹¬í•˜ëŠ” ë“œë ˆì´í¬ë¥¼ ì¶”ì í•©ë‹ˆë‹¤. ìˆ² ì†ì—ì„œ ê·¸ë“¤ì€ ì´ìƒí•œ ì´ë¯¸ì§€, ë¹ˆ ìš°ë¦¬, ê·¸ë¦¬ê³  ì£½ì€ ê·¸ë¦° ë² ë ˆ ë¶€ëŒ€ì›ì˜ ì£½ìŒì˜ ë„êµ¬ë¥¼ ë°œê²¬í•©ë‹ˆë‹¤.\n\n<img src=\"/assets/img/2024-06-19-TheHuntPartOne_1.png\" />\n\në” ë‚˜ì•„ê°€ë©°, ê·¸ë“¤ì€ ì™¸ê³„ì¸ í•˜ëŠ˜ì„ ë°”ë¼ë³´ë©° ìì‹ ë“¤ì´ ë” ì´ìƒ ì§€êµ¬ì— ìˆì§€ ì•ŠìŒì„ ê¹¨ë‹«ìŠµë‹ˆë‹¤. ì´ ê³³ì€ ì‚¬ëŒë“¤ê³¼ ë‹¤ë¥¸ ë™ë¬¼ë“¤ì´ ì£½ëŠ” ì‚¬ëƒ¥í„°ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ë¯¸ê²”ì€ ì‚´í•´ë˜ê³ , ê·¸ì˜ ì‹œì²´ëŠ” ìƒì¡´ìë“¤ì„ í•¨ì •ì— ë¹ ëœ¨ë¦¬ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤. ê·¸ë£¹ì€ ì•¼ìˆ˜ì˜ ìì·¨ë¥¼ ë”°ë¼ê°€ ì–´ëŠ ìº í”„ë¡œ ë„ì°©í•˜ê²Œ ë˜ê³ , ê±°ê¸°ì„œ í”„ë ˆë°í„°ê°€ ì¡í˜€ ìˆëŠ” ê²ƒì„ ë°œê²¬í•©ë‹ˆë‹¤. ê·¸ë“¤ì˜ ì‚¬ëƒ¥ê¾¼ì¸ íŠ¸ë˜ì»¤, ë²„ì„œì»¤, ê·¸ë¦¬ê³  íŒ”ì½”ë„ˆë¼ê³  ë¶ˆë¦¬ëŠ” ì„¸ ë§ˆë¦¬ í° ìƒë¬¼ì´ ê·¸ë£¹ì„ ê³µê²©í•˜ê³ , ì½”í”¼ë¥¼ ì£½ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë“¤ì€ íƒˆì¶œí•©ë‹ˆë‹¤. ë ˆì•„ì˜ ê³ ë°±í•œ 'í‚¬ëŸ¬'ëŠ” 1987ë…„ ê³¼í…Œë§ë¼ì—ì„œ íŠ¹ìˆ˜ ë¶€ëŒ€ë¥¼ ì‚´í•´í•œ ìœ ì‚¬í•œ ìƒë¬¼ì˜ ì„¤ëª…ê³¼ ì¼ì¹˜í•˜ì§€ë§Œ ìƒì¡´ìì— ì˜í•´ ë¬¼ë¦¬ì³ì§€ê¸°ë„ í–ˆìŠµë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n![TheHuntPartOne_2.png](/assets/img/2024-06-19-TheHuntPartOne_2.png)\n\ní˜¼ì ë‚¨ì€ ë¯¸êµ­ ìœ¡êµ° ë³‘ì‚¬ê°€ ë‹¬ì—ì„œ \"ì—´ ë²ˆì˜ ì‹œì¦Œ\" ë™ì•ˆ í¬ì‹ìë“¤ê³¼ ê·¸ í”¼í•´ìë“¤ë¡œë¶€í„° ìˆ¨ì–´ ì‚´ì•„ë‚¸ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ê·¸ëŠ” ëª¨ë‘ë¥¼ ìì‹ ì˜ ì€ì‹ ì²˜ë¡œ ì¸ë„í•˜ê³  í¬ì‹ìë“¤ì´ ì„¸ ëª…ì”© ëª¨ì—¬ ê¸°ìˆ ì„ ì—°ë§ˆí•˜ë©° ë‹¤ë¥¸ ì„¸ê³„ì—ì„œ ì†Œì¤‘í•œ ë¬¼ê±´ì„ í›”ì³ ì§€êµ¬ë¡œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì„ ì„¤ëª…í•©ë‹ˆë‹¤. ê°€ë¸Œë¦¬ì—˜ì€ ë˜í•œ í¬ì‹ìì™€ ìŠˆí¼ í¬ì‹ìë¼ê³  ë¶ˆë¦¬ëŠ” ë‹¤ë¥¸ ë¶€ëŒ€ ê°„ì— ìŸíƒˆì´ ìˆë‹¤ê³  ë°í™ë‹ˆë‹¤. ë“œë ˆì´í¬ëŠ” í¬ì‹ìë“¤ì„ í•´ë°©ì‹œì¼œ ê³ í–¥ìœ¼ë¡œ ë°ë ¤ì˜¤ê¸°ë¥¼ í¬ë§í•˜ë©° ê³„íšì„ ì„¸ì›ë‹ˆë‹¤. ê·¸ë“¤ì€ ì¥ë¹„ë¥¼ êµ¬ì…í•©ë‹ˆë‹¤. ë“œë ˆì´í¬ëŠ” í­ë°œë¬¼ì„ ì‚¬ìš©í•˜ì—¬ í¬ì‹ìë“¤ì„ ê¾€ì–´ êµ´ ì†ìœ¼ë¡œ ì´ë•ë‹ˆë‹¤. ê°€ë¸Œë¦¬ì—˜ì€ ê·¸ë£¹ì„ í•´ë°©í•˜ëŠ” íŠ¸ë˜ì»¤ì—ê²Œ ì‚´í•´ë‹¹í•©ë‹ˆë‹¤.\n\n![TheHuntPartOne_3.png](/assets/img/2024-06-19-TheHuntPartOne_3.png)\n\nê·¸ì— ì´ì–´ ë°œìƒí•œ ì¶”ê²©ì „ì—ì„œ ì´ë°˜ì€ íŠ¸ë˜ì»¤ë¥¼ ì£½ì´ê³  ì´ë‹¨ì„ êµ¬í•˜ê¸° ìœ„í•´ ìì‹ ì„ í¬ìƒí•©ë‹ˆë‹¤. ìƒì¡´ìë“¤ì€ ë²„ì„œì»¤ì—ê²Œ ê³µê²©ì„ ë°›ì§€ë§Œ ë¼ìŠ¤ê°€ ë²„ì„œì»¤ì˜ ì£¼ì˜ë¥¼ ë¶„ì‚°ì‹œí‚¤ê³  ë‹¤ë¥¸ ì´ë“¤ì´ ë„ë§ì¹  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. í•˜ì˜¤ëŠ” ê°€ë¸Œë¦¬ì—˜ë¡œë¶€í„° ìˆ¨ì–´ ë‘ì—ˆë˜ ì¹´íƒ€ë‚˜ë¡œ íŒŒìš¸ì½”ë„ˆì™€ ê²°íˆ¬ë¥¼ ë²Œì´ë©° ê·¸ë¥¼ ì£½ì´ê³  ìì‹ ì˜ ìƒì²˜ë¡œ ì¸í•´ ì£½ìŠµë‹ˆë‹¤. ì´ë‹¨ì´ ë“œë ˆì´í¬ì˜ ê³„íšì„ ì´ì–´ê°€ê¸¸ í¬ë§í•˜ì§€ë§Œ í•¨ì •ì— ê±¸ë ¤ ë¶€ìƒì„ ì…ìŠµë‹ˆë‹¤. ë¦¬ì•„ê°€ ê·¸ë¥¼ ë– ë‚˜ì§€ ì•Šê² ë‹¤ê³  í•˜ì ë“œë ˆì´í¬ëŠ” ê·¸ë“¤ì„ ë‚¨ê²¨ë‘ê³  ë– ë‚©ë‹ˆë‹¤. ê·¸ë“¤ì€ ë²„ì„œì»¤ë“¤ì—ê²Œ ì¡í˜€ êµ¬ë© ì†ì— ê°‡íˆê³  ìº í”„ë¥¼ í–¥í•´ ê³„ì† ë‚˜ì•„ê°‘ë‹ˆë‹¤. ë“œë ˆì´í¬ëŠ” ì§€êµ¬ë¡œ ì´ë™í•˜ê¸° ìœ„í•´ í¬ì‹ìë“¤ì„ í•´ë°©í•©ë‹ˆë‹¤.\n\n<div class=\"content-ad\"></div>\n\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-TheHuntPartOne_4.png)\n\nê·¸ëŠ” í”„ë ˆë°í„° ê°‘ì˜·ì„ ì…ê³ , ì†ëª© ì»´í“¨í„°ë¡œ ìš°ì£¼ì„ ì„ ì¼œê³  ì§€êµ¬ë¡œ í–¥í•œë‹¤. ë“œë ˆì´í¬ëŠ” ìš°ì£¼ì„ ì„ íƒˆì¶œí•˜ì§€ë§Œ, ë²„ì„œì»¤ê°€ ë„ì°©í•˜ì—¬ ë‹¤ë¥¸ í”„ë ˆë°í„°ë¥¼ ì••ë„í•˜ê³  ëª©ì„ ë² ì–´ ê·¸ì˜ ì†ëª© ì»´í“¨í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš°ì£¼ì„ ì„ íŒŒê´´í•˜ê³ , ë“œë ˆì´í¬ë¥¼ ì£½ì¸ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ì´ì „ì— ì‹ë¬¼ì—ì„œ ë³¸ ì‹ ê²½ ë…ì†Œë¥¼ ì‚¬ìš©í•˜ì—¬ ë¦¬ì•„ë¥¼ ë§ˆë¹„ì‹œí‚¤ë©°, ê·¸ ë˜í•œ ì§€êµ¬ì— ë‚¨ê³  ì‹¶ì€ ì•”ì‚´ìì„ì„ ë°íŒ ì´ë‹¨ì´ë‹¤. ë“œë ˆì´í¬ê°€ ë‚˜íƒ€ë‚˜ ì´ë‹¨ì„ ë…ë¦½ì‹œí‚¨ í›„ ìˆ˜ë¥˜íƒ„ìœ¼ë¡œ ê·¸ë¥¼ ìœ ì¸í•˜ì—¬ ë²„ì„œì»¤ë¥¼ ìƒì²˜ ì…íˆëŠ” í•¨ì •ì„ ì„¤ì¹˜í•œë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-19-TheHuntPartOne_5.png)\n\në¦¬ì•„ì˜ ë„ì›€ìœ¼ë¡œ ë“œë ˆì´í¬ëŠ” ë²„ì„œì»¤ë¥¼ ë¬¼ë¦¬ì¹˜ê³  ì£½ì¸ë‹¤. ì‚¬ëŒë“¤ì€ ì§€êµ¬ë¡œ ëŒì•„ê°€ëŠ” ë°©ë²•ì„ ì°¾ê¸° ìœ„í•´ ìˆ²ìœ¼ë¡œ í–¥í•œë‹¤. ìƒì¡´ ì¤‘ í˜•ì„±ëœ ì¸ì—°ì€ ê·¸ë“¤ë¡œ í•˜ì—¬ê¸ˆ ìˆ²ì˜ ì‹ ë¹„ì™€ ìì‹ ì˜ ë„ì „ì— ì§ë©´í•  ë•Œ í˜ì„ ì£¼ë©°, ì‹¸ì›€ì´ ëë‚˜ì§€ ì•Šì•˜ì§€ë§Œ ì‚´ì•„ë‚¨ê³  ê¸¸ì„ ì°¾ê² ë‹¤ëŠ” ê²°ì˜ë¥¼ í•˜ê³  ìˆìŒì„ ê¹¨ë‹«ëŠ”ë‹¤.\n","ogImage":{"url":"/assets/img/2024-06-19-TheHuntPartOne_0.png"},"coverImage":"/assets/img/2024-06-19-TheHuntPartOne_0.png","tag":["Tech"],"readingTime":3}],"page":"66","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true}