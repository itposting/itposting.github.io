{"pageProps":{"posts":[{"title":"판매 가능한 독특한 AI 생성 카드 디자인 10가지","description":"","date":"2024-06-30 19:14","slug":"2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell","content":"\n\n![Unique AI-Generated Playing Card Designs](/assets/img/2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_0.png)\n\n안녕하세요, AI로 생성된 예술 작품의 창조자 여러분! 이전 글에서는 AI를 활용하여 자신만의 타로 카드 덱을 디자인하는 데 도움이 되는 10가지 프롬프트와 이미지를 제공했습니다. 이는 예술가들이 AI 창작물로부터 수익을 창출하는 인기 있는 방법이 되었습니다. 오늘은 판매 가능한 제품으로 AI 생성된 예술을 활용하는 좋은 방법 중 하나인 플레잉 카드를 디자인하기 위한 10가지 새로운 프롬프트와 이미지를 공유하겠습니다!\n\n전 글에서는 여러분이 자신만의 덱을 만들 때 고화질 이미지의 중요성에 대해 강조했습니다. 함께 작업할 카드 인쇄 회사를 선정할 때 고밀도의 이미지를 제공하고 품질이 우수한지 확인하는 것이 중요합니다.\n\n플레잉 카드의 역사는 중국의 탕 시대(9세기)로 거슬러 올라가며, 이후 14세기에 유럽에 소개되었습니다. 이 카드들은 타로 덱과 많은 유사점을 공유하며, 4가지 문양과 숫자 카드를 포함합니다. 시간이 흘러서 많은 게임이 플레잉 카드 덱을 활용해 만들어지고 즐겨지며, 포커, 블랙잭, 브릿지, 하트 등이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n카드 게임이 여전히 인기 있는 제품임에 놀랄 것이 없죠! 이 기사에서는 10가지 AI 프롬프트와 이미지를 살펴볼텐데, 여러분에게 자신만의 카드를 디자인하거나 독특한 컨셉을 고안하는데 영감을 줄 것입니다. 따라서 창의적인 아이디어를 얻으려면 계속 읽어보세요!\n\n더 많은 AI 아트 콘텐츠를 원하시면 무료로 저의 블로거 페이지를 방문해보세요. 일부 광고가 있긴 하지만 콘텐츠에 접속하려면 등록이나 구독이 필요하지 않습니다.\n\n이 중 일부 AI 프롬프트와 이미지는 제가 만들었고, 일부는 원래 여기에서 특집으로 다뤄졌던 것들입니다: [링크](https://www.midjourney.com/explore). 직접 시도해보고 어떤 것을 창조할 수 있는지 확인해보세요! (참고: 이러한 AI 프롬프트는 더 나은 결과를 위해 편집되었으며 여기서 공유하는 모든 AI 이미지는 저에 의해 다시 생성/검증되었습니다.)\n\n## 판매할 수 있는 고유한 AI 생성 카드 디자인 10가지\n\n<div class=\"content-ad\"></div>\n\n\n[2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_1.png](/assets/img/2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_1.png)\n\n[2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_2.png](/assets/img/2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_2.png)\n\n[2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_3.png](/assets/img/2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_3.png)\n\n읽어주셔서 감사합니다! 항상 행복한 AI 이미지 생성 되세요!\n","ogImage":{"url":"/assets/img/2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_0.png"},"coverImage":"/assets/img/2024-06-30-10UniqueAI-GeneratedPlayingCardDesignsYouCanSell_0.png","tag":["Tech"],"readingTime":2},{"title":"구글의 오픈 소스 모델 Gemma 2 출시","description":"","date":"2024-06-30 19:12","slug":"2024-06-30-TheOpenSourceModelGemma2byGoogleisHere","content":"\n\n취약하지만 접근성이 높은 LLM입니다.\n\n![Gemma 2](/assets/img/2024-06-30-TheOpenSourceModelGemma2byGoogleisHere_0.png)\n\n다시 한 번 다른 언어 모델을 소개합니다… 이번에는 구글의 오픈 소스 모델인 Gemma 2입니다!\n\n인공 지능 분야는 대규모 언어 모델(LLM)의 능력이 폭발적으로 증가했습니다… 대규모 데이터셋으로 훈련된 이 복잡한 시스템들은 인간과 유사한 텍스트를 이해하고 생성하는 놀라운 능력을 보여주며, 한 때 인간 지능의 독점 영역으로 여겨졌던 경계를 넘어섰습니다. 그렇지만!!! 이러한 진전은 종종 엄청난 계산 리소스 비용을 지불해야 했기에 많은 연구원과 개발자에게는 액세스가 제한되는 문제가 있었습니다. 이 맥락에서 구글이 개발한 Gemma 2가 소개됩니다. Gemma 2는 경쟁력 있는 성능을 실용적인 크기 내에서 제공하기 위해 섬세하게 설계된 새로운 세대의 오픈 소스 LLM이며, 강력한 인공 지능 도구에 대한 접근성을 더 쉽게 만들어줍니다.\n\n<div class=\"content-ad\"></div>\n\n더 알고 싶으신가요? 만약 그렇다면, 여기 있어요:\n\n- Gemma 2: 모델 패밀리\n- 건축 혁신: 효율성을 위한 건축 블록\n- 지식 증류: 현명한 스승으로부터 배우기\n- 성능 벤치마크: 새로운 표준 설정\n- 책임과 안전: 윤리적 요구사항\n- 결론\n\n# Gemma 2: 모델 패밀리\n\nGemma 2는 단일 모델이 아니라 특정 계산 제약 조건에 맞게 맞춘 여러 모델로 이루어진 패밀리입니다. 현재 라인업에는 90억과 270억 개 파라미터 모델이 포함되어 있으며, 곧 20억 개 파라미터 모델이 출시될 예정입니다. 이 범위는 개발자들이 자원 및 애플리케이션 요구사항에 가장 적합한 모델을 선택할 수 있도록 유연성을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n# 건축 혁신: 효율의 기반 요소들\n\n\"Gemma 2\"는 자신의 기반이 되는 디코더 전용 트랜스포머 아키텍처를 선배 모델인 \"Gemma (1)\"로부터 계승합니다. 그러나, 더 나은 효율성과 성능을 도모하기 위해 주요 아키텍처 세부 개선점을 통합하였습니다:\n\n- 로컬 및 글로벌 어텐션 교차: \"Gemma 2\"는 로컬 슬라이딩 윈도우 어텐션과 글로벌 어텐션의 레이어를 전략적으로 교대로 배치합니다. 이 접근 방식은 텍스트 내에서 로컬 컨텍스트와 보다 넓은 관계를 모두 포착하여 미묘한 균형을 이룹니다. 로컬 어텐션은 일정한 토큰 윈도우에 초점을 맞추어 계산 부담을 줄이는 반면, 글로벌 어텐션은 시퀀스의 모든 토큰을 고려하여 장거리 의존성을 식별하는 모델의 능력을 유지합니다. 이를 예로 들어보겠습니다. \"The cat sat on the mat, but it was thinking about the delicious fish it had for dinner\"라는 문장을 고려해보면, 로컬 어텐션은 \"cat\"과 \"sat\" 사이의 관계를 이해하는 데 초점을 맞출 수 있고, 글로벌 어텐션은 \"it\"을 \"cat\"과 \"fish\"에 연결하여 대명사의 참조를 포착할 수 있습니다.\n- 그룹화된 쿼리 어텐션 (GQA): GQA는 효율성을 희생하지 않으면서 계산 요구를 더 줄이기 위한 혁신적인 어텐션 메커니즘입니다. 모든 가능한 단어 쌍 사이의 어텐션 점수를 계산하는 대신, GQA는 쿼리와 키를 작은 그룹으로 나누어 이 그룹 내에서 어텐션을 계산합니다. 이 스마트한 파티셔닝은 특히 더 긴 시퀀스에 대해 처리 속도를 크게 향상시킵니다.\n- 로짓 소프트 캡핑: 훈련 안정성을 향상시키기 위해 \"Gemma 2\"는 로짓 소프트 캡핑을 사용합니다. 이 기법은 내부 표현에서 극단적인 값들을 방지하여 보다 견고하고 예측 가능한 동작을 유도합니다.\n- RMSNorm을 사용한 포스트-노름 및 프리-노름: \"Gemma 2\"는 각 레이어의 입력과 출력을 정규화하기 위해 RMSNorm (Root Mean Square 레이어 정규화)을 활용합니다. 이 선택은 더 부드러운 훈련과 개선된 모델 수렴에 기여합니다.\n\n\"Gemma 2\"의 모든 특징을 다시 한번 알아보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-30-TheOpenSourceModelGemma2byGoogleisHere_1.png)\n\n# 지식 증류: 현명한 선생님으로부터 배우기\n\nLLM 교육은 기본적으로 다음 토큰 예측에 의존하며, 모델은 시퀀스에서 다음 단어를 예측하는 방법을 학습합니다. 이 방법은 효과적이지만 최적의 성능을 위해 방대한 데이터 세트가 필요할 수 있습니다. 특히 2B 및 9B 모델을 포함하는 Gemma 2는 지식 증류라는 더 정교한 기술을 채택합니다.\n\n현명한 선생님으로부터 배우는 학생을 상상해보십시오. 학생이 선생님의 행동을 그대로 흉내 내는 대신, 학생은 선생님의 추론과 사고 과정을 이해함으로써 더 깊은 통찰을 얻게 됩니다. 비슷하게, 지식 증류에서는 더 큰 사전 훈련된 \"선생님\" 모델로부터 더 작은 \"학생\" 모델이 배우게 됩니다. 학생 모델은 다음 토큰을 예측하는 것뿐만 아니라 선생님이 예측한 모든 가능한 다음 토큰에 대한 확률 분포를 근사화하는 방식으로 교육됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n이 접근 방식은 중요한 장점을 제공합니다:\n\n- 데이터 효율성: 학생 모델은 훈련 데이터가 적더라도 더 큰 데이터셋에서 얻은 선생님의 지식을 활용하여 비교 가능한 성능을 달성합니다.\n- 빠른 훈련: 증류는 더 풍부한 기울기를 제공하여 학생 모델을 보다 최적의 솔루션 공간으로 이끌어 훈련을 가속화합니다.\n- 향상된 성능: 더 강력한 모델에서 학습하여 학생 모델은 종종 동일한 데이터셋에서 전통적인 다음 토큰 예측 훈련을 통해 달성할 수 있는 성능을 능가합니다.\n\n# 성능 기준: 새로운 기준 설정하기\n\nGemma 2는 엄격한 기준에 따라 빛을 발하며, 유사한 크기의 다른 오픈 모델을 지속적으로 능가하고 규모가 훨씬 큰 모델에도 도전합니다.\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-06-30-TheOpenSourceModelGemma2byGoogleisHere_2.png)\n\n당연히 현재의 최첨단 모델인 GPT-4o와 Claude 3.5 Sonnet과는 비교할 수 없습니다. GPT-4o와 Claude 3.5 Sonnet은 각각 HumanEval인 python 코딩의 벤치마크에서 90.2% 및 92.0%와 같이 인상적인 값을 달성할 수 있습니다. 또한, 3.5 Sonnet은 학교 수학의 벤치마크인 GSM8K에서 0-shot 방식으로 96.4%의 성과를 보여줍니다. \n\n그러나, Gemma 2의 강점은 접근성과 현실성에 있습니다. 더 작은 모델 크기로 인해 보다 넓은 하드웨어 범위에 배포할 수 있어, 자원이 제한된 개발자와 연구자들에게 혜택을 줄 수 있습니다.\n\n# 책임과 안전: 윤리적 필수성\n\n<div class=\"content-ad\"></div>\n\nLLM의 잠재적인 영향은 책임 있는 개발과 배포에 강한 헌신이 필요합니다. Gemma 2는 안전과 윤리 고려 사항을 핵심으로 구축되었습니다.\n\n- 안전 정책 및 교육 시간 완화: Gemma 2의 훈련 데이터는 해로운 및 편향적인 콘텐츠를 제거하기 위해 엄격하게 필터링됩니다. 게다가, 모델은 안전 정책으로 세밀하게 조정되어 부적절하거나 유해한 결과물을 생성할 위험을 최소화합니다.\n- 견고하고 투명한 평가: Gemma 2는 자동화된 벤치마크와 인간 평가를 결합하여 능력과 잠재적 위험을 평가하기 위해 철저히 평가됩니다. 이러한 평가는 안전, 공정성, 편향, 강건성을 포함한 다양한 측면을 다룹니다.\n- 책임 있는 생성적 AI 툴킷: 개발자들을 지원하기 위해 구글은 포괄적인 책임 있는 생성적 AI 툴킷을 제공합니다. 이 툴킷은 Gemma 2 모델의 안전하고 책임 있는 배포를 보장하기 위한 리소스, 도구 및 모베스트 프랙티스를 제공합니다.\n\n# 결론\n\nGemma 2는 오픈 LLM 기술의 상쾌한 바람으로, 첨단 성능, 실용적 효율성, 책임 있는 인공지능에 대한 강력한 헌신의 조합을 제공합니다: 이 강력한 도구들에 대한 이용을 민주화함으로써, Gemma 2는 연구 및 교육부터 콘텐츠 제작에 이르기까지 다양한 분야에서 혁신의 새로운 물결을 촉진할 수 있습니다. 사용하려면, 모델의 가중치는 예상대로 Hugging Face에서 이용 가능합니다!\n\n<div class=\"content-ad\"></div>\n\n멋진 마크다운 작성하셨네요! 부담 갖지 마시고 계속 찾아뵙세요.","ogImage":{"url":"/assets/img/2024-06-30-TheOpenSourceModelGemma2byGoogleisHere_0.png"},"coverImage":"/assets/img/2024-06-30-TheOpenSourceModelGemma2byGoogleisHere_0.png","tag":["Tech"],"readingTime":5},{"title":"절대 초보자를 위한 신경망 직접 코딩 기초부터 구현까지","description":"","date":"2024-06-30 19:11","slug":"2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners","content":"\n\n쌀선별기에 대해 알고 계신가요? 여기에 그 이미지가 있어요-\n\n![img](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_0.png)\n\n이 기사는 꽤 길어요. 하지만 여러분의 시간을 낭비하게 하려는 것이 아니에요. 이 긴 글은 사실 직관적으로 이해하기 쉽고 학습 속도를 높이기 위해 여기 있는 거예요. 또한 기술 용어와 수학은 피해서 더 간단하게 소화하도록 할게요.\n\n멋져요! 이제 쌀선별기로 돌아가보죠. 이 기계는 벼를 받아들이고 그 후에 어떤 처리(탈곡)를 해요. 마지막에 쌀과 견과가 출력으로 나와요-\n\n<div class=\"content-ad\"></div>\n\n![Coding a Neural Network from Scratch for Absolute Beginners](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_1.png)\n\n신경망이나 일반적으로 모든 AI 모델은 일종의 처리 기계와 같습니다. 데이터를 입력으로 받아들이고 어떤 형태의 변환을 실행한 후 변환된 결과를 출력합니다. 예를 들어, 모델에 염소 이미지를 제공하면 이미지를 \"염소\"라는 단어로 변환합니다. 이렇게 생각하는 것이 매우 도움이 됩니다 - 분류, 분할, 생성과 같은 어떤 유형의 작업을 수행하더라도 모델은 단순히 하나의 데이터를 다른 데이터로 변환하는 것뿐입니다.\n\n간단한 문제인 폭풍 예측으로 넘어가 봅시다. 어두운 구름과 온도의 급격한 하락이 있다면, 우리는 폭풍이 온다고 예측할 수 있습니다. 아래는 데이터의 테이블 형식 표현입니다-\n\n![Coding a Neural Network from Scratch for Absolute Beginners](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_2.png)\n\n<div class=\"content-ad\"></div>\n\n실생활에서는 날씨 예측이 복잡한 과정입니다. 여기서는 어두운 구름과 온도 감소가 모두 있는 경우에만 폭풍이 발생한다고 예측할 것입니다. 이 문제를 간단한 'if/else' 문으로 해결할 수 있습니다. 아래는 파이썬 코드입니다-\n\n```js\ndef predict(dark_clouds, temperature_drop):\n    storm = 0\n    if dark_clouds == 1 and temperature_drop == 1:\n        storm = 1\n    return storm\n\nprint(predict(1, 1))\nprint(predict(1, 0))\nprint(predict(0, 1))\nprint(predict(0, 0))\n```\n\n그러나 여기서는 머신러닝을 다루고 있으므로 문제를 명시적으로 해결하길 원하지 않습니다. (\"왜냐하면?\"이라고 물어볼 수 있습니다. 실제로 프로그래밍하기 매우 어려운 문제들이 있습니다. 그런 문제들을 해결하기 위해 머신러닝을 사용합니다.). 대신, 주어진 솔루션을 평가하고 더 나은 솔루션을 제안할 수 있는 코드를 작성해야 합니다-\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*itmi_oBBInInevageKOOxw.gif)\n\n<div class=\"content-ad\"></div>\n\n실전에서는 무작위 예측으로 시작하여 그것을 점진적으로 개선해나갑니다. 모든 것이 괜찮은데, 그럼 뉴런이 무엇인가요?! 뉴런은 여러 입력을 받아들이고, 일종의 마법을 부리며 결과물을 출력하는 함수와 같습니다.\n\n```js\ndef predict(dark_clouds, temperature_drop):\n    storm = 마법!\n    return storm\n```\n\n마법이 커질수록, 비밀이 어리석어집니다!! 뉴런은 단순히 각 입력에 대해 출력에 미치는 영향에 따라 가중치를 부여합니다. 그런 다음, 가중 입력을 모두 누적합니다. 합계가 1보다 크면 1을 출력하고, 그렇지 않으면 0을 출력합니다.\n\n![이미지](/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_3.png)\n\n<div class=\"content-ad\"></div>\n\n여기 두 개의 입력이 있기 때문에 각각에 대한 두 개의 가중치를 유지해야 합니다. 따라서, 필요한 가중치와 predict() 함수를 가진 neuron 클래스를 생성할 수 있습니다.\n\n```js\nclass Neuron:\n    def __init__(self):\n        self.w1 = 2\n        self.w2 = 0.5\n\n    def predict(self, dark_clouds, temperature_drop):\n        storm = 0\n        if (dark_clouds*self.w1 + temperature_drop*self.w2) > 1:\n            storm = 1\n        return storm\n\nneuron = Neuron()\nprint(neuron.predict(1, 1))\nprint(neuron.predict(1, 0))\nprint(neuron.predict(0, 1))\nprint(neuron.predict(0, 0))\n```\n\n기다려 주세요! 가중치 값을 어디서 가져오는 건가요? 그것이 바로 머신러닝이죠 :)\n\n제발, 그냥 글을 읽지 말아주세요. 읽기만으로는 깊은 직관력을 갖출 수 없습니다; 연습이 필요합니다. 아직 하지 않으셨다면, Python 편집기나 GoogleColab을 열고 코드를 직접 실행해보세요.\n\n<div class=\"content-ad\"></div>\n\n지금은 w1을 2로 설정하고 w2를 0.5로 설정해 봅시다. 코드를 실행하면 다음 결과가 나올 것입니다-\n\n```js\n1\n1\n0\n0\n```\n\n여기서 오직 한 가지 실수가 있는 것을 알 수 있습니다- 2번째 예측값은 0이어야 합니다. 이제 두 가중치를 모두 3으로 설정해 봅시다. 그러면, w1=3이고 w2=3이 됩니다. 이제 우리는 다음 결과를 얻습니다-\n\n```js\n1\n1\n1\n0\n```\n\n<div class=\"content-ad\"></div>\n\nUps! 지금 두 가지 오류가 있어요 - 2번째와 3번째 예측이 틀렸어요. w1=0.6, w2=0.8로 설정해보겠습니다 -\n\n```js\n1\n0\n0\n0\n```\n\n와우! 이제 모든 정답을 맞췄어요. 다른 가중치 값을 사용해서 정확한 결과를 얻을 수 있는지 확인해보세요.\n\n지금까지 알게 된 것은 - 가중치를 변경함으로써 입력-출력 패턴에 맞게 예측 함수를 조정할 수 있습니다. 따라서, 두 입력과 출력값을 받아 가중치를 조정하기 위해 어떤 매직(다시 한번)을 하는 학습 함수가 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 일부 무작위 값으로 가중치를 초기화하겠습니다 (여기서 예측 함수는 다음과 같이 최소화됩니다 [...])-\n\n```js\nimport random\n\nclass Neuron:\n    def __init__(self):\n        self.w1 = random.random()\n        self.w2 = random.random()\n\n    def predict(self, dark_clouds, temperature_drop): [...]\n\n    def learn(self, dark_clouds, temperature_drop, storm):\n        self.w1 = 마법!\n        self.w2 = 마법!\n```\n\n그래서 여기서의 마법은 먼저 우리가 가진 무작위 가중치로 결과를 예측해보는 것입니다. 그런 다음 예측값을 실제 결과에서 뺌으로써 오차를 계산합니다. 마지막으로, 오차와 관련 입력(가중치로 곱해진 값)에 의해 가중치를 업데이트합니다. 이것은 가중치가 오차에 미치는 영향(관련 입력)에 기초하여 가중치에 벌을 부과하는 것과 같습니다. 이것을 생각해볼 수도 있는데, 에러를 생성하는 데 가중치의 부분에 따라 가중치에 에러를 분배하는 것과 같습니다.\n\n```js\nimport random\n\nclass Neuron:\n    def __init__(self): [...]\n\n    def predict(self, dark_clouds, temperature_drop): [...]\n\n    def learn(self, dark_clouds, temperature_drop, storm):\n        오차 = self.predict(dark_clouds, temperature_drop) - storm\n        self.w1 -= 오차 * dark_clouds / 100\n        self.w2 -= 오차 * temperature_drop / 100\n```\n\n<div class=\"content-ad\"></div>\n\n너무 많은 변화를 원하지 않아요. 솔루션으로 나아가기 위해 작은 단계를 나아갈 거예요 (큰 단계는 종종 발산을 일으킵니다). 그래서 가중치를 업데이트할 때 에러를 100으로 나눠줘요.\n\n이제 훈련 및 테스트 코드를 추가할 수 있어요-\n\n```js\nimport random\n\nclass Neuron: [...]\n\nneuron = Neuron()\n\nwhile True:\n    # 테스트\n    if (neuron.predict(1, 1) == 1 and\n            neuron.predict(1, 0) == 0 and\n            neuron.predict(0, 1) == 0 and\n            neuron.predict(0, 0) == 0):\n        break\n\n    # 훈련\n    neuron.learn(1, 1, 1)\n    neuron.learn(1, 0, 0)\n    neuron.learn(0, 1, 0)\n    neuron.learn(0, 0, 0)\n\n# 출력\nprint(neuron.predict(1, 1))\nprint(neuron.predict(1, 0))\nprint(neuron.predict(0, 1))\nprint(neuron.predict(0, 0))\n```\n\n알 수 있듯이, 모든 올바른 출력을 얻을 때까지 훈련을 실행하고 있어요.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_4.png\" />\n\n이렇게 까지 오신 것을 축하드립니다! 당신은 제로베이스에서 인공 신경세포를 직접 코딩하고 훈련시켰습니다!! 멋지세요!!!\n\n훈련 및 테스트를 위한 함수를 만들어 봅시다 -\n\n```js\nimport random\n\nclass Neuron: [...]\n\n\ndata = [[1, 1, 1],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 0]]\n\ndef runTraining(neuron):\n    for row in data:\n        neuron.learn(row[0], row[1], row[2])\n\ndef runTesting(neuron):\n    return [neuron.predict(row[0], row[1]) for row in data]\n\nneuron = Neuron()\nwhile True:\n    output = runTesting(neuron)\n    print(output)\n    if output == [row[2] for row in data]:\n        break\n\n    runTraining(neuron)\n```\n\n<div class=\"content-ad\"></div>\n\n코드를 여러 번 실행하면 매번 해결책에 도달하기 위해 필요한 단계가 다를 수 있어요. 이는 가중치를 초기화하는 데 사용되는 랜덤 값 때문입니다. 때로는 한 단계만으로도 해결에 도달할 수 있을 수도 있어요.\n\n자, 이제 다른 출력값들과 놀아볼까요? 두 번째 출력값을 1로 변경하고 코드를 여러 번 실행해보세요 -\n\n```js\ndata = [[1, 1, 1],\n        [1, 0, 1],\n        [0, 1, 0],\n        [0, 0, 0]]\n```\n\n이번에는 해결책에 도달하기 위해 더 많은 단계가 소요되나요? 그런 이유가 무엇일까요? 시간을 내서 곰곰히 생각해보세요. 각 훈련 단계 이후에 가중치를 출력하여 변화를 분석해볼 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n이제, 첫 번째 출력을 0으로 설정하고 다시 실행해보겠습니다.\n\n```js\ndata = [[1, 1, 0],\n        [1, 0, 1],\n        [0, 1, 0],\n        [0, 0, 0]]\n```\n\n해결책에 도달하는 데 더 적은 단계가 필요한가요? 아니면 더 많은 단계가 필요한가요? 이해하는 것은 인공 뉴런의 기본 메커니즘을 이해하는 데 매우 유용합니다.\n\n이제, 모든 출력을 1로 설정해보겠습니다 -\n\n<div class=\"content-ad\"></div>\n\n```js\r\n데이터 = [[1, 1, 1],\r\n        [1, 0, 1],\r\n        [0, 1, 1],\r\n        [0, 0, 1]]\r\n```\r\n\r\n무슨 일이 일어나고 있나요? 컴퓨터가 다운되었나요? 아니면 응답하지 않는 건가요? 사실, while 루프에 갇혔습니다. 모든 올바른 출력을 얻지 못하기 때문입니다. 문제는 4번째 행인 [0, 0, 1]에 발생합니다. 그리고 그 이유를 이해하는 것은 쉽습니다 - 입력 값이 둘 다 0(영)이기 때문입니다. 그렇기 때문에 어떤 가중치를 곱해도 0이 됩니다. 따라서, predict() 함수의 조건인 `(dark_clouds*self.w1 + temperature_drop*self.w2) ` 1`은 절대 충족되지 않을 것입니다.\n\n여기서 멈춰주세요. 이 기발한 문제에 대해 생각해보세요. 이를 해결하기 위해 무엇을 할 것인지 고민해보세요. 계속 읽기 전에 뇌에 충분한 시간을 주세요.\n\n여기서 문제가 되는 것은 조건에서의 임계점인 1(하나)입니다. 1 대신 -1(음수 1)을 임계점으로 사용할 수 있습니다- `(dark_clouds*self.w1 + temperature_drop*self.w2) ` -1` . 이렇게 하면 문제가 해결됩니다. 그러나 그렇게 되면 모든 0(영) 출력에 대한 문제가 발생할 것입니다-\n\n<div class=\"content-ad\"></div>\n\n```js\n데이터 = [[1, 1, 0],\n        [1, 0, 0],\n        [0, 1, 0],\n        [0, 0, 0]]\n```\n\n따라서 해당 임계값을 조정해야 합니다. 임계값에 랜덤 값을 설정하고 가중치를 학습한 방식과 동일한 방법으로 학습할 수 있습니다. 여기에 코드 전체가 있습니다-\n\n```js\nimport random\n\nclass Neuron:\n    def __init__(self):\n        self.w1 = random.random()\n        self.w2 = random.random()\n        self.t = random.random()\n\n    def predict(self, dark_clouds, temperature_drop):\n        storm = 0\n        if (dark_clouds*self.w1 + temperature_drop*self.w2) > self.t:\n            storm = 1\n        return storm\n\n    def learn(self, dark_clouds, temperature_drop, storm):\n        error = self.predict(dark_clouds, temperature_drop) - storm\n        self.w1 -= error * dark_clouds / 100\n        self.w2 -= error * temperature_drop / 100\n        self.t += error / 100\n\ndata = [[1, 1, 1],\n        [1, 0, 1],\n        [0, 1, 1],\n        [0, 0, 1]]\n\ndef runTraining(neuron):\n    for row in data:\n        neuron.learn(row[0], row[1], row[2])\n\ndef runTesting(neuron):\n    return [neuron.predict(row[0], row[1]) for row in data]\n\nneuron = Neuron()\nwhile True:\n    output = runTesting(neuron)\n    print(output)\n    if output == [row[2] for row in data]:\n        break\n\n    runTraining(neuron)\n```\n\n와우! 놀랄만한 여정이었어요! 기계 학습(ML)의 세계에 오신 것을 환영합니다. 이제 어떤 어려운 ML 용어를 알아보도록 하죠-\n\n<div class=\"content-ad\"></div>\n\n편향: 머신 러닝에서 임계값 t를 단순히 편향이라고 부릅니다.\n\n매개변수: w1, w2 및 t(가중치와 편향)는 학습을 통해 배우는 변수인 매개변수로 불립니다. 매개변수를 선택하는 행위를 매개변수화라고 합니다.\n\n모델: 학습 후에는 올바른 출력을 생성하는 좋은 w1, w2 및 t (가중치와 편향) 값들이 있게 됩니다. 이러한 매개변수 값의 집합을 모델이라고 부릅니다.\n\n학습률: 함수 learn()에서 매개변수를 조정하는 동안 값들을 100으로 나눕니다. 이를 0.01로 곱하는 것으로 생각할 수 있습니다. 이 0.01을 학습률이라고 부르며, 종종 알파(α)로 표시됩니다. 학습률은 매우 중요한 하이퍼파라미터입니다(사람이 설정하는 값으로, 학습을 통해 학습되지 않는 값).\n\n<div class=\"content-ad\"></div>\n\n그레디언트 디센트: 우리가 learn() 함수에서 실행한 알고리즘은 매개변수(가중치와 편향)를 조정하기 위한 그레디언트 디센트라고 합니다. 더 구체적으로는 확률적 경사 하강법(SGD)입니다.\n\n회귀: 예측, 오차 계산 및 매개변수 조정의 전체 반복 과정을 회귀라고 합니다. 여기서 사용한 변형은 선형 회귀입니다.\n\n에포크: 올바른 출력값에 도달하기 위해 회귀에서 필요한 반복 수입니다.\n\n위 코드는 두 가지 입력만을 고려했습니다. 그러나 배열을 사용하여 어떤 수의 입력이라도 쉽게 업그레이드할 수 있습니다. 전체 코드는 여기에서 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n우리에게는 마지막 테스트가 하나 더 있어요 :D\n\n```js\ndata = [[1, 1, 0],\n        [1, 0, 1],\n        [0, 1, 1],\n        [0, 0, 0]]\n```\n\n이곳에는 하나의 뉴런만 있어요. 그리고 이 문제를 해결할 수 있는 뉴런이 한 개만 있다는 것이 증명되었어요. 이 문제를 해결하기 위해 여러 개의 뉴런(또는 신경망)이 필요할 거예요. [곧 연속되는 파트가 나올 거에요...]","ogImage":{"url":"/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_0.png"},"coverImage":"/assets/img/2024-06-30-CodingaNeuralNetworkfromScratchforAbsoluteBeginners_0.png","tag":["Tech"],"readingTime":10},{"title":"ChatGPT에 대한 2024년 최신 진실","description":"","date":"2024-06-30 19:09","slug":"2024-06-30-ChatGPTisBullshit","content":"\n\n원페이지가 하나의 이유로 산업계에서 큰 화제를 일으키고 있어요:\n\n그 이유가 뭔지, 그리고 그게 무슨 의미를 갖는지 알고 싶나요?\n\n# 인공지능의 진정한 본성\n\n<div class=\"content-ad\"></div>\n\n대형 언어 모델(Large Language Model, LLM)이 실수를 할 때, 우리는 그 모델이 '환각을 일으켰다'고 말합니다.\n\nLLM은 확률론적(의사 난수 생성) 단어 생성기이기 때문에, 모델이 진실에서 벗어난 예상치 못한 결과물을 출력할 확률이 항상 있는 것입니다.\n\n그리고 분명히 말하자면, 이것은 일부러 이루어지는 것입니다.\n\n자연어로 같은 생각이나 감정을 표현하는 다양한 방법이 있기 때문에, 우리는 모델에 불확실성을 모델링하도록 훈련시킵니다. 이를 위해 우리는 새로운 예측마다 정확한 단어를 결정하도록 하지 않고, 모든 단어 어휘에 대한 확률 분포를 출력하도록 강제합니다.\n\n<div class=\"content-ad\"></div>\n\n다시 말해, 아래에서 볼 수 있듯이, 모델은 입력 시퀀스에 대한 계속으로 통계적으로 합리적인 단어 (어휘)를 순위별로 나열합니다.\n\n![image](/assets/img/2024-06-30-ChatGPTisBullshit_1.png)\n\n하지만 역설적으로, 우리는 항상 가장 확률이 높은 단어를 선택하지는 않습니다. 사실, 상위 k개 단어 중 하나를 무작위로 샘플링하며, 모두가 아마도 합리적인 계속으로 판단됩니다 (위 이미지에서 5개의 옵션은 모두 의미론적으로 유효합니다).\n\n이는 모델의 창의력을 향상시키기 위해 수행되며, 때로는 이것이 바람직하며 모델의 언어 모델링 능력을 향상시키는 데 도움이 된다고 여겨집니다.\n\n<div class=\"content-ad\"></div>\n\n그 모델이 잘못된 가정을 내어놓고 어색한 주장을 하는 경우, 그것이 정말로 인간이 하는 것처럼 '환각'을 하는 것일까요?\n\n## 로봇에 의인화를 부여하다\n\n연구자들은 이겍이 명백히 잘못되었다고 말합니다.\n\n환각은 세상을 잘못 인식하여 현실과 어긋난 주장을 만들어내는 것을 의미합니다. 그러나 이것이 바로 그 차이점입니다:\n\n<div class=\"content-ad\"></div>\n\n---\n새로운 데이터\n\nChatGPT와 친숙해지기 위해 몇 가지 텍스트를 입력해보세요. 이것은 머신러닝 모델을 더 재미있고 유용하게 만들 수 있습니다.\n---\n\nLLM은 현실을 인식할 수 없어요.\n\n그들은 텍스트의 렌즈를 통해 현실을 보기 때문에 실제로 경험할 수 없어요.\n\n그 이유로 '환각'이라고 부르는 것은 도움이 되기보다 오히려 해를 끼치죠. 하지만 왜 거짓이라고 부르지 않는 건 어떨까요?\n\n# ChatGPT의 목표 이해하기\n\n<div class=\"content-ad\"></div>\n\n연구자들은 'ChatGPT가 거짓말을 했다'고 말하는 것이 LLMs의 실제 본성을 왜곡한다고 주장합니다. 거짓말을 하려면 누군가가 어떤 것에 대한 진실을 알고 의도적으로 대체로 부정확한 주장을 해야 합니다.\n\n사실, 팀은 모델이 진실을 말하려고 하는 것이 아니기 때문에 진실과 거짓을 알 수 없다고 주장합니다. 모델은 단순히 인간의 언어를 모방하려고 하는 것뿐입니다.\n\n그래서 LLMs에 더 적용되는 용어인 '허풍을 떨다' 또는 부정확한 주장을 퍼뜨리지만 그 부정확함을 인식하지 못하는 것입니다.\n\n그런데 왜 그럴까요?\n\n<div class=\"content-ad\"></div>\n\n모델이 '진실을 말한다'는 점에서, 그 모델은 훈련 데이터의 진실성만큼 정확합니다.\n\n모델은 각 단어와 문장의 진실성을 평가하지 않습니다. 대신, 통계적 패턴과 확률에 기반하여 응답을 생성합니다. 이는 진실이나 거짓 여부와 독립적으로 이루어집니다.\n\n결국, 모델이 마치 답변을 찾기 위해 노력하는 것처럼 보일지라도, 실제로 하는 일은 제공된 입력 순서에 따라 자체 지식에서 해답을 검색하고 있습니다. 모델이 진실을 찾고 있는 것이 아니라, 주어진 순서의 다음으로 가장 통계적으로 타당한 후속 조치를 찾고 있는 것입니다.\n\n하지만 모델을 더 정확하게 만들 방법이 있을까요?\n\n<div class=\"content-ad\"></div>\n\n## 진실을 찾아 나서며\n\n우리가 추론이 올바른 해결책을 찾을 때까지 가능한 해결책의 공간을 탐색하는 한 형태의 탐색인 것으로 가정한다면 (나의 연구 결과에 따르면 이는 LLMs가 효과적으로 추론할 수 있는지 여부와는 별개의 논점이며 동의하는 견해인 것으로 보여집니다), LLMs와 런타임 탐색을 결합함으로써 그들의 추론 능력을 향상시키고, 따라서 부정확성을 감소시킬 수 있습니다.\n\n그러나 이 모델에서도 여전히 진실을 찾는 것이 아니며, 목표는 여전히 인간의 언어를 모방하는 것입니다.\n\n그렇다면, 아마도 진실성을 암묵적으로 향상시키는 방법이 있을 수 있습니다. 이는 연구자들이 엔트로피 최소화와, 최근에는 테스트 시 점진적인 미세 조정을 통해 오랫동안 조사해온 두 가지 방법입니다.\n\n<div class=\"content-ad\"></div>\n\n- 엔트로피 최소화에서는 모델이 엔트로피가 낮은 응답을 선호하는 귀납편향을 갖고 있습니다. 다시 말해, 여러 응답을 생성하고, 차별화 방법으로, 가능한 가정의 수가 가장 적은(즉, 가장 간단한) 응답을 가장 좋은 답이라고 취하는 가설을 적용합니다. 일부 분들께는 Ockham의 면도날과 유사하게 느껴질 것입니다.\n\n- 테스트 시간 미세조정에서 Jack Cole과 Mohamed Osman은 推論에 대한 모델을 세밀 조정하여 유명한 ARC-AGI 벤치마크(대규모 언어 모델에 대한 가장 어려운 벤치마크)의 해법을 활발히 탐색하고 있습니다.\n\n그러나 저의 겸손한 견해에 따르면(제가 틀릴 수도 있습니다), 이러한 검색과 LLM을 결합하는 매우 흥미로운 방법이 모델의 정확성을 향상시킬 수 있다는 점에도 불구하고, 본질적으로 모델은 여전히 진실을 탐색하는 것이 아니라 이전에 메모리화한 해결 경로와 유사한 최상의 통계적으로 타당한 응답을 제공하고 있지 않는다는 문제를 해결하지 못하는 것 같습니다.\n\n다시 말해, 더 똑똑한 검색 방법과 LLM은 더 나은, 더 사실적인 응답으로 이어질 수 있지만, 모델은 여전히 단순히 통계적으로 최적의 답변을 제공하는 목표를 실현하고 있으며, 거기에 반드시 응답의 진실성을 고려하지는 않습니다. 비록 논의된 귀납편향이 내제적으로 진실성을 향상시킬 수 있다고 하더라도요.\n\n<div class=\"content-ad\"></div>\n\n앞서 설명한 바와 같이 모델들이 더 나은 품질의 데이터를 소화하고 압축 능력을 향상시키면, '참'이라고 할 수 있는 주장이 '거짓'이라고 할 때보다 모델에게 통계적으로 더 합리적일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 모델이 진실을 찾을 수 없는 한(그 존재를 모르기 때문에), 학습 데이터에서 미대표적인 진실은 모델이 가짜로 답변하게 유도하거나, 더 정확히 말하면 '헛소리로' 오도록 할 수 있습니다.\n\n나는 몰라. 당신은 알고 있나요?","ogImage":{"url":"/assets/img/2024-06-30-ChatGPTisBullshit_0.png"},"coverImage":"/assets/img/2024-06-30-ChatGPTisBullshit_0.png","tag":["Tech"],"readingTime":4},{"title":"5분 안에 알아보는 비전 트랜스포머와 마스크드 오토인코더","description":"","date":"2024-06-30 19:07","slug":"2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes","content":"\n\n## 컴퓨터 비전으로 일반화된 NLP 작업을 안내하는 간단한 가이드\n\n2017년 transformer 아키텍처가 등장하면서 언어 모델링, 가려진 단어 예측, 번역 및 질의 응답과 같은 대부분의 자연어 처리 작업들이 혁신을 이루었습니다. Transformers가 컴퓨터 비전 작업에서도 뛰어난 성과를 거뒀다는 데는 2~3년이 걸리지 않았습니다. 이 이야기에서는 transformers가 컴퓨터 비전 분야로 진출할 수 있게 된 두 가지 기본 아키텍처를 탐구합니다.\n\n## 목차\n\n- Vision Transformer\n  - 주요 아이디어\n  - 운영\n  - 혼합 아키텍처\n  - 구조의 손실\n  - 결과\n  - 가려진 자가 반복 학습\n- 가려진 오토인코더 비전 Transformer\n  - 주요 아이디어\n  - 아키텍처\n  - 최종 결론 및 예제\n\n<div class=\"content-ad\"></div>\n\n# 비전 트랜스포머\n\n![이미지](/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_0.png)\n\n## 주요 아이디어\n\n비전 트랜스포머는 단순히 표준 트랜스포머 구조를 이미지 입력을 처리하고 학습하기 위해 일반화하는 것을 의미합니다. 저자들이 강조한 아키텍처에 대한 중요한 아이디어가 있습니다:\n\n<div class=\"content-ad\"></div>\n\n## 동작\n\n“가능한 수정을 가장 적게 하는 것”을 말 그대로 받아들이는 것은 옳습니다. 사실 그들은 거의 수정을 하지 않습니다. 그들이 실제로 수정하는 것은 입력 구조입니다:\n\n- NLP의 transformer encoder는 입력 문장/문단을 나타내는 원핫 벡터 시퀀스(또는 동등한 토큰 인덱스)를 가져와 문맥 임베딩 벡터 시퀀스를 반환합니다. 이는 나중에 사용될 수 있는 벡터들이며(예: 분류)\n- CV를 일반화하기 위해, vision transformer는 입력 이미지를 나타내는 패치 벡터 시퀀스를 가져와 문맥 임베딩 벡터 시퀀스를 반환합니다. 이는 나중에 사용될 수 있는 벡터들입니다(예: 분류)\n\n특히, 입력 이미지의 차원이 (n, n, 3)이라고 가정할 때, 이를 transformer에 입력으로 전달하기 위해 vision transformer가 수행하는 작업은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- 위의 그림과 같이 k (예: k=3)로 k² 패치로 나눕니다.\n- 이제 각 패치는 (n/k, n/k, 3)이고, 다음 단계는 각 패치를 벡터로 평평하게 만드는 것입니다.\n\n패치 벡터는 3*(n/k)*(n/k) 차원입니다. 예를 들어, 이미지가 (900,900,3)이고 k=3을 사용한다면, 패치 벡터는 평평화된 패치의 픽셀 값을 나타내는 300*300*3 차원이 될 것입니다. 논문에서는 k=16을 사용하고 있습니다. 따라서, 제목에 \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\"이라고 표시됩니다. 단어를 나타내는 one-hot 벡터를 주지 않고 이미지의 패치를 나타내는 픽셀 벡터로 대신합니다.\n\n나머지 작업은 원래 트랜스포머 인코더와 동일합니다:\n\n- 이러한 패치 벡터는 훈련 가능한 임베딩 레이어를 통과합니다.\n- 각 벡터에 위치 임베딩이 추가되어 이미지의 공간 정보를 유지합니다.\n- 출력은 각 패치에 대한 인코더 표현 (패치 또는 이미지 수준의 분류에 사용 가능)이 될 수 있습니다.\n- 더 자주 (및 논문에서처럼), CLS 토큰이 전단에 추가되고 해당 표현을 사용하여 전체 이미지에 대한 예측을 수행합니다 (BERT와 유사).\n\n<div class=\"content-ad\"></div>\n\nTransformer Decoder에 대해 어떻게 생각하시나요?\n\n기억해두세요, Transformer Encoder와 마찬가지로 Transformer Decoder도 마찬가지로 작동합니다; 차이점은 self-attention 대신 masked self-attention을 사용한다는 것입니다 (하지만 동일한 입력 signature를 유지합니다). 어쨌든, 단순히 다음 패치를 예측하는 것은 큰 흥미를 불러일으키는 작업이 아닐 수 있으므로 대부분의 경우 decoder-only Transformer 아키텍처를 드물게 사용할 것으로 기대됩니다.\n\n## 하이브리드 아키텍처\n\n작가들은 또한 이미지 자체 대신 CNN feature map으로 시작하여 하이브리드 아키텍처를 형성하는 것이 가능하다고 언급합니다 (CNN이 비전 Transformer에 출력을 전달). 이 경우 입력을 일반적인 (n,n,p) feature map으로 생각하고 패치 벡터는 차원이 (n/k)*(n/k)*p로 생각합니다.\n\n<div class=\"content-ad\"></div>\n\n## 구조 손실\n\n당신이 생각할 수도 있겠지만, 이미지를 선형 구조로 처리하는 것이 아니기 때문에 이 아키텍처가 그리 좋지 않다고 생각할 수 있습니다. 저자가 의도적으로 이를 언급하여 이 구조가 의도적임을 나타내려고 노력한 것을 알 수 있습니다.\n\n저희는 이를 증명하기 위해 transformer가 이를 학습할 수 있는 능력을 가지고 있음을 그들의 실험에서 좋은 성능을 보여줌으로써, 그리고 더 중요한 것은 다음 논문의 아키텍처를 통해 확인할 것입니다.\n\n## 결과\n\n<div class=\"content-ad\"></div>\n\n결과에서 주요 결론은 비전 트랜스포머가 작은 데이터셋에서 CNN 기반 모델보다 우월한 성능을 내지 않지만, 큰 데이터셋에서는 접근하거나 능가할 수 있으며 어느 쪽이든 상당히 적은 계산량이 필요하다는 것입니다:\n\n![이미지](/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_1.png)\n\n여기서 JFT-300M 데이터셋(300M개의 이미지)을 사용한 경우, 해당 데이터셋에서 사전 훈련된 ViT 모델들이 ResNet 기반 베이스라인보다 우수한 성능을 보이면서 훈련에 필요한 계산 자원이 상당히 적다는 것을 볼 수 있었습니다. 사용된 큰 비전 트랜스포머인 ViT-Huge(632M 개의 매개변수 및 k=16)는 ResNet 기반 모델에 사용된 계산량의 약 25%만을 사용하고 여전히 우수한 성능을 발휘했습니다. 계산량의 6.8%만을 사용하는 ViT-Large를 사용했을 때에도 성능이 크게 저하되지 않았습니다.\n\n한편, ImageNet-1K(단 1.3M개의 이미지)에서 훈련된 경우 ResNet이 더 우수한 성과를 냈다는 결과도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 마스킹에 의한 자가-지도학습\n\n저자들은 자가-지도학습을 위해 가리기된 패치 예측에 대한 예비 탐구를 수행했습니다. 이는 BERT에서 사용된 가리기된 언어 모델링 작업을 모방하며 (즉, 패치를 가리고 예측하는 것), 자가-지도학습을 위한 것입니다.\n\n자가-지도 사전 훈련을 통해, 작은 ViT-Base/16 모델은 ImageNet에서 79.9%의 정확도를 달성했습니다. 이는 처음부터 훈련하는 것보다 2%의 중요한 향상을 보입니다. 그러나 여전히 지도된 사전 훈련보다 4% 뒤에 있습니다.\n\n# 가리기된 오토인코더 비전 트랜스포머\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_2.png\" />\n\n## 주요 아이디어\n\n비전 트랜스포머 논문에서 볼 수 있듯이, 입력 이미지의 패치를 마스킹하여 사전 훈련의 이득은 일반적인 NLP와 비교했을 때 그다지 중요하지 않았습니다. 반면 일부 파인튜닝 작업에서 마스킹 전 사전 훈련이 우수한 결과를 낼 수 있는 일반 NLP와는 다르게 이득이 크게 나타나지 않았습니다.\n\n본 논문에서는 인코더와 디코더를 포함한 비전 트랜스포머 아키텍처를 제안하며, 이를 마스킹하여 사전 훈련하면 기본 비전 트랜스포머 모델 대비 상당한 개선이 나타납니다(기본 크기의 비전 트랜스포머를 지도 학습하는 것과 비교하여 최대 6%의 향상을 보임).\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_3.png)\n\n다음은 샘플(입력, 출력, 실제 레이블)입니다. 입력을 재구성하면서 누락된 패치를 채우려고 시도한 오토인코더입니다.\n\n## 아키텍처\n\n그들의 인코더는 이전에 설명한 일반적인 비전 트랜스포머 인코더입니다. 교육 및 추론에서는 \"관측된\" 패치만 사용합니다.\n\n\n<div class=\"content-ad\"></div>\n\n한편, 그들의 디코더는 보통 비전 트랜스포머 인코더와 동일하지만 다음을 사용합니다:\n\n- 누락된 패치를 위한 마스크된 토큰 벡터\n- 알려진 패치를 위한 인코더 출력 벡터\n\n따라서 누락된 패치가 있는 이미지 [ [ A, B, X], [C, X, X], [X, D, E]]에서 X는 누락된 패치를 나타냅니다. 디코더는 패치 벡터 시퀀스를 가져와야 합니다 [Enc(A), Enc(B), Vec(X), Vec(X), Vec(X), Enc(D), Enc(E)]. Enc는 패치 벡터가 주어졌을 때 인코더 출력 벡터를 반환하고 X는 누락된 토큰을 나타내는 벡터입니다.\n\n디코더의 마지막 레이어는 비전 트랜스포머 인코더에서 생성된 문맥 임베딩을 패치 크기와 동일한 길이의 벡터로 매핑하는 선형 레이어입니다. 손실 함수는 오차 제곱을 사용하는 평균 제곱 오차입니다. 이 손실 함수에서 우리는 마스크된 토큰으로 인한 디코더 예측만 고려하며 현재 존재하는 토큰에 해당하는 예측은 무시합니다 (예: Dec(A), Dec(B), Dec(C) 등).\n\n<div class=\"content-ad\"></div>\n\n## 최종 설명 및 예시\n\n저자들이 이미지의 패치 중 약 75%를 가리는 것을 제안한다는 것이 놀라울 수도 있습니다. 반면 BERT는 단어의 약 15%만 가리게 됩니다. 그들은 다음과 같이 이를 정당화합니다:\n\n스스로 해보고 싶으신가요? NielsRogge의 데모 노트북을 확인해보세요.\n\n여기까지 입니다. 우리는 컴퓨터 비전 세계로 일반화되는 기본 트랜스포머 모델을 이해하기 위한 여정을 함께해 왔습니다. 이 내용이 명확하고 통찰력 있으며 여러분의 시간을 가치 있게 보내게 되었기를 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n참고 자료:\n\n[1] Dosovitskiy, A. et al. (2021) 'An image is worth 16x16 words: Transformers for image recognition at scale', arXiv.org. [온라인] Available at: https://arxiv.org/abs/2010.11929 (방문 날짜: 2024년 6월 28일).\n\n[2] He, K. et al. (2021) 'Masked autoencoders are scalable vision learners', arXiv.org. [온라인] Available at: https://arxiv.org/abs/2111.06377 (방문 날짜: 2024년 6월 28일).","ogImage":{"url":"/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_0.png"},"coverImage":"/assets/img/2024-06-30-FromVisionTransformerstoMaskedAutoencodersin5Minutes_0.png","tag":["Tech"],"readingTime":6},{"title":"라즈베리파이에서 x86_64부터 ARM64까지 크로스 아키텍처 도커 배포 방법","description":"","date":"2024-06-30 19:06","slug":"2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi","content":"\n\n애플리케이션을 일관된 환경에서 다양한 아키텍처로 배포하는 것은 컨테이너화에서 처음으로 겪은 중요한 도전 중 하나였어요. 이 글에서는 x86_64 머신에서 Docker 이미지를 빌드하고 ARM64 라즈베리 파이에서 실행하는 경험을 공유하려고 해요. 이 여정은 Docker Buildx를 사용하고 이미지를 전송하며 cron과 함께 Python 스크립트를 실행하도록 컨테이너를 구성하는 과정을 포함하고 있답니다.\n\n여기서는 KISS 원리(Keep It Simple, Stupid)를 준수하고자 하며 관련된 코드에 집중하기로 하고 불필요한 설명은 건너뛸 거예요. 시스템과 필수 구성 요소가 최신 상태임을 전제로 하고 업데이트는 생략할 거에요.\n\n# 1. Docker Buildx 설정\n\n```js\ndocker buildx install\ndocker buildx create --use\n```\n\n<div class=\"content-ad\"></div>\n\n# 2. ARM64용 도커 이미지 빌드하기\n\n```js\ndocker buildx build --platform linux/arm64 -t <my-python-app> --load .\n```\n\n# 3. 이미지 내보내고 전송하기\n\n```js\ndocker save <my-python-app> -o <my-python-app>.tar\nsudo scp <my-python-app>.tar pi@raspberrypi:/home/pi/\n```\n\n<div class=\"content-ad\"></div>\n\n이 예시에서 사용자 이름은 pi입니다. 여러분의 자격 증명으로 교체해 주세요\n\n## 4. 라즈베리 파이에 이미지 로드하기\n\n```js\ndocker load -i <나의-파이썬-앱>.tar\n```\n\n## 5. 특권 플래그를 사용하여 컨테이너 실행하기\n\n<div class=\"content-ad\"></div>\n\n컨테이너를 실행하려면 여러 속성을 지정해야 했어요. 예를 들어, 환경 변수를 포함시키고 호스트와 컨테이너 간 데이터 공유를 위해 폴더를 마운트했어요. 또한 반드시 --privileged 플래그를 설정해야 했어요. 그렇지 않으면 컨테이너가 제대로 작동하지 않았어요.\n\n```js\ndocker run -d \\\n  --name <name> \\\n  --platform linux/arm64 \\\n  -e MY_ENV_VAR=value\\\n  --privileged \\\n  --mount type=bind,source=<path on raspberry>,target=<path inside container> \\\n  <my-python-app>\n```\n\n# 6. 크론 작업 설정\n\n크론 작업이 제대로 실행되려면 환경 변수가 crontab 파일에 정의되어 있고 Python 인터프리터의 전체 경로가 지정되어 있어야 했어요.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 환경 변수 정의\nMY_ENV_VAR=value\n\n# m h  dom mon dow   command\n* * * * * /usr/local/bin/python /app/my_script.py >> /var/log/cron.log 2>&1\n```\n\n주된 문제는 플랫폼을 (--platform) 지정하는 것, --privileged 플래그를 설정하는 것, 그리고 환경 변수가 cron 파일에 올바르게 정의되는 것이었습니다. 이 기사가 누군가에게 도움이 되어 도커와 라즈베리 파이를 사용해 실험하는 데 시간을 절약할 수 있기를 바랍니다. 즐거운 하루 되세요! :)","ogImage":{"url":"/assets/img/2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-30-Cross-ArchitectureDockerDeploymentFromx86_64toARM64onRaspberryPi_0.png","tag":["Tech"],"readingTime":2},{"title":"슈퍼휴먼의 시대 AI와 로봇이 우리의 생산성을 폭발적으로 향상시키는 방법","description":"","date":"2024-06-30 19:06","slug":"2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity","content":"\n\n안녕하세요, 저는 미래를 모습을 만들어가는 최신 기술을 탐험하는 것에 열정을 가진 소프트웨어 엔지니어인 야쉬입니다. 웹3과 인공지능의 흥미로운 영역을 탐험하는 호기심 많은 마음으로, 인간-인공지능 협력의 변혁적인 힘에 대한 제 생각을 나누어 주는 것에 기쁨을 느낍니다.\n\n그럼 시작해볼까요?\n\n우리가 이 여정을 시작함에 따라, 인공지능과 로봇공학은 우리의 능력을 증강시키고 전례없는 생산성과 효율성을 끌어올릴 준비가 되어 있습니다. 그들의 잠재력을 활용하여 우리는 더 적은 시간에 더 많은 것을 더 정확하게 달성할 수 있을 것입니다. 정밀함과 정확성을 갖춘 상태로 두 배 많은 것을 절반의 시간에 달성할 수 있는 능력을 상상해보세요. 생산성의 미래가 여기 있으며, 이는 인간의 창의력과 기술적 발전의 융합에 의해 이루어졌습니다.\n\n![이미지](/assets/img/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity_0.png)\n\n<div class=\"content-ad\"></div>\n\n인간의 잠재력 향상:\n인간과 AI의 협업 미래는 엄청난 약속을 품고 있습니다. 두 가지의 강점을 활용하여 우리는 다음을 달성할 수 있습니다:\n\n- 생산성과 효율성을 증가시키다\n- 의사 결정 및 문제 해결 능력 강화\n- 건강 결과와 삶의 질 향상\n- 혁신과 기업가 정신 육성\n- 교육 및 기술 개발을 위한 새로운 길 만들기\n\n미래를 항해하며:\n이 여정에 착수할 때, 이러한 기술적 발전과 함께 오는 도전과 책임을 인식하는 것이 중요합니다. 우리는 다음 사항을 우선적으로 고려해야 합니다:\n\n- 윤리적 AI 개발 및 배포\n- 데이터 개인 정보 보호와 보안\n- 노동 인력 재훈련과 업스킬링\n- 기술 및 그 혜택에 대한 포용적 접근\n\n<div class=\"content-ad\"></div>\n\n대화에 참여해 주셔서 감사합니다 - 아래 댓글에 생산성의 미래에 대한 생각을 공유해주세요. 인간과 AI의 협업 가능성을 함께 탐험해봐요!\n\n계속해서 주목해 주세요 - 저의 블로그를 구독하시면 Web3, AI 및 기술의 미래에 대한 더 많은 통찰력을 얻을 수 있습니다. 함께 미래를 만들어 나가요!\n\n- 야시 파틸","ogImage":{"url":"/assets/img/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity_0.png"},"coverImage":"/assets/img/2024-06-30-UnlockingtheSuperhumanHowAIandRoboticsWillUnleashOurProductivity_0.png","tag":["Tech"],"readingTime":2},{"title":"직접 해보는 학습의 힘 DIY 교육의 효과","description":"","date":"2024-06-30 19:05","slug":"2024-06-30-Hands-OnLearningThePowerofDIYinEducation","content":"\n\n<img src=\"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_0.png\" />\n\n교과서와 강의가 교육 분야를 지배하는 시대에 조용한 변화가 일고 있습니다. DIY (스스로 해보기) 정신에 힘입어 손으로 배우는 것이 학생들이 정보를 학습하고 유지하는 방식을 변화시키고 있습니다. 이 방식은 단순히 매료되는 것뿐만 아니라, 빠르게 변화하는 세계에 대비하여 학생들을 준비시켜줍니다.\n\n화면 뒤에서 : 과학\n\n연구 결과에 따르면, 손으로 배우는 경험은 여러 뇌 영역을 활성화시켜 신경 연결을 강화하고 학습 능력을 향상시킵니다. 학생들이 DIY 프로젝트에 참여하면 문제 해결 능력, 비판적 사고, 창의력을 발전시키는데, 이는 21세기 성공에 필수적인 능력들입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_1.png\" />\n\n다음 몇 가지를 소개해 드립니다:\n\n- STEM 교육: 다리 건설, 보조 장치 디자인, 또는 태양열 자동차 제작과 같은 DIY 프로젝트를 통해 학생들은 물리학, 공학 및 수학의 복잡한 개념을 이해할 수 있습니다.\n- 언어 예술: 학생들은 자신만의 책, 만화, 또는 대본을 만들면서 글쓰기, 편집, 그리고 스토리텔링 기술을 발전시킬 수 있습니다.\n- 환경 과학: 조랑말집 건설, 테라리움 제작, 또는 재활용 시스템 디자인과 같은 DIY 프로젝트는 지속가능성과 보전에 대한 감사心을 육성합니다.\n\n\"왜\" : 교육에서 DIY의 혜택\n\n<div class=\"content-ad\"></div>\n\n교육과정에 DIY 프로젝트를 통합함으로써 학생들은 교실 밖으로 계속 이어지는 다양한 혜택을 누릴 수 있습니다. 학업 성취도 향상부터 창의력과 비판적 사고 능력 향상까지, 교육 분야에서 DIY의 장점은 다양하고 유효합니다. 학생들이 실습 학습을 채택함으로써, 학업, 직업, 그리고 삶에서 성공을 위해 준비가 되는 중요한 기술을 개발할 수 있습니다.\n\n어떻게?\n\n- 참여 증가: 실습 학습은 학생 참여와 동기부여를 촉진합니다.\n- 기억력 향상: DIY 프로젝트는 학생들이 개념을 더 효과적으로 기억하게 도와줍니다.\n- 소프트 스킬 개발: 협력, 커뮤니케이션, 문제 해결 능력은 DIY 활동을 통해 향상됩니다.\n- 창의성 강화: 학생들은 창의적인 해결책을 개발하기 위해 상상력을 발휘합니다.\n- 미래를 위한 준비: DIY 교육은 지속 가능한 에너지, 로봇공학, 생명공학과 같은 떠오르는 분야에서의 경력을 위한 학생들을 준비합니다.\n\n![Hands-On Learning: The Power of DIY in Education](/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_2.png)\n\n<div class=\"content-ad\"></div>\n\n오오... 증거들! 성공 스토리\n\n- 메이커 운동: 이 세계적인 현상은 학교와 지역사회가 DIY 교육을 채택하도록 영감을 주어 학생들의 참여와 혁신이 증가하도록 이끌었습니다.\n- 프로젝트 기반 학습: 뉴욕시 교육부의 iSchool과 같은 학교들은 DIY 프로젝트를 도입하여 학업 성취 및 학생 만족도가 향상되었습니다.\n- MIT의 Fab Lab: 이 유명한 프로그램은 학생들이 혁신적인 프로젝트를 설계하고 구축할 수 있게 하여 창의성과 기업가정신을 육성했습니다.\n- DIY Girls' 프로그램: 이 이니셔티브는 손잡이 프로젝트를 통해 과학, 기술, 공학, 수학(STEM) 분야를 추구하도록 젊은 여자 아이들을 격려하여 자신감과 학업 성취도가 증가했습니다.\n- Cardboard Challenge: 이 세계적인 대회는 카드보드를 사용하여 혁신적인 프로젝트를 만들도록 학생들에 영감을 주어 창의력, 비판적 사고, 문제 해결 능력을 촉진했습니다.\n- STEM 아카데미: 이 프로그램은 DIY 프로젝트를 교육과정에 통합하여 학생 성과가 향상되고 STEM 분야에 대한 관심이 증가했습니다.\n\n교육자이자 혁신가인 Sugata Mitra는 “학습의 미래는 정보 전달이 아니라 발견을 촉진하는 것이다”라고 말합니다. DIY 프로젝트를 통한 실습 학습은 교육을 혁신하는 강력한 방법을 제공합니다. 이 방법을 수용함으로써, 학생들이 창의적인 문제 해결사, 비판적 사고가 필요한 사람, 혁신가가 되도록 돕을 수 있습니다.\n\nDIY 세계를 탐험하려면 TinQ를 다운로드하세요 🏹","ogImage":{"url":"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_0.png"},"coverImage":"/assets/img/2024-06-30-Hands-OnLearningThePowerofDIYinEducation_0.png","tag":["Tech"],"readingTime":3},{"title":"Arduino로 퀀텀 컴퓨팅 구현하기 가이드 및 팁","description":"","date":"2024-06-30 19:04","slug":"2024-06-30-QuantumComputingonArduino","content":"\n\n![이미지](https://miro.medium.com/v2/resize:fit:1000/0*fA_-0zuJ81UEVDTs.gif)\n\n테크 자이언트들이 수십억 달러를 양자 컴퓨팅에 투자하고 초전도 회로와 저온 냉각 시스템에 거액을 쓰는 세상에서, 나는 약간 다른 방법을 택했습니다. Arduino Uno(실제로 훨씬 저렴한 Elegoo Uno), 손에 꼽을만큼의 LED, 그리고 양자 지배력에 대한 끝없는 열망으로 무장한 채, 저는 고급스러운 양자 컴퓨터를 부러워할 Arduino 양자 에뮬레이터를 만들었습니다.\n\n여기, Arduino 양자 컴퓨터를 소개합니다. 7개의 큐빗으로 무장한 본격적인 양자 계산의 강자이며, 손바닥에 들어맞는 크기로 실내 온도에서 작동합니다. 저기, 희석 냉동고야, 너도 이거 같아라!\n\n![이미지](/assets/img/2024-06-30-QuantumComputingonArduino_0.png)\n\n<div class=\"content-ad\"></div>\n\n지금, 아마 “그런데 구글의 Sycamore 프로세서는 53큐빗을 가지고 있지 않나요? IBM의 최신 양자 컴퓨터는 433큐빗을 자랑하지 않나요?” 라고 생각하실 수도 있습니다. 물론, 만약에 기술적으로 모든 것에 대해 깊이 이해하고 싶다면 말이죠. 하지만 여기 한 가지 묻고 싶은 게 있어요: 그들의 양자 컴퓨터가 LED를 깜박일 수 있나요? 제 생각에는 안 될 것 같네요.\n\n우리의 활기찬 아두이노 양자 에뮬레이터는 여러분이 즐겨 사용하는 모든 양자 게이트를 지원해요: Hadamard, CNOT, X, Y, S, T 그리고 Z. 심지어 GHZ 상태를 “양자 얽힘” 이라고 매우 느리게 말할 때보다 빠르게 준비할 수 있답니다.\n\n```js\nH(0);  \nfor(int i = 0; i < NUM_QUBITS - 1; i++) {\n  CX(i,i+1);\n}\n```\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1000/0*U2A8oH-Ril25vd52.gif\" />\n\n<div class=\"content-ad\"></div>\n\n가장 멋진 부분은 뭘까요? 다른 양자 컴퓨터들은 박사 학위를 가진 물리학자 팀이 운영해야하는 반면, 우리의 아두이노 양자 에뮬레이터는 C++의 기본 이해와 실제 양자 역학에 대한 완전한 무관심만 있으면 누구나 프로그래밍할 수 있습니다.\n\n그치만, 더할 나위 없이 좋은 소식이 있습니다! 다른 양자 컴퓨터들과 달리, 외부 간섭으로부터 격리되어야 하는 다른 양자 컴퓨터와 달리, 우리의 아두이노 양자 컴퓨터는 잡음을 필요로 합니다. 사실, 그것은 연결되지 않은 핀에서 발생하는 아날로그 잡음을 사용하여 난수 생성기를 시작합니다. 이것은 결함이 아니라 기능입니다!\n\n```js\nrandomSeed(analogRead(0));\n```\n\n지금, 여러분이 생각할 수 있는 것을 알아요. \"이것은 혁명적이네요! 비용은 얼마나 드나요?\" 잘 준비되세요. 다른 양자 컴퓨터가 수백만 달러에 이르는 반면, 여러분은 저렴한 가격으로 이 양자 파워하우스를 약 25달러(또는 더 저렴한 Elegoo 포함 시 10달러)에 제작할 수 있습니다. 네, 좋은 식사 비용으로 양자 컴퓨팅 혁명에 함께 참여할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n요약하자면, 다른 연구자들이 대수적으로 큰 숫자를 인수분해하거나 복잡한 양자 시스템을 시뮬레이션하는 등의 사소한 문제에 시간을 낭비하는 도중에 우리는 여기서 5볼트로 동작하는 LED를 중첩시킬 것입니다. 양자 컴퓨팅의 미래는 이미 여기에 있고, 그것은 5볼트로 운영됩니다.\n\n코드는 오픈 소스이며 아파치 라이선스(https://github.com/)하에 제공됩니다.\n\n또한 내 커모도어64 양자 에뮬레이터도 확인해보세요.\n\n면책사항: 이 양자 에뮬레이터는 실제로 클래식 컴퓨터보다 빠르게 어떤 실제 세계 문제를 해결할 수 없을 수도 있습니다. 그러나, 다른 대부분의 양자 컴퓨터도 여전히 그렇지 않으니 걱정하지 마세요!","ogImage":{"url":"/assets/img/2024-06-30-QuantumComputingonArduino_0.png"},"coverImage":"/assets/img/2024-06-30-QuantumComputingonArduino_0.png","tag":["Tech"],"readingTime":2},{"title":"배 만들기 - VI 제6편","description":"","date":"2024-06-30 19:02","slug":"2024-06-30-BuildingaShipVI","content":"\n\n우리가 선체를 건설하기로 한 모델은 CA Thayer입니다. 여기에서 선도도와 오프셋 표를 찾을 수 있습니다. 이 페이지에서 발표 자료를 찾을 수 있습니다. 2, 3, 4페이지의 슬라이드를 살펴보세요. 편한 포맷으로 다운로드하세요. 이 세 가지 자료는 선체를 건설하는 데 필요하지만, 나머지 자료도 유용할 수 있습니다(만약 전체 선박을 건설할 계획이 있다면). 이미지를 출력하고, 2와 3번 이미지를 가운데에서 합치세요(수직적인 간격 없이 - 아래 참조).\n\n![이미지1](/assets/img/2024-06-30-BuildingaShipVI_0.png)\n![이미지2](/assets/img/2024-06-30-BuildingaShipVI_1.png)\n\n이렇게 합치세요:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-30-BuildingaShipVI_2.png\" />\n\n[팁: 이 작업은 두 이미지를 인쇄하면 훨씬 쉬워집니다. 또한 인쇄하면 물리적인 계획을 확인할 수 있습니다]. 이제 이 컬렉션에 stationlines 플롯 + 오프셋 테이블을 추가하고 시작할 수 있습니다. 오프셋 테이블을 (물론 수동으로) Excel과 같은 편집 가능 / 조작 가능한 형식으로 복사하세요. 추가 단계와 스케일링에 대한 가치 있는 자료가 될 것입니다.\n\n<img src=\"/assets/img/2024-06-30-BuildingaShipVI_3.png\" />\n\nFigure 4에 있는 오프셋 테이블에 주의를 기울이면: 최상단 행 (STATIONS로 레이블이 지정됨)은 앞부터 뒤로의 스테이션 라인 번호를 매깁니다. 가장 왼쪽 열은 킬(kiel)로부터의 워터라인의 높이를 나타냅니다. Figure 3에 제시된 프로필에서 배를 보면, 선체가 X-Z 평면(화면이 X-Z 평면인)의 X축을 따라 배치됩니다. 이 경우, 선체는 Y축으로 돌출됩니다(화면 평면 내부와 외부로). 이를 염두에 둔 채로 오프셋 테이블을 살펴보세요. 각 행은 Z값에 해당합니다. 각 열은 X값에 해당합니다. 각 셀의 숫자는 피트-인치-8분의 1인치 (17-5-2는 17ft + 5인치 + 2/8 또는 1/4인치를 의미)의 Y 오프셋(돌출)입니다. 모형 제작 목적으로는 피트-인치 숫자만 채용해도 충분합니다. 세 번째 숫자가 4라면 인치를 하나 더 올립니다(또는 하지 않고 완전히 무시합니다).\n\n<div class=\"content-ad\"></div>\n\n이제 내가 만든 엑셀 시트로 갑니다. 다섯 개의 숫자 그룹이 있습니다 - 즉, 서투르게 서식이 되어 있는 다섯 개의 테이블이 있습니다. 첫 번째 테이블은 소수점을 건너뛰고 오프셋 테이블의 복사본입니다. 두 번째는 피트만, 그리고 세 번째는 인치만 포함합니다. 네 번째는 사실상 Y 오프셋이 센티미터로 변환된 것입니다 [저는 인도인이고 메트릭 시스템으로 일하기 때문에요].\n\n마지막은 우리가 스케일을 설정하는 곳입니다. 그 전에 선체의 총 길이를 결정해야 합니다. 제 경우에는 600mm(60cm / 약 2ft)를 선택했습니다. 당신의 배의 총 길이가 M 센티미터이고, 선체의 최종 크기가 N 센티미터인 경우 [제 경우, N = 60], 스케일링 인자 = N / M 입니다. 예를 들면:\n\n선체 길이 (M) = 54 미터\n\n모형 선체의 최종 길이 (N) = 60 센티미터\n\n<div class=\"content-ad\"></div>\n\n**스케일 요소 (SF) = N / M = 0.6 / 50 = 0.012 (12 / 100)**\n\n원본 크기에서 거리(d)가 60cm이라면, 모형에서의 거리는 d x SF로 계산됩니다. 60 x 12 / 100 = 7.2cm이 됩니다.\n\n**테이블 5 단계 1:** 테이블 4에서 모든 값을 선호하는 전체 선체 길이로 줄여주세요.\n\n**테이블 5 단계 2:** 동일한 변환 + 스케일링 요소를 사용하여 Z 값을 모형의 cm로 변환해주세요.\n\n<div class=\"content-ad\"></div>\n\n5번 테이블의 3단계: X축 값을 추론합니다. 이를 위해 먼저 선 데칼을 측정합니다. 이전 단계(2)에서 계산한 원래 높이가 있습니다. 모델의 인쇄된 길이를 Z 높이로 변경한 다음, 원하는 길이에 도달하도록 두 번째 스케일링을 수행합니다. 예를 들어, 출력물의 높이가 5cm이고 원래 높이가 약 20 ft (600cm)이면, 각 cm이 약 4ft (120 cm)이 되고, 각 mm이 원본에서 12cm임을 알 수 있습니다. 다음으로 역으로 변환하고자 하는 원래 길이를 cm 단위로 표시하는 역염 단면 사이 간격을 측정합니다. 이것이 X축을 따라 이동하는 거리/길이입니다. 위에서 계산된 스케일 인수를 사용하여 이 원래 길이에서 원하는 길이로의 두 번째 변환/스케일링을 수행합니다(Y축에 대한). 참조된 엑셀 시트의 5번 테이블에는 이러한 모든 계산이 이미 수행되어 있습니다. 그러나 정밀도와 신뢰의 성향에 따라 직접 수학을 해야 합니다.\n\n이것은 작업의 역량 부분입니다. 다음은 키를 설치합니다(VII부).\n\n그때까지 안녕!","ogImage":{"url":"/assets/img/2024-06-30-BuildingaShipVI_0.png"},"coverImage":"/assets/img/2024-06-30-BuildingaShipVI_0.png","tag":["Tech"],"readingTime":3}],"page":"1","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}