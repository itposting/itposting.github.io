{"pageProps":{"posts":[{"title":"비판적 사고 AI를 뛰어넘는 보이지 않는 위협","description":"","date":"2024-06-22 19:45","slug":"2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI","content":"\n\n## 뉴스\n\n인공지능이 그렇게 할 기회조차 없이, 인류의 멸망은 비판적 사고의 죽음으로 직접 초래될 것입니다.\n\n세대를 거듭할수록 우리의 독해 능력이 점차 줄어들고 있습니다. 할당된 텍스트를 읽는 시간은 적고, 그것을 이해하는 것은 더더욱 적으며, 더 나은 방식으로 분석하는 능력이 부족합니다. 이러한 추세가 계속된다면 우리 사회의 기본 구조가 침식되는 결과를 초래할 것입니다.\n\n우리는 부분적으로 만들어진 제품들의 시대를 경험하고 있으며, 매체에 담긴 바이트들의 시대이기도 합니다. 그 결과, 우리의 주의력과 본질이 커다란 복잡한 텍스트를 이해하는 능력은 줄어들거나 사라지고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n우리가 전부 소장하던 것을 한눈에 다시 살펴봅니다. 이제 몇 초 동안만 지속되는 것을 보려고 합니다.\n\n오늘날 사람들은 다양한 기술의 발전을 통해 지식을 얻었지만, 그 반대로 사고 과정이 분산되었습니다. 세상이 우리의 감각을 완전히 공격하지 않는 조용한 순간을 찾기가 어렵습니다.\n\n소셜 미디어 플랫폼을 넘어오는 헤드라인이나 게시물의 관련성은 감정이 아닌 이성을 자극하여 가짜 뉴스 현실에 노출시킵니다. 사람들은 댓글을 보지 않고 센세이션 투의 제목과 간단한 설명에만 반응하여 게시물을 홍보합니다.\n\n관련성, 일화, 세부 사항에 대한 열등 의식은 더 이상 옹호되지 않습니다. 관련 요인은 사실적인 것에서 감정적이고 원시적 충동으로 전환되었습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Critical Thinking](/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_0.png)\n\n만약 읽기 이해력이 없다면, 의미 있는 방식으로 읽거나 비판적으로 사고하거나 판단할 수 없습니다. 비판적 평가, 다양한 의견 수용, 삼닠적 추론, 그리고 증거 중심적 방법 수용과 같은 이해력 있는 기술들이 사라지고 있습니다.\n\n증거에 의존하는 대신에, 우리의 믿음은 종말론적인 이야기와 원하는 것만 보려는 원칙에 의해 가솔린을 붓게 됩니다. 우리는 정보를 얻지만 대부분 소화하지 못합니다.\n\n이는 정보화된 국민의 기반이 되는 데 도움이 되지 않습니다 - 이는 건강한 민주주의의 기능에 핵심적입니다.\n\n\n<div class=\"content-ad\"></div>\n\n그러므로 '당신과 나 같은 사람들은 독해 방법을 전혀 모르는 것 같다'는 주장은 과장일 수 있습니다. 사실, 우리는 독해를 통해 전통적으로 정의된 인쇄 매체를 더 깊이 분석하는 방법을 기억하지 못하는 것으로 보입니다.\n\n'원시적 사고는 여전히 존재하지만 일상생활에서는 실천되지 않는다'라고 말할 수 있습니다. 이것은 내재적 재능을 갖고 있지만 적용하지 못하는 지식의 미토콘드리아 풍부함입니다.\n\nYouTube에서 정치 콘텐츠를 공부하고 분석할 때 상당히 도움이 될 수 있습니다. 우리는 이에 응답합니다.\n\n다른 세계의 의견을 가중치를 두거나 우리의 의견과 일치하지 않는 정보를 찾는 대신, 우리는 우리의 사고와 일치하는 게시물과 기사를 찾는 데 시간을 보냅니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Critical Thinking](/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_1.png)\n\n이런 일이 계속 일어나면 합리적인 대화 대신 소셜 미디어에서의 전체적인 분위기가 우리의 생각을 좌지우지하는 결과를 낳을 수 있습니다. 이것은 '마음이 자신을 운동하지 않기 때문에 더 이상 적극적인 기관이 아니라 지적으로 게으르게 된 것' 때문입니다.\n\n습관적인 독서는 단순히 읽고 쓸 수 있는 능력을 의미하는 것이 아니라 기능적 글쓰기에 대한 숙련 이상의 의미가 있습니다.\n\n교육은 새로운 지식과 다른 사람들의 문화를 풍부하게 해주며 우리가 성장하도록 돕습니다. 책을 읽음으로써 사람들은 새로운 지평을 열 수 있고 이를 통해 다른 삶에 대해 배울 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n따라서, 의미 있는 읽기 연습은 정신적 성장을 촉진하고 주의력, 분석력, 추상적 사고 능력과 같은 더 나은 기능을 제공하는 것으로 이어집니다.\n\n감정 지능을 향상시키는 한 방법은 거친 현실과 픽션을 통해 인간적 경험에서 우리에게 우위를 주는 것입니다. 비평적 읽기에 의해 제안된 사고가 중단되고, 밀접한 독해 연습의 저하로 인한 감정적 성장이 저해되는 것도 능동적으로 이해해야 합니다.\n\n많은 사람들이 ChatGPT 형식으로 최신 기술을 본 지금, 인공지능(AI)이 우리 시대의 가장 큰 위협이라고 말하고 있습니다. 정교한 인공지능 기술은 작업을 자동화하고 딥 페이크로 개인을 제어하며 가짜 뉴스를 확대할 수 있습니다.\n\n그러나 AI 시스템은 여전히 사람들에 의해 프로그래밍되고 프로그래머가 제공한 능력을 활용하기 때문에 그러한 시스템으로 남게 됩니다. 현재의 AI는 목표를 갖고 위험할 수 있지만, 능동적이지 않으며 생각하거나 느끼는 능력이 없다는 점을 강조해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_2.png\" />\n\n한편, 비판적인 독해 능력을 없애는 것은 실제로 수많은 사람들의 감성적인 사고를 죽이는 것입니다. 창의적인 마음을 가진 이들이 실현하고, 건설하고, 통치하며, 선악을 운영하는 기술을 창출합니다.\n\n윤리적인 결정을 내리는 인지 시스템은 전 세계에 영향을 미치며 중요한 역할을 합니다. 이러한 비판적 사고력의 상실은 세계를 이해하고 다양한 개념과 이론을 이해하는 데 필요한 기본적인 능력의 감퇴를 초래하며, 존재의 위협이 됩니다.\n\n또한, 인간적인 접근은 현재 알고리즘으로 대체될 수 없습니다. 그러나 우리는 천년 동안 연마된 비판적 독해와 사고 기술에 대한 현재 지식을 포기해야 할까요? 그렇다면 이에 대응할 알고리즘도 필요하지 않을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n개인마다 그 정보를 전파하기 전에 심사숙고하는 비평적 사고 독자가 되기를 염원할 수 있습니다. \n\n우리는 현대 미디어 뿐만 아니라 다른 형태의 미디어에서도 의도적인 비평적 독해 능력을 발휘할 수 있습니다. 그러나 개인 요인과 그들의 결정의 역할을 강조하지 않는 것은 심각한 분석을 만들어내지 않습니다.\n\n독자의 부재나 독해능력의 감소가 단순한 현상으로 설명될 수 없습니다.\n\n이것을 다음과 같은 용어로 설명할 수 없습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![Critical Thinking: The Unseen Threat Outpacing AI](/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_3.png)\n\n또한, 한 세대가 세상을 방치한다는 것은 양자나온(Qanon) 같은 엉망인 주장에 빠진 젊은이부터 노인이까지 방대한 인구를 설명하지 못합니다.\n\n그러나 이 두 가지 단순화된 접근 방식은 논의 중인 과정의 복잡성을 이해하는 방법을 제공하지 않습니다. 현대의 미디어 환경에서 디지털 플랫폼이 우세한 플랫폼이라는 사실을 고려하지 않을 수 없습니다.\n\n이러한 기술을 통해 정보 재앙이 발생하며, 구체적 자료가 집중적으로 공유되는 동안 주의력이 분산되고 소비를 위해 최적화된 간결한 정보의 전달을 편향시키는 바이어스가 포함됩니다. 자동화 결정 과정은 충격적인 제목이 인사이트 있는 토론보다 더 많이 공유되게 합니다.\n\n\n<div class=\"content-ad\"></div>\n\n소셜 네트워크는 특히 강한 거짓 정보가 올라오는 완벽한 장소입니다. 단순한 접근법과 현실적이고 복잡한 아이디어를 둘러싼 과대포장으로 인해 발생하는 소음으로 인해 이러한 아이디어들은 듣기 어렵게 되어 있습니다.\n\n소셜 네트워크에서의 현대적인 미디어 문화는 포괄적이고 지속적인 심도 있는 독해와는 정반대로 인식을 형성하고 있습니다. 너무 많은 자극이 존재하여 주의를 산만하게 하며 집중력을 방해합니다.\n\n![이미지](/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_4.png)\n\n우리는 앱과 사이트를 전환하며 여러 가지 개념을 알아가기 힘들고, 결국 거의 아무것도 이해하지 못합니다. 이는 우리의 중점이 다른 기사로 넘어가기만 하는 데 집중되어 특정 주제에 집중하지 않는다는 것을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n앱과 사이트의 디자인은 우리의 심리적 취약점을 의도적으로 이용합니다. 업데이트를 위해 새로 고치고, 자동 재생을 통해 새로움에 노출시키면서 뇌는 실제로는 새로운 컨텐츠가 없는데도 새로운 것을 생각하게 속입니다.\n\n알림은 외부 개념의 갑작스러운 표시로 우리의 생각에 끼워 맞춥니다. 가끔은 clickbait 헤드라인이 호기심을 끌기 위해 감정을 이용하는데, 이는 독자들을 오도합니다.\n\n알고리즘은 어떤 콘텐츠가 우리를 밤새 깨어 있게 만드는지 정확히 알고 있습니다. 곧 우리의 정신적 반사 반응은 산만하게 되어, 마치 파블로프의 개가 종소리를 듣고 침을 흘리는 것처럼 조건이 맞춰지죠.\n\n더 나쁜 것은, 이 환경이 사용자가 가능한 한 오랫동안 사이트에 집중하도록 설계된 매혹적인 그래픽 인터페이스 내에 허위 콘텐츠를 감추고 있다는 겁니다.\n\n<div class=\"content-ad\"></div>\n\n매일 사람들은 초기에는 지루하고 흥미롭지 않아 보이는 비디오를 관찰하기 위해 시청합니다. 사람들은 얕은 콘텐츠를 듣기 위해 자신들의 반죽되지 않은 속보를 밀어주는 아름다운 사람들을 위해 기꺼이 시간을 할애합니다.\n\n게시판과 팔로워들의 화면은 도둑놈처럼 참을성 없게 소중한 집중력을 훔쳐갑니다. 대중의 주의는 현명하게 조작할 수 있는 개인에게 이로운 상품으로 변질됩니다.\n\n반면 중요한 정보가 담긴 긴 글들은 주목을 얻기 위해 투쟁해야 합니다.\n\n![크리티컬 씽킹과 보이지 않는 위협, AI를 앞서나가는](/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_5.png)\n\n<div class=\"content-ad\"></div>\n\n사람들을 중독성 있는 인터페이스로 유인하려는 계획은 없지만, 교육적인 토론에 도움이 되는 것들을 만들겠다고 합니다. 알고리즘들이 하는 것처럼 독자들의 기권을 무시하지 않으려고 합니다.\n\n맞아요, clickbait으로 더 많은 돈을 벌기를 원하는 것이 아니라 정보를 전달하고자 합니다. 그럼에도 불구하고, 그러한 집중력이 필요한 독해 환경은 끝없는 자극적 자극을 흡수하면서 포스트인더스트리얼 인식 기본을 혼란스럽게 만듭니다.\n\n안타깝게도, 깊이 파고들기는 시간이 많이 소요되기 때문에 종종 가치가 없어 보입니다. 스캐밍하고 스크롤링과는 달리 지식을 마구 소비하는 연도 동안 운동이 된 것과는 다릅니다.\n\n앱 및 웹사이트의 디자인은 우리의 심리적 약점을 의도적으로 이용합니다. 새롭게 즐거워지고 업데이트되는 느낌이 들고, 자동 재생은 끊임없이 화면을 바꾸어 우리의 뇌가 완전히 새로운 것으로 생각하게 만듭니다.\n\n<div class=\"content-ad\"></div>\n\n알림은 외부 신호를 통해 내부 사고과정에 집중을 방해합니다. 사람들은 종종 실제 관심보다는 감정에 기반한 헤드라인에 반응하며, 클릭베이트는 호기심을 유혹하기 위해 감정을 겨냥합니다.\n\n알고리즘은 우리가 무엇이 우리를 끌어들이는지를 학습하도록 독특하게 조정되어 있다는 것이 밝혀졌습니다. 그리고 아주 짧은 시간 안에 우리의 마음은 주의를 산만하게 하도록 적응되며, 마치 파블로프의 개처럼 조건이 되어 있습니다.\n\n한 세대가 다른 세대에게 자신들의 무지를 강조함으로써 비판적 사고와 독해능력을 배제한다는 것은 부당한 일입니다.\n\n이러한 것들은 다시 익숙해지는 과정으로 살아나게 할 수 있습니다. 이에 따라 깊은 개인 독서와 의미 있는 분석에 대한 욕망은 우리 안의 가장 좋은 부분 - 인간의 마음과 영혼을 보호합니다.\n\n<div class=\"content-ad\"></div>\n\n## 나를 팔로우해주시는 이 모든 멋진 분들께 감사드립니다!!!\n\n## 여러분의 지원 덕분에 더 많은 글쓰기에 동기부여 받고 자신감을 얻게 되었어요. 감사합니다…\n\n드. Cüneyt Yardımcı, Yasemin Yiğit Kuru, Darrin Atkins, Timothy M. Stafford, PhD, Filza Chaudhry, H. Mikel Feilen, 안토니오 프란시스코 교수","ogImage":{"url":"/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_0.png"},"coverImage":"/assets/img/2024-06-22-CriticalThinkingTheUnseenThreatOutpacingAI_0.png","tag":["Tech"],"readingTime":7},{"title":"강화 학습의 비밀을 풀다 Actor-Critic 초보자 가이드","description":"","date":"2024-06-22 19:43","slug":"2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide","content":"\n\n## 이해해야 할 개념:\n\n강화 학습: 시간 차 학습\n\n강화 학습: Q-Learning\n\n딥 Q 학습: 심층 강화 학습 알고리즘\n\n<div class=\"content-ad\"></div>\n\n정책 그라디언트의 직관적인 설명\n\n## Actor-Critic 알고리즘이란 무엇인가요?\n\nActor-Critic은 환경의 피드백에 기반하여 에이전트의 작업을 최적화하는 강화 학습 알고리즘입니다.\n\n![이미지 설명](/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_0.png)\n\n<div class=\"content-ad\"></div>\n\nActor: Actor는 환경을 탐색하여 최적 정책을 학습합니다.\n\nCritic: Critic은 Actor가 취한 각 행동의 가치를 평가하여 그 행동이 더 나은 보상을 가져오는지를 판단하고, Actor에게 취해야 할 최선의 행동을 안내합니다.\n\n그런 다음 Actor는 Critic의 피드백을 사용하여 정책을 조정하고 더 현명한 결정을 내려 전반적인 성능을 향상시킵니다.\n\n![이미지](/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_1.png)\n\n<div class=\"content-ad\"></div>\n\n## Actor-Critic 알고리즘은 어떻게 작동하나요?\n\n![Actor-Critic 알고리즘 이미지](/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_2.png)\n\nActor-Critic 알고리즘은 환경으로부터 입력을 받아와 그 상태를 기반으로 최적의 행동을 결정합니다.\n\n알고리즘의 Actor 구성 요소는 환경으로부터 현재 상태를 입력으로 받아옵니다. 이는 상태에 대한 각 행동의 확률을 출력하는 정책으로 동작하는 신경망을 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n비평가 네트워크는 현재 상태와 Actor의 출력된 액션을 입력으로 받아 이 정보를 사용하여 예상되는 미래 보상, 즉 Q-값을 추정합니다. Q-값은 특정 정책을 따라 특정 상태에서 에이전트가 받을 수 있는 예상 누적 보상을 나타냅니다.\n\n반면에 가치 상태는 특정 상태에서 취한 조치와 관계없이 예상되는 미래 보상을 나타냅니다. 특정 상태에 대한 모든 가능한 조치에 대한 Q-값의 평균으로 계산됩니다.\n\n## Adv. = Q(s,a) — V(s)\n\n이점 함수는 Actor의 정책을 안내하는 데 유용한 정보를 제공하여 최상의 결과로 이끌어지는 행동을 결정하고 정책을 그에 맞게 조정할 수 있도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n결과적으로, 이점 함수는 Actor와 Critic 둘 다에게 역전파되어, 두 구성 요소 모두가 지속적으로 업데이트되고 개선되는 함수를 허용합니다. 이로 인해 액터는 더 나은 결과를 이끄는 결정을 내릴 때 더 효과적해지고, 전반적으로 성능이 향상됩니다. 궁극적으로, Actor-Critic 알고리즘은 기대되는 미래 보상을 최대화하는 최적의 정책을 배웁니다.\n\nActor-Critic 알고리즘은 A2C, ACER, A3C, TRPO, PPO와 같은 다른 알고리즘들의 기초로 삼아진 프레임워크입니다.\n\n## 다양한 Actor-Critic 기반 강화 학습 알고리즘\n\n- A2C- 어드밴티지 Actor Critic: 어드밴티지 Actor-Critic(A2C) 방법의 Critic은 𝑉(𝑠)를 예측하도록 훈련되어, 부트스트래핑을 위해 𝐴(𝑠,𝑎)=𝑄(𝑠,𝑎)−𝑉(𝑠)을 추정하는 데 사용됩니다. Actor는 정책을 업데이트하기 위한 가이던스 신호로 어드밴티지 함수를 사용하여 훈련됩니다.\n- ACER- 경험 재생이 있는 Actor Critic: ACER는 경험 재생을 사용하는 효율적인 액터-크리틱 알고리즘으로, 신뢰 영역 정책 최적화 방법을 사용하여 성능을 향상시킵니다.\n- A3C- 비동기 어드밴티지 Actor Critic: 액터-크리틱 알고리즘의 병렬, 비동기 멀티스레드 구현. 병렬로 여러 에이전트가 각자의 환경에서 훈련을 받아 동시에 상태 공간의 다른 부분을 탐색합니다. 에이전트들은 정책 그레디언트를 계산하고 주기적으로 글로벌 네트워크로 업데이트를 보내거나 종단상태에 도달했을 때 업데이트를 보냅니다. 글로벌 네트워크는 업데이트마다 새로운 가중치를 에이전트들에게 전파하여 공통 정책을 공유할 수 있도록 합니다.\n- TRPO- 신뢰 영역 정책 최적화: Actor-크리틱 알고리즘과 신뢰 영역을 사용하여 정책 업데이트를 제약합니다. 정책 업데이트는 이전 정책과 업데이트된 정책 사이의 KL 발산을 사용하여 측정되며, 각 반복에서 신뢰 영역을 측정하는 데 사용됩니다.\n- PPO- 근접 정책 최적화: 근접 정책 최적화(PPO)는 여러 번의 확률적 그래디언트 상승을 통해 각 정책 업데이트를 수행하는 액터-크리틱 알고리즘에 기반합니다. 각 훈련 에포크에서 너무 큰 정책 업데이트를 피해 정책의 변경을 제한하여 정책의 훈련 안정성을 향상시킵니다.\n\n<div class=\"content-ad\"></div>\n\n## Actor-Critic 알고리즘은 어떤 응용 분야에서 사용되나요?\n\nActor-Critic 알고리즘은 다음과 같은 분야에서 널리 활용됩니다:\n\n- 제조업이나 서비스 산업의 로봇을 위한 제어 시스템,\n- 게임에서 게임 전략을 최적화하는 데 사용됨,\n- 전력 그리드, 자율 주행 차량, 산업 프로세스와 같은 복잡 시스템.\n\n## 코드 구현\n\n<div class=\"content-ad\"></div>\n\n여기에서는 두 개의 신경망을 사용할 것입니다: Actor와 Critic.\n\n![Actor-Critic](/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_3.png)\n\n각 에피소드 단계에서 Actor 네트워크를 사용하여 에이전트는 현재 상태에서 행동을 취하고 다음 상태로 이동하며 환경으로부터 보상을 받습니다. Actor의 신경망은 그 상태에서 각 가능한 행동을 취할 확률을 출력하는 정책으로 작동합니다.\n\n보상과 다음 상태의 추정 가치를 사용하여 이득 함수를 계산하는데, 이는 행동을 취하는 것의 예상 반환값에서 현재 상태의 추정 가치를 뺀 것입니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_4.png)\n\n액터 네트워크를 업데이트하면서 액터 손실을 계산합니다. 이는 취한 행동의 로그 확률의 음수에 이득을 곱한 값입니다.\n\n![image](/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_5.png)\n\n![image](/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_6.png)\n\n\n<div class=\"content-ad\"></div>\n\nA2C는 빠르고 효율적이며 대량의 데이터에서 빠르게 효과적으로 학습할 수 있어요. Actor는 환경을 탐험하고 Critic은 Actor가 취할 수 있는 최상의 행동을 활용하기 위한 피드백을 제공하여 시간에 따라 최적 정책을 달성하려고 노력해요.\n\nA2C는 연속된 행동 공간에서 잘 작동하지만 이산적인 행동 공간에서는 그렇지 않아요. 최적 성능에 대한 하이퍼파라미터에 민감하며 잘못된 하이퍼파라미터는 훈련을 불안정하게 만들 수 있어요.\n\n## 결론:\n\nActor-Critic 알고리즘은 두 가지 구성 요소를 사용해요. Actor는 탐사를 통해 최적 정책을 학습하며 Critic은 Actor의 행동을 평가하여 상태에 대한 최상의 행동을 결정해요. Critic은 향상된 성능을 도출할 피드백을 Actor에게 제공해요. Actor-Critic 알고리즘은 연속적인 행동 공간과 훈련에 대한 하이퍼파라미터에 대해 잘 작동해요. Actor-Critic 모델은 불안정성을 피하기 위해 충분한 실험을 해야 해요.\n\n<div class=\"content-ad\"></div>\n\n## 참고 자료:\n\nREINFORCEMENT LEARNING THROUGH ASYNCHRONOUS ADVANTAGE ACTOR-CRITIC ON A GPU\n\nAsynchronous Methods for Deep Reinforcement Learning\n\n[PDF 바로가기](https://www.davidsilver.uk/wp-content/uploads/2020/03/pg.pdf)\n\n<div class=\"content-ad\"></div>\n\nhttp://rail.eecs.berkeley.edu/deeprlcourse-fa17/f17docs/lecture_5_actor_critic_pdf\n\nhttps://ai.stackexchange.com/questions/7390/what-is-the-difference-between-actor-critic-and-advantage-actor-critic","ogImage":{"url":"/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_0.png"},"coverImage":"/assets/img/2024-06-22-UnlockingtheSecretsofActor-CriticReinforcementLearningABeginnersGuide_0.png","tag":["Tech"],"readingTime":5},{"title":"로봇은 더 똑똑해지고 있을까 로봇 공학에서 인식에 대한 대화","description":"","date":"2024-06-22 19:41","slug":"2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics","content":"\n\n이 기사는 보통 여기서 하는 시리즈와는 별도로 됩니다. 이젠 대화를 나누는 것처럼 얘기하는 걸 좋아합니다 (하지만 전 며칠 동안 계속 말을 할 거에요 ㅋㅋ). 그래서 당신이 좋아하는 음료를 준비하고 로봇과 그들이 얼마나 \"똑똑\"해졌는지에 대해 이야기해봐요.\n\n![로봇](/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_0.png)\n\n지난 달들에 로봇이 놀라운 일들을 하는 비디오를 보셨을 것입니다. 그런 비디오를 보면서 \"와, 이건 놀라워. 이제 로봇들이 이것을 할 수 있나? 그들은 매일 더 똑똑해지고 있어\"라고 생각했을 수 있어요. 예를 들면, Figure 01 인간형 로봇이 물체를 다루는 모습이나 Scythe 로봇이 자율적으로 잔디를 자르는 것 등이 있습니다.\n\n여기서 잠깐 멈추고 로봇의 인식 관점에서 관련 두 가지 문제, 동시 위치 추정 및 지도 작성(SLAM) 그리고 빈 피킹(bin picking)을 바라봅시다.\n\n<div class=\"content-ad\"></div>\n\n## 로봇의 과거와 현재의 인식\n\n우선, 로봇 공학 분야에서 \"인식\"이란 무엇인가요? 모르는 분을 위해 설명드리자면, 로봇의 카메라, LiDAR, 레이더 또는 접촉 센서와 같은 다양한 센서를 사용해 환경을 감지하고 해석하는 능력을 의미합니다. 환경에 대한 유용한 정보를 추출하기 위해 센서 데이터를 수집하고 처리하는 것을 포함합니다.\n\n인식은 로봋의 SLAM에 매우 중요합니다. 다시 말씀드리면, 동시 위치 추정 및 지도 작성(SLAM)은 로봇 공학에서 기본적인 문제입니다. 이는 로봇이 알 수 없는 환경을 탐색하면서 동시에 그 환경의 지도를 작성하고 그 안에서 자신의 위치를 판단하는 것을 의미합니다.\n\n2016년에 Cadena와 다른 저자들은 \"동시 위치 및 지도 작성의 과거, 현재 및 미래: 견고한 인식 시대를 향하여\"라는 과학 논문을 발표했습니다. 그들의 연구에서는 SLAM 분야에서 30년 이상의 작업을 검토하고, 이를 고전적 시대(1986-2004), 알고리즘 분석 시대(2004-2015), 그리고 견고한 인식 시대(2015-현재)로 그룹화했습니다. 각 시대를 간단히 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n고전 시대:\n이것은 Extended Kalman Filters, Rao-Blackwellized Particle Filters 및 최대 우도 추정을 사용하여 SLAM이 불확실성을 처리하는 주요 방법을 소개합니다. 또한 모든 것이 원활하게 작동하고 올바른 데이터 조각을 연결하는 데 필요한 기본 도전에 대해 이야기합니다.이 시대의 SLAM의 두 가지 예는 아래에 나와 있습니다.\n\n![image](/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_1.png)\n\n일반적으로, 첫 번째 제안된 SLAM 시스템은 환경에서 장애물을 감지하고 맵에 표현할 수 있었습니다. 맵핑에 사용된 가장 인기 있는 센서는 초음파 및 LiDAR였습니다.\n\n알고리즘 분석 시대:\n연구자들은 SLAM의 기본 기능인 시간이 지남에 따른 위치 추적이 얼마나 잘되는지, 신뢰할 수 있는지, 그리고 대량의 데이터를 어떻게 처리하는지 등을 조사했습니다. 드문 데이터가 SLAM이 더 빠르고 더 잘 작동하게 하는 것을 발견했습니다. 이때 무료로 사용할 수 있는 주요 SLAM 소프트웨어인 Gmapping 및 ORB-SLAM을 만들기 시작했습니다.\n\n<div class=\"content-ad\"></div>\n\n![그림](/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_2.png)\n\n이전 시대의 기초를 활용하여 이 시대에는 카메라와 다른 시각 센서들이 보다 인기를 끌게 되었으며, \"Visual-SLAM\"이라는 용어가 제안되었습니다. 게다가 커뮤니티는 3D 환경 표현을 이용한 다양한 SLAM 기술을 소개했습니다.\n\n로버스트-인식 시대:\nSLAM 시스템은 단순히 형상을 매핑하는 것을 넘어, 환경에 대한 고수준의 이해를 얻기 위해 기하학적 재구성을 위해 높은 수준의 고려를 합니다. 물체의 의미(의미론)나 관련된 물리학적 측면과 같은 것들을 고려합니다. 당사자가 수행해야 하는 작업에 맞게 로봇이 필요한 세부 사항에 초점을 맞추어 센서 데이터에서 추가 잡음을 걸러내어 로봇이 작업을 성취하는 데 도움을 줍니다. 로봇이 수행해야 할 작업에 따라 맵을 조정합니다.\n\n이 애니메이션 이미지를 자세히 살펴보면 많은 세부 사항을 알 수 있습니다. 장면 속 물체는 환경의 일부로 이해되며, 같은 클래스의 물체는 경계 상자에서 동일한 색으로 레이블이 지정되며, LiDAR 및 레이더의 3D 데이터는 카메라의 2D 이미지와 결합됩니다. 게다가 다양한 물체가 결합되어 장면으로부터 더 많은 정보를 추출하는데 활용됩니다. 마지막 애니메이션 이미지에서와 같이 흰색 차량과 그의 깜박임등, 후방등, 브레이크 라이트 등이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 빈 피킹에서의 인식\n\n빈 피킹은 컴퓨터 비전 및 로봇 공학 분야에서의 기본적인 도전으로 자리 잡고 있습니다. 로봇 팔은 빈(또는 컨테이너)으로부터 다양한 방향의 물체를 효율적으로 잡기 위해 진공 그리퍼, 평행 그리퍼 또는 대체 로봇 도구를 사용하여 센서로 장착되어 있습니다. 이 문제는 Cadena의 논문에 언급되지 않았지만, SLAM의 동일한 연령 그룹이 여기에 적용될 수 있습니다(그리고 이것은 내 의견입니다).\n\n이 문제에 대한 가장 인기 있는 접근 방식 중 하나는 알고리즘 분석 시대부터 출발한 포인트 클라우드(PC) 등록에 기반하고 있습니다. 섭취 아이템의 3D 형태는 미리 알려져 있어야하며, 센서를 사용하여 매번 픽하기 전에 빈을 스캔했습니다. 이 스캔을 통해 3D PC가 생성되었고, 이후 PC 등록 알고리즘으로 전송되었습니다. 이 알고리즘은 섭취된 아이템과 빈의 PC 간에 일치를 찾는 역할을 했습니다. 아래의 애니메이션 이미지가 이 과정을 설명합니다.\n\n이 접근 방식이 그 당시에 작동했지만, 그 한계를 쉽게 이해할 수 있습니다. 예를 들어, 빈당 하나의 아이템 유형만 있어야 한다면, 그렇지 않은 경우에는 빈의 PC와 여러 섭취 아이템을 매칭하는 계산 비용이 막대할 수 있습니다. 게다가, 이러한 접근 방식은 빠르게 확장되지 않으며, 새로운 아이템을 위해서는 항상 아이템을 스캔하여 3D 형태 표현을 생성해야 합니다(또는 제조사에게 CAD 파일을 요청해야 합니다).\n\n<div class=\"content-ad\"></div>\n\n이들은 여러 종류의 항목이 들어있는 소스 바구니를 비울 수 있습니다. 게다가, 그들의 시스템은 새로운 (시스템이 이전에 본 적이 없는 항목) 항목을 즉시 선택할 수 있을 정도로 광범위한 수준의 일반화를 달성했습니다.\n\n마지막으로, 빠른 확장과 새로운 항목에 적응하는 부분 이외에, 이같은 지각 개선은 \"모든 음식 항목을 선택해 주세요\", \"장난감을 선택해 주세요\", 또는 \"놀 수 있는 항목을 가져다 주세요\"와 같은 다른 인간 수준의 명령을 처리할 수 있도록 합니다. 위의 예에서, 그들의 시스템이 바구니에서 고장난 항목을 선택하는 것을 볼 수 있습니다.\n\n이제 우리가 로봇의 지각 발전에 대해 다루었으니, 이 기사의 가장 흥미로운 부분으로 넘어갈 수 있습니다.\n\n## 로봇의 지각 발전의 영향과 속도\n\n<div class=\"content-ad\"></div>\n\n제가 각 시대의 주요 작품에서 몇 장의 이미지를 넣었는데, 그냥 이 기사를 읽기 쉽게 만들기 위해서 하는 게 아니에요. 고대 시대의 이미지를 보면 환경으로부터의 장애물을 거의 표현하지 못했음을 알 수 있어요. 대부분의 구축된 지도는 2D였고, 환경에서의 3D 장애물을 평평하게 만들었어요. 환경 내의 다양한 물체들은 모두 \"장애물\"로 라벨링되었고, 로봇이 그것들을 피한다면 괜찮았어요.\n\n시각 센서의 발전으로, 알고리즘 분석 시대는 더 많은 3D 맵을 보여주고 환경에 색상을 추가함으로써 지각을 개선했어요. 비록 이것에 대해 언급하지 않았지만, 이 시대는 또한 장면의 동적 부분을 걸러내기 시작했어요. 따라서 2004년부터 2015년까지 가장 큰 차이는 3D 맵의 탐험과 이러한 맵에 색상 정보를 추가한 것이었어요. 여기서 간략하게 설명하고 있지만, 11년간 로봇 지각에서는 발전이 그리 크지 않았다는 점이요.\n\n반면에, 견고한 지각 시대는 다른 두 시대를 무색하게 만들었어요. 여전히 제가 박사 학위 논문 제안을 작성하는 중이던 2016년에 카데나(Cadena)의 작품을 읽었을 때를 기억해요. 그 논문에서, 제 마음에 남는 한 문장을 적었어요:\n\n생각해보면, 이야기가 너무 맞죠. 2015년까지의 로봇 지각은 방법론과 기술적인 측면에서 견고한 기반을 구축하고 개선하는 데 초점을 맞췄어요. 그 부분이 충분히 견고해지면, 연구 커뮤니티와 산업계는 환경을 \"자유로운(free)\", \"점유된(occupied)\", 혹은 \"알 수 없는(unknown)\"로만 라벨링하는 것이 충분하지 않다는 것을 깨달았어요. 그 때들이 생김새를 가볍게 생각하면, 환경에서 고수준 정보를 추론하는 의미론을 추구하기로 결정했어요. 이 정보는 다양한 물체, 방, 위치의 이름과 범주를 포함하지만 이에 한정되지 않아요.\n\n<div class=\"content-ad\"></div>\n\n2015년부터 2020년까지 Zoox와 Sereact가 환경에 대한 그 수준의 이해를 달성했다는 사실이 놀라운 것 같아요. 그들로부터 일부 세부 정보를 논의해보고, 이미지를 다시 여기에 포함해서 위로 스크롤할 필요 없도록 할게요.\n\n아래 부분에서 자율 주행 자동차가 사람들이 앉아 있고 걷고 있지 않을 때를 이해할 수 있다는 것을 볼 수 있어요. 또한, 인간의 제스처를 이해할 수 있어서 앞으로 나아갈 수 있다는 의미입니다.\n\n또 다른 경우에는, 자동차가 안전 조끼를 입은 공사모를 쓴 사람이 교통 표지판을 들고 있는 상황을 이해한 것을 볼 수 있어요. 이 사람은 보통 사람이 아니라 차량이 멈추라는 도로 공사 작업자입니다.\n\n마지막으로, 주차된 차량에 문이 열려 있는 것을 이해한 자동차는 그곳에서 사람이 나올 수 있다는 것을 의미해요. 이 상황에서 Zoox 차는 어떤 사고도 예방하기 위해 더 주의 깊게 운전합니다.\n\n<div class=\"content-ad\"></div>\n\n저는 bin picking 분야의 지각 개선 사항도 다룰 예정이라고 언급했던 것 같아요. 이곳에서 Sereact에서의 좋은 예시를 소개하고 있습니다. 이 경우에는 사람이 로봇에게 상품 존 폐기품을 선택하도록 요청하고 있습니다. 출처 창고에는 6개의 프링글스 캔이 들어 있고 이 중 하나가 부서졌습니다. 시스템의 인식 부분은 이를 이해할 수 있고, 부서진 캔을 선택합니다.\n\n# 요약\n\n우리는 로봇 지각의 의미론적을 고려하는 강인한-지각 시대에 살고 있습니다. 이는 로봇이 Sereact가 보여준 것처럼, 상품 존에서 부서진 항목을 선택하거나 Zoox가 하는 것처럼 사고를 예측하는 고수준 작업을 수행할 수 있게 합니다. 우리 인간들에게는 \"부서진\"이 무엇을 의미하는지는 명확하고 간단하지만, 정의할 수 있나요? 창고의 모든 항목에 대해 이 조건을 설명하는 규칙과 특성을 정의하는 건 거의 불가능합니다 (예: 부서진 캔과 부서진 머그잔은 다릅니다).\n\n실제로 이러한 의미론적 이해는 LLM과 VLM에서 출발하며, 텍스트 및 시각적 정보를 결합합니다. 로봇이 사람의 옷이 그들이 본 상황에서 다른 역할을 함을 이해할 때야 (길 공사 작업자와 같이 보여진 것처럼) 이 사람에 적절히 반응할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n물론, 로봇학의 하드웨어 부분에서도 상당한 발전이 있었습니다. 예를 들어, Boston Dynamics와 그 Atlas 로봇을 생각해 볼 수 있습니다. 수압식 버전은 폐지되고 새로운 완전 전기식 버전이 출시되었습니다. 그러나 저는 고수준 작업을 수행하는 로봇들에게 있어서 인식 소프트웨어의 개선이 더욱 중요하다고 느낍니다.\n\n이 기사의 주요 질문에 대한 대답이 있습니다. 한 번 들은 적이 있는데, 지식을 축적하는 것이 아닌 그 지식을 활용하는 방법을 아는 사람이 똑똑하다고 합니다. 그래서 로봇이 \"새로운\" 지식을 활용하여 보다 복잡한 작업을 해결한다면, 그들은 실제로 똑똑해지고 있는 것이 맞습니다.\n\n어떻게 생각하시나요?\n\n지금은 여기까지입니다.\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n- Newman, Paul 등. “탐색 및 복귀: 실시간 동시 매핑 및 로컬라이제이션의 실험적 검증.” ICRA, 2002.\n- Thrun, Sebastian. “팀의 이동 로봇을 위한 온라인 매핑 알고리즘.” Carnegie-Mellon Univ Pittsburgh PA School of Computer Science, 2000.\n- Mur-Artal, R., Montiel, J.M.M., 및 Tardos, J.D. “ORB-SLAM: 다목적 및 정확한 단안 SLAM 시스템.” IEEE Transactions on Robotics. 2015.\n- Grisetti, G., Stachniss, C., 및 Burgard, W. “적응적 제안 및 선택적 리샘플링을 통한 Rao-Blackwellized 입자 필터를 사용한 그리드 기반 SLAM 개선.” ICRA. 2005.\n- youtube.com/watch?v=BVRMh9NO9Cs에서 추출.\n- Cadena C, Carlone L, Carrillo H, Latif Y, Scaramuzza D, Neira J, Reid I, Leonard JJ. 동시 위치 결정 및 매핑의 과거, 현재 및 미래: 견고한 인식 시대로. IEEE Transactions on robotics. 2016.\n- https://www.youtube.com/watch?v=gRV4KvIDn9Y&ab_channel=T³TipsTricksTests에서 추출.\n- https://www.youtube.com/watch?v=_ieObX5f_ws&ab_channel=Sereact에서 추출.","ogImage":{"url":"/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_0.png"},"coverImage":"/assets/img/2024-06-22-AretherobotsgettingsmarterAconversationaboutperceptioninrobotics_0.png","tag":["Tech"],"readingTime":8},{"title":"로봇 공학 기술 2024년에 주목해야 할 10가지 혁신","description":"","date":"2024-06-22 19:40","slug":"2024-06-22-ROBOTICTECHNOLOGY","content":"\n\n![로봇 기술](/assets/img/2024-06-22-ROBOTICTECHNOLOGY_0.png)\n\n로봇 기술은 로봇의 설계, 건설, 운영 및 사용을 다루는 공학 및 과학 분야를 가리킵니다. 로봇은 프로그래밍 가능한 기계로, 위험하거나 지루하거나 사람들에게는 불가능한 작업을 자동으로 또는 준자동으로 수행할 수 있는 기능을 가지고 있습니다.\n\n로봇 기술은 기계 공학, 전기 공학, 컴퓨터 과학 및 인공지능을 포함한 다양한 학문을 아우릅니다. 로봇 기술의 주요 구성 요소는 다음과 같습니다:\n\n- 기계 설계:\n\n<div class=\"content-ad\"></div>\n\n로봇공학은 로봇이 움직이고 환경과 상호작용할 수 있도록 물리적인 구조, 관절 및 메커니즘을 만드는 것을 포함합니다.\n\n2. 센서 및 액추에이터:\n\n로봇은 주변 환경을 인식하기 위해 센서를 사용하고 물체를 조작하거나 자신의 구성요소를 이동시키기 위해 액추에이터를 사용합니다. 센서로는 카메라, LIDAR, 레이더, 초음파 등이 포함될 수 있으며, 액추에이터로는 모터, 공압 시스템 또는 유압 시스템이 사용될 수 있습니다.\n\n![로봇공학](/assets/img/2024-06-22-로봇공학_1.png)\n\n<div class=\"content-ad\"></div>\n\n3. 제어 시스템:\n\n로봇의 행동을 지배하는 알고리즘 및 소프트웨어로, 로봇이 결정을 내릴 수 있게 하고 움직임을 계획하며 변화하는 조건에 적응할 수 있게 합니다.\n\n4. 인공 지능:\n\n인공 지능은 현대 로봇에서 매우 중요한 역할을 합니다. 경험으로부터 학습하고 패턴을 인식하며 결정을 내리고 심지어 인간 지능과 닮은 행동을 보일 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n5. 인간-로봇 상호 작용:\n\n로봇이 사회의 다양한 영역에 점차 통합되면서, 인간이 로봇과 안전하고 효과적으로 작업할 수 있도록 설계된 인터페이스와 상호 작용 방법이 점점 중요해지고 있습니다.\n\n로봇 기술의 응용 분야는 다양하며 빠르게 확장되고 있습니다. 로봇이 사용되는 일반적인 분야에는 제조업(산업용 로봇), 의료(수술 로봇, 보조 로봇), 물류 및 창고(자율 주행 차량, 로봇 팔), 농업(농업 로봇), 탐사(우주 탐사로봇, 수중 로봇), 오락(로봇 동반자, 테마 파크 어트랙션) 등이 있습니다.\n\n기술이 발전함에 따라 로봇은 더욱 능력이 향상되고 다재다능하며 가격이 더 더 낮아져 다양한 산업과 일상생활에서 점점 더 많이 수용되고 있습니다. 그러나 로봇이 일자리, 개인정보 보호, 안전 및 자유에 미치는 영향과 관련된 윤리적 및 사회적 고려사항은 중요한 논의 및 논쟁의 대상입니다.","ogImage":{"url":"/assets/img/2024-06-22-ROBOTICTECHNOLOGY_0.png"},"coverImage":"/assets/img/2024-06-22-ROBOTICTECHNOLOGY_0.png","tag":["Tech"],"readingTime":2},{"title":"힌두교 의식을 수행하는 로봇  신도들이 로봇이 신도들을 대체할까 걱정하는 이유","description":"","date":"2024-06-22 19:39","slug":"2024-06-22-RobotsareperformingHinduritualssomedevoteesfeartheyllreplaceworshippers","content":"\n\n## AI 및 로봇 기술의 사용이 예배에 수행되는 흥미로운 질문을 던지고 있습니다.\n\n웰레슬리 대학 문화인류학 강의 교수 할리 월터스\n\n예술가와 교사 뿐만 아니라 자동화와 인공지능 발전으로 인해 잠을 설치는 사람들이 있습니다. 로봇이 힌두교의 성스러운 의식에 도입되고 있는데, 모든 신자들이 기뻐하지는 않습니다.\n\n2017년에 인도의 기술 기업이 로봇 팔을 소개하여 \"아아티\"를 수행하였습니다. 이 의식은 신자가 신에게 기름 등을 제공하여 어둠을 제거한다는 의미로 실시됩니다. 이 특별한 로봇은 가네샤, 코끼리 머리를 한 신의 상징이 군중들에게 전시되고 중앙 인도의 푸네의 뮬라-무타 강에 름길에 드러지는 가네샤 축제에서 공개되었습니다.\n\n<div class=\"content-ad\"></div>\n\n이후로, 그 로봇 아르티 팔은 여러 개의 프로토 타입을 영감을 주었는데, 그 중 일부는 오늘날도 인도 전역에서 꾸준히 의식을 진행하며, 동아시아와 남아시아에서 다양한 종교적 로봇과 함께 의식을 진행하고 있습니다. 심지어 현재에서도 인도 남부 해안 케랄라에 있는 움직이는 사원 코끼리를 포함하여 로봇 의식은 여전히 진행 중입니다.\n\n그러나 종교적 로봇 사용 이러한 종류가 인공 지능 및 로봇 기술의 도굴과 숭배에 대한 논쟁을 증가시켰습니다. 일부 신도와 신자들은 이것이 사회 발전을 이끌 것으로 보는 인간 혁신의 새로운 지평임을 느끼지만, 다른 사람들은 로봇을 신봉하는 사람들을 대체하는 데 사용하는 것이 미래에 대한 나쁜 징조라고 걱정합니다.\n\n그러나 종교에 특화된 문화 인류학자로서 나는 로봇 학술에 대한 신학보다는 사람들이 실제로 그들의 영적 실천에 관해 말하고 하는 내용에 더 집중합니다. 제 현재의 종교 로봇 연구는 주로 그것들을 \"신성 물체-인\"의 개념에 중점을 두고 있으며, 그들은 그렇지 않았던 것들이 살아있는 의식을 갖고 있다고 여겨집니다.\n\n또한 제 연구는 힌두교와 불교 신자들이 로봇을 신봉하는 사람들을 대체함으로써 표현하는 불안에 관심을 기울이며, 그 로봇들이 실제로 더 나은 신도가 될 수 있는지에 대해 살펴봅니다.\n\n<div class=\"content-ad\"></div>\n\n# 의례 자동화는 새로운 것이 아닙니다\n\n의례 자동화 또는 적어도 로봇 정신 수행이라는 아이디어는 남아시아 종교에서 새로운 것이 아닙니다.\n\n역사적으로 이는 힌두교도인들이 자주 하는 신상들을 위해 수행하는 목욕 의례를 위해 계속 물을 떨어뜨리는 특별한 항아리부터 요가 스튜디오와 공급점에서 종종 볼 수 있는 풍력을 이용한 불교의 기도반 모빌까지 다양합니다.\n\n현대적인 의례 자동화가 무슨 모습인지에는 이제 더 이상 묵상 비노나 로자리와 같은 기도 대상이 전혀 필요하지 않는 휴대전화 앱을 다운로드하는 것처럼 보일 수 있지만, 이러한 새로운 형태의 의례 수행 로봇들은 복잡한 대화를 유발하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n타네스워 살마는 산스크리트 학자이자 문학 비평가로, 힌두교 신앙에서 인간 종족의 최초 국왕인 만누 왕 이야기 속에 처음 나타난 힌두교 로봇에 대해 주장합니다. 만누의 어머니 사란유는 대건축가의 딸로, 가정 업무와 의식적 의무를 완벽하게 수행하는 살아있는 조각상을 만들었습니다.\n\n<img src=\"/assets/img/2024-06-22-RobotsareperformingHinduritualssomedevoteesfeartheyllreplaceworshippers_0.png\" />\n\n민속학자 애드리안 메이어는 힌두교 서사시에서의 기계식 아이콘들에 관한 종교적 이야기, 예를 들어 힌두 신공인 비슈바카르만의 기계 전투전차는 종교적 로봇의 전조로 현재에 이르는 것으로 자주 생각됩니다.\n\n뿐만 아니라, 이러한 이야기들은 현대 국가주의자들에 의해 때때로 공간선박부터 미사일까지 고대 인도가 모든 것을 이전에 발명했다는 증거로 해석될 때도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 현대적 전통이나 전통적인 현대?\n\n그러나 최근에 종교 실천에서 AI와 로봇을 사용하는 것은 힌두교인과 불교인들 사이에서 자동화가 어떤 미래로 이끌 수 있는지에 대한 우려를 야기하고 있습니다. 어떤 경우에는 힌두교인들 사이에서 자동화된 종교가 인류를 밝고 새로운 기술적 미래로 이끌 것이라는 약속인지 아니면 단순히 도래하는 종말의 증거인지에 대한 논쟁이 벌어지고 있습니다.\n\n다른 경우에는 로봇의 증가가 신전이 종교 실천자보다 오히려 자동화에 더 의존하도록 하여 사람들이 종교 실천을 그만두게 할 수 있다는 우려가 있습니다. 이러한 우려 중 일부는 남아시아 및 전 세계적으로 많은 종교에서 지난 몇십 년 동안 정신적 교육과 실천에 헌신할 의지가 줄어드는 젊은이들의 수에서 비롯됩니다. 더구나 전 세계에 흩어진 이민민 다수의 가족들로 인해 사제나 \"판딧\"이 점점 작고 작은 공동체를 지원하게 되는 경우가 많습니다.\n\n그러나 문제인 하는 적은 의식 전문가라는 문제의 해결책이 로봇이라면, 사람들은 여전히 의식 자동화가 자신들에게 혜택을 줄 것인지에 대해 의문을 제기합니다. 또한, 로봇 신을 구현하고 의인화 시키기 위해 동시에 사용하는 것에 대해 의문을 제기합니다. 왜냐하면 이러한 아이콘들은 사람들에 의해 프로그래밍되고 그로 인해 엔지니어들의 종교적 견해를 반영하기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n# 종교에 대한 올바른 접근\n\n학자들은 종종 이러한 우려들이 모두 하나의 지배적인 주제를 반영한다고 지적합니다 — 로봇들이 어떤 식으로든 신을 숭배할 때 인간들보다 더 뛰어나다는 내재적인 불안감이 있습니다. 이로 인해 삶의 의미와 우주 속 자신의 위치에 대한 내부 갈등이 발생하기도 합니다.\n\n힌두교와 불교 신자들에게는 의식 자동화의 증가가 특히 우려스럽습니다. 그 이유는 이들 전통이 종교학자들이 \"정행\"(orthopraxy)이라고 참조하는 것에 중점을 둔다는데 있습니다. 여기서는 올바른 윤리적이고 예배적 행동에 더 높은 중요성을 부여하는데 종교적 교리에 대한 구체적인 신념보다 더 중요하게 여깁니다. 다시 말해, 종교 실천에서 무엇을 얼마나 완벽하게 하는가가 영적 발전에 있어 개인적으로 믿는 것보다 더 필수적으로 여겨집니다.\n\n이것은 또한 자동화된 의식이 인간의 의식적 오류에서 로봇의 의식적 완벽까지 이어지는 연속체에 있다는 것을 의미합니다. 간단히 말해, 로봇이 당신의 종교를 더 잘 할 수 있는 이유는 로봇이 사람과는 달리 영적으로 부패할 수 없기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n로봇은 감소하는 목사단에 대한 매력적인 대안으로만 사용되는 것이 아니라 일상적인 맥락에서 그들의 이용이 증가하는 것을 설명합니다: 로봇이 잘못을 한다는 걱정이 없기 때문에 사람들은 그들을 사용합니다. 그리고 의식 수행 옵션이 제한될 때 아무것도 없는 것보다 나은 경우가 많습니다.\n\n# 로봇에 의해 구원받다\n\n결국, 현대 힌두교나 불교에서 종교적 회복을 위해 로봇에 의존하는 것은 미래적으로 보일 수 있지만, 현재 순간에 매우 속한다고 할 수 있습니다. 이는 힌두교, 불교 및 남아시아의 다른 종교들이 기계적 지혜를 활용하여 사람의 약점을 초월하려는 것으로 상상되는 것이라는 점을 보여줍니다. 왜냐하면 로봇은 지치지 않으며 말해야 할 것을 잊지 않고, 잠들지도 않고 떠나지도 않기 때문입니다.\n\n구체적으로 말하면, 로봇 자동화는 동아시아와 남아시아(특히 인도와 일본)에서 의식 수행을 완벽하게 하는 데 사용되고 있으며, 이는 인간 성도에게는 불가능한 것을 달성할 수 있도록 합니다. 완벽하고 흠없는 의식 수행을 아이디어와 결합시켜 더 나은 종교의 개념을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n현대 로봇공학은 종교가 더 이상 인간이 없는 것이 가장 좋은 종류의 종교가 된다는 특별한 문화적 모순처럼 느껴질 수 있습니다. 하지만 인간들이 로봇을 만들고, 로봇이 신이 되고, 신이 다시 인간이 되는 이 중첩 속에서, 우리는 다시 한번 우리 자신을 재해석한 것뿐입니다.\n\n이 기사는 The Conversation에서 나온 것으로, 학술 전문가들의 지식을 공유하기 위해 헌신하는 독립 비영리 뉴스 기관입니다. 좀 더 자세한 정보를 원하시거나, 연합통신 및 종교 뉴스 서비스와 공동으로 발행하는 종교 이야기 이번 주간 뉴스레터를 받아보시려면 저희에 대해 더 알아보시거나 구독해주세요.\n\nHolly Walters는 이 기사로부터 이익을 얻는 어떠한 회사나 기관에도 속하지 않으며, 컨설팅하거나 주식을 소유하거나 금전 지원을 받지 않습니다. 학술적 직위 이외의 관련 소속사항을 기재하지 않았습니다.","ogImage":{"url":"/assets/img/2024-06-22-RobotsareperformingHinduritualssomedevoteesfeartheyllreplaceworshippers_0.png"},"coverImage":"/assets/img/2024-06-22-RobotsareperformingHinduritualssomedevoteesfeartheyllreplaceworshippers_0.png","tag":["Tech"],"readingTime":5},{"title":"Nvidia 우주를 향하다","description":"","date":"2024-06-22 19:38","slug":"2024-06-22-Nvidiaadastra","content":"\n\n![Nvidiaadastra_0](/assets/img/2024-06-22-Nvidiaadastra_0.png)\n\n요즘에 Nvidia가 세계에서 가장 가치 있는 기업으로 급부상했을 뿐만 아니라 창업자 제인슨 황(Jensen Huang)은 이미 상당한 부를 보유한 상황에서 더 기다림으로써 그 부를 증가시키고 있습니다. 지난 수요일에 제가 전 직원이자 주주인 학생 중 한 명과 짧은 대화를 나누었는데, 그 학생은 지금 팔아야 할지 아니면 주가가 계속 상승할 것을 기대하며 보유해야 할지 고민하고 있었습니다.\n\n황 자신도 이 의구심을 공유하고 있습니다. AI 시장에서 표준이 된 칩 세일즈가 가능했던 것에 대한 우려를 앞두고 이미 소프트웨어와 클라우드 서비스로 옮겨가려 하며, Nvidia 칩을 위한 맞춤형 랙과 함께 현재 수요와 관련된 제품 및 서비스 포트폴리오를 구축하고 있습니다.\n\nNvidia가 최고기록을 경실할 예정인가요, 아니면 아직 긴 여정을 거쳐야 할까요? 우선, 더 많은 기업들이 제품과 서비스에 머신 러닝과 AI를 통합함으로써 AI의 보편성이 점점 더 높아지고 있지만, 우리는 아직 성숙한 시장에서 매우 멀리 떨어져 있으며 더구나 정체된 시장에서도 더 멀리 떨어져 있습니다.\n\n<div class=\"content-ad\"></div>\n\n둘째, 우리는 일반적으로 컴퓨터 화면 앞에서 이루어지는 행정 업무에 생성적 AI를 적용하는 첫 번째 단계에 대해 논의하고 있습니다. 매우 다양한 유형의 보조 인력, 예측을 얻기 위한 데이터 처리 등이 매우 흥미롭지만, 물리적 세계에서 이루어지는 많은 활동을 배제합니다. 이 두 번째 단계는 로봇공학의 발전과 교차되는데, 이 환경에서는 테슬라의 매우 알려진 Optimus와 같은 여러 프로젝트가 아직 상대적으로 초기 단계에 있는 것을 볼 수 있습니다. Figure, Agility 등도 있습니다.\n\n일론 머스크는 언젠가 로봇이 인간을 능가할 것이라 예측합니다; 혹시 그렇지 않더라도, 결국 그것들은 생성적 AI에 의해 구동될 것이기 때문에 클래식 로봇공학에서와 같이 단계별로 프로그래밍되어야 하는 것은 아닐 것입니다. 그렇다면, Nvidia는 완전히 새로운 수요 세그먼트가 닥칠 것입니다. 하지만 당연히 큰 질문은 이러한 로봇이나 장치들이 Nvidia 칩을 내장할 것인가에 대한 것입니다. 적어도 Alphabet 소유의 Intrinsic과 같은 하나의 회사는 이미 로봇 플랫폼에 Nvidia 칩을 통합했으며, 이는 향후 회사 제품에 대한 수요를 가리킵니다. 실제로 황 CEO는 로봇공학이 새로운 AI 전선이라고 말합니다.\n\n그렇다면, Nvidia에 대해 하늘은 한계인가요? 주식 시장 가치에서 새로운 이정표를 세울 것인가요? AI가 더 많은 세그먼트로 진입할 것으로 보이며 모든 산업의 회사들이 최고의 알고리즘을 위해 경쟁할 것으로 보이는 시점에 Nvidia의 별이 가시지 않는 것으로 보아, 아마도 여전히 유지될 것으로 생각됩니다. 테크놀로지는 빛보다 빠르게 움직이며 경쟁사는 선두자의 시장을 빼앗기 위해 어디서든 나타날 수 있습니다. 그러나 현재 상황에서, 발전의 방향을 고려할 때, Nvidia가 아직 긴 여정을 가야 한다는 점이 내 느낌입니다.\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 마크다운 형식으로 변경해주세요.","ogImage":{"url":"/assets/img/2024-06-22-Nvidiaadastra_0.png"},"coverImage":"/assets/img/2024-06-22-Nvidiaadastra_0.png","tag":["Tech"],"readingTime":2},{"title":"벤 디토가 전하는 2024년 로봇공학과 AI의 미래 전망","description":"","date":"2024-06-22 19:36","slug":"2024-06-22-ExploringtheFutureofRoboticsandAIInsightsfromBenDitto","content":"\n\n<img src=\"/assets/img/2024-06-22-ExploringtheFutureofRoboticsandAIInsightsfromBenDitto_0.png\" />\n\n최근 Mindplex 팟캐스트 에피소드에서는 Ben Ditto의 마음을 탐험하는 Ben Goertzel 박사와 Desdemona와의 대화가 진행되었습니다. 이 대화는 기술, 예술 및 인류가 교차하는 매혹적인 영역에 심취합니다.\n\n음악 비디오와 패션 촬영으로 유명한 저명한 창의적 전문가인 Ben Ditto는 그의 여정의 복잡성과 로봇공학, AI 및 인지과학으로의 모험의 깊은 함의를 해체하기 위해 중심무대에 서 있습니다.\n\n주인공 Lisa Rein은 Ben Ditto를 소개하면서 그의 다채로운 포트폴리오에 스며든 독특한 신비한 감각을 인정합니다. 대화가 펼쳐지며, Ditto의 창의적 추구가 전통적 매체에 국한되지 않고 첨단 기술 영역까지 확장된다는 것이 분명해집니다.\n\n<div class=\"content-ad\"></div>\n\n# 로봇에 개성 부여의 복잡성\n\n디토는 로봇에 개성을 부여하는 것이 얼마나 어려운지 강조하면서 토론을 시작합니다. 처음에는 간단해 보이지만 실제로는 복잡한 미로를 탐험해야 한다고 언급합니다. 디토의 노력은 혁신과의 댄스처럼, AI 기술이 빠르게 발전함에 따라 나타나는 새로운 기회와 장애물을 마주하면서 나아가고 있습니다.\n\n벤 디토는 로봇공학에 대한 매력적이고 어려운 주제에 대해 이야기하며, 도구 구현을 통해 로봇공학을 실제로 적용하는 쉬움과 어려움을 지적합니다. 그는 재능있는 사람들과 협력하고 산업에서 혁신적인 전환점을 이룰 가능성에 대해 논하며, 열정을 전합니다.\n\n디토는 로봇공학의 매혹적이고 어려운 풍경을 더 탐험하며, 구현 상의 단순함과 복잡성을 강조합니다. 그는 숙련된 전문가들과 협력하는 열정을 강조하면서, 분야에서 선도적인 발전을 추구하는 집단의 노력을 강조하며, 로봇이 우리의 일상 속에 자연스럽게 통합되는 미래를 시사합니다.\n\n<div class=\"content-ad\"></div>\n\n![Exploring the Future of Robotics and AI Insights from Ben Ditto](/assets/img/2024-06-22-ExploringtheFutureofRoboticsandAIInsightsfromBenDitto_1.png)\n\n## 인지와 감정의 상호작용\n\n대화의 가장 매력적인 부분 중 하나는 벤 고츨 박사의 인간형 로봇 데스데모나와의 작업에 대한 것입니다. 그는 내부와 외부 시각을 분리하는 선이 얼마나 미묘한지 명확히 해 주며 집단 감정과 인지 개념과의 연관성을 언급합니다. 다이토는 로봇의 성격 시스템을 연구하면서 인지 및 성격 이론을 적용하여, 인간-로봇 상호작용에 영향을 미치는 복잡한 동력을 조사합니다.\n\n벤 디토는 인간형 로봇 데스데모나와의 작업을 통해 내부 및 외부 시각 사이의 조화, 그리고 공동 인지와 감정 개념과의 연결에 대해 이야기합니다. 그는 로봇의 성격 시스템이 인지와 성격 이론에 기반하며, 외부 환경을 이해하는 데 있어 최대한의 이해도를 달성하기 위해 조절될 수 있음을 설명하며 사람들이 그 로봇을 어떻게 보는지에 영향을 줄 수 있다고 설명합니다.\n\n<div class=\"content-ad\"></div>\n\n딧토는 인공지능과 로봇 과학의 맥락에서 인지, 언어, 기억의 복잡성을 더 자세히 파고들고 있습니다. 그는 감정 상태가 기억 접근에 미치는 중요한 영향에 주목합니다 - 이는 인간의 경험을 반영하는데, 이러한 영향을 로봇 시스템에 통합함으로써 만난 경험의 감정적 맥락에 따라 컴퓨터가 이를 기억하거나 잊을 수 있는 미래를 상상합니다.\n\n![로봇과 AI의 미래 탐구: 벤 딧토의 통찰](/assets/img/2024-06-22-ExploringtheFutureofRoboticsandAIInsightsfromBenDitto_2.png)\n\n## AI 개발에서의 윤리적 고려사항\n\n대화는 딧토가 정신적 매개변수를 조정하는 것에 내재된 윤리적 딜레마에 대한 사고를 전개하면서 더욱 생각해 보게 합니다. 그는 유익한 결과를 확보하기 위한 필요성을 인지하면서 이러한 복잡성을 탐험하기 위해 개방적인 소통과 상호이해를 옹호합니다. 그는 또한 향수의 개념에 대해 이야기하며, 나쁜 기억이 좋은 기억보다 빨리 사라진다는 생각을 제안하고, 이 아이디어가 로봇에도 적용될 수 있다고 언급합니다.\n\n<div class=\"content-ad\"></div>\n\n디토는 혁신적 기술의 혁명적 가능성에 대한 완전한 열광으로 프로그램 전반에 걸쳐 모든 대화를 뒤덮고 있어요. 디토의 관찰은 인공지능이 인간 간 상호 작용에 미치는 영향부터 AI 기술이 제기하는 도덕적 문제까지 사회에 미치는 중요한 영향에 대해 심사숙고하게 만들어줘요.\n\n## 전통과 혁신의 융합\n\n벤 디토는 이들이 대화를 이어가면서 자신의 창의적 접근을 콜라주 예술과 비교해요. 디토는 현대와 빈티지를 능숙하게 조화시켜 비주얼적으로 강렬한 스토리텔링을 만들어내며, 두 가지로부터 영감을 받아요.\n\n그는 음악 비디오에서 증강 현실(AR)을 실험하는 과정과 AR 얼굴 기술이 미래의 예술 표현을 형성하는 데 미치는 광범위한 잠재력에 대한 통찰을 공유해요. 디토가 그림자 지체를 인식뿐만 아니라 인간들과도 깊은 수준에서 상호 작용하는 미래의 선구자인 Yaya Labs와 Desi와 같은 프로젝트를 언급하며 과학 소설이 현실과 융합되는 세계를 상상해요. 함께 그렇게 언급하면 열정이 넘쳐나요.\n\n<div class=\"content-ad\"></div>\n\nDr. Ben Goertzel은 사고과학의 영역으로 모험을 떠나 인식을 갖는 뇌 장기, 즉 초감각 및 선지능을 부여하는 가능성에 대해 고찰하고 있습니다. 확고한 낙관주의로, 그는 이러한 뇌 장기가 극도로 짧은 시간 내에 등장할 것으로 예측하며, 기술적 진보가 인간 인지에 대한 우리의 이해를 형태를 변화시키고 있다는 점을 강조합니다.\n\n## 기술과 문화의 복합적 미로를 탐험하며\n\n이 대화는 디토가 기술 발전의 사회 문화적 함의에 대한 고찰로 전환되었습니다.\n\n그는 자신의 다큐멘터리 시리즈에서 3D 프린팅 총에 대해 탐구한 선택에 대해 이야기하며, 이 기술이 사회, 특히 총 소유와 미국 제2 수정에 어떻게 영향을 미쳤는지 밝히고 있습니다. 디토는 3D 프린팅의 혁신적 잠재력을 명확히 하며, 기술이 문화적 서사와 정치적 논쟁에 어떻게 영향을 미치는지 강조합니다.\n\n<div class=\"content-ad\"></div>\n\n딧토는 유토피아적인 아이디어 및 인공지능이 사회적 규범과 상호 작용하는 주제에 대해 다룹니다. 그는 월스트리트와 부유층이 암호화폐를 도입한 방식을 검토하며, 도덕을 고려하지 않고 기술적인 유토피아를 추구하는 것에 대해 경고합니다.\n\n딧토는 인간과 인공지능 간의 복잡한 관계를 균형 잡힌 시각으로 탐구하며, 인공지능 동반자가 외로움을 줄이고 사회적 문제를 해결하는 데 미치는 중요성을 강조합니다. 그러나 그는 인공지능을 활용한 솔루션의 확산에 맞서 인간 연결을 보존하는 가치를 강조하며, 노인 돌봄을 인공지능 동반자에게 아웃소싱할 수 있는 가능성에 대해 우려를 제기합니다.\n\n## 정신건강 치료 재구상\n\n벤 딧토는 기술과 컴퓨터가 사람들의 정신 건강을 돕는 데 사용되는 것에 대해 논의합니다. 그는 기술이 유용할 수 있다고 믿지만, 치료와 치료에 관련하여 실제 인간적인 연결과 관계에 집중하는 것이 매우 중요하다고 생각합니다.\n\n<div class=\"content-ad\"></div>\n\n디토는 정서적인 문제를 치료하기 위해 흔히 사용되는 약물과 인지행동요법(CBT)이라는 특정 요법에 대한 의존을 도전합니다.\n\n그는 이러한 방법이 모두에게 항상 효과적이지는 않을 뿐만 아니라, 요법이 일반화되어서는 안 된다고 말합니다. 오히려 디토는 우리가 정서적 건강에 대해 보다 정평적이며 인간 중심적인 접근 방식이 필요하다고 제안하며, 초점은 사람들과 개인적 수준에서 이해하고 연결하는 데 있어야 한다고 언급합니다.\n\n그는 또한 영국에서 항우울제의 과용에 대해 이야기하며, 약물이 도움이 될 수 있지만 항상 최선이거나 유일한 해결책은 아니라고 지적합니다. 디토는 어떤 정서적인 문제들은 단순히 개인의 생물학적인 요인이 아닌 사회적 문제와 사람들의 경험에서 더 발생될 수 있음을 믿습니다. 그는 효과적인 요법의 핵심 부분으로 강하고 건강한 대인관계 구축의 중요성을 강조합니다.\n\n## 자폐증과 신경다양성의 복잡성\n\n<div class=\"content-ad\"></div>\n\n벤 디토는 우리가 자폐증을 어떻게 이해하며 어떻게 사람들에게 영향을 미치는지에 대해 이야기합니다. 그는 자폐증을 정의하는 방식이 시간이 지남에 따라 많이 변화되었으며, 이로 인해 더 많은 사람들이 진단을 받게 되었다고 믿습니다.\n\n그는 진단 증가가 많은 돈을 벌어들이는 큰 산업을 만들어냈다고 주장합니다. 디토는 때로는 사람들이 문제를 가지고 있기 때문이 아니라 기업과 전문가들에게 이익이 되기 때문에 자폐증으로 진단을 받는다고 제안합니다. 그는 자폐 스펙트럼에 속하는 방법이 단 하나뿐인 것은 아니라고 생각합니다.\n\n그 대신, 그는 우리가 신경 이질을 받아들이고 축하해야 한다고 믿습니다. 모든 사람이 생각하고 배우는 다양한 방식을 갖고 있으며, 그것이 인간이 하는 중요하고 자연스러운 부분이라는 것을 인정하는 것이 중요하다고 생각합니다.\n\n벤 디토는 자폐증과 자폐 스펙트럼 장애에 대한 개념에 대해 논의하며, 정의의 확장이 진단의 크게 증가와 매년 490억 달러 규모의 수익을 창출하는 산업을 만들어냈다고 주장합니다.\n\n<div class=\"content-ad\"></div>\n\n그는 스펙트럼 상의 개인들에게 본질적으로 잘못된 것이 있는 것이 아니라 많은 사람들에게 이윤을 가져다주는 구조물로 여겨진다고 제안합니다. Ditto는 단일 \"스펙트럼\" 개념을 비판하며, 대신 신경다양성을 인간의 자연스러운 부분으로 보며, 각각의 개인이 다른 학습 스타일과 능력을 갖고 있다고 생각합니다.\n\n## 창의적 진화 탐구: 음악, 패션 및 로봇공학\n\n자평할 때 Ditto는 존 레논과 요코 오노의 상징적 이미지에서 영감을 받은 포토 촬영에 참여한 경험에 대한 이해를 공유하면서 자신이 모델링의 세계로 진입한 경과를 전합니다.\n\n촬영의 주제임에도 불구하고, Ditto는 포토그래퍼 Matas Porto가 아이디어를 개념화한 데 공로가 있었다고 평가하며, 예술적 노력의 협업적인 성격을 강조합니다. 촬영의 다양한 문화적 해석에 대해 되새기며, Ditto는 지각의 세밀한 점과 오해의 가능성을 강조하며, 그림의 맥락에서 함께 일한 로봇 데시가 잘못 해석된 경우를 인용합니다.\n\n<div class=\"content-ad\"></div>\n\n디토는 음악, 패션 및 로봇공학을 아우르는 다채로운 경력 궤적을 제공합니다. 벤 디토의 작품은 기술과 예술을 흥미로운 방식으로 결합합니다. 그는 창의적인 감독과 협력하며 가상 아바타와 증강 현실을 탐구하여 음악과 공연에서 새로운 경험을 만들어 냅니다. 가상 아바타와 작업하는 것은, 디토에게는 인간 유명인과 작업하는 것과 유사한데, 디지털 페르소나를 사용하여 예술 표현의 경계를 넓히는 데 사용합니다.\n\n디토는 특히 인스타그램에서 대담하고 도발적인 콘텐츠로 알려져 있습니다. 전통적인 아름다움 관념에 도전하는 파격적인 이미지를 만들고 공유합니다. 이러한 이미지에는 폭력적인 장면이나 쇠약한 도시지역의 모습이 포함될 수 있는데, 아름다움은 예상치 못한 곳에서 발견될 수 있다는 것을 보여줍니다. 디토의 접근 방식은 사람들에게 아름다운 것이 무엇인지에 대한 신념을 의심하고 예술과 미학의 복잡성과 다양성을 감상하도록 독려합니다.\n\n## 마무리\n\n앞으로 바라보면, 디토는 음악가와의 협업부터 세계 투어 참여까지의 야망을 나눕니다. 그러나 그의 야망은 전통적인 예술적 추구를 넘어서는데, 그는 로봇 군대를 시작하여 \"세련되게 세상을 지배하려\"는 가능성을 장난스럽게 고찰합니다. 철학적인 변화 속에서, 디토는 이중성의 개념에 대해 사색하며, 자매는 같은 존재의 두 형상이라고 제안하여 재미있는 상상력과 심오한 철학적 탐구를 접목하는 그의 성향을 포착합니다.\n\n<div class=\"content-ad\"></div>\n\n대화가 끝나면 청취자들은 Ditto의 창의성, 기술, 그리고 인간의 상태에 대한 확신 있는 시각으로 얽힌 통찰과 반성을 남게 됩니다. 끊임없이 변화하는 세계에서 Ben Ditto는 예술적 혁신의 초록불이로 나타나 우리에게 사회적 관행에 돑쳐들고 인간 표현의 무한한 잠재력을 환영하도록 동창합니다.\n\n# Mindplex 소개\n\n![이미지](/assets/img/2024-06-22-ExploringtheFutureofRoboticsandAIInsightsfromBenDitto_3.png)\n\nMindplex 팟캐스트 팀은 이 흥미로운 세상에 대해 고민하고 배우는 것을 함께해보기를 당신을 초대합니다. 서로 이해하고 협력하여 선의의 싱귱러리를 만들어 나가는 도중의 모든 어려움의 진정한 본질을 파악하는 데 도움이 되기를 기대합니다.\n\n<div class=\"content-ad\"></div>\n\n마인플렉스 팟캐스트와 마인플렉스 매거진은 싱귤래리티넷이 제공하는 마인플렉스 분산형 미디어 플랫폼의 일부입니다.\n\n마인플렉스 웹사이트를 방문해 프로필을 설정하고, 매거진에 기고할 수도 있습니다.\n\n## 팔로우하기:\n\n- 마인플렉스 매거진 방문하기\n- 텔레그램 가입하기\n- 마인플렉스 소셜 가입하기\n- 디스코드 가입하기\n- 트위터, 링크드인에서 팔로우하기\n- 페이스북에서 좋아요 누르기","ogImage":{"url":"/assets/img/2024-06-22-ExploringtheFutureofRoboticsandAIInsightsfromBenDitto_0.png"},"coverImage":"/assets/img/2024-06-22-ExploringtheFutureofRoboticsandAIInsightsfromBenDitto_0.png","tag":["Tech"],"readingTime":7},{"title":"RT-2, 구글의 새 혁신 실제 월-E를 만드는 비결","description":"","date":"2024-06-22 19:34","slug":"2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E","content":"\n\n안녕하세요! 아래는 Markdown 형식으로 변경된 표입니다.\n\n\n![이미지](/assets/img/2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E_0.png)\n\n\nChatGPT가 2022년 11월에 출시된 이후로, 전 세계가 AI를 중심으로 돌아가는 것 같죠.\n\n하지만 걱정하지 마세요. 이 글은 'ChatGPT는 놀라운 기술이다'를 다시 말하는 글이 아니에요. 오늘은 더 혁명적인 주제에 대해 이야기할 거예요.\n\n바로 Google Deepmind의 새로운 로봇, RT-2에 대해요.\n\n<div class=\"content-ad\"></div>\n\n로봇 팔이라 해도 RT-2는 그 중에서도 뛰어난 능력을 자랑해요. 실제로 RT-2를 만드는 데 구글은 이제까지 본 적 없는 새로운 AI 모델을 만들어야 했죠.\n\n융합된 지능이 이곳에 있습니다.\n\n그리고 아마도 월-이도요.\n\n## 여기에서 함께 나와 AI에 대해 쉽게 배워보세요!\n\n<div class=\"content-ad\"></div>\n\n# 새로운 모델 클래스\n\n지난 6개월 동안 인류가 AI로 이룬 성과는 정말 놀라운 것입니다.\n\n간단히 말해, 우리는 인간과 자연어를 통해 소통하는 기계를 누구나 이용할 수 있게 만들었습니다.\n\n하지만 AI의 잠재력은 단순한 텍스트를 뛰어 넘습니다. 많은 연구자들이 더 큰 목표를 향해 눈치를 돌리고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 다중 모드 구축을 향한 길\n\n최근 팟캐스트에서 AI 슈퍼히어로 앤드류 엔지가 컴퓨터 비전이라는 이미지를 처리하고 이해하기 위해 모델을 훈련시키는 AI 분야가 \"텍스트 프롬프팅\"보다 약 \"두 년 뒤\"라고 언급했습니다. 그러나 그는 그것이 해당 모델들과 동등한 혁명이 될 것으로 예상했습니다.\n\n그가 \"텍스트 프롬프팅\"로 언급한 것은 다름 아닌 대형 언어 모델 또는 LLM(Large Language Models)로, 그 중 가장 대표적인 예가 ChatGPT입니다.\n\n그러나 우리 모두가 알다시피, 우리가 능력 면에서 인간 수준의 기계를 구축하려면 우리인간이 다중 모드인것보다 훨씬 더 많은 것이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n일반적인 용어로 말하면, 우리는 세상에 대한 이해를 텍스트만으로 구축하지 않습니다. 우리에겐 눈이 있고, 귀가 있고, 촉감도 있죠... 우리의 모든 감각이 세상이 무엇인지를 파악하는 데 도움을 줍니다.\n\n실제로 이러한 감각들은 우리가 어릴 때 세상에 대해 배우는 데 도움을 줍니다. 우리가 맨 처음 문장을 읽기 보다 훨씬 이전부터 말이죠.\n\n그러므로 AI 연구자들이 텍스트뿐만 아니라 다른 것들도 처리하는 모델, 혹은 명확히 말하자면 멀티모달 모델을 만들고 싶어하는 것은 자연스러운 일입니다.\n\n그리고 이에 대한 AI 공간에서 가장 흥미로운 혁신 중 하나는 시각-언어 모델 중 하나입니다.\n\n<div class=\"content-ad\"></div>\n\n## VLMs, 더 ‘인간적인’ 기계들\n\n비전-언어 모델(VLMs)은 OpenAI의 CLIP이나 Microsoft의 Kosmos와 같은 모델로, 이름에서 알 수 있듯이 텍스트뿐만 아니라 이미지도 처리하는 모델입니다.\n\n예를 들어, OpenAI의 CLIP은 대조 손실 절차를 따라 이미지와 텍스트 사이에 얽혀 있는 임베딩 공간을 생성함으로써 작동합니다(간단히 말하면 동일한 것을 설명하는 이미지와 텍스트를 모아주는 것이 중요하며 Dall-E와 같은 확산 모델을 구축하는 데 필수적입니다). 그러나 Kosmos와 같은 모델은 아직 탐험하지 않은 잠재력을 보여주는 모델입니다.\n\nKosmos의 작동 방식은 매우 간단합니다. 이미지나 텍스트(또는 둘 다)를 보내면, 이에 기반하여 텍스트를 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n참고로, Carnegie Mellon University에서 개발한 이름이 GILL인 또 다른 VLM을 아래에서 확인할 수 있습니다. 시각적 프롬프팅이 정확히 무엇인지 명확하게 이해할 수 있습니다:\n\n![GILL](https://miro.medium.com/v2/resize:fit:1056/1*IXxrTUmN37X9vs8dqK85-w.gif)\n\n하지만 이제 Google은 한 단계 더 나아가고 있습니다.\n\n그들은 이러한 모델을 현실 세계로 가져오고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n로봇공학을 더 나은 수준으로 발전시키려는 시도 중에, Google Deepmind는 깨달음을 얻었습니다:\n\n그리고 그것으로, Google은 인공지능 로봇학의 새로운 핵심 요소인 Vision-language-action 모델(VLAs)을 만들었습니다.\n\n간단히 말해, VLAs는 로봇이 이후 이동을 수행하는 데 사용할 수 있는 동작을 출력할 수 있는 모델입니다.\n\n하지만 그것들이 정말 무엇이며, 왜 그렇게 혁신적인 것일까요?\n\n<div class=\"content-ad\"></div>\n\n## Wall-e, 그게 진짜야?\n\n로봇 공학 분야에서 연구자들을 미치게 만드는 것이 있다면, 그것은 분명히 데이터일 겁니다.\n\n사실 데이터의 부재일 때든요.\n\nAI 모델이 데이터의 양과 질에 완전히 의존한다는 점을 고려할 때, 후자는 가능했지만 전자는 정말 악몽이었어요.\n\n<div class=\"content-ad\"></div>\n\n따라서, 로봇공학을 더 나은 수준으로 발전시키기 위해 구글이 베팅을 했습니다:\n\n그들은 웹 규모의 텍스트와 이미지 데이터에 접근할 수 있는 VLM(범용 언어 모델)을 사용해 이러한 모델이 학습한 표현을 로봇으로 전이할 수 있다고 가설을 세웠습니다.\n\n간단히 말해서, 로봇 데이터를 기반으로 세계에 대한 고수준 의미 지식을 갖춘 로봇을 만드는 것이 이루기 어려운 일이라면, 기존의 VLM 모델을 사용하고 고품질의 로봇 데이터로 적합화시키는 것은 어떨까요?\n\n그리고 이제 이를 VLAs(로봇 언어 모델)라고 부를 수 있게 된 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 행동 예측기\n\nLLMs나 VLMs와 마찬가지로 VLAs도 동일한 일을 수행합니다. 토큰을 예측합니다.\n\n그러나 ChatGPT와 같이 텍스트 토큰을 예측하는 대신, RT-2와 같은 VLAs는 로봇이 수행해야 할 작업을 카메라 관측에 기반하여 예측할 수도 있습니다. 아래 이미지에서 확인할 수 있습니다:\n\n![이미지](/assets/img/2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E_1.png)\n\n<div class=\"content-ad\"></div>\n\n얻은 결과는 우리에게 매우 중요한 두 가지 교훈을 알려줍니다.\n\n## 일반화와 발생\n\nAI로봇 기술의 최첨단인 RT-2를 평가할 때 결과는 매우 명확합니다(RT-2 모델은 녹색과 파란색으로 표시됨):\n\n![RT-2 모델](/assets/img/2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E_2.png)\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! 항상 그렇듯이, 요점은 세부사항에 있습니다. RT-2를 주의 깊게 관찰하면, 이는 로봇공학의 가장 어려운 두 가지 임무, 즉 일반화와 신흥성에 뛰어난 성과를 보여줍니다.\n\n간단히 말하자면, RT-2는 교육 중 본 적이 없는 상황, 예를 들어 보이지 않는 물체나 환경과 같은 상황에서도 잘 수행하는 능력(일반화)과 VLM 덕분에 얻은 언어 지식의 규모로 학습한 새로운 예상치 못한 능력(신흥성)을 펼쳐냈습니다.\n\n가장 놀라운 점은: 이것이 첫 번째 추론이 가능한 로봇이라는 것입니다.\n\n이 점을 증명하기 위해, 구글이 진행한 6,000건 이상의 시험 중에서 몇 가지 인상적인 행동이 포함되어 있습니다:\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E_3.png)\n\n한 예를 들어 ‘추론’으로 볼 수 있는 것을 분석해 봅시다. 맨 위 두 번째 왼쪽을 보면, 로봇은 두 번째 과자봉지의 나쁜 위치를 이해하여 요청에 완벽히 대답할 수 있습니다.\n\n이 작업을 수행하려면, 모델은 카메라로 촬영된 이미지의 밀도가 높은 의미 지식이 필요했습니다. 즉, 탁자 끝에 있는 봉지가 떨어질 수 있다는 것을 이해하면서, 다른 봉지는 그렇지 않다는 것을 알아냈습니다.\n\n비슷하게, 아래 오른쪽 예에서 모델은 당나귀와 문어의 차이를 이해할 뿐만 아니라, “육지 동물”이 당나귀를 의미한다는 것을 생각할 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n더 정량적인 관점에서 구글은 모델을 세 가지 기준으로 평가했습니다:\n\n- 심볼 이해\n- 추론\n- 인간 인식\n\n놀랍게도, RT-2는 이 모든 면에서 우수하게 성과를 거두었으며, 다음에 나온 예시와 같은 동작을 수행할 수 있는 능력을 입증했습니다:\n\n![이미지](/assets/img/2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E_4.png)\n\n<div class=\"content-ad\"></div>\n\n인상적인 점은 RT-2가 알 수 없는 상황에서 잘 작동할 수 있었던 것처럼, 위의 이미지들도 새로운 업무를 수행할 수 있는 능력을 보여줍니다. 다시 말해, 시각 언어 모델을 추가하더라도 새로운 로봇 동작을 생성하는 데는 한계가 있었지만 (논문에서 인정함), 로봇에 풍부한 의미 지식을 전달하여 배치, 물체 인식, 논리 추론과 같은 복잡하고 신흥 개념에 대해 훨씬 더 인식력을 갖도록 만들었습니다.\n\n# 혁신의 바퀴는 계속 회전합니다\n\nRT-2를 본 이후에는 내년 말까지 세계 각국의 제조업체가 이러한 로봇을 사용하여 프로세스를 개선하는 것이 놀라운 일이 아닐 것입니다.\n\n<div class=\"content-ad\"></div>\n\n인공지능 로봇들은 주변 환경에 대해 훨씬 더 인식력을 가지고 있습니다. 그들의 신경망 속에 점점 더 복잡한 세계 모델을 구축하여 하루가 다르게 진화하고 있는데, 이는 수천 년이 걸린 인간들의 진화에 의해 이루어졌던 것과 매우 가까워지고 있습니다.\n\n그러나 많은 사람들은 이러한 모델들이 단순한 확률론적 앵무새에 불과하다고 주장할 것입니다. 이들은 그저 \"지능적인 활동\"을 단순히 암기하는 것으로 여기는 것이죠.\n\n그러나 가장 이상하고 예상치 못한 경우에도 \"지능적으로\" 행동하는 기계들을 보면, 이 모델들이 자신이 하는 일을 실제로 이해한다고 주장하지 않을 수 있는 것이 정말로 도전이 됩니다. 이제 이러한 모델들은 \"체화된 지능\"이라고 묘사하는 것과 같이 지능적인 물리적 행동을 수행할 수 있는 조건에 이르렀습니다.\n\nRT-2에 관한 것을 생각해보면, 이는 바로 진행 중인 로봇 기술이 미래의 몇 달 동안 어떻게 진화할지에 대한 단순한 꼭대기에 지나지 않을 것입니다. 그래서 아마도 영화 '월-E'가 우리 삶에서 생각했던 것보다 그렇게 멀리 떨어져 있지 않다는 생각이 들 수도 있겠네요.\n\n<div class=\"content-ad\"></div>\n\n프레스 릴리스와 연구 논문 링크입니다.","ogImage":{"url":"/assets/img/2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E_0.png"},"coverImage":"/assets/img/2024-06-22-RT-2GooglesNewBreakthroughToBuildWall-E_0.png","tag":["Tech"],"readingTime":6},{"title":"진화하는 로봇 뇌 2024 최신 기술과 트렌드","description":"","date":"2024-06-22 19:33","slug":"2024-06-22-Evolvingrobotbrains","content":"\n\n제 학사 학위 논문 이후에 오랜만이네요. 그때 했던 것들을 함께 공유해보려고 합니다.\n\n![로봇 뇌 발전](/assets/img/2024-06-22-Evolvingrobotbrains_0.png)\n\n여기서 말하는 로봇이란 실제 세계에서 일을 하는 기계를 의미하고, 뇌란 AI 알고리즘을 의미합니다. \n\n좀 더 자세히 설명하자면, 그 AI 알고리즘은 신경망입니다. 모두가 이미 알고 있듯이, 신경망은 생물학적 뇌에서 영감을 받았지만 이제 다시 강조해보는 것도 좋을 것 같아요. 이게 왜 이때에 관련이 있는지 조금 있다 보시면 아실 거예요.\n\n<div class=\"content-ad\"></div>\n\n진화란, 로봇을 제어하는 데 충분히 좋은 신경망을 \"검색\"하는 것을 의미합니다.\n\n본문에서 설명할 로봇의 작업은 붉은 레이저 포인터를 따라가는 것입니다.\n\n이 작업을 수행할 수 있는 신경망을 \"검색\"하는 방법은 여러 가지가 있지만, 저에게 특히 흥미로웠던 방법은 유전 알고리즘을 사용하여 검색하는 것이었습니다. 이 방법은 자연 진화에서 영감을 받은 것입니다. 지금 이해할 수 있겠지만, 왜 신경망이 생물학적 뇌에서 영감을 받았는지 말씀드린 이유입니다. 생물학적 뇌와 자연 진화는 자연에서 매우 잘 작동했고 (우리를 창조했습니다); 따라서 이들의 알고리즘적 유사물을 사용하여 로봇을 만드는 것은 유망한 아이디어입니다. 이 접근 방식을 연구하는 분야를 신경 진화(neuroevolution)라고 부릅니다.\n\n저는 Omni 바퀴가 3개 달린 로봇을 만들었기 때문에 각 바퀴에 적절한 토크를 가해 어떤 방향으로든 움직일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그것을 제어하는 신경망은 두 개의 입력과 두 개의 출력을 갖고 있어요.\n\n![image](/assets/img/2024-06-22-Evolvingrobotbrains_1.png)\n\n타겟의 위치(빨간 레이저 포인터)를 감지하기 위해, 로봇에 부착된 스마트폰의 비디오 스트림을 분석하는 매우 간단한 프로그램을 사용했어요. 비디오에서는 빨간색 픽셀로 둘러싸인 가장 흰색이었던 픽셀들을 찾고 있어요. 여기에 레이저 포인터가 있어요. 그 중심은 빛이 너무 세서 흰색이고, 중심 주변은 빨간색이에요.\n\n![image](/assets/img/2024-06-22-Evolvingrobotbrains_2.png)\n\n<div class=\"content-ad\"></div>\n\n이 지점의 픽셀 좌표는 뉴럴 네트워크에 입력되며, 초기에 무작위로 예측된 두 개의 숫자가 원하는 로봇 이동을 나타냅니다.\n\n이동을 각 바퀴에 필요한 토크로 변환하기 위해 공식이 있습니다.\n\n아래는 유전 알고리즘을 사용하여 충분히 좋은 네트워크를 찾기 위한 중요한 두 가지입니다:\n\n<div class=\"content-ad\"></div>\n\n- 먼저 각 네트워크에 대해 점수 매기기를 해야 해요.\n- 두 번째로, 선택사항이지만 프로세스 속도를 높이는 데 많은 도움이 되는 것은 로봇을 시뮬레이션하는 것입니다. 운 좋게도 이 작업은 너무 간단해서 시뮬레이션에 문제가 되지 않아요.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1200/1*jjwsVjTC3L3tww9A7Il30w.gif)\n\n내 시뮬레이션은 표준 유전 알고리즘 단계를 따라갑니다:\n\n- 초기의 무작위 인공신경망 모집단 생성\n- 시뮬레이션에서 모두 평가\n- 점수 지정\n- 점수를 기반으로 다음 인공신경망 모집단을 만들 때 사용할 네트워크 결정\n\n<div class=\"content-ad\"></div>\n\n이러한 단계를 여러 차례 반복한 후에는 신경망이 작업을 수행하는 데 점점 더 잘되는 것이 명백하게 보입니다.\n\n![이미지](/assets/img/2024-06-22-Evolvingrobotbrains_4.png)\n\n## 데모\n\n성능이 우수한 하나의 신경망을 선택하여 이 신경망에 스마트폰 카메라에서 발견한 빨간 점의 위치를 공급했습니다. 네트워크의 출력을 토크 값으로 변환하고, 마지막으로 아두이노를 사용하여 모터가 바퀴를 회전하도록했습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](https://miro.medium.com/v2/resize:fit:640/1*fEWqKo2wyiaOo4Nmb3wO9A.gif)\n\n## 다음은 무엇인가요?\n\n이미지 처리를 입력 단계로 추가하여 네트워크에 깔끔하고 간단한 입력을 생성하는 단축키를 사용했어요. 비디오 스트림을 직접 네트워크에 공급하는 것은 더 어려울 수 있어요. 특히 이러한 큰 네트워크에 신경 진화를 어떻게 적용할 수 있는지 흥미롭게 생각해봐야 할 것 같아요.\n","ogImage":{"url":"/assets/img/2024-06-22-Evolvingrobotbrains_0.png"},"coverImage":"/assets/img/2024-06-22-Evolvingrobotbrains_0.png","tag":["Tech"],"readingTime":3},{"title":"라즈베리 파이 제로 W로 WiFi 카메라 직접 만드는 방법","description":"","date":"2024-06-22 19:32","slug":"2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW","content":"\n\n넓은 선택지를 가진 소비자용 WiFi 카메라가 있습니다. 아기 모니터나 가정 감시와 같은 용도로는 적합할 수 있지만, 몇 가지 단점이 있습니다. 매우 자주 소유권 애플리케이션을 사용해야 할 수도 있지만 그러한 애플리케이션은 전혀 유지보수되지 않을 수 있고 또한 클라우드 서비스와 통합될 수도 있어 편리하지만 여전히 보안 위험이 될 수 있습니다. 네트워크 구성에 따라 카메라가 전체 인터넷 액세스를 받아 악의적인 행동을 할 수 있습니다.\n\n만약 이러한 사항들이 걱정이 된다면, 그리고 더 높은 수준의 신뢰성을 가진 WiFi 카메라를 원한다면, 대안으로 자체 제작해보는 것도 좋은 경험이 될 수 있습니다. 선택한 하드웨어에 따라 예산을 유지하는 동시에 저렴하고 신뢰할 수 있는 장치를 얻을 수 있습니다. 이 기사에서는 Raspberry Pi Zero W를 사용하여 어떻게 만드는지 보여줄 것입니다. 하지만 이 일반적인 개념은 WiFi를 지원하는 대부분의 Linux 장치에서도 작동할 것입니다.\n\n## 하드웨어 선택\n\n내 설정에서는 Raspberry Pi Zero W와 5MP Raspberry Pi 카메라를 선택했고, 비용은 약 24유로였습니다. 또한 SD 카드와 마이크로 USB 전원 어댑터를 구입했는데, 이것은 추가 9유로였습니다. 주의해야 할 점은 풀 사이즈 Raspberry Pi와 Raspberry Pi Zero에는 다른 CSI 포트가 있으므로 다른 종류의 평평한 케이블이 필요하다는 것입니다. 카메라 모듈을 주문할 때 적절한 종류를 선택해야 합니다. [Link Text](https://www.arducam.com/raspberry-pi-camera-pinout/)\n\n![이미지](/assets/img/2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW_0.png)\n\n<div class=\"content-ad\"></div>\n\n필요에 따라 프리미엄 구성품으로 선택할 수도 있습니다. 목록에 있는 설정은 스트림 처리량과 품질 면에서 놀라운 성능을 제공하지는 않을 거예요.\n마지막으로 하드웨어용 케이스도 구입하거나 가장 마음에 드는 3D 모델을 찾아서 인쇄할 수도 있어요.\n\n## OS 설정\n\n기본적으로 리눅스 OS가 실행되어 WiFi에 연결되고 SSH를 통해 로그인할 수 있어야 해요. 이 단계에 도달하기 위해서 https://medium.com/@celecavac/setting-up-a-headless-raspberry-pi-the-hard-way-15e78e644d50 에 방문해보세요.\n\n## RTSP\n\n<div class=\"content-ad\"></div>\n\n이 카메라 설정에서는 실시간 스트리밍 프로토콜(RTSP)을 사용할 것입니다. 과거에는 rtsp-simple-server가 이를 위한 인기 있는 도구였습니다. 현재도 사용 가능하지만 미디어MTX 프로젝트의 일부로 이용할 예정입니다.\n\n이를 실행하기 위해 라즈베리 파이에서 다음 명령을 실행하여 libcamera0 및 libfreetype6 패키지를 설치해야 합니다:\n\n```js\nsudo apt update\nsudo apt upgrade -y\nsudo apt install -y libcamera0 libfreetype6\n```\n\n그런 다음 https://github.com/bluenviron/mediamtx/releases 에서 최신 릴리스를 선택할 수 있습니다. 저는 현재 v1.1.1 버전을 선택하여 armv6 변형을 사용했습니다. 나중에 'Illegal instruction' 오류가 발생하면 적합하지 않은 CPU 아키텍처를 사용하여 릴리스를 다운로드했을 가능성이 큽니다.\n아카이브를 다운로드하려면 다운로드 링크를 복사하여 `wget url` 명령을 사용할 수 있습니다. 다운로드가 완료되면 명령 `tar -xzf archive-name --one-top-level`를 사용하여 내용을 추출할 수 있습니다. 이 과정은 다음과 비슷해야 합니다:\n\n<div class=\"content-ad\"></div>\n\n\n![Wi-Fi Camera](/assets/img/2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW_1.png)\n\n생성된 디렉토리의 이름을 변경하고 아카이브를 삭제할 수도 있습니다:\n\n```js\nmv mediamtx_v1.1.1_linux_armv6 mediamtx\nrm mediamtx_v1.1.1_linux_armv6.tar.gz\n```\n\n이 시점에서 우리는 단지 mediamtx.yml 파일을 업데이트하여 Wi-Fi 카메라를 실행할 수 있습니다. 파일을 살펴보고 필요없는 설정 및 프로토콜을 비활성화할 수 있지만, paths: 섹션 하위의 모든 것을 삭제하고 다음을 입력하는 것이 주요 작업입니다:\n\n\n<div class=\"content-ad\"></div>\n\n```yaml\npaths:\n  cam:\n    source: rpiCamera\n    rpiCameraWidth: <width>\n    rpiCameraHeight: <height>\n```\n\n내 상황에 가장 잘 작동한다는 것을 발견하여 width=1280 및 height=720으로 설정하면 다음과 같이 보입니다:\n\n![image](/assets/img/2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW_2.png)\n\n이제 바이너리를 실행하고 YAML 파일 경로를 제공하여 서버를 시작할 수 있습니다. `./mediamtx mediamtx.yml`\n\n<div class=\"content-ad\"></div>\n\n\n![](/assets/img/2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW_3.png)\n\n내 네트워크의 다른 모든 기기에서 스트림을 사용할 수 있게 됩니다. 테스트를 위해 ffplay rtsp://`rpi-ip-address`:8554/cam 및 ffplay rtsp://raspberrypi.local:8554/cam을 사용할 수 있습니다. Debian 기반 시스템에서는 sudo apt install ffmpeg을 사용하여 ffplay를 설치할 수 있습니다.\n\n![](/assets/img/2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW_4.png)\n\n## 자동 시작\n\n\n<div class=\"content-ad\"></div>\n\n현재 설정에서는 Raspberry Pi에 로그인하고 매번 재부팅할 때마다 ./mediamtx mediamtx.yml을 수동으로 실행해야 합니다.\n이를 피하기 위해 mediamtx 서비스를 정의하고 RTSP 서버를 자동으로 시작할 수 있습니다.\n\nmediamtx 서비스 파일을 생성하고 아래 내용을 입력하려면 sudo nano /etc/systemd/system/mediamtx.service를 실행할 수 있습니다:\n\n```js\n[Unit]\nDescription=MediaMTX service\nWants=network.target\n\n[Service]\nExecStart=/home/pi/mediamtx/mediamtx /home/pi/mediamtx/mediamtx.yml\n\n[Install]\nWantedBy=multi-user.target\n```\n\n서비스는 아직 활성화되지 않았으며, 이를 달성하려면 다음 명령을 실행하면 됩니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nsudo systemctl daemon-reload\nsudo systemctl enable mediamtx.service\n```\n\n앞으로 라즈베리 파이를 다시 부팅할 때마다 RTSP 서버가 자동으로 시작됩니다.\n\n## 보안\n\n이제 WiFi 카메라가 사용 가능하며 쉽게 사용할 수 있는 핵심 기능을 갖추고 있습니다. 그러나 누구든지 네트워크에 액세스할 수 있는 경우 완전히 노출됩니다. 인증이 없으며 비디오 스트림이 암호화되지 않은 상태로 전송됩니다.\n이 문제를 한 가지 해결책으로 다루기 위해 직접 액세스를 차단하고 모든 것을 SSH 터널을 통해 전송하도록 설정할 수 있습니다. SSH는 이미 활성화되어 있어 연결이 기본적으로 인증되고 암호화됩니다.\n\n<div class=\"content-ad\"></div>\n\n어떤 일을 하기 전에 mediamtx.yml 파일로 돌아가서 # RTSP 설정 섹션을 수정해 봅시다. 여기서는 프로토콜을 [udp, multicast, tcp] 에서 TCP로만 제한하려고 합니다. 따라서 protocols [tcp]로 변경해야 합니다.\n\nRTSP 포트에 대한 액세스를 비활성화하려면 간단히 Uncomplicated Firewall을 설치하고 SSH를 화이트리스트에 추가하고 실행해 봅시다:\n\n```js\nsudo apt install -y ufw\nsudo ufw allow ssh\nsudo ufw enable\n```\n\n그런 다음 `ffplay rtsp://rpi-ip-address:8554/cam` 또는 `ffplay rtsp://raspberrypi.local:8554/cam` 을 사용하여 스트림에 다시 액세스해 보고 더 이상 액세스할 수 없는지 확인할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nSSH 터널을 통해 스트림을 보내려면 라즈베리 파이의 포트를 로컬 머신에 바인딩할 수 있습니다. 동일한 포트 8554를 사용할 수 있지만 필수는 아닙니다. 로컬로 동일한 포트를 사용하는 여러 카메라를 바인딩하려면 다른 포트 번호를 사용하는 것이 더 간단합니다.\n원격 포트 8554를 8601로 바인딩하려면 다음 명령을 실행할 수 있습니다: ssh -NL 8601:localhost:8554 pi@raspberrypi.local 또는 ssh -NL 8601:localhost:8554 pi@`라즈베리파이-IP주소`.\n어쩌면 각 부팅 시에 이 명령을 자동으로 실행하고 싶을 수도 있습니다. 그렇다면 비슷한 방식으로 Auto-start 섹션에 표시된대로 사용자 지정 서비스 이름을 사용하고 이 명령을 ExecStart= 옆에 추가할 수 있습니다.\n\n명령이 실행 중이면 해당 기기에 포트가 바인딩되어 있어야 합니다. 우리가 이 명령을 실행하는 기기로 ffplay 명령을 직접 라즈베리 파이로 방향 전환하지 않아도 되며 현재 액세스하려는 기기로 직접 전환해야 합니다. 포트 번호도 변경되었음을 유의하세요: ffplay rtsp://localhost:8601/cam\n\n마지막으로, 이것은 당연한 일일 수 있지만, 기본 비밀번호를 사용했다면 비밀번호를 변경해야 합니다. sudo raspi-config를 실행한 다음 System Options로 이동하여 Password로 이동하여 변경할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW_0.png"},"coverImage":"/assets/img/2024-06-22-BuildingyourownWiFicamerawithRaspberryPiZeroW_0.png","tag":["Tech"],"readingTime":6}],"page":"29","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}