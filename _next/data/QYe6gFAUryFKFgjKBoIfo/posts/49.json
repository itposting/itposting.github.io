{"pageProps":{"posts":[{"title":"소형 머신 러닝 - 주성분 분석","description":"","date":"2024-06-20 17:00","slug":"2024-06-20-TinyMLPrincipalComponentAnalysis","content":"\n\nFrom mathematical foundations to edge implementation\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 Research group: Conecta.ai (ufrn.br)\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_0.png)\n\n<div class=\"content-ad\"></div>\n\n# 1 — PCA 알고리즘 이론\n\n주성분 분석 (PCA)은 데이터 분석에서 널리 사용되는 강력한 기술로, 데이터 세트의 차원을 줄이면서 중요한 정보를 유지하는 데 특히 유용합니다. 이는 원래 변수를 주성분이라고 불리는 새로운, 상관관계가 없는 변수 세트로 변환하여 달성됩니다. PCA의 주요 측면을 자세히 살펴봅시다:\n\n- 차원 축소: PCA는 고차원 데이터 세트를 처리하는 데 중요합니다. 중요한 정보를 추출하고 관련성이 낮은 특징을 제거하여 분석 프로세스를 단순화합니다.\n- 데이터 탐색 및 시각화: PCA는 데이터 탐색 및 시각화에 중요한 역할을 합니다. 숨겨진 패턴과 통찰을 찾아내는 데 기여합니다.\n- 선형 변환: PCA는 데이터의 선형 변환을 수행하며, 분산의 방향을 식별하는 데 목적을 두고 있습니다. 이를 통해 데이터 세트의 더 간결한 표현이 가능해집니다.\n- 특성 선택: 주성분은 설명하는 분산에 기반하여 순위가 매겨집니다. 이 순위는 데이터의 가장 중요한 측면을 강조하는 효과적인 특성 선택을 용이하게 합니다.\n- 데이터 압축: PCA는 데이터를 압축하는 데 뛰어납니다. 큰 데이터 세트의 효율적인 저장 및 처리를 위해 원본 정보의 상당 부분을 유지합니다.\n- 클러스터링 및 분류: PCA는 클러스터링 및 분류 작업에서 실용적으로 활용됩니다. 잡음을 줄이고 기존 구조를 강조함으로써 알고리즘의 성능을 향상시킵니다.\n\n## 1.1 — 데이터 적합성\n\n<div class=\"content-ad\"></div>\n\n\"Adequacy of Data\" 또는 \"Data Suitability\"는 일반적으로 사용 가능한 데이터가 특정 목적이나 분석에 적합하고 충분하며 관련성 있는지 여부를 나타냅니다. 그것은 손에 있는 데이터가 의도된 사용 또는 연구에 필요한 요구 사항과 기준을 충족하는지를 평가합니다.\n\n1.1.1 — Kaiser-Meyer-Olkin(KMO)\n\nKaiser-Meyer-Olkin 측정치는 분석을 위한 표본의 적절성을 평가하며, 고려중인 변수가 구분된 신뢰성 있는 요인을 얻을 것으로 예상되는지 여부를 나타냅니다. KMO 통계치는 0에서 1 사이의 범위 내에 있으며, 더 높은 값은 요인 분석에 더 적합함을 나타냅니다.\n\n- KMO가 0.5 이상일 경우: 주로 허용 가능하다고 간주되며, 데이터 집합이 요인 분석에 적합함을 나타냅니다.\n- KMO가 0.5 미만일 경우: 데이터 집합이 요인 분석에 적합하지 않을 수 있다는 것을 시사합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_1.png\" />\n\n1.1.2 — Bartlett의 구형성 검정\n\nBartlett의 구형성 검정은 요인 분석의 맥락에서 사용되는 통계적 검정으로, 관측된 변수들의 상관 행렬이 항등 행렬과 유의하게 다른지를 결정하기 위해 사용됩니다. 간단히 말하면, 이는 변수들 사이에 충분한 상관관계가 있는지를 평가하여 요인 분석을 계속 진행할 수 있는지 여부를 파악하는 데 도움이 됩니다.\n\n다음은 Bartlett의 구형성 검정의 자세한 단계와 수학적 공식입니다:\n\n<div class=\"content-ad\"></div>\n\n단계 1: 가설 설정\n\n- 귀무가설 (H0): 관찰된 상관 행렬은 독립 행렬이며 변수 간 상관 관계가 없음을 나타냅니다.\n- 대립가설 (H1): 관찰된 상관 행렬은 독립 행렬이 아니며 변수 간 유의한 상관 관계가 있다는 것을 시사합니다.\n\n단계 2: 바트렛의 구형성 검정 통계량 계산\n\n바트렛의 구형성 검정 통계량은 카이제곱 (χ2) 분포를 따릅니다. 검정 통계량의 공식은 다음과 같습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_2.png\" />\n\n여기서:\n\n- n은 관찰값의 수입니다.\n- p는 변수의 수입니다.\n- det(R)은 관찰된 상관 행렬의 행렬식입니다.\n- det(I)은 항등 행렬의 행렬식입니다.\n\n단계 3: 자유도 결정\n\n<div class=\"content-ad\"></div>\n\n자유도(df)는 카이 제곱 분포의 경우 다음과 같이 계산됩니다:\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_3.png)\n\n단계 4: 임계값과 비교\n\n계산된 χ² 통계량을 선택한 유의 수준 (예: 0.05)에서 카이 제곱 분포 표의 임계값과 비교합니다.\n\n<div class=\"content-ad\"></div>\n\n### 단계 5: 결정 내리기\n\n만약 계산된 χ2 값이 임계값보다 크다면, 귀무가설을 기각해야 합니다. 이는 변수들 간에 상관 관계가 유의미하며 요인 분석이 적절할 수 있다는 것을 시사합니다.\n\n### 1.2 — 상관계수 행렬\n\n변수 집합에 대한 Pearson 상관계수 행렬은 행렬 형태로 표현될 수 있습니다. n개의 변수를 X1,X2,…,Xn으로 표시한다고 가정해 봅시다. 이러한 변수에 대한 Pearson 상관계수 행렬 R은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_4.png)\n\nHere:\n\n- The diagonal elements (main diagonal) are all 1 because each variable perfectly correlates with itself.\n- The off-diagonal elements (rij) represent the Pearson correlation coefficient between variables Xi and Xj.\n- The matrix is symmetric (rij=rji) because the correlation between Xi and Xj is the same as the correlation between Xj and Xi.\n\nThe formula to compute rij (Pearson correlation coefficient between Xi and Xj) is given by:\n\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_5.png)\n\n이 공식에는 평균 (Xˉi 및 Xˉj) 및 제곱 차이의 합이 포함되어 있습니다. 두 변수에 대한 이전에 설명한 쌍별 계산과 유사합니다.\n\n피어슨 상관 관계는 선형 관계만을 측정하므로 비선형 관계는 포착하지 못할 수 있습니다. 피어슨 상관 계수는 -1에서 1 사이의 범위를 가집니다:\n\n- r=1: 완벽한 양의 상관 관계;\n- r=−1: 완벽한 음의 상관 관계;\n- r=0: 선형 상관 관계 없음.\n\n<div class=\"content-ad\"></div>\n\n## 1.3 — 고유값과 고유벡터\n\n1.3.1 — 고유값 (λ)\n\n고유값은 데이터의 최대 변이성을 포착하는, 정사각 행렬에서 유도된 독립적인 벡터들입니다. 고유값은 따라서 연구된 변수들에 의해 포착된 총 분산의 부분으로 이해될 수 있습니다.\n\n- 고유값은 식 Av=λv이 비제로 해 v를 가지는 스칼라 λ입니다.\n- 종종 λ로 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n고윳값을 찾는 방정식은 A를 원래 행렬에서 λI(단위 행렬)을 뺀 후 Determinant를 구하여 얻는 특성 방정식을 풀어야 합니다:\n\ndet(A−λI)=0\n\nλ에 대한 이 방정식을 해결하면 행렬 A의 고윳값을 얻게 됩니다.\n\n1.3.2 —고유벡터 (v)\n\n<div class=\"content-ad\"></div>\n\n- 고유벡터는 방정식 Av=λv를 만족하는 0이 아닌 벡터 v입니다.\n- 종종 v로 표기됩니다.\n\n- 고유값을 구했다면, 각 고유값을 방정식 Av=λv에 대입하여 v에 대해 풀어서 해당하는 고유벡터를 찾을 수 있습니다. 이 솔루션들이 고유벡터를 형성합니다.\n\n이 과정은 아래와 같이 요약될 수 있습니다:\n\n- 고유문자식: det(A−λI)=0;\n- 고유값(λ) 구하기: 고유문자식을 해결하여 고유값 λ를 찾습니다.\n- 고유벡터(v) 찾기: 각 고유값 λ에 대해, (A−λI)v=0인 선형 방정식을 풀어 해당하는 고유벡터 v를 찾습니다.\n\n<div class=\"content-ad\"></div>\n\n## 1.4 — 요인들\n\nPCA는 식별된 직교 기저의 새로운 축을 나타내는 요인의 집합입니다. 첫 번째 요인은 샘플의 분산을 가장 잘 설명하는 조합입니다. 두 번째 요인은 두 번째로 높은 분산을 설명하며 첫 번째 요인과 관련이 없습니다. 이와 같이 계속됩니다. 따라서 PCA 알고리즘의 출력은 초관련 변수 집합으로부터 유도된 상관관계가 없는 변수 집합입니다.\n\nPCA에서 주성분(요인)을 형성하기 위해 원래 변수들의 선형 조합을 행렬 형태로 표현할 수 있습니다. 표준화된 데이터 행렬을 Z로 표시하고(열은 표준화된 변수를 나타냄), 고유벡터 행렬을 V로 표시합니다(열은 고유벡터를 나타냄). k번째 주성분(Fk)을 얻기 위한 선형 조합은 다음과 같이 표현될 수 있습니다:\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_6.png)\n\n<div class=\"content-ad\"></div>\n\n여기에는 Z가 표준화된 데이터 행렬이고, Vk는 k번째 고유값에 해당하는 고유벡터 행렬의 k번째 열입니다. Fk의 개별 요소는 다음과 같이 표현될 수 있습니다:\n\n\n| Fk1 |\n| Fk2 |\n| ... |\n| Fkn |\n\n\n이 식에서 Fki는 k번째 주성분의 i번째 관측값, Zij는 j번째 표준화된 변수의 i번째 관측값, Vjk는 j번째 고유벡터의 k번째 요소입니다.\n\n이 선형 결합을 사용하여 k번째 주성분을 원래 표준화된 변수들의 가중 합으로 표현할 수 있습니다. 가중치는 k번째 고유벡터의 요소로 제공됩니다. 각 주성분은 원래 변수들의 다른 선형 결합을 나타내며, 데이터의 최대 분산을 포착합니다.\n\n<div class=\"content-ad\"></div>\n\n1.4.1 — 요인 수\n\n- 카이저의 규칙: 이 방법은 각각의 고유값이 1보다 큰 값을 가지는 요인을 선택하는 방법으로 구성되어 있습니다. 다시 말해서, 우리는 1 이상의 분산을 설명하는 요인들만 사용하고 싶습니다.\n- 공유 분산 분석: 이 방법은 누적된 공유 분산의 합을 분석하는 주관적인 방법입니다. 이 방법을 통해 우리는 가능한 한 적은 수의 요인을 유지하면서 가장 많은 분산을 설명하는 요인의 수를 선택하려고 합니다. 이를 위해, 비즈니스 문제에 따라 70~90%의 공유 분산이 설명되면 충분할 수 있으므로, 공유 분산의 70~90%를 합한 요인이 정의될 것입니다.\n\n## 1.5— 요인 부하\n\n요인 부하는 특정 요인에 대한 각 원본 변수에 할당된 가중치를 의미합니다. 이러한 부하는 각 변수와 해당 요인간의 관계의 강도와 방향을 나타냅니다. 요인 부하의 수학적 설명을 살펴봅시다.\n\n<div class=\"content-ad\"></div>\n\nPCA에서 요인 적재량은 표준화된 데이터의 공분산 행렬 또는 상관 행렬의 고유벡터에서 유도됩니다. Vk가 k번째 고유값에 연결된 고유벡터라고 가정해 봅시다. j번째 변수와 k번째 요인의 요인 적재량(λjk)은 Vk의 요소에서 얻어집니다.\n\n요인 적재량은 원래 변수 Xj가 k번째 요인에 얼마나 기여하는지를 나타냅니다. λjk가 양수이면, Xj와 k번째 요인 사이에 긍정적 상관 관계가 있다는 것을 시사하며, 음수이면 음적 상관 관계를 시사합니다. 요인 적재량의 크기는 관계의 강도를 나타냅니다.\n\n요인 모델에서 요인 적재량(λjk)은 원래 변수와 잠재적인 요인 사이의 관계를 나타내는 매개변수입니다. 이 모델은 다음과 같이 표현됩니다:\n\n<div class=\"content-ad\"></div>\n\n아래와 같은 테이블을 Markdown 포맷으로 바꿔주세요.\n\n\n| 변수 | 설명 |\n|------|------|\n| Xj   | j번째 원본 변수 |\n| λjk  | Xj와 k번째 요인 간의 관계를 나타내는 요인 로딩 |\n| Fk   | k번째 잠재 요인 |\n| εj   | j번째 변수와 연관된 오차 |\n\n\n<div class=\"content-ad\"></div>\n\n기존 변수에서 잠재 요인으로 설명되는 분산의 비율을 의미합니다. \"공용성\"의 수학적 설명을 살펴보겠습니다.\n\n만약 p개의 원래 변수 X1,X2,…,Xp가 있다면, j번째 변수 (Hj)의 공용성은 다음과 같이 계산됩니다:\n\n\n<div class=\"content-ad\"></div>\n\n- m은 인자의 수입니다.\n- λjk는 j번째 변수의 k번째 인자에 대한 인자 적재입니다.\n\n공통 분산은 잠재적 요인에 의해 설명된 Xj 변수의 분산의 총량을 나타냅니다. 합계에서 각 항목 2λjk^2은 공통 분산에 기여하며, k번째 인자에 의해 설명된 변수 Xj의 분산의 비율을 나타냅니다.\n\n실용적으로, Hj가 1에 가까우면 변수 Xj가 잠재적 요인에 의해 잘 설명된다는 것을 나타냅니다. 0에 가까우면 변수는 모델의 요인들에 의해 잘 표현되지 않습니다.\n\n모든 변수의 공통성의 합계는 모델의 요인들에 의해 설명된 총 분산의 전반적인 지표입니다. 변수가 p개인 경우, 총 분산은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n아래는 요인에 의해 설명된 분산이며:\n\n![image2](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_12.png)\n\n요인에 의해 설명된 분산의 비율은 요인에 의해 설명된 분산을 총 분산으로 나누어 계산할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 2— TinyML 구현\n\n이 예시를 통해 ESP32, 아두이노, 라즈베리파이 및 다른 다양한 마이크로컨트롤러 또는 IoT 장치에 기계 학습 알고리즘 (PCA)을 구현할 수 있습니다.\n\n1 — 다음 명령으로 micromlgen 패키지를 설치하세요:\n\n```js\n!pip install micromlgen\n!pip install factor_analyzer\n```\n\n<div class=\"content-ad\"></div>\n\n2 — 라이브러리 가져오기\n\n```python\nfrom micromlgen import port\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport numpy as np\n\nfrom factor_analyzer.factor_analyzer import calculate_kmo\nfrom factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\nfrom factor_analyzer import FactorAnalyzer\n```\n\n3 — 데이터셋 로드\n\nDecathlon\n\n<div class=\"content-ad\"></div>\n\n41행 13열로 구성된 데이터베이스가 있습니다. 첫 10개 열은 각 선수의 10종목 경기 성적에 해당합니다. 열 11과 12는 각각 선수의 등급과 획득한 점수를 나타냅니다. 마지막 열은 2004년 올림픽 게임 또는 2004년 데카스론과 같은 종목에 해당하는 범주형 변수입니다.\n\n다음은 변수입니다.\n\n- 100m (100m 달리기)\n- long.jump (멀리뛰기)\n- shot.put (역도)\n- High.jump (높이뛰기)\n- 400m (400m 달리기)\n- 110m.hurdle (110m 허들)\n- Discus (원반 던지기)\n- Pole.vault (양봉)\n- Javeline (투창)\n- 1500m (1500m 달리기)\n\n\npatch = './data/decathlon.csv'\ndf = pd.read_csv(patch, index_col=0)\n\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! 아래는 Markdown 형식으로 테이블의 변경 내용이 있습니다.\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_13.png\" />\n\n4 — 데이터셋 시각화\n\n```js\nsns.pairplot(df)\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_14.png\" />\n\n<div class=\"content-ad\"></div>\n\n5- 데이터 표준화하기\n\n```js\ncolumns_selected = ['100m', 'Long.jump', 'Shot.put', 'High.jump', '400m', '110m.hurdle',\n       'Discus', 'Pole.vault', 'Javeline']\n\nX = df[columns_selected]\n```\n\n```js\nX_standardized = StandardScaler().fit_transform(X)\ndf_X_standardized = pd.DataFrame(X_standardized, columns=columns_selected)\n```\n\n6- 데이터의 상관 행렬 분석하기\n\n<div class=\"content-ad\"></div>\n\n6.1- 상관 행렬\n\n```js\ncorr = X.corr()\ncorr\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_15.png\" />\n\n```js\n# 그림 크기 조정\nplt.figure(figsize=(10, 8))\n\n# 히트맵 생성을 위한 기존 코드\nsns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)\n\n# 히트맵에 값 추가\nfor i in range(len(corr.columns)):\n    for j in range(len(corr.columns)):\n        plt.text(j + 0.5, i + 0.5, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', color='w')\n\n# 히트맵 표시\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_16.png)\n\n6.2 — 고유값과 고유벡터\n\n```js\nX = np.matrix(X)\ncov_matrix =  np.cov(np.transpose(X))\n```\n\n```js\nnp.diagonal(cov_matrix)\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_17.png\" />\n\n```js\neigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\nsorted_indices = np.argsort(eigenvalues)[::-1]\neigenvalues = eigenvalues[sorted_indices]\neigenvectors = eigenvectors[:, sorted_indices]\n```\n\n```js\neigenvalues\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_18.png\" />\n\n<div class=\"content-ad\"></div>\n\n```js\n고유벡터\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_19.png)\n\n7— 데이터 적합성\n\n7.1 — 카이저-마이어-올킨 (KMO)\n\n<div class=\"content-ad\"></div>\n\n```js\n# KMO 값 계산\nkmo_score, kmo_model = calculate_kmo(X)\n\n# KMO 점수 표시\nprint(f'카이저-마이어-올킨 (KMO) 점수: {kmo_model}')\n```\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_20.png)\n\n```js\n# 변수별로 KMO를 시각화하는 막대 차트 생성\nplt.figure(figsize=(12, 6))\nplt.bar(df_X_standardized.columns, kmo_score, color='blue')\nplt.title('변수별 KMO')\nplt.xlabel('변수')\nplt.ylabel('KMO 값')\nplt.grid()\nplt.xticks(rotation=45, ha='right')  # 더 잘 보이도록 x축 레이블 회전\n```\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_21.png)\n\n\n<div class=\"content-ad\"></div>\n\n7.2 — 바틀렛의 구 구형성 검정\n\n```js\n# 바틀렛의 구 구형성 검정 계산\nchi_square, p_value = calculate_bartlett_sphericity(X)\n\n# 검정 통계량 표시\nprint(f'카이제곱 값: {chi_square}')\nprint(f'P-value: {p_value}')\n```\n\n![Image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_22.png)\n\n```js\n# 바틀렛의 구 구형성 검정 시각화\nplt.figure(figsize=(6, 4))\nplt.bar(['카이제곱 값', 'P-value'], [chi_square, p_value], color=['blue', 'green'])\nplt.title(\"바틀렛의 구 구형성 검정\")\nplt.ylabel('값')\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_23.png\" />\n\n### 8 - 주성분 분석\n\n```js\nX = np.asarray(X)\n```\n\n```js\npca = PCA()\npca.fit(X)\nautovalores = pca.explained_variance_\nautovetores = pca.components_\n```\n\n<div class=\"content-ad\"></div>\n\n8.1 — 카이젤의 법칙\n\n```js\n# 관련 요인 분석 객체를 생성하고 데이터에 적합화합니다\nfa = FactorAnalyzer()\nfa.fit(X)\n\n# 고유값을 가져옵니다\neigenvalues, _ = fa.get_eigenvalues()\n```\n\n```js\n# 고유값을 요인 번호에 대해 그려봅니다\nplt.figure(figsize=(10, 8))\nplt.plot(range(1, len(eigenvalues) + 1), eigenvalues, marker='o')\nplt.title(\"Scree Plot\")\nplt.xlabel(\"요인 번호\")\nplt.ylabel(\"고유값\")\nplt.axhline(1, color='red', linestyle='dashed', linewidth=2, label=\"카이젤의 기준 (고유값 = 1)\")\nplt.legend()\nplt.grid()\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_24.png\" />\n\n<div class=\"content-ad\"></div>\n\n8.2 — 공유 분산의 분석\n\n```js\nexp_var_cumul = np.cumsum(pca.explained_variance_ratio_)\n```\n\n```js\n# 공분산 설명 비율 시각화\nplt.figure(figsize=(10, 8))\n# 각 요인으로 설명되는 누적 분산 플롯\nplt.plot(exp_var_cumul )\nplt.title('요인별 공분산 설명 비율')\nplt.xlabel('요인 수')\nplt.ylabel('누적 설명 분산 (%)')\nplt.grid()\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_25.png\" />\n\n<div class=\"content-ad\"></div>\n\n8.3 — Plot Components\n\n```python\nmodel = PCA(n_components=2)\nX_pca = model.fit(X)\n```\n\n```python\ncomponents = model.fit_transform(X)\ncomponents \n```\n\n```python\nloadings = model.components_.T * np.sqrt(model.explained_variance_)\n\nfig = px.scatter(components, x=0, y=1)\n\nfor i, feature in enumerate(columns_selected):\n    fig.add_shape(\n        type='line',\n        x0=0, y0=0,\n        x1=loadings[i, 0],\n        y1=loadings[i, 1]\n    )\n    fig.add_annotation(\n        x=loadings[i, 0],\n        y=loadings[i, 1],\n        ax=0, ay=0,\n        xanchor=\"center\",\n        yanchor=\"bottom\",\n        text=feature,\n    )\nfig.show()\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_26.png)\n\n9 - Inverse Transform\n\n```js\nX_reconstructed = model.inverse_transform(components)\nX_reconstructed\n```\n\n![Image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_27.png)\n\n\n<div class=\"content-ad\"></div>\n\n10— 마이크로콘트롤러에 구현할 모델 획득\n\n```js\nprint(port(model))\n```\n\n```js\n#pragma once\nnamespace Eloquent {\n    namespace ML {\n        namespace Port {\n            class PCA {\n                public:\n                    /**\n                    * 차원 축소 적용\n                    * @warn 목적지 벡터가 제공되지 않으면 원본 벡터를 덮어씁니다!\n                    */\n                    void transform(float *x, float *dest = NULL) {\n                        static float u[2] = {0};\n                        u[0] = dot(x, -0.010208828727, 0.009522664636, 0.07801034572, 0.004103495259, -0.003935853874, -0.004232033634, 0.21088426957, -0.00282519103, 0.974263356619);\n                        u[1] = dot(x, -0.015215508318, 0.016476395215, 0.128355383147, 0.008750586985, -0.049637455695, -0.049172415055, 0.964175225747, -0.0112017847, -0.219782142624);\n                        memcpy(dest != NULL ? dest : x, u, sizeof(float) * 2);\n                    }\n\n                protected:\n                    /**\n                    * 가변 길이 인수로 점곱 계산\n                    */\n                    float dot(float *x, ...) {\n                        va_list w;\n                        va_start(w, 9);\n                        static float mean[] = {10.998048780488, 7.26, 14.477073170732, 1.976829268293, 49.616341463415, 14.605853658537, 44.325609756098, 4.76243902439, 58.316585365854};\n                        float dot = 0.0;\n\n                        for (uint16_t i = 0; i < 9; i++) {\n                            dot += (x[i] - mean[i]) * va_arg(w, double);\n                        }\n\n                        return dot;\n                    }\n                };\n            }\n        }\n    }\n```\n\n11— 템플릿을 .h 파일에 저장\n\n<div class=\"content-ad\"></div>\n\n```js\nwith open('./PCA/PCA.h', 'w') as file:\n    file.write(port(model))\n```\n\n12- 완성된 아두이노 스케치\n\n아래에 표시된 대로 아두이노 스케치에 \"PCA.h\" 파일을 포함시키세요:\n\n```js\n#include \"PCA.h\"\n\nEloquent::ML::Port::PCA pca;\n\nvoid setup() {\n    Serial.begin(115200);\n}\n\nvoid loop() {\n    float X_1[9] = {11.04,  7.58, 14.83,  2.07, 49.81, 14.69, 43.75,  5.02, 63.19};\n    float result_1[2];\n    pca.transform(X_1, result_1);\n    Serial.print(\"입력 X1로 예측한 결과:\");\n    for (int i = 0; i < 2; i++) {\n        Serial.print(\" \");\n        Serial.print(result_1[i]);\n    }\n    Serial.println();  // 맨 끝에 새 줄 추가\n    delay(2000);\n\n    float X_2[9] = {10.76,  7.4 , 14.26,  1.86, 49.37, 14.05, 50.72,  4.92, 60.15};\n    float result_2[2];\n    pca.transform(X_2,  result_2);\n    Serial.print(\"입력 X2로 예측한 결과:\");\n    for (int i = 0; i < 2; i++) {\n        Serial.print(\" \");\n        Serial.print(result_2[i]);\n    }\n    Serial.println();  // 맨 끝에 새 줄 추가\n    delay(2000);\n}\n```\n\n<div class=\"content-ad\"></div>\n\n결과:\n\n구성요소 X1: [ 4.65528953, -1.59196422]\n\n역변환 X1: [10.97474627, 7.27810093, 14.63589674, 1.98200161, 49.67703998, 14.66443304, 43.77240463, 4.76711978, 63.20194867]\n\n구성요소 X2: [ 3.12393184, 5.77720022]\n\n<div class=\"content-ad\"></div>\n\n역변환 된 X2: [10.87825406, 7.38493559, 15.46230692, 2.0402022, 49.3172806, 14.30855419, 50.55463117, 4.68889837, 60.09039224]\n\n![이미지](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_28.png)\n\n전체 프로젝트는 다음에서 확인할 수 있어요: [TinyML/07_principal_components_analysis at main · thommaskevin/TinyML](github.com)\n\n## 만약 마음에 드신다면, 제게 커피한 잔 ⚡️💰(Bitcoin)을 사주실래요?\n\n<div class=\"content-ad\"></div>\n\n아래는 Markdown 형식으로 변경된 코드입니다:\n\n\ncode: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n![image](/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_29.png)\n","ogImage":{"url":"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_0.png"},"coverImage":"/assets/img/2024-06-20-TinyMLPrincipalComponentAnalysis_0.png","tag":["Tech"],"readingTime":17},{"title":"마이크로 머신러닝  합성곱 신경망 CNN","description":"","date":"2024-06-20 16:55","slug":"2024-06-20-TinyMLConvolutionalNeuralNetworksCNN","content":"\n\n수학적 기초부터 엣지 구현까지\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 연구 그룹: Conecta.ai (ufrn.br)\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png)\n\n<div class=\"content-ad\"></div>\n\n## 요약\n\n# 1 — 컨볼루션 신경망 역사\n\n컨볼루션 신경망(CNN)의 개념은 1980년대 금사이 후코시마의 연구로 형성되기 시작했습니다. 그는 Neocognitron을 개발했는데, 이는 동물의 시각 시스템 구조에서 영감을 받아 자가 조직화 과정을 통해 시각적 패턴을 인식할 수 있는 학습이 가능한 계층적 구조를 가졌습니다. 이 작업은 현대 CNN의 개발을 위한 중요한 선행 연구였습니다.\n\n<img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_1.png\" />\n\n<div class=\"content-ad\"></div>\n\nCNN의 현대 아키텍처는 얀 르쿤과 그의 동료들에 의해 1980년대 후반과 1990년대 초에 제안되었습니다. 그들은 MNIST 데이터셋에서 손으로 쓴 숫자를 인식하기 위해 설계된 컨볼루션 신경망인 LeNet-5를 개발했습니다. LeNet-5는 여러 개의 컨볼루션 레이어를 거친 후 pooling 레이어와 완전 연결 레이어로 이어지는 구조로, 오늘날 사용되는 CNN의 아키텍처의 기초를 구축했습니다.\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_2.png)\n\n초기 성공에도 불구하고 CNN의 활용은 계산 제약과 대규모 레이블 데이터셋의 부족으로 제한되었습니다. 그러나 컴퓨팅 파워가 증가하고 GPU(그래픽 처리 장치)를 사용해 딥 네트워크를 훈련하는 기술이 실현 가능해지면서 CNN은 더 많은 관심을 끌게 되었습니다. 게다가 ImageNet과 같은 대규모 레이블 이미지 데이터베이스의 개발은 딥 네트워크를 효과적으로 훈련하기 위한 필수 자료를 제공했습니다.\n\n2012년에 Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton이 개발한 AlexNet이 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 경쟁 상대들보다 큰 폭으로 우승하면서 전환점이 찾아왔습니다. AlexNet은 여러 컨볼루션 레이어, ReLU 활성화 함수, 그리고 dropout과 같은 정규화 기법을 활용하여 시각 인식 작업에 CNN의 성능을 입증했습니다. 이후로 CNN은 다양한 응용 분야에 대한 주요 도구가 되어 지속적인 혁신을 이끌어내는 데 이르렀습니다. VGGNet, GoogLeNet(Inception), ResNet과 같은 모델들은 네트워크의 깊이, 효율성, 정확도를 향상시키기 위한 새로운 아키텍처와 기법들을 소개했습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_3.png\" />\n\n지금은 CNN이 많은 인공지능 시스템의 필수 구성 요소입니다. 이미지 인식 뿐만 아니라 비디오 분석, 자연어 처리, 의학 진단, 자율 주행차 등 다양한 분야에서 사용됩니다. 연구는 계속해서 발전하고 있으며, 효율적인 합성곱 신경망, 깊은 신경망(DNNs), 생성적 적대 신경망(GANs) 등의 혁신이 이루어지고 있습니다.\n\n# 2— 합성곱 신경망 이론\n\n수학에서 \"합성곱\"은 한 함수가 다른 함수에 의해 변환되는 통합 연산을 나타냅니다. 그러나 신경망의 맥락에서는 이 개념이 전통적인 통계적 해석과 다릅니다.\n\n<div class=\"content-ad\"></div>\n\n기본적으로 우리는 입력 함수로 시작합니다. 우리의 경우에는 주로 이미지입니다. 또한, 필터(커널이라고도 함)를 소개합니다. 이미지는 점곱 연산을 통해 변환되는 함수로, 일반적으로 \"합성곱(convolution)\"이라고 합니다. 그 다음, 이러한 필터를 입력 이미지에 적용하면 \"특성 맵(feature maps)\"이라고 하는 출력 이미지를 얻게 됩니다.\n\n## 2.1 — 합성곱 계층\n\n합성곱 계층은 패턴을 감지하고 필터(커널)를 통해 특성 맵을 생성하기 위해 이미지가 처리되는 곳입니다. 이러한 특성 맵은 필터가 식별하려는 각 속성을 나타냅니다. 필터는 일반적으로 (3x3) 또는 (5x5) 행렬로 구성되어 있으며, 각 필터는 입력 이미지에서 동일한 크기의 필드를 차지합니다. 그런 다음, 필터가 한 칸씩 가로로 이동하고 같은 프로세스가 반복됩니다. 가로 끝에 도달하면 필터가 한 칸 아래로 이동하고 점곱 프로세스가 다시 수평으로 적용됩니다. 그 결과는 순서대로 출력에 추가되어 특성 맵을 생성합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/0*4UZXfXs7eQ3TT02M.gif)\n\n<div class=\"content-ad\"></div>\n\n입력 이미지를 나타내는 텐서 I의 차원이 m1 x m2 x mc인 경우를 가정해 봅시다. 이 텐서에서,\n\n![image1](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_4.png)\n\n우리는 입력 이미지와 일치하는 채널 수를 가진 (n1 x n2 x nc) 차원을 가지는 필터를 적용합니다. 이 필터는 이미지를 왼쪽에서 오른쪽으로 움직이면서, 입력 텐서 I의 해당 영역과 요소별 곱셈을 수행하고 이러한 곱셈 결과를 합산합니다. 스트라이드 매개변수는 필터가 이미지를 횡단하는 단계 크기를 결정합니다. I와 K 사이의 이 작업의 결과는 다른 차원 (m1 - n1 + 1) x (m2 - n2 + 1) x 1을 가진 또 다른 텐서를 생성합니다.\n\n![image2](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_5.png)\n\n<div class=\"content-ad\"></div>\n\n안녕하세요,\n\n<img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_6.png\" />\n\n특징 맵의 (i, j)번째 항목은 다음과 같이 계산됩니다:\n\n<img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_7.png\" />\n\n<div class=\"content-ad\"></div>\n\n다음 예를 선택했습니다. 5x5x1 차원 이미지가 3x3x1 커널로 합성되고 s=1 스트라이드가 적용됩니다.\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_8.png)\n\n특징 맵의 (i, j)-번째 항목은 단일 채널에 대한 다음 일반 공식으로 주어집니다:\n\n![formula](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_9.png)\n\n<div class=\"content-ad\"></div>\n\n위 예에서 feature map의 (1, 1)번 째 항목을 계산해 봅시다:\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_10.png)\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_11.png)\n\n사용할 수 없는 항목은 0으로 대체되었습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_12.png)\n\n마찬가지로, 남은 항목들은 동일한 공식을 사용하여 계산할 수 있습니다. 이 과정은 서로 다른 유형의 필터를 적용함으로써 반복되며, 각각이 이미지의 다른 특징을 캡처하는 것을 보여줍니다. 예를 들어, 필터 개수가 하나 이상이 될 수 있어서 스트라이드 개념이 도입됩니다.\n\n## 2.2— 패딩 레이어\n\n기본 CNN은 (n x n) 크기의 흑백 이미지와 (f x f) 크기의 필터/커널을 사용하여 결과를 제공하며, 출력 크기는 (n - f + 1) x (n - f + 1)이 됩니다. 예를 들어, (8 x 8) 이미지와 (3 x 3) 필터를 사용한 어떤 합성 곱 작업의 경우, 출력 이미지 크기는 (6 x 6)이 됩니다. 이러한 크기의 감소는 이미지 처리 중 일관적으로 발생하며, 레이어의 출력이 일반적으로 입력보다 작습니다. 또한, 합성 곱 작업에서 사용되는 필터는 픽셀을 횡단하면서 항상 모서리에 초점을 두지 않습니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n![TinyML CNN](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_13.png)\n\n머신 러닝에서 일반적으로 사용되는 여러 유형의 패딩이 있습니다:\n\n- Same 패딩: Same 패딩은 원본 이미지의 외부 프레임에 일반적으로 0과 같은 추가 요소를 추가하는 것을 포함합니다. 이 방식으로 입력을 확장함으로써, 필터가 더 넓은 영역을 스캔할 수 있게 되어 출력 이미지가 원본과 동일한 크기를 유지할 수 있습니다. 이것은 컨볼루션 작업 중 공간적 차원을 유지하는 데 유용합니다.\n- Valid 패딩: Same 패딩과는 달리, Valid 패딩은 이미지에 추가 요소를 추가하는 것을 포함하지 않습니다. 필터는 추가 요소 없이 원본 이미지를 훑어갑니다. 이것은 간격으로 인한 일부 데이터 손실이 발생할 수 있지만, valid 패딩은 출력 피쳐 맵의 크기를 줄이고자 할 때 사용됩니다. 이러한 축소는 모델의 매개변수 수를 줄이고 계산 효율성을 향상시킬 수 있습니다.\n- Causal 패딩: Causal 패딩은 주로 시퀀스-투-시퀀스 모델 및 시계열 예측에 사용되며, 특히 1차원 컨볼루션 레이어에서 사용됩니다. 이 유형의 패딩은 데이터 시퀀스의 시작 부분에 요소를 추가하여 알고리즘이 초기 시간 단계에 대한 값을 예측할 수 있게 합니다. 과거 및 현재 데이터를 예측에 포함시킴으로써, causal 패딩은 모델이 추론 중에 사용할 수 없는 미래 데이터를 활용하지 않도록 보장합니다.\n- Full 패딩: 이 유형의 패딩은 입력의 테두리 주위에 여러 레이어의 0을 추가하여 원본 이미지 크기보다 큰 출력 피쳐 맵을 생성합니다. Full 패딩은 덜 일반적이지만 더 큰 출력 크기가 필요한 특정 시나리오에서 사용할 수 있습니다.\n\n## 2.3 —Pooling Layer\n\n\n<div class=\"content-ad\"></div>\n\n풀링 레이어에서는 컨볼루션된 특징의 공간 차원이 일반적으로 축소되어 입력 이미지에서 주요한 특징을 추출하는 데 도움이 됩니다. 이 크기의 축소는 컨볼루션 레이어에서 얻은 출력에 풀링 함수를 적용하여 달성됩니다. 이렇게 가정해 봅시다:\n\n![그림 1](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_14.png)\n\n풀링된 부분의 차원은 다음과 같습니다:\n\n![그림 2](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_15.png)\n\n<div class=\"content-ad\"></div>\n\n딥러닝에서는 3가지 종류의 풀링이 있어요:\n\n평균 풀링: 커버된 영역 내 픽셀 값의 평균이 출력 매트릭스로 전달됩니다.\n\n최대 풀링: 커버된 영역 내 픽셀 값 중 가장 높은 값이 출력 매트릭스로 전달됩니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_16.png)\n\n<div class=\"content-ad\"></div>\n\n전역 최대 풀링(Global Max Pooling) : 모든 입력 크기의 픽셀 값 중 가장 높은 값이 출력 행렬로 전달됩니다. 이 유형의 풀링에서 풀 크기는 입력 크기와 동일합니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_17.png)\n\nsum pooling, average pooling, max pooling과 같은 다양한 유형의 풀링이 있습니다. 최대 풀링의 예는 아래에 제공됩니다. 최대 풀링은 2x2 패치에 수행됩니다. 각 패치에서 최댓값이 선택됩니다.\n\n## 2.4 — 플래튼 레이어\n\n<div class=\"content-ad\"></div>\n\n플래튼 레이어는 신경망 아키텍처에서 중요한 구성 요소이며, 특히 합성곱 레이어에서 완전히 연결된 레이어로의 전환 시에 중요합니다. 이 레이어는 합성곱 및 풀링 레이어에서 생성된 다차원 피쳐 맵을 일차원 벡터로 변환하여, 분류 또는 회귀 작업을 위해 후속 완전히 연결된 레이어로 전달할 수 있습니다.\n\n![이미지 설명](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_18.png)\n\n다음은 플래튼 레이어의 작동 방식입니다:\n\n- 입력: 플래튼 레이어의 입력은 일반적으로 이전 합성곱 또는 풀링 레이어에서 생성된 피쳐 맵을 나타내는 다차원 텐서입니다. 예를 들어, 마지막 합성곱 또는 풀링 레이어가 높이, 너비, 깊이의 피쳐 맵을 생성한다면 입력 텐서는 (배치 크기, 높이, 너비, 깊이) 형태를 가질 것입니다.\n- 플래팅: 플래팅 레이어는 단순히 피쳐 맵의 모든 요소를 하나의 차원을 따라 연결하여 입력 텐서를 일차원 벡터로 다시 형태화합니다. 예를 들어, 피쳐 맵이 높이, 너비, 깊이의 차원을 가진다면 플래팅 레이어는 이를 높이 * 너비 * 깊이의 길이를 가진 벡터로 변환합니다.\n- 출력: 플래팅 레이어의 출력은 피쳐 맵을 플래팅한 일차원 벡터입니다. 이 벡터는 이후의 완전히 연결된 레이어의 입력으로 전달될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n평탄화 레이어의 목적은 특성 맵에서 캡처된 공간 정보를 완전 연결 레이어에서 처리할 수 있는 형식으로 변환하는 것입니다. 완전 연결 레이어는 일차원 입력 벡터를 필요로하므로 특성 맵을 평탄화함으로써 신경망이 데이터의 다양한 공간 위치에 걸쳐 복잡한 패턴과 관계를 효과적으로 학습할 수 있습니다. 이를 통해 더 정확한 예측을 할 수 있습니다.\n\n이전의 합성곱 또는 풀링 레이어에 의해 생성된 특성 맵 𝐹 집합이 있다고 가정해봅시다. 이러한 특성 맵의 차원을 다음과 같이 표기해 봅시다:\n\n- 𝐻: 특성 맵의 높이\n- 𝑊: 특성 맵의 너비\n- 𝐷: 특성 맵의 깊이 (채널 수)\n- 𝐵: 배치 크기 (배치에 포함된 샘플 수)\n\n그러면 특성 맵 𝐹의 형태는 (B,H,W,D)가 됩니다. 여기서 𝐵은 배치 크기를 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n이러한 피처 맵을 일차원 벡터로 평탄화하기 위해, 단순히 이를 길이 𝐻×𝑊×𝐷의 벡터로 재구성합니다. 수학적으로 표현하면 다음과 같습니다:\n\nFlatten(𝐹)=reshape(𝐹, (𝐵, 𝐻×𝑊×𝐷))\n\n이 경우, 재구성 연산은 (𝐵, 𝐻, 𝑊, 𝐷) 텐서를 (𝐵, 𝐻×𝑊×𝐷) 텐서로 재구성하여 공간 차원을 하나의 차원으로 펼치게 됩니다.\n\n예를 들어, 만약 𝐹가 차원이 (4,5,5,3)인 경우 (배치 크기가 4, 높이가 5, 너비가 5, 깊이가 3인 피처 맵), 그러면 평탄화된 출력은 (4,75) 차원을 갖게 되며, 각 행은 배치의 한 샘플에 대한 평탄화된 피처 맵을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n이 평탄화된 벡터는 신경망의 후속 완전 연결 레이어에 입력으로 전달될 수 있습니다.\n\n# 3 — TinyML 구현\n\n이 예제를 통해 ESP32, 아두이노, 라즈베리 파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에서 머신러닝 알고리즘을 구현할 수 있습니다.\n\n3.0 — requirements.txt 파일에 나열된 라이브러리를 설치합니다.\n\n<div class=\"content-ad\"></div>\n\n```python\n!pip install -r requirements.txt\n```\n\n3.1 — 라이브러리 가져오기\n\n```python\nimport numpy as np\nfrom sklearn.datasets import load_digits\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport time\nimport seaborn as sns\nimport os\n```\n\n3.2 — 데이터셋 불러오기\n\n\n<div class=\"content-ad\"></div>\n\nMNIST은 Modified National Institute of Standards and Technology database의 줄임말로, 기공 학습 및 컴퓨터 비전 분야에서 널리 사용되는 데이터셋입니다. 이 데이터셋은 0에서 9까지의 손으로 쓴 숫자들의 모음으로, 각 숫자는 28x28 픽셀 크기의 회색 음영 이미지로 표현됩니다. 이 데이터셋에는 총 70,000개의 이미지가 포함되어 있으며, 이 중 60,000개의 이미지는 훈련에 사용되고 10,000개의 이미지는 테스트에 사용됩니다.\n\n링크: [https://www.nist.gov/itl/products-and-services/emnist-dataset](https://www.nist.gov/itl/products-and-services/emnist-dataset)\n\n```python\ndef get_data():\n    np.random.seed(1337)\n    x_values, y_values = load_digits(return_X_y=True)\n    x_values /= x_values.max()\n    # reshape to (8 x 8 x 1)\n    x_values = x_values.reshape((len(x_values), 8, 8, 1))\n    # split into train, validation, test\n    TRAIN_SPLIT = int(0.6 * len(x_values))\n    TEST_SPLIT = int(0.2 * len(x_values) + TRAIN_SPLIT)\n    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n\n    return x_train, x_test, x_validate, y_train, y_test, y_validate\n```\n\n3.3 — 데이터 분할\n\n<div class=\"content-ad\"></div>\n\n```js\nX_train, X_test, X_validate, y_train, y_test, y_validate = get_data()\n```\n\n3.4 — 탐색적 데이터 분석\n\n```js\nX_train__ = X_train.reshape(X_train.shape[0], 8, 8)\n\nfig, axis = plt.subplots(1, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train__[i], cmap='binary')\n    digit = y_train[i]\n    ax.set(title = f\"실제 숫자는 {digit}입니다.\")\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_19.png)\n\n\n<div class=\"content-ad\"></div>\n\n3.5— 모델 정의하기\n\n```js\nmodel = tf.keras.Sequential()\nmodel.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(8, 8, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(len(np.unique(y_train))))\n```\n\n```js\nmodel.summary()\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_20.png)\n\n<div class=\"content-ad\"></div>\n\n```js\nplot_model(model, to_file='./figures/model.png')\n```\n\n![Plot](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_21.png)\n\n3.6—모델 컴파일하기\n\n```js\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n```\n\n<div class=\"content-ad\"></div>\n\n3.7 — 모델 훈련\n\n```js\nhistory = model.fit(X_train, y_train,\n                    epochs=50,\n                    batch_size=16,\n                    validation_data=(X_validate, y_validate))\n```\n\n```js\nmodel.save('.\\models\\model.keras')\n```\n\n```js\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'r.', label='훈련 손실')\nplt.plot(epochs, val_loss, 'y', label='검증 손실')\nplt.title('훈련 및 검증 손실')\nplt.xlabel('에포크')\nplt.ylabel('손실')\nplt.grid()\nplt.legend()\nplt.savefig('.\\\\figures\\\\history_traing.png', dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_22.png\" />\n\n모델 평가\n\n테스트 데이터\n\n```js\ndef test_model(model, x_test, y_test):\n    x_test = (x_test / x_test.max()).reshape((len(x_test), 8, 8, 1))\n    y_pred = model.predict(x_test).argmax(axis=1)\n    print('정확도', ((y_pred == y_test).sum() / len(y_test))*100, \"%\")\n```\n\n<div class=\"content-ad\"></div>\n\n\n```js\ntest_model(model, X_test, y_test)\n```\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_23.png)\n\n3.8.2 — Confusion matrix\n\n```js\nfig = plt.figure(figsize=(10, 10)) # Set Figure\n\ny_pred = model.predict(X_test) # Predict class probabilities as 2 => [0.1, 0, 0.9, 0, 0, 0, 0, 0, 0, 0]\nY_pred = np.argmax(y_pred, 1) # Decode Predicted labels\nmat = confusion_matrix(y_test, Y_pred) # Confusion matrix\n\n# Plot Confusion matrix\nsns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues, fmt='.0f', \n            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test), \n            annot_kws={\"fontsize\": 14}, linewidths=1, linecolor='white')\n\nplt.xlabel('Predicted Values', fontsize=14)\nplt.ylabel('True Values', fontsize=14)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.savefig('.\\\\figures\\\\confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_24.png)\n\n3.8.3— 예측 유효성 검사 결과\n\n```js\ny_pred = model.predict(X_test)\nX_test__ = X_test\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test__[i], cmap='binary')\n    ax.set(title = f\"실제 숫자: {y_test[i]}\\n예측 숫자: {y_pred[i].argmax()}\")\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_25.png)\n\n\n<div class=\"content-ad\"></div>\n\n3.9 — 마이크로컨트롤러에 구현할 모델을 얻기\n\n3.9.1 — C 프로그래밍을 위해 일부 16진수 값을 배열로 변환하기\n\n```js\n# 함수: C 프로그래밍을 위해 일부 16진수 값을 배열로 변환\ndef hex_to_c_array(hex_data, var_name):\n\n  c_str = ''\n\n  # 헤더 가드 생성\n  c_str += '#ifdef __has_attribute\\n'\n  c_str += '#define HAVE_ATTRIBUTE(x) __has_attribute(x)\\n'\n  c_str += '#else\\n'\n  c_str += '#define HAVE_ATTRIBUTE(x) 0\\n'\n  c_str += '#endif\\n'\n  c_str += '#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) && !defined(__clang__))\\n'\n  c_str += '#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\\n'\n  c_str += '#else\\n'\n  c_str += '#define DATA_ALIGN_ATTRIBUTE\\n'\n  c_str += '#endif\\n\\n'\n\n  # C 변수 선언\n  c_str += 'const unsigned char ' + var_name + '[]  DATA_ALIGN_ATTRIBUTE = {'\n  hex_array = []\n  for i, val in enumerate(hex_data) :\n\n    # 16진수에서 문자열로 변환\n    hex_str = format(val, '#04x')\n\n    # 각 줄이 80자 이내로 유지되도록 서식 지정 추가\n    if (i + 1) < len(hex_data):\n      hex_str += ','\n    if (i + 1) % 12 == 0:\n      hex_str += '\\n '\n    hex_array.append(hex_str)\n\n  # 마지막 중괄호 추가\n  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n\n  # 헤더 가드 종료\n  c_str += 'const int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n\n  return c_str\n```\n\n3.9.2—모델을 Float32와 Int8형식으로 변환하기\n\n<div class=\"content-ad\"></div>\n\n```js\ndef representative_dataset():\n    for i in range(len(X_train)):\n        input_data = np.array([X_train[i]], dtype=np.float32)\n        yield [input_data]\n\ndef converter_quantization_model(model, model_name):\n\n    # Convert the model to float32\n    converter_float32 = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_float32.optimizations = [tf.lite.Optimize.DEFAULT]\n    converter_float32.target_spec.supported_types = [tf.float32]\n    converter_float32._experimental_lower_tensor_list_ops = False\n    converter_float32.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n    converter_float32.representative_dataset = representative_dataset\n    tflite_model_float32 = converter_float32.convert()\n    print(tflite_model_float32)\n    with open(model_name+'_quant_float32' + '.h', 'w') as file:\n        file.write(hex_to_c_array(tflite_model_float32, model_name+'_quant_float32'))\n    with open(model_name+'_quant_float32.tflite', 'wb') as f:\n        f.write(tflite_model_float32)\n    size_model_tflite_float32 = os.path.getsize(model_name+'_quant_float32.tflite')\n    print(model_name+f'_quant_float32.tflite: {size_model_tflite_float32} Bytes')\n\n    # Convert the model to Int8\n    converter_int8 = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]\n    converter_int8.target_spec.supported_types = [tf.int8]\n    converter_int8.representative_dataset = representative_dataset\n    converter_int8.target_spec.supported_ops = [\n        tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n        tf.lite.OpsSet.SELECT_TF_OPS,\n    ]\n    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n    converter_int8.experimental_new_converter = True\n    converter_int8.experimental_new_quantizer = True\n    converter_int8.experimental_new_calibrator = True\n    tflite_model_int8 = converter_int8.convert()\n    with open(model_name+'_quant_int8' + '.h', 'w') as file:\n        file.write(hex_to_c_array(tflite_model_int8, model_name+'_quant_int8'))\n    with open(model_name+'_quant_int8.tflite', 'wb') as f:\n        f.write(tflite_model_int8)\n    size_model_tflite_int8 = os.path.getsize(model_name+'_quant_int8.tflite')\n    print(model_name+f'_quant_int8.tflite: {size_model_tflite_int8} Bytes')\n\n    return None\n```\n\n```js\nmodel_name='.\\models\\model'\nconverter_quantization_model(model, model_name)\n```\n\n3.10 — Quantized Model Evaluation\n\n```js\ndef evaluate_quantization(model_path, X_test, y_test, quantization_type):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Evaluate the quantized model\n    input_index = interpreter.get_input_details()[0]['index']\n    output_index = interpreter.get_output_details()[0]['index']\n    predictions = []\n    processing_times = []\n\n    X_test = np.array(X_test, dtype=np.float32)\n    \n    for X in X_test:\n        interpreter.set_tensor(input_index, [X])       \n        start_time = time.time()\n        interpreter.invoke()\n        end_time = time.time()\n        processing_time = end_time - start_time\n        processing_times.append(processing_time)\n        output = interpreter.get_tensor(output_index).argmax(axis=1)\n        predictions.append(output[0])\n\n    acc = accuracy_score(y_test, predictions)\n   \n    # Calculate the average and standard deviation of differences\n    result = { \"Accuracy (%): \":acc*100,\n                \"Process time (s): \": np.mean(processing_times)\n            }\n\n    return result\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nmodel_name = '.\\models\\model'\n```\n\n```js\neval_quant_float32 = evaluate_quantization(model_name + '_quant_float32.tflite', X_test, y_test, 'float32')\neval_quant_float32\n```\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_26.png)\n\n```js\neval_quant_int8 = evaluate_quantization(model_name + '_quant_int8.tflite', X_test, y_test, 'int8')\neval_quant_int8 \n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_27.png\" />\n\n## 3.11 — 모델 배포\n\n이 예제를 통해 ESP32, 아두이노, 아두이노 Portenta H7 with Vision Shield, 라즈베리파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에 머신러닝 알고리즘을 구현할 수 있습니다.\n\n3.11.1 — EloquentTinyML 라이브러리 설치\n\n<div class=\"content-ad\"></div>\n\n도서관 폴더로 이동하여 EloquentTinyML-main을 설치해주세요.\n\n3.11.2 — 완전한 아두이노 스케치\n\nmodel_quant_float32.h 또는 model_quant_int8.h 파일을 열어서 다음에서 모든 16진수 값을 복사하세요:\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_28.png)\n\n<div class=\"content-ad\"></div>\n\n아래와 같이 변경해주세요:\n\n\nand model len\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_29.png)\n\nand cut in model.h:\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_30.png)\n\n\n<div class=\"content-ad\"></div>\n\nand\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_31.png)\n\n3.11.2 — 완성된 아두이노 스케치\n\n```js\n#include <EloquentTinyML.h>\n#include <eloquent_tinyml/tensorflow.h>\n\n// sine_model.h contains the array you exported from Python with xxd or tinymlgen\n#include \"model.h\"\n\n#define N_INPUTS 64\n#define N_OUTPUTS 10\n// in future projects you may need to tweak this value: it's a trial and error process\n#define TENSOR_ARENA_SIZE 6*1024\n\nEloquent::TinyML::TensorFlow::TensorFlow<N_INPUTS, N_OUTPUTS, TENSOR_ARENA_SIZE> tf;\n\nfloat input[64] = {0.00000000000f, 0.12500000000f, 0.00000000000f, 0.50000000000f, 0.56250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.81250000000f, 0.31250000000f, 0.87500000000f, 0.50000000000f, 0.43750000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.75000000000f, 0.31250000000f, 0.12500000000f, 0.00000000000f, 0.56250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.43750000000f, 0.31250000000f, 0.00000000000f, 0.00000000000f, 0.18750000000f, 0.31250000000f, 0.00000000000f, 0.00000000000f, 0.18750000000f, 0.62500000000f, 0.00000000000f, 0.00000000000f, 0.12500000000f, 0.62500000000f, 0.00000000000f, 0.00000000000f, 0.06250000000f, 0.81250000000f, 0.00000000000f, 0.00000000000f, 0.06250000000f, 0.75000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.31250000000f, 0.81250000000f, 0.31250000000f, 0.56250000000f, 0.81250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.56250000000f, 1.00000000000f, 1.00000000000f, 0.43750000000f, 0.00000000000f};\n\nfloat y_pred[10] = {0};\n\nvoid setup() {\n    Serial.begin(9600);\n    delay(4000);\n    tf.begin(model);\n\n    // check if model loaded fine\n    if (!tf.isOk()) {\n      Serial.print(\"ERROR: \");\n      Serial.println(tf.getErrorMessage());\n\n      while (true) delay(1000);\n    }\n}\n\nvoid loop() {\n\n        tf.predict(input, y_pred);\n        for (int i = 0; i < 10; i++) {\n            Serial.print(y_pred[i]);\n            Serial.print(i == 9 ? '\\n' : ',');\n        }\n    Serial.print(\"Predicted class is: \");\n      Serial.println(tf.probaToClass(y_pred));\n      // or you can skip the predict() method and call directly predictClass()\n      Serial.print(\"Sanity check: \");\n      Serial.println(tf.predictClass(input));\n      delay(2000);\n\n}\n```\n\n<div class=\"content-ad\"></div>\n\n3.12 — 결과\n\n3.12.1 — 양자화된 모델 Float32\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_32.png)\n\n3.12.1 — 양자화된 모델 Int8\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_33.png)\n\nFull project in: [TinyML/13_CNN at main · thommaskevin/TinyML](https://github.com/thommaskevin/TinyML)\n\n## If you like it, consider buying my coffee ☕️💰 (Bitcoin)\n\ncode: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n\n<div class=\"content-ad\"></div>\n\n`<img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_34.png\" />`","ogImage":{"url":"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png"},"coverImage":"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png","tag":["Tech"],"readingTime":23},{"title":"시리얼 통신 마스터하기 아두이노 메가 2560 마스터와 우노 슬레이브 UART 튜토리얼","description":"","date":"2024-06-20 16:52","slug":"2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial","content":"\n\n\n![이미지](/assets/img/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial_0.png)\n\n# 소개\n\n아두이노 프로젝트의 영역에서 시리얼 통신은 기본적인 기술입니다. 이것은 새로운 언어로 대화하는 것을 배우는 것과 같습니다. 하지만 단어 대신에 전기 신호를 사용합니다. 이 튜토리얼에서는 두 가지 인기 있는 아두이노 보드인 메가 2560을 마스터로, 그리고 우노를 슬레이브로하여 UART (Universal Asynchronous Receiver-Transmitter) 통신을 설정하는 방법을 알아볼 것입니다. 이 안내서를 끝까지 따라오면 이 두 보드가 서로 '대화'할 수 있는 방법에 대해 명확히 이해하게 될 것입니다.\n\n# 필요한 것\n\n\n<div class=\"content-ad\"></div>\n\n- 1 x 아두이노 메가 2560\n- 1 x 아두이노 우노\n- 점퍼 와이어\n- 아두이노 IDE\n\n# 마스터 이해하기: 아두이노 메가 2560\n\n# 설정\n\n시리얼 포트 초기화: 우리의 메가 2560은 두 개의 시리얼 포트를 사용합니다. 디버깅용으로 Serial을 사용하고 Uno와 통신하기 위해 Serial1을 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nSerial.begin(9600);\nSerial1.begin(9600);\n```\n\nLED로 표시기 사용: 내장 LED를 사용하여 받은 데이터를 시각적으로 표현합니다.\n\n```js\npinMode(LED_BUILTIN, OUTPUT);\ndigitalWrite(LED_BUILTIN, HIGH);\n```\n\n# 루프\n\n\n<div class=\"content-ad\"></div>\n\n데이터 수신: Mega는 시리얼 포트에서 데이터를 기다립니다.\n\n```js\nif (Serial.available() > 0) {\n   char received = Serial.read();\n   ...\n}\n```\n\n데이터 전달: 데이터를 수신하면 Mega는 동일한 데이터를 Serial1을 통해 Uno로 전달합니다.\n\n```js\nSerial1.write(received);\n```\n\n<div class=\"content-ad\"></div>\n\n데이터에 따른 조치: 받은 데이터가 '1'이면 LED가 꺼지고, '2'이면 켜집니다.\n\n```js\nif (received == '1') {\n   digitalWrite(LED_BUILTIN, LOW);\n} else if (received == '2') {\n   digitalWrite(LED_BUILTIN, HIGH);\n}\n```\n\n# 슬레이브 이해하기: 아두이노 우노\n\n# 설정\n\n<div class=\"content-ad\"></div>\n\n소프트웨어 시리얼: Uno는 하드웨어 시리얼 포트가 하나뿐이기 때문에, 우리는 SoftwareSerial을 사용하여 가상 시리얼 포트를 생성합니다.\n\n```js\nSoftwareSerial Serial1(10, 9); // RX, TX\n```\n\n시리얼 포트 초기화: 하드웨어 및 소프트웨어 시리얼 포트가 모두 초기화됩니다.\n\n```js\nSerial.begin(9600);\nSerial1.begin(9600);\n```\n\n<div class=\"content-ad\"></div>\n\n# 루프\n\n데이터 수신: Uno는 Mega로부터 소프트웨어 시리얼 포트에서 데이터를 수신합니다.\n\n```js\nif (Serial1.available() > 0) {\n   char received = Serial1.read();\n   ...\n}\n```\n\n데이터 응답: Mega와 유사하게, Uno는 수신한 데이터를 사용하여 LED를 제어합니다.\n\n<div class=\"content-ad\"></div>\n\n\n```js\nif (received == '1') {\n   digitalWrite(LED_BUILTIN, LOW);\n} else if (received == '2') {\n   digitalWrite(LED_BUILTIN, HIGH);\n}\n```\n\n# 함께 모두 넣어봅시다\n\n# 아두이노 메가 2560 (마스터)\n\n```js\n#include <SoftwareSerial.h>\n\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);\n    digitalWrite(LED_BUILTIN, HIGH);\n    Serial.begin(9600);\n    Serial1.begin(9600);\n}\n\nvoid loop() {\n    if (Serial.available() > 0) {\n        char received = Serial.read();\n        Serial1.write(received);\n\n        if (received == '1') {\n            digitalWrite(LED_BUILTIN, LOW);\n        } else if (received == '2') {\n            digitalWrite(LED_BUILTIN, HIGH);\n        }\n    }\n}\n```\n\n\n<div class=\"content-ad\"></div>\n\n# 아두이노 Uno (슬레이브)\n\n```js\n#include <SoftwareSerial.h>\n\nSoftwareSerial Serial1(10, 9); // RX, TX\n\nvoid setup() {\n    pinMode(LED_BUILTIN, OUTPUT);\n    digitalWrite(LED_BUILTIN, HIGH);\n    Serial.begin(9600);\n    Serial1.begin(9600);\n}\n\nvoid loop() {\n    if (Serial1.available() > 0) {\n        char received = Serial1.read();\n\n        if (received == '1') {\n            digitalWrite(LED_BUILTIN, LOW);\n        } else if (received == '2') {\n            digitalWrite(LED_BUILTIN, HIGH);\n        }\n    }\n}\n```\n\n# 배선\n\n5V to 5V 연결:\n\n<div class=\"content-ad\"></div>\n\n- 아두이노 메가의 5V 핀을 아두이노 우노의 5V 핀에 연결하십시오. 이 단계에서 우노를 메가로부터 전원을 공급합니다.\n\n그라운드 연결:\n\n- 아두이노 메가의 GND(그라운드) 핀을 아두이노 우노의 GND 핀에 연결하십시오. 이 공통 그라운드는 올바른 통신을 위해 중요합니다.\n\nTX에서 RX로 연결:\n\n<div class=\"content-ad\"></div>\n\n- 아두이노 메가의 TX1 (송신) 핀을 아두이노 우노의 10번 핀에 연결하세요. 코드에서 우노의 SoftwareSerial에서 10번 핀을 RX (수신) 핀으로 설정해주세요.\n\n컴퓨터 연결 및 시리얼 모니터:\n\n- USB 케이블을 사용하여 아두이노 메가를 컴퓨터에 연결하세요.\n- 아두이노 IDE를 열고 메가에 대한 올바른 COM 포트를 선택하세요.\n- 아두이노 IDE에서 시리얼 모니터를 열어주세요. 이것은 메가에서 우노로 데이터를 보내는 데 사용될 것입니다.\n\n이제 실험을 위한 설정이 완료되었습니다. 아두이노 IDE의 시리얼 모니터에 '1' 또는 '2'를 입력하면 (메가를 선택한 상태에서), 메가는 TX1을 통해 10번 핀에 데이터를 보내고, 우노는 수신된 데이터에 따라 LED를 켜거나 끌 것입니다.","ogImage":{"url":"/assets/img/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial_0.png"},"coverImage":"/assets/img/2024-06-20-MasteringSerialCommunicationArduinoMega2560MasterandUnoSlaveUARTTutorial_0.png","tag":["Tech"],"readingTime":4},{"title":"컴퓨터에서 RC 모델을 프로그래밍하여 제어하기","description":"","date":"2024-06-20 16:51","slug":"2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer","content":"\n\n유니버설 RC 컨트롤러와 멀티 모듈을 사용하여 만들기\n\n# RC 모델 제어를 위한 비침입적 방식\n\n\"자율주행 미니-Z와 함께 경주하는\" 프로젝트의 일환으로, 첫 번째 작업은 컴퓨터에서 미니-Z를 제어하는 방법을 찾는 것입니다. 이를 달성하기 위한 여러 가지 방법이 있습니다. 예를 들어, RC 차량에 마이크로컨트롤러를 추가하거나 무선 송신기를 수정하여 제어 신호를 프로그램 할 수 있습니다. 그러나 저는 제 RC 모델을 수정하지 않는 비침입적인 방법을 선호합니다. 따라서 컴퓨터가 라디오 송신기를 모방하고 기본 Mini-Z를 제어할 수 있는 솔루션을 찾고 있습니다.\n\n이 방식을 택한 이유는 몇 가지가 있습니다. 첫째, Mini-Z는 제 취미이며 아직도 즐겁게 놀고 싶어서 손상을 입히고 싶지 않습니다.: ) 게다가, 제 프로젝트의 목표는 사람과 경주하는 것이기 때문에, 자동차가 일반 플레이어의 자동차와 동일한 구성을 유지하여 공정한 경기를 보장하고 싶습니다.\n\n<div class=\"content-ad\"></div>\n\n# 컴퓨터에서 라디오 신호 전송하기\n\n내 첫 번째 아이디어는 트레이너 포트를 통해 컴퓨터를 라디오 송신기에 연결할 수 있는지 알아보는 것입니다. 라디오 송신기의 트레이너 포트는 주로 모델용 원격 제어(RC) 시스템에서 사용됩니다. 두 송신기를 연결하는 인터페이스 역할을 하며, 일반적으로 강사가 학생을 가르치는 훈련 목적으로 사용됩니다. PPM 신호를 에뮬레이트하고 송신기에 입력할 수 있다면, 주식 모델 컨트롤러의 라디오를 활용할 수 있을 것입니다.\n\n![이미지](/assets/img/2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer_0.png)\n\n실제로, 트레이너 포트에 대한 정보를 찾던 중 이 프로젝트인 PPMControl을 발견했습니다. 누군가가 이미 이 아이디어를 구현했습니다. 이 접근 방식이 괜찮다면, 이 프로젝트를 살펴보시기 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 이 해결책을 사용할 수 없다는 것을 발견했어요. 현대 RC 모델에서 2.4GHz 무선 신호가 흔하지만, 서로 다른 브랜드나 심지어 같은 브랜드 내의 다른 시리즈도 서로 다른 프로토콜을 사용합니다. 따라서 2.4GHz 송신기를 사용하더라도 모델과 호환되지 않을 수 있습니다. 예를 들어, 내 Mini-Z는 FHSS 프로토콜을 사용하는데, 이를 지원하는 컨트롤러만 호환됩니다. FHSS 프로토콜을 지원하는 컨트롤러를 찾던 중 여러 프로토콜을 지원하는 모듈을 개발한 흥미로운 프로젝트를 발견했어요.\n\n# 멀티 모듈\n\n![이미지](/assets/img/2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer_1.png)\n\n멀티 모듈은 4가지 다른 RF 구성 요소를 통합한 오픈 소스 2.4GHz 송신기 모듈로, 거의 모든 RC 송신기가 다양한 수신기와 모델을 작동할 수 있도록 합니다. 일종의 유니버설 TV 원격 제어기로, 여러 TV 브랜드의 원격 제어 코드를 이미 모두 포함하고 있는 것을 비유할 수 있어요. 마찬가지로 멀티 모듈은 여러 RF 구성 요소를 포함하며 가장 일반적인 RC 프로토콜을 지원합니다. 이는 모듈 포트가 있는 무선 송신기와 사용하도록 처음에 설계되었습니다.\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer_2.png\" />\n\n이 프로젝트는 오픈 소스로, 새로운 프로토콜을 추가할 수 있도록 허용합니다. 계속 활발히 유지되는 이 프로젝트에는 공동 작업자들이 계속해서 새로운 모델 지원을 추가하고 있습니다. 그래서 나는 컴퓨터와 연결해서 RC 모델을 수정하지 않고도 모든 RC 모델을 프로그래밍 방식으로 제어할 수 있게끔 고려 중입니다.\n\n# 구현\n\n이 모듈은 시리얼 및 PPM 입력을 수락하며, 이상적으로 컴퓨터에서 직접 시리얼 신호를 보내는 것이 좋을 것입니다. 그러나 작성 시점에 라디오 송신기의 시리얼 사양에 대한 명확한 문서를 찾지 못했기 때문에 (참고 자료가 있는 경우 알려주세요!). 개념을 먼저 테스트하고 싶었기 때문에, 컴퓨터에서 시리얼 명령을 수신하고 그에 따라 PPM 신호를 생성하는 변환기로 아두이노를 사용했습니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n![Image 3](/assets/img/2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer_3.png)\n\n아두이노에는 이미 PPMEncoder 라이브러리가 있습니다. 따라서 제 프로그램은 주로 시리얼 통신을 초기화하고 라이브러리를 호출하여 PPM 신호를 생성합니다. 컴퓨터 측에서는 시리얼 포트 연결을 지원하고 스티어링(채널 1)과 스로틀(채널 2)의 타겟 펄스 폭을 전송하는 간단한 파이썬 애플리케이션을 작성했습니다.\n\n![Image 4](/assets/img/2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer_4.png)\n\n# 결론\n\n\n<div class=\"content-ad\"></div>\n\n마침내 비디오에서 보여준 대로 차량을 수정하지 않고 재고 Mini-Z를 제어할 수 있게 되었어요. 이 설정은 철저히 제품의 조합이며, 납땜도 필요 없고 모든 항목은 다른 목적으로 재사용할 수 있어요. 이 기사가 여러분의 프로젝트에 도움이 되는 비침입적인 방법을 제공하는 데 도움이 되기를 바라요.\n\n참고: \n\n이 프로젝트의 소스 코드: https://github.com/kelvinkoko/universal-rc-controller","ogImage":{"url":"/assets/img/2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer_0.png"},"coverImage":"/assets/img/2024-06-20-ControlanyRCmodelprogrammaticallyfromcomputer_0.png","tag":["Tech"],"readingTime":3},{"title":"아두이노 프로그래밍에서 iOS 앱 개발로","description":"","date":"2024-06-20 16:48","slug":"2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment","content":"\n\n## BLE 연결을 통한 IoT 프로젝트 구축 실습 가이드\n\n이 튜토리얼에서는 iOS 앱 개발과 Arduino 프로그래밍의 세계를 탐험하면서 전자 보드를 무선으로 제어할 수 있는 간단한 시스템을 생성하는 방법을 살펴보겠습니다. Bluetooth Low Energy (BLE) 연결 기능을 활용하여 Arduino Nano 33 BLE Sense 보드와 상호작용하고 LED 상태를 제어하며 센서에서 온도 데이터를 읽는 모바일 애플리케이션을 개발할 것입니다. 이 실습 가이드를 통해 iOS 앱과 Arduino 스케치를 개발하는 단계별 프로세스를 경험하면서 자체 IoT 프로젝트를 만들 수 있는 귀중한 기술을 습득할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_0.png)\n\nNano 33 BLE Sense는 BLE 연결 및 센싱 기능이 필요한 프로젝트에 적합한 소형 Arduino 보드입니다. 다양한 센서를 갖추고 있어 IoT 응용 프로그램, 웨어러블 기기 및 데이터 획득 프로젝트에 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n# BLE 통신 이해하기\n\nBLE는 저전력 기기를 위해 설계된 무선 통신 기술입니다. 이는 클라이언트-서버 아키텍처를 사용하며 다음과 같이 기기가 작동할 수 있습니다:\n\n- 중앙 (클라이언트): 통신을 시작하고 제어합니다.\n- 주변 (서버): 액세스할 데이터 또는 작업을 제공합니다.\n\n서비스와 특성은 BLE 통신의 구성 요소입니다:\n\n<div class=\"content-ad\"></div>\n\n- 서비스는 관련 기능이나 데이터 모음을 나타냅니다.\n- 특징은 서비스 내에서 특정한 데이터 값을 가리킵니다.\n\n연결을 설정하려면 주변 기기가 광고 패킷이라는 작은 메시지를 방송하여 가용성을 알립니다. 중심 기기는 스캔 과정을 통해 이러한 패킷을 수신하고 주변 기기를 발견할 수 있습니다.\n\n중심 기기가 관심 있는 주변 기기를 식별하면 연결을 설정하고 사용 가능한 서비스와 특징과 상호 작용을 시작할 수 있습니다.\n\n우리 프로젝트에서 iOS 앱은 중심의 역할을 하고, Arduino 보드는 주변으로 동작합니다. 보드는 두 개의 별도 서비스 내에서 두 개의 특징을 통해 데이터를 노출할 것입니다:\n\n\n<div class=\"content-ad\"></div>\n\n- Led Status Characteristic (in Led Service): 이 특성은 쓰기 속성을 가진 특성으로, 앱이 0 (끄기) 또는 1 (켜기) 값을 쓰면 LED의 상태를 변경할 수 있습니다.\n- Temperature Characteristic (in Sensor Service): 이 특성은 읽기 및 알림 속성을 가진 특성으로, 보드에서 측정된 온도 값을 검색하고 온도 업데이트에 대한 알림을 받을 수 있도록 합니다.\n\n![이미지](/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_1.png)\n\n# Arduino 프로그램 빌드\n\nArduino 프로그램은 ArduinoBLE 및 Arduino_HTS221 라이브러리를 활용하여 BLE 통신 및 온도 감지 기능을 가능하게 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\r\n#include <ArduinoBLE.h>\n#include <Arduino_HTS221.h>\r\n```\n\n먼저, 스케치는 UUID를 사용하여 필요한 BLE 서비스 및 특성을 설정하고 각 특성에 대한 속성을 정의합니다. UUID(Universally Unique Identifiers)는 BLE 통신 프로토콜에서 서비스 및 특성을 식별하는 데 사용되는 고유 식별자입니다.\n\n```js\r\nBLEService ledService(\"cd48409a-f3cc-11ed-a05b-0242ac120003\");\nBLEByteCharacteristic ledstatusCharacteristic(\"cd48409b-f3cc-11ed-a05b-0242ac120003\", BLEWrite);\n\nBLEService sensorService(\"d888a9c2-f3cc-11ed-a05b-0242ac120003\");\nBLEByteCharacteristic temperatureCharacteristic(\"d888a9c3-f3cc-11ed-a05b-0242ac120003\", BLERead | BLENotify);\r\n```\n\n그런 다음, 프로그램은 BLE 모듈을 초기화하고 로컬 이름 및 광고 서비스를 설정합니다. 사용자가 정의한 로컬 이름은 Arduino에 의해 방송되며 페리퍼럴을 식별하는 사람이 읽을 수 있는 식별자 역할을 합니다. 광고 서비스를 Led 서비스로 설정함으로써, Arduino는 iOS 앱이나 다른 중앙 장치에게 제공하는 특정 서비스에 대해 알립니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nvoid setup() {\n    // ...\n\n    // BLE 초기화\n    if (!BLE.begin()) {\n        while (1);\n    }\n\n    // 광고할 로컬 이름과 서비스 UUID 설정\n    BLE.setLocalName(\"iOSArduinoBoard\");\n    BLE.setAdvertisedService(ledService);\n}\n```\n\nBLE 스택에 서비스와 특성이 추가되며, 온도 특성에 대한 읽기 요청 핸들러가 설정됩니다.\n\n```js\n// 서비스에 특성 추가\nledService.addCharacteristic(ledstatusCharacteristic);\nsensorService.addCharacteristic(temperatureCharacteristic);\n\n// BLE 스택에 서비스 추가\nBLE.addService(ledService);\nBLE.addService(sensorService);\n\n// 온도 특성에 대한 읽기 요청 핸들러 설정\ntemperatureCharacteristic.setEventHandler(BLERead, temperatureCharacteristicRead);\n```\n\n프로그램은 광고를 시작하고 메인 루프에 진입합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n // 광고 시작\n BLE.advertise();\n}\n```\n\n메인 루프에서는 중앙 기기가 연결하도록 대기하며, 연결되면 통신을 처리하는 루프를 시작합니다.\n\n```js\nvoid loop() {  \n  // BLE 센트럴 기기가 연결될 때까지 대기\n  BLEDevice central = BLE.central();\n\n  // 센트럴 기기가 페리페럴에 연결된 경우\n  if (central) {\n    // ...\n    while (central.connected()) {\n      // ...\n    }\n  }\n}\n```\n\n이 루프 내에서 프로그램은 주기적으로 센서에서 온도를 읽어 올바른 온도 값을 업데이트합니다. 또한, 센트럴 기기가 LedStatus 특성에 새 값을 쓰지 않았는지 확인합니다. 새 값을 감지하면 LED를 켜거나 끕니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nwhile (central.connected()) {\n    // ...\n    // 온도 값을 읽어옴\n    temperature = (int) HTS.readTemperature();\n    temperatureCharacteristic.writeValue(temperature);\n    \n    // ...\n    // LedStatus characteristic의 쓰기 여부 확인\n    if (ledstatusCharacteristic.written()) {\n        if (ledstatusCharacteristic.value()) {\n            digitalWrite(LED_BUILTIN, HIGH);\n        } else {\n            digitalWrite(LED_BUILTIN, LOW);\n        }\n    }\n}\n```\n\n마지막으로, 온도 characteristic의 읽기 요청에 응답하기 위해 read 이벤트 핸들러 함수를 구현했습니다. 이 함수는 현재 온도 값을 characteristic에 작성합니다.\n\n```js\nvoid temperatureCharacteristicRead(BLEDevice central, BLECharacteristic characteristic) {\n    temperatureCharacteristic.writeValue(temperature);\n}\n```\n\n# iOS 앱 설계\n\n\n<div class=\"content-ad\"></div>\n\niOS 앱은 사용자 친화적인 인터페이스로 설계되었으며 두 가지 주요 화면으로 구성되어 있습니다:\n\n- 스캔 화면: 앱을 실행할 때 초기화면으로 작동하여 사용자가 주변 기기를 스캔할 수 있게 합니다. 발견된 기기의 목록을 표시하며 사용자는 특정 기기의 이름을 탭하여 연결을 시작할 수 있습니다. 연결에 성공하면 앱은 연결 화면으로 전환됩니다.\n- 연결 화면: 연결된 아두이노와 상호 작용할 수 있는 인터페이스를 제공합니다. 사용자는 LED의 상태를 수정하여 켜거나 끌 수 있습니다. 또한 사용자는 온도를 두 가지 모드로 읽을 수 있습니다: 단일 읽기(Read) 또는 변화의 지속적 모니터링(Notify).\n\n![이미지](/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_2.png)\n\n이 앱은 MVVM (Model-View-ViewModel) 디자인 패턴을 사용한 Clean Architecture에 영감을 받은 아키텍처로 구축되었으며 몇 가지 조정을 통해 단숨함과 이해하기 쉬운 요소를 향상시켰습니다. 이 접근 방식은 앱을 3개의 구분된 계층으로 구성하여 컴포넌트 독립성과 테스트 가능성을 촉진합니다:\n\n<div class=\"content-ad\"></div>\n\n- 프리젠테이션 계층은 사용자 인터페이스와 상호 작용을 처리합니다. 이 계층은 View(사용자 인터페이스 렌더링 담당)와 ViewModel(View의 상태를 관리하는)으로 구성됩니다.\n- 도메인 계층은 응용 프로그램의 핵심 비즈니스 로직을 나타냅니다. 이 계층은 사용 사례를 캡슐화하고 데이터와 상호 작용합니다. 사용 사례는 응용 프로그램에서 수행할 수 있는 특정 비즈니스 작업을 나타냅니다.\n- 데이터 계층은 데이터 접근 및 지속성을 담당합니다. 데이터 작업을 추상화하는 엔티티를 포함합니다.\n\n![image](/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_3.png)\n\n앱은 CoreBluetooth를 활용하여 Bluetooth 관련 작업을 처리할 것입니다. CoreBluetooth는 Apple이 제공하는 프레임워크로, iOS 플랫폼에서 Bluetooth 기기와의 원활한 통신을 가능하게 합니다. Bluetooth 기능 구현을 간소화하는 포괄적인 기능 세트를 제공합니다.\n\nCoreBluetooth를 활용하여, 앱은 주변의 Bluetooth 주변 기기를 탐지하고 연결을 설정하며 기기 간 데이터를 교환할 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n자 이제 iOS 프로그래밍에 직접 참여해 봅시다!\n시작하기 전에 필요한 필수 도구 몇 가지가 있습니다: 맥 컴퓨터와 Apple 플랫폼을 위한 공식 통합 개발 환경(Integrated Development Environment, IDE) 인 Xcode입니다. Xcode는 iOS 애플리케이션을 디자인, 코딩 및 디버깅할 수 있는 종합적인 도구 및 자원 세트를 제공합니다.\n\nXcode를 열고, 환영 화면에서 \"새 Xcode 프로젝트 생성\"을 선택하고 iOS 섹션에서 App 템플릿을 선택하세요. 고유한 제품명(iOSArduinoBLE)을 제공하고, 팀 식별자(귀하의 Apple ID 이름)를 선택하고, 언어(Swift)와 프로젝트를 저장할 위치를 선택하세요.\n\n...여기까지입니다! 시작해 봅시다.\n\n<div class=\"content-ad\"></div>\n\n# iOS 앱: Arduino 보드를 스캔하고 연결하기\n\n스캔 화면에서 사용자는 깔끔하고 직관적인 UI로 BLE 장치를 발견하고 연결할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_5.png)\n\n이 화면의 기본 아키텍처는 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- ScanView: 화면의 UI를 렌더링하는 데 책임이 있습니다. SwiftUI를 사용하여 디자인되었습니다.\n- ScanViewModel: \"Start Scan\" 버튼을 탭하거나 장치 이름을 선택하는 이벤트를 처리합니다. 스캔 및 연결 작업을 실행하기 위해 ScanViewModel은 CentralUseCase에 의존합니다.\n- CentralUseCase: CoreBluetooth 프레임워크와 상호 작용하기 위한 필수 로직을 캡슐화하며, CBCentralManager 객체를 활용합니다. 이 객체는 프레임워크 내에서 스캔을 시작하고 연결을 설정하며 주변기기를 관리합니다.\n\n![이미지](/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_6.png)\n\n데이터 레이어에는 Peripheral 및 UUIDs 두 가지 엔티티가 포함되어 있습니다. Peripheral 객체는 BLE 장치를 나타내며, 장치 이름, 식별자 및 기타 관련 속성과 같은 세부 정보를 보유합니다. UUIDs는 응용 프로그램에서 사용할 서비스 및 특성 목록을 보유하는 컬렉션입니다.\n\n# 스캐닝\n\n<div class=\"content-ad\"></div>\n\n\"Start Scan\" 버튼을 누르면 ScanView가 사용자 상호작용을 캡처하고 요청을 처리하기 위해 ScanViewModel로 전달합니다.\n\n```js\n//  ScanView.swift\n// ...\nButton {\n    viewModel.scan()\n} label: {\n    Text(\"Start Scan\")\n    .frame(maxWidth: .infinity)\n}\n// ...\n```\n\nScanViewModel은 상호작용을 받으면 해당 사용 사례에서 스캔 기능을 트리거합니다. 사용 사례는 LedService를 광고하는 디바이스만 찾도록 지시 받습니다.\n\n```js\n//  ScanViewModel.swift\n// ...\nfunc scan() {\n    useCase.scan(for: [UUIDs.ledService])\n}\n```\n\n<div class=\"content-ad\"></div>\n\n최종적으로 사용 사례는 CoreBluetooth 프레임워크와 상호 작용하여 스캔 프로시저를 시작합니다.\n\n```js\n// CentralUseCase.swift\n// ...\nlazy var central: CBCentralManager = {\n CBCentralManager(delegate: self, queue: DispatchQueue.main)\n}()\n\nfunc scan(for services: [CBUUID]) {\n guard central.isScanning == false else {\n     return\n }\n central.scanForPeripherals(withServices: services, options: [:])\n}\n```\n\nCoreBluetooth에서 scanForPeripherals 함수를 사용할 때, CBCentralManagerDelegate 메소드를 통해 응답을 처리할 수 있습니다. 발견된 페리페럴을 처리하는 델리게이트 메소드는 didDiscover이며, 스캔 과정 중에 페리페랄이 발견될 때마다 호출됩니다.\n\n기기가 발견되면 CentralUseCase는 onPeripheralDiscovery 클로저(즉, 자체 포함된 코드 블록)를 호출하여 새로 발견된 페리페럴의 세부 정보를 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n```swift\n// CentralUseCase.swift\n// ...\nextension CentralUseCase: CBCentralManagerDelegate {\n  func centralManager(_ central: CBCentralManager, didDiscover peripheral: CBPeripheral,\n                       advertisementData: [String : Any], rssi RSSI: NSNumber) {\n      onPeripheralDiscovery?(.init(cbPeripheral: peripheral))\n  }\n  // ...\n}\n```\n\nScanViewModel은 내부 상태를 업데이트하고 ScanView에 새로운 장치가 주변 장치 목록에 표시될 준비가 되었음을 알립니다.\n\n```swift\n// ScanViewModel.swift\n// ...\nuseCase.onPeripheralDiscovery = { [weak self] peripheral in\n    guard let self = self else {\n        return\n    }\n    self.foundPeripherals.insert(peripheral)\n    self.state = .scan(Array(self.foundPeripherals))\n}\n```\n\n```swift\n// ScanView.swift\n// ...\nVStack {\n    List(peripheralList, id: \\.id) { peripheral in\n        Text(\"\\(peripheral.name ?? \"N/A\")\")\n        // ...\n    }\n}\n// ...\n}\n.onReceive(viewModel.$state) { state in\n    switch state {\n        // ...\n        case .scan(let list):\n            peripheralList = list\n        // ...\n    }\n}\n```\n\n<div class=\"content-ad\"></div>\n\n# 연결하기\n\n목록 중 한 장치를 누르면 ScanView가 사용자 상호 작용을 캡처하고 해당 페리페럴에 연결하기 위해 ScanViewModel에 요청을 전달합니다.\n\n```js\n// ScanView.swift\n// ...\nList(peripheralList, id: \\.id) { peripheral in\n    Text(\"\\(peripheral.name ?? \"N/A\")\")\n        // ...\n        .onTapGesture {\n            viewModel.connect(to: peripheral)\n        }\n}\n```\n\n이 작업은 ScanViewModel이 연결 작업을 해당 사용 사례에 전달하도록 유도합니다.\n\n<div class=\"content-ad\"></div>\n\n```swift\n//  ScanViewModel.swift\n// ...\nfunc connect(to peripheral: Peripheral) {\n    useCase.connect(to: peripheral)\n}\n```\n\n마침내 사용 사례는 선택한 장치와 연결 프로세스를 시작하는 동안 스캐닝 프로세스를 중단하여 CoreBluetooth 프레임워크와 상호 작용합니다.\n\n```swift\n//  CentralUseCase.swift\n// ...\nfunc connect(to peripheral: Peripheral) {\n    central.stopScan()\n    central.connect(peripheral.cbPeripheral!)\n}\n```\n\n연결이 성공하면 didConnect 대리자 메서드가 호출됩니다. CentralUseCase는 이 정보를 ScanViewModel에게 onConnection 클로저를 호출하여 전달합니다.\n\n<div class=\"content-ad\"></div>\n\n```swift\n//  CentralUseCase.swift\n// ...\nfunc centralManager(_ central: CBCentralManager, didConnect peripheral: CBPeripheral) {\n    onConnection?(.init(cbPeripheral: peripheral))\n}\n```\n\nScanViewModel은 내부 상태를 업데이트하고 선택한 장치와의 연결이 설정되었음을 ScanView에 알립니다.\n\n```swift\n//  ScanViewModel.swift\n// ...\nuseCase.onConnection = { [weak self] peripheral in\n    self?.state = .connected(peripheral)\n}\n```\n\n그에 따라 ScanView는 ConnectView로 전환합니다.\n\n<div class=\"content-ad\"></div>\n\n```swift\n// ScanView.swift\n// ...\n.onReceive(viewModel.$state) { state in\n    switch state {\n    case .connected:\n        shouldShowDetail = true\n    // ...\n    }\n}\n.navigationDestination(isPresented: $shouldShowDetail) {\n    if case let .connected(peripheral) = viewModel.state  {\n        let viewModel = ConnectViewModel(useCase: PeripheralUseCase(),\n            connectedPeripheral: peripheral)\n        ConnectView(viewModel: viewModel)\n    }\n}\n```\n\n# iOS 앱: 데이터 쓰기 및 읽기\n\nConnect 화면에서 사용자는 Arduino와 상호 작용하여 LED 및 온도와 관련된 정보를 교환할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_7.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n아키텍처는 이전 화면과 일관성을 유지하며 다음 구성 요소를 포함합니다:\n\n- ConnectView: LED 상태를 제어하는 UI 요소, 온도 정보를 읽는 UI 요소, 및 장치와의 연결을 해제하는 UI 요소를 표현합니다. SwiftUI를 사용하여 구현되었습니다.\n- ConnectViewModel: LED 제어를 위한 온/오프 버튼을 탭하거나 온도 알림 활성화를 전환하거나 즉시 온도를 읽는 버튼을 누르는 등 사용자 상호작용을 캡처합니다. 또한 연산을 처리하기 위해 PeripheralUseCase와 통신합니다.\n- PeripheralUseCase: CentralUseCase와 유사하게 CoreBluetooth와 관련된 로직을 담당합니다. CBPeripheral 객체와 상호작용하여 특성과 서비스를 통해 데이터를 관리하고 교환합니다.\n\n![아무 이미지](/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_8.png)\n\n서비스와 특성과의 데이터 교환을 시작하기 전에 발견 단계를 수행해야 합니다. 이 단계에서 CoreBluetooth 프레임워크는 연결된 주변 장치에 의해 제공되는 사용 가능한 서비스와 특성에 대한 정보를 스캔하고 검색합니다.\n\n<div class=\"content-ad\"></div>\n\n# 발견\n\nConnectViewModel 및 해당 PeripheralUseCase를 생성한 후에는 발견 서비스 프로시저가 시작됩니다. 발견된 각 서비스에는 해당하는 특성도 발견됩니다.\n\nCoreBluetooth 프레임워크에서의 응답은 각각의 대리자 메서드인 didDiscoverServices 및 didDiscoverCharacteristicsFor로 전달됩니다. 이러한 메서드는 장치에서 발견된 서비스 및 특성에 대한 정보를 앱에 제공합니다.\n\n```swift\n//  PeripheralUseCase.swift\n// ...\nfunc discoverServices() {\n cbPeripheral?.discoverServices([UUIDs.ledService, UUIDs.sensorService])\n}\n// ...\nfunc peripheral(_ peripheral: CBPeripheral, didDiscoverServices error: Error?) {\n // ...\n  for service in services {\n      // ...\n      peripheral.discoverCharacteristics(uuids, for: service)\n  }\n}\n```\n\n<div class=\"content-ad\"></div>\n\nOnce the discovery process is completed, the `ConnectViewModel` is notified with `onPeripheralReady`, and the UI is prepared to handle operations on the discovered characteristics.\n\n```js\n// PeripheralUseCase.swift\n// ...\nfunc peripheral(_ peripheral: CBPeripheral, didDiscoverCharacteristicsFor service: CBService, error: Error?) {\n  for characteristic in characteristics {\n      discoveredCharacteristics[characteristic.uuid] = characteristic\n  }\n\n  if discoveredCharacteristics[UUIDs.temperatureCharacteristic] != nil &&\n      discoveredCharacteristics[UUIDs.ledStatusCharacteristic] != nil {\n      onPeripheralReady?()\n  }\n}\n```\n\n# Controlling LED\n\nWhen the user presses the on/off buttons, it triggers a write operation to the LedStatus characteristic with a numerical value (1 for “On” and 0 for “Off”). This action, in turn, controls the integrated LED on the board, either turning it on or off accordingly.\n\n<div class=\"content-ad\"></div>\n\n일반적인 흐름을 따라 전체 프로세스가 관리됩니다:\n\n```js\n// ConnectView.swift\n// ...\nButton(\"On\") {\n    viewModel.turnOnLed()\n}\n// ...\nButton(\"Off\") {\n    viewModel.turnOffLed()\n}\n\n// ConnectViewModel.swift\n// ...\nfunc turnOnLed() {\n    useCase.writeLedState(isOn: true)\n}\n\nfunc turnOffLed() {\n    useCase.writeLedState(isOn: false)\n}\n\n// PeripheralUseCase.swift\n// ...\nfunc writeLedState(isOn: Bool) {\n    cbPeripheral?.writeValue(Data(isOn ? [0x01] : [0x00]), for: ledCharacteristic, type: .withResponse)\n}\n```\n\n# 온도 읽기\n\n온도 측정은 두 가지 방법으로 수행할 수 있습니다: 한 번의 값을 얻기 위해 트리거되는 읽기 작업을 사용하는 싱글 샷 모드 또는 실시간 업데이트를 받기 위해 알림 작업을 사용하는 연속 모드입니다.\n\n<div class=\"content-ad\"></div>\n\n다음은 읽기 작업 요청의 흐름입니다:\n\n```js\n//  ConnectView.swift\n// ...\nButton(\"READ\") {\n  viewModel.readTemperature()\n}\n\n//  ConnectViewModel.swift\n// ...\nfunc readTemperature() {\n  useCase.readTemperature()\n}\n\n//  PeripheralUseCase.swift\n// ...\nfunc readTemperature() {\n cbPeripheral?.readValue(for: tempCharacteristic)\n}\n```\n\n알림 작업 흐름의 활성화/비활성화는 동일한 패턴을 따릅니다:\n\n```js\n//  ConnectView.swift\n// ...\nToggle(\"Notify\", isOn: $isToggleOn)\n// ...\n.onChange(of: isToggleOn) { newValue in\n if newValue == true {\n  viewModel.startNotifyTemperature()\n } else {\n  viewModel.stopNotifyTemperature()\n }\n}\n\n//  ConnectViewModel.swift\n// ...\nfunc startNotifyTemperature() {\n  useCase.notifyTemperature(true)\n}\n\nfunc stopNotifyTemperature() {\n  useCase.notifyTemperature(false)\n}\n\n//  PeripheralUseCase.swift\n// ...\nfunc notifyTemperature(_ isOn: Bool) {\n cbPeripheral?.setNotifyValue(isOn, for: tempCharacteristic)\n}\n```\n\n<div class=\"content-ad\"></div>\n\n두 작업은 모두 CoreBluetooth의 동일한 대리자에 응답을 생성합니다. 구체적으로 didUpdateValueFor 메서드입니다. 읽기 작업의 경우 요청한 데이터와 함께 단일 응답이 있을 것입니다. 알림의 경우, 알림이 비활성화될 때까지 응답이 계속 전송됩니다. 각 응답은 UI 상태를 업데이트하기 위해 ConnectViewModel의 onReadTemperature 클로저를 트리거합니다.\n\n```swift\n//  PeripheralUseCase.swift\n// ...\nfunc peripheral(_ peripheral: CBPeripheral, didUpdateValueFor characteristic: CBCharacteristic, error: Error?) {\n  switch characteristic.uuid {\n   case UUIDs.temperatureCharacteristic:\n     let value: UInt8 = {\n       guard let value = characteristic.value?.first else {\n         return 0\n       }\n       return value\n     }()\n     onReadTemperature?(Int(value))\n  }\n}\n\n//  ConnectViewModel.swift\n// ...\nuseCase.onReadTemperature = { [weak self] value in\n self?.state = .temperature(value)\n}\n\n//  ConnectView.swift\n// ...\n@State var lastTemperature: Int = 0\n// ...\nText(\"\\(lastTemperature) °C\")\n// ...\n.onReceive(viewModel.$state) { state in\n  switch state {\n   // ...\n   case let .temperature(temp):\n       lastTemperature = temp\n  }\n}\n```\n\n# 연결 해제\n\n연결 해제 버튼을 누르면 흐름이 약간 다른 방향으로 진행됩니다. 연결 해제 작업은 CBCentralManager 객체에 속하므로 CentralUseCase에서 수행되어야 합니다. 이를 가능하게 하기 위해 사용자가 버튼을 누르면 현재 화면이 해제되고 사용자는 스캔 화면으로 돌아갑니다.\n\n<div class=\"content-ad\"></div>\n\n```swift\n//  ConnectView.swift\n// ...\nButton {\n  dismiss()\n} label: {\n  Text(\"연결 해제\")\n  .frame(maxWidth: .infinity)\n}\n```\n\nScanView가 나타날 때, 수행하는 첫 번째 작업은 이미 연결된 장치가 있는지 확인하고 있다면 연결을 해제하는 것입니다. 이 작업은 해당 ScanViewModel에서 처리되며, 그런 다음 CentralUseCase에 해당 요청을 전달하여 CoreBluetooth 프레임워크에서 연결 해제 작업을 수행합니다.\n\n```swift\n//  ScanView.swift\n// ...\n.onAppear {\n  viewModel.disconnectIfConnected()\n}\n\n//  ScanViewModel.swift\n// ...\nfunc disconnectIfConnected() {\n  guard case let .connected(peripheral) = state,\n  peripheral.cbPeripheral != nil else {\n      return\n  }\n  useCase.disconnect(from: peripheral)\n}\n\n//  CentralUseCase.swift\n// ...\nfunc disconnect(from peripheral: Peripheral) {\n  central.cancelPeripheralConnection(peripheral.cbPeripheral!)\n}\n```\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n이 글에서는 Arduino 프로그래밍부터 iOS 앱 개발로 이동하는 여정을 살펴보았는데, 이 과정에서 BLE 연결을 통해 IoT 프로젝트를 구축하는 데 초점을 맞추었습니다.\n\n우리는 Xcode와 CoreBluetooth 프레임워크를 사용하여 iOS 앱을 만드는 방법을 배웠습니다. BLE의 기본 지식을 습득하고, 청결한 아키텍처 원칙을 공부하며, 확장 가능하고 유지보수 가능한 코드베이스를 보장하기 위해 MVVM 디자인 패턴을 구현해 보았습니다.\n\n이 프로젝트는 여러분의 IoT 프로젝트를 시작하는 좋은 지점이 될 수 있습니다. 그러나 CoreBluetooth를 직접 사용하는 것은 백그라운드 작업 처리의 복잡도와 상위 수준의 기능(메쉬, 펌웨어 업데이트 등) 부족과 같은 몇 가지 제한 사항이 있을 수 있습니다. 이러한 제한 사항을 극복하기 위해, 추가적인 추상화 계층과 고급 기능을 지원하는 서드파티 라이브러리를 활용하는 것이 좋습니다.\n일부 인기 있는 옵션은 다음과 같습니다:\n\n- RxBluetoothKit: 강력한 ReactiveX 기반 BLE 라이브러리.\n- Bluejay: 간편하고 사용하기 쉬운 BLE 라이브러리를 강조하는 현대적인 라이브러리.\n- LittleBlueTooth: 가벼우면서 간편한 BLE 라이브러리.\n\n<div class=\"content-ad\"></div>\n\n# 코드\n\n- iOSArduinoBLE_ArduinoSketch\n- iOSArduinoBLE_iOSApp","ogImage":{"url":"/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_0.png"},"coverImage":"/assets/img/2024-06-20-FromArduinoprogrammingtoiOSAppdevelopment_0.png","tag":["Tech"],"readingTime":18},{"title":"작은 기계 학습 - 포아송 회귀","description":"","date":"2024-06-20 16:45","slug":"2024-06-20-TinyMLPoissonRegression","content":"\n\n수학적 기초부터 엣지 구현까지\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 Research group: Conecta.ai (ufrn.br)\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_0.png)\n\n<div class=\"content-ad\"></div>\n\n## 요약\n\n# 1 — 포아송 회귀 이론\n\n포아송 회귀 모형은 결과가 발생 횟수인 이벤트를 묘사하는 데 사용됩니다: 무양한 정수 값의 이산 데이터로, 어떤 일이 어느 기간 동안 몇 번 발생하는지나 슈퍼마켓 대기 줄에 있는 사람 수와 같이 무양한 것을 계산합니다.\n\n계수 데이터는 비율 데이터로도 표현될 수 있으며, 어떤 일이 특정 기간 내에 몇 번 발생하는지를 순수한 개수로 표현할 수 있습니다. 예를 들어, 하루에 세 끼 식사를 합니다.\n\n<div class=\"content-ad\"></div>\n\nPoisson 회귀는 카운트 데이터와 비율 데이터를 분석하는 데 도움이 되며, 특정 응답 변수 Y에 영향을 미치는 설명 변수가 무엇인지를 확인할 수 있습니다. 예를 들어, 슈퍼마켓은 포아송 회귀를 사용하여 대기줄에 있는 사람 수를 더 잘 이해하고 예측할 수 있습니다.\n\n포아송 분포는 특정 시간 동안 이벤트 또는 이벤트 Y가 발생할 확률을 모델링하며, 이때 발생하는 Y는 이전 Y의 발생 시기에 영향을 받지 않는다고 가정합니다. 이를 수학적으로 표현하면 다음과 같습니다:\n\n\\[P(Y = y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\]\n\n여기서 y = 0,1,2,⋯.\n\n<div class=\"content-ad\"></div>\n\n여기서 μ는 노출 단위당 이벤트가 발생할 평균 횟수입니다. Poisson 분포 매개 변수로도 언급됩니다. 노출은 시간, 공간, 인구 규모, 거리 또는 면적이 될 수 있지만 일반적으로 시간으로 가정되며, (t)로 표시됩니다. 노출 값이 제공되지 않으면 1로 가정됩니다.\n\n## 1.1 — 가정\n\nPoisson 회귀는 통계 모델과 마찬가지로 모델 사용 및 결과 해석 시 고려해야 할 특정 가정이 있습니다. 다음은 Poisson 회귀의 주요 가정입니다:\n\nA. 관측치의 독립성: 관측치는 서로 독립적이어야 합니다. 이것은 한 관측치에서 이벤트의 발생이 다른 관측치에서 이벤트의 발생에 영향을 미치지 않아야 함을 의미합니다. 관측치 간의 의존성이 있으면 편향된 매개변수 추정치와 잘못된 추론으로 이어질 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nB. 매개변수의 선형성: 독립 변수와 포아송 분포의 로그 변환된 평균 간의 관계는 선형이어야 합니다. 이 가정은 각 독립 변수가 종속 변수에 미치는 효과가 독립 변수의 다른 값에 걸쳐 일정함을 의미합니다.\n\nC. 오버디스퍼전스의 부재: 포아송 회귀는 종속 변수의 분산이 평균과 동일하다는 것을 가정합니다. 그러나 현실 세계에서는 분산이 평균을 초과하는 오버디스퍼전스라고 알려진 상황을 자주 만납니다. 만약 오버디스퍼전스가 존재한다면, 비효율적인 매개변수 추정과 과소평가된 표준 오차로 이어질 수 있습니다.\n\nD. 모델의 올바른 명세: 모델에 모든 관련 독립 변수를 포함하고 모델의 기능적 형태를 올바르게 명세하는 것이 중요합니다. 중요한 변수를 빠뜨리거나 잘못된 기능적 형태를 사용하는 경우 편향된 매개변수 추정과 부정확한 예측을 유발할 수 있습니다.\n\nE. 계수 데이터: 포아송 회귀는 발생 이벤트 수를 나타내는 종속 변수가 고정된 시간 또는 공간 단위 내에 발생하는 경우에 대한 계수 데이터를 모델링하는 데 적합합니다. 비계수 데이터에 포아송 회귀를 사용하는 것은 모델의 기본 가정을 위반하고 신뢰할 수 없는 결과를 초래할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nF. 다중공선성 없음: 독립 변수들 간에 다중공선성이 없어야 합니다. 다중공선성은 두 개 이상의 독립 변수가 높은 상관 관계를 가질 때 발생하며, 종속 변수에 대한 개별적인 영향을 추정하기 어렵게 만듭니다. 높은 다중공선성은 표준 오차를 과대폭으로 증폭시키고 추정 매개변수를 불안정하게 만들 수 있습니다.\n\nG. 이상치 없음: 데이터의 이상치는 매개변수 추정치에 불필요한 영향을 미치고 모형의 전체적인 적합도에 영향을 줄 수 있습니다. 회귀 결과의 타당성을 보장하기 위해 이상치를 식별하고 적절히 처리하는 것이 중요합니다.\n\n## 1.2— 모형\n\nGeneralized Linear Models(GLM)은 반응 변수가 정규 분포가 아닌 분포를 따르는 모형입니다. 이는 반응 변수가 Yes, No와 같이 범주형이며 −∞부터 +∞까지 범위가 아닌 모형에서 선형 회귀 모형과 대조적입니다.\n\n<div class=\"content-ad\"></div>\n\n따라서, 응답과 예측 변수 간의 관계가 선형일 필요는 없을 수 있습니다. 일반화 선형 모형에서는:\n\n![image](/assets/img/2024-06-20-TinyMLPoissonRegression_2.png)\n\n여기서 g(⋅)는 선택한 링크 함수를 나타냅니다.\n\n포아송 회귀 모형은 카운트 데이터 및 분할표를 모델링하는 데 사용되는 일반화 선형 모형입니다. 출력인 Y(카운트)는 포아송 분포를 따르는 값입니다. 이는 예상 값(평균)의 로그를 전제로 하며, 이를 일부 알려지지 않은 매개변수로 선형 형태로 모델링할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n비선형 관계를 선형 형태로 변환하기 위해 링크 함수가 사용됩니다. 이 함수는 포아송 회귀의 로그입니다. 이로 인해 포아송 회귀 모델은 종종 로그-선형 모델이라고도 불립니다. 포아송 회귀 모델의 일반적인 수학적 형태는 다음과 같습니다:\n\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_3.png\" />\n\n\n여기서 μi는 반응 변수 Yi의 기대값입니다.\n\n계수 α와 β는 수치이며, 여기서 α는 절편을 나타내며 때로는 α는 β0으로도 표시됩니다. x는 예측 변수 또는 설명 변수입니다.\n\n<div class=\"content-ad\"></div>\n\n한 개의 예측 변수(predictor variable)와 한 개의 응답 변수(response variable)를 갖는 방정식을 고려해 봅시다:\n\n![equation1](/assets/img/2024-06-20-TinyMLPoissonRegression_4.png)\n\n이는 다음과 동일합니다:\n\n![equation2](/assets/img/2024-06-20-TinyMLPoissonRegression_5.png)\n\n<div class=\"content-ad\"></div>\n\n포아송 회귀 모형에서 설명변수는 수치값 또는 범주값의 조합을 가질 수 있습니다.\n\n포아송 분포와 포아송 회귀의 가장 중요한 특징 중 하나는 등분산성입니다. 이는 분포의 평균과 분산이 같음을 의미합니다.\n\n평균을 μ라고 가정해보겠습니다. 포아송 회귀에서는 평균과 분산이 다음과 같이 관련되어 있습니다:\n\n![equation](/assets/img/2024-06-20-TinyMLPoissonRegression_6.png)\n\n<div class=\"content-ad\"></div>\n\n여기서 σ²은 분산 파라미터를 나타냅니다. 포아송 모델이 완전히 적합되려면 분산이 평균과 동일해야 합니다(var(Y) = E(Y)) 즉, σ² 값은 1이 되어야 합니다.\n\n분산이 평균보다 클 때에는 이를 초과분산(overdispersion)이라고 하며, σ² 값이 1보다 큽니다. 반면 σ² 값이 1보다 작을 때에는 이를 미달분산(underdispersion)이라고 합니다.\n\n## 1.3 — 계수 추정\n\n포아송 회귀에서는 모델 파라미터를 추정하여 독립 변수와 종속 계수 변수 간의 최적 관계를 찾습니다. 이 추정은 주로 최대 우도법을 사용하여 수행됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 1.3.1 — 최대 우도 방법 (Maximum Likelihood Method, MLM)\n\n최대 우도 방법은 통계 모델의 매개 변수를 추정하기 위한 널리 사용되는 통계 기법입니다. 이 방법은 관측된 데이터의 우도를 극대화하는 매개 변수 값을 찾습니다. 즉, 우리는 제안된 모델에 의해 생성되었을 가능성이 가장 높은 관측된 데이터를 만드는 매개 변수를 찾습니다.\n\n포아송 회귀 분석에서 우도 함수는 각 개별 관측을 위한 관측된 횟수를 관측 확률의 곱으로 정의됩니다. 형식적으로, 우도 함수 L(β0, β1,…, βp)는 다음과 같이 주어집니다:\n\n<div class=\"content-ad\"></div>\n\n여기에 있습니다:\n\n- n은 총 관측값의 수입니다.\n- yi는 i번째 관측값의 관측된 수입니다.\n- μi는 i번째 관측값에 해당하는 이론적 평균으로, 로그 링크 함수에 의해 주어집니다.\n\n파라미터 추정의 목표는 우도 함수를 최대화하는 계수 β0, β1,..., βp의 값을 찾는 것입니다. 다시 말해, 우리는 관측된 데이터가 포아송 회귀 모델에 의해 생성되었을 가능성이 가장 높은 매개변수를 찾습니다.\n\n# 2 — TinyML 구현\n\n<div class=\"content-ad\"></div>\n\n위의 예시를 통해 ESP32, Arduino, Arduino Portenta H7 with Vision Shield, Raspberry 및 다른 다양한 마이크로컨트롤러 또는 IoT 기기에서 머신러닝 알고리즘을 구현할 수 있습니다.\n\n2.0 — requirements.txt 파일에 나열된 라이브러리를 설치하세요\n\n```js\n!pip install -r requirements.txt\n```\n\n2.1 — 라이브러리 가져오기\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import PoissonRegressor\nfrom sklearn.metrics import (\n    mean_absolute_error,\n    mean_poisson_deviance,\n    mean_squared_error,\n)\n\nimport m2cgen as m2c\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom matplotlib import pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n```\n\n2.2 — 데이터셋 로드\n\n“차량 속성 및 배출 데이터셋”은 2000년에 제조된 다양한 차량에 대한 포괄적인 정보를 포함하고 있습니다. 이 데이터셋에는 제조사, 모델, 차량 클래스, 엔진 크기, 실린더 수, 변속기 유형 및 연료 유형과 같은 세부 정보가 포함되어 있습니다. 또한 연료 소비 및 이산화탄소 배출에 대한 범위를 제공하여 각 차량의 환경 영향에 대한 통찰을 제공합니다. 이 데이터셋은 소형부터 중형까지 다양한 차종을 포함하며, 전통적인 모델부터 고성능 모델까지 모두 포함하고 있습니다. 이 정보를 통해 분석가와 연구자는 차량 특성, 연료 효율성 및 배출 추세를 연구할 수 있습니다. 이 데이터셋은 자동차 산업 환경을 이해하고 환경 지속 가능성 및 교통 정책에 대한 논의에 정보를 제공하는 소중한 자료원으로 사용됩니다.\n\n링크: https://www.kaggle.com/datasets/krupadharamshi/fuelconsumption/data\n\n\n<div class=\"content-ad\"></div>\n\n```python\ndf = pd.read_csv('./data/FuelConsumption.csv')\ndf.head()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_8.png\" />\n\n```python\ndf.info()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_9.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n```js\ndf.describe()\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_10.png)\n\n2.3 — 데이터 정리\n\n```js\n# 1. 결측값이 있는 행 제거\ndf.dropna(inplace=True)\n# 2. 중복값 제거\ndf.drop_duplicates(inplace=True)\n```\n\n<div class=\"content-ad\"></div>\n\n\n# 데이터 프레임 정리 후에 결과 표시\ndf.describe()\n\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_11.png)\n\n2.4 — 탐색적 데이터 분석\n\n```python\nsns.pairplot(df[['ENGINE SIZE','CYLINDERS','FUEL CONSUMPTION','COEMISSIONS ']])\nplt.savefig('.\\\\figures\\\\pairplot.png', dpi=300, bbox_inches='tight')\n```\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_12.png\" />\n\n```js\ncorr = df[['ENGINE SIZE','CYLINDERS','FUEL CONSUMPTION','COEMISSIONS ']].corr('spearman')\n```\n\n```js\n# 그림 크기 조절\nplt.figure(figsize=(18,10))\n# 히트맵 생성을 위한 기존 코드\nheatmap = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap='coolwarm')\n# 히트맵에 값 추가\nfor i in range(len(corr.columns)):\n    for j in range(len(corr.columns)):\n        plt.text(j + 0.5, i + 0.5, f\"{corr.iloc[i, j]:.2f}\", ha='center', va='center', color='black', fontsize=18)\n\nplt.xticks(fontsize=20, rotation=45)\nplt.yticks(fontsize=20, rotation=0)\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(labelsize=20)\n\nplt.savefig('.\\\\figures\\\\heatmap.png', dpi=300, bbox_inches='tight')\n\n# 히트맵 표시\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-20-TinyMLPoissonRegression_13.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n2.5— 훈련 및 테스트 데이터로 분할하기\n\n```js\nX=df[['엔진 크기','실린더', 'CO2 배출량']]\ny=df[['연료 소비']]\n```\n\n```js\n# 데이터를 훈련 세트와 테스트 세트로 분할하기\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n```\n\n2.6 — 회귀 모델 생성하기\n\n<div class=\"content-ad\"></div>\n\n```js\ndef score_estimator(y_pred , y_true):\n\n    print(\n        \"MSE: %.3f\"\n        % mean_squared_error(\n            y_true, y_pred\n        )\n    )\n    print(\n        \"MAE: %.3f\"\n        % mean_absolute_error(\n            y_true, y_pred, \n        )\n    )\n\n    # 푸아송 손실을 계산할 때, 유효하지 않은 비 양수 예측을 무시합니다.\n    mask = y_pred > 0\n    if (~mask).any():\n        n_masked, n_samples = (~mask).sum(), mask.shape[0]\n        print(\n            \"경고: 추정자가 푸아송 손실을 계산할 때, %s개의 샘플 중 %s개의 비 유효한, 비 양수 예측 값이 있습니다. 이러한 예측 값은 푸아송 손실을 계산할 때 무시됩니다.\"\n            % (n_samples, n_masked)\n        )\n\n    print(\n        \"평균 푸아송 손실: %.3f\"\n        % mean_poisson_deviance(\n            y_true ,\n            y_pred  \n        )\n    )\n```\n\n```js\nmodel = PoissonRegressor(alpha=1e-12)\n```\n\n2.7 — 모델 학습\n\n```js\nmodel.fit(X_train, y_train)\n```\n\n<div class=\"content-ad\"></div>\n\n2.8 — 모델 평가\n\n```js\ny_train_pred = model.predict(X_train)\ny_test_pred = model.predict(X_test)\n```\n\n```js\n# 잔차 계산\ntrain_residuals = y_train.values.reshape(1,-1).tolist()[0] - y_train_pred\n# 잔차의 평균과 표준 편차 계산\ntrain_residuals_mean = np.mean(train_residuals)\ntrain_residuals_std = np.std(train_residuals)\n# 잔차 계산\ntest_residuals = y_test.values.reshape(1,-1).tolist()[0] - y_test_pred\n# 잔차의 평균과 표준 편차 계산\ntest_residuals_mean = np.mean(test_residuals)\ntest_residuals_std = np.std(test_residuals)\n\n\n# 잔차 시각화\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(y_train_pred, train_residuals, c='blue', marker='o', label=f'학습 데이터')\nplt.axhline(y=0, color='r', linestyle='-')\nplt.axhline(y=train_residuals_mean, color='k', linestyle='--', label=f'평균: {train_residuals_mean:.3f}')\nplt.axhline(y=train_residuals_mean + 2 * train_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*train_residuals_std:.2f}')\nplt.axhline(y=train_residuals_mean - 2 * train_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*train_residuals_std:.2f}')  \nplt.xlabel('예측 값')\nplt.ylabel('잔차')\nplt.title('잔차 대 예측 값 (학습 데이터)')\nplt.legend(loc='upper left')\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.scatter(y_test_pred, test_residuals, c='green', marker='s', label=f'테스트 데이터')\nplt.axhline(y=0, color='r', linestyle='-')\nplt.axhline(y=test_residuals_mean, color='k', linestyle='--', label=f'평균: {test_residuals_mean:.3f}')\nplt.axhline(y=test_residuals_mean + 2 * test_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*test_residuals_std:.2f}')\nplt.axhline(y=test_residuals_mean - 2 * test_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*test_residuals_std:.2f}')  \nplt.xlabel('예측 값')\nplt.ylabel('잔차')\nplt.title('잔차 대 예측 값 (테스트 데이터)')\nplt.legend(loc='upper left')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n\n\n# 정규성 확인\nplt.figure(figsize=(10, 5))\n\nplt.subplot(1, 2, 1)\nplt.hist(train_residuals, bins=20, color='blue', alpha=0.6)\nplt.title('잔차 히스토그램 (학습 데이터)')\nplt.xlabel('잔차')\nplt.ylabel('빈도')\nplt.axvline(x=train_residuals_mean, color='k', linestyle='--', label=f'평균: {train_residuals_mean:.3f}')\nplt.axvline(x=train_residuals_mean + 2 * train_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*train_residuals_std:.3f}')\nplt.axvline(x=train_residuals_mean - 2 * train_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*train_residuals_std:.3f}')  \nplt.legend(loc='upper right')\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.hist(test_residuals, bins=20, color='green', alpha=0.6)\nplt.title('잔차 히스토그램 (테스트 데이터)')\nplt.xlabel('잔차')\nplt.ylabel('빈도')\nplt.axvline(x=test_residuals_mean, color='k', linestyle='--', label=f'평균: {test_residuals_mean:.3f}')\nplt.axvline(x=test_residuals_mean + 2 * test_residuals_std, color='g', linestyle='--', label=f'+2 표준 편차: {2*test_residuals_std:.3f}')\nplt.axvline(x=test_residuals_mean - 2 * test_residuals_std, color='g', linestyle='--', label=f'-2 표준 편차: {-2*test_residuals_std:.3f}')  \nplt.legend(loc='upper right')\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! 요청하신 내용을 한국어로 번역해 드리겠습니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_15.png)\n\n2.8.1 — 훈련 데이터로 모델 평가하기\n\n```js\nprint(\"PoissonRegressor 평가:\")\nscore_estimator(y_train_pred, y_train)\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_16.png)\n\n<div class=\"content-ad\"></div>\n\n```js\nplt.plot(y_train.values, label=\"원본\")\nplt.plot(y_train_pred, label=\"예측\")\nplt.legend(loc='best', fancybox=True, shadow=True)\nplt.grid()\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_17.png)\n\n2.8.2 — 테스트 데이터로 모델 평가\n\n```js\nprint(\"PoissonRegressor 평가:\")\nscore_estimator(y_test_pred, y_test)\n```\n\n<div class=\"content-ad\"></div>\n\n![2024-06-20-TinyMLPoissonRegression_18.png](/assets/img/2024-06-20-TinyMLPoissonRegression_18.png)\n\n```js\nplt.plot(y_test.values, label=\"original\")\nplt.plot(y_test_pred, label=\"predicted\")\nplt.legend(loc='best', fancybox=True, shadow=True)\nplt.grid()\n```\n\n![2024-06-20-TinyMLPoissonRegression_19.png](/assets/img/2024-06-20-TinyMLPoissonRegression_19.png)\n\n2.9 — Microcontroller에 구현될 모델 얻기\n\n<div class=\"content-ad\"></div>\n\n```js\ncode = m2c.export_to_c(model)\nprint(code)\n```\n\n```js\n#include <math.h>\ndouble score(double *input)\n{\n    return exp(1.7347124654302846 + input[0] * 0.011406244946132144 + input[1] * 0.01010646886054758 + input[2] * 0.0028201461971878914);\n}\n```\n\n2.10— .h 파일에 템플릿 저장\n\n```js\nwith open('./PoissonRegressor.h', 'w') as file:\n    file.write(code)\n```\n\n<div class=\"content-ad\"></div>\n\n## 2.11 — 모델 배포\n\n2.11.1 — 아두이노 스케치 완성\n\n```js\n#include \"PoissonRegressor.h\"\n\nEloquent::ML::Port::PoissonRegressor PoissonRegressor;\n\nvoid setup()\n{\n  Serial.begin(115200);\n}\n\nvoid loop()\n{\n  float X_1[] = {6., 2.7, 5.1, 1.6};\n  int result_1 = PoissonRegressor.predict(X_1);\n  Serial.print(\"X1을 입력으로 한 예측 결과(실제 값 = 1):\");\n  Serial.println(result_1);\n  delay(2000);\n\n  float X_2[] = {4.8, 3.1, 1.6, 0.2};\n  int result_2 = PoissonRegressor.predict(X_2);\n  Serial.print(\"X2을 입력으로 한 예측 결과(실제 값 = 0):\");\n  Serial.println(result_2);\n  delay(2000);\n}\n```\n\n2.12 — 결과\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-20-TinyMLPoissonRegression_20.png)\n\n전체 프로젝트: TinyML/15_Poisson_Regressor at main · thommaskevin/TinyML (github.com)\n\n## 만약 마음에 드신다면 제게 커피 한 잔 사주세요 ☕️💰 (Bitcoin)\n\n코드: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-20-TinyMLPoissonRegression_21.png)\n","ogImage":{"url":"/assets/img/2024-06-20-TinyMLPoissonRegression_0.png"},"coverImage":"/assets/img/2024-06-20-TinyMLPoissonRegression_0.png","tag":["Tech"],"readingTime":15},{"title":"최신 Cura 소프트웨어에 Sovol SV06-Plus 추가하기","description":"","date":"2024-06-20 16:42","slug":"2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware","content":"\n\n<img src=\"/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_0.png\" />\n요즘 소벌 SV06-Plus 3D 프린터를 4학년 학생들을 위한 교실에 구입했는데, 처음 몇 개의 인쇄물에서 문제가 발생했습니다. 몇 차례 시행착오 끝에, 문제는 Ultimaker Cura 슬라이싱 소프트웨어 구성과 관련되어 있음을 깨달았습니다.\n\n소벌은 Cura 소프트웨어의 버전을 제공하지만 5개의 버전이 뒤떨어져 있고 윈도우 사용자만을 대상으로 합니다. 나머지들을 위해서는 스스로 해결해야 한다는 생각 같습니다. 다소 짜증이 나는 부분이지만, 몇 차례 시도와 나쁜 출력물 끝에, 최신 Ultimaker Cura 슬라이싱 소프트웨어에 SV06-Plus 프로필을 추가하는 방법을 Reddit의 게시물에서 찾아 성공적으로 진행하고 있습니다. 다른 사람들이 이 정보를 찾을 수 있도록, 원래 방법의 그래픽 버전을 작성했습니다. 기술에 능통하다면, 원본을 살펴보세요. 매우 쉽습니다.\n\n# 튜토리얼 시작\n\n<div class=\"content-ad\"></div>\n\n이 튜토리얼은 두 부분으로 나뉩니다. 먼저, 절대 초보자를 위해 설치 과정을 안내합니다. 이미 최신 버전의 Ultimaker Cura를 설치한 경우에는 'The Sovol SV06-Plus Profile 추가' 섹션으로 건너뛰세요.\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_1.png)\n\n# 설치\n\n## Cura Version 5 + Sovol SV06 Plus\n\n<div class=\"content-ad\"></div>\n\n공식 웹사이트: [https://sovol3d.com/products/sovol-sv06-plus](https://sovol3d.com/products/sovol-sv06-plus)\n\n![Sovol SV06 Plus](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_2.png)\n\n## [테스트 완료] 다음 컴퓨터 시스템에서\n\n- MacOs Ventura 13.3, Apple M2\n- Windows 10\n- Windows 11\n\n<div class=\"content-ad\"></div>\n\n1 — https://ultimaker.com/에 방문해 보세요.\n\n2 — 네비게이션에서 Software 위로 커서를 올려 UltiMaker Cura를 선택하세요.\n\n![UltiMaker Cura](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_3.png)\n\n3 — 이후에 Download For Free 버튼을 클릭하세요.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_4.png\" />\n\n1. 4번 - 운영 체제를 선택하세요.\n\n2. 5번 - .dmg 파일이 다운로드되기 시작해야 합니다. 파일 이름은 다음과 같을 것입니다: UltiMaker-Cura-#.#.#-mac.dmg. 여기서 #.#.#은 소프트웨어 버전 번호일 것입니다. 예: 5.3.1\n\n3. 6번 - .dmg 파일을 두 번 클릭하여 설치하세요.\n\n<div class=\"content-ad\"></div>\n\n7 - 창이 나타납니다. 약관에 동의하고 설치를 계속하세요.\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_5.png)\n\n8 - 다음 창에서 Ultimaker Cura를 애플리케이션 폴더로 끌어다 놓으세요.\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_6.png)\n\n<div class=\"content-ad\"></div>\n\n9. 컴퓨터 속도에 따라 진행 표시 막대를 볼 수 있을 수 있습니다.\n\n![image](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_7.png)\n\n10. 8단계의 설치 팝업 창을 닫습니다.\n\n11. Ultimaker Cura 애플리케이션을 엽니다.\n\n<div class=\"content-ad\"></div>\n\n12 — Cura를 열고 싶어하는지 물어보는 팝업이 나타날 수 있습니다. 이것은 인터넷에서 다운로드한 앱이라는 것을 알려줍니다. '열기'를 클릭하세요.\n\n![image](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_8.png)\n\n13 — Cura를 처음 열면 '시작하기' 버튼이 보일 것입니다.\n\n14 — 클릭하고 동의하세요!\n\n<div class=\"content-ad\"></div>\n\n15 - 다음을 클릭하세요.\n\n16 - 마지막으로, Ultimaker는 [건너뛰기], [무료 Ultimaker 계정 생성], 또는 [로그인]을 원하는지 물을 것입니다. 이 튜토리얼에서는 일단 [건너뛰기]를 선택하겠습니다.\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_9.png)\n\n17 - 다음으로, 프린터 추가를 요청합니다. 우리는 아직 SVO6 Plus를 위한 프로필 구성 파일을 가져오지 않았기 때문에, 임시 커스텀 프린터를 만들겠습니다.\n\n<div class=\"content-ad\"></div>\n\n18 — 선택하세요: UltiMaker 프린터가 아닌 프린터\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_10.png)\n\n19 — 이번에는 선택하세요: 네트워크에 연결되지 않은 프린터 추가\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_11.png)\n\n<div class=\"content-ad\"></div>\n\n20 — 다음으로 UltiMaker가 선택된 브랜드 목록을 볼 수 있습니다. 다음 브랜드인 Custom으로 스크롤하여 선택하세요: Custom FFF\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_12.png)\n\n21 — 우리가 SV06 Plus 프린터를 추가한 후에 이 프린터의 이름을 지정하지 마세요. 현재는 [다음]을 클릭하세요.\n\n22 — 기계 설정에 대해 [다음]을 클릭하세요.\n\n<div class=\"content-ad\"></div>\n\n23 — 새로운 내용을 보려면 건너뛰기를 클릭하세요\n\n24 — 마지막으로, [완료]를 선택하세요\n\n25 — 이제 Cura 애플리케이션 창이 표시됩니다. 아래 스크린샷과 비슷한 모습입니다.\n\n![Cura 애플리케이션 창](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_13.png)\n\n<div class=\"content-ad\"></div>\n\n# + Sovol SV06-Plus 프로필 추가하기\n\n우선, 파일 및 원본 지시 사항을 제공해준 Reddit 사용자 vgergo에게 감사의 말씀을 전합니다. 원본 Reddit 게시물 — 그는 Cura 프로필을 더 잘 이해하기 위한 자세한 자습서를 작성했습니다.\n\n1 — 다음 zip 폴더를 다운로드하세요: Sovol SV06 Plus Configuration Files.zip\n\n2 — 이제 폴더를 추출/해제하십시오. 추출된 폴더에는 다음과 같은 폴더와 파일이 포함되어 있어야 합니다.\n\n<div class=\"content-ad\"></div>\n\n\n```json\ndefinition > SV06_Plus.def.json\nextruders  > SV06_extruder_0.def.json \nimages     > sovolbackplate.png \nmeshes     > sovol_300_300_platform.obj\n```\n\n3. Cura가 실행 중이거나 열려 있는지 확인해 주세요.\n\n4. 상단 네비게이션에서 '도움말'을 찾고 선택해주세요.\n\n5. 드롭다운이 나타납니다. '설정 폴더 표시'를 선택해주세요.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_14.png)\n\n6 — 이제 Cura 구성 파일이 모두 저장된 디렉토리가 표시됩니다.\n\n7 — 추출/압축 해제된 폴더를 Cura 구성 파일 옆으로 이동하세요.\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_15.png)\n\n\n<div class=\"content-ad\"></div>\n\n8 - 이제 파일을 드래그 앤 드롭하거나 복사하여 붙여 넣으세요.\n\n```js\n' /definitions/' 로 'SV06_Plus.def.json' 파일을 복사\n' /extruders/' 로 'SV06_extruder_0.def.json' 파일을 복사\n```\n\n<img src=\"/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_16.png\" />\n\n```js\n# 이미지 및 메쉬 폴더는 복사할 때까지 존재하지 않습니다.\n\n'/5.3/images'로 '/images'를 복사\n'/5.3/meshes'로 '/meshes'를 복사\n```\n\n<div class=\"content-ad\"></div>\n\n9. Cura 애플리케이션을 닫고 다시 열어주세요.\n\n10. 새로운 Sovol SV06 Plus 프린터를 추가해 봅시다. 두 가지 방법으로 진행할 수 있어요. [Custom] 버튼을 클릭하거나 상단 네비게이션에서 다음을 선택하세요:\n설정 ` 프린터 ` 프린터 추가\n\n![2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_17.png](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_17.png)\n\n![2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_18.png](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_18.png)\n\n<div class=\"content-ad\"></div>\n\n11— 이제 이전과 마찬가지로 선택하세요:\n\n- 울티메이커 프린터가 아님\n- 네트워크에 연결되지 않은 프린터를 추가하세요\n\n12 — 이번에는 리스트가 나타나면 Sovol 브랜드가 나타날 때까지 아래로 스크롤하고 확장하세요. 이제 프린터 목록에 Sovol-SV06 Plus가 나타날 것입니다.\n\n![이미지](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_19.png)\n\n<div class=\"content-ad\"></div>\n\n13 - 그것을 선택하면 동일한 이름을 부여받습니다. 그런 다음 [추가]를 클릭하세요.\n\n14 - 이제 Sovol SV06 Plus와 유사한 외관과 올바른 크기를 가진 사용자 정의 빌드 플랫폼이 표시됩니다. 아래 스크린샷을 참조하세요.\n\n![스크린샷](/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_20.png)\n\nGitHub에서 확인하실 수 있습니다: https://github.com/drjonesy/CuraSovol3D#add_sv06_plus","ogImage":{"url":"/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_0.png"},"coverImage":"/assets/img/2024-06-20-AddSovolSV06-PlustotheLatestCuraSoftware_0.png","tag":["Tech"],"readingTime":6},{"title":"3D 프린팅으로 완전히 만든 ARC 로켓과 국가대회에 진출하는 법","description":"","date":"2024-06-20 16:40","slug":"2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals","content":"\n\n올해 우리 팀은 ARC 국가 결승전에 진출하여 3D 프린트 된 로켓을 사용하여 Mission 상의 '가장 혁신적인 방법'상을 수상했습니다. 이 글에서는 이 로켓을 개발하면서 경험한 여정과 배운 점을 공유하겠습니다. ARC나 로켓 항공공학에 관심 있는 팀들은 이 디자인에 대한 우리의 학습과 경험에서 이득을 볼 것입니다.\n\n![이미지](/assets/img/2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals_0.png)\n\n2003년에 시작된 미국 로켓 공모전인 ARC는 전 세계에서 가장 큰 로켓 대회로, 수천 개의 고등학교 팀이 참가합니다. 올해의 도전 과제는 BT-70(56mm) 페이로드 튜브를 사용하고, 그런 다음 BT-80(66mm)으로 변환되는 지느러미 부분이었습니다. 일반적으로 이러한 로켓은 판지 및 기타 시중 제품으로 제작됩니다. 예를 들어, 팀들은 이 Apogee Components의 바디 튜브 부품이나 이 변환 부품을 사용할 수 있습니다. 그리고, 에폭시와 같은 접착제를 사용하여 부착합니다. 목재 센터링 링과 같은 것들은 모터를 부착하는 데 사용됩니다.\n\n로켓의 비행은 목표 최고점(올해는 820피트)으로부터의 거리와 목표 시간(43-46초)으로 점수가 매겨집니다. 우리는 처음에 판지 로켓으로 시작했고 여름 동안 많은 낮은 점수의 비행을 했습니다. 그러나 더 많은 발사를 하면서 로켓이 점점 일관성 없이 되었고, 10회 발사 후에는 우리가 원하는 일정한 낮은 점수를 더이상 얻을 수 없었습니다. 전통적인 로켓 디자인에는 다른 단점이 많이 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 비싸요 — 우리의 로켓은 오프 더 셀프 부품을 사용해 만들었을 때 약 $100 정도에요.\n- 느려요 — 하루에 6시간씩 3일 동안 작업해서 2대의 로켓을 만들었어요. 프로세스 각각의 단계 사이에 에폭시가 건조되어야 해서 시간이 오래 걸렸어요.\n- 반복 작업이 어려워요 — 사용자 정의 지오메트리는 튜브에 사물을 정확히 장착하는 것이 어려워서 만들기 어려웠어요.\n\n시즌이 끝나가는 시점에, 우리는 공학 설계 프로세스를 적용하고 싶었어요. 여기서 빠른 반복이 성공의 핵심이에요. 그래서 우리는 완전히 3D로 출력하기로 결정했어요. 신뢰할 수 있는 디자인을 얻기까지 여러 번의 발사와 학습을 거치다가, 추진 로켓이 견딜 수 있는 힘을 유지하면서 낮은 질량을 유지할 수 있는 신뢰할 수 있는 디자인에 이르렀어요. 그리고 이렇게 해서 얻은 이점들을 발견했어요:\n\n- 저렴해요 — 약 $3 정도의 가격이 나가는 250g의 필라먼트가 필요해요.\n- 빠르게 만들 수 있어요 — 출력하는 데 24시간이 걸리고 조립하는 데 단 10분만 걸려요.\n- 반복 작업이 용이해요 — 모든 부품이 모듈식이기 때문에 무언가가 고장나거나 변경이 필요한 경우, 해당 부분을 교체할 수 있어요. 전통적인 로켓과 달리 (영구적으로 에폭시로 뭉쳐진) 전체를 다시 만들 필요가 없어요.\n\n하지만 이 모든 것이 장점만 있는 것은 아니에요. 여기 몇 가지 단점이 있어요:\n\n<div class=\"content-ad\"></div>\n\n- 무게가 더 무겁습니다 - 플라스틱보다 현저히 가벼운 전환폭에 연결된 기판이 있기는 하지만, 튜브는 PLA(우리가 사용한 3D 프린팅 재료)가 몸체 튜브에 사용된 크래프트 종이보다 거의 3배 밀도가 높기 때문에 훨씬 더 무겁습니다. 전체적으로, 약 50g 정도 더 무겁습니다.\n- 강도가 부족합니다 - 모듈성은 가격이 붙는데, 부품 간의 연결부는 파괴될 수 있습니다. 이는 PLA가 카드보드보다 훨씬 부서지기 쉽기 때문에 더 심해집니다. 콘크리트나 자갈 위에 경칩하여 3D 프린팅된 로켓이 부서지기도 합니다.\n\n결국, 해당 디자인은 2개의 외곽선과 3%의 채움률로 인쇄되었습니다. 이것이 대부분의 기본 구조에 대해 수용할만한 강도와 무게를 제공한다는 것을 발견하였습니다.\n\n# 우리가 배운 것\n\n로켓이 발사되면, 추진제가 짧은 기간 동안 연소됩니다 - 우리는 대략 1초 동안입니다. 그런 다음, 로켓은 중력과 저항에 의해 느리게 내려오는 약 7초 동안 이륙 절정 지점(apogee)에서 미끄러집니다. 이 기간에 모터 지연이 타는 동안, 마침내 낙하산을 발사하며, 최상(비행의 꼭대기)에서 이상적으로 이루어집니다. 하지만 현실적으로는 종종 이상 또는 이하에서 열리기도 합니다. 높은 속도로 개방되는 낙하산으로 인한 급속한 감속이 모델의 전 구조 전체에 큰 압력을 가해서, 많은 로켓을 분실하는 문제가 있었습니다. 다음은 우리가 로켓을 강화하기 위해 한 일부 조취입니다:\n\n<div class=\"content-ad\"></div>\n\n\n![image1](/assets/img/2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals_1.png)\n\nTo enhance the strength of the fin can tube, which lacks internal structure (only containing parachutes), we incorporated helical ribs.\n\n![image2](/assets/img/2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals_2.png)\n\nTo reinforce each part without significant weight gain, we integrated fillets across the design.\n\n\n<div class=\"content-ad\"></div>\n\n\n![Rocket](/assets/img/2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals_3.png)\n\nThe shock cord mount broke (left). We solved this by using a slicer modifier to add 4 perimeters (right). We did the same with the payload tube.\n\n## 조정 방법\n\n고도를 제어하기 위해 질량을 변경해야 하는데, 중심 축을 움직이지 않도록 조정해야 합니다. 중심 축을 움직이면 안전성에 영향을 줄 수 있습니다. 이를 해결하기 위해 질량을 중심 축에 두어야 합니다. 우리는 2부식 페이로드를 사용하여 이를 달성했습니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n![로켓 이미지](/assets/img/2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals_4.png)\n\n왼쪽의 전이 구간에는 페니를 넣을 수 있는 관이 있었어요. 그런 다음, 우리는 넣은 3개의 나사로 우주선 관로 페이로드 관을 장착했어요. 이 3개의 나사는 페이로드 관의 3개 구멍에 넣는 열린 삽입기(bottom-right)에 들어갔어요.\n\n# 작동했나요?\n\n네, 잘 작동했어요! 19점으로 국가대회에 진출할 수 있었어요. 한 주 동안 4개의 예비 우주선을 만들었고, 새로운 기능을 원할 때마다 디자인을 빠르게 업데이트할 수 있었어요. 한 부분이 고장 나더라도 전체 우주선을 버리지 않고 교체할 수 있었어요. 모든 부품이 모듈식이기 때문에, 우주선 간에 부품을 그대로 옮길 수 있었고, 충격 줄과 낙하산 보호대에 30회 이상 쏘아올릴 수 있었어요. ARC 팀이 이에 관심이 있는 경우, 전체 3D 프린팅된 로켓을 꼭 추천드리겠어요.\n\n\n<div class=\"content-ad\"></div>\n\nThingiverse에서 CAD 파일을 확인해보세요!","ogImage":{"url":"/assets/img/2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals_0.png"},"coverImage":"/assets/img/2024-06-20-HowImadeafully3d-printedARCrocketandqualifiedfornationals_0.png","tag":["Tech"],"readingTime":4},{"title":"PLA와 PLA 필라멘트의 차이는 무엇인가요","description":"","date":"2024-06-20 16:39","slug":"2024-06-20-WhatisthedifferencebetweenPLAandPLAfilament","content":"\n\nPLA (Polylactic Acid) 및 PLA+ (PLA 플러스)은 부가 제조 분야에서 일반적으로 사용되는 3D 프린터 필라멘트 유형입니다. 비슷한 점을 공유하지만 두 제품 사이에는 몇 가지 주요 차이가 있습니다.\n\n소재 구성: PLA와 PLA+는 대부분 옥수수 전분이나 사탕수수로 만들어진 재생 가능 자원에서 파생됩니다. 그러나 PLA+ 필라멘트는 표준 PLA보다 성능을 향상시키기 위해 첨가제나 조절제를 포함합니다.\n\n강도 및 내구성: PLA+ 필라멘트는 일반적으로 표준 PLA 필라멘트보다 강하고 내구성이 뛰어납니다. 충격 조절제나 내열제와 같은 조절제를 첨가함으로써 재료의 충격, 굽힘 및 변형 저항력이 향상됩니다. 이러한 증가한 강도로 더 견고한 출력물을 만들 수 있어 파손 가능성을 줄일 수 있습니다.\n\n![PLA and PLA+ 차이](/assets/img/2024-06-20-WhatisthedifferencebetweenPLAandPLAfilament_0.png)\n\n<div class=\"content-ad\"></div>\n\n인쇄 온도: PLA+는 일반 PLA에 비해 일반적으로 더 높은 인쇄 온도를 가지고 있어요. 보통 PLA 필라멘트는 190~220°C 정도에서 잘 인쇄되지만, PLA+ 필라멘트는 약간 더 높은 온도 범위, 일반적으로 210~235°C 정도를 요구하죠. 두 종류의 3D 프린터 필라멘트를 전환할 때 인쇄 설정을 적절하게 조정하는 것이 중요해요.\n\n표면 마무리: 일반 PLA 필라멘트와 비교했을 때, PLA+ 필라멘트는 종종 보다 부드러운 표면 마무리를 제공해요. PLA+의 향상된 유동 특성은 인쇄 중 층 간격이 줄어들고 최종 출력물의 신경쓰이는 층이 줄어듭니다.\n\n인쇄 용이성: 일반적으로 PLA+ 필라멘트는 표준 PLA 필라멘트에 비해 조금 더 어려운 인쇄로 간주됩니다. 향상된 강도와 높은 인쇄 온도로 인해 3D 프린터의 정밀한 캘리브레이션과 인쇄 설정의 조정이 더 많이 필요할 수 있어요. 그러나 적절한 조정을 하면 대부분의 일반 소비자용 3D 프린터에서도 신뢰할 수 있게 PLA+를 인쇄할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n다른 제조사들은 PLA+의 조성에 차이를 둘 수 있으므로 각 브랜드마다 특정 속성과 특징이 달라질 수 있음을 유의해야 합니다. 최적의 인쇄 설정과 결과를 보장하기 위해 항상 각 3D 프린터 필라멘트에 대한 제조사의 권장사항과 지침을 참고하는 것이 좋습니다.","ogImage":{"url":"/assets/img/2024-06-20-WhatisthedifferencebetweenPLAandPLAfilament_0.png"},"coverImage":"/assets/img/2024-06-20-WhatisthedifferencebetweenPLAandPLAfilament_0.png","tag":["Tech"],"readingTime":2},{"title":"선박 건조 V - 이론에서 실무로 고난과 역경","description":"","date":"2024-06-20 16:38","slug":"2024-06-20-BuildingaShipVfromTheorytoPracticethetravails","content":"\n\n오프셋 테이블은 배의 선체를 시각화하는 훌륭한(그러나 혼란스러운) 방법입니다. 이것들은 단순한 숫자에서 전체 3D 구조물로 이어지는 과정을 제공합니다. 만일 나무/판재로 배를 건설할 때 오프셋 테이블에 의존한다면, 재료에 따라 오프셋이 변하는 점을 알아두세요. 일부 나무 판재는 잘 구부러지지만, 다른 것들은 그렇지 않습니다. 이러한 경우에는 나무의 자연 곡선을 따라야 합니다. 이것은 어렴풋하게 배워온 교훈으로, 아직 완전한 답을 가지고 있지 않습니다. 대부분의 경우, 내 디자인은 3D 프린팅 부품들에 의존하고 곡률은 플라스틱에 설정되어 있었기 때문입니다.\n\n이 시점에서, 다음을 전제합니다:\n- 당신이 좋아하는 선체 계획을 찾았다.\n- 선체에 대한 라인 드로잉(및/또는 오프셋 테이블)을 찾았다.\n- 오프셋을 충분히 스케일링하여 최종 오프셋 테이블을 얻었다. 이 테이블은 각 Z(높이)에서 선체의 X - Y 좌표를 가져야 합니다.\n\n요약하자면, 저는 선체를 외부의 모든 스테이션 라인 지점에 접촉하는 표면으로 시각화합니다. 이 관점의 장점은 선체를 특정 Z(높이) 값에서 스테이션 라인에 접촉하는 일련의 곡선으로 정의할 수 있다는 것입니다. 이러한 곡선을 연결하여 표면을 만들면, 바로 당신의 선체가 완성됩니다.\n\n<div class=\"content-ad\"></div>\n\n역 노선 좌표 예제를 보려면 여기를 참조하십시오. 저는 스쿠너 CA 세이어 계획을 기반으로 만들었습니다. 물론, CA 세이어가 제가 시도한 첫 번째 모델은 아니었습니다. 먼저 사콜레바 그리에고(Sacoleva Griego)라는 작은 어선 모델을 시작했습니다. [여기 링크는 Google 검색으로 찾은 많은 링크 중 하나입니다. 더 나은/저렴한 링크를 찾으셨다면 그걸로 대체해주세요].\n\n이 모델은 작업을 시작하기에 나쁘지 않았지만, 제가 저렴하고 디자인 파일을 사기 꺼려서 돈을 아껴 쓰고 싶었습니다. 대신에 제공된 선 도면을 출력하여 규칙과 계산기로 분석했습니다. 이를 통해 선박의 선호를 대략적으로 좋은 좌표로 파악할 수 있었습니다 (아래에는 선박을 위한 사이즈 조정된 도면이 있습니다). 전체 크기의 TIF는 여기에서 제공됩니다. 다시 말씀드리지만, 인터넷에서 저화질 이미지를 찾아 확대했습니다. 그래서 품질은 조금 양해 부탁드립니다.\n\n![선박 건조 관련 이미지](/assets/img/2024-06-20-BuildingaShipVfromTheorytoPracticethetravails_0.png)\n\n선박 설계 시 중요한 문제 중 하나는 스테이션 라인(무릎)을 킬(등)에 고정하는 것입니다. 당연히 생각한 것은 잠금장치처럼 맞물리도록 설계하는 것이었습니다 - 무릎에 구불리고 킬에 놓일 도리깃이있습니다. 아래 이미지는 킬의 홈에 놓일 탭이 있는 스테이션 라인을 보여줍니다 (아래 그림은 두 번째 이미지입니다).\n\n<div class=\"content-ad\"></div>\n\n오, 빌딩 어 숲 Ⅴ선박 실제제작 과정에서 겪은 어려움을 제대로 반영한 디자인인데요. 원래 간단한 디자인이었지만 (으흠!) 탭이 홈에 완벽하게 맞지 않아서 늑골이 홈에 정상적으로 앉지 않는 문제가 발생했어요. 사진 속의 키르 부분에서, 초록색 화살표가 Y축을 나타내고 파란색이 Z축을 나타냅니다. 보이지 않는 빨간색 화살표가 X축이며 늑골 홈을 따라 진행됩니다. 홈과 탭의 불완전성으로 인해 X축을 따라 큰 편차가 발생하여 Y축을 중심으로 회전했을 때 정상적이지 않았다는 것을 의미했어요. 이는 스테이션 라인이 충분히 정상적이지 않아서(늑골에 수직이 아니었기 때문) 스테이션 라인으로서 충분하지 않다는 뜻이에요. 다시 디자인 작업을 시작하겠습니다!\n\nY축을 중심으로 회전을 상쇄하기 위해 탭을 X축을 따라 연장하여 추가적인 안정성을 제공했어요. 수정된 디자인은 아래와 같이 보이게 되었습니다:\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-20-BuildingaShip-VfromTheorytoPracticethetravails_3.png)\n\n탭의 확장을 볼 수 있어요. 이게 X축에서 중요한 안정성을 제공해 주는데, 그치만..!!\n\n맞아요, 맞추셨어요. Y축에 대한 회전은 안정화되었지만, X축에 대한 불안정성은 안 제거되었어요. 다시 말해, 홈/잠금이 갈래를 X-Y 평면에 수직으로 유지하기에는 너무 얇고 얕았어요(3mm). 갈래는 왼쪽이나 오른쪽으로 움직이고 중앙에 위치하지 않았어요. 다시 말하면, 이는 선상이 선체를 정의하는 능력에 영향을 미치죠.\n\n하지만 (다시 한 번), Y축을 중심으로 움직임과 같이 극복하기 어려운 문제는 아니었어요. 명쾌한 CA 접착제를 사용해서 (거의) 해결되었어요.\n\n<div class=\"content-ad\"></div>\n\n와우!! 다음 작업(도전?)은 이 골격 주변에 선체를 짓는 것이었습니다. 우리의 계획은 FreeCAD에서 선체 점을 사용하여 표면을 만들고 두께를 추가하고 등고선에 맞는 널판을 만드는 것이었습니다. 간단한 계획. 여기서 신들의 웃음소리가 들리시나요? 들리게 될 거에요.\n\n위의 사진에서 무언가를 보거나 알아차렸나요? [만약 못 봤다면 용서받을게요, 왜냐하면 문제를 직면할 때까지 저도 몰랐기 때문입니다] 우리는 Y축 주위의 회전과 X축 주위의 회전을 제어했지만, X축을 따라 슬라이딩/이동을 제어하지 않았습니다. 선체는 모양과 워크선의 위치에 의해 정의되는 정밀한 3D 모양입니다. 그러나 우리의 설계에서는 워크선이 홈을 따라 이동하지 않는 제약이 없었습니다. 그래서 나는 3D 출력한 어떤 표면도 디자인에 맞지 않았을 것입니다. 왜냐하면 워크선이 있어야 할 곳에 위치하지 않았기 때문입니다.\n\n이때 나는 디자인을 만지작거리기 싫어서 그냥 임의로 작업했습니다. 두 워크선 사이의 간격과 같은 길이의 간격 바를 출력해서 사용했습니다 (확장된 탭을 제외하고). 다행히도 이 경우에는 워크선이 거의 모두 균일 간격이었습니다. 다시 출력하고 선체를 짓기로! 마침내 실제로 보였어요. 여기 사진이 있습니다!\n\n![사진](/assets/img/2024-06-20-BuildingaShipVfromTheorytoPracticethetravails_4.png)\n\n<div class=\"content-ad\"></div>\n\n다음으로 선체 스트립을 인쇄하고 여기에 스테이션 라인에 고정하려고 시도했습니다.\n\n![Image](/assets/img/2024-06-20-BuildingaShipVfromTheorytoPracticethetravails_5.png)\n\n여기 몇 가지 문제가 명백히 있습니다. Z 축을 따라 왜곡이 있습니다. 어떻게 생겼는지 묻지 마세요 — 아직 알아내지 못했습니다. 가장 가능성이 높은 것은 탭에 결함이 있는 것으로, 홈에 삽입될 때 회전을 유발한다는 것입니다. 그러나 선체가 \"실제\" 스테이션 라인 윤곽을 따라 판자로 인쇄되었기 때문에 모든 것을 유지하는 것처럼 보입니다.\n\n또 다른 실험을 하기도 했는데, 선체를 표면으로 만들었지만 전혀 스테이션 라인을 사용하지 않았습니다. 아래 디자인처럼 보였습니다 (FreeCAD에서).\n\n<div class=\"content-ad\"></div>\n\n\n![BuildingaShipVfromTheorytoPracticethetravails_6](/assets/img/2024-06-20-BuildingaShipVfromTheorytoPracticethetravails_6.png)\n\n디자인 측면에서 매우 간단하고 좋은 결과를 얻었어요 — 거의. 인쇄할 때 선체는 이렇게 보였어요:\n\n![BuildingaShipVfromTheorytoPracticethetravails_7](/assets/img/2024-06-20-BuildingaShipVfromTheorytoPracticethetravails_7.png)\n\n아! 마침내 찾았다. FreeCAD에서 여러 곡선을 사용하여 표면을 생성할 때, 표면에는 두께가 없어요. 그래서 표면에 두께를 추가해야 합니다. 그러나 두께는 주요 축 중 하나에만 한 번에 추가할 수 있어요. 즉, 두께는 곡선이 주요 축을 횡단하는 선체 일부 영역에서 너무 얇아요. 특히 X-Y 대 Z. 이것이 위 모델에서 보이는 결함을 일으켰어요.\n\n\n<div class=\"content-ad\"></div>\n\n여기서 실패가 있었지만, 나는 이것이 선체를 만드는 가장 좋은 방법이라고 확신하고 있어요. 3D 곡선을 따라 균일하게 두께를 두는 방법을 적용할 수 있다면 좋겠어요. 만약 누군가가 FreeCAD에서 그것을 하는 방법을 찾는다면 아래 댓글을 남겨 주세요. 감사하겠어요.\n\n그래서 이번에는 정말 다시 시작해 볼 거에요.\n\n다음 파트까지 잘 지내요! 계속 실험해 보세요.","ogImage":{"url":"/assets/img/2024-06-20-BuildingaShipVfromTheorytoPracticethetravails_0.png"},"coverImage":"/assets/img/2024-06-20-BuildingaShipVfromTheorytoPracticethetravails_0.png","tag":["Tech"],"readingTime":5}],"page":"49","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}