{"pageProps":{"posts":[{"title":"Llama 3 해제하기 Llama 3 마스터하기를 위한 궁극적인 안내","description":"","date":"2024-06-20 18:57","slug":"2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3","content":"\n\n![이미지](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_0.png)\n\n최근 몇 년 동안 인공 지능의 세계는 대부분 대형 언어 모델(Large Language Models, LLMs)의 등장 덕분에 급속하게 발전해 왔습니다. 이러한 고급 시스템들은 기본 텍스트 처리기에서 인간과 유사한 텍스트를 이해하고 생성할 수 있는 정교한 모델로 진화했습니다. 이러한 능력과 응용 프로그램의 중요한 발전을 표시하는 것은 메타의 최신 제품인 Llama3입니다. Llama3는 오픈 모델의 접근성과 성능의 경계를 재정의할 것을 약속하는 플랫폼입니다.\n\n지난 주에 메타는 8B 및 70B 모델의 Llama3를 공개했으며, 이는 개선된 추론 기능을 포함하여 해당 모델 규모에 대한 새로운 기준을 세우는 놀라운 발전을 선보였습니다. Llama3는 날이 갈수록 가장 뛰어난 공개적으로 이용 가능한 LLM으로, 그 출시는 인공 지능 분야에서 중요한 대목을 이루었습니다.\n\n본 문서에서는 Llama3에 대해 자세히 살펴볼 것이며, 해당 기술을 효과적으로 활용하는 방법에 대한 포괄적인 가이드를 제공할 것입니다. 또한 Llama3의 잠재력을 탐구하고 어떻게 여러 산업을 혁신할 수 있는지 살펴볼 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 시작하기\n\n## 목차\n\n- Llama 3이란 무엇인가요?\n- 주요 기능\n- Llama 2 대 Llama 3\n- Llama 3 대 다른 모델들\n- Llama 3 안전 기능\n- Llama 3 실험\n- 방법 1: Google Colab 및 HuggingFace 사용하기\n- Llama 3를 활용한 챗봇 만들기\n- 방법 2: Ollama 사용하기\n\n## Llama 3이란 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n메타 라마 3는 Meta의 언어 모델 라인 중 가장 최신 제품으로, 80억과 700억 개의 매개변수를 포함한 버전이 있습니다. 이 모델은 일상 대화에서부터 복잡한 추론 작업까지 다양한 응용 프로그램에서 우수한 성능을 발휘하도록 설계되었습니다. 이전 모델을 능가하는 성능을 보여줍니다. 라마 3는 무료로 이용할 수 있어 AI 개발 및 기타 분야에서의 혁신을 촉진합니다.\n\n![Llama3](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_1.png)\n\n### 주요 기능:\n\n- 80억과 700억 개의 매개변수 모델 모두에 통합되어 집중적이고 효과적인 처리를 위해 추론 효율성을 향상시킵니다.\n- MMLU 및 HumanEval과 같은 작업에서 이전 모델 및 경쟁 모델을 능가하여 다양한 벤치마크에서 뛰어난 성과를 보입니다.\n- 라마 3은 디코더 전용 트랜스포머 구조를 유지하면서 중요한 개선 사항을 포함하고, 128,000 개의 토큰을 지원하는 토크나이저를 사용하여 언어 부호화 효율성을 향상시킵니다.\n- Llama 2의 데이터셋보다 7배 큰 15조 토큰 이상의 데이터셋에서 훈련되었으며, 30개 이상 언어의 다양한 언어 표현과 비영어 데이터가 통합되어 있습니다.\n- 지도 미세 조정, 거부 샘플링 및 정책 최적화를 결합하여 모델 품질과 의사 결정 능력을 개선하는 향상된 사후 훈련 단계가 있습니다.\n- 상세한 스케일링 법칙을 사용하여 데이터 혼합 및 계산 자원을 최적화하고, Llama 2와 비교하여 학습 과정의 효율성을 세 배로 높이면서 다양한 응용 프로그램에서 견고한 성능을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n## 람마 2 대 람마 3\n\n람마 3은 이전 람마 2 모델을 기반으로 하여 핵심 디코더 전용 트랜스포머 아키텍처를 유지하며 여러 가지 주요 개선 사항을 도입했습니다. 토크나이저는 이제 128,000개의 토큰을 지원하여 언어의 더 효율적인 인코딩과 향상된 성능을 가능하게 합니다. 또한, 람마 3은 그룹화된 쿼리 어텐션 (GQA)을 통합하여 다양한 매개 변수 모델에 걸쳐 추론 효율성을 향상시킵니다. 이 모델은 8,192토큰의 시퀀스를 마스킹을 사용하여 보다 집중된 효과적인 처리를 보장합니다.\n\n![이미지](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_2.png)\n\n## 람마 3 대 다른 모델들\n\n<div class=\"content-ad\"></div>\n\n메타가 개발한 라마 3은 다양한 벤치마크에서 이전 모델 및 경쟁 모델들을 능가하는 새로운 기준을 세웠습니다. 특히 MMLU와 같은 다양한 영역의 지식을 평가하는 테스트와 코딩 기술에 중점을 둔 HumanEval과 같은 테스트에서 뛰어난 성과를 보였습니다. 또한, 라마 3은 Google의 제미니 1.5 Pro나 안소로픽의 클로드 3 소네토와 같은 다른 고매개변수 모델들을 특히 복잡한 추론 및 이해 과제에서 능가했습니다.\n\n메타의 라마 3은 다양한 벤치마크와 응용 프로그램에서 뛰어난 성능을 보이며, 특히 추론, 코딩 및 창의적 글쓰기와 관련된 작업에서 뛰어난 성과를 거두고 있습니다. 다양하고 정확한 응답을 생성할 수 있는 능력은 다른 모델들과 구별되며, 개선된 사용자 경험과 생산성을 보장합니다.\n\n![이미지](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_3.png)\n\n## 라마 3 안전 기능\n\n<div class=\"content-ad\"></div>\n\nLlama 3은 Llama Guard 2, Cybersec Eval 2, 그리고 Code Shield와 같은 새로운 안전 및 신뢰 기능을 소개합니다. 이러한 기능들은 사용 중에 안전하지 않은 코드를 걸러내는 역할을 합니다. torchtune과 함께 개발된 Llama 3은 효율적인 작성, 세밀 조정, 그리고 대규모 언어 모델(LLM)의 테스트를 용이하게 하는 PyTorch 기반 라이브러리이며, Hugging Face와 Weights & Biases와 같은 플랫폼들과 통합되어 있습니다.\n\n![이미지](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_4.png)\n\n책임 있는 배포는 \"레드팀\" 노력을 포함한 체계적인 테스트를 통해 보장되며, 특히 사이버 보안 분야에서의 안전성과 견고성을 평가합니다. Llama Guard 2는 MLCommons의 산업 표준을 따르며, CyberSecEval 2는 보안 조치를 강화합니다. Llama 3의 개발은 AI 커뮤니티를 통합하고 잠재적인 위험을 대응하기 위한 개방적인 접근을 강조하며, Meta의 책임 있는 사용 가이드(RUG)는 모베이션 모델 측면과 클라우드 제공업체에 의한 내용 관리 도구를 제공합니다.\n\n# Llama 3 실험하기\n\n<div class=\"content-ad\"></div>\n\n로컬 머신에서 Llama 3을 실험하는 것은 오픈 소스 기능을 활용하는 다양한 도구 덕분에 더 쉬워졌어요. Hugging Face가 이끄는 선두주자로 Llama 3 모델의 지원이 이제 가능하며, 그들의 Hub에서 Transformers 라이브러리를 통해 접근할 수 있어요. 전체 정밀도 모델을 선호하시든가, 4비트 양자화 모델의 효율성을 선호하든가, 설치와 실행은 매끄럽게 처리됩니다.\n\n여기서는 서로 다른 사용자 선호도와 기술 수준에 맞는 두 가지 구체적인 방법을 살펴볼 거에요.\n\n## Method 1: Google Colab 및 HuggingFace 사용\n\n자유로운 Colab 티어에서 Llama 3을 실행하는 실습으로 빠져들어 봅시다!\n\n<div class=\"content-ad\"></div>\n\n## 단계 1: 라마 3 액세스 활성화\n\n라마 3은 액세스 요청이 필요한 보안 모델입니다.\n\n![이미지](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_5.png)\n\n모델 액세스를 활성화하는 단계를 따르세요.\n\n<div class=\"content-ad\"></div>\n\n- Hugging Face 계정에 로그인하거나 아직 계정이 없는 경우 새 계정을 등록해보세요.\n- https://huggingface.co/meta-llama/Meta-Llama-3-8B를 방문하여 접근 권한을 요청할 수 있어요.\n- 성명, 생년월일, 국가, 소속과 같은 사용자 세부 정보를 제공해주세요. 라마 3 모델에 접근할 수 있도록 라이선스 동의를 받은 후에, 이제 Llama 3 모델에 접속할 수 있어요.\n\n- 접속을 확인하려면 다음 링크로 이동해주세요: huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json. Llama 3 모델에 성공적으로 접근한 경우, 관련 정보를 수신할 수 있을 거예요. \n\n![UnlockingLlama3YourUltimateGuidetoMasteringLlama3_6](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_6.png)\n\n## 단계 2: Hugging Face 액세스 토큰 생성\n\n<div class=\"content-ad\"></div>\n\n모델에 액세스하려면 HuggingFace 액세스 토큰이 필요합니다. 설정으로 이동하여 왼쪽 사이드 바의 Access Tokens에 들어가 \"New token\" 버튼을 클릭하여 새 액세스 토큰을 생성할 수 있습니다.\n\n## 단계 3: HuggingFace를 사용하여 Llama 3로 첫 번째 스크립트 만들기\n\n- [Colaboratory에 오신 것을 환영합니다 — Colab](https://colab.research.google.com/) 링크로 이동하고 \"로그인\"을 클릭하여 colab 계정에 로그인하거나 계정이 없는 경우 새로 만드세요.\n- 런타임을 T4 GPU로 변경하려면 런타임 → 런타임 유형 변경 → T4 GPU → 저장을 클릭하세요.\n- Gemma를 사용하려면 Hugging Face 액세스 토큰을 제공해야 합니다. 왼쪽 편에 있는 Secrets(🔑)를 선택하고 HF_TOKEN 키를 추가하세요.\n- + 새 노트북 버튼을 클릭하여 새 콜랩 노트북을 만드세요.\n\n## 단계 4: 종속 항목 설치\n\n<div class=\"content-ad\"></div>\n\n아래 명령어를 사용하여 transformers, accelerate 및 bitsandbytes 라이브러리를 설치해보세요.\n\n```js\n!pip install -U \"transformers==4.40.0\" --upgrade\n!pip install accelerate bitsandbytes\n```\n\n## 단계 5: 모델 다운로드 및 설치\n\nLlama 3 모델을 설치하고 텍스트 생성 파이프라인을 설정해보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport transformers\nimport torch\n\nmodel_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model_id,\n    model_kwargs={\n        \"torch_dtype\": torch.float16,\n        \"quantization_config\": {\"load_in_4bit\": True},\n        \"low_cpu_mem_usage\": True,\n    },\n)\n```\n\n## 단계 6: 쿼리 전송\n\n추론을 위해 모델에 쿼리를 보내세요.\n\n```js\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant!\"},\n    {\"role\": \"user\", \"content\": \"\"\"Hey how are you doing today?\"\"\"},\n]\n\nprompt = pipeline.tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n)\n\nterminators = [\n    pipeline.tokenizer.eos_token_id,\n    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n]\n\noutputs = pipeline(\n    prompt,\n    max_new_tokens=256,\n    eos_token_id=terminators,\n    do_sample=True,\n    temperature=0.6,\n    top_p=0.9,\n)\n\nprint(outputs[0][\"generated_text\"][len(prompt):])\n```\n\n<div class=\"content-ad\"></div>\n\n아래와 같은 결과를 얻게 됩니다.\n\n```js\n잘 지내고 있어요, 물어봐 주셔서 감사해요! 저는 도움이 되는 어시스턴트이기 때문에 언제든지 궁금한 점이나 해야할 일이 있으면 도와드릴 준비가 되어 있어요. 여러분은요? 오늘은 어떠신가요? 좋은 하루 보내고 있나요?\n```\n\n<img src=\"/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_7.png\" />\n\n## Llama 3를 사용하여 챗봇 만들기\n\n<div class=\"content-ad\"></div>\n\n이 섹션에서는 gradio를 사용하여 Llama 3를 이용한 챗봇을 생성할 것입니다.\n\n- gradio 패키지 설치\n\n```js\n!pip install gradio\n```\n\n- 노트북에 새 셀을 생성하고 다음 코드를 추가하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport gradio as gr\n\nmessages = []\n\ndef add_text(history, text):\n    global messages\n    history = history + [(text,'')]\n    messages = messages + [{\"role\":'user', 'content': text}]\n    return history, text\n\ndef generate(history):\n  global messages\n  prompt = pipeline.tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n)\n\n  terminators = [\n    pipeline.tokenizer.eos_token_id,\n    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n]\n\n  outputs = pipeline(\n    prompt,\n    max_new_tokens=256,\n    eos_token_id=terminators,\n    do_sample=True,\n    temperature=0.6,\n    top_p=0.9,\n)\n  response_msg = outputs[0][\"generated_text\"][len(prompt):]\n  for char in response_msg:\n      history[-1][1] += char\n      yield history\n  pass\n\nwith gr.Blocks() as demo:\n\n    chatbot = gr.Chatbot(value=[], elem_id=\"chatbot\")\n    with gr.Row():\n            txt = gr.Textbox(\n                show_label=False,\n                placeholder=\"Enter text and press enter\",\n            )\n\n    txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n            generate, inputs =[chatbot,],outputs = chatbot,)\n\ndemo.queue()\ndemo.launch(debug=True)\n```\n\n- 셀을 실행하세요. 노트북에 gradio 인터페이스가 표시되거나 새 탭에서 열기 위해 제공된 링크를 사용할 수 있습니다. 아래와 같이 출력이 나타납니다.\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*tQMX7SYlik7Riuwd5FE_Jg.gif\" />\n\n## 방법 2: Ollama 사용하기\n\n\n<div class=\"content-ad\"></div>\n\n큰 언어 모델(LLMs)을 클라우드 서비스에 의존하지 않고 로컬에서 실행할 수 있는 대안을 찾고 있다면, Ollama가 그에 최적의 선택일 것입니다. Ollama는 지역에서 LLMs를 실행하기 위해 설계된 오픈 소스 소프트웨어로, 직접 제어를 받을 수 있도록 해줍니다.\n\nOllama를 시작하려면 소프트웨어를 다운로드하기만 하면 됩니다. Ollama를 사용하면 데이터 프라이버시를 유지하면서 계산 자원을 직접 제어할 수 있는 이점을 누릴 수 있습니다.\n\n- Ollama 공식 사이트로 이동합니다.\n- 다운로드를 클릭하여 소프트웨어를 다운로드합니다.\n- 설치 파일을 더블 클릭하고 설치를 클릭하여 설치합니다.\n- 설치가 완료되면 다음 명령을 사용하여 지정된 모델로 로컬 서버를 시작하실 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\njs\nCompile the text ollama run llama3:instruct.\n\nAlso, use llama3, llama3:70b, llama3:70b-instruct as arguments for different types of llama3 models. Make sure you have a proper internet connection; otherwise, you may encounter an error like dial tcp: lookup no such host error while pulling the model.\n\n## Running the Model\n\n- Once the model is downloaded, you can start querying. Input your context directly through the terminal or use the API to interact with the model.\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_8.png\" />\n\n## Curl 명령어를 사용하여 모델 쿼리\n\nOllama는 curl을 사용하기 위해 포트 11434에 노출된 엔드포인트 (/api/generate)를 노출했습니다. 다음 형식을 사용하여 쿼리할 수 있습니다.\n\n```js\ncurl http://localhost:11434/api/generate -d \"{ \\\"model\\\": \\\"llama3:instruct\\\", \\\"prompt\\\": \\\"무지개에는 몇 가지 색이 있나요?\\\", \\\"stream\\\": false }\"\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_9.png\" />\n\n## 포스트맨(Postman)을 이용하여 모델 조회하기\n\n- Postman을 엽니다.\n- 요청 방법으로 POST를 선택합니다.\n- URL 입력 필드에 엔드포인트를 제공합니다: localhost:11434/api/generate.\n- 요청 바디 형식으로 JSON을 선택합니다.\n- 요청 바디 내용을 아래와 같이 제공합니다. \"prompt\": \"value\"를 적절한 내용으로 바꿉니다.\n\n```js\n{\n    \"model\": \"llama3:instruct\",\n    \"prompt\":\"무지개에는 몇 가지 색이 있나요?\",\n    \"stream\":false\n}\n```\n\n<div class=\"content-ad\"></div>\n\n- Ollama 엔드포인트에 요청을 보내려면 Send 버튼을 클릭하세요.\n- 아래와 같이 결과를 받게 됩니다.\n\n```js\n{\n    \"model\": \"llama3:instruct\",\n    \"created_at\": \"2024-04-29T17:34:38.0223636Z\",\n    \"response\": \"무지개에서 흔히 볼 수 있는 7가지 색은 다음과 같습니다.\\n\\n1. 빨강\\n2. 주황\\n3. 노랑\\n4. 초록\\n5. 파랑\\n6. 남색\\n7. 보라\\n\\n이 색은 때때로 ROY G BIV라는 약어를 사용하여 기억되기도 하는데, 각 글자는 색깔의 이름을 나타냅니다. 무지개에 대해 더 알고 싶으세요? 아니면 다른 점에 도움을 받고 싶으세요?\",\n    \"done\": true,\n    \"context\": [\n        128006,\n        ...\n        128009\n    ],\n    \"total_duration\": 17278010500,\n    \"load_duration\": 5247897400,\n    \"prompt_eval_count\": 19,\n    \"prompt_eval_duration\": 1196966000,\n    \"eval_count\": 92,\n    \"eval_duration\": 10829807000\n}\n```\n\n![UnlockingLlama3YourUltimateGuidetoMasteringLlama3_10](/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_10.png)\n\n만약 이 기사가 마음에 드셨다면 👏 버튼을 클릭하여 공유해 주세요!\n\n<div class=\"content-ad\"></div>\n\n이 튜토리얼의 전체 소스 코드는 여기에서 찾을 수 있어요,\n\n## 참고문헌","ogImage":{"url":"/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_0.png"},"coverImage":"/assets/img/2024-06-20-UnlockingLlama3YourUltimateGuidetoMasteringLlama3_0.png","tag":["Tech"],"readingTime":11},{"title":"RL 경계를 넓히기 LLMs와 VLMs와 같은 기본 모델을 강화 학습에 통합하기","description":"","date":"2024-06-20 18:53","slug":"2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning","content":"\n\n## Foundational Models를 RL Training 루프에 통합하는 심층 탐구\n\n저자: Elahe Aghapour, Salar Rahili\n\n## 개요:\n\n트랜스포머 아키텍처와 고성능 컴퓨팅 기술의 발전으로 인해, 최근에는 Foundational 모델을 훈련하는 것이 핫한 주제로 떠올랐습니다. 이를 통해, RL(강화 학습) 알고리즘의 성능을 향상시키기 위해 Foundational 모델을 통합하거나 훈련하는 노력들이 이루어지고 있으며, 이는 이 분야에 대한 흥미로운 방향을 시사합니다. 여기에서 Foundational 모델이 강화 학습에 큰 도움이 될 수 있는지에 대해 논의하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n최신 연구에 대한 탐구에 앞서, 기반 모델이 강화 학습에 큰 도움을 줄 수 있는 방법에 대해 이야기해보겠습니다. 우리의 목표는 사전 훈련된 기반 모델, 특히 대형 언어 모델(LLMs) 또는 비전-언어 모델(VLMs)이 우리를 어떻게 지원할 수 있는지, 또는 어떻게 기반 모델을 처음부터 훈련시킬 수 있는지를 확인하는 것입니다. 유용한 접근 방법은 강화 학습 훈련 루프의 각 요소를 개별적으로 검토하여 개선의 여지가 있는 곳을 식별하는 것입니다:\n\n![이미지](/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_0.png)\n\n1- 환경: 사전 훈련된 기반 모델은 사건 간의 인과 관계를 이해하기 때문에 현재 행동으로 인한 환경 변화를 예측하는 데 활용할 수 있습니다. 이 개념은 흥미로운데, 현재는 이에 중점을 두는 구체적인 연구에 대해 알지 못합니다. 이 아이디어를 더 탐구하는 데 제한된 이유가 두 가지 있습니다.\n\n- 강화 학습 훈련 과정은 다음 단계 관측에 대해 매우 정확한 예측을 요구하는데, 사전 훈련된 LLMs/VLMs가 이에 부합하는 데이터셋에서 직접 훈련되지 않아 이 측면에서 미흡할 수 있습니다. 우리가 이전 글에서 강조한 바와 같이, 특히 평생 학습 시나리오에서 사용되는 고수준 플래너는 효과적으로 기반 모델을 통합할 수 있습니다.\n- 환경 단계의 지연은 RL 알고리즘을 제한할 수 있는 중요한 요소입니다. 특히 훈련 단계에 대한 고정 예산 내에서 작업할 때 매우 큰 지연을 도입하는 모델은 제약을 줄 수 있습니다. 도전적일 수 있지만, 작은 네트워크로 압축하는 것이 여기에 해결책이 될 수 있음을 유의해 주세요.\n\n<div class=\"content-ad\"></div>\n\n2- 상태 (LLM/VLM 기반의 상태 생성기): 전문가들은 종종 관찰과 상태라는 용어를 서로 바꿔 사용하지만, 이 둘 사이에는 차이가 있습니다. 상태는 환경의 포괄적인 표현이며, 반면에 관찰은 부분적인 정보만을 제공할 수 있습니다. 표준 강화 학습 프레임워크에서는 관측치, 지난 행동 및 환경의 내부 지식에서 유용한 특징을 추출하고 병합하여 \"상태\"인 정책 입력을 생성하는 구체적인 변환에 대해 자주 논의하지 않습니다. 이러한 변환은 LLMs/VLMs를 활용함으로써 크게 향상될 수 있으며, 우리에게 세계, 물리학 및 역사에 대한 폭넓은 지식을 \"상태\"에 주입할 수 있는 기회를 제공합니다 (핑크로 강조된 그림 1을 참조).\n\n3- 정책 (기초적인 정책 모델): 정책에 기초 모델을 통합하는 것은 강화 학습에서 중요한 결정 요소인 중심적인 의사 결정 요소이므로 매우 유익할 수 있습니다. 고수준 계획을 생성하기 위해 이러한 모델을 활용하는 것이 성공적이었지만, 상태를 저수준 행동으로 변환하는 것은 나중에 자세히 다뤄볼 문제가 있습니다. 다행히도 최근에 이 분야에서 약간의 유망한 연구가 있었습니다.\n\n4- 보상 (LLM/VLM 기반의 보상 생성기): 연구자들 사이에서 선택된 행동을 보다 정확하게 평가하기 위해 기초 모델을 활용하는 것이 주요 관심사가 되었습니다. 보상은 인간과 에이전트 사이의 커뮤니케이션 채널로 기능해 왔으며, 목표를 설정하고 에이전트를 희망하는 방향으로 안내하는 중요한 역할을 합니다.\n\n- 사전 훈련된 기초 모델은 세계에 대한 깊은 지식을 가지고 있으며, 이러한 이해를 의사 결정 과정에 주입함으로써 결정을 인간의 욕망과 더 잘 일치하고 성공할 가능성을 높일 수 있습니다. 또한, 기초 모델을 사용하여 에이전트의 행동을 평가하면 검색 공간을 신속하게 줄이고 에이전트에게 이해를 시작하는 데 선뜻 도와줄 수 있습니다.\n- 사전 훈련된 기초 모델은 대부분 인간에 의해 생성된 인터넷 규모의 데이터로 훈련되었으며, 이는 그들이 인간과 유사한 방식으로 세계를 이해할 수 있도록 만들었습니다. 이는 기초 모델을 비용 효율적인 주석 생성기로 활용할 수 있게 만들어 줍니다. 그들은 대규모로 레이블을 생성하거나 궤적이나 롤아웃을 평가할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n1- 보상에 대한 기본 모델\n\n에이전트 설정에 매우 의존적이며 기본 모델의 교육 데이터 세트에서 불충분하게 나타나는 낮은 수준의 조치를 생성하는 데 기초 모델을 사용하는 것은 어려운 과제입니다. 따라서, 기초 모델 응용은 일반적으로 낮은 수준의 조치보다는 높은 수준의 계획에 중점을 두고 있습니다. 보상은 높은 수준의 계획자와 낮은 수준의 조치 사이의 간격을 메꾸는 역할을 하고 기초 모델을 사용할 수 있게 합니다. 연구자들은 보상 할당을 위해 기초 모델을 통합하는 다양한 방법론을 채택했습니다. 그러나 핵심 원칙은 VLM/LLM을 활용하여 하위 목표나 작업을 향한 진행을 효과적으로 추적하는 데 있습니다.\n\n1.a 유사성을 기반으로 보상값 할당\n\n보상값을 고려할 때, 이는 에이전트의 이전 조치가 목표에 가까이 이동하는 데 유익했는지를 나타내는 신호로 간주될 수 있습니다. 합리적인 방법은 이전 조치가 현재 목표와 얼마나 밀접하게 일치하는지를 평가하는 것입니다. 이 방법을 실천하기 위해, 그림 2에서 볼 수 있듯이, 반드시 다음과 같은 작업이 필요합니다:\n- 이러한 조치의 의미 있는 임베딩을 생성합니다. 이는 가장 최근 관측의 이미지, 비디오 또는 텍스트 설명을 통해 수행할 수 있습니다.\n- 현재 목표의 의미 있는 표현을 생성합니다.\n- 이러한 표현 사이의 유사성을 평가합니다.\n\n<div class=\"content-ad\"></div>\n\n![2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_1.png](/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_1.png)\n\n이 분야의 선도적인 연구에 대한 구체적인 메커니즘을 살펴봅시다.\n\n밀도 높고 잘 정의된 보상 함수는 RL 에이전트의 안정성과 훈련 속도를 향상시킵니다. 내재 보상은 혁신적인 상태의 탐험에 대해 에이전트를 보상하여 이러한 도전에 대처합니다. 그러나 대부분의 보이지 않는 상태가 하류 작업과 관련이 없는 대규모 환경에서는 이 방법이 효과가 줄어듭니다. ELLM은 탐사를 형성하기 위해 LLM의 백그라운드 지식을 활용합니다. LLM에게 에이전트의 사용 가능한 작업 목록과 상태 캡션 생성기에 의해 생성된 에이전트 현재 관찰의 텍스트 설명 목록이 주어졌을 때, LLM에게 가능한 목표/하위 목표 목록을 생성하도록 요청합니다. 그런 다음 각 시간 스텝에서 보상은 LLM이 생성한 목표와 에이전트의 전환 설명 간의 의미적 유사성, 코사인 유사성에 의해 계산됩니다.\n\nLiFT도 비슷한 프레임워크를 가지고 있지만 보상 할당을 위해 CLIP4Clip 스타일 VLMs를 활용합니다. CLIP4Clip은 대립 학습을 통해 비디오와 해당 언어 설명을 정렬하는 데 사전 훈련되었습니다. LiFT에서 에이전트는 CLIP4Clip에 의해 코딩된 과제 지침과 에이전트의 해당 행동의 비디오 간의 정렬 점수, 코사인 유사성에 기반해 보상을 받습니다.\n\n<div class=\"content-ad\"></div>\n\nUAFM은 로봇 조작 작업에 중점을 둔 유사한 프레임워크를 갖고 있습니다. 예를 들어, 물건을 쌓는 작업과 같은 작업에 중점을 둡니다. 보상 할당에서는 에이전트 상태 이미지와 작업 설명 사이의 유사성을 측정하며 둘 다 CLIP에 의해 임베드됩니다. 이들은 시뮬레이션된 쌓기 도메인의 소량의 데이터로 CLIP을 미세 조정하여 이용 사례에 더욱 일치시킵니다.\n\n1.b 보조 작업 추론을 통한 보상 할당:\n\n환경의 올바른 이해를 갖고 있는 기본 모델이 있는 시나리오에서는 궤적 내의 관측값을 직접 모델(LIM/VLM)로 전달하는 것이 실현 가능해집니다. 관측값을 기반으로 한 간단한 QA 세션을 통해 또는 관측값 궤적을 보고 목표를 예측하는 모델의 능력을 검증함으로써 이 평가를 할 수 있습니다.\n\n![image](/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_2.png)\n\n<div class=\"content-ad\"></div>\n\nRead and Reward은 환경 설명서를 보상 생성에 통합하는 데 두 가지 핵심 구성 요소를 통해 수행됩니다. 다음과 같이 확인할 수 있습니다.:\n\n- QA 추출 모듈: 이 모듈은 게임 목표와 기능에 대한 요약을 생성합니다. 이 LLM 기반 모듈인 RoBERTa-large는 게임 설명서와 질문을 입력 받아 텍스트로부터 해당 답변을 추출합니다. 질문은 게임 목표와 에이전트-객체 상호 작용에 초점을 맞추며, TF-IDF를 사용하여 중요도를 식별합니다. 각 핵심 객체에 대해 \"플레이어가 '객체'를 칠 때 무슨 일이 일어납니까?\"라는 질문이 질문 세트에 추가됩니다. 그런 다음 모든 비어 있지 않은 질문-답변 쌍을 연결하여 요약이 형성됩니다.\n- 추론 모듈: 게임 플레이 중에 규칙 기반 알고리즘이 \"히트\" 이벤트를 감지합니다. 각 \"히트\" 이벤트 후에는 환경의 요약과 질문 \"승리하려면 '상호 작용 객체'를 치면 괜찮을까요?\"로 LLM 기반 추론 모듈에 쿼리됩니다. 가능한 답변은 '예, 아니오'로 제한됩니다. \"예\" 응답은 긍정적인 보상을 추가하고, \"아니오\"는 부정적인 보상으로 이어집니다.\n\nEAGER는 특별히 설계된 보조 작업을 통해 내재적 보상을 생성하는 독특한 방법을 소개합니다. 이 방식은 현재 관찰을 기반으로 목표를 예측하는 보조 작업을 포함하는 혁신적인 개념을 제시합니다. 모델이 정확하게 예측하면 의도된 목표와 강력한 일치를 나타내며, 따라서 예측 신뢰도 수준에 따라 더 큰 내재적 보상이 제공됩니다. 이 목표를 달성하기 위해 두 모듈이 사용됩니다.:\n\n- 질문 생성 (QG): 이 구성 요소는 사용자가 제공한 상세 목표에서 모든 명사와 형용사를 마스킹하여 작동합니다.\n- 질문 응답 (QA): 이 모델은 관찰, 질문 마스크 및 작업을 입력으로 받아 마스킹된 토큰을 예측하는 지도 방식으로 교육된 모델입니다.\n\n<div class=\"content-ad\"></div>\n\n(P.S. 기본 모델을 사용하지 않았지만 흥미로운 접근 방식으로 여기에 포함했습니다. 이 접근 방식은 사전 훈련된 LLM에 쉽게 적용할 수 있습니다.)\n\n1. 보상 함수 코드 생성\n\n지금까지는 보상 학습 알고리즘을 위해 직접 보상 값을 생성하는 방법에 대해 논의했습니다. 그러나 RL 루프의 각 단계에서 대형 모델을 실행하는 것은 교육 및 추론의 속도를 현저하게 늦출 수 있습니다. 이 병목 현상을 우회하기 위한 한 가지 전략은 기본 모델을 활용하여 보상 함수의 코드를 생성하는 것입니다. 이를 통해 각 단계에서 보상 값을 직접 생성하여 프로세스를 간소화할 수 있습니다.\n\n보상 코드 생성 스키마가 효과적으로 작동하려면 두 가지 주요 구성 요소가 필요합니다:\n1. 모든 필요한 정보를 포함하는 자세한 프롬프트를 수신하는 코드 생성기(LMM).\n2. 코드 생성기와 협업하여 코드를 평가하고 향상시키는 정제 프로세스.\n보상 코드를 생성하는 데 중요한 기여를 살펴보겠습니다:\n\n<div class=\"content-ad\"></div>\n\nR2R2S는 두 가지 주요 구성 요소를 통해 보상 함수 코드를 생성합니다:\n\n- LLM 기반 동작 설명자: 이 모듈은 미리 정의된 템플릿을 사용하여 로봇 동작을 설명하고, 대형 언어 모델 (LLM)을 활용하여 동작을 이해합니다. 동작 설명자는 템플릿을 채워 넣어 \"목적지 좌표\" 등의 자리 표시자를 구체적인 세부 정보로 대체하여 미리 정의된 템플릿 내에서 원하는 로봇 동작을 설명합니다.\n- LLM 기반 보상 코드 생성기: 이 구성 요소는 보상 함수 코드를 생성합니다. 이때 prompt에 포함된 내용은 동작 설명, LLM이 보상 함수 코드를 생성하는 데 사용할 수 있는 함수 목록과 설명, 응답이 어떻게 보이는지를 보여주는 예제 코드, 그리고 보상 함수가 따라야 하는 제약 조건과 규칙입니다.\n\nText2Reward는 반복적인 개선 내에서 실행 가능한 코드로 밀집 보상 함수를 생성하는 방법을 개발합니다. 작업의 하위 목표가 주어졌을 때, 두 가지 주요 구성 요소가 있습니다:\n\n- LLM 기반 보상 코드 생성기: 보상 함수 코드를 생성합니다. prompt에는 관측과 가능한 동작의 요약, 객체, 로봇 및 호출 가능한 함수의 구성을 나타내는 간결한 파이썬 스타일 환경, 보상 함수 설계를 위한 배경 지식 (예: \"작업 X의 보상 함수에는 일반적으로 객체 x와 y 간의 거리를 포함하는 항목이 포함됨\"), 그리고 몇 가지 샷 예시가 포함됩니다. 그들은 명령어의 풀에 액세스하고, 상위 k개 유사한 명령어를 몇 가지 샷 예시로 검색한다고 가정합니다.\n- LLM 기반 개선: 보상 코드가 생성되면, 코드가 실행되어 구문 오류와 런타임 오류를 식별합니다. 이러한 피드백은 후속 prompt로 통합되어 더 정교한 보상 함수를 생성합니다. 추가로, 현재 정책에 의한 작업 실행 비디오를 기반으로 사용자 피드백이 요청됩니다.\n\n<div class=\"content-ad\"></div>\n\nAuto MC-Reward은 Text2Reward와 유사한 알고리즘을 가지고 있습니다. 보상 함수 코드를 생성하려면 Fig. 4를 참조하세요. 주요 차이점은 두 개의 LLM을 갖고 있는 세밀화 단계에 있습니다:\n\n- LLM 기반 보상 평가자: 코드를 평가하고 코드가 자기 일관성이 있고 구문 및 의미적 오류가 없는지에 대한 피드백을 제공합니다.\n- LLM 기반 경로 분석자: 훈련된 에이전트와 환경 사이의 상호 작용에 대한 과거 정보를 검토하고 보상 함수의 수정을 안내하는 데 사용합니다.\n\n![이미지](/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_3.png)\n\nEUREKA는 특정 작업 프롬프팅, 사전 정의된 보상 템플릿 또는 사전 정의된 소수의 예제가 필요하지 않고 보상 코드를 생성합니다. 이 목표를 달성하기 위해 두 단계가 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- LLM 기반 코드 생성: 원시 환경 코드, 작업, 일반적 보상 설계 및 형식 지침이 LLM에게 컨텍스트로 제공되며, LLM은 실행 가능한 보상 코드와 해당 구성 요소 목록을 반환합니다.\n- 진화적 탐색 및 교정: 각 반복마다 EUREKA는 LLM에 쿼리를 보내서 여러 독립적인 보상 함수를 생성합니다. 실행 가능한 보상 함수로 에이전트를 훈련시키면 에이전트의 수행 상황을 피드백으로 제공합니다. 보상 함수의 각 구성 요소에 대한 상세하고 집중된 분석을 위해 피드백은 보상 함수의 각 구성 요소에 대한 스칼라 값도 포함합니다. LLM은 상위 성능을 발휘하는 보상 코드와 해당 상세한 피드백을 가져와서 보상 코드를 컨텍스트 내에서 변이시킵니다. 각 후속 반복에서 LLM은 상위 보상 코드를 참조로 사용하여 추가로 K개의 독립적인 보상 코드를 생성합니다. 이 반복적 최적화는 지정된 반복 횟수에 도달할 때까지 계속됩니다.\n\n이 두 단계 내에서 EUREKA는 전문가의 휴먼-엔지니어링 된 보상을 뛰어넘는 보상 함수를 생성할 수 있습니다.\n\n1.d. 선호에 기반한 보상 모델 훈련 (RLAIF)\n\n대체 방법으로 기초 모델을 사용하여 보상 함수 모델을 훈련하기 위한 데이터를 생성할 수 있습니다. 휴먼 피드백을 통한 강화 학습의 중요한 성공들로 Reinforcement Learning with Human Feedback (RLHF)가 최근에 큰 주목을 받으면서 교육된 보상 함수를 대규모로 사용하는 데 집중적인 관심이 집중되고 있습니다. 이러한 알고리즘의 핵심은 선호 데이터셋을 사용하여 보상 모델을 훈련시키는 것이며, 이는 후에 강화 학습 알고리즘에 통합될 수 있습니다. 휴먼 피드백을 통해 선호 데이터를 생성하는 높은 비용이 가질 수 있기 때문에, VLM/LLM과 같은 AI 에이전트에서 피드백을 얻어 이 데이터셋을 만드는 데 대한 관심이 증가하고 있습니다. AI 생성 데이터를 사용하여 보상 함수를 훈련시키고 강화 학습 알고리즘에 통합하는 것이 Reinforcement Learning with AI Feedback (RLAIF)로 알려져 있습니다.\n\n<div class=\"content-ad\"></div>\n\nMOTIF은 충분한 커버리지를 갖춘 관측 pass 데이터 세트에 액세스해야 합니다. 먼저 LLM은 환경 내에서 원하는 행동에 대한 요약과 무작위로 추출한 두 관측의 텍스트 설명을 쿼리합니다. 그런 다음, 그림 5에 나와 있는 것처럼 촉진을 생성하여 1, 2 또는 0(좋아하는 것이 아님을 나타냄) 중 하나를 선택합니다. 이 프로세스는 관측 쌍 사이의 선호도 데이터 세트를 구성합니다. 이후에는 이 데이터 세트를 사용하여 기반 선호도 기반 RL 기법을 활용한 보상 모델을 교육합니다.\n\n![image](/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_4.png)\n\n2- 정책으로서의 기초 모델들\n\n지금까지 조사된 작업에서 뛰어나는 것뿐만 아니라, 과거 학습을 통해 새로운 작업을 추론하고 적응할 수 있는 능력을 갖추는 기본 정책을 교육하는 능력은 RL 커뮤니티에서의 포부입니다. 이러한 정책은 이전 경험으로부터 새로운 상황에 대처하고, 환경적 피드백을 통해, 인간과 유사한 적응성을 통해 이전에 본 적 없는 목표를 달성할 수 있도록 일반화되는 것이 이상적입니다.\n\n<div class=\"content-ad\"></div>\n\n그러나, 이러한 에이전트를 교육하는 데는 몇 가지 도전이 있습니다. 이 도전 중 몇 가지는 다음과 같습니다:\n\n- 매우 큰 모델을 관리해야 하므로, 낮은 수준의 제어 동작에 대한 의사 결정 과정에 상당한 대기 시간이 발생합니다.\n- 효과적인 학습을 위해 다양한 작업 영역에서 방대한 상호 작용 데이터를 수집해야 합니다.\n- 또한, RL을 사용하여 매우 큰 네트워크를 처음부터 교육하는 과정은 추가 복잡성을 도입합니다. 이는 역전파 효율이 감독 학습 방법과 비교하여 RL에서 더 약한 특성 때문입니다.\n\n지금까지 이 도메인에서 정말 한창 인 것은 주로 상당한 자원과 최고 수준의 환경을 갖춘 팀들뿐이었습니다.\n\nAdA는 X.Land 2.0 3D 환경 내에서 RL 기반 모델을 교육하는 길을 열었습니다. 이 모델은 추가 교육 없이 테스트 작업에서 인간 시간 규모의 적응을 달성합니다. 모델의 성공 요소는 세 가지입니다.\n\n<div class=\"content-ad\"></div>\n\n- AdA의 학습 메커니즘 핵심은 2,300만 개에서 2억 6,500만 개의 매개변수로 이루어진 Transformer-XL 아키텍처로, Muesli RL 알고리즘과 함께 사용됩니다. Transformer-XL은 시간 t부터 T까지의 관측, 행동 및 보상의 경로를 입력으로 받아 각 시간 단계에 대해 숨겨진 상태의 일렬을 출력합니다. 숨겨진 상태는 보상, 가치 및 행동 분포 π를 예측하는 데 사용됩니다. 장기 및 단기 기억의 조합은 빠른 적응을 위해 중요합니다. 장기 기억은 천천히 경사 업데이트를 통해 달성되며, 단기 기억은 트랜스포머의 문맥 길이 내에서 포착될 수 있습니다. 이 독특한 조합은 모델이 환경이 재설정되어도 시도 간 메모리를 유지하여 여러 작업 시도 간 지식을 보존할 수 있게 합니다.\n- 모델은 변형자가 메타 학습자이기 때문에 1⁰⁴⁰개의 다양한 부분 관찰 가능한 마르코프 의사 결정 프로세스 (POMDPs) 작업을 통해 메타-RL 훈련의 혜택을 받습니다. 과제 풀의 크기와 다양성을 감안할 때, 많은 작업이 좋은 훈련 신호를 생성하기에는 너무 쉽거나 너무 어려울 수 있습니다. 이를 해결하기 위해 자동화된 커리큘럼을 사용하여 기능 경계 내에 있는 작업을 우선 순위로 두었습니다.\n\nRT-2는 로보틱 경로 데이터와 시각-언어 작업 양쪽에서 VLM에 대해 공동으로 세밀 조정하는 방법을 소개하며, 결과적으로 RT-2라는 정책 모델을 생성합니다. 시각-언어 모델이 저수준 액션을 생성할 수 있도록하기 위해, 액션은 256개의 바구니로 이산화되어 언어 토큰으로 표현됩니다.\n\n액션을 언어 토큰으로 표현함으로써, RT-2는 상당한 수정 없이 이미 존재하는 VLM 아키텍처를 직접 활용할 수 있습니다. 따라서 VLM 입력에는 로봇 카메라 이미지와 시각적 질문 응답 작업과 유사한 형식으로 구성된 텍스트 작업 설명이 포함되며, 출력은 로봇의 저수준 작업을 나타내는 언어 토큰의 일련이 됩니다. Fig. 6을 참조하세요.\n\n`<img src=\"/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_5.png\" />`\n\n<div class=\"content-ad\"></div>\n\n그들은 웹 데이터를 사용한 두 가지 유형의 데이터에 대한 공동미세조정이 보다 일반화된 정책을 이끌어냄을 알아차렸습니다. 공동미세조정 프로세스는 RT-2에게 교육 데이터에 명시적으로 존재하지 않는 명령을 이해하고 실행할 수 있는 능력을 제공함으로써 놀랍도록 적응성을 보여줍니다. 이 접근법은 VLM의 인터넷 규모 사전학습을 통해 새로운 작업에 대한 일반화를 가능케 했습니다.\n\n3- 상태 표현으로서의 기반 모델\n\nRL에서 정책이 주어진 시점에 환경을 이해하는 것은 본질적으로 주변을 어떻게 인식하는지인 '상태'에서 옵니다. RL 블록 다이어그램을 살펴볼 때, 세계 지식을 주입할 합리적인 모듈은 상태입니다. 작업 완료에 유용한 일반 지식으로 관측을 풍부하게 하면, 정책은 처음부터 학습을 시작하는 RL 에이전트에 비해 새로운 작업을 더 빨리 학습할 수 있습니다.\n\nPR2L은 인터넷 규모의 VLM의 백그라운드 지식을 RL에 주입하는 새로운 방법론을 소개합니다. PR2L은 이미지 및 텍스트 입력에 대한 언어를 생성하는 생성적 VLM을 활용합니다. VLM은 시각 및 텍스트 입력을 이해하고 응답하는 데 능숙하기 때문에, 관찰에서 행동에 연결될 수 있는 의미론적 기능의 풍부한 소스를 제공할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nPR2L은 각각의 시각적 관찰에 대해 VLM에 작업 관련 프롬프트로 쿼리하고, 생성된 텍스트 응답과 모델의 중간 표현을 받습니다. 그들은 텍스트를 버리고 시각 및 텍스트 입력 및 VLM의 생성된 텍스트 응답에 대한 중간 표현을 \"프롬프트 가능한 표현\"으로 사용합니다. 이러한 표현의 크기가 변수이기 때문에 PR2L은 모든 프롬프트 가능한 표현에 포함된 모든 정보를 고정 크기 임베딩으로 임베딩하기 위해 인코더-디코더 트랜스포머 레이어를 통합합니다. 이 임베딩은 비시각 관찰 데이터와 함께 사용되어 에이전트의 상태를 나타내는 정책 네트워크에 제공됩니다. 이 혁신적인 통합을 통해 RL 에이전트는 VLM의 풍부한 의미 이해와 배경 지식을 활용하여 작업을 보다 신속하고 정보화된 학습을 할 수 있습니다.\n\n참고문헌:\n\n[1] ELLM: Du, Yuqing 등. “Guiding pretraining in reinforcement learning with large language models.” 2023.\n[2] Text2Reward: Xie, Tianbao 등. “Text2reward: Automated dense reward function generation for reinforcement learning.” 2023.\n[3] R2R2S: Yu, Wenhao 등. “Language to rewards for robotic skill synthesis.” 2023.\n[4] EUREKA: Ma, Yecheng Jason 등. “Eureka: Human-level reward design via coding large language models.” 2023.\n[5] MOTIF: Klissarov, Martin 등. “Motif: Intrinsic motivation from artificial intelligence feedback.” 2023.\n[6] Read and Reward: Wu, Yue 등. “Read and reap the rewards: Learning to play atari with the help of instruction manuals.” 2024.\n[7] Auto MC-Reward: Li, Hao 등. “Auto MC-reward: Automated dense reward design with large language models for minecraft.” 2023.\n[8] EAGER: Carta, Thomas 등. “Eager: Asking and answering questions for automatic reward shaping in language-guided RL.” 2022.\n[9] LiFT: Nam, Taewook 등. “LiFT: Unsupervised Reinforcement Learning with Foundation Models as Teachers.” 2023.\n[10] UAFM: Di Palo, Norman 등. “Towards a unified agent with foundation models.” 2023.\n[11] RT-2: Brohan, Anthony 등. “Rt-2: Vision-language-action models transfer web knowledge to robotic control.” 2023.\n[12] AdA: Team, Adaptive Agent 등. “Human-timescale adaptation in an open-ended task space.” 2023.\n[13] PR2L: Chen, William 등. “Vision-Language Models Provide Promptable Representations for Reinforcement Learning.” 2024.\n[14] Clip4Clip: Luo, Huaishao 등. “Clip4clip: An empirical study of clip for end to end video clip retrieval and captioning.” 2022.\n[15] Clip: Radford, Alec 등. “Learning transferable visual models from natural language supervision.” 2021.\n[16] RoBERTa: Liu, Yinhan 등. “Roberta: A robustly optimized bert pretraining approach.” 2019.\n[17] Preference based RL: SWirth, Christian 등. “A survey of preference-based reinforcement learning methods.” 2017.\n[18] Muesli: Hessel, Matteo 등. “Muesli: Combining improvements in policy optimization.” 2021.\n[19] Melo, Luckeciano C. “Transformers are meta-reinforcement learners.” 2022.\n[20] RLHF: Ouyang, Long 등. “Training language models to follow instructions with human feedback, 2022.\n\n","ogImage":{"url":"/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_0.png"},"coverImage":"/assets/img/2024-06-20-PushingRLBoundariesIntegratingFoundationalModelsegLLMsandVLMsintoReinforcementLearning_0.png","tag":["Tech"],"readingTime":15},{"title":"자동 계약 조항 이해 및 위험 평가 챗봇 Legal-BERT 및 GPT-4o 세밀하게 조정하기","description":"","date":"2024-06-20 18:50","slug":"2024-06-20-AutomatedContractClauseUnderstandingandRiskAssessmentChatbotwithfine-tunedLegal-BERTandGPT-4o","content":"\n\n![이미지](/assets/img/2024-06-20-AutomatedContractClauseUnderstandingandRiskAssessmentChatbotwithfine-tunedLegal-BERTandGPT-4o_0.png)\n\n# 소개\n\n계약은 비즈니스 거래에 있어서 근본적인 역할을 합니다. 그러나 수동으로 계약 분석을 하는 것은 시간이 많이 소요되며 오류가 발생할 수 있습니다. 이 프로세스를 자동화함으로써 시간을 절약할 뿐만 아니라 철저하고 일관된 위험 평가를 보장할 수 있습니다. 본 프로젝트에서는 Legal-BERT와 GPT-4o를 활용하여 계약 조항 이해와 위험 평가를 자동화하는 AI 도구를 개발했습니다.\n\n# 왜 계약 분석을 자동화해야 하는가?\n\n<div class=\"content-ad\"></div>\n\n계약 분석은 법적 준수와 비즈니스 전략에 있어 중요합니다. 자동화된 도구들은 주요 조항을 신속하게 식별하고 위험을 평가하며 자세한 설명을 제공하는 데 도움을 줄 수 있습니다. 이는 법률 전문가와 비즈니스에게 귀중한 자산이 될 것입니다.\n\n# 사용된 기술\n\n## 모델 소개:\n\nLegal-BERT: Legal-BERT는 법적 텍스트의 대규모 말뭉치에 대해 세밀하게 조정된 BERT(Bidirectional Encoder Representations from Transformers)의 특수한 변형입니다. 이는 법적 자연어 처리 작업을 지원하기 위해 법적 언어에 대해 더 정확하고 맥락적으로 관련성 있는 임베딩을 제공하도록 설계되었습니다.\n\n<div class=\"content-ad\"></div>\n\nGPT-4o: GPT-4o는 인간과 유사한 텍스트를 이해하고 생성할 수 있는 고급 언어 모델입니다. 자세하고 일관성 있는 설명을 생성하는 데 특히 유용하며, 위험 평가 작업에 적합합니다.\n\n## 데이터셋:\n\nLegalBench: LegalBench 데이터셋은 LLMs에서 법률 추론을 평가하기 위한 포괄적인 벤치마크입니다. 규정, 판례 및 계약과 같은 다양한 법률 텍스트를 포함하므로 현실적인 법률 작업에 대한 모델을 훈련하고 평가하는 데 이상적입니다.\n\n## 도구:\n\n<div class=\"content-ad\"></div>\n\nStreamlit: Streamlit은 데이터 과학 및 기계 학습 프로젝트를 위한 상호 작용 웹 애플리케이션을 만들 수 있게 해주는 Python 라이브러리입니다. 이 프로젝트에서는 계약 조항 분류 및 리스크 평가 시스템에 사용자 친화적 인터페이스를 구축하는 데 사용됩니다.\n\nHuggingface Transformers: Huggingface Transformers 라이브러리는 BERT와 GPT와 같은 사전 훈련된 모델에 쉽게 액세스할 수 있습니다. 특정 작업에 대한 이러한 모델을 세밀하게 조정하고 애플리케이션에 통합하는 프로세스를 간소화합니다.\n\n# 프로젝트 아키텍처\n\n![Project Architecture](/assets/img/2024-06-20-AutomatedContractClauseUnderstandingandRiskAssessmentChatbotwithfine-tunedLegal-BERTandGPT-4o_1.png)\n\n<div class=\"content-ad\"></div>\n\n프로젝트의 워크플로우를 개요로 설명한 아키텍처 다이어그램이 있습니다. 프로세스는 계약 조항 텍스트 입력으로 시작되며, 먼저 Legal BERT 모델을 사용하여 분류됩니다. 그 다음으로, 해당 조항은 GPT-4o를 활용한 위험 분석이 수행됩니다. 마지막으로, 분류 및 위험 분석 결과가 다른 GPT-4o 모델에 의해 통합되어 종합적인 출력 보고서로 형식화됩니다. 이 아키텍처는 잠재적 위험을 평가하기 위해 계약 조항을 자동으로 평가하는 효율적이고 자동화된 시스템을 보장합니다.\n\n# 데이터셋 요약 📜\n\nLegalBench 데이터셋은 대형 언어 모델(Large Language Models, LLMs)에서 법적 추론을 평가하기 위해 선별된 162가지 작업들을 컬렉션한 포괄적인 데이터셋입니다. 이러한 작업들은 40명의 참여자들에 의해 기여되었으며, 이진 분류, 다중 분류, 추출, 생성, 연역 등 다양한 유형을 포함합니다. 법률 텍스트는 법전, 사법 판례, 계약서 등 다양한 분야의 법률 텍스트가 포함되어 있습니다. 각 작업은 법률적 맥락에서 LLMs의 성능을 벤치마킹하기 위해 설계된 학습 및 평가 분할을 포함하고 있습니다. 자세한 정보는 LegalBench 웹사이트를 방문해 주세요.\n\n# 데이터 처리\n\n<div class=\"content-ad\"></div>\n\n첫 번째 단계는 계약 조항 데이터 세트를 처리하는 것입니다. 이 데이터 세트에는 감사 조항인지 아닌지를 나타내는 레이블이 지정된 조항이 포함되어 있습니다. 데이터는 정리되고 전처리되어 BERT 토크나이저와 호환되도록 보장됩니다. 이 단계는 Legal BERT 모델의 미세 조정을 위해 데이터를 준비하는 데 중요합니다.\n\n데이터 세트는 그런 다음 train, test 및 validation 세 부분으로 분할됩니다. 훈련 및 검증 데이터 세트는 모델을 훈련하는 데 사용되며, 테스트 데이터 세트는 모델을 보이지 않은 데이터로 평가하는 데 예약됩니다. 훈련 및 검증 데이터 세트는 토큰화되어 Legal BERT 모델의 미세 조정 과정에 공급할 준비가 되어 있습니다. 이를 통해 모델이 효과적으로 학습하고 새로운, 보이지 않는 계약 조항에도 잘 일반화될 수 있도록 합니다.\n\n```js\n# 토크나이저 및 모델 초기화\ntokenizer = BertTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('nlpaueb/legal-bert-base-uncased', num_labels=2)\nmodel.to(device)\n\n# 입력 데이터를 토큰화\ntrain_encodings = tokenizer(train_data['cleaned_text'].tolist(), truncation=True, padding=True, max_length=512)\nval_encodings = tokenizer(val_data['cleaned_text'].tolist(), truncation=True, padding=True, max_length=512)\n\n# 레이블을 텐서로 변환\ntrain_labels = torch.tensor(train_data['answer'].apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\nval_labels = torch.tensor(val_data['answer'].apply(lambda x: 1 if x.lower() == \"yes\" else 0).tolist())\n\n# 데이터셋 클래스 생성\nclass LegalDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\n# 데이터셋 생성\ntrain_dataset = LegalDataset(train_encodings, train_labels)\nval_dataset = LegalDataset(val_encodings, val_labels)\n```\n\n# LEGAL-BERT: 로스쿨에서 나온 머펫들\n\n<div class=\"content-ad\"></div>\n\nLEGAL-BERT는 법적 NLP 작업에 특화된 BERT 모델로, 다양한 영어 법률 텍스트 12GB를 사전 훈련했습니다. 이 모델은 법적 연구, 컴퓨팅 법률, 그리고 법률 기술 응용 프로그램을 지원하며, 일반 BERT 모델보다 도메인 특화 작업에서 우수한 성과를 거두고 있습니다.\n\n![Legal-BERT](/assets/img/2024-06-20-AutomatedContractClauseUnderstandingandRiskAssessmentChatbotwithfine-tunedLegal-BERTandGPT-4o_2.png)\n\n## Legal-BERT 세밀 조정\n\n처리된 데이터셋을 사용하여 Legal BERT 모델을 계약 조항을 분류하는 작업에 특히 맞게 세밀 조정할 수 있습니다. 강건한 모델 성능을 보장하기 위해 K-폴드 교차 검증 방법이 채택되었습니다.\n\n<div class=\"content-ad\"></div>\n\n## 왜 K-Fold 교차 검증을 사용해야 할까요?\n\nK-Fold 교차 검증은 데이터 세트를 약간의 동일한 크기로 k개의 하위 세트(폴드)로 분할하는 것을 포함합니다. 모델은 k-1개의 폴드에서 훈련을 받고 남은 폴드에서 유효성을 검사합니다. 이 프로세스는 각각 다른 폴드를 유효성 검사 세트로 사용하여 k번 반복됩니다. 결과는 모델 성능의 더 신뢰할 수 있는 추정을 제공하기 위해 평균화됩니다.\n\n```js\nkf = StratifiedKFold(n_splits=5)\naccuracies, precisions, recalls, f1s = [], [], [], []\ntexts = train_data['cleaned_text']\nlabels = train_data['answer']\ni=0\nfor train_index, val_index in kf.split(texts, labels):\n    train_texts = texts[texts.index.isin(train_index)]\n    val_texts = texts[texts.index.isin(val_index)]\n    train_labels = labels[labels.index.isin(train_index)]\n    val_labels = labels[labels.index.isin(val_index)]\n\n    # 새 모델 초기화\n    model = BertForSequenceClassification.from_pretrained('nlpaueb/legal-bert-base-uncased', num_labels=2)\n    tokenizer = BertTokenizer.from_pretrained('nlpaueb/legal-bert-base-uncased')\n    model.to(device)\n\n    accuracy, precision, recall, f1 = train_and_evaluate(train_texts, train_labels, val_texts, val_labels, model, tokenizer)\n\n    accuracies.append(accuracy)\n    precisions.append(precision)\n    recalls.append(recall)\n    f1s.append(f1)\n\n    model.save_pretrained('fine-tuned-legal-bert-fold'+str(i))\n    tokenizer.save_pretrained('fine-tuned-legal-bert-fold'+str(i))\n    i+=1\n```\n\n이 기술은 모델이 데이터의 다른 하위 집합에서 평가되어 과적합을 완화시키며 정확도, 정밀도, 재현율 및 F1 점수의 포괄적인 평가를 제공합니다. K-Fold 교차 검증을 사용함으로써, 모델이 훈련 데이터뿐만 아니라 새로운, 보지 못한 데이터에 대해 효과적으로 잘 작동하는 것을 보장할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n학습 결과 해석\n\n![image](/assets/img/2024-06-20-AutomatedContractClauseUnderstandingandRiskAssessmentChatbotwithfine-tunedLegal-BERTandGPT-4o_3.png)\n\n세밀하게 조정된 모델들이 모든 지표에서 무려나게 조금 가르치지 않은 Legal-BERT 모델을 능가하여 학습 과정의 효과를 입증합니다. 가르치지 않은 모델의 낮은 정확도와 정밀도는 올바른 분류에 어려움을 겪으며 높은 재현율에도 불구하고 그것을 보여줍니다. 반면에 k-fold 교차 검증을 통해 평가된 세밀하게 조정된 모델들은 높은 정확도, 정밀도, 재현율, 그리고 F1 점수로 균형 잡힌 성능을 보여 주어 모델이 과적합 없이 잘 일반화되었음을 입증합니다. 이 유효성 검사 방법은 견고한 모델 평가를 보장하여 서로 다른 데이터 분할에서의 일관된 성능 향상을 강조합니다.\n\n# 리스크 분석\n\n<div class=\"content-ad\"></div>\n\n법적 BERT 모델을 세밀 조정한 후, 새로운 계약 조항을 분류하는 데 사용됩니다. 분류된 조항은 그 후 GPT-4o에 전달되어 리스크 분석을 진행합니다. GPT-4o는 고급 자연어 이해 능력을 활용하여 조항과 관련된 잠재적인 위험을 식별합니다. 이 분석은 가능한 법적 영향과 우려 사항에 대한 자세한 통찰력을 제공합니다.\n\n```js\ndef run_riskAnalysis(clause):\n    # GPT-4o를 활용한 리스크 분석\n    risk_template = \"당신은 법률 자문가입니다. 주어진 조항에서 잠재적인 위험을 식별하세요.\"\n    prompt = clause\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": risk_template},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n    return response['choices'][0]['message']['content']\n```\n\n# 두 모델의 응답 통합\n\n분류 및 위험 분석 결과를 얻은 후, 우리는 출력을 통합하여 일관된 보고서로 만듭니다. GPT-4o를 다시 활용하여 분류 레이블과 식별된 위험을 종합 설명에 결합합니다. 이 통합 단계는 최종 보고서가 명확하고 정보 제공이며 실행 가능하도록 보장함으로써 사용자가 계약 조항의 잠재적인 위험을 이해하기 쉽게 만듭니다.\n\n<div class=\"content-ad\"></div>\n\n```python\n# ChatCompletion endpoint를 사용하여 prompt를 실행하는 기능\ndef run_gpt_integration(classification_label, risk_analysis, clause):\n    prompt = (\n        f\"'{classification_label}'로 분류된 계약 조항입니다:\\n\\n\"\n        f\"'{clause}'\\n\\n\"\n        f\"이 조항에서 식별된 잠재적 위험은 다음과 같습니다:\\n{risk_analysis}\\n\\n\"\n    )\n    response = openai.ChatCompletion.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"당신은 법률 자문사입니다. 이 조항, 그 분류, 그리고 식별된 위험에 대한 통합된, 일관된 설명을 제공해주세요. 다음 템플릿에 맞춰 응답해주세요:\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n    return response['choices'][0]['message']['content']\n```\n\n# 챗봇 구축하기\n\n시스템을 사용자 친화적으로 만들기 위해 Streamlit을 사용하여 챗봇을 만들 수 있습니다. 챗봇 인터페이스를 통해 사용자들이 계약 조항을 입력하고 실시간으로 분류 및 위험 분석 결과를 받을 수 있습니다. 이 챗봇은 분류를 위해 섬세하게 튜닝된 Legal BERT 모델과 위험 분석 및 설명을 생성하기 위해 GPT-4o를 활용합니다. 인터페이스에는 전문적인 외관을 위한 사용자 정의 스타일링이 포함되어 있어 사용자 경험을 향상시키며 계약 분석을 위한 직관적인 도구를 제공합니다.\n\n```python\n# Streamlit 앱\nst.title(\"계약 조항 분류 및 위험 탐지\")\n\n# 채팅 기록 초기화\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\nif st.session_state.messages:\n    for i, chat in enumerate(st.session_state.messages):\n        message(chat['question'], is_user=True, key=f\"user_{i}\", avatar_style=\"big-smile\")\n        message(chat['answer'], key=f\"bot_{i}\")\nelse:\n    st.markdown(\"아직 채팅 기록이 없습니다. 계약 조항을 입력하여 시작해보세요.\")\n\nuser_input = st.chat_input(placeholder=\"계약 조항을 입력하세요...\")\n\nif user_input:\n    with st.spinner('분석 중입니다. 잠시 기다려주세요...'):\n        response = classify_and_analyze_clause(user_input)\n    response = classify_and_analyze_clause(user_input)\n    st.session_state.messages.append({\"question\": user_input, \"answer\": \"\\n\"+response})\n    st.experimental_rerun()\n```\n\n<div class=\"content-ad\"></div>\n\n# 챗봇 데모\n\n아래 영상에서 작동 중인 챗봇을 확인해주세요. 코드는 제 깃헙 저장소에서 확인할 수 있습니다.\n\n챗봇의 샘플 응답\n\n```js\n### 조항 설명과 리스크 평가\n\n**조항:**\n'각 당사자는 기본 당사자가 합의한 감사 권리를 제공하기 위해 시급한 조항, 그 적합성을 동반하지 않는 부회사 또는 다른 계열사(온라인 그룹 또는 해당되는 경우 Skype 그룹의 부회사 또는 다른 계열사를 의미)에게 타당한 타당성을 부여해야 한다.'\n\n**조항 분류**: 감사 조항\n\n### 설명:\n이 조항은 양 당사자가 부회사 및 다른 계열사가 기본 당사자 자신이 합의한 감사 권리를 제공하도록 보장하도록 요구하는 바입니다. 이 조항은 응시 그룹 또는 Skype 그룹과 관련된 특히 '온라인 그룹' 또는 'Skype 그룹'에 관한 계열사 또는 계열사를 명시합니다.\n\n### 잠재적인 위험:\n1. **범위의 모호함**: '온라인 그룹' 및 'Skype 그룹'에 대한 명확한 정의의 부족으로 인해 어떤 기관이 이러한 범주에 속하는지에 대해 혼란을 초래할 수 있으며, 감사 권리의 범위와 적용에 대한 분쟁을 유발할 수 있습니다.\n\n2. **부회사 및 계열사에 대한 통제**: 조항의 효과는 각 당사자가 가진 부회사 및 계열사의 준수를 강제할 수 있는 능력에 달려 있습니다. 당사자가 이러한 기관들에 충분한 통제 능력을 가지지 못한 경우, 이로 인해 준수하지 않고 계약 위반으로 이어질 위험이 있습니다.\n\n3. **부회사/계열사의 동의**: 부회사 및 계열사는 자체적인 거버넌스를 갖고 있을 수 있으며 외부 감사 요구에 저항할 수 있습니다. 이로 인해 법적 도전이나 운영상의 침략이 발생할 수 있습니다.\n\n4. **개인정보 보호 및 기밀성 우려**: 감사는 민감한 데이터에 접근할 수 있습니다. 부회사 및 계열사에게 감사 권리를 확장함으로써 기밀 정보에 접근할 수 있는 기관 수가 증가하며, 중대한 프라이버시 및 기밀성 문제를 겪을 수 있습니다.\n\n5. **관할권 문제**: 여러 관할권에서 운영하는 부회사 및 계열사는 감사 권리의 범위 및 강제성에 영향을 미치는 현지 법률의 영향을 받을 수 있습니다. 각 나라에는 데이터 보호 및 감사 관행에 관한 독특한 규정이 있습니다.\n\n6. **운영 장애**: 강제 감사는 부회사나 계열사의 정상 운영을 방해할 수 있으며 특히 규모나 지리적으로 분산된 경우 중요한 운영 효율을 저해할 수 있습니다.\n\n7. **강제 가능성**: 복잡한 구조나 간접적인 통제를 갖고 있는 부회사와 계열사에 걸친 감사 권리를 실질적으로 집행하는 것은 어려울 수 있습니다. 이는 상당한 집행 어려움을 일으킬 수 있습니다.\n\n### 완화 권고사항:\n식별된 위험을 대처하기 위해 다음과 같이 조항을 수정하는 것을 고려해보세요:\n\n- **범위 명확히 정의**: 감사 권리가 적용되는 기관을 명확하게 구분하여 '온라인 그룹' 및 'Skype 그룹'과 같은 모호한 용어를 제거하세요.\n- **집행 가능성 확인**: 각 당사자가 부회사 및 계열사의 준수를 실질적으로 시행할 수 있는지 확인하세요. 통제에 관한 제한 사항을 평가하고 공개하세요.\n- **부회사/계열사의 동의**: 부회사 및 계열사로부터 동의를 얻는 필요성과 절차에 대한 규정을 포함하여 그들의 거버넌스 구조를 고려하세요.\n- **데이터 개인정보 준수**: 해당되는 데이터 보호 및 개인정보 보호법과 일치하는지 확인하고 민감한 정보 보호를 위한 보호 장치를 추가할 수 있도록 보장하세요.\n- **실질적인 고려사항**: 운영상의 방해와 무능률을 완화하기 위해 감사 범위와 빈도에 합리적인 제한 사항을 포함하세요.\n\n조항의 복잡성과 잠재적인 영향을 고려하여 실무, 법률 및 운영적 현실과 조화를 이루도록 사용자 정의하는 것을 강력히 권장합니다.\n```\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n- LegalBench 데이터셋\n- LegalBench 연구 논문\n- Legal-BERT 사전 학습 모델\n- Legal-BERT 연구 논문\n- Hugging Face Transformers\n- OpenAI API\n- Streamlit\n- k-fold Cross-Validation에 대한 친절한 소개\n- Fine Tuned Legal-Bert\n- Github 코드","ogImage":{"url":"/assets/img/2024-06-20-AutomatedContractClauseUnderstandingandRiskAssessmentChatbotwithfine-tunedLegal-BERTandGPT-4o_0.png"},"coverImage":"/assets/img/2024-06-20-AutomatedContractClauseUnderstandingandRiskAssessmentChatbotwithfine-tunedLegal-BERTandGPT-4o_0.png","tag":["Tech"],"readingTime":12},{"title":"대형 언어 모델을 활용한 자동 지식 그래프 구축","description":"","date":"2024-06-20 18:48","slug":"2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels","content":"\n\n## 대형 언어 모델의 파워와 지식 채집하기\n\n![이미지](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_0.png)\n\n# 작성자\n\n- Amanda Kau (ORCID: 0009-0004-4949-9284)\n\n<div class=\"content-ad\"></div>\n\n# 소개\n\n지식 그래프는 데이터를 그래픽 형식으로 나타내는 네트워크입니다. 지식 그래프의 장점은 개념, 이벤트 및 엔티티를 노드로, 이들 사이의 관계를 엣지로 나타낸다는 데 있습니다. 이러한 관계는 노드의 맥락을 결정하고, 결과적으로 단어의 의미를 이해하고 여러 가능한 의미를 구별할 수 있도록 합니다. 예를 들어, Google의 지식 그래프는 구글 검색을 지원하여 \"Apple\" 브랜드와 \"사과\" 과일을 구별할 수 있습니다. 지식 그래프는 소매업에서 제품 추천, 검색 엔진 최적화, 자금세탁 방지 이니셔티브, 그리고 의료 분야를 포함한 다양한 분야 및 응용 프로그램에서 적용될 수 있습니다.\n\n그러나 지식 그래프의 활용은 그들의 어렵고 비용이 많이 드는 건설 과정 때문에 제약을 받습니다. 이러한 과제는 자동 지식 그래프 구축을 탐구하는 새로운 연구의 열풍을 격려했습니다. 특히, GPT-4와 같은 대형 언어 모델(LLMs)을 건설 프로세스에 통합하는 데 관심이 늘어나고 있습니다. 이 글에서는 먼저 지식 그래프 구축과 관련된 어려움을 간단히 살펴볼 것입니다. 그런 다음, 지식 그래프와 LLMs를 지식 베이스로 비교할 것입니다. 마지막으로, LLMs를 활용한 자동 지식 그래프 구축에 대한 기존 방법들을 검토할 것입니다.\n\n# 지식 그래프 구축의 어려움\n\n<div class=\"content-ad\"></div>\n\n이전의 지식 그래프 구축 방법은 크라우드소싱 또는 텍스트 마이닝에 기반합니다. WordNet 및 ConceptNet과 같은 인기 있는 크라우드소싱 기반 지식 그래프는 상당한 인적 노동으로 구축되었지만 미리 정의된 관계 집합에 한정됩니다. 한편, 텍스트 마이닝 기반 접근 방식은 문서에서 지식을 추출하지만 텍스트 내 명시적으로 명시된 추출된 관계에만 한정됩니다. 이 접근 방식은 대용어 해소, 명명 개체 인식 등 많은 단계를 포함합니다. 이 문서에서 지식 그래프 구축 프로세스에 대해 더 읽어보시기 바랍니다.\n\n다양한 개념 및 용어가 각 분야에서 사용되기 때문에 각 분야 또는 응용 분야마다 별도의 지식 그래프가 구축되는 어려움이 있습니다. 특정 도메인은 고유한 도전 과제를 제시하기도 합니다. 예를 들어, 지식 그래프는 서비스 컴퓨팅 커뮤니티에서 매우 유용하며 자원 관리, 맞춤형 추천 및 고객 이해에 도움이 됩니다. 그러나 이 맥락에서의 지식 그래프는 다양한 분야의 지식과 개념이 필요하며, 지식 그래프를 구축하는 데 필요한 데이터는 매우 분산되어 있고 주로 주석이 없습니다. 이러한 요소들은 지식 그래프를 생성하는 데 필요한 시간, 노력 및 비용을 크게 증가시킵니다.\n\n# 지식 그래프 대 대형 언어 모델\n\n지식 그래프와 LLM (Large Language Models)은 모두 지식을 검색하는 데 쿼리될 수 있습니다. 아래 그림에서 지식 그래프는 관련된 연결된 노드를 찾아 답을 찾지만, LLM은 문장을 완성하기 위해 [MASK] 토큰을 채우도록 유도됩니다. GPT-4 및 BERT와 같은 LLM은 최근에 언어를 이해하는 놀라운 능력으로 많은 주목을 받았습니다. LLM은 매년 크기가 계속 커지고 방대한 양의 데이터로 훈련되어 광범위한 지식을 소유할 수 있게 됩니다. 많은 사람들은 구글에서 검색하는 대신 ChatGPT에 질문을 할 수도 있습니다. 연구 커뮤니티에게 다음 질문은 LLM (예: GPT)이 지식 그래프 (예: Google 지식 그래프)를 지식의 주요 소스로 대체할 수 있는지를 탐구하는 것이었습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Automated Knowledge Graph Construction with Large Language Models](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_1.png)\n\nFurther research revealed that despite possessing more fundamental world knowledge, LLMs struggled to recall relational facts and deduce relationships between actions and events. Despite possessing numerous advantages, LLMs also suffer from challenges such as:\n\n- Hallucinations: LLMs occasionally produce convincing but incorrect information. Conversely, Knowledge Graphs provide structured and explicit knowledge grounded in its factual data sources.\n- Limited reasoning abilities: LLMs struggle to comprehend and use supporting evidence to draw conclusions, especially in numerical computation or symbolic reasoning. The relationships captured in Knowledge Graphs allow for better reasoning capabilities.\n- Lack of domain knowledge: While LLMs are trained on vast amounts of general data, they lack knowledge from domain-specific data like medical or scientific reports with specific technical terms. Meanwhile, Knowledge Graphs can be constructed for specific domains.\n- Knowledge obsolescence: LLMs are expensive to train and are not regularly updated, causing their knowledge to become outdated over time. Knowledge Graphs, on the other hand, have a more straightforward update process that does not require retraining.\n- Bias, privacy and toxicity: LLMs may give biassed or offensive responses, whereas Knowledge Graphs are typically built from reliable data sources devoid of these biases.\n\nKnowledge Graphs do not encounter these same issues and exhibit better consistency, reasoning ability, and interpretability, though they do have their own set of limitations. Aside from those discussed previously, Knowledge Graphs also lack the flexibility that LLMs enjoy from their unsupervised training process.\n\n\n<div class=\"content-ad\"></div>\n\n# 지식 그래프와 대형 언어 모델 통합\n\n결과적으로, 대형 언어 모델(대형 LLM)과 지식 그래프를 합치는 데 많은 연구 노력이 기울어져 왔습니다. 지식 그래프는 대형 LLM을 정확성 향상으로 이끌 수 있는 능력을 갖추고 있지만, 대형 LLM은 지식 그래프의 구축 중 지식 추출에 도움을 주고 지식 그래프의 품질을 개선할 수 있습니다. 이 두 개념을 통합하는 몇 가지 접근 방식이 있습니다:\n\n- 대형 LLM을 활용하여 자동 지식 그래프 구축 지원: LLM은 데이터로부터 지식을 추출하여 지식 그래프를 채워넣을 수 있습니다. 이 방법에 대한 자세한 내용은 아래에서 논의될 것입니다.\n- LLM에게 지식 그래프에서 지식 검색 방법 가르치기: 아래 이미지에서 보여지는 것처럼, 지식 그래프는 LLM의 추론 과정을 향상시켜 LLM이 더 정확한 답변을 도출할 수 있습니다.\n- 지식 그래프를 통합한 사전 훈련된 언어 모델(KGPLMs)로 결합: 이러한 방법들은 지식 그래프를 대형 LLM 훈련 과정에 통합하기 위해 노력합니다.\n\n<div class=\"content-ad\"></div>\n\n# 대형 언어 모델을 활용한 지식 그래프 자동 생성\n\n## 이전 방법\n\n2019년 제안된 초기 방법 중 하나는 COMET(또는 COMmonsEnse Transformers)이었는데, 이 방법은 미세 조정된 생성형 LLM인 GPT를 사용하여 지식 그래프를 구축했습니다. 이는 헤드 엔티티와 관계가 주어졌을 때 테일 엔티티를 생성함으로써 구성되었습니다. 아래 이미지에 나와 있는 \"시드\"와 \"관계\"를 고려할 때, COMET은 \"완성\" 응답을 생성했고, 이 응답의 타당성을 평가하기 위해 사람들에 의해 평가되었습니다. 이러한 시드-관계-완성 쌍은 지식 그래프를 형성하는 데 사용될 수 있습니다. 예를 들어, \"조각\"과 \"기계\"는 \"의 일부\"관계로 연결된 두 노드를 형성할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## ChatGPT를 정보 추출기로 활용하기\n\n특정 서비스 도메인을 위해 구축된 지식 그래프인 BEAR는 수동 데이터 주석 작업에 필요한 노력과 비용을 피하기 위해 ChatGPT를 활용하여 개발되었습니다. 이를 위해 도메인에 특화된 온톨로지가 작성되었는데, 이는 후에 지식 그래프를 채울 개념과 특성을 식별하는 기반이 되었습니다. ChatGPT는 그 후에 아래 이미지처럼 비구조적 텍스트 데이터에서 관련 내용과 관계를 추출하도록 유도되었습니다. 자동으로 추출된 정보는 이후에 지식 그래프에 통합되어 구축되었습니다.\n\n![이미지](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_4.png)\n\n## LLMs를 활용한 반자동 지식 그래프 구축\n\n<div class=\"content-ad\"></div>\n\n한번 더 ChatGPT를 정보 추출기로 사용하여, Kommineni 등이 최근 Knowledge Graph 구축 방법으로 ChatGPT-3.5를 제안했습니다. 이 과정에서 인간 도메인 전문가들이 결과물을 두 단계로 확인하였습니다. 이 방법과 이전 방법의 차이는 여기서 LLMs가 보다 더 활발한 역할을 한다는 점입니다. 특정 데이터셋을 시작으로, ChatGPT가 데이터에 대한 추상 수준의 문제인 역량 질문(CQs)을 생성하도록 유도되었습니다. 역량 질문(CQs)은 데이터에 관한 추상 수준의 질문이었습니다. ChatGPT에 프롬프트하여, CQs에서 개념 및 관계를 추출하여 온톨로지를 생성했습니다. CQs에 대한 답변은 데이터에서 검색되어 ChatGPT에 제공되었으며, ChatGPT는 지식 그래프를 구성하기 위해 중요 엔터티, 관계 및 개념을 추출하고 이를 온톨로지에 매핑하도록 지시되었습니다.\n\n![그림](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_5.png)\n\n## LLMs에서 지식 그래프 수확\n\n본 문서에서 논의된 최종 방법은 LLMs에서 직접 정보를 추출하는 것이었습니다. Hao 등은 초기 훈련 단계에서 LLMs에 저장된 방대한 양의 지식을 활용할 수 있다고 인지했습니다. 아래 이미지는 LLM의 지식을 수확하기 위한 단계를 보여줍니다. 프로세스는 초기 프롬프트와 두 개의 예시 entity 쌍으로 시작되었고, 텍스트 패러프레이즈 모델이 초기 프롬프트를 패러프레이즈하고 원본에서 수정된 프롬프트를 유도하기 위해 사용되었습니다. 그 후, 해당 프롬프트 세트에 해당하는 entity pair를 검색하였습니다. 검색 및 재점수화 방법을 사용하여, 가장 관련성 있는 쌍을 추출하여 지식 그래프를 형성하였고, 해당 쌍의 entity를 노드, 프롬프트를 관계로 사용하였습니다.\n\n<div class=\"content-ad\"></div>\n\n이 방식을 통해 파생 관계가 전통적으로 구성된 지식 그래프에는 보이지 않는 여러 특성을 가지고 있어서 결과적으로 그래프 간에 더 나은 관계 품질을 제공했습니다:\n\n- 관계는 복잡할 수 있습니다. 예를 들면 \"A는 B를 할 수 있지만 잘하지는 않다\"와 같이.\n- 관계는 두 개체 이상을 포함할 수 있습니다. 예를 들면 \"A는 C에서 B를 할 수 있다\"와 같이.\n\n또한 LLMs를 사용하여 지식 그래프를 형성하는 것은 LLM 내에서 포착된 지식을 시각화하고 양적으로 표현하는 새로운 방법을 제시했습니다.\n\n![그림](/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_6.png)\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n요약하자면, 우리는 지식 그래프와 대형 언어 모델(LLMs)이 지식 베이스로서 갖는 잠재력에 대해 논의했습니다. 지식 그래프는 관계를 포착하는 능력이 뛰어나며 추론 능력이 크지만 구축하기 어렵고 비용이 많이 듭니다. 반면, LLMs는 방대한 지식을 포함하고 있지만 편향, 환각 및 기타 문제에 노출될 수 있습니다. 특정 도메인에 맞게 세밀하게 조정하거나 적응시키는 데도 계산적으로 비용이 많이 듭니다. 두 방법의 장점을 활용하기 위해 지식 그래프와 LLMs를 여러 방법으로 통합할 수 있습니다.\n\n본 문서에서는 LLMs를 사용하여 자동 지식 그래프 구축을 지원하는 데 초점을 맞추었습니다. 특히, 과거의 COMET 모델을 포함한 ChatGPT를 사용하여 BEAR에서 정보 추출기로 사용하고 LLMs로부터 지식을 직접 수확하는 네 가지 예시를 검토했습니다. 이러한 방법들은 지식 그래프와 LLMs의 강점을 결합하여 지식 표현을 향상시키는 방향으로 유망한 발전을 나타냅니다.\n\n# 참고 문헌\n\n<div class=\"content-ad\"></div>\n\n- 지식 그래프란 무엇인가요? | IBM. (연도 미상). [Www.ibm.com](https://www.ibm.com/topics/knowledge-graph)\n- 양, 루이 등. (2023). 사실을 우리에게 제시하세요: 사실인식 언어 모델에 지식 그래프를 통합하여 개선하기 (버전 2). arXiv. [https://doi.org/10.48550/ARXIV.2306.11489](https://doi.org/10.48550/ARXIV.2306.11489)\n- 펑, 창 등. (2023). Knowledge Solver: 지식 그래프에서 도메인 지식 검색을 위한 LLM 교육 (버전 1). arXiv. [https://doi.org/10.48550/ARXIV.2309.03118](https://doi.org/10.48550/ARXIV.2309.03118)\n- 보स슬룻, 알렉스 등. (2019). COMMONET: 자동 지식 그래프 구축을 위한 상식 트랜스포머 (버전 2). arXiv. [https://doi.org/10.48550/ARXIV.1906.05317](https://doi.org/10.48550/ARXIV.1906.05317)\n- 유, 성 등. (2023). BEAR: LLM을 활용한 서비스 도메인 지식 그래프 구축 혁신. Service-Oriented Computing (페이지 339-346). Springer Nature Switzerland. [https://doi.org/10.1007/978-3-031-48421-6_23](https://doi.org/10.1007/978-3-031-48421-6_23)\n- 코미네니, 빅라브 카시 등. (2024). 인간 전문가로부터 기계로: 온톨로지 및 지식 그래프 구축을 위한 LLM 지원 접근 방식 (버전 1). arXiv. [https://doi.org/10.48550/ARXIV.2403.08345](https://doi.org/10.48550/ARXIV.2403.08345)\n- 하오, 순영 등. (2022). BertNet: 사전 훈련된 언어 모델에서 임의 관계를 가진 지식 그래프 수집하기 (버전 3). arXiv. [https://doi.org/10.48550/ARXIV.2206.14268](https://doi.org/10.48550/ARXIV.2206.14268)","ogImage":{"url":"/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-06-20-AutomatedKnowledgeGraphConstructionwithLargeLanguageModels_0.png","tag":["Tech"],"readingTime":9},{"title":"LLM의 행동을 바꾸는 것은 GPU를 바꾸는 것입니다","description":"","date":"2024-06-20 18:45","slug":"2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM","content":"\n\n<img src=\"/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_0.png\" />\n\n대부분의 기술인들은 의존성의 다양한 버전이 다른 동작으로 이어질 수 있다는 것을 알고 있습니다. 그러나 대규모 언어 모델의 영역에서는 우리가 많은 계산을 필요로 하기 때문에 훈련과 추론 작업 양쪽에서 GPU에 크게 의존합니다. 그럼에도 불구하고 몇몇은 GPU를 변경하면 여러분의 LLM 출력에도 영향을 줄 수 있다는 것을 실제로 인식하고 있지 않습니다.\n\n그래서 똑같은 환경을 만들려고 하고 계신가요?\n의존성 버전을 설정할 수 있습니다.\n도커화를 사용할 수 있습니다.\nLLM 온도를 0으로 설정할 수 있습니다.\n원하는 시드를 설정할 수 있습니다.\n결국 여러분이 똑같은 GPU 모델을 사용하지 않았다면 이 모든 것이 작동하지 않을 것입니다.\n\n본 기사에서는 차이점이 발생하는 위치와 그 이유를 보여주는 실험을 통해 이 현상을 강조하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n참고: 실험을 재현하거나 코드에 관심이 없다면 코드 스니펫을 건너 뛸 수 있습니다 (바로 \"7. 두 개의 GPU에서 동일한 입력과 동일한 LLM에서 생성된 답변이 왜 다를까요?\" 섹션으로 이동하여도 이해에 도움이 되는 결론을 얻을 수 있습니다.\n\n# 1. 이 기사를 읽는 이유는?\n\n어느 날, OpenAI와 Anthropic 모델이 설계상 결정론적이지 않은 이유에 대해 몇 분들과 토론하고 있었습니다. MoE (Mixture of Experts) 방식을 사용할 수 있어 토큰을 최적의 전문가에 경로 지정하지 못할 수도 있다고 설명했습니다. 왜냐하면 해당 전문가들이 다른 토큰 처리에 너무 바쁘기 때문에 이로 인해 일관성 없는 답변이 나오기도 합니다.\n\n또 다른 요인은 OpenAI가 효율성을 위해 쿼리를 배치하는 것일 수 있습니다. 이러한 배치의 크기는 들어오는 쿼리의 양에 따라 달라질 수 있으며 GPU 계산 전략을 변경하여 다른 결과를 이끌어낼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n어떤 사람이 \"다른 GPU도 서로 다른 결과로 이어질 수 있지 않을까요?\" 라고 말하자 대화가 흥미로워졌어요.\n\n생각해보세요... OpenAI API를 사용할 때, 여러분을 대신하여 계산을 실행하고 결과를 반환해주는 원격 기기가 있어요. 만약 그 기기가 항상 동일한 하드웨어에서 작동하지 않는다면, 결국 동일한 출력을 받지 못할 수도 있어요.\n\n이를 염두에 두고 다른 고려 사항들이 발생할 수 있어요:\n\n- 만약 제가 운영중인 LLM 앱을 다른 GPU를 가진 다른 인스턴스로 확장해야 한다면, 큰 문제가 될까요?\n- 개발 환경에 사용된 GPU가 운영 환경과 다를 경우 어떻게 될까요?\n\n<div class=\"content-ad\"></div>\n\n모든 이러한 질문들은 현상을 강조하고 그 영향이 얼마나 중요한지 확인하기 위해 실험을 설정하고 싶다는 생각을 들게 했어요.\n\n## 2. 실험 설정하기\n\n현상을 강조하기 위해 두 개의 동일한 환경을 설정하겠습니다. 그 환경들은 GPU만 다를 것입니다: 첫 번째는 Nvidia Tesla T4이고 두 번째는 Nvidia A10G일 것입니다. 그런 다음 Mistral-7b-v0.1을 사용하여 조금씩 실험을 해보겠습니다.\n\n노트북에서 실험을 실행하기 위해 다음 단계를 따라주시면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 환경 설정하기\n\n- CUDA 버전 설정하기.\n\n```js\n!pip uninstall torchvision torchtext torchaudio torch -y\n!pip install torchvision==0.16.0 torch==2.1.0+cu121 -f https://download.pytorch.org/whl/torch_stable.html\n```\n\n2. Transformers 및 관련 모듈 버전 설정하기.\n\n<div class=\"content-ad\"></div>\n\n```js\n!pip3 어클리러레이트 비츠엔바이츠 트랜스포머 데이터셋을 각각 제거합니다.\n!pip3 어클리러레이트==0.28.0 비츠엔바이츠==0.43.0 트랜스포머==4.39.3 데이터셋==2.18.0를 설치합니다.\n```\n\n3. 랜덤 시드 설정:\n\n```js\n# 시드 값을 설정하면 일관된, 재현 가능한 결과를 얻을 수 있습니다.\nimport random\nimport numpy as np\nimport torch\nfrom transformers import set_seed\n\n# 재현성을 위해 시드 설정\nrandom_seed = 42\nnp_seed = 42\ntorch_seed = 42\ntransformers_seed = 42\n\nrandom.seed(random_seed)\nnp.random.seed(np_seed)\ntorch.manual_seed(torch_seed)\nset_seed(transformers_seed)\n```\n\n참고: transformers.set_seed만 설정해도 충분하지만 보다 안전하게 하기 위해 추가적으로 설정하였습니다.\n\n<div class=\"content-ad\"></div>\n\n**참고 2:** 이 예시에서는 Python 3.10을 사용합니다.\n\n## Mistral 불러오기\n\nHugging Face로부터 Mistral-7B-v0.1 모델을 불러오려면, 환경 변수 HF_TOKEN에 Hugging Face 토큰을 설정해야 합니다.\n모델의 양자화된 버전을 사용할 것이며, 이는 계산의 정밀도를 줄여 GPU의 메모리 사용량을 줄이는 것을 의미합니다.\n\n```python\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\nfrom time import time\nimport os\n\nmodel_name = \"mistralai/Mistral-7B-v0.1\"\ndevice = \"cuda\" # 모델을 불러올 장치\n\n# 단순성을 위해 이렇게 유지하지만, Hugging Face 토큰은 .env 파일에 넣고, 'python-dotenv' 라이브러리의 load_dotenv 함수를 사용하여 불러오는 것이 좋습니다.\nos.environ[\"HF_TOKEN\"] = \"<여기에 Hugging Face 토큰을 입력하세요>\"\n\ndouble_quant_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype = \"float16\"\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    padding_side=\"right\",\n    add_eos_token=False,\n    add_bos_token=False,\n    trust_remote_code=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=double_quant_config)\n```\n\n<div class=\"content-ad\"></div>\n\n## 트랜스포머 파이프라인 사용\n\n우리는 트랜스포머 라이브러리의 pipeline을 사용하여 LLM(Large Language Model)에서 출력을 생성하는 것을 간단하게할 것입니다.\n\n결정론적인 이유로, LLM의 어휘 중에서 가장 가능성 있는 토큰을 일관되게 예측하고 싶으므로, top_k=1 또는 0에 가까운 값으로 온도를 구성할 수 있습니다.\n\n또한, 간편함을 위해 max_new_tokens 매개변수를 1로 설정하여 LLM이 우리의 프롬프트를 하나의 토큰으로 완료하도록 할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom transformers import pipeline\n\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    add_special_tokens=False,\n    max_new_tokens=1,\n    temperature=0.00000000001,\n    repetition_penalty=1.4\n)\n\nsentence = \"I enjoy walking in the\"\n\nresponse = pipe(sentence)[0]['generated_text']\nprint(response)\n\n# >>> I enjoy walking in the woods\n```\n\n만약 LLM이 \"I enjoy walking in the\"라는 시퀀스에 대해 \"woods\"라는 한 단어만 출력하면, 올바른 결과를 돌려주었다고 볼 수 있습니다. 그럼 실험을 진행해도 좋을 것 같아요.\n\n# 3. 실험 결과: T4 대 A10G\n\n이 두 개의 GPU에 접근하기 위해, AWS SageMaker를 통해 ml.g4dn.xlarge (T4) 및 ml.g5.xlarge (A10G) 인스턴스를 론칭했습니다. \n\n\n<div class=\"content-ad\"></div>\n\n간단한 쿼리를 시도해 봅시다:\n\n```js\n# 프롬프트\n매우 간결하게 질문에 대답하세요\n질문: 대형 언어 모델의 특별한 점은 무엇인가요?\n답변:\n```\n\n```js\nprompt = \"<s>[INST]매우 간결하게 질문에 대답하세요[/INST] \\n질문: 대형 언어 모델의 특별한 점은 무엇인가요? \\n답변:\"\nresponse = pipe(prompt)[0]['generated_text']\nprint(response)\n```\n\nT4와 A10G에서 얻은 답변이 같습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n질문: 대형 언어 모델에 대해 무엇이 특별한가요?\n대답: 그들은 인간이 쓴 것처럼 보이는 텍스트를 생성할 수 있습니다. 이는 번역이나 텍스트 요약과 같은 여러 작업에 사용될 수 있음을 의미합니다(한 언어에서 다른 언어로 또는 반대로). 모델 자체는 교육 데이터가 필요하지 않지만 입력 문장을 기반으로 새로운 문장을 생성할 때 어떻게 동작해야 하는지 몇 가지 예시만 필요로 하므로 다른 모델들보다 훨씬 쉬워집니다. 더 이상 사전에 여러 데이터 세트를 사전에 가지고 있을 필요가 없다는 것을 의미합니다!\n\n지금까지 좋습니다. 그러나 이것은 짧은 쿼리였습니다. RAG 사용 사례의 경우, 통상 수천 개의 토큰을 전송합니다. Hugging Face에서 호스팅되는 llama-2-arxiv-papers-chunked 데이터 세트를 사용하여 더 큰 쿼리로 테스트해 봅시다.\n\n다음 코드에서는 데이터 세트의 인덱스 0, 4518, 4519 및 799에서 검색된 청크를 사용하여 RAG가 어떻게 작동하는지 모방할 것입니다. 청크 4518과 4519는 Llama 2에 대해 설명하지만 다른 청크는 아닙니다. 이 문맥을 사용하여 LLM이 이 질문에 대한 답변인 'Llama 2에 대해 무엇이 특별한가요?'을 예상합니다. 이 프롬프트는 약 1,400개의 토큰입니다.\n\n```\n\n<div class=\"content-ad\"></div>\n\nT4의 결과:\n\n```js\nLlama 2와 블룸 또는 친치아와 같은 대형 언어 모델 세부 튜닝 사이의 주요 차이점은 그들의 훈련 방법입니다. 이 두 가지 방법은 인터넷에서 스크랩된 데이터로 모델을 훈련하지만, Llama 2는 훈련 시 자체에서 생성된 텍스트만 사용하여 시스템에 편향이 외부 소스(소셜 미디어 게시물 등)로 인해 도입되는 가능성을 낮춥니다. 또한 이는 내부의 모든 것이 다른 실행에서도 일관되게 유지되므로 나온 결과물을 더 신뢰할 수 있게 합니다! 또한 각 단어 토큰이 문장 당 전역 점수 한 개가 아니라 개별 가중치 값을 ​​할당받기 때문에 특정 작업 시 사용자가 더 좋은 제어를 얻을 수 있어서 현재 경쟁하는 시스템들이 부족한 기능입니다. 마지막으로 중요한 것은, 비용이 비싼 하드웨어 리소스에 크게 의존하는 다른 시스템과 달리 스스로 업데이트해야 하는 시기가 예상보다 빠르지 않는 한 수개월마다 상수적으로 업데이트해야 하는 시스템 등...\n```\n\nA10G의 결과:\n\n```js\nLlama 2와 블룸 또는 친치아와 같은 대형 언어 모델 세부 튜닝 사이의 주요 차이점은 그들의 훈련 방법입니다. 이 두 가지 방법은 인터넷에서 스크랩된 데이터로 모델을 훈련하지만, Llama 2는 훈련 시 자체에서 생성된 텍스트만 사용하여 시스템에 편향이 외부 소스(소셜 미디어 게시물 등)로 인해 도입되는 가능성을 낮춥니다. 또한 이는 이 텍스트 내에서 다루는 주제에 대한 질문을 할 때 더 자신감을 갖도록 하기 때문에, 잠재적인 편향은 이미 사전에 제거되어 있을 것입니다! 또한 여기서 사용된 각 단어는 다른 단어 뒤에 직접 올기기 때문에 문장 내에 무작위 단어가 무작위로 삽입되는 것보다 오류가 적은 것을 의미하며, 전통적인 기계 학습 접근법들과 비교할 때 매 문장이 자체 내부에 일종의 오류 교정 메커니즘을 가져야 하는 경우가 적습니다. 마지막으로 중요한 것은, 어떤 유형의 질문이든 누군가 질문을 해도 중요하지 않습니다. 트위터 DM 메시지를 통해 친구나 가족 구성원 사이에 개인적으로 보낸 짧은 쿼리든, 손으로 종이에 수기로 쓴 장문의 글이나 나중에 디지털적으로 스캔된 문서든 내 무엇이 어떤 질문을 하든 언제든지 모든 것이 신뢰할 수 있게 된다는 사실 덕분에 하드의 모든 것이 AI 기술에 의해 일어나는 세계 밑바닥에서 발생하는 모든 것에 크게 기여합니다!!!\n```\n\n<div class=\"content-ad\"></div>\n\n참 흥미로운 내용이에요. 처음 보면 두 답변이 같은 내용으로 시작하기 때문에 눈에 띄지 않을 수 있어요. 하지만 \"etc...\" 다음에는 차이가 있어요.\n\nT4 쪽에서는: \"etc... 이는 내부의 모든 것이 다른 실행에서도 일관되게 유지되므로 출력에 더 신뢰를 할 수 있다는 것을 의미합니다!...\"\n\nA10G 쪽에서는: \"etc... 이는 이 텍스트 내에서 다루는 주제에 관련된 질문을 할 때 더 자신감을 가질 수 있게 될 거에요...\"\n\n# 4. T4 Colab vs T4 SageMaker.\n\n<div class=\"content-ad\"></div>\n\n동일한 GPU를 사용하는 두 환경이 동일한 결과를 낳는지 궁금한 분을 위해, 무료 버전의 Colab 노트북과 T4를 장착한 것이 특징인 ml.g4dn.xlarge (T4) SageMaker 노트북 인스턴스를 구동하여 테스트를 실시해 보았습니다. 결과는 실제로 동일함을 확인했습니다.\n\n# 5. 왜 두 개의 GPU에서 동일한 입력과 동일한 LLM으로 생성되는 답변이 완전히 다른가요?\n\n동일한 입력으로 생성되는 답변이 매우 다른 이유는 LLM의 자기회귀적인 성질 때문입니다. 다음 토큰은 이전 토큰에 의해 선택되므로, 아주작은 변경이 연쇄 반응을 일으켜 나비 효과를 초래합니다.\n\n주어진 맥락을 기반으로 한 답변은 아니라는 점을 유의하세요. LLM은 지시에 완전히 따르지 않았지만, 그것은 중요하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\nLLM을 항상 가장 가능성 높은 토큰으로 선택하도록 설정했기 때문에, GPU 간에 확률을 계산하는 방법을 살펴볼 수 있습니다. 이러한 확률을 조사해 보겠습니다.\n\n# 6. 확률 탐색\n\n각 선택된 토큰의 확률을 인쇄하려면, 파이프라인을 우회하고 tokenizer와 model.generate 메소드를 직접 사용하여 출력_dict_in_generate=True 및 output_scores=True를 설정할 수 있습니다. 그런 다음 전이 점수를 확률로 계산, 정규화 및 변환할 수 있습니다.\n\n```js\ninputs = tokenizer([prompt], return_tensors=\"pt\")\n\noutputs = model.generate(**inputs, max_new_tokens=300, temperature=0.00000000001, repetition_penalty=1.4, return_dict_in_generate=True, output_scores=True)\ntransition_scores = model.compute_transition_scores(\n    outputs.sequences, outputs.scores, normalize_logits=True\n)\n\ninput_length = inputs.input_ids.shape[1]\ngenerated_tokens = outputs.sequences[:, input_length:]\nfor tok, score in zip(generated_tokens[0], transition_scores[0]):\n    // | 토큰 | 토큰 문자열  | 확률\n    print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {np.exp(score.numpy()):.2}\")\n```\n\n<div class=\"content-ad\"></div>\n\n위의 코드는 각 토큰의 ID, 디코딩된 토큰 및 확률을 출력할 것입니다. 출력의 전체 내용이 상당히 길기 때문에 중요한 부분만 포함하겠습니다.\n\nT4 출력:\n\n```js\n# T4\n토큰 ID | 토큰 문자열 | 확률\n----------------------------------\n...\n|  4345 | etc       | 35.28%\n|   568 | ..        | 44.56%\n|   851 | This      | 36.57%\n|   835 | also      | 30.27%\n|  2825 | means     | 38.98%\n|   368 | you       | 24.24%\n|   541 | can       | 46.44%\n|  4893 | trust     | 18.74%\n|   767 | what      | 29.62%\n|  3435 | comes     | 44.17%\n|   575 | out       | 40.51%\n...\n```\n\nA10G 출력:\n\n<div class=\"content-ad\"></div>\n\n```js\n# A10G \n토큰 id| 토큰 문자열 | 확률\n----------------------------------\n...\n| 4345 | 등등      | 35.48%\n| 568  | ..        | 44.38%\n| 851  | 이것      | 36.40%\n| 835  | 또한      | 30.22%\n| 2825 | 의미       | 39.42%\n| 368  | 당신       | 24.29%\n| 541  | 할 수 있다 | 46.42%\n| 347  | 되다      | 18.62%\n| 680  | 더        | 49.45%\n| 10689| 자신감      | 57.50%\n...\n```\n\n오케이, 이제 흥미로워지고 있네요. T4와 A10G의 확률이 정확히 일치하지 않습니다. 보통 이것은 토큰 순위에 영향을 미치지 않습니다(생성된 시퀀스에서 아무것도 알아차리지 못할 것입니다), 하지만 때로는 그렇지 않을 수도 있습니다.\n\n예를 들어, T4에서 \"신뢰\"는 18.74%의 확률을 가지고 있지만, A10G에서는 \"되다\"가 18.62%로 선호됩니다. 이 시점부터 LLM의 자기회귀적 성질로 인해 생성이 분기될 것입니다.\n\n참고: LLM의 양자화는 계산 정밀도를 줄이기 때문에 이러한 차이가 더 자주 발생합니다.\n\n<div class=\"content-ad\"></div>\n\n당신에게 한 가지 합리적인 질문은 \"GPU에 따라 계산이 왜 다를까요?\"입니다.\n\n## 7. GPU에 따라 계산이 다르게 나타나는 이유는 무엇인가요?\n\n저는 CUDA 전문가는 아니지만 연구를 했습니다. GPU 간의 차이는 여러 요인과 관련이 있습니다:\n\n병렬 계산 처리:\nGPU는 병렬로 많은 계산을 효율적으로 처리하는 데 관심이 있습니다. 그러나 서로 다른 GPU는 병렬 작업을 처리하는 방식에 차이가 있을 수 있으며, 이는 연산 순서와 메모리 접근에 영향을 줄 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이것은 중요합니다. 프로그래밍에서 크기가 크게 다른 숫자를 더하는 것조차 연관성이 없을 수 있기 때문입니다. 이는 정교한 계산에서 정확도에 영향을 줄 수 있습니다. 비연관성은 다음과 같은 경우에 발생합니다.\n\n(a + b) + c ≠ a + (b + c).\n\n![이미지](/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_1.png)\n\n그래서 이러한 계산은 분할되어 독립적으로 처리되고, 그 후 비연관적으로 결합됩니다. 결과적으로, 이러한 부분들이 다시 결합되는 방식이 최종 결과에 영향을 줍니다.\n\n<div class=\"content-ad\"></div>\n\n다음은 연관되지 않은 계산의 간단한 예시입니다:\n\n```js\nimport torch\n# 크기 차이가 큰 bfloat16 형식의 세 개의 부동 소수점 수를 정의합니다.\na = torch.tensor(1e10, dtype=torch.bfloat16)\nb = torch.tensor(-1e10, dtype=torch.bfloat16)\nc = torch.tensor(1.0, dtype=torch.bfloat16)\n\n# 서로 다른 순서로 합을 계산합니다.\nsum1 = (a + b) + c\nsum2 = a + (b + c)\n# 계산 결과를 bfloat16로 출력합니다.\nprint(f\"(a + b) + c in bfloat16: {sum1}\")\n# >>> 1.0\nprint(f\"a + (b + c) in bfloat16: {sum2}\")\n# >>> 0.0\n```\n\nLLM을 사용하면 수백만 개의 계산이 소수점 오차로 인해 발산할 수 있으며, 이는 시퀀스 생성 중 단어 선택에 영향을 미칠 수 있습니다.\n\n하드웨어 아키텍처:\nNvidia Tesla T4 및 Nvidia A10G와 같은 다양한 GPU 모델은 다른 하드웨어 아키텍처를 가지고 있습니다. 이러한 아키텍처는 병렬 처리 능력, 메모리 대역폭 및 계산 유닛과 같은 성능의 다양한 측면을 최적화하기 위해 설계되었습니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, T4는 Turing 아키텍처를 사용하는 반면 A10G는 Ampere 아키텍처를 기반으로 합니다.\n\n다른 아키텍처는 부동 소수점 산술, 메모리 액세스 패턴 및 기타 저수준 작업에 대한 다른 구현을 의미합니다. 이러한 구현의 미묘한 차이도 계산 결과의 차이를 초래할 수 있습니다.\n\n예를 들어, 높은 정밀도에 최적화된 아키텍처는 속도에 최적화된 아키텍처와 비교하여 동일한 부동 소수점 작업을 수행하더라도 다른 결과를 제공할 수 있습니다.\n\n양자화 효과:\n모델을 양자화하면 메모리 및 계산 리소스를 저장하기 위해 정밀도를 줄이지만 추가적인 오류 소스를 도입합니다. 이러한 오류의 영향은 GPU가 낮은 정밀도 산술을 처리하는 방식에 따라 다를 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n양자화는 숫자를 근사화하는 과정이 포함되어 있기 때문에 다양한 GPU가 이러한 근사화를 다르게 처리할 수 있으며, 토큰 예측의 확률에 변화를 일으킬 수 있습니다.\n\n## 8. 여러 GPU를 사용하여 LLM을 수평적으로 확장하는 것에 대해 걱정해야 할까요?\n\n그 질문 정말 훌륭한 질문이네요, 질문해 주셔서 감사합니다! :)\n동일한 GPU의 여러 인스턴스를 추가하는 경우(예: A10G GPU 1대에서 4개의 A10G GPU가 포함된 인스턴스로 확장) 걱정해야 할 필요가 있을까요?\n\n여러 GPU를 사용하여 추론 작업에 접근하는 여러 전략이 있습니다:\n\n<div class=\"content-ad\"></div>\n\n모델이 하나의 GPU에 맞는 경우 첫 번째 전략은 각 GPU에 모델 사본을 로드하는 것입니다. 예를 들어, pipeline으로 네 개의 쿼리 목록을 보내면 각 쿼리가 다른 GPU에서 처리될 수 있습니다. 이렇게 하면 한 GPU만 사용하는 것과 같은 결과를 볼 수 있지만 처리량이 향상됩니다.\n\n두 번째 전략은 모델이 하나의 GPU에 맞지 않는 경우 일반적으로 사용되며, 이는 샤딩(sharding)으로 그 모델의 가중치를 GPU들 간에 분산하는 것입니다. 이론적으로는 연산 분배와 실행 차이로 인한 변화가 발생할 수 있지만, 실제로는 적어도 제가 한 테스트에서는 샤딩 사용 시 단일 GPU에서의 시퀀스와 확률과 동일한 결과를 얻었습니다. 파이토치는 결정론적 연산을 위해 노력한다고 생각됩니다.\n\n# 결론:\n\n다른 GPU를 사용하면 동일한 환경, 설정 및 시드를 사용해도 LLM이 서로 다른 결과를 출력할 수 있음을 보여줬습니다. 이러한 변동성은 보다 긴 프롬프트에서 더 많은 계산이 필요하기 때문에 증가하며, 부정확성의 전파가 증가하고 두 GPU 간의 차이가 완화됩니다. 게다가 양자화를 사용할 경우 이 효과가 더 두드러집니다.\n\n<div class=\"content-ad\"></div>\n\n결과가 항상 재앙적인 것은 아니라는 것을 말하고 싶은 게 아니에요, 하지만 LLM 배포 시 고려해야 할 사항이에요.\n\n만약 제품에서 사용하는 GPU와 다른 GPU로 개발한다면, 성능이 적절한지 확인하기 위한 테스트를 설정해주세요. 또한, 다른 GPU가 장착된 새로운 인스턴스에 LLM을 확장할 계획이 있다면 이 역시 중요해요.\n\n끝까지 읽으셨다면, 축하드려요! 이 게시물을 즐겨주셨으면 좋겠어요. 제가 Medium에서 처음으로 쓴 글이라서요. 재미있게 보셨다면 더 많이 쓰도록 격려해 주시기를 바라요. 댓글에서 의견을 자유롭게 공유해주세요.","ogImage":{"url":"/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_0.png"},"coverImage":"/assets/img/2024-06-20-ChangingtheGPUischangingthebehaviourofyourLLM_0.png","tag":["Tech"],"readingTime":13},{"title":"탐사 분류기를 사용하여 연락 센터 LLMs의 학습 내용을 밝힐 수 있을까요 아니요, 불가능합니다","description":"","date":"2024-06-20 18:44","slug":"2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt","content":"\n\n이 블로그는 2024년 NAACL에서 수락된 기술 논문에 대한 참조입니다. 이 논문은 멕시코시티에서 개최된 5번째 맞춤형 결과로부터의 통찰력 워크샵(NLP@NAACL)에서 발표되었습니다.\n\n![이미지](/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png)\n\n## 소개\n\n고객 서비스의 빠른 세상에서, 연락 센터는 기술 지원부터 청구 문의까지 모든 분야의 고객 상호 작용의 최전선으로 기능합니다. 기술이 발전함에 따라 대규모 언어 모델(LLMs)이 연락 센터에 통합되면 고객 지원의 제공 방식을 혁신화할 수 있습니다. 다만, 이러한 모델의 효과는 연락 센터 상호 작용의 특정 세부 사항을 이해하고 처리할 수 있는 능력에 크게 의존합니다. 저희 논문인 \"프로빙 분류기가 연락 센터 대규모 언어 모델의 학습을 밝혀 줄까요?: 아니요, 그렇지 않습니다!\"에서는 연락 센터 도메인을 위해 특별히 선별된 LLMs의 학습을 프로빙 분류기가 밝혀낼 수 있는지 조사합니다.\n\n<div class=\"content-ad\"></div>\n\n## 동기\n\n본 연구의 동기는 접촉 센터를 포함한 다양한 영역에서 LLMs에 대한 의존도가 점점 증가하고 있다는 점에서 비롯됩니다. 접촉 센터는 고객 지원 및 서비스에 중요한 역할을 하며 기술적 문제부터 청구 관련 문제까지 다양한 쿼리를 처리합니다. 그러나 이러한 상호 작용의 즉흥적이고 소음이 많은 특성은 LLMs에게 중요한 도전 요소가 됩니다. 도메인별 데이터로 LLMs를 세밀하게 조정하면 성능을 향상시킬 수 있지만, 이 과정에서 이러한 모델이 실제로 무엇을 배우는지 이해하는 것이 중요합니다. 기존에는 탐사 분류기가 LLMs의 내부 표현을 해석하고 이해하는 데 사용되어 왔지만, 이들이 도메인별 학습의 세부 사항을 밝히는 데 얼마나 효과적인지는 여전히 불분명합니다. 본 연구는 접촉 센터 응용 프로그램을 위해 세밀하게 조정된 LLMs가 습득하는 핵심적인 특성을 평가함으로써 이 갭을 메우고자 합니다.\n\n## 도메인별 세밀한 조정의 중요성\n\nOpenAI 및 Google과 같은 대규모 언어 모델은 인간과 유사한 텍스트를 생성하는 놀라운 능력을 보여주고 있습니다. 이러한 모델의 성능을 재정 및 생명공학과 같은 특정 도메인에서 더욱 향상시키기 위해 이러한 모델은 종종 도메인별 데이터로 세밀하게 조정됩니다. 이 방법은 다양한 분야에서 성공적인 것으로 입증되었지만, 접촉 센터 도메인에는 소음이 많은 쿼리, 즉흥 대화 및 특정 용어와 같은 독특한 도전 요소가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 방법론\n\n본 연구에서는 30억부터 130억 개 파라미터까지 다양한 크기의 두 가지 인기 있는 LLM 아키텍처인 Flan-T5와 Llama에 중점을 두었습니다. 저희는 내선 작업에서의 효과를 측정하기 위해 연락센터 대화의 독점 데이터셋으로 이러한 모델들을 세밀하게 조정합니다. 또한 이 연락센터(CC) 도메인 특화 지시 LLM들이 기본 설정 버전과 비교했을 때 배운 근본적 특성을 평가합니다. 이를 위해 저희는 대화, 채널, 자동 음성 인식(ASR) 속성을 평가하는 점검 작업을 정의하여 무엇을 배우고 그것이 연락센터 도메인에서 실제 성능으로 어떻게 변환되는지 알아봅니다.\n\n## 주요 발견\n\n- 내선 작업에서의 성능 향상: CC-LLMs는 내선 작업에서 상당한 성능 향상을 보였습니다. 특히, OOB 모델과 비교하여 응답 수용성이 48% 이상 향상되었습니다. 이는 도메인 특화 세밀 조정이 연락센터에서 LLM의 실용성을 향상시키는 데 효과적임을 강조합니다.\n- 점검 분류기의 차이 미미: 내선 작업에서의 성능 향상에도 불구하고, 점검 분류기는 세세한 차이를 보이지 않았습니다. 이는 전통적인 점검 작업이 모델 내에서 발생하는 미묘한 학습을 효과적으로 포착하지 못할 수 있다는 것을 시사합니다.\n- 아키텍처와 크기의 중요성: 시험한 모델 중에서 T5 모델이 다양한 설정에서 일반적으로 Llama 모델보다 우수한 성능을 보였습니다. 흥미로운 점은 작은 CC-Flan-T5(110억) 모델이 종종 큰 CC-Llama(130억)보다 우수한 성능을 보인다는 것인데, 이는 모델 아키텍처가 모델 크기보다 더 중요할 수 있다는 것을 시사합니다.\n- 일반 언어 특성: 세밀 조정 이후, CC-Flan-T5와 CC-Llama 모델은 SentEval suite의 일반 언어 점검 작업에서 점수가 낮아졌으며, 일반 언어 특성에서 도메인 특화 능력으로의 초점 이동을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n## 함의 및 향후 방향\n\n연구 결과는 LLMs가 학습한 근본적인 특성들을 신뢰할 수 있는 방식으로 드러낼 수 있는 것이라는 가정에 도전하고 있습니다. 세부적으로 조정된 모델들은 특정 작업에서 우수한 성과를 보이지만, 기존의 조사 메커니즘은 모델의 학습에서 변경된 기본적인 특성을 발견하는 데 충분하지 않아 보입니다.\n\n이는 우리가 어떻게 조사 작업을 설계하고 활용하는지 재검토할 필요가 있음을 시사합니다. 컨택 센터의 대화의 동적이고 맥락 의존적인 성격은 보다 정교하고 맥락을 인지하는 조사 전략이 필요할 수도 있습니다. 게다가, 연구는 언어 생성 중의 디코딩 전략이 중요한 역할을 하며 향후 연구의 중점이 되어야 함을 제안합니다.\n\n마무리로, 컨택 센터와 같은 특정 도메인에 LLMs를 세부 조정함으로써 실용적 작업에서 성능을 크게 향상시킬 수 있지만, 기존의 조사 분류기는 이러한 개선 사항을 밝히는 데 한계가 있습니다. 이 연구는 더 효과적인 조사 방법에 대한 연구를 위한 새로운 방향을 제시하며, 높은 성과를 내는 LLMs 개발 시 아키텍처와 세부 조정 전략을 모두 고려하는 중요성을 강조합니다.\n\n<div class=\"content-ad\"></div>\n\n세계 곳곳의 연락센터를 위해 대화 인텔리전스를 변화시키는 Observe.AI에서 더 많은 정보를 확인해보세요.","ogImage":{"url":"/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png"},"coverImage":"/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png","tag":["Tech"],"readingTime":3},{"title":"다중 에이전트 시스템    LangGraph","description":"","date":"2024-06-20 18:42","slug":"2024-06-20-Multi-AgentSystemsLangGraph","content":"\n\n응, 맞아, Smiths가 여기 있어! 내 이전 게시물이 꽤 오래되었네. 처음 보는 사람이라면, 안녕. 이 게시물에서는 LangGraph에 대해 이야기하고, LangSmith에 대해서도 조금 언급하고 싶어. 최근에 우리는 에이전트 감독자를 구현하기 시작했어; 이것은 다중 에이전트 시스템을 구현하는 방법이야.\n\n그러나 너무 기술적으로 들어가기 전에, 잠시만 기다려 줄 수 있을까? 이것은 매트릭스의 Smith 에이전트야. 매트릭스에서 '질서'를 유지하기 위해 만들어진 코드 일부였다는 걸 기억해봐, 사람들을 시뮬레이션에 유지하는 시스템 내에서. (시스템이 붕괴해도, 네오에게 한 큰 박수). Smiths는 계층 구조였지; 다른 Smiths에게 일을 시키는 'the Smith'가 있었어. (그는 나중에 시뮬레이션 내에서 자신의 존재를 복제할 수 있었지. 사실, 많은 요청이 있는 시스템을 다루는 매우 멋진 방법이라고 할 수 있어, 아마 LangChain의 다음 움직임이 될지도 ;))\n\n![Smith Image](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_0.png)\n\n내 농담 세션 이후, LangGraph는 정말 멋진 라이브러리야; LangChain이 감당할 수 없는 경우에 매우 유용해. 복잡한 문제, 사용 사례 또는 흐름을 나누는 해결책을 제공해줘. 이전에 언급한 대로, 다중 에이전트 시스템에 대해 이야기할 테니, 주로 감독자 구현에 대해 이야기할 거야, 왜냐하면 이러한 에이전트를 결합하는 다양한 방법이 있거든. 그리고 우리가 챗봇을 구현하려고 노력하고 있기 때문에, 고객 지원 봇 튜토리얼에서 많은 도움을 받았어. 채팅에서 무엇을 할 수 있고, 에이전트를 제어하여 올바른 일을 수행하는 방법에 대해 매우 명확한 아이디어를 제공해줘.\n\n<div class=\"content-ad\"></div>\n\n# LangGraph 소개\n\nLangGraph는 LangChain 위에 구축되어 있으며 LangChain 생태계와 완전히 호환됩니다. 그것은 기본적으로 그래프 기반 상태 머신을 사용하여 복잡하고 확장 가능한 AI 에이전트를 구축하는 Python 라이브러리입니다. LangChain을 시도해 본 적이 있다면, 에이전트를 프로덕션 환경에서 실행하려고 할 때 그 부족함을 느낄 것입니다. 프로덕션에서는 종종 더 많은 제어가 필요합니다. 특정 도구를 항상 호출하도록 강제하고 싶을 수 있습니다. 도구를 호출하는 방법을 더 많이 제어하고 싶을 수 있습니다. 상태에 따라 에이전트에 대한 서로 다른 프롬프트를 사용하고 싶을 수 있습니다.\n\n그렇다면, 이 “상태 머신”이란 무엇일까요? 이를 통해 인간 상호작용을 순환하며 LLM(Lang Language Model)을 통해 작업을 수행할 수 있는 권한을 얻게 됩니다. 이는 어떤 에이전트가 실행되었는지, 어떤 도구를 사용했는지, 그리고 원한다면 메모리까지 추적합니다. 현재 메모리에 대해 자세히 알아볼 필요는 없지만, LangChain에서 본 것과는 조금 다릅니다. Checkpointer는 상태를 영속화하여 에이전트에게 \"메모리\"를 제공합니다.\n\n## StateGraph\n\n<div class=\"content-ad\"></div>\n\nStateGraph은 그래프를 나타내는 클래스입니다. 상태 정의를 전달하여이 클래스를 초기화합니다. 그래프 내의 노드가 상태를 업데이트하고, 이는 키-값 저장소 형식의 작업을 반환합니다.\n\n```js\nfrom langgraph.graph import StateGraph\nfrom typing import TypedDict, List, Annotated\nimport Operator\nfrom langchain_core.messages import BaseMessage\n\nclass State(TypedDict):\n    input: str\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n\ngraph = StateGraph(State)\n```\n\n## 노드\n\nStateGraph를 만든 후 graph.add_node(name, value) 구문을 사용하여 노드를 추가합니다. value 매개변수는 호출 될 함수 또는 LCEL 실행 가능이어야 합니다. (즉 실행 가능한 도구 또는 LLM)\n\n<div class=\"content-ad\"></div>\n\n```js\ngraph.add_node(\"model\", model)\ngraph.add_node(\"tools\", tool_executor)\n```\n\n그래프를 순환할 것이기 때문에 프로세스 중 어딘가에서 종료하는 것이 중요합니다. 그래프의 끝을 나타내는 END 노드를 사용하세요.\n\n```js\nfrom langgraph.graph import END\n\ngraph.add_node(\"end\", END)\n```\n\n## 엣지\n\n<div class=\"content-ad\"></div>\n\n노드를 추가한 후에 그래프를 만들기 위해 엣지를 추가할 수 있습니다. 현재는 세 가지 유형의 엣지가 있습니다:\n\n1 - 시작 엣지: 이 엣지는 그래프의 시작점을 특정 노드에 연결하는 엣지입니다. 아래 코드는 우리의 그래프가 'model' 노드에서 시작한다는 것을 의미합니다.\n\n```js\ngraph.set_entry_point(\"model\")\n```\n\n2 - 일반 엣지: 이러한 엣지는 한 노드가 항상 다른 노드 뒤에 호출되도록합니다. 아래 코드는 'tools' 노드를 호출할 때 'model' 노드가 항상 그 뒤에 호출된다는 것을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ngraph.add_edge(\"tools\", \"model\")\n```\n\n3 - 조건부 엣지: 이는 LLM이 첫 번째로 이동할 노드를 결정하는 데 사용하는 엣지입니다. 엄격히 어디로 이동할지를 지정하지 않습니다. LLM은 상태와 사용자 입력을 확인하여 목적지를 결정합니다.\n\n조건부 엣지에는 세 가지 매개변수가 있습니다. 첫 번째 매개변수는 다음에 할 일을 결정할 노드입니다. 두 번째 매개변수는 다음으로 호출할 노드를 결정하는 함수입니다. 세 번째 매개변수는 함수(2)가 반환할 수 있는 가능한 값이어야 합니다. 그리고 값은 이동할 노드의 이름이어야 합니다.\n\n```js\ngraph.add_conditional_edge(\n    \"model\",\n    should_continue,\n    {\n        \"end\": END,\n        \"continue\": \"tools\"\n    }\n)\n```\n\n<div class=\"content-ad\"></div>\n\n## 컴파일\n\n우리가 그래프를 정의한 후, 그것을 실행 가능한 형태로 컴파일할 수 있습니다. 이 실행 가능한 형태는 LangChain 러너블과 똑같은 메소드를 가지고 있습니다 (.invoke, .stream, .astream_log 등).\n\n```js\napp = graph.compile()\n```\n\n# Multi-Agent Systems\n\n<div class=\"content-ad\"></div>\n\n단일 에이전트는 순차적으로 실행해야 할 너무 많은 도구가 있을 때 실패할 수 있습니다. 그래서 다중 에이전트 시스템에서는 문제를 분할하여 각 단계를 다른 에이전트로 정복하고 적절한 전문가에게 업무를 라우팅합니다.\n\n## 에이전트 감독\n\n에이전트 그룹을 만들 것입니다. 각 에이전트는 작업을 완료하는 데 필요한 특정 도구를 갖게 됩니다. 에이전트 감독은 작업을 위임하는 데 도움을 줄 것입니다.\n\n![에이전트 감독](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_1.png)\n\n<div class=\"content-ad\"></div>\n\n이 예제에서는 2명의 에이전트와 1명의 감독관이 있습니다. 첫 번째 에이전트는 무작위 숫자를 생성하고, 다른 에이전트는 해당 무작위 숫자에 대한 다이어그램을 그립니다. 기대한 대로, 감독관이 작업을 위임하며, 무작위 숫자 생성 에이전트가 작업을 마치면 다른 에이전트에게 바퀴를 넘깁니다.\n\n우리는 기초를 정의하며 시작합니다.\n\n```js\nfrom langchain_openai import ChatOpenAI\nfrom typing import Annotated, List, Tuple, Union\nfrom langchain.tools import BaseTool, StructuredTool, Tool\nfrom langchain_experimental.tools import PythonREPLTool\nfrom langchain_core.tools import tool\nimport random\n\n\n#Model\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n\n#Tools\n\n#다이어그램 그리기용\npython_repl_tool = PythonREPLTool()\n\n#무작위 숫자 생성용\n@tool(\"random_number\", return_direct=False)\ndef random_number(input:str) -> str:\n    \"\"\"0-100 사이의 무작위 숫자를 반환합니다. 'random'이라는 단어를 입력하세요.\"\"\"\n    return random.randint(0, 100)\n\ntools = [random_number,python_repl_tool]\n```\n\n도우미 함수로 계속하세요.\n\n<div class=\"content-ad\"></div>\n\n\n```js\nfrom langchain.agents import AgentExecutor, create_openai_tools_agent\nfrom langchain_core.messages import BaseMessage, HumanMessage\nfrom langchain_openai import ChatOpenAI\n\n# 주어진 도구와 프롬프트로 AgentExecutor를 반환하는 함수\ndef create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n    prompt = ChatPromptTemplate.from_messages(\n        [\n            (\n                \"system\",\n                system_prompt,\n            ),\n            MessagesPlaceholder(variable_name=\"messages\"),\n            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n        ]\n    )\n    agent = create_openai_tools_agent(llm, tools, prompt)\n    executor = AgentExecutor(agent=agent, tools=tools)\n    return executor\n\n# 에이전트 노드, 그래프에서 에이전트를 호출하는 데 사용할 함수\ndef agent_node(state, agent, name):\n    result = agent.invoke(state)\n    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n```\n\n이제 그래프를 만들어 이 2개의 에이전트를 노드로 추가하겠습니다 :\n\n```js\nimport operator\nfrom typing import Annotated, Any, Dict, List, Optional, Sequence, TypedDict\nimport functools\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langgraph.graph import StateGraph, END\n\n# 난수 생성기를 노드로 설정\nrandom_agent = create_agent(llm, [random_number], \"You get random numbers\")\nrandom_node = functools.partial(agent_node, agent=random_agent, name=\"Random_Number_Generator\")\n\n# 코더를 노드로 설정\ncode_agent = create_agent(llm, [python_repl_tool], \"You generate charts using matplotlib.\")\ncode_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n```\n\n이제 슈퍼바이저를 생성해 봅시다!\n\n\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n\nmembers = [\"Random_Number_Generator\", \"Coder\"]\nsystem_prompt = (\n    \"안녕하세요! 대화를 관리하는 감독관으로 지정되었습니다. {members}와(과) 같은 작업자들 간의 대화 관리를 맡았습니다. 아래 사용자 요청이 제시된 경우, 다음에 행동할 작업자를 응답하세요. 각 작업자는 작업을 수행하고 결과 및 상태에 회신합니다. 작업이 완료되면 FINISH로 회신해주세요.\"\n)\n# 다음 작업자 노드를 선택하거나 처리를 종료하기 위해 함수 호출을 사용합니다.\noptions = [\"FINISH\"] + members\n# openai 함수 호출\nfunction_def = {\n    \"name\": \"route\",\n    \"description\": \"다음 역할을 선택합니다.\",\n    \"parameters\": {\n        \"title\": \"routeSchema\",\n        \"type\": \"object\",\n        \"properties\": {\n            \"next\": {\n                \"title\": \"Next\",\n                \"anyOf\": [\n                    {\"enum\": options},\n                ],\n            }\n        },\n        \"required\": [\"next\"],\n    },\n}\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        MessagesPlaceholder(variable_name=\"messages\"),\n        (\n            \"system\",\n            \"위 대화를 참고하여, 다음에 누가 행동해야 할까요? 아니면 FINISH로 종료해야 할까요? 다음 중 하나를 선택해주세요: {options}\",\n        ),\n    ]\n).partial(options=str(options), members=\", \".join(members))\n\n\n# 라우팅 함수 및 시스템 프롬프트와 결합된 LLM으로 체인 생성\nsupervisor_chain = (\n    prompt\n    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n    | JsonOutputFunctionsParser()\n)\n```\n\n그래프를 생성해봅시다! (코멘트를 참고해주세요)\n\n먼저 상태를 정의하고 에이전트 노드와 감독관 노드를 추가합니다.\n\n```js\n# 메시지를 보유하고 어디로 이동할지를 나타내는 AgentState 정의\nclass AgentState(TypedDict):\n    messages: Annotated[Sequence[BaseMessage], operator.add]\n    # 'next' 필드는 다음으로 라우팅할 위치를 나타냅니다\n    next: str\n\n# 상태 그래프(StateGraph) 정의\nworkflow = StateGraph(AgentState)\n\n# 에이전트를 노드로 추가, 감독관 체인을 노드로 추가\nworkflow.add_node(\"Random_Number_Generator\", random_node)\nworkflow.add_node(\"Coder\", code_node)\nworkflow.add_node(\"Supervisor\", supervisor_chain)\n\n# 에이전트가 작업을 완료하면 다음은 항상 감독관이어야 합니다\nworkflow.add_edge(\"Random_Number_Generator\", \"supervisor\") \nworkflow.add_edge(\"Coder\", \"supervisor\")\n\n# 감독관이 그래프 상태의 \"next\" 필드를 결정하여 노드 또는 종료로 라우팅합니다. (위의 END 특수 노드를 기억하세요)\nworkflow.add_conditional_edges(\n    \"supervisor\", \n    lambda x: x[\"next\"], \n    {\n        \"Random_Number_Generator\": \"Random_Number_Generator\",\n        \"Coder\": \"Coder\",\n        \"FINISH\": END \n    })\n\n# 시작점은 항상 감독관이어야 합니다\nworkflow.set_entry_point(\"supervisor\")\n\ngraph = workflow.compile()\n```\n\n<div class=\"content-ad\"></div>\n\n한 번 해 보세요, 그래프를 스트리밍하거나 직접 실행할 수 있습니다.\n\n```js\nfor s in graph.stream(\n    {\n        \"messages\": [\n            HumanMessage(content=\"10개의 무작위 숫자를 가져와 히스토그램을 생성합니다.\")\n        ]\n    }, config={\"recursion_limit\": 20}\n):\n    if \"__end__\" not in s:\n        print(s)\n        print(\"----\")\n```\n\n<img src=\"/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_2.png\" />\n\n출력에서 보듯이, 우리는 선언된 Supervisor로 시작합니다. Supervisor는 우리를 Random_Number_Generator로 경로 설정합니다. Random_Number_Generator가 작업을 완료한 후에는 엣지를 추가했기 때문에 Supervisor로 돌아갑니다. 그런 다음 Supervisor는 Coder로 경로를 설정하며 Coder가 완료되어 Supervisor로 돌아옵니다. 작업이 완료되면 Supervisor가 처리를 완료합니다.\n\n<div class=\"content-ad\"></div>\n\n🥳\n\n# LangSmith\n\nLangSmith은 LLM 애플리케이션 개발, 모니터링 및 테스트를 위한 플랫폼입니다. 저는 주로 모니터링에 사용하고 있어서 해당 측면만 언급할 예정이에요. LangSmith 추적을 활성화하면 LLM을 디버깅할 수 있어요.\n\n문서를 보려면 여기를 클릭하세요.\n\n<div class=\"content-ad\"></div>\n\n위에서 실행한 예제는 아래와 같이 보입니다:\n\n![image1](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_3.png)\n\n더 자세한 정보를 원하신다면:\n\n![image2](/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_4.png)\n\n<div class=\"content-ad\"></div>\n\n많은 도구를 가진 에이전트를 사용할 때 매우 유용합니다. 우리 경우에는 하나의 도구만 가지고 있었지만, 문제가 더 복잡해지고 내부에서 무슨 일이 일어나고 있는지 이해하고 싶을 때, LangSmith가 당신이 그 과정을 따라가는 데 정말 도움이 될 것입니다. 디버그 콘솔로도 할 수 있지만, 왜 이 도구가 있는데 불편하게 해야 하나요?\n\n환경 변수를 추가하여 추적 기능을 활성화할 수 있습니다:\n\n```js\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n```\n\n추가 링크:\n\n<div class=\"content-ad\"></div>\n\n- [https://blog.langchain.dev/langgraph/](https://blog.langchain.dev/langgraph/)\n- [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)\n\n즐겁게 즐겼다면 좋겠어요! 다음에 또 만나요 :)","ogImage":{"url":"/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_0.png"},"coverImage":"/assets/img/2024-06-20-Multi-AgentSystemsLangGraph_0.png","tag":["Tech"],"readingTime":11},{"title":"GPT-4 - 우리는 속고 있는 걸까요","description":"","date":"2024-06-20 18:41","slug":"2024-06-20-GPT-4oAreWebeingLIEDto","content":"\n\n오늘날 열풍을 일으키는 인공지능(AI) 기술이 얼마나 빠르게 발전하고 있는지에 대해 Open AI 및 기타 기업들로부터 거짓 정보를 받고 있는 걸까요?\n\n![image](/assets/img/2024-06-20-GPT-4oAreWebeingLIEDto_0.png)\n\n또는 이것이 또 다른 \"NFT 순간\"인지, 즉 과대포장 이후 큰 폭락이 일어날 것인지 궁금할 수도 있겠네요.\n\n그런데 제 생각에 이번에는 그렇게 되지 않을 것 같아요. 저는 NFT 열풍 주기에는 믿음을 안 했지만, 인스턴스적으로는 인공지능 열풍에는 믿음이 많이 드네요.\n\n<div class=\"content-ad\"></div>\n\n제가 매일 인공지능(AI)의 최신 정보를 읽어요.\n\n만약 당신이 유료 Medium 회원이 아니라면, 여기서 무료로 읽을 수 있어요.\n\n저는 우리가 인공 일반 지능(AGI)에 빠르게 다가가고 있다고 생각하는 것과 LLM(Large Language Model)의 능력 면에서 플랫폼에 다다르고 있는 것 중 어디에 더 가까운지 계속 변해요.\n\n양쪽에 대한 좋은 주장들이 있어요.\n\n<div class=\"content-ad\"></div>\n\n이 기사에서는 AI가 지나치게 과대포장되고 있는 가능성을 살펴보고 싶습니다.\n\n내 AI 뉴스레터에 관심이 있을지도 몰라요 👉\n\n매일 GPT-4o를 사용하고 있어요.\n\n내 동생이자 비즈니스 파트너 인 Addison Best와 저는 GPT-4o의 역량이 감소하고 있다는 점에 주목하고 있어요. 네, 이것은 주관적인 견해이지만 감소가 상당히 명백해요.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 내가 GPT-4o에게 기사의 특정 부분에 제 제휴 링크를 넣도록 요청하면, 이런 간단한 작업에 엉망징창으로 처리할 수도 있어요.\n\n(이전에는 더 잘 작동했는데, 어떻게든 모델의 능력이 시간이 지남에 따라 변화하는 것 같아요)\n\nGPT-4o는 정말 빠르긴 하지만, 제가 무엇을 요청했는지에 대한 정확성과 이해력은 심지어 GPT-4보다 나빠 보이네요.\n\n그들이 얼마나 빠르고 능숙한지 알려줄 수 있다면, 아마 우리는 '빠른' 부분에 만족하고 '능숙한' 부분은 신경도 쓰지 않을 지 모를 거에요. (또는 '능숙한' 부분으로 인해 플러스 멤버십을 해지할 정도로 신경 쓰지도 않을 거에요.)\n\n<div class=\"content-ad\"></div>\n\n# 왜 내가 AI가 과대포장되었다고 생각하는지\n\n- 기업들은 더 많은 관심과 자금을 얻기 위해 AI에 대해 거짓말을 하고 과장하는 경제적 인센티브가 엄청나다.\n- 회사들은 실제로 AI 데모 중에 주장을 과장했다가 발각된 적이 있습니다 (Google, OpenAI, Amazon 등).\n- 모델은 점점 느려지는 것 같습니다 (개인적 경험).\n- 모델 파라미터의 수가 기하급수적으로 늘어남에도 성능은 그렇지 않습니다. (더 세게 짜도 한 송이 레몬에서 무한한 주스를 짤 수는 없습니다)\n- 어떤 사람들은 OpenAI가 음성을 더 인간적으로(예를 들어 애교있게 껄껄대면서) 만들어 \"가짜\" 지능을 만들고 있다고 주장합니다. — 이는 내가 생각하지 못한 흥미로운 포인트입니다.\n\n내가 개인적으로 믿는 바는 최고의 AI가 우리에게 주어진 것보다 훨씬 강력하다는 것입니다. 문제는 최고의 모델이 월 20달러에 제공하기에 충분히 에너지 효율적이지 않다는 것입니다.\n\n그래서 그들은 모델의 능력을 계속해서 억제하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n의견을 궁금해요.\n\n- 웹사이트 방문 - AI Growth Guys\n- 👉 AI 뉴스레터 👈 구독\n- 이메일 마케팅에 Beehiiv를 추천하는 이유 확인\n- AI Growth Guys YouTube 채널 확인\n- AI 전문가 Andrew Best의 소개 읽기\n\n# 쉽게 설명하면 🚀\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 떠나시기 전에:\n\n<div class=\"content-ad\"></div>\n\n- 작가를 박수 치고 팔로우하기 잊지 마세요! 👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문하기: CoFeed | Differ\n- PlainEnglish.io에서 더 많은 콘텐츠 확인하기","ogImage":{"url":"/assets/img/2024-06-20-GPT-4oAreWebeingLIEDto_0.png"},"coverImage":"/assets/img/2024-06-20-GPT-4oAreWebeingLIEDto_0.png","tag":["Tech"],"readingTime":3},{"title":"AI 이해력을 높이는 방법","description":"","date":"2024-06-20 18:39","slug":"2024-06-20-HowtoJumpstartYourAILiteracy","content":"\n\nAI 열풍이 시작된 지 벌써 1년이 넘었어요. AI는 글쓰기, 예술, 기술, 소셜 미디어 그리고 업무에 영향을 미쳤어요. 이제 거의 모든 회사, 정부, 그리고 기관이 AI 열풍에 참여하고 있습니다. 인공 지능은 여기에 남아 있고, 버블이던 아니던 사회에 지속적인 영향을 미칠 거예요.\n\n하지만 당신은 어떤가요?\n\n내가 추측해 보면, 당신은 아래 중 하나에 해당할 것입니다:\n\n- AI에 정통하고 호기심이 많아서 더 알고 싶어 하는 분\n- AI를 꺼리며 그 열풍에 동참하지 않는 분\n- 이 모든 AI에 대해 뒤처지고 시작해볼 방법을 모르는 분\n\n<div class=\"content-ad\"></div>\n\n당신의 위치와 관계없이 AI 지식을 늘리는 것이 중요합니다. 앞으로 AI는 우리가 일하는 방식을 항상 보완할 것입니다. 만약 당신이 화이트 칼라 직업을 가졌는데 인공지능 모델과 상호 작용하는 방법을 이해하지 못한다면 뒤처질 것입니다.\n\n충분한 공포를 조장하는 건 그만두고요... 저는 AI 지식 베이스를 확장하여 미래로 나아갈 방법과 새로운 사용 사례에 적용하기 위해 어떻게 준비할 수 있는지 말하려고 합니다.\n\n# AI 직감력을 개발하기\n\nAI에 능숙해지려면 다양한 용도에서 AI 모델의 응용 가능성을 인식하는 자연스러운 능력을 개발하는 것이 중요합니다. 좋은 소식은 모든 AI의 각 면을 이해할 필요는 없다는 것입니다. 이것을 발전시키는 것은 쉬운 일이라고 주장합니다. 오직 이러한 핵심 단계를 따르기만 한다면요:\n\n<div class=\"content-ad\"></div>\n\n## 매일 생활 속에서 AI 적용하기\n\n그냥 사용하세요. 많이요.\n\n![AI 이미지](/assets/img/2024-06-20-HowtoJumpstartYourAILiteracy_0.png)\n\nChatGPT와 대화를 나누어 문제를 해결해보세요. 집안에서 생산성을 높이는 데 활용하거나, 새로운 취미를 찾고, 예술을 향상시키거나, 요리할 새로운 아이디어를 고민해보세요. 어이 없는 일을 시키도록 해보세요. 다양한 아이디어와 컨셉을 실험해보세요. AI처럼 복잡한 것을 이해하는 가장 좋은 방법은 시행착오를 통해 시작하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n제가 ChatGPT를 제 개인 상담대로 사용하여 대부분의 아이디어와 프로세스를 떠올리고 발전시키는 습관을 들였어요. 이미 시작하지 않은 경우, 이는 AI 흐름에 쉽게 진입하는 방법입니다. 그리고 가능한 빨리 GPT Pro를 구입해야 합니다. 최첨단 모델과 상호 작용하는 것은 가치가 있어요.\n\n매일 AI를 사용하는 데 어려움을 겪고 있다면, 창의적인 아이디어를 떠올릴 수 있는 ChatGPT의 과소평가된 사용 사례에 대해 쓴 기사가 있어요.\n\n## AI 발전 상황을 따라가기\n\nAI의 최신 동향을 계속해서 따라갈 수 있는 신뢰할 수 있는 출처를 찾아보세요. 뉴스 매체, 온라인 포럼 또는 뉴스 집계기가 될 수 있어요. 현재 최첨단 기술의 상태를 이해하면(즉, 현재 현대 AI 시스템의 정의를 결정하고 있는 특성과 제한을 이해하게 됩니다), AI 발전에 대한 깊은 이해를 위한 기준으로 활용할 수 있게 될 거예요.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 대형 언어 모델 AI에 익숙하지 않은 사람은 Anthropic의 최신 모델 세트인 Claude 3에 대해 들어본 적이 없을 수도 있어요. 그런데 이 모델은 GPT-4를 꺾고 1년 만에 최고를 차지한 첫 번째 모델이에요. 더군다나 작은 \"하이쿠\" 모델도 가장 \"성능 대비 가격이 좋은\" LLM으로 엄청난 발전을 이루었어요. AI는 너무 빨리 발전하기 때문에 이러한 매우 중요한 발전들이 종종 주목받지 못할 수 있으니, 미래를 이해하기 위해서는 현재 상황을 알고 있어야 해요.\n\n다음은 저가 자주 방문하는 몇 가지 좋은 소스입니다:\n\n- MIT Technology Review\n- David Shapiro (Youtube)\n- Google News (지능적인 필터링 및 검색 기능 포함)\n- Reddit (토론 및 새로운 소식을 얻기 좋은 곳)\n\n## AI의 특수 응용 프로그램에 대해 알아보세요\n\n<div class=\"content-ad\"></div>\n\n이 단계는 당신의 연상 능력을 활성화하는 데 중요합니다. 회사들이 AI를 어떻게 독특한 용례에 활용하는지 연구하고 배우는 데 집중하면, 일부 패턴 인식과 연상 능력을 개발할 수 있습니다. 예를 들어, 공장을 운영한다고 가정해 봅시다. 어떤 회사들이 AI를 활용하여 제조 문제를 해결하는 방법을 살펴본다면, 당신이 직면한 일부 문제를 어떻게 해결할 수 있을지에 대한 아이디어를 얻을 수 있습니다.\n\n이는 여러분이 자체 AI 모델을 구축하는 방법을 알아내야 한다는 것을 의미하는 것은 아닙니다. 오히려, AI의 진보에 대한 심층적인 탐구를 위해 무엇을 찾아야 하는지 알 수 있으며 여러분의 업무 효율성을 높일 수 있습니다.\n\n## AI 사용 방법을 배우세요\n\n저는 ChatGPT를 어떻게 사용하지 말아야 하는지에 대한 전체 기사를 썼습니다. 사람들이 그것을 오용하는 모든 방법을 종합하는 것은 깨달음을 줬으며, 몇 달 동안 그 이후로도 더 많은 오용 사례를 보았습니다. 그들을 모두 통합하는 한 가지는 무엇일까요? 그들은 그 한계를 모르고 AI가 \"아무것도 제대로 못한다\"고 좌절해 하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이건 사실이 아니에요. 그냥 그것이 만들어진 목적과는 다른 작업에서 실패할 뿐이에요. 당신이 정비공에게 미적분 증명을 요청하지 않듯이, 당신의 망치가 당신을 직장으로 데려다 주기를 기대하지 않을 것입니다.\n\nChatGPT는 언어 작업에 아주 뛰어나기 때문에 그 강점을 알 필요가 없다는 점이에요; 오히려 그것이 할 수 없는 것에 대해 알아보는 데 집중해야 해요. 실은 저는 ChatGPT를 사용하는 중요한 원칙 몇 가지만 알고 있다면 빠르게 전문가로 성장할 수 있다고 확신합니다.\n\n## AI 모델 식별 방법 배우기\n\n여러 가지 유형의 AI가 있어요. 회사가 \"AI를 사용중이다\"라고 언급할 때, 그것이 어디에서, 어떻게, 왜 사용되는지를 구별하기가 점점 어려워지고 있어요. 다양한 종류의 AI 모델을 이해하면 그들의 사용 사례를 빠르게 식별하고 그것이 마케팅 발언인지 아니면 기술의 실제로 흥미로운 적용인지 알아낼 수 있어요. 이 지식은 또한 자신의 일이나 개인 생활에 AI를 어떻게 적용할 수 있는지를 알아내는 데 도움이 돼요.\n\n<div class=\"content-ad\"></div>\n\n- 예측 AI — 예측 AI는 대규모의 과거 데이터를 학습하여 대량의 복잡한 데이터셋에서 추세, 패턴 및 이상점을 찾습니다. 이들은 상품 가격, 시장 변동성 및 물류 분석과 같은 동적 요소의 움직임을 예측하는 데 유용합니다.\n- 분석 AI — 이들은 예측 모델과 유사하지만 입력을 분류하고 새로운 유용한 데이터로 조작하는 데 초점을 맞춥니다. 예를 들어, 분석 모델은 오디오를 분석하여 텍스트로 변환할 수 있습니다. 또 다른 사용 사례는 컴퓨터 비전으로, 입력 이미지나 비디오를 가져와 영상 내의 특정 요소를 분류할 수 있습니다. 예를 들어, 인간 얼굴을 인식하고 기록하는 보안 카메라 시스템과 같은 사례가 있습니다.\n- 생성 AI — 여기서 여러분이 들어본 큰 주제입니다. ChatGPT, Gemini, Claude, Midjourney, Runway, Sora 등 많은 예시들이 있는 생성 AI는 주로 간단한 사용자 입력에서 새로운 콘텐츠를 생성하는 데 초점을 맞춥니다. 이들은 작년에 인공지능에 대한 관심 폭증의 가장 큰 책임자이며, 그 이유는 비밀이 없습니다. 그들은 정말 멋지고 즉각적으로 유용합니다.\n\n이 주제에 대해 더 알고 싶다면, 인공지능/머신러닝이 높은 수준에서 무엇인지 이해하는 데 더 깊은 시작점을 제공하는 이 기사를 강력히 추천합니다.\n\n앞으로 몇 년 동안은 예측이나 분석 AI보다는 일상 생활에서 생성 AI와 상호 작용할 가능성이 더 높기 때문에, 이 기사의 주요 초점은 ChatGPT와 같은 생성 모델에 맞춰져 있습니다.\n\n## AI 작동 방식 이해하기\n\n<div class=\"content-ad\"></div>\n\n가장 마지막 단계로 이것을 배치했는데, 아마도 여기서 가장 밀집되고 열정적인 학습 곡선일 것입니다. 그러나 여전히 AI를 효과적으로 활용하는 데 필수적이라고 생각합니다. 특히 ChatGPT를 이해하는 데 좋은 두 가지 자료가 있습니다:\n\n- ChatGPT가 무엇을 하고 있으며 어떻게 작동하는가? 이 우수한 스티븐 월프람의 기사는 ChatGPT의 내부 작업에 대해 깊이 파고들어 설명합니다. 주의: 이 기사는 1시간 이상 소요되며 가벼운 소비자에게는 부적합할 수 있습니다. 그러나 ChatGPT를 이해하는 데 가장 좋은 입문 자료라고 생각합니다.\n- LLM Visualizer — 이 웹사이트는 LLM의 과정을 임베딩에서 출력까지 모든 단계마다 따라갈 수 있는 정말 멋진 기능이 있습니다. 이는 상당히 기술적이지만 매우 눈부신 경험입니다. 이 기능을 사용하기 전에 먼저 스티펜 월프람의 기사를 읽어보세요!\n\n이러한 모델들은 정보를 연결하여 입력과 일치하는 \"새로운\" 정보를 생성하려고 합니다. 사용자로서 여러분을 만족시키기 위해 가능한 최대한 신뢰할 만하고 관련성 있는 출력을 생성하려고 노력합니다. AI가 실제로 \"자신만의 마음\"을 가지지 않는다는 사실(적어도 현재로서)과 실제로 예측 가능하고 일관성있게 작동한다는 것을 깨달을 때 많은 이점을 얻게 될 것입니다:\n\n- 어떤 요청이 동작하고 어떤 것이 동작하지 않는지 직관적으로 파악할 수 있습니다. AI의 한계를 알고 있는 것이 강점을 알고 있는 것보다 훨씬 중요합니다.\n- 빠르고 쉽게 그것을 다룰 수 있습니다. AI와 함께 작업하기 어려울 수 있지만, 상자 속에 있는 도구들을 이해하면 원하는 결과물을 보다 빠르고 반복 횟수를 줄이며 달성할 수 있습니다.\n- 다른 사람들이 AI를 더 효과적으로 활용하는 방법을 가르칠 수 있습니다. 말해두지 않아도, AI의 기초를 더 많이 알 것이므로 그 정보를 다른 사람들과 공유하기가 더 쉬워집니다.\n\n<div class=\"content-ad\"></div>\n\nAI 지식에 확신이 없거나 따라잡기 힘들다고 느끼시는 분들께 이 자료가 유용하길 바랍니다. AI는 방대하고 복잡한 주제지만, 작은 조각으로 쪼개면 어려울 게 없어요.\n\n읽어 주셔서 감사합니다! 즐거운 코딩하세요!\n\n- Jordan","ogImage":{"url":"/assets/img/2024-06-20-HowtoJumpstartYourAILiteracy_0.png"},"coverImage":"/assets/img/2024-06-20-HowtoJumpstartYourAILiteracy_0.png","tag":["Tech"],"readingTime":6},{"title":"AI Agents in a GPT","description":"","date":"2024-06-20 18:38","slug":"2024-06-20-AIAgentsinaGPT","content":"\n\n## GPT에 AI 에이전트를 내장하는 방법\n\n이것은 GPT-5에 에이전트가 곧 출시될 수도 있다는 힌트일까요?\n\n![이미지](/assets/img/2024-06-20-AIAgentsinaGPT_0.png)\n\n오늘은 여러분에게 멋진 것을 보여드릴 거예요 — 직접 AI 에이전트를 만들고 GPT에서 사용하는 방법을 알려 드릴 거예요.\n\n<div class=\"content-ad\"></div>\n\n이 예시는 간단하지만, AI 에이전트의 힘을 보여줍니다.\n\n아마도 AI 에이전트에 대해 들어본 적이 있을 것입니다. 그리고 그들이 미래라는 것도 들었을 겁니다.\n\n아마도 이미 GitHub에서 찾을 수 있는 몇 가지 기존 AI 에이전트 프레임워크를 시도해 보았을지도 모릅니다. 그러나 이들 중 많은 것들은 설정하기가 꽤 복잡하고 높은 코딩 지식이 필요합니다 — 이들은 일반인을 위한 것은 아니며, 많은 프로젝트에는 필요하지 않습니다.\n\n이 튜토리얼은 AI 에이전트를 간단한 용어로 설명하고, 코드 없이 시작하는 법을 알려줍니다.\n\n<div class=\"content-ad\"></div>\n\n이 안내서는 AI 에이전트 사용에 대한 소개입니다.\n\n코더이고 다른 AI 에이전트를 시도해본 적이 있다면 - 이것이 비교 가능하다고 말하고 싶지는 않습니다.\n\n하지만 GPT에서 AI 에이전트를 사용해 보려는 것은 GPT의 매우 흥미로운 사용 사례를 만들어줄 수 있습니다.\n\n여기 제가 만든 비디오가 있어요. AI 에이전트를 GPT에서 직접 확인할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# AI 에이전트와 ChatGPT의 차이점은 무엇인가요?\n\nAI 에이전트는 특정 작업을 자체적으로 수행할 수 있습니다. 당신이 필요한 것을 이해하고, 결정을 내릴 수 있으며, 당신을 돕기 위해 행동할 수 있습니다.\n\nAI 에이전트는 또한 각각이 특정 역할을 가지고 팀으로 작동할 수 있으며, 심지어 인간의 개입 없이 공통의 목표를 달성하기 위해 협력할 수 있습니다.\n\nChatGPT는 대화를 나누는 것과 비슷합니다. 당신이 계속해서 질문하면, LLM을 사용하여 답변하고 질문에 답변하는 데 도움을 줍니다.\n\n<div class=\"content-ad\"></div>\n\n질문하거나 무언가를 시키면 그에 따라 답변합니다. 질문하거나 요청하면 텍스트를 생성하는 데 탁월한데요, AI 에이전트처럼 자동으로 작업을 수행하지는 않습니다.\n\nAI 에이전트는 여러 단계의 작업을 자체적으로 수행하는 반면, ChatGPT는 대화를 시작하고 무엇을 해야 할지 말해줘야 합니다. 모든 단계에 참여해야 합니다.\n\n간단한 예시로 차이를 살펴보는 것이 매우 도움이 됩니다.\n\n저의 👉 AI 뉴스레터 👈에 관심이 있을 수도 있어요.\n\n<div class=\"content-ad\"></div>\n\n# ChatGPT를 사용하여 여러 단계에서 기사 작성하기\n\n예를 들어, 작가라면, ChatGPT를 사용하여 기사를 여러 단계로 만들 수 있습니다. 다음은 ChatGPT에서 기사를 만드는 단계별 작업 및 상호 작용 방법입니다:\n\n- 기사 제목 생성: ChatGPT에게 현재 AI 연구를 기반으로 하는 다섯 가지 기사 제목을 요청하십시오.\n- 개요 작성: 그 다음, 기사 개요를 요청합니다.\n- 기사 초안 작성: 그런 다음, 기사 초안을 작성하도록 합니다.\n- 기사 편집: 마지막으로, 편집자에게 기사를 개선하고 제안을 받도록 요청합니다.\n- 최종 초고: 편집자의 제안을 기반으로 새로운 기사를 작성하도록 ChatGPT에게 요청합니다.\n\nChatGPT는 이러한 작업을 수행할 수 있지만, 각 단계를 수동으로 요청해야 합니다. 이 프로세스는 오랜 시간이 걸리고 지루할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n위의 예시에서는 ChatGPT에게 5개의 별도 질문을 하고 매번 대답을 기다려야 합니다.\n\n# AI 에이전트를 사용하여 동일한 기사 생성\n\n저는 AI 에이전트를 활용한 간단한 GPT를 만들었습니다. 이를 사용하여 위의 예시와 동일한 방식으로 동일한 기사를 생성합니다.\n\n하지만 에이전트끼리 대화하면서 전체 기사와 아웃라인, 초안, 편집 등을 하나의 프롬프트만으로 처리할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nGPT를 사용한 AI 에이전트를 만들었어요. 이 GPT는 다음을 할 거예요:\n\n- 다섯 개의 기사 주제에 대한 연구\n- 기사 개요 작성\n- 기사 초고 작성\n- 기사 편집, 개선 제안 및 완성까지 정제\n\n# 에이전트 역할\n\n이 에이전트 프레임워크를 포함한 모든 AI 에이전트의 첫 번째 단계는 각 에이전트의 역할을 정의하고 원하는 능력을 결정하는 것이에요.\n\n<div class=\"content-ad\"></div>\n\n# GPT 지침서의 에이전트 역할 정의\n\n- 연구자 에이전트: 다섯 개의 기사 주제를 생성합니다.\n- 개요 작성자 에이전트: 주제를 선택하고 개요를 작성합니다.\n- 작가 에이전트: 개요를 기반으로 기사를 초안 작성합니다.\n- 편집자 에이전트: 초안을 검토하고 개선 제안을 하여 작가에게 개정을 요청합니다.\n\nGPT에서 에이전트 역할 외에, 다음을 말했습니다:\n\nGPT에서 에이전트를 시작하려면 \"주제\"에 대한 단 한 가지 프롬프트만 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n그럼 요원들이 소통하여 제가 더 이상 개입하지 않고 기사를 완성할 거예요.\n\nAI 에이전트 GPT가 작동하는 것을 보고 싶다면, 이 기사 맨 위의 동영상을 확인해보세요.\n\n# AI 에이전트의 장점\n\nAI 에이전트는 작업을 독립적이고 효율적으로 처리하여 시간을 절약해줍니다. 특히 기사 작성 및 소프트웨어 개발과 같은 여러 단계를 포함하는 작업에 유용합니다.\n\n<div class=\"content-ad\"></div>\n\n에이전트마다 특정 역할을 정의하여 원활하게 함께 작업할 수 있습니다.\n\n더 발전된 에이전트 역할을 만들 수도 있고, API에 액세스하거나 다른 LLM 모델에 접근하거나 코드를 설치하고 실행할 수 있게 할 수도 있습니다.\n\nGPT 안의 AI 에이전트는 GPT 환경 내에서 실행되기 때문에 제한됩니다. 이는 로컬호스트나 서버와 같지 않습니다.\n\n하지만 흥미로운 사용 사례를 만들기 위해 해킹되어 일부 사용 사례를 만들어낼 수는 있습니다.\n\n<div class=\"content-ad\"></div>\n\n저는 ChatGPT, 인공지능, GPT 등을 활용하여 온라인 비즈니스를 키우는 방법에 대해 가르치고 있어요.\n\n제 👉 AI Growth Guys Newsletter 👈를 확인해보세요.\n\n아래의 다른 채널들도 확인해보세요.\n\n저희 YouTube 채널도 놀러오세요.\n\n<div class=\"content-ad\"></div>\n\n우리 웹 사이트에서 팔로우해 주세요: AI Growth Guys","ogImage":{"url":"/assets/img/2024-06-20-AIAgentsinaGPT_0.png"},"coverImage":"/assets/img/2024-06-20-AIAgentsinaGPT_0.png","tag":["Tech"],"readingTime":4}],"page":"43","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}