{"pageProps":{"posts":[{"title":"MapReduce에 대해 알아야 할 모든 것","description":"","date":"2024-06-19 05:12","slug":"2024-06-19-EverythingyouneedtoknowaboutMapReduce","content":"\n\n## Google에서 제공하는 'MapReduce: 대규모 클러스터에서 간소화된 데이터 처리' 논문의 모든 주요 통찰\n\n![image](/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_0.png)\n\n# 목차\n\n- 동기\n- 모델\n- MapReduce 구현\n- 지원 기능\n\n<div class=\"content-ad\"></div>\n\n# 소개\n\n2009년에 데이터 엔지니어로 일하셨군요.\n\n회사에서는 HDFS에 저장된 TB 단위의 데이터를 사용하고 계시군요.\n\n데이터 처리를 위한 로직을 작성하셨군요.\n\n<div class=\"content-ad\"></div>\n\n하나의 기계에서 실행했군요.\n\n작업을 끝내는 데 반나절이 걸렸군요.\n\n그래서 어떻게 최적화했나요?\n\n더 많은 기계를 사용해야 한다는 것을 깨달았죠.\n\n<div class=\"content-ad\"></div>\n\n그러나 어떻게 하면 계산을 신뢰할 수 있게 병렬 처리할 수 있을까요?\n\n당신이 2009년에 있었던 상황을 기억해봅시다:\n\n- Google BigQuery 출시 1년 전 (2010년)\n- Apache Spark 개발 2년 전 (2012년)\n- Amazon Redshift 출시 4년 전 (2013년)\n- AWS에서 Snowflake 출시 5년 전 (2014년)\n\n가장 가능성이 큰 선택은 구글에서 2004년에 처음으로 소개되었고 나중에 Yahoo가 오픈 소스화한 대규모 병렬 처리 프레임워크인 MapReduce였습니다.\n\n<div class=\"content-ad\"></div>\n\n이번 주에는 Google의 전형적인 논문을 통해 이 프레임워크에 대해 배우게 될 것입니다: MapReduce: 대규모 클러스터에서 간소화된 데이터 처리.\n\n# 동기\n\nGoogle에서는 수백 개의 연산이 대량의 데이터를 처리합니다. 이 중 대부분은 간단합니다. 그러나 데이터가 너무 많아서 한 대의 기계에서 처리할 수 없으며, 연산을 수백 대 또는 수천 대의 기계로 분산하여 실행하고 합리적으로 완료해야 합니다. 여기서 도전 과제가 있습니다:\n\n- 연산을 어떻게 병렬화할 것인가?\n- 데이터를 어떻게 효율적으로 분산할 것인가?\n- 장애를 어떻게 처리할 것인가?\n\n<div class=\"content-ad\"></div>\n\n이를 해결하기 위해 Google은 병렬화의 세부 사항을 추상화하여 간단한 계산을 표현할 수 있는 새로운 추상화를 설계했습니다. 이 모델은 Lisp와 다른 함수형 언어의 map 및 reduce 원시 기능에서 영감을 받았습니다. 이 작업의 Google 주요 기여 사항은 다음과 같습니다:\n\n- 병렬 계산을 정의하는 간단하고 강력한 인터페이스.\n- 대규모 계산의 자동 병렬화와 분배를 가능하게 함.\n- 상용 기계에서 높은 성능 달성 가능.\n\n# 모델\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_1.png)\n\n<div class=\"content-ad\"></div>\n\n다음은 사용자가 정의하는 두 가지 기능을 갖는 모델입니다:\n\n- Map: 키/값 쌍 입력을 받아들이고 중간 키/값 쌍을 출력하는 함수입니다. 라이브러리는 동일한 키의 모든 값들을 그룹화하고 Reduce 작업에 전달합니다.\n- Reduce: Map 작업으로부터 중간 값들을 받습니다. 중간 값들은 이터레이터를 통해 Reduce에 제공됩니다. 그런 다음 Reduce 함수에서 정의된 로직을 사용하여 동일한 키의 중간 값들을 병합합니다 (예: Count, Sum 등). Reduce는 일반적으로 최대 하나의 출력 값을 생성합니다.\n\n정의 이후에 MapReduce 프로그램은 대규모 커머디티 머신 클러스터에서 병렬화되어 실행됩니다. 런타임은 사용자 개입 없이 데이터 파티셔닝, 장애 허용 및 머신 간 통신을 처리할 것입니다.\n\n# MapReduce 구현\n\n<div class=\"content-ad\"></div>\n\n# 실행 개요\n\n시스템은 데이터를 M개의 분할로 자동으로 분할합니다. 이 M개의 분할에서의 Map 호출은 여러 대의 기계에 분산됩니다. 이러한 분할은 서로 다른 기계에 의해 병렬로 처리될 수 있습니다. 중요한 점을 처리하기 위해 중요한 공간을 R 버킷으로 분할하는 파티션 함수(예: 키의 해시 함수)를 사용하여 Reduce 호출이 분산됩니다. 사용자는 파티션(R) 수와 파티션 함수를 정의할 수 있습니다.\n\n**일반적인 MapReduce 흐름에 대한 이미지:**\n\n![MapReduce](/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_2.png)\n\n일반적인 MapReduce 흐름에 따른 일반적인 단계는 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- 맵리듀스 라이브러리는 입력 파일을 일반적으로 16에서 64 메가바이트(MB)로 나눈 M 개의 조각으로 분할합니다. (사용자가 크기/조각 팩터를 구성할 수 있습니다.)\n- 그런 다음 여러 대의 기계에서 프로그램을 복사본으로 시작합니다. (여러 대의 기계에서 맵리듀스 프로세스가 실행될 것이라고 생각할 수 있습니다.)\n- 맵리듀스 프로세스 중 하나는 마스터라고 불리며 나머지는 마스터에서 작업을 수신하는 워커입니다.\n- M개의 맵 작업과 R개의 리듀스 작업이 있고, 유휴 상태의 워커는 마스터로부터 맵 또는 리듀스 작업을 수신합니다.\n- 맵 워커는 해당 분할을 읽어 각 쌍을 사용자가 정의한 맵 함수에 전달합니다. (예: 각 값에 X를 곱하거나). 워커는 중간 키/값 쌍 출력을 메모리에 버퍼링합니다.\n- 워커는 주기적으로 버퍼링된 쌍을 로컬 디스크에 기록한 다음 그 위치를 디스크에 마스터에게 알립니다.\n- 마스터는 리듀스 워커에게 이러한 위치에 대해 통지합니다. 통지를 받은 리듀스 워커는 맵 워커의 로컬 디스크에서 버퍼링된 데이터를 읽기 위해 원격 프로시저 호출을 사용합니다.\n- 중간 데이터 읽기가 완료되면 리듀스 워커는 중간 키를 기준으로 데이터를 정렬하여 동일한 키의 모든 발생을 그룹화합니다. 리듀스 워커는 데이터를 정렬해야하는데, 이는 맵 워커에서 서로 다른 키를 처리해야 하기 때문입니다. 정렬은 동일한 키의 값이 서로 가까이 있도록합니다.\n- 리듀스 워커는 정렬된 중간 데이터를 반복하여 각 고유 키마다 해당 키와 대응하는 중간 값 집합을 사용자의 리듀스 함수에 전달한 다음, 리듀스 함수의 출력을 이 리듀스 파티션에 대한 최종 출력 파일에 추가합니다.\n- 모든 맵 및 리듀스 작업이 완료되면 마스터가 사용자 프로그램을 깨웁니다 (종류의 비동기 프로세스).\n- 성공적으로 완료된 후, 맵리듀스 실행의 출력은 R 버킷과 관련된 R 출력 파일에서 사용할 수 있습니다. 분리된 파일을 반환하면 사용자가 이러한 결과 파일을 다른 맵리듀스 프로그램이나 다른 분산 애플리케이션에 입력할 수 있습니다.\n\n# 마스터 데이터 구조\n\n마스터는 각 맵 및 리듀스 작업의 상태와 워커 기계의 식별 정보를 저장합니다. 마스터는 또한 맵 및 리듀스 워커 사이의 \"중개역할\"을 합니다: 맵 워커로부터의 중간 파일의 위치를 리듀스 워커에게 알려줍니다. 각 완료된 맵 작업에 대해 마스터는 중간 파일의 위치와 크기를 저장합니다. 맵 워커들이 작업을 완료하면 중간 파일의 위치 및 크기 정보를 마스터에게 업데이트합니다. 마스터는 이 정보를 진행 중인 리듀스 작업을 하는 워커에게 푸시합니다.\n\n# 내고장성\n\n<div class=\"content-ad\"></div>\n\nMapReduce의 궁극적인 목표 중 하나는 여러 대의 기계에서 대량의 데이터를 신뢰성 있게 처리하는 것입니다. 그렇다면, 만약 실패가 발생한다면 어떨까요?\n\n작업자의 실패\n\n![작업자 이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_3.png)\n\n- 마스터는 주기적으로 핑을 보내 작업자의 상태를 확인합니다.\n- 작업자로부터 일정 시간 동안 응답이 없으면, 마스터는 작업자의 실패로 간주합니다.\n- 완료되거나 실패한 Map 작업은 대기 상태로 재설정되어 마스터가 다른 기계에서 이러한 작업을 다시 예약할 수 있습니다. 완료된 Map 작업은 로컬 디스크에 결과가 저장되므로, 만약 Map 기계가 실패하면 Map 결과도 접근할 수 없게 됩니다.\n- 실패한 Reduce 작업은 또한 대기 상태로 설정되어 다시 예약될 수 있습니다. 완료된 Reduce 작업은 결과가 전역 파일 시스템에 저장되므로 다시 실행할 필요가 없습니다.\n- 작업자 A가 Map 작업을 처리하고, 나중에 작업자 A가 실패하면, 마스터의 일정에 따라 작업자 B가 이 Map 작업을 담당하게 되며, 모든 Reduce 작업자에게 다시 실행이 필요함을 통지합니다. 처음에 Map Worker A의 데이터를 사용한 모든 Reduce 작업은 Worker B의 데이터를 읽게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n실패한 마스터\n\n- 마스터는 주기적인 메타데이터 체크포인트를 작성합니다.\n- 마스터가 다운되면, 마지막 체크포인트 상태에서 새로운 마스터를 시작할 수 있습니다.\n\n# 지역성\n\n![이미지](/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_4.png)\n\n<div class=\"content-ad\"></div>\n\n구글은 GFS가 관리하는 입력 데이터가 클러스터의 기계들의 로컬 디스크에 저장되어 있음을 이용하여 네트워크 대역폭을 활용합니다. GFS는 각 파일을 64MB 블록으로 나누고 각 블록의 중복된 복제본 (기본 3개)을 다른 기계에 저장합니다. MapReduce 마스터는 해당 입력의 복제본을 저장하는 기계에 Map 작업을 스케줄하려고 노력합니다. 마스터가 그 방법으로 스케줄을 할 수 없으면 해당 작업의 입력 데이터의 복제본 근처에 Map 작업을 스케줄하려고 시도합니다. 이렇게 함으로써 대부분의 워커가 입력 데이터를 로컬에서 읽고 네트워크 대역폭을 소비하지 않도록 보장합니다.\n\n## 작업의 정밀도\n\nMapReduce는 M 단계를 M 조각으로, Reduce 단계를 R (사용자가 제한함) 조각으로 나눕니다. 일반적으로 M과 R은 사용 가능한 워커보다 훨씬 더 커야 합니다. 각 워커가 여러 다양한 작업을 수행하도록 함으로써 동적으로 작업을 분산하고 워커가 실패할 때의 복구 속도를 높일 수 있습니다: 실패한 Map 작업은 완료된 모든 다른 워커 기계들 사이에 분산될 수 있습니다. M과 R의 크기에는 제한이 있어야 합니다. 마스터는 O(M + R) 스케줄링 결정을 내려야 하고 O(M ∗ R) 상태를 메모리에 유지해야 하기 때문에 마스터에 부담이 많이 가지 않도록 하는 것이 필요합니다.\n\n## 백업 작업\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_5.png\" />\n\n맵리듀스 작업의 전체 대기 시간이 증가하는 일반적인 이유 중 하나는 \"straggler\"입니다. straggler는 소수의 맵 또는 리듀스 작업 중 하나를 완료하는 데 더 오랜 시간이 걸리는 머신을 가리킵니다. straggler는 나쁜 디스크가 장착된 머신이거나 마스터가 머신에서 여러 작업을 예약하여 작업 간 리소스 경합을 야기하는 등 다양한 이유로 발생할 수 있습니다. Google은 이에 대한 해결책을 갖고 있습니다. MapReduce 작업이 거의 완료되기 직전에 마스터는 진행 중인 나머지 작업의 백업 실행을 예약합니다. 이 백업 작업은 기본 작업과 함께 병행하여 실행됩니다. 주요 작업 또는 백업 실행이 완료되면 작업은 완료된 것으로 표시됩니다. 따라서 주요 작업에 문제가 발생하여 처리 속도가 늦추어지면, straggler 증상이 없는 백업 작업이 프로세스를 효율적으로 처리할 수 있습니다.\n\n# 지원 기능\n\n맵리듀스의 기본 기능은 대부분의 요구사항을 충족시키지만, Google은 몇 가지 확장 기능이 유용하다고 판단했습니다.\n\n<div class=\"content-ad\"></div>\n\n# 파티션 함수\n\n기본 데이터 파티션 함수는 해싱입니다. 다른 논리가 필요한 상황을 지원하기 위해 MapReduce 라이브러리 사용자는 사용자 정의 파티션 함수를 제공할 수 있습니다.\n\n# 순서 보장\n\nMapReduce는 중간 키/값 쌍이 주어진 파티션 내에서 키 순서를 오름차순으로 처리함을 보장합니다. 이는 각 파티션마다 정렬된 출력 파일을 생성하는 것이 쉬워지도록 만듭니다. 사용자가 데이터가 정렬되어 있으면 편리하다고 생각할 때 유용합니다.\n\n<div class=\"content-ad\"></div>\n\n# Combiner Function\n\n컴바이너 함수는 맵 워커에서 실행됩니다. 일반적으로 사용자는 컴바이너 함수와 리듀스 함수를 구현하는 데 동일한 코드를 사용합니다. 둘 사이의 유일한 차이점은 MapReduce 라이브러리가 함수의 출력을 처리하는 방법입니다:\n\n- 리듀스 함수의 출력은 최종 출력 파일에 작성됩니다.\n- 컴바이너 함수의 출력은 중간 파일에 작성되고, 이 파일은 리듀스 작업으로 전송됩니다.\n\n# 입력 및 출력 유형\n\n<div class=\"content-ad\"></div>\n\n맵리듀스는 다양한 형식의 입력 데이터를 읽을 수 있는 지원을 제공합니다. 예를 들어, 텍스트 유형은 키를 파일 내 오프셋으로 처리하고 값을 라인의 내용으로 처리합니다. 사용자는 간단한 리더 인터페이스를 구현하여 새로운 입력 유형을 지원할 수 있습니다. 출력 유형에 대해, 맵리듀스는 다양한 형식으로 데이터를 생성하기 위한 일련의 출력 유형을 지원하며 사용자가 새로운 출력 유형을 정의할 수도 있습니다.\n\n# 부작용\n\n맵리듀스를 사용하면 매핑 또는 리듀싱 작업이 추가 파일을 추가로 생성할 수 있는지 여부를 지정할 수 있습니다.\n\n# 잘못된 레코드 건너뛰기\n\n<div class=\"content-ad\"></div>\n\n가끔 사용자 코드에 버그가 있어 Map 또는 Reduce 함수가 특정 레코드에서 크래시하는 경우가 있습니다. 이러한 버그로 인해 MapReduce 프로그램이 완료되지 못할 수 있습니다. 보통은 버그를 수정하는 것이 일반적인 해결책이지만 때로는 추가 조치가 필요할 수도 있습니다. 버그가 제3자 라이브러리에서 발생할 수 있으며 해당 소스 코드에 접근할 수 없는 경우가 있습니다. 또한 경우에 따라 일부 레코드를 무시하는 것이 허용됩니다. Google은 옵션 실행 모드를 제공하여 MapReduce 라이브러리가 어떤 레코드가 크래시를 발생시킬 수 있는지 감지하고 이러한 레코드를 건너뛰어 전진 진행을 이룰 수 있습니다.\n\n# 상태 정보\n\n마스터는 내부 HTTP 서버를 실행하고 MapReduce 프로그램의 모니터링 및 추적을 위한 일련의 상태 페이지를 제공합니다. 상태 페이지에는 계산의 진행 상황을 보여주는 정보가 포함되어 있습니다. 완료된 작업, 진행 중인 작업, 입력 크기, 중간 크기, 출력 크기 등이 표시됩니다. 또한 각 작업에서 생성된 표준 오류 및 표준 출력 파일에 대한 링크도 포함되어 있습니다. 최상위 상태 페이지에는 실패한 워커와 그들이 실패할 때 처리하던 맵 및 리듀스 작업이 표시됩니다. 사용자는 이 데이터를 사용하여 계산이 얼마나 걸릴지 예상하고 더 많은 리소스를 추가해야 하는지 여부를 판단할 수 있습니다.\n\n# 카운터\n\n<div class=\"content-ad\"></div>\n\nMapReduce 라이브러리는 다양한 이벤트의 발생 횟수를 세는 카운터를 제공합니다. 예를 들어, 사용자 코드는 처리된 총 단어 수를 세고 싶어할 수 있습니다. 이 기능을 사용하려면 사용자는 명명된 카운터 객체를 만들고 Map 및 Reduce 함수에서 카운터를 적절하게 증가시킵니다. 워커는 주기적으로 카운터 값을 마스터에 보고하며, 이 보고는 마스터로부터 ping-health-check 요청에 대한 응답과 함께 전송됩니다. 마스터는 성공한 Map 및 Reduce 작업에서 카운터 값을 집계하고 프로그램이 완료될 때 사용자 코드로 반환합니다. 카운터 값을 집계할 때 마스터는 동일한 Map/Reduce 작업, 백업 작업 또는 실패한 작업의 중복 실행의 영향으로 발생하는 중복을 제거합니다.\n\n# 마무리\n\n이 글을 통해 큰 규모 클러스터에서 간단한 데이터 처리를 위한 MapReduce의 편리함을 알아냈습니다. 두 가지 Map 및 Reduce 함수로 구성되어 있지만 이 프레임워크는 상용품 기계의 대규모 클러스터에서 연산을 병렬화하는 매우 효율적이고 견고한 방법을 제공합니다. 글을 마치기 전에 한 가지 더 알려드립니다: BigQuery 처리 엔진인 Dremel은 MapReduce의 영감을 받아 개발되었습니다.\n\n이제 이만 쉬어 가도록 하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n다음 블로그에서 만나요 ;)\n\n# 참고 자료\n\n[1] Jeffrey Dean and Sanjay Ghemawat, MapReduce: Simplified Data Processing on Large Clusters (2004).","ogImage":{"url":"/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_0.png"},"coverImage":"/assets/img/2024-06-19-EverythingyouneedtoknowaboutMapReduce_0.png","tag":["Tech"],"readingTime":9},{"title":"undefined","description":"","date":"2024-06-19 05:11","slug":"undefined","content":"\n\n<img src=\"/assets/img/undefined_0.png\" />\n\n우리의 데이터 처리 세계에서는 Azure Data Factory (ADF) 파이프라인에서 Databricks 노트북을 실행하는 환경에서 비용을 관리하는 것이 중요합니다. 성능을 유지하면서 비용을 줄이기 위해 대화식 클러스터에서 작업 클러스터로 마이그레이션하기로 결정했습니다. 이 과정에서 우리가 관찰하고 배운 내용을 공유하려고 합니다.\n\n세팅\n\n우리의 데이터 처리에는 두 가지 유형의 실행 프로세스가 포함되어 있었습니다:\n1. 병렬 실행: ADF에서 동시에 트리거된 여러 노트북.\n2. 순차 실행: 종속성으로 인해 특정한 순서로 트리거된 노트북들이 서로 뒤이어 실행됩니다.\n\n<div class=\"content-ad\"></div>\n\n최초 계획\n\n병렬 실행:\n- 이전 방법: 대화식 클러스터 사용.\n- 새 방법: 작업 클러스터로 전환.\n- 이유: 각 작업 클러스터의 실행 시간이 모든 노트북이 동시에 트리거되기 때문에 동일했습니다.\n\n순차 실행:\n- 이전 방법: 대화식 클러스터 사용.\n- 새 방법: 작업 클러스터 사용 시도 중.\n- 도전: 각 작업 클러스터의 실행 시간이 누적되며, 노트북 세트마다 약 세 분이 추가됩니다. 십 개 세트가 있으면 이 과정에 추가로 30분이 소요되므로 순차 실행에 대해서는 계속 대화식 클러스터를 사용했습니다.\n\n스핀 업 시간을 줄이기 위해 컴퓨팅 풀 사용을 고려했지만, 이는 비용 절감이라는 주요 목표와 부합하지 않았습니다.\n\n<div class=\"content-ad\"></div>\n\n이주 작업\n\n우선, 동일한 구성을 가진 인터랙티브 클러스터 5개가 있었습니다. 비용 효율성을 위해:\n- 병렬 실행을 작업 클러스터로 옮겼습니다.\n- 순차적 실행을 위해 인터랙티브 클러스터 3개를 해체하여 2개만 남겼습니다.\n\n우리 클러스터 구성:\n- 노드 유형: Standard_DS32_v3\n- 워커 노드: 2에서 20으로 자동 확장\n\n작업 클러스터에도 동일한 구성을 사용했습니다.\n\n<div class=\"content-ad\"></div>\n\n예상치 못한 결과\n\n첫 달에는 비용이 감소할 것으로 예상했지만, 뜻밖에도 비용이 40% 증가했습니다.\n\n비용 분석:\n- 이전 이주 후: 대화식 클러스터 월 비용 $26,000\n- 이주 후:\n  - 대화식 클러스터: 월 $16,000\n  - 작업 클러스터: 월 $18,000\n  - 총합: 월 $34,000\n\n해결책\n\n<div class=\"content-ad\"></div>\n\n비용 증가를 인식하여, 저희는 작업 클러스터를 재구성했습니다:\n1. Standard_DS16_v3:\n   - 결과: 작업 완료에 소요되는 시간은 동일했습니다.\n   - 비용: 월 $12,000으로 감소했습니다.\n\n2. Standard_DS8_v3:\n   - 결과: 작업이 추가 10분 소요되었습니다.\n   - 비용: 더욱 감소하였으며, 효율적인 작업 완료 시간을 유지했습니다.\n\n이 조정으로 성능을 희생하지 않고 비용을 크게 줄일 수 있었습니다.\n\n맺음말\n\n<div class=\"content-ad\"></div>\n\n우리의 대화형 클러스터에서 작업 클러스터로의 여정은 예상치 못한 변화로 가득찼어요. 처음에는 비용이 증가했지만, 작업 클러스터를 재구성함으로써 상당한 절약을 이뤄 냈어요. 우리의 경험은 성능과 비용을 최적화하기 위해 지속적으로 모니터링하고 구성을 조정하는 중요성을 강조합니다.\n\n다음 기사에서는 클러스터 구성을 변경해도 작업을 완료하는 데 걸리는 시간이 거의 변하지 않은 이유에 대해 자세히 다뤄볼 거에요.\n\n참고: 여기서 언급된 비용은 대략적인 수치이며 설명 용도로 사용되었습니다.\n\n더 많은 통찰력을 기대해주세요!","ogImage":{"url":"/assets/img/undefined_0.png"},"coverImage":"/assets/img/undefined_0.png","tag":["Tech"],"readingTime":2},{"title":"QGIS에서 Landsat 표면 반사 데이터 다루기","description":"","date":"2024-06-19 05:09","slug":"2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS","content":"\n\n표 정보로 형식을 변경합니다. \n\n표 정보는 Markdown 형식으로 변경할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n지구 탐사자(또는 원하는 데이터 저장소)에서 주문하세요.\n\n![이미지](/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_0.png)\n\nNDVI(및 기타 지수/계산)에 대해서는 표면 반사율 데이터를 사용하세요: Landsat Collection 2 Level-2\n\n진- 또는 거짓-컬러 이미지의 경우 래디언스(레벨-1) 또는 표면 반사율(레벨-2)이 모두 작동합니다(레벨-2가 서로 다른 시간과 지역에서 더 일관성 있지만, 흐림이나 구름이 있을 경우 아티팩트가 발생할 수 있습니다).\n\n<div class=\"content-ad\"></div>\n\n샘플 데이터셋이 필요하시다면, 2016년 5월 및 2023년 6월에 대해 인접한 두 장면으로부터 Landsat 데이터의 네 개 밴드를 업로드했습니다.\n\n데이터를 다운로드한 후 다음 명령어를 사용하여 QGIS로 가져오세요:\n\n레이어 ` 레이어 추가 ` 래스터 레이어 추가...\n\nNDVI 및 “표준” 위양색을 위해 B5 (근적외선), B4 (적색) 및 B3 (녹색)를 선택하세요. 그런 다음 추가를 클릭하세요\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_1.png)\n\n다중 스펙트럼(색상) 이미지를 만들려면 \"가상 래스터\"를 생성하세요.\n\n래스터 `기타` 가상 래스터 만들기...\n\n각 입력 파일을 별도의 밴드에 배치하는 것을 확인하세요 (이것은 중요합니다 — 그렇지 않으면 이미지가 단일 그레이스케일 밴드가 됩니다!)\n\n\n<div class=\"content-ad\"></div>\n\n\"…버튼을 사용하여 입력 레이어를 선택하세요.\n\n세 개의 밴드를 모두 선택하고, B5를 맨 위에, B4를 가운데에, B3를 가장 아래로 재배열하세요. 이렇게 하면 근적외선 = 빨강, 빨강 = 녹색, 초록 = 파랑의 밴드 순서가 설정됩니다.\n\n실행을 눌러주세요\n\n<img src=\"/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_2.png\" />\"\n\n<div class=\"content-ad\"></div>\n\n지금 이 시점에서 이 복합체의 이름을 바꾸고 저장하는 것이 좋은 생각입니다.\n\n이미지 이름을 마우스 오른쪽 버튼으로 클릭한 후 `내보내기 '다음으로 저장 ...'를 선택하십시오.\n\n출력 모드를 Raw data로 설정하십시오.\n\n원하는 폴더를 선택하고 파일 이름 옆에있는 ...을 클릭하여 이름을 입력하십시오.\n\n<div class=\"content-ad\"></div>\n\n압축 기능을 활성화하는 것도 좋은 아이디어입니다. (원시 데이터에는 높은 압축률을 선택하고, 렌더링된 이미지에는 낮은 압축률을 선택하세요)\n\n확인을 클릭하세요\n\n![이미지](/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_3.png)\n\n이미지 이름을 마우스 오른쪽 버튼으로 클릭한 후에 속성 '심볼'을 선택하세요\n\n<div class=\"content-ad\"></div>\n\n최소/최대 값 설정 확장\n\n누적 개수 설정을 선택하고, 범위를 2.0–98.0에서 0.1–99.9로 변경해주세요.\n\n선택 사항: 빨강, 녹색, 파랑에 대해 세 개의 최소값을 동일한 값으로 설정하고, 최대값도 빨강, 녹색, 파랑에 대해 동일한 값으로 설정해주세요. 표면 반사 데이터는 대기 효과가 제거된 백분율 값이며, 파장별 밝기 차이나 대기 산란을 조절할 필요가 없습니다.\n\n<img src=\"/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_4.png\" />\n\n<div class=\"content-ad\"></div>\n\n정확도를 \"실제 (느림)\"으로 설정한 후에 \"적용\"을 클릭하세요 (\"적용\"은 레이어 속성 창을 닫지 않고 결과를 미리 볼 수 있습니다). \"실제 (느림)\"은 전체 이미지의 모든 픽셀을 읽기 때문에 \"추정 (빠름)\"보다 조금 느릴 수 있지만 더 좋은 결과를 얻을 수 있다고 생각합니다.\n\n레이어 렌더링을 확장하여 (보이지 않는 경우 창을 아래로 스크롤하세요).\n\n감마를 1.8-2.2 사이의 값으로 설정한 후에 \"적용\"을 클릭하세요 (선호하는대로 설정하세요, 더 높은 숫자는 전체적으로 더 밝은 이미지를 만듭니다).\n\n메인 QGIS 창으로 돌아가려면 \"확인\"을 클릭하세요.\n\n<div class=\"content-ad\"></div>\n\n작업이 완료된 이미지를 GeoTIFF로 내보내려면, 먼저 레이어 팔레트에서 이미지 이름을 마우스 오른쪽 버튼으로 클릭한 다음 `Export Save As ...`를 선택하세요.\n\n출력 모드를 렌더링된 이미지로 설정해주세요.\n\n출력 폴더와 파일 이름을 선택하고, 저장 공간을 아낄 수 있는 만큼 Create Options 및 Low Compression(픽셀 당 8비트 이미지에 적합)을 확인해주세요.\n\n이미지를 저장하려면 OK를 클릭하세요!\n\n<div class=\"content-ad\"></div>\n\n여러 장면을 작업 중이라면, 인접 장면 및/또는 다른 날짜로 반복하거나 데이터를 가져와 다중 분광 파일을 만들어 방금 만든 스타일을 다른 장면으로 전송하세요. 새 파일을 저장하고 레이어 패널에 추가한 후, 2016 이미지에서 스타일을 복사/붙여넣기하세요:\n\n이미 조정한 래스터 레이어를 마우스 오른쪽 버튼으로 클릭하고 스타일 선택 ` 스타일 복사\n\n그런 다음 대상 레이어를 마우스 오른쪽 버튼으로 클릭하고 스타일 선택 ` 스타일 붙여넣기\n\n빛의 양과 대기 상황에 독립적인 표면 반사 데이터를 다루고 있기 때문에 같은 설정이 다른 시간과 다른 장소에서도 작동할 수 있습니다. (반사도 데이터는 계절과 날씨에 따라 변할 수 있으며, 각 장면은 개별적으로 보정되어야 합니다.) 그러나 이미지 간에 큰 변화가 있는 경우에는 사용하는 데이터를 최소값 및 최대값 계산에 신중히 선택해야 합니다. 눈이나 구름, 그림자가 있는 구름은 맑은 장면과 비교할 때 값이 크게 변할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# Raster 계산기를 사용하여 NDVI 계산하기\n\n저는 Normalized Difference Vegetation Index (NDVI)를 예시로 사용하고 있습니다. 이는 간단하고 널리 사용되는 지표이지만, 다른 분광 지수를 계산하는 데도 동일한 프로세스가 적용됩니다. 수식만 다를 뿐입니다. (Index Database는 산불 심각도부터 수질까지 모든 항목에 대한 지표를 찾기에 좋은 장소입니다. 다른 것을 실험해보고 싶다면 이용해보세요. 선택한 지표가 무엇이든, 올바른 단위를 얻기 위해 스케일링(0.000275)과 오프셋(-0.2) 요소를 적용하고 추가 계산을 수행하기 전에 기억하세요.)\n\n같은 표면 반사 데이터로 시작하되, 근적외선과 적외선 데이터만 필요합니다 (Landsat 8 및 9의 밴드 5와 4).\n\nRaster `Raster Calculator…`을 선택하세요.\n\n<div class=\"content-ad\"></div>\n\n그런 다음 다음 방정식을 입력하십시오 (따옴표로 묶인 부분은 계산에 사용되는 밴드를 나타냅니다. - 실제 데이터에 따라 달라질 수 있습니다).\n\n((“LC08_L2SP_157039_20160518_20200907_02_T1_SR_B5@1” * 0.0000275 - 0.2) -(“LC08_L2SP_157039_20160518_20200907_02_T1_SR_B4@1” * 0.0000275 - 0.2))/((“LC08_L2SP_157039_20160518_20200907_02_T1_SR_B5@1” * 0.0000275 - 0.2) + (“LC08_L2SP_157039_20160518_20200907_02_T1_SR_B4@1” * 0.0000275 - 0.2))\n\nNDVI 알고리즘은 보통 (NIR — Red)/(NIR + Red)로 구성되지만 추가적인 용어가 있는 이유는 무엇인가요? 16비트 정수 값으로 저장된 데이터를 반사도로 변환하여 스케일을 맞추어야 하기 때문입니다. 보통 반사도는 0에서 1까지의 범위에 있습니다. (표면 반사 알고리즘에서의 지나친 보정으로 값이 0 미만으로 떨어지고 특정 지형 (해천을 향한 산의 경사면)은 1 이상의 값으로 이끌 수 있기 때문에 이상치가 가능하지만 일반적으로 나타나지 않습니다.) 스케일 계수인 0.0000275와 오프셋인 0.2는 모든 Landsat 8 & 9 버전 2 데이터에서 일관적이지만 Sentinel-2와 같은 다른 이미지 원본에서는 달라질 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_5.png)\n\n<div class=\"content-ad\"></div>\n\n계산을 실행하기 전에, 출력이 저장될 폴더를 선택하고 \"Output Layer: ...\"라는 이름으로 출력 파일을 지정해야 합니다.\n\n그런 다음 NDVI 값을 계산하려면 확인 버튼을 클릭하세요. 이 값들은 새로운 레이어로 나타날 것입니다. 기본적으로 데이터는 씬에서 발견된 최소 및 최대 값을 기준으로 조정된 그레이스케일로 표시됩니다. 이것은 읽기가 어렵고, 크게 영감을 주는 것이 아닐 수 있으므로, 아마도 QGIS에서 컬러 램프라고 불리는 팔레트를 적용하고 싶을 것입니다.\n\n이미지 이름을 마우스 오른쪽 버튼으로 클릭한 후, `Symbology`를 선택하세요.\n\n<div class=\"content-ad\"></div>\n\n렌더 타입을 싱글밴드 의사 색상으로 변경해주세요.\n\n최솟값을 0으로, 최댓값을 0.8로 설정해주세요 (이 값은 NDVI의 기본값으로, -1부터 +1까지의 범위를 가지지만, 식물이 자라는 지역은 0 아래로 내려가거나 0.8을 넘을 일이 거의 없습니다.)\n\n해석하기 쉬운 지각적 팔레트를 채택해 색상 램프를 선택해주세요.\n\nQGIS에 여러 장면을 로드한 경우, 동일한 표현 매개변수를 각각에 적용하기 위해 스타일을 복사하여 붙여넣는 방법을 사용하시면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n이미 스타일링한 레이어에서 마우스 오른쪽 버튼을 클릭하고 스타일 ` 스타일 복사를 선택하여 데이터셋에서 설정을 복사한 다음 대상 레이어를 마우스 오른쪽 버튼으로 클릭하고 스타일 ` 스타일 붙여넣기를 선택하여 설정을 적용할 수 있습니다.\n\n멀티 스펙트럼 컴포지트의 스케일링 및 감마 설정에도 동일한 방법이 적용되며, 이는 특히 표면 반사 데이터를 다룰 때 효과적입니다.\n\n# 보너스: Open Street Map (벡터) 오버레이 추가\n\nQGIS에서 이미 래스터 데이터를 처리하고 스타일을 지정한 후 QuickOSM 플러그인을 사용하여 Open Street Map (OSM)의 벡터 데이터를 추가할 수 있습니다. OSM 및 QuickOSM은 깊은 주제이므로 여기서는 시작하는 데 도움이 될만한 팁 몇 가지만 제공하겠습니다.\n\n<div class=\"content-ad\"></div>\n\nQGIS에서 플러그인을 추가하려면 Plugins - Manage and Install Plugins...를 선택하세요.\n\n<img src=\"/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_7.png\" />\n\n플러그인을 로드하려면 OSM 또는 QuickOSM을 검색하고, 해당 플러그인을 선택한 후 설치 플러그인을 클릭하세요.\n\n그러면, Vector 메뉴를 통해 OSM 데이터를 추가할 수 있습니다: Vector - QuickOSM - QuickOSM\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_8.png\" />\n\n데이터를 찾으려면 넓은 특징 카테고리(경계, 고속도로 또는 자연과 같은)에 해당하는 값(행정, 국립공원 또는 정치와 같은 더 구체적인 카테고리)를 입력하십시오. 이렇게 하면 빠르게 복잡해질 수 있습니다(궁금하시다면 모든 OSM 기능에 대한 설명이 여기 있습니다). 그래서 여러 카테고리를 하나의 검색으로 결합하는 프리셋 기능을 사용하는 것을 권합니다. OSM은 지도와 함께 데이터베이스이기도 한데 머리가 아프게 만들 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_9.png\" />\n\nOSM에서 검색 및 다운로드를 하기 전에 검색 영역을 제한하는 마지막 단계입니다. 지도에서 관심 영역으로 사용할 레이어를 선택하는 것이 좋은 접근 방식이라고 생각합니다. 기능 목록 아래에 있는 드롭다운 메뉴 In을 선택하세요. Layer Extent로 변경하고 작업 중인 Landsat 씬을 선택하면 해당 레이어의 가장자리와 교차하는 데이터로 검색이 제한됩니다.\n\n<div class=\"content-ad\"></div>\n\n데이터베이스를 검색하고 데이터를 다운로드하려면 쿼리 실행을 클릭한 후 벡터를 따로 점, 선 및 폴리곤 레이어로 추가하세요.\n\n![image](/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_10.png)\n\n일반적으로 저는 데이터를 처리하는 도구로 QGIS를 사용하고, 포토샵 및/또는 일러스트레이터에서 정리하기 전에 모든 오버레이 벡터, 장식 및 주석이 포함된 고해상도 이미지를 내보낼 수 있는 것이 도움이 됩니다.\n\n기본적으로 QGIS는 화면에 표시된 줌 수준 및 바운딩 박스에서 내보냅니다. 전체 해상도로 내보내려면 레이어를 마우스 오른쪽 버튼으로 클릭한 후 네이티브 해상도로 확대(100%)를 선택하세요.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_11.png)\n\n데이터의 전체 범위로 경계를 설정하려면 Project ` Import/Export ` Export Map to PDF …(벡터를 유지하기 위함) 또는 Export Map to TIFF …(모든 것을 픽셀로 래스터로 변환하기 위함)를 클릭하세요. 그런 다음 Layer에서 Calculate & drop-down 목록에서 내보내고자 하는 레이어를 선택하세요. QGIS는 선택한 레이어의 크기에 맞는 전체 해상도의 이미지를 렌더링 및 내보내며 지리 위치 정보와 함께 완성됩니다. (적어도 GeoTIFF를 위해, 제 설치에서는 GeoPDF 옵션이 작동하지 않습니다.)\n\n도움이 되었다면, 연락을 유지하고 싶거나, 원격 감지 및 지도 제작에 대한 실습에 관심이 있다면 LinkedIn을 통해 연락하시거나, robertbsimmon@gmail.com으로 이메일을 보내거나 제 포트폴리오를 확인해보세요.\n","ogImage":{"url":"/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_0.png"},"coverImage":"/assets/img/2024-06-19-WorkingWithLandsatSurfaceReflectanceDatainQGIS_0.png","tag":["Tech"],"readingTime":8},{"title":"차트 전쟁 - 쌓인 막대 차트 대 히트맵","description":"","date":"2024-06-19 05:07","slug":"2024-06-19-ChartWarsStackedBarChartvsHeatmap","content":"\n\n## 빠른 성공 데이터 과학\n\n![이미지](/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_0.png)\n\n빠르게 하나의 숫자 변수를 공유하는 두 가지 범주 변수가 있을 때, 그들을 비교할 수 있는 가장 좋은 시각화 방법은 무엇인가요?\n\n\"스택된 막대 차트\"라고 생각했다면, 그것은 이해할 수 있어요. 어쩌면 시간이 부족한 상황이었으니까요.\n\n<div class=\"content-ad\"></div>\n\n스택된 막대 차트는 금방 혼잡해지기 쉽습니다. 여기에는 미국 노동통계국의 공개 도메인 데이터를 사용한 예시가 있습니다. 두 가지 범주형 변수는 소비 유형(예: 식품 및 교통)과 연령대입니다. 수치 변수는 전체 지출의 백분율입니다.\n\n![차트](/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_1.png)\n\n가장 큰 전체 지출을 쉽게 파악할 수 있지만, 각 연령대별로 해석하는 것은 돋보기를 사용해도 어려울 수 있습니다. 또한 x축이 100%를 초과하므로 혼란스러울 수 있습니다.\n\n그룹화된 막대 차트를 사용하면 조금 더 나아지지만 여전히 읽기 어려울 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_2.png\" />\n\n이런 차트를 보면 제작자가 무엇을 하려고 했는지 알았는지, 아니면 의도적으로 데이터를 혼란스럽게 만들려고 했는지 궁금해집니다.\n\n대안으로는 히트맵이 있습니다. 히트맵은 색상을 사용하여 2차원 공간에서 값을 보여주는 데이터 시각화 기술입니다. 이전 데이터를 히트맵으로 표현한 것은 다음과 같습니다:\n\n<img src=\"/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_3.png\" />\n\n<div class=\"content-ad\"></div>\n\n히트맵은 막대 차트보다 여러 가지 개선 사항을 가지고 있어요. 우선, 환영 느낌이 들어서, 복잡한 막대 차트보다 혐오스럽지 않아요. 각 셀의 크기가 같아서 작은 항목이 눈에 잘 띄게 축소되지 않아요. 실제 값들을 게시할 공간도 있어요.\n\n한눈에 가장 큰 지출을 파악할 수 있고, 세부 등급은 명백해요. 상당한 차이점들이 두드러지고, 색이 변하지 않는 행들은 연령 그룹 전체에서 지출 수준이 비슷했음을 의미해요.\n\n주택이 가장 큰 지출이라는 것과 평생에 걸쳐 일정한 것인 것을 쉽게 알 수 있어요. 음식 역시 일정해요. 이동 수단은 점차 청소년 시기부터 고령 시기까지 천천히 줄어들어요; 의료비는 대략 세 배; 보험료는 급격히 낮아지고; 그리고 현금 기부(자녀나 자선 단체에)는 꾸준히 증가해요.\n\n다음 섹션에서, 저는 Python, pandas 및 Plotly Express를 사용해 이 히트맵을 어떻게 생성했는지 확인할 거에요.\n\n<div class=\"content-ad\"></div>\n\n# 히트맵 코드\n\n다음 코드는 CSV 파일을 팬더스 데이터프레임으로 로드한 다음, Plotly Express를 사용하여 히트맵으로 플롯합니다. 입력 데이터는 미국 인구조사국이 편성한 2021년 소비자 지출 조사의 요약판입니다.\n\n## 라이브러리 가져오기 및 파일 로드\n\n이 프로젝트에서는 외부 라이브러리 팬더스와 Plotly Express를 사용할 것입니다. 이전 링크에서 설치 지침을 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nGIST에서 URL 주소를 사용하여 CSV 파일을 로드할 거예요. 그리고 DataFrame의 인덱스를 \"Expenditure Type\" 열로 설정해서 편하게 플로팅할 거예요.\n\n```js\nimport pandas as pd\nimport plotly_express as px\n\n# CSV 파일을 DataFrame으로 읽기:\ndf = pd.read_csv('https://bit.ly/3RsVQkF', header=1)\ndf.set_index('Expenditure Type', inplace=True)\ndisplay(df)\n```\n\n<img src=\"/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_4.png\" />\n\n각 카테고리의 총 지출 비율을 나타내는 값이에요. 다시 한 번 언급하자면, 약간의 작은 카테고리는 제외했기 때문에 100%에 완전히 더해지지는 않을 거예요.\n\n<div class=\"content-ad\"></div>\n\n## 히트맵 그리기\n\nPlotly Express는 Matplotlib의 Seaborn과 같은 라이브러리인 Plotly 라이브러리입니다: 더 친절하고 부드러운 플로팅 선택지입니다. Plotly Express를 사용하면 최소한의 코드로 다양한 시각화를 만들 수 있습니다.\n\n다음 코드는 주석이 있는 셀 값이 추가되어 일반적인 Plotly Express의 코드보다 더 많은 양의 코드로 구성되어 있습니다. 또한 이전에 사용하던 노란색-주황색-갈색 (YlOrBr) 스케일 대신 회색 색상 스케일을 사용하고 있습니다.\n\n```js\n# 히트맵 생성:\nfig = px.imshow(df, \n                labels=dict(x=\"연령대\", \n                            y=\"지출 유형\", \n                            color=\"지출 비율\"),\n                color_continuous_scale='Greys',\n                title='<br><br>\\\n                       2021 연령대별 지출 (비율)')\n\n# 셀 값 주석 추가:\nfor i, expenditure_type in enumerate(df.index):\n    for j, age_bracket in enumerate(df.columns):\n        fig.add_annotation(x=j, y=i, \n                           text=str(df.loc[expenditure_type, age_bracket]), \n                           showarrow=False)\nfig.update_annotations(font=dict(family=\"Arial\", \n                                 size=12, \n                                 color=\"firebrick\"))\n\n# 그림 크기 및 여백 설정:\nfig.update_layout(width=600, height=1000, \n                  margin=dict(l=20, r=10, t=20, b=20))\n\n# 축 레이블을 굵게 설정:\nfig.update_yaxes(tickfont_family=\"Arial Black\")\nfig.update_xaxes(tickfont_family=\"Arial Black\")\n\n# 색상 스케일 끄기:\nfig.update(layout_coloraxis_showscale=False)\n```\n\n<div class=\"content-ad\"></div>\n\n히트맵은 Plotly Express의 imshow() 메서드에 의해 생성됩니다. 해당 인수에는 데이터프레임, x-y 라벨 및 히트맵 셀 색상(딕셔너리 데이터 형식으로 전달), 색상 스케일 및 제목이 포함됩니다.\n\n제목 문자열의 시작에 HTML 줄 바꿈 문자(`br`)이 있는 것을 주목해주세요. 이 문자가 없으면 Plotly Express의 기본값으로 제목이 예기치 않게 히트맵 행렬 위에 높게 나타납니다. 누군가 이에 대해 불평해야 합니다.\n\n여기서 가장 간단하지 않은 코드는 셀을 주석으로 설명하기 위해 사용된 for 루프입니다. 셀의 값에 텍스트를 추가하는 것은 선택 사항이며, 색상 스케일이 이를 처리하지만, 저는 그래픽을 크게 향상시킨다고 생각합니다. 두 개의 범주형 열을 반복하고 Plotly의 add_annotations() 메서드를 사용하여 값을 게시하는 프로세스입니다.\n\n나머지 코드는 플롯을 형식화하고 주석 덕분에 더 이상 필요하지 않은 색상 스케일을 해제하는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n다음은 회색-빨강 색상 체계의 히트맵입니다:\n\n![히트맵](/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_5.png)\n\nPlotly Express는 팝업 호버 창과 같은 유용한 기능이 있는 동적 시각화를 제공합니다. 이 창은 마우스 커서가 히트맵 셀과 같은 선택된 그래픽 요소 위를 지날 때 정보를 표시합니다:\n\n![동적 시각화](/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_6.png)\n\n<div class=\"content-ad\"></div>\n\n이 hover 창들은 색상이나 주석이 해석하기 어려울 때 명확성을 더해줍니다. 또한 시각화에 직접적으로 포함되지 않은 DataFrame 열의 값과 같은 추가 정보를 표시할 수 있습니다.\n\n# 요약\n\n히트맵은 데이터 포인트의 크기를 시각화하기 위해 이차원 그리드와 색상 그라데이션을 사용합니다. 패턴과 상관 관계를 드러내고 핫스팟을 식별하며 여러 변수를 동시에 비교하는 데 유용합니다.\n\n다른 시각화인 쌓인 막대 차트와 같은 경쟁 시각화는 지나치게 복잡해질 수 있는 반면, 히트맵은 접근하기 쉽습니다. 모든 셀이 동일한 크기이므로 작은 기여도가 \"줄어들지 않고\" 모든 데이터 포인트가 명확하게 주석 처리될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nPlotly Express에는 pandas DataFrame에서 쉽게 heatmap을 생성하는 내장 메소드가 있습니다. 이 hover 창 기능을 사용하면 표를 조사하고 DataFrame에 저장된 추가 데이터를 표시할 수 있습니다.\n\n# 데이터로 이야기하기\n\n가장 중요한 데이터 시각화 결정은 올바른 차트 유형을 선택하는 것입니다. 이 결정에 어려움이 있는 경우, 'From Data to Viz' 웹사이트와 'Storytelling with Data' 차트 안내를 방문해보세요. 두 사이트 모두 데이터 과학자들에게 유용한 리소스입니다.\n\n# 더 나은 쌓인 막대 차트\n\n<div class=\"content-ad\"></div>\n\n스텍 바 차트 모두 좋은 것은 아닙니다. \"Marimekko\" 차트라는 변형은 꽤 매력적일 수 있어요:\n\n# 감사합니다!\n\n읽어 주셔서 감사합니다. 앞으로 더 많은 퀵 서클러스 데이터 과학 프로젝트를 위해 저를 팔로우해 주세요.","ogImage":{"url":"/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_0.png"},"coverImage":"/assets/img/2024-06-19-ChartWarsStackedBarChartvsHeatmap_0.png","tag":["Tech"],"readingTime":6},{"title":"데이터 분석가 포트폴리오 프로젝트SQL  Power BI","description":"","date":"2024-06-19 05:05","slug":"2024-06-19-DataAnalystPortfolioProjectSQLPowerBI","content":"\n\n## 뉴욕 시티 Airbnb 리스트\n\n![이미지](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_0.png)\n\n에어비앤비는 2008년부터 짧은 기간과 장기 체류 및 경험을 위한 온라인 마켓플레이스로 활동하는 미국 회사입니다. 에어비앤비는 주택 소유주와 부동산 관리자가 싱글 룸, 아파트부터 전체 집까지 다양한 숙박 옵션을 나열하도록하여 숙박 업계의 모습을 완전히 바꿨습니다.\n\n나는 뉴욕 시티의 Airbnb 리스트 데이터를 탐색해보고 몇 가지 통찰을 발견해보려고 합니다.\n\n<div class=\"content-ad\"></div>\n\n문제를 정의하는 것이 첫 번째 단계입니다. 다루어야 할 비즈니스 목표는 다음과 같습니다:\n\n1. 다양한 호스트와 지역에 대해 어떤 것을 배울 수 있나요?\n\n2. 객실 분포는 어떠한가요?\n\n3. 어떤 호스트가 가장 바쁘고 그 이유는 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n4. 다른 지역 간의 교통량에 뚜렷한 차이가 있나요? 이에 대한 이유가 무엇일 수 있습니까?\n\n나 자신을 이해관계자로 생각할 때, 위의 비즈니스 목표를 기반으로 추세를 파악하고 싶습니다.\n\n## 데이터 수집\n\n통찰력을 얻기 위해, 데이터가 필요합니다! 나는 캐글(Kaggle)에서 데이터를 다운로드했습니다 (뉴욕 시티 에어비앤비 공개 데이터).\n\n<div class=\"content-ad\"></div>\n\n이 데이터셋에는 id, name, host_id, host_name, neighbourhood_group, neighbourhood, latitude, longitude, room_type, price, minimum_nights, number_of_reviews, last_review, reviews_per_month, calculated_host_listings_count, availability_365 등 총 16개 열이 있고, 48,000행 이상의 데이터가 포함되어 있습니다.\n\n이 공개 데이터셋은 에어비앤비의 일부이며, 원본 소스는 해당 웹사이트에서 확인할 수 있습니다.\n\n## 데이터 가져오기\n\n이 데이터셋은 CSV 형식으로 다운로드했습니다. MySQL 프로젝트에서 작업 중이므로 MySQL에 데이터를 가져와야 합니다. MySQL로 데이터를 가져오는 방법은 다양합니다.\n\n<div class=\"content-ad\"></div>\n\n- 스키마를 생성한 후 해당 스키마 이름 아래의 테이블을 마우스 오른쪽 버튼으로 클릭하고 \"테이블 가져오기 데이터 마법사\" 옵션을 선택하세요. csv 파일 경로를 지정하고 다음을 클릭하세요. 새 테이블을 생성하거나 기존 테이블을 사용할 수 있습니다. 데이터가 MySQL로 쉽게 가져와집니다.\n- 다음으로 LOAD DATA 문을 사용하는 방법이 있습니다. 데이터베이스에 연결한 후 테이블을 만들고 LOAD DATA 문을 실행하세요. CSV 파일 내용이 MySQL로 가져와집니다.\n\n```js\nLOAD DATA INFILE '파일/경로'\nINTO TABLE 테이블_이름\nFIELDS TERMINATED BY ','\nLINES TERMINATED BY '\\n'\nIGNORE 1 ROWS;\n```\n\n일부 날짜 형식 오류로 인해 LOAD DATA 문이 다릅니다. 먼저 \"airbnb\"라는 스키마를 생성했습니다. 해당 데이터베이스 아래에 \"airbnb_listings\" 테이블을 만들었습니다.\n\n![이미지](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_1.png)\n\n<div class=\"content-ad\"></div>\n\n데이터베이스와 테이블을 생성한 후에는 CSV에서 MySQL로 데이터를 가져와야 합니다. 데이터 세트가 정리되지 않았기 때문에 LOAD DATA 문이 다소 까다로울 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_2.png)\n\n'@variable' — 데이터를 사용자 변수로 로드합니다.\n\nNULLIF — 빈 문자열을 NULL로 변환합니다.\n\n<div class=\"content-ad\"></div>\n\n'last_review'에 대한 CASE 문을 사용했습니다. 'last_review' 변수가 빈 문자열인 경우 NULL 값으로 설정됩니다. 다음 조건은 문자열이 'dd-mm-yyyy' 패턴과 정확히 일치하는지 확인합니다. 날짜가 dd-mm-yyyy 형식이면 STR_TO_DATE를 사용하여 변환합니다. 다음 조건은 문자열이 'yyyy-mm-dd' 패턴과 정확히 일치하는지 확인합니다. 날짜가 'yyyy-mm-dd' 형식이면 STR_TO_DATE를 사용하여 변환합니다. 위의 어떤 조건도 충족하지 않으면 NULL로 설정됩니다.\n\n<img src=\"/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_3.png\" />\n\n데이터 가져오기가 성공적으로 완료되었습니다! 다음으로 데이터를 처리하고 정리하여 정확한 결과를 얻어야 합니다. 지저분하고 일관성이 없는 데이터를 사용하면 부정확한 통찰력을 얻게 됩니다.\n\n## 데이터 정리\n\n<div class=\"content-ad\"></div>\n\n데이터 클리닝은 데이터 분석에서 매우 중요합니다.\n\n자세히 살펴봅시다!\n\n중복 제거\n\nMySQL 데이터베이스의 데이터 세트에서 중복 값을 제거하려면 먼저 특정 열의 유사한 값이 있는 행을 찾아 중복 행을 식별해야 합니다. 추가로 발생한 행을 삭제하여 각 중복 행의 발생을 하나로 줄입니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 Markdown 형식으로 테이블 태그를 수정한 내용입니다.\n\n\n![이미지](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_4.png)\n\n중복 행의 각 파티션별로 'id'를 선택하고 각 행에 번호를 할당하는 서브쿼리를 생성했습니다. 이 테이블에는 중복 된 행이 없습니다.\n\n결측치/NULL 값 제거\n\n- 호스트 이름이 NULL 인 행을 삭제했습니다. 나에게는 null 값이 있는 호스트 이름들은 중요하지 않다고 생각합니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n![테이블](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_5.png)\n\n테이블에서 행을 제거하기 위해서는 삭제 문을 사용합니다. 이 쿼리에서는 모든 null 값을 가진 호스트 이름이 제거되었습니다. null 값을 가지는 행은 21개 있습니다.\n\n2. 'last_review' 및 'reviews_per_month' 열에는 10k+ 개의 NULL 값을 가진 행이 있습니다. 데이터를 살펴본 결과, 이러한 값이 null인 이유는 호스트가 리뷰를 받지 않았기 때문입니다. 따라서 'number_of_reviews' 열이 0입니다.\n\n![테이블](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_6.png)\n\n\n<div class=\"content-ad\"></div>\n\n널 값 모두 제거하는 건 좋은 선택이 아닙니다. 나는 대신 보완과 플래깅을 결합할 것이에요.\n\n'last_review'의 경우, 가장 최근의 리뷰 날짜 또는 '2000-01-01'과 같은 플레이스홀더 날짜로 널 값을 대체할 수 있어요. 'reviews_per_month'의 경우, 해당 열의 평균 또는 중앙값을 사용할 수 있어요. 나는 해당 열의 평균을 사용할 거에요.\n\n플래깅은 원래 값이 널인 행을 플래그하는 새 열을 추가하는 과정이에요. 이는 나중에 분석에 유용할 수 있어요. 나는 'last_review_null'과 'reviews_per_month_null'이라는 새 열을 만들어 원래 값이 널인 행을 플래그할 거에요.\n\n![이미지](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_7.png)\n\n<div class=\"content-ad\"></div>\n\n여기 작동 방식을 보여드리겠습니다!\n\n![이미지](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_8.png)\n\n이제 데이터가 깨끗하고 일관적입니다. 분석을 시작해보겠습니다. 위에서 언급한 질문에 대한 답을 찾아보겠습니다.\n\n## 데이터 분석\n\n<div class=\"content-ad\"></div>\n\n이해관계자가 해결하고 싶어하는 첫 번째 질문은 \"다른 호스트들과 지역에 대해 무엇을 배울 수 있을까요?\"\n\n![이미지1](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_9.png)\n\n![이미지2](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_10.png)\n\n가장 많은 숙박 시설을 보유한 호스트는 Michael로, 418개의 숙박 시설을 보유하며 평균 평점은 26.52입니다. Williamsburg의 브루클린 이웃 지역은 대략 3919개의 숙박 시설이 있으며 평균 가격은 $143.8입니다.\n\n<div class=\"content-ad\"></div>\n\n두 번째 질문은 \"객실의 분포는 무엇인가요?\"입니다.\n\n![image](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_11.png)\n\n대다수의 관광객이 \"전체집/아파트\"를 선호합니다(대략 25400명). 그 다음으로는 약 22314명의 \"개인실\"을 선호합니다. 사람들은 \"공용 공간\"을 예약하는 경우가 적습니다. 이 정보는 임대용으로 제공되는 다양한 객실 유형의 분포를 이해하는 데 도움이 됩니다.\n\n세 번째 질문은 \"가장 바쁜 호스트는 누구이며 그 이유는 무엇인가요?\"입니다.\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_12.png)\n\n가장 바쁜 호스트는 \"Nalicia\"로 월평균 리뷰 수가 약 18.12정도로 해당 지역에서 매우 인기가 있다는 것을 의미합니다. 그 다음으로 \"Dona\"가 월평균 13.9 리뷰를 받았습니다.\n\n네 번째 질문은 \"다른 지역 간 교통량에 뚜렷한 차이가 있는가 있으며 그 이유는 무엇일까요?\"\n\n![image](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_13.png)\n\n<div class=\"content-ad\"></div>\n\n가장 많은 트래픽이 있는 동네는 \"이스트 엘머스트\"인데요, 월평균 후기 개수가 4.56개입니다. 이스트 엘머스트가 가장 많은 트래픽을 가지고 있는 이유는 여러 가지가 있을 수 있습니다. 가능한 이유로는 인기가 많거나 높은 수요가 있는 지역에 위치해 있어 더 많은 방문객과 잠재적인 손님들을 유치하는 것일 수도 있습니다. 그리고, 이스트 엘머스트가 이전 손님들로부터 긍정적인 후기와 추천을 받았기 때문에 동네에 머무르는 사람들이 더 많아져서 트래픽이 증가할 수 있습니다.\n\n## 대시보드\n\n![대시보드](/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_14.png)\n\n## 주요 인사이트\n\n<div class=\"content-ad\"></div>\n\n서로 다른 호스트 및 지역에 대한 통찰:\n\n나리시아는 월 평균 후기 18.1개로 선두를 달리고 있으며, 도나(14.0), 에이슬링(13.4), 말리니(13.2), 애나벨(13.0)이 그 뒤를 이었습니다. 이는 나리시아가 탁월한 서비스를 제공하거나 손님들이 호감을 갖는 독특한 숙소를 제공하고 있을 수 있다는 것을 시사합니다. 윌리엄스버그가 3.9천개로 가장 많은 숙소를 보유하고 있으며, 그 뒤를 베드포드-스테이븐턴트(3.7천), 할렘(2.7천), 부시윅(2.5천), 그리고 어퍼 웨스트 사이드(2.0천)가 이었습니다. 이러한 지역들의 인기는 위치, 문화적 의미, 또는 가격 등의 이유로 해석될 수 있습니다.\n\n객실 분포에 대한 통찰:\n\n집/아파트 전체가 숙소의 51.97%를 차지하고, 개인실이 45.66%, 공용실은 2.37%에 그칩니다. 이 분포는 사생활과 공간에 대한 선호도를 나타내며, 집 전체와 개인실이 대다수를 차지하고 있음을 시사합니다.\n\n<div class=\"content-ad\"></div>\n\n가장 바쁜 호스트와 이유에 대한 통찰:\n\n평균 월별 리뷰를 기준으로, Nalicia가 가장 바쁜 호스트입니다. 높은 리뷰 수는 일반적으로 많은 게스트의 이용과 만족을 나타내며, Nalicia는 많은 게스트를 끌어들이는 것뿐만 아니라 만족시키고 있다는 것을 시사합니다.\n\n다른 지역 간 트래픽 차이와 가능한 이유에 대한 통찰:\n\nEast Elmhurst가 4.6으로 선두를 달리고 있으며, 이어서 Silver Lake와 Springfield Gardens(모두 4.3) 그리고 Rosebank와 Huguenot(모두 3.8)가 뒤를 따르고 있습니다. 이러한 지역의 높은 트래픽은 관광명소나 공항과의 근접성, 전반적인 가격 대비 편의성 등 여러 요인으로 인한 것일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 추천사항\n\n- 고성능 호스트 및 지역에 집중: 고밀도 이웃 지역에 위치한 호스트들을 장려하여 그들의 위치 장점을 강화할 수 있도록 품질을 유지하거나 향상시키기를 권장합니다. \nNalicia와 같은 최고 호스트의 인사이트를 공유하여 다른 사람들이 서비스를 개선할 수 있도록 돕습니다.\n- 마케팅 및 전략 개선: Williamsburg와 Bedford-Stuyvesant와 같은 고리스팅 지역에서의 마케팅 노력을 강화하여 더 많은 손님을 유치합니다.\n- 호스트 지원: 교통량이 적은 지역에 위치한 호스트들을 위해 집중 지원과 교육을 제공하여 경쟁력을 향상하도록 합니다. Top 호스트들의 데이터 및 성공 요인을 다른 이들과 공유하여 서비스를 향상시키도록 돕습니다.\n- 상품 다양화: 시장 조사에 따르면 필요성이 있을 경우, 이집트룸과 같이 보조되는 공유 공간의 종류에 대한 다양성을 촉진합니다.\n\n보이라~~!\n\n이것이 에어비앤비 리스트 데이터 프로젝트에 관한 모든 것입니다. 이제 이해당사자는 제시된 인사이트와 권장 사항에 대해 실천할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n제 세션을 읽어주셔서 감사합니다! 피드백이나 제안이 있다면 자유롭게 남겨주십시오. 데이터 여정을 즐기시길 바랍니다!\n\n전문분야는 Excel, SQL, Tableau, Power BI, 그리고 R을 활용한 입문 레벨 프리랜서 데이터 분석가입니다. 흥미로운 대시보드와 프레젠테이션을 제작합니다. shana.nasrin2601@gmail.com으로 고용해주세요.","ogImage":{"url":"/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_0.png"},"coverImage":"/assets/img/2024-06-19-DataAnalystPortfolioProjectSQLPowerBI_0.png","tag":["Tech"],"readingTime":8},{"title":"파이썬 Streamlit과 GPT4 UNHCR 난민 데이터 매핑 방법","description":"","date":"2024-06-19 05:02","slug":"2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData","content":"\n\n\n\n![Python Streamlit](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_0.png)\n\n파이썬 Streamlit은 상호 작용적인 웹 인터페이스를 만드는 놀라운 프레임워크입니다. GPT-4는 빠르게 작동하는 Streamlit 코드를 만들어 줄 수 있어요.\n\n파이썬 Plotly와 함께 사용하면 데이터 시각화에 아름다운 지도와 차트를 손쉽게 만들 수 있어요.\n\n대부분의 경우, 제가 증명해줄 필요가 있죠. 그러니까 제가 어떻게 보여줄지 기대해 주세요.\n\n\n<div class=\"content-ad\"></div>\n\n웹 인터페이스에서 CSV 데이터 세트를 사용하여 다양한 데이터 시각화를 만들 수 있습니다. 추가로 슬라이더 및 드롭다운 메뉴와 같은 상호 작용 레이어를 여러 개 추가할 수도 있습니다. 이 모든 작업은 데이터세트와 GPT-4에 몇 가지 간단한 프롬프트만 필요합니다.\n\n그럼 데이터세트를 찾아보고 이를 실행해 봅시다.\n\n# 데이터 세트 — UNHCR 난민 데이터\n\nUNHCR(UN High Commission for Refugees)는 전 세계적으로 난민의 움직임에 대한 통계를 추적합니다.\n\n<div class=\"content-ad\"></div>\n\n데이터는 여기에서 자유롭게 액세스할 수 있어요.\n\n다운로드 페이지로 이동한 후에는 선택한 데이터에 대해 더 자세히 볼 수 있어요:\n\n![이미지](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_1.png)\n\n이 프로젝트에서는 각 난민의 출신 국가와 피난국을 검색해보겠어요.\n\n<div class=\"content-ad\"></div>\n\n이 데이터셋은 Streamlit/Plotly 코드 생성의 힘을 보여주는 완벽한 데이터셋입니다.\n\n이 데이터를 사용하여 난민 데이터를 보여주는 전 세계 지도를 만들 수 있습니다:\n\n- 출신 국가 - 피정국이 어디로 이동하고 있는지\n- 피정 국가 - 피정국이 어디에서 오고 있는지\n\n데이터셋을 다운로드하면 스프레드시트 형식으로 열어서 다루고 있는 내용을 확인할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_2.png)\n\n이 프로젝트에 관심 있는 데이터 필드는 다음과 같습니다:\n\n- 출신 국가 (3자리 ISO 코드 포함) - 망명을 찾는 사람이 어디에서 왔는지\n- 망명국 (3자리 ISO 코드 포함) - 실제로 망명을 찾는 사람이 있는 곳\n- 인정된 결정 - 망명을 찾는 사람이 수용되었는지 (국가별 숫자 합계)\n\n출신 국가와 망명 국가 모두 코로플레스 맵을 만드는 데 사용할 수 있는 3자리 ISO 코드가 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n이 정말 유용하네요! 맵 생성을 크게 간소화해줍니다.\n\n이제 GPT-4 프롬프트로 넘어가겠습니다!\n\n## 단계 1: 데이터셋 로드, GPT-4 분석을 위한 프롬프트\n\n먼저, 데이터셋에 있는 필드와 값에 대한 이해가 GPT-4에게 있는지 확인해야 합니다. 그러므로 먼저 파일을 채팅 창에 업로드하고 GPT-4의 분석을 요청해보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n![PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_3](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_3.png)\n\nGPT-4는 각 필드에 대한 설명을 답변합니다.\n\n![PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_4](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_4.png)\n\n간결함을 위해 데이터 시각화에 필요한 필드만 포함했습니다. GPT-4의 답변에서 데이터 세트의 필드에 대한 확실한 이해가 엿보입니다.\n\n<div class=\"content-ad\"></div>\n\n좋아요 — 이제 GPT-4에게 데이터 시각화를 위한 입력을 준비했습니다.\n\n# 단계 2: 첫 번째 지도 시각화 생성\n\n먼저, 우리는 망명국을 선택할 수 있는 지도를 만들고 싶습니다 — 망명 신청자의 출신 국가를 어디에서 오는지 확인할 수 있도록 해보세요.\n\nGPT-4에게 알려주세요: 제공된 데이터 세트를 사용하여 사용자가 드롭다운 메뉴에서 국가를 선택할 수있는 Streamlit 애플리케이션을 만들어주세요. 이 애플리케이션은 '인정 결정' 필드를 사용하여 출신 국가의 숫자를 보여주는 Plotly express 코로플레스 맵을 표시해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n결과 GPT-4에서 코드를 Markdown 형식으로 변경하였습니다:\n\n```python\nimport streamlit as st\nimport pandas as pd\nimport plotly.express as px\n\n# 데이터셋 불러오기\nfile_path = 'asylum-decisions.csv'  # 필요시 경로 업데이트\nasylum_data = pd.read_csv(file_path)\n\n# Streamlit 앱 생성\nst.title('Asylum Decisions Analysis')\n\n# 망신국가 선택을 위한 드롭다운 메뉴\ncountry_of_asylum = st.selectbox(\n    'Select a Country of Asylum:',\n    asylum_data['Country of asylum'].unique()\n)\n\n# 선택한 망신국가 기반으로 데이터 필터링\nfiltered_data = asylum_data[asylum_data['Country of asylum'] == country_of_asylum]\n\n# 출신국가별로 그룹화하고 인정된 결정 수 합산\ngrouped_data = filtered_data.groupby('Country of origin (ISO)').sum().reset_index()\n\n# 코로플레스 맵 생성\nfig = px.choropleth(\n    grouped_data,\n    locations='Country of origin (ISO)',\n    color='Recognized decisions',\n    hover_name='Country of origin (ISO)',\n    color_continuous_scale=px.colors.sequential.Plasma,\n    labels={'Recognized decisions': 'Recognized Decisions'},\n    title=f'Recognized Decisions for Asylum Seekers in {country_of_asylum}'\n)\n\n# 맵 출력\nst.plotly_chart(fig)\n\n# 상세 데이터를 표로 추가하여 표시\nst.write('Detailed Data:', grouped_data)\n```\n\n해당 코드는 상호작용 웹 앱을 만드는 데 사용되는 streamlit, 데이터 조작 및 분석에 사용되는 pandas, 시각화를 만드는 데 사용되는 plotly.express 등 관련 라이브러리를 포함하고 있어요.\n\n<div class=\"content-ad\"></div>\n\n업로드한 데이터 세트에 액세스하는 코드이며 이를 사용하여 데이터 프레임을 만듭니다(pandas 라이브러리 사용). 데이터 프레임은 데이터 시각화를 위한 가장 좋은 방법입니다. 데이터 프레임은 그런 다음 Plotly express 함수 choropleth()로로드되며 이 함수는 각 원본 국가의 숫자(인식된 결정)를 보여주는 전역 맵을 생성합니다.\n\n이 코드를 즐겨 사용하는 Python 편집기(저는 PyCharm을 사용합니다)에 복사하여 붙여넣기하고 Python 파일(예: streamlit_map01.py)로 저장할 수 있습니다.\n\n이 프로젝트에 대한 제 예시 PyCharm 작업 환경은 다음과 같습니다:\n\n![Image](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_5.png)\n\n<div class=\"content-ad\"></div>\n\nPyCharm을 사용하면 내장 터미널 창(보기/도구 창/터미널)을 사용하여 새 Streamlit 애플리케이션을 실행할 수 있습니다:\n\n![이미지](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_6.png)\n\n그리고 새 코드를 실행한 결과:\n\n![이미지](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_7.png)\n\n<div class=\"content-ad\"></div>\n\n와우, 그냥 그렇게하면, 사용자가 원산지 국가를 선택할 수있는 인터랙티브 애플리케이션이 만들어졌어요. 애플리케이션에서 캐나다가 선택되어 있고, 원산지 국가들이 표시되어 있어요.\n\n정말 멋진 시작이에요! 하지만 더 개선할 수 있을 것 같아요.\n\n사용자가 연도별로 선택할 수 있게하여 추가적인 상호작용을 추가해 봅시다.\n\n# 단계 3: 연도별로 표시하기 위한 슬라이더 추가\n\n<div class=\"content-ad\"></div>\n\n이제 사용자가 연도를 선택할 수 있도록 슬라이더를 추가하여 세분화 수준을 한 단계 더 높일 수 있습니다(현재는 데이터 집합의 모든 연도를 표시 중입니다). GPT-4에 추가 작업을 요청해 보겠습니다.\n\nGPT-4에 제안: 좋아요, 사용자가 연도를 선택할 수 있도록 슬라이더를 추가하고, 크로플레스 맵에는 해당 연도의 결과만 표시하도록 해주세요.\n\n코드의 주요 부분은 동일하지만, GPT-4가 사용자가 국가를 선택한 후 추가 필터를 추가하는 슬라이더 코드를 추가할 것입니다.\n\n다음은 추가 코드의 예시입니다(간결하게 표현):\n\n<div class=\"content-ad\"></div>\n\n```js\n# 연도를 선택할 수 있는 슬라이더\nyear = st.slider(\n    '연도를 선택하세요:',\n    int(asylum_data['Year'].min()),\n    int(asylum_data['Year'].max()),\n    int(asylum_data['Year'].min())\n)\n\n# 선택된 국가와 연도에 따라 데이터 필터링\nfiltered_data = asylum_data[(asylum_data['Country of asylum'] == country_of_asylum) & (asylum_data['Year'] == year)]\n\n# 원산지 국가별로 그룹화하여 인정된 결정 수 합산\ngrouped_data = filtered_data.groupby('Country of origin (ISO)').sum().reset_index()\n```\n\n좋아요! 우리는 새로운 Python 코드의 전체 부분을 복사하여 붙여넣거나 저장할 수 있습니다(나의 예시에서 streamlit_map02.py 파일을 생성했습니다).\n\n새로운 Python 코드의 실행 결과:\n\n<img src=\"/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_8.png\" />\n\n<div class=\"content-ad\"></div>\n\n당신이 볼 수있듯이, 큰 변화는 물론, 사용자가 연도를 선택할 수 있도록 드롭다운 바로 아래에 슬라이더를 추가한 것입니다.\n\n특정 나라 출신 사람들이 어떤 나라로 피난처 신청을 하는지도 볼 수 있으면 어떨까요? 이 데이터도 이미 데이터 세트에 포함되어 있습니다. 이미 연도와 나라별 선택 기능을 추가했습니다. 이 정보를 보려면 첫 번째 지도 옆에 두 번째 지도를 추가하여 접근 가능한 데이터를 두 배로 늘리면 됩니다.\n\n출발!\n\n# 단계 4: 두 번째 코로플레스 맵 추가하기\n\n<div class=\"content-ad\"></div>\n\n우리는 국가의 난민국가를 보여주는 두 번째 지도를 추가할 수 있습니다. 그리고 이것을 우리가 만든 첫 번째 지도 옆에 놓을 수 있습니다.\n\n이 두 지도를 함께 보면 선택한 국가에 대한 두 가지 정보를 확인할 수 있습니다:\n\n- 어느 국가에서 난민을 구합니다\n- 어느 국가로 난민을 보냅니다\n\nGPT-4에게 지침: 슬라이더와 드롭다운을 사용하여 선택한 국가에 대한 피난지 국가를 표시하는 두 번째 지도를 추가하십시오(첫 번째 지도 옆에 놓으세요. 지도는 각각 자체 컨테이너에 있어야 합니다). 두 지도가 모두 초기 연도와 드롭다운에서 업데이트되도록 해주세요. 두 번째 지도의 색상 체계를 'YlOrRd'로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\nGPT-4가 코드를 생성해줍니다. 여러분은 자신이 선호하는 편집기에 다시 복사하여 붙여넣기/저장/실행할 수 있습니다 (저는 streamlit_map03.py라는 세 번째 파일을 만들었습니다).\n\n참고: 이 프롬프트를 올바르게 만드는 데 몇 차례 시도했습니다. 명시적으로 언급되지 않는 한 GPT-4는 두 번째 지도를 첫 번째 드롭다운과 연결하지 않을 수도 있습니다(또는 두 번째 드롭다운을 추가할 수도 있습니다).\n\n최종 디스플레이:\n\n![이미지](/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_9.png)\n\n<div class=\"content-ad\"></div>\n\n와우, 정말 인상적이에요. 데이터셋과 3가지 모듈식 프롬프트로, 행성상 모든 국가 간 난민 이동을 볼 수 있는 대화형 웹 애플리케이션을 만들었어요.\n\n그리고 GPT-4는 이 모든 것을 100줄 미만의 코드로 (내 최종 Python 파일에는 70줄) 완성했어요.\n\n좋은 경험이 되었기를 바라요. 함께 해줘서 고마워요!\n\n# 요약하자면...\n\n<div class=\"content-ad\"></div>\n\n위의 GPT-4 프롬프트 단계를 모듈식으로 따르면 대부분의 사람이 수동으로 코딩하는 데 소요되는 시간의 일부분에 웹 응용 프로그램을 매우 유용하게 개발할 수 있습니다.\n\n그러나 여기서 주의해야 할 점이 있습니다 — GPT-4는 응답에서 정확하지 않습니다. 코드나 결과가 여기에 표시된 것과 정확히 같아야 한다는 보장은 없습니다. 이것이 오늘의 LLM 환경의 특성입니다.\n\n내 경험상 GPT-4는 계속해서 작동하는 코드를 생성할 수 있지만, 그것이 생성 될 때마다 동일한 코드는 아닙니다.\n\n전문가 팁: 마음에 드는 작동 코드 덩어리(레이아웃/색상 선택/기능 등)가 있으면, 다음 모듈식 단계에 사용하기 위해 이 코드를 GPT-4에 다시 피드해야 합니다. 이렇게 하면 GPT-4가 진로를 유지하는 데 도움이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n이런 프롬프트들을 한 번 시도해 보세요! 그리고 제게 어땠는지 꼭 알려주세요.\n\n읽어 주셔서 감사합니다.\n\n만약 이런 종류의 이야기가 당신에게 딱 맞고, 나를 작가로서 지원하고 싶다면, 제 Substack을 구독해 주세요.\n\nSubstack에서는 나의 독자들만을 위해 매주 뉴스레터와 다른 플랫폼에서 찾을 수 없는 기사들을 게시합니다.","ogImage":{"url":"/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_0.png"},"coverImage":"/assets/img/2024-06-19-PythonStreamlitAndGPT4HowToMapUNHCRRefugeeData_0.png","tag":["Tech"],"readingTime":8},{"title":"대시보드의 역사 마차부터 KPI까지","description":"","date":"2024-06-19 05:00","slug":"2024-06-19-TheHistoryofDashboardsFromCarriagestoKPIs","content":"\n\n대시보드는 현대 데이터 분석 및 의사결정 프로세스의 핵심 요소가 되었습니다. 실시간으로 데이터를 시각화하는 강력한 도구로서, 개인 및 조직이 신속하게 정보에 기반한 결정을 내릴 수 있도록 도와줍니다. 대시보드의 역사에 대한 이 자세한 살펴봅니다. 기원부터 진화, 현재 상태까지 살펴보면 이 도구들이 어떻게 우리의 데이터 중심 세계에서 중요해졌는지 통찰력을 제공할 것입니다.\n\n![대시보드 역사](/assets/img/2024-06-19-TheHistoryofDashboardsFromCarriagestoKPIs_0.png)\n\n초기 시작: 대시보드 개념\n\n\"대시보드\"라는 단어는 원래 말마차의 앞부분에 놓인 물리적 장벽을 가리켰습니다. 이 장벽은 말에 의해 일으키는 진흙과 부스러기로부터 운전자를 보호하는 역할을 했습니다. 본질적으로 안전과 편의를 위한 실용적 도구로 작용했습니다.\n\n<div class=\"content-ad\"></div>\n\n![img](/assets/img/2024-06-19-TheHistoryofDashboardsFromCarriagestoKPIs_1.png)\n\n20세기 초반에는 이 개념이 자동차에 적용되었습니다. 자동차의 계기판은 운전자가 차량을 안전하게 운행하기 위해 속도, 연료 수준, 엔진 온도 등과 같은 중요 정보를 표시했습니다. 이 중요 정보를 한 곳에 통합하는 초기 아이디어는 현대 디지털 대시보드의 기초를 마련했습니다.\n\n아날로그 대시보드: 게이지와 다이얼\n\n자동차 기술이 발전함에 따라 대시보드도 발전했습니다. 20세기 중반에는 자동차 대시보드가 여러 게이지와 다이얼을 포함하도록 발전했습니다. 이 아날로그 장치들은 속도계, 탁도계, 연료 게이지 및 온도 지시기와 같은 다양한 데이터를 한 눈에 제공했습니다. 이 대시보드는 운전자가 차량의 상태와 성능을 빠르게 파악할 수 있도록 직관적으로 설계되었습니다. 다양한 데이터 포인트를 조직화되고 접근하기 쉬운 방식으로 제시하는 능력은 우리가 오늘 사용하는 대시보드로 나아가는 중요한 발전을 이루었습니다.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-19-TheHistoryofDashboardsFromCarriagestoKPIs_2.png)\n\n디지털 혁명: 컴퓨터 기반 대시보드\n\n20세기 중반 컴퓨터의 등장은 정보 표시 방식에 중요한 변화를 가져왔습니다. 초기 컴퓨터 대시보드는 단순한 텍스트 기반 인터페이스였으며 데이터를 원시적인 형식으로 표시했습니다. 그러나 1980년대에 그래픽 사용자 인터페이스(GUI)가 등장하면서 대시보드는 시각적으로 더 매력적이고 사용자 친화적으로 변했습니다. GUI를 통해 차트, 그래프 및 다른 시각적 요소를 통합할 수 있게 되었으며, 이로써 사용자가 데이터를 해석하기가 훨씬 쉬워졌습니다. 이 변화는 정적 디스플레이에서 동적, 상호 작용형 대시보드로의 전환이 시작되었다.\n\n비즈니스 인텔리전스와 디지털 대시보드의 등장\n\n<div class=\"content-ad\"></div>\n\n1990년대는 비즈니스 인텔리전스(BI) 도구의 등장을 목격했는데, 이는 기관이 데이터를 관리하고 활용하는 방식을 변화시켰습니다. SAP, 오라클, 마이크로소프트와 같은 기업들은 대량의 데이터를 집계하고 대시보드를 통해 의미 있게 표현할 수 있는 정교한 소프트웨어를 개발했습니다. 이러한 디지털 대시보드는 강력한 분석 도구가 되어 기업이 성과 지표를 추적하고 추세를 식별하며 데이터 기반의 결정을 내릴 수 있도록 돕습니다. 여러 데이터 원천을 통합하고 일관된 방식으로 시각화하는 능력은 비즈니스 영역과 전략을 혁명적으로 변화시켰습니다.\n\n21세기: 대화형 및 실시간 대시보드\n\n인터넷 보급과 기술 발전으로 대시보드는 매우 상호작용적이며 실시간 데이터 업데이트를 제공할 수 있는 기능을 갖추게 되었습니다. Tableau, Power BI, QlikView와 같은 도구를 통해 구동되는 현대적인 대시보드는 사용자들이 자신의 뷰를 사용자화하거나 특정 데이터 포인트를 자세히 살펴볼 수 있고 이전에는 불가능했던 방식으로 데이터와 상호 작용할 수 있게 합니다. 이 대시보드는 데이터베이스, 클라우드 서비스, API 등 다양한 소스에서 데이터를 가져와 사용자에게 세심하고 최신의 메트릭스를 제공합니다. 상호 작용성과 실시간 데이터에 대한 강조는 이러한 도구들을 많은 분야에서 반가운 도구로 만들었습니다.\n\n<div class=\"content-ad\"></div>\n\n다양한 분야의 대시보드\n\n오늘날, 대시보드는 각각 특정 요구사항과 응용 프로그램을 가진 다양한 산업 분야에서 사용됩니다:\n\n의료: 의료 분야에서의 대시보드는 환자 데이터를 추적하고, 병원 자원을 모니터링하며, 공중보건 트렌드를 분석합니다. 이러한 대시보드는 환자 치료 및 운영 효율성 향상에 도움을 줍니다.\n\n금융: 금융 대시보드는 시장 트렌드, 투자 성과, 위험 관리로부터 통찰을 제공합니다. 실시간으로 금융 건강상태와 전략적 계획을 모니터링할 수 있게 돕습니다.\n\n<div class=\"content-ad\"></div>\n\n교육: 교육 기관은 학생 성적, 출석 및 행정 지표를 추적하는 대시보드를 사용합니다. 이러한 대시보드는 개선할 부분을 식별하고 교육 성과를 최적화하는 데 도움을 줍니다.\n\n마케팅: 마케팅 대시보드는 캠페인 성과, 고객 참여 및 소셜 미디어 지표를 분석합니다. 이들은 마케팅 전략을 개선하고 ROI를 측정하는 데 도움을 줍니다.\n\n대시보드의 미래\n\n앞으로 대시보드의 미래는 인공 지능 (AI) 및 기계 학습 (ML)의 발전에 의해 형성될 것으로 예상됩니다. 이러한 기술은 예측 분석, 자동화된 통찰력 및 자연어 처리 (NLP) 능력을 제공하여 대시보드를 향상시킬 수 있습니다. AI 기반 대시보드는 사용자의 요구를 예측하고 추천을 제공하며 데이터를 더 직관적인 방식으로 제시할 수 있을 것입니다. 또한 가상 현실 (VR) 및 증강 현실 (AR)의 통합은 몰입형 데이터 시각화 경험을 이끌어내어 복잡한 데이터셋과 상호 작용하는 것을 더 쉽게 만들 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n결론\n\n단순한 보호 장벽으로부터 정교한 데이터 시각화 도구로 발전한 대시보드들은 놀라운 변화를 겪어왔습니다. 사용자들의 요구와 기술 발전에 맞춰 지속적으로 발전해왔습니다. 앞으로도 대시보드는 혁신을 계속할 것으로 예상되며, 데이터를 이해하고 상호 작용하는 보다 강력하고 직관적인 방법을 제공할 것입니다.","ogImage":{"url":"/assets/img/2024-06-19-TheHistoryofDashboardsFromCarriagestoKPIs_0.png"},"coverImage":"/assets/img/2024-06-19-TheHistoryofDashboardsFromCarriagestoKPIs_0.png","tag":["Tech"],"readingTime":4},{"title":"Windows에서 글꼴을 더 선명하게 만드는 방법","description":"","date":"2024-06-19 04:59","slug":"2024-06-19-HowtoMakeFontsCleareronWindows","content":"\n\n![이미지](/assets/img/2024-06-19-HowtoMakeFontsCleareronWindows_0.png)\n\n화면 폰트를 선명하고 선명하게 보이도록 하는 것은 독서 경험을 크게 향상시키고 눈의 피로를 줄일 수 있습니다. 여기 윈도우 컴퓨터에서 글꼴 선명도를 향상시키는 두 가지 효과적인 방법이 있습니다.\n\n# 방법 1: 글꼴 평활화를 위한 시각 효과 조정\n\n- 성능 옵션 열기:\n\n<div class=\"content-ad\"></div>\n\n- 시작 메뉴를 클릭하세요.\n- 검색 창에 \"Windows의 모양 및 성능 조정\"을 입력하고 결과에서 선택하세요.\n\n2. 시각 효과 수정:\n\n- 성능 옵션 창에서 시각 효과 탭으로 이동하세요.\n- 화면 글꼴의 부드러운 가장자리 옵션을 찾아 선택 해제하세요.\n- 그런 다음 옵션을 다시 선택하여 다시 활성화하세요.\n\n3. 변경 사항 적용:\n\n<div class=\"content-ad\"></div>\n\n- 변경 사항을 저장하려면 '적용'을 클릭한 다음 '확인'을 누르세요.\n\n![이미지](/assets/img/2024-06-19-HowtoMakeFontsCleareronWindows_1.png)\n\n# 방법 2: ClearType 텍스트 튜너 사용하기\n\n- ClearType 텍스트 튜너를 엽니다:\n\n<div class=\"content-ad\"></div>\n\n- 시작 메뉴를 클릭하세요.\n- 검색 상자에 \"ClearType\"을 입력하세요. \"Adjust ClearType Text\"을 보면 클릭하거나 Enter를 누르세요.\n\n2. ClearType 활성화:\n\n- ClearType Text Tuner 창에서 \"Turn on ClearType\" 옆의 상자를 체크하세요.\n- 계속하려면 다음을 클릭하세요.\n\n3. 텍스트 조정:\n\n<div class=\"content-ad\"></div>\n\n- 화면 안내에 따라 ClearType 설정을 조정하세요. 여러 텍스트 샘플이 나타날 것이며, 가장 마음에 드는 것을 선택하세요.\n\n4. 설정 완료:\n\n- 단계를 완료한 후, 설정을 적용하기 위해 완료를 클릭하세요.\n\n![이미지](/assets/img/2024-06-19-HowtoMakeFontsCleareronWindows_2.png)\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n이러한 방법을 따르면 Windows 환경에서 화면 글꼴의 선명도와 날카로움을 상당히 향상시킬 수 있습니다. 오늘 이러한 조정을 해보고 보다 선명하고 깔끔한 텍스트를 디스플레이에서 즐겨보세요!","ogImage":{"url":"/assets/img/2024-06-19-HowtoMakeFontsCleareronWindows_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoMakeFontsCleareronWindows_0.png","tag":["Tech"],"readingTime":2},{"title":"윈도우에서 발생하는 참조된 메모리의 명령을 읽거나 쓸 수 없습니다 오류를 해결하는 방법","description":"","date":"2024-06-19 04:58","slug":"2024-06-19-HowtoFixInstructionatReferencedMemoryCouldNotBeReadorWriteErrorinWindows","content":"\n\n![Instruction at Referenced Memory Could Not Be Read or Write Error](/assets/img/2024-06-19-HowtoFixInstructionatReferencedMemoryCouldNotBeReadorWriteErrorinWindows_0.png)\n\n\"참조된 메모리의 명령을 읽거나 쓸 수 없습니다\"라는 오류 메시지를 만나면 Windows 사용자에게는 담담한 경험일 수 있습니다. 이 오류 메시지는 일반적으로 \"0x00000000에서 참조된 메모리의 0x00000000에서 메모리를 읽을 수 없습니다\"로 표시되는데, 이는 프로그램이 또는 프로세스가 무단으로 액세스하려는 메모리나 오염된 메모리에 문제가 있음을 나타냅니다. 이 문제는 컴퓨터를 종료하거나 다시 시작하거나 웹 브라우저를 열거나 그래픽 집약 프로그램을 시작하거나 심지어 게임을 할 때 발생할 수 있습니다.\n\n# \"메모리를 읽을 수 없음\" 오류 해결 방법\n\n\"참조된 메모리의 명령을 읽거나 쓸 수 없습니다\" 오류는 시스템의 메모리 액세스 프로토콜 내부의 중요한 문제를 나타냅니다. 오염된 시스템 파일, 소프트웨어 간 충돌, 일시적인 메모리 글리치 또는 하드웨어 고장을 포함한 다양한 요소가이 오류를 유발할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 클린 부트 실행하기\n\n소프트웨어 간 충돌, 특히 제3자 서비스나 어플리케이션과 관련된 충돌은 메모리 관련 오류로 이어질 수 있습니다. 클린 부트는 윈도우를 최소한의 드라이버와 시작 프로그램으로 시작함으로써 이러한 충돌을 최소화합니다. 이 과정을 통해 백그라운드 애플리케이션이 문제의 근원인지 확인할 수 있습니다. 클린 부트를 실행하려면 시스템 구성 도구를 사용하여 시작 항목과 마이크로소프트가 아닌 서비스를 선택적으로 비활성화한 후 컴퓨터를 재시작하여 오류가 지속되는지 확인해야 합니다.\n\n- Windows + R을 눌러 msconfig를 입력한 후 Enter를 누릅니다.\n- 시스템 구성 창에서 서비스 탭으로 이동합니다.\n- 모든 마이크로소프트 서비스 숨기기를 선택한 다음 모두 비활성화를 클릭합니다.\n- 시작 탭으로 전환하여 작업 관리자 열기를 클릭합니다.\n- 작업 관리자에서 각 시작 항목에 대해 선택한 후 비활성화를 클릭합니다.\n- 작업 관리자를 닫고 시스템 구성 창에서 확인을 클릭합니다. 컴퓨터를 다시 시작합니다.\n\n## 시스템 파일 검사기 (SFC)와 DISM 실행하기\n\n<div class=\"content-ad\"></div>\n\n시스템 파일이 손상되었거나 누락된 경우 시스템의 안정성에 큰 영향을 미칠 수 있습니다. 시스템 파일 검사기(SFC)는 사용자가 손상된 Windows 시스템 파일을 검사하고 복원할 수 있는 유틸리티입니다. 이를 배경화면 이미지 서비스 및 관리 도구(DISM)와 결합하면 Windows 이미지를 복구하여 시스템 무결성을 더욱 향상시킬 수 있습니다. 이러한 도구를 실행하면 Windows PC에 발생하는 대부분의 문제를 해결할 수 있습니다.\n\nSFC 스캔:\n\n- 시작 버튼을 마우스 오른쪽 버튼으로 클릭한 다음 Windows Terminal(관리자) 또는 명령 프롬프트(관리자)를 선택하십시오.\n- sfc /scannow를 입력하고 Enter를 누릅니다. 프로세스가 완료될 때까지 기다려주세요.\n\nDISM 스캔:\n\n<div class=\"content-ad\"></div>\n\n- 동일한 터미널에서 DISM /Online /Cleanup-Image /RestoreHealth를 입력하고 Enter 키를 눌러주세요. 완료될 때까지 기다려주세요.\n\n## CHKDSK를 사용하여 디스크 오류 확인하기\n\n하드 드라이브의 파일 시스템 손상이나 불량 섹터도 메모리 관련 오류에 기여할 수 있습니다. Check Disk 유틸리티 (CHKDSK)는 파일 시스템의 무결성을 스캔하고 디스크 관련 문제를 해결하여 시스템 안정성과 성능을 향상시킵니다.\n\n- Windows 터미널이나 명령 프롬프트를 관리자 권한으로 엽니다.\n- chkdsk /f를 입력하고 Enter 키를 눌러주세요. 다음 시스템 재부팅 시 점검을 예약하라는 메시지가 표시되면 Y를 입력하고 컴퓨터를 다시 시작해주세요.\n\n<div class=\"content-ad\"></div>\n\n## 메모리 진단 도구 실행하기\n\n메모리와 관련된 오류의 일반적인 원인 중 하나는 불량 RAM 모듈입니다. Windows Memory Diagnostic은 메모리 문제를 확인하는 유용한 도구로, 오류의 원인이 될 수 있는 불량 RAM 스틱을 확인합니다. 진단 도구에서 문제를 식별하면 고장 난 메모리 모듈을 교체하는 것이 좋습니다.\n\n- Windows 키 + R을 눌러 mdsched.exe를 입력하고 Enter를 누릅니다.\n- \"지금 다시 시작하여 문제 확인\" 또는 \"다음에 컴퓨터를 재시작할 때 문제 확인\" 중 선택합니다.\n\n## 가상 메모리 설정 조정하기\n\n<div class=\"content-ad\"></div>\n\n가상 메모리 또는 페이징 파일은 물리적 RAM의 확장으로 작동하여 하드 디스크 공간을 사용합니다. 가상 메모리 부족은 특히 메모리 집약적 작업 중에 오류를 일으킬 수 있습니다. 시스템의 가상 메모리 설정을 조정하여 할당된 공간을 늘리면 이러한 오류를 완화할 수 있으며 작업에 대한 더 많은 '공간'을 제공할 수 있습니다.\n\n- 데스크탑에서 This PC를 마우스 오른쪽 버튼으로 클릭하고 속성을 선택합니다.\n- 성능 아래에 있는 고급 시스템 설정 ` 설정을 클릭합니다.\n- 고급 탭으로 이동하여 가상 메모리 아래에 있는 변경 항목을 클릭합니다.\n- 모든 드라이브에 대해 페이지 파일 크기를 자동으로 관리 해제합니다.\n- 드라이브를 선택하고 사용자 지정 크기를 클릭한 다음 초기 크기와 최대 크기를 시스템 RAM 및 요구 사항에 따라 설정합니다. 설정을 클릭한 다음 확인을 클릭합니다.\n\n## 악성 코드 검사 수행\n\n악성 코드 감염은 시스템 프로세스를 방해하고 메모리 관련 오류를 일으킬 수 있습니다. 안티바이러스 소프트웨어를 사용하여 전체 시스템 스캔을 수행하면 악성 소프트웨어를 감지하고 제거하여 오류를 해결할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 안티바이러스 소프트웨어를 열고 전체 시스템 스캔을 실행하는 옵션을 선택해주세요.\n- 발견된 악성 코드를 제거하기 위해 화면 안내에 따라 진행해주세요.\n\n## 시스템 복원 수행\n\n시스템 복원을 통해 컴퓨터를 이전에 정상적으로 작동했던 상태로 되돌릴 수 있습니다. 특히 최근 시스템 변경 또는 업데이트 후에 에러가 발생했을 때 유용합니다. 이 기능을 사용하면 오류를 일으키고 있는 최근 변경 사항을 취소하여 시스템의 안정성을 복구할 수 있습니다.\n\n- Windows + S를 눌러 복원점 생성이라고 입력하고 Enter 키를 눌러주세요.\n- 시스템 속성 창에서 시스템 복원을 클릭해주세요.\n- 오류가 발생하기 전의 복원 지점을 선택하고 시스템을 복원하기 위해 안내에 따라 진행해주세요.\n\n<div class=\"content-ad\"></div>\n\n소스: https://windows101tricks.com/memory-could-not-be-read/","ogImage":{"url":"/assets/img/2024-06-19-HowtoFixInstructionatReferencedMemoryCouldNotBeReadorWriteErrorinWindows_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoFixInstructionatReferencedMemoryCouldNotBeReadorWriteErrorinWindows_0.png","tag":["Tech"],"readingTime":4},{"title":"윈도우에서 Kali Linux로의 원격 SSH 연결 설정하기","description":"","date":"2024-06-19 04:57","slug":"2024-06-19-EstablishingRemoteSSHConnectionsfromWindowstoKaliLinux","content":"\n\n리모트 Kali Linux VM에 SSH 키 설정하기\n\n![이미지](/assets/img/2024-06-19-EstablishingRemoteSSHConnectionsfromWindowstoKaliLinux_0.png)\n\n인증을 위해 SSH 키를 설정하는 것은 단독으로 비밀번호를 사용하는 것보다 더 안전한 방법일 수 있습니다. SSH 키는 강력한 비밀번호조차도 해독하기 어려운 복잡한 구조를 가지고 있습니다. 또한 이를 통해 비밀번호를 입력하지 않고 원격으로 Kali Linux 시스템에 안전하게 로그인할 수 있습니다. 제대로 구성되었을 때 SSH 키 기반의 인증은 브루트 포스 비밀번호 공격을 사실상 무용지물로 만들어줍니다. 암호화 키는 해독하기가 더 어렵기 때문입니다. 또한 SSH 에이전트를 사용하면 편리함을 더할 수 있습니다. 보안을 희생하지 않고 한 번 비밀 키로 인증하면 자격 증명을 매번 입력하지 않고 서버에 자유롭게 연결할 수 있습니다.\n\nWindows 상의 PowerShell에서 키 생성하기\n\n<div class=\"content-ad\"></div>\n\n어드민 PowerShell을 열고 다음을 입력해주세요.\n\n```js\nssh-keygen\n```\n\ncat 명령어를 사용하여 공개 키를 확인해보실 수 있습니다. 공개 키는 다음 경로에 위치해 있어야 합니다.\n\n```js\nC:\\Users\\<username>/.ssh/id_rsa.pub\n```\n\n<div class=\"content-ad\"></div>\n\n이 공개 키는 Kali Linux 상에서 인증을 하는 데 사용될 것입니다. 이를 복사하여 Kali Linux 상의 authorized_keys 파일에 붙여넣으시면 됩니다. 사용자가 이미 상자에 접속한 경우이고 sudo 사용자로 SSH 키를 설정할 수 있는 권한이 있으시면 이 과정은 쉽습니다. 그냥 텍스트 편집기를 사용하여 파일을 수정하면 됩니다.\n\nMarkdown 형식으로 표를 변경해주시기 바랍니다:\n\n```bash\nnano ~/.ssh/authorized_keys\n```\n\nWindows에서 Kali Box에 연결하기\n\n이제 Windows 상의 PowerShell을 열고, -i 옵션을 사용하여 키 파일 (id_rsa)이 어디에 있는지 지정하여 Kali 상자에 연결하실 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nssh -i C:\\Users\\<username>/.ssh/id_rsa <username>@<Server_IP>\n```\n\n이 명령어를 입력하면 Kali 상자에 연결됩니다. 그러나 이것을 기억하는 것은 많을 수 있습니다. 이를 효율적으로 실행하기 위해 함수와 별칭을 만드는 것이 더 실용적일 수 있습니다.\n\n효율성을 위한 함수 및 별칭 만들기\n\nPowerShell에서 새 함수와 별칭을 만드는 것은 간단한 프로세스입니다. 새 함수를 정의하려면 function 명령어를 사용하고 실행할 코드가 포함된 스크립트 블록을 사용하면 됩니다. 예를 들어, Connect-Kali라는 함수를 생성하려면 다음 구문을 사용하면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nfunction Connect-Kali { ssh -i C:\\Users\\<username>/.ssh/id_rsa <username>@<Server_IP> }\n```\n\n새 별칭을 생성하려면 먼저 PowerShell 프로필이 있는지 확인해야 합니다. PowerShell 인스턴스를 열고 다음 명령을 사용하세요.\n\n```js\nTest-Path $PROFILE \n```\n\n명령이 False를 반환하면 다음 문법을 사용하여 프로필을 만들어야 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nNew-Item -type file -path $PROFILE -force \n```\n\n<img src=\"/assets/img/2024-06-19-EstablishingRemoteSSHConnectionsfromWindowstoKaliLinux_1.png\" />\n\n이제 프로필을 편집할 수 있습니다:\n\n```js\nnotepad.exe $PROFILE\n```\n\n<div class=\"content-ad\"></div>\n\n프로필에 다음 함수 및 별칭 라인을 추가하세요 (경로 세부 정보로 수정)\n\n```js\nfunction Connect-Kali { ssh -i C:\\Users\\<사용자이름>/.ssh/id_rsa <사용자이름>@<서버IP> } New-Alias -Name kali -Value Connect-Kali\n```\n\n구문 분석:\n\n- New-Alias: PowerShell에서 새 별칭을 생성합니다.\n- -Name kali: 별칭 kali의 이름을 지정합니다.\n- -Value Connect-Kali: 이는 앞서 정의된 Connect-Kali 함수의 값입니다.\n\n<div class=\"content-ad\"></div>\n\n프로필을 다시 불러오세요:\n\n```js\n. $PROFILE\n```\n\n이제 PowerShell에서 단순히 kali를 입력하여 Connect-Kali 함수를 실행하면 지정된 원격 기계로의 SSH 연결이 시작됩니다.\n\n맺음말:\n\n<div class=\"content-ad\"></div>\n\n여기 있습니다. SSH 키를 사용하여 인증하는 것이 패스워드보다 더 안전하며 복잡하고 더 어렵게 해킹할 수 있습니다. 이 방법을 사용하면 Kali Linux 시스템으로의 안전한 패스워드 없는 원격 로그인이 가능해져 브루트포스 공격을 무력화시킵니다. 또한, SSH 에이전트를 사용하면 여러분의 개인 키로 일회성 인증을 허용하여 자격 증명을 반복해서 입력하지 않고도 매끄럽고 안전한 연결을 구현할 수 있습니다.\n\n링크:\n\n- 구독하기! [https://medium.com/@ekiser_48014/subscribe](https://medium.com/@ekiser_48014/subscribe)","ogImage":{"url":"/assets/img/2024-06-19-EstablishingRemoteSSHConnectionsfromWindowstoKaliLinux_0.png"},"coverImage":"/assets/img/2024-06-19-EstablishingRemoteSSHConnectionsfromWindowstoKaliLinux_0.png","tag":["Tech"],"readingTime":3}],"page":"89","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true}