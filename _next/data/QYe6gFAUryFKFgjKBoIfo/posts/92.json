{"pageProps":{"posts":[{"title":"복원력은 기술 이상의 개념입니다","description":"","date":"2024-06-19 04:17","slug":"2024-06-19-Resiliencyismorethanjusttechnology","content":"\n\n## Change Healthcare 랜섬웨어 공격에서 배운 점\n\n![이미지](/assets/img/2024-06-19-Resiliencyismorethanjusttechnology_0.png)\n\n저프 카이서먼과 브란 키설\n\nVerizon의 연례 데이터 침해 조사 보고서(DBIR)는 전 세계적으로 사이버 사고 및 데이터 침해에 대한 광범위한 정보를 제공합니다. 항상 흥미로운 동시에 놀라운 정보를 담고 있습니다. 2023년에는 랜섬웨어가 정보 기밀성, 무결성 또는 가용성에 대한 변경(사고)과 정보의 공개(침해)와 관련된 조치의 15.5%를 차지했으며, 정보 공개와 관련된 조치의 24%를 차지했습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-19-Resiliencyismorethanjusttechnology_1.png)\n\nDBIR 보고서에 따르면, 올해 랜섬웨어는 약간 감소했지만, 사기공격은 크게 증가했습니다. 이는 주로 MOVEit 침입 중 사용된 전술로 인한 것이었으나, Verizon는 랜섬웨어와 사기를 별도로 추적할 계획이지만 관련된 공격으로 계속 추적할 것이라고 믿습니다. 랜섬웨어는 여전히 장애를 유발하고 재정에 영향을 미치는데, Change Healthcare를 향한 공격과 그 이후 다른 의료 기업에 대한 공격을 통해 이는 너무나 명확해졌습니다.\n\n산업 시스템의 상호 연결성으로 모든 산업이 직면하는 위험이 있습니다. 의료 분야가 Change Healthcare 사건을 통해 이를 드러냈지만, 금융 서비스, 소매업 및 제조업에서도 유사한 문제가 존재합니다.\n\n이 추세는 고가용성 아키텍처, 업무 지속 계획 및 재해 복구를 넘어가는 접근 방식이 필요합니다. 이것이 새로운 접근 방식인 회복력입니다.\n\n\n<div class=\"content-ad\"></div>\n\n# Change Healthcare 사건 개요\n\n2024년 2월 21일, Change Healthcare는 BlackCat/ALPHV 랜섬웨어 그룹에 의한 대규모 사이버 공격을 당했습니다. 공격은 서비스 복구를 위해 원금을 요구하며, Change Healthcare의 시스템에서 데이터를 암호화하는 랜섬웨어 공격으로 분류되었습니다. Change Healthcare는 약 2,200만 달러의 금액을 요구한 보고를 지불했는지 확인하지는 않았지만, 보안 연구원들은 이와 다른 의견을 내놓았으며, 서비스는 3월 중순에 완전히 복구되었습니다. 이 공격은 Change Healthcare의 서비스에 의존하는 수백만 명의 미국인들에게 영향을 끼쳤습니다.\n\nUnitedHealth Group (UHG)에 인수된 헬스케어 기술 기업인 Change Healthcare는 지불 및 수익 주기 관리 및 임상 의사 결정 지원을 포함한 다양한 서비스를 제공합니다. 회사는 매년 15,000억 건의 청구를 처리하며 총 1.5조 달러를 초과하여 미국의 헬스케어 인프라의 중요한 구성 요소입니다. Change Healthcare의 네트워크에 무단 접근하여 실행된 이 공격은 청구 처리 및 자격 확인과 같은 중요한 운영을 방해하여 환자 치료 서비스, 병원 재정 및 수익 주기 관리에 영향을 미쳤습니다.\n\n- 2월 21일: 사이버 공격이 발생; Change Healthcare는 시스템을 오프라인으로 전환 결정\n- 2월 26일: 미국 병원 협회가 Change Healthcare 침해 사항의 영향에 대해 보건 및 인간 서비스 부서(HHS)에 통보\n- 2월 28일: 의료 단체 관리 협회(Medical Group Management Association)가 HHS에 개입하여 완화 계획을 제안\n- 3월 1일: 250 Bitcoin의 보상 요구가 지불\n- 3월 20일: 비즈니스 중요 시스템 및 운영이 복구\n\n<div class=\"content-ad\"></div>\n\n요약하면, 전체 시스템이 다운된 날이 25일이 있었으며, 2천 2백만 달러의 비트코인 결제가 이루어졌습니다. 이 사건의 실제 영향을 정확하게 예측하는 것은 불가능하지만, 우리는 몇 가지 지표를 가지고 있어 예상 비용이 수십억 달러에 달할 것으로 추정됩니다:\n\n- 중요한 서비스가 중단되어 의료 서비스, 청구 처리, 자격 확인, 처방처리 및 환자 치료 제공에 영향을 미쳤습니다. 이는 피해의 가장 중대한 사례였습니다.\n- 제공자 및 네트워크에 대한 재정적 영향이 가장 큰 문제였습니다. 시설은 서비스 제공과 요금 청구, 급여 처리 또는 물류를 유지할 수 없어 피해를 입었던 조직에 긴절하고 중대한 재정적 영향을 미쳤습니다.\n- UHG는 영향을 받은 조직에 단기 재정 지원을 제공하는 임시 자금 지원 프로그램을 시작했습니다. 이 프로그램의 비용에 대한 숫자는 알고 있지 않습니다.\n- 아날로그 관리와 펜-앤-페이퍼 운영으로 다시 돌아가는 것은 영향을 받은 조직에 또 다른 중대한 타격이었습니다.\n\n즉시 발생하는 비용 외에도 소송 가능성, 민사처벌 및 규제 준수 벌금과 관련된 비용, 이 사건 중 피해를 입은 각 데이터 주체에 대한 2년간의 신용도 보호 서비스 비용이 추가됩니다.\n\n고객 영향에 대해 잊어선 안 됩니다. 단기적으로는 약물 접근성에 명백한 영향이 있었으며 연결된 비용에 대한 불확실성이 있었습니다. 장기적으로는 치료 지속성과 환경의 안정성에 관해 의문이 있습니다. 고객들은 자신의 치료 환경이 회복될 것이며, 만약 회복된다면 장기적인 영향은 무엇일지 궁금해합니다.\n\n<div class=\"content-ad\"></div>\n\n사이버공격으로 산업 단체와 연방 정부가 신속히 대응하였고, 영향을 받은 제공업체에게 지원 프로그램과 안내가 제공되었습니다. UHG는 영향을 받은 의료 공급 업체를 돕기 위한 임시 자금 지원 프로그램을 설립했고, 연방 기관들은 위협 인텔리전스 및 지원을 제공하기 위해 협력했습니다. 이 사건은 의료 기관들에 대한 견고한 회복력 조치와 예비 계획의 중요성을 강조하며, 고도로 안전한 데이터 관행과 적극적인 업무 연속성 계획이 필요함을 강조합니다.\n\n# 회복력\n\n회복력은 고가용성 및 재해 복구와 같은 전통적인 솔루션을 넘어섭니다.\n\n- 고가용성(HA)은 기존 구성 요소의 일부가 실패할 때 시스템이 작동할 수 있도록 하는 것을 목표로 합니다. 이러한 구성 요소는 일반적으로 서버, 데이터베이스, API 또는 기탠 구성 요소입니다.\n- 재해 복구(DR)는 정보 기술 능력에 장애가 발생했을 때 사용할 복구 환경을 제공합니다. 장애는 데이터 센터 손실, 적지의 컴퓨팅 리소스 손실, 네트워크 장애 또는 랜섬웨어 등을 포함할 수 있습니다. DR은 업무 기능 손실이 발생할 것을 인정하며, \"운영으로 복귀\" 측정 기준에 따라 합의됩니다. 랜섬웨어의 경우, DR은 암호화되지 않은 백업을 찾고 악성 코드를 격리시킨 경우에만 효과적입니다.\n\n<div class=\"content-ad\"></div>\n\n탄력성은 정보 기술 능력이나 시스템 구성 요소보다는 비즈니스 프로세스에 중점을 둡니다. 이 의미에서 탄력성은 비즈니스 연속성(BC)과 일치합니다. 그 차이는 목표에 있습니다: BC의 목표는 회복하는 것이지만, 탄력성의 목표는 프로세스의 지속적 기능성입니다.\n\n이전에 언급된 시스템들의 상호 연결성을 고려할 때, 탄력성을 두 가지 관점에서 고려하는 것이 중요합니다. 내부 탄력성은 내부 프로세스의 지속적 기능성을 다루고, 외부 탄력성은 외부 상류 또는 하류 디지털 공급망 서비스의 지속적 기능성을 다룹니다. 내부 탄력성이 외부보다 더 잘 이해되어왔지만, 최근 사건은 외부 탄력성이 보다 넓은 영향을 미칠 수 있다는 것을 보여주고 있습니다.\n\n\"프로세스의 지속적 기능성\"이란 무엇을 의미할까요? 지속적 기능성은 어려움에도 불구하고 중요한 내부 및 외부 비즈니스 프로세스가 최대한 오랫동안 기능을 유지하는 것을 의미합니다. 이를 달성하는 다양한 방법이 있지만, 고려해야 할 핵심 질문들이 있습니다.\n\n내부 프로세스에 대해:\n\n<div class=\"content-ad\"></div>\n\n- 보통 사용되는 기술 이외에 지원할 수 있는 하위 프로세스가 있을까요?\n- 사용할 수 있는 수동 하위 프로세스가 있을까요?\n- 업무 지연을 돕기 위해 하위 프로세스로 전환 가능한 인력이 있을까요?\n- 건너뛴 하위 프로세스가 있을까요?\n\n외부 프로세스에 대해:\n\n- 기술을 사용하여 다른 제공 업체를 활용할 수 있는지, 제공 업체를 쉽게 전환할 수 있는 기술이 있는지 확인해보세요.\n- 다른 제공 업체를 활용할 수 없을 때 사용할 수 있는 수동 프로세스가 준비되어 있나요?\n- 고객들이 연락할 수 있는 경우를 대비한 의사 소통 계획이 있나요?\n\n# 다음 단계는 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n복구력 성장을 위한 로드맵은 중요한 비즈니스 기능 및 해당 기능을 지원하는 상하위 종속성을 이해하는 것으로 시작합니다. 현재 이러한 기능의 상태를 명확히 파악한 후 그들의 복구력을 향상시키기 위한 로드맵을 개발하는 것이 중요합니다.\n\n복구력과 고가용성/재해 복구는 서로 다르며 둘 다 성공에 중요합니다. 고가용성/재해 복구 없이의 복구력은 조직의 큰 부분이 장애 중에 용량이 줄어들고 장애가 필요이상으로 오래 지속됨을 수용해야 함을 의미합니다. 복구력 없이의 고가용성/재해 복구는 시스템이 영향을 받은 시간부터 시스템이 복구될 때까지 핵심 비즈니스 기능이 사용 불가능하다는 것을 수용해야 합니다. 둘 다 제공할 때에만 완전한 해결책을 제공합니다.\n\n저희는 복구력에 대한 실천이 중요하다고 믿습니다. 조직은 다양한 수준의 시뮬레이션 또는 테이블탑 연습을 활용해야 합니다. 계획은 문서상으로 멋져 보이지만, 실전이 계획을 실행 가능하게 만드는 요소입니다.\n\n마지막으로, 복구력은 문화적 사고 변화를 요구합니다. 언제든지 사람들이 일상적인 업무 부하에 없던 새로운 작업으로 전환해야 할 수 있습니다. 이는 조직 변화와 인재 관리에 대한 지원이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n슬라럼은 비즈니스, 기술 및 인간성이 교차하는 지점에서 가치를 창출하는 차세대 프로페셔널 서비스 회사입니다. 자세히 알아보고 오늘 문의하세요.","ogImage":{"url":"/assets/img/2024-06-19-Resiliencyismorethanjusttechnology_0.png"},"coverImage":"/assets/img/2024-06-19-Resiliencyismorethanjusttechnology_0.png","tag":["Tech"],"readingTime":5},{"title":"원본 IP 추적하기 초보자를 위한 안내","description":"","date":"2024-06-19 04:16","slug":"2024-06-19-HuntingforOriginIPABeginnersGuide","content":"\n\n안녕하세요,\n\n제 이름은 Pruthu Raut이고 Bug Bounty에 초보입니다. 이번 글은 원본 IP를 찾는 것에 초점을 맞추어 처음으로 작성한 것입니다. 웹 애플리케이션 방화벽(WAF) 우회 및 서버에 직접 액세스하여 여러 취약점을 악용하는 것이 주요 관심사입니다. 이제 원본 IP를 찾기 위해 시작해봅시다.\n\n# 단계 1: 도메인 획득\n\n먼저 도메인을 획득합니다. 도메인을 얻은 후 도메인 주소를 복사하고 웹 브라우저에서 엽니다. 웹 브라우저에서 열면 홈페이지가 나타납니다. 그런 다음 추가 단계를 위해 다시 도메인을 얻습니다. 웹사이트가 Cloudflare를 사용 중임을 명확히 알 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Step 2: Using Shodan](https://www.shodan.io/)\n\n![Image 1](/assets/img/2024-06-19-HuntingforOriginIPABeginnersGuide_1.png)\n\n\n<div class=\"content-ad\"></div>\n\n우리의 첫 번째 방법은 Shodan을 사용하는 것입니다. Shodan을 사용하면, 아래와 같은 shodan dork와 함께 도메인을 붙여넣습니다.\n\nssl:”redacted.com”\n\n그런 다음 검색 창에 붙여넣습니다. Shodan은 해당 도메인과 관련된 여러 IP 주소를 반환합니다. 각 IP 주소를 웹 브라우저에서 열어 해당 도메인과 동일한 홈페이지에 접속할 수 있는지 확인합니다. 올바른 IP를 찾지 못하면 다음 검색 엔진으로 넘어갑니다.\n\n# 단계 3: Censys 사용하기\n\n<div class=\"content-ad\"></div>\n\nhttps://search.censys.io/\n\n![Hunting for Origin IP - Beginner's Guide](/assets/img/2024-06-19-HuntingforOriginIPABeginnersGuide_2.png)\n\n그런 다음, 우리는 Censys를 사용합니다. 도메인을 Censys 검색 창에 입력합니다. 결과에서 첫 번째 IP 주소가 도메인과 동일한 웹페이지로 이어진다면, 원본 IP를 찾은 것입니다. Wappalyzer 확장 프로그램을 사용하여 WAF를 확인함으로써 이를 확인할 수 있습니다.\n\n# 단계 4: 웹 애플리케이션 방화벽 (WAF) 확인\n\n<div class=\"content-ad\"></div>\n\n![텍스트](/assets/img/2024-06-19-HuntingforOriginIPABeginnersGuide_3.png)\n\n이제 메인 도메인 웹사이트에 Cloudflare와 같은 WAF가 있는지 확인해 봅시다. 반면, IP 주소를 확인할 때는 WAF가 없는지 확인해 봅니다. WAF가 없다면 DDoS 공격을 할 수 있고, 속도 제한 우회, SQL Injection 수행 및 다른 취약점에 접근할 수 있습니다.\n\n# 단계 5: Foofa 사용하기\n\n[https://en.fofa.info/](https://en.fofa.info/)\n\n<div class=\"content-ad\"></div>\n\n만약 Shodan이나 Censys를 사용하여 원본 IP를 찾는 데 어려움을 겪는다면, Foofa라는 다른 검색 엔진이 있습니다. 도메인을 입력하면 Foofa가 관련된 IP 주소를 제공해줍니다.\n\n더 많은 검색 엔진 :\n\n- [https://securitytrails.com/](https://securitytrails.com/)\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n이 테이블 태그를 마크다운 형식으로 바꿔보겠습니다.\n\n이렇게 원본 IP를 찾을 수 있어요. 이 가이드가 도움이 되었으면 좋겠어요. 원본 IP를 신고하고 관련 정보를 기재한 리포트도 곧 보내드릴게요. 버그를 신고하거나 회사와 플랫폼에 제출할 때 비슷한 형식을 사용하시면 좋을 거예요.\n\n그럼 그때까지, 안녕히 가세요. 다음에 또 만나요!\n\n제 소셜 미디어:\n\nX: [https://x.com/techypruthu](https://x.com/techypruthu)\n\n<div class=\"content-ad\"></div>\n\nLinkedIn: [Pruthu Raut](https://www.linkedin.com/in/pruthu-raut-89260a26a/)\n\n## 보고서\n\n## 개요\n\n웹 응용 프로그램 방화벽 (WAF)은 패턴 일치 및 트래픽 분석을 사용하여 교차 사이트 스크립팅 (XSS), SQL 삽입 및 악성 문자열과 같은 공격으로부터 응용 프로그램을 보호합니다. 일부 응용프로그램은 주요 방어 수단으로 WAF에 완전히 의존합니다. WAF를 우회하는 공격자는 특별히 만든 페이로드를 통해 응용 프로그램 서버에 직접 액세스할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 사업 영향\n\nWAF 우회는 고객의 응용 프로그램 보안에 대한 신뢰에 영향을 미쳐, 사업에 평판 피해와 간접적인 재정적 손실을 가져올 수 있습니다. 공격자가 서버에 직접 액세스 권한을 성공적으로 얻으면 사용자 계정 침해와 데이터 유출로 이어질 수 있습니다.\n\n# 재현 단계\n\n- 대상 웹 사이트 방문하고 확장 프로그램 \"Wappalyzer\"를 사용하여 사이트가 Cloudflare WAF를 사용하는지 확인합니다.\n- https://search.censys.io/ 방문합니다.\n- 대상 도메인을 검색 상자에 붙여넣습니다.\n- 찾은 IP 주소 'IP'를 방문합니다.\n- 방화벽이 없음을 확인합니다.\n- 확장 프로그램 \"Wappalyzer\"를 사용하여 사이트가 Cloudflare WAF를 사용하고 있지 않은지 확인합니다.\n\n<div class=\"content-ad\"></div>\n\n# 권장 사항\n\n- 클라우드플레어로부터 \"직접 IP\" DNS 공급 업체로 이동하더라도 서버 IP는 노출될 수 있습니다.\n- 서버 방화벽을 구성하여 클라우드플레어 IP 범위만 허용하십시오.\n- 사람들에게 호스트 이름을 사용하도록 강제하세요; 이 작업은 000_default 구성 파일에서 수행할 수 있습니다.\n- 클라우드플레어 자체 가이드라인과 일치하는 이러한 권장 사항은, 원본 서버가 클라우드플레어의 IP 주소 범위와 전용 통신해야 한다는 것입니다. 그렇지 않으면 클라우드플레어 블로그의 게시물에 보고된 것처럼, 역방향 프록시를 보유하는 것에 의한 보호 기능이 사실상 무용지물이 될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-19-HuntingforOriginIPABeginnersGuide_0.png"},"coverImage":"/assets/img/2024-06-19-HuntingforOriginIPABeginnersGuide_0.png","tag":["Tech"],"readingTime":4},{"title":"AI를 활용하여 멋진 다중 프레임 일러스트레이션을 생성해보세요","description":"","date":"2024-06-19 04:14","slug":"2024-06-19-Generatestunningmulti-frameillustrationswithAI","content":"\n\n이전 게시물에서는 DALL-E(ChatGPT)를 사용하여 멀티 프레임 이미지에서 캐릭터 일관성을 어떻게 달성하는지 설명했습니다.\n\n오늘은 Ideogram 및 Midjourney와 같은 다른 AI 창조 예술 도구와 함께 활용할 수있는 일러스트레이션을 만드는 다른 방법을 살펴보겠습니다.\n\n우연히 DALL-E에게 이미지를 생성하도록 요청했는데, 특히 마음에 드는 하나가 있습니다:\n\n![image](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_0.png)\n\n<div class=\"content-ad\"></div>\n\n그러던 중, DALL-E (ChatGPT)에게 다른 주제로 전환하도록 지시하여 자연어로 직접 소통하도록 했어요.\n\n![Image 1](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_1.png)\n\n![Image 2](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_2.png)\n\n![Image 3](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_3.png)\n\n<div class=\"content-ad\"></div>\n\n# 프롬프트 템플릿 요약\n\n다음으로, DALL-E에게 스타일을 요약하고 일반적인 프롬프트 템플릿을 제공하도록 요청했습니다.\n\n다음은 제공된 프롬프트 템플릿입니다:\n\n![프롬프트 템플릿](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_4.png)\n\n<div class=\"content-ad\"></div>\n\n그런 다음, 저는 DALL-E에게 고양이가 다른 활동에 참여하는 이미지를 생성하도록 요청했습니다:\n\n결과적인 효과에 상당히 만족했어요:\n\n![cat engaging in different activities](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_5.png)\n\n일반적인 템플릿을 만들기 위해 DALL-E에게 프롬프트 템플릿을 요약해 주도록 했습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![Image 6](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_6.png)\n\n![Image 7](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_7.png)\n\n![Image 8](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_8.png)\n\n![Image 9](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_9.png)\n\n\n<div class=\"content-ad\"></div>\n\n위의 프롬프트에서 활동을 1-16까지 확장하면 다음 이미지가 생성됩니다:\n\n![이미지1](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_10.png)\n\n![이미지2](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_11.png)\n\nDALL-E에게 9패널 또는 16패널 이미지를 생성하도록 요청하면 종종 패널 수가 맞지 않고 불안정할 수 있습니다. 이 문제를 해결하기 위해 ideogram.ai에 의지했습니다. 제네릭 템플릿을 Claude에게 보내 프롬프트를 생성하도록 요청했어요.\n\n<div class=\"content-ad\"></div>\n\n아래 이미지가 생성되었습니다.\n\n# 멀티 프레임 일러스트레이션 쇼케이스\n\n# 낚시 마스터들\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_13.png\" />\n\n<img src=\"/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_14.png\" />\n\n<img src=\"/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_15.png\" />\n\n# Chemistry Teacher\n\n\n<div class=\"content-ad\"></div>\n\nMarkdown 형식으로 테이블 태그를 변경해주세요.\n\n\n![이미지](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_16.png)\n\n# 낚시 선생님\n![이미지](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_17.png)\n\n# 야구 선수\n\n\n<div class=\"content-ad\"></div>\n\n\n![Astronaut](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_18.png)\n\n# Astronaut\n\n![Roller Coaster Enthusiasts](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_19.png)\n\n# Roller Coaster Enthusiasts\n\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_20.png)\n\n# Master of the Grilled Fish\n\n![image](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_21.png)\n\n# Battle Masters\n\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_22.png)\n\n# Masters of Synchronized Swimming\n\n![image](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_23.png)\n\n# Ballet Master on Ice\n\n\n<div class=\"content-ad\"></div>\n\n아래는 Markdown 형식으로 변경해 봅니다.\n\n\n![Generatestunningmulti-frameillustrationswithAI_24](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_24.png)\n\n# Singer\n\n![Generatestunningmulti-frameillustrationswithAI_25](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_25.png)\n\n# Environmental Guards\n\n\n<div class=\"content-ad\"></div>\n\n\n![Street Dancer](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_26.png)\n\n# Street Dancer\n\n![Expressionist Cat](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_27.png)\n\n# Expressionist Cat\n\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_28.png\" />\n\n# Gourmet\n\n<img src=\"/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_29.png\" />\n\n# Homework Robot Cat\n\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_30.png)\n\n# Other Examples\n\nideogram.ai is great at drawing various animals using the prompt template I created.\n\n![image](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_31.png)\n\n\n<div class=\"content-ad\"></div>\n\n아이디오그램.ai가 생성하는 이미지에 텍스트도 생성될 수 있습니다.\n\n\\[이미지1\\](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_32.png)\n\n\\[이미지2\\](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_33.png)\n\n\\[이미지3\\](/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_34.png)\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n다양한 AI 도구를 탐색하고 프롬프트 템플릿을 개선함으로써 여러 프레임 일러스트레이션을 만들 수 있습니다. 이 방법을 사용하면 융통성과 창의성을 발휘하여 AI 생성 아트의 가능성을 넓힐 수 있습니다.\n\nby公众号：kate人不错\n\n## 기사가 마음에 드셨나요?\n\n<div class=\"content-ad\"></div>\n\n네, 그렇다면:\n\n- 댓글 남기기\n- 업데이트 팔로우하기\n- 무료 이메일 알림","ogImage":{"url":"/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_0.png"},"coverImage":"/assets/img/2024-06-19-Generatestunningmulti-frameillustrationswithAI_0.png","tag":["Tech"],"readingTime":6},{"title":"AI 음성 복제가 오디오북 산업을 뒤흔들 준비 중입니다","description":"","date":"2024-06-19 04:10","slug":"2024-06-19-AIVoiceCloningisAbouttoShakeUptheAudiobookIndustry","content":"\n\n![AIVoiceCloningisAbouttoShakeUptheAudiobookIndustry](/assets/img/2024-06-19-AIVoiceCloningisAbouttoShakeUptheAudiobookIndustry_0.png)\n\n요즘들어 오디오북이 많이 인기를 끌고 있어요. 생동감 넘치는 내레이션과 다양한 효과음을 통해 텍스트 기반의 책보다 더 몰입감을 느낄 수 있죠. 사람들은 오디오북을 들으며 다른 (보통 언어를 사용하지 않는) 작업을 할 수 있어서 바쁜 사람들이나 읽을 시간이 부족한 사람들에게 좋은 선택지가 될 수 있어요. 시각 장애가 있는 독자들에게도 비싼 점자책의 대안이 될 수 있어요.\n\n저는 오디오북이 읽는 것과 관련된 활동적인 청취를 포함하여 읽은 것으로 간주될 수 있다고 생각했던 오디오북 비판론자였어요. 그러나 생각이 바뀌었어요. 오디오북을 사랑하게 되었고, 매일 읽는 책의 수가 거의 세 배로 늘어났어요.\n\n<div class=\"content-ad\"></div>\n\n이 모든 것은 오디오북의 위대함을 인정한다는 것을 의미합니다. 그리고 그것이 왜 인디 작가로서 나는 내 소설 중 하나를 오디오북으로 만들고 싶어했는지 설명합니다. 그러나 이 일은 (창작과 제작 부분 포함) 값이 싸지 않습니다!\n\n오디오북을 만들고 싶다면, 이야기를 내려주기 위해 성우나 성우들에게 돈을 지불해야 합니다. 녹음 스튜디오나 녹음 장비를 구입해야 합니다 (성우가 그것을 수행하는 경우를 제외하고요, 그들의 비용의 일환으로 진행하는 경우가 많습니다). 오디오 엔지니어/프로듀서에게 책을 편집하도록 지시해야 하며, 다른 기능을 추가하려면 비용이 늘어납니다, 예를 들어 추가 효과음 등 (다시 말하지만, 많은 성우들이 프로듀서로도 활동하며 오디오를 편집합니다). 자신의 책이 어떻게 읽히는지 중요하다면, 책을 오디오 대본으로 적응하는 데 시간과 노력을 들여서 성우들이 책을 어떻게 읽어야 하는지에 대한 지침을 제공해야 합니다.\n\n이 일을 직접 수행할 수도 있지만, 내려주기와 오디오 편집은 각각의 학습 곡선과 비용이 있는 어려운 시간 소모적인 작업입니다.\n\nACX와 같은 최신 플랫폼은 이 프로세스를 크게 간소화했지만, 간소화되었더라도, 프로세스는 여전히 상당히 비싸며 복잡성이 없는 것은 아닙니다.\n\n<div class=\"content-ad\"></div>\n\n# 음성 AI와 오디오북\n\n생성적 음성 AI는 오디오북 제작에 중요한 영향을 미치며, 현재 이 기술에 대해 많은 기업들이 작업 중에 있습니다.\n\nResemble.AI는 이와 같은 기업 중 하나로, \"생성적 음성 AI를 새로운 수준으로 끌어올리고 있다\"고 자처합니다. (이 회사가 Netflix 다큐멘터리 시리즈 '앤디 워홀 다이어리'를 위해 앤디 워홀의 목소리를 재현한 곳입니다.)\n\nResemble.AI의 생성적 음성 AI 툴킷은 다양한 응용 분야가 있지만, 그 중 하나는 작가와 출판사를 위한 오디오북 제작입니다. 맞아요: AI가 생성한 오디오북입니다.\n\n<div class=\"content-ad\"></div>\n\n그들과 같은 기술의 점점 더 많은 이용 가능성은 오디오북 제작의 비용 효율성이 크게 향상될 뿐만 아니라, 관련된 복잡한 프로세스도 감소될 것입니다.\n\nResemble.AI의 웹사이트에는 다음과 같이 나와 있습니다. \"Resemble AI의 디지턈 내레이션 기술을 이용하면 이전에 듣지 못했던 수백만 권의 책들을 쉽게 오디오북으로 변환할 수 있습니다. 이전에 오디오북 제작의 비용과 복잡성을 감당할 수 없었던 독립 작가들과 작은 출판사들은 이제 자신들의 책들을 점점 늘어나는 오디오북 청취자들에게 제공할 수 있게 되었습니다.\"\n\n생산 과정을 간소화함으로써 Resemble.AI는 전통적으로 연결된 시간과 자금 투자를 대폭 줄일 것입니다. 데이터를 제출한 후 몇 분 내에 AI 목소리를 만들 수 있게 되는 능력으로, 작가들(인디 작가 포함)은 빠르게 자신의 이야기를 매혹적인 오디오북으로 변신시킬 수 있을 것입니다. 이를 통해 더 많은 청중에게 도달할 수 있는 동시에 큰 비용을 들이지 않고도 가능할 것입니다.\n\nResemble.AI의 기술은 현재 일부 사용자에게만 공개되어 있지만, 준비하세요: 그들과 같은 기술에 대한 접근이 점점 더 늘어남에 따라 오디오북 산업은 AI 내레이션 책을 대대적으로 증가할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# AI로 내려받은 오디오북 제작 과정은 어떻게 될까요?\n\n상상해보세요: 저는 현대 소설을 AI 낭독으로 변환하고 싶어 합니다.\n\n먼저, 두 가지 옵션이 있습니다: 제 목소리를 복제하거나 (다른) AI 목소리를 사용할 수 있습니다.\n\n나는 내 목소리 클론을 사용하여 오디오북을 낭독하기로 결정했습니다. Resemble.AI를 사용하면 프로세스가 간단합니다. 웹 녹음기를 사용하여 목소리를 녹음하거나 내 목소리가 포함된 기존 오디오 데이터를 업로드할 수 있습니다. 저는 후자의 옵션을 선택했고, AI를 훈련하기 위해 몇 분 (25문장)의 녹음만으로 충분합니다.\n\n<div class=\"content-ad\"></div>\n\nAI를 사용하여 내 AI 음성 복제본을 이용해 완전한 오디오북을 생성하는 데 조금 더 시간이 걸립니다.\n\n만두! 모두를 위해 초기 녹음을 얻었어요. 내 만족도를 보장하기 위해 들어봐야겠어요.\n\n만족스러우면, 언젠가! 내 오디오북의 상당 부분을 완성했습니다.\n\n만족하지 못하면, 다른 음성을 사용하기로 결정할 수도 있어요. 어찌되었건 Resemble.AI의 음성 마켓에서 다른 음성을 이용해볼 수 있어요. 사이트는 \"다양한 장르에 최적화된 디지털 음성의 폭넓은 선택이 [당신이] 상상하는대로 오디오북의 소리를 보장할 것\"이라고 약속해줍니다.\n\n<div class=\"content-ad\"></div>\n\n저는 그들의 프로그래밍 인터페이스를 활용하여 제 목소리 클론의 성능이나 그들의 마켓플레이스에서 제공되는 다른 AI 내레이터들의 성능을 실험할 수도 있어요.\n\n그들의 API 중 하나인 감정 그라디언트는 사용 가능한 도구 중 하나인데요, 여기서 감정, 강조, 그리고 드라마틱한 일시정지를 추가할 수 있어요. 감정은 표현력(음높이), 공격성(음량), 그리고 음조(속도)를 의미하는데, 이 모든 요소들이 다양한 수준으로 다뤄질 수 있어요. 이 기능을 사용하면 특정 구절, 개별 문장, 또는 단어 하나까지 강조할 수 있어요. 이렇게 하면 AI 내레이터가 어떻게 소리낼지에 상당한 제어력을 가질 수 있어요.\n\n일부 독자들은 AI 내레이터가 저자의 말을 망칠까 걱정할 수 있겠죠. 이는 타당한 우려에요. AI는 특정 단어들을 잘못 읽을 수 있습니다. Resemble.AI가 제공하는 예시 중 하나(이 비디오에서 확인할 수 있어요)는 다음 문장입니다. \"비둘기가 낮게 날았다가 바다로 다이빙했다.\" 만약 이 문장을 제공한다면, AI는 \"dove\"의 두 형태를 명사 또는 동사로 오인할 수 있습니다. 그래서 Resemble.AI에는 단어를 클릭하여 품사를 올바르게 선택할 수 있는 드롭다운 메뉴가 나오는 기능이 있어요. (하지만 \"토마토, 토마토\"라는 속담에는 이 방법이 도움이 될 지는 모르겠네요!)\n\n만약 이 모든 단계를 거친 후에도 만족스럽지 않다면 — 예를 들어 내레이션 소리가 너무 로봇적으로 들린다면 — 더 많은 옵션을 사용할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\nResemble.AI의 음성 대 음성 엔진이 필요한 것일지도 모릅니다. 이 음성 대 음성 엔진은 \"인간과 유사한 성능을 실제로 반영하는 AI 보이스오버를 생성할 수 있습니다. 인간의 언어의 모든 불완전함을 포함한 것들\"을 만들어 낼 수 있습니다. 이러한 불완전함에는 원본 음성의 \"모든 세물릿, 수다스러운 표현, 사투리, 강세\"가 포함되어 있습니다... 그 모든 것들이 AI가 생성한 음성에 반영됩니다.\n\n물론, 음성 대 음성 엔진을 사용하면 오디오북 제작 과정에 상당한 시간이 추가되지만, 놀라운 혜택을 얻을 수 있는 선택지입니다.\n\n이 엔진을 사용하면 \"억양을 변화시키고, 강세를 더하며 음조를 수정\"함으로써 제 목소리의 소리를 변조할 수 있습니다. 저는 감정을 추가하기 위해 화난, 공격적인 스킨이나 초강한 스킨과 같은 보이스 스킨을 사용할 수 있습니다.\n\n더욱이: Resemble.AI 사용자는 음성 대 음성 음성 생성과 텍스트 대 음성 음성 생성을 매끄럽게 결합하여 \"자동화, 품질 또는 텍스트 대 음성 시스템의 속도를 희생하지 않으면서 독특한 인간과 유사한 음성화를 만들 수 있습니다.\" 즉, 책의 특정 부분에는 텍스트 대 음성을 사용하고 나레이션이 특정한 방식으로 들리길 원하는 책의 다른 부분에는 음성 대 음성을 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n제 현대 소설에는 세 가지 번갈아가는 시점이 사용되므로, 나는 Resemble.AI의 서비스에 매우 만족하고 있습니다. 나는 각 시점의 내러레이터가 다르게 들리기를 원하기 때문입니다. 이 기술의 변조 기능, 음성 스킨 및 합성 음성을 사용하여 나는 내 음성 클론을 모든 세 개의 음성의 기반으로 사용하더라도 또한 각 시점 캐릭터들이 서로 다르게 들리도록 쉽게 구현할 수 있습니다.\n\n또한, Resemble.AI의 로컬라이제이션 기능을 통해 내 책을 최대 60개 언어로 번역하여 전 세계 독자들에게 더 쉽게 접근할 수 있습니다. Localize를 사용하면 실제로 일본어로 말하는 제 자신의 목소리 클론을 들을 수도 있습니다. 내 생각에는 신기한 일이죠.\n\n\"우리는 작가와 출판사와 밀접히 협력하여 최종 제품이 원작에 충실하고 작가의 목소리에 정의를 할 수 있도록 보장합니다,\" 라는 Resemble.AI의 웹사이트 오디오북 페이지에 약속하고 있습니다. 나는 이러한 회사들이 오디오북 산업의 변화에 어느 정도 기여하는지 얼마나 궁금하게 생각합니다.\n\n# 음성 클론 기술의 윤리학\n\n<div class=\"content-ad\"></div>\n\n물론 Resemble.AI의 기술은 다양한 윤리 문제를 불러일으킵니다.\n\n일반적으로 음성 클론의 윤리는 이미 매우 모호한데, 음성 클론의 잠재적 남용과 남용이 끔찍한 결과를 초래할 수 있기 때문입니다 (아마도 Resemble.AI가 최근 공개한 Resemble Detect는 딥페이크 오디오를 탐지할 수 있다고 하여 이것이 그 이유일 것입니다). 예를 들어, 음성 클론은 아이들을 조종하거나 사기 행위에 가담하거나, 혐오 발언을 퍼뜨리고 폭력을 선동하기 위해 딥페이크 콘텐츠를 생성하는 등 다양한 형태의 속임수에 사용될 수 있습니다.\n\n음성 클론의 단점이 너무나 추악하기 때문에, Resemble.AI와 같은 기업에 대한 우려가 전혀 타당합니다. Resemble.AI는 윤리 성명서에 전체 페이지를 바친 상태이며, 해당 페이지에서 자신들의 AI를 사용할 수 없는 금지된 용도 목록을 제공합니다:\n\n<div class=\"content-ad\"></div>\n\n이 목록은 직접적으로 사람들이 기술을 이러한 목적으로 사용하는 것을 막지는 못하지만, 기술을 오용하는 사용자는 계정이 정지될 가능성이 높을 것입니다 (또는 법 집행 기관이 개입될 경우 더 나쁜 결과를 안게 될 수도 있습니다; 이러한 법적 결과는 음성 클론에 대한 규제가 발전함에 따라 달라질 수 있습니다).\n\nResemble.AI와 같은 기술을 사용하여 오디오북을 제작하는 것과 관련된 다른 윤리적 고민도 있습니다. \n\n당신의 목소리를 사용하여 Resemble.AI로 오디오북을 만든다면, 당신이 Resemble.AI 사이트에 본인의 음성 클론을 업로드하면, 데이터 침해를 통해 도용될 가능성이 있고 다른 (잠재적으로 악의적인) 목적으로 사용될 수도 있습니다. 그리고 이미 여러분의 목소리 녹음이 이미 공개되어 있거나 불법적이거나 숨겨진 방법으로 획득된 경우에는 당신의 목소리를 기반으로 한 다른 AI 음성 생성기가 여러분의 목소리에 학습될 수 있습니다.\n\n회사의 AI 음성을 훈련시키기 위해 사용된 사람들의 목소리를 기본적으로 통제 권한을 포기한 것일까요? 그들은 절대적으로 나쁜 책들과 (가능성이 있는) 해로운 콘텐츠/목적을 가진 책들과 영원히 관련될 것에 대해 걱정해야 할까요? 그것이 사실인 것 같습니다.\n\n<div class=\"content-ad\"></div>\n\n작업과 소득 손실이 생길 것입니다, 비록 음성 클로닝 자체가 새로운 수익원이 될 것입니다. Resemble.AI는 다양한 성우들과 협력하여 그들의 음성 AI 마켓플레이스에서 사용 가능한 합성 인간 기반 음성을 만들었으므로, 이를 훈련하기 위해 사용된 성우들은 자신의 AI 대응품에서 수동 수익을 올린다고 추측됩니다. 장기적으로 일부 성우들에게 이득이 될 수 있지만, 자신의 음성 클론을 판매하는 용이함 (그리고 이 과정에서 진정한 음성 연기가 필요하지 않음)으로 인해 AI 음성 시장이 빠르게 포화되어 새로운 성우들이 음성 클로너들에게 제공되는 수동 수익을 활용하는 것이 어려워질 것으로 예측합니다. 한편, 현재 오디오북 제작 등을 통해 수입의 많은 부분을 얻고 있는 성우들은 어떻게 될까요? AI 음성 클론이 이 산업에서 제공되는 일자리를 크게 줄일 것인가요?\n\n일부 유명인들은 이를 통해 추가 소득을 올리기 위해 뛰어들 수도 있을 것 같습니다 (자신의 음성이 제어할 수 없는 콘텐츠를 낭송하는 데 사용된 것에 반대하지 않는다면). 예를 들어, 몬 블랑 프리먼의 음성이 비픽션 책을 낭송하는 데 사용 가능하다면, Resemble.AI와 같은 소프트웨어의 가격 모델에 어떤 영향을 줄까요? 이것이 음성 클론 간의 경쟁에 어떤 영향을 미칠까요? 오디오북 제작자들은 널리 알려진 음성을 소제 더 선호할까요?\n\nAI가 생성한 책이 오디오북 시장을 포화시킬 것인가요? 제 예측은: 상당히 그럴 것입니다. 저는 출판 산업이 항상 좋은 글에 관심이 없다고 단언하며, 많은 좋은 작가들이 최선을 다하지만 전통적인 출판을 달성하지 못하는 경우도 많다고 믿습니다. 한편, 많은 쓰레기 책이 출판됩니다. Resemble.AI와 같은 기술은 이러한 숨겨진 보석 작가들 중 일부가 독자들에게 더 많은 책을 전달하는 데 도움이 될 수 있지만, 또한 그들을 더 많은 쓰레기 책의 산더미에 묻을 수도 있으며, 결과적으로 그들이 더 많은 독자에게 도달하지 못하게 할 수 있습니다.\n\n또한 오디오북 출판 플랫폼이 AI가 생성한 오디오북의 곧 다가올 쇄도에 어떻게 대응할지 살펴봐야 합니다. AI가 생성한 오디오북 주변에 어떤 신규 규제가 만들어질까요? 이러한 책들은 사람이 낭송한 오디오북과 비교하여 어떻게 마케팅 및 판매될까요?\n\n<div class=\"content-ad\"></div>\n\n마침내, 일부 독자는 인간이 내주는 이야기들을 선호하여 완전히 AI로 이야기하는 책을 비난할 것이라고 확신합니다. 마찬가지로, \"너무 로봇적으로 들리는\" 실제 이야기꾼들도 AI 이야기꾼과 함께 배척될 수 있습니다. (만약 \"인간 같이 들리는\" 사람들이 새로운 트렌드가 된다면, 우리 모두 함께 웃을 수 있겠죠.)\n\n나는 새로운 AI 기술에 대해 자주 갈등을 느끼기 때문에, AI에 대한 내 입장을 확정하기 어려웠어요. AI가 위대한 일을 이룰 수 있는 잠재력을 갖고 있다고 생각하지만, 특히 인간들이 그것을 남용할 방법을 두려워하기도 해요.\n\n나는 나 자신을 AI 패배주의자로 생각합니다: AI가 머물러 있고 세계에 영향을 미칠 것이라는 것을 깨달았으니, 그것을 가장 잘 활용하고 긍정적인 영향에 집중하는 것이 어떨까요?\n\n예를 들어, 내 꿈인 오디오북을 싸고 효율적으로 만들기 위해 AI를 사용하고 싶다면, 왜 안되겠어요? 내 관점에서는, 모두가 AI로 이야기하는 책을 출시하기로 결정하기 전에, 빨리 몽땅에 올라타는 게 좋을 것 같아요. 그 날이 우리가 생각하는 것보다 빨리 올 수도 있어요.\n\n<div class=\"content-ad\"></div>\n\n- 'Resemble.AI'와 전혀 관련이 없음을 주의해주세요. 그들의 회사를 주의 깊게 지켜보고 있습니다. 그들이 하는 일에 대해 걱정되고 기대되는 마음이 교차하고 있습니다. 이 기사는 광고가 아닙니다.\n\n## 생성기로부터 더 많은 정보","ogImage":{"url":"/assets/img/2024-06-19-AIVoiceCloningisAbouttoShakeUptheAudiobookIndustry_0.png"},"coverImage":"/assets/img/2024-06-19-AIVoiceCloningisAbouttoShakeUptheAudiobookIndustry_0.png","tag":["Tech"],"readingTime":8},{"title":"중간 이미지를 써본적 없이 만드는 방법","description":"","date":"2024-06-19 04:09","slug":"2024-06-19-HowtoCreateMidjourneyImagesWithoutWritingaSinglePrompt","content":"\n\n## 자유로운 창의력\n\n안녕하세요, Midjourney 크루 여러분. 모두 잘 지내고 있길 바라요.\n\n완벽한 프롬프트를 작성하고 환상적인 이미지를 만드는 데는 시간이 걸린다는 것을 알고 계실 것입니다... 물론 Midjourney가 몇 가지 키워드로 상상력을 발휘하게 할 수도 있죠.\n\n어찌되었든 몇 마디쯤은 써야 합니다. 이제 Midjourney는 텍스트를 이미지로 변환하는 생성기니까요.\n\n<div class=\"content-ad\"></div>\n\n하지만 실제로 한 마디도 쓰지 않고 이미지를 만들 수 있는 또 다른 방법이 있습니다.\n\n🚨 전혀 유도없이요! 대단하지 않나요?\n\n자세한 내용에 대해 들어가기 전에, 프롬프트를 생성하는 세 번째 방법을 간단히 설명해 드리겠습니다. 이것은 Midjourney의 설명 기능을 사용합니다. 이미지를 업로드한 후 작은 \"i\" 아이콘을 클릭하기만 하면 됩니다.\nMidjourney는 이미지를 설명하는 일련의 문구와 키워드를 제시할 것입니다. 이들을 섞거나 매치하여 이미지를 복제(복사하지는 않음)하는 프롬프트를 만들 수 있습니다.\n\n여기에 describe에 대해 더 쓴 글이 있습니다:\n\n<div class=\"content-ad\"></div>\n\n🎯 그러나 이제는 프롬프팅없이 계속 진행해 봅시다.\n\n## 블렌딩이 중요합니다\n\nMidjourney 블렌드 기능이 여러분의 새로운 친구입니다.\n\n할 일은 간단합니다. 웹 사이트에 이미지를 업로드하거나 자체 작품을 사용하기만 하면 됩니다. 최소 두 개를 업로드한 후에는 엔터 키를 누르기만 하면 Midjourney가 모든 마법을 다 해 줄 것입니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 예제입니다:\n\n## 소녀와 앵무새\n\nMidjourney는 첫 번째 두 이미지를 세 번째 이미지로 잘 결합했고 전체적인 스타일과 캐릭터를 유지했습니다.\n\n<div class=\"content-ad\"></div>\n\n## 잘 돌아가다가 갑자기 안 돌아갈 때가 있어요\n\n시작해서 혼합을 시작할 때는 조금 랜덤할 수 있어요.\n\n결과물을 알 수 없지만, 그것도 프로세스의 일부이며 재미있고 놀라운 것이에요. 팁: 때로는 창작물을 두 번 또는 세 번 재실행하는 것이 도움이 될 때도 있어요.\n\n맞아요, 때로는 이상한 이미지가 나오기도 하지만, 다시 말하지만 그것도 재미의 일부에요.\n\n<div class=\"content-ad\"></div>\n\n## 컴퓨터 소녀\n\n## 밤에 울부짖는 늑대\n\n## 드래곤 판타지\n\n## 알프스의 사무실\n\n<div class=\"content-ad\"></div>\n\n## 고급 팁\n\n한 걸음 더 나아가고 싶다면 혼합하면서 프롬프트도 표시할 수 있습니다. 이 경우 이미지는 참조용으로 사용됩니다.\n\n결과물은 완전히 다를 것입니다. 두 이미지를 단순히 혼합하는 대신 Midjourney는 이제 텍스트에 이미지보다 더 많은 중요성을 부여할 것입니다.\n\n그러므로 상세한 프롬프트를 작성하는 것이 중요합니다. 첫 번째부터 프롬프팅을 시작했다면 더 좋았을 텐데, 맞죠?\n\n<div class=\"content-ad\"></div>\n\n아래에 표가 있습니다. 이미지를 혼합하면 어떤 프롬프트도 없이 완전히 새로운 이미지를 만들 수 있습니다.\n\n💬 이미지를 혼합해 보신 적이 있나요?\n\n<img src=\"/assets/img/2024-06-19-HowtoCreateMidjourneyImagesWithoutWritingaSinglePrompt_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n이 이야기는 Generative AI에 발행되었습니다. 최신 AI 이야기를 함께 보려면 LinkedIn을 통해 저희와 연락하고 Zeniteq를 팔로우해주세요.\n\n생성적 AI에 대한 최신 뉴스 및 업데이트를 받기 위해 뉴스레터를 구독해주세요. 함께 AI의 미래를 만들어 봅시다!\n\n![이미지](/assets/img/2024-06-19-HowtoCreateMidjourneyImagesWithoutWritingaSinglePrompt_3.png)","ogImage":{"url":"/assets/img/2024-06-19-HowtoCreateMidjourneyImagesWithoutWritingaSinglePrompt_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoCreateMidjourneyImagesWithoutWritingaSinglePrompt_0.png","tag":["Tech"],"readingTime":2},{"title":"알고리즘 세계에서 미디어의 출처를 확인하는 방법","description":"","date":"2024-06-19 04:07","slug":"2024-06-19-VerifyingtheOriginofMediainanAlgorithmicWorld","content":"\n\n## C2PA 콘텐츠 신뢰성 사양 및 Rust SDK 소개\n\n![이미지](/assets/img/2024-06-19-VerifyingtheOriginofMediainanAlgorithmicWorld_0.png)\n\n인간이 직접 제작한 정품 미디어를 딥페이크나 기타 알고리즘으로 생성된 미디어와 구분하는 것은 알려진 바와 같이 매우 어렵습니다. 기존 도구들은 주어진 미디어가 생성될 확률을 제시하지만 확실성을 확보하는 것은 어렵습니다. 알고리듬 미디어와 딥페이크가 온라인 공간을 덮치면서, 정치 및 선거 관련 미디어의 신뢰성을 검증하는 것이 향후 중요해질 것입니다. 온라인 오보나 디스인포메이션을 걸러내는 것 이외에도, 디지털 작품의 원본 권한을 주장하고 싶어하는 예술가들에게 신뢰성을 인정하는 것도 가치가 있습니다.\n\n디지털 이미지나 비디오가 정품인지, 인공적으로 생성되었거나 복제된 것인지를 이해하려면 다음과 같은 것들을 알고 있어야 할 수도 있습니다:\n\n<div class=\"content-ad\"></div>\n\n미디어 메타데이터의 무결성을 확인하는 암호학적으로 안전한 서명 방법이나 카메라 정보, 좌표 및 기타 정보와 같은 것들을 확인하는 방법이 필요합니다.\n또한 원래 형태에서 많이 수정되지 않았음을 알 수 있는 방법이 필요할 것입니다. 수정이 있었다면 그 수정 내용 또한 알 수 있어야 합니다.\n\n그러한 해결책이 있습니다. 아래에서 다음 내용에 대해 이야기하겠습니다:\n- C2PA 명세\n- 명세가 작동하는 방식\n- 코드 지원\n- 어떤 이점이 있는지\n- 문제점\n- 앞으로의 전망은?\n\n# C2PA 명세\n\n<div class=\"content-ad\"></div>\n\n콘텐츠 검증 및 출처 연동을 담당하는 콘텐츠 신뢰도 이니셔티브의 일부인 C2PA 기술 명세서가 Adobe가 주도하는 이니셔티브에서 제작되었습니다. 알고리즘으로 생성된 미디어를 감지하려는 대신, 이 명세서는 미디어의 출처와 미디어가 수명 동안 거쳐온 수정 작업들의 순서를 확인할 수 있는 시스템을 설명합니다. 이 정보는 관련 메타데이터 구조 내에서 암호화된 형태로 주장됩니다.\n\n다른 말로 하면, 이 표준은 메타데이터에서 해당되는 클래스의 미디어가 사실 인간이 생성한 것임을 확신시켜줍니다. 이 메타데이터가 없는 미디어는 C2PA 표준에서 혜택을 받을 수 없습니다. 이 표준은 선택 사항이며, 이에 동의한 장비 제조업체(예: 카메라), 미디어 편집 소프트웨어(포토샵 등), 그리고 미디어의 출처를 확인하고 싶어하는 모든 시스템들에 의존합니다.\n\n![이미지](/assets/img/2024-06-19-VerifyingtheOriginofMediainanAlgorithmicWorld_1.png)\n\n이 시스템과 관련된 개념 중 하나는 미디어와 관련된 Exif 형식이며, 사진이 촬영된 지역, 하드웨어 세부 정보, 카메라 설정과 같은 정보를 포함할 수 있습니다. 그리고 이러한 Exif 데이터는 JPEG와 같은 미디어 파일에 직접 포함됩니다. 이 데이터는 일반적으로 암호화되지 않습니다.\n\n<div class=\"content-ad\"></div>\n\nC2PA 사양은 지원되는 미디어 유형에 직접 메타데이터를 미디어 파일에 포함합니다 (다른 유형의 경우 \"사이드카\" 매니페스트 파일을 생성합니다). 매니페스트에는 다음과 같은 정보가 포함됩니다:\n\n- 미디어 원본 정보 (디지턈 카메라 캡처, 다른 창작물)\n- 시간 경과에 따른 미디어 수정 내역, 사용된 도구 및 작업자\n- 매니페스트가 조작 방지임을 보장하는 디지털 서명\n- 그 외\n\n메타데이터 자체는 JUMBF 형식(JPEG Universal Metadata Box Format)으로 저장됩니다.\n\n# 사양이 작동하는 방식\n\n<div class=\"content-ad\"></div>\n\n해당 명세는 미디어의 원본에 대한 데이터 집합과 그에 대한 모든 후속 작업에 대한 주장을 포함하는 매니페스트를 설명합니다.\n\n예를 들어 매니페스트는 사진이 특정 날짜와 시간에 특정 카메라로 촬영되었고, 이후 (예를 들어 자르기와 같은) 미디어 편집 도구를 통해 편집되었다는 것을 주장할 수 있습니다. 미디어에 대한 주장은 W3C 신뢰 가능 자격증서로 디지털적으로 서명될 수 있으며, 해당 주장은 (사람 또는 조직)의 Claim으로 넘어갈 수 있습니다. 이에 대한 코드 예시는 아래에서 설명하겠습니다.\n\n![Verifying the Origin of Media in an Algorithmic World](/assets/img/2024-06-19-VerifyingtheOriginofMediainanAlgorithmicWorld_2.png)\n\n복잡하기는 하지만, 툴의 신뢰성 같은 몇 가지 가정을 하면 (수정된 매니페스트를 업데이트한 툴에 대한 신뢰성과 같은), 이 정보는 카메라로 촬영된 미디어와 Midjourney와 같은 모델에 의해 생성된 미디어의 차이점에 대해 알려줄 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n암호화 서명은 청구와 함께 제공되며, 이를 통해 주장이나 다른 메타데이터가 후속 수정되었는지를 판단할 수 있습니다. 예를 들어, 미디어의 원천을 순수 알고리즘 미디어에서 디지털 캡처로 변경하려고 시도하는 경우입니다.\n\n# 코드 해설\n\n여러 파일 유형에 C2PA 개념을 적용할 수 있는 Rust SDK(그리고 c2pa-js와 같은 몇 가지 다른 SDK도 있습니다)가 있습니다.\n\n지금은 해당 SDK를 사용하는 방법에 대한 간단한 단계별 해설을 찾지 못했지만, 일부 탐험적인 코드를 사용하여 해당 SDK의 빠른 개요 데모를 여기에 게시했습니다.\n\n<div class=\"content-ad\"></div>\n\n이 코드는 특정 미디어 파일을 위한 새로운 Manifest를 초기화합니다. 이 Manifest에는 작성자 세부 정보, 콘텐츠에 대한 주장, Exif 또는 사용자 지정 구조와 같은 메타데이터를 인코딩합니다.\n\n예를 들어:\n\n```js\n// 새 미디어를 위한 새 Manifest 생성\nlet mut manifest = Manifest::new(\"mikes-c2pa-test-code/0.1\".to_owned());\n\n// 새, 독창적인 창작물로 이 미디어를 설정\nlet creative_work = CreativeWork::new()\n    .add_author(\n        SchemaDotOrgPerson::new()\n            .set_name(\"Mike Cvet\")\n              .expect(\"set name\")\n            .set_identifier(\"mikecvet\")\n              .expect(\"set identifier\")\n    )?;\n\n// 이 미디어가 생성되었고, 관련 정보가 포함된 주장\nlet created = Actions::new()\n    .add_action(\n        Action::new(c2pa_action::CREATED)\n            // 이것을 원본 디지털 이미지 생성 유즈케이스로 가정\n            .set_source_type(\"https://cv.iptc.org/newscodes/digitalsourcetype/digitalCapture\".to_owned())\n            .set_software_agent(\"mikes-c2pa-test-code/0.1\")\n            .set_when(now_string.clone())\n    );\n\n// 주장을 Manifest에 추가\nmanifest.add_assertion(&creative_work)?;\nmanifest.add_assertion(&created)?;\n\n// 서명 도구 생성\nlet signer = create_signer::from_files(\n  signcert_path, pkey_path, SigningAlg::Ps256, None\n);\n\n// Manifest에 서명하고 미디어 파일에 삽입\nmanifest.embed(&source, &dest, &*signer.unwrap())?;\n```\n\nManifest 내용에는 주장 및 일부 서명 정보에 대한 섹션이 포함됩니다.\n\n<div class=\"content-ad\"></div>\n\n실제 서명 암호 해시는 Manifest 표시 출력에서 삭제되었습니다.\n\n```js\n  \"manifests\": {\n    \"urn:uuid:5772a32a-777e-46d5-b65e-50426d95e84e\": {\n      \"claim_generator\": \"mikes-c2pa-test-code/0.1 c2pa-rs/0.25.2\",\n      \"title\": \"제목\",\n      \"format\": \"image/jpeg\",\n      \"instance_id\": \"xmp:iid:56beb158-2cde-4ef4-b111-5a5a4aea7bef\",\n      \"ingredients\": [],\n      \"assertions\": [\n        {\n          \"label\": \"stds.schema-org.CreativeWork\",\n          \"data\": {\n            \"@context\": \"http://schema.org/\",\n            \"@type\": \"CreativeWork\",\n            \"author\": [\n              {\n                \"@type\": \"Person\",\n                \"identifier\": \"mikecvet\",\n                \"name\": \"Mike Cvet\"\n              }\n            ]\n          },\n          \"kind\": \"Json\"\n        },\n        {\n          \"label\": \"c2pa.actions\",\n          \"data\": {\n            \"actions\": [\n              {\n                \"action\": \"c2pa.created\",\n                \"digitalSourceType\": \"https://cv.iptc.org/newscodes/digitalsourcetype/digitalCapture\",\n                \"softwareAgent\": \"mikes-c2pa-test-code/0.1\",\n                \"when\": \"2023-08-21T08:46:18.159790+00:00\"\n              }\n            ]\n          }\n        },\n\n       /* 더 많은 섹션 */\n\n      \"signature_info\": {\n        \"issuer\": \"C2PA Test Signing Cert\",\n        \"cert_serial_number\": \"720724073027128164015125666832722375746636448153\"\n      },\n      \"label\": \"urn:uuid:5772a32a-777e-46d5-b65e-50426d95e84e\"\n  }\n}\n```\n\nManifestStore는 Manifest 및 이들의 직렬화, 역직렬화, 유효성 검사를 관리합니다.\n\nManifestStore의 서식이 있는 보기 구조를 조사하면 다음이 표시됩니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n{\n  \"active_manifest\": \"uuid:5772a32a-777e-46d5-b65e-50426d95e84e\",\n  \"manifests\": {\n    // 현재 manifest로 식별되는 것에 유의하세요; 다른 manifest들도 존재할 수 있습니다.\n    \"urn:uuid:5772a32a-777e-46d5-b65e-50426d95e84e\": {\n\n      // 이 상자에 설명된 manifest에 포함된 모든 내용입니다.\n    }\n  }\n}\n```\n\n활성 manifest는 미디어에 적용되는 가장 최근의 주장 집합을 가리킵니다. 미디어 파일과 연결된 많은 manifest가 있을 수 있으며, 과거 버전에 대한 주장을 나타냅니다.\n\n파생 자산은 기존 미디어나 콘텐츠에서 만들어진 것입니다. 예를 들어 편집 도구에 로드되어 수정된 이미지 등이 있습니다. 새 Manifest를 생성할 때는 이전 주장을 부모 구성요소로 포함시킵니다. Rust SDK에서는 미디어 파일로부터 기존 Manifest를로드하여 편집하는 것이 불가능하며, 새로운 Manifest가 생성되어야 합니다. 예를 들어, 미디어 편집 소프트웨어가 부모 미디어가 잘린 주장을 추가하려면 다음과 같이 보일 수 있습니다:\n\n```js\n// Manifest를 편집할 수 없습니다. manifest 저장소의 내용을 수정하려면, 이전 버전의 콘텐츠와 해당 manifest를 ingredient로 가져와야 합니다.\nlet parent = Ingredient::from_file(file_path).expect(\"source file\");\n\nlet mut manifest = Manifest::new(\"mikes-c2pa-test-code/0.1\".to_owned());\n\nlet actions = Actions::new()\n    // 이 미디어는 지정된 사용자 에이전트에 의해 열렸습니다.\n    .add_action(\n        Action::new(c2pa_action::OPENED)\n            .set_parameter(\"identifier\", parent.instance_id().to_owned())\n            .expect(\"set id\")\n            .set_reason(\"editing\")\n            .set_software_agent(\"mikes-c2pa-test-code/0.1\")\n            .set_when(now_string.clone())\n    )\n    // 이 미디어는 지정된 사용자 에이전트에 의해 잘렸습니다.\n    .add_action(\n        Action::new(c2pa_action::CROPPED)\n            .set_parameter(\"identifier\", parent.instance_id().to_owned())\n            .expect(\"set id\")\n            .set_reason(\"editing\")\n            .set_source_type(\"https://cv.iptc.org/newscodes/digitalsourcetype/minorHumanEdits\".to_owned())\n            .set_software_agent(\"mikes-c2pa-test-code/0.1\")\n            .set_when(now_string.clone())\n    );\n```\n\n<div class=\"content-ad\"></div>\n\n이것은 콘텐츠에 대한 새로운 주장 세트를 포함하는 새로운 Manifest를 설정합니다:\n\n```js\n{\n  \"claim_generator\": \"mikes-c2pa-test-code/0.1 c2pa-rs/0.25.2\",\n  \"title\": \"test_file.jpg\",\n  \"format\": \"image/jpeg\",\n  \"instance_id\": \"xmp:iid:996edb05-fdf0-4d28-93a2-4e8bf3db3684\",\n  \"ingredients\": [\n    {\n      \"title\": \"test_file.jpg\",\n      \"format\": \"image/jpeg\",\n      \"instance_id\": \"xmp:iid:56beb158-2cde-4ef4-b111-5a5a4aea7bef\",\n      \"relationship\": \"parentOf\",\n      \"active_manifest\": \"urn:uuid:5772a32a-777e-46d5-b65e-50426d95e84e\"\n    }\n  ],\n  \"assertions\": [\n    {\n      \"label\": \"c2pa.actions\",\n      \"data\": {\n        \"actions\": [\n          {\n            \"action\": \"c2pa.opened\",\n            \"parameters\": {\n              \"identifier\": \"xmp:iid:56beb158-2cde-4ef4-b111-5a5a4aea7bef\"\n            },\n            \"reason\": \"editing\",\n            \"softwareAgent\": \"mikes-c2pa-test-code/0.1\",\n            \"when\": \"2023-08-22T05:08:19.134866+00:00\"\n          },\n          {\n            \"action\": \"c2pa.cropped\",\n            \"digitalSourceType\": \"https://cv.iptc.org/newscodes/digitalsourcetype/minorHumanEdits\",\n            \"parameters\": {\n              \"identifier\": \"xmp:iid:56beb158-2cde-4ef4-b111-5a5a4aea7bef\"\n            },\n            \"reason\": \"editing\",\n            \"softwareAgent\": \"mikes-c2pa-test-code/0.1\",\n            \"when\": \"2023-08-22T05:08:19.134866+00:00\"\n          }\n        ]\n      }\n    }\n  ],\n```\n\n이 새로운 주장 세트는 서명되어 있으며 새로운 액티브 Manifest로 미디어에 포함됩니다.\n\n# 이것이 우리에게 무엇을 제공합니까?\n\n<div class=\"content-ad\"></div>\n\n적재소를 이런식으로 불러와 보겠다면:\n\n```js\n  let manifest_store = ManifestStore::from_file(\"./out/test_file.jpg\")?;\n\n  match manifest_store.validation_status() {\n      // 주의: 오류가 있는 경우에만 상태가 나타남\n      Some(statuses) if !statuses.is_empty() => {\n          \n          println!(\"매니페스트를 불러오는 중 유효성 검사 오류 발생:\");\n          for status in statuses {\n              println!(\"유효성 검사 코드: {}\", status.code());\n          }\n\n          panic!(\"데이터 유효성 오류 발생\");\n      },\n      _ => ()\n  }\n```\n\n이렇게 출력됩니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n매니페스트 로딩 중 유효성 검사 오류가 발생했습니다:\n\n유효성 상태 코드: assertion.dataHash.mismatch\n```\n\nManifestStore가 자산의 해시(매니페스트 포함)가 매니페스트 자체에 저장된 해시와 일치하지 않음을 감지했습니다. 따라서 데이터 해시 불일치를 통해 이미지 또는 매니페스트가 변경되었음이 명백해졌습니다.\n\n그러므로 이론적으로, 모든 것이 예상대로 작동한다면, 주어진 미디어 파일의 생성 및 수정 이력이 완전히 고려되고 실제임을 완전히 이해하는 데 이 데이터를 사용할 수 있습니다.\n\n<img src=\"/assets/img/2024-06-19-VerifyingtheOriginofMediainanAlgorithmicWorld_3.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n# 문제들\n\nC2PA 표준도 만병통치약은 아닙니다. 미디어 유형의 신뢰성을 확립할 수 있는 좋은 기회가 있을 것 같지만 다른 고려 사항이 있습니다.\n\n## 개인정보\n\n이 표준은 개인의 고유 식별 데이터를 미디어의 원천 또는 조작과 연결함으로써 작동합니다. 이 데이터의 널리 퍼지는 것은 아마도 산업이 나아가는 방향에 따라 기본적으로 그렇게 될 수 있으며, 미디어 제작자나 저자에게는 의도하지 않았거나 바람직하지 않은 일일 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 동등한 신뢰할 수 있는 정보에 대한 접근\n\n미래에서 우리가 미디어를 창작자의 검증된 자격 증명과 함께 서명할 때에 미디어가 더 신뢰할 만하다고 생각한다면, 그 자격 증명이 없는 사람들이 만든 미디어의 가치는 감소될 것입니다.\n\n## 표준 준수\n\n기술 표준은 규제가 아니며, 중요한 것은 기업들과 그와 연관된 소프트웨어가 적용해야만 영향을 미칩니다. 대부분의 수혜자가 일반적으로 사용할 수 있도록 하기 위해서는 대부분의 미디어가 C2PA 매니페스트를 가져야 할 것입니다. 예를 들어, Apple이 관심을 갖지 않는다고 결정하거나, 미래의 인기 있는 비디오 편집 도구가 동일한 결정을 내린 경우, 이는 생태계에서 일상적으로 생성된 막대한 양의 사용자 생성 미디어를 제외시킵니다.\n\n<div class=\"content-ad\"></div>\n\n## 표준 남용\n\nC2PA는 오픈 표준이기 때문에 누군가가 해당 표준을 준수하는 도구를 만들지 못하게 막는 것은 거의 불가능합니다. 그러나 예를 들어, 모든 알고리즘으로 생성된 미디어를 디지털 캡처로 레이블링하고 해당 내용으로 서명하는 도구를 만들 수 있습니다. 이로 인해 사용 가능한 C2PA 매니페스트 집합이 오염되며, 신뢰할 수 있다면 이를 검증하기 위해 매니페스트 기록에 포함된 사용자 에이전트를 검사해야 할 것입니다.\n\n# 미래에 대한 전망은?\n\n이 표준이 기술 산업에 보다 깊게 자리 잡고 기업들이 계속해서 이를 엄격히 준수한다는 것을 가정한다면, 미디어를 세 가지 그룹으로 나누어 생각할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 신뢰할 만한 출처 정보를 갖춘 미디어는 미디어의 생성 및 수정의 연대기에 대한 맥락을 제공하며 디지털 서명에 의한 암호 보증이 일부 제공됩니다.\n- 출처 데이터에 수정 또는 모순이 감지되는 미디어(예: 순수 알고리즘 미디어의 원본을 디지털 캡처로 대체하거나 수정된 타임스탬프 또는 배우 식별자의 경우와 같이 언급된 경우). 관심 있는 또는 숙련된 관찰자에게 변조가 명백하게 드러나고, 그런 후, 그들 스스로 미디어의 정당성에 대한 결론을 내릴 것입니다.\n- 출처 정보가 전혀 없는 미디어는 그 출처에 대해 확신하기 어렵고, 우리는 확률적 기법에 의존하여 그 신빙성을 결정하려고 합니다.\n\n기자, 미디어 기관 및 소셜 플랫폼은 이러한 범주의 발행에 대해 서로 다른 기준을 적용할 수 있습니다. 첫 번째로, 그들은 증명의 요구를 매우 신뢰할 만한 것으로 다룰 수 있습니다. 둘째로, 그 반대로 할 수 있습니다.\n\n세 번째로, 이러한 기관들은 위험 허용성, 배우들의 신임성 및 생성적 미디어를 감지하려는 도구의 결과를 기반으로 기자적인 결정을 내려야 할 것입니다. 법정에서 제시된 증거, 교실에서 사용된 미디어, 그리고 다른 맥락에서도유사한 고려사항이 해당됩니다.\n\n이것이 어떻게 전개될지, 그리고 어떤 위험이 있는지 아직 일러 알 수 없습니다. 그러나 이 사양 및 그 흐름이 온라인 공간에서 미디어 출처의 검증을 표준으로 만드는 데 중요한 역할을 할 수 있다고 보입니다. 산업의 충분한 약속과 지원이 제공된다면,이 시스템은 미디어 출처 투명성을 온라인 공간의 표준으로 만드는 잠재력을 지닙니다.\n\n<div class=\"content-ad\"></div>\n\nCAI는 광범위한 산업 관심을 받고 있지만, 이러한 출처 규격을 활용하기 위해 산업 전반에서 어떤 구체적인 기술적 약속이 이뤄질지 기다리고 있습니다.","ogImage":{"url":"/assets/img/2024-06-19-VerifyingtheOriginofMediainanAlgorithmicWorld_0.png"},"coverImage":"/assets/img/2024-06-19-VerifyingtheOriginofMediainanAlgorithmicWorld_0.png","tag":["Tech"],"readingTime":12},{"title":"Masa와 Batchingai가 협력하여 Masa Oracle 데이터를 그들의 AI 창작 미술, NFT 플랫폼으로 가져옵니다","description":"","date":"2024-06-19 04:06","slug":"2024-06-19-MasaandBatchingaiPartnertoBringMasaOracleDatatotheirAIGenerativeArtNFTPlatform","content":"\n\n<img src=\"/assets/img/2024-06-19-MasaandBatchingaiPartnertoBringMasaOracleDatatotheirAIGenerativeArtNFTPlatform_0.png\" />\n\n안녕하세요! 맛사가 한국의 AI 생성 예술 NFT 프로젝트인 Batching.ai와 협업했다는 소식을 전해드립니다. Batching.ai는 맛사 오라클을 통합하여 사용자의 소셜 프로필에서 데이터를 수집하고, 이를 재미있고 창의적인 AI 생성 예술 및 NFT로 변환할 예정입니다.\n\nBatching.ai의 고급 AI 이미지 생성 기술은 이미지의 다양성 생성뿐만 아니라, 기존 NFT 이미지를 활용하여 파생 작품을 쉽게 만들 수 있습니다. Batching.ai의 기술을 활용하면 사용자와 프로젝트 모두가 다른 플랫폼보다 더 빠르게 컬렉션을 만들고 문화를 확장하며 홍보 자산을 개발할 수 있습니다.\n\n맛사의 데이터 오라클은 Twitter, Discord, Telegram 등의 플랫폼에서 소중한 사용자 데이터를 수집 및 집계합니다. 맛사의 데이터 오라클을 통해 실시간 구조화된 데이터에 액세스할 수 있으며, 다양한 AI 응용 프로그램에 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이제 Batching.ai가 Masa Data Oracle을 통합함으로써 사용자와 창작자들은 소셜 프로필에서 집계된 사용자 데이터를 기반으로 창조적 AI 아트를 쉽게 만들고 즉시 NFT로 전환할 수 있게 될 것입니다. Masa AI Data Oracle은 또한 사용자의 관심사, 소셜 행동 및 온라인 활동을 캡처하여 Batching.ai에서 동적 이미지를 생성하는 데 사용할 수 있습니다.\n\n이 혁신적인 파트너십을 통해 사용자들은 즉시 사용자 맞춤형 아트 및 NFT, 밈을 만들고 관련 있는 문화적 순간을 포착할 수 있게 될 것입니다. MidJourney와 같은 플랫폼들이 제공하는 창조적인 AI 아트가 대세를 이루고 있지만, 여전히 깊은 개인 맞춤 요소가 부족합니다.\n\n우리는 창조적인 AI 아트 제작의 가능성을 한 층 더 높였습니다. 당신의 디지털과 소셜 풋프린트를 저장하는 Masa의 Data Oracle을 활용함으로써 Batching.ai는 NFT 창작의 새로운 르네상스를 이끌고 있습니다. 사용자에 의해 영감을 받은 아트로 경제적 이익을 얻을 수 있게 하면서, 맞춤형, 재미있고 매력적인 콘텐츠 제작을 이전보다 쉽게 해주고 있습니다.\n\n여기서 Batching.ai에 대해 더 알아보세요: [여기](https://www.batching.ai)\n\n<div class=\"content-ad\"></div>\n\n# Masa Community에 참여해보세요! 👨‍🚀\n\n웹사이트 | 디스코드 | 텔레그램 | 트위터","ogImage":{"url":"/assets/img/2024-06-19-MasaandBatchingaiPartnertoBringMasaOracleDatatotheirAIGenerativeArtNFTPlatform_0.png"},"coverImage":"/assets/img/2024-06-19-MasaandBatchingaiPartnertoBringMasaOracleDatatotheirAIGenerativeArtNFTPlatform_0.png","tag":["Tech"],"readingTime":2},{"title":"파이썬 가드레일로 LLM 출력 신뢰도 향상하기","description":"","date":"2024-06-19 04:03","slug":"2024-06-19-ImproveLLMOutputReliabilitywithPythonGuardrails","content":"\n\n![이미지](/assets/img/2024-06-19-ImproveLLMOutputReliabilitywithPythonGuardrails_0.png)\n\n# IF문을 잘 활용하면 LLM의 출력물을 믿을 수 있는 수준으로 향상시킬 수 있어요\n\nLLM은 창의력과 복잡한 작업 해결에 뛰어나지만 엄격한 규칙을 따르는 데 어려움을 겪기도 하며 종종 설정된 범위를 약간 넘어서 답변을 제공하기도 합니다. 앱을 개발할 때 이러한 주의사항은 사용자들이 퇴장하게 만들 수 있는 실패와 터무니없는 답변으로 이어질 수 있습니다.\n\n좋은 소식은 엄격한 규칙을 작성하는 것이 모든 프로그래머의 기본 역량이며, 지금 LLM과 함께 작업하고 있다고 해서 IF문을 사용하는 방법을 잊은 것은 아니라는 점입니다.\n\n<div class=\"content-ad\"></div>\n\n# LLM 라스트마일 배송 문제\n\n출력을 제어하는 것은 특히 LLM을 API와 같은 앱의 다른 구성 요소와 통합할 때 중요합니다. 사용자 평면 요구 사항의 설명을 검색 매개변수로 변환하는 text_to_params 도구를 작업하는 동안, API 함수와 호환되지 않는 결과 매개변수를 생성하는 것을 깨달았습니다.\n\n전체 API 문서에 액세스할 수 있고 매개변수의 90% 이상을 올바르게 한 상태에서도 여러 매개변수 중 하나가 완전히 답을 망가뜨리는 경우가 있었습니다. 이러한 예시 중 일부는 가격 단위를 혼동하여 price_per_meter를 total_price로 오해하거나 숫자 필터에 m2와 같은 단위를 추가하거나, 가격 태그에서 월세임을 시사하는데도 판매 제안을 찾는 경우 등이 있었습니다.\n\n이러한 모든 경우를 처리하고 1,000 토큰 이상을 추가한 사용자 입력을 조작하는 데 많은 시간을 들인 후, 몇 가지 유효성 검사 함수를 사용하여 이러한 것들을 Python에서 더 효율적으로 처리할 수 있음을 깨달았습니다.\n\n<div class=\"content-ad\"></div>\n\n이 이야기는 생산 준비가 된 LLM-파워 앱을 구축하는 시리즈 중 두 번째 이야기입니다. 권장사항으로 프롬프트 최적화에 대한 팁을 확인하시기를 권장합니다.\n\n# Python 가드레일을 사용하는 장점은 다음과 같습니다.\n\n- 프롬프트 크기를 크게하지 않고도 엣지 케이스 처리\n- 다른 응용 프로그램과의 마일지저호환성 보장\n- 예상치 못한 사용자 동작에 대응하는 LLM 앱 만들기\n- 성능 향상 및 더 작은 모델 사용 가능\n\n텍스트-투-파라미터 도구 예제를 이어가면, 특히 까다로운 질문 세트에 대한 도구 정확도를 가드레일을 추가하거나 제거하여 비교하는 실험을 실행했습니다.\n\n<div class=\"content-ad\"></div>\n\n## 모델별 검색 매개변수 정확도\n\n![이미지](/assets/img/2024-06-19-ImproveLLMOutputReliabilitywithPythonGuardrails_1.png)\n\n# LangChain에서 Python을 LLM 호출과 혼합하는 방법\n\nLangChain을 사용하면 LLM 호출, 출력 구문 분석 및 일반 Python 함수를 모두 RunnableSequence로 결합하여 편리하게 결합할 수 있습니다. RunnableSequence는 사실상 대부분의 체인의 기초입니다.\n\n<div class=\"content-ad\"></div>\n\n아래 예시 코드에서는 사용자 요구 사항을 필터와 함께 사전으로 변환하는 간단한 텍스트-to-params 도구에 초점을 맞추었습니다. Python을 사용하여 LLM 출력을 변환하는 것은 구조화된 JSON 출력과 함께 작업할 때 가장 효율적입니다. 그러나 동일한 접근 방식은 텍스트 응답(예: 분류기와 같은 작은 NLP 모델 사용)에도 활용할 수 있습니다.\n\n```js\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0, model=\"gpt-4o\")\n\nprompt = \"\"\"\nSYSTEM\ndescription을 key:value 쌍으로 필터 매개변수로 변환합니다.\n허용된 필터 특징: [`area_min`, `area_max`, `price_min`, `price_max`]\n\n답변은 유효한 $JSON_BLOB이어야하며 다음과 같이 표시됩니다:\n\n```\n{\n  \"filters\": $FOUND_FILTERS,\n}\n\n\n시작! 항상 유효한 json blob로 응답해야 함을 상기시킵니다.\n\n새 메시지\n{input}\n\n(무엇이든 JSON blob으로 응답할 것을 상기시킵니다)\n\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template(prompt)\n\ndef search_params_guardrails(tool_output: dict) -> str:\n    min_sale_price = 100000\n    filters = tool_output.get(\"filters\", {})\n    \n    if 'price_max' in filters.keys():\n        price_threshold = filters[\"price_max\"]\n        filters[\"offer_type\"] = 'sale' if price_threshold >= min_sale_price else 'rent'\n        \n    return {\"filters\":filters}\n\n\n샘플 코드의 첫 번째 부분에서는 OpenAI 모델, Prompt Template, JsonOutputParser(지시사항과 함께 유효한 JSON을 얻는 데 도움을 주는) 및 다른 LLM이 설정한 기타 필터에 기초하여 `offer_type` 필드를 추가하는 기본 api_params_guardrail 기능을 준비합니다.\n\n```js\nchain_text_to_params = prompt | llm | JsonOutputParser() | search_params_guardrails\n```\n\n<div class=\"content-ad\"></div>\n\n그럼 체인을 구성하여 준비된 구성 요소의 실행 순서를 정의합니다. 각 구성 요소는 이전 단계의 출력을받고 처리를 유지하여 체인 끝에 최종 결과를 제공합니다.\n\n![Chain Configuration](/assets/img/2024-06-19-ImproveLLMOutputReliabilitywithPythonGuardrails_2.png)\n\n체인을 설정하고 나면 invoke를 사용하여 호출할 수 있습니다. 입력으로 필요한 속성의 유형을 설명합니다. 이 간단한 프롬프트는 텍스트에서 정보를 올바르게 추출뿐만 아니라 해당 정보를 유효한 사전으로 파싱하고 함수를 기반으로 offer_type 매개변수를 추가했습니다.\n\n# 파이썬 함수를 사용한 LLM 결과 개선의 실용적 예제 3가지\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! 저는 한국어로 번역을 도와드리는 인공지능입니다.\n\n제가 준비한 텍스트를 파라미터로 변환하는 도구에 몇 가지 속임수를 추가했습니다. 이러한 속임수들은 더 신뢰할 수 있고 호환성이 있는 LLM 출력물을 생성하는 데 도움이 되었습니다.\n\n## 1. LLM은 너무 리터럴할 수 있으므로 답변에 조금의 지혜를 더해보세요.\n\n처음 LLM 앱을 테스트하기 시작하면, 처음 프롬프트가 모든 이상한 사용자 쿼리와 경계 케이스를 다루지 않았거나 LLM이 일부 도메인 지식을 놓친 것에 빨리 깨닫게 됩니다.\n\nMieszko를 작업 중인 동안 직면한 문제 중 하나는 사용자 요구 사항을 검색 필터 JSON으로 변환하는 도구가 너무 리터럴하다는 것이었습니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 사용자가 50m2 정도의 면적을 가진 아파트를 3500-3600 zł의 예산 내에서 찾고 싶다고 설명한다면, LLM은 다음 필터를 생성했습니다:\n\n```js\nsearch_filters = {\n  \"price\": {\"min\": 3500, \"max\": 3600}, \n  \"area\": {\"min\": 50, \"max\": 50}\n}\n```\n\n이 필터들이 논리적으로는 잘못되지 않았지만, 사용자는 월 3200 zł에 55m2 아파트를 보는 것에 대해 훨씬 더 기뻤을 것입니다. 그래서 필터들은 다음과 같이 변경되어야 합니다:\n\n```js\nsearch_filters = {\n  \"price\": {\"max\": 3600}, \n  \"area\": {\"min\": 45, \"max\": 55}\n}\n```\n\n<div class=\"content-ad\"></div>\n\n저는 프롬프트에 더 많은 지침을 추가해 봤지만, 수십 가지 검색 매개변수와 대부분의 매개변수에 사용자 정의 유효성 검사 규칙이 있는 경우 몇 백개의 토큰이 추가될 것입니다. 도구 출력물을 수정하여 동일한 결과가 더 안정적으로 생성되도록 단순한 가드레일 함수를 추가했습니다.\n\n이제 두 가지 문제에 국한된 코드 예제를 제공해 드리겠습니다:\n\n```js\ndef search_params_guardrails(params):\n    # 'price'가 있는 경우, 'min'과 'max' 모두가 있는지 확인하고, min이 max의 20% 이하인 경우 min 임계값 제거\n    if 'price' in params and all(key in params[\"price\"] for key in ['min', 'max'])\n        if (params['price']['max'] - params['price']['min']) / params['price']['max'] <= 0.20:\n          del params['price']['min']\n    \n    # 'area'가 있는 경우, 'min'과 'max' 모두가 있는지 확인하고, min과 max가 동일한 경우 min은 0.9배로, max는 1.1배로 확장\n    if 'area' in params and all(key in params[\"area\"] for key in ['min', 'max'])\n        if params['area']['min'] == params['area']['max']:\n            params['area']['min'] *= 0.9\n            params['area']['max'] *= 1.1\n    \n    return params\n```\n\n## 2.퍼지 매치가 수십 가지 카테고리를 선택해야 하는 지시를 대체할 수 있는지 여부를 검증하세요.\n\n<div class=\"content-ad\"></div>\n\n검색 매개변수 도구를 구축하는 동안 한 가지 사소한 문제가 더 발생했습니다. 범주형 필드를 처리하는 것이었습니다. 'offer_type'과 같이 가능한 레이블이 'sale' 또는 'rent'만 있는 필드가 있으면 쉽게 프롬프트 지시사항에 적합하게 맞출 수 있습니다.\n\n그러나 더 많이 세분화된 필드로 넘어가면 상황이 복잡해집니다. 제 경우에는 와르샤와의 지역(18개 인스턴스) 및 동(143개 인스턴스)이었습니다. 이러한 모든 레이블을 프롬프트에 추가하면 1,058개의 토큰이 추가되어 매 호출당 1센트의 비용이 들게 될 것입니다. GPT 4-터보를 사용할 때 또한 마찬가지입니다.\n\nGPT 3.5조차도 와르샤의 지리에 대한 기본적인 이해가 있기 때문에 프롬프트에 모든 이 정보를 제공할 필요가 없습니다. 가장 중요한 문제는 때로는 철자가 달라지거나 사용자 입력에서 직접 복사된 오류 또는 약어가 있는 경우였습니다.\n\n지역과 동이 검색 API에서 사용 가능한 값과 호환되도록 하기 위해 처음엔 퍼지 매치를 사용하여 LLM 세트 매개변수를 선별된 목록으로 제한했고, 실제로 모든 허용된 레이블을 프롬프트를 통해 제공하지 않았습니다.\n\n<div class=\"content-ad\"></div>\n\n## 알려진 유효 라벨 세트에 대해 범주형 라벨을 검증하는 간소화된 퍼지 매치 코드입니다.\n\n```js\nfrom fuzzywuzzy import process\nimport json\n\ndef fuzzy_match(label: str, allowed_labels:list, score_cutoff=90, allowed_len_diff = 3):\n    best_match = process.extractOne(label, allowed_labels, score_cutoff=score_cutoff)\n    if best_match and abs(len(best_match[0]) - len(label)) > allowed_len_diff:\n        # 모호한 일치를 피하기 위해 더 큰 길이 차이가 있는 매치 제거\n        best_match=None\n        \n    return best_match[0] if best_match else None\n\ndef validate_category_feature(labels: list, allowed_labels:list)->list:\n    labels_val = [fuzzy_match(label, allowed_labels) for label in labels]\n    labels_val = [item for item in labels_val if item is not None] \n    \n    return labels_val\n\ndef validate_category_filters(params:dict, cat_features: list)->dict:   \n    # 각 cat_feature에 대한 허용된 라벨 목록이 포함된 json 경로로 변경\n    path = \"allowed_labels_per_feature_map.json\" \n    with open(path, \"r\") as f:\n        allowed_labels_per_feature = json.load(f)\n        \n    for feature in cat_features:\n        allowed_labels = allowed_labels_per_feature[feature]\n        labels = params.get(feature, [])\n        if labels:\n            labels_val = validate_category_feature(labels, allowed_labels)\n            if labels_val:\n                params[feature] = labels_val\n\n\n    return params\n```\n\n이 접근 방식은 지리적 영역에만 적용되지 않으며, 전자 상거래에서 브랜드나 모델을 선별하는 등 다른 영역에도 구현할 수 있습니다. 이는 다음과 같이 더 넓은 범위의 가드레일 집합으로 구현할 수 있습니다.\n\n```js\ndef search_params_guardrails(params):\n  ... 이전 로직\n  # 범주형 필터가 API 허용 값을 준수하는지 확인\n  params = validate_category_filters(params, [\"district\", \"subdistrict\"])\n\n  ... 후속 로직\n\n  return params\n```\n\n<div class=\"content-ad\"></div>\n\n## 3. 제한적인 필터를 완화함으로써 실패한 API 호출을 재시도하세요\n\n마지막 마일 배송 문제의 또 다른 부분은 LLMs가 사용자의 요청에 가능한 한 많은 필터를 맞추려고 하는 경향이 있다는 것입니다. 예를 들어, 사용자가 저렴한 가격대 내에서 편안한 아파트를 요청했을 때, LLM은 샤워, 욕조, 식기 세척기, 발코니 등 모든 편의 시설을 추가해야 한다고 판단할 수 있습니다. 저렴한 가격 요구 사항과 결합하여 API 호출에 전달되는 최종 필터가 제로 집합으로 끝날 수 있습니다.\n\n모델이 매개변수 설정을 재시도할 기회를 주더라도 이는 다른 LLM 호출을 의미하며 이로 인해 비용과 대기 시간이 증가합니다. 대신, 나는 가장 제한적인 필터 세트를 순차적으로 제외하면서 API 호출을 재시도하기로 결정했습니다. 그렇게 하면 결국 유효한 답변을 얻을 수 있을 거라는 희망을 품게 되었습니다.\n\n```js\ndef get_offers_count_with_loosening_filters(params):\n\n    # 빈 응답일 경우 삭제할 선택적 필터 목록\n    optional_filters = [\"interior_standard\", \"amenities\", \"building_type\", \"build_year\", \"market\"]\n    valid_response = False\n    dropped_filters = {}\n\n    while True:\n        # 선택된 필터 내에서 활성 제공 건 수에 대한 정보를 반환하는 API 호출\n        offer_json, valid_response = call_api(params)\n\n        if valid_response:\n            available_offers = offer_json.get(\"unique_offers_pool\", 0)\n\n            output = f\"{available_offers}개의 제공 건이 발견되었습니다. 다음 필터와 일치합니다: {params}\"\n\n            if dropped_filters:\n                output += f\", 그러나 이 요구 사항에 맞는 {dropped_filters} 필터를 제외해야 합니다.\"\n\n            return output\n\n        else:\n           \n            if not optional_filters:\n                # 모든 선택적 필터를 소진했을 경우 예외 발생\n                return f\"{params}와(과) 일치하는 제공 건을 찾을 수 없습니다. 사용 가능한 제공 건을 찾으려면 필터링을 덜 엄격하게 설정하세요.\"\n            else:\n                # params에서 한 개의 선택적 필터를 제거하고 다시 시도합니다.\n                dropped_filter = optional_filters.pop(0)\n                if dropped_filter in params:\n                    dropped_filters[dropped_filter] = params.pop(dropped_filter, None)\n```\n\n<div class=\"content-ad\"></div>\n\n이 함수가 모든 출력을 완전한 문장으로 반환하는 것을 알 수 있습니다. LLM 에이전트가 사용하는 전체 텍스트-파라미터 도구를 통해 대화 형식의 설명과 함께 도구 출력이 반환되면 에이전트 추론에 더 쉽게 구현할 수 있습니다. 검색 가능하게 만들기 위해 삭제된 필터의 명확한 설명은 에이전트가 최종 사용자에게 설명하는 데 도움이 됩니다.\n\n# 요약\n\n전망 가능한 미래에도 빠른 LLM 개발에도 불구하고, 그들은 에너지 비용과 각 답변을 처리하는 데 많은 시간이 필요한 대형 생물체로 남아있을 것입니다. 필요한 곳에서 이 파워를 활용하되 가능한 경우 간단하고 검증된 솔루션으로 돌아가도 두려워하지 마세요. 이러한 접근 방식에 대해 행성과 당신의 지갑이 감사할 것입니다.\n\n이 글은 효율적이고 신뢰할 수 있는 LLM 기반 앱을 구축하는 실용적인 팁에 중점을 둔 시리즈의 일부입니다. 새로운 글이 게시될 때 알림을 받으려면 제 프로필을 구독하세요.\n\n<div class=\"content-ad\"></div>\n\n## 시간 내어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-19-ImproveLLMOutputReliabilitywithPythonGuardrails_0.png"},"coverImage":"/assets/img/2024-06-19-ImproveLLMOutputReliabilitywithPythonGuardrails_0.png","tag":["Tech"],"readingTime":10},{"title":"데이터 과학, NLP 및 대형 언어 모델에 대한 직관적인 통찰력","description":"","date":"2024-06-19 04:02","slug":"2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels","content":"\n\n## 데이터 과학, 기계 학습, 자연어 처리 및 대형 언어 모델의 핵심 간소화\n\n![이미지](/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_0.png)\n\n- 소개\n- 섹션 1: 데이터 과학과 기계 학습의 직관\n  - 데이터 과학이란 무엇인가?\n  - 기계 학습의 기본\n- 섹션 2: 자연어 처리(NLP) 이해\n  - NLP란 무엇인가?\n  - 주요 NLP 작업\n  - NLP 모델의 진화\n- 섹션 3: 대형 언어 모델(LLMs) 소개\n  - LLMs란 무엇인가?\n  - 주요 특성\n  - 트랜스포머\n  - 인기 있는 LLMs\n- 섹션 4: 주요 개념 심층 탐구\n  - 임베딩\n  - 유사성 측정\n  - 파인튜닝\n  - 프롬프트 엔지니어링\n  - 에이전트\n- 결론\n- 참고 및 추가 독서\n\n# 소개\n\n<div class=\"content-ad\"></div>\n\n저희 초보자를 위한 데이터 과학, 기계 학습 및 관련 개념 안내에 오신 것을 환영합니다. 이 글은 검색 증강 생성 (RAG)과 같은 고급 주제를 더 잘 이해하기 위해 필요한 기본 지식을 제공합니다. 이 분야에 처음 접하셨거나 간단한 짧은 복습이 필요한 경우라면, 이 가이드를 통해 중요한 개념을 쉽고 직관적인 방법으로 이해하는 데 도움이 됩니다.\n\n# 섹션 1: 데이터 과학과 기계 학습의 직관\n\n## 데이터 과학이란?\n\n데이터 과학은 통계, 컴퓨터 과학 및 영역 지식을 결합하여 데이터에서 통찰을 추출하는 분야입니다. 범죄를 해결하는 대신에, 데이터 과학자는 데이터 내에 숨겨진 패턴과 트렌드를 발견합니다. 데이터 과학자는 조직이 정보에 기반한 결정을 내릴 수 있도록 데이터를 수집, 정제, 분석하고 시각화합니다.\n\n<div class=\"content-ad\"></div>\n\n## 기계 학습의 기본 사항\n\n기계 학습은 데이터 과학의 하위 집합으로, 우리는 컴퓨터에게 데이터에서 배우도록 가르칩니다. 명시적으로 프로그램 규칙을 작성하는 대신 컴퓨터에게 데이터를 공급하고 자체적으로 패턴을 찾게 합니다.\n\n- 피쳐와 레이블: 피쳐는 입력 변수(나이, 키 등)이고, 레이블은 출력 변수(누군가의 몸무게 예측과 같은)입니다.\n- 학습과 테스트: 데이터를 학습 및 테스트 세트로 나눕니다. 학습 세트는 모델을 가르치는 데 사용되고, 테스트 세트는 그 성능을 평가하는 데 사용됩니다.\n\n기계 학습의 종류:\n\n<div class=\"content-ad\"></div>\n\n- 지도 학습: 모델이 라벨이 붙은 데이터에서 학습합니다. (예: 과거 데이터를 기반으로 한 집 값 예측)\n- 비지도 학습: 모델이 라벨이 없는 데이터에서 패턴을 찾습니다. (예: 고객을 다른 세그먼트로 클러스터링하는 것)\n- 강화 학습: 모델이 시행착오를 통해 학습하며 올바른 행동에 대해 보상을 받습니다. (예: 로봇에 미로를 탐험시키는 것)\n\n## 섹션 2: 자연어 처리(NLP) 이해하기\n\n### NLP란 무엇인가요?\n\n자연어 처리(NLP)는 컴퓨터와 사람 간의 상호 작용에 초점을 맞춘 인공지능 분야입니다. 이는 컴퓨터에게 사람의 언어를 이해하고 생성할 수 있도록 가르치는 것을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n## 중요한 NLP 작업\n\n토큰화: 텍스트를 개별 단어나 토큰으로 분리하는 작업입니다.\n어간 추출과 표제어 추출: 단어를 그들의 기본 형태나 어간으로 줄이는 작업입니다 (예: \"running\"을 \"run\"으로).\n개체명 인식 (NER): 텍스트에서 이름, 날짜, 위치 같은 엔티티를 식별하는 작업입니다.\n품사 태깅 (POS): 문장 내 각 단어에 명사, 동사와 같은 품사를 할당하는 작업입니다.\n\n## NLP 모델의 진화\n\n전통적인 모델: 초기 NLP 모델은 n-그램과 TF-IDF와 같은 기법을 사용했으며, 이는 주로 수동 제작된 규칙과 통계적 방법에 의존했습니다.\n현대적인 모델: 요즘 NLP는 딥러닝을 활용합니다. Word2Vec와 GloVe와 같은 모델은 단어 임베딩을 만들어냅니다 (단어의 벡터 표현), 반면에 BERT와 GPT는 문맥을 더 효과적으로 이해하기 위해 트랜스포머를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n# 섹션 3: 대규모 언어 모델 (LLM) 소개\n\n## LLM이란?\n\n대규모 언어 모델(LLM)은 방대한 양의 텍스트 데이터로 훈련된 고급 모델입니다. 이러한 모델은 놀라운 정확도로 텍스트를 생성하고 이해할 수 있습니다.\n\n## 주요 특성\n\n<div class=\"content-ad\"></div>\n\n문맥 이해력: 이전 모델과는 달리 LLM은 단어가 사용된 문맥을 이해하여 더 정확한 결과를 제공합니다.\n다재다능함: 번역부터 텍스트 생성까지 다양한 작업을 수행할 수 있습니다.\n\n## 트랜스포머\n\n트랜스포머는 대부분의 현대 LLM의 중추를 이룹니다. 자기 주의 메커니즘(self-attention)을 도입하여 문장에서 다양한 단어의 중요성을 가중 평가하여 예측을 수행할 수 있게 했습니다.\n\n자기 주의 메커니즘: 이것은 모델이 입력 텍스트의 관련 부분에 집중하여 문맥을 더 잘 이해할 수 있게 합니다.\n혜택: 트랜스포머는 고도로 병렬화되며 RNN(순환 신경망)과 같은 이전 아키텍처보다 텍스트의 장거리 종속성을 더 잘 처리할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 인기있는 LLMs\n\nGPT (Generative Pre-trained Transformer): 일관된 문맥과 관련된 텍스트를 생성하는 능력으로 유명합니다.\n\nBERT (Bidirectional Encoder Representations from Transformers): 문장 속 단어들의 문맥을 이해하는 데 능숙하여, 질문응답 및 감성 분석과 같은 작업에 탁월합니다.\n\nT5 (Text-To-Text Transfer Transformer): 모든 NLP 작업을 텍스트 대 텍스트 형식으로 변환하므로, 다양한 응용 분야에 대해 매우 다재다능하고 효과적입니다.\n\n<div class=\"content-ad\"></div>\n\n# 섹션 4: 주요 개념 심층 탐색\n\n## 임베딩\n\n임베딩은 단어나 문장의 의미와 맥락을 포착한 수치적 표현입니다. 비슷한 단어들이 가까이 모여 있는 다차원 공간에서의 좌표로 생각해보세요.\n\n![임베딩 이미지](/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_1.png)\n\n<div class=\"content-ad\"></div>\n\n어떻게 사용되나요: 임베딩은 유사도 측정, 클러스터링, 및 분류와 같은 다양한 NLP 작업에 사용됩니다.\n\n## 유사성 측정\n\n유사성 측정은 두 개의 텍스트가 얼마나 비슷한지를 결정하는 데 도움을 줍니다. 일반적인 측정 방법으로는 다음이 있습니다:\n\n코사인 유사도: 두 벡터 사이의 각도의 코사인을 측정합니다. 벡터가 같은 방향을 가리킨다면 코사인 유사도는 1입니다.\n유클리드 거리: 공간에서 두 점 사이의 직선 거리를 측정합니다. 작은 거리는 더 높은 유사성을 나타냅니다.\n\n<div class=\"content-ad\"></div>\n\n## 세밀한 조정\n\n세밀한 조정은 사전 훈련된 모델을 가져와서 작은 과제별 데이터 세트를 사용하여 특정 작업에 적응하는 과정입니다. 이를 통해 모델은 사전 훈련 중에 얻은 방대한 지식을 활용하면서 새로운 작업에 특화됩니다.\n\n사전 훈련 대 세밀한 조정: 사전 훈련은 일반 교육과 같으며, 세밀한 조정은 특정 작업을 위한 전문 훈련과 같습니다.\n실제 예시: 감성 분석을 위한 BERT 세밀한 조정 또는 사용자 지정 텍스트 생성을 위한 GPT 세밀한 조정.\n\n## 프롬프트 엔지니어링\n\n<div class=\"content-ad\"></div>\n\n프롬프트 엔지니어링은 언어 모델로부터 원하는 결과를 얻기 위한 입력을 만드는 것을 의미합니다. 가장 좋은 성능을 얻기 위해 질문이나 지시 사항을 제공하는 올바른 방법을 찾는 것이 중요합니다.\n\n프롬프트 유형: 직접적인 질문, 지시 사항 또는 예시.\n효과적인 프롬프트 디자인: 명확하고 구체적인 언어를 사용하고, 문맥을 제공하며 때로는 모델을 안내할 예시를 포함합니다.\n\n## 에이전트\n\n에이전트는 NLP 및 기타 AI 기술을 사용하여 자율적으로 작업을 수행하는 시스템입니다.\n\n<div class=\"content-ad\"></div>\n\n에이전트 유형: 챗봇, 가상 어시스턴트, 추천 시스템.\n에이전트 구축: 상호 작용 흐름 설계, 관련 데이터에 대한 교육, 사용자와 상호 작용할 수 있는 환경에 배포 포함됩니다.\n도전 과제: 정확성 보장, 모호한 입력 처리, 대화에서 맥락 유지하기.\n\n# 결론\n\nRAG와 같은 고급 주제로 물들기 전에 데이터 과학, 기계 학습, NLP 및 LLMs의 기본을 이해하는 것이 중요합니다. 이러한 기본 개념은 RAG가 어떻게 작동하는지와 그 중요성을 이해하는 데 필요한 배경을 제공합니다.\n\n# 참고 자료 및 추가 독서\n\n<div class=\"content-ad\"></div>\n\n일반 데이터 과학 및 기계 학습:\n\n- [스탠포드 대학의 데이터 과학 입문](https://datascience.stanford.edu/) \n- [구글의 기계 학습 총정리](https://developers.google.com/machine-learning/crash-course)\n- [분류 모델이 작동하는 방식 이해하기](https://towardsdatascience.com/classification-lets-understand-the-basics-78baa6fbff48)\n\n자연어 처리 (NLP):\n\n- [파이썬에서의 강력한 자연어 처리 - spaCy 문서](https://spacy.io/usage/projects) \n- [Jalammar의 Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n- [스탠포드 대학의 NLP 강좌: 대화형 에이전트 구현하기](https://web.stanford.edu/class/cs224n/)\n\n<div class=\"content-ad\"></div>\n\n대형 언어 모델 (LLMs):\n\n- [OpenAI 블로그: GPT-3 공개](https://openai.com/news/)\n- [Google AI 블로그: BERT - 언어 이해를 위한 깊고 양방향 트랜스포머에 대한 프리 트레이닝 공개](https://blog.research.google/2018/11/open-sourcing-bert-state-of-art-pre.html)\n- [Colin Raffel 등에 의한 텍스트-투-텍스트 전송 트랜스포머 (T5)](https://arxiv.org/pdf/1910.10683)\n\n구체적인 개념:\n\n- [단어 임베딩 설명 - Towards Data Science](https://towardsdatascience.com/a-guide-to-word-embeddings-8a23817ab60f)\n- [코사인 유사도 - 위키백과](https://en.wikipedia.org/wiki/Cosine_similarity)\n- [트랜스포머로 파인 튜닝 - Hugging Face](https://huggingface.co/docs/transformers/en/training)\n- [대형 언어 모델을 위한 좋은 프롬프트 작성 방법 - Hugging Face](https://huggingface.co/docs/transformers/en/tasks/prompting)\n- [챗봇의 종류 - Chatbots Magazine](https://chatbotsmagazine.com/the-complete-beginner-s-guide-to-chatbots-8280b7b906ca)","ogImage":{"url":"/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_0.png"},"coverImage":"/assets/img/2024-06-19-IntuitiveInsightsintoDataScienceNLPandLargeLanguageModels_0.png","tag":["Tech"],"readingTime":6},{"title":"파이-3와 Azure PDF 데이터 추출  ExtractThinker","description":"","date":"2024-06-19 04:00","slug":"2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker","content":"\n\nPDF 및 이미지에서 구조화된 데이터를 추출하는 것은 어려울 수 있지만, 광학 문자 인식 (OCR)과 언어 모델 (LLMs)을 결합하면 강력한 솔루션을 제공할 수 있습니다. Azure 생태계 내에서 문서 지능 서비스를 활용하면 문서를 분석할 때 좋은 선택이 될 것입니다.\n\n이 글에서는 Azure AI 스튜디오의 Phi-3 미니 모델을 활용하여 데이터 추출 프로세스를 개선하는 방법을 보여드리겠습니다. Phi-3 미니 모델은 38억 개의 매개변수를 가진 작은 언어 모델(SML)로 효율적이고 정확한 결과를 제공하여 이 작업에 이상적인 선택지입니다. 이 예제는 Azure에 중점을 두고 있지만, 이와 유사한 도구를 사용하여 다른 제공업체에서도 적용할 수 있는 원칙을 다룹니다.\n\n해당 솔루션은 다른 클라우드 제공업체에도 쉽게 복제되며, 비슷한 품질, 가격, 기능을 제공합니다.\n\n# OCR 선택하기 - Azure 문서 지능\n\n<div class=\"content-ad\"></div>\n\nAzure Document Intelligence은 Microsoft 생태계에 속하는 OCR 제품입니다. 가격 측면에서는 아래 이미지에서 볼 수 있듯이 세 가지 계층으로 나뉩니다:\n\n![이미지](/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_0.png)\n\n\"read\"는 단락과 필기 텍스트만 추출합니다. 기본적으로 전통적인 OCR입니다. 대부분의 문서 추출에는 충분하지만 복잡한 문서에는 부족할 수 있습니다.\n\n\"prebuilt\" 레이아웃은 작업에 가장 적합한 선택지이며 나머지는 LLM이 처리합니다. 이 옵션에는 영수증, 송장, 신분증, W-2 등 여러 템플릿이 있지만, 표와 확인란과 같은 구조를 강조해야 하는 추출이 필요합니다. 이를 위해 \"prebuilt-layout\"을 문서 유형으로 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n마지막으로 가장 비싼 옵션은 \"사용자 정의\" 레이아웃입니다. 시스템에 공급될 문서 및 추출해야 할 필드에 따라 교육되어야 합니다. LLM 분야의 발전을 고려할 때, 이 기사에서 설명된 대로 폐기되고 수행되어야 합니다.\n\n# Azure Ai studio의 Phi-3\n\nPhi-3는 Microsoft의 주력 모델 그룹입니다. 그들은 작고 OpenAI에서 다루지 않는 시장 점유율을 차지하고 있습니다. OpenAI는 세계 최고의 모델을 제공하는 데 빛을 발합니다.\n\n![이미지](/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_1.png)\n\n<div class=\"content-ad\"></div>\n\n허깅 페이스에 대한 이 모델 요약에 따르면, 이 모델은 3.3조 토큰을 학습했습니다. 이 작은 모델은 추출 및 분류와 같은 작업에 우수한 결과를 제공할 수 있습니다. 게다가 각 클래스는 컨텍스트 창 옵션을 제공합니다: 4k 컨텍스트 창과 128k 컨텍스트 창이 있습니다. 이 경우 약간 낮은 품질과 약간 높은 비용의 상충이 있습니다. \"토큰 당 유연한 요금제\" 모델의 가격은 다음과 같습니다:\n\n![이미지](/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_2.png)\n\n먼저, 이 기사 발행 당시 \"유연한 요금제\"에 비전 모델이나 작은 모델이 포함되어 있지 않습니다. 위 이미지에 표시된 모델만 사용할 수 있지만, 전용 머신에 호스팅해야 합니다.\n\n그러나 가격은 중요합니다. 요금 측면에서 미니 모델은 GPT 3.5 터보의 50% 비용이 들며, 위의 벤치마크 결과에 따르면 영어 기반 텍스트에서 비슷한 성능을 발휘합니다. 왜냐하면 Mixtral 7x8B는 GPT 3.5 (이전 버전)과 비슷한 성능을 보였기 때문입니다. 중간 모델은 GPT 3.5 터보와 비슷한 비용을 가지며 영어 기반 텍스트에서 약간 더 나은 성과를 내지만, 다른 언어에는 적합하지 않습니다. 따라서 사용 사례 분리는 다중 언어에 적합한 경우 \"GPT 3.5 터보를 선택하는 것이 좋을 것\"입니다.\n\n<div class=\"content-ad\"></div>\n\n# 코드 구현\n\n전체 예시는 여기에서 찾을 수 있지만, 이 섹션에서는 코드가 어떻게 작동하는지에 대해 자세히 설명해 드릴 것입니다. 이 예시는 Azure와 Phi-3에 초점을 맞추고 있지만, 다른 구성 요소를 사용할 때도 유사하게 작동합니다.\n\n## 내부 작동 방식\n\n<img src=\"/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_3.png\" />\n\n<div class=\"content-ad\"></div>\n\n위 이미지는 ExtractThinker가 여러 조각들과 함께 작동하는 방법을 보여줍니다. Azure DI는 이 예에서 \"Layout\"를 문서 유형으로 사용하여 라인, 테이블 및 확인란과 같은 구조를 가진 콘텐츠를 추출합니다. 이는 데이터 매핑할 때 모델에 추가 정보를 제공합니다. 추출기 구성 요소는 그런 다음 모델 메시지에 삽입될 프롬프트를 생성합니다. 이는 비전 모델이며 이미지도 결과를 증가시키기 위해 추가할 수 있습니다.\n\n아래는 ExtractThinker에 이를 아카이빙하는 방법입니다:\n\n```js\nsubscription_key = os.getenv(\"AZURE_SUBSCRIPTION_KEY\")\nendpoint = os.getenv(\"AZURE_ENDPOINT\")\napi_key = os.getenv(\"AZURE_AI_API_KEY\")\n\nextractor = Extractor()\nextractor.load_document_loader(\n    DocumentLoaderAzureForm(subscription_key, endpoint)\n)\n\nllm = LLM(model=\"azure/Phi-3-mini-128k-instruct\",\n          api_base=\"https://Phi-3-mini-128k-instruct-qjsac-serverless.swedencentral.inference.ai.azure.com\",\n          api_key=api_key,\n          api_version=\"v1\")\n\nextractor.load_llm(llm)\n\ncontent = extractor.extract(\"path\\\\driverLicense.jpg\", InvoiceContract)\n```\n\n## 확장성\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_4.png)\n\n추출 관점에서 고전적인 문서는 운전면허증, 매매 계약서, 송장 등이 될 수 있습니다. 이러한 문서들은 보통 작거나 한두 장 정도이므로 이미지에서 보듯이 크기가 다른 두 모델을 최적화하여 흐름을 조정할 수 있습니다. 4k 창을 초과하는 문서의 일부 (예: 5%)가 작성될 경우, 다음 코드를 사용하여 창을 초과할 경우 예외 처리를 할 수 있습니다:\n\n```js\ndef router():\n    model_list = [\n        {\n            \"model_name\": \"azure/Phi-3-mini-4k-instruct\",\n            \"litellm_params\": {\n                \"model\": \"azure/Phi-3-mini-4k-instruct\",\n                \"api_base\": os.getenv(\"AZURE_API_BASE\"),\n                \"api_key\": os.getenv(\"AZURE_API_KEY\")\n            },\n        },\n        {\n            \"model_name\": \"azure/Phi-3-mini-128k-instruct\",\n            \"litellm_params\": {\n                \"model\": \"azure/Phi-3-mini-128k-instruct\",\n                \"api_base\": os.getenv(\"AZURE_API_BASE\"),\n                \"api_key\": os.getenv(\"AZURE_API_KEY\")\n            }\n        },\n    ]\n\n    # 라우터 구성 정의\n    router = Router(\n        model_list=model_list,\n        default_fallbacks=[\"azure/Phi-3-mini-128k-instruct\"],\n        context_window_fallbacks=[\n            {\"azure/Phi-3-mini-4k-instruct\": [\"azure/Phi-3-mini-128k-instruct\"]},\n        ],\n        set_verbose=True\n    )\n\n    return router\n```\n\n# 추출용 미니 모델, 분류용 중간 모델\n\n\n<div class=\"content-ad\"></div>\n\n문서 및 페이지의 분류에 관련된 경우, 더 큰 모델을 사용하는 것이 좋습니다 (중간). 이 모델에 대한 입력 비용은 미니 모델의 출력보다 저렴합니다 ($0.5 대 $0.8 당 MT), 그리고 출력물은 몇 개의 토큰일 것입니다 (예: 출력물은 \"송장(Invoice)\"이라는 1에서 3개의 토큰을 포함할 수 있습니다).\n\n다음은 코드입니다:\n\n```js\n# 분류\n분류들 = [\n    Classification(name=\"운전 면허증(Driver License)\", description=\"이것은 운전 면허증입니다\"),\n    Classification(name=\"송장(Invoice)\", description=\"이것은 송장(Invoice)입니다\"),\n]\n\n추출기 = Extractor()\n추출기.load_document_loader(DocumentLoaderAzureForm(subscription_key, endpoint))\n\nllm = LLM(model=\"azure/Phi-3-medium-4k-instruct\",\n          api_base=\"https://Phi-3-medium-4k-instruct-qjsac-serverless.swedencentral.inference.ai.azure.com\",\n          api_key=\"...\",\n          api_version=\"v1\",)\n\n추출기.load_llm(llm)\n\n결과 = 추출기.classify_from_path(\"경로\\\\운전면허증.jpg\", 분류들)\n```\n\n# 비용 절감\n\n<div class=\"content-ad\"></div>\n\n비용을 절약할 때 맞춤형 모델과 비교해야 합니다. 어떤 계약도 추출에 사용할 수 있기 때문에 결과는 개발 비용을 고려하지 않고 훈련된 모델의 결과와 유사해야 합니다. 대부분의 과중한 작업은 LLM이 수행하기 때문입니다.\n\n[이미지](/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_5.png)\n\n숫자는 여유를 두고 보수적으로 유지되어, \"맞춤형\" 레이아웃과 비교할 수 있도록 했습니다. 가능한 최대한 비용을 낮추는 것이 목표라면 \"문서 유형\"을 \"읽기\"로 설정하고 phi-3 mini 가격을 사용하여 $2를 초과하지 않을 수 있습니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\nAzure Document Intelligence 및 Phi-3 모델을 결합하여 PDF 및 이미지에서 구조화된 데이터를 효율적으로 추출할 수 있어요. 이 과정은 광학 문자 인식(OCR)을 사용하여 텍스트와 문서 구조를 인식하고, 언어 모델(LLMs)을 활용하여 관련 데이터를 정확하게 추출하는 것을 포함합니다.\n\n이 방법은 문서 추출을 위한 Azure의 미리 구축된 레이아웃과 처리를 위한 Phi-3 미니 모델을 활용하여 비용 효율적이고 효율적인 결과를 도출합니다.\n\n확장 가능한 솔루션을 구현하고 대체 매커니즘을 활용하여 다양한 문서 유형 및 크기를 신뢰성 있게 처리할 수 있어요.","ogImage":{"url":"/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_0.png"},"coverImage":"/assets/img/2024-06-19-Phi-3andAzurePDFDataExtractionExtractThinker_0.png","tag":["Tech"],"readingTime":7}],"page":"92","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true}