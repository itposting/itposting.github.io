{"pageProps":{"posts":[{"title":"당신의 이야기를 위한 시각적 서술 만들기 ChatGPT, 중간여행의 마법","description":"","date":"2024-05-27 15:27","slug":"2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic","content":"\n당신에게 익숙한 소리인가요? 혈관을 타고 카페인이 흘러 들어오며, 완벽한 단어들의 전성기가 화면 위에 머물기 시작하고, 마침내 지금 막 미디엄의 낯선 세계에 최신 작품을 펼쳐보려는 찰나, 벽에 부딪치는 순간. 이것은 작가의 블록이 아니라, 똑같이 악랄하고 영혼을 파괴하는 무언가요 - 완벽한 이미지를 찾는 탐험.\n\n잘못 이해하지 마세요. 스톡 사진은 자리가 있다. 나는 스톡 사진을 좋아해. 하지만 한 가지 주요 문제가 있습니다. 진짜 스톡 사진을 사랑하거든요. Unsplash나 Pexels를 검색하기 시작한 순간 부터 내가 완벽한 이미지를 찾을 때까지 시간이 흐른 것을 목격한 적이 있습니다. 열심히 노력하는 사진작가로서, 아름다운 사진들에 집착하게 되어, 한 가지 두드러진 사진을 찾으려 애씁니다. 그게 요컨대, 나는 눈에 띄는 안경을 쓴 천반쪽 청년의 가짜 '유희정신' 표정을 사용할 만큼 낮아질 정도로 자랑스러운 사실입니다. 아니면 더 나쁜 경우에는 흔한 노트북 옆에 햇빛을 받는 컵 커피와 같은 이미지를 사용하고 있는 거죠. 때마침, 사실상, 쓰인 세계의 모든 '깊은' 생각은 동일한 여섯 개의 사진으로만 강조될 수 있다는 것 같습니다.\n\n휴... 깊게 숨을 들이마십시다. 차분해질게요.\n\n몇 달 전, 좌절에 격려로부터 영감을 받은 한 순간에, MidJourney AI 마술과 우리 자신의 작가적 조합을 결합하여 맞춤 이미지를 만드는 것에 대해 썼습니다. 넓은 인터넷 황무지를 헤매는 시간을 절약했고, 우리 단어가 실제로 자신만의 시각적 요소를 만들어 냈기 때문에 그것이 어딘가 멋있었습니다. 거의 3천 회의 조회수와 약간의 미디엄 부스트 마법을 거치면서, 그 글은 인기가 있어 보였습니다. 자, 알겠나요? 저는 연구실에서 바쁘게 지내고 있었습니다 (아니요, 사실 제가 연구실이 없어, 그런데 뭔가 공식적이죠) 새롭고 개선된 버전을 연마해서 이제 여러분에게 공개할 준비가 되었습니다. 그러니 커피를 마시고 자신의 두뇌를 켜세요.\n\n<div class=\"content-ad\"></div>\n\n# AI로 무장하기\n\n자, 좀 더 나아가기 전에, 우리 이야기에는 ChatGPT와 MidJourney 두 가지 주요 AI 주인공이 있어요. 이 두 가지에 대해 들어봤다고 가정할게요. 만약 세상의 일들 때문에 지상급이 되어 버렸다면 이해해 줄게요. 이 글을 더 읽으려면 알아야 할 중요한 정보가 있어요:\n\nChatGPT: 저는 ChatGPT의 고급 데이터 분석 모드를 활용하고 있어요. 이 기능은 유료 ChatGPT Plus 구독자에게만 제공돼요. 구독하지 않았다면, 보통 ChatGPT로도 해보고 결과를 보실 수 있지만, 설명한 것과 다르게 작동할 경우에는 편지를 보내지 마시길 바래요.\n\nMidJourney: 현재 가장 진보된 생성형 AI 미술 도구 중 하나일 수 있지만, 무료가 아니에요. 또한 MidJourney에는 사용하기 어려운 사용자 인터페이스가 있어서 Discord를 통해서 사용해야 해요. 만약 이 말이 헷갈리는데도 깊이 들어가 보려 한다면, 혼자서 시도하시는 것이 좋아요. MidJourney를 사용하지 못하는 경우에는 무료 도구인 Playground.ai를 대신 사용해 볼 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n이 둘은 함께하면 이 기사 전체를 효과적으로 전달해주는 다이내믹한 듀오야. 그리고 내 이전 글에서 MidJourney 방법이 시간을 아낄 만큼 멋지다고 열폭을 토했는데, 그걸 ChatGPT의 분석 능력과 결합하면? 우와, 여러분 말야, 이제 우리가 틀을 깨버릴 준비가 됐어.\n\n# 시작하기: 당신의 작품을 선택하세요\n\n이 파티를 계속 즐길 준비가 됐나요? 로봇들과 룸바 춤추기 시작할 준비가 됐나요? ChatGPT와 인터랙션 조금 할 준비가 됐나요? 어떤 여정이 아니라 MidJourney(여기서 뭔가 보이죠?). 좋아, 그만 하자, 이제 그만 할게.\n\n여기 우리 목표를 다시 강조해볼게요: 우리가 하는 건 우리가 작성한 멋진 글을 가져다가 독특하고 원본 이미지 4장을 만들어내서 사용하는 거에요. 이미지들은 모두 동일한 창의적 주제와 관련이 있을 것이고, 이는 당신의 기사 콘텐츠와 분위기와 관련이 있을 거에요. 이제 이 방법을 따라가는 데에는 시간이 걸리겠지만, 익숙해지면 다른 글에도 몇 분 안에 반복적으로 할 수 있어. 멋지죠!\n\n<div class=\"content-ad\"></div>\n\n먼저, 우리는 쓴 글 중 하나를 선택해야 해요. 거의 모든 기사든 상관 없어요 — 하지만 더 열정적이면 결과를 더 즐길 거예요. 저는 몇 년 전에 쓴 \"Beneath Office Rivalries Lurks an Evil Pleasure\"라는 제목의 글을 선택했어요. 그때 골랐던 멋진 스톡 이미지 헤더가 있어요. 분명히 기억이 나요 — 저는 아기 여자아이의 기저귀를 갈아입히고 요랑에 넣었고, 이미지를 찾아 기사를 제출하기 위해 늦게까지 일했어요. 그런데 갑자기, 딸의 첫 고등학교 첫 날이 왔어요. 그때 발견할 수 있는 좋은 이미지를 찾는 데 오래 걸렸어요!\n\n어쨌든, 몇 년 후에 후회하는 이미지가 조금 더 있었던 훌륭한 묘사적 이미지로 가득한 기사에요. 그래서 회고적으로 그림을 몇 개 더 넣는 게 좋을 거예요.\n\n글을 선택했으면, 그것을 텍스트 파일에 복사하여 붙여넣으세요. PDF나 워드 문서도 보통 괜찮아요 — 단지 텍스트 파일이 ChatGPT의 데이터 분석을 빠르게 처리하는 데 더 좋다고 생각해요. 그렇게 했나요? 그럼 계속해봐요.\n\n# 단계 2: ChatGPT 분석\n\n<div class=\"content-ad\"></div>\n\n넵, ChatGPT에게 이야기나 기사를 소개할 시간이에요. AI가 깊숙히 파고들어 단어의 본질을 흡수하고 여러분의 말과 함께 하도록 하고 싶어요. 그래서 나는 고급 데이터 분석 모드를 사용하는 걸 좋아해요. 그것이 그렇게 잘할 것 같아 보이기 때문이에요. 그게 사실인지에 대한 경증적 증거는 없지만, 직감이라고 하죠. 그리고 나는 살짝 이상한 사람이라서 고급 모드로 물건을 만지작거리는 것을 좋아해요. 아마도 그게 왜 내 삶이 항상 복잡한지도 모르겠죠.\n\n그러니, 너에게 두 가지 일을 시킬 거야:\n\n- 내 탁월한 프롬프트(아래)를 ChatGPT 입력란에 복사해넣어. 지금은 세부 사항에 빠져들지 말고요; 나중에 각 단계를 더 자세히 살펴 볼 거에요. 그리고 지금은 엔터를 누르지 말고 \"메시지 보내기\"도 클릭하지 마세요! 제발 참을성 좀 가져 주세요.\n\n\n| 작업 명세서|\n| ------------ |\n| 당신은 디테일에 뛰어난 창조적인 디자이너이자, 단어와 이야기를 몰입적인 이미지와 아트워크로 해석하는 능력을 지녔네요. 당신의 작업은 아래의 작업을 하나씩 수행하는 거에요:\n\n1. 첨부된 전체 기사를 분석해주세요. 분석 결과를 바탕으로, 기사의 분위기와 맥락을 이해한 뒤, 이 기사에 대한 이미지와 아트워크를 만들기 위해 적용할 창조적 스타일을 추천해주세요. 유명한 예술 표현, 트렌드, 스타일, 시기, 방법 등의 조합을 사용하여 창조적 스타일을 설명해주세요. 이미지 스타일은 실제 사진이 아닌, 기사의 맥락에 잘 어울리는 창조적 표현이어야 합니다.\n\n2. 위에서 언급한 창조적 스타일 설명으로부터 MidJourney(생성 기반 이미지 생성 도구)를 위한 프롬프트에 사용할 수 있는 키워드를 요약해주세요. 예를 들어, 일반적인 프롬프트는 다음과 같을 수 있습니다: \"깔끔한 선 아트, 에곤 슈일레 스타일, 금속 포인트 스케치, 표현적인 선\" 또는 \"그래피티 스타일, 홀리우드 포트레이트, 로맨틱 그래피티, 에어브러시 아트, 레트로, 도형 내에 포함\"\n\n3. 세 번째 작업에서는 전체 기사를 분석하고, 이야기 속에서 창조적인 이미지의 주제로 사용하기 적합한 네 개의 짧은 구절을 식별해주세요. 기사 전체 텍스트를 분석해주세요. 이 구절들을 사람화하거나 물체화하여 시각적으로 상상하기 쉬운 2-3 단어 짧은 설명으로 바꿔주세요. 예를 들어, \"어두운 그림자의 고통\"이라는 구절은 실제로 볼 수 없으므로, 그것을 한 쪽 얼굴이 그림자에 완전히 가려진 남자의 초상화로 사람화할 수 있습니다: \"그림자에 가려진 얼굴\".\n\n4. 이 마지막 작업에서는 MidJourney를 위한 생성적 AI 아트 프롬프트를 만들 것입니다. 작업 3과 작업 2의 결과를 결합하여 총 네 개의 프롬프트를 제공할 것입니다. 그러나 작업 3에서 선택한 정확한 구절을 사용하는 대신, 각 구절에 대한 시각화나 이미지화를 사용해주세요. 해당 이미지를 몇 단어로 간추려 사람화 또는 물체화해주세요. 예를 들어: \"안에 있는 악마: 이것은 쌍성을 나타내는 것으로, 천사적이고 악마적인 면이 함께 보이는 인물을 보여주는 것일 수 있습니다.\" 이것을 \"반 천사 반 악마 쌍면\"으로 바꿀 수 있습니다. 각 프롬프트에 다음을 추가해주세요: --ar 4:3 --s 400 --c 40\n\n한 작업을 끝내고 다음 작업을 시작하기 전에 제 승인을 받아주세요.\n\n\n<div class=\"content-ad\"></div>\n\n2. 챗GPT 입력 상자의 작은 \"+\" 아이콘을 클릭하세요. 이렇게 하면 기사가 포함된 텍스트 파일을 업로드할 수 있게 됩니다. 파일을 선택하고 업로드가 완료될 때까지 기다리면 됩니다. 몇 초 정도 소요될 거에요. 당신이 논문을 썼나요? 어쩌면 당신은 격인가봐요.\n\n![이미지](/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_0.png)\n\n이제 \"메시지 보내기\"를 눌러 마법이 시작되도록 해보세요! 챗GPT는 각 작업을 처리하고, 다음으로 넘어가기 전에 사용자의 확인을 기다릴 거에요. 마치 훈련된 애완동물처럼요. 이제 결과를 살펴보고 여기에서 무슨 일이 벌어지고 있는지 설명해보겠어요.\n\n작업 1 - 창의적인 스타일 추천\n\n<div class=\"content-ad\"></div>\n\n여기, 우리는 ChatGPT에게 우리의 작품 내용을 분석하고 기사의 톤과 맥락에 따라 이미지와 아트워크에 적용할 창의적인 스타일을 제안해 달라고 요청하고 있어. 나의 결과는 다음과 같아:\n\n\n<img src=\"/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_1.png\" />\n\n\n와우, 나는 이미 좋아해. 표현주의와 명암과도조명이 만나 초현실주의와 추상 상징주의가 만난다. 뭔가 비뚤어진 데이비드 리치 영화 같아.\n\n이 모든 정보는 분명히 우리의 미래 MidJourney 프롬프트에 포함하기에 너무 많다는 것이 분명하니까, 그것이 바로 작업 2의 목적이야.\n\n<div class=\"content-ad\"></div>\n\nChatGPT, proceed with condensing the creative style description into keywords suitable for the MidJourney prompt. Thank you!\n\n<div class=\"content-ad\"></div>\n\n태스크 1에서 스타일 설명을 모두 정리해서 이렇게 되었어요:\n\n“표현주의, 대담한 색채, 왜곡된 형태, 과장된 선들, 짙은 어둠과 밝은 빛 대비, 초현실주의, 꿈같은 장면, 예상치 못한 겹치기, 추상적 상징주의, 가면, 그림자, 거울.”\n\n좋아요, 이제 태스크 3로 넘어가겠습니다.\n\n태스크 3 — 창의적 이미지로 전환할 구절을 찾으세요\n\n<div class=\"content-ad\"></div>\n\nThe rubber’s really hittin’ the road now. ChatGPT은 우리 이야기를 살펴보고, 화려한 이미지를 만들어낼 수 있는 구문들을 추려냅니다. ChatGPT가 모든 찬사를 받고 있는 것 같아, 하지만 거기에는 나의 지시가 있었다는 것을 잊지 말아주세요. 구문을 추출할 때, 우리는 그 구문을 시각화할 수 있는 방식으로 설명하도록 요청했습니다 - 이것은 MidJourney가 구문과 관련된 더 많은 시각적 콘텐츠를 생성할 때 도움이 됩니다. 적어도 내 경험으로는요, 거의 완벽한 경험이라고 해야겠네요. 여기 나에게 대한 결과물이에요:\n\n![CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic](/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_3.png)\n\n내 기사에서 추출해낸 구문들이 정말 좋다고 생각해. 이들은 모두 깊은 의미를 품고 있어 머릿속에서 관련 이미지를 상상할 수 있게 합니다. 특히, 만약 당신이 사이코면 그런 이미지들이 더 와닿을지도 몰라요. 저는 사이코가 아니라고 약속합니다. 친구 ChatGPT가 멋진 일을 해냈어요. Task 4에 대해 그것에게 승인을 해주도록 하죠.\n\nTask 4 — MidJourney를 위한 생성형 AI 아트 프롬프트 구축\n\n<div class=\"content-ad\"></div>\n\n이것은 ChatGPT 프롬프트의 최종 목적지입니다. 여기서 우리는 AI에게 task 2와 task 3에서의 발견을 병합하여, MidJourney에서 사용할 네 개의 이미지 프롬프트를 작성하도록 요청했습니다. 우리의 프롬프트에는 MidJourney에 몇 가지 매개변수를 덧붙이도록 지시합니다. 이들은 다음과 같습니다:\n\n--ar 4:3 | 이미지의 종횡비를 설정합니다. 적합하게 변경할 수 있습니다.\n\n--s 400 | stylize 매개변수를 일반적인 기본 값보다 크게 설정합니다. 기본적으로, 더 멋진 이미지를 만들어냅니다.\n\n--c 40 | 이것은 혼돈 매개변수입니다. 숫자가 높을수록 MidJourney가 단일 프롬프트에서 반환하는 네 개의 초기 이미지 각각에 대한 다양성이 높아집니다.\n\n<div class=\"content-ad\"></div>\n\n조합 스타일라이즈와 카오스 매개 변수의 조합으로 우리는 적어도 하나의 탁월한 창의적인 스타일을 얻을 것이라고 생각합니다. 숫자를 바꿔보세요. 제 최종 프롬프트는 아래에 있습니다. 여러분의 프롬프트는 어떤가요?\n\n![이미지](/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_4.png)\n\n## 단계 3: MidJourney 리믹스와 주제적 숙달\n\n감염되는 비트가 있는 노래들이 있죠. 그리고 \"와, 이건 리믹스하면 멋질 것 같다!\" 라고 생각하시잖아요? 그렇다면 MidJourney의 \"리믹스\" 기능은 음악과는 전혀 상관이 없습니다. 미안해요, 그냥 멋진 오프닝 후크처럼 들렸던 것 뿐이에요.\n\n<div class=\"content-ad\"></div>\n\n응, 좋아, 한 번 해볼게요… MidJourney 리믹스 기능의 마법은 서로 다른 이미지에 일관된 예술적 스타일을 적용하는 능력에 있어요. 마치 음악 비트가 노래 리믹스 전체에 일관되게 펼쳐지는 것처럼요 (이게 작동됐나요?). 그 의미는 뭐냐면, 동일한 멋진 세트에 속한 것처럼 모든 이미지가 보이도록 전체 이미지 컬렉션을 설정할 수 있다는 거예요. 그리고 모두가 동일한 멋진 창조자에 의해 디자인된 것처럼 말이죠. 기사에 있는 이미지를 살아있게 만드는 꽤 괜찮은 방법이죠. 거의 그런 의도로 한 것처럼! (참고: 정말 그렇게 하고 싶었어요.)\n\n이제 ChatGPT가 우리의 주제적 '룩'을 식별했으니, 리믹스 기능을 통해 이 스타일을 생성하려는 모든 이미지에 적용할 수 있어요. 그래서, 이제 어떻게 하는지 알아볼게요.\n\n단계 1 — '룩' 만들고 선택하기\n\n가장 먼저 할 일은 소소한 설정 조정입니다 — 리믹스 모드가 켜져 있는지 확인하세요. 디스코드의 프롬프트 상자에 /prefer remix를 입력하여 이 작업을 수행하세요.\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_5.png)\n\nNow, whack in the first prompt ChatGPT served up to you. For me, it’s this one:\n\n/imagine: Half Angel Devil duality, expressionism, bold colors, distorted forms, exaggerated lines, chiaroscuro, strong light-dark contrast, surrealism, dreamlike scenes, unexpected juxtapositions, abstract symbolism, masks, shadows, mirrors --ar 3:4 --s300 --c 30\n\nHere’s what MidJourney served up:\n\n\n<div class=\"content-ad\"></div>\n\n![CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_6](/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_6.png)\n\n스타일 및 혼돈 매개변수가 잘 작동하는 것을 알 수 있어요. 우리는 네 가지 매우 다른 스타일을 가지고 있어요. 저는 왼쪽 아래 스타일을 좋아해요 - 그 모습이 내 작품에 잘 어울려요. 그래서 MidJourney의 'U3' 버튼을 클릭해서 확대해 보려고 해요. 그것이 네 개 중 첫 번째 이미지가 되고, 다음 세 개를 만들기 위한 참조 리믹스 이미지가 될 거예요.\n\n단계 2 - 리믹스 x 3\n\n확대가 완료되면 다음 이미지를 만들 수 있어요. 여기서 리믹스 기능을 켜는 게 중요하게 작용해요. 따라서 'Vary (강력)' 버튼을 클릭해서 리믹스 프롬프트를 활성화해 보세요.\n\n<div class=\"content-ad\"></div>\n\n지금 할 일은 ChatGPT의 다음 프롬프트를 리믹스 입력란에 넣는 것입니다. 실제로 여기서 바꾸는 것은 첫 몇 단어뿐입니다—시각화에 대한 ChatGPT가 선택한 짧은 구절—나머지는 동일합니다. 그러니, \"Half Angel Devil duality\"가 \"Shadowy Figure dancing\"로 바뀝니다.\n\n매우 중요한 미니 단계: 제출하기 전에 스타일라이즈 및 카오스 매개변수를 삭제하십시오(위의 스크린샷에서 강조된 매개변수를 참조하십시오). 그렇지 않으면 첫 번째 이미지의 초기 스타일이 디지털 소용돌이에서 손실되어 목적이 상실됩니다! 여러분 중의 영리한 사람들은 위에서 게시한 ChatGPT 프롬프트를 수정하여 마지막 세 개의 프롬프트에서 매개변수를 제외할 수도 있습니다. 천재적입니다!\n\n그래서, 계속해서 업로드 버튼을 클릭하십시오. MidJourney는 첫 번째 확장된 이미지와 동일한 스타일을 계승해야 하는 새로운 네 개의 이미지로 보상해줄 것입니다. 여러분들의 이미지는 어떻습니까? 제 것은 아래에 있습니다.\n\n![image](/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_7.png)\n\n<div class=\"content-ad\"></div>\n\n위의 왼쪽 상단 이미지처럼 \"그림자처럼 춤추는 모습\"을 나타내는 이미지는 없죠? 저는 이 우울한 집단 중에서 확대하고 사용할 이미지로 선택할 것입니다.\n\n이제 마지막 두 이미지 프롬프트에 대해 동일한 과정을 반복해야 합니다. 첫 번째 원본 확대 이미지로 돌아가서 '다양화 (강조)' 버튼을 다시 누르고 리믹스 상자에 다음 프롬프트를 입력하면 됩니다. 물론, 우리가 이야기한 두 매개변수를 삭제해야 할 거예요!\n\n매번 네 개의 이미지 세트를 받을 것이며, 선택한 첫 번째 이미지와 동일한 스타일을 가져야 합니다. 가장 어려운 작업은 각 그룹에서 선호하는 이미지를 선택하는 것입니다!\n\n# 최종 임무\n\n<div class=\"content-ad\"></div>\n\n이 모든 결과물의 결론은 무엇일까요? 여러분의 말을 더 강화하는 일관된 시각적 내러티브가 만들어집니다. 독자들은 여러분의 이야기에 몰입할 뿐만 아니라, 여러분의 심미적 솜씨가 그들을 시각적으로 감명시킬 것입니다.\n\n아래는 내 마지막 네 장의 이미지입니다. 기억을 되살리기 위해, 여기 ChatGPT가 제시한 원문의 각각이 어떤 것을 대표하는지입니다 (왼쪽부터 오른쪽, 위에서 아래로):\n\n- 내면의 악마: 천사적이고 악마적인 모습을 함께 보여주는 존재로 표현될 수 있는 이중 표현입니다.\n- 악독과의 댄스: 그림자 속에서 춤추는 모습으로, 이를 둘러싼 악의나 혼란의 요소가 있을 수 있습니다.\n- 루시퍼 효과: 이름에 과연한, 천사적인 존재에서 타락한 존재로의 변화를 표현할 수 있습니다.\n- 선 안의 선과 악: 좌우로 나뉘는 팽팽한 줄 혹은 균형 막대로 시각화될 수 있습니다. 한 쪽은 어둠으로 이어지고, 다른 한 쪽은 빛으로 이어질 것이며, 아마 어떤 방향으로 기울어야 하는지를 고민하는 존재가 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n함께 보면 정말 멋지잖아요? 당신이 작품의 분위기를 완벽하게 캡처하는 이미지 스타일을 가졌을 때 — 빈티지 세피아 룩, 추상적인 페인트 스왈, 네온 느낌의 느낌, 또는 위에 있는 것이 뭔지 모르겠지만 — 다른 사람들이 하는 것보다 훨씬 뛰어난 노력을 한 것 같은 느낌이 들어요. 비록, 아마도... 사실은 그렇지 않을지라도요. 당신의 작품이 돋보이도록 도와주는 것은 좋은 일이라고 생각하시죠?\n\n만약 집에서 함께 하고 계셨다면, 당신의 최종 이미지를 보고 그것에 대한 의견을 듣고 싶어해요 — 댓글에 공유해주세요 (댓글에 이미지를 추가하는 것이 가능한지는 잘 모르겠어요. 이미지 링크를 첨부하거나 설명해주셔야 할 것 같아요.)\n\n# 모두 감싸서\n\n그래서, 주식 사진 사이트로 빠져들지 않고 이미지 게임을 높이는 방법을 찾고 있었다면, 우리가 유용한 워크플로우를 발견한 것 같아요.\n\n<div class=\"content-ad\"></div>\n\n그리고, 알다시피 AI로 생성된 예술에는 반대 의견을 가진 사람들이 있죠. 아마도 \"네가 스스로와 어떻게 살아?\" 같은 댓글을 조금 받게 될지도 모르겠어요. 나는 MidJourney가 만들어 내는 모든 예술작품이 바람에서 날아올라온 게 아니라는 것을 알고 있어요. 그것은 그것이 훈련된 무수한 이미지, 스타일 및 영향으로부터 생겨난 결과물이에요. 그리고 이것이 백만 달러(또는 적어도 수천 단어의 미디엄 기사)의 질문에 우리를 이끌어요: AI로 생성된 예술에 대한 권리는 누구의 것인가? 지적 재산권이 침해되는 것은 누구의 것인가요?\n\n아, 그에 대한 답은 없어요. 그 난 뭘 알고 있다고 생각했나요? 귀엽네요, 감사합니다. 하지만 아니에요 - 이것은 법적 어려움이자 학자, 기술자, 예술가, 그리고 업자들이 모두 미묘하게 토론하는 철학적인 문제에요. 이런 일들은 어느 정도로 음악 및 영화 산업 전반이 작용한 대로 스스로 해결될 거에요. 그 일이 처리되면 나도 기뻐할 거예요 (이미 이 도구들에 대한 돈을 내고 있으니, 그들이 실현할 자격이 있는 사람들에게 수당을 분배할 방법을 어떻게 찾았더라도 좋아할 거에요!)\n\n어쨌든, 나는 새로운 예술적 움직임의 최전선에서 일화처럼 돌 것을 만들려고 하는 척하고 있지 않아요. 저는 솔직히 말해서, 내 물리적 신체를 사용해서 뭔가를 만들어내는 데 있어, 저는 기대를 부풀리는 사람들중 한 사람일 뿐이라고 생각해요. 그래서 기계에 의존하는 게 나예요. 그치만 쓰는 건 꽤 잘해요 - 그래서 그렇죠.\n\n내가 이 MidJourney에 관심을 두게 된 계기가 궁금해요? 제가 방금 말했듯이, 나는 조금이나마 격었어요. 순진한 열정으로, 나는 올해 초에 MidJourney의 가장 높은 계층에 가입한 연간 요금제에 신청했고, 이 멋진 기술을 활용할 창의적인 폭풍우와 사업 아이디어의 풍부함을 기대했어요. 현실은 무엇인가요? 나는 다량의 크레딧과 약간의 후회만 가득하게 되었어요. 하지만, 어쨌든! 위대한 힘(혹은 크레딧)과 함께 오는 큰 책임이 있죠. 그래서, 나는 내 연간 $1000 투자에 대한 어느 정도의 수익을 얻고 남들과 공유하기 위해 최대한 배우고 있어야한다고 생각했어요 - 그것이 바로 너희들이죠!\n\n<div class=\"content-ad\"></div>\n\n여기 이렇게 해서 우리가 여기에 도착한 거예요. 건강하지 않은 미드지니 크레딧을 갖고 있는 취미 작가가 이것을 만들었다면, 여러분도 할 수 있어요. 다음에 또 만나요. 즐겁게 창작하세요.\n\n## 더 많은 내용은 \"The Generator\"에서 확인하세요\n","ogImage":{"url":"/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_0.png"},"coverImage":"/assets/img/2024-05-27-CreatingVisualNarrativesforYourStoriesChatGPTMidJourneyMagic_0.png","tag":["Tech"],"readingTime":13},{"title":"영화 장르 스타일로 중간 과정을 안내해보세요","description":"","date":"2024-05-27 15:26","slug":"2024-05-27-GuideMidjourneywithFilmGenreStyles","content":"\n테이블 태그를 마크다운 형식으로 변경해 주세요.\n\n<div class=\"content-ad\"></div>\n\n저는 그 규칙들에 완전히 동의하고, 모두가 그런 행동을 피하도록 강력히 권장합니다. 유감스럽게도, 많은 사용자들이 사진작가, 감독, 영화 제작사, 브랜드 이름을 사용해서 이미지를 만들곤 합니다.\n\n제 의견으로는 이는 잘못된 행위이며, 저작권 위반 등 불필요한 문제를 야기합니다.\n\n하지만 그건 정말 쉽고 유혹적인 일이죠.\n\n최근에 저는 과학 극면을 소재로 한 이미지 세트를 만들어야 했고, 그 이미지들은 스타워즈 스타일을 연상시켜야 했습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_0.png)\n\n나는 스타워즈에 대해 꽤 친숙하고 3D 아티스트로서 제작에 일부 참여한 경험이 있어 스타워즈 스타일의 이미지를 만드는 것이 쉬울 것으로 생각했습니다.\n\n그러나 그 이미지를 브랜드 이름을 사용하지 않고 만들려고 하니 처음에 생각했던 것보다 더 복잡했습니다.\n\n\"낡은,\" \"무법자,\" \"사막과 과학 소설적 건축물\"과 같은 형용사를 선택하여 작업을 시작했습니다. 우주선과 풍경, 기복과 건물을 설명하려고 했으나 키워드가 쌓여서 제작 과정이 어려워졌습니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n![GuideMidjourneywithFilmGenreStyles_1](/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_1.png)\n\nIt turned out that there was a very simple solution without lengthy prompts or mentioning brands.\n\n![GuideMidjourneywithFilmGenreStyles_2](/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_2.png)\n\nInstead of trying to stuff my prompts with detailed definitions of things, I needed to think more about how Midjourney works.\n\n\n<div class=\"content-ad\"></div>\n\nMidjourney는 이미지를 기반으로 훈련되었습니다. 훈련을 위해 사진에 대한 정의로 인간들이 세심하게 라벨을 달았습니다.\n\n일부 사진은 간단했습니다. 예를 들어 \"고양이\"라고 합니다. 그러나 보다 유용하게 만들기 위해 정의를 추가적인 단어로 확장해야 했습니다. 예를 들어 \"휴식 중,\" \"잠자는 중,\" 또는 \"놀고 있는 중\" 같은 단어가 포함되어야 했습니다.\n\n훈련용 사진 중 일부는 그림 속 물건 이상의 것을 포함했습니다. 그것이 바로 장르, 스타일 및 예술적 흐름이 나오는 곳입니다. 이러한 개념은 단순히 사진 속 물체의 설명뿐만 아니라 훨씬 더 많은 정보를 담고 있습니다.\n\nMidjourney의 창조자들은 그 부분에 대해 잘 해냈습니다. Midjourney는 다양한 유동적인 장르 및 스타일 개념들에 대해 잘 훈련받았으며, 각 개념과 관련된 정보를 알고 있으며, 프롬프트에서 빠진 부분을 채울 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_3.png)\n\n제 프로젝트에서는 이름을 붙이고 설명하는 대신, 이 구체적인 이미지를 만들 때 관련된 장르를 설명하는 것이 훨씬 나은 것 같아요.\n\n맞아요, 스타 워즈는 과학 소설 장르에 속합니다. 그러나 이 장르에는 많은 스타일이 있으며 그 중 많은 것들이 스타 워즈와는 전혀 닮지 않아요.\n\n또한 이것은 서사시입니다. 서사시는 넓은 의미에서 거대한 풍경, 조망, 다층적인 심오함 등을 필요로 합니다. 제 프롬프트에 \"서사시\"라는 단어를 사용하면 많은 말들을 줄일 수 있어요.\n\n\n<div class=\"content-ad\"></div>\n\n하지만 무언가가 아직 부족합니다. 여러 개의 스타워즈 영화 스크린샷을 살펴본 후 결론을 내렸어요: 무법자 배경과 서부 영화에 많은 시네마적 요소가 공유된다구요.\n\n마지막 프롬프트를 추가하고 나니, “무법자 우주선, 공상과학, 대담함, 서부 스타일”과 같이 매우 간단한 프롬프트로 원하는 이미지가 정확히 펼쳐졌어요.\n\n그러면 \"우주선\"을 \"로봇\"이나 \"무법자 마을\"로 대체할 수 있고, Midjourney가 나머지를 처리해줄 거예요.\n\n<div class=\"content-ad\"></div>\n\n\n![GuideMidjourneywithFilmGenreStyles_5](/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_5.png)\n\nMidjourney는 카메라 각도, 조명, 구도 규칙 및 다른 장르와 관련된 많은 요소를 잘 알고 있습니다. 필요한 요소로 이미지를 채워 넣을 수 있으며, 프롬프트에 언급하지 않아도 됩니다.\n\n프롬프트에서 장르를 사용해도 윤리 규칙을 위반하는 것은 아닙니다.\n\n![GuideMidjourneywithFilmGenreStyles_6](/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_6.png)\n\n\n<div class=\"content-ad\"></div>\n\n알겠어요! 모든 사람이 바로 원하는 이미지를 설명하는 특정 장르나 조합을 파악하는 전문가는 아니에요. 그렇다고 ChatGPT가 예시 이미지를 분석하고 정의를 제공하는 데 도움이 될 수 있어요.\n\n그러니 여기 있어요: 프롬프트를 단순화하고 윤리 규칙을 위반하지 않고 좋은 결과물을 얻는 방법이에요. 제가 여러분의 창작물에 도움이 됐으면 좋겠어요.\n\nAivaras Grauzinis\n","ogImage":{"url":"/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_0.png"},"coverImage":"/assets/img/2024-05-27-GuideMidjourneywithFilmGenreStyles_0.png","tag":["Tech"],"readingTime":3},{"title":"이미지 변환하기 - MidJourney의 고급 SREF 블렌딩 기술","description":"","date":"2024-05-27 15:24","slug":"2024-05-27-TransformingImageryAdvancedSREFBlendingTechniquesinMidJourney","content":"\n## MIDJOURNEY EXPLORATIONS SREFS\n\n미드저니에서 스타일과 캐릭터 참조를 조합하여 독특하고 매력적인 이미지를 만드는 방법을 배우세요. 로맨틱 SREF ID가 70개 이상 포함되어 있습니다!\n\n저는 MiJourney에서 독창적인 로맨틱 SREF 스타일을 수집하며 \"MiJourney로 매혹적인 역사적 로맨스 표지 만들기\"라는 글을 썼습니다. 그러나 하나의 글에 모두 담기에는 너무 많았어요. \"MiJourney 마스터링: SREF ID를 활용한 고급 스타일 조작\"이라는 이어지는 글에서 로맨틱 이미지에 대한 추가 30개 ID를 공유했고, 스타일 가중치를 조절해 프롬프트에 영향을 미치는 방법을 보여드렸어요. 오늘은 더 많은 페인터리한 로맨틱 SREF 스타일을 모아봤습니다. 아래에서 찾아보실 수 있어요. 그 전에, 스타일을 혼합하여 완전히 독특한 이미지 참조 스타일을 만드는 방법에 대해 이야기해봐요.\n\n랜덤 SREF ID는 그 자체로 매우 극단적이고 압도적일 수 있습니다. 이전 글에서는 스타일 가중치를 줄여 영향을 줄이는 방법을 보여드렸어요. 이제 약간의 변화를 섞어 새로운 것을 만들어봅시다. 아래에서 세 가지 간단한 혼합을 보여드릴게요. 왼쪽 이미지는 스타일 참조 없이 만든 것으로, 우리 왕자와 공주에게 \"가장 현실적인 사진\" 스타일을 주기 위해 원시적이고 매우 낮은 스타일을 사용했어요.\n\n<div class=\"content-ad\"></div>\n\n```md\n전문 스튜디오 초상 사진. 더블렛을 입은 왕자와 빨간 머리 공주가 유니크한 의상을 입고 서로 마주보며 서로를 사랑스럽게 바라봅니다. 렘브란트 조명 사용. --ar 2:3 --style raw --stylize 1\n```\n\n그런 다음, 임의의 SREF ID를 사용한 이미지 중 하나와 함께 이를 결합했습니다. 어떤 추가적인 것도 없이 간단히 혼합했습니다. 이 조합을 통해 원본 이미지를 밝게하고 배경을 약간 변경하고자 했습니다. 그들이 밝아졌고, 그녀의 드레스가 파란색에서 흰색으로 바뀐 것을 주목해주세요.\n\n```md\nhttps://s.mj.run/h-qSBRaD4DE https://s.mj.run/CCRptYYRWv8 --ar 2:3\n```\n\n다음 조합에서는 밝히고 배경을 추가하려고 시도했습니다. 그렇게 성공적이었습니다: 그녀의 드레스가 밝아지고, 그의 의상에 일부 새로운 붉은 색 디테일과 금 장식이 생겼습니다. 아치 형태에 조금 놀라웠지만, 실제로 #3는 상당히 멋져 보입니다.\n\n```\n\n<div class=\"content-ad\"></div>\n\n```\n\nhttps://s.mj.run/h-qSBRaD4DE https://s.mj.run/uZ36l-hDQsE --ar 2:3\n\nWith the next one, I tried once again for a brighter sky. Midjourney felt that a more dynamic sky was needed, so my bright sky turned into a sunset. I found the rim lighting on the prince and princess to be an interesting and quite dynamic touch. In this variant, her dress was not recolored, but his suit has gained many embellishments.\n\nhttps://s.mj.run/L1_rPjYej0k https://s.mj.run/h-qSBRaD4DE --ar 2:3\n\nI decided to take another step towards flamboyance for a more striking difference in the images. Firstly, I have combined them as simple image references.\n\n```\n\n<div class=\"content-ad\"></div>\n\n```md\nhttps://s.mj.run/h-qSBRaD4DE https://s.mj.run/l7tQBc4KhhA 햇빛이 비치는 테라스에서 더블렛을 입은 왕자와 새틴 드레스를 입은 공주가 함께 있는 모습; 날씨의 따뜻함이 그 들의 사랑을 반영하며, 테라스는 숨막히는 풍경을 제공합니다. 이 디자인은 역사적 로맨스 소설 표지와 비슷한 스타일로 만들어졌어요. --ar 2:3\n\n이 중간 이미지는 꽤나 독특한 SREF ID로부터 왔어요. 간단한 참조 이미지 조합이 배경에 생동감을 불어넣고 그들의 의상을 환한 장식물로 꾸밉니다. 이제 우리는 조금의 발화를 더해볼게요. 아래 코드는 동일한 두 이미지를 왼쪽 이미지를 캐릭터 참조로, 중간 이미지를 스타일 참조로 넣어 합쳤어요.\n\n이 두 캐릭터에 대한 참조가 작동한다는 사실에 놀랐어요. 보통 제한은 단일 캐릭터만 가능하다고 기대하죠. 다른 종류의 프롬프트를 충분히 시도해보지 않아서 그것을 테스트할만한 겁니다. 얼굴이 가깝고 프롬프트가 유사하기 때문에 여기에서 작동한다고 의심해요. 얼굴을 섞어 동일하게 만들거나 하는 것으로 생각했는데 그런 것 같아 보이지 않았어요.\n```\n\n<div class=\"content-ad\"></div>\n\n--cref이 왼쪽 이미지에는 원본에 가까운 옷을 유지하면서 배경을 완전히 변경할 수 있어서 좋은 결과를 얻을 수 있어요. 그런데 만약 옷도 바꾸고 싶다면 어떻게 할까요? --cw 50을 사용하여 캐릭터 가중치를 낮추면(기본값 100에서) 변경할 수 있어요.\n\n```js\na prince in a doublet and a princess in a satin gown on a sunlit terrace; the warmth of the day reflecting their love; the terrace offering a breathtaking view, in the style of historical romance novel cover --ar 2:3 --sref https://s.mj.run/l7tQBc4KhhA --cref https://s.mj.run/h-qSBRaD4DE --cw 50\n```\n\n--cref를 사용했음에도 불구하고 얼굴이 약간 변한 것에 유의하세요. 하지만 숫자를 낮춤으로써 옷이 중간의 sref 이미지와 더 많은 특성을 취하게 할 수 있어요. 결과가 마음에 들지만 최종 사진에는 거의 충분히 장미가 없다면 어떻게 해야 할까요? 이에 대한 해결책이 있답니다. 스타일 가중치를 증가시켜 더 매력을 부여해보세요! 아래에서 동일한 명령을 실행하고 --sw 500를 추가했어요.\n\n```js\na prince in a doublet and a princess in a satin gown on a sunlit terrace; the warmth of the day reflecting their love; the terrace offering a breathtaking view, in the style of historical romance novel cover --ar 2:3 --sref https://s.mj.run/l7tQBc4KhhA --sw 500 --cref https://s.mj.run/h-qSBRaD4DE --cw 50\n```\n\n<div class=\"content-ad\"></div>\n\n그래서, 많은 일이 벌어지고 있지만 우리의 결과를 봐봐—장미들이 가득하지! 만약 당신이 모든 부분에 익숙하지 않다면, 나는 그것들을 단계별로 설명해줄게.\n\n\\[URL\\] \\[URL\\] 이미지 참조. 당신의 프롬프트를 이끌어가기 위해 이미지 하나 이상을 포함시킬 수 있어. 일반적으로 이미지 참조로, Midjourney는 이미지 요소들을 직접 당신의 프롬프트에 넣으려고 할 거야. 그러니까, 당신의 이미지에 코끼리가 있다면, 당신의 프롬프트 결과에 코끼리가 등장할 거야.\n\n--sref \\[URL\\]이거나 --sref ######## 스타일 참조 이미지나 랜덤 ID. 당신의 프롬프트 스타일에 영향을 주기 위해 하나의 이미지를 사용할 수 있어. sref는 이미지 URL이나 sref random으로 제공된 코드 중 하나를 사용할 수 있어.\n\n--cref \\[URL\\] 이미지를 캐릭터 참조로 취급하고 그 캐릭터를 새로운 프롬프트에 유지하려고 해.\n\n<div class=\"content-ad\"></div>\n\n--cw 캐릭터의 무게는 1에서 100까지 범위 내에 있습니다. 100에서는 캐릭터의 모든 측면을 유지하려고 노력합니다. 기본값은 100이지만 다른 값을 지정하지 않는 한 100으로 설정됩니다. 50으로 설정하면 캐릭터 무게가 캐릭터의 의상에 일부 변경을 허용합니다. 0으로 설정하면 얼굴만 보존하려고 노력하며 눈, 코, 입을 비롯한 나머지 부분은 변경할 수 있습니다.\n\n--sw 스타일 무게는 기본적으로 100이지만 1에서 1000까지 어디서든 사용할 수 있습니다. 마지막 예에서는 숫자를 500까지 올려 스타일을 이미지에 더 부각시킬 수 있는 방법을 보여주었습니다. 그 경우에는 장미와 Midjourney를 더 원했습니다!\n\n# 모든 것을 함께해 봅시다\n\n위의 예제에서 랜덤 SREF ID가 있는 이미지 하나만 사용했습니다. 이것은 중간 이미지가 우리의 프롬프트에 어떤 스타일을 가하고 있는지 명확히 이해할 수 있도록 했기 때문입니다. 하지만 이것은 필수는 아닙니다. 다양한 이미지를 작업할 때는 원하는 결과를 얻을 것으로 생각되는 이미지를 혼합하십시오. 이 기사의 목적을 위해 비슷한 프롬프트를 사용하여 이미지를 혼합했을 때 가장 만족스러운 결과를 얻었습니다.\n\n<div class=\"content-ad\"></div>\n\n이미지의 다른 가로 세로 비율을 섞을 때 블랙 바가 자주 나타난다는 것을 인지하는 것이 중요합니다. 약간 귀찮을 수 있지만, 쉽게 해결할 수 있어요. Vary(Region) 도구를 사용하여 주변 이미지의 약간을 포함해 블랙 바를 선택하면 Midjourney가 해당 부분을 채워줄 거에요.\n\n이미지, 스타일, 캐릭터 참조 등을 사용하여 위의 기술을 혼합하는 방법을 사용하세요. 여러분의 이미지를 매우 흥미로운 곳으로 데려갈 수 있어요!\n\n# 화가적 SREF ID\n\n# 마지막으로\n\n<div class=\"content-ad\"></div>\n\n오늘은 MidJourney의 강력한 SREF ID를 사용하여 스타일과 캐릭터 참조를 혼합하는 복잡한 점에 대해 살펴보았어요. 서로 다른 스타일 가중치와 캐릭터 가중치를 실험하여 독특하고 매혹적인 이미지를 만들 수 있어요. 캔버스를 담백하게 표현하거나 생동감 넘치는 역사적 장면을 만들고 싶다면, 이러한 기술을 통해 창의력의 경계를 넓힐 수 있어요. 다양한 조합과 설정을 실험하여 당신의 비전을 현실로 만드는 완벽한 균형을 찾아보세요.\n\n만약 이 글에서 무엇을 얻었다면 - 멋진 새로운 아이디어든, 재밌게 읽은 것이든 - 만약 클랩 버튼을 눌러주시면 정말 감사하겠어요. 최대 50번의 클랩을 줄 수 있으니, 계속 클릭해주세요! :) 제 새로운 글이 나오면 업데이트를 받기 위해 팔로우해주세요. 여러분의 피드백과 참여는 제가 다음에 어떤 콘텐츠를 만들어야 하는지 결정하는 데 도움이 되며, 제가 옳은 길을 걷고 있다는 것을 알려줍니다. 여러분과 공감하는 콘텐츠를 만들었다는 것을 알 때 진심으로 의미가 있어요. 제안이나 요청이 있으시다면 댓글을 남겨주세요! 끝까지 읽어주셔서 정말 감사드리고, 다음 글에서 뵙겠습니다.\n","ogImage":{"url":"/assets/img/2024-05-27-TransformingImageryAdvancedSREFBlendingTechniquesinMidJourney_0.png"},"coverImage":"/assets/img/2024-05-27-TransformingImageryAdvancedSREFBlendingTechniquesinMidJourney_0.png","tag":["Tech"],"readingTime":6},{"title":"중간여행 매거진이 여러분의 감각을 기쁘게 해줄 수 있을까요","description":"","date":"2024-05-27 15:23","slug":"2024-05-27-CanMidjourneyMagazineDelightYourSenses","content":"\n![CanMidjourneyMagazineDelightYourSenses](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_0.png)\n\n가끔 인쇄 매체 산업이 자유 낙하 중인 것 같아요. 그러나 샌프란시스코의 인공 지능(AI) 연구소인 Midjourney는 최근 사용자들의 AI 이미지를 특집한 인쇄 매체를 출시하기로 대담한 결정을 내렸어요. 왜냐하면 인터넷이 인쇄 매체 산업을 죽이지 않았다는 걸 밝혀냈기 때문이에요. 그뿐만 아니라! 최근 등장한 생성적인 AI 이미지 대해운은 인쇄 산업 표준에 큰 전환을 가져오고 있어요. 소비자들이 AI로 생성된 이미지를 인쇄해서 볼 가치가 있는지라는 문제는 이미 낙제했어요. 당신은 알고리즘으로 조합된 눈 호감이으로 풍격난 페이지를 넘기고 싶을까요?\n\n# 근사한 느낌\n\n며칠 전 나의 우편함에 오랜만에 매거진 구독이 도착했어요. 심푸른 눈동자 한 쌍이 신비한 창백한 도자 인형 얼굴 뒤에서 나를 뚫고 들어왔어요. 파란, 노란, 카민 점들이 튀어나온 이 권돌이 얼굴 상단에서 길게 펼쳐진 시선이 풍만하게 그려진 입술로 슬쩍 떨어졌고, 밤의 마스카라로 강조된 아몬드 족자 눈에 어울리는 붉은색 입술이 돋보였어요. 간단한 제목 아래에는 발행일과 비전 선언이 표시된 백색 정보 줄이 있었어요.\n\n<div class=\"content-ad\"></div>\n\n전체 패키지는 손에 잘 들어와요. 프리미엄 뉴스 스탠드 잡지에서 기대할 수 있는 두께와 무게를 갖췄고, 벨벳 에그셸 커버까지 있어 손가락에서 척척 소름이 끼치는 느낌을 줍니다. 다채롭게 꾸며진 페이지를 넘기는 것은 맛있게 신나는 경험이에요. 하지만 이게 얼마나 오래 지속될까요?\n\n# 미드저니, 미래일까 희미한 유행일까?\n\n![이미지](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_1.png)\n\n미드저니 매거진은 색과 모양의 심포니예요. 단순한 출판물 이상의 경험이죠. 앰비셔스한 디지털 부모에게만 이용 가능한 디스코드 앱을 통해 접속할 수 있는 미드저니 매거진은 인공지능 생성 시각적 효과와 매일 라떼 가격을 견줄만한 값을 지닌다는 점에서 의문을 던지죠: 구독 출판물의 미래일까요, 아니면 지나가는 유행일까요?\n\n<div class=\"content-ad\"></div>\n\n빛나는 이미지 속으로 들어가보면, 철저하고도 기이하게 익숙한 영역에 자신을 발견할 수 있을 겁니다. 사이버네틱 여성들의 강렬한 시선, 판타지 풍경, 켄터키 더비 모자를 쓴 오리들, 워해머와 같은 괴물들까지. 이 잡지는 마치 인간과 기계 사이에 대사를 초대하며, 아야와스카 정신의 본질을 들어내는 것 없이 여러분을 초대하는 것 같아요.\n\n하지만, 이 잡지는 미취 세계를 가진 사람들도 있는데요. 이 잡지는 Curate Creative의 공동 창립자인 Michelle Pegg 등 비평가들이 있어요. 최근의 Wired 기사에서 Pegg는 Midjourney가 화려하고 매력적이지만, 일반적인 잡지에서 발견되는 영혼이 부족하다고 선언했어요. 왜 그런지 쉽게 이해되네요. 잡지는 이야기, 의견, 높은 품질의 보도가 현실적이고 정돈된 경험으로 융합되는 캔버스였거든요. Midjourney 잡지는 아름답고 재미있을지 몰라도, 심금을 울리는 지성적인 소울메이트를 찾고 있다면 아닐 지도 몰라요.\n\n# 비물질적인 것의 물질적 매력\n\n![이미지](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_2.png)\n\n<div class=\"content-ad\"></div>\n\n많은 사람들이 전통 매거진이 매력적인 이유는 인간 전문가들 - 작가, 사진작가 및 디자이너들 -이 의미 있는 것을 만들기 위해 애쓰는 노고 때문이라고 주장합니다. 그들은 Midjourney의 AI-주도적인 과정을 영혼을 효율성을 위해 희생하는 단축으로 비난합니다.\n\n그럼에도 불구하고 Midjourney의 방식에는 매혹적인 요소가 있습니다. 아마도 그것은 페이지를 넘기는 놀라운 경험이 그런 것일지도 모릅니다. 각각의 페이지를 넘길 때마다, 다음에 무슨 광적인 광경이나 감동적인 아름다움을 마주하게 될지 알 수 없습니다. 마치 잡지 자체가 ASMR (자율 감각 메리디언 반응)의 촉감 형태가 된 것처럼, 디지털 경험으로는 재현할 수 없는 감각을 일으킵니다. 질감을 좋아하는 책애호가들은 이것을 알고 있습니다 - 디지털 시대에 종이를 만져보는 즐거움은 숭배스럽습니다. 내용이 인간이 아니더라도 나 자신을 알면 될 뿐입니다.\n\nAI는 인쇄 산업을 되살릴 수 있는 빠진 재료가 될 수 있습니다. 아니, 그것은 기자들과 디자이너들의 작업을 대규모로 대체하지는 않을 것입니다. 아마도 우리는 그러한 출판물을 매거진이 아닌 쇼케이스 카탈로그라고 부르는 것이 바람직할지도 모릅니다. 우리가 매거진이 어떠해야 하는지에 대한 오래된 본능과 습관을 극복한다면, Midjourney의 출판물을 기술과 예술의 혁신적인 교차로로 보게 될 수도 있습니다. 거기에서 인간의 창조성과 기계 생성 시각 요소가 매료적인 둘둘 놀이를 펼칠 수 있는 장소로 만드는 잡지를 만들어낼 수 있습니다.\n\n# 완벽의 역섬포터도스\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_3.png)\n\nMidjourney Magazine의 한 가지 큰 단점은 심도의 부족입니다. 시각적으로 멋있을지언정 깊이는 없습니다. 그러나 이 이상하고도 이 제한은 바로 그것의 강점일 수 있습니다. 이 잡지는 모든 사람들에게 모든 것이 되려 하지 않으며, 이야기를 전하려 하지도 않습니다. 제공하는 것은 시각이 최고인 세계로의 초대이며, 이를 통해 관객들에게 탐험하고, 의문을 제기하고, 참여하거나 (악플러들은 어차피 혐오할 것이니까) 무시할 것을 요청합니다.\n\n사실 잡지 산업은 광고 수익의 감소와 품질 제작 비용의 상승으로 오랫동안 고심해 왔습니다. Midjourney는 다른 서술을 제공합니다. 사용자가 생성한 AI 콘텐츠를 활용함으로써 어떤 비용을 감소시킬 수 있음과 동시에 시각-촉감적 경험에 흥미를 느끼는 새로운 관객을 끌어들일 것입니다.\n\n그래서 Midjourney는 영혼이 없는가? 아마도 그럴지도 모릅니다. 그러나 굉장히 빨리 변화하는 글로벌 미디어 환경의 맥락에서 \"영혼\"이란 무엇인지에 대해 의문을 제기하게 만듭니다. 우리의 기대를 재정의하며, 아직 작성 중인 규칙들이 쓰인 미발표 영역으로 우리를 이끌어 줍니다. 논란이 될 수 있습니까? 예, 그러나 감각을 들뜨게 하는 맛있는 놀라움이기도 합니다. 그리고 누가 알겠습니까? 혹시 그것이 우리의 인쇄물과의 사랑 관계를 다시 끌어 올릴 필요가 있는 것은 아닌가요? 이것은 옥수수 우유 라떼값을 지불할 가치가 있지 않을까요?\n\n<div class=\"content-ad\"></div>\n\n# 아래의 인용구를 즐기지만 구독해서 전윕감을 느껴보세요 ;-).\n\n![이미지1](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_4.png)\n\n![이미지2](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_5.png)\n\n![이미지3](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_6.png)\n\n<div class=\"content-ad\"></div>\n\n![link](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_7.png)\n\n![link](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_8.png)\n\n![link](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_9.png)\n\n![link](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_10.png)\n\n<div class=\"content-ad\"></div>\n\n\n![Image 1](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_11.png)\n\n![Image 2](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_12.png)\n\n![Image 3](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_13.png)\n\n![Image 4](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_14.png)\n\n\n<div class=\"content-ad\"></div>\n\n이 이야기는 Generative AI에서 발행되었습니다. LinkedIn에서 저희와 연결하여 피드에서 최신 AI 이야기와 인사이트를 받아보세요. 함께 AI의 미래를 함께 만들어봅시다!\n\n\n![image](/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_15.png)\n\n","ogImage":{"url":"/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_0.png"},"coverImage":"/assets/img/2024-05-27-CanMidjourneyMagazineDelightYourSenses_0.png","tag":["Tech"],"readingTime":5},{"title":"IP-Adapter-FaceID-PlusV2-0 샷 페이스 전송  자동 설치 프로그램, 그라디오 앱  집적화된 컴퓨팅, 런팟, 캐글, 윈도우","description":"","date":"2024-05-27 15:21","slug":"2024-05-27-IP-Adapter-FaceID-PlusV20ShotFaceTransferAutoInstallerGradioAppMassedComputeRunPodKaggleWindows","content":"\n\n위의 ZIP 파일에는 Windows, RunPod, Massed Compute 및 무료 Kaggle 계정 노트북용 설치 프로그램이 포함되어 있습니다.\n\n이것은 VENV를 생성하고 그 안에 모든 것을 설치합니다. Python 3.10.x와 함께 작동합니다 — 3.10.11을 권장합니다.\n\n또한 C++ 도구와 Git이 필요합니다. 모두 설치하는 방법은 다음 동영상을 참고하시면 됩니다 : https://youtu.be/-NjNy7afOQ0\n\n2024년 5월 27일 최신 정보 : https://www.patreon.com/posts/95759342\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-27-IP-Adapter-FaceID-PlusV20ShotFaceTransferAutoInstallerGradioAppMassedComputeRunPodKaggleWindows_0.png\" />\n\n2024년 1월 21일 업데이트\nSDXL 모델이 ip-adapter-faceid-plusv2_sd15로 업그레이드되었습니다.\nKaggle 노트북도 V3로 업그레이드되어 이제 SDXL을 지원합니다.\n\n우선 이 놀라운 모델을 제공해 주셔서 너무 감사드립니다.\n\n저는 Gradio를 코딩하고 비디오를 준비하는 데 1주일 이상 소요했습니다. 이 스레드를 유지하고 Readme 파일에 추가해 주시기를 희망합니다.\n\n<div class=\"content-ad\"></div>\n\n비디오가 게시된 후 얼굴 임베딩 캐싱 메커니즘도 추가했어요. 그래서 이제 이미지당 얼굴 임베딩 벡터를 한 번만 계산하므로 이미지 생성 속도가 엄청나게 빨라졌어요.\n\nIP-어댑터-얼굴ID를 사용하여 즉각적으로 얼굴 전송: Windows용 전체 튜토리얼 및 GUI, RunPod 및 Kaggle\n\n![이미지](/assets/img/2024-05-27-IP-Adapter-FaceID-PlusV20ShotFaceTransferAutoInstallerGradioAppMassedComputeRunPodKaggleWindows_1.png)\n\n다음과 같은 장들이 있어요.\n\n<div class=\"content-ad\"></div>\n\n'''\n0:00 IP-Adapter-FaceID 풀 튜토리얼 소개\n2:19 IP-Adapter-FaceID Gradio 웹 앱 사용 요구 사항\n2:45 Windows에서 Hugging Face 모델이 기본적으로 다운로드되는 위치\n3:12 Hugging Face 모델이 다운로드되고 캐시되는 폴더 경로 변경 방법\n3:39 IP-Adapter-FaceID Gradio 웹 앱 설치 및 Windows에서 사용하는 방법\n5:35 설치 후 IP-Adapter-FaceID 웹 UI 시작 방법\n5:46 IP-Adapter-FaceID와 Stable Diffusion XL (SDXL) 모델 사용 방법\n5:56 입력 얼굴 선택 및 0샷 얼굴 이동 이미지 생성 시작 방법\n6:06 웹 UI의 각 옵션이 하는 일 설명\n6:44 드롭다운 메뉴 모델 및 의미 설명\n7:50 사용자 정의 및 로컬 모델을 사용하는 방법 및 사용자 정의 모델 경로 설정 방법\n8:09 사용자 정의 모델 및 로컬 모델을 영구적으로 웹 UI 드롭다운 메뉴에 추가하는 방법\n8:52 IP-Adapter-FaceID 웹 앱에서 CivitAI 모델 사용 방법\n9:17 CKPT 또는 Safetensors 모델 파일을 확산기 형식으로 변환하는 방법\n10:05 사용자 정의 모델 경로 입력에 내보낸 확산기 모델 사용하는 방법\n10:24 생성된 이미지 다운로드 및 이미지 저장 위치\n10:40 SDXL 모드 사용 방법\n11:37 사용자 정의 로컬 모델을 영구적으로 웹 앱 모델 드롭다운 목록에 추가하는 방법\n13:28 RunPod에 IP-Adapter-FaceID Gradio 웹 앱 설치 및 사용하는 방법\n15:39 설치 후 RunPod에서 IP-Adapter-FaceID Gradio 웹 앱 시작하는 방법\n16:02 RunPod 또는 Kaggle에서 사용 시 주의해야 할 사항\n16:43 Pod 간에 영구적으로 저장하는 방법\n17:17 RunPod에서 웹 앱 편집 및 UI에 모델 영구적으로 추가하는 방법\n17:46 RunPod에서 시작된 웹 UI 인스턴스 종료하는 방법\n18:08 RunPod에 fuser 명령어 설치하는 방법\n19:01 RunPod에서 IP-Adapter-FaceID와 사용자 정의 CivitAI 모델 사용 방법\n20:00 CivitAI에서 wget 방법이 실패할 경우 RunPod 또는 Kaggle에서 작동하는 방법\n20:34 RunPod에서 파일을 올바르게 삭제하는 방법\n20:58 RunPod에서 CKPT 또는 Safetensors 체크포인트를 확산기로 변환하는 방법\n22:58 RunPod에서 SD 1.5 모델 변환 예시 표시\n24:18 무료 Kaggle 노트북에서 IP-Adapter-FaceID Gradio 웹 앱 설치 및 사용하는 방법\n26:10 Kaggle의 temp 디렉토리에 사용할 사용자 정의 모델 다운로드하는 방법\n26:47 Kaggle에서 Gradio 앱을 사용하기 위해 토큰을 받고 활성화하는 방법\n27:05 인증 토큰 설정 후 Kaggle에서 웹 UI 시작하는 방법\n28:26 Kaggle에서 사용할 수 있도록 사용자 정의 CivitAI 또는 모델을 확산기로 변환하는 방법\n29:23 1클릭으로 Kaggle 노트북에서 생성된 모든 이미지 다운로드하는 방법\n30:12 Discord 채널 링크: https://discord.com/servers/software-engineering-courses-secourses-772774097734074388\n'''\n","ogImage":{"url":"/assets/img/2024-05-27-IP-Adapter-FaceID-PlusV20ShotFaceTransferAutoInstallerGradioAppMassedComputeRunPodKaggleWindows_0.png"},"coverImage":"/assets/img/2024-05-27-IP-Adapter-FaceID-PlusV20ShotFaceTransferAutoInstallerGradioAppMassedComputeRunPodKaggleWindows_0.png","tag":["Tech"],"readingTime":3},{"title":"개인용 AI 기술 소식 에이전트 구축하기","description":"","date":"2024-05-27 15:18","slug":"2024-05-27-BuildaPersonalAITechNewsAgent","content":"\n### 귀하의 선호에 따라 기술 사이트를 크롤링하여 주요 트렌드를 요약합니다\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_0.png)\n\nAI 시대에 이런 것을 구축하는 것이 쉽다고 생각할 수 있습니다. 그러나 고성능 LLM에 접근할 수 있다고 해서 구조화된 데이터가 필요하지 않다는 뜻은 아닙니다.\n\n여기서 구축하려는 것은 매일과 매주 실행되는 개인 맞춤형 기술 보고봇으로, 기술 커뮤니티가 공유하고 이야기하는 내용을 기반으로 기술 트렌드와 뉴스를 요약해야 합니다. 개인적인 선호에 맞게 구축되어야 하므로 요약 내용이 얼마나 간결해야 하는지와 어떤 내용에 초점을 맞춰야 하는지 결정할 수 있어야 합니다.\n\n<div class=\"content-ad\"></div>\n\n사용 중인 데이터는 기술 사이트를 크롤링하여 키워드를 추출하고 이를 집계하여 다양한 카테고리 내에서 어떤 것이 트렌드인지 파악하는 데 도움을 주는 API입니다.\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_1.png)\n\n이 아이디어는 API를 쿼리하고 트렌드 지표와 우리의 선호도에 기반하여 LLM으로 공급해야 하는 소스를 프로그래밍적으로 설정함으로써 올바른 데이터를 요약하도록 도와주는 것입니다.\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_2.png)\n\n<div class=\"content-ad\"></div>\n\n만약 이와 같은 검색 API를 만들고 싶다면, 여기 이전 게시물을 확인해보세요. 이것은 이 API가 어떻게 작동하는지에 대해 좀 더 자세히 다룹니다.\n\n해당 기사에서는 오픈 소스 NLP를 사용하여 키워드를 추출하고 분류하여 수천 개의 텍스트를 분석하고 링크하는 방법에 대해 언급했습니다. 또한 여기서 자신의 NLP 모델을 세밀하게 조정하는 방법에 대해 이야기했고, API를 구축하는 데 도움이 된 모델을 오픈 소스로 공개했습니다.\n\n그러나 이를 처음부터 만들 필요는 없습니다.\n\n저는 이 API를 기반으로 구축될 최종 결과에 더 관심이 있으며, 이를 통해 이와 같은 뉴스 보고서를 생성할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Personal AI Tech News Agent](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_3.png)\n\n보고서는 우리가 받은 내용의 짧은 스니펫입니다. 최대 열 가지 카테고리를 선택할 수 있고, 물론 매일 또는 매주 기술 봇이 찾을 키워드는 무한합니다.\n\n여기에서 보고서의 전체 예시를 찾을 수 있습니다. 원하는 대로 조정하여 모양을 바꿀 수 있습니다. 한 가지 카테고리에만 집중하거나 몇 가지 키워드에만 초점을 맞출 수도 있습니다.\n\n우리를 대신해서 일을 하는 LLM이 있는데요, 각 카테고리 내에서 제공된 데이터로 그 소스를 요약합니다. 이 뉴스레터나 보고서를 조직하는 사람은 없습니다. 데이터가 있고, 그리고 LLM이 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n빌딩 아키텍처는 제외합니다. 그 외에 모든 것은 저희가 처리할게요!\n\n# 소개\n\n저희는 저코드 도구를 사용하지 않아요. 그래서 코딩에 완전히 처음이신 분들에겐 이해하기 어려울 수도 있어요. 하지만 코드 자체는 미리 준비돼 있을 테니, 당신이 해야 할 일은 설정을 당신의 기호에 맞게 조정하는 것뿐이에요. 다만, 무료 AWS 계정이 필요해요.\n\n전체 튜토리얼은 5에서 10분 정도 걸릴 거예요. 이에 따른 비용은 OpenAI 토큰만 사용하는 것이에요.\n\n<div class=\"content-ad\"></div>\n\n여기에서 사용할 리포지토리를 찾을 수 있어요.\n\n간단한 소개와 봇의 아키텍처를 살펴보고, 그 후에 봇을 만들기 시작할 거에요.\n\n## 몇 가지 질문과 답변\n\n이 작업에 얼마나 기술적으로 이해해야 하나요? 매우 기술적으로 해줄 필요는 없어요. AWS에 배포하기 위해 Serverless Framework를 사용하기 때문에 시작부터 AWS 계정이 설정되어 있다면 더 좋을 거에요.\n\n<div class=\"content-ad\"></div>\n\n얼마든지 비용이 발생합니까? AWS 무료 티어 한도를 초과하지는 않을 겁니다. 따라서 비용은 LLM 토큰을 위한 것입니다 - 이 경우에는 GPT-3.5. 하루에 요청하는 카테고리 및 키워드 수에 따라 보고서 하나당 보통 $0.05 이하의 비용이 듭니다.\n\n시간 투자는 얼마나 되나요? 이미 제가 코드를 작성해 놓았기 때문에 크지 않아요. 여러분은 그대로 가져다 쓸 수 있습니다. 다만 원하시는 대로 조정하실 수도 있어요.\n\n## 인프라\n\nAPI 자체를 구축하는 작업은 이미 완료되었기 때문에 대부분의 작업은 그냥 이 데이터를 활용하는 것뿐이에요.\n\n<div class=\"content-ad\"></div>\n\n위 기술 봇을 구축하기 위해선, 함수에 AWS Lambda를 사용하고 스케줄에 따라 매주 평일 10 UTC에 실행되도록 AWS EventBridge를 사용할 것입니다. AWS를 배포하기 위해 Serverless Framework를 사용할 것인데, 이는 프로세스를 간단화해줍니다.\n\n여기서 사용할 언어는 파이썬입니다.\n\n![Tech Bot](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_4.png)\n\n이메일을 보내기 위해 AWS Simple Email Service를 사용할 것이지만, 원하는 매체를 자유롭게 선택하셔도 됩니다.\n\n<div class=\"content-ad\"></div>\n\n슬랙이나 WhatsApp으로 업데이트를 받고 싶다면, 코드를 조정하여 해당 정보를 거기로 보내도록 설정할 수 있어요. 그러나, 이 튜토리얼에서는 이메일을 보내는 방법만 알려드릴 거에요.\n\n그럼 데이터를 위한 API는 어떨까요? 우리에게 데이터를 제공하는 API에 대해 더 알고 싶다면 여기를 확인해보세요. 당신만의 API를 생성할 수도 있어요. 하지만, 이 경우에는 제가 사용하는 것을 사용할 수 있어요. 무료이며 작고 정교한 NLP 모델을 사용하여 유지 비용이 최소화되고 있답니다.\n\n이전에 키워드를 추출하는 NLP 모델을 오픈소스로 공개했었어요. 따라서 여러분도 완전히 본인의 것을 만드는 것이 가능해요.\n\n우리가 작업할 데이터를 확인하려면, 빠른 API 호출로 테이블 엔드포인트를 확인할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n```js\ncurl -X GET \"https://safron.io/api/table?period=daily&sort=trending\"\n```\n\n어제 여러 기술 웹사이트에서 NLP 모델이 추출한 키워드의 양과 트렌딩 키워드를 먼저 정렬할 것입니다.\n\n특정 키워드나 행 ID에 대한 검색 결과를 얻으려면 소스 엔드포인트를 사용합니다.\n\n```js\ncurl -X POST \\\n-H \"Content-Type: application/json\" \\\n-d '{\"keywords\": [\"ChatGPT\", \"AI\"]}' \\\n\"https://safron.io/api/sources\"\n```\n\n<div class=\"content-ad\"></div>\n\n이렇게 하면 'AI'와 'ChatGPT'라는 키워드를 기반으로 최근 6일간의 소스 또는 검색 결과를 얻을 수 있어요. 여기서 날짜와 소스를 제어할 수도 있습니다.\n\n하지만, 이 애플리케이션에서는 뉴스레터를 작성하기 위해 키워드 대신 JSON 요청의 본문에 ID를 사용하고 있어요. 코드 리포지토리를 엿볼 수 있다면 어떻게 하는지 확인할 수 있어요.\n\n더 큰 LLM은 어떻게 되죠? 마지막으로, 우리는 데이터를 제공하는 더 큰 LLM을 통합하고 있어요. 이것에 대한 오픈 소스 사용 여부는 당신에게 달려있어요. 그러나 간편함을 위해 OpenAI에서 방금 출시한 새로운 GPT-3.5-turbo-1205 모델을 사용중이에요.\n\n이 부분을 잘 수행하기 위해 충분히 큰 모델이 필요하니 GPT-3.5, Claude Haiku 또는 Mistral Medium로 시작하는 것을 권장해요. 최소 16k의 컨텍스트 창이 필요할 거에요.\n\n<div class=\"content-ad\"></div>\n\n# 기술적인 부분\n\n이를 구축하기 위해서 몇 가지가 필요합니다.\n\nAWS 계정이 필요합니다. 이미 가지고 있지 않다면 만들어 주세요. 이 프로젝트에서는 무료 티어를 초과하지 않겠지만, 빌링 알림을 설정하는 것이 좋습니다.\n\n로컬에 NodeJS, npm 및 Python이 설치되어 있는지 확인해 주세요. API를 테스트하는 데 Postman을 가지고 있는 것도 좋지만 필수는 아닙니다.\n\n<div class=\"content-ad\"></div>\n\n이 애플리케이션을 완료하는 단계는 다음과 같습니다.\n\n- AWS에서 IAM 사용자 구성\n- OpenAI API 키 획득\n- 로컬 환경 설정\n- API에서 데이터 테스트\n- 봇에 대한 개인 설정 구성\n- 이메일을 위해 AWS SES 설정\n- 일정에 따라 애플리케이션 배포\n\n## AWS 구성\n\n먼저 AWS 콘솔에서 IAM 사용자를 설정해야합니다.\n\n<div class=\"content-ad\"></div>\n\nAWS 콘솔에서 IAM으로 이동하세요. 새로운 사용자를 만들어 마음에 드는 이름을 지어보세요. 이 사용자는 관리 콘솔에 액세스할 필요가 없을 거에요.\n\n권한 설정에서는 직접 정책을 연결하고 다음으로 정책을 생성해야 합니다.\n\n아래 허용 권한을 붙여넣기하려면 JSON 형식을 선택하세요.\n\n<div class=\"content-ad\"></div>\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"VisualEditor0\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"iam:GetRole\",\n        \"events:DescribeRule\",\n        \"apigateway:*\",\n        \"s3:*\",\n        \"logs:*\",\n        \"events:PutRule\",\n        \"events:RemoveTargets\",\n        \"events:PutTargets\",\n        \"events:DeleteRule\",\n        \"iam:CreateRole\",\n        \"cloudformation:*\",\n        \"iam:AttachRolePolicy\",\n        \"iam:PutRolePolicy\",\n        \"events:PutTargets\",\n        \"iam:PassRole\",\n        \"lambda:*\",\n        \"iam:TagRole\",\n        \"iam:UntagRole\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n```\n\n이것은 매우 광범위한 권한 집합을 포함하고 있어서 항상 주의해야 합니다. 그러나 Serverless는 모든 것이 원할하게 작동하려면 꽤 많은 권한이 필요합니다. 더 세밀한 권한 집합을 설정할 수 있는지 Serverless 문서를 살펴볼 수 있지만, 그렇지 않으면 계속 진행할 것입니다.\n\n정책에 의미 있는 이름을 지어 '저장'을 클릭하십시오. 저는 내 것을 serverless로 지었습니다.\n\n정책을 보려면 IAM 사용자를 다시 만들어야 할 수도 있지만, 페이지를 새로 고침하면 표시될 것입니다.\n\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_6.png\" />\n\n사용자를 생성한 다음 액세스 키를 생성할 수 있는 위치를 찾습니다.\n\n사용 목적을 묻는 질문에 답할 때 '로컬 코드'를 선택하고 .csv 파일을 다운로드합니다. 나중에 Serverless가 응용 프로그램을 만들 때 이 자격 증명이 필요합니다.\n\n일반적으로 응용 프로그램을 배포한 후에이 사용자의 권한을 취소하지만, 나는 본능적으로 겁쟁이입니다. 그러나 응용 프로그램을 배포한 후까지 기다리겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## OpenAI API 키 얻기\n\nplatform.openai.com으로 가서 새 계정을 만들거나 로그인하세요. 'API 키'로 이동하세요.\n\n새 API 키를 받아 안전한 곳에 저장하세요.\n\n이 어플리케이션에 필요한 유일한 비용은 토큰이나 직불 카드를 추가해야 한다는 것입니다. 하지만 대부분의 사용자들이 이미 계정을 가지고 있을 것이라고 생각합니다.\n\n<div class=\"content-ad\"></div>\n\n## 로컬 환경 설정\n\n이 작업을 위해 NodeJS, npm 및 Python이 설치되어 있는지 확인하세요.\n\n터미널에서 node -v 및 npm -v를 실행하여 Node.js 및 npm이 설치되어 있는지 확인할 수 있습니다. 그렇지 않은 경우 Node.js를 설치해야 합니다 (npm은 Node.js와 함께 제공됩니다). Node.js와 npm을 설치하려면 Node.js 웹사이트를 방문하여 설치 프로그램을 로컬로 다운로드하세요.\n\n또한 Python이 설치되어 있는지 및 해당 버전을 확인하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\npython --version\n```\n\n이 명령을 실행하면 'Python 3.11.5.'가 반환됩니다.\n\n만약 다른 버전을 가지고 있다면, serverless.yml 파일에서 런타임을 업그레이드하거나 변경해주세요.\n\n```yaml\nprovider:\n  name: aws\n  runtime: python3.11\n```\n\n<div class=\"content-ad\"></div>\n\n내 노트북에는 Docker도 설치되어 있습니다. Docker가 실행 중이 아니라면 종속 항목을 Docker와 함께 패키징하도록 serverless.yml 파일을 false로 변경하십시오.\n\n```js\ncustom: pythonRequirements: dockerizePip: false;\n```\n\n우리가 Docker를 사용할 필요가 없다고 생각하기 때문에 이 부분은 생략해도 문제가 되지 않습니다.\n\n모든 것이 올바르게 설정되었다고 확신이 드시면 새 폴더를 로컬로 설정하는 방법으로 계속 진행할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nmkdir tech-bot\ncd tech-bot\n```\n\n서버리스 프레임워크를 전역으로 설치했는지 확인해주세요.\n\n```js\nnpm install -g serverless\n```\n\n그런 다음 다음과 같이 작업할 리포지토리를 복제해주세요.\n\n<div class=\"content-ad\"></div>\n\n```js\ngit clone https://github.com/ilsilfverskiold/ai-tech-news-bot.git\ncd ai-tech-news-bot\n```\n\n가상 환경을 설정하고 활성화하세요.\n\n```js\npython -m venv venv\nsource venv/bin/activate  # Windows에서는 `venv\\Scripts\\activate`\n```\n\n의존성을 설치할 수 있도록 서버리스 플러그인을 설치해주세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nserverless plugin install -n serverless-python-requirements\n```\n\nrequirements.txt 파일에 저장된 필수 종속성을 설치하세요.\n\n```js\npip install -r requirements.txt\n```\n\n마지막으로, AWS에서 IAM 사용자를 생성할 때 다운로드한 AWS 자격 증명을 추가해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n다음과 같이 설정해주세요.\n\n```js\nserverless config credentials --provider aws --key YOUR_AWS_ACCESS_KEY --secret YOUR_AWS_SECRET_KEY\n```\n\n이렇게 하면 AWS에 우리 애플리케이션을 배포할 수 있게 될 거에요.\n\n## API 테스트\n\n<div class=\"content-ad\"></div>\n\n이 LLM에 곧 넣을 데이터를 테스트해봅시다. 어떤 결과를 얻는지 확인해보세요.\n\n브라우저에서 아래 내용을 검색 창에 붙여넣어보세요.\n\n```js\nhttps://www.safron.io/api/table?period=daily&sort=trending\n```\n\n우리가 받게 될 결과는 이런 식일 겁니다.\n\n<div class=\"content-ad\"></div>\n\n```json\n{\nupdate_date: \"2024-02-19\",\nrows: 2983,\nresults: [\n  {\n    keyword: \"AWS\",\n    date: \"2024-02-19T00:00:00.000Z\",\n    count: 72,\n    category: \"Platforms & Search Engines\",\n    row_ids: [],\n    sentiment: {},\n    yesterday_count: 34,\n    sentiment_previous: {},\n    countChange: 111.76470588235294,\n    trending: true\n  },\n  {\n    keyword: \"Security\",\n    date: \"2024-02-19T00:00:00.000Z\",\n    count: 40,\n    category: \"Subjects\",\n    row_ids: [],\n    sentiment: {},\n    yesterday_count: 27,\n    sentiment_previous: {},\n    countChange: 48.148148148148145,\n    trending: true\n  }\n  ...\n]\n```\n\n여기서 보면, 이제 'trending'인지, 특정 키워드인지 또는 특정 카테고리에 속하는지에 따라 객체를 프로그래밍적으로 필터링할 수 있습니다.\n\n필터링한 후에는 소스 엔드포인트의 row_ids를 사용하여 이러한 키워드에 대한 소스를 가져올 수 있습니다.\n\n```json\nhttps://safron.io/api/sources\n```\n\n<div class=\"content-ad\"></div>\n\n이 엔드포인트는 POST 요청을 필요로 합니다. Postman을 사용하여 이를 테스트할 것입니다.\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_7.png)\n\n소스 엔드포인트에는 JSON 본문에 'keywords' 또는 'ids'를 전달할 수 있습니다. 여기서는 'ids'를 사용하고 있습니다. 이 'ids'는 테이블 엔드포인트의 row_ids에서 얻을 수 있습니다. 애플리케이션에서도 이것을 수행할 것입니다.\n\n먼저 특정 키워드의 row_ids를 가져오기 위해 테이블 API를 쿼리하고, 그런 다음 이러한 'ids'를 다른 요청에 사용하여 소스/search 엔드포인트로 이동하여 올바른 소스와 URL을 얻어올 것입니다.\n\n<div class=\"content-ad\"></div>\n\n걱정 마세요, 이를 위해 코드를 설정할 필요는 없지만 이게 어떻게 작동하는지 알려드릴게요.\n\n## 선호도 설정 및 개인화하기\n\n클론한 저장소의 코드를 로컬에서 열어주세요. 보통 저는 이를 간단한 바로 가기 단축키를 사용해서 VSCode에서 합니다.\n\n```js\n.code\n```\n\n<div class=\"content-ad\"></div>\n\n해당 단축키를 설정해야 하므로, 편리하다면 코드 디렉토리를 직접 선택하여 원하는 코드 편집기에서 엽니다.\n\n설정을 구성하려면 config.py로 이동하세요.\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_8.png)\n\n여기에서 세 가지 선택 사항이 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 발견된 트렌딩 키워드에 대한 카테고리 제한을 설정할 수 있어요.\n- 관심 키워드를 설정할 수 있어요. 이러한 키워드들은 트렌딩 여부와 상관없이 항상 발견 대상이 되어야 해요.\n- 각 카테고리 내의 키워드 수와 함께 발견할 카테고리를 설정할 수 있어요.\n\n여기서 좀 더 시도해보거나 그대로 둬도 돼요. 임시 프론트엔드가 준비돼 있어서 다른 키워드를 발견하고 무엇이 있는지 확인할 수 있어요.\n\n## 이메일 알림을 위한 AWS SES 설정하기\n\nLLM이 생성한 이메일도 보내야 해요.\n\n<div class=\"content-ad\"></div>\n\n\"이미 generate_html_report 함수를 위한 email 템플릿을 helper_functions.py에 설정해 두었어요.\n\n코드 베이스로 이동해서 generate_html 함수를 찾아 이메일 레이아웃을 조정할 수 있어요. 이건 선택 사항이에요.\n\n<img src=\"/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_9.png\" />\n\n만약 괜찮다면, 이 부분은 넘어가도 돼요.\"\n\n<div class=\"content-ad\"></div>\n\n가장 중요한 것은 AWS SES에서 확인된 원본 주소를 설정하는 것입니다.\n\n그래서 AWS 콘솔로 돌아가주세요. Simple Email Service를 찾으세요.\n\n이메일을 보낼 수 있는 이메일 주소를 추가해야 합니다. 그리고 해당 이메일 주소로 이메일을 보내기 전에 확인을 받아야 합니다.\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_10.png)\n\n<div class=\"content-ad\"></div>\n\n이메일 뉴스레터를 받고 싶은 이메일 주소를 식별하기 위한 식별자를 만들어보세요. safron.io라는 도메인을 가지고 있기 때문에 그것을 발신지로 사용했지만, 개인 이메일 주소를 사용해야 합니다.\n\nconfig.py 파일 아래 코드에서 올바른 지역, 수신 및 발신 주소를 설정하는 것도 잊지 마세요.\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_11.png)\n\n로컬에서 테스트하기 전에 마지막으로 IAM 사용자에게 SES 액세스 권한도 부여해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n이제 이 작업을 수행하기 위해 IAM으로 돌아가서 이전에 생성한 사용자를 찾아서 권한 추가를 클릭한 후 AmazonSESFullAccess를 찾아 IAM 사용자에 추가하면 됩니다.\n\n![image](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_12.png)\n\n이제 응용 프로그램은 이메일을 보낼 수 있게 됩니다.\n\n만약 \"저는 무작위 사람들에게도 이 이메일을 보내고 싶어요!\"라고 생각하신다면 도메인 이름과 AWS로부터 샌드박스 환경을 벗어나기 위한 확인이 필요합니다. 이는 조금 복잡한 과정일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n기술적으로 여기에 Slack, Whatsapp를 사용하거나 그 경우에는 MailChimp를 설정할 수도 있습니다.\n\n## AWS에 배포\n\n마지막 단계는 이를 테스트하고 AWS에 푸시하는 것입니다.\n\n저는 개인적으로 먼저 로컬에서 시도해보겠습니다. 뉴스레터 템플릿을 조금 개선하고 뉴스레터가 어떻게 보이는지 확인하고 싶을 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n터미널에서 다음을 실행하세요.\n\n```js\nserverless invoke local --function newsletterTrigger\n```\n\n로컬에서 실행하면 어떻게 되어야 할까요? 아래에서 제 코드를 확인해보세요.\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*fhNnFNqkI4IGIntv2_nP9Q.gif\" />\n\n<div class=\"content-ad\"></div>\n\n이메일이 발신된 후 어떻게 될까요? 이메일 받은 편지함에는 다음과 같은 내용이 표시됩니다.\n\n\n![이미지](/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_13.png)\n\n\n사용자 설정, 시스템 템플릿, 그리고 LLM 선택에 따라 달라질 수 있어요.\n\n이미 serverless.yml 파일에 EventBridge 일정을 설정했기 때문에, 평일에 10시(UTC)에 트리거됩니다. 보고서를 발송할 시간을 변경하고 싶다면 그렇게 할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n행복하다면, AWS로 푸시하세요.\n\n```js\nserverless deploy\n```\n\n## 완료 결과\n\n이제 매일 오전 10시 UTC에 자동으로 실행되는 개인 기술 뉴스레터가 있습니다. 그리고 주간 뉴스레터는 매주 금요일에 실행됩니다. 특히 관심 있는 내용을 기반으로 작동해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 몇 가지 메모\n\n일주일에 한 번만 스카우트하고 싶을 키워드와 매일 스카우트하고 싶을 키워드가 있을 것 같아요. 'AI'는 매일 검색하는 것이 좋은데, 데이터 소스가 많기 때문이에요. 반면 'Mistral'과 같은 소스가 적은 키워드를 확인할 때는 6일 동안 데이터를 수집하는 것이 더 좋아요. 이렇게 하면 데이터를 요약하기에 더 많은 정보를 얻을 수 있어요.\n\nLLMs는 맥락 창이 매우 짧기 때문에 키워드 당 최대 150개의 소스와 요약 정보만 처리할 수 있어요.\n\n그랬던가요?\n\n<div class=\"content-ad\"></div>\n\n멋진 프로젝트네요! 제가 원하는 것을 제공해줘서 좋지만, 아직 진행 중인 프로젝트이죠.\n\n다음에는 무엇이 있을까요?\n\n이 데이터에 더 많은 ML 프로세스를 적용하여 보다 나은 추세 지표를 얻는 것이 흥미로울 수 있을 것 같아요. 현재 사용 중인 알고리즘이 조금 불안정하기 때문에 그 부분을 개선하는 것도 흥미로울 수 있겠죠. 또한, 검색하는 키워드를 기반으로 보고서를 받기 위해 더 나은 UI를 만드는 것도 흥미로울 것 같아요.\n\n게다가, 테크 분야 외부의 데이터를 더 넣어주면, 다양한 분야에서 사람들이 무엇에 대해 이야기하는지 이해할 수도 있을 거예요.\n\n<div class=\"content-ad\"></div>\n\n알겠어요.\n\n유용한 기술 봇을 설정했거나 상상력을 자극했기를 바랍니다.\n\n❤\n","ogImage":{"url":"/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_0.png"},"coverImage":"/assets/img/2024-05-27-BuildaPersonalAITechNewsAgent_0.png","tag":["Tech"],"readingTime":14},{"title":"Hugging Face의 Flan-T5 모델을 사용하여 고객 인사이트를 분석해 봅시다","description":"","date":"2024-05-27 15:16","slug":"2024-05-27-AnalyseCustomerInsightswithHuggingFacesFlan-T5Model","content":"\n\n현재의 데이터 중심 세계에서는 기업들이 항상 고객을 이해하고 관계를 발전시키는 방법을 찾고 있습니다. 이 임무에서 가장 흥미로운 도구 중 하나가 Hugging Face의 Flan-T5 모델입니다. 이 고급 자연어 처리(NLP) 모델은 또 다른 기술용어가 아니라, 기업이 데이터와 고객과 상호작용하는 방식을 혁신하는 중요한 도구입니다. Flan-T5가 고객 인사이트를 혁신하는 방법을 알아보기 위해 실제 사례를 살펴보겠습니다.\n\n# 과제: 고객 피드백 이해하기\n\n우리 팀은 여러 채널(설문, 소셜 미디어, 이메일, 라이브 챗)에서 고객 피드백을 수집했습니다. 이 피드백은 많은 인사이트가 담겨있지만 흩어져 있고 구조화되어 있지 않습니다. 수천 개의 코멘트를 살펴 트렌드와 실행 가능한 항목을 식별하는 작업은 허구속의바늘을 찾는 것과 같습니다.\n\n# Flan-T5 등장\n\n<div class=\"content-ad\"></div>\n\n허깅페이스의 Flan-T5 모델이 등장하는 곳입니다. Flan-T5는 \"Fine-tuned Language-Agnostic Network, Text-To-Text Transfer Transformer\"의 약자로, 다언어 및 다양한 맥락에서 인간과 유사한 텍스트를 이해하고 생성할 수 있는 고급 NLP 모델입니다. 이 모델의 강점은 특정 작업에 대해 세밀하게 조정될 수 있는 능력에 있어서, 이는 고객 피드백을 구문 분석하고 분석하는 데 이상적인 후보자로 만들어 줍니다.\n\n# Flan-T5 구조\n\nFlan-T5는 Transformer 아키텍처를 기반으로 하며, 구체적으로 텍스트-텍스트 프레임워크를 사용합니다. 이는 모든 NLP 작업 - 번역, 요약 또는 질의 응답 - 이 텍스트 입력을 텍스트 출력 문제로 캐스팅된다는 의미입니다. 다음은 아키텍처의 간소화된 개요입니다:\n\n- 인코더: 입력 텍스트를 처리하고 연속 표현의 집합으로 변환합니다.\n- 디코더: 이러한 연속 표현을 취하여 출력 텍스트를 생성합니다.\n\n양방향 인코더는 양방향에서 컨텍스트를 포착하며, 이는 고객 피드백의 세부 정보를 이해하는 데 효과적입니다.\n\n<div class=\"content-ad\"></div>\n\n# 해결책 구현:\n\n단계 1: 데이터 수집 및 전처리\n먼저, 모든 고객 피드백을 중앙 데이터베이스에 수집하고 데이터 전처리를 통해 노이즈를 제거합니다.\n\n단계 2: 플란-T5 파인튜닝\nHugging Face의 Transformers 라이브러리를 사용하여 플란-T5 모델을 파인튜닝합니다.\n\n```python\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n\n# 토크나이저 및 모델 로드\ntokenizer = T5Tokenizer.from_pretrained('google/flan-t5-base')\nmodel = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')\n\n# 데이터 토큰화\ndef preprocess_function(examples):\n    return tokenizer(examples['feedback'], truncation=True, padding='max_length', max_length=512)\n\ntrain_data_tokenized = train_data.apply(preprocess_function, axis=1)\ntest_data_tokenized = test_data.apply(preprocess_function, axis=1)\n\n# 훈련 인자 준비\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01\n)\n\n# 트레이너 인스턴스 생성\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data_tokenized,\n    eval_dataset=test_data_tokenized\n)\n\n# 모델 훈련\ntrainer.train()\n```\n\n<div class=\"content-ad\"></div>\n\n**단계 3:** 감성 분석 및 주제 모델링\n미세 조정된 모델을 배포하여 감성 분석을 수행하고 주요 주제를 식별합니다.\n\n# 현실 세계의 영향\n\nFlan-T5를 구현한 후, 전자상거래 회사는 변화적인 결과를 보았습니다:\n\n- 향상된 고객 이해: 모델은 피드백을 의미 있는 통찰로 정확하게 분류했습니다. 예를 들어, 부정적인 피드백의 상당 부분이 지연된 배송과 관련이 있음을 강조하여 회사가 물류 문제에 대응하도록 유도했습니다.\n- 선제적 고객 서비스: 실시간으로 트렌드를 식별함으로써 고객 서비스팀이 일반적인 문제에 선제적으로 대응하여 전반적인 고객 만족도를 향상시켰습니다.\n- 데이터 기반의 결정: 마케팅 및 제품 개발 팀은 이러한 통찰을 사용하여 캠페인을 맞춤화하고 제품 기능을 개선하여 고객 참여 및 충성도를 증대시켰습니다.\n\n<div class=\"content-ad\"></div>\n\n# Flan-T5가 돋보이는 이유\n\nFlan-T5의 매력은 그의 적응성에 있습니다. 이는 단순히 감성 분석이나 주제 모델링에 한정되지 않습니다. 비즈니스는 다음과 같은 다양한 응용 프로그램을 위해 그 기능을 활용할 수 있습니다:\n\n- 자동화된 고객 지원: 고객 쿼리를 이해하고 높은 정확도로 응답하는 챗봇 구현.\n- 콘텐츠 생성: 다양한 고객 세그먼트와 공감대를 형성하는 맞춤 마케팅 콘텐츠 작성.\n- 예측 분석: 고객의 행동과 선호도를 예측하여 전략적 결정을 이끌어내는 것.\n\n# Flan-T5 시작하기\n\n<div class=\"content-ad\"></div>\n\n플란-T5를 채택하는 것은 Hugging Face의 사용자 친화적인 도구와 포괄적인 문서 덕분에 생각보다 쉽습니다. 아래는 빠른 로드맵입니다:\n\n- Hugging Face의 모델 허브 탐색: 플란-T5를 찾아서 사전 훈련된 모델을 실험해보세요.\n- 트랜스포머 라이브러리 활용: 특정 데이터셋에서 모델을 세밀하게 조정하기 위해 트랜스포머 라이브러리를 활용하세요.\n- 배포 및 모니터링: 모델을 기존 시스템에 통합하고 성능을 지속적으로 모니터링하며 개선하세요.\n\n# 결론\n\nHugging Face의 플란-T5 모델의 능력을 활용하면 기업은 고객에 대한 심층적인 이해를 얻을 수 있습니다. 비구조적인 피드백을 실행 가능한 통찰로 변환함으로써 기업은 고객 경험을 향상시키고 참여를 촉진하며 궁극적으로 수익을 증대시킬 수 있습니다. 고객 기대가 지속적으로 변화하는 세상에서 플란-T5와 같은 최첨단 NLP 모델로 앞서가는 것은 선택이 아니라 필수입니다. 고객 인사이트를 혁신하시 ready하세요? 미래는 플란-T5입니다.","ogImage":{"url":"/assets/img/2024-05-27-AnalyseCustomerInsightswithHuggingFacesFlan-T5Model_0.png"},"coverImage":"/assets/img/2024-05-27-AnalyseCustomerInsightswithHuggingFacesFlan-T5Model_0.png","tag":["Tech"],"readingTime":4},{"title":"RAG 자동화를 위한 건축 설계도 Vertex AI 검색을 활용한 고급 문서이해","description":"","date":"2024-05-27 15:10","slug":"2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch","content":"\n<img src=\"/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_0.png\" />\n\n안녕하세요!\n\n생성적 AI는 개발자와 기업에 수많은 기회를 제공하여 비즈니스 프로세스를 혁신하고 고객 경험을 변화시키며 새로운 수익 방식을 발견하게 도와줍니다. 그러나 이 잠재력을 완전히 실현하려면, 건축가와 IT 리더들은 AI 모델, 응용 프로그램 및 에이전트를 신속하게 실험하고 반복할 수 있는 동시에 비용 관리, 거버넌스 및 확장성을 고려해야 하는 복잡한 환경을 탐험해야 합니다.\n\n최근 개최된 Next’24 구글 클라우드 이벤트에서 저희는 강력한 Vertex AI Search 및 Conversation 제품과 다양한 고급 개발자 도구를 통합한 혁명적인 솔루션인 Vertex AI Agent Builder를 공개했습니다. 이 포괄적인 제공은 개발자들이 복잡한 작업과 문의를 원활하게 처리할 수 있는 정교한 AI 기반 에이전트를 만들고 배포할 수 있게 도와주어 다양한 영역에서 혁신과 효율성을 촉진합니다.\n\n# Vertex AI Search 이해하기\n\n<div class=\"content-ad\"></div>\n\nVertex AI Search은 구글 클라우드 내에서 제공되는 포괄적인 플랫폼으로, 조직이 직원 및 고객을 위한 맞춤형 검색 솔루션을 만들 수 있도록 설계되었습니다. 이 플랫폼은 웹사이트, 구조화된 데이터(예: BigQuery 테이블, JSON 라인) 및 비정형 데이터(예: PDF, HTML, 텍스트)를 포함한 다양한 데이터 원본에 대해 구글 검색과 유사한 경험을 제공합니다.\n\n이전 블로그 포스트에서는 Vertex AI Search를 사용하여 공개적으로 색인된 웹페이지에서 대상 웹페이지를 수집하는 방법에 대해 논의했습니다. 이 방법은 이러한 웹페이지의 사전 구글 색인을 활용합니다. 우리는 PDF 문서를 채굴하기 위한 지식 발견 파이프라인을 구축하는 데 이 방법을 사용했습니다.\n\n우리 이전 포스트의 연장선으로 이 기사를 고려해 주세요. 여기서는 추출된 PDF 문서를 처리하는 방법에 대해 다룹니다. 이러한 문서는 이미 준비되어 있을 수 있어 바로 사용할 수 있습니다. 또는 당신의 기업에게 기밀인 소유 문서일 수도 있습니다. 여기서는 이러한 문서의 데이터를 수용하고 처리하며, 복잡한 쿼리에 응답할 수 있는 시스템을 구축하는 방법을 탐색할 것입니다. 예를 들어 사실 정보를 검색하거나 분기 보고서의 재무 표에서 숫자를 인출하는 것과 같은 복잡한 쿼리에 대답할 수 있는 시스템을 구축합니다.\n\n주로, Vertex AI Search는 GCP의 완전 관리형 플랫폼으로, 구글 검색 품질 기능을 기업 데이터에 통합하여 두 가지 주요 이점을 제공합니다:\n\n<div class=\"content-ad\"></div>\n\n- 향상된 검색 경험: 기존의 키워드 기반 검색을 모던한 대화형 경험으로 변환시켜 주는 기능입니다. 구글의 혁신적인 생성 검색과 비슷한 방식으로 작동합니다. 이 기능은 내부 및 고객 상대 애플리케이션의 효율성을 크게 향상시킵니다.\n- 강화된 생성 AI 애플리케이션: 생성 AI 애플리케이션 내 답변 생성을 지원합니다. 기업 데이터를 기반으로 하는 생성 AI는 Vertex AI 검색을 통해 실제 비즈니스 사용 사례에 중요한 정확성, 신뢰성 및 적합성을 보장합니다. 이는 검색 기능의 통합을 간편하게 하는 준비된 RAG 시스템 역할을 하며, 검색 기능을 획기적으로 향상해 줍니다.\n\n맞춤형 RAG 파이프라인 구축은 복잡할 수 있습니다. Vertex AI 검색은 준비된 솔루션을 제공하여 이 프로세스를 간단하게 만들어 줍니다. 데이터 추출 및 변환, 정보 검색 및 요약까지 검색 및 발견 프로세스의 모든 측면을 간소화하여 클릭 몇 번으로 줄여 줍니다. 결과적으로, 일반 검색 엔진으로 Vertex AI 검색을 사용하여 강력한 RAG 애플리케이션을 신속하게 개발할 수 있습니다.\n\n준비된 솔루션은 상당한 편의성을 제공하지만, Vertex AI 검색은 개발자에게 자세한 제어도 허용합니다. 플랫폼의 유연성을 활용하여 RAG 파이프라인 각 단계를 사용자의 필요에 맞게 맞춤화할 수 있습니다. 이 하이브리드 접근 방식을 통해 사전 구축된 구성 요소와 맞춤형 기능을 이상적으로 조화시킬 수 있어, 응용 프로그램이 특정 사용 사례와 완벽하게 일치하도록 보장할 수 있습니다.\n\nVertex AI 검색은 다양한 API 세트를 통해 이를 실현합니다. 이러한 API를 통해 Vertex AI 검색의 RAG 시스템의 기본 구성 요소를 노출시켜 개발자가 맞춤형 사용 사례에 대응하거나 자세한 제어를 필요로 하는 고객을 지원할 수 있습니다. 이는 Document AI Layout Parser API, Ranking API, Grounded Generation API, Check Grounding API 등을 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n시작해 봅시다! 먼저 데이터셋을 이해하는 데 집중할 차례입니다. 이는 저희 RAG 파이프라인의 기반이 되는 것이죠. 그런 다음에는 이 데이터를 Vertex AI Search에 효과적으로 수집하여 신속하게 검색할 수 있도록 구성하는 방법을 배우게 될 거에요. Vertex AI Search 내에서 색인 전략에 중점을 두어야 하는데, 이는 인공지능이 필요할 때 가장 관련성 높은 정보에 접근할 수 있도록 하는 데 중요합니다. 우리는 색인된 문서를 쿼리하는 기술에 대해 자세히 살펴보고, 다양한 파이프라인 접근 방식을 실험할 겁니다. 마지막으로 결과물을 수집하고, 검색 정확도 및 생성된 답변의 품질을 평가하는 방법을 배우게 될 거에요. 이 여정을 통해 여러분은 RAG와 Vertex AI Search의 힘을 활용하여 더 스마트하고 정보에 기반한 AI 파이프라인을 구축하는 데 필요한 지식을 습득하게 될 거에요.\n\n# 데이터셋\n\n저희 실험에 사용할 데이터셋은 Alphabet, Amazon, Microsoft 세 기술 기업의 분기 보고서로 구성되어 있어요. 2021년 1분기부터 2023년 4분기까지의 기간 동안, 3년 동안의 36개 문서(각 기업당 12개)로 이루어진 데이터셋이에요.\n\n실험을 용이하게 하기 위해, 이 문서들에서 100개의 질문-답변 쌍을 유도했어요. 각 쌍은 한 문서에 직접 연결되어 있어, 단일 통로 질문-답변 시나리오를 구축합니다. 세심하게 만들어진 질문과 답변은 테이블과 복잡한 단락에서 정보를 추출하는 데 초점을 맞추었으며, RAG 시스템에 상당한 도전을 제공합니다. 이 100개의 질문-답변 쌍은 저희가 다룰 다양한 RAG 파이프라인 설계의 성능을 평가하기 위한 참 값 역할을 합니다. PDF 금융 분기 보고서 데이터셋은 여기에서 찾을 수 있으며, 질문-답변 쌍 데이터셋은 ground_truth.csv라는 CSV 파일에 있습니다. 이 파일에는 다음 메타 정보가 포함되어 있습니다 - i)매핑 문서, ii) 기업 이름, iii) 시기. 이 메타 정보는 CSV 파일의 document 열 하나에 포함되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\nAlphabet의 2020년 1분기 보고서에서 주로 영업 소득과 마진에 관련된 재무 결과를 요약한 샘플 테이블이 아래에 표시됩니다.\n\n![테이블](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_1.png)\n\n우리의 실제 CSV에서의 샘플 질문과 위 테이블을 통해 파생된 예상 답변이 있습니다.\n\n```js\nGoogle의 2021년 3월 말 영업 소득은 얼마이며 (십억으로), 이전 연도 동기 대비 어떻게 비교되었습니까?\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nGoogle의 영업 이익은 2021년 제1사분기에 164.37억 달러였습니다. 이는 2020년 제1사분기의 79.77억 달러에서 증가한 금액입니다.\n```\n\n위 답변을 작성하기 위해서는 먼저 쿼리에서 구체적인 세부 정보를 추론하여 올바른 문서를 검색해야 합니다. 이에는 올바른 페이지로 이동하고 적절한 테이블을 참조하며 열 정보를 구문 분석하는 것이 포함됩니다. 그런 다음 필드를 열 제목에 매핑하고 올바른 정보를 찾습니다. 마지막으로 이러한 수집된 정보를 일관된 답변으로 통합합니다.\n\n참고: 미국의 Microsoft는 전통적인 달력 년도와 일치하지 않는 재무 연도를 따릅니다. 예를 들어, 그들의 재정 첫 분기는 7월부터 9월까지의 기간을 다룹니다. 따라서 그들의 제1사분기 실적 보고서는 실제 달력에서 이전 분기의 성과를 반영합니다. 질문과 문서명에 이미 이 사항이 고려되어 있습니다.\n\n# 문서 수용 및 색인화\n\n\n\n<div class=\"content-ad\"></div>\n\n파이낸셜 문서를 이해하고 질문에 답하는 데 효과적으로 Vertex AI Search를 활용하려면 먼저 데이터를 준비하고 가져와야 합니다. 이를 위해 Vertex AI Search에서 전용 데이터 저장소를 생성하고 Google Cloud Storage (GCS)에서 파이낸셜 문서를 이 저장소로 가져와야 합니다. 다행히도, Vertex AI Search는 정보의 구문 분석, 조각화 및 색인 작업을 자동으로 처리해줍니다.\n\n다음으로, 데이터를 활용하여 견고한 검색 및 검색 기능을 제공하는 문서 검색 응용 프로그램을 구성할 것입니다. 이러한 단계를 따라가면 파이낸셜 문서의 효과적인 색인 및 탐색을 위한 견고한 기초를 확립할 수 있습니다. 이를 통해 실험 및 문서 질문 응답용 견고한 파이프라인을 개발하는 데 필요한 정보에 빠르게 액세스할 수 있습니다. 각 단계를 자세히 살펴보겠습니다.\n\nI. 데이터 저장소 생성:\n\nVertex AI Search의 데이터 저장소는 처리된 문서가 저장되는 컨테이너입니다. 처리된 조각을 포함하도록 데이터 저장소를 생성하려면 Vertex AI Search 프로젝트 내에서 쉽게 인식할 수 있도록 데이터 저장소에 고유한 식별자와 표시 이름을 할당해야 합니다. 현재 데이터 저장소에는 아무 문서도 포함되어 있지 않습니다. 다음 단계로 문서를 이 데이터 저장소에 푸시(입력)할 것입니다. 여기서 강조할 사항은 원본 PDF 문서가 실제로 GCS에 저장된다는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n아래 코드 스니펫은 REST API를 사용하여 Vertex AI Search를 구현하는 방법을 간단히 보여줍니다. 또한 Vertex AI Python SDK를 사용할 수도 있습니다. 여기서 Discovery Engine Vertex AI에 대한 문서를 참조하실 수 있습니다. 데이터 저장소를 생성하는 전체 코드는 여기에서 확인하실 수 있습니다.\n\n```js\nurl = f\"https://discoveryengine.googleapis.com/v1alpha/projects/{config.PROJECT_ID}/locations/global/collections/default_collection/dataStores?dataStoreId={data_store_id}\"\n\nheaders = {\n    'Authorization': f'Bearer {config.ACCESS_TOKEN}',\n    'Content-Type': 'application/json',\n    'X-Goog-User-Project': config.PROJECT_ID\n}\ndata = {\n    'displayName': data_store_display_name,\n    'industryVertical': IndustryVertical.GENERIC,\n    'solutionTypes': SolutionType.SOLUTION_TYPE_SEARCH,\n    'contentConfig': DataStore.ContentConfig.CONTENT_REQUIRED,\n    'documentProcessingConfig': {\n        'defaultParsingConfig': {\n            'layoutParsingConfig': {}\n        }\n    }\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n```\n\nII. GCS에서 문서 입력:\n\n데이터 저장소가 생성되면 지정된 GCS 버킷에서 귀사의 금융 문서를 입력하기 시작합니다. 이 프로세스에는 데이터 집합의 원본 PDF 문서가 저장된 GCS 버킷의 URI를 지정해야 합니다. 이전에는 manifest 파일을 생성해야 합니다. 이것은 Vertex AI 검색에 입력할 문서들의 모든 메타데이터를 포착하는 JSON 파일입니다. 이 파일의 샘플 행인 metadata.json은 아래에서 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n```json\n{\n  \"id\": \"1\",\n  \"jsonData\": \"{\\\"company\\\": \\\"alphabet\\\", \\\"time_period\\\": \\\"Q1 2021\\\"}\",\n  \"content\": {\n    \"mimeType\": \"application/pdf\",\n    \"uri\": \"gs://vais-rag-patterns/raw_docs/alphabet-q1-2021.pdf\"\n  }\n}\n```\n\n아래는 삽입을 초기화하기 위한 코드의 예시 미리보기입니다. 이 코드는 REST API를 활용하며, 전체 코드는 여기 링크된 Git 저장소에서 찾을 수 있습니다.\n\n```js\nurl = f\"https://discoveryengine.googleapis.com/v1/projects/{project_id}/locations/global/collections/default_collection/dataStores/{data_store_id}/branches/0/documents:import\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {config.ACCESS_TOKEN}\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"gcsSource\": {\n        \"inputUris\": [gcs_input_uri]\n    }\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n```\n\nIII. 문서 검색 애플리케이션 만들기:```\n\n<div class=\"content-ad\"></div>\n\n우리 문서들의 성공적인 소화 후 마지막 단계는 문서 검색 애플리케이션을 생성하는 것입니다. 이 애플리케이션은 색인된 데이터와 상호 작용하여 재무 문서를 검색, 검색하고 분석하는 데 필요한 도구와 기능을 제공할 것입니다.\n\n이 앱을 만들기 위해 필요한 샘플 코드는 아래에 표시되어 있습니다. 회사 티어를 검색하도록 활성화하고 LLM을 사용하여 고급 검색을 활성화해야 합니다. 이는 효과적으로 문서 질의에 답할 수 있습니다. 이 프로세스는 REST API를 사용하지만 Python SDK를 사용하여도 수행할 수 있습니다. 앱 생성을 위한 완전한 코드는 여기에서 찾을 수 있습니다.\n\n```js\nurl = f\"https://discoveryengine.googleapis.com/v1alpha/projects/{config.PROJECT_ID}/locations/global/collections/default_collection/engines?engineId={data_store_id}\"\n\nheaders = {\n    \"Authorization\": f\"Bearer {config.ACCESS_TOKEN}\",\n    \"Content-Type\": \"application/json\",\n    \"X-Goog-User-Project\": config.PROJECT_ID\n}\n\ndata = {\n    \"displayName\": data_store_display_name,\n    \"dataStoreIds\": [data_store_id],\n    \"solutionType\": SolutionType.SOLUTION_TYPE_SEARCH,\n    \"searchEngineConfig\": {\n        \"searchTier\": SearchTier.SEARCH_TIER_ENTERPRISE,\n        \"searchAddOns\": SearchAddOn.SEARCH_ADD_ON_LLM\n    }\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n```\n\n위에서 설명한 전체 프로세스를 용이하게 만들기 위해 여기에 제공된 스크립트를 활용할 수 있습니다. 데이터 흡수와 애플리케이션 설정에 관련된 모든 필요한 단계를 처리합니다. 구조화된 방식으로 이 접근 방법을 따르면 Vertex AI Search의 강력함을 활용하여 재무 문서를 가치 있는 지식 베이스로 변환할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# RAG 자동화를 위한 아키텍처 패턴\n\n저희의 원시 PDF 문서가 Vertex AI Search 내에 소화되고 색인화되었으므로, 처리된 문서를 쿼리하고 답변을 생성하는 것이 이제 쉽게 간소화될 수 있습니다. 제공된 Python SDK 샘플 코드는 이전에 구성된 검색 애플리케이션을 통해 데이터베이스를 쿼리하는 방법을 보여줍니다. 참조용 전체 코드는 이곳에서 확인할 수 있습니다.\n\n```js\nclient_options = (\n    ClientOptions(api_endpoint=f\"{LOCATION}-discoveryengine.googleapis.com\")\n    if LOCATION != \"global\"\n    else None\n)\n\nclient = discoveryengine.SearchServiceClient(client_options=client_options)\n\nserving_config = client.serving_config_path(\n    project=config.PROJECT_ID,\n    location=LOCATION,\n    data_store=data_store_id,\n    serving_config=\"default_config\",\n)\n\ncontent_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(\n    snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(\n    return_snippet=False\n    ),\n    extractive_content_spec=discoveryengine.SearchRequest.ContentSearchSpec.ExtractiveContentSpec(\n        max_extractive_answer_count=3,\n        max_extractive_segment_count=3,\n    ),\n    summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(\n        summary_result_count=5,\n        include_citations=True,\n        ignore_adversarial_query=False,\n        ignore_non_summary_seeking_query=False,\n    ),\n)\n\nrequest = discoveryengine.SearchRequest(\n    serving_config=serving_config,\n    query=search_query,\n    filter=filter_str,\n    page_size=5,\n    content_search_spec=content_search_spec,\n    query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(\n        condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,\n    ),\n    spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(\n        mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO\n    ),\n)\n\nresponse = client.search(request)\n```\n\n이를 기반으로, 우리는 이제 여러 가지 방법으로 Vertex AI Search API를 사용하여 쉽게 RAG 파이프라인을 구축할 수 있습니다. 다음으로, 이를 실행하는 네 가지 일반적인 패턴을 살펴보며, 이러한 파이프라인이 구현될 수 있는 유연성과 쉬움을 보여드릴 것입니다.\n\n<div class=\"content-ad\"></div>\n\nVertex AI Search에서 검색 요청을 구성할 때 유용한 정보를 추출하기 위한 사양을 설정하는 것이 중요합니다. 스니펫, 세그먼트 및 답변 옵션을 활성화하여 관련 콘텐츠를 포괄적으로 검색할 수 있습니다. 또한 LLM 파워를 활용한 요약 기능을 활성화하면 검색 결과의 간단한 요약(답변)을 생성하여 사용자 경험을 향상시킬 수 있습니다. 결과적으로 생성되는 JSON 응답에는 요약된 답변과 추출된 세그먼트 및 답변이 모두 포함됩니다.\n\nVertex AI Search는 텍스트 데이터를 세그먼트화하고 추출하는 다음과 같은 세 가지 메소드를 사용합니다:\n\n- 스니펫: 검색 결과 문서에서 간단한 발췌문을 제공하여 콘텐츠 미리보기를 제공하며 종종 히트 하이라이팅을 포함합니다.\n- 추출형 답변: 원본 문서에서 직접 추출된 문장을 제공하여 간결하고 맥락에 맞는 답변을 제공합니다.\n- 추출형 세그먼트: 보다 상세한 직접 추출된 텍스트 데이터를 제공하여 답변 제시, 후처리 작업 및 대규모 언어 모델의 입력으로 사용할 수 있습니다.\n\n또한 스펠 수정 및 쿼리 확장을 위한 설정을 구성하여 검색 정확도를 높이고 잠재적 결과를 확장할 수도 있습니다. 우리의 사용 사례에서는 스니펫을 무시합니다.\n\n<div class=\"content-ad\"></div>\n\n# 패턴 I: 기본 설정(out-of-the-box, OOB) 답변 생성을 통한 검색\n\n패턴 I는 Vertex AI Agent Builder 콘솔 또는 Discovery Engine API를 통해 구현할 수 있는 간단하고 일반적인 파이프라인입니다. 이 파이프라인은 검색 인덱스에서 관련 정보를 검색하여 가져오는 데 사용됩니다. 이 인덱스는 데이터 저장소(datastore) 및 검색 앱을 통해 이전에 설정한 것이며 원본 원시 PDF가 GCS에 저장된 인덱스에 매핑됩니다. 또한 이 파이프라인은 내부 시스템(Large Language Model, LLM Powered)을 사용하여 검색 결과를 기반으로 간결한 답변을 생성합니다. 이를 통해 외부 LLM에 대한 명시적 호출이 필요 없습니다. 사용자는 단일 API 요청만으로 지원 문서에서의 구체적인 답변과 인용을 함께받을 수 있습니다. 이를 통해 관련 정보를 검색하고 요약하는 프로세스가 간소화됩니다. 이 파이프라인을 보여주는 코드는 [여기](공유된 저장소 링크)에서 찾을 수 있습니다.\n\n![RAG Automation](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_2.png)\n\n위 다이어그램은 Vertex AI Search를 구동하는 간단한 RAG 파이프라인을 보여줍니다. 워크플로는 클라우드 스토리지에 저장된 원시 PDF 문서들의 컬렉션으로 시작합니다. 이러한 문서들은 이미 Vertex AI Search에 의해 흡수되고 처리되어 구조화된 인덱스가 생성되어 효율적인 검색 및 검색이 이루어집니다. 사용자가 쿼리를 제출하면 Vertex AI Search는 이러한 인덱스를 활용하여 가장 관련성 높은 문서를 신속하게 식별합니다. 그런 다음 이 문서들에서 적절한 정보를 추출하고 정보의 출처를 나타내는 인용을 포함하여 사용자에게 답변을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\nPattern I의 주목할 만한 장점은 그 간결함과 독립성입니다. 외부 LLM 호출이 필요하지 않고 전체 프로세스를 단일 API 요청으로 통합하여 필요를 제거합니다. 그러나 이러한 간소화된 방법은 유연성에 제한을 가져올 수 있습니다. 이는 최종 요약에서 관련성이 적은 문서에서 불필요한 정보를 포함시킬 수도 있습니다. 단일 소스에서 파생된 답변에 중점을 둔 단방향 질문 응답에 초점을 맞추어 검색 결과로부터 답변을 생성하는 것이 중요합니다.\n\n다음 갱신된 파이프라인 반복 (Pattern II)에서는 쿼리 이해 단계에서 메타데이터 통합을 탐색하고, 결과를 개선하기 위해 선택한 LLM으로 Gemini를 활용할 것입니다. 이 방법은 소음을 최소화하고 가장 관련 있는 검색된 정보에 집중하여 요약된 답변을 최적화하는 데 목표를 두고 있습니다.\n\n# Pattern II: OOB 답변 생성과 필터링된 검색\n\nPattern II는 필터링을 통한 쿼리 이해에 초점을 맞춘 사전 검색 단계를 포함하여 검색을 향상시키는 것입니다. 이는 사용자가 자연어 쿼리를 선호하는 상황을 다루며, 수동 필터링이 필요 없도록 하거나 원하는 필터가 즉시 제공되지 않는 상황을 수용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n파이프라인은 Gemini를 사용하여 사용자의 자연어 쿼리를 처리하여 시작합니다. Gemini는 기업 이름 및 기간과 같은 주요 정보를 추출하기 위해 명명된 엔티티 인식(NER)을 수행합니다. 이 추출된 메타데이터는 JSON 형식으로 출력되며 사용자의 의도와 더 일치하도록 검색 결과를 필터링하는 데 활용됩니다. 이 과정은 노이즈를 줄이는 뿐만 아니라 검색 메트릭을 크게 향상시킵니다.\n\n또한 추출된 기업 이름 및 기간 정보는 수집 단계에서 설정된 형식과 구문에 준수해야 합니다. 이 구현에서 메타데이터 필터링은 Vertex AI Search 내의 문서에 이전에 할당된 기업 이름 및 기간 태그를 활용합니다.\n\n따라서 이 개선은 Pattern I를 기반으로 쿼리 이해 단계를 검색 이전에 도입함으로써 검색 결과의 정확성과 관련성을 극대화합니다.\n\n상단의 아키텍처 다이어그램에 나타난 대로, 워크플로는 사용자가 특정 필터의 제약 없이 정보 요구를 표현하는 자연어를 사용하여 검색을 시작하는 것으로 시작됩니다. 그런 다음 쿼리가 Gemini에 전달되어 명명된 엔티티 인식(NER)을 수행하여 기업 이름 및 기간과 같은 관련 메타데이터를 추출합니다. 이 추출된 메타데이터는 JSON 형식으로 구조화되어 쉽게 필터링되며 이후 Vertex AI Search에서 사용되어 문서 색인을 필터링하여 추출된 기업 및 기간 정보와 일치하는 결과만을 좁혀서 제공합니다. 마지막으로, 필터링된 결과이기 때문에 더 관련성이 높은 문서들이 사용자에게 제공되며 정보의 출처를 나타내는 인용을 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n위에서 설명한 pipeline의 코드 구현은 여기서 참조할 수 있습니다. 이 구현에서의 Entity 인식은 프롬프트를 사용하여 회사 이름 추출에는 zero-shot 방식을 활용하고 시기 추출에는 양성 및 음성 예시를 이용한 few-shot 방식을 사용합니다.\n\n```js\n아래 쿼리에서 회사 이름을 추출하십시오.\n회사 이름은 `Microsoft`, `Alphabet`, 또는 `Amazon` 중 하나입니다.\n회사 이름이 `LinkedIn`이면 `Microsoft`로 번역하십시오.\n\n중요 사항: 추출된 회사 이름은 반드시 줄 바꿈이나 구두점 또는 추가 공백 없이 단일 단어여야합니다.\n```\n\n```js\n쿼리로부터 특정 시기를 추출하십시오. 유효한 시기는 'Q1 2021' 형식만 가능합니다.\n\n유효하지 않은 형식의 예시:\n'Q2 2020 to Q2 2021'\n'Q2 2020 - Q2 2021'\n'Q2 2020, Q2 2021'\n\n추출된 시기는 단일 분기와 단일 연도만을 나타내야 합니다. 현재와 과거 간의 대조만을 고려해야합니다.\n\n중요 사항: 쿼리가 현재와 과거를 비교할 때 과거 참조를 무시하십시오.\n\n예시\n========\n'2020년 첫 분기'를 'Q1 2020'으로 변환하세요.\n'Q2 2021에서 Q2 2020 대비 증가'를 'Q2 2021'로 번역하세요.\n'2022년 12월 31일 종료 12개월'을 'Q4 2022'로 번역하세요.\n```\n\n# Pattern III: Extractive Segments 및 Gemini Pro를 활용한 필터링 검색 및 응답 생성\n\n<div class=\"content-ad\"></div>\n\n이전에는 Vertex AI Search에서 관련 콘텍스트를 가져오는 세 가지 다른 정밀도 수준에 대해 학습했습니다: 스니펫, 추출 세그먼트 및 추출된 답변. 이 패턴인 Pattern III에서는 검색 결과에서 추출된 세그먼트를 활용하여 기존 (OOB) 답변 생성 단계 (Pattern I 및 II)를 대체합니다. 생성된 답변에 특정한 스타일, 뉘앙스, 형식, 길이 또는 구조가 필요한 경우 특히 중요합니다. 이러한 시나리오에서 추출된 세그먼트를 외부 LLM인 Gemini와 함께 질의와 함께 명시적으로 전달할 수 있습니다. 우리는 요구 사항에 더 가까운 답변 생성을 위해 다양한 방법으로 프롬프트를 유연하게 설계할 수 있습니다. Pattern III는 이러한 방식을 포괄합니다.\n\n위에 표시된 아키텍처 다이어그램은 Pattern III의 워크플로우를 보여줍니다. 여기서 사용자는 먼저 자연어 질의를 제출하고, 이는 초기에 Gemini에 의해 관련 메타데이터를 추출하도록 처리됩니다. 이 구조화된 메타데이터는 Pattern I와 II와 유사하게 Vertex AI Search가 문서 색인을 효율적으로 검색하고 관련 문서를 식별하는 데 사용됩니다. 이러한 필터링된 문서에서 사용자의 질문에 직접 답변하는 구체적인 세그먼트가 추출됩니다. 최종 단계에서 Gemini는 이러한 추출된 세그먼트를 처리하여 사용자에게 포괄적인 답변을 생성하고 정보의 출처 문서를 나타내는 인용 정보를 통합합니다. 사용자는 정보가 추출된 문서에 대한 참조와 함께 질의에 대한 최종 답변을 받게 됩니다. 이 패턴을 다루는 코드는 여기에서 찾을 수 있습니다.\n\n이 워크플로에 대한 답변 생성에 사용되는 프롬프트는 아래에 표시된 것과 같이 간단할 수도 있고 특정 요구 사항에 기반하여 더 복잡하고 정교할 수도 있습니다.\n\n```js\n다음 콘텍스트를 기반으로 아래 질문에 명확하고 간결한 답변을 제공하십시오:\n\n콘텍스트: {콘텍스트}\n\n질문: {질문}\n```\n\n<div class=\"content-ad\"></div>\n\n# 패턴 IV: Gemini Pro를 활용한 추출적 답변을 통한 필터링된 검색과 답변 생성\n\n이번에는 이전의 패턴 III 구조를 대부분 유지하면서 주요 수정 사항을 가진 파이프라인 반복입니다. 이전에 문서에서 추출된 세그먼트를 활용하는 대신 추출적 답변을 활용합니다. 이 변경은 이전 프롬프트 구조를 유지한 채 이루어졌습니다. 이 변경의 영향을 설명하기 위해 테스트 세트에서 질문을 살펴보고 세그먼트 대비 답변에서 파생된 생성된 답변을 비교하겠습니다.\n\n아래에는 예상 질문과 그라운드 트루스 파일에서 기대되는 답변이 표시되어 있습니다.\n\n```js\n마이크로소프트의 실적 보고서에 따르면 2021년 Q1 LinkedIn의 매출 증가액은 얼마이고,\n일정한 화폐단위 조정을 고려했을 때 성장률은 어떻게 되는가?\n```\n\n<div class=\"content-ad\"></div>\n\n2021년 제1분기에는 링크드인의 매출이 전년대비 25% 증가했습니다. 환율 변동을 조정한 경우 성장률은 23%였습니다.\n\n우선, Vertex AI 검색에서 샘플 질문에 대한 추출 세그먼트를 살펴봅시다. 아래는 상위 세 개의 세그먼트입니다. 우리의 질문에 대한 답변은 비즈니스 하이라이트 하단에 있는 세그먼트 1과 테이블 콘텐츠 일부인 세그먼트 2에서 유도할 수 있음을 알 수 있습니다. 지미니 포스트-검색을 사용하여 최종 답변을 생성하기 위해 세그먼트를 연결하여 단일 문맥으로 전달하면 됩니다.\n\n## 비즈니스 하이라이트\n\n생산성 및 비즈니스 프로세스의 매출은 $13.6 억으로 증가했으며,\n15% 증가했습니다 (환율 변동으로 12% 상승),\n다음과 같은 비즈니스 하이라이트가 포함되어 있습니다:\n\n- 오피스 상용 제품 및 클라우드 서비스 매출이 14% 증가했습니다\n  (환율 변동으로 10% 증가),\n  오피스 365 상용 매출의 22% 증가로 주도되었습니다 (환율 변동으로 19% 상승)\n- 오피스 소비자 제품 및 클라우드 서비스 매출이 5% 증가했으며\n  (환율 변동으로 2% 증가),\n  마이크로소프트 365 소비자 구독자 수는 5020만으로 증가했습니다\n- 링크드인 매출이 25% 증가했습니다 (환율 변동으로 23% 상승)\n- 다이내믹스 제품 및 클라우드 서비스 매출이 26% 증가했습니다\n  (환율 변동으로 22% 상승),\n  다이내믹스 365 매출이 45% 증가로 주도되었습니다 (환율 변동으로 40% 증가)\n\n미세한 과정을 통한 재무 성과 일정 화 동일 통화 환산은 다음과 같습니다:\n\n| 세그먼트                    | 2020년 | 2021년 | 증가율 | 동일 통화 여파 |\n| --------------------------- | ------ | ------ | ------ | -------------- |\n| 생산성 및 비즈니스 프로세스 | $11743 | $13552 | 15%    | 12%            |\n| 인텔리전트 클라우드         | $12281 | $15118 | 23%    | 20%            |\n| 더 개인화된 컴퓨팅          | $10997 | $13036 | 19%    | 16%            |\n\n마이크로소프트에 대해\n\n마이크로소프트 (나스닥 \"MSFT\" @microsoft)는 지능형 클라우드와 지능형 엣지 시대에 대한 디지털 전환을 실현합니다. 그 사명은 지구상의 모든 사람과 기관에 더 높은 성공을 이루도록 자율화하는 것입니다.\n```\n\n\n<div class=\"content-ad\"></div>\n\nRevenue in Intelligent Cloud는 $ 15.1 억으로 23% 증가했습니다 (일정 환율로 20% 상승), 다음 비즈니스 하이라이트가 있습니다:\n• 서버 제품 및 클라우드 서비스 수익은 26%(일정 환율에서 23% 증가) 성장했으며, Azure 수익은 50%(일정 환율에서 46% 상승) 증가했습니다.\n개인 컴퓨팅에서의 수익은 $ 13.0 억으로 19% 증가했습니다 (일정 환율로 16% 상승), 다음 비즈니스 하이라이트가 있습니다:\n• Windows OEM 수익이 10% 증가했습니다.\n• Windows 기업 제품 및 클라우드 서비스 수익은 10% 증가했습니다 (일정 환율로 7% 증가).\n• Xbox 콘텐츠 및 서비스 수익은 34% (일정 환율로 32% 증가).\n• 트래픽 취득 비용을 제외한 검색 광고 수익은 17%(일정 환율로 14%) 증가했습니다.\n• Surface 수익이 12%(일정 환율로 7%) 증가했습니다.\n\nMicrosoft는 2021 회계 연도 3분기에 주주에게 주식 재매수 및 배당금 100 억 달러를 돌려주었습니다. 이는 2020 회계 연도 3분기에 비해 1% 증가한 금액입니다.\n\n비즈니스 전망\nMicrosoft는 분기별 이익 발표에 관련하여 전방향 가이드를 제공할 것이며 이어서 이익 회의 전화와 웹캐스트에서 설명할 것입니다.\n\n분기별 하이라이트, 제품 출시 및 개선 사항\n매 분기마다 Microsoft는 수백 개의 제품을 새로 출시하거나 현재 제품 및 서비스를 개선하는 서비스로 제공합니다. 이러한 출시는 고객이 보다 생산적이고 안전하며 클라우드 및 엣지에서 차별화된 가치를 전달하기 위해 설계된 중요한 연구 및 개발 투자의 결과입니다. 우리가 어떻게 사업에서 혁신을 가속하고 시장 기회를 확대하고 있는지 보여주기 위해 제품 범주별로 분류된 이 분기의 주요 제품 출시 및 다른 하이라이트를 소개합니다.\n\n코로나19 대응\nMicrosoft는 직원의 안전을 보장하고 영역 사회의 건강과 안녕을 보호하며 원격 근무 상태에서 최상의 업무를 수행할 수 있도록 고객 및 협력사에 기술과 자원을 제공하는 데 초점을 맞추고 있습니다. Microsoft의 COVID-19 대응에 대한 자세한 정보는 여기에서 확인할 수 있습니다.\n\n환경, 사회 및 지배 (ESG)\nMicrosoft의 미션을 더욱 잘 실현하기 위해 우리는 양질의 영향을 미칠 수 있는 곳에만 환경, 사회 및 지배 (ESG) 노력에 중점을 둡니다. 최신 노력과 우선 사항에 대해 자세히 알아보려면 투자자 관계 ESG 웹사이트를 방문하십시오.\n\n<div class=\"content-ad\"></div>\n\n흥미롭게도, 우리가 궁금한 질문에 대한 답을 얻기 위해 필요한 정보는 마지막(세 번째) 추출한 답변에만 포함되어 있는 것을 알 수 있습니다. 최종 답변을 생성하기 위해 세 개의 추출한 답변을 모두 한 문맥으로 연결하여 Gemini에게 제공하고, 원래의 질문과 함께 제출하여 답변을 생성합니다.\n\n```js\nRevenue in Intelligent Cloud은 $15.1 억으로 23% 증가했으며 (환율 상수로는 20% 증가), 다음과 같은 비즈니스 현황을 보여줍니다:\n• 서버 제품 및 클라우드 서비스 수익이 26% 증가했으며 (환율 상수로는 23% 증가), Azure 수익이 50% 증가(환율 상수로는 46% 증가) • More Personal Computing의 수익은 $13.0 억으로 19% 증가했으며 (환율 상수로는 16% 증가), 다음과 같은 비즈니스 현황을 보여줍니다: • Windows OEM 수익이 10% 증가함 • Windows 상용 제품 및 클라우드 서비스 수익이 10% 증가함 (환율 상수로는 7% 증가)\n• Xbox 콘텐츠 및 서비스 수익이 34% 증가함 (환율 상수로는 32% 증가)\n• 트래픽 채광 비용 제외 검색 광고 수익이 17% 증가함 (환율 상수로는 14% 증가)\n• Surface 수익이 12% 증가함 (환율 상수로는 7% 증가)\nMicrosoft은 2021 회계 연도 3분기에 $10.0 억을 주주에게 주식 매수와 배당금 형태로 반환했으며, 이는 2020 회계 연도 3분기 대비 1% 증가했습니다.\n비즈니스 전망 Microsoft는 이 분기 실적 발표와 관련하여 이익 회의 전화와 웹캐스트에서 전반적인 안내를 제공할 것입니다.\n```\n\n```js\n재무 성과\n통화 변동 조정 2021년 3월 31일 3개월 종료 (백만 달러, 주당 금액 제외)\n수익 운영 이익 순이익 희석주당순이익\n2020년 표시 요건 (GAAP) $35021 $12975 $10752 $1.40\n2021년 표시 (GAAP) $41706 $17048 $15457 $2.03\n2021년 조정 (non-GAAP) $41706 $17048 $14837 $1.95\nY/Y 변경율 (GAAP) 19% 31% 44% 45%\nY/Y 변경율 (non-GAAP) 19% 31% 38% 39%\n통화 변동 영향 $972 $634 $615 $0.08\nY/Y 변경율 (non-GAAP) 통화 변동 16% 27% 32% 34%\n세그먼트 수익 통화 변동 조정 2021년 3월 31일 3개월 종료 (백만 달러)\nProductivity and Business Processes Intelligent Cloud More Personal Computing\n2020년 표시 $11743 $12281 $10997\n2021년 표시 $13552 $15118 $13036\nY/Y 변경율 15% 23% 19%\n통화 변동 영향 $366 $367 $239\nY/Y 통화 변동율 12% 20% 16%\n선택된 제품 및 서비스 수익 통화 변동 조정 2021년 3월 31일\nY/Y 변경율 (GAAP) 통화 변동 영향 Y/Y 통화 변동율\nOffice 상업용 제품 및 클라우드 서비스 14% (4)% 10%\nOffice 365 상업용 22% (3)% 19%\nOffice 소비자 제품 및 클라우드 서비스 5% (3)% 2%\nLinkedIn 25% (2)% 23%\nDynamics 제품 및 클라우드 서비스 26% (4)% 22%\nDynamics 365 45% (5)% 40%\n서버 제품 및 클라우드 서비스 26% (3)% 23%\nAzure 50% (4)% 46%\nWindows OEM 10% 0% 10%\nWindows 상업용 제품 및 클라우드 서비스 10% (3)% 7%\nXbox 콘텐츠 및 서비스 34% (2)% 32%\nSurface 12% (5)% 7%\n검색 광고 트래픽 채광 비용 제외 17% (3)% 14%\nMicrosoft에 대해 Microsoft(Nasdaq \"MSFT\" @microsoft)는 지능적인 클라우드와 지능형 엣지 시대의 디지털 변형을 가능케 합니다.\n```\n\n<div class=\"content-ad\"></div>\n\n저희가 확인한 바로는 Gemini가 생성한 최종 응답이 추출 세그먼트를 사용한 이전 응답보다 더 짧고 간결하다는 것을 알 수 있습니다.\n\n```js\n제공된 맥락에 따르면, Microsoft의 실적 보고서에 따르면 2021년 1분기 LinkedIn의 매출 증가율은 25%였습니다. 일정 통화를 고려한 경우 성장율은 23%였습니다.\n```\n\n해당 패턴을 포함한 소스 코드는 여기에서 찾을 수 있습니다.\n\n# 대안적 패턴\n\n<div class=\"content-ad\"></div>\n\n- 이전에 설명한 표준 워크플로우를 넘어서 PDF 문서로부터 답변 생성을 혁신적으로 개선할 수 있는 여러 고급 기술들이 있습니다. 그 중 하나는 질의 확장인데, 이는 초기 검색 질의를 관련 용어나 동의어로 확장시킵니다. 이 기능은 Vertex AI Search를 사용하여 매개변수를 AUTO로 설정함으로써 쉽게 활성화할 수 있습니다. 또는 DIY 사전 검색 단계를 설계하여 LLM을 사용하여 질의 변형을 생성한 후 Vertex AI Search에 병렬 호출을 할 수도 있습니다. 질의 확장은 질의 응답 시스템에서 정보 검색의 품질을 향상시키는 중요한 기술입니다. 다양한 질의 변형을 생성하여 검색의 관련성을 향상시키는 것뿐만 아니라 정확한 답변을 생성하는 데 필수적인 최상위 검색 문서의 대표성을 확보하는 데 핵심적인 역할을 합니다.\n- 문서 내 키워드 부스팅은 관련성을 향상시키는 또 다른 강력한 기술입니다. 이는 Vertex AI Search를 사용하여 즉시 지원됩니다. 특정 용어에 우선 순위를 부여함으로써 검색 결과의 관련성을 향상시킬 수 있습니다.\n- 게다가 검색 튜닝을 사용하여 검색 성능을 향상시킬 수도 있습니다. 이 접근 방법은 특정 산업이나 회사에 특화된 쿼리를 일반적인 언어 모델로 충분히 해결할 수 없을 때 특히 유용합니다. 검색 튜닝은 Vertex AI Search를 통해 즉시 지원됩니다.\n- PDF 문서의 사전 처리 유형을 선택하여 검색 관련성을 향상시키는 것도 중요합니다. 서로 다른 문서 파서를 사용하여 PDF 문서의 사전 처리 유형을 선택함으로써 검색 관련성을 향상시킬 수 있습니다. Vertex AI Search는 기본적으로 레이아웃 파서, OCR 파서 및 디지털 파서를 지원합니다. 우리의 사용 사례에서는 레이아웃 파서를 사용했습니다. 이는 Vertex AI Search를 위해 RAG용으로 PDF 문서를 사용할 계획이라면 권장됩니다. 또는 Document AI를 사용하여 문서에서 표를 추출하는 등 다른 정교한 방법론을 사용할 수 있습니다. PDF와 추출한 표를 텍스트 형식으로 변환하여 PDF로 처리하지 않고 Vertex AI Search에 삽입할 수 있습니다.\n- 마지막으로 사용자 정의 임베딩 기반 정보 검색이 필요한 기업을 위해 Vertex AI는 강력한 벡터 검색 기능을 제공합니다. Vertex AI의 벡터 검색은 수십억 벡터를 수용하고 밀리초 내에 가장 가까운 이웃을 식별할 수 있습니다. 벡터 검색(이전에는 Matching Engine로 알려짐)은 Vertex AI Search와 유사하며 Agent Builder의 일부입니다. Agent Builder는 이 두 검색 옵션의 캡슐화로 생각할 수 있습니다. 뒤에 덧붙이자면, 이 기사에서 extensively 다룬 것은 모두 Vertex AI Search에 관한 것입니다. Vertex AI 벡터 검색은 벡터 저장소로, chunking 전략, 임베딩 모델 선택, 의미 유사성 검색을 위한 점수 매기는 알고리즘 선택 등 모든 것에 대한 전체 사용자 정의를 원할 때 좋은 대체 옵션입니다. Agent Builder는 check grounding, grounded generation 및 ranking API와 같은 독립적인 API도 포함하고 있습니다. 이러한 API를 사용하여 벡터 검색과 함께 커스텀 RAG 파이프라인을 구축할 수 있습니다.\n\n# RAG 파이프라인 평가\n\n![Architecture Blueprint for RAG Automation Advanced Document Understanding using Vertex AI Search](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_3.png)\n\n다음으로, 검색 성능 및 생성된 답변 품질을 평가하는 방법에 대해 알아보겠습니다. 우리는 검색 시스템을 평가하는 데 적합한 다양한 지표를 실험해보고, RAG 파이프라인에서 답변 품질을 평가하는 지표를 살펴볼 것입니다. 이 평가 과정을 통해 RAG 시스템을 개선하고 최적화하며 어떤 접근 방식이 더 효과적인지 이해하는 데 도움이 될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# I. 정보 검색 평가\n\n## 가) K에서의 정밀도\n\nK에서의 정밀도는 상위 K개의 검색 문서에서 관련 결과의 비율을 측정하는 지표입니다. 이 측정 방법은 초기 결과의 질이 정보의 철저한 검색보다 우선하는 시나리오에서 특히 중요합니다. 이러한 경우의 대표적인 예로 웹 검색 엔진이 있습니다. 여기서 사용자들은 주로 검색 결과의 첫 페이지에 집중합니다.\n\n예를 들어, YouTube에서 \"종이 비행기를 만드는 방법\"에 대한 상위 5개의 교육 비디오를 요청했다고 가정해보겠습니다. 이 중 5개 중 3개의 비디오가 목적에 맞게 지시를 제공한다면, K=5에서의 정밀도는 5개 중 3개 또는 60%가 됩니다. 이 지표는 초기 검색 결과의 관련성을 측정하는 방법을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n단일 점프 질문 응답 사용 사례에서는 각 쿼리 당 관련 항목(문서) 하나를 획득하는 것이 목표입니다. 따라서 K = 1일 때의 정밀도(Precision)를 계산하는 것이 논리적입니다. 이 경우 결과는 이진형입니다: Vertex AI Search에 의해 반환된 검색된 항목 중에서 원하는 문서를 가장 위에 위치시키는지 여부입니다.\n\n<img src=\"/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_4.png\" />\n\n## b) K에 대한 재현율(Recall)\n\n정보 검색 분야에서, K에 대한 Recall 메트릭은 검색 결과 중 상위 K 결과 내에서 검색된 모든 관련 문서의 비율을 측정하는 데 사용됩니다. 이는 정밀도와 다르게 Recall은 모든 잠재적으로 관련 있는 문서를 식별하는 시스템의 능력에 중점을 둡니다. 이러한 측정은 법적이나 학술 연구와 같은 분야에서 주요 문서의 누락이 심각한 결과로 이어질 수 있는 경우에 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, 종이 비행기 제작에 관한 10가지 중요한 비디오가 있다는 시나리오를 가정해 보겠습니다. 상위 5개 결과에 관심이 있습니다. 이 중 상위 5개 결과 중에서 10개 비디오 중 4개가 포함되어 있다면, 5개 중 재현율(Recall)은 10개 중 4개로 40%가 됩니다. 이 백분율은 상위 K개 결과 내에서 모든 가능한 관련 결과를 포착하는 검색 시스템의 효과성을 나타냅니다.\n\n우리의 사용 사례의 고유한 맥락을 고려할 때, 관련 문서가 하나뿐인 경우 관련 문서 한 개에 대한 재현율을 계산하는 것이 논리적입니다. 정밀도와 유사하게, 이는 특정 항목이 검색되었는지 여부를 나타내는 이진 결과를 얻을 것입니다.\n\n<img src=\"/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_5.png\" />\n\n참고: 우리의 사용 사례에서는 단일-홉 질문 응답이고, 답변이 항상 하나의 문서에 매핑된다는 것을 의미합니다. 여러 문서에서 유도된 답변인 다중-홉의 경우, 검색 @ k와 정밀도 @ k가 모두 1로 설정됩니다. 다중-홉 시나리오인 경우, k @ 3 및 k @ 5와 같은 더 높은 값이 더 유용하고 이로운 결과를 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n저희 사용 사례에서는 필터를 적용하지 않은 표준 검색에서 k=1에서 정밀도와 리콜이 각각 51% (패턴 I)입니다. 그러나 명명된 엔티티 인식(Named Entity Recognition, NER)을 사용하고 필터를 적용하면 이러한 지표가 90%까지 증가합니다 (패턴 II).\n\n## c) MRR (평균 역순 순위)\n\n평균 역순 순위(Mean Reciprocal Rank, MRR)는 응답 목록에서 처음으로 올바른 답변의 역순 평균 순위를 측정하는 통계 지표입니다. MRR은 첫 번째 관련 문서의 위치가 추가 관련 문서의 존재보다 더 중요한 상황에서 특히 유용합니다. 이 지표는 질문 응답 시스템 및 사용자가 만족스러운 답변을 처음 만나는 것이 중요한 검색 환경 등에서 일반적으로 사용됩니다.\n\n마카다미아 쿠키에 대한 완벽한 레시피를 찾기 위해 검색 엔진을 사용한다고 상상해보세요. 만일 맨 처음 클릭한 레시피가 바로 필요한 것이라면, 그 검색 엔진은 완벽한 평균 역순 순위(MRR) 1점을 획득합니다. 즉, 바로 최적의 결과를 제공했다는 것을 의미합니다. 그러나 이상적인 레시피가 처음 확인한 것이 아니라 세 번째로 발견하는 것이 매력적이라면, 해당 검색에 대한 MRR은 1/3으로 낮아집니다.\n\n<div class=\"content-ad\"></div>\n\nMRR(Mean Reciprocal Rank)의 공식은 다음과 같습니다:\n\n![image](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_6.png)\n\n여기서 𝑄은 총 쿼리 수를 나타내며, rᵢ는 i 번째 쿼리에 대한 첫 번째 관련 답변의 순위 위치를 의미합니다.\n\n우리의 사용 사례에서는 Pattern I(필터없는 문서 검색)에서 MRR이 64%입니다. 그러나 Pattern II에서 필터를 적용하면 이 숫자가 91%로 증가합니다.\n\n<div class=\"content-ad\"></div>\n\n## d) DCG (Discounted Cumulative Gain)\n\nDCG는 결과 목록에서의 위치를 기반으로 문서의 유용성 또는 \"이득\"을 측정합니다. 여기서의 가정은 검색 결과에서 먼저 나타나는 문서가 나중에 나타나는 것보다 사용자에게 더 관련성이 높다는 것입니다. \"할인\" 부분은 결과 목록에서의 위치에 비례하여 로그 비례 요소로 각 문서의 관련성 점수를 감소시키는 것을 의미합니다. 이는 사용자가 목록을 아래로 이동할수록 각 이후 결과를 확인할 가능성이 줄어든다는 것을 반영합니다. 수식은 다음과 같습니다:\n\n![수식](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_7.png)\n\n여기서 p는 순위 위치, relᵢ는 𝑖 위치의 결과의 관련성 점수이며 log⁡₂(𝑖+1)은 (𝑖+1)의 이진 로그를 나타내는 할인 요소입니다. relᵢ를 계산하기 위해 우리는 단순히 관련 문서에 대해 이진 관련성 1을 사용하고 관련 없는 문서에 대해 0을 사용합니다.\n\n<div class=\"content-ad\"></div>\n\nMRR과 비교할 때, DCG는 최상위 결과물 하나만 고려하는 대신 여러 결과물의 관련성을 고려하여 검색 품질을 보다 포괄적으로 판단합니다. MRR과 DCG는 검색 성능에 대해 다른 시각을 제공하며, MRR은 최상위 결과물의 정확성에 초점을 두는 반면 DCG는 전체 결과 목록의 관련성을 고려합니다. 두 지표를 모두 모니터링하여, 회수 전략의 효과를 자세히 이해할 수 있습니다.\n\n## e) NDCG (정규화된 할인 누적 이익)\n\nDCG는 순위가 매겨진 목록의 총 관련성을 측정하는 반면, NDCG는 다양한 목록 간에 비교를 허용하는 DCG의 정규화된 버전으로, 일반적으로 DCG보다 NDCG가 선호됩니다. NDCG는 랭킹 시스템을 평가하기 위한 더 표준화되고 해석 가능한 지표를 제공하기 때문입니다. NDCG의 공식은 아래와 같습니다:\n\n![이미지](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_8.png)\n\n<div class=\"content-ad\"></div>\n\n위에서:\n\n- DCG𝑝은 원래 공식을 사용하여 위치 𝑝에서의 DCG값을 의미합니다.\n- IDCG𝑝는 이상적인 DCG로, 모든 결과가 관련성에 따라 완벽하게 정렬된 경우 위치 𝑝에서의 최대 가능한 DCG값입니다. IDCG𝑝의 공식은 아래에 나와 있습니다:\n\n\n![IDCG formula](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_9.png)\n\n\n여기서는 관련성 점수를 내림차순으로 정렬합니다.\n\n<div class=\"content-ad\"></div>\n\n우리의 사용 사례에서는 패턴 I 및 II에 대한 NDCG를 측정합니다. 패턴 I에 대해서는 평균 NDCG가 약 64% 정도입니다. 필터를 적용하면 이 수치가 약 91%로 증가합니다.\n\n## f) 평균 정밀도 (AP)\n\nAP는 검색 엔진과 같은 시스템이 관련 항목을 어떻게 순위를 매기는지를 측정합니다. 얼마나 많은 관련 항목이 발견되었는지와 그들이 얼마나 높게 순위되었는지를 모두 고려합니다. 예를 들어, 종이 비행기를 제작하는 방법에 관한 상위 5개의 지침 동영상을 요청했고, 여기에 동영상 순서가 다음과 같이 제공된다고 가정해 봅시다:\n\n- 동영상 A: 완벽한 지침 (관련 있음)\n- 동영상 B: 전혀 관련 없음 (관련 없음)\n- 동영상 C: 괜찮은 지침 (관련 있음)\n- 동영상 D: 다른 관련 없는 동영상 (관련 없음)\n- 동영상 E: 훌륭한 지침 (관련 있음)\n\n<div class=\"content-ad\"></div>\n\nAP를 계산하기 위해서는 관련 동영상이 발견된 각 지점에서의 정밀도를 살펴봅니다:\n\n- 동영상 A 이후: 1/1 = 100%\n- 동영상 C 이후: 2/3 = 66.7%\n- 동영상 E 이후: 3/5 = 60%\n\n이제 이러한 정밀도 값을 평균합니다: (100% + 66.7% + 60%) / 3 = 75.6%\n\n따라서이 검색 결과의 AP는 75.6%입니다. 이는 평균적으로 검색 중에 관련 결과를 상당히 빨리 얻게 된다는 것을 의미합니다. Precision @ 5는 처음 5개 결과의 관련성에만 초점을 맞추지만 (이 경우 60%), AP는 관련 동영상이 발견된 순서도 고려하여 상위 위치를 보상합니다. 이는 검색 엔진이 귀하를 위해 관련 결과를 찾는 데 얼마나 잘 수행되고 있는지에 대해 보다 세밀한 그림을 제공합니다. AP를 계산하는 공식은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_10.png)\n\nwhere\n\n- H is the set of positions of relevant documents.\n- ∣𝐻∣ is the number of relevant documents.\n- 𝑃(𝑖) is the precision at position 𝑖. P(i) for a relevant document at position 𝑖 is 1/i.\n\n## g) Mean Average Precision (MAP)\n\n\n<div class=\"content-ad\"></div>\n\nMAP은 여러 검색 또는 질의를 평가하기 위해 평균 정밀도 (AP)의 개념을 확장한 것입니다. AP는 하나의 검색이 관련 항목을 어떻게 순위 지정하는지를 측정하는 반면, MAP는 여러 검색에서 AP 점수를 평균하여 여러 질의에 대한 시스템의 전반적인 성능 측정을 제공합니다. 이는 단지 하나가 아닌 여러 테스트에서 평균 성적을 받는 것과 같습니다.\n\nMAP는 복수의 관련 문서가 각 질의에 대해 다루는 복잡한 시나리오를 처리할 수 있는 능력으로 인해 종종 선호됩니다. 하지만 각 질의에 하나의 관련 결과물만 있는 경우, MAP는 흥미로운 단순화를 겪습니다. 하나 관련 문서에 대한 질의를 다룰 때, MAP는 본질적으로 다음과 같이 요약됩니다:\n\n- 평균 정밀도가 정밀도가 됩니다: 각 질의의 AP는 단일 관련 문서가 나타나는 순위에서 달성된 정밀도에 단순히 해당합니다.\n- 정밀도가 역순위(Reciprocal Rank)가 됩니다: 하나의 관련 문서만 있는 경우, 정밀도는 해당 순위의 역수입니다(예: 문서가 3위에 있으면 정밀도는 1/3입니다). 이 값은 정확히 MRR 계산에 사용되는 값입니다.\n- MAP은 MRR을 반영합니다: 모든 질의에 대한 이 AP 값들의 평균인 MAP는 관련 문서의 역순위를 평균내어 지각한다. 이것이 바로 MRR이 하는 일입니다. 이 중첩성 때문에 특정 설정에서 MAP을 사용하면 MRR이 이미 제공하는 것 이상의 추가 통찰력을 제공하지 않습니다. MAP은 보통 여러 관련 문서가 각 질의에 대해 포함된 시나리오(다중 단계 질문 응답)에서 보다 유익하며, 서로 다른 순위에서 모든 관련 문서가 얼마나 잘 검색되었는지에 대한 세밀한 관점을 제공할 수 있습니다.\n\n패턴 I 및 II에 대한 실험에서, MAP은 본질적으로 MRR과 같습니다. 패턴 I에서 64%이며, 패턴 II에서 약 91%로 증가합니다.\n\n<div class=\"content-ad\"></div>\n\n상기 평가를 복제하는 데 필요한 모든 지원 코드는 여기에서 찾을 수 있습니다.\n\n# 답변 평가\n\n다음 단계에서는 RAG 파이프라인의 답변 생성 구성 요소를 평가해 보겠습니다. 각 질문에 대한 실제 정답이 제공되므로 생성된 답변의 품질을 평가하고 테스트 세트의 예상 응답과 의미론적으로 유사하며 정확한지 확인하는 것이 목표입니다.\n\n이를 위해 두 가지 서로 다른 메트릭을 적용할 수 있습니다. 첫 번째 메트릭은 cosine similarity를 활용하여 의미론적 유사성을 양적으로 평가합니다. 두 번째 메트릭은 LLM의 역할로, 생성된 답변과 인간이 생성한 답변을 동시에 LLM에 제시하여 모델의 출력이 인간의 기대와 얼마나 일치하는지를 평가할 수 있습니다. 이 접근 방식을 통해 생성된 답변의 사실적 정확성 및 전반적 일관성을 평가하여 인간이 작성한 응답과 구별할 수 없도록 보장할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 가) 의미 유사성\n\n이 메트릭은 생성된 답변과 기대한 답변의 벡터 표현 사이의 각도의 코사인을 측정합니다. 생성된 응답과 실제 답변(기대 값) 간의 의미적 유사성을 평가하는 것을 의미합니다. 이 평가는 기대 값과 응답을 기반으로 하며, 0부터 1까지의 값을 갖습니다. 높은 점수는 생성된 응답과 기대 값 사이의 더 좋은 일치를 나타냅니다.\n\n기대된 답변과 생성된 답변은 모두 텍스트 임베딩 모델 텍스트-임베딩-003을 사용하여 인코딩됩니다. 이 모델은 Vertex AI API를 통해 제공됩니다. 의미 유사성에 대한 코드 구현은 여기에서 찾을 수 있습니다.\n\n## 나) 사실적 정확성\n\n<div class=\"content-ad\"></div>\n\n이전 RAG 파이프라인에서 생성된 답변의 정확성을 평가하기 위해 우리는 Gemini를 활용합니다. 질문, 기대 답변(실제 답변), 그리고 생성된 답변이 Gemini에 전달됩니다. 프롬프트 템플릿을 사용하여 Gemini가 생성된 답변을 \"정확\"(기대 답변과 완전히 부합), \"부분적으로 정확\"(정보 일부를 포함하지만 불완전하거나 일부 오류가 있는 것), 또는 \"부정확\"(기대 답변과 부합하지 않는 것)으로 분류하도록 안내합니다. 이 분류는 답변 품질을 세분화하여 평가하게 해주며, 답변 생성 모델이 개선이 필요한 부분을 식별하는 데 도움이 됩니다. 이 평가 프로세스의 구현 세부사항은 여기에서 확인할 수 있습니다.\n\n아래 표는 이전에 실험한 네 가지 패턴(RAG 파이프라인)을 비교한 전반적인 답변 정확도를 보여줍니다. 정확도를 계산하기 위해 완전히 정확한 답변에는 1.0의 점수를 할당하고, 부분적으로 정확한 답변에는 0.5의 점수를, 그리고 LLM 사실적 정확성 출력에 따라 부정확하게 분류된 답변에는 0의 점수를 부여합니다. 그림에서는 외부 LLM 패스를 활용하여 추출방식을 사용하여 답변을 생성하는 패턴 IV가 다른 모든 접근 방법을 능가하여 정확도가 거의 70%에 달한다는 것을 보여줍니다.\n\n\n지정된 질문과 아래 표시된 기대 및 생성된 답변을 제공하고,\n답변을 비교하여 `correct`, `partially correct`, 또는 `incorrect` 중 하나의 클래스로 분류하세요.\n\n답변이 부분적으로 정확하거나 부정확한 경우, 이유를 제공하세요.\n출력은 클래스와 이유로 된 Python 딕셔너리 형식으로 제공해야 합니다.\n클래스에는 한 단어만 포함되어야 하며(기대 클래스임),\n이유는 숫자와 사실에만 초점을 맞추어 간결하게 제공해야 합니다.\n\n예상 및 예측된 답변 간의 의미론에 집중하지 마십시오.\n\n중요: 숫자와 사실만 비교하세요.\n\n단위가 다른 경우 비교 전에 정규화하세요.\n예) 10억 = 1000백만.\n\n질문: {question}\n\n기대 답변: {expected_ans}xa\n\n예측 답변: {predicted_ans}\n\n예측된 답변을 기대 답변과 비교하세요.\n예측된 답변이 사실적으로 정확하며 주어진 질문을 충족하는지 결정하세요.\n\n다음 형식에 따라 응답을 제공하세요:\n{format_instructions}\n\n\n<div class=\"content-ad\"></div>\n\n네, 해당 테이블 태그를 마크다운 형식으로 변경해 볼게요.\n\n\nWe can also break down the distribution of classes across the four different approaches (pipelines) to gain a better understanding of how improvements gradually occur with enhancements.\n\n![Distribution of classes](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_12.png)\n\nThe box plots below show the distribution of semantic similarity scores across different classes (correct, partially correct, incorrect) for the four different document question-answering RAG pipelines we previously created. The x-axis represents the different classes, while the y-axis signifies the semantic similarity score, ranging from 0 (no similarity) to 1 (perfect similarity). These box plots display the median, quartiles, and range of the semantic similarity scores within each class. Overall, the figure provides a concise and informative visual representation of the performance of various question-answering approaches in terms of semantic similarity.\n\n![Box Plots](/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_13.png)\n\n\n<div class=\"content-ad\"></div>\n\n분포를 통해 다양한 패턴이 나타납니다:\n\n- OOB (패턴 I): 모든 클래스에서 다양한 점수 범위가 나타나며, 부분적으로 정확하지 않은 답변이 더 많이 나타납니다. 이는 즉, 기본 설정의 (OOB) 방식이 우리의 테스트 세트에서 일관되게 정확한 답변을 제공하는 데 어려움을 겪는 것을 시사합니다.\n- OOB + 필터 (패턴 II): OOB 방식보다 특히 잘못된 답변을 줄이는 측면에서 뚜렷한 향상이 나타납니다. 분포는 더 높은 유사도 점수 쪽으로 기울어져 있어 필터를 적용한 후 정확도가 향상되었음을 나타냅니다. 패턴 II의 잘못된 범주에 대한 흥미로운 관찰은 의미론적 유사성 분산이 감소하고 0.5에서 0.6 사이로 중심을 이동한다는 것입니다. 이는 패턴 I과 달리 의미적 유사성 점수의 범위가 더 넓었던 0.5에서 1까지 였던 것과 비교했을 때입니다.\n- 추출 세그먼트 (패턴 III): 이전 두 가지 방식과 비교했을 때 올바른 및 부분적으로 올바른 답변의 비율이 더 높은 개선을 보여줍니다. 이는 문맥에서 관련 세그먼트를 추출하는 것이 OOB 모델 또는 기본 필터링에 의존하는 것보다 효과적인 전략임을 시사합니다.\n- 추출 답변 (패턴 IV): 가장 우수한 성능을 달성하며, 가장 많은 올바른 답변과 가장 적은 잘못된 답변이 나타납니다. 이는 문맥에서 완전한 답변을 직접 추출하는 것이 가장 의미론적으로 유사하고 정확한 응답을 제공한다는 것을 나타냅니다.\n\n지금까지 RAG 파이프라인의 두 가지 주요 단계인 검색 및 답변 생성을 평가하는 방법에 대해 논의했습니다. 검색에서는 검색된 문서의 관련성을 평가하는 데 집중했습니다. 이를 더 확장하여 페이지 또는 검색된 문맥의 관련성을 평가할 수도 있습니다. 그러나 이를 위해 이에 대한 정답 정보를 보유하고 있어야 합니다.\n\n답변 품질의 경우, Ragas와 같은 다른 오픈 소스 대안 프레임워크를 사용하거나 해당하는 경우 Vertex AI의 Rapid Evaluation API를 활용할 수도 있습니다. Rapid Evaluation 서비스를 사용하면 점별 및 쌍별로 여러 메트릭을 통해 LLM을 평가할 수 있습니다. 추론 시간 입력, LLM 응답 및 추가 매개변수를 제공하면 서비스가 평가 작업과 관련된 특정 메트릭을 반환합니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n이 가이드에서는 금융 분야에서 업계 수준의 RAG 파이프라인을 생성하기 위해 Vertex AI Search의 활용을 탐색했습니다. 금융 데이터 세트의 삽입 및 색인화를 자세히 다루었으며 이러한 색인을 활용하여 다양한 방법으로 검색을 수행했습니다. Vertex AI Search가 제공하는 다양한 컨텍스트 유형에 액세스하고 비교를 위해 네 가지 다른 RAG 파이프라인을 생성했습니다. 또한 대체 파이프라인 구성을 살펴보았습니다.\n\n그런 다음 검색 성능 메트릭 및 답변 품질 평가 기술을 평가했습니다. 결과를 비교함으로써 다른 접근 방식의 효과에 대한 유익한 통찰력을 얻었습니다.\n\n우리의 주요 발견은 Vertex AI Search가 표준 및 완전히 사용자 정의 가능한 RAG 솔루션을 구축하기 위한 포괄적인 기능 세트를 제공한다는 것입니다. 이 플랫폼은 어떠한 선택한 도메인 내에서 정보 검색 및 질문 답변 작업을 혁신적으로 간소화합니다. 앞으로의 게시물에서는 Vertex AI의 미개척 기능을 활용한 다른 패턴을 탐색할 예정입니다.\n\n<div class=\"content-ad\"></div>\n\n이 가이드의 내용을 완전히 이해하려면 공유 코드 리포지토리를 설정하는 것을 권장합니다. 작업 환경에서 지침을 따라 실험과 결과를 복제하세요. 이렇게 하면 여러분이 손쉽게 자신의 사용 사례에 적응하고 확장할 수 있습니다!\n\n기사를 읽어 주신 것과 참여해 주신 것에 감사드립니다. 팔로우와 박수가 많은 의미를 갖습니다. 본문이나 공유 소스 코드에 관한 질문이 있으면 언제든지 arunpshankar@google.com 또는 shankar.arunp@gmail.com으로 연락해 주세요. 또한 https://www.linkedin.com/in/arunprasath-shankar/에서 저를 찾을 수도 있습니다.\n\n모든 피드백과 제안을 환영합니다. 대규모 기계 학습, NLP/NLU에 관심이 많으시고 협업을 열망한다면 기쁘게 연결할 수 있습니다. 더불어 Google Cloud, VertexAI, 그리고 NLP/ML에서의 다양한 생성적 AI 구성 요소와 응용 프로그램을 이해하려는 개인, 스타트업 또는 기업이시라면 도와 드리겠습니다. LinkedIn에서 연락 주시기 바랍니다!\n","ogImage":{"url":"/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_0.png"},"coverImage":"/assets/img/2024-05-27-ArchitecturalBlueprintsforRAGAutomationAdvancedDocumentUnderstandingusingVertexAISearch_0.png","tag":["Tech"],"readingTime":35},{"title":"질문-응답 시스템 주요 아키텍처 개요","description":"","date":"2024-05-27 15:08","slug":"2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures","content":"\n## 확장 가능한 정보 검색 시스템을 구축하는 디자인 방식 탐색\n\n![Question-AnsweringSystemsOverviewofMainArchitectures](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_0.png)\n\n# 소개\n\n최근 몇 년 동안 질문-응답 애플리케이션이 강력하게 등장했습니다. 현대적인 검색 엔진, 챗봇 또는 단순히 대량의 테마 데이터에서 관련 정보를 검색하는 애플리케이션 등 어디에서나 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이름에서 알 수 있듯이 QA 응용 프로그램의 목적은 텍스트 단락에서 주어진 질문에 대한 가장 적합한 답변을 검색하는 것입니다. 처음 몇 가지 방법은 키워드 또는 정규 표현식을 사용한 단순한 검색으로 이뤄졌습니다. 당연히 이러한 접근 방식은 최적이 아닙니다: 질문이나 텍스트에 오타가 있을 수 있습니다. 게다가, 정규 표현식은 쿼리에서 주어진 단어와 관련이 높은 유의어를 감지할 수 없습니다. 이러한 접근 방식은 결과적으로, 트랜스포머와 벡터 데이터베이스 시대에 특히 강력한 새로운 방법론으로 대체되었습니다.\n\n이 기사에서는 현대적이고 확장 가능한 QA 응용 프로그램을 구축하기 위한 세 가지 주요 설계 접근 방식을 다룹니다.\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_1.png)\n\n# 추출형 QA\n\n<div class=\"content-ad\"></div>\n\n추출형 QA 시스템은 세 가지 구성 요소로 구성되어 있습니다:\n\n- 검색기 (Retriever)\n- 데이터베이스 (Database)\n- 리더 (Reader)\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_2.png)\n\n먼저, 질문이 검색기에 입력됩니다. 검색기의 목표는 질문에 해당하는 임베딩을 반환하는 것입니다. 간단한 벡터화 방법인 TF-IDF, BM-25부터 더 복잡한 모델까지 다양한 구현이 있을 수 있습니다. 대부분의 경우 트랜스포머와 같은 모델 (BERT)이 검색기에 통합됩니다. 단순한 단어 빈도수만을 의존하는 날것한 접근 방식과는 달리, 언어 모델은 텍스트의 의미를 캡처할 수 있는 밀집된 임베딩을 구축할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n질문에서 쿼리 벡터를 얻은 후, 외부 문서 모음에서 가장 유사한 벡터를 찾는 데 사용됩니다. 각 문서에는 질문에 대한 답변이 포함될 확률이 있습니다. 보통 문서 모음은 학습 단계에서 처리되어 리트리버에 전달되어 해당 문서에 대한 임베딩을 출력합니다. 이러한 임베딩은 일반적으로 효과적인 검색을 제공할 수 있는 데이터베이스에 저장됩니다.\n\n쿼리 벡터와 가장 유사한 상위 k개의 데이터베이스 벡터를 검색함으로써, 원래 텍스트 표현을 사용하여 다른 구성 요소인 리더가 답변을 찾습니다. 리더는 초기 질문을 취하고 k개의 검색된 문서 각각에서 텍스트 단락에서 답변을 추출하고 이 답변이 올바른 확률을 반환합니다. 가장 높은 확률을 갖는 답변이 마지막으로 독점 QA 시스템에서 반환됩니다.\n\n# 오픈 생성형 QA\n\n오픈 생성형 QA는 추출형 QA와 정확히 동일한 프레임워크를 따릅니다. 단, 리더 대신 제너레이터를 사용한다는 점에서 차이가 있습니다. 리더와 달리 제너레이터는 텍스트 단락에서 답변을 추출하지 않습니다. 대신, 질문과 텍스트 단락에서 제공된 정보를 사용하여 답변이 생성됩니다. 추출형 QA의 경우와 마찬가지로 가장 높은 확률을 갖는 답변이 최종 답변으로 선택됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Question-Answering Systems Overview of Main Architectures](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_3.png)\n\n비슷한 구조를 가지고 있기 때문에, 추출형 또는 개방적 생성 구조를 사용하는 것이 더 나은 시점에 대한 질문이 생길 수 있습니다. 독자 모델이 상대적 정보를 포함한 텍스트 단락에 직접 액세스할 수 있는 경우, 일반적으로 정확하고 간결한 답변을 검색하는 데 충분히 똑똑합니다. 반면에, 대부분의 경우 생생 생성 모델은 주어진 맥락에 대해 더 긴 범용 정보를 생성하는 경향이 있습니다. 이는 질문이 개방형 형태로 제시될 때 유익할 수 있지만, 짧거나 정확한 답변이 예상되는 상황에는 해당되지 않을 수 있습니다.\n\n## 검색 보조 생성\n\n최근 기계 학습에서 \"검색 보조 생성\" 또는 \"RAG\"라는 용어의 인기가 급증했습니다. 간단히 말하면, 이는 개방형 생성 QA 시스템에 기반을 둔 LLM 응용 프로그램을 생성하는 프레임워크입니다.\n\n\n<div class=\"content-ad\"></div>\n\n경우에 따라서, LLM 응용 프로그램이 여러 지식 도메인과 작동하는 경우, RAG 검색기는 주어진 쿼리에 가장 관련있는 지식 도메인을 식별하려는 보조 단계를 추가할 수 있습니다. 식별된 도메인에 따라 검색기는 다양한 작업을 수행할 수 있습니다. 예를 들어, 특정 도메인에 속하는 쿼리의 경우 해당 도메인의 벡터 데이터베이스를 사용하여 쿼리에 가장 관련있는 정보를 검색할 수 있습니다.\n\n이 기술은 모든 문서가 아닌 특정 문서 하위 집합을 통해 검색하기 때문에 검색 프로세스를 더 빠르게 만듭니다. 게다가, 검색을 더 신뢰할 수 있게 만들 수 있습니다. 왜냐하면 최종 검색된 컨텍스트가 더 많은 관련 문서에서 구성되기 때문입니다.\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_4.png)\n\n## 닫힌 생성 QA\n\n<div class=\"content-ad\"></div>\n\n닫힌 생성형 QA 시스템은 외부 정보에 액세스할 수 없으며 질문에서 제공된 정보만 사용하여 답변을 생성합니다.\n\n![이미지](/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_5.png)\n\n닫힌 QA 시스템의 명백한 이점은 대규모 외부 문서 집합을 검색할 필요가 없어지므로 파이프라인 시간을 줄일 수 있다는 점입니다. 그러나 교육 및 정확도 측면에서는 비용이 발생합니다: 생성기는 충분히 강력하고 적절한 답변을 생성할 수 있도록 충분한 학습 지식을 갖추어야 합니다.\n\n닫힌 생성형 QA 파이프라인은 다른 단점도 있습니다. 생성기는 교육을 받은 데이터에 후에 나타난 정보를 알지 못합니다. 이 문제를 해결하기 위해 생성기는 최신 데이터셋에 다시 교육을 받을 수 있습니다. 그러나 생성기는 일반적으로 수백만 또는 수십억 개의 매개변수를 가지고 있기 때문에 이러한 교육은 매우 많은 자원을 필요로 합니다. 이와 비교하여 추출형 QA 및 개방형 생성형 QA 시스템으로 동일한 문제를 다루는 것은 훨씬 간단합니다. 벡터 데이터베이스에 새로운 콘텍스트 데이터를 추가하는 것만으로 충분합니다.\n\n<div class=\"content-ad\"></div>\n\n대부분의 경우 일반적인 질문이 있는 애플리케이션에서는 폐쇄형 생성 접근 방식이 사용됩니다. 매우 구체적인 도메인의 경우, 폐쇄형 생성 모델의 성능이 저하되는 경향이 있습니다.\n\n# 결론\n\n본 문서에서 QA 시스템 구축을 위한 세 가지 주요 접근 방법을 발견했습니다. 이들 중에서 절대적인 승자는 없습니다. 각각이 각자의 장단점을 갖고 있습니다. 그러므로 먼저 입력 문제를 분석하고 올바른 QA 아키텍처 유형을 선택하여 더 나은 성능을 내도록 하는 것이 선행되어야 합니다.\n\n머신 러닝 분야에서 Open Generative QA 아키텍처가 현재 트렌드로 떠오르고 있으며, 특히 최근에 등장한 혁신적인 RAG 기술들과 함께 그 인기가 높아지고 있습니다. NLP 엔지니어라면 지금 당장 RAG 시스템에 주목하는 것이 좋습니다. 이 시스템들은 최근에 엄청난 속도로 발전하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 자료\n\n- 질의 응답 | Hugging Face\n\n모든 이미지는 특별히 언급되지 않는 한 저자에 의해 제공됩니다.\n","ogImage":{"url":"/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_0.png"},"coverImage":"/assets/img/2024-05-27-Question-AnsweringSystemsOverviewofMainArchitectures_0.png","tag":["Tech"],"readingTime":5},{"title":"성의 기초","description":"","date":"2024-05-27 15:07","slug":"2024-05-27-TheVeryFoundationofSex","content":"\n\n![image](/assets/img/2024-05-27-TheVeryFoundationofSex_0.png)\n\n나의 남자친구는 정말 질투심이 많은 사람인데, 그게 맘에 든다. 최근에 그는 약물을 먹여 적나라하게 만지작거리며 자국들을 즐기던 야한 이야기를 나눠주었다. 그 결과로 그는 세로필름으로 감싸져 있고 누군가에 의해 최면을 걸리게 된 것이었다. 그는 몇 년간 에로틱 탐험의 세계에 발을 들인 적이 있었는데, 아마도 나와 같은 기간 동안 활동했던 것 같다.\n\n매우 섹시한 최면 비디오를 보려면 여기를 클릭해주세요: [영상 링크](https://youtu.be/mkcTmNe6kQU?si=LktapkZGHkdnbZFW)\n\n특히 격렬한 세션 끝에 하룻밤, 그의 품에서 잠이 들었다. 그가 부드럽게 내 등을 쓸어 주며, 나는 몸을 돌리고 그가 속삭였다. \"너는 완전 훌륭한 사람이 됐어.\" 그 말에 오싹함이 느껴졌다. 왜냐하면 그가 몇 년 동안 내 블로그를 열심히 읽고 있었다는 것을 알고 있었기 때문이다. 몇 년 동안! 그리고 나는 보통 그저 내 이중 인생에 관해 아무것도 모르는 무술에서 만나는 바보들의 성적 유혹과 데이트 제의를 무시하곤 했다.\n\n\n<div class=\"content-ad\"></div>\n\n제가 여기 있을 때 그는 내 마음을 자극하고, 왜 그가 일찍이 연락을 한 때 나에게 더 빨리 손을 내밀지 않았는지 궁금하게 만들고 있습니다. 몇 년 전에 그가 처음 연락했을 때 응답했다면 어떠했을까요? 그러나 그 시절에는 준비가 되지 않았습니다. 제가 박사과정 첫 해에 있었고, 뇌졸중 회복 중이었으며, Peter가 남긴 상처를 극복하고 있었습니다. 그것은 복합적인 외상의 시기였습니다.\n\n그렇다면 여성과 남성, 그들이 어떻게 흥분되는지와 어떤 관련이 있을까요? 여성은 일반적으로 남성에 비해 정서적 관련에서 흥분하는 경향이 더 있습니다. 남성은 주로 신체적 자극에 더 많이 반응할 수 있지만, 여성은 정서적 연결과 강도를 통해 흥분하는 경향이 있습니다.\n\n여성은 감정적인 강도에 끌리는데, 그것이 전체 경험을 높여주기 때문입니다. 신체적 쾌락뿐만 아니라, 원하는 대로 느껴지고 소중하게 여기며, 더 깊은 수준에서 이해받는 경험에 관련이 있습니다. 남성이 감정을 섬세하게 성적 애착으로 연결할 수 있을 때, 그는 단순한 신체성을 초월하는 강력한 연결을 만들어냅니다.\n\nNLP(신경 언어 프로그래밍)를 사용하여 이러한 감정적 강도를 만들려면, 이 단계를 따르세요 (기본으로 돌아가 보겠습니다):\n\n<div class=\"content-ad\"></div>\n\n- 소통을 조절해요\n\n그녀의 몸짓, 목소리 톤, 말의 속도를 반영하여 깊은 연결을 형성하세요. 이렇게 하면 그녀가 이해받고 편안해 집니다.\n\n- 앵커링 활용\n\n일부 접촉, 말, 또는 제스처를 긍정적인 감정과 흥분과 연관짓습니다. 예를 들어, 센슈얼한 말을 속삭이는 동안 부드럽게 그녀의 손목에 손을 대어 접촉과 그녀의 흥분 사이에 강한 연결을 만들어 보세요.\n\n<div class=\"content-ad\"></div>\n\n3. 감각을 자극하는 표현 사용\n\n흥분을 증폭시키는 상황을 묘사하는 데 생동감과 감각이 풍부한 언어를 사용하세요. 그녀의 피부가 느껴지는 방법, 숨을 가쁘게 하게 되는 것, 그녀의 몸이 어떻게 반응하는지 이야기해 보세요.\n\n4. 절제와 리딩\n\n그녀의 감정 상태에 맞추어 시작한 후 서서히 그녀를 흥분하고 강렬한 상태로 이끌어보세요. 스토리텔링, 판타지 묘사 또는 자신의 욕망을 공유하는 것으로도 가능합니다.\n\n<div class=\"content-ad\"></div>\n\n5. 언어 패턴 활용하기\n\n임베디드 명령, 비유, 이중 굴레와 같은 최면적인 언어 패턴을 사용하여 그녀의 생각과 감정을 이끌어보세요. 예를 들어, \"당신이 편안해질수록, 더욱 흥분하고 있는 자신을 발견할 수도 있습니다.\"\n\n6. 기대감 조성하기\n\n조금씩 강도를 높이며 만지작거리고 긴장감을 쌓아가며 기대감을 조성하세요. 그녀가 더 바라게 만들어 강력한 감정적, 신체적 반응을 일으키게 하세요.\n\n<div class=\"content-ad\"></div>\n\n이러한 기술을 숙달함으로써 여러분은 그녀를 매혹시키고 격렬한 감정의 매듭을 만들어 흥분시키며, 잊지 못할 만족스러운 경험을 창출할 수 있습니다.\n\n저희는 다가오는 60일간의 NLP 훈련에서 이 기본적인 방법들을 가르치는 것에 열정적입니다. 여러분이 함께해 주시기를 강력하게 추천드리며, 저희는 이를 접근하기 쉽게 슬라이딩 스케일로 제공하고 있습니다.\n\n제 소개를 조금 드리자면, 저는 Robert Dilts 밑에서의 NLP 트레이너 자격증을 소지하고 있으며, 제 마스터 프랙티셔너 및 프랙티셔너 자격증은 NLPCA(팀 할볼름과 로버트 해리슨에 의해 양성된)에서 받았습니다. 저는 2003년부터 NLP를 실천해 오고 있습니다. 저의 최면 자격증은 National Guild를 통해 받았으며, 저의 박사 학위는 아리조나 대학과 프레스코트 대학에 인정받았습니다.\n\n거기에 더하여, 저는 kink 씬에서 20년 이상의 경험을 갖고 있습니다. 여러분이 저희와 함께 훈련할 수 있는 이 기회를 강력하게 추천드립니다.\n","ogImage":{"url":"/assets/img/2024-05-27-TheVeryFoundationofSex_0.png"},"coverImage":"/assets/img/2024-05-27-TheVeryFoundationofSex_0.png","tag":["Tech"],"readingTime":3}],"page":"2","totalPageCount":11,"totalPageGroupCount":1,"lastPageGroup":11,"currentPageGroup":0},"__N_SSG":true}