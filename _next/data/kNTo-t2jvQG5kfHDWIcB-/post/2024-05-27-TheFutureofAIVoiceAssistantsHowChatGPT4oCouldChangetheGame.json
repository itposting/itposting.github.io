{"pageProps":{"post":{"title":"AI 음성 어시스턴트의 미래 ChatGPT 4o가 게임을 바꿀 수 있는 방법","description":"","date":"2024-05-27 13:26","slug":"2024-05-27-TheFutureofAIVoiceAssistantsHowChatGPT4oCouldChangetheGame","content":"\n\n<img src=\"/assets/img/2024-05-27-TheFutureofAIVoiceAssistantsHowChatGPT4oCouldChangetheGame_0.png\" />\n\n2014년 메인스트림으로 등장한 이후로, 음성 비서는 많은 사람들에게 익숙한 가정용품이 되었습니다. 최소한 당신의 스마트폰에는 있죠 (아마도 당신의 대화를 조용히 듣거나 엿듣고 있을지도 모릅니다). 알람 설정, 운전 중에 손을 사용하지 않고 전화 걸기, 스마트 홈 가전제품을 제어하는 일이든, 이러한 장치들은 우리의 일상에 매끄럽게 통합되어 왔습니다. 이러한 도입으로 활성화된 장치의 수도 급증했습니다 — 전 세계적으로 활성화된 장치 수는 40억대가 넘습니다. 이러한 장치 중에서 아마존 에코, 애플 시리, 그리고 구글 어시스턴트(\"OK Google\")가 가장 인정받는 이름들로, 아마존 에코만으로도 시장의 절반 이상을 차지하고 있습니다(미국에서 약 60%).\n\n<img src=\"/assets/img/2024-05-27-TheFutureofAIVoiceAssistantsHowChatGPT4oCouldChangetheGame_1.png\" />\n\n하지만 솔직히 말하면: 음성 비서를 사용해본 적이 있다면, 그들의 로봇 음성이나 때로는 간단한 명령을 이해하지 못하는 데 짜증이 났을 가능성이 높습니다. 그러나, 이것은 곧 ChatGPT 4o의 출시로 바뀌게 될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n오픈에이아이(OpenAI)가 최근 최신 주력 언어 모델인 ChatGPT 4o를 발표했어요. 이 모델은 텍스트, 이미지, 오디오, 비디오 입력의 어떤 조합이든 처리하고 해당에 맞게 응답할 수 있는 능력을 가지고 있어요. 이전에는 '음성 모드'로 작동하는 ChatGPT는 오디오 입력을 텍스트로 변환해 처리해야 했었어요. 그러나 최신 모델은 오디오 입력을 직접 해석할 수 있어요. 당신의 억양, 표정, 심지어 배경 소음을 고려하고 230밀리초 이내에 인간과 거의 같은 속도로 응답할 수 있어요.\n\n이러한 발전들은 ChatGPT가 이제 다른 사람처럼 여러분과 대화할 수 있음을 의미해요. 실시간으로 시각적 입력을 처리하는 능력은 이 기능을 더욱 향상시켰어요. 두 기능을 결합한 잠재력은 엄청난데요. 오픈에이아이는 실시간 번역, 아재개그 풀기, 비꼬는 댓글 남기기, 심지어 자장가 부르기를 하는 ChatGPT의 데모를 통해 이를 보여줬어요.\n\n더 인상적인 점은 오픈에이아이는 누구나 오픈에이아이 계정이 있는 사람은 물론이고, GPT 4o와 그 어시스턴트 API를 사용할 수 있도록 만들었단 거에요. 이 말은 누구든 몇 줄의 코드(또는 그 이상이더라도, ChatGPT가 도와줄 거예요!)로 앱에 인간과 유사한 음성 어시스턴트를 통합할 수 있다는 거예요. 한편, 마이크로소프트는 새로운 모델이 Azure OpenAI 서비스를 통해 일반적으로 사용 가능하다고 발표했는데요. 이는 기업과 개발자들이 Azure 환경 내에서 자사의 프로프라이어터리 데이터를 활용해 어시스턴트를 통합하고 대화를 커스터마이징하기가 더 쉬워진다는 뜻이에요.\n\n이러한 발전은 우리 옛날 로봇 음성 어시스턴트 시대의 끝을 알리는 신호이죠. 음성 어시스턴트 시장은 변화에 도전하고 있지만, 구글과 아마존과 같은 산업 거물들은 신속히 대응하고 있어요.\n\n<div class=\"content-ad\"></div>\n\n예를 들어 Google은 최근 Google I/O 컨퍼런스에서 프로젝트 아스트라에 대한 미리보기를 제공하여, 자신들의 Gemini 모델을 이용한 인간과 유사한 음성 어시스턴트에 대한 접근 방식을 소개했습니다. 뒤쳐지지 않으려는 아마존은 기존 음성 어시스턴트인 알렉사의 GenAI 기능을 강화할 것으로 예상되며, 업그레이드된 음성 어시스턴트의 수익성을 높이기 위해 구독 플랜을 도입할 것이라는 소문도 있습니다.\n\n이러한 모든 발전은 우리를 주변 환경과 상호작용하며 일상 업무를 돕는 참으로 주변 음성 어시스턴트에 더 가까워지게 합니다. 어쩌면 '자비스'처럼 무척 진보한 기술이 포함됩니다. 아이언맨 영화에서 토니 스타크의 보조 인공지능입니다. 이러한 고급 기술은 기업, 교육, 의료 및 기타 분야에 걸쳐 광범위한 응용이 가능합니다.","ogImage":{"url":"/assets/img/2024-05-27-TheFutureofAIVoiceAssistantsHowChatGPT4oCouldChangetheGame_0.png"},"coverImage":"/assets/img/2024-05-27-TheFutureofAIVoiceAssistantsHowChatGPT4oCouldChangetheGame_0.png","tag":["Tech"],"readingTime":3},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>2014년 메인스트림으로 등장한 이후로, 음성 비서는 많은 사람들에게 익숙한 가정용품이 되었습니다. 최소한 당신의 스마트폰에는 있죠 (아마도 당신의 대화를 조용히 듣거나 엿듣고 있을지도 모릅니다). 알람 설정, 운전 중에 손을 사용하지 않고 전화 걸기, 스마트 홈 가전제품을 제어하는 일이든, 이러한 장치들은 우리의 일상에 매끄럽게 통합되어 왔습니다. 이러한 도입으로 활성화된 장치의 수도 급증했습니다 — 전 세계적으로 활성화된 장치 수는 40억대가 넘습니다. 이러한 장치 중에서 아마존 에코, 애플 시리, 그리고 구글 어시스턴트(\"OK Google\")가 가장 인정받는 이름들로, 아마존 에코만으로도 시장의 절반 이상을 차지하고 있습니다(미국에서 약 60%).</p>\n<p>하지만 솔직히 말하면: 음성 비서를 사용해본 적이 있다면, 그들의 로봇 음성이나 때로는 간단한 명령을 이해하지 못하는 데 짜증이 났을 가능성이 높습니다. 그러나, 이것은 곧 ChatGPT 4o의 출시로 바뀌게 될 것입니다.</p>\n<p>오픈에이아이(OpenAI)가 최근 최신 주력 언어 모델인 ChatGPT 4o를 발표했어요. 이 모델은 텍스트, 이미지, 오디오, 비디오 입력의 어떤 조합이든 처리하고 해당에 맞게 응답할 수 있는 능력을 가지고 있어요. 이전에는 '음성 모드'로 작동하는 ChatGPT는 오디오 입력을 텍스트로 변환해 처리해야 했었어요. 그러나 최신 모델은 오디오 입력을 직접 해석할 수 있어요. 당신의 억양, 표정, 심지어 배경 소음을 고려하고 230밀리초 이내에 인간과 거의 같은 속도로 응답할 수 있어요.</p>\n<p>이러한 발전들은 ChatGPT가 이제 다른 사람처럼 여러분과 대화할 수 있음을 의미해요. 실시간으로 시각적 입력을 처리하는 능력은 이 기능을 더욱 향상시켰어요. 두 기능을 결합한 잠재력은 엄청난데요. 오픈에이아이는 실시간 번역, 아재개그 풀기, 비꼬는 댓글 남기기, 심지어 자장가 부르기를 하는 ChatGPT의 데모를 통해 이를 보여줬어요.</p>\n<p>더 인상적인 점은 오픈에이아이는 누구나 오픈에이아이 계정이 있는 사람은 물론이고, GPT 4o와 그 어시스턴트 API를 사용할 수 있도록 만들었단 거에요. 이 말은 누구든 몇 줄의 코드(또는 그 이상이더라도, ChatGPT가 도와줄 거예요!)로 앱에 인간과 유사한 음성 어시스턴트를 통합할 수 있다는 거예요. 한편, 마이크로소프트는 새로운 모델이 Azure OpenAI 서비스를 통해 일반적으로 사용 가능하다고 발표했는데요. 이는 기업과 개발자들이 Azure 환경 내에서 자사의 프로프라이어터리 데이터를 활용해 어시스턴트를 통합하고 대화를 커스터마이징하기가 더 쉬워진다는 뜻이에요.</p>\n<p>이러한 발전은 우리 옛날 로봇 음성 어시스턴트 시대의 끝을 알리는 신호이죠. 음성 어시스턴트 시장은 변화에 도전하고 있지만, 구글과 아마존과 같은 산업 거물들은 신속히 대응하고 있어요.</p>\n<p>예를 들어 Google은 최근 Google I/O 컨퍼런스에서 프로젝트 아스트라에 대한 미리보기를 제공하여, 자신들의 Gemini 모델을 이용한 인간과 유사한 음성 어시스턴트에 대한 접근 방식을 소개했습니다. 뒤쳐지지 않으려는 아마존은 기존 음성 어시스턴트인 알렉사의 GenAI 기능을 강화할 것으로 예상되며, 업그레이드된 음성 어시스턴트의 수익성을 높이기 위해 구독 플랜을 도입할 것이라는 소문도 있습니다.</p>\n<p>이러한 모든 발전은 우리를 주변 환경과 상호작용하며 일상 업무를 돕는 참으로 주변 음성 어시스턴트에 더 가까워지게 합니다. 어쩌면 '자비스'처럼 무척 진보한 기술이 포함됩니다. 아이언맨 영화에서 토니 스타크의 보조 인공지능입니다. 이러한 고급 기술은 기업, 교육, 의료 및 기타 분야에 걸쳐 광범위한 응용이 가능합니다.</p>\n</body>\n</html>\n"},"__N_SSG":true}