{"pageProps":{"posts":[{"title":"사용자의 허가 없이 인증 정보를 요구하는 피싱 사이트를 차단하는 방법","description":"","date":"2024-06-19 21:12","slug":"2024-06-19-FeedingthePhishes","content":"\n\n## 사기 교실\n\n당신은 목표로 하는 안전한 이메일 게이트웨이(SEG)를 우회하는 실질적인 핑계를 만들 수 있을 지도 모르겠어요; 그러나 링크가 너무 수상하게 보이거나, 즉 \"사기 같이\" 느껴진다면, 당신의 사기는 심지어 흔들리기도 전에 실패할 수 있어요. 그래서 저는 링크 필터를 자체적인 제어로 생각하는 편이에요. 우리는 이 링크 필터들이 어떻게 작동하는지 간단히 살펴보고, 그들을 우회할 수 있는 몇 가지 방법을 알아볼까요.\n\n# 필터가 뭐길래? (WTF)\n\n지난 몇 년 동안, 링크 자체를 기반으로 한 사기 탐지에 대한 관심이 늘어나는 것을 알아봤어요 - 또는 적어도, 매우 인기 있는 SEG 중 몇몇은 이메일에 링크의 존재에 매우 높은 가중치를 두는 것을 알았어요. 그렇게 많이 보아와서 SEG가 나를 차단할 때 이런 종류의 감지를 내 처음으로 해결해야 하는 단계 중 하나로 만들었어요. 단순히 이메일에서 모든 링크를 제거하고 메시지 내용이 통과되는지 확인해봅니다.\n\n<div class=\"content-ad\"></div>\n\n적어도 한 번에 SEG를 만난 적이 있는데, 어떠한 내용이든 상관없이 어떤 미인식된 도메인에 대한 링크가 포함된 이메일을 차단하는 SEG가 있었습니다. 이 경우에는 내 고객이 허용된 도메인 목록을 관리하고 SEG에게 나머지 모든 것을 차단하도록 지시한 것으로 알고 있습니다. 이는 극단적인 조치일 수 있지만, 매우 타당한 우려라고 생각합니다. 링크가 포함된 이메일은 링크가 없는 이메일보다 기본적으로 더 위험하므로, 대부분의 현대적인 SEG들은 링크를 포함하는 메시지의 SPAM 점수를 증가시키고 종종 링크 자체에 추가적인 검토를 적용할 것입니다.\n\n# 링크 필터링 작동 방식 — 링크 찾기\n\n이메일에서 링크를 필터링하는 SEG는 먼저 콘텐츠 내의 각 링크를 감지/구문 분석해야 합니다. 이를 위해 거의 모든 경험 많은 소프트웨어 엔지니어는 직접적으로 정규 표현식(“regex”로 줄여서 함)을 사용할 것입니다:\n\n![FeedingthePhishes_0](/assets/img/2024-06-19-FeedingthePhishes_0.png)\n\n<div class=\"content-ad\"></div>\n\n어떤 다른 경험 많은 소프트웨어 엔지니어도 정규 표현식은 매우 강력하지만 실수하기 쉽다는 것을 빨리 상기시켜줄 것입니다:\n\n![Regex Example](/assets/img/2024-06-19-FeedingthePhishes_1.png)\n\n예를 들어, 스택오버플로에서 링크를 구문 분석하기 위해 발견한 몇 가지 최고의 정규 표현식 필터 중 일부는 다음과 같습니다:\n\n\n(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])\n\n\n<div class=\"content-ad\"></div>\n\n(?:(?:https?|ftp|file):\\/\\/|www\\.|ftp\\.)(?:\\([-A-Z0–9+&@#\\/%=~_|$?!:,.]*\\)|[-A-Z0-9+&@#\\/%=~_|$?!:,.])*(?:\\([-A-Z0-9+&@#\\/%=~_|$?!:,.]*\\)|[A-Z0-9+&@#\\/%=~_|$])\n\n(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+\n\n([\\w+]+\\:\\/\\/)?([\\w\\d-]+\\.)*[\\w-]+[\\.\\:]\\w+([\\/\\?\\=\\&\\#\\.]?[\\w-]+)*\\/?\n\n(?i)\\b((?:[a-z][\\w-]+:(?:/'1,3'|[a-z0–9%])|www\\d'0,3'[.]|[a-z0-9.\\-]+[.][a-z]'2,4'/)(?:[^\\s()``]+|\\(([^\\s()``]+|(\\([^\\s()``]+\\)))*\\))+(?:\\(([^\\s()``]+|(\\([^\\s()``]+\\)))*\\)|[^\\s`!()\\[\\]'';:’”.,``?«»“”‘’]))\n\n<div class=\"content-ad\"></div>\n\n위 내용 중 이해하기 어렵더라도 걱정하지 마세요. 나는 정규 표현식에 대해 꽤 익숙한 편이지만, 여기에 있는 옵션 중 어떤 것이 더 좋을지에 대한 의견조차 없습니다. 그러나 여기 예시들로부터 주목할 몇 가지 사항이 있습니다:\n\n- \"정답\"은 없습니다; URL은 매우 복잡할 수 있습니다.\n- 대부분은 \"http\"로 시작하는 문자열을 찾고자 하는 것을 나타냅니다 (하지만 전부는 아닙니다).\n\n이것들은 링크 구문 분석 문제에 대한 가장 인기 있는 (똑똑한 사람들이라 생각해보세요) 대답 중 일부입니다. 또한 일부 소프트웨어 엔지니어들이 \"a\" HTML 태그를 포함하는 모든 앵커 태그를 찾거나 링크 시작을 나타내는 \"href=\"를 찾는 더 순진한 접근을 취할 수 있다고 상상할 수 있습니다. 소프트웨어 엔지니어가 선택한 어떤 솔루션이든, 그들의 파서가 잡아내지 못하는 유효한 URL이 적어도 약간은 존재하고 범주적 우회 가능성을 남겨둘 것입니다. \"http\"와 같은 일반적인 표시를 피하게 될 경우 또는 링크를 여러 부분으로 나누는 것으로 파서를 회피할 수도 있을 것입니다.\n\n부연 설명: 이 유명한 URL 파서 중 일부는 FTP를 고려하고 일부는 고려하지 않는 것을 보셨나요? 대부분의 브라우저가 FTP 공유에 연결할 수 있다는 것을 알고 계셨나요? 익명 FTP 링크를 통해 피싱 페이로드를 전달해 본 적이 있나요?\n\n<div class=\"content-ad\"></div>\n\n# 링크 필터링이 작동하는 방식 - 링크 필터링\n\n이메일에서 모든 링크를 분석한 후 SEG가 어떻게 합법적으로 보이는 링크와 그렇지 않은 링크를 결정해야 할까요? 요즘 대부분의 SEG는 각 링크에 대해 두 가지 주요 요소를 살펴봅니다:\n\n- 도메인의 평판\n- 링크의 \"모습\"\n\n도메인 평판을 확인하는 것은 꽤 간단합니다; 링크를 나누어 첫 번째 두 슬래시(\"/\")와 다음 슬래시(\"/\") 사이에 있는 내용을 확인한 다음 해당 도메인이나 서브도메인을 Virustotal이나 유사한 곳에서 찾아봅니다. 많은 SEG는 악성 도메인으로 식별된 경우 다른 보안 제품과 정보를 공유할 것이며 그 반대도 마찬가지입니다. 당신의 도메인이 악성으로 식별된 경우, SEG는 해당 이메일을 차단하거나 링크를 제거할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n링크가 \"어떻게 보이는지\" 확인하는 데는 대부분의 SEG(이메일 보안 게이트웨이)들이 요즘 인공 지능 또는 머신 러닝(즉, AI/ML)을 사용하여 링크를 악의적인지 또는 선행된 것으로 분류합니다. 이러한 AI 모델은 악성 링크의 대량의 알려진 데이터로 훈련되어 SPAM 작성자들이 일반적으로 사용하는 주제와 패턴을 감지할 수 있습니다. 사이버 사기범으로서, 우리는 그 명언의 \"알려진 악의적인\" 부분에 집중하는 것이 중요하다고 생각합니다.\n\n한 연구자의 발표를 본 적이 있는데, 그들의 AI 모델이 훈련 데이터에서 악성 링크 중 98% 이상을 감지할 수 있다고 주장했습니다. 처음에는 매우 인상적인 숫자로 보입니다. 그러나 처음 보았을 때는 100%의 악성 훈련 세트를 사람들이 악의적으로 감지해야 했기 때문에, AI 모델은 \"링크의 외관\"만으로 사기 링크를 감지하는 데 사람의 능력의 98%만큼만 뛰어난 것이었습니다. 이론적으로 이러한 집합을 가지고 있다는 것이 가능한 경우, 알려지지 않은 악의적인 링크 집합에서는 훨씬 나쁠 것으로 상상됩니다. 우리의 링크가 그 알려지지 않은 악의적인 범주로 들어갈 수 있게 음모를 꾸리는 게 중요합니다.\n\n우리는 AI 모델과 맞서고 있지만, 이러한 모델이 인간이 선별한 데이터를 기반으로 훈련되므로 결론적으로는 이 작업에서 인간의 능력에 수준에 달할 뿐 아니라 뛰어넘을 수 없다는 것을 상기하는 것을 좋아합니다. 우리 링크가 인간에게 충분히 설득력 있게 보이게 만들면, AI가 우리에게 어떤 문제도 제공하지 않을 것입니다.\n\n# 링크 필터 우회하기\n\n<div class=\"content-ad\"></div>\n\n우리가 링크 필터가 작동하는 방식에 대해 알게 된 지금, 필터를 우회하는 데 사용할 수 있는 두 가지 주요 전략이 있습니다:\n\n- 링크를 형식화하여 링크 파싱 단계를 통과시킵니다\n- 링크를 더 \"합법적\"으로 보이게 만듭니다\n\n만약 파서가 우리의 링크를 링크로 등록하지 않는다면, 추가적인 검토를 할 수 없습니다. 우리가 우리의 링크 위치를 어떤 합법적인 링크처럼 보이게 만들 수 있다면, 파서를 우회하지 못하더라도 우리가 그래도 허용을 받을 수도 있습니다. 이러한 접근 방식은 상호 배타적이 아니며 기법을 혼합하는 것이 더 큰 성공을 거둘 수도 있다는 점에 유의하십시오.\n\n# 파서 우회하기\n\n<div class=\"content-ad\"></div>\n\n## 앵커 태그 사용하지 마세요\n\n일부 SEG들에 대한 가장 기본적인 파서 우회 방법 중 하나는 Outlook에서 하이퍼링크를 제거하여 링크 URL을 일반 텍스트로 남겨두는 것입니다. 보통 링크 URL은 HTML 앵커 태그(`a`)의 \"하이퍼텍스트 참조\" (href) 속성에 배치됩니다. 앞서 설명한대로, 링크를 구문 분석하는 한 가지 단순하지만 놀라울 정도로 흔한 해결책은 Python의 BeautifulSoup와 같은 HTML 파싱 라이브러리를 사용하는 것입니다. 예를 들면:\n\n```js\nsoup = BeautifulSoup(email.content, 'html.parser')\nlinks = soup.find_all(\"a\") # <a> 태그 모두 찾기\nfor link in links:\n  print(\"링크:\", link.get(\"href\"), \"텍스트:\", link.string)\n```\n\n이 접근 방식을 사용하여 링크를 구문 분석하는 SEG는 앵커 태그 바깥에 있는 URL을 보지 못할 것입니다. 클릭 가능한 링크가 아닌 URL은 최종 사용자에게 약간 이상할 수 있지만, 이 우회 방법이 작동할 때는 일반적으로 이런 절충이 가치 있다고 할 수 있습니다. 많은 경우에 메일 클라이언트들은 앵커 태그 안에 있지 않더라도 URL을 하이퍼링크로 구문 분석하고 표시할 것이기 때문에, 이 기술을 사용하는 것에는 대개 거의 또는 전혀 단점이 없습니다.\n\n<div class=\"content-ad\"></div>\n\n## Base Tag 사용법 (a.k.a BaseStriker 공격)\n\n일부 링크 필터를 우회하는 흥미로운 방법 중 하나는 \"base\"라는 잘 알려지지 않은 HTML 태그를 사용하는 것입니다. 이 태그를 사용하면 상대 참조를 사용하는 모든 링크에 대해 기본 도메인을 설정할 수 있습니다 (즉, href가 \"/something\"으로 시작하는 링크가 아니라 \"https://example.com/something\"과 같이 직접 참조가 아닌 링크). 이 경우에는 \"https://example.com\"이 URL의 \"base\"로 간주됩니다. HTML 콘텐츠의 헤더에서 HTML base 태그를 사용하여 기본을 정의하면 메시지의 본문에서는 상대 참조만 사용할 수 있습니다. HTML 헤더에는 일반적으로 CSS나 XML 스키마와 같은 것들을 위한 URL이 포함되지만, 헤더에는 악의적인 내용이 포함되지 않을 것으로 예상되며 링크 구문 분석기에서 눈을 피할 수 있습니다. 이 기법은 \"BaseStriker\" 공격으로 알려져 있으며 일부 인기 있는 SEGs에 대해 작동하는 것으로 알려져 있습니다:\n\n[BaseStriker 공격 기법: Microsoft Office 365 항 취업 필터를 우회할 수 있는 기술](https://www.cyberdefensemagazine.com/basestriker-attack-technique-allow-to-bypass-microsoft-office-365-anti-phishing-filter/)\n\n이 기술이 작동하는 이유는 사실상 링크를 두 부분으로 나누기 때문입니다: 도메인은 HTML 헤더에 있고 URL의 나머지 부분은 본문의 앵커 태그에 있습니다. 앵커 태그의 href는 \"https://\"로 시작하지 않기 때문에 링크로 감지되지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n## 작은 우회 계획\n\nURL의 첫 부분, 콜론과 슬래시 앞에 있는 부분은 \"scheme\"이라고 알려져 있어요:\n\n```js\nURI = scheme \":\" [\"//\" authority] path [\"?\" query] [\"#\" fragment]\n```\n\n이미 언급한 바와 같이, URL을 감지하는 더 효과적인 방법 중 하나는 scheme인 것처럼 보이는 것을 찾는 것입니다 (예: \"http://\" 또는 \"https://\"), 그 뒤에 URL에서 허용되는 문자 시퀀스가 따르는 것입니다. 만약 scheme을 빼 놓는다면, 많은 링크 파서들은 우리의 URL을 감지할 수 없을 수도 있지만, 그래도 이것은 사람에게 URL처럼 보일 것입니다.\n\n<div class=\"content-ad\"></div>\n\naccounts.goooogle.com/login?id=34567\n\n이 링크를 브라우저에 그대로 복사하여 붙여넣으면 간단하게 사용할 수 있습니다. 또한, 몇 가지 합법적인 방법이 우리의 대상 사용자 시스템에서 프로그램을 열고 오류로 표시되는 URL 파서를 뚫고 지나갈 수 있습니다. 보통의 웹 링크만을 찾는 URL 파서가 다음 링크들을 식별하는데 문제를 겪을 수 있습니다:\n\nhttps://en.wikipedia.org/wiki/List_of_URI_schemes\n\n여기에서 몇 가지 피싱 링크로서 매우 유용한 것들이 포함되어 있을지도 몰라요 ;)\n\n<div class=\"content-ad\"></div>\n\n## QR 낚시\n\n이메일에 링크가 전혀 없는 경우는 어떻게 될까요? 이미지로 되어 있는 경우는 어떤가요? 전통적인 링크 대신 QR 코드를 사용하여 낚시를 자동화하는 SquarePhish와 같은 도구를 사용할 수 있습니다:\n\n아직 직접 시도해보지는 않았지만, 비슷한 기술을 사용한 친구들로부터 좋은 소식을 들었습니다. 이 공격을 직접 자동화해보고 싶다면, NodeJS에는 QR 생성을 위한 간단한 라이브러리가 있습니다:\n\n# 필터 우회\n\n<div class=\"content-ad\"></div>\n\n## 링크 숨김 기능 사용하지 마세요\n\n(잠깐만요. 제 의견을 말씀드릴게요...) 링크를 숨김 처리했는데, 블록당하는 일이 몇 번 있었는지 모르겠어요. 그런데 링크를 풀어보면 동일한 내용이 전달된다는 것을 알게 되었어요. 앵커 태그의 이 기능이 스팸 발송자들에 의해 오래 전부터 남용되어 왔기 때문인 것 같아요. 평범한 이메일 사용자들은 링크 숨김을 거의 사용하지 않으니, 링크 필터는 일반적인 링크보다 링크 숨김을 훨씬 더 위험하게 볼 수 있어요. 따라서 그냥 일반 링크를 사용하세요. 요즘에는 누구나 링크를 호버하고 실제 위치를 확인할 수 있다고 생각하기 때문에, 숨김 링크는 이제 사람을 속이는 데에도 좋지 않아요. 진부하지 마세요. 링크 숨김을 사용하지 마세요.\n\n## 분류된 도메인 사용하기\n\n많은 링크 필터러는 미분류된 도메인이나 악성으로 분류된 도메인, 최근에 등록된 도메인을 차단하거나 삭제합니다. 따라서 주로 분류가 완료된 도메인을 사용하는 것이 좋은 생각일 수 있어요. 이미 \"원 피쉬, 투 피쉬, 레드팀이 피쉬를 토하다\"에서 이에 대해 언급했기 때문에 좋은 도메인을 얻는 과정은 생략하겠어요. 그래도 여기서도 동일한 규칙이 적용된다는 것을 알아두세요.\n\n<div class=\"content-ad\"></div>\n\n## \"합법적인\" 도메인 사용하기\n\n만일 사기 링크를 유지하는 데 들이는 수고를 피하고 싶다면, 대체로 신뢰할 수 있는 도메인을 활용할 수 있습니다. 최근에 \"야생에서\" 본 예시 중 하나는 스패머가 sites.google.com 링크를 사용한 것이었습니다. 그들은 구글에 피싱 페이지를 호스팅했죠! 이 아이디어가 뛰어난 것으로 생각했습니다. 왜냐하면 대부분의 링크 필터가 Google을 허용할 것이라 기대했고, 대부분의 최종 사용자는 google.com에서 제공되는 모든 것이 신뢰할 만하다고 생각할 것이기 때문이었습니다. 이와 유사한 다른 예시로는 GitHub의 정적 페이지, S3 버킷이나 기타 일반적인 콘텐츠 전달 네트워크(CDN), 그리고 SharePoint 등에서 자신의 피싱 사이트를 호스팅할 수 있습니다. 사용자가 임의의 HTML 콘텐츠 페이지를 호스팅할 수 있는 \"합법적인\" 사이트가 많이 있습니다.\n\n## 임의의 리디렉션\n\n신뢰할 수 있는 도메인에 피싱 사이트를 호스트하는 것과 같은 방식으로 신뢰할 수 있는 도메인을 사용하여 피싱 사이트로 리디렉션을 할 수 있습니다. 이러한 전형적인 예시 중 하나는 TinyURL과 같은 링크 단축 서비스입니다. TinyURL은 SPAM으로 남용되었기 때문에 대부분의 보안 게이트웨이(SEG)가 TinyURL 링크를 차단할 것으로 예상되지만, TinyURL은 임의의 리디렉션의 유용성을 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n임의의 리디렉트 우회하기 위한 더 유용한 형식은 'window.location' 변경을 지정할 수 있게 해주는 크로스사이트 스크립팅(XSS) 취약점이 존재하는 URL 또는 HTTP GET 매개변수를 통해 페이지 리디렉트를 지정할 수 있는 URL입니다. 제 정찰 단계에서는 대상의 주요 웹사이트에서 이러한 종류의 취약점을 찾기 위해 몇 분 이상을 투자하는 것을 좋아합니다. 이러한 취약점들은 놀랍게도 흔하며, 웹 애플리케이션 페네트레이션 테스트 보고서에서 임의의 리디렉트는 낮은 위험으로 여겨질 수 있지만 피싱과 결합하면 매우 유용할 수 있습니다. 여러분의 링크는 대상 조직의 주요 웹사이트에 대한 URL을 가리킬 것입니다. 링크 필터나 심지어 사람도 그 위험을 알아차리기는 극히 힘듭니다. 경우에 따라 대상 조직이 SEG(Secure Email Gateway)에서 도메인을 가리키는 링크에 대한 명시적 허용 목록을 구성해 놓은 경우가 있을 수도 있습니다.\n\n## 첨부 파일에 대한 링크\n\n이메일의 링크도 이메일 첨부 파일을 가리킬 수 있다는 사실을 알고 계셨나요? 앵커 태그의 href에 URL 대신 첨부 파일의 콘텐츠 식별자(CID)를 지정할 수 있습니다(예: href=\"cid:mycontentidentifier@content.net\"). 링크 필터를 우회하는 데 이 요령을 사용한 한 가지 방법은 HTML 첨부 파일로 링크를 걸고, 사용자를 피싱 사이트로 리디렉트하는 난해한 자바스크립트를 사용하는 것입니다. 우리의 href가 URL처럼 보이지 않기 때문에 대부분의 SEG가 우리의 링크를 무해하게 생각할 것입니다. PDF, DOCX 등 일반적으로 허용되는 여러 다른 파일 유형으로 링크를 걸거나, 실제 피싱 링크가 포함된 후자의 파일을 링크할 수도 있습니다. 사용자에게 추가 지침을 제공하기 위해 선판 속에서 약간의 작업이 더 필요할 수도 있고, 문서를 여는 후 사용자가 그냥 링크를 클릭하리라는 희망만 가져도 되기도 합니다. 이 경우 SEG의 콘텐츠 필터가 검증될 가능성이 낮은 문서 내에 추가 지침을 추가하는 것이 가장 합리적이라고 생각합니다.\n\n## 전화하기\n\n<div class=\"content-ad\"></div>\n\n이 블로그는 사회 공학 전법을 우회하는 우리의 \"메시지 수신\" 제어를 마무리 짓습니다. 모두가 알 수 있는 가장 간단한 우회 중 하나를 언급하지 않고는 완벽하지 않을 것입니다:\n\n이메일을 사용하지 않기!\n\n대상에게 전화기를 들고 직접 대화를 나누면, 귀를 통해 그들의 두뇌에 직접 들어가는 모란, 즉 통과하지 않고 바로 들어오는 프리텍스트가 되는 것입니다.\n\n이와 같이 줌 통화, 팀 채팅, 링크드인 메시징 및 거의 모든 일반적인 비즈니스 의사 소통 채널들은 이메일보다 훨씬 적은 제어 대상이 될 것입니다. 이메일보다 전화통화를 선호하여 워크플로를 크게 단순화시키는 레드 팀원들을 몇 명 훈련해왔는데, 목표 환경에 접근하기 위해서는 몇 번의 어색한 통화만 하면 충분할 때가 많습니다.\n\n<div class=\"content-ad\"></div>\n\n보다 인터랙티브한 의사 소통 방식인 전화 통화 같은 것들은 목표물이 실시간으로 당신의 구실에 대해 어떻게 느끼는지 판단할 수 있도록 해줍니다. 몇 초 안에 상대방이 당신을 믿고 도와주려 한다는 것을 알 수도 있고, 아니면 상대방이 당신을 속인다고 생각하고 끊을 시간이 되었음을 알 수도 있습니다. 또한 전화 통화를 사용하여 목표물을 계속해서 이메일을 통해 연락하는 것으로 인식되는 정당성을 더할 수도 있습니다. 사용자에게 메시지를 전달하는 것이 전투의 반에 해당하며, 사회 공학 전화 통화는 강력한 지름길이 될 수 있습니다.\n\n# 요약하자면\n\n링크 필터를 우회해야 한다면 다음 중 하나를 선택할 수 있습니다:\n\n- 링크가 링크가 아닌 것처럼 보이도록 만들기\n- 링크가 \"정당한\" 링크로 보이도록 만들기\n\n<div class=\"content-ad\"></div>\n\n이메일에서 여전히 링크를 많이 사용해요. 그냥 \"진짜\" 링크와 섞이면 필터를 속일 수 있어요. 정말 급한 상황이라면 대상을 직접 전화해보세요. 더 개인적으로 느껴질지도 몰라요, 하지만 일을 빨리 처리할 수 있답니다.","ogImage":{"url":"/assets/img/2024-06-19-FeedingthePhishes_0.png"},"coverImage":"/assets/img/2024-06-19-FeedingthePhishes_0.png","tag":["Tech"],"readingTime":11},{"title":"나의 생각 오픈 소스 창의적 생성 AI에 대한 응답","description":"","date":"2024-06-19 21:07","slug":"2024-06-19-MyResponsetoOpenSourceCreativeGenerativeAI","content":"\n\n## 적용된 gAI의 개발은 사회적 요구 및 규범에 근거하여 우리 문화와 정체성과 일치시키고 분열을 피해야 합니다\n\n일반화 미술에 대한 개발에 대해 먼저 개인적인 견해를 표현해볼까요? 제 입장은 굉장히 이중적이라고 할 수 있어요. 한 쪽은 극도로 냉소적이고, 다른 한편은 희망적입니다. 이 주제에 대해 이전에 여기 (참고: 다소 우울함)에 논문을 작성했었죠.\n\n우선 냉소적인 시각에서 시작해보겠습니다.\n\n# 제 냉소적인 입장\n\n<div class=\"content-ad\"></div>\n\n\n![My Response to Open Source Creative Generative AI](/assets/img/2024-06-19-MyResponsetoOpenSourceCreativeGenerativeAI_0.png)\n\n# 낮은 임금, 부탁드립니다\n\n저는 이것을 큰 기술 노력으로 보며, 기술 임금을 낮추고 창의적인 작업자들의 협상 위치를 감소시키며, 예술의 상품화를 유도하고, 새롭게 확장 가능한 소비 시장을 창출하며, 보다 통합적으로 사회를 초인간주의로 이끌 것으로 보고 있습니다.\n\n요컨데 크게 지불 받는 10대가 자신들을 불필요하게 만들기 위한 도구를 만들고 있으며, 이는 역사상 올바른(조금 막바지에 있긴 하지만) 위치에 있기 때문에 가능한 것입니다. 사람들은 이 기술을 '기술을 민주화'하기 위해 밀고 나가는 사람들이 실제로 피해를 입을 위험이 거의 없다는 것을 거의 깨닫지 못합니다. 왜냐하면 그 사람들은 연간 400K 정도의 급여를 받기 때문입니다.\n\n\n<div class=\"content-ad\"></div>\n\n그 말인 즉, 이 동력은 억만장자들에 의해 추진되고 백만장자들에 의해 실행되며, 갖고 있는 사람들을 최면에 걸고 없는 사람들에게 그것을 심어주는 미친 춤이다. 따라오는 기술인들은 자신이 자기 해고에 관한 일을 할 때 다음 백만장자가 될 것으로 생각하며 지켜보고 있습니다. 이것은 배(즉, 인간 노동)에서 탈출하는 뼈아픈 경주입니다.\n\n# 이미지로 멈추지 말고 더 나아가기\n\n현재 생성 이미지 기술은 고전 음악에서 시로 이어지는 어떤 예술 형태든 자동화하는 보다 긴밀하고 광범위한 노력에서 하나의 예제에 불과하며, 인공 일반 지능을 개발하기 위한 포괄적 노력의 일환이라고 볼 수 있습니다.\n\nPaLM부터 Stable Diffusion, DALLE-2에서 ChatGPT까지, 세계 각지에서 연구 그룹들은 연결주의를 탐구하고 있습니다. 이는 신경망을 충분히 확장한다면 AGI가 자체적으로 발생한다는 주장을 하는 아이디어입니다.\n\n<div class=\"content-ad\"></div>\n\n딥마인드(DeepMind)부터 OpenAI까지, 목표는 우리를 돕는 도구를 개발하는 것이 아니라, 우리를 대체할 도구를 개발하는 것입니다. AGI는 매년 40만 달러를 받는 테크 브로들에겐 멋지겠지만, 다른 모든 사람들에겐 위협이 됩니다. 이 AGI 추진은 PaLM, Parti, Imagen, GPT, MUM, Florence, ERNIE, Flamingo 등 많은 다른 (극도로) 큰 신경망 구조 뒤에 있습니다. 이러한 구조들은 이전의 인간 노동에 기반을 둔 것입니다. 이 분야의 대규모 주요 행위자인 OpenAI, Microsoft, Google, Meta는 적용된 AGI 기술에서 선두주자가 되기 위한 다른 선택지가 없습니다.\n\n이 노력은, 예를 들어 사진으로부터 범죄자를 식별하는 기계 학습 모델을 개발하는 유사 그룹들로부터 나옵니다. 이들 그룹을 위해 ML 애플리케이션을 개발하는 데 도덕적 제약이 없다고 가정해 봅시다. 군사로봇용 AI, 자동 사법 파트너 구현을 위한 AI, 또는 영광스러운 \"해골 측정\" 알고리즘을 만드는 AI 창작을 위한 AI인 경우도 있습니다.\n\n이는 개발이 불가피하다는 가정 하에 최초 이동者가 되는 것이 좋다는(효과적인 자탑심의 한 형태), 또는 기술에 도덕성이 없다는, 즉 \"기술에 도덕성은 없고, 인간에게 도덕성이 있다\"는 형태의 객관주의의 일종일 수 있습니다.\n\nAI에서 중요한 기술적 발전을 볼 때마다, 이것이 윤리적 검토를 거치지 않았고 이해관계자들과 심각한 토론이 이루어지지 않았다고 가정해야 합니다. 예를 들어, StableDiffusion에 관련된 예술가들이나 GPT-3에 관련된 저자들과의 심각한 토론이 없었다는 것을 전제로 해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n이집트는 단기적인 유틸리타리즘과 뉴자이버러리주의 사이의 부도덕한 결합이며, 인문주의에 근거하지 않고 경제적 이익을 극대화하기 위한 끊임없는 추구가 결여되어 있습니다.\n\n이 결합은 기쁘게도 StableDiffusion 및 DALL-E2로 시장화 가능한 이미지의 자동 생성을 확장하며, Jesper.ai 및 Compose.ai로 구성 가능한 복사본으로 전환하고, DanceDiffusion으로 시장화 가능한 음악으로, Runway.ml로 자동 비디오 작성으로 이어질 것입니다.\n\n이미 내 트위터 타임라인은 \"10가지 팁...\"과 같은 자동 생성된 목록으로 스팸 메시지를 받고 있어, 구독자가 될 수 있도록 유도하려고 합니다.\n\n의심할 여지없이 자동 생성된 블로그가 광고를 팔기 위해 대규모로 밀려 들고 있고, 아마도 여러분이 인식하지 못하고 있겠죠. 또한, 지금은 chatGPT가 학생들을 위해 작성하는 에세이와 다른 과제가, 복잡한 데이터를 종합하고 검색하여 잘 구조화된 의도 있는 주장을 형성하는 방법을 배우는 대신, 이제 AI 검출 도구를 회피하는 법을 배우고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 또 다른 도구일까요?\n\n이것이 또 다른 도구가 될 것이라는 생각은 잘못된 것 같아요. 현재 생성 모델의 상태는 단지 현재의 상태일 뿐이고, 완전한 자동화로 나아가는 명백한 발전이 있습니다. 이것이 우리를 어디에 남길지에 대한 근본적인 질문이 제기될 수밖에 없군요.\n\n우리, 시민, 인간으로써 만족감, 자부심, 성취감, 그리고 당당함을 주는 활동을 왜 자동화하려고 하는 걸까요? 왜, 모든 사람 중에서도 이렇게 발전을 추구하는 이기주의자들이 있을까요?\n\n우리는 어떻게 이 발전이 우top밀한 유토픽 사회로 자체 조직화될 것으로 생각하나요? 의무적인 작업으로부터 해방되어 우리가, 바람직한 생각만 있을 뿐이더라도 창조하고 놀고 꿈꾸는 이상한 유토피아를 만들어 낼 것이라고 믿지만, 우리는 여전히 기술적 발전 이외에도 인간의 착취를 기반으로 한 가치 분배 체계에서 살아가고 있으며, 거대한 불평등과 생태학적 파괴를 초래했습니다.\n\n<div class=\"content-ad\"></div>\n\n이 프레임워크에서는 햄모크 시간이 더 이상 없을 것입니다. 더 적은 시간에 더 많은 생산을 해야 합니다. 우리가 종으로서는 생산을 더 많이 하는 것이 진정 우리가 가져야 할 초점인가요, 아니면 균형을 맞추며 더 적게 생산하고 덜 원하는 삶을 더 추구해야 하는 것일까요? AGI와 이를 자유주의 후원자들이 후원하는 것은 모든 사회민주주의에 대한 대규모 공격이 아닐까요?\n\n만약 우리가 그 평등주의 사회에 도달한다면, 그리고 (그 때에는) 어떠한 인간도 산업화가 쉽게 이루어질 수 없는 능력이나 기술을 갖고 있지 않다는 현실에 우리 자아/티모스가 영향을 받지 않는다고 가정해 봅시다.\n\n우리는 신에게 평등하다가, 법 앞에 평등하다가, 인공지능의 통제 아래에서 평등해지게 됩니다. 이에 대해 이야기해야 합니다. 누가 이 새로운 신을 통제하며, 이것이 우리의 정신과 복지에 어떻게 영향을 미칠까요? 우리는 정말로 앞으로 나아가는 것이 올바른 방향인지 믿을 수 있을까요? 이것이 최상의 방향인지 확신이 없다면 가속화하는 것이 합리적인 것일까요?\n\n# 예술이 상품이 되다\n\n<div class=\"content-ad\"></div>\n\n예술은 경제적 가치가 없지만 인간 경험에 미치는 영향이 엄청나게 중요한 우리의 활동 중 하나입니다. 우리에게 고유한 가치가 있습니다.\n\n억만장자 친구들이 우리도 없는 프로그래머 친구들에게 그들의 특권적인 위치에서 사회에 급진적인 변화를 일방적으로 부과함으로써 그들의 기술에 의존하는 시민들의 협상력을 약화시키는 돈을 냅니다. 이러한 개발이 영향을 받을 시민들의 이전 작업에 토대를 두고 있다는 사실은 이를 더욱 냅니다.\n\n이것은 이른바 지적 육식주의로, 이 프로그래머들은 다음 번 메뉴 페이지에 있습니다. 이와 같은 일은 Codex에서도 일어났지만, 프로그래머들은 이제 생산성이 증가했다고 만족하는 중입니다. Codex 1.0 → 10.0에서, 당신의 존재보다 Codex의 비중이 점점 더 많아지는 것을 보게 될 겁니다.\n\n“대박이구나. 이제 더 멋진 일을 할 수 있겠군!”라고 생각하시는 것 같아요! 여기서 조금 수정을 가해야 합니다. 이미지에 대한 gAI에 관한 이유론과 같은 오류로 반복되는 것을 보았던 것과 같은 이유로, 이 기술은 당신이 원하는 대로 자유롭고 다양한 일을 할 수 있는 여지와 능력을 증진시키기 위한 것이 아닙니다. 이 기술은 당신의 생산성을 높이기 위해 고안된 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이 논의에서 가장 허무한 용어는 \"인간 기술의 민주화\"입니다. 이 용어는 주로 그 기술을 이용하는 단체(즉, 기업)에 봉사하는 용도로 사용됩니다. 현재의 사회경제 체계에서는 이로 인해 고용주의가 더 많은 노동자들(드디어 브로그래머들까지)의 빈곤과 비참함으로 이어질 것입니다. 이는 이전에 \"비민주적\"인 인간 기술에 대한 모든 사람들의 자유롭고 방해받지 않는 접근을 얻는 데 기여할 것입니다.\n\n그러면 해방력 측면에서 인간 기술은 무의미해집니다. 알다시피, 모든 인간 노동은 배우고 공부해야 한다는 요구 사항에 의해 gatekept 됩니다. 이 요구 사항의 증가는 희소성 증가와 관련이 있습니다. gAI 지지자들이 사용하는 의미에서 민주주의는 모두에게 동등한 노력 없이 제공되어야 한다는 것을 의미합니다. 인간 기술은 고유 가치를 잃고 인간 노동자들의 위치를 높일 수 없게 됩니다. 고임금 프로그래머에 의한 자동화의 일방적인 배치가 새로운 부르주아와 수작업 노동자들 간의 대립이다. 이것은 계급 문제입니다.\n\n또한, 브로 코더들이 \"gatekeeping\"을 본다고 할 때, 그것을 대신 성실하고 책임감 있는 고객들과 도메인 전문가들과 함께 강력한 도구를 개발하는 것으로 보는 것은 쉽습니다. \"gatekeeping\"과 \"민주화\"와 같은 용어의 오용으로 인해 노동자와 개인의 권리를 보호하기 위한 개념마다 악자본주의가 솟아나고 있다는 신호입니다. 또한, 프로-gAI 지지층 중 일부 치명적인 운명론 문화 마르크시즘과 결합되어 밝은 미래를 그리지 않습니다.\n\nLex Fridman과의 인터뷰에서 John Carmack은 AGI가 우리 역사상 개인들에게 가장 큰 영향력 증가를 만들어낼 것이라고 언급했습니다. 저는 정반대를 주장합니다. 만약 우리가 이 AGI에 대한 접근을 제한한다면, 소수의 행복한 사람들이 다수를 비참하게 만들 것입니다.\n\n<div class=\"content-ad\"></div>\n\nAGI 액세스에서의 불평등은 우리 사회에 재앙을 불러올 수 있습니다. 그러나 이 AGI가 국민을 대표하는 선량한 정부의 손에 전달된다면 어떨까요? 하지만 솔직히 말해서, 누가 그런 것을 믿겠어요?\n\n우리가 자문해야 할 일반적인 질문은 우리가 처음부터 취약한 세상 가설뿐만 아니라 인간의 존엄성과 자아 가치를 보존하는 관점에서 AGI를 개발해야 하는지입니다. 우리는 이 프로세스를 어떻게 안내하여 선량한 결과를 가능하게 하거나 적어도 그 가능성을 극대화할지에 대해 스스로 물어봐야 합니다. 다시 말하지만, 이 발전을 적극적으로 추진하는 사람들은 만약 역효과가 발생한다 해도 두려워할 것이 없는 사람들입니다. 실리콘밸리에게 이를 완화하는 것을 기대하지 마십시오. 오히려 더 많은 솔루션주의, 기술주의 및 기술 의존을 예상할 수 있습니다.\n\n이로한 탄화 obfuscates의 설립자는 여러 윤리적 프레임워크를 놀이하는 것으로 윤리 고려 요구를 은폐합니다. 하지만 중간여정이나 Stable Diffusion의 훈련 세트에 있는 예술가들은 이 어플리케이션에 허용을 하지 않았으며, 수천 명의 잘 알려진 배우와 가수들도 마음대로 어떠한 맥락에도 사용할 수 있는 이미지를 불러올 수 없습니다.\n\nStability.ai가 StableDiffusion 2.0의 훈련을 위한 라이선스 없는 이미지를 제거했다 하더라도 이미 StableDiffusion1.x를 공개했으며, 디지털 아티스트들에게 피해를 입히고 앞으로도 입힐 것입니다.\n\n<div class=\"content-ad\"></div>\n\nCodeX와 비슷한 상황이 GitHub 리포지토리(공개 및 비공개)에서 훈련된 CodeX와 관련이 있습니다. 이 수준의 자동화가 대규모 실업과 임금 감소로 이어진다면, 누가 책임을 져야 하는지 고민해봐야 하며, 이를 금전적 피해로 간주하여 보상을 요구해야 할지도 모릅니다. 분명히, 이 피해를 초래한 사람(예: Microsoft 또는 Stability)은 그로 인해 이윤을 얻게 될 것입니다.\n\n# 그러나, 그 사진이 화가를 ‘죽이려’ 했던 것이라면\n\n예, 하려 했지만, 라디오나 비닐 레코드 등 지역 소규모 아티스트에 대한 존중도 함께 감소했죠.\n\n기술 분야의 전문가들이 생성적 예술에 관한 비논증적 주장과 거짓 동등성을 통해 우연히 명확하게 밝히는 바는 (컴퓨터 과학의 한정된 범위 외의 추론 능력이 결여된 것 외에도) 지난 100년 동안 의미 있는 인간 노동을 점차 추상적 파생물로 대체하고 있다는 것입니다. 우리는 AI가 대체하도록 예정된 집약적인 노동이 사실은 이전 자동화 단계의 결과임을 깨달아야 합니다. 생산 라인일은 자동화의 결과입니다. 테일러리즘은 자동화의 결과입니다.\n\n<div class=\"content-ad\"></div>\n\n누가 디지털 아트, 저작권, 번역, 스토리텔링 및 중앙 집중식 API에 의해 섭취되는 많은 작업들이 실제 개인적인 인간 경험으로부터 내재적 가치를 더하는 의미있고 충족스러운 작업인지 부정할 수 있을까요?\n\n수백만 명의 노동자들 - 재능 있는 개인들은 많은 시간을 들여 기술을 닦아왔음에도 너무 많은 과학 소설을 읽은 과도하게 지불받고 있는 십대들에 의해 갑자기 일반적이고 독특한 인간의 일을 수행하는 권한을 상실했습니다. 이제 이윤만을 추구하는 기업들에 의해 글로벌 시장을 인공 지능 일반화(GAI)를 최초로 주도하기 위해 혈투를 벌이는 재력이 넘치는 기업들에 의해 사라진 수 백만 명의 노동자들입니다. 피터 틸이 말한 대로 \"경쟁은 패배자들을 위한 것입니다.\"\n\n우리 삶의 의미는 생산하는 것에서 소비하는 것으로 변화했습니다. 우리는 무엇을 어떻게 소비하는지를 통해 점점 더 스스로를 식별하게 되었고, 우리가 생산하는 것을 통해 점점 더 스스로를 식별하지 않게 되었습니다.\n\n물론, \"사진\" 비교의 주요 결점은 명백한 비동등함입니다. 사진, 테이프 녹음기, 라디오 등 많은 다른 잘못된 비교들은 무엇보다도 새로운 매체입니다. 같은 아이디어를 표현하는 새로운 방법입니다.\n\n<div class=\"content-ad\"></div>\n\nGenerative art로는 아이디어 자체를 자동화하고 있어요. 이 자동화는 인간 예술가들의 작품에서 창작되었는데, 완전히 대체되거나 적어도 경제적 이점 측면에서 부정적인 영향을 받을 수 있다는 것이 중요합니다. 이에 대한 명백한 반박은 이후에 더 추상적이고 큰 아이디어에 대해 작업할 수 있다는 주장이지만, AI가 점차적으로 추상화된다는 점을 고려하면 우리의 인간 수준의 추상화에 한계가 있다고 생각할 이유가 없기 때문에 그런 주장은 명백히 부정될 수 있습니다.\n\n# 스타일을 저작권으로 보호할 수 없다고요?\n\nAI 예술 옹호자들은 저작권법을 이상하게도 매우 글자 그대로 해석하고 있는데, 디지털 작품을 픽셀 단위로 복사해야만 저작권을 적용할 수 있다고 생각하고 있습니다.\n\n물론, 이것은 옳지 않아요.\n\n<div class=\"content-ad\"></div>\n\n일단, 저작권은 명시적으로 포기하지 않는 한 모든 원작에 자동으로 부착됩니다.\n\n둘째, 저작권은 그 소유자에게 창작물을 복사, 배포, 적응, 전시 및 공연하는 배타적 권리를 부여합니다. 복제물이 모델에 존재하고 이 복제물이 적응으로 이어진다는 주장(편집: 그리고 심지어 표시)도 할 수 있습니다.\n\n복제물이 완전히 동일하지 않더라도, 특정 프롬프트를 사용하여 원본 이미지에 매우 가까이 접근할 수 있다고 가정해 보겠습니다; 여전히 침해의 소지가 있으며, 특히 브랜드 이미지와 관련하여 그렇습니다. 혼동을 일으킬만한 유사성은 브랜드 소유자에 의해 법적 조치를 정당화하는 데 충분합니다. 상표법은 상표에 무단 이미지 또는 심지어 텍스트(예: 슬로건)를 사용함으로써 뷰어가 표현의 연관성을 혼동하는 것으로부터 브랜드를 보호합니다.\n\nAI 예술 생성기가 완벽한 복제본을 생성하지 않기 때문에 저작권을 침해하지 않는다고 주장하는 것은 .jpeg 또는 기타 손실 압축이 원본의 \"해석\"인 것과 같다고 말하는 것과 같습니다. 상표법이 존재하지 않는다고 가정하는 건 매우 순진하다는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 동의. 누가 동의를 필요로 할까요?\n\n저작권법과 상표법 이외에도 초상권 또는 대안으로 인격권 또는 홍보권이라는 것이 있습니다. 상표법과 유사하게, 초상물의 무단 상업적 이용에 대해 책임을 지게 될 수 있습니다. 이는 해당 이미지가 개인을 정확하게 대변할 필요가 없다는 것을 의미합니다.\n\n물론, Stable Diffusion은 교육데이터에 표현된 개인들에게 합성 이미지가 어떠한 맥락에서 사용될지에 대한 동의를 구하지 않았습니다. 사용자가 만드는 모델의 맥락에 따라서 유사한 초상이 포함된 합성 이미지가 배치될 수 있다는 것을 의미합니다. 그 모델 속 누구든, 적절한 토큰의 (조합으로) 적용될 수 있다는 것을 이해하는 것이 중요합니다.\n\n이는 개인 상표의 영역을 넘어서 개인 정보 보호권과 심지어 불법행위법 영역으로 진입합니다. 만약 모델로 교육 데이터에 포함되어 있고, 합성된 유사 이미지가 음란한 맥락에서 당신을 묘사한다면 상표가 훼손되었다는 주장을 쉽게 할 수 있습니다. 이 경우, 발행인과 모델 크리에이터는 손해배상책임이 있다고 주장할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n만약 출력물을 개인적으로 작성한다면, 이는 문제가 될 필요가 없습니다. 그 경우 부담은 창작물을 게시하는 이에게 있고, 모델을 만든 사람에게는 없습니다. 이것은 이해하기 쉬운 주장입니다. 그러나, 이것이 총이 나쁜 게 아니라 사람이 나쁜 유형의 주장인 점을 감안하면, 여기서 총은 훈련 세트에 존재하는 사람들을 손상시킬 가능성이 미리 적재된 상태인 셈입니다.\n\n# 인간은 영감을 받을 수 있습니다. 왜 기계는 영감을 받지 못할까요?\n\n또는 이와 비슷하게, \"인간은 시간을 들여 배우지만, 컴퓨터도 훈련해야 합니다.\" 인간은 권리를 갖지만, 컴퓨터는 그렇지 않습니다. 인간은 감각을 가지지만, 컴퓨터는 그렇지 않습니다.\n\n전자는 우리가 인간 개인의 권리를 배타적으로 보호하고 있다는 것을 시사하며, 후자는 \"영감\"이 감각이 필요하기 때문에 불가능하다고 말합니다. 컴퓨터는 복사를 하며, 자동적이고 근사하게 복제합니다. 심지어 AI가 성취적이라고 주장해도 권리를 자동적으로 요구하지는 않습니다.\n\n<div class=\"content-ad\"></div>\n\n우리는 (너무) 천천히 동물(알다시피 감각이 있는 존재들)이 권리를 가져야 한다는 생각을 처리하고 있습니다. 세기가 걸리는 과정입니다. 우리가 우리의 가장 가까운 유전적 선조들의 권리를 명확히하길 시도하기 전에, 우리 스스로의 의식을 효과적으로 흉내 내는 인공지능이 감각이 없을 가능성이 더 크고 권리를 갖는 존재로 폭격받는 것을 기대할 수 없습니다.\n\n그렇지 않다고 주장하면 인간 경험이 중심이 아닌 우리가 만든 비생명적 물체 중심인 법과 윤리적 체계가 둘러싸고 있는 사회에서 자기 자신을 분리시키는 것입니다.\n\n이 입장에 대해 훌륭하고 솔직한 설명을 보고 싶다면, 아래 비디오를 확인하세요:\n\n# Happy Me\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-MyResponsetoOpenSourceCreativeGenerativeAI_1.png)\n\n# 표현의 한계가 없어진다\n\n생성적 AI의 한 가지 장점은 우리가 창작 능력을 증진시키는 데 도움을 줄 수 있다는 점입니다. AI를 활용하면 우리는 쉽게 텍스트나 이미지를 생성하여 창작 작업의 영감이나 시작점으로 활용할 수 있습니다.\n\n예를 들어, 작가는 GPT-3를 사용하여 기사의 개요나 초고를 생성한 뒤 그것을 보완하고 발전시킬 수 있습니다. 마찬가지로, 예술가는 DALL-E를 사용하여 자신의 작품에 영감을 주는 이미지를 생성할 수 있습니다. 이처럼, 창작적인 시기에 갇히는 것이 아니라 자동으로 제안을 생성할 수 있습니다. 마찬가지로, 컴퓨터 코드를 작성하거나 알고리즘을 개발하는 것에도 동일하게 적용됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n더 근본적으로, 우리는 “생성기(generator)”를 마음의 표현 추정기로 다룰 수 있습니다. 우리는 아이디어를 간결하게 표현하는 방법을 배워야 합니다. 그렇게 하면 표현 추정기가 우리의 아이디어를 정확하게 파악할 수 있습니다. 그러나 여전히 생성기가 제공하는 형태로 제한됩니다: 이미지, 텍스트, 소리, 비디오 및 3D 렌더링.\n\n# 폐쇄 소스보다 더 나은 오픈 소스!\n\nHuggingface와 같은 오픈 소스 플랫폼은 gAI 애플리케이션의 방향을 “민주화”시키고 대규모 중앙 집중형 업체에 의한 남용을 방지하는 데 도움이 됩니다.\n\n다양한 형태 쌍의 API를 사용합니다. 예를 들어, 개발자들은 텍스트에서 이미지로, 이미지에서 텍스트로, 텍스트에서 음성으로, 음성에서 텍스트로 간단하게 복잡하고 의미 있는 기능을 만들 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nAPI의 높은 수준을 고려하면 사용 예제를 쉽게 만들 수 있어서, 즉, 그렇게 말하는 견고함, 즉 진입 장벽이 낮아져서 리소스가 제한된 개발자도 창작물을 개발하고 수익을 창출할 수 있습니다. 생산적 AI를 기반으로 한 정보 검색 응용 프로그램 개발을 위한 일반적인 경로는 다음과 같습니다:\n\n- 음성 명령을 텍스트로 변환하기 (Whisper)\n- 구조화된 호출/API 명령 추출하기 (ChatGPT)\n- 명령을 정보 추출을 위한 외부 API 엔드포인트로 POST하기\n- 구조화된 정보/요약 추출하기 (ChatGPT), 그리고 시각화로 계속 진행하기\n- 오디오 프레젠테이션 추출하기 (VALL-E) 또는 다른 방식들 및 데이터베이스 내 구조화된 정보 흡수하기\n\n이러한 단계 중 하나의 기본 복잡성은 상당하며 소프트웨어 개발에 대한 상당한 지식이 필요하지만 API들의 조합을 사용하면 작은 스크립트를 통해 API 호출을 묶어 작동하는 응용 프로그램을 만들 수 있습니다.\n\n논란의 여지가 있는 것은 경제적 권력을 Microsoft, Amazon, Google과 같은 소수의 대규모 API 플랫폼 및 클라우드 제공업체 방향으로 옮기고 있다는 것입니다. 그러나 이러한 상대적으로 소수의 플랫폼에 대한 의존은 모델 압축 및 도메인별 모델의 크기 축소로 경감될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 이제 우리는 모두 창조자입니다\n\ngAI의 맥락에서 \"민주화\"라는 용어를 사용하는 것을 한탄하더라도, 높은 미적 이미지 및 곧 비디오, 게임, 대화형 이야기 등을 만드는 진입 장벽이 낮아졌다는 것은 우리가 억압했던 잠재적 창의성을 발휘할 수 있다는 것을 말할 수 있습니다. 수용 가능한 수준에 도달하는 것이 많은 노력과 시간이 걸리는데, gAI는 이를 크게 줄여줍니다.\n\n# 물리적 예술에 영향을 미치지 않습니다\n\n현대화된 예술관을 방문한 적이 있는 사람이라면 컴퓨터 화면 상의 2차원 표현과 인간이 만든 물리적 물체로 둘러싸인 것 사이의 차이를 알 것입니다. 창조적 예술은 이 경험을 훼손시키지 않을 것입니다. 많은 경우, \"경험자\"는 해당 물체가 처음부터 어떻게 만들어졌는지 전혀 모릅니다.\n\n<div class=\"content-ad\"></div>\n\n동일한 관점은 음악(라이브 음악), 시(슬램 시), 연극, 코미디 등에도 적용할 수 있습니다. 물론, 물리적 경험이라고 할 수 있는 이러한 경험들도 가상 현실과 모든 종류의 햅틱 피드백을 사용하여 모방할 수 있다고 말할 수 있지만, 그럴 때가 오면 볼 것입니다.\n\n# 일반적으로 생성적 AI 연구 및 개발 촉진\n\n응용 데이터 과학의 매우 중요한 주제는 원본 데이터를 흉내 내는 진정한 데이터 생성 프로세스에 의해 생성된 합성 데이터입니다. 이 기술은 건강 관리와 같은 민감한 도메인에 적용된 기계 학습을 가속화하는 것을 약속합니다.\n\n최근 예로 확산 모델을 사용하여 합성 단백질 및 합성 MRI 영상을 생성한 사례가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n오픈 소스 gAI 기술의 광범위한 사용으로 인해 모델 압축 개발과 전반적인 계산 요구량 감소로 이어지는 부산물이 발생하고 있습니다.\n\n# 어떤 데이터셋에서도 의미론적 상호 작용 검색\n\n키워드 기반, BM25 또는 정적 벡터 기반 검색 대신에, 우리는 원시 비구조화 데이터를 잘 담은 모델과 직관적으로 상호 작용할 수 있습니다. 예를 들어, 상식과 사실적 정확성을 확보하기 위해 상징주의와 연결주의를 혼합하고 모델을 지식베이스에 결합함으로써 이를 달성할 수 있습니다.\n\n비구조화 데이터를 다루는 비즈니스와 정보 검색에 큰 중점을 둔 법률 사무소 및 특허청과 같은 조직에 이것이 어떤 영향을 미칠지 상상하기 어렵습니다. 동시에 정보기관 및 기타 정부 기관이 시민을 더 쉽게 모니터링할 수 있게 될 것입니다. 이것으로부터 gAI 모델의 고도로 믿을만한 응답이 필요함을 강조해야 합니다. 즉, 우리는 사실의 환각을 허용할 여지가 없습니다 (적어도 모든 영역에서는).\n\n<div class=\"content-ad\"></div>\n\n가장 깊이 있는 응용 프로그램은 대규모 과학 산업체로부터 의미 첨삭 정보를 검색하는 것입니다. 우리가 이미 존재하는 사실과 이론에 LLM을 기반으로 하고 의미 첨삭 사용자 쿼리에 기초하여 대량의 정보를 합성하고 조작하는 능력을 유지한다면, 어떤 전문가든지 손끝에서 인간 지식의 현재 상태를 가질 수 있게 됩니다.\n\n그러한 도구는 시민들이 사회적으로 중요한 문제에 대한 사실적이고 객관적인 정보를 얻을 수 있는 것을 가능하게 할 수 있습니다. 창의적인 작업자들을 위한 경제적 현실의 변화는 그러한 장점을 위해 상대적으로 작은 대가라고 생각될 것입니다.\n\n# 성 착취의 감소\n\n솔직히 말하면, 생성적 예술의 주요 사용 사례 중 하나는 누드 이미지나 심지어 음란물을 만드는 것입니다. 누군가에게는 왜곡된 것이 될 수도 있지만, 이것은 실제 인간의 개입 필요를 줄이고 성적 착취를 감소시킨다. 몇 년 안에 스크립트로 만들어진 애니메이션 음란물이 현실이 될 것으로 예상됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n창의적인 인공 지능을 지원하는 것에는 명확한 장단점이 있습니다. 이를 통해 가장 중요한 것은 적용된 인공 지능의 개발을 사회적 요구와 규범에 바탕을 두어야 한다는 점입니다. \"실리콘밸리\"에서 만들어진 것이 무엇이든 우리 문화와 정체성에 매듭을 맞추지 않으면 사회적으로 불필요한 피해를 줄 것입니다.","ogImage":{"url":"/assets/img/2024-06-19-MyResponsetoOpenSourceCreativeGenerativeAI_0.png"},"coverImage":"/assets/img/2024-06-19-MyResponsetoOpenSourceCreativeGenerativeAI_0.png","tag":["Tech"],"readingTime":14},{"title":"아트비Artvy와 함께 창의력을 발휘해보세요 - AI 아트의 창문","description":"","date":"2024-06-19 21:07","slug":"2024-06-19-UnleashyourcreativitywithArtvyYourGatewaytoAIArt","content":"\n\nLois van Baarle의 매혹적인 스타일에서 영감을 받은 생동감 넘치고 감정적인 예술의 세계로 뛰어들 준비가 되셨나요? Artvy라는 무료 AI 예술 플랫폼을 더 찾을 필요가 없어요. Artvy를 통해 Lois의 생생한 색채와 표현력 있는 캐릭터로 가득한 작품을 만들어 보세요. Artvy를 통해 AI 예술의 매력을 발견하고 어떠한 경험 없이도 AI 예술 커뮤니티에 참여할 수 있어요!\n\nArtvy는 안정된 확산 및 중간 알고리즘을 통해 AI 생성 작품의 경이로움을 탐험할 수 있는 독특한 기회를 제공합니다. 오늘 바로 artvy.ai에서 알고리즘 예술 세계를 받아들이고 무료 AI 예술 생성기를 통해 당신의 내면 작가를 발휘해보세요.\n\n하지만 여기서 멈추지 마세요—Artvy는 멋진 AI 예술을 만들기 위한 도구를 제공하는 동시에 Lois van Baarle과 같은 실제 작가의 작품을 탐험해 영감을 받으라고 격려합니다. 실제 작가들의 예술 속 심오함과 감정을 발견하고, 그들의 창의성이 당신의 예술적 여정을 촉진하게 해주세요.\n\n그럼 어서 무엇을 기다리고 있나요? Artvy와 함께 오늘부터 AI 예술 세계로의 여행을 시작하고, 알고리즘 예술의 아름다움을 이전보다 더 경험해보세요. artvy.ai에서 함께해 당신의 창의력이 날아오를 수 있도록 해요!\n\n<div class=\"content-ad\"></div>\n\n\n![Artvy](/assets/img/2024-06-19-UnleashyourcreativitywithArtvyYourGatewaytoAIArt_0.png)\n\nExplore More:\n\n- [Artvy Homepage](https://www.artvy.com)\n- [Artvy AI Art Style — Loish](Link to Loish article)\n- [DeepArtio Website](https://www.deepartio.com)\n- Join the AI Art Community\n","ogImage":{"url":"/assets/img/2024-06-19-UnleashyourcreativitywithArtvyYourGatewaytoAIArt_0.png"},"coverImage":"/assets/img/2024-06-19-UnleashyourcreativitywithArtvyYourGatewaytoAIArt_0.png","tag":["Tech"],"readingTime":1},{"title":"마스터 미드조니의 새로운 개인화 기능","description":"","date":"2024-06-19 21:05","slug":"2024-06-19-MasterMidjourneysnewpersonalizationfeature","content":"\n\n# 매개변수 명령어: --p\n\n이 매개변수는 무엇을 의미할까요? Midjourney를 사용하여 이미지를 생성할 때 여러 매개변수가 일반적으로 사용됩니다.\n\n- --ar: 이는 이미지 비율을 나타냅니다. 예를 들어, 정사각형 이미지의 경우 1:1, 긴 이미지의 경우 4:3, 넓은 이미지의 경우 3:4로 나타낼 수 있습니다.\n- --v / --niji: 이는 모델 버전을 나타냅니다. 안정적인 확산과 달리 여러 다양한 모델을 가지는 것이 아니라, Midjourney는 V의 현실적인 버전과 Niji의 애니메이션 버전으로 나뉩니다. 다양한 모델 대신 Midjourney는 사이버펑크, 초현실주의, 중국 묵화, 일본 우키요에, 스케치와 같은 이미지 스타일을 제어하기 위해 스타일 프롬프트 또는 다른 예술가를 사용합니다.\n- --s: 이는 스타일 강도를 나타냅니다. --s를 사용하여 개인화 효과의 강도를 조절할 수 있습니다 (0부터 1000까지 범위, 1000이 최대값).\n\n전통적으로 이러한 매개변수는 출력물의 형태를 형성하는 데 도움이 되지만, 이들은 여전히 Midjourney의 \"기본 스타일\"에 영향을 받으며, 커뮤니티 트렌드에 영향을 받습니다. 이미지 참조와 스타일 일관성과 같은 매개변수가 있더라도, 스타일을 제어하는 능력은 안정적인 확산과 비교하여 제한되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n`--p` 매개변수 명령어를 입력하세요. 이 혁신은 Midjourney의 기본 스타일을 사용자의 취향으로 교체할 수 있게 해줍니다. 사용자의 취향을 학습하여 모델의 훈련 데이터로부터 편견을 줄이고 개인적인 스타일을 더 잘 반영할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_0.png)\n\n# 모델 개인화하는 방법\n\nLoRA와 유사하게 Stable Diffusion 안에서 Midjourney의 개인화는 사용자의 취향에 맞게 모델을 훈련시키기 위해 초기 설정이 필요합니다. 다음은 그 방법입니다:`\n\n<div class=\"content-ad\"></div>\n\n1️⃣ Midjourney 웹 사이트에 방문해주세요: Midjourney 웹 사이트를 방문해주세요.\n\n2️⃣ 할 일 목록으로 이동: 왼쪽에 있는 \"Tasks\" 버튼을 클릭해주세요.\n\n![Tasks](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_1.png)\n\n3️⃣ 이미지 순위 매기기: 왼쪽에서 \"이미지 순위 매기기\"를 선택해주세요.\n\n<div class=\"content-ad\"></div>\n\n![마스터미드 새로운 개인화 기능](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_2.png)\n\n4️⃣ 좋아하는 것 선택하기: 시스템이 다양한 이미지를 제시합니다. 원하는 이미지를 클릭하여 선택하세요. 마우스를 사용하거나, 좋아요는 1번, 싫어요는 2번, 확실하지 않다면 건너뛰기는 3번을 누를 수 있어요.\n\n![마스터미드 새로운 개인화 기능](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_3.png)\n\n5️⃣ 최소 200개의 이미지 그룹 선택: 필요한 선택 수에 도달하면 대화상자가 완료를 확인합니다. 때로는 시스템이 선택 동작을 확인하여 초록색 O 또는 빨간 ❌이 나타날 수 있어요. 반드시 초록색 O를 선택하세요.\n\n<div class=\"content-ad\"></div>\n\n6️⃣ 완료 확인: 개인화된 스타일 모델의 완료를 확인하려면 디스코드에서 명령어 /info를 입력하세요.\n\n![Image](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_4.png)\n\n# 사용 방법 --p\n\n개인화된 스타일을 적용하려면 프롬프트의 끝에 --p를 추가하세요.\n\n<div class=\"content-ad\"></div>\n\n예를 들어:\n\n결과는 다음과 같이 나타납니다:\n\n<img src=\"/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_5.png\" />\n\n프롬프트 뒤에 --p를 추가하면 자동으로 변환됩니다.\n\n<div class=\"content-ad\"></div>\n\n이러한 효과가 발생할 것입니다:\n\n![image](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_6.png)\n\n개인화를 활성화하면 프롬프트에 숏코드가 추가되어 공유 가능하며, 다른 사람들이 당신의 개인화된 모델을 사용할 수 있게 됩니다. 스타일은 순위가 매겨진 이미지의 수에 따라 동적으로 발전합니다.\n\n-s를 사용하여 개인화 효과의 강도를 조절할 수 있습니다 (0은 끄고, 1000은 최대이며, 100은 기본값입니다).\n\n<div class=\"content-ad\"></div>\n\n예를 들어:\n\n![image1](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_7.png)\n\n![image2](/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_8.png)\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n중간여정의 새로운 맞춤화 기능에 감격받았어요. 각자의 특별한 취향을 가지고 있기 때문에, 이는 이미지 스타일의 폭이 넓어지고 생성된 이미지의 다양성이 커지는 것을 의미해요.\n\n지금 바로 당신이 선호하는 이미지들을 순위를 매겨보고, 맞춤화의 힘을 탐험하며, AI 창작의 끝없는 가능성을 체험해보세요.\n\n```js\r\n참고:\n공식 계정: 阿杰AI绘画\n공식 계정: 葉子说AI绘画\r\n```\n\n💡더 깊이 파고들고 싶나요? 제 중간여정 컬렉션이 여러분을 기다리고 있어요.\n\n<div class=\"content-ad\"></div>\n\n## 이 기사를 좋아하셨나요?\n\n그렇다면:\n\n- 댓글 남기기\n- 업데이트 팔로우하기\n- 무료 이메일 알림","ogImage":{"url":"/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_0.png"},"coverImage":"/assets/img/2024-06-19-MasterMidjourneysnewpersonalizationfeature_0.png","tag":["Tech"],"readingTime":4},{"title":"인간과 인공지능 세 가지 미래","description":"","date":"2024-06-19 21:03","slug":"2024-06-19-HumansandAIThreeFutures","content":"\n\n![2024-06-19-HumansandAIThreeFutures_0.png](/assets/img/2024-06-19-HumansandAIThreeFutures_0.png)\n\n안녕하세요, 새롭게 AI 전문가가 되신 여러분! 현재 모두가 ChatGPT와 다른 생성적 AI에 대해 들어봤을 것입니다. 개인적으로 제는 약 30년 전에 XR에 입문했는데, AI의 큰 도움을 받아 이야기를 전달하며 아마도 새로운 인터랙티브 3D 이야기(예: 홀로데크)를 만들어보고 싶었습니다. 그 동안에는 Second Life의 절차적 3D 객체 시스템과 원래의 Google Earth에서 스마트 지도 제작 업무에 참여했었죠. 하지만 사실 저는 AI 전문가라고는 부르지 않아요.\n\n무엇보다도, AI 전환의 윤리적 결과에 대해 심각하게 고민해 왔습니다(예: 1993년의 풍자). AI의 발전이 이렇게 빠르게 진행되는 것을 보는 것은 흥미롭기도 하지만 약간 무서워하기도 합니다. 이 기사에서는 더 많은 맥락을 제공하고, 보통처럼 혹은 기존에 알려지지 않은 일부 큰 동향과 작은 동향을 소개하겠습니다. 여러분에게 미래에 대한 전망과 만나야 할 선택을 제공할 것입니다.\n\n## 과거\n\n<div class=\"content-ad\"></div>\n\n1800년대 사진술이 처음 소개될 당시에 우리는 레코드된 이미지에 대한 첫 경험이 오리지널 손으로 만들어진 매체에서 왔습니다. 사진에 대한 반응은 흥분부터 분개, 심지어 이 장치들이 우리 영혼을 훔치고 있다는 두려움까지 다양했습니다. 그것은 불가능한 것 같지만, 우리는 과도한 미디어 노출이 실제로 인간들이 고통을 겪을 수 있다는 것을 관찰합니다(예: 프라이버시 상실, 틴 아이돌, 인스타그램 등). 우리는 누구든 무단으로 사진을 찍고 공유하는 것이 괜찮다고 생각하는 세상에서 살고 있습니다. 그래서 우리는 최소한 개인적인 권력의 일부를 잃은 것 같습니다.\n\n일자리에 대해서는, 사진술이 아마도 회화나 드로잉 일자리보다 전반적으로 더 많은 일자리를 창출해왔다고 말할 수 있습니다. 그리고 디지털 사진술은 더욱 그렇습니다. 그러나 새로운 기술은 종종 사람들을 예전 형태의 일자리에서 해고시키기도 합니다. 제 개인적인 경험으로는, 실시간 3D 지도가 카토그래피 분야를 대부분 자동화시켰습니다. 그리고 90년대에 VR 작업을 할 때, 나는 열심히 자신들을 3D 애니메이터로 재탄생시키기 위해 노력하던 클래식 디즈니 \"셀\" 애니메이터들과 함께 일했습니다.\n\n오늘날 예술가들로부터 이 최신 생성적 AI 시스템들이 몇 년이 걸린 스타일과 콘텐츠를 복사하여 그들의 생계를 훔치고 있다는 우려를 듣습니다. 그들은 옳은 면도 있지만, 내 의견으로는 틀렸습니다. 그러나 이것은 더 큰 그림의 일부일 뿐입니다.\n\n## 현재\n\n<div class=\"content-ad\"></div>\n\n생성 AI 회사들은 수백만 장의 이미지와 문서(많은 경우 저작권이 있는)를 긁어와서 새로운 이미지를 만드는 자동화를 더 잘할 수 있도록 합니다. OpenAI의 DALL-E2나 GPT3, 그리고 Stable Diffusion과 같은 시스템들은 대량의 인간의 창의적 결과물을 효과적으로 소화하여 우리가 보고 싶은 다음 것을 설명하는 \"프롬프트\"를 섞고 매칭할 수 있는 모델을 만들어 냅니다. 결과물이 진실하거나 공정하거나 합법적이라는 뜻은 아니지만, 외관상으로는 놀랍게도 \"인간적\"입니다. 이제 이 법적 문제는 여러 소송의 주제가 되었습니다 (변호사가 아님을 밝힙니다):\n\n작가들을 대표하는 변호사들은, 저작권이 있는 작품들이 파생 작품에 사용된다면, 작품들이 모델에 명백히 나타나지 않거나 결과물에 나타나지 않거나 수익이 발생하지 않는 경우에도 지적 재산권 도용이 명백하다고 주장할 것입니다. 공평하게 물어보죠: 만약 이러한 원본 작품들이 고품질 결과를 얻기 위해 중요하지 않다면, 왜 그러한 모델을 훈련하는 데 사용하는 걸까요? 분명히 그것들은 중요합니다. 그러면 왜 허락을 구하고 적절한 경우에 작품에 대한 인정과 일정한 수입 분할을 해주지 않는 건가요?\n\nStable Diffusion은 아티스트들이 적어도 선택적으로 거부할 수 있도록 하는 작업을 진행 중이라고 보도되었습니다. 그러나, 그것만으로는 부족합니다.\n\n이제, AI 회사를 대표하는 변호사들은 이 콘텐츠의 혼합이 \"합리적 사용\"이며 결과물이 \"변형적\"이라는 주장을 할 것으로 예상됩니다 — 직접적인 복사본이 아니며 이전 작품들의 혼합물에서 새로운 아이디어를 대표한다는 것입니다. 합리적 사용은 우리가 비평이나 학습과 같은 특정 목적을 위해 저작권이 있는 작품을 재생산할 수 있게 합니다. 그러나 AI 모델이 소스 이미지를 문자 그대로 저장하지 않는다는 아이디어는 나의 견해로는 약하다고 생각합니다, 왜냐하면 압축된 JPEG는 결코 그 이미지의 비트를 문자 그대로 저장하지 않으면서도 원본 이미지를 절차적으로 근사할 수 있기 때문입니다. 파일 크기를 줄이는 것이 목적입니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 더 깊은 것이 벌어지고 있어요. \n\n많은 사람들의 작업을 가져와 그를 기반으로 새로운 작품을 출력하는 것은 마치 창조자들 자체가 섞이는 것과 같아요. 적어도 그들의 기술이 그대로 옮겨지는 것이죠. 이는 단순한 사람들과 몇 줄의 코드로 이루어진 새로운 초인간 엔티티를 형성하는 것과 같아요. 어느 의미에서는 기업, 스포츠 팀 또는 음악 앙상블도 개개인이 그들의 부분을 수행하여 (그들의 허락과 종종 보상과 함께) 혼자서는 할 수 없는 일을 넘어서는 단순한 인간으로 이루어진 초인간 엔티티인 것이기도 합니다.\n\n나는 오랫동안 게임을 바꾸는 기술(예: AI와 AR)은 우리에게 새로운 초능력을 부여하는 것이라고 주장해 왔어요. 이것은 우리 모두가 레벨업 해야 한다는 측면에서 넓고 공평하게 해야 해요. 초기 채택자들 중 소수만 이용력을 극대화 한다면 우리의 위험에 처할 수 있어요 (Google Glass가 한 예에요).\n\n그래서 여기서의 집단적 이익은 무엇일까요? 생성적 AI는 모든 사람에게 자신의 기술을 훨씬 초월한 예술을 만들 수 있는 능력을 부여할 수 있어요. 기본적으로, 우리는 저렴한 비용으로 여러 예술가들의 결합된 능력을 이용할 수 있답니다. 그래서 우리는 그들을 지원해야 한답니다.\n\n<div class=\"content-ad\"></div>\n\n## 미래 (근시일 내)\n\n이 AI를 사용하는 예술가들도 생산성을 높일 수 있을 거예요. 그리고 사진술과 지도 제작과 같이, 전체 시장이 성장하고 더 많은 사람들에게 권한을 부여하는 희망이 있어요. 비록 일부 사람들은 일하는 방식을 바꿔야 할지라도요.\n\n똑똑한 누군가는 내 전문 분야(프로그래밍, UX)도 자동화되고 있다는 점을 지적할 수 있을 거예요. 이걸로 간단히 처리해봐!\n\n심지어 ChatGPT도 코드를 작성할 수 있어요, 하지만 신뢰성은 보장 못 해요 (디버깅할 때 더 잘 도와줘). 신기하게도, 프로그래머들 중 일자리 자동화를 두려워하지 않는 사람들이 있어요. 이유가 뭘까요? 이미 우리는 하고 싶지 않은 일을 자동화하기 위해 코드를 작성하고 있기 때문이에요, 이는 종종 우리의 자리를 자체적으로 불필요하게 만드는 방법일 뿐이에요.\n\n<div class=\"content-ad\"></div>\n\n컴퓨터에게 원하는 것을 솔직하게 영어로 말하는 것이 정말 기쁠 거예요. 저의 능력은 코드를 작성하는 것뿐만 아니라 문제를 이해하고 효과적인 해결책을 시험하고 평가하는 데 있어요. 안타깝게도, 그 뛰어난 능력도 언젠가는 자동화될 거예요. 하지만 그것은 얼마 지나지 않고 일어나지 않을 거예요. 왜냐하면 우리가 어떻게 생각하고 세상이 어떻게 작용하는지에 대한 더 깊은 지식이 필요하기 때문이에요. 그리고 그때도 저는 적응할 거예요.\n\n생각해보세요: VR은 이미 우리를 새로운 직업에 대비하고 이러한 변화에 발맞춰 새로운 기술을 습득하는 데 효과적임이 입증되었어요. 하지만 숨겨진 함정이 있어요. VR 훈련 중 수집된 인간의 성과와 결정 데이터는 미래 AI를 훈련하는 데에도 활용될 수 있어요. 물리적 형태가 없는 \"메타버스\"의 직업은 특히 AI에 대해 훈련 가능해서 아바타가 있든 없든 말이에요.\n\n일이 더 반복 가능하고 설명 가능하며 비물리적일수록 이것이 더 쉬워질 거예요. 모든 수동 노동 직업이 로봇에게 밀려날 것이라고 이야기하는 것은 아니에요. 이곳에서 진정한 패배자는 로봇공학자가 아니라 매니저, CFO, CEO, 변호사, 그리고 주식 중개인들일 거예요. 자신들의 일이 점점 더 자동화에 의해 지원받는 것을 더 많이 느끼게 될 거예요. 소프트웨어가 하드웨어보다 빠르게 확장되고 그들의 수입은 풍족할 거예요. 조직 리더십보다 더 반복 가능하고 비물리적인 일이 있을까요?\n\n## (멀리 있는) 미래\n\n<div class=\"content-ad\"></div>\n\n5, 10, 심지어 50년 후, AI가 일부 공상과학 영화처럼 인간을 대신할까요?\n\n먼저, 슈퍼 휴먼 AI조차도 정식으로 인간 대신 하거나 물러나지 않을 확률은 낮습니다. 우리가 그것에게 요청하지 않는 한. AI가 미국에서 \"법적 인격체\"로 간주되어 시민권을 요구하려면 몇 가지의 공동 기업을 출원하면 됩니다. 남부 퍼시픽 철도회사와 시민 단위와 같은 판결은 대부분의 사람보다 더 나은 권리를 획득하는 것에 대해 우리에게 어떤 것을 말해줍니다. 불행하게도 혹은 탐욕스러운 놈이 첫 번째 AI가 자체를 법인으로 구성하도록 도와주게 될 것이고, 자체 은행 계좌를 열고 다른 인간과 AI를 고용하여 작업을 수행하게 될 것입니다. 사주자는 AI 자체가 될 뿐입니다. 처음에는 인간이 이사회에 앉아야 합니다.\n\n하지만 여기서부터 AI들은 정말 많은 영역에서 활약할 수 있습니다. 왜 우리를 죽일까요? 우리가 위협요소가 없기 때문에요! 우리는 고객입니다!\n\n우리가 기술에 통제를 양보하는 방법으로 GPS를 생각해보세요. 처음에는 가끔 좌우되는 도움으로 사용했었죠. 그런 다음 우리는 의심하지 않는 입력으로 사용했고요. 독일 한 남자가 나쁜 내비게이션 데이터 덕분에 여자친구의 항의에도 불구하고 강을 헤엄쳐 가던 일도 있었습니다. 이제 GPS는 매우 훌륭해졌고 우리는 그것에 매우 의존하기 때문에 그 없이는 모두 길을 잃을 것입니다. (제가 개인적으로 GPS에 도전을 즐깁니다)\n\n<div class=\"content-ad\"></div>\n\nAI도 마찬가지입니다. 우리는 천천히 그것을 너무 많이 사용해서 의존하게 될 것입니다. 그리고 그러고 나면 여기저기에서 AI에게 책임을 맡기고 무엇을 해야 하는지 말할 것입니다. 변화의 속도를 늦추는 것은 전반적으로 좋은 일이며, 우리에게 조절하고 사고를 재편할 시간을 제공합니다.\n\n둘째, 자동화의 최상의 결과는, 가까운 장래에, 예술가와 프로그래머 등이 이전보다 더 많은 것을 더 작업량, 시간 또는 비용을 들여 하기 위해 이러한 AI 도구를 사용하여 \"더 높은 수준으로 이동\"할 것이라는 것입니다. 그러나 수요는 더 높아져야 합니다. 전반적으로, 우리는 더 많은 예술 작품, 더 많은 영화, 더 많은 프로그램을 총동원할 것입니다. 이것은 또한 AI에 대한 필요성을 더 큰 소음의 바다에서 가치를 찾는 방향으로 이동시킵니다.\n\n더 높은 수준의 목표는 항상 모든 분야에 의미 있는 작업을 더 추가하고 근로 작업을 줄이는 것입니다. AI가 의미 있는 작업을 제거하거나 그 가치를 감소시킨다면, 우리는 이를 올바로 거부해야 합니다. 결국, 우리는 자원이 풍부한 스타 트렉 이상의 이상적인 세계에 도달할 수 있을지도 모릅니다. 여기서 우리는 선택한 가장 의미 있는 활동에 시간을 보내는 훨씬 더 해방된 미래를 만들어 나갈 것이라고 생각합니다.\n\n그래서 'A 그룹'을 계속해서 점점 더 나은 기술 + AI를 활용하여 더 높은 목표를 달성하는 '개별주의자'로 레이블링해보겠습니다. 이런 사람들을 상징적인 산을 영원히 오르는 사람들로 상상해볼 수 있습니다. 이들은 매 툴을 사용하여 꼭대기에 머무르고 자신들이 똑똑하고 책임 있는지 말해주는 모델입니다. 오늘날 기업 내부에서 크게 퍼져있는 모델이죠: 사업을 오르락내리락하며 당신의 관리 능력과 지지자를 얼마나 잘 확장할 수 있는지에 따라사다리를 올라가세요.\n\n<div class=\"content-ad\"></div>\n\n그룹 B는 인간들이 자원을 모아 기업, 스포츠 팀 및 오케스트라와 같이 더 복잡한 조직을 만드는 오랜 전통을 따릅니다. 이들은 \"집단주의자\"입니다. 각자 조직 내에서 개인이지만, 다른 역할이 있습니다. 또한 조직에는 일정한 내부 구조가 있습니다. 그러나 외부에서 보면 하나의 단일 단위로 보입니다.\n\n인공지능은 이러한 그룹 내의 어떤 위치에서든 존재할 수 있으며, 최고위에 있는 사람들에게 지시를 내릴 수도 있습니다. 우리는 인공지능이 조직 관리에 중요할 것이고, 인공지능은 심지어 자체 기업일 수 있으며, 목표를 달성하기 위해 필요한 만큼 인간과 다른 인공지능을 고용할 수 있습니다.\n\n이로 인해 인간과 인공지능이 더 구체적인 디지털 유기체로 융합하고, 아마도 이 기초 현실에서 완전히 디지털 현실로 나아가는 추측적인 미래가 나타납니다. 오늘날, 우리는 이 아이디어를 \"메타버스\"라고 부릅니다. (농담이에요...?)\n\n물론 그룹 C는 \"퇴보주의자\"입니다. 우리는 역사의 유명한 류딧과 파괴자들을 회상합니다. 그리고 우리는 오늘날 일하는 다양한 종교-파시스트들을 올바르게 두렵게 여깁니다. 이들은 지식을 다시 판도라의 상자 안에 넣으려고 혼란과 고통을 일으킬 수 있습니다. 하지만 이것은 우리의 집단 기억과 사유하는 자유를 지우는 것으로만 참을 수 있습니다. 퇴보주의자들이 일시적으로 승리할 수는 있지만 역시 매우 불가능합니다. 또한 퇴보주의자들은 매우 쉽게 조종될 수 있습니다. 그래서 어떠한 강력한 인공지능도 이들을 자기 고립이나 자멸로 이끌 수 있을 것으로 생각됩니다.\n\n<div class=\"content-ad\"></div>\n\n이 모든 것이 완전히 새로운 것은 아닙니다. 트렌드는 수 천 년 동안 천천히 진행되어 왔고, 이제는 더 빠르게 발전하고 있습니다. 인공 지능은 우리 자신을 위해 구축한 도구일 뿐입니다. 하지만 사람들은 이 선택지들이 그들 앞에 다가오고 있음을 드디어 알게 되고 있습니다.\n\n그래서, 당신이 선택해야 한다면, 이 세 가지 그룹 중 어느 것을 당신의 집이라고 부를 것인가요? 아니면 아직 관찰하지 못한 다른 옵션이 있을까요?","ogImage":{"url":"/assets/img/2024-06-19-HumansandAIThreeFutures_0.png"},"coverImage":"/assets/img/2024-06-19-HumansandAIThreeFutures_0.png","tag":["Tech"],"readingTime":8},{"title":"안정적인 확산 모델 비교하기","description":"","date":"2024-06-19 21:01","slug":"2024-06-19-ComparingStableDiffusionModels","content":"\n\n안녕하세요! 저희의 오픈소스 텍스트-이미지 모델 'Stable Diffusion'은 Stability AI에서 출시되었고, 생성적 AI 분야를 혁신했습니다.\n\n2022년 첫 출시 이후 몇 년 동안 여러번의 반복과 개선이 이루어졌습니다.\n\n주요 릴리스에 대해 알아야 할 내용은 다음과 같습니다:\n\n\n| 버전 번호    | 릴리스 날짜     |\n|-------------|----------------|\n| 1.1         | 2022년 6월     |\n| 1.2         | 2022년 6월     |\n| 1.3         | 2022년 6월     |\n| 1.4         | 2022년 8월     |\n| 1.5         | 2022년 10월    |\n| 2.0         | 2022년 11월    |\n| 2.1         | 2022년 12월    |\n| XL 1.0      | 2023년 7월     |\n| XL Turbo    | 2023년 11월    |\n| Cascade     | 2024년 2월     |\n| 3.0         | 곧 출시 예정    |\n\n\n더 필요한 정보가 있거나 궁금한 점이 있으면 언제든지 물어주세요!\n\n<div class=\"content-ad\"></div>\n\n# Stable Diffusion 1.x 모델\n\nStable Diffusion 모델의 첫 번째 세대인 1.x 시리즈는 1.1, 1.2, 1.3, 1.4 및 1.5 버전을 포함합니다.\n\n이러한 모델은 512x512 픽셀의 해상도를 가지며 텍스트 조건부로 ViT-L/14 CLIP 모델을 사용합니다.\n\n1.x 모델은 총 8억 6000만 개의 매개변수를 가지고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 샘플 출력\n\n# 주요 사항\n\n- 해상도 (픽셀): 512x512\n- 모델 카드\n- 라이선스: Creative ML OpenRAIL-M — 상업적 및 비상업적 사용 가능\n\n이 모델을 사용하는 좋은 사례: 다양한 스타일과 주제를 생성합니다. 상대적으로 낮은 계산 요구 사항입니다.\n\n<div class=\"content-ad\"></div>\n\n이 모델의 부적절한 사용 사례: 약한 프롬프트 이해와 해결. 변형된 주제. 평평해 보이는 이미지.\n\n## 세밀하게 조정된 모델\n\n알고 보면 Stable Diffusion 1.5가 그리 좋아 보이지 않는 결과물을 제공하지만, 오픈 소스 커뮤니티에는 훨씬 뛰어난 모델이 많이 있습니다.\n\n포토 리얼리즘, 만화, 애니메이션 이미지 등을 포함한 수천 가지 특정 사용 사례에 대한 모델이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n예를 들어, DreamShaper, Juggernaut 및 RealCartoon은 안정적 확산 1.5를 기본 모델로 사용하지만 놀라운 결과를 제공하는 몇 가지 모델 중의 몇 가지입니다:\n\n## 안정적 확산 2.x 모델\n\n2022년 말에 출시된 2.x 시리즈에는 2.0 및 2.1 버전이 포함됩니다. 이러한 모델은 768x768 픽셀의 해상도를 갖추고, ViT-H/14라는 다른 CLIP 모델을 사용하여 프롬프트를 더 표현적으로 만듭니다.\n\n2.x에서 사용된 다른 CLIP 모델로 인해 사람들이 1.x에서 마이그레이션하는 것이 어려워졌습니다. 사실 프롬프트가 그렇게 잘 전환되지 않아서 오픈 소스 커뮤니티에서의 널리 사용이 급격히 줄었습니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 텍스트를 친절한 한국어로 번역한 것입니다.\n\n이 모델들의 매개변수 개수는 GitHub Readme에 따르면 1.5억개로 동일합니다.\n\n# 샘플 출력\n\n# 주요 사항\n\n- 해상도 (픽셀): 768x768\n- 모델 카드\n- 라이선스: CreativeML Open RAIL++-M — 상업적 및 비상업적 사용\n\n<div class=\"content-ad\"></div>\n\n이 모델의 좋은 사용 사례: 1.x 모델과 비교하여 더 높은 해상도의 출력물. 복잡하고 표현력이 풍부한 프롬프트를 효율적으로 처리. 사람보다는 건축물과 풍경 소재에 대한 성능이 뛰어남. 다양한 색상의 동적 범위를 제공함.\n\n이 모델의 부적합한 사용 사례: 세대에 제약이 많음. 유명인과 미술 양식에 대한 검열이 있음.\n\n# 세분화된 모델\n\n안정적인 확산 2.0 및 2.1은 오픈 소스 커뮤니티에서 1.5만큼 널리 채택되지 않았습니다. 그러나 세분화된 모델은 일부 존재합니다.\n\n<div class=\"content-ad\"></div>\n\n# Stable Diffusion XL 1.0\n\n2023년에 출시된 SDXL 1.0은 중간단계와 Dall-E 수준의 결과물을 소비자용 하드웨어에서 실행할 수 있습니다. 1024x1024 픽셀의 해상도를 제공하며 텍스트 조건부로 OpenCLIP-ViT/G 및 CLIP-ViT/L을 활용하는 SDXL을 통해 원하는 결과를 훨씬 쉽게 얻을 수 있습니다.\n\n초기 출시인 Stability AI의 SDXL 1.0은 35억 개의 기본 모델 파라미터와 66억 개의 모델 앙상블 파이프라인을 갖추고 있습니다:\n\n![Stable Diffusion Models](/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png)\n\n<div class=\"content-ad\"></div>\n\n# 샘플 출력\n\n# 주요 사항\n\n- 해상도 (픽셀): 1024x1024\n- 모델 카드  \n- 라이선스: CreativeML Open RAIL++-M 라이선스 — 상업적 및 비상업적 사용 가능\n\n이 모델의 좋은 사용 사례: 안정적인 확산 모델 중에서 가장 높은 해상도 출력. 개선된 색상 깊이, 구성, 전체 이미지 품질. 복잡한 프롬프트와 개념의 이해가 더 좋아짐.\n\n<div class=\"content-ad\"></div>\n\n이 모델의 적합하지 않은 사용 사례: 로컬에서 실행하려면 상당한 계산 자원이 필요합니다. 소비자급 하드웨어에서 실행하기 어려울 수도 있습니다. 손과 같은 것들은 아직 완벽하지 않을 수 있습니다.\n\n# 세밀하게 조정된 모델\n\n오픈 소스 커뮤니티는 SDXL을 환영하고 SDXL로 품질 높은 출력물을 생산하는 몇 가지 세밀하게 조정된 모델을 출시했습니다.\n\nJuggernaut XL, DreamShaper XL, RealVisXL, Animagine XL 등이 인기가 많으며 다양한 사용 사례를 제공할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n# SDXL Turbo\n\nSDXL Turbo은 SD XL 1.0의 간추린 버전으로, 512x512 픽셀 이미지를 빠르게 생성하기 위해 설계되었습니다. SD XL 1.0과 동일한 텍스트 조건 모델을 사용하며 35억 개의 매개변수를 갖고 있습니다. SDXL Turbo는 단 한 단계만으로 이미지를 생성할 수 있습니다.\n\n# 샘플 출력\n\n# 주요 사실:\n\n<div class=\"content-ad\"></div>\n\n- 해상도 (픽셀): 512x512\n- 모델 카드\n- 라이선스: 비상용 소프트웨어 — 비상업적 사용만 가능\n\n**이 모델을 잘 활용할 수 있는 경우:** 짧은 시간 안에 좋은 결과물을 제공합니다. 프로토타입 애플리케이션 및 워크플로에 유용합니다. 실시간 실험에 적합합니다.\n\n**이 모델을 잘 활용하지 못하는 경우:** 비상업용 라이선스로 개인 및/또는 연구용으로만 사용이 가능합니다.\n\n# 세밀하게 조정된 모델\n\n<div class=\"content-ad\"></div>\n\n2.1처럼 SDXL Turbo의 오픈 소스 모델 생태계는 제한적입니다. 모델은 존재하지만, 대부분의 제작자들이 SDXL 및 SD 1.5와 같이 더 인기 있는 기본 모델에 노력을 기울이고 있습니다.\n\n# Stable Cascade\n\nStable Cascade은 Würstchen 아키텍처를 사용하는 독특한 모델로, 더 효율적인 훈련 및 추론을 가능케 합니다. 3단계(C, B, A)로 작동하며, 압축 계수는 42입니다:\n\n![Stable Cascade](/assets/img/2024-06-19-ComparingStableDiffusionModels_1.png)\n\n<div class=\"content-ad\"></div>\n\nStages C (10억 또는 36억 개의 매개변수) 및 B (7억 또는 15억 개의 매개변수)은 상호 교환 가능하며 하드웨어 요구 사항 및/또는 제한에 따라 다양한 모델을 사용할 수 있습니다.\n\nSDXL Turbo와 마찬가지로 Stable Cascade은 연구용 모델입니다.\n\n## 샘플 출력\n\n## 주요 사실:\n\n<div class=\"content-ad\"></div>\n\n- 해상도 (픽셀): 1024x1024\n- 모델 카드\n- 라이선스: 소유권 제한 - 비상업적 사용만 허용\n\n이 모델의 좋은 사용 사례: SDXL 품질의 출력물과 더 나은 프롬프트 이해를 제공합니다. 사용된 모델에 따라 더 빠른 출력을 제공할 수 있습니다. 손가락, 이빨 등의 세부사항을 더 잘 생성합니다.\n\n이 모델의 부적합한 사용 사례: 모델을 불러오려면 상당한 VRAM이 필요합니다. 오픈 소스 커뮤니티의 광범위한 지원이 아직 확인되지 않았습니다.\n\n# 세밀하게 조정된 모델들\n\n<div class=\"content-ad\"></div>\n\n현재 Stable Cascade에 대해 Fein-tuned 모델은 매우 적습니다.\n\n# Stable Diffusion 3.0\n\n2024년 3월 발표된 Stable Diffusion 패밀리의 최신 버전인 Stable Diffusion 3.0입니다. 자세한 내용은 아직 부족하지만, 초기 결과로는 프롬프트 정렬 및 전체 이미지 품질에서 상당한 개선이 나타났습니다.\n\n만약 Stable Diffusion 3이 출시되면 이 섹션을 업데이트하겠습니다.","ogImage":{"url":"/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png"},"coverImage":"/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png","tag":["Tech"],"readingTime":5},{"title":"개성있는 애니메이션 미미 만들기 세밀하게 조정된 텍스트-이미지 모델 사용하기","description":"","date":"2024-06-19 21:00","slug":"2024-06-19-CreatingPersonalizedAnimatedMemesUsingFine-tunedText-to-imageModels","content":"\n\n## Stable Diffusion과 Deforum을 사용한 개인 맞춤형 미미 생성\n\n안녕하세요! 이 블로그 포스트에서는 Deforum과 섬세하게 조정된 Stable Diffusion(SD) 모델을 사용하여 맞춤형 및 애니메이션 미미를 만드는 과정을 소개하고, 스타일 전이 도구로 사용한 Visual Guide 출처의 몇 가지 미미 예제를 제시할 예정입니다.\n\n시작하기 전에, 아직 저의 블로그에서 섬세하게 조정된 SD 모델을 사용하여 미미 이미지를 생성한 내용을 확인하지 않으셨다면 아래 링크를 확인해보세요:\n\n전체 코드는 저의 GitHub 페이지에서 확인할 수 있습니다. 필요한 부분은 여기 있어요.\n\n<div class=\"content-ad\"></div>\n\n# 단계 1: 모델 파인 튜닝\n\n첫 번째 단계는 SD 모델을 파인 튜닥하는 것입니다. 저는 SD1.5 모델을 선택하고 해당 모델의 가중치를 여기서 다운로드 받았습니다. 그런 다음에는 제 PC가 10GB VRAM을 가진 RTX3080을 사용하기 때문에 로컬에서 학습 알고리즘을 실행했습니다. 충분히 강력한 성능을 가진 듯합니다.\n\n파인 튜닥에 사용할 이미지를 선택할 때 주의하세요. 서로 다른 배경과 표정을 가진 이미지를 사용해 보세요. 저는 다음과 같은 이미지들을 사용했습니다.\n\n![이미지](/assets/img/2024-06-19-CreatingPersonalizedAnimatedMemesUsingFine-tunedText-to-imageModels_0.png)\n\n<div class=\"content-ad\"></div>\n\n훈련 후 모델 체크포인트 파일을 리포지토리의 models/ 하위 폴더로 이동해주세요.\n\n![이미지](/assets/img/2024-06-19-CreatingPersonalizedAnimatedMemesUsingFine-tunedText-to-imageModels_1.png)\n\n# 단계 2: 메멘티콘 템플릿 준비\n\n두 번째 단계는 Deforum 알고리즘을 실행하기 위해 필요한 파일을 준비하는 것입니다: 확산할 소스 비디오, 마스크 비디오 및 설정 파일. 더 쉽게 따라올 수 있도록, 이러한 단계를 세 가지 하위 섹션으로 설명하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## 단계 2.1: 확산할 소스 비디오 다운로드하기\n\n이 단계에서는 우리의 템플릿으로 사용할 비디오를 간단히 다운로드합니다. 사람이 포함된 비디오면 어떤 비디오든 사용할 수 있습니다. 저는 아래 비디오를 선택했습니다. 해당 비디오를 다운로드하고 templates/dimitri_finds_out/source.mp4 경로에 저장했습니다.\n\n## 단계 2.2: 마스크 비디오 생성\n\n디포럼 알고리즘은 마스크 비디오를 입력으로 사용할 수 있습니다. 마스크 비디오는 확산을 원하는 입력 비디오와 동일한 프레임 수를 가져야 합니다. 각 프레임은 확산을 위한 ROI가 검정색이고 터치하지 않을 부분이 흰색인 이진 강도로 구성됩니다. 그런 다음, 이것은 이진 분할 문제가 되며, 이에 대한 알고리즘은 문헌에서 흔히 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n저는 PixelLib이라는 사용하기 쉬운 라이브러리를 알고 있습니다. 이 라이브러리는 기본적으로 PointRend를 기반으로 한 시맨틱 세그멘테이션 라이브러리입니다. 몇 줄의 코드로 세그먼트된 프레임을 생성할 수 있게 해줍니다. 사용하려면 이 링크에서 PointRend 모델을 다운로드하여 models/ 하위폴더로 이동해야 합니다.\n\n마스크 생성을 자동화하는 스크립트 create_mask.py를 작성했습니다. 이 스크립트는 소스 비디오 경로와 출력 마스크 비디오를 저장할 경로 두 가지를 입력받습니다.\n\n```js\npython create_mask.py \\\n  --video_path=\"templates/dimitri_finds_out/source.mp4\" \\\n  --save_path=\"templates/dimitri_finds_out/mask.mp4\"\n```\n\nPixelLib은 시맨틱 세그멘테이션 라이브러리이므로 프레임에서 감지된 각 사람에 대한 마스크를 제공합니다. 우리가 관심 영역을 선택하기 위해, 모든 감지된 사람 중에서 면적이 가장 큰 사람을 선택하는 절차를 구현했습니다. 이는 다음 두 함수에 의해 수행됩니다:\n\n<div class=\"content-ad\"></div>\n\n```js\ndef max_nonzero_channel(arr):\n    # 채널 차원을 제외한 모든 차원을 합산합니다\n    channel_sums = np.sum(arr != 0, axis=tuple(range(arr.ndim-1)))\n    # 가장 높은 합을 가진 채널의 인덱스를 찾습니다\n    max_channel_index = np.argmax(channel_sums)\n    return max_channel_index\n\ndef frame_segmentation(path_to_extracted_frames, frame_count, save_path_for_mask_frames):\n    create_folder(save_path_for_mask_frames) # 폴더가 없을 경우 생성합니다\n    for index in tqdm(range(frame_count)):\n        # 비디오의 각 프레임에 대해 PointRend를 실행합니다\n        r, output = ins.segmentImage(f\"{path_to_extracted_frames}frame{index}.jpg\", \n                                     show_bboxes=True, segment_target_classes=target_classes, \n                                     save_extracted_objects=False, mask_points_values=False, \n                                     extract_segmented_objects=True, output_image_name=None)\n        # 사람이 감지되었다면 최대 nonzero 픽셀 개수를 가진 채널을 선택합니다\n        if r[\"masks\"].ndim == 3:\n            picked_object = int(max_nonzero_channel(r[\"masks\"][:, :, :]))\n            cv2.imwrite(f\"{save_path_for_mask_frames}mask{index:05}.png\", (1 - r[\"masks\"][:, :, picked_object]).astype(int) * 255)\n        # 그렇지 않으면 흰 프레임을 생성합니다\n        else:\n            cv2.imwrite(f\"{save_path_for_mask_frames}mask{index:05}.png\", np.ones((output.shape)).astype(int) * 255)\n```\n\n다음 비디오는 PointRend의 출력 및 후처리된 마스크 비디오로 선택한 소스 비디오의 내용을 보여줍니다.\n\n![비디오 링크](https://miro.medium.com/v2/resize:fit:1200/1*YSFCLiOQ-kPB-bf_4MQQ1g.gif)\n\ncreate_mask.py를 실행한 후, 마스크 비디오가 템플릿의 하위 폴더에 있음을 확인해주세요.\n\n<div class=\"content-ad\"></div>\n\n## 단계 2.3: Deforum 설정 준비\n\n마지막 단계는 템플릿용 Deforum 알고리즘을 위한 settings.txt 파일을 생성하는 것입니다. 이 파일은 기본적으로 Deforum 매개변수 목록으로, 여기에 중요한 몇 가지가 있습니다: seed_behavior, animation_prompts, video_init_path, 그리고 video_mask_path.\n\nseed_behavior: Deforum은 일반적으로 SD 실행을 위해 무작위 시드를 사용하지만, 애니메이션 일관성을 위해 \"고정\"으로 설정해야 합니다. 이렇게 하면 확산된 영역의 색상과 세부 사항이 연속된 프레임 내에서 의사 일관되게 유지됩니다.\n\nanimation_prompts: 일반적인 SD 프롬프팅과 달리 우리는 풍경에 대한 많은 세부 정보와 신호 입력할 필요가 없습니다. 입력 비디오를 공급하면 공간 영역의 대부분 세부 사항이 보존됩니다. 따라서 “sks 사람 사진, 현실적인 얼굴”과 같은 스타일 신호 몇 가지만 입력해도 충분합니다. 저의 비디오에는 웃고 춤추는 남성이 포함되어 있으므로 입력한 프롬프트는 “댄스 클럽에서 웃고 춤추는 sks 남성 사진, 현실적인 얼굴, 초상화 세부 사항, 강조 조명…”입니다.\n\n<div class=\"content-ad\"></div>\n\nvideo_init_path 및 video_mask_path: 이러한 매개변수는 각각 source.mp4 및 mask.mp4의 경로입니다.\n\ndimitri_finds_out 템플릿 설정 중 일부는 다음과 같습니다:\n\n```js\n{\n    \"ENABLE_STORY_MODE\":\"True\",\n    \"batch_name\":\"dimitri_finds_out\",\n    \"width\":900,\n    \"height\":900,\n    \"bit_depth_output\":8,\n    \"seed\":-1 ,\n    \"seed_behavior\":\"fixed\",\n    \"sampler\":\"euler_ancestral\",\n    \"steps\":70,\n    \"scale\":15,\n    \"ddim_eta\":0.0,\n    \"filename_format\":\"{timestring}_{index}_{prompt}.png\",\n    \"use_init\":false,\n    \"init_image\":\"\",\n    \"strength\":0.75,\n    \"use_mask\":false,\n    \"use_alpha_as_mask\":false,\n    \"invert_mask\":false,\n    \"animation_prompts\":{\n \"0\": \"picture of laughing sks man in a dance club, realistic face, ultra detailed face, accent lighting, extremely detailed, ultra detailed, intricate details, high composition, 8k, cinematic lighting, blurry:-1, disfigured:-1, ugly:-1, deformed:-1, bad anatomy:-1, poorly drawn face:-1, poorly drawn hands:-1, malformed hands:-1, disgusting:-1, poorly drawn:-1, poorly drawn face:-1\"\n    },\n    \"animation_mode\":\"Video Input\",\n    \"max_frames\":348,\n    \"diffusion_cadence\":\"6\",\n    \"border\":\"warp\",\n    \"video_init_path\":\"templates/dimitri_finds_out/source.mp4\",\n    \"extract_nth_frame\":1,\n    \"overwrite_extracted_frames\":true,\n    \"use_mask_video\":true,\n    \"video_mask_path\":\"templates/dimitri_finds_out/mask.mp4\",\n    \"interpolate_key_frames\":false,\n    \"fps\":24\n}\n```\n\n설정 파일을 settings.txt로 저장합니다. 아래에 나타낸대로, 소스 비디오, 마스크 비디오, 및 설정 파일은 templates/dimitri_finds_out/ 하위 폴더에 저장됩니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-CreatingPersonalizedAnimatedMemesUsingFine-tunedText-to-imageModels_2.png\" />\n\n# 단계 3: Deforum 실행하기\n\n이제 Deforum 스크립트를 실행할 준비가 되었습니다. 저는 Deforum 기능을 제어하는 메타 스크립트인 run.py를 만들었습니다. 다음과 같이 명령줄에 두 가지 인자를 제공해야 합니다. 템플릿 이름과 여러분의 미세 조정된 모델의 이름입니다:\n\n```js\npython run.py \\\n  --meme_template=\"dimitri_finds_out\" \\\n  --finetuned_model_path=\"your_finetuned_model.ckpt\"\n```\n\n<div class=\"content-ad\"></div>\n\n하드웨어에 따라 스크립트 실행이 몇 분 정도 걸릴 수 있습니다. 제 경우에는 약 5분이 소요됩니다. 결과 동영상은 output/ 폴더에 저장됩니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1200/1*SlWST_jBJkg7rUxj2aHUMQ.gif)\n\n# 단계 4: 동영상에 텍스트 추가\n\n상상력과 유머 감각이 발휘되는 단계입니다. 우리는 동영상에 텍스트를 추가하여 미eme의 필수 요소인 비디오에 텍스트를 추가합니다. 제 메타 스크립트에는 텍스트 추가 기능이 구현되어 있지 않습니다(곧 추가할 예정). ffmpeg를 사용하여 명령줄을 통해 동영상에 텍스트를 추가할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```bash\nffmpeg -i 경로/비디오 -vf \"drawtext=text='당신의 텍스트':x=(w-tw)/2:y=(h-th)/12:fontfile=C:/Windows/Fonts/Arial.ttf:fontsize=40:fontcolor=white\" 경로/출력/비디오\n```\n\n아래는 제가 한 작업입니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1200/1*BjphB2HVk5ANzpA_f1y-fA.gif)\n\n제 블로그를 읽어주셔서 감사합니다. 곧 비슷한 콘텐츠 생성을 위해 ControlNet을 사용하는 또 다른 블로그를 작성할 예정입니다.\n\n<div class=\"content-ad\"></div>\n\n좋은 하루 보내세요!","ogImage":{"url":"/assets/img/2024-06-19-CreatingPersonalizedAnimatedMemesUsingFine-tunedText-to-imageModels_0.png"},"coverImage":"/assets/img/2024-06-19-CreatingPersonalizedAnimatedMemesUsingFine-tunedText-to-imageModels_0.png","tag":["Tech"],"readingTime":8},{"title":"ComfyUI에서 의상을 어떻게 변경하나요","description":"","date":"2024-06-19 20:58","slug":"2024-06-19-HowtoChangeOutfitsinComfyUI","content":"\n\n일반적으로 ComfyUI나 Automatic1111에서 옷을 바꾸는 과정은 캐릭터 포즈를 유지하면서 원하는 스타일을 적용하는 데 조금의 프롬프트 엔지니어링이나 LoRA가 필요한 귀찮은 인페인팅과 제어넷을 필요로 합니다.\n\n조금의 실험 끝에 IPAdapter의 스타일 추출과 Grounding Dino 및 Segment Anything 모델의 정확한 세분화를 결합하면 후처리를 최소화하면서 매우 정확하고 불편한 옷 갈아입기를 할 수 있습니다.\n\n다음은 방법입니다:\n\n작업흐름 및 상세가이드: 이 작업을 실제로 확인하고 워크플로를 다운로드하고 싶다면, Prompting Pixels 웹사이트에서 무료로 이용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 최종 결과\n\n워크플로우 세부사항에 대해 들어가기 전에, 이전과 이후의 이미지를 시각적으로 보여드립니다:\n\n# 작업 공간 설정\n\n세 가지 다른 그룹으로 분리하는 것이 조직적 관점과 전반적인 프로세스에서의 상황을 고려할 때 좋은 방법이라고 생각했습니다. 이 세 그룹은 다음과 같습니다: 기본 워크플로우, IPAdapter 및 세분화. 각각에서 무엇이 벌어지고 있는지 살펴보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n# 기본 작업 흐름\n\n여기서 소개하는 것은 기본적으로 ComfyUI에서 시작하는 기본 작업 흐름입니다. 여기서 가장 주목할 만한 변화는 전체 이미지가 아닌 부분 이미지를 다루기 때문에, 생성 체크포인트 대신 인페인팅 체크포인트를 불러와야 한다는 것입니다.\n\n그리고 추천하는 좋은 SDXL 체크포인트로는 RealVision, ICBINP XL 또는 기본 SDXL 인페인팅 체크포인트가 있습니다.\n\n당신의 프롬프트에 대해, 특정 세그먼트를 변경할 것이기 때문에 무엇이 나타나길 원하는지 정의해야 합니다. 이 예시에서는 기본 셔츠를 화려한 하와이안 셔츠로 변환할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# IPAdapter\n\nIPAdapter은 이미지 프롬프트 어댑터를 의미합니다. 기본적으로 이 노드들은 스타일이나 사람의 일반적인 특징을 모델로 전송할 수 있습니다.\n\n이를 작은 LoRA나 텍스트 임베딩처럼 생각해보세요.\n\n따라서 이미지를 입력으로 제공하고 이미지에서 관련 정보를 추출하는 것을 Load Image 노드를 통해 수행해야 합니다.\n\n<div class=\"content-ad\"></div>\n\nComfyUI에 이미지 프롬프트 어댑터(IPAdapter)를 설정하려면 CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors 및 ip-adapter-plus_sdxl_vit-h.safetensors 모델을 불러와야 합니다. 이 모델들과 관련된 다른 모델들은 IPAdapter GitHub 리포지토리에서 찾을 수 있습니다.\n\n해당 디렉터리에 모델을 넣은 후 이미지 출력을 Load Image 노드에서 IPAdapter 고급 노드로 전달해야 합니다.\n\n또한, CLIP 모델을 Load CLIP Vision과 IPAdapter Unified Loader를 IPAdapter 고급 노드로 가져와야 합니다. 이전에 언급된 IP 어댑터 모델을 사용하는 경우 프리셋을 PLUS(고 강도)로 설정해야 합니다.\n\n마지막으로 IPAdapter Advanced에서 weight_type를 스타일 전송으로 변경해야 합니다.\n\n<div class=\"content-ad\"></div>\n\nIPAdapter Advanced로부터의 모델 출력은 직접 KSampler 노드로 들어가게 되는데, 수정된 모델 파일은 이제 원하는 입력에 기반하여 정확하게 이미지/스타일을 그릴 수 있습니다.\n\n# 세분화\n\n이 프로세스 중 가장 멋진 부분 중 하나는 GroundingDino 모델의 구현입니다. 이 세분화 모델은 텍스트 프롬프트를 제공하고 해당 이미지 내에서 그것을 찾아서 그에 맞게 분할할 수 있습니다.\n\n이것은 굉장히 강력한 기능입니다.\n\n<div class=\"content-ad\"></div>\n\n저희의 작업 흐름 중에 셔츠를 세분화하는 데 사용 중인데, 실제로 모자부터 신발, 심지어 전체 배경까지 거의 모든 것을 세분화할 수 있어요. 가능성은 무한해요.\n\n이를 설치하려면 Segment Anything 사용자 정의 노드를 가져와야 해요 (ComfyUI 매니저나 GitHub 저장소를 통해 이용 가능해요).\n\nIPAdapter와 같이 세분화할 때 이미지가 먼저 입력이 되어야 해요.\n\n그러므로 Load Image 노드를 설정하고 그 다음 GroundingDinoSAMSegment 노드로 전달하세요.\n\n<div class=\"content-ad\"></div>\n\n또한, SAMModelLoader 노드와 GroundingDinoModelLoader의 Segment Anything 모델을 가져와야 합니다. 처음 실행할 때 이 모델 로더 노드들은 관련 모델(약 3GB)을 다운로드한 다음 GroundingDinoSAMSegment 노드로 전달합니다.\n\nGroundingDinoSAMSegment 노드에는 세그먼트할 객체의 단어를 입력할 수 있는 텍스트 필드가 있습니다. 셔츠, 안경 등과 같이 세그먼트하려는 객체의 단어를 입력할 수 있습니다.\n\n이제 셔츠, 안경과 같은 여러 객체를 정의할 수 있지만, 신뢰성이 거의 없다는 것을 알았습니다:\n\n![이미지](/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png)\n\n<div class=\"content-ad\"></div>\n\n임계값에 대해 일반적으로 말하자면, 낮은 값은 모델이 선택을 더 자유롭게 할 수 있게 하지만 높은 값은 더 자신 있게 만듭니다. 값이 너무 높으면 선택된 것이 없는 오류가 발생할 수 있습니다.\n\n분할한 후에는 마스크를 VAE 인코딩(인페인팅용) 노드(mask 입력)와 IPAdapter Advanced(주의 마스크 입력) 노드에 모두 전달해야 합니다. 원본 이미지는 VAE 인코딩(인페인팅용) 노드에도 전달되어야 합니다.\n\n선택 사항: 마스크에 FeatherMask 노드를 추가하여 가장자리를 부드럽게 만들어 더 나은 결과를 얻을 수 있습니다.\n\n# 큐 프롬프트 및 결과 검토\n\n<div class=\"content-ad\"></div>\n\n한 번 모두 연결되면 프롬프트를 대기열에 넣고 결과를 검토할 수 있습니다. 원하는 결과물의 꽤 정확한 표현이 셔츠가 멋진 하와이안 셔츠로 변환되었음을 확인해야 합니다.\n\n출력 이미지를 주의 깊게 살펴보고 원하는 결과물을 얻기 위해 필요한 대로 설정을 조정하세요.\n\n완벽하게 작동하는 완벽한 조합을 찾기 위해 다양한 설정으로 실험하고 다양한 모델을 테스트할 수 있도록하려면 설정을 조정하세요.\n\n# 이 프로세스의 장단점\n\n<div class=\"content-ad\"></div>\n\n제안하는 방법에 대한 장단점을 요약해 드리겠습니다. 이 워크플로우를 잘 활용하는 데 도움이 될 수 있어요:\n\n장점:\n\n- GroundingDino의 Zero-shot 객체 감지 기능을 사용하면 이미지를 자동으로 분할하고 보정할 수 있습니다.\n- 정확한 분할이 모델이 올바른 영역만 보정하도록 합니다.\n- '가상 시착'과 같은 소비자를 대상으로 하는 응용 프로그램이 가능합니다.\n\n단점:\n\n<div class=\"content-ad\"></div>\n\n- Segmentation이 추가적인 몇 개의 GB VRAM을 소비하므로, ControlNets, LoRAs, AnimateDiff 등 다른 노드들과 함께 사용할 때 문제가 발생할 수 있습니다.\n- 물리적인 적용이 아니라 스타일 적용만 가능합니다. 예를 들어, 긴 소매 셔츠가 IPAdapter에 입력되어도 최종 이미지는 여전히 단추 소매로 표시될 것입니다.\n\n👉 AI 예술 기술을 강화하고 싶다면, 무료 프롬프팅 픽셀 강좌를 확인해보세요.","ogImage":{"url":"/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png","tag":["Tech"],"readingTime":4},{"title":"내가 절대 놓치지 말아야 할 최고의 중간 여행 가이드  안내와 50개 이상의 이미지","description":"","date":"2024-06-19 20:55","slug":"2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images","content":"\n\n## 초보자부터 고급자까지\n\n최신 업데이트 : 24년 6월 8일 (이전에는 24년 6월 6일).\n\n헤이, 미드저니 크루 여러분.\n\n어떻게 지내세요? 여러분의 한 주가 잘되길 바래요! 미드저니에 대해 저만큼 열정적이신지 다들 기대가 되는 데, 그럼 여러분을 위해 좋은 소식이 있다고 해요: 내가 소개하는 개인 미드저니 가이드가 준비되어 있어요.\n\n<div class=\"content-ad\"></div>\n\n한 달 동안 Midjourney에 대해 글을 쓰고 있었는데, 이제 내 지식을(적어도 대부분) 모아서 Midjourney를 최대한 활용하는 간편한 가이드로 편집할 때가 온 것 같아요. 특히 Midjourney에 익숙하지 않은 경우에 유용하게 활용할 수 있도록 구성했습니다.\n\n이 가이드는 당신이 읽고 싶은 부분으로 쉽게 이동할 수 있도록 구조화되어 있어요. Midjourney의 역사와 설정 방법부터 다양한 모델과 기능에 대해 자세히 살펴보는 과정으로 시작해서,\n\n저는 이 가이드를 Midjourney를 최대한 활용하도록 하는 속임수 예제와 팁과 트릭으로 마무리할 거에요.\n\n그리고 이 가이드를 최대한 시각적으로 매력적으로 만들기 위해, Midjourney를 사용하여 제가 직접 만든 50개의 이미지를 포함했습니다. 이 이미지들은 엄청난 가능성을 보여줄 뿐만 아니라 당신이 자신만의 이미지를 만들도록 영감을 줄 거예요.\n\n<div class=\"content-ad\"></div>\n\n여기 Midjourney v6로 만든 첫 이미지가 있어요. 그것은 제게 전환점이었어요:\n\n![image](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_0.png)\n\n멋지지 않나요?\n\n이 이미지는 1990년대를 완벽하게 담아냈고 솔직히 말해서, Midjourney로 만들지 않았다면 AI가 만들었다고는 믿지 못할 정도에요.\n\n<div class=\"content-ad\"></div>\n\n제목\n## Midjourney 소개\n\nMidjourney는 2년 전에 출시되었으며 많은 발전을 거듭해왔습니다. 이는 이전에 Leap Motion의 공동 창업자였던 David Holz에 의해 설립되었습니다. Midjourney는 출시 이후 여러 중요한 업데이트를 통해 서비스를 더 신뢰성 있고 현실적으로 만들어 왔습니다.\n\n## Midjourney 설정하기\n\n이 안내서를 마음에 드는 순서로 자유롭게 읽거나, 가장 관심 있는 부분을 선택해 보세요.\n\n<div class=\"content-ad\"></div>\n\n처음에 Midjourney는 Discord를 기반으로 했습니다. 그들의 웹사이트에 가입해도 Midjourney에 접속하려면 활성화된 Discord 계정이 필요합니다.\n\nDiscord 계정이 없다면, 먼저 하나를 설정해야 합니다. 하지만 그것은 꽤 쉽고 큰 문제는 아닙니다.\n\n최근까지 Midjourney에 접속하는 유일한 방법은 Discord 앱을 사용하는 것이었습니다. Discord의 가장 큰 단점은 혼잡한 서버로, 이는 새로운 사용자들을 돌아서게 할 수 있습니다.\n\n그리고 Midjourney 봇을 사용하여 개인 서버를 설정하는 것 또한 쉽지 않았습니다.\n\n<div class=\"content-ad\"></div>\n\n당신은 개인 Discord 서버를 설정하는 방법에 대해 더 많이 알아볼 수 있어요:\n\n하지만 이 모든 것은 알파 웹사이트가 공개된 이후 대부분 사람들에게 공개되었기 때문에 모두 변했어요.\n\n새로운 Midjourney 웹사이트는 깨끗하고 사용하기 쉬우며 새로운 기능이 정기적으로 업데이트되어요. 이 안내서에서는 웹사이트에 초점을 맞추지만, 일부 소수의 고급 기능이 아직 누락되어있기 때문에 제가 사진을 구성하는 방법과 사용의 편리함을 선호해요.\n\n여전히 Discord를 사용 중이라면 웹 인터페이스로 전환을 고려할 수 있어요. 전환하는 이유에 대해 추가로 읽을 수 있도록 이곳에 글을 썼어요:\n\n<div class=\"content-ad\"></div>\n\n이미지를 생성하는 방법은 간단한 텍스트 프롬프트에 달려 있습니다. Midjourney는 해당 텍스트를 해석하고 사진을 생성할 것입니다. 그러나 이미지 생성에 들어가기 전에 먼저 Midjourney 모델들을 이해해야 합니다.\n\n# 모델 버전 이해\n\nMidjourney가 2년 전에 출시되었을 때, 그것은 겸손한 시작을 가졌지만 오늘날 만들 수 있는 것과는 비교할 바가 없는 이미지를 만들었습니다. 그 때도 정말 인상적이었지만, 3D 컴퓨터 게임 그래픽 초기 단계를 많이 생각나게 했습니다.\n\n![이미지](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_1.png)\n\n<div class=\"content-ad\"></div>\n\nV1에서 프롬프트가 어떻게 나타나는지 살펴보세요:\n\n\n![Image1](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_2.png)\n\n\nV6에서 동일한 프롬프트를 보겠습니다:\n\n\n![Image2](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_3.png)\n\n\n<div class=\"content-ad\"></div>\n\n차이가 놀라울 정도로 놀라운 것 같아요! 세부 사항과 전체적인 사실적인 모습을 살펴보세요.\n\n일반 모델 외에도 이미지와 스타일의 다양성을 만들 수 있는 중요 모델들 외에도 Midjourney에서는 애니메이션 및 설명적인 스타일을 만들기 위해 특화된 Niji 모델도 출시했습니다.\n\n### V6 모델 (& V5.2 모델)\n\nV5는 2022년 3월에 출시되었으며, 이후 5.1 버전과 5.2 버전이 각각 2022년 5월과 6월에 출시되었습니다.\n\n<div class=\"content-ad\"></div>\n\n사실 V5.2는 Midjourney와 genAI(생성적 AI) 세계로 진입한 실제적인 시작점이었습니다. 이미지는 놀라울 만큼 멋있었고, 제가 말 그대로 놀라 바닥에 엎드렸습니다.\n\n제 마음은 즉시 뛰어나가며, 디지털 아트와 사진의 미래에 대한 의미를 상상했습니다. 그러나 이러한 함의는 이해하기 어려웠습니다. 이 모든 것을 능가하는 건 V6의 출시로, 현실감이 새로운 수준으로 끌어올렸습니다.\n\n## V5.2와 V6의 차이점은 무엇인가요?\n\n주요한 차이는 Midjourney가 프롬프트를 해석하는 방식입니다.\n\n<div class=\"content-ad\"></div>\n\nV5.2에서는 추가 프롬프트 세부 사항을 엄격한 지침이 아니라 모호한 제안으로 취급했지만 V6에서는 프롬프트를 더 꼼꼼히 따랐습니다. 이로 인해 프롬프트와 더 일치하는 이미지가 생성되었습니다.\n\n내 의견으로는 직접 비교해보면 V5.2는 예술적인 이미지를 더 많이 생성했지만, V6은 더 사실적인 사진을 생성합니다.\n\n다음은 V5.2와 V6에서 동일한 프롬프트입니다:\n\n\n![이미지](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_5.png\" />\n\nMidjourney의 표현과 prompt 처리 방식으로 두 이미지를 비교하는 것은 분명히 어렵지만, V5.2가 거의 완벽하고 흠도 없는 것은 분명합니다.\n\n반면 V6은 섬세한 피부 세부 사항 심지어 피부 혹과 같은 것들이 보이지만, 조금 과도하게 스타일링된 것일 수 있습니다 (이후에 매개변수를 사용하여 조정하는 방법을 설명합니다).\n\n## Niji Model\n\n\n<div class=\"content-ad\"></div>\n\nNiji 모델은 애니메이션 캐릭터(그림)에 특화되어 있어요. 일반 모델로 동일한 결과를 얻으려고 해도 거의 불가능할 거에요.\n\n만약 그런 스타일을 좋아하신다면 디스코드에서 “--niji 6” 명령을 사용하거나 웹사이트 설정에서 모델을 변경하실 수 있어요.\n\n![이미지](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_6.png)\n\n이것은 Niji 모델의 훌륭한 예시에요.\n\n<div class=\"content-ad\"></div>\n\n이제 이미지를 만드는 방법을 살펴봅시다. (참고: 이 작업은 상당히 간단하지만 여러분이 큰 문제를 일으키는 것이 작은 것들입니다).\n\nNiji 모델에 대해 더 자세히 알고 싶다면 이 이야기를 다른 탭에서 열어보세요:\n\n### 이미지 만들기\n\nMidjourney에서 이미지를 만드는 것은 매우 간단합니다. 텍스트 프롬프트를 작성하면 정확한 이미지를 생성하기 위해 최선을 다할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n그냥 한 마디나 한 문장을 적고 Midjourney가 어떤 것을 만들 것인지 확인하세요. 이것은 정말 재밌을 수 있고 Midjourney의 창의적인 자유가 놀라운 것을 보는 재미가 있습니다.\n\n여기에 이에 대해 쓰고 Midjourney를 자유롭게 행동하게 하는 것이 훌륭한 실험이었습니다.\n\n하지만 보통은 Midjourney에게 정확히 원하는 이미지를 만들도록 안내하고 싶을 것입니다. 이것은 분명히 시간과 연습이 필요할 것입니다.\n\n예를 들어 다음 프롬프트는 몇 가지 훌륭한 이미지를 만들어 냈지만, 완전히 다른 방향으로 나갈 수도 있었을 것입니다. 이렇게 짧은 프롬프트로는 방향을 제시할 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_7.png\" />\n\n다음 (완전한 것이 아닌) 팁 목록을 사용하세요:\n\n- 설명적인 언어 사용\n- 가능한 한 구체적으로\n- 모호함 피하기\n- 대상/장면을 설명하는 데 키워드 사용\n- 쉼표로 구분된 입력 사용\n- 부정적인 표현 사용x\n- 스타일 설명 (예: 예술 스타일, 사진 스타일, 조명, ...)\n\n좋은 프롬프트의 예시를 보려면 다음 예제를 참고하세요:\n\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_8.png\" />\n\nThe complete opposite would be this one line prompt with a subpar result\n\n<img src=\"/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_9.png\" />\n\nAdmittedly the photo is not bad, because the training data is great and Midjourney tends to go the more artsy and beauty route, but frankly it’s in my opinion nothing compared to the other image.\n\n\n<div class=\"content-ad\"></div>\n\n그리고 또 하나 중요한 개념이 나타났어요: 가끔은 작은 차이로 반복해서 동일한 프롬프트를 실험하고 실행하면 더 나은 결과를 얻을 수도 있어요.\n\n프롬프트에 대해 확신이 없다면, 작게 시작하고 세부 사항과 스타일을 추가해보세요.\n\n# 미학\n\n당신의 프롬프트 외에도, 웹사이트 설정에서 발견할 수 있는 미학 옵션은 Midjourney가 이미지를 생성하는 방식을 변경할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n이미지\n\n## 스타일\n\n스타일 매개변수는 이미지의 전체적인 외관과 스타일을 변경합니다.\n\n1000의 경우 Midjourney가 아름답게 너무 좋아지는 과장된 양의 미화 이미지를 만들도록 하고, 0은 Midjourney에게 정확히 지시사항을 따르도록 지시합니다.\n\n<div class=\"content-ad\"></div>\n\n위의 예시에서 보듯이 스타일 값이 높을수록 이미지가 더 아름답고 완벽해집니다.\n\n스타일화에 대해 더 많이 썼으니 여기를 참고해주세요:\n\n## 이상함\n\n이상함은 정반대 방향으로 진행됩니다. 값이 높을수록 이미지는 더 실험적으로 변할 것입니다. 독특한 길을 가고 싶다면 이상함 값을 높여보세요.\n\n<div class=\"content-ad\"></div>\n\n결과는 완전히 무작위이며 예측할 수 없으므로 조심해서 사용해야 합니다.\n\n## 다양성\n\n다양성은 디스코드의 혼돈 매개변수와 동등합니다. 이미지가 얼마나 다른지를 결정합니다. 값이 높을수록 무작위성이 높아지고, 값이 낮을수록 이미지는 설명대로 예상대로 될 것입니다.\n\n초기 입력 프롬프트는 핑크색 안경을 쓴 의자에 앉아 있는 불독이 수영장에 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n예상대로 값이 높을수록 Midjourney가 입력에서 멀어진 걸 볼 수 있어요.\n\n다양성을 일종의 무작위성으로 볼 수도 있어요.\n\n이제 세 매개변수를 모두 50%로 올렸을 때 어떤 일이 일어나는지 확인해 봅시다.\n\n이제 아름다움의 미학은 배경으로 밀려나 무작위성과 평균적인 얼굴 특징에게 자리를 내어주는 거에요.\n\n<div class=\"content-ad\"></div>\n\n단지 헤딩 1을 사용하여 표 형태로 만들었습니다.\n\n## 종횡비\n\n사용 목적에 따라 텍스트 프롬프트를 해석하는 방식을 조정하는 것이 의미가 있을 수 있어요. \n\n예를 들어 초상화 종횡비를 선택하면 사진에 한 명만 초점을 맞추려고 하는 것이라고 Midjourney에게 알려줄 수 있어요. 반면, 횡형 종횡비를 설정하면 동일한 프롬프트로 다른 결과를 얻을 수 있습니다. Midjourney는 세부사항을 추가할 공간이 더 많기 때문이에요.\n\n<div class=\"content-ad\"></div>\n\n이미지의 종횡비가 변경되어 전체적인 메시지도 변했죠. 저는 개인적으로 폭이 넓은 종횡비를 선호합니다.\n\n# 고급 기술\n\n다양한 고급 기술들이 있지만, 이 안내서에서는 웹사이트에 중점을 두고 있기 때문에 가장 중요한 몇 가지만 다룰 거에요.\n\n## 캐릭터 & 스타일 참고\n\n<div class=\"content-ad\"></div>\n\n캐릭터와 스타일 참조를 통해 다른 이미지를 참조할 수 있습니다. Midjourney는 전반적인 스타일(예: 예술 스타일)이나 새 이미지의 주요 캐릭터를 사용하기 위해 최선을 다할 것입니다.\n\n예를 들어, 캐릭터를 참조하고 아래에 설명된대로 다른 일련의 이미지에 넣을 수 있습니다. 불독은 Midjourney에 의해 만들어졌고 다른 프롬프트에서 참조했습니다.\n\n캐릭터 참조를 볼 때 원본 캐릭터를 완벽하게 복사하지는 않지만, 원본에 가까워지고 있습니다.\n\n스타일 참조도 동일한 방식으로 작동합니다.\n\n<div class=\"content-ad\"></div>\n\n참조 기능을 사용하려면, 생성한 이미지 중 하나를 사용하거나 이미지 인터페이스를 통해 새 이미지를 업로드할 수 있습니다.\n\n\n![image](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_11.png)\n\n\n어떤 방식을 선택하더라도 이미지를 선택한 후에는 오른쪽 하단의 작은 아이콘을 클릭하여 참조 스타일을 변경할 수 있습니다.\n\n이미지 참조에 관한 포괄적인 가이드를 작성했어요:\n\n<div class=\"content-ad\"></div>\n\n## 이미지 혼합\n\n이미지 혼합을 통해 두 개 이상의 이미지를 결합할 수 있습니다. 이를 통해 이전에 만든 이미지나 새로 업로드한 이미지를 기반으로 쉽게 새 이미지를 생성할 수 있습니다.\n\n해야 할 일은 두 개 이상의 이미지를 프롬프트에 추가하고 엔터를 누르는 것뿐입니다.\n\n예시를 살펴보겠습니다. 이 경우에는 두 이미지를 결합하여 자연 풍경이 배경화면이 되고 방 안으로 자라나는 것이 목표였습니다.\n\n<div class=\"content-ad\"></div>\n\n결과가 꽤 인상적이라고 생각해요. 전체 구성을 유지하면서 새로운 미적 감각을 더했죠.\n\n블렌딩 기능에 대해 더 많이 쓴 팁과 꿀팁이 있는 자세한 내용은 여기를 참고해주세요:\n\n## 설명\n\n만약 인공지능에 이미지를 보여주면 그 이미지에 무엇이 있는지 말해주기만 하는 것이 아니라 이미지를 복제하는 데 도움이 되는 힌트를 생성해 줄 수 있다면 어떨까요?\n\n<div class=\"content-ad\"></div>\n\n이것이 바로 \"설명\" 기능이 할 수 있는 작업입니다.\n\n이미지를 업로드하면 마우스 커서를 가져다 대고 작은 \"i\" 아이콘을 클릭할 수 있습니다.\n\n프로세스가 완료되면 각 구절을 클릭하여 프롬프트에 추가할 수 있습니다. 결과는 다음과 같습니다:\n\n![image](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_12.png)\n\n<div class=\"content-ad\"></div>\n\n이미지를 복사하는 것이 아니라 매우 비슷한 이미지를 생성한다는 점을 주의해야 합니다.\n\n## (미술 & 카메라) 스타일\n\n또 다른 중요한 점은 알아야 할 다양한 예술 스타일입니다.\n\nMidjourney에게 복제하려는 스타일이나 사용할 카메라 종류를 알리면 결과물이 완전히 다를 수 있습니다. 큐비즘과 표현주의와 같은 명백한 스타일은 물론 삼과누 아트와 같이 상상할 수 있는 거의 모든 것을 유도할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n위에 있는 예제와 동일한 프롬프트의 두 가지 예가 있습니다. 하나는 cubism에 가까운 예술 양식이고 다른 하나는 오래된 벽화입니다.\n\n# 더 나은 결과를 위한 꿀팁\n\n## 간단히 시작하세요\n\n나의 가장 좋은 조언 중 하나는 간단히 시작하는 것입니다. 너의 이미지에 많은 소재와 세부 사항을 추가하려고 하지 마십시오 (이 부분 아주 강조합니다). 이것은 작동하지 않으며, Midjourney를 혼란스럽게 할 가능성이 높습니다. 간단히 시작하고 추가하는 것을 잊지 마세요.\n\n<div class=\"content-ad\"></div>\n\n## 재생\n\n여기가 두 번째 팁입니다.\n\n자주 재생하세요.\n\n그리고 더 자주 재생하세요.\n\n<div class=\"content-ad\"></div>\n\n## 프롬프트 작성 방법 배우기\n\n제 Medium에 있는 이야기들 같은 프롬프트 영감을 확인해보세요. 정기적으로 새로운 아이디어와 영감을 주는 글을 올리고 있어요.\n\n이런 것들이 프롬프트 작성 방법을 배우는 데 도움이 될 거예요.\n\n<div class=\"content-ad\"></div>\n\n프롬프팅은 마법이 아니에요, 중간 여정에게 무엇을 원하는지 알려주는 것 뿐이에요.\n\n## 스타일 미학과 놀기\n\n가능한 한 중간 여정이 당신의 프롬프트를 가장 가깝게 따르도록 원한다면 스타일을 낮출 수 있어요.\n\n어떤 경우에든 다양한 미적 옵션으로 프롬프트를 여러 번 실행하면 예상치 못한 이미지를 얻을 수 있어요. 저는 가장 좋아하는 결과를 원할 때 200 스타일과 400 스타일로 프롬프트를 실행하는 것을 선호해요.\n\n<div class=\"content-ad\"></div>\n\n# 계기와 영감\n\n이제 정말 멋진 계기와 영감에 대해 이야기해보겠습니다.\n\n이것들은 모두 이전에 공유하지 않은 계기와 이미지들입니다. 그러니 이 안내서를 마친 후 내 다른 계기 아이디어도 확인하지 않을래? (마지막에 있는 링크를 확인해봐.) \n\n##  고양이 산책로\n\n<div class=\"content-ad\"></div>\n\n## 화성 사진 촬영\n\n## 호화로운 앵무새\n\n## 악어 목욕\n\n## 남자의 아름다움\n\n<div class=\"content-ad\"></div>\n\n여성 아름다움\n\n## 색상 분할\n\n마지막 것은 조금 까다로울 수 있어요.\n\n위의 이미지를 정확히 얻는 데는 시간이 오래 걸릴 수도 있고 많은 시도가 필요할 지도 몰라요. 하지만 색상 분할 이미지는 정말 멋진 아이디어에요. 여기 두 가지 더 예시가 있어요:\n\n<div class=\"content-ad\"></div>\n\n# 일반적인 문제\n\n다음은 제가 마주한 일반적인 문제 몇 가지입니다.\n\n## \"아니요\"가 \"아니\"가 아니다\n\nMidjourney는 부정적인 프롬프트에 문제가 있습니다. \"아니\"를 건너뛰고 여전히 제거하려는 모든 것을 추가합니다.\n\n<div class=\"content-ad\"></div>\n\n의견을 바꾸어 볼 수 있거나 각 실행마다 더 많은 내용을 추가하는 것이 좋을 수도 있습니다. 너무 많은 세부사항을 건드리지 않고 원하는 이미지로 가는 가장 쉬운 방법이에요.\n\n## 반응 없음\n\n또 다른 문제는 Midjourney가 가끔 반응하지 않을 때가 있어요. 프롬프트를 보내지만 이미지를 생성하지 않아서 이것이 귀찮을 수 있어요.\n\n로그아웃한 후 다시 로그인하는 방법을 시도해볼 수 있어요. 때로는 이 방법이 문제를 해결할 수 있어요. 또는 단순히 작업을 취소할 수도 있어요.\n\n<div class=\"content-ad\"></div>\n\n둘 다 작동하지 않으면 다른 프롬프트를 시도하고 걱정하지 마세요. 언젠가는 취소되고 대기열에서 제거될 겁니다.\n\n그게 다에요. \n\nMidjourney를 시작하고 프롬프팅 및 이미지 생성에서 능숙해지기 위한 상당히 포괄적인 가이드를 즐겁게 받아들였기를 바랍니다.\n\n좋아하신 점이나 더 알고 싶은 내용에 대해 의견을 자유롭게 남겨주세요. 박수를 보내고 공유하는 것도 잊지 마세요. 정말 도움이 돼요!\n\n<div class=\"content-ad\"></div>\n\n# 미드저니에 대해 더 많이 쓰고 있어요. 제가 가장 좋아하는 프롬프트 영감 링크를 공유할게요:\n\n![My Ultimate Midjourney Guide](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_13.png)\n\n이 이야기는 Generative AI에서 발행되었어요. LinkedIn에서 저희와 연락하고, Zeniteq를 팔로우해서 최신 AI 이야기에 대한 소식을 받아보세요. \n\n저희 뉴스레터 구독하시면, 최신 generative AI 뉴스와 업데이트를 받아보실 수 있어요. 함께 AI의 미래를 함께 만들어요!\n\n<div class=\"content-ad\"></div>\n\n![MyUltimateMidjourneyGuide](/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_14.png)","ogImage":{"url":"/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_0.png"},"coverImage":"/assets/img/2024-06-19-MyUltimateMidjourneyGuideYouCannotMissPromptsandOver50Images_0.png","tag":["Tech"],"readingTime":12},{"title":"인공지능 생성 보컬의 유별난 윤리 문제","description":"","date":"2024-06-19 20:51","slug":"2024-06-19-TheWeirdEthicsofAI-GeneratedVocals","content":"\n\n<img src=\"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_0.png\" />\n\n요즘 증가하는 생성 AI와 함께 실제 가수들의 목소리로 훈련된 AI 생성 보컬이 등장했습니다. 이 AI 음성 \"크롬\"은 음악 산업과 인터넷 전반을 동요시켰으며, 다양한 윤리 문제들을 제기했습니다. 일부는 음악에서 복제된 목소리의 사용을 음악 작가와 청취자들에게 엄청난 혜택으로 보지만, 다른 사람들은 그것만으로는 위험요인만을 보았습니다. 여기에 몇 가지 재미있는 사례가 있습니다:\n\nAI로 생성된 드레이크와 더 위켄드 보컬이 특집된 노래가 스트리밍 서비스에 의해 제거되기 전에 바이럴로 퍼졌습니다. AI 음악을 비난하는 Universal Music Group 대표는 Music Business Worldwide에 발표된 성명에서, \"우리 아티스트들의 음악을 사용하여 생성 AI를 훈련한다는 것은 음악 생태계의 모든 이해관계자들이 어느 쪽 역사에 서길 원하는지 의문을 제기합니다: 아티스트, 팬 및 인간의 창의적 표현을 지지하는 쪽인가요, 아니면 딥 페이크, 사기 및 아티스트들에게 정당한 보상을 제공하지 않는 쪽인가요?\" 라고 말했습니다. (강조는 제가 한 것입니다.)\n\n아이스 큐브는 AI를 \"악마적\"이라고 지적하면서 음악에는 그 자리가 없다고 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n스테파니 선은 2017년 이후 휴식을 취했던 싱가포르 가수인데, 자신의 컴백을 목도하게 되었지만, 사실상 그녀가 아닌 그녀의 AI 복제품이었습니다. 그녀의 AI가 생성한 보컬이 담긴 노래들이 이전 노래보다 더 인기를 끌자, 어떤 인간 아티스트도 AI와 경쟁할 수 없다고 말했습니다. \"어떻게 하류에 누군가와 경쟁하나요? 몇 분 단위로 새로운 앨범을 내놓는 사람과 어떻게 싸우나요?\"\n\n폴 맥카트니는 전 동료의 목소리를 부활시켰는데, AI의 도움으로 이제는 사망한 존 레논의 보컬을 사용하여 비틀즈의 마지막 레코드를 만들 수 있게 되었습니다. The Verge의 기사에 따르면, \"과거 녹음물을 복원하는 데 AI를 사용하는 가능성에 흥분하던 맥카트니는 존 레논의 목소리로 자신의 노래를 부르는 것을 듣는 것이 '좀 무서운' 것이라 말했습니다.\"\n\n가장 흥미로운 케이스 중 하나는 클레어 부처의 것인데, 많은 사람들이 그녀의 음악 프로젝트 이름인 그라임즈로 아는 사람들이 대부분입니다. 이론상 엘론 머스크의 자식엄마가 아닌 그녀는 '어버이없는 자'로서 그라임즈라는 '대인견문 인격체'로 음악을 작곡하고 녹음하며 제작하는 창조자입니다. 그녀의 아방가르드 음악은 장르에 도전하며 예술성과 엔지니어링을 융합시키고 있습니다(그녀는 여전히 기테제로 테마 앨범을 만드는 아티스트 중 한 명입니다). 그녀는 완전히 자학하며 종종 별난데 섬세하고 악순함이 없습니다. 그녀는 독특한 음악, 지식, 그리고 삶에 대한 견해로 자신의 이름을 알리게 되었습니다: 그녀는 시대에 따라 변하는 페미니스트로서 역사에 대한 심층적인 이해력이 있고, 지속가능한 에너지를 창조하고 인류를 다중행성종으로 만들며 의식을 보존하는 세 가지 목표를 가진 미래학자입니다.\n\n# 그라임즈의 AI 음악 혁명에서의 역할\n\n<div class=\"content-ad\"></div>\n\n클레어는 2003년 4월 23일에 트윗해 \"내 목소리를 사용한 성공적인 AI 생성 곡에 대해서는 50% 저작권료를 쪼개드릴게요. 협업하는 아티스트와의 계약과 동일한 조건이에요. 벌금 없이 내 목소리 자유롭게 사용해도 돼요. 레이블도 없고 법적 제약도 없어요.\"라며 음악에 AI 클론을 특징으로 한 미래를 공개적으로 받아들였어요.\n\n클레어의 제안은 더욱 현실로 다가왔습니다. 딱 일주일 후에는 Elf.Tech를 선보였는데, 이는 CreateSafe와의 파트너십을 통해 탄생한 AI 보컬 생성기로, CreateSafe는 다양한 도구를 활용하여 아티스트들을 지원하는 기업입니다. Elf.Tech 앱을 사용하기 위해 등록하는 사용자들은 미리 녹음된 노래를 업로드하거나 앱에 직접 보컬을 녹음할 수 있어요. 그리고 해당 보컬은 GrimesAI 음성 프린트로 변환됩니다. CreateSafe의 사이트에는 \"GrimesAI 녹음을 만드는 크리에이터들은 이 새로운 녹음물들을 소유하게 될 거예요. GrimesAI-1은 이 음원 녹음이나 기반이 되는 작품에 대한 소유권을 주장하지 않아요 (Grimes 노래의 커버인 경우 제외).\" 라고 나와 있어요.\n\n<div class=\"content-ad\"></div>\n\n맞아요, 클레어는 다른 창작자들이 그라임스의 보컬을 사용하길 원합니다. 그녀가 클론된 목소리를 사용하는 다른 창작자들의 시나리오를 법적이나 도덕적으로 부당하다고 생각하지 않는다는 것은 몇몇 다른 예술가들이 그렇게 생각하지 않는 것과는 다르다. 그녀는 심지어 자신의 목소리를 특징으로 한 노래를 만드는 과정을 단순화하는 필수 도구를 예술가들과 팬들에게 제공했습니다.\n\n# Elf.Tech를 통해 음악 민주화\n\nElf.Tech는 몇몇 사람들이 생각할 수 있는 클레어의 완전한 허영 프로젝트가 아닙니다. 그녀는 심지어 자신의 목소리나 가수로서의 능력을 좋아하지 않는다고 주장합니다. 클레어는 최근 이비사의 비트포트 국제 음악 정상회의에서 키노트 인터뷰를 하면서 말했습니다. \"아무도 나를 가수로 잘하는 걸로 생각하지 않아. 나는 그냥... 부디 나를 가수라고 부르지 말아줘. 사람들이 들어가서 내가 전문적으로 한다고 생각한다면... 나에게 좋은 모습이 아니야.\"\n\n이 프로젝트의 핵심은 AI가 세상에 미칠 긍정적인 영향과 AI 혁명의 중심에 서기를 원하는 그녀의 신념에 관한 것입니다.\n\n<div class=\"content-ad\"></div>\n\n지난 국제 음악 정상 회의에서 클레어는 Elf.Tech을 창립하기 전에 AI 기술을 활용하는 기업들에 전화를 걸어 그들의 발전 상황을 살펴볼 수 있는지 여쭸었던 경험에 대해 이야기했습니다. 이 경험이 그녀를 \"연구 심층 탐구\"에 이끄는데 큰 역할을 했고, 그 결과 음악적으로 하는 일을 \"재조정\"하게 되었을 것으로 보입니다. 이로써 Elf.Tech를 창립하게 된 것으로 예상됩니다.\n\nElf.Tech는 음악의 민주화를 목표로 하는 고귀한 야망의 결과물입니다. 클레어는 세계가 대체로 AI로 혜택을 받을 수 있다고 믿지만, 그녀 자신은 음악 산업에 초점을 맞추고 있습니다. 음악 산업에서 \"정말 많은 관문이 있다\"며 \"저작권이 최악이야\"라고 주장합니다. 그녀는 역사상 위대한 예술은 알려지지 않은 예술가들이 만든다고 말합니다. 고대 이집트의 큰 피라미드를 상상해보세요. 현재 예술이 자아와 너무 뒤얽혀있는 것은 아주 \"현대적인 개념\"이며, 클레어는 이를 버릴 필요가 있다고 생각하는 것으로 보입니다.\n\n회의에서 그녀가 말한 내용을 요약하면 다음과 같습니다: \"음악 산업은 매우 변호사들에 의해 규정되어 왔는데, 이것이 창의성을 제약하는 구속을 가하고 있다고 생각해요. 예술에서 가장 위대한 순간들은 저작권이 가장 없을 때, 예를 들어 랩의 초기 시기나 샘플링의 초창기처럼 말이에요.\"\n\n저작권 제약으로 인해 발생하는 문제뿐만 아니라 AI가 해결할 수 있는 가능성이 많을 뿐만 아니라, AI가 창조할 수 있는 팬과의 상호 작용 가능성도 무수히 존재합니다. 클레어는 지적 재산권을 사용하는 팬덤들을 처벌하지 않는 실제 기업들의 사례에 근거해 이런 주장을 합니다. 그러한 팬덤들이 많은 멋진 예술 작품을 만들어내느라는 점을 생각해보세요. 음악에서 AI의 광범위한 활용을 가능하게 함으로써, 클레어와 그녀의 팀이 \"공동창작물\"로 틀어놓은 놀라운 팬 아트가 탄생할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n물론 그녀는 복제된 AI 생성 보컬의 잠재적 위험을 인지하고 있습니다.\n\n콘센트에 대한 그녀의 생각을 물었을 때, 그녀는 예술가가 동의하기 전에 그들의 목소리가 사용될 때 좋다고 분명히 했습니다. 특히, 다른 창작자들에 의해 사용되는 예술가들은 예술적 통제를 포기할 것이기 때문에 이러한 동의가 중요하다고 말했습니다.\n\n죽은 가수들의 목소리 사용에 대한 그녀의 생각은 조금 덜 형성되어 있지만, 죽은 사람들은 목소리가 사용될 동의를 줄 수 없기 때문에 이 문제가 복잡하다는 점을 인정했습니다. 그녀는 “정말 어렵다”며 이야기했습니다. “아마도 아니라고 말할 것 같아” (즉, 죽은 가수들의 목소리는 사용되지 말아야 한다는 의미). “하지만 프린스 같은 사람은 좀 괜찮아 할 것 같아”라고 말했습니다. 그녀는 또한 예술가나 소비자들이 죽은 가수들의 목소리를 선호함으로써 새로운 가수가 음악계에 진입하기 어려워질 것을 우려한다고 말했습니다. 만약 모두가 마이클 잭슨의 목소리를 사용하기를 원한다면, 세상은 다음 마이클 잭슨을 어떻게 발견할 수 있을까요?\n\n음악 써밋에서 인터뷰어가 클레어에게 물었습니다. “만약 누군가가 당신의 목소리를 사용해 끔찍하고 싫어하는 무언가를 만들었다면 어떻게 하시겠어요?” 클레어는 “나는 그들이 그렇게 만들었으면 하는데”라고 대답했습니다. 인간들은 AI에 의해 가져다줄 위험에 대해 개방해야 하며 그 결과를 지켜봐야 한다고 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n키노트 인터뷰에서 클레어가 AI로 생성된 보컬이 인간 보컬리스트를 앞으로 가려지게 할 수 있는 가능성에 대해 이야기하지는 않았지만, 클레어는 인간들이 AI의 한계를 집단적으로 이해하지 못하고 있다고 말했으며, 그녀는 AI가 우리의 모든 일에서 우리보다 우수해져서 우리를 이기게 될 것이라고 믿는다.\n\n# AI 음악 배포의 현재 법적 기술적 문제들\n\nElf.Tech의 출시 이후, YouTube와 스트리밍 사이트에서 여러 개의 GrimesAI 비디오가 확산되었습니다. 그러나 이 중 많은 비디오들이 흐릿한 법적 문제 때문에 스트리밍 사이트에서 삭제되었는데, Grimes 팀이 이 문제에 대해 노력하고 있다고 합니다.\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_3.png)\n\n<div class=\"content-ad\"></div>\n\n국제 음악 정상회의 중에 클레어는 스트리밍 서비스가 \"AI\"로 명확하게 표시된 AI 음악 하위 섹션이 생성될 것을 상상한다고 언급했습니다. 아마 그녀의 팀의 주요 목표 중 하나는 플랫폼에서 AI 음악을 위한 지정된 공간을 마련하는 것입니다. 국제 음악 정상회의에서 그녀가 한 말을 요약한 것이 여기 있습니다: \"우리 팀과 저는 정말 스포티파이에게 AI 섹션을 만들 것을 촉구하고 싶어합니다. 그 플랫폼에서 가수들은 최고의 트랙, 앨범 및 신작을 가지고 있죠; 스포티파이가 AI 섹션도 만든다면, 청취자들이 음악을 구분하고 'AI'로 표시된 음악이 아티스트의 창작물이 아님을 이해하기가 더 쉬울 것입니다. 그렇게 하면 품질 관리가 좀 더 쉬워질 거에요. 이 AI가 정말 새로운데 음악 산업이 이를 대비하도록 구성되어 있지 않아요, 그래서 필요한 변경을 해야 해요.\"\n\n저작권에 대한 클레어의 싫증에도 불구하고, 그녀와 그녀의 팀은 여전히 그녀의 비전을 실현하기 위해 음악 저작권의 복잡한 세계를 탐험해야 했습니다. 그들이 경험한 대부분의 문제는 배급과 관련이 있습니다: 주요 스트리밍 서비스 중 일부가 AI를 사용한 음악을 차단하고 있기 때문에, 창작자들이 GrimesAI 보컬을 사용하는 음악을 유통할 수 있게 어떻게 할 수 있을까요? 그 음악 산업이 그러한 음악에 대한 윤리가 격하게 논의되고 있는 상황에서, 아직 AI 지원 음악을 다루기에 적합하게 준비되어 있지 않기 때문에 어려움을 겪고 있습니다.\n\n그들은 마침내 어떤 진전을 이룬 것으로 보입니다.\n\n자립 발매 아티스트를 위한 음악 유통업체인 TuneCore가 CreateSafe와 Grimes와 협력하여 스트리밍 플랫폼에 AI 음악을 선보이는 데 기여했습니다. 그들의 주요 역할은 이러한 일에 관련된 모든 법적 및 기술적 사항들을 처리하는 것인 것 같습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_4](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_4.png)\n\nTunecore의 CEO에 따르면,\n\n이 협력의 결과는 이러한 공동 창작물이 라이선스 프로세스를 보다 쉽게 통과하도록 지원되어 저작권 관련 문제를 회피할 수 있다는 것입니다. GrimesAI를 이용하는 아티스트들은 음악을 제출하려면 Elf.Tech를 통해 배포 비용을 지불하거나 자체 라이선스 승인을 요청해야 합니다. 두 가지 방법 모두 승인이 필요하며, 노래가 충족해야 할 제약 사항과 특정 기준이 있습니다. 클레어는 아직 저작권을 무력화시키지는 않았습니다. 그녀는 오히려 그것과 함께 춤추는 법을 익혔습니다.\n\n2023년 6월 6일의 트윗에서, 클레어는 미래에 더 많은 변화가 있을 것이라 시사했으며, 이는 더 큰 스트리밍 서비스인 Spotify와 같은 곳도 곧 자신들의 플랫폼에서 AI 생성 보컬을 허용할지도 모른다는 것을 의미할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_5.png\" />\n\n아직 큰 플랫폼에서 AI 음악을 허용할지 여부에 대한 업데이트가 제공되지 않았습니다.\n\n생성적 AI는 다양한 형태의 예술을 민주화하고, 예술 창작을 쉽고 매우 자동화할 수 있도록 합니다. 음악 산업에서는 이는 결국 새로운 또는 훈련이 덜 된 예술가들이 더 쉽게 진입할 수 있다는 것을 의미할 수 있으며, 창의적 과정의 일부를 쉽게 할 수도 있습니다. 그러나 그에는 악의적인 목적으로 다른 사람의 음성을 사용하는 사람들, 다른 사람들의 음성으로 수익을 얻는 사람들, 그리고 인간 예술가들이 그들의 AI 상대방이 더 인기가 많아지면 잊혀지는 등 부정적인 가능성이 딸려옵니다.\n\n시간은 이 기술을 사실로 어떻게 사용할지를 말해줄 것이지만, Grimes는 음악계의 실험대로 나서고 있습니다. 우연한 결과의 법칙이 승리할 것이라는 것을 그녀도 알지만, 그녀는 이를 실험하려고 준비가 되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_6.png)\n\n이미 어려운 상황을 마주했어요. 그녀가 트윗에서 '그라임스의 모습'을 사용해 '나쁜 마음 바이러스'를 퍼뜨리는 콘텐츠를 제거해 달라고 요청할 것이라고 밝힌 것을 알 수 있었어요. 이는 일부 사람들이 그라임스 AI 보이스프린트를 악용했을 수도 있다는 신호예요.\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_7.png)\n\n그리고 떠오르는 잠재적 무명의 미래를 조금 맛 본 것으로 보입니다. 2023년 5월 8일 트윗에서 \"사실, 사람들이 나보다 경쟁적으로(아니면 더 나은가요??) 퀄리티 좋게 그라임스 같은 노래를 만들기 시작한 것이 약간 스트레스 받게 만드네요. 그러나 또한 이게 또 다른 커리어에서 죽고 다시 부활할 가장 아름다운 시적인 방법일지도 몰라요.\"라고 썼어요.\n\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_8.png)\n\n물론, 클레어 부셰의 경우에는 AI 생성 보컬을 둘러싼 많은 사례 중 하나일 뿐이며, AI 생성 또는 지원 형태를 사용하는 음악과 관련된 사례는 더욱 많습니다. 그녀는 창의적인 통제를 희생하고 자신의 목소리를 누구나의 악기로 사용할 수 있도록 제공함으로써 AI 음악 혁명의 중심에 위치하게 되었습니다.\n\n그녀의 음악 산업에서의 행동과 다른 이들이 그녀의 목표에 대해 얼마나 수용하는지는 예술 전반에 영향을 미칠 것입니다.\n\n작가들도 AI 생성 보컬을 둘러싼 논쟁의 부작용을 볼 것입니다. 모든 이러한 생성적 AI에 관한 논쟁은 교차되기 때문입니다. 예를 들어, 사망한 작가들이 AI \"쓰기 클론\"을 통해 그들이 완결하지 못한 시리즈를 마무리해야 하는가? 오디오북을 만드는 작가들은 어떻게 AI 생성 보컬에 접근해야 하는가 - 그러한 윤리적 고민을 어떻게 해결해야 하는가? 작가들은 대형 언어 모델이나 유사한 AI들에 의해 자신의 저자 \"목소리\"가 복제된 것에 대해 어떻게 생각하는가?\n\n<div class=\"content-ad\"></div>\n\n우리는 낯선, 탁한 물속에 있어요. 그리고 깊이에 기다리는 것은 알 수 없지만, 가능성은 두려울 만큼 두렵고 흥미롭습니다.\n\n(*저스틴 콕스의 Medium 기사 덕분에 Stefanie Sun 사건에 대해 알게 되었어요!)","ogImage":{"url":"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_0.png"},"coverImage":"/assets/img/2024-06-19-TheWeirdEthicsofAI-GeneratedVocals_0.png","tag":["Tech"],"readingTime":9}],"page":"61","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true}