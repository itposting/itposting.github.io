{"pageProps":{"posts":[{"title":"고급 계산을 위한 클러스터 컴퓨터 활용 포괄적 가이드","description":"","date":"2024-06-19 02:54","slug":"2024-06-19-UtilisingaClusterComputerforAdvancedComputationsAComprehensiveGuide","content":"\n\n<img src=\"/assets/img/2024-06-19-UtilisingaClusterComputerforAdvancedComputationsAComprehensiveGuide_0.png\" />\n\n계산, 프로그래밍, 기계 학습, 신경망, 인공 지능 및 로보틱스를 위해 조립된 클러스터 컴퓨터를 사용하는 것은 몇 가지 단계가 필요합니다. 여기에 시작하는 데 도움이 되는 포괄적인 안내서가 있습니다:\n\n클러스터 설정\n\n하드웨어 설정\n\n<div class=\"content-ad\"></div>\n\n클러스터 내의 각 컴퓨터(노드)가 네트워크에 올바르게 연결되었는지 확인해주세요.\n\n이더넷 또는 인피니밴드와 같은 고속 네트워킹 하드웨어를 사용해주세요. 모든 노드에 안정적인 전원 공급을 확인해주세요.\n\n밀집된 연산 중에 오버히팅을 방지하기 위해 적절한 냉각이 되어 있는지 확인해주세요.\n\n## 소프트웨어 설정\n\n<div class=\"content-ad\"></div>\n\n- 운영 체제: 모든 노드에 Linux 배포판을 설치하세요. 고성능 컴퓨팅에서 널리 사용되는 운영 체제입니다.\n- 네트워킹: 모든 노드가 통신할 수 있도록 네트워킹을 구성하세요. 일반적으로 노드 간 비밀번호 없는 통신을 위해 SSH 키를 설정하는 것이 필요합니다.\n- 클러스터 관리 소프트웨어: Apache Hadoop, Kubernetes 또는 OpenMPI와 같은 클러스터 관리 소프트웨어를 설치하여 노드 간 작업을 관리하고 조율하세요.\n\n환경 설정하기\n\n분산 파일 시스템\n\n- HDFS: Hadoop 기반 설정에 대해, Hadoop 분산 파일 시스템(HDFS)을 설치하고 구성하여 노드 간 데이터를 관리하세요.\n- NFS/GlusterFS: Hadoop이 아닌 설정에 대해, NFS 또는 GlusterFS를 공유 저장소로 활용해보세요.\n\n<div class=\"content-ad\"></div>\n\n소프트웨어 라이브러리 및 도구\n\n- 프로그래밍 언어: 필요한 프로그래밍 언어(예: Python, C++, Java)가 설치되어 있는지 확인합니다.\n- 라이브러리: 머신러닝 및 데이터 처리를 위한 관련 라이브러리를 설치합니다 (예: TensorFlow, PyTorch, Scikit-Learn, NumPy).\n- 컨테이너화: Docker 또는 Singularity를 사용하여 클러스터 전체에서 일관된 환경을 생성하고 배포합니다.\n\n작업 구성 및 실행\n\n## 작업 예약\n\n<div class=\"content-ad\"></div>\n\n작업 예약 소프트웨어인 SLURM, PBS 또는 Kubernetes를 사용하여 작업을 관리하고 리소스를 할당하세요.\n\n필요한 리소스를 지정하는 작업 스크립트를 작성하세요(예: 노드 수, CPU/GPU 요구 사항) 및 실행할 작업.\n\n프로그래밍 및 개발\n\n- 분산 컴퓨팅: 여러 노드를 활용할 수 있는 프로그램을 작성하세요. MPI (메시지 패싱 인터페이스) 애플리케이션의 경우 OpenMPI 또는 MPICH와 같은 라이브러리를 사용하세요.\n- 병렬 처리: Python의 Dask나 대용량 데이터 처리를 위한 Spark와 같은 병렬 처리 라이브러리를 사용하세요.\n- 머신 러닝 프레임워크: TensorFlow나 PyTorch와 같은 분산 훈련을 위해 프레임워크를 구성하세요. 이는 매개변수 서버와 워커 노드 설정을 포함할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n특정 응용 프로그램\n\n기계 학습 및 신경망\n\n- 분산 훈련: TensorFlow의 tf.distribute.Strategy 또는 PyTorch의 torch.distributed를 사용하여 여러 노드에 걸쳐 훈련을 분산시킵니다.\n- 데이터 처리: 데이터 파이프라인이 모델에 데이터를 효율적으로 공급할 수 있도록 하고, 분산 데이터 저장 및 처리 시스템을 사용할 수 있습니다.\n\n인공 지능\n\n<div class=\"content-ad\"></div>\n\n- 추론: 대규모 추론 작업을 위해 클러스터 전체에 훈련된 모델을 배포합니다.\n- 모델 서빙: TensorFlow Serving 또는 TorchServe와 같은 도구를 사용하여 모델 서빙을 관리하고 확장합니다.\n\n로봇공학\n\n- 시뮬레이션: Gazebo와 같은 도구를 활용하여 복잡한 고품질 시뮬레이션을 클러스터를 활용하여 실행합니다.\n- 제어 알고리즘: 실시간으로 실행될 수 있는 고급 제어 알고리즘을 개발하고 클러스터 전체에 분산하여 배포합니다.\n\n모니터링 및 유지보수\n\n<div class=\"content-ad\"></div>\n\n**모니터링 도구**\n\n- 리소스 모니터링: 프로메테우스, 그라파나 또는 갱글리아 같은 모니터링 도구를 사용하여 클러스터의 성능과 리소스 사용량을 추적합니다.\n- 로깅: ELK 스택(Elasticsearch, Logstash, Kibana)이나 플루언트드 같은 도구를 활용하여 중앙 집중식 로깅을 구현하여 모든 노드에서 로그를 수집하고 분석합니다.\n\n**유지 보수**\n\n소프트웨어 및 라이브러리를 최신 상태로 유지하여 보안과 호환성을 보장하세요.\n\n<div class=\"content-ad\"></div>\n\n중요한 데이터와 구성을 정기적으로 백업하여 데이터 손실을 예방하세요.\n\n예제 워크플로우\n\n다음은 클러스터에서 머신 러닝 모델을 학습하는 예제 워크플로우입니다:\n\n- 데이터 준비: HDFS 또는 다른 분산 파일 시스템을 사용하여 데이터를 저장하고 전처리합니다.\n- 환경 설정: Docker를 사용하여 모든 종속성이 포함된 컨테이너를 생성하고 노드 간에 배포합니다.\n- 작업 제출: SLURM을 사용하는 작업 스크립트를 작성하여 리소스를 요청하고 TensorFlow를 사용하여 분산 훈련 작업을 실행합니다.\n- 모델 훈련: 스크립트는 여러 노드 간에 훈련을 시작하며, 각 노드는 모델 훈련 프로세스의 일부를 실행합니다.\n- 모니터링: Grafana를 사용하여 훈련 진행 상황과 리소스 이용을 모니터링합니다.\n- 모델 배포: 훈련이 완료되면 TensorFlow Serving을 사용하여 모델을 대규모 추론에 배포합니다.\n\n<div class=\"content-ad\"></div>\n\n고급 계산을 위한 클러스터 컴퓨터를 설정하고 사용하는 것은 하드웨어와 소프트웨어의 신중한 계획과 구성을 필요로 합니다. 분산 컴퓨팅 프레임워크, 기계 학습 라이브러리 및 효과적인 모니터링 도구를 활용하여 클러스터 전반에 걸쳐 복잡한 계산과 AI 애플리케이션을 효율적으로 실행할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-19-UtilisingaClusterComputerforAdvancedComputationsAComprehensiveGuide_0.png"},"coverImage":"/assets/img/2024-06-19-UtilisingaClusterComputerforAdvancedComputationsAComprehensiveGuide_0.png","tag":["Tech"],"readingTime":4},{"title":"신기한 여행 스탠포드의 매직 월드 크리에이터","description":"","date":"2024-06-19 02:53","slug":"2024-06-19-WonderJourneyStanfordsMagicalWorldCreator","content":"\n\n제 뉴스레터에서 최근 세계적인 Fei-Fei Li의 Stanford 연구소에서 만든 최신 모델에 대해 이야기했었죠. 그 모델은 명령으로 무한한 마법의 3D 세계를 만들어냈습니다.\n\n하지만 저는 그 모델의 깊은 부분까지 파헤치게 되었고, 그 모델에 너무 매료되어 세계에서 가장 진보된 텍스트/이미지-3D 모델이 어떻게 작동하는지 상세히 설명하고 싶어졌습니다.\n\n이 모델은 게임, 가상 현실, 증강 현실, 혼합 현실에 혁명을 일으킬 수 있을 뿐만 아니라, Fei Fei Li 자신이 시사한 대로, AI가 우리의 세계를 더 잘 이해할 수 있는 세계 모델을 만드는 데 도움이 될 수 있습니다.\n\n# 마법 창조하기\n\n<div class=\"content-ad\"></div>\n\nWonderJourney는 텍스트 설명 또는 이미지를 기반으로 무한하지만 일관된 3D 장면을 생성하는 AI 모델입니다.\n\n시각적으로 완벽하지는 않지만 비디오의 모든 것이 완전히 AI로 생성된 것이라는 아이디어는 정말 놀라운 것이죠.\n\n하지만 이것이 어떻게 작동하는 걸까요?\n\n## 모듈식 접근\n\n<div class=\"content-ad\"></div>\n\nWonderJourney는 세 가지 구성 요소로 나뉩니다:\n\n- LLM: 다음 장면을 생성하는 데 책임을 지는 대형 언어 모델(Large Language Model).\n- VSG(Visual Scene Generator): LLM의 다음 장면 텍스트 설명과 현재 장면 이미지를 입력으로 받아 다음 3D 장면을 생성하는 모델.\n- VLM validator: 새로 생성된 장면을 검사하고 품질이 충분히 높지 않은 경우 재시도를 요청하는 Vision Language Model.\n\n전체 모델의 표현은 다음과 같습니다:\n\n![WonderJourney Model](/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png)\n\n<div class=\"content-ad\"></div>\n\n이해하기 어려운 내용이죠. 다양한 기술적 구성 요소에 대해 설명하기 전에 완전한 예시를 보는 것이 좋습니다:\n\n- 사용자가 요청한 내용: \"산속의 아늑한 마을, 자갈길과 나무집이 있는 곳. 뒤쪽에 눈을 덮은 봉우리가 솟아 있습니다.\"\n- LLM이 새로운 장면 생성: \"아늑한 마을을 지나 숲으로 들어가면, 땅에 입체적인 그림자를 드리우는 덤불들이 보입니다.\"\n- Visual Scene Generator가 다음 3D 장면을 생성하며 마을을 멀리 뒤쪽에 밀어 넣어 숲으로 이동하는 느낌을 전달합니다.\n- VLM이 새로운 장면을 확인하고, 우리는 이 과정을 반복합니다.\n\n![이미지](/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_1.png)\n\n이제 전체적인 파이프라인을 이해했으니, 생각해볼 점은 이 모든 것이 어떻게 작동하는 걸까요?\n\n<div class=\"content-ad\"></div>\n\n## 다양한 모델 집합\n\n원더저니의 멋진 점 중 하나는 그 구성 요소들이 모듈식이라는 것입니다. 즉, 좋아하는 LLM, VSG 또는 VLM을 사용할 수 있다는 뜻이죠. 그러나 원더저니에는 몇 가지 중요한 모델이 포함되어 있습니다.\n\n따라서, 이해를 돕기 위해 3D 장면이 어떻게 생성되고 카메라의 역할에 대해 상세히 설명하면서 전반적인 내용을 설명하는 것이 좋을 것 같아요.\n\n## 2D에서 3D로, 그리고 그 반대로\n\n<div class=\"content-ad\"></div>\n\n3D 장면을 논의할 때, 화상의 경우를 제외하고는 여전히 2D 화면에 표시해야 합니다 (가상 헤드셋 제외, WonderJourney의 사용 사례가 아닙니다).\n\n다시 말해, 전반적인 작업의 많은 부분은 3D 장면이 \"카메라\"의 2D 렌즈 (사용자의 화면)로부터 어떻게 보여질지 계산하는 것입니다.\n\n그러므로, 새로운 장면을 사용할 때마다, WonderJourney는 2D 이미지를 사용해서 새로운 3D 장면을 생성하지만, 결국 이 장면은 화면에 다시 2D로 투영됩니다.\n\n이를 알고 나면 이제 WonderJourney가 어떻게 작동하는지 이해할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 깊이, 포인트 클라우드 및 투영\n\n새로운 장면을 생성하는 전체 프로세스는 다음과 같습니다:\n\n![이미지](/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_2.png)\n\n- 먼저, 모델은 초기 조건으로 텍스트 또는 이미지를 취하며, 사용자가 텍스트 설명만을 제공한 경우 이미지를 생성합니다.\n- 이 입력을 사용하여, 먼저 이미지에서 각 요소의 깊이를 추정하며, 즉, 각 객체가 실제로 얼마나 먼지 가까운지를 추정합니다 (예: 하늘은 항상 '멀리있음'으로 추정되어야 합니다).\n- 다음 단계는 깊이 추정으로부터 포인트 클라우드를 생성하는 것이며, WonderJourney는 이를 정제하여 요소 사이의 '날카로운' 경계를 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n그러나, 저희는 여전히 현재 뷰를 작업 중이며 새로운 뷰가 필요합니다. 이를 위해 2D 화면(우리)에서 3D 장면을 볼 '카메라'는 뒤로 밀려서 이전 장면이 멀리 뒤쪽에 나타나도록 하여 '우리가 그것에서 멀어지고 있다'는 아이디어를 전달합니다. 이제 다음 장면에 나타날 현재 장면의 일부가 위치하고, 새 프레임의 그 부분이 렌더링됩니다.\n\n그런 다음, 이 부분적 렌더링과 다음 장면의 LLM(언어-이미지 모델) 설명을 사용하여 WonderJourney는 나머지 장면을 outpaint하는데, 이 경우에는 Stable Diffusion 모델을 사용하지만, 중요한 건 LLM의 새로운 장면이어야 하는 내용에 따라 조건이 부여된다는 것입니다.\n\n마지막으로, 새 이미지를 얻었으면, 우리는 간단히 깊이 추정 및 정제 프로세스를 반복하여 필요에 따라 여러 가지 대안적인 뷰를 생성하여 새로운 포인트 클라우드를 만듭니다.\n\n이 새로운 포인트 클라우드는 본질적으로 새로운 3D 뷰를 구축하며, VLM(시각 언어 모델)이 평가합니다. 품질 임계값을 충족하면, 해당 장면이 뷰어의 2D 화면에 투사되고, 프로세스가 반복됩니다.\n\n<div class=\"content-ad\"></div>\n\n여기 있어요, 끝없이 이어지고 항상 일관된 3D 여행이 마련되었습니다.\n\n# 모든 형태의 정복\n\n한 번 더, 학계는 사용자의 텍스트 또는 이미지 명령에 기반한 무한한 3D 장면을 생성할 수 있는 첫 번째 모델의 가능성을 확장했습니다.\n\n마지막으로, Fei Fei Li의 생각을 빌리자면, 강력한 3D 생성 모델을 구축하는 것은 AI에게 우리 세상에 대한 큰 공간적 이해력을 제공할 수 있으며, 이는 그들의 지능을 향상시키는 방법으로 활용될 수 있고, 누가 알겠으나, 구체적 AI 모델, 즉 인간형 로봇의 등장을 용이하게 할 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n현실 세계와 상호 작용할 수 있는 능력을 기계에 부여하면, 시뮬레이션 환경을 통해라도 사람들과 격차를 줄일 수 있을 것입니다. 우리는 관찰과 세상과의 상호 작용을 통해 배우기 때문에, 오늘날의 최첨단 AI 모델들을 뛰어넘는 능력을 갖게 됩니다, 어떻게 ChatGPT나 Claude가 감탄을 자아내는지와 상관없이요.\n\n우리가 이것이 옳은 길이라고 주장할 수는 없겠지만, 텍스트를 단순히 모델에 던지고 AGI로 성장할 것을 바라는 것보다는 훨씬 매력적으로 보입니다.","ogImage":{"url":"/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png"},"coverImage":"/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png","tag":["Tech"],"readingTime":4},{"title":"사고, 빠르고 느린, LLMs와 PDDL과 함께","description":"","date":"2024-06-19 02:50","slug":"2024-06-19-ThinkingFastandSlowwithLLMsandPDDL","content":"\n\n\"ChatGPT가 실수를 할 수 있다는 사실을 확인해 주세요.\" 이제 프롬프트 바로 아래에 적혀 있고, ChatGPT가 날짜부터 전체 참조까지 아무 것이나 단정적으로 만들어 내는 것에 대해 익숙해졌습니다. 하지만 기본적인 추론에 대해서는 어떨까요? 인공지능(AI) 연구 초기에 나온 간단한 탑 재배치 작업을 살펴본다면, 대형 언어 모델(Large Language Models, LLM)이 어떻게 한계에 도달하는지 보여주고, 이에 대처하기 위해 계획 도메인 정의 언어(Planning Domain Definition Language, PDDL)와 상징적 해결사들을 소개하겠습니다. LLM은 본질적으로 확률적이므로, 이러한 도구가 미래의 AI 에이전트의 내장될 가능성이 높습니다. 이는 상식적인 지식과 날카로운 추론을 결합할 것입니다. 이 글에서 최대한 많은 정보를 얻으려면, VS Code의 PDDL 확장 프로그램과 planutils 플래너 인터페이스를 사용하여 직접 PDDL 환경을 설정하고 예제를 따라해 보세요.\n\n대형 언어 모델(LLM)에서는 각 문자가 응답의 이전 문자뿐만 아니라 사용자의 프롬프트의 모든 이전 문자에 대해 조건이 걸립니다. 거의 모든 것을 학습한 LLM은 신의 영역이 되었을 뿐만 아니라 재치도 갖추게 되었습니다. 그러나 LLM이 실제로 문제에 대해 생각하려 하지 않고 근본적으로 게으르다는 것을 깨닫는 데 오래 걸리지 않습니다. 이는 \"인공지능\" 분야의 고전적인 문제 도메인인 \"블록 세계\"에서 나오는 간단한 예제로 설명할 수 있습니다. 아래 그림에 나타난 것처럼, 왼쪽의 탑을 오른쪽의 탑으로 변환하는 작업을 고려해보세요.\n\n![image](/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_0.png)\n\n여기에서 작업은 왼쪽의 탑을 오른쪽의 탑으로 바꾸는 것입니다. 로봇이 다음과 같은 기능이 있다고 가정합니다:\"\n\n<div class=\"content-ad\"></div>\n\n- pickup `색깔`: 테이블의 아무 곳에 색깔이 `색깔`인 블록을 집어올립니다.\n- putdown `색깔`: 테이블의 아무 곳에 색깔이 `색깔`인 블록을 내려놓습니다.\n- unstack `색깔1` `색깔2`: 맨 위에 `색깔2`가 있는 탑에서 `색깔1` 색을 가진 블록을 집어올립니다.\n- stack `색깔1` `색깔2`: 맨 위에 `색깔2`가 있는 탑에 `색깔1` 색을 가진 블록을 위에 놓습니다.\n\n그래서 ChatGPT3.5는 이런 문제에 어떻게 대처하나요? 이것이 프롬프트입니다:\n\n![이미지](/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_1.png)\n\nChatGPT는 주어진 구문 형식으로 필요한 조치 순서를 즉시 제공합니다. 놀랍죠! 하지만 기다려주세요. 올바른 조치는 처음 세 가지만 맞는 것 같습니다! 로봇은 먼저 파란색 블록을 탑의 맨 위에서 어디든 테이블로 옮기고, 그런 다음 녹색 블록도 동일한 작업을 합니다. 이제 모든 블록이 테이블 위에 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![ThinkingFastandSlowwithLLMsandPDDL_2](/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_2.png)\n\nChatGPT는 지금 파란 블록을 집어 빨간 블록 위에 쌓으라고 제안했습니다. 하지만 이것은 우리가 원하는 바가 전혀 아닙니다: 파란 블록은 바닥에 있어야 합니다. 또한 탑이 완전하지 않습니다. 우리가 도와보겠습니다:\n\n![ThinkingFastandSlowwithLLMsandPDDL_3](/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_3.png)\n\nChatGPT는 단서를 받고 단순히 마지막에 추가했습니다. 이제 초록 블록이 파란 블록 위에, 그리고 파란 블록이 빨간 블록 위에 쌓여 있습니다. 출력을 올바른 형식으로 만들기 위해 더 많은 단서를 제공함으로써 해결 할 수 있을 수도 있지만, 우리는 모두 ChatGPT가 실제로 두 가지 동일하게 잘못된 솔루션 사이를 왔다갔다하며 순환하기 시작하는 것을 보았습니다.\n\n\n<div class=\"content-ad\"></div>\n\nChatGPT4o는 조금 더 나은 작업을 수행하며, 동일한 프롬프트에 대해 다음 출력물을 생성합니다:\n\n```js\nunstack blue green\nputdown blue\nunstack green red\nputdown green\npickup blue\nstack green blue\npickup red\nstack red green\n```\n\n이 사실상 맞지만, 중간에 있는 \"pickup blue\"에 대해 문제가 발생합니다. \"You cannot 'stack green blue' after 'pickup blue' as the robot is still holding 'blue'\"라는 불만에 의해, ChatGPT-4o는 마지못해 다음과 같이 따릅니다:\n\n```js\nunstack blue green\nputdown blue\nunstack green red\nputdown green\npickup blue\nputdown blue (if needed, otherwise skip)\npickup green\nstack green blue\npickup red\nstack red green\n```\n\n<div class=\"content-ad\"></div>\n\nChatGPT-4o가 실제로 ChatGPT-3.5보다 큰 발전이었다는 것이 밝혀졌어요. 초기 프롬프트에 더 많은 정보를 추가하는 것도 도움이 된다는 것을 알게 되었어요. 그러나 위에 표시된 최적의 행동 순서를 ChatGPT에 얻게 하는 것은 매우 어렵고, 더 복잡한 제약 조건에는 \"한 번에 테이블에 블록을 두 개만 놓을 수 있다\"거나, 인간형 조립 작업에서 두 팔을 사용하는 것과 같은 것은 전혀 불가능하다는 것이 증명되었어요.\n\nLLM에게 일부 신용을 주자면, 문제가 사실 모호하다고 주장할 수도 있어요. 실제로 위의 행동들을 신중하게 생각해보면 더 많은 오해로 이어질 것이라고 생각돼요. 예를 들어, ChatGPT에게 한 블록을 집을 때 다른 블록을 집기 전에 첫 번째 블록을 놓기 전까지 다른 한에 놓을 수 없게 하는 것을 전혀 알려준 적이 없다는 점이요.\n\n# 계획 도메인 정의 언어\n\n그렇다면 어떻게 이러한 문제를 공식적으로 설명하여 마지막 불확실성의 조각을 제거할까요? 한 가지 방법은 인공지능 계획 커뮤니티에서 표준이 되어온 계획 도메인 정의 언어 (PDDL)입니다. PDDL은 1998년부터 존재해오고 지속적으로 영역을 확장해왔으며, 다양한 문제 해결자를 탄생시켰습니다. 현재 계획 커뮤니티가 다루고 있는 문제 유형을 감을 잡기 위해 2023년 국제 계획 대회 작업을 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\nPDDL 정의는 두 개의 파일로 구성됩니다:\n\n- 도메인\n- 문제\n\n타워 예제를 사용하여 문제를 시작해봅시다:\n\n```js\n(define (problem blocks)(:domain blocksworld)\n\n(:objects\n    red green blue  - block\n    )\n\n(:init\n    (ontable red) ; 블록 red\n    (on green red) ; 블록 green\n    (on blue green)(clear blue) ; 블록 blue\n    (handempty)\n\n)\n\n(:goal (and\n    (on green blue)\n    (on red green)\n))\n)\n```\n\n<div class=\"content-ad\"></div>\n\nPDDL은 s-표현식을 사용하는데, 이는 LISP에 익숙하지 않은 사람들에게는 조금 적응이 필요할 수 있어요. 일반적으로 \"A + B\"라고 말하는 대신에 \"+\" 연산자를 먼저 써서 (+ A B)와 같은 형태로 작성해야 합니다.\n\n위의 예시에서 마지막 부분에서 \"goal\"이 정의되는 부분을 보실 수 있어요. (on green blue)는 \"green on blue\"를 읽고, (on red green)은 \"red on green\"을 읽어요. 마찬가지로 \"and\" 연산자는 두 문장 모두가 참이어야 한다는 것을 보장합니다. 즉, \"red on green and green on blue\"가 됩니다. 괄호들은 또 다른 과거의 요구사항입니다: LISP는 \"List Processor\"의 약자로, 리스트를 Python의 튜플과 유사하게 정의합니다. 예를 들어, (:goal `list`))는 또 다른 리스트를 받아들이는데, 다시 두 개의 리스트를 포함합니다. 여기서 (and `list`)는 내장 연산자이지만 (on `list`)는 아닙니다. 이것이 도메인 파일의 필요성이고, 나중에 소개하도록 하겠습니다.\n\n목표뿐만 아니라, PDDL 문제에는 초기 조건 목록도 필요합니다. 이들은 술어들로 제공되며, True 또는 False만을 가질 수 있는 표현식입니다. PDDL은 이러한 술어들을 (:init `list`) 다음에 오는 리스트에 모아두는데, 여기에는\n\n- (ontable red)\n- (on green red)\n- (on blue green)\n- (clear blue)\n- (handempty)\n\n와 같은 조건들이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이러한 형용사를 변수 또는 함수로 생각하는 것은 유혹적일 수 있습니다. 그러나 이들은 그 둘 다 아닙니다. 단순히 명제입니다. 예를 들어, 문제에 명제 (handempty)가 추가되었다면, 이는 참입니다. 거짓으로 변경하려면 문제에서 제거해야 합니다. 따라서 이는 두 가지 값 중 하나를 포함할 수 있는 변수가 아닙니다. 정의되어 있으면 참이고, 정의되어 있지 않으면 거짓입니다.\n\n나머지 모든 형용사들은 처음 봤을 때에는 함수처럼 보이지만, 이들도 단순히 명제일 뿐입니다. (ontable red)는 빨간 블록이 탁자 위에 앉아 있다고 알려줍니다. (on green red)는 녹색 블록이 빨간 블록 위에 있다고 알려주며, (on blue green)는 파란 블록이 녹색 블록 위에 있다고 시그널을 줍니다. (clear blue)는 파란 블록이 잡을 수 있다는 것을 나타냅니다.\n\n그러나 파라미터 역할을 할 수 없으면 PDDL은 상당히 쓸모가 없을 것입니다. :objects 목록은 형용사를 구성할 수 있는 모든 객체를 정의합니다. 조금 더 엄밀하게 만들기 위해 PDDL은 typing을 제공하기도 합니다. 여기서 \"-블록\"은 빨간색, 녹색, 파란색이 모두 블록 유형임을 나타냅니다. 이렇게 하면 위의 모든 형용사가 블록 유형의 객체와만 작동하므로 논리 오류를 방지하는 데 조금 더 수월해집니다. 또한, 해당 유형의 객체만 고려하여 해결책을 찾는 것이 더 쉬워지며, 이에 따라 필요한 동작만 고려하면 됩니다.\n\n형용사들은 도메인 설명서에서 정의됩니다. 도메인의 이름은 문제 설명서의 :domain 목록에 지정됩니다. 도메인 이름은 도메인 파일의 첫 줄에도 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n(define (도메인 블록월드)\n\n(:requirements :typing :negative-preconditions)\n\n(:types block) \n\n(:predicates\n (on ?a ?b - block)\n (clear ?a - block)\n (holding ?a - block)\n (handempty)\n (ontable ?x - block)\n)\n\n(:action pickup ; 이 액션은 테이블에서 들어올 때만 사용됩니다\n:parameters (?x - block)\n:precondition (and (ontable ?x)\n    (handempty)\n    (clear ?x)\n   )\n:effect (and (holding ?x)\n    (not (handempty))\n    (not (clear ?x))\n    (not (ontable ?x))\n  )\n)\n(:action unstack ; 블록에서 들어올 때만 적합\n:parameters (?x ?y - block)\n:precondition (and (on ?x ?y)\n    (handempty)\n    (clear ?x)\n   )\n:effect (and (holding ?x)\n    (not (handempty))\n    (not (clear ?x))\n    (clear ?y)\n    (not (on ?x ?y))\n  )\n)\n\n(:action putdown\n:parameters (?x - block)\n:precondition (and (holding ?x)\n   )\n:effect (and (ontable ?x)\n    (not (holding ?x))\n    (handempty)\n    (clear ?x)\n  )\n)\n\n(:action stack\n:parameters (?x ?y - block)\n:precondition (and (holding ?x)\n    (clear ?y)\n   )\n:effect (and (on ?x ?y)\n    (not (holding ?x))\n    (handempty)\n    (not (clear ?y))\n    (clear ?x)\n  )\n)\n\n)\n\n이 두 파일을 problem.pddl 및 domain.pddl로 저장하면 VS Code 확장 프로그램을 사용하여 Figure 1에 표시된 것과 같은 계획을 생성할 수 있습니다. 그렇지 않으면 온라인 PDDL 편집기를 사용하고 LAMA 솔버를 사용할 수도 있습니다.\n\n블록월드 도메인을 위한 유형과 술어는 도메인 파일에서 매우 일찍 정의되어 있습니다:\n\n(:types block) \n\n(:predicates\n (on ?a ?b - block)\n (clear ?a - block)\n (holding ?a - block)\n (handempty)\n (ontable ?x - block)\n)\n\n<div class=\"content-ad\"></div>\n\n여기서 사용된 유형 (block만)은 :types 목록에 제공됩니다. 술어는 :predicates에 입력되며 전체를 \"?로 표시된 자리 표시자\"가 사용합니다. 모든 술어가 실제로 위의 패턴을 따르는지 확인하려면 위에 정의된 문제를 확인할 수 있습니다.\n\n유의할 점은 타이핑이 이미 PDDL의 비표준 기능임을 의미합니다. 타입이 사용됨을 파서와 솔버에 알리려면 :requirements 목록의 맨 처음에 :typing이 제공됩니다.\n\n이제 작업을 사용하여 술어를 조작할 수 있습니다. :action은 매개변수, 선행 조건 및 효과로 구성된 목록입니다. 작업은 모든 선행 조건이 True인 경우에만 실행됩니다. 작업의 효과는 술어의 생성 또는 삭제입니다. 여기서는 :negative-preconditions를 추가하여 가능하게 된 (not `list`) 연산자를 사용합니다.\n\n```\n(:action pickup ; 이 작업은 테이블에서 선택하는 것만을 위한 작업입니다\n:parameters (?x - block)\n:precondition (and (ontable ?x)\n    (handempty)\n    (clear ?x)\n   )\n:effect (and (holding ?x)\n    (not (handempty))\n    (not (clear ?x))\n    (not (ontable ?x))\n  )\n)\n\n\n<div class=\"content-ad\"></div>\n\n픽업 액션은 블록 오브젝트 하나의 매개변수를 갖고 있어요. 여기서는 동일한 오브젝트를 가리킬 때 ?x를 사용해요. 액션이 실행되려면 세 가지 조건이 참이어야 해요:\n\n- (ontable ?x)\n- (handempty)\n- (clear ?x)\n\n오브젝트는 테이블 위에 있어야 하고, 그리퍼는 비어 있어야 하며, 오브젝트는 집을 수 있어야 해요. ontable ?x와 clear ?x는 함수가 아니에요. 이것들은 문제의 :init 목록에 제공되었거나 런타임에 액션에 의해 생성되어야 하는 술어들이에요.\n\n여기서 :effect가 등장해요. 이 목록에는 액션이 실행된 후 참이 될 술어들이 포함되어 있어요. 요것들이죠:\n\n<div class=\"content-ad\"></div>\n\n- (?x을(를) 잡고)\n- (손이 비어 있지 않음)\n- (?x가 비어있지 않음)\n- (?x가 테이블 위에 없음)\n\n즉, 작업 (pickup ?x)을 성공적으로 실행하면 로봇이 ?x를 잡고 있게 되며, (손이 비어 있지 않음), (?x가 비어있지 않음) 및 (?x가 테이블 위에 없음)과 같은 예측이 삭제됩니다.\n\n이 설정은 계획을 만드는 방법에 대한 첫 번째 단서를 제공합니다. 원하는 결과로 이어지는 효과를 살펴보고, 동일한 방법으로 선행 조건을 충족하도록 하여 초기 상태에 이르기까지 도달할 수 있습니다. 또는 초기 조건 집합에 모든 가능한 작업을 적용하고 목표를 찾을 때까지 이러한 결과 상태를 처리할 수 있습니다. 이 두 가지 모두 어려운 문제로, 계획은 NP-어렵다고 합니다.\n\n이제 남은 작업을 살펴보겠습니다. 먼저, unstack은 블록 ?x를 블록 ?y에서 집습니다. 이를 위해서는 ?x가 ?y에 있고, 손이 비어 있으며, ?x가 비어 있어야 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n(:action unstack ; block을 가져오기에 적합\n:parameters (?x ?y - block)\n:precondition (and (on ?x ?y)\n    (handempty)\n    (clear ?x)\n   )\n:effect (and (holding ?x)\n    (not (handempty))\n    (not (clear ?x))\n    (clear ?y)\n    (not (on ?x ?y))\n  )\n)\n\n로봇이 블록 ?y를 들 수 있도록 되었습니다. 이에 따라 (handempty), (clear ?x), (on ?x ?y)이 삭제되었습니다. 또한 (clear ?y)가 True로 변경되어, 블록 ?y가 현재 들어올 수 있는 상태가 되었습니다. putdown 및 stack 동작도 동일한 패턴을 따릅니다.\n\n# PDDL 문제 해결\n\n여기서 설명한 계획 문제는 AI 분야의 가장 오래된 주제 중 하나이지만, 여전히 활발히 연구되고 있는 분야입니다. PDDL의 최신 버전에는 시간 및 양에 대한 추론 능력이 포함되어 있으며, 특정 계획 문제는 일부 알고리즘을 사용하여 더 잘 해결할 수 있습니다. 가장 일반적인 플래너 중 하나인 \"FastDownward\" (https://www.fast-downward.org/)는 PDDL 2.1 기능 대부분을 지원합니다. 대부분의 플래너 목록은 https://planning.wiki/ref/planners/atoz에서 찾을 수 있으며, 대부분의 플래너는 지원하는 요구 사항 목록을 표시합니다.\n```\n\n<div class=\"content-ad\"></div>\n\n문제 설명을 공식화하는 것 외에도 AI 커뮤니티는 플래너 인터페이스를 통합하고 https://github.com/AI-Planning/planutils 프로젝트가 도커 컨테이너를 제공하여 다양한 플래너 중에서 선택할 수 있도록 하고 로컬 웹서버를 통해 사용 가능하게 합니다. 이 방법은 VSCode의 Planning Domain Definition Language 확장 기능에 통합되어 있습니다. 구문 강조 기능 뿐만 아니라 해당 도구를 사용하여 초기 및 목표 상태, 그리고 결과 계획을 시각화할 수 있습니다. 또한 블록 작업과 같은 자체 JavaScript 시각화를 추가할 수 있습니다. 이 예제는 여기에서 찾을 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_4.png)\n\nLinux, Mac 또는 Windows에서 planutils를 Docker 컨테이너에 설정하는 것은 VS Code 확장 프로그램 안내에 따라 간단합니다. 그러나 Docker 컨테이너 내의 planutils의 Flask 서버에 액세스할 수 있도록 \"호스트 네트워킹\"을 활성화해야 합니다.\n\n#Planning and ChatGPT\n\n<div class=\"content-ad\"></div>\n\nChatGPT와 달리, 계획자는 항상 올바른 작업 순서를 제시할 것입니다. 특정 문제에 대해 모든 술어 및 동작을 설정하는 것이 번거로워 보일 수 있지만, 실제 환경에서는 그렇게 하는 것이 무리하지 않습니다. 복잡한 여행 일정을 만들거나 긴 구매 주문을 처리하거나 식료품을 쇼핑하거나 복잡한 조립을 실행할 인간형 로봇을 만들기 위해 소프트웨어 에이전트를 구축한다면, 사용 가능한 API 종류를 잘 파악하고 그들이 작동하기 위해 필요한 것들(전제 조건)과 성공적으로 실행된 경우 무엇이 발생할지 알고 있어야 합니다. 그런 다음 계획 실행에는 (1) 세계의 상태를 기반으로 술어 목록을 작성하는 것, (2) 계획자가 하나씩 내뱉는 모든 동작을 호출하는 것, 그리고 (3) 실행 중 환경이 변경될 경우 선택적으로 다시 계획하는 것이 필요합니다. 이 프레임워크를 구현한 후 ChatGPT를 간단히 프롬프트하여 적합한 목표를 생성시킬 수 있습니다:\n\n![이미지](/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_5.png)\n\n이 접근 방식은 결국 동일한 한계에 부딪힐 것이지만, 적절한 목표를 설정하는 것은 \"자동차 조립\"과 같이 수천 개의 동작이 필요할 수도 있는 목표에 대한 긴 목록보다 훨씬 처리가능합니다. 또한 ChatGPT가 심볼의 이름을 어떻게 지정할지 추측했습니다. 블록월드 예시가 매우 잘 문서화되어 있어서 색상을 사용하기로 선택한 것일 수도 있습니다.\n\n# 카운터와 시간을 고려한 계획들\n\n<div class=\"content-ad\"></div>\n\n지금까지는 부울 술어에 대해 이야기했습니다. PDDL의 최신 버전은 양과 시간을 지원합니다. 아래 예시에서는 카운터 변수를 사용하여 초기값이 0이며 3에 도달해야 하는 문제가 제시됩니다.\n\n```js\n(define (problem say-hello-3-times) \n(:domain counter-test)\n\n(:init\n    (= (counter) 0)\n)\n\n(:goal\n    (and \n        (= (counter) 3)\n    )\n)\n)\n```\n\n이 문제를 해결할 액션을 제공하는 도메인은 다음과 같습니다:\n\n```js\n(define (domain counter-test)\n\n(:requirements :strips :fluents)\n\n(:functions\n        (counter)\n)\n\n(:action hello-world\n    :parameters ()\n    :precondition ()\n    :effect (and \n     (increase (counter) 1)\n    )\n)\n\n)\n```\n\n<div class=\"content-ad\"></div>\n\ncounter 함수는 :fluents에서 사용 가능한 functions에 정의되어 있습니다. \"Hello World\"를 출력할 수 있는 hello-world 동작은 그런 다음 (counter를 1 증가시키는) 효과를 제공합니다. PDDL fluents는 시간이 지남에 따라 변할 수 있는 상태 변수입니다. 이는 단순히 카운터 이상의 가치가 있습니다. 연료 수준, 에너지 소비, 또는 이커머스 카트에 있는 승객 또는 상품의 수에 대해 추론할 수 있게 합니다.\n\n따라오신 분들께서는 FastDownward 솔버가 :fluents 요구 사항을 처리할 수 없다는 것을 알 수 있을 것입니다. 이를 처리할 수 있는 계획자는 planutils를 통해 사용할 수 있는 Expressive Numeric Heuristic Search Planner (ENHSP)입니다. planutils 도커 컨테이너에서 planutils install enhsp-2020을 사용하여 설치하거나 온라인 편집기에서 EHSP 솔버를 사용할 수 있습니다.\n\n또한 각각의 동작에 타이밍을 연관시켜 계획을 시간 영역으로 확장할 수 있습니다. 이 내용은 VS Code PDDL 익스텐션 제작자의 이 튜토리얼에서 잘 설명되어 있습니다:\n\n# 조건부 효과\n\n<div class=\"content-ad\"></div>\n\n조건부 효과는 when 키워드를 사용하여 특정 조건에 따라 다른 결과를 지정할 수 있는 기능입니다 (:conditional-effects가 필요합니다). 트럭 적재 예제에서, 상태 표현식 requires-caution은 일반적인 경우 패키지가 부서지기 쉬울 때에만 True로 설정됩니다.\n\n```js\n(define (domain truck)\n\n(:requirements :strips  :conditional-effects)\n(:predicates \n  (in ?package ?truck)  \n  (empty ?truck)\n  (requires-caution ?truck)\n  (fragile ?object)\n  )\n\n(:action load-truck\n    :parameters (?package ?truck)\n    :precondition (and \n                    (empty ?truck))\n    :effect (and\n        (in ?package ?truck)\n        (when (fragile ?package)\n            (requires-caution ?truck))))\n)\n```\n\n이 도메인과 관련된 샘플 문제는 다음과 같습니다:\n\n```js\n(define (problem load-truck) \n(:domain truck)\n\n(:objects truck77 shipment123)\n(:init \n    (empty truck77) \n    (fragile shipment123))   \n\n(:goal (and (in shipment123 truck77)))\n)\n```\n\n<div class=\"content-ad\"></div>\n\nFastDownward를 사용하여이 문제를 해결할 수 있습니다. 불확실성을 구현하는 방법으로 'when'에 대해 생각하는 것은 유혹적입니다. 두 가지 상호 배타적 'when' 문을 사용할 수 있으며, 이를 통해 로봇 장애물을 모델링하는 방법은 인터넷에서 흔히 볼 수 있는 예입니다. 그러나 이는 실시간으로 술어를 평가하지 않기 때문에 실제로 말이 되지 않습니다. 동작의 다른 가지에 확률을 연결할 수 있도록 허용하는 PPDDL(Probabilistic PDDL)이라는 PDDL의 확률론적 버전도 존재합니다. 그러나 PPDDL도 동일한 문제를 가지고 있으며, 확률론적 방식으로 문제를 해결할 수 있게만 해주며 마치 Markov Decision Problem과 유사합니다.\n\n# 최신 트렌드\n\n최근에는 커뮤니티가 직접 Python으로 계획 문제를 구현하도록 이동하는 추세입니다. 예를 들어, PDDL로 가져오고 내보낼 수 있는 Unified Planning 라이브러리가 있으며 최신 솔루션과 통합되어 있으며 리플래닝과 계획 복구를 지원하며 리얼타임 애플리케이션에 중요한 기능입니다. Scikit-decide는이를 한 단계 더 나아가서, 심볼릭 계획 또는 강화 학습과 함께 사용할 수있는 계획 문제에 대한 통합 접근 방식을 제공합니다. 더 많은 정보를 원하시면 ICAPS-2024에서 튜토리얼을 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n상징적 계획자들의 능력은 모든 가능성을 체계적으로 평가하여 수량과 시간에 대한 제약을 고려하여 올바른 작업 순서를 찾는 데 있습니다. 이 능력은 ChatGPT와 같은 LLM의 추론 능력과는 별개입니다. 이 둘의 시스템은 결국 같은 문제를 해결하도록 밀어붙이지만, 이 이분법은 또한 인간 경험을 모델링합니다. 우리의 정신 장치가 한계에 도달하면, 우리는 손전등이나 종이와 연필 또는 다른 도구를 사용하여 알고리즘을 고수하여 문제를 해결합니다.\n\nChatGPT가 훈련을 통해 일반적인 문제 해결자가 되는 것은 그다지 가능성이 낮습니다. 우리가 모든 가능한 영역을 포괄할 수 있는 예제를 제공하는 일은 너무나도 어렵기 때문이며, LLM은 정확성을 강제할 방법을 제공하지 않습니다. 이것은 비즈니스 애플리케이션이나 현실 세계에서 운영되는 로봇과 같은 제품 시스템에게 특히 중요합니다. 불행히도, 모든 솔버가 PDDL의 모든 기능을 지원하는 것은 아니며, 올바른 PDDL 정의와 솔버의 조합을 찾는 것은 어려울 수 있습니다.\n\nChatGPT를 상징적 계획과 보완하는 것 외에도, 오픈 월드 추론과 상징적 계획을 훨씬 더 밀접하게 통합할 수 있는 큰 기회가 있습니다. 예를 들어, LLM은 상식 정보를 사용하여 한 방향으로의 검색을 다른 방향보다 우선시하는 데 사용될 수 있습니다. 마찬가지로, 자연어의 PDDL 기호 및 술어는 OWL-ViT와 같은 도구를 사용하여 실제 세계의 이미지를 감지하는 데 사용될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_0.png"},"coverImage":"/assets/img/2024-06-19-ThinkingFastandSlowwithLLMsandPDDL_0.png","tag":["Tech"],"readingTime":15},{"title":" 변화가 다가오고 있어요","description":"","date":"2024-06-19 02:48","slug":"2024-06-19-Changeiscoming","content":"\n\n## Arondite가 만들고 있는 것을 주도하는 두 가지 큰 트렌드는 무엇인가요?\n\n![이미지](/assets/img/2024-06-19-Changeiscoming_0.png)\n\n이전 글에서 Arondite를 설립한 이유에 대해 소개했습니다. 이번 게시물에서는 우리가 발견한 가장 중요한 기술 트렌드 두 가지와 그들이 제시하는 새로운 기회와 도전에 대해 설명하겠습니다.\n\n### 두 가지 큰 트렌드\n\n<div class=\"content-ad\"></div>\n\n이것들은:\n\n1. 로봇 및 자율 시스템에서의 침체 폭발 현상입니다.\n\n2. 그 시스템을 정의하는 인공 지능의 중요성이 점점 증가하고 있습니다.\n\n로봇 및 자율 시스템의 수가 빠르게 증가하면서 데이터 및 미션 관리의 복잡도가 기하급수적으로 증가하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n한편, 엣지 컴퓨팅 및 전력 효율성의 지속적인 발전은 전자 전투에 빈번히 영향을 받는 전투 공간과 교차하고 있습니다. 결과적으로, 인공지능의 시스템 능력을 정의하는 능력이 가속화되고 있습니다.\n\nAI 기술의 발전이 로봇 및 자율 시스템의 영역으로 흘러들면서, 이러한 시스템들이 더욱 성능이 우수하고 신뢰성이 높아지고 있습니다. 이에 따라 이러한 시스템들은 더욱 가치가 있어지고 이미 진행 중인 이러한 시스템의 폭발적인 성장을 가속화시킵니다.\n\n이 두 가지 추세가 결합함으로써 지수적 변화가 발생하고, 컴퓨팅 분야에서 1970년대에 본 변화와 유사한 로봇 및 자율 시스템의 민주화가 바로 앞으로 다가오고 있음을 의미합니다.\n\n1960년대 후반에는 컴퓨터가 크고 비싼 장비였습니다. 그래서 군사 본부, 학술 연구소 및 대규모 기술 기업으로 한정되었습니다. 그러나 1970년대 후반에는 패러다임이 바뀌었습니다. 마찬가지로, 저희는 로봇 및 자율 시스템이 자신들의 개인용 컴퓨터 시대를 맞이하고 있다고 믿습니다. 컴퓨팅의 민주화가 새로운 기회와 도전을 가져왔던 것처럼, 로봇 및 자율 시스템의 민주화도 마찬가지입니다.\n\n<div class=\"content-ad\"></div>\n\n기회와 도전\n\n이 변경의 결과가 깊은 영향을 줄 것으로 믿습니다. 사회는 AI 및 자율 시스템의 힘을 활용하면서도 보안, 유연성 및 인간의 통제 원칙을 희생하지 않을 것입니다. Arondite에서는 AI 이해와 통제, 데이터 복잡성 및 동적 팀워크라는 해결해야 할 세 가지 큰 도전을 보고 있습니다.\n\nAI 이해와 통제. 로봇 및 자율 시스템의 보다 광범위한 사용은 인류에게 새로운 가치를 제공하리라 약속하지만, 방어 분야에서는 도전도 가져옵니다. 우리가 구축한 AI는 감사 가능하고 이해 가능하며 검사 가능해야 합니다. 모델은 보호되어야 하며 그 유래를 이해해야 합니다. AI가 다양한 시스템에서 보다 널리 배포됨에 따라, 우리는 각각에 의미 있는 인간의 통제를 유지하고 제조업체가 다른 제조업체의 혼합 플릿을 통하여 심지어 표준을 강제로 적용해야 할 것입니다. 민주국가의 시민으로서, 우리는 우리 윤리가 우리의 공학적 결정에 스며들어가도록 보장해야 합니다. Arondite에서는 이 분야에서 리더십을 제공하는 것이 우리의 주요 책무 중 하나라고 믿고 있습니다.\n\n데이터 복잡성과 보안. 방어는 또한 데이터 관리와 임무 관리에서의 신생 복잡성에 맞서야 하며, 고객이 데이터와 AI를 활용하면서도 보안을 희생하지 않도록 해야 합니다. 이로 인해 몇 가지 중요한 질문이 제기됩니다. 어떻게 점점 더 복잡한 시스템의 혼합물 간에 쉬운 협업을 가능하게 할 수 있을까요? 얼마나 보안을 저해하지 않고 동맹국과 기업이 AI를 함께 개발할 수 있을까요? 어떻게 적절한 AI 모델이 올바른 위치에 배치되는지 보장할 수 있을까요? AI가 예상대로 작동 중이며 실제 세계 피드백을 자동으로 캡처하여 모델 신뢰성과 성능을 향상시킬 수 있을까요? 저희에게는 이러한 종류의 기능이 선택사양이 아니라 문제를 해결하는 중요한 부분임을 보증합니다. 이 없이는 복잡한 데이터 환경에서 신뢰를 유지하거나 고객에게 조직 전체로 제품을 안전하게 확장할 자신감을 줄 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n**동적 팀 구성.** 변화 속도가 높아질수록, 인간-기계 팀도 동적으로 형성되고 재구성되어야 합니다. 로봇 시스템이 협업하는 것이 인간들이 협업하는 것만큼 쉬워져야 한다고 믿습니다. 이는 센서, 로봇 또는 자율 시스템과 연결해야 하는 사용자가 세계를 모델링할 수 있는 완전히 새로운 방법을 구축하는 것을 의미합니다. 사용자는 그런 다음 예기치 못한 작업을 수행하기 위해 다양한 기계들을 유연한 팀으로 결합할 수 있어야 합니다.\n\n이러한 도전에 직면하여, 우리는 인공지능으로 정의된 로봇 시스템들의 집단적인 능력을 발휘할 수 있도록 도와줄 것입니다. 결과적으로, 이는 국방을 포함한 기관들이 보안, 유연성 및 인간의 통제에 영향을 주지 않으면서 로봇 및 자율 시스템을 결합해 활용할 수 있게 만들 것입니다.\n\n**저자**\n\n윌 블라이스, 아론다이트의 공동 창립자이자 CEO","ogImage":{"url":"/assets/img/2024-06-19-Changeiscoming_0.png"},"coverImage":"/assets/img/2024-06-19-Changeiscoming_0.png","tag":["Tech"],"readingTime":3},{"title":"음성 쓰레기 분류 라즈베리 파이와 티처블 머신","description":"","date":"2024-06-19 02:46","slug":"2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine","content":"\n\n\n![이미지](/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_0.png)\n\n전 세계적으로 매년 20억 톤의 가정 폐기물이 생산됩니다. 이것은 우리 환경에 무거운 부담을 줍니다. 매립지와 환경에 끝내 찌르는 폐기물을 줄이기 위해 전 세계 주민들은 가정 폐기물을 분리 수거해야 합니다. 그리고 쓰레기 분리는 큰 비즈니스입니다. Fortunebusinessinsights.com에 따르면, 2019년 글로벌 폐기물 분류 장비 시장은 약 7억 달러였습니다. 그리고 2027년에는 18억 달러에 이를 것으로 예상됩니다.\n\n![이미지](/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_1.png)\n\n하지만 유감스럽게도 중국에서는 쓰레기 분리 시스템이 효과적이지 않습니다. 정책이 약하게 시행되며, 위반에 대한 처벌이 거의 없습니다. 더 나쁜 것은 쓰레기 분류가 혼란스럽습니다. 제 건물에는 섬유, 재활용, 음식물, 잔여 폐기물을 각각 수집하는 다섯 개의 용기가 있습니다. 각 라벨 아래에는 예시의 짧은 목록이 있습니다. 예를 들어, 와인과 플라스틱 병은 \"재활용\" 용기로 가야 합니다. 그리고 옷과 가방은 \"섬유\"에 속합니다.\n\n\n<div class=\"content-ad\"></div>\n\n하지만 목록은 모든 종류의 쓰레기를 다 다루기에는 너무 짧습니다. 나는 종종 우드 또는 금속판이 어느 컨테이너에 들어가야 하는지 모르기 때문에 컨테이너 앞에서 어리둥절해졌어요. 대부분의 경우, 결국 쓰레기는 \"잔여 폐기물\" 농푸에 들어갑니다. 이런 경우에는 누군가가 올바른 컨테이너를 알려주면 좋겠죠? 그리고 나는 Freethink의 이 YouTube 비디오를 보았습니다.\n\n이 비디오는 인공지능이 도와주는 로봇 쓰레기 분류 시스템을 보여줍니다. 이 시스템은 컴퓨터 비전을 사용하여 다양한 종류의 쓰레기를 인식한 다음 로봇 팔을 사용하여 분리합니다. 요즘에는 인공지능 컴퓨터 비전이 매우 정확합니다. 우리는 쓰레기 분류 문제에 대처하기 위해 완전히 활용해야 합니다.\n\n이 비디오에 영감을 받아 나는 집에 내 쓰레기 분류 라즈베리 파이를 만들었어요 (그림 1 및 비디오 2).\n\n시스템은 라즈베리 파이, 비디오 카메라 및 스피커로 구성되어 있습니다. 카메라가 쓰레기 물체를 \"보게 되면\", 라즈베리 파이는 스피커를 통해 쓰레기 카테고리를 말합니다. 컴퓨터 비전 모델은 Google의 Teachable Machine에서 훈련되었습니다. 이 기사에서 시스템을 설명합니다. 이 프로젝트의 코드는 여기 내 GitHub 저장소에 호스팅되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그리고 Teachable Machine 모델 파일은 제 Google 드라이브에 호스팅되어 있습니다.\n\n# 1. 구성 요소\n\n이 프로젝트에서는 Raspberry Pi 4를 사용했습니다. RAM이 4GB이고 저장 용량이 64GB입니다. 또한 Pi에 USB 비디오 카메라와 USB 스피커를 연결했습니다 (그림 1 및 3). \n\n![이미지](/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_2.png)\n\n<div class=\"content-ad\"></div>\n\n나는 Google의 Teachable Machine 프로젝트를 데스크톱 컴퓨터에서 작업했어. 그리고 나는 모델과 다른 파일을 내 집 네트워크를 통해 Raspberry Pi로 전송했어.\n\n# 2. Teachable Machine에서 쓰레기 분류 모델 훈련하기\n\n이 프로젝트에서, 나는 재활용 가능한(recyclable), 직물(textiles), 그리고 비어 있는(empty) 세 가지 클래스로 모델을 훈련했어. 나는 kaggle.com에서 보틀과 컵 데이터세트 그리고 의류 데이터세트(이 문서에서 설명함)를 발견했어. 나는 또한 처음 두 카테고리에 내 사진 몇 장을 추가했어. 비어 있는 카테고리에는 다양한 종류의 벽 사진을 포함했어. 이 마지막 클래스는 물체가 없을 때 시스템을 대기 상태로 만들고 싶기 때문에 필수적이야.\n\nTeachable Machine 웹사이트로 이동해서 이미지 프로젝트를 시작해봐. 내가 언급한 세 가지 클래스를 생성해. 각 클래스에 사진을 업로드해. 또는 위에서 제공한 내 공유 모델 파일을 열어볼 수도 있어.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_3.png)\n\n이제 Train Model 버튼을 클릭하여 훈련 프로세스를 시작할 수 있습니다. 훈련 이후 모델을 몇 장의 사진 또는 카메라를 사용하여 테스트할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_4.png)\n\n결과에 만족하셨다면 Export Model 버튼을 클릭하세요. Tensorflow 탭을 선택하고 Savedmodel 옵션을 선택한 후 Download my model 버튼을 클릭하세요.\n\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_5.png)\n\n당신의 브라우저가 모델이 준비되면 다운로드가 시작됩니다.\n\n# 3. 앱 작성\n\n호스트 컴퓨터에서 pi_garbage_classifier라는 폴더를 만듭니다. 다운로드한 파일을 프로젝트 폴더에 압축해제합니다. 이제 app.py라는 파일을 만들어 각 부분을 조합할 것입니다. 이것은 Teachable Machine의 코드 스니펫에 기반합니다 (Figure 6). 그러나 놀랍게도 샘플 코드는 잘못되었고 오도독도 못하다. keras_model.h5를 열려고 시도했지만 다운로드한 모델은 model.savedmodel이라는 이름입니다.\n\n\n<div class=\"content-ad\"></div>\n\n여기는 app.py의 코드입니다.\n\n```python\nimport cv2\nimport numpy as np\nfrom keras.models import load_model\nimport os\nimport time\nimport re\nimport sys\n\npathname = os.path.dirname(sys.argv[0])\n\nprint('sys.argv[0] =', sys.argv[0], \"pathname\", pathname)    \n\n# 모델 불러오기\nmodel = load_model(f'{pathname}/model.savedmodel')\n\n# 레이블을 labels.txt 파일에서 가져옵니다. 이것은 나중에 사용됩니다.\nlabels = open(f'{pathname}/labels.txt', 'r').readlines()\n\nwhile True:\n    time.sleep(5)\n\n    # CAMERA는 컴퓨터의 기본 카메라에 따라 0 또는 1이 될 수 있습니다.\n    camera = cv2.VideoCapture(0)\n    # 웹캠 이미지 불러오기\n    ret, image = camera.read()\n    camera.release()\n    \n    # 이미지를 (224-높이,224-너비) 픽셀로 크기 조정합니다.\n    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n    \n    # 이미지를 윈도우에 표시합니다.\n    \n    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n    \n    image = (image / 127.5) - 1\n    \n    probabilities = model.predict(image)\n    \n    max_prob = np.max(probabilities)\n    label = re.sub(r'\\d+\\s+', '', labels[np.argmax(probabilities)]).strip()\n\n    print (label, f\"proba: {max_prob}\")\n    \n    if label != \"empty\" and max_prob > 0.9:\n        os.system(f\"festival --tts {pathname}/voice/{label}.txt\")\n\n    keyboard_input = cv2.waitKey(1)\n    \n    if keyboard_input == 27:\n        break\n```\n\n내 코드에 메인 루프에 sleep 함수를 추가했습니다. 이를 통해 시스템은 5초마다 이미지를 캡처합니다. OpenCV는 캡처된 프레임을 버퍼링하기 때문에 각 반복에서 카메라를 초기화해야 합니다. 코드는 또한 예측 확률이 0.9보다 높으면 쓰레기 카테고리를 발표하기 위해 페스티벌 유틸리티를 사용합니다. 페스티벌은 텍스트 음성 변환 유틸리티입니다. 텍스트 파일을 읽어 내용을 읽어 줄 수 있습니다. 이 프로젝트에서는 voice라는 폴더를 만들고 발표 파일을 넣었습니다. 각 발표 파일에는 카테고리 이름만 작성했습니다. 읽기 편의를 위해 파일 내용을 수정하여 발표를 사용자 정의할 수 있습니다. \n\n그래서 최종적으로 폴더 구조는 다음과 같아야 합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_6.png\" />\n\n# 4. Raspberry Pi 설정하기\n\n저는 learn.adafruit.com에 있는 훌륭한 설정 안내서를 따랐어요. 먼저, Raspberry Pi Imager를 사용하여 마이크로 SD 카드에 Raspberry Pi OS (64비트)를 기록하세요. 고급 옵션에서 SSH를 활성화하고 사용자 이름과 암호를 설정하세요.\n\n카드를 Pi에 넣고 전원을 켜세요. 네트워크에 연결하고 다음 SSH 명령어로 로그인하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 만약 콘솔에서 \"REMOTE HOST IDENTIFICATION HAS CHANGED!\" 라고 나오면\n# 다음 명령어를 실행하여 리셋하세요\n# ssh-keygen -R raspberrypi.local\n\nssh pi@raspberrypi.local\n```\n\n라즈베리 파이 쉘이 준비되면, 아래 명령어를 하나씩 사용하여 필요한 소프트웨어를 설치하세요.\n\n```js\n# 라즈베리 파이에서 실행하세요\n\nsudo apt update\nsudo apt upgrade -y\n\n# 선택 사항\n# sudo apt install -y python3-pip\n\npip3 install --upgrade setuptools\n\npip3 install Pillow==9.2.0\n\npip install opencv-python\n\nRELEASE=https://github.com/PINTO0309/Tensorflow-bin/releases/download/v2.10.0/tensorflow-2.10.0-cp310-none-linux_aarch64.whl\n\nCPVER=$(python --version | grep -Eo '3\\.[0-9]{1,2}' | tr -d '.')\n\npip install $(echo \"$RELEASE\" | sed -e \"s/cp[0-9]\\{3\\}/CP$CPVER/g\")\n\nsudo apt install -y festival\n\n# 선택 사항\n# sudo reboot\n\nmkdir ~/pi_garbage_classifier\n```\n\n위의 마지막 명령어는 라즈베리 파이의 홈 디렉토리에 pi_garbage_classifier 라는 폴더를 만듭니다. 프로젝트 파일을 데스크톱 컴퓨터에서 이 폴더로 전송하려면 다음 명령어를 사용하세요.\n\n<div class=\"content-ad\"></div>\n\n\n# 호스트 데스크톱에서\n\ncd [your_desktop_pi_garbage_classifier_path]\nscp -r ./* pi@raspberrypi.local:~/pi_garbage_classifier/\n\n\n파일을 복사한 후에는 다음 명령어로 앱을 테스트하세요:\n\n\n# 라즈베리 파이에서\n\npython /home/pi/pi_garbage_classifier/app.py\n\n\n앱이 시작하는 데 몇 초 정도 걸립니다. 카메라 램프가 깜박일 때, 카메라 앞에 다양한 물체를 두어 시스템을 테스트할 수 있습니다. 물체의 클래스를 알리고 콘솔에 다음 출력이 나타날 것입니다 (그림 8).\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_7.png)\n\n앱은 종료할 때까지 계속 실행될 거에요.\n\n# 5. 라즈베리 파이(Pi) 배포\n\n이제 시스템을 독립적으로 만들어 배포할 시간입니다. 앱을 Pi의 자동 시작 파일에 추가해야 합니다. rc.local과 cron 두 가지 방법을 시도해봤는데, 이 방법들은 데스크톱을 시작하기 전에 앱을 시작하기 때문에 USB 스피커를 활용할 수 없었어요. 그래서 이 포스트에서 해결책을 찾았어요. 시스템 자동 시작 파일에 관련된 것이죠. 따라서 이 명령어를 실행하여 파일을 편집해보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nsudo nano /etc/xdg/lxsession/LXDE-pi/autostart\n```\n\n다음 줄을 파일에 추가하세요.\n\n```js\n@python /home/pi/pi_garbage_classifier/app.py\n```\n\n이렇게 autostart 파일이 보이게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_8.png\" />\n\n프로그램을 종료하려면 Ctrl+X를 누르고 동일한 파일에 변경 사항을 저장하려면 Y를 누르세요. 다음 명령어를 사용하여 장치를 다시 부팅하세요.\n\n```js\nsudo reboot\n```\n\n부팅 후 시스템은 자동으로 작업을 수행해야 합니다. 이제 네트워크 케이블을 제거하고 Pi를 원하는 곳에 배치할 수 있습니다 (비디오 2). 이제 쓰레기의 목적지에 대해 확실하지 않을 때에는 항상 상담할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n이 기사에서는 시범용 쓰레기 분류 시스템을 구축하는 방법을 보여드렸어요. 설정하는 데 약 30분 가량 밖에 걸리지 않았죠. 아직까지는 두 가지 종류의 쓰레기와 전체 가정 쓰레기의 일부만 인식할 수 있지만 필수 구성 요소들은 모두 갖추고 있어요. 모델에 더 많은 객체와 클래스를 추가할 수 있습니다. 또한 이 프로젝트는 일종의 프레임워크입니다. 다시 말해, 새로운 모델을 훈련하고 Pi에 모델 파일을 교체하여 식물 분류 시스템이나 물체 인식기와 같이 완전히 다른 것으로 변환할 수 있어요.\n\nGoogle의 티처블 머신은 정말 우리에게 빛이 되어줬어요. 이전에는 서로 다른 화가들의 그림을 분석하는 데 사용했었죠. 물론 PyTorch나 Keras로 직접 컴퓨터 비전 모델을 사용자화할 수도 있어요. 하지만 그런 작업은 상당한 시간과 노하우를 요구할 수 있어요. 반면, 티처블 머신은 이 모든 것을 아주 간단하게 만들어줘요. 몇 번의 클릭만으로 과연성 있는 모델을 쉽게 얻을 수 있어요. 더불어 모델을 확장하고 수정하는 것도 쉬워요.\n\n하지만 생각해 볼 수 있는 작은 단점도 있어요. 티처블 머신은 인터페이스에서 모델 성능을 보여주지 않아요. 따라서 우리는 모델이 얼마나 잘 작동할지를 알 방법이 없어요. 더 많은 클래스를 추가할수록 모델 성능이 떨어지기 때문에 우리는 모델을 충분히 신뢰하고 배포하기 전에 모델의 정확도를 측정해야 해요.\n\n<div class=\"content-ad\"></div>\n\n이 프로젝트를 시도해 보라고 권장합니다. 그리고 피드백을 주시면 좋을 것 같아요!","ogImage":{"url":"/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_0.png"},"coverImage":"/assets/img/2024-06-19-AnAudioTrash-SortingRaspberryPiwithTeachableMachine_0.png","tag":["Tech"],"readingTime":9},{"title":"라즈베리 파이의 AI 키트는 얼마나 좋은가요","description":"","date":"2024-06-19 02:45","slug":"2024-06-19-HowgoodisRaspberryPisAIKit","content":"\n\n![image](/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_0.png)\n\n라즈베리 파이가 머신 러닝 기능을 갖춘 싱글 보드 컴퓨터 AI Kit을 출시했습니다. 최근 IPO 출시를 촉진하기 위한 것일 수도 있지만, 성능 데이터를 보면 AI 엣지 컴퓨팅 시장을 뒤흔들 것으로 보입니다.\n\n이 AI 키트는 Hailo-8L 가속기와 라즈베리 파이의 자체 M.2 HAT+ 보드로 구동됩니다.\n\n어쨌든, 이 $70의 AI 가속기는 정말 좋은 품질입니다. 아래 섹션에서 제시된 것처럼 임베디드 애플리케이션을 위한 강력한 가격을 얻을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## Hailo-8L 소개:\n\n라즈베리 파이는 액셀러레이터 제공 업체로 Hailo를 선택했습니다. Hailo-8L은 최근 발표된 Hailo-8 칩의 간소화된 버전으로, 26TOPS를 제공합니다. Hailo-8L은 칭찬받을 만한 13TOPS를 제공하여 라즈베리 파이에 필요한 AI 성능을 제공합니다.\n\n![이미지](/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_1.png)\n\n최근 몇 주 사이에 TOPS 레코드가 빠르게 깎이고 있다는 글을 작성했습니다. 최근 AMD가 50TOPS로 TOPS 차트를 석권하고 있어, 13TOPS는 낮아 보일 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그런데 중요한 점을 고려해야 합니다. 이 내용은 임베디드 환경에서 사용될 것이며, 13TOPS는 컴퓨터 비전 분야의 엣지 애플리케이션에 큰 이점을 제공할 것입니다. 또한, 작성 시점에서 RISC-V Linux 랩탑은 단지 2TOPS를 제공합니다.\n\nHailo는 특히 저전력 엣지 AI 애플리케이션에 중점을 둔다는 사실을 알아두세요. 그들은 심지어 NVIDIA를 훌륭하게 이길 수 있습니다. 아래는 NVIDIA의 Jetson Nano 및 Xavier NX와 비교한 Hailo의 성능입니다.\n\n![Hailo Performance Comparison](/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_2.png)\n\n이 칩은 TensorFlow, TensorFlow Lite, Keras, PyTorch 및 ONNX를 포함한 다양한 AI 프레임워크를 널리 지원합니다.\n\n<div class=\"content-ad\"></div>\n\n상기 숫자 및 성능 이점을 고려하면, Hailo와 함께 Raspberry Pi를 선택하는 것이 명백해 보입니다.\n\n## Raspberry Pi 인공지능 키트 아키텍처 및 디자인\n\n현재 이 AI 키트는 x86 및 Arm 호스트 아키텍처를 모두 지원합니다.\n\nRaspberry Pi CEO인 Eben은 Apple 및 Qualcomm SoC의 AI PC를 위해 최근 출시된 통합 NPU와는 달리 별도의 가속기 보드를 계획적으로 준비했다고 전했습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Raspberry Pi AI Kit](/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_3.png)\n\n라즈베리 파이는 이미 저렴한 40나노미터에서 IO 기능을 사용하여 분리된 아키텍처를 갖고 있습니다. CPU 및 GPU는 16나노미터에 있습니다. 코어는 16나노미터에 있지만 NPU를 추가하면 면적이 커져 비용이 많이 드는 문제가 발생할 수 있습니다.\n\n비 AI 응용 프로그램을 위해 라즈베리 파이 5를 사용하려는 사용자도 있을텐데요 ;-) 이들은 불필요한 NPU 다이 면적 비용을 위해 더 많은 돈을 지불해야 합니다. 이제 선택권이 생겼고 하드웨어 엔지니어들은 선택권을 좋아합니다. . .\n\n라즈베리 파이 3 버전 자체는 AI 응용 프로그램에 사용되었지만 AI 워크로드는 클라우드에서 실행되었습니다. 이 새로운 라즈베리 파이 5는 Hailo-8L을 사용하여 에지에서 작은 모델과 최적화된 LLM(로컬 모델 매니저)을 직접 수행할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n## 라즈베리 파이 AI 키트의 현재 상태:\n\n이 라즈베리 파이는 PCIe 2.0 인터페이스를 통해 Hailo-8L 가속기와 통신합니다. 그리고 PCIe 2.0은 라즈베리 파이 5 버전에만 있습니다. 따라서 AI 기능을 시도하려면 보드를 교체해야 합니다. 하지만, 심지어 라즈베리 파이 5의 M.2 HAT+도 약 80달러 정도에 구매할 수 있습니다.\n\n이 키트에는 Hailo-8L의 열을 효과적으로 방출하기 위한 사전 부착된 열 패드가 포함되어 있습니다. Hailo-8L은 소비전력은 적지만 상당히 더울 수 있습니다.\n\n라즈베리 파이는 이것이 많은 메이커 커뮤니티에게 새로운 영역임을 이해합니다. 따라서 사용자가 AI 기능을 개발하는 데 필요한 데모 및 소프트웨어 유틸리티를 제공할 계획입니다.\n\n<div class=\"content-ad\"></div>\n\n하드웨어는 그대로 작동하지만 중요한 점은 소프트웨어가 아직 완전하지 않다는 것입니다. 그러나 몇 달 안에 상황이 변할 것입니다.\n\nTom's Hardware 팀이 리뷰 키트를 받았을 때 몇 가지 문제가 발생했습니다. Raspberry Pi OS 업데이트가 AI 기능 일부를 활성화할 예정이라는 것을 알았습니다. 현재 사용이 제한되지만, 이미 teddy bear를 포함한 이미지를 감지할 수 있었습니다. 따라서 현재는 약간의 노력이 필요합니다.\n\n이 데모는 속도 측정을 수행하지 않았지만, 팀은 몇 가지가 더 빠르다고 \"느꼈다\"고 언급했습니다. 미래에 Raspberry Pi가 필요한 경우에는 우리 자신의 모델을 실행할 수 있다고 언급했다.\n\n<div class=\"content-ad\"></div>\n\n## 사용 사례:\n\n라즈베리 파이 & 헤일로는 이미지 인식을 포함한 컴퓨터 비전 하드웨어의 저전력 장점이 엣지 노드에서 중요하다고 주장합니다.\n\n이 회사는 또한 게임에 AI 기능을 추가하는 데 적합한 몇 가지 모델을 보유하고 있다고 합니다. — 음, 인간들...\n\n![이미지](/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_5.png)\n\n<div class=\"content-ad\"></div>\n\nWindows 11이 라즈베리 파이가 목표로 하는 대상이 아니라서, 이 키트는 Microsoft Copilot 소프트웨어용이 아니라는데요. 그러나 일부 기능이 작동할 수 있는 가능성은 배제되지 않습니다. Copilot+ PC에 요구되는 40TOPS 중 13TOPS는 거의 1/3이므로 어떤 부분은 실제로 작동할 것으로 예상됩니다.\n\n## 결론\n\n양 회사 모두 메이커 커뮤니티가 자체 문제를 해결할 독특한 사용 사례를 개발할 것으로 기대하고 있습니다. 저 또한 라즈베리 파이 커뮤니티의 힘으로 인해 차이가 날 것이라고 믿습니다. 교실 프로젝트 외에도 많은 로봇 응용 프로그램이 새롭게 발견된 13TOPS AI 기능을 사용하기 시작할 것입니다.\n\n보다 원활한 플랫폼 작동을 위해 더 많은 라즈베리 파이 소프트웨어 업데이트를 기다려야 합니다. 흥미로운 사실은 라즈베리 파이 CEO가 Hailo와의 협력이 이로써 끝나지 않는다고 언급했다는 것입니다. . . .\n\n<div class=\"content-ad\"></div>\n\n에지 AI의 미래가 무엇을 가지고 있는지 정말 흥미로울 것입니다.\n\n더 많은 혁신 및 딥 테크 이야기를 보려면 박수를 보내 주시고 저를 팔로우해주세요. 매주 발송되는 혁신 스냅 소식지를 구독하여 혁신을 영감받으세요.\n\n![2024-06-19 How good is Raspberry Pi's AI Kit](/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_6.png)\n\n이 이야기는 Generative AI에 게재되었습니다. LinkedIn에서 저희와 연결하고 최신 AI 이야기에 대한 소식을 받으려면 Zeniteq를 팔로우하세요.\n\n<div class=\"content-ad\"></div>\n\n최신 생성적 AI 뉴스와 업데이트를 받으려면 뉴스레터를 구독해주세요. 함께 AI의 미래를 만들어봐요!\n\n`<img src=\"/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_7.png\" />`","ogImage":{"url":"/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_0.png"},"coverImage":"/assets/img/2024-06-19-HowgoodisRaspberryPisAIKit_0.png","tag":["Tech"],"readingTime":5},{"title":"시그널 인텔리전스, 라즈베리 파이","description":"","date":"2024-06-19 02:43","slug":"2024-06-19-SignalsIntelligenceTheRaspberryPi","content":"\n\n\n![이미지](/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_0.png)\n\n라즈베리파이는 소형이면서도 효과적인 SIGINT 연구 스테이션을 제공합니다.\n\n미디엄 회원이 아니라면 substack를 통해 무료로 읽을 수 있습니다.\n\n신호 분석을 초보자의 관점에서 시작할 때, 시작하기가 어렵고 다루어야 할 정보가 많을 수 있습니다. 하드웨어 기반 시스템, 웹 기반 시스템이 있으며 무엇이라도 라디오 스펙트럼에서 보고 있는 것이죠?! 이렇게 하면 새로운 프로젝트가 재미있고 흥미로운 것으로 변할 수 있는데, 여기에 참여하는 동안 인내력과 동기부여를 빼앗기기도 합니다.\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_1.png\" />\n\n안녕하세요! 오늘은 주요 싱글 보드 컴퓨터를 사용하여 몇 가지 선택된 하드웨어와 결합하여 기본 SIGINT 수신 스테이션을 만드는 방법에 대해 이야기하려고 합니다. 이를 사용하여 항공기, 지역 신호, ISM 신호 및 올바른 안테나를 사용하면 우주 신호까지 감지할 수 있습니다. 기본 Raspbian OS를 사용하는 대신 전용 SIGINT에 포커싱된 OS를 사용할 것입니다. 하드웨어를 준비하고 시작해 봅시다!\n\n<img src=\"/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_2.png\" />\n\n이 프로젝트를 완료하려면 SD 카드에 플래싱하는 경험과 기본적인 Linux 경험이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n# 드래곤 소개\n\n코로나 대유행 중에 만들어진 Dragon OS는 라디오 중심의 펜 테스트 및 분석 배포판으로, Kali Linux나 Parrot OS와 유사합니다. 다양한 신호 프로토콜과 하드웨어와 함께 작동할 수 있으며, Bluetooth, Wi-Fi, ISM, 전화 및 대부분의 라디오 스펙트럼을 싼 가격의 장치인 RTL-SDR 또는 블레이드RF 또는 hackRF 시스템과 같은 전용 SDR 장치를 사용하여 즉시 사용할 수 있도록 설정되어 있습니다.\n\n신호 기반 배포판 중 처음은 아니지만 쉽게 시작할 수 있는 것 중 하나이며 미리 설치된 다양한 도구와 표준 패키지 관리자로 초보자에게 매우 친숙합니다. 라즈베리 파이와 결합하면 매우 멋진 장비가 됩니다.\n\n# 요구 사항\n\n<div class=\"content-ad\"></div>\n\n라즈베리 파이 보드\n\n주변기기 (전원 공급 장치, SD 카드, 키보드 및 모니터 또는 SSH 액세스를 위한 장치)\n\nRTL-SDR 동글\n\n모니터 모드 Wi-Fi 카드\n\n<div class=\"content-ad\"></div>\n\n# 운영 체제\n\n기본 Raspbian 배포본은 다양한 용도에 좋은 OS이지만, SIGINT 용도로는 다소 부족합니다. 적절히 구성할 수는 있지만, 이에는 추가 시간이 소요될 것입니다. 효율성이 중요한 우리에게 시간은 소중하니 이제 다른 옵션이 있습니다. 우리는 DragonOS를 사용할 것입니다. 이 OS는 라디오 스펙트럼을 탐색하는데 도움이 되는 다양한 유용한 도구로 구성되어 있어서 불필요한 노력 없이 사용할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_3.png)\n\n또한 다양한 소프트웨어 정의 라디오를 위한 사전 구성된 드라이버가 많이 제공됩니다. 이에는 RTL-SDR, bladeRF, hackRF 등이 포함되어 있습니다. 이는 대부분의 장치가 일반적으로 플러그 앤 플레이가 가능하다는 것을 의미합니다. 초보자에게 이는 이상적입니다. 대부분의 프로젝트를 쉽게 구성하도록 만들어주어 작업에 집중할 수 있게 해주며, 필요한 드라이버를 찾느라 고생할 필요가 없습니다.\n\n<div class=\"content-ad\"></div>\n\n# 설정하기\n\n우리의 Pi를 적절한 이미지로 구성하려면, 먼저 해당 이미지를 다운로드한 다음 SD 카드에 플래시해야 합니다. 하지만 먼저 OS 이미지가 필요합니다.\n\n최신 버전의 Dragon이 SourceForge 리포지토리에서 다운로드할 수 있습니다. 다음 링크에서 찾을 수 있습니다.\n\n![Image](/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_4.png)\n\n<div class=\"content-ad\"></div>\n\n한 번 Sourceforge 페이지에 접속하면, 가장 최근 업데이트 날짜를 확인하여 최신 버전을 받고 있는지 확인할 수 있습니다. 우리가 사용하는 Raspberry Pi 모델의 올바른 이미지를 받는지도 확인해야 합니다. 다양한 모델 간에 소량의 차이가 있기 때문입니다. 그런 다음, 확인이 완료되면 다운로드 탭을 눌러 로컬에서 이용 가능하게 대기하면 됩니다.\n\n![Signals Intelligence The Raspberry Pi_5](/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_5.png)\n\n로컬 머신에 설치되면, SD 카드에 플래시가 필요합니다. 이를 위해 다른 프로젝트에서와 같이 Balena Etcher를 사용할 수 있습니다. 하지만 먼저 다운로드의 무결성을 확인하기 위해 MD5 합을 비교해야 합니다. Linux 사용자라면 다음 명령어로 터미널에서 이를 할 수 있습니다.\n\n```js\nmd5sum /다운로드한/파일의/경로\n```\n\n<div class=\"content-ad\"></div>\n\n무결성을 확인하려면 표시된 출력물을 Sourceforge 웹사이트에 저장된 출력물과 비교해야 합니다. 일치하면 파일이 정상이며 준비된 상태입니다.\n\n최종 단계는 우리의 Raspberry Pi와 함께 사용할 수 있도록 OS를 SD 카드에 플래시하는 것입니다. 이는 상당히 간단한 단계이므로 자세히 설명하지는 않겠습니다. 그러나 문제가 발생하면 Balena 웹사이트를 사용하여 문제 해결할 수 있습니다.\n\n플래시가 완료되면 SD 카드를 Pi에 넣고 전원을 공급하고 부팅이 완료될 때까지 기다리면 됩니다. 설치가 올바르게 되었다면 데스크톱으로 부팅할 수 있어야 합니다. 이 시점에서 기본 사용자/비밀번호 조합을 변경했는지 확인해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n터미널에 들어가서 ls 명령어를 사용하여 사용 가능한 파일/프로그램을 검색해볼 수 있어요.\n\n```js\nls -la\n```\n\n<img src=\"/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_7.png\" />\n\n# 마지막으로 함께 하고 싶은 말씀\n\n<div class=\"content-ad\"></div>\n\n여기 요즘 만들어놓은 Raspberry Pi 보드를 활용해 기본적이면서도 광대한 신호 분석 스테이션으로 변신시켰습니다. 이제 여러분의 라디오 수신기 및 기본 센서 패키지의 범위에만 한정되어 있는 프로젝트입니다.\n\nDragon과 함께 미리 설치된 소프트웨어의 폭넓은 범위를 고려했을 때, 설치는 쉽지만 다음 단계가 무엇인지 궁금할 수 있습니다. 그러나 우리는 앞으로 몇 달 동안 Dragon OS에서 사용 가능한 일부 도구를 통해 작동하는 자습서를 통해 도움을 드릴 예정입니다.\n\nRaspberry Pi를 홈 빌트 프로젝트에 사용한 적이 있나요? 프로젝트 제안이 있거나 특정 주제를 다루는 자습서를 보고 싶으신가요? 댓글에 제안을 남겨주세요. 여러분의 소중한 의견을 기다리고 있습니다!\n\nMedium은 최근 일부 알고리즘 변경을 도입하여 이와 같은 기사의 발견 가능성을 개선했습니다. 이 변경 사항은 높은 품질의 콘텐츠가 보다 넓은 관객에게 도달하도록 하는 데 중요한 역할을 합니다. 여러분의 참여가 이를 실현하는 데 결정적인 역할을 하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n만약 이 기사가 유익하고 정보가 많거나 재미있었다면, 우리는 친절히 당신의 지원을 보여주시도록 권장합니다. 이 기사에 박수를 보내면 작가에게 그들의 작품이 감사히 받아들여지고, 또한 그것을 이용할 수 있는 다른 사람들에게 그 가시성을 높이는 데 도움이 됩니다.\n\n🌟 이 기사를 즐겼다면? 우리의 작품을 지원하고 커뮤니티에 참여해보세요! 🌟\n\n💙 Ko-fi에서 저를 지원해주세요: Investigator515\n\n📢 독점 업데이트를 위해 OSINT 텔레그램 채널에 참여하세요.\n\n<div class=\"content-ad\"></div>\n\n📢 최신 이벤트 정보를 받으시려면 우리의 크립토 텔레그램을 팔로우해주세요\n\n🐦 트위터에서도 팔로우해주세요\n\n🟦 블루스카이에도 참여하실 수 있습니다!\n\n🔗 추천하는 기사들:\n\n<div class=\"content-ad\"></div>\n\n- 뭐야 이건?! 로켓 엔진\n- OSINT 수사관을 위한 셀프 케어 & 회복 가이드\n\n✉️ 이와 같은 콘텐츠를 더 보고 싶으세요? 이메일 업데이트 신청하세요","ogImage":{"url":"/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-19-SignalsIntelligenceTheRaspberryPi_0.png","tag":["Tech"],"readingTime":5},{"title":"Raspberry Pi 날씨 스테이션 만들기 DHT11  Python  QuestDB 소스 코드 포함","description":"","date":"2024-06-19 02:42","slug":"2024-06-19-AneasyRaspberryPiweatherstationusingDHT11PythonQuestDBwithsourcecode","content":"\n\n가끔은 예전 프로젝트로 돌아가서 업데이트하고 다시 생각해보는 것도 재미있어요. 몇 년 전에 라즈베리 파이, 파이썬, 포테이너, 프로메테우스 및 그라파나를 사용하여 간단한 온도 및 습도 모니터를 만들었어요. 전체 프로젝트와 자습서는 여기에서 확인할 수 있어요. 이 서비스 스택은 RPi 3B(1GB RAM만 있는)에 호스팅되었고, 해당 서비스들이 이 목적을 위해 많은 리소스를 사용하고 있었는데, 그 이후로 이 디자인을 개선하고 싶어했어요.\n\n## 이전 아키텍처\n\n이전에는 15초마다 프로메테우스가 센서 데이터를 읽는 Python API에 도달했지만, 잘못된 값과 같은 에러를 확인하지 않았어요. 이 값들은 프로메테우스에 저장되어 사용자가 대시보드를 요청할 때마다 그라파나에서 읽었어요. 이 서비스들은 모두 좋지만, 모든 메모리와 CPU가 제한된 환경에서 작동하기 때문에 많은 리소스가 필요해요.\n\n![이전 아키텍처 이미지](/assets/img/2024-06-19-AneasyRaspberryPiweatherstationusingDHT11PythonQuestDBwithsourcecode_0.png)\n\n<div class=\"content-ad\"></div>\n\n## 새 아키텍처\n\n새 아키텍처를 위한 주요 목표는 이 서비스의 오버헤드를 줄이는 것이었습니다. 여전히 모든 서비스를 구성하기 위해 도커를 사용하고 있지만, 더 적은 자원을 사용하면서도 동일한 가치를 제공합니다.\n\n이제 사용자 인터페이스(프론트엔드)는 간단한 정적 SPA(NuxtJS로 제작됨)로 처리되고, 가벼운 Apache 컨테이너 (Nginx 또는 다른 웹 서버)를 사용하여 제공됩니다. 사용자가 이 페이지를 처음 요청할 때 브라우저로 다운로드되어 그 곳에서 실행되므로 서버 측에서 처리할 내용이 줄어듭니다.\n\n이제 Python API는 백그라운드 스케줄러를 사용하여 매 분마다 센서에서 데이터를 읽고, 이를 고성능 시간 기반 저장 및 쿼리에 능한 PostgreSQL 기반 데이터베이스 인 questdb에 저장하는 역할을 합니다. 또한 DHT11용 최신 라이브러리를 이용합니다. API는 또한 Flask를 사용하여 센서의 최신 측정치를 읽을 수 있는 엔드포인트를 노출시켜 SPA에서 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-19-AneasyRaspberryPiweatherstationusingDHT11PythonQuestDBwithsourcecode_1.png\" />\n\nSPA는 80번 포트에서 제공되며, Python API는 81번 포트에서 제공되어 questdb 인스턴스에서 데이터를 검색하여 JSON payload로 반환합니다. 이러한 모든 서비스는 쉬운 배포와 구성을 위해 docker-compose 파일을 사용하여 생성되었습니다.\n\n<img src=\"/assets/img/2024-06-19-AneasyRaspberryPiweatherstationusingDHT11PythonQuestDBwithsourcecode_2.png\" />\n\n전체 프로젝트는 github.com/gmullernh/dht11-weather-station에서 확인할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n## 결과\n\n스택은 이제 더 적은 리소스를 사용하며 머신에 더 많은 서비스를 추가하고 더 나은 최적화 결과를 얻을 수 있습니다. questdb에서 데이터를 쓰거나 읽을 때 CPU 및 RAM 사용량이 증가하는 경우가 있지만, 그 외에는 값들이 낮은 백분위수 주변에 있습니다.\n\n![이미지](/assets/img/2024-06-19-AneasyRaspberryPiweatherstationusingDHT11PythonQuestDBwithsourcecode_3.png)\n\n## 향후 개선사항\n\n<div class=\"content-ad\"></div>\n\n이 디자인을 개선하는 데 경량 데이터베이스 엔진(questdb는 정말 좋지만 이 규모에는 더 작은 것이 있을 수 있습니다)을 사용하거나 Python API를 Rust, Go 또는 유사한 경량 런타임 언어로 교체하고 SPA에 그래프 시각화 및 더 많은 데이터 분석과 같은 기능을 추가할 수 있습니다. 또한, 프로젝트를 개선하는 데 도움을 주시면 감사하겠습니다.","ogImage":{"url":"/assets/img/2024-06-19-AneasyRaspberryPiweatherstationusingDHT11PythonQuestDBwithsourcecode_0.png"},"coverImage":"/assets/img/2024-06-19-AneasyRaspberryPiweatherstationusingDHT11PythonQuestDBwithsourcecode_0.png","tag":["Tech"],"readingTime":3},{"title":"올나이터 편지 졸업 프로젝트 에디션","description":"","date":"2024-06-19 02:40","slug":"2024-06-19-TheAll-NighterChroniclesFinalYearProjectEdition","content":"\n\n![Image](/assets/img/2024-06-19-TheAll-NighterChroniclesFinalYearProjectEdition_0.png)\n\n우리가 6학기를 보냈던 어느 좋은 날, 이 놀라운 소식이 전해졌어요.\n\n여기에 있네요: \"친애하는 학생 여러분, 이제 최종년도 프로젝트 작업을 시작할 시간이며, 프로젝트는 독특해야 하고 프로젝트 아이디어는 새로운 아이디어여야 합니다\".\n\n우리 모두가 놀라웠어요. 작은 프로젝트를 완료한 지 며칠밖에 되지 않았는데 갑자기 이런 소식이 들렸으니 말이에요. 우리는 안타까운이라는 걸 알게 됐어요. 2019년부터 2023년까지의 코로나 졸업반으로, 우리는 1.5년 가까운 긴 격리 기간을 겪었고, 학기는 6개월에서 거의 3.5개월로 단축되었어요. 그 결과, 학기 진행도가 빨라졌답니다.\n\n<div class=\"content-ad\"></div>\n\n이제 프로젝트 아이디어를 선택하고 혁신적인 아이디어를 내는 것이 정말 어려웠습니다. 선택한 팀은 총 4명으로, 우리 중 한 명의 친구가 프로젝트 전체를 주도했고, 그가 없었다면 이 프로젝트는 이루어지지 않았을 것입니다.\n오랜 브레인스토밍 세션 끝에 우리는 철도 트랙에 존재하는 균열을 자동으로 감지하는 장치를 개발하기로 결정했습니다.\n\n그래서 ‘자율 철도 트랙 균열 감지 시스템 및 경보 드론 로버’라는 이름이 지어졌습니다.\n\n프로젝트는 두 단계로 나눠졌습니다: 1단계와 2단계로, 1단계는 장치를 구축하고 작동하는 방법을 설계하고 계획하는 것이 목표였으며, 2단계는 구현에 대한 부분이었습니다.\n\n실제로 디자인 부분과 계획 부분은 더 쉽게 처리된 부분이었으며, 교수님들로부터 여러 번의 검토를 받았고 결과적으로 이 프로젝트는 사람들 사이에서 얘기거리가 되었습니다. 이는 이 프로젝트가 산업에 있어서 얼마나 관련성을 가지고 있는지 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n계획에는 프로젝트 아이디어에 대한 업계 주요 인사와의 만남이 포함되어 있었고, 그때 이 프로젝트가 산업에 좋은 영향을 미칠 것이라는 것을 알 수 있었으며, 그들이 장치 설계에 많은 도움을 주었습니다. 교수님들로부터 여러 번의 리뷰를 받은 후, 우리는 첫 번째 부담을 겪게 되었습니다. 즉, 장치 예산이 다소 높았고 우리 팀은 이 프로젝트를 완료하기 위해 직접 자금을 마련할 수가 없었습니다. 많은 어려움을 겪으며, 우리는 우리 대학에서 자금을 조달하여 이 프로젝트를 시작할 수 있었습니다.\n\n우리 프로젝트의 두 번째 단계로 나아가며, 7학기인 최종 학년에 진입했습니다. 이제 제목에서 언급했듯이, 우리의 불면의 밤들이 시작되었습니다. 1단계 단계에서 이미 프로젝트의 50%를 완성했으며 동료들과 교수들로부터 우수한 평가를 받은 상태였습니다. 그러나 2단계에 진입하면서 모든 문제들이 발생하기 시작했습니다. 중간에 이미 다양한 도전에 직면했지만, 이번 문제가 악몽처럼 느껴졌습니다.\n\n우리 장치는 새내기들인 우리와 완전히 새롭게 제작되었기 때문에 지속적으로 작동을 중단합니다. 개발 각 단계에서 모든 것을 공부하는 것은 우리가 직면한 가장 어려운 도전이었으며, 이에 더해 개발 중 발생한 갑작스러운 문제들이 우리를 크게 지치게 만들었습니다. 이러한 고생 속에서 우리 프로젝트의 척추라고 할 수 있는 친구 중 한 명이 끊임없이 노력했고, 우리는 이에 동참하여 그를 도왔습니다. 프로젝트를 완료하라는 기한은 3개월이었고, 완성된 프로젝트와 15%의 표절이 포함된 최종 프로젝트 보고서를 제출해야 했습니다.\n\n이는 우리에게 정말 바쁜 시간이었으며, 대학에 다니고 프로젝트를 준비하고 숙제/시험을 완료해야 했기 때문에 우리는 모두의 잠을 희생하고, 이로 인해 우리는 건강 문제를 겪었고, 그 친구(프로젝트의 중심 인물)는 심각한 병으로 병원에 입원해야 했습니다. 이 모든 일이 함께해서 우리는 이를 중단하기로 결정했지만, 그 친구가 우리에게 그렇게 하지 말라고 말하고, 우리가 어떻게든 우리의 의도를 보여주기 위해 프로토타입 수준까지 완성해야 한다고 격려했습니다.\n\n<div class=\"content-ad\"></div>\n\n마침내 친구가 그것을 완성하려고 스스로 앉아 이 프로젝트를 우리의 마지막 최종 검토에 표시하기로 했어요. 우리는 모두 장치에서 문제가 나타날 때마다 매우 깔끔하게 어떻게 작동하는지를 보여줄 수 있었고, 우리가 관심이 있을 경우 우리 선배들에게 넘겨줄 수 있으니 대학에서도 전시할 수 있었다.\n\n이 글을 읽으니 섞인 감정이 드러나는 것 같아요. 그러나 시간이 흘러가면서, 우리가 모두 함께 좋은 시간을 보낸 그날들을 회상하게 됐어요. 유일한 후회는 우리가 친구가 외로이 그것에 종일 종일 노력해 우리를 구할 수 없을 때였다는 거죠. 항상 그에 대해 감사하며, 마지막으로 불면의 날들은 끝나고, 그것이 기억 속으로 이어지는 좋은 예전의 기억이 됐어요.","ogImage":{"url":"/assets/img/2024-06-19-TheAll-NighterChroniclesFinalYearProjectEdition_0.png"},"coverImage":"/assets/img/2024-06-19-TheAll-NighterChroniclesFinalYearProjectEdition_0.png","tag":["Tech"],"readingTime":3},{"title":"내 차가운 차 상자에서 만든 DIY 목 장식 상자 프로젝트","description":"","date":"2024-06-19 02:39","slug":"2024-06-19-MyDIYWoodChestProjectfromaTeaBox","content":"\n\n## THE DIY DIARIES/JAPANESE/TEA BOXES/RECYCLING\n\n여러 해 전에 일본에서 살았을 때 샤바코 선박 상자를 두 개 샀어요. 우리는 신혼 부부였고, 처음으로 만든 집을 저렴한 가격으로 꾸미려고 했어요.\n\n버려진 나무와 시멘트 블록이 책장이 되었고, 우유 상자로 레코드 음반을 저장했으며, 중고 가구 소판이 우리의 품안에서 자리를 차지했어요.\n\n사람들은 여전히 \"spoon(스푼)\"이라고 말할까요?\n\n<div class=\"content-ad\"></div>\n\n우리 작은 일본집 근처에서 Chabako를 판매하는 곳을 발견했어요. Chabako는 루즈 티를 배송하는 데 사용되는 일본 목재 상자에요.\n\n각 상자에 약 스물 미국 달러 정도 지불한 것 같아요. 나는 배송 라벨을 제거하고 목재를 연마하여 마무리를 하고 차고 세일용 소파의 엔드 테이블로 만들 계획이에요.\n\n일본인들이 차고 세일을 하는지는 모르겠지만, 미국인들은 하는 걸로 알아요. 미국으로 돌아가는 명령을 받으면, 그들은 종종 짐이 너무 무거워지는 것을 막기 위해 물건을 팔곤 했는데, 물론 새롭게 도착한 사람들이 이들 물건을 사곤 했어요.\n\n우리 소파는 우리가 일본을 떠나고 난 후 동일한 가격에 도착한 부부에게 팔렸어요. 꽤 좋았어요 — 우리는 차도 그렇게 했거든.\n\n<div class=\"content-ad\"></div>\n\n우드는 잣목입니다. 배송 라벨을 제거한 후 상자를 갈아내고 다듬어서 아름답고 러스틱한 모습의 수납 상자들을 만들었어요. 이것들은 오늘까지 사용 중이며, 45년 전에는 멋진 엔드 테이블로 사용되었죠.\n\n내부는 주석이나 아연도가 되어 있으며, 뚜껑이 아주 잘 만들어져서 상자가 거의 밀폐됩니다. 이 상자들은 양모 담요나 재킷을 보관하는 데 훌륭했어요.\n\n<img src=\"/assets/img/2024-06-19-나의 DIY 목공상자 프로젝트에서_0.png\" />\n\n측면의 건설 세부사항에 주목해주세요. 연결 부분은 나누어 놓았고, 상자는 매우 튼튼하여 국제적이고 국내적인 여러 번의 이사를 고르게 견디었습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![My DIY Wood Chest Project from a Tea Box](/assets/img/2024-06-19-MyDIYWoodChestProjectfromaTeaBox_1.png)\n\n구매할 때, 나의 상자들은 위 상자와 비슷했다. 이 상자가 현재 이베이에서 $200.00에 판매 중이니, 아마 제가 45년 전에 $20.00을 썼던 것은 잘 한 선택이었을지도 모르겠다.\n\n하지만 비슷한 차 상자를 $75.00 정도에 판매하고 있는 것도 보았다.\n\n만약 한 개를 보게 되면, 그냥 사 버리세요.\n\n\n<div class=\"content-ad\"></div>\n\n품질이 아주 좋아요. 아연 메탈 안쪽은 담는 물건을 안전하게 보호해주고 벌레가 들어가는 것을 막아줘요.\n\n최근에는 손님용 침실 창가에 하나를 두기로 결정했어요. 황동 코너와 전면용 잠금장치를 달아보았는데, 아마존에서 저렴하게 구입할 수 있어요. 분위기를 더해주는 좋은 장식품이죠.\n\n상자나 중고 가구 등 여러 가지 물건에 이 장식용 코너를 붙여서 간단하게 꾸밀 수 있어요.\n\n그리고 저렴하게 구입할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n청동 모서리는 4개에 $9.59이었고 레트로 청동 잠금장치는 아마존에서 2개에 $7.99였어요.\n\n나무 차바코 상자는 오늘날 한 제조업체에서만 생산됩니다. 기업들은 더 현대적인 운송 방법으로 이동했어요.\n\n차바코 상자는 전 세계로 차를 발송하기 위해 사용되었고, 빈 상자가 항상 일본으로 반환되지 않았기 때문에 많은 나라에서 찾아볼 수 있어요.\n\n차바코 상자는 에도 시대에 형태를 갖추기 시작했는데, 그때부터 일본이 차를 수출 상품으로 발송하기 시작했기 때문이에요.\n\n<div class=\"content-ad\"></div>\n\n스즈오카 현은 차 수출을 위한 차 박스가 개발되었고 대부분의 상자가 만들어진 중요한 차 생산지였습니다.\n\n우리가 살던 가나가와 현과 접해 있어서 아마도 1970년대/80년대에 중고 상자를 많이 보게 된 이유일지도 모르겠어요.\n\n![이미지](/assets/img/2024-06-19-MyDIYWoodChestProjectfromaTeaBox_2.png)\n\n일본 차에 대해 많이 이야기하다보니, 제가 차를 마시기로 결심했어요. 스타벅스 컵에서 마셔도 되는 건가요?\n\n<div class=\"content-ad\"></div>\n\n적어도 도쿄 스타벅스 컵이라니요.\n\n눈을 크게 뜨고 주변을 살피면, 버림받은 물건들을 다시 활용하여 유용하고 아름답게 만들 수 있는 다양한 방법을 발견할 수 있어요.\n\n자신만의 DIY 재활용 이야기가 있나요?\n\n분명히 있을 거예요.\n\n<div class=\"content-ad\"></div>\n\n\"Amanda Laughtland의 저술 \"The DIY Diaries\"에서 발행을 고려해보세요.\n\n![이미지](/assets/img/2024-06-19-MyDIYWoodChestProjectfromaTeaBox_3.png)\"","ogImage":{"url":"/assets/img/2024-06-19-MyDIYWoodChestProjectfromaTeaBox_0.png"},"coverImage":"/assets/img/2024-06-19-MyDIYWoodChestProjectfromaTeaBox_0.png","tag":["Tech"],"readingTime":3}],"page":"96","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true}