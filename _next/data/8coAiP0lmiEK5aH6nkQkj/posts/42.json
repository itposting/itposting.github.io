{"pageProps":{"posts":[{"title":"초보자를 위한 Kubernetes와 Docker 비교 가이드","description":"","date":"2024-06-22 00:35","slug":"2024-06-22-KubernetesvsDockerABeginnersGuide","content":"\n\n![Docker vs Kubernetes](/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_0.png)\n\n도커와 쿠버네티스는 컨테이너화와 오케스트레이션에 대해 자주 이야기되는 두 가지 필수 도구입니다. 이 블로그에서는 도커와 쿠버네티스의 역할을 분석하고, 상호 작용하는 방법을 설명하여 각각을 사용해야 할 때를 이해하는 데 도움이 될 것입니다.\n\n# 도커란 무엇인가요?\n\n도커는 컨테이너를 사용하여 응용 프로그램을 구축, 배포 및 실행하는 프로세스를 간소화하는 상용 플랫폼입니다. 컨테이너는 코드, 런타임, 시스템 도구, 라이브러리 및 설정을 포함하여 소프트웨어를 실행하는 데 필요한 모든 것을 포함하는 가볍고 휴대 가능하며 일관된 환경입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_1.png\" />\n\n# Docker의 주요 기능\n\n- 클라이언트-서버 아키텍처: Docker는 클라이언트-서버 아키텍처를 사용합니다. Docker 클라이언트는 Docker 데몬과 통신하여 컨테이너를 빌드, 실행 및 관리합니다.\n- Dockerfile: 개발자는 Dockerfile을 작성하여 Docker 이미지를 생성합니다. Dockerfile에는 컨테이너를 빌드하는 방법에 대한 일련의 지침이 포함됩니다.\n- 사용 편의성: Docker는 응용프로그램을 패키징하는 간단한 방법을 제공하여 소프트웨어를 공유하고 배포하는 것을 더 쉽게 만듭니다.\n\n# Kubernetes란?\n\n<div class=\"content-ad\"></div>\n\n쿠버네티스(자주 K8s로 불립니다)는 컨테이너화된 애플리케이션의 배포, 확장 및 관리를 자동화하기 위해 설계된 오픈 소스 플랫폼입니다. 처음에는 구글에서 개발되었으며, 지금은 쿠버네티스가 컨테이너 오케스트레이션의 산업 표준이 되었습니다.\n\n![Kubernetes](/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_2.png)\n\n# 쿠버네티스의 주요 기능\n\n- 오케스트레이션: 쿠버네티스는 머신 클러스터를 관리하고 사용 가능한 자원을 기반으로 컨테이너를 예약하여 실행할 수 있습니다.\n- 파드: 컨테이너는 파드라고 불리는 단위로 그룹화되며, 쿠버네티스에서 가장 작은 배포 가능한 단위입니다. 파드는 하나 이상의 리소스를 공유하는 컨테이너를 포함할 수 있습니다.\n- 서비스 검색 및 로드 밸런싱: 쿠버네티스는 클러스터 내에서 서비스 검색과 로드 밸런싱을 자동으로 관리합니다.\n- 자동화된 롤아웃 및 롤백: 쿠버네티스는 업데이트를 자동으로 배포하고, 문제가 발생할 경우 변경 사항을 롤백할 수 있습니다.\n- 구성 관리: 쿠버네티스는 구성 및 비밀 관리를 도와 원활하게 애플리케이션을 구성할 수 있도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n# Kubernetes와 Docker 비교\n\n이미지 참조: /assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_3.png\n\n# Docker의 사용 사례\n\n- 개발 및 테스트: Docker는 일관된 개발 및 테스트 환경을 만들기에 완벽합니다.\n- 간편한 배포: Docker는 컨테이너 오케스트레이션이 주요 고려사항이 아닌 소규모 배포에 적합합니다.\n- CI/CD 파이프라인: Docker는 지속적 통합 및 지속적 배포 (CI/CD) 파이프라인과 매끄럽게 통합됩니다.\n\n<div class=\"content-ad\"></div>\n\n# Kubernetes를 사용하는 사례\n\n- 대규모 배포: Kubernetes는 복잡한 대규모 배포를 여러 서버에 걸쳐 처리하기 위해 설계되었습니다.\n- 클라우드 네이티브 애플리케이션: Kubernetes는 클라우드 환경에서 실행되어야 하는 애플리케이션에 이상적이며, 자동 스케일링 및 멀티 클라우드 배포를 지원합니다.\n- 마이크로서비스 아키텍처: Kubernetes는 각 서비스가 자체 컨테이너에 배포되고 독립적으로 스케일링되는 마이크로서비스 아키텍처를 관리하는 데 뛰어난 성능을 발휘합니다.\n- 관리형 서비스: 모든 주요 클라우드 제공업체는 인프라를 유지 관리하는 운영 부담을 줄이는 관리형 Kubernetes 서비스를 제공합니다.\n\n# Docker Swarm과 Kubernetes 중 어떤 것을 선택해야 할까요?\n\nDocker Swarm 또는 Kubernetes를 사용할지 결정할 때 다음 사항을 고려해 보세요:\n\n<div class=\"content-ad\"></div>\n\n# 도커 스웜\n\n![도커 스웜 이미지](/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_4.png)\n\n- 설정 용이성: 도커 스웜은 설정이 쉽고 더 적은 구성이 필요합니다.\n- 소규모 작업량: 더 작고 복잡하지 않은 작업량에 적합합니다.\n- 간단한 인프라: 복잡성 없이 직접 인프라를 관리하는 팀에 적합합니다.\n\n# 쿠버네티스\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_5.png\" />\n\n- 다양한 기능: Kubernetes는 여러 배포 전략, 네트워크 인그레스 관리 및 관찰 가능성을 포함하여 다양한 기능을 제공합니다.\n- 확장성: 대규모 및 복잡한 배포에 더 적합합니다.\n- 클라우드 통합: 클라우드 네이티브 애플리케이션을 위한 우수한 서비스 관리 기능을 제공합니다.\n\n# 결론\n\n<img src=\"/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_6.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n도커는 컨테이너화된 애플리케이션을 빌드, 패키징 및 배포하는 데 탁월한 플랫폼입니다. 반면에 쿠버네티스는 대규모로 컨테이너화된 애플리케이션을 관리하는 강력한 오케스트레이션 도구입니다.\n\n더 작은 프로젝트나 간단한 설정의 경우 도커 스웜이 충분할 수 있습니다. 그러나 더 크고 복잡한 배포, 특히 고급 기능과 클라우드 네이티브 기능이 필요한 경우 쿠버네티스가 더 나은 선택일 것입니다.\n\n읽어 주셔서 감사합니다. 좋아요를 눌러주시고 더 많은 기사를 보고 싶으시면 제 뉴스레터를 구독해주세요. 트위터와 링크드인에서도 저와 소통할 수 있습니다. 🤠","ogImage":{"url":"/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_0.png"},"coverImage":"/assets/img/2024-06-22-KubernetesvsDockerABeginnersGuide_0.png","tag":["Tech"],"readingTime":4},{"title":"크로스-리전 네트워크 성능 문제 조사 방법","description":"","date":"2024-06-22 00:31","slug":"2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue","content":"\n\nHechao Li, Roger Cruz\n\n# 클라우드 네트워킹 토폴로지\n\nNetflix는 SVOD(Subscription Video on Demand)와 라이브 스트리밍, 그리고 게임 서비스에 필수적인 다양한 애플리케이션을 지원하는 매우 효율적인 클라우드 컴퓨팅 인프라를 운영합니다. Amazon AWS를 활용하여, 저희 인프라는 전 세계 다양한 지역에 걸쳐 호스팅되어 있습니다. 이러한 글로벌 배포는 저희 애플리케이션이 고객에게 더 가까운 위치에서 트래픽을 제공함으로써 콘텐츠를 보다 효과적으로 전달할 수 있게 합니다. 분산 시스템과 마찬가지로, 저희 애플리케이션은 때로는 서비스 제공을 계속적으로 유지하기 위해 지역 간 데이터 동기화가 필요합니다.\n\n다음 다이어그램은 지역 간 트래픽을 위한 간단한 클라우드 네트워크 토폴로지를 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_0.png\" />\n\n# 처음 봤을 때의 문제\n\n우리의 클라우드 네트워크 엔지니어링 당직팀은 교차 지역 트래픽이 있는 애플리케이션에 영향을 미치는 네트워크 문제를 해결하기 위한 요청을 받았습니다. 초반에는 애플리케이션이 시간 초과를 경험하고 있어서 아마도 최적의 네트워크 성능으로 인한 것이라고 생각되었습니다. 우리가 다 아는 대로, 네트워크 경로가 길수록 데이터 패킷이 통과해야 하는 장치가 많아져 문제가 발생할 가능성이 높아집니다. 이 사건에서는 클라이언트 애플리케이션이 미국 지역의 내부 서브넷에 위치하고 있으며 서버 애플리케이션이 유럽 지역의 외부 서브넷에 위치하고 있는 것으로 확인되었습니다. 따라서, 데이터 패킷이 인터넷을 통해 멀리 여행해야하므로 네트워크를 탓하는 것은 자연스럽습니다.\n\n네트워크 엔지니어로서, 네트워크에 책임을 뒤질 때 우리의 초기 반응은 보통 “아니야, 네트워크가 문제일 수 없어”이며 우리의 작업은 이를 입증하는 것입니다. 최근 네트워크 인프라에 변경 사항이 없었으며 다른 애플리케이션에 영향을 주는 AWS 이슈가 보고되지 않은 상황에서 당직 엔지니어는 소음이 심한 이웃 문제를 의심하고 호스트 네트워크 엔지니어링 팀의 지원을 받기로 결정했습니다.\n\n<div class=\"content-ad\"></div>\n\n# 이웃들 탓하기\n\n이 맥락에서 잡음이 나는 이웃 문제는 컨테이너가 다른 네트워크 집약적인 컨테이너와 호스트를 공유할 때 발생합니다. 이러한 잡음이 나는 이웃들은 과도한 네트워크 자원을 소모하여 동일한 호스트의 다른 컨테이너가 네트워크 성능이 저하되는 문제를 일으킵니다. 각 컨테이너가 대역폭 제한을 가지고 있더라도, 과다 등록은 이와 같은 문제를 초래할 수 있습니다.\n\n동일한 호스트의 다른 컨테이너들을 조사한 결과 - 이 중 대부분은 동일한 애플리케이션의 일부였습니다 - 우리는 잡음이 나는 이웃의 가능성을 빠르게 제외했습니다. 문제가 있는 컨테이너와 모든 다른 컨테이너의 네트워크 처리량은 설정된 대역폭 제한보다 크게 낮았습니다. 우리는 이 문제를 해결하기 위해 이 대역폭 제한을 제거하여 애플리케이션이 필요한만큼의 대역폭을 사용할 수 있도록 했지만, 문제는 여전히 지속되었습니다.\n\n# 네트워크 탓하기\n\n<div class=\"content-ad\"></div>\n\n네트워크에서 RST 플래그로 표시된 몇 개의 TCP 패킷을 관찰했습니다. 이 플래그는 연결을 즉시 종료해야 함을 나타냅니다. 이러한 패킷의 빈도가 과도하게 높지는 않았지만, RST 패킷의 존재는 여전히 네트워크에서 의심을 불러일으켰습니다. 이것이 실제로 네트워크로 인한 문제인지 확인하기 위해 클라이언트에서 tcpdump를 수행했습니다. 패킷 캡처 파일에서 정확히 30초 후에 닫힌 TCP 스트림을 발견했습니다.\n\n18:47:06에 SYN\n\n![image](/assets/img/2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_1.png)\n\n3-way 핸드쉐이크 (SYN, SYN-ACK, ACK) 이후, 트래픽은 정상적으로 흘렀습니다. 18:47:36에 FIN (30초 후)까지 아무 이상이 없었습니다.\n\n<div class=\"content-ad\"></div>\n\n![packet_capture_image](/assets/img/2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_2.png)\n\n패킷 캡처 결과를 통해 클라이언트 애플리케이션이 FIN 패킷을 보내 연결 종료를 시작했음을 명확히 확인할 수 있었습니다. 그 이후로 서버는 데이터를 계속 보냈지만, 클라이언트가 이미 연결을 닫기로 결정했기 때문에, 이후 서버에서의 모든 데이터에 대해 클라이언트가 RST 패킷으로 응답했습니다.\n\n패킷 손실 때문에 클라이언트가 연결을 닫지 않았는지 확인하기 위해 서버 측에서도 데이터를 캡처하여 모든 서버에서 보낸 패킷이 제대로 수신되었는지 확인했습니다. 이 작업은 서버 측의 NAT 게이트웨이(NGW)를 통해 패킷이 전달되는 복잡성으로 인해 어려움이 있었습니다. 이는 서버 측에서 클라이언트의 IP 및 포트가 NGW의 것으로 나타나는데 이는 클라이언트 측에서 볼 때와 다릅니다. 따라서 TCP 스트림을 정확하게 매칭시키기 위해 클라이언트 측에서 TCP 스트림을 식별하고, 원시 TCP 시퀀스 번호를 찾아 이 번호를 서버 측에서 필터로 사용하여 해당 TCP 스트림을 찾아야 했습니다.\n\n클라이언트와 서버 측의 패킷 캡처 결과를 통해 서버에서 보낸 모든 패킷이 클라이언트가 FIN을 보내기 전에 제대로 수신되었음을 확인했습니다.\n\n<div class=\"content-ad\"></div>\n\n현재 네트워크적인 측면에서 상황이 명확해 졌어요. 클라이언트가 서버에 데이터 요청을 보내 연결을 시작했어요. 서버는 문제 없이 클라이언트에게 데이터를 계속 전송했어요. 그러나 특정 시점에, 서버는 아직 전송할 데이터가 있는데도 클라이언트가 데이터 수신을 중단하기로 선택했어요. 이로 인해 문제가 클라이언트 애플리케이션 자체와 관련이 있을 수 있다는 의심을 품게 되었어요.\n\n# 애플리케이션에 책임을 묻다\n\n문제를 완전히 이해하기 위해, 이제 애플리케이션이 어떻게 작동하는지 이해해야 해요. 아래 다이어그램에 표시된 것처럼, 애플리케이션은 us-east-1 지역에서 실행됩니다. 이는 교차 지역 서버에서 데이터를 읽어 동일 지역의 소비자에 데이터를 작성합니다. 클라이언트는 컨테이너로 실행되고, 서버는 EC2 인스턴스입니다.\n\n특히, 교차 지역에서의 읽기는 문제가 있었지만 쓰기 경로는 순조롭었습니다.가장 중요한 것은 데이터를 읽는 데 30초의 응용 프로그램 수준의 시간 제한이 있었다는 것이에요. 서버에서 초기 데이터 일괄을 30초 내에 읽지 못하면 응용 프로그램(클라이언트)이 오류를 발생시켰어요. 이 시간 제한을 60초로 증가시키면 모든 것이 예상대로 작동했어요. 이것이 클라이언트가 FIN을 시작한 이유가 된 것입니다 — 서버가 데이터 전송을 기다리는 데 인내심을 잃어서였죠.\n\n<div class=\"content-ad\"></div>\n\n![2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_3](/assets/img/2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_3.png)\n\n아마 서버는 데이터를 더 느리게 전송하도록 업데이트 되었을까요? 아니면 클라이언트 애플리케이션이 데이터를 더 느리게 수신하도록 업데이트 되었을까요? 또는 30초 이내에 완전히 전송할 수 없을 정도로 데이터 양이 너무 커졌을까요? 불행하게도, 모든 이 3가지 질문에 대해 애플리케이션 소유자로부터 부정적인 답변을 받았습니다. 서버는 변경 없이 1년 이상 운영되어 왔고, 최신 클라이언트 롤아웃에서 중요한 업데이트가 없었으며, 데이터 양도 일정했습니다.\n\n# 커널을 탓하다\n\n최근 네트워크와 애플리케이션 모두 변경되지 않았다면, 무엇이 변경되었을까요? 실제로, 우리는 문제가 최근에 발행된 Linux 커널 업그레이드 (버전 6.5.13에서 6.6.10으로 업그레이드)와 동시에 발생했음을 발견했습니다. 이 가설을 테스트하기 위해, 커널 업그레이드를 롤백했을 때 애플리케이션의 정상 작동이 복원되었음을 확인했습니다.\n\n<div class=\"content-ad\"></div>\n\n솔직히 말해서, 그 때 나는 커널 버그라고는 믿지 않았어요. 왜냐하면 저는 커널 내의 TCP 구현은 견고하고 안정적이라고 생각했거든요 (스포일러 주의: 얼마나 틀렸는지요!). 하지만 우리는 다른 각도에서 아이디어가 바닥나 있었어요.\n\n좋은 커널 버전과 나쁜 커널 버전 사이에는 약 14,000개의 커밋이 있었어요. 팀의 엔지니어들은 체계적이고 성실하게 두 버전 사이를 이분법적으로 나누었어요. 이분법적 접근법이 몇 개의 커밋으로 좁혀지자, 커밋 메시지에 \"tcp\"가 포함된 변화가 우리의 주의를 끌었어요. 최종 이분법적 접근으로 이 커밋이 문제의 근원임이 확인되었어요.\n\n또한, 이 커밋과 관련된 이메일 기록을 검토하는 도중, 같은 커널 업그레이드 이후에 파이썬 테스트 실패를 신고한 다른 사용자를 발견했어요. 비록 그들의 해결책이 우리 상황에 직접적으로 적용되지는 않았지만, 더 간단한 테스트도 우리 문제를 재현할 수 있음을 시사했어요. strace를 사용하여, 어플리케이션이 서버와 통신할 때 다음 소켓 옵션을 구성했다는 것을 관찰했어요:\n\n```js\n[pid 1699] setsockopt(917, SOL_IPV6, IPV6_V6ONLY, [0], 4) = 0\n[pid 1699] setsockopt(917, SOL_SOCKET, SO_KEEPALIVE, [1], 4) = 0\n[pid 1699] setsockopt(917, SOL_SOCKET, SO_SNDBUF, [131072], 4) = 0\n[pid 1699] setsockopt(917, SOL_SOCKET, SO_RCVBUF, [65536], 4) = 0\n[pid 1699] setsockopt(917, SOL_TCP, TCP_NODELAY, [1], 4) = 0\n```\n\n<div class=\"content-ad\"></div>\n\n그런 다음, 클라이언트가 동일한 소켓 옵션 집합을 구성하는 서버에서 클라이언트로 파일을 전송하는 최소한의 클라이언트-서버 C 애플리케이션을 개발했습니다. 테스트 중에는 클라이언트가 FIN을 발행하기 전에 일반적으로 30초 내에 전송되는 데이터 양을 나타내는 10M 파일을 사용했습니다. 이전 커널에서는 이 교차 지역 전송이 22초만에 완료되었으나 새 커널에서는 39초가 걸렸습니다.\n\n# 근본 원인\n\n최소한의 재현 설정을 통해 문제의 근본 원인을 궁극적으로 파악할 수 있었습니다. 문제의 근본 원인을 이해하기 위해서는 TCP 수신 창에 대한 이해가 필수적입니다.\n\n## TCP 수신 창\n\n<div class=\"content-ad\"></div>\n\n간단히 말하면, TCP 수신 창은 수신자가 송신자에게 \"이만큼의 바이트를 ACK하지 않고 보내도 괜찮다\"라고 알려주는 것입니다. 송신자가 서버이고 수신자가 클라이언트인 경우에는:\n\n![이미지](/assets/img/2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_4.png)\n\n## 창 크기\n\n이제 TCP 수신 창 크기가 처리량에 영향을 줄 수 있다는 것을 알았으니, 질문은 이 창 크기가 어떻게 계산되는지입니다. 응용 프로그램 작성자로서 당신은 창 크기를 결정할 수 없지만, 받은 데이터를 버퍼링하는 데 사용할 메모리의 양을 결정할 수 있습니다. 이는 방금 전 strace 결과에서 본 SO_RCVBUF 소켓 옵션을 사용하여 설정됩니다. 그러나 이 옵션의 값은 수신 버퍼에 대기하는 응용 프로그램 데이터의 양을 의미한다는 것을 유의하십시오. man 7 socket에서 확인할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n사용자가 값 X를 제공하면, 커널은 변수 sk_rcvbuf에 2X를 저장합니다. 다시 말해, 커널은 장부 오버헤드가 실제 데이터와 마찬가지로 많다고 가정합니다(sk_rcvbuf의 50%와 같음).\n\n## sysctl_tcp_adv_win_scale\n\n하지만 위의 가정이 항상 맞지는 않을 수 있습니다. 실제로 오버헤드는 최대 전송 단위(MTU)와 같은 여러 요소에 따라 다를 수 있습니다. 그래서 커널은 이 sysctl_tcp_adv_win_scale을 제공했는데, 이를 사용하여 커널에 실제 오버헤드가 얼마인지 알려줄 수 있습니다. (99%의 사람들이 이 매개변수를 올바르게 설정하는 방법을 알지 못한다고 믿습니다. 저도 분명히 하나죠. 커널인데 오버헤드를 모르는데 어떻게 나에게 그걸 알려달라고 기대하겠어요?)\n\nsysctl 문서에 따르면,\n\n<div class=\"content-ad\"></div>\n\n거의 모든 사람들이 99% 기본값 1을 사용하고 있습니다. 이는 결국 rcvbuf/2^tcp_adv_win_scale = 1/2 * rcvbuf로 오버헤드가 계산됨을 의미합니다. 이것은 SO_RCVBUF 값을 설정할 때의 가정과 일치합니다.\n\n요약해보겠습니다. SO_RCVBUF를 65536으로 설정한다고 가정해 봅시다. 이 값은 소켓 옵션의 setsockopt 시스콜에 의해 설정된 값입니다. 그러면 다음과 같은 결과가 나옵니다:\n\n- SO_RCVBUF = 65536\n- rcvbuf = 2 * 65536 = 131072\n- 오버헤드 = rcvbuf / 2 = 131072 / 2 = 65536\n- 수신 창 크기 = rcvbuf — 오버헤드 = 131072–65536 = 65536\n\n(참고: 이 계산은 단순화된 것입니다. 실제 계산은 더 복잡합니다.)\n\n<div class=\"content-ad\"></div>\n\n간략히 말해서, 커널 업그레이드 전 수신 윈도우 크기는 65536이었습니다. 이 창 크기로 응용 프로그램은 30초 내에 10M 데이터를 전송할 수 있었습니다.\n\n## 변경 내용\n\n이 커밋은 sysctl_tcp_adv_win_scale을 더 이상 사용하지 않도록 만들었고, 오버헤드나 창 크기를 더 정확하게 계산할 수 있는 스케일링 비율을 도입했습니다. 이것이 옳은 조치입니다. 변경으로 인해, 윈도우 크기는 이제 rcvbuf * scaling_ratio입니다.\n\n그러면 scaling_ratio는 어떻게 계산되는 걸까요? skb-`len 및 truesize로 skb 내의 tcp 데이터 길이와 skb의 총 크기를 사용하여 계산됩니다. 이는 하드코딩된 50%보다 실제 데이터를 기반으로 한 더 정확한 비율입니다. 그럼 다음 질문은 여기 있습니다: TCP 핸드셰이크 중 데이터를 전송하기 전에 초기 scaling_ratio를 어떻게 결정할까요? 답은, 대략 0.25로 설정된 마법과 보수적인 비율이 선택되었습니다.\n\n<div class=\"content-ad\"></div>\n\n이제 다음과 같습니다:\n\n- SO_RCVBUF = 65536\n- rcvbuf = 2 * 65536 = 131072\n- 수신 창 크기 = rcvbuf * 0.25 = 131072 * 0.25 = 32768\n\n요약하자면, 커널 업그레이드 후 수신 창 크기가 반으로 줄었습니다. 그 결과로 처리량이 절반으로 줄어 데이터 전송 시간이 두 배로 증가했죠.\n\n당연히 궁금증이 생길 수 있습니다. 초기 창 크기가 작은 것은 이해되지만, 나중에 페이로드의 더 정확한 비율(즉, skb-`len/skb-`truesize)이 있을 때 창이 왜 커지지 않나요? 몇 가지 디버깅을 거친 뒤에 우리는 scaling_ratio가 더 정확한 skb-`len/skb-`truesize로 업데이트된다는 것을 알 수 있었어요. 우리의 경우에는 약 0.66입니다. 그러나 다른 변수인 window_clamp는 이에 맞게 업데이트되지 않습니다. window_clamp는 광고할 수 있는 최대 수신 창이며, 초기 scaling_ratio를 사용하여 0.25 * rcvbuf로 초기화됩니다. 그 결과로 수신 창 크기가 이 값으로 제한되어 더 커질 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n# 문제 해결\n\n이론상으로는 window_clamp를 scaling_ratio와 함께 업데이트하는 것이 해결책입니다. 그러나 다른 예기치 않은 동작을 도입하지 않는 간단한 해결책을 찾기 위해 최종 결정은 초기 scaling_ratio를 25%에서 50%로 증가시키는 것이었습니다. 이로써 수신 윈도우 크기가 원래의 기본 sysctl_tcp_adv_win_scale과 하위 호환성을 유지할 수 있습니다.\n\n한편, 문제가 변경된 커널 동작뿐만 아니라 응용 프로그램이 SO_RCVBUF를 설정하고 30초의 응용 프로그램 수준 타임아웃을 가지고 있기 때문에 발생한다는 것을 유의해야 합니다. 사실, 응용 프로그램은 Kafka Connect이며 두 가지 설정 모두 기본 구성(receive.buffer.bytes=64k 및 request.timeout.ms=30s)입니다. 또한 receive.buffer.bytes를 -1로 변경하여 Linux가 수신 윈도우를 자동 조정할 수 있도록 허용하기 위해 카프카 티켓을 작성했습니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n이번 디버깅 연습은 넷플릭스의 여러 계층과 인프라를 다루는 매우 흥미로운 경험이었습니다. 사실 \"네트워크\"가 문제가 아니었지만, 이번에는 네트워크를 구성하는 소프트웨어 구성 요소인 커널 내의 TCP 구현이 문제였음을 발견했습니다.\n\n만약 이러한 기술적인 도전에 흥미를 느낀다면, 저희의 클라우드 인프라 엔지니어링 팀에 합류를 고려해보세요. 넷플릭스 채용 페이지를 방문하여 Cloud Engineering 직무 기회를 살펴보세요.\n\n# 감사의 말\n\n저희를 위해 이 문제를 조사하고 완화하기 위해 노력한 동료인 Alok Tiagi, Artem Tkachuk, Ethan Adams, Jorge Rodriguez, Nick Mahilani, Tycho Andersen 및 Vinay Rayini에게 특별히 감사드립니다. 또한 Linux 커널 네트워크 전문가인 Eric Dumazet에게 패치를 검토하고 적용해 준 것에 대해 감사의 말씀을 전합니다.","ogImage":{"url":"/assets/img/2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_0.png"},"coverImage":"/assets/img/2024-06-22-InvestigationofaCross-regionalNetworkPerformanceIssue_0.png","tag":["Tech"],"readingTime":10},{"title":"리눅스 프로세스 여정  로그인 과정 깊이 파헤치기","description":"","date":"2024-06-22 00:28","slug":"2024-06-22-TheLinuxProcessJourneylogin","content":"\n\n일반적으로 \"login\"은 Linux 시스템에서 세션을 시작하는 데 사용되는 ELF 바이너리로 기본적으로 \"/usr/bin/login\" (또는 /bin/login)에 위치합니다. Linux 시스템에 로그인할 때 사용되며 인자를 전달하지 않으면 사용자의 프롬프트가 표시됩니다. (https://man7.org/linux/man-pages/man1/login.1.html) - 아래 스크린샷에 나와 있습니다 (https://www.tecmint.com/understanding-shell-initialization-files-and-user-profiles-linux/).\n\n전체적으로, login은 \"util-linux\" 패키지의 일부이며 이는 \"Linux Kernel Organization\"에 의해 배포되는 표준 패키지입니다. kill, more, renice, su 등과 같은 이 패키지에 포함된 다른 실행 파일도 있음을 이해하는 것이 중요합니다 (https://en.wikipedia.org/wiki/Util-linux). \"login\"의 소스 코드를 \"util-linux\" 깃허브 레포지토리 (https://github.com/util-linux/util-linux/blob/master/login-utils/login.c)에서 확인할 수 있습니다.\n\n또한, login은 시스템 전체 사용자 인증을 위한 프레임워크를 제공하는 PAM (Package Authentication Modules)에 기반합니다. 이를 확인하기 위해 \"ldd\" (https://medium.com/@boutnaru/linux-instrumentation-part-4-ldd-888502965a9b)를 사용할 수 있으며 libpam.so 및 아마도 libpam_misc.so도 표시될 것입니다 (https://medium.com/@boutnaru/the-linux-security-journey-pam-pluggable-authentication-module-388496a8785c).\n\n마지막으로, \"login\"의 동작에 영향을 주는 다양한 구성 파일이 있습니다 (PAM 구성 파일 외). 이러한 구성 파일 중에는 \"/etc/login.def\", /etc/motd, /etc/passwd 및 /etc/nologin이 있으며 미래의 글에서 자세한 정보를 확인할 수 있습니다. 또한 \"login\"에 의해 처리되는 로그 기반 파일도 있습니다. 예를 들어 /var/run/utmp, /var/log/wtmp 및 /var/log/lastlog이 있으며 미래의 글에서 자세히 다루겠습니다 (https://linux.die.net/man/1/login).\n\n<div class=\"content-ad\"></div>\n\n제 다음 글에서 만나요 ;-) 트위터에서 제 계정을 팔로우할 수 있어요 — @boutnaru (https://twitter.com/boutnaru). 그리고 다른 글들은 미디엄에서도 읽을 수 있어요 — https://medium.com/@boutnaru. 무료 eBook도 https://TheLearningJourneyEbooks.com에서 찾을 수 있어요.\n\n![이미지](/assets/img/2024-06-22-TheLinuxProcessJourneylogin_0.png)","ogImage":{"url":"/assets/img/2024-06-22-TheLinuxProcessJourneylogin_0.png"},"coverImage":"/assets/img/2024-06-22-TheLinuxProcessJourneylogin_0.png","tag":["Tech"],"readingTime":2},{"title":"리눅스 보안 여정  EGID 유효 그룹 ID 이해하기","description":"","date":"2024-06-22 00:26","slug":"2024-06-22-TheLinuxSecurityJourneyEGIDEffectiveGroupID","content":"\n\nEUID(Effective User ID)와 마찬가지로 EGID(Effective Group ID)도 있어요. 리눅스 시스템에서 특정 작업(프로세스/쓰레드)의 권한을 결정하는 데 주로 사용되며 그룹 소속을 의미합니다.\n\n또한, 특권 사용자인 root와 같이 특권 사용자만 액세스하는 파일에 액세스할 수 있도록 비특권 사용자가 RGID(Real Group ID)와 다른 경우도 있습니다. \"current_egid\" 매크로를 사용하여 커널 내에서 EGID에 액세스할 수 있습니다.\n\n마지막으로 효과적인 그룹 ID를 출력하는 \"id\" 명령 줄 유틸리티를 사용할 수 있습니다. 또한 사용자 모드에서는 \"getegid()\" 시스템 호출을 사용하여 호출한 프로세스/작업의 효과적인 그룹 ID를 검색할 수 있습니다. 동일한 이름의 라이브러리 호출도 있습니다.\n\n다음 글에서 뵐게요 ;-) 트위터에서 저를 팔로우할 수도 있습니다 - @boutnaru. 미디엄에서 다른 글도 읽어보세요 - https://medium.com/@boutnaru. 무료 eBook은 https://TheLearningJourneyEbooks.com에서 다운로드할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n![Linux Screenshot](/assets/img/2024-06-22-TheLinuxSecurityJourneyEGIDEffectiveGroupID_0.png)","ogImage":{"url":"/assets/img/2024-06-22-TheLinuxSecurityJourneyEGIDEffectiveGroupID_0.png"},"coverImage":"/assets/img/2024-06-22-TheLinuxSecurityJourneyEGIDEffectiveGroupID_0.png","tag":["Tech"],"readingTime":1},{"title":"쉘 트랩과 POSIX 신호 쉽게 이해하기","description":"","date":"2024-06-22 00:22","slug":"2024-06-22-ShellTrapsandPOSIXSignals","content":"\n\n\n![Shell traps](/assets/img/2024-06-22-ShellTrapsandPOSIXSignals_0.png)\n\nShell traps catch POSIX signals (and more) to allow asynchronous inter-process communication to inform any process or particular thread of various events and do some work.\n\nBut do you know about all the different signals and ways to use the `trap` command?\n","ogImage":{"url":"/assets/img/2024-06-22-ShellTrapsandPOSIXSignals_0.png"},"coverImage":"/assets/img/2024-06-22-ShellTrapsandPOSIXSignals_0.png","tag":["Tech"],"readingTime":1},{"title":"개발자를 위한 Linux 명령어 치트시트 필수 DevOps 커맨드 모음","description":"","date":"2024-06-22 00:12","slug":"2024-06-22-CheatSheetLinuxCommandsforDevOps","content":"\n\n<img src=\"/assets/img/2024-06-22-CheatSheetLinuxCommandsforDevOps_0.png\" />\n\n당연히요! DevOps 전문가로서, 리눅스 명령줄을 능숙하게 사용하는 것은 서버 관리, 자동화 및 문제 해결에 매우 중요합니다. 이 포괄적인 가이드에서는 명확한 설명과 실용적인 예제를 함께 제공하여 50가지 이상의 필수 리눅스 명령(치트시트)를 다룰 것입니다. 이를 통해 당신의 리눅스 기술을 쉽고 실용적인 방식으로 향상시키는 데 도움이 될 것입니다.\n\n- id - 현재 사용자 또는 다른 사용자의 사용자 및 그룹 이름 및 숫자 ID (UID 또는 그룹 ID)를 찾는 데 사용됩니다.\n예: id -u root\n\n2. cd - 디렉토리 변경: 다른 디렉토리로 이동합니다.\n예시: cd /home/user/documents\n\n<div class=\"content-ad\"></div>\n\n3. **pwd** - Print Working Directory: 현재 디렉토리의 전체 경로를 표시합니다. 예시: pwd\n\n4. **mkdir** - Make Directory: 새로운 디렉토리를 생성합니다. 예시: mkdir new_folder\n\n5. **rm** - Remove: 파일이나 디렉토리를 삭제합니다. 예시: rm file.txt\n\n6. **cp** - Copy: 파일이나 디렉토리를 복사합니다. 예시: cp file.txt /backup\n\n<div class=\"content-ad\"></div>\n\n7. mv - 이동: 파일이나 디렉토리를 이동합니다.\n예시: mv file.txt /new_location\n\n8. touch - 빈 파일 생성: 새로운 빈 파일을 생성합니다.\n예시: touch new_file.txt\n\n9. cat - 연결하고 내용 표시: 파일의 내용을 확인합니다.\n예시: cat file.txt\n\n10. nano - 텍스트 편집기: 텍스트 파일을 편집합니다.\n예시: nano file.txt\n\n<div class=\"content-ad\"></div>\n\n11. grep - 텍스트 검색: 파일에서 텍스트 패턴을 검색합니다.\n예시: grep \"패턴\" file.txt\n\n12. find - 파일 및 디렉터리 검색: 파일 및 디렉터리를 찾습니다. 예시: find /검색할/경로 -name \"파일명\"\n\n13. chmod - 파일 권한 변경: 파일 권한을 수정합니다.\n예시: chmod 755 file.sh\n\n14. chown - 소유권 변경: 파일 또는 디렉터리의 소유자 및 그룹을 변경합니다.\n예시: chown 사용자:그룹 file.txt\n\n<div class=\"content-ad\"></div>\n\n15. **ps** - Process Status: 현재 실행 중인 프로세스를 표시합니다.\n예시: ps aux\n\n16. **top** - 시스템 활동 모니터링: 시스템 프로세스를 실시간으로 모니터링합니다. 예시: top\n\n17. **kill** - 프로세스 종료: 프로세스 ID를 사용하여 프로세스를 종료합니다. 또한 이름 또는 다른 속성에 기반하여 프로세스를 종료하는 pkill을 사용할 수도 있습니다.\n예시: kill PID\npkill 프로세스_이름\n\n18. **wget** - 파일 다운로드: 인터넷에서 파일을 다운로드합니다.\n예시: wget https://example.com/file.zip\n\n<div class=\"content-ad\"></div>\n\n19. less - 파일 내용을 한 화면씩 볼 수 있어 파일 내에서 쉽게 이동하고 검색할 수 있습니다. 예시: less test.log\n\n20. tar - 아카이브 및 추출: 압축된 아카이브 파일을 생성하거나 추출합니다. 예시: tar -czvf archive.tar.gz folder\n\n21. ssh - 보안 셸: 원격 서버에 안전하게 연결합니다. 예시: ssh user@remote_host\n\n22. scp - 안전하게 파일 복사: SSH를 사용하여 로컬 및 원격 시스템 간에 파일을 복사합니다. 예시: scp file.txt user@remote_host:/path\n\n<div class=\"content-ad\"></div>\n\n23. rsync - Remote Sync: 시스템 간 파일 및 디렉터리를 동기화합니다.\n예시: rsync -avz local_folder/ user@remote_host:remote_folder/\n\n24. df - 디스크 여유 공간: 디스크 공간 사용량을 표시합니다.\n예시: df -h\n\n25. du - 디스크 사용량: 파일 및 디렉터리의 크기를 표시합니다.\n예시: du -sh /path/to/directory\n\n26. ifconfig - 네트워크 구성: 네트워크 인터페이스를 표시하거나 구성합니다 (폐기됨, ip를 사용하세요).\n예시: ifconfig\n\n<div class=\"content-ad\"></div>\n\n27. **ip** - IP Configuration: IP 주소 및 네트워크 설정을 관리합니다. 예: `ip addr show`\n\n28. **netstat** - 네트워크 통계: 네트워크 연결 및 통계를 표시합니다 (사용이 권장되지 않습니다, **ss**를 사용하세요). 예: `netstat -tuln`\n\n29. **systemctl** - 시스템 제어: systemd를 사용하여 시스템 서비스를 관리합니다. 예: `systemctl start service_name`\n\n30. **journalctl** - 시스템 로그: systemd의 저널을 사용하여 시스템 로그를 확인합니다. 예: `journalctl -u service_name`\n\n<div class=\"content-ad\"></div>\n\n31. free - 이 명령은 이용 가능한 총 빈 공간의 양을 표시합니다.  \n예시: free -m\n\n32. at - 나중에 명령 실행: 지정된 시간에 명령을 실행합니다.  \n예시: echo \"command\" | at 15:30\n\n33. ping - 네트워크 연결 확인: 호스트로의 네트워크 연결을 확인합니다.  \n예시: ping google.com\n\n34. traceroute - 경로 추적: 호스트에 도달하기 위해 패킷이 이동하는 경로를 추적합니다.  \n예시: traceroute google.com\n\n<div class=\"content-ad\"></div>\n\n35. - 웹사이트 연결 확인: 웹사이트가 정상적으로 작동하는지 확인합니다.\n예시: curl -Is https://example.com | head -n 1\n\n36. dig - 도메인 정보 검색기: 도메인의 DNS 정보를 가져옵니다.\n예시: dig example.com\n\n37. hostname - 호스트 이름 표시 또는 설정: 시스템의 호스트 이름을 표시하거나 변경합니다.\n예시: hostname\n\n38. who - 사용자 표시: 현재 로그인한 사용자를 표시합니다.\n예시: who\n\n<div class=\"content-ad\"></div>\n\n39. useradd - 사용자 추가: 새 사용자 계정을 만듭니다.\n예시: useradd 새사용자\n\n40. usermod - 사용자 수정: 사용자 계정 속성을 수정합니다.\n예시: usermod -aG 그룹이름 사용자이름\n\n41. passwd - 비밀번호 변경: 사용자 비밀번호를 변경합니다.\n예시: passwd 사용자이름\n\n42. sudo - 슈퍼유저 권한 실행: 슈퍼유저로써 명령어를 실행합니다.\n예시: sudo 명령어\n\n<div class=\"content-ad\"></div>\n\n43. **lsof** - 파일 목록 표시: 열려 있는 파일과 해당 파일을 사용하는 프로세스 목록을 표시합니다. 예시: lsof -i :포트\n\n44. **nc** - Netcat: 네트워크 연결을 통해 데이터를 읽고 쓰는 네트워크 유틸리티입니다. 예시: echo \"Hello\" | nc 호스트 포트\n\n45. **scp** - 호스트 간 안전한 복사: 호스트 간에 파일을 안전하게 복사합니다. 예시: scp 파일.txt 사용자@원격_호스트:/경로\n\n46. **sed** - 스트림 편집기: 정규 표현식을 사용한 텍스트 조작입니다. 예시: sed `s/old/new/g` 파일.txt\n\n<div class=\"content-ad\"></div>\n\n47. awk - 텍스트 처리: 패턴 스캔 및 텍스트 처리.\n예시: awk `'print $2'` file.txt\n\n48. cut - 텍스트 열 추출: 텍스트에서 특정 열을 추출합니다. 예시: cut -d\",\" -f2 file.csv\n\n49. sort - 줄 정렬: 텍스트 파일의 줄을 정렬합니다.\n예시: sort file.txt\n\n50. diff - 파일 비교: 두 파일을 비교하여 차이점을 표시합니다. 예시: diff file1.txt file2.txt\n\n<div class=\"content-ad\"></div>\n\n51. ls - 파일 및 디렉토리 목록 조회: 디렉토리 내용을 나열합니다.\n예시: ls -la\n\n52. history - 이 명령은 이전에 실행된 명령을 확인하는 데 사용됩니다.\n예시: history 10\n\n53. cron - 작업 일정 예약: 예약된 작업을 관리합니다.\n예시: crontab -e\n\n54. ssh-keygen - 이 명령은 공개 및 개인 인증 키 쌍을 생성하는 데 사용됩니다. 이 인증 과정을 통해 사용자는 암호를 제공하지 않고 원격 서버에 연결할 수 있습니다.\n예시: ssh-keygen\n\n<div class=\"content-ad\"></div>\n\n55. nslookup - \"Name server Lookup\"의 약자입니다. DNS 호스트 이름을 IP 또는 IP를 호스트 이름으로 확인하는 도구입니다. 문제 해결 중에 매우 유용합니다.  \n예시: nslookup google.com\n\n56. tr - 문자 변환 또는 삭제에 사용됩니다.\n\n이러한 명령어는 Linux 시스템과 작업하는 DevOps 전문가에게 필수적인 다양한 작업을 다룹니다. 각 명령어와 옵션에 대한 자세한 정보는 항상 man 페이지 (man 명령)를 참조하시기 바랍니다.  \n예시: cat crazy.txt | tr \"[a-z]\" \"[A-Z]\"\n\n57. tnc - \"Test Network Connection\"의 약어입니다. 주로 문제 해결 중에 사용되는 명령어입니다. 연결에 대한 진단 정보를 표시합니다.  \n예시: tnc google.com --port 443\n\n<div class=\"content-ad\"></div>\n\n\n58. w - 현재 사용자를 표시합니다.\n\n59. su - 사용자 전환.\n예시: su - root\n\n60. ac(All Connections) — 모든 사용자 또는 지정된 사용자의 총 연결 시간을 나타냅니다.\n예시: ac john\n\n61. tail — 파일의 마지막 부분을 표시합니다. 실시간 로그 모니터링에 자주 사용됩니다.\n예시: tail monitor.logs\n\n\n<div class=\"content-ad\"></div>\n\n62. head — 파일의 첫 부분을 표시하여 파일 내용의 처음을 빠르게 확인하는 데 자주 사용됩니다.\n예시: head content.txt\n\n63. ip route — IP 라우팅 테이블을 표시하거나 조작하는 데 사용됩니다. IP 테이블 규칙을 명확하게 표시합니다.\n예시: ip rout\n\nDevOps 작업을 위한 Linux 명령어와 팁 자세히 보기\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\nDevOps 전문가들은 주로 시스템을 관리하고 작업을 자동화하며 인프라의 원활한 작동을 보장하기 위해 필수적인 Linux 명령어 세트에 의존합니다. 이러한 명령어는 DevOps 작업에 기초를 두고 있으며 시스템 관리부터 배포 자동화에 이르기까지 다양한 문맥에서 사용됩니다.","ogImage":{"url":"/assets/img/2024-06-22-CheatSheetLinuxCommandsforDevOps_0.png"},"coverImage":"/assets/img/2024-06-22-CheatSheetLinuxCommandsforDevOps_0.png","tag":["Tech"],"readingTime":6},{"title":"개발자를 행복하게 만드는 5가지 필수 Linux 명령어","description":"","date":"2024-06-22 00:10","slug":"2024-06-22-5LinuxCommandsthatMakesYouaHappyDev","content":"\n\n![Linux Commands](/assets/img/2024-06-22-5LinuxCommandsthatMakesYouaHappyDev_0.png)\n\n저는 다음 명령어를 사용하는 개발자들이 정말로 가장 흥미로운 사람들이라는 것을 발견했어요!\n\n# CMATRIX\n\nCMatrix는 더 매트릭스 웹사이트의 스크린세이버를 기반으로 합니다. 이것은 \"매트릭스\" 영화에서 본 것처럼 터미널에서 텍스트가 날아다니는 것을 보여줍니다. 모든 라인을 동일한 속도로 또는 비동기적으로 그리고 사용자가 정의한 속도로 스크롤할 수 있습니다. CMATRIX는 영감을 받아…","ogImage":{"url":"/assets/img/2024-06-22-5LinuxCommandsthatMakesYouaHappyDev_0.png"},"coverImage":"/assets/img/2024-06-22-5LinuxCommandsthatMakesYouaHappyDev_0.png","tag":["Tech"],"readingTime":1},{"title":"예제 중심으로 배우는 AWK를 사용한 리눅스유닉스 텍스트 처리 방법","description":"","date":"2024-06-22 00:06","slug":"2024-06-22-TextProcessingwithAWKinLinuxUnixwithexamples","content":"\n\n![이미지](/assets/img/2024-06-22-TextProcessingwithAWKinLinuxUnixwithexamples_0.png) \n\nawk은 패턴 스캔 및 처리를 위한 강력한 프로그래밍 언어이자 명령 줄 도구입니다. 일반적으로 텍스트 처리에 사용되며 데이터 추출 및 보고 도구로 주로 사용됩니다. 이 안내서는 awk의 기본을 이해하고 Linux/Unix에서 효과적으로 사용하는 방법을 보여줄 것입니다.\n\n# awk 소개\n\nawk는 생성자인 Alfred Aho, Peter Weinberger, Brian Kernighan의 이름을 따서 지어졌습니다. 사용자가 지정한 패턴 및 작업을 적용하여 텍스트를 한 줄씩 처리합니다.\n\n<div class=\"content-ad\"></div>\n\n# 기본 구문\n\nawk의 기본 구문은 다음과 같습니다:\n\n```js\nawk '패턴 { 동작 }' 파일\n```\n\n- 패턴: 일치해야 하는 조건을 지정합니다.\n- 동작: 패턴이 일치할 때 수행할 작업을 지정합니다.\n\n<div class=\"content-ad\"></div>\n\n아래는 Markdown 형식으로 표의 내용을 변경한 코드 예시입니다:\n\n\n| 표형식의 데이터 |\n\n\n# 일반적인 사용 사례 및 예시\n\n텍스트를 입력하여 awk를 인라인으로 사용할 수도 있습니다:\n\n```js\necho \"text\" | awk '패턴 { 동작 }'\n```\n\n예를 들어, 다음과 같은 data.txt 파일이 있다고 가정해보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nJohn Doe 30 180\nJane Smith 25 165\nAlice Johnson 35 170\nBob Brown 28 175\nCharlie White 32 160\n```\n\n<img src=\"/assets/img/2024-06-22-TextProcessingwithAWKinLinuxUnixwithexamples_1.png\" />\n\n## 1. Printing Specific Columns separated by space\n\nTo print the first names (1st field) and ages (3rd field) separated by space:\n\n<div class=\"content-ad\"></div>\n\n```js\nawk '{ print $1, $3 }' data.txt\n\n\n----- 결과 -----\n\nJohn 30\nJane 25\nAlice 35\nBob 28\nCharlie 32\n```\n\n## 2. 특정 열을 특정 문자로 구분하여 출력하기\n\n성씨(1번 필드)와 나이(3번 필드)를 세미콜론으로 구분하여 출력하는 방법:\n\n```js\nawk '{ print $1 \";\" $3 }' data.txt\n\n\n----- 결과 -----\n\nJohn;30\nJane;25\nAlice;35\nBob;28\nCharlie;32\n```\n\n<div class=\"content-ad\"></div>\n\n## 3. 조건에 따라 행 필터링하기\n\n네 번째 열이 169보다 큰 경우에 해당하는 모든 행을 출력합니다.\n\n```js\nawk '$4 > 169' data.txt\n\n\n----- 결과 -----\n\nJohn Doe 30 180\nAlice Johnson 35 170\nBob Brown 28 175\n```\n\n## 4. 특정 단어를 포함하는 행 출력하기\n\n<div class=\"content-ad\"></div>\n\n\"John\"이라는 단어를 포함한 라인을 출력합니다.\n\n```js\nawk '/John/' data.txt\n\n\n----- 결과 -----\n\nJohn Doe 30 180\nAlice Johnson 35 170\n```\n\n이 기능은 로그 파일을 처리하고 \"Error\" 또는 \"Warning\"과 같은 키워드를 포함하는 라인을 검색할 때 특히 유용합니다.\n\n## 5. 열을 더합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nawk '{ print $3 + $4 }' data.txt\n\n----- 출력 결과 -----\n\n210\n190\n205\n203\n192\n```\n\n- 다른 대안 (변수 사용)\n\n```js\nawk '{ sum=$3+$4 ; print sum }' data.txt\n```\n\n<div class=\"content-ad\"></div>\n\n## 6. 합계 값\n\n세 번째 열의 값을 합산하여 총합을 출력합니다.\n\n```js\nawk '{ sum+=$3 } END { print sum }' data.txt\n\n----- 출력 결과 -----\n\n150\n```\n\n## 7. 평균 계산\n\n<div class=\"content-ad\"></div>\n\n평균 연령을 계산하려면 (세 번째 필드):\n\n```js\nawk '{ sum += $3; count++ } END { print sum / count }' data.txt\n\n\n----- 결과 -----\n\n30\n```\n\n## 8. 행 번호 출력\n\n각 행에 행 번호를 추가하고 출력합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nawk '{print NR, $0}' data.txt\n\n\n----- 출력 -----\n\n1 John Doe 30 180\n2 Jane Smith 25 165\n3 Alice Johnson 35 170\n4 Bob Brown 28 175\n5 Charlie White 32 160\n```\n\n## 9. 필드 수 출력\n\n각 줄의 필드 수를 출력합니다.\n\n```js\nawk '{ print \"필드 수:\", NF }' data.txt\n\n\n----- 출력 -----\n\n필드 수: 4\n필드 수: 4\n필드 수: 4\n필드 수: 4\n필드 수: 4\n```\n\n<div class=\"content-ad\"></div>\n\n## 10. 첫 번째 및 마지막 필드 인쇄\n\n```js\nawk '{ print $1, $NF }' data.txt\n\n\n----- 결과 -----\n\nJohn 180\nJane 165\nAlice 170\nBob 175\nCharlie 160\n```\n\n## 11. 대문자로 필드 출력\n\n첫 번째 필드를 대문자로 출력\n\n<div class=\"content-ad\"></div>\n\n```js\nawk '{ print toupper($1) }' data.txt\n\n----- 결과 -----\n\nJOHN\nJANE\nALICE\nBOB\nCHARLIE\n```\n\n## 12. 필드에서 부분 문자열 추출하기\n\n2번 필드에서 부분 문자열 추출: 1번 문자부터 3번 문자까지\n\n```js\nawk '{print substr($2,1,3)}' data.txt\n\n----- 결과 -----\n\nDoe\nSmi\nJoh\nBro\nWhi\n```\n\n<div class=\"content-ad\"></div>\n\n## 13. 각 행의 두 번째 필드의 길이 출력\n\n각 행의 두 번째 필드의 길이를 출력합니다.\n\n```js\nawk '{ print length($2) }' data.txt\n\n\n----- 결과 -----\n\n3\n5\n7\n5\n5\n```\n\n## 14. 사용자 정의 함수\n\n<div class=\"content-ad\"></div>\n\n더 복잡한 작업을 위해 awk 스크립트 내에서 함수를 정의할 수 있어요:\n\n```js\nawk '\nfunction square(x) { return x * x }\n{ print $3, \" --> square :\" , square($3) }\n' data.txt\n\n\n----- 출력 결과 -----\n\n30  --> square : 900\n25  --> square : 625\n35  --> square : 1225\n28  --> square : 784\n32  --> square : 1024\n```\n\n# 결론\n\nawk는 여러 가지 방법으로 텍스트 파일을 조작하고 분석하는 데 도움이 되는 다재다능한 도구입니다. 데이터 추출, 계산 수행 또는 텍스트 변환 등을 하고자 할 때 awk는 작업을 간편하게 해주는 다양한 기능을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\nawk 명령어를 적극 활용하여 그 능력을 최대한 발휘하고 리눅스/유닉스에서 더 효율적인 텍스트 처리를 위한 워크플로에 통합해보세요!","ogImage":{"url":"/assets/img/2024-06-22-TextProcessingwithAWKinLinuxUnixwithexamples_0.png"},"coverImage":"/assets/img/2024-06-22-TextProcessingwithAWKinLinuxUnixwithexamples_0.png","tag":["Tech"],"readingTime":4},{"title":"쿠버네티스 네트워킹 완벽 가이드 로드 밸런스, BGP, IPVS 등 핵심 기술 탐구하기","description":"","date":"2024-06-22 00:02","slug":"2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond","content":"\n\n쿠버네티스 세계에서는 매일 ipvs 대 iptables || pureLB 대 metalLB || overlay 대 underlay || Nodeport 대 Loadbalance와 같은 용어가 자주 들려옵니다. 이런 정보들을 다양한 소스에서 얻어서 하나로 묶는 것은 정말 어렵습니다. 그래서 저는 여기서 그것을 해냈습니다.\n\n이 질문에 대한 답을 아시나요?\n네트워킹 측면이 모두 어떻게 관리되는가요?\npureLB가 CNI에 어떻게 연결되는가요?\nClusterIP 서비스가 IPVS에 어떻게 연결되는가요?\nNodeport를 사용했을 때 netstat으로 열린 포트를 볼 수 없는 이유는 무엇일까요?\n\n# 모든 것의 큰 그림\n\n저는 머릿 속에 20개의 웹사이트와 기사를 모두 정리해서 쿠버네티스 네트워킹을 이해하는 것이 어려웠지만, 그걸 해냈고, 여러분에게 더 쉽게 이해시킬 수 있기를 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n제가 말씀드릴 주제는 이러한 주제들이 Kubernetes와 어떻게 연결되어 있는지 보고 통합되어 있는지를 알아보겠습니다.\n로드 밸런싱, ipvs, iptables, BGP, 브릿지, CNI, PureLB, 엔드포인트, 서비스, 오버레이, 언더레이, ipip, kube-proxy, 인그레스 컨트롤러.\n\n빠르고 단계별로 진행해 봅시다:\n\n# 1- CNI, LB 컨트롤러와 Kube-proxy의 관계\n\nCNI: 각 컨테이너에 대한 네트워크 인터페이스를 생성하고 구성하여 Kubernetes 네트워킹을 구성합니다. Kubelet은 CNI를 호출하여 네트워크 인터페이스를 설정하고 IP 주소를 할당합니다.\n\n\n<div class=\"content-ad\"></div>\n\nCNI는 2가지 모델에서 작동합니다:\n- 캡슐화(overlay)\n- 비캡슐화(underlay)\n\n- 캡슐화(overlay): VXLAN 및 IPSEC와 같은 기술을 나타냅니다. 이는 여러 Kubernetes 노드에 걸칠 수 있는 레이어-3 네트워킹의 레이어-2입니다. 레이어-2는 격리되어 있어 라우팅 배포가 필요하지 않습니다. IP 패키지를 제공하는 IP 헤더를 생성합니다. 이 모델은 워커와 파드를 연결하는 브리지를 제공합니다. 통신을 관리하는 요소는 CRI입니다.\n\n![이미지](/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_0.png)\n\n- 비캡슐화(underlay): 컨테이너 간에 패킷을 라우팅하기 위한 L3 네트워크를 제공합니다. BGP를 사용하여 라우팅 정보를 분배하기 위해 워커가 필요합니다. 이 모델은 워커 사이에 네트워크 라우터를 확장하는 것을 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_1.png)\n\nLB-controller: MetalLB, PureLB,...은 Kubernetes의 LoadBalancer 서비스 유형의 기능을 제공합니다.\n로드 밸런서(LB) 서비스를 생성할 때 할당된 외부 IP는 기본 인터페이스 아래에 보조 주소로 생성됩니다. 이는 BGP BIRD 라우터가 IP를 캡처하고 경로, 주소 및 기타 구성을 추가할 수 있게 합니다.\n\n새로운 IP가 할당되면:\n\n![이미지](/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_2.png)\n\n\n<div class=\"content-ad\"></div>\n\nKube-proxy: iptables, ipvs 등에서 네트워크 규칙을 유지합니다.\n네트워크 정책, NAT, 전방규칙을 추가합니다.\n\n간단한 예를 들어보면:\nsvc를 생성하면 kube-proxy가 iptables에 규칙을 추가합니다.\n\n이 부분에 대한 요약:\n\n- Kube-proxy: IPTABLES, IPVS 등에서 규칙을 유지합니다.\n- CNI: 기본 네트워크에 대한 공통 인터페이스를 제공하고, 트래픽을 원하는 대상으로 라우팅하며, 관련 기능을 수행합니다.\n- LB-controller: 부하 분산 기능을 제공하고, 호스트 인터페이스를 업데이트하여 보조 IP 주소를 추가합니다.\n\n<div class=\"content-ad\"></div>\n\n# 2-POD to POD / Container to Container — 단일 노드 (IP 주소 기반)\n\n![링크와 관련된 이미지](/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_3.png)\n\nCustom Bridge (CBR), Veth (가상 이더넷), Ethernet (eth) 및 전체 네트워킹 설정은 containerd, CRI-O, Mirantis 등의 컨테이너 런타임에 의해 처리됩니다. 대부분의 컨테이너 런타임 인터페이스 (CRI)는 Calico, Flannel, Cilium 등의 옵션을 포함하여 목적에 맞게 컨테이너 네트워킹 인터페이스 (CNI) 플러그인을 활용합니다.\n\nPod 내의 모든 컨테이너는 동일한 네트워크를 공유합니다. 왜냐하면 그들은 동일한 네트워크 네임스페이스 내에 있기 때문이죠.\n\n<div class=\"content-ad\"></div>\n\n\"일시 정지(pause) 컨테이너는 Kubernetes에서 네트워킹 및 프로세스간 통신(IPC)을 책임집니다.\n\n각 파드마다 CBR에 Veth가 생성되며, 이 브리지에서 L-2 라우팅이 수행됩니다. 예를 들어, 파드1에서 파드2로의 패킷은 CBR을 통해 전달되며, 이 경우 NAT가 발생하지 않습니다.\n\n# 3- POD to POD / Container to Container — multi node (IP 기반)\n\n![이미지](/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_4.png)\"\n\n<div class=\"content-ad\"></div>\n\n각 노드가 동일한 네트워크에 있기 때문에 팟의 IP 주소가 노드 네트워크 전체에서 라우팅됩니다.\n- 두 노드 모두 동일한 네트워크에 있습니다. (서로를 볼 수 있음)\n- CNI는 각 노드의 각 팟에 대한 라우트를 생성합니다.\n\nNode-1의 CBR에는 pod4의 Mac 주소가 없기 때문에 패킷이 지정된 라우팅 테이블이 있는 인터페이스를 통해 전달됩니다. 이것은 터널, 다른 인터페이스, eth0 등이 될 수 있습니다. 구조에 따라 실제로 달라집니다.\n\nKubernetes의 각 노드는 자체 CIDR을 갖고 있어 올바른 노드로 트래픽을 라우팅할 수 있습니다.\n\n# 4- POD to POD / Container to Container — multi node (Service IP addr based)\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_5.png)\n\n서비스에 관한 경우, IPTABLES/IPVS가 중요한 역할을 합니다. Netfilter에서, 서비스 IP 주소는 무작위로 관련 pod IP 주소로 변경됩니다(로드 밸런싱 알고리즘에 따라). Kube-proxy는 Netfilter 규칙을 업데이트하고 pod IP 주소를 서비스에 할당하는 책임이 있습니다.\n\n노드가 svc 목적지를 갖는 패킷을 받을 때, Netfilter에서 규칙이 서비스와 일치하고 대상 pod IP 주소로 경유됩니다.\n\n그렇다면, 그 과정이 어떻게 이루어지는 걸까요?\n\n\n<div class=\"content-ad\"></div>\n\n서비스는 서비스 선택기에 지정된 파드 레이블과 일치하여 엔드포인트 슬라이스를 업데이트합니다. 선택기가 파드의 레이블과 일치하면 IP 주소, 포트, 프로토콜 등과 같은 관련 정보가 검색되어 서비스와 관련된 엔드포인트 슬라이스에 주입됩니다.\n\n# 큰 그림에 대비 준비 되셨나요? 준비 되셨다면 이제 시작하세요.\n\n<img src=\"/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_7.png\" />\n\n<div class=\"content-ad\"></div>\n\n이 그림에는 CNI (Calico), IPVS, PURELB, IPIP (overlay) 및 인그레스 컨트롤러가 모두 함께 구현되어 있으며 각각의 역할이 있습니다.\n\nCalico: Calico에 의해 모든 네트워킹이 처리됩니다. 오버레이 (IPIP) 및 언더레이 (BGP).\n\n- 이전에 언급한 바와 같이 모든 파드 IP 주소는 이 경우에는 kube-ipvs 브리지 인터페이스인 CBR에 할당됩니다.\n- 각 파드는 자체 가상 인터페이스를 갖습니다.\n- tunl0 (IPIP)은 가상 인터페이스로, 오버레이 아키텍처로 노드를 서로 연결합니다. 이는 모든 파드의 IP 주소가 이 터널을 통과한다는 것을 의미합니다.\n- PureLB는 로드 밸런서(LB) 컨트롤러이며 kube-lb0를 가상 인터페이스로 구현하여 호스트 네트워크를 관리하며, 호스트 기본 인터페이스에 LB IP 주소를 추가로 할당합니다.\n- PureLB는 BGP, OSPF와 같은 라우팅 프로토콜과 호환됩니다. 이미 Calico에 의해 구현된 BGP BIRD 라우터가 있기 때문에, PureLB는 이를 인식하고 다른 BGP 라우터를 구현하지 않습니다.\n- BGP는 인터페이스에 할당된 모든 IP 주소를 수집하고 이를 라우팅 테이블에서 정의합니다.\n\n지금까지, 파드-1에서 다른 노드의 파드-5에 도달하려는 패킷이 있을 때, kube-ipvs가 알지 못하는 것에 대한 답변을 할 수 없어서, 다음 단계는 BGP에 의해 업데이트된 라우팅 테이블입니다. 오버레이 네트워크 아키텍처를 갖고 있기 때문에, 원하는 대상으로 라우팅될 것입니다. 서비스를 호출하면 ipvs 규칙이 작동합니다.\n\n<div class=\"content-ad\"></div>\n\n이제는 IPVS에서 Endpoints, 서비스, NodePort 및 LB가 유일한 규칙임을 알고 있습니다. 그것을 염두에 두고:\n\n![이미지](/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_8.png)\n\n저희는 인그레스 컨트롤러를 위한 로드밸런서 유형의 서비스를 가지고 있습니다. 이는 외부에서 인그레스에 접근 가능함을 의미합니다. 이 IP를 호출하면 패킷이 적절한 노드로 이동한 후, IPVS가 그것을 NodePort(NAT)로 전달하여 노드를 통해 경로를 찾아 해당 노드로 이동합니다.\n\n그 후에, NodePort는 ClusterIP와 연관되는데, 이는 인그레스 컨트롤러 팟의 IP 주소를 알고 있습니다. 이 설정은 유용한데, 인그레스 컨트롤러가 패킷을 받는 즉시 정의된 규칙을 기반으로 원하는 서비스로 경로를 설정하고, 그 후 목적지 팟으로 이동하기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사의 목표는 각 구성 요소에 대한 철저한 설명을 제공하는 것이 아니었습니다. 대신, 이미 각 개념에 익숙한 사람들을 위해 정보를 통합하여 한 곳에서 포괄적인 개요를 제공하는 데 초점을 맞추었습니다.\n\n저는 여러 출처를 사용했고, 더 많은 정보를 위해 여기에 언급합니다:\n\nhttps://medium.com/thermokline/comparing-k8s-load-balancers-2f5c76ea8f31\n\nhttps://medium.com/@seifeddinerajhi/kube-proxy-and-cni-the-hidden-components-of-kubernetes-networking-eb30000bf87a\n\n<div class=\"content-ad\"></div>\n\n[Calico Networking](https://docs.tigera.io/calico/latest/networking/)\n\n[Overview of PureLB](https://purelb.gitlab.io/docs/how_it_works/overview/)","ogImage":{"url":"/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_0.png"},"coverImage":"/assets/img/2024-06-22-DecipheringtheKubernetesNetworkingMazeNavigatingLoad-BalanceBGPIPVSandBeyond_0.png","tag":["Tech"],"readingTime":7},{"title":"좀비 프로세스의 비밀을 밝히다 Linux에서 알아야 할 모든 것","description":"","date":"2024-06-21 23:58","slug":"2024-06-21-LinuxUnveilingtheMysteriesofZombieProcesses","content":"\n\n\n![LinuxUnveilingtheMysteriesofZombieProcesses](/assets/img/2024-06-21-LinuxUnveilingtheMysteriesofZombieProcesses_0.png)\n\n어떤 프로세스가 \"exit\"를 호출하면 즉시 사라지지 않는다는 사실을 아는 사람은 적을 것입니다. 대신, \"좀비\" 프로세스라고 불리는 데이터 구조를 남깁니다. Linux 프로세스의 다섯 가지 상태 중에서 좀비 프로세스는 특히 독특합니다.\n\n거의 모든 메모리 공간을 포기했으며 실행 가능한 코드가 전혀 없으며 스케줄링될 수 없으며 단지 ...에 위치하고...\n","ogImage":{"url":"/assets/img/2024-06-21-LinuxUnveilingtheMysteriesofZombieProcesses_0.png"},"coverImage":"/assets/img/2024-06-21-LinuxUnveilingtheMysteriesofZombieProcesses_0.png","tag":["Tech"],"readingTime":1}],"page":"42","totalPageCount":112,"totalPageGroupCount":6,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}