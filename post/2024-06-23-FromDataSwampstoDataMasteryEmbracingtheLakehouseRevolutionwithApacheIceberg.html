<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>데이터 늪에서 데이터 마스터까지 Apache Iceberg와 함께하는 레이크하우스 혁명  | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="데이터 늪에서 데이터 마스터까지 Apache Iceberg와 함께하는 레이크하우스 혁명  | itposting" data-gatsby-head="true"/><meta property="og:title" content="데이터 늪에서 데이터 마스터까지 Apache Iceberg와 함께하는 레이크하우스 혁명  | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg" data-gatsby-head="true"/><meta name="twitter:title" content="데이터 늪에서 데이터 마스터까지 Apache Iceberg와 함께하는 레이크하우스 혁명  | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 16:31" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">데이터 늪에서 데이터 마스터까지 Apache Iceberg와 함께하는 레이크하우스 혁명 </h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="데이터 늪에서 데이터 마스터까지 Apache Iceberg와 함께하는 레이크하우스 혁명 " loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<img src="/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_0.png">
<p>우리의 데이터 인프라는 처음에 Amazon S3를 사용한 데이터 레이크와 Amazon Redshift를 사용한 데이터 웨어하우스의 조합으로 이루어져 있었습니다.</p>
<p>이 구성은 대량의 데이터를 저장하고 분석할 수 있는 장점이 있었지만, 추가 저장 공간 및 유지보수 문제와 ACID 규칙 준수를 지원하지 않는 등 여러 가지 도전 과제가 있었습니다.</p>
<h1>목표</h1>
<div class="content-ad"></div>
<p>호수집 구조로 전환하는 목표는 데이터 레이크와 데이터 웨어하우스의 최상의 특징을 결합하는 것이었습니다. 이미 완전히 발달한 데이터 레이크가 있었기 때문에, 우리의 초점은 데이터 웨어하우스의 기능을 통합하는 데 있었습니다.</p>
<h2>데이터 레이크하우스와 데이터 레이크 및 데이터 웨어하우스의 차이는 무엇인가요?</h2>
<p>이름에서 알 수 있듯이 '데이터 레이크하우스'는 데이터 레이크와 데이터 웨어하우스의 최상의 특징을 결합합니다. 본질적으로 데이터 레이크하우스는 데이터 레이크의 기능을 확장하여 데이터 웨어하우스와 유사한 기능을 통합합니다. 데이터 레이크의 유연성, 확장 가능성 및 비용 효율성을 제공하는 한편, 데이터 웨어하우스와 주로 관련된 튼튼한 데이터 관리와 ACID (원자성, 일관성, 분리, 지속성) 트랜잭션을 제공하려고 합니다.</p>
<h1>왜 아파치 아이스버그를 선택했나요?</h1>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_1.png">
<ul>
<li>ACID 트랜잭션: ACID 트랜잭션을 지원하여 데이터 일관성과 신뢰성을 보장하고, 동시에 쓰기 및 읽기를 허용하여 데이터 오염이 발생하지 않습니다.</li>
<li>비용 및 유지보수 감소: Redshift와 연관된 높은 저장 및 라이선스 비용을 최소화하며, 기본적으로 compaction 및 압축(zstd)을 지원합니다.</li>
<li>성능 최적화: 메타데이터 가지치기, 파티셔닝 및 데이터 건너뛰기와 같은 기능을 통해 쿼리 성능을 크게 향상시킵니다.</li>
<li>호환성: Apache Spark, Flink, Presto 등 여러 데이터 처리 엔진과 함께 작동하여 작업에 최적인 도구를 선택할 수 있는 유연성 제공.</li>
<li>Parquet, ORC, Avro와 같은 파일 형식 지원.</li>
<li>기존의 AWS 생태계 및 Athena, Glue, Catalog, EMR 등과 시프트레이엘튼랏하는 탐바.</li>
<li>성능 향상: 빠르게 쿼리되어 데이터를 효율적으로 검색할 수 있습니다.</li>
<li>통합 데이터 처리: 일괄 및 스트리밍 데이터 처리에 대해 통합된 경험을 제공하여 실시간 및 기존 데이터의 원활한 통합 및 처리를 가능하게 합니다.</li>
</ul>
<img src="/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_2.png">
<h1>Iceberg 아키텍처:</h1>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_3.png" alt="Image 1"></p>
<p><img src="/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_4.png" alt="Image 2"></p>
<h1>Apache Iceberg을 활용한 Lakehouse 전환 단계</h1>
<p>환경 설정:</p>
<div class="content-ad"></div>
<ul>
<li>저장소 구성: Amazon S3와 같은 확장 가능한 저장소 솔루션을 설정하여 원본 데이터와 처리된 데이터를 저장하세요. 이미 저희와 같이 S3를 활용 중이라면 데이터 및 메타데이터를 저장할 대상 버킷을 정의하세요.</li>
<li>Iceberg 설치 및 구성: EMR을 사용 중이므로 Spark 세션을 생성할 때 Iceberg 관련 설정을 추가해야 합니다.</li>
</ul>
<pre><code class="hljs language-js">spark = <span class="hljs-title class_">SparkSession</span>.<span class="hljs-property">builder</span> \
    .<span class="hljs-title function_">appName</span>(<span class="hljs-string">"user_device_data"</span>) \
    .<span class="hljs-title function_">master</span>(<span class="hljs-string">"yarn"</span>) \
    .<span class="hljs-title function_">config</span>(<span class="hljs-string">"spark.sql.defaultCatalog"</span>, catalog) \
    .<span class="hljs-title function_">config</span>(f<span class="hljs-string">"spark.sql.catalog.{catalog}"</span>, <span class="hljs-string">"org.apache.iceberg.spark.SparkCatalog"</span>) \
    .<span class="hljs-title function_">config</span>(f<span class="hljs-string">"spark.sql.catalog.{catalog}.warehouse"</span>,
            <span class="hljs-string">"&#x3C;Your S3 Warehouse Path>"</span>) \
    .<span class="hljs-title function_">config</span>(<span class="hljs-string">"spark.sql.catalog.glue_catalog.catalog-impl"</span>, <span class="hljs-string">"org.apache.iceberg.aws.glue.GlueCatalog"</span>) \
    .<span class="hljs-title function_">config</span>(<span class="hljs-string">"spark.sql.catalog.glue_catalog.io-impl"</span>, <span class="hljs-string">"org.apache.iceberg.aws.s3.S3FileIO"</span>) \
    .<span class="hljs-title function_">config</span>(<span class="hljs-string">"spark.sql.extensions"</span>, <span class="hljs-string">"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions"</span>) \
</code></pre>
<p>데이터 이전:</p>
<ul>
<li>데이터레이크 — 기존 Parquet에서 Iceberg로 데이터 마이그레이션: 먼저 테이블을 만들었고, 기존 데이터레이크에서 데이터를 읽어와 Apache Spark를 사용하여 Iceberg 테이블에 기록함으로써 메타데이터가 올바르게 캡처되도록합니다.</li>
<li>데이터웨어하우스 — Redshift 데이터를 Iceberg 형식으로 투입: Redshift에서 언로드한 데이터를 S3로 복사한 후, 데이터레이크와 동일한 접근 방식을 따랐습니다.</li>
</ul>
<div class="content-ad"></div>
<p>아래와 같은 방법으로 인플레이스 마이그레이션을 수행할 수 있습니다:</p>
<ul>
<li>add_files 사용</li>
<li>migrate 사용</li>
</ul>
<p><a href="https://aws.amazon.com/blogs/big-data/migrate-an-existing-data-lake-to-a-transactional-data-lake-using-apache-iceberg/" rel="nofollow" target="_blank">기존 데이터 레이크를 Apache Iceberg를 사용한 트랜잭션 데이터 레이크로 마이그레이션하기</a></p>
<p>기존 ETL 프로세스에서의 조정:</p>
<div class="content-ad"></div>
<ul>
<li>우리는 모든 ETL 작업에 대한 싱크 구성을 변경하여 데이터 아이스버그 형식으로 쓰게 했습니다. 위에서 언급한 구성은 스파크 세션을 만들 때 사용되었습니다.</li>
</ul>
<p>데이터 거버넌스 및 메타데이터 관리:</p>
<p>Iceberg 테이블의 유지 보수 작업.</p>
<ul>
<li>Compact : 우리는 다시 쓰고 결과 파일의 원하는 크기로 재작성하기 위해 rewriteDataFiles 절차를 실행합니다. 이것은 읽기 시간을 최적화하는 데 도움이 됩니다.</li>
</ul>
<div class="content-ad"></div>
<p>('write.parquet.target-file-size-bytes '='52428800')</p>
<h1>약 이만큼의 바이트를 대상으로 생성된 파일의 크기를 제어합니다.</h1>
<ol start="2">
<li>스냅샷 만료: 분석에 더 이상 필요하지 않은 데이터에 대해 스냅샷 만료를 실행하여 불필요한 저장 비용을 피합니다. 만료된 스냅샷과 연결된 매니페스트 목록, 매니페스트 및 데이터 파일은 여전히 유효한 스냅샷과 연관되어 있지 않은 한 스냅샷 삭제 시에 삭제됩니다.</li>
</ol>
<p>우리는 이 작업을 수행하기 위해 expireSnapshots 프로시저를 실행합니다.</p>
<ol start="3">
<li>오래된 메타데이터 파일 제거: Iceberg는 새 메타데이터 파일이 생성될 때 오래된 메타데이터 파일을 삭제하는 설정을 활성화할 수 있습니다. 또한 테이블이 보유해야 하는 메타데이터 파일 수를 설정할 수 있습니다. 우리는 그 수를 5로 설정했습니다.</li>
</ol>
<div class="content-ad"></div>
<pre><code class="hljs language-js">write.<span class="hljs-property">metadata</span>.<span class="hljs-property">delete</span>-after-commit.<span class="hljs-property">enabled</span>  <span class="hljs-literal">true</span>
write.<span class="hljs-property">metadata</span>.<span class="hljs-property">previous</span>-versions-max <span class="hljs-number">5</span>
</code></pre>
<ol start="4">
<li>Orphan 파일 삭제 : Orphan 파일 제거를 위해 deleteOrphanFiles 절차를 실행하여 필요 없는 파일을 저장하지 않습니다. 이러한 파일들은 정기적인 정리 프로세스에서 선택되지 않습니다.</li>
</ol>
<p>쿼리 및 분석:</p>
<ul>
<li>쿼리 최적화: Iceberg는 메타데이터 가지치기(metadata pruning) 및 프리디케이트 푸시다운(predicate pushdown)과 같은 기능을 지원하여 쿼리 성능을 최적화할 수 있습니다. 데이터와 메타데이터 모두에 대한 쿼리 엔진으로 Athena를 사용하고 있습니다.</li>
</ul>
<div class="content-ad"></div>
<p>메타데이터 쿼리 치트 시트 : <a href="https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg-table-metadata.html" rel="nofollow" target="_blank">https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg-table-metadata.html</a></p>
<ul>
<li>실시간 분석 활성화: 스파크 ETL 프로세스에서 데이터 수집 및 업데이트가 발생하여 배치 및 스트리밍 데이터 처리에 통합된 경험을 제공합니다.</li>
</ul>
<h1>Apache Iceberg 구현의 장점</h1>
<p>비용 효율성:</p>
<div class="content-ad"></div>
<ul>
<li>저장 비용 절감: Apache Iceberg는 기본 Z-표준 (zstd) 압축을 사용하여 저장 공간 요구 사항을 크게 줄입니다. 또한 파티션 분할을 지원하여 데이터 스캔을 제한하여 저장 공간 사용을 최적화합니다.</li>
<li>중복 데이터 웨어하우징 솔루션 소거: Iceberg의 ACID 규정 준수로 기존 데이터 웨어하우징 솔루션이 불필요해집니다. Amazon S3의 저장 비용은 Redshift의 그것보다 상당히 낮기 때문에 Redshift 라이선싱 비용을 상당히 절약할 수 있습니다.</li>
</ul>
<p>Apache Iceberg의 채택으로 일반 Parquet 형식으로 데이터를 저장하는 비용과 전체 S3 비용 모두 30%의 저장 비용 절감과 20%의 S3 비용 절감을 이끌었습니다.</p>
<p>성능 향상:</p>
<ul>
<li>쿼리 성능 개선: Iceberg의 최적화된 데이터 관리 및 인덱싱으로 쿼리 성능과 데이터 검색 시간이 상당히 향상되었습니다.</li>
</ul>
<div class="content-ad"></div>
<p>역사적 데이터 수정:</p>
<ul>
<li>간편화된 데이터 업데이트: 이전에는 역사적 데이터를 수정하기 위해 작은 배치 작업을 작성해야 했습니다. 아이스버그를 사용하면 몇 가지 업데이트 명령을 실행함으로써 이를 달성할 수 있어, 프로세스가 간소화되었습니다.</li>
</ul>
<p>접근 제어:</p>
<ul>
<li>간편화된 행 수준 접근: Redshift에서 서로 다른 국가에 대한 행 수준 접근을 제공하는 것은 복잡했습니다. 아이스버그를 통해 데이터 파티셔닝을 사용하여 특정 버킷에 대한 접근 정책을 쉽게 구현할 수 있어, 접근 관리가 간소화됩니다.</li>
</ul>
<div class="content-ad"></div>
<p>Apache Iceberg를 구현함으로써 비용 효율성, 향상된 성능, 간단화된 기존 데이터 수정 및 향상된 액세스 관리를 달성했습니다.</p>
<h1>결론</h1>
<p>여러 데이터셋을 Apache Iceberg로 이관하는 작업을 성공적으로 완료했으며 이미 상당한 비용 및 성능 이점을 확인하고 있습니다. 레이크하우스 아키텍처로의 전환은 데이터 레이크와 데이터 웨어하우스의 최상의 기능을 활용할 수 있게 해주어 더 효율적이고 확장 가능한 데이터 인프라를 구축하게 되었습니다.</p>
<p>이 구현 기간 동안 빈말 야다브와 시바무 구프타에게 놀라운 헌신과 값진 기여에 진심으로 감사드립니다.</p>
<div class="content-ad"></div>
<p>사실, 한국어로 "테이블" 태그를 "Markdown" 형식으로 변환하면 되는 것 같아요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"데이터 늪에서 데이터 마스터까지 Apache Iceberg와 함께하는 레이크하우스 혁명 ","description":"","date":"2024-06-23 16:31","slug":"2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_0.png\" /\u003e\n\n우리의 데이터 인프라는 처음에 Amazon S3를 사용한 데이터 레이크와 Amazon Redshift를 사용한 데이터 웨어하우스의 조합으로 이루어져 있었습니다.\n\n이 구성은 대량의 데이터를 저장하고 분석할 수 있는 장점이 있었지만, 추가 저장 공간 및 유지보수 문제와 ACID 규칙 준수를 지원하지 않는 등 여러 가지 도전 과제가 있었습니다.\n\n# 목표\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n호수집 구조로 전환하는 목표는 데이터 레이크와 데이터 웨어하우스의 최상의 특징을 결합하는 것이었습니다. 이미 완전히 발달한 데이터 레이크가 있었기 때문에, 우리의 초점은 데이터 웨어하우스의 기능을 통합하는 데 있었습니다.\n\n## 데이터 레이크하우스와 데이터 레이크 및 데이터 웨어하우스의 차이는 무엇인가요?\n\n이름에서 알 수 있듯이 '데이터 레이크하우스'는 데이터 레이크와 데이터 웨어하우스의 최상의 특징을 결합합니다. 본질적으로 데이터 레이크하우스는 데이터 레이크의 기능을 확장하여 데이터 웨어하우스와 유사한 기능을 통합합니다. 데이터 레이크의 유연성, 확장 가능성 및 비용 효율성을 제공하는 한편, 데이터 웨어하우스와 주로 관련된 튼튼한 데이터 관리와 ACID (원자성, 일관성, 분리, 지속성) 트랜잭션을 제공하려고 합니다.\n\n# 왜 아파치 아이스버그를 선택했나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_1.png\" /\u003e\n\n- ACID 트랜잭션: ACID 트랜잭션을 지원하여 데이터 일관성과 신뢰성을 보장하고, 동시에 쓰기 및 읽기를 허용하여 데이터 오염이 발생하지 않습니다.\n- 비용 및 유지보수 감소: Redshift와 연관된 높은 저장 및 라이선스 비용을 최소화하며, 기본적으로 compaction 및 압축(zstd)을 지원합니다.\n- 성능 최적화: 메타데이터 가지치기, 파티셔닝 및 데이터 건너뛰기와 같은 기능을 통해 쿼리 성능을 크게 향상시킵니다.\n- 호환성: Apache Spark, Flink, Presto 등 여러 데이터 처리 엔진과 함께 작동하여 작업에 최적인 도구를 선택할 수 있는 유연성 제공.\n- Parquet, ORC, Avro와 같은 파일 형식 지원.\n- 기존의 AWS 생태계 및 Athena, Glue, Catalog, EMR 등과 시프트레이엘튼랏하는 탐바.\n- 성능 향상: 빠르게 쿼리되어 데이터를 효율적으로 검색할 수 있습니다.\n- 통합 데이터 처리: 일괄 및 스트리밍 데이터 처리에 대해 통합된 경험을 제공하여 실시간 및 기존 데이터의 원활한 통합 및 처리를 가능하게 합니다.\n\n\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_2.png\" /\u003e\n\n# Iceberg 아키텍처:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_3.png)\n\n![Image 2](/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_4.png)\n\n# Apache Iceberg을 활용한 Lakehouse 전환 단계\n\n환경 설정:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 저장소 구성: Amazon S3와 같은 확장 가능한 저장소 솔루션을 설정하여 원본 데이터와 처리된 데이터를 저장하세요. 이미 저희와 같이 S3를 활용 중이라면 데이터 및 메타데이터를 저장할 대상 버킷을 정의하세요.\r\n- Iceberg 설치 및 구성: EMR을 사용 중이므로 Spark 세션을 생성할 때 Iceberg 관련 설정을 추가해야 합니다.\n\n```js\r\nspark = SparkSession.builder \\\n    .appName(\"user_device_data\") \\\n    .master(\"yarn\") \\\n    .config(\"spark.sql.defaultCatalog\", catalog) \\\n    .config(f\"spark.sql.catalog.{catalog}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n    .config(f\"spark.sql.catalog.{catalog}.warehouse\",\n            \"\u003cYour S3 Warehouse Path\u003e\") \\\n    .config(\"spark.sql.catalog.glue_catalog.catalog-impl\", \"org.apache.iceberg.aws.glue.GlueCatalog\") \\\n    .config(\"spark.sql.catalog.glue_catalog.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\r\n```\n\n데이터 이전:\n\n- 데이터레이크 — 기존 Parquet에서 Iceberg로 데이터 마이그레이션: 먼저 테이블을 만들었고, 기존 데이터레이크에서 데이터를 읽어와 Apache Spark를 사용하여 Iceberg 테이블에 기록함으로써 메타데이터가 올바르게 캡처되도록합니다.\n- 데이터웨어하우스 — Redshift 데이터를 Iceberg 형식으로 투입: Redshift에서 언로드한 데이터를 S3로 복사한 후, 데이터레이크와 동일한 접근 방식을 따랐습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같은 방법으로 인플레이스 마이그레이션을 수행할 수 있습니다:\n\n- add_files 사용\n- migrate 사용\n\n[기존 데이터 레이크를 Apache Iceberg를 사용한 트랜잭션 데이터 레이크로 마이그레이션하기](https://aws.amazon.com/blogs/big-data/migrate-an-existing-data-lake-to-a-transactional-data-lake-using-apache-iceberg/)\n\n기존 ETL 프로세스에서의 조정:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 우리는 모든 ETL 작업에 대한 싱크 구성을 변경하여 데이터 아이스버그 형식으로 쓰게 했습니다. 위에서 언급한 구성은 스파크 세션을 만들 때 사용되었습니다.\n\n데이터 거버넌스 및 메타데이터 관리:\n\nIceberg 테이블의 유지 보수 작업.\n\n- Compact : 우리는 다시 쓰고 결과 파일의 원하는 크기로 재작성하기 위해 rewriteDataFiles 절차를 실행합니다. 이것은 읽기 시간을 최적화하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n('write.parquet.target-file-size-bytes '='52428800') \n# 약 이만큼의 바이트를 대상으로 생성된 파일의 크기를 제어합니다.\n\n2. 스냅샷 만료: 분석에 더 이상 필요하지 않은 데이터에 대해 스냅샷 만료를 실행하여 불필요한 저장 비용을 피합니다. 만료된 스냅샷과 연결된 매니페스트 목록, 매니페스트 및 데이터 파일은 여전히 유효한 스냅샷과 연관되어 있지 않은 한 스냅샷 삭제 시에 삭제됩니다.\n\n우리는 이 작업을 수행하기 위해 expireSnapshots 프로시저를 실행합니다.\n\n3. 오래된 메타데이터 파일 제거: Iceberg는 새 메타데이터 파일이 생성될 때 오래된 메타데이터 파일을 삭제하는 설정을 활성화할 수 있습니다. 또한 테이블이 보유해야 하는 메타데이터 파일 수를 설정할 수 있습니다. 우리는 그 수를 5로 설정했습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nwrite.metadata.delete-after-commit.enabled  true\nwrite.metadata.previous-versions-max 5\n```\n\n4. Orphan 파일 삭제 : Orphan 파일 제거를 위해 deleteOrphanFiles 절차를 실행하여 필요 없는 파일을 저장하지 않습니다. 이러한 파일들은 정기적인 정리 프로세스에서 선택되지 않습니다.\n\n쿼리 및 분석:\n\n- 쿼리 최적화: Iceberg는 메타데이터 가지치기(metadata pruning) 및 프리디케이트 푸시다운(predicate pushdown)과 같은 기능을 지원하여 쿼리 성능을 최적화할 수 있습니다. 데이터와 메타데이터 모두에 대한 쿼리 엔진으로 Athena를 사용하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메타데이터 쿼리 치트 시트 : [https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg-table-metadata.html](https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg-table-metadata.html)\n\n- 실시간 분석 활성화: 스파크 ETL 프로세스에서 데이터 수집 및 업데이트가 발생하여 배치 및 스트리밍 데이터 처리에 통합된 경험을 제공합니다.\n\n# Apache Iceberg 구현의 장점\n\n비용 효율성:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 저장 비용 절감: Apache Iceberg는 기본 Z-표준 (zstd) 압축을 사용하여 저장 공간 요구 사항을 크게 줄입니다. 또한 파티션 분할을 지원하여 데이터 스캔을 제한하여 저장 공간 사용을 최적화합니다.\n- 중복 데이터 웨어하우징 솔루션 소거: Iceberg의 ACID 규정 준수로 기존 데이터 웨어하우징 솔루션이 불필요해집니다. Amazon S3의 저장 비용은 Redshift의 그것보다 상당히 낮기 때문에 Redshift 라이선싱 비용을 상당히 절약할 수 있습니다.\n\nApache Iceberg의 채택으로 일반 Parquet 형식으로 데이터를 저장하는 비용과 전체 S3 비용 모두 30%의 저장 비용 절감과 20%의 S3 비용 절감을 이끌었습니다.\n\n성능 향상:\n\n- 쿼리 성능 개선: Iceberg의 최적화된 데이터 관리 및 인덱싱으로 쿼리 성능과 데이터 검색 시간이 상당히 향상되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n역사적 데이터 수정:\n\n- 간편화된 데이터 업데이트: 이전에는 역사적 데이터를 수정하기 위해 작은 배치 작업을 작성해야 했습니다. 아이스버그를 사용하면 몇 가지 업데이트 명령을 실행함으로써 이를 달성할 수 있어, 프로세스가 간소화되었습니다.  \n\n접근 제어:\n\n- 간편화된 행 수준 접근: Redshift에서 서로 다른 국가에 대한 행 수준 접근을 제공하는 것은 복잡했습니다. 아이스버그를 통해 데이터 파티셔닝을 사용하여 특정 버킷에 대한 접근 정책을 쉽게 구현할 수 있어, 접근 관리가 간소화됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nApache Iceberg를 구현함으로써 비용 효율성, 향상된 성능, 간단화된 기존 데이터 수정 및 향상된 액세스 관리를 달성했습니다.\n\n# 결론\n\n여러 데이터셋을 Apache Iceberg로 이관하는 작업을 성공적으로 완료했으며 이미 상당한 비용 및 성능 이점을 확인하고 있습니다. 레이크하우스 아키텍처로의 전환은 데이터 레이크와 데이터 웨어하우스의 최상의 기능을 활용할 수 있게 해주어 더 효율적이고 확장 가능한 데이터 인프라를 구축하게 되었습니다.\n\n이 구현 기간 동안 빈말 야다브와 시바무 구프타에게 놀라운 헌신과 값진 기여에 진심으로 감사드립니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사실, 한국어로 \"테이블\" 태그를 \"Markdown\" 형식으로 변환하면 되는 것 같아요.","ogImage":{"url":"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_0.png"},"coverImage":"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_0.png\"\u003e\n\u003cp\u003e우리의 데이터 인프라는 처음에 Amazon S3를 사용한 데이터 레이크와 Amazon Redshift를 사용한 데이터 웨어하우스의 조합으로 이루어져 있었습니다.\u003c/p\u003e\n\u003cp\u003e이 구성은 대량의 데이터를 저장하고 분석할 수 있는 장점이 있었지만, 추가 저장 공간 및 유지보수 문제와 ACID 규칙 준수를 지원하지 않는 등 여러 가지 도전 과제가 있었습니다.\u003c/p\u003e\n\u003ch1\u003e목표\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e호수집 구조로 전환하는 목표는 데이터 레이크와 데이터 웨어하우스의 최상의 특징을 결합하는 것이었습니다. 이미 완전히 발달한 데이터 레이크가 있었기 때문에, 우리의 초점은 데이터 웨어하우스의 기능을 통합하는 데 있었습니다.\u003c/p\u003e\n\u003ch2\u003e데이터 레이크하우스와 데이터 레이크 및 데이터 웨어하우스의 차이는 무엇인가요?\u003c/h2\u003e\n\u003cp\u003e이름에서 알 수 있듯이 '데이터 레이크하우스'는 데이터 레이크와 데이터 웨어하우스의 최상의 특징을 결합합니다. 본질적으로 데이터 레이크하우스는 데이터 레이크의 기능을 확장하여 데이터 웨어하우스와 유사한 기능을 통합합니다. 데이터 레이크의 유연성, 확장 가능성 및 비용 효율성을 제공하는 한편, 데이터 웨어하우스와 주로 관련된 튼튼한 데이터 관리와 ACID (원자성, 일관성, 분리, 지속성) 트랜잭션을 제공하려고 합니다.\u003c/p\u003e\n\u003ch1\u003e왜 아파치 아이스버그를 선택했나요?\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_1.png\"\u003e\n\u003cul\u003e\n\u003cli\u003eACID 트랜잭션: ACID 트랜잭션을 지원하여 데이터 일관성과 신뢰성을 보장하고, 동시에 쓰기 및 읽기를 허용하여 데이터 오염이 발생하지 않습니다.\u003c/li\u003e\n\u003cli\u003e비용 및 유지보수 감소: Redshift와 연관된 높은 저장 및 라이선스 비용을 최소화하며, 기본적으로 compaction 및 압축(zstd)을 지원합니다.\u003c/li\u003e\n\u003cli\u003e성능 최적화: 메타데이터 가지치기, 파티셔닝 및 데이터 건너뛰기와 같은 기능을 통해 쿼리 성능을 크게 향상시킵니다.\u003c/li\u003e\n\u003cli\u003e호환성: Apache Spark, Flink, Presto 등 여러 데이터 처리 엔진과 함께 작동하여 작업에 최적인 도구를 선택할 수 있는 유연성 제공.\u003c/li\u003e\n\u003cli\u003eParquet, ORC, Avro와 같은 파일 형식 지원.\u003c/li\u003e\n\u003cli\u003e기존의 AWS 생태계 및 Athena, Glue, Catalog, EMR 등과 시프트레이엘튼랏하는 탐바.\u003c/li\u003e\n\u003cli\u003e성능 향상: 빠르게 쿼리되어 데이터를 효율적으로 검색할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e통합 데이터 처리: 일괄 및 스트리밍 데이터 처리에 대해 통합된 경험을 제공하여 실시간 및 기존 데이터의 원활한 통합 및 처리를 가능하게 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_2.png\"\u003e\n\u003ch1\u003eIceberg 아키텍처:\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_3.png\" alt=\"Image 1\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg_4.png\" alt=\"Image 2\"\u003e\u003c/p\u003e\n\u003ch1\u003eApache Iceberg을 활용한 Lakehouse 전환 단계\u003c/h1\u003e\n\u003cp\u003e환경 설정:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e저장소 구성: Amazon S3와 같은 확장 가능한 저장소 솔루션을 설정하여 원본 데이터와 처리된 데이터를 저장하세요. 이미 저희와 같이 S3를 활용 중이라면 데이터 및 메타데이터를 저장할 대상 버킷을 정의하세요.\u003c/li\u003e\n\u003cli\u003eIceberg 설치 및 구성: EMR을 사용 중이므로 Spark 세션을 생성할 때 Iceberg 관련 설정을 추가해야 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003espark = \u003cspan class=\"hljs-title class_\"\u003eSparkSession\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ebuilder\u003c/span\u003e \\\n    .\u003cspan class=\"hljs-title function_\"\u003eappName\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"user_device_data\"\u003c/span\u003e) \\\n    .\u003cspan class=\"hljs-title function_\"\u003emaster\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"yarn\"\u003c/span\u003e) \\\n    .\u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"spark.sql.defaultCatalog\"\u003c/span\u003e, catalog) \\\n    .\u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"spark.sql.catalog.{catalog}\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"org.apache.iceberg.spark.SparkCatalog\"\u003c/span\u003e) \\\n    .\u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"spark.sql.catalog.{catalog}.warehouse\"\u003c/span\u003e,\n            \u003cspan class=\"hljs-string\"\u003e\"\u0026#x3C;Your S3 Warehouse Path\u003e\"\u003c/span\u003e) \\\n    .\u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"spark.sql.catalog.glue_catalog.catalog-impl\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"org.apache.iceberg.aws.glue.GlueCatalog\"\u003c/span\u003e) \\\n    .\u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"spark.sql.catalog.glue_catalog.io-impl\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"org.apache.iceberg.aws.s3.S3FileIO\"\u003c/span\u003e) \\\n    .\u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"spark.sql.extensions\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\"\u003c/span\u003e) \\\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e데이터 이전:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e데이터레이크 — 기존 Parquet에서 Iceberg로 데이터 마이그레이션: 먼저 테이블을 만들었고, 기존 데이터레이크에서 데이터를 읽어와 Apache Spark를 사용하여 Iceberg 테이블에 기록함으로써 메타데이터가 올바르게 캡처되도록합니다.\u003c/li\u003e\n\u003cli\u003e데이터웨어하우스 — Redshift 데이터를 Iceberg 형식으로 투입: Redshift에서 언로드한 데이터를 S3로 복사한 후, 데이터레이크와 동일한 접근 방식을 따랐습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아래와 같은 방법으로 인플레이스 마이그레이션을 수행할 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eadd_files 사용\u003c/li\u003e\n\u003cli\u003emigrate 사용\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"https://aws.amazon.com/blogs/big-data/migrate-an-existing-data-lake-to-a-transactional-data-lake-using-apache-iceberg/\" rel=\"nofollow\" target=\"_blank\"\u003e기존 데이터 레이크를 Apache Iceberg를 사용한 트랜잭션 데이터 레이크로 마이그레이션하기\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e기존 ETL 프로세스에서의 조정:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e우리는 모든 ETL 작업에 대한 싱크 구성을 변경하여 데이터 아이스버그 형식으로 쓰게 했습니다. 위에서 언급한 구성은 스파크 세션을 만들 때 사용되었습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e데이터 거버넌스 및 메타데이터 관리:\u003c/p\u003e\n\u003cp\u003eIceberg 테이블의 유지 보수 작업.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCompact : 우리는 다시 쓰고 결과 파일의 원하는 크기로 재작성하기 위해 rewriteDataFiles 절차를 실행합니다. 이것은 읽기 시간을 최적화하는 데 도움이 됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e('write.parquet.target-file-size-bytes '='52428800')\u003c/p\u003e\n\u003ch1\u003e약 이만큼의 바이트를 대상으로 생성된 파일의 크기를 제어합니다.\u003c/h1\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e스냅샷 만료: 분석에 더 이상 필요하지 않은 데이터에 대해 스냅샷 만료를 실행하여 불필요한 저장 비용을 피합니다. 만료된 스냅샷과 연결된 매니페스트 목록, 매니페스트 및 데이터 파일은 여전히 유효한 스냅샷과 연관되어 있지 않은 한 스냅샷 삭제 시에 삭제됩니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e우리는 이 작업을 수행하기 위해 expireSnapshots 프로시저를 실행합니다.\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e오래된 메타데이터 파일 제거: Iceberg는 새 메타데이터 파일이 생성될 때 오래된 메타데이터 파일을 삭제하는 설정을 활성화할 수 있습니다. 또한 테이블이 보유해야 하는 메타데이터 파일 수를 설정할 수 있습니다. 우리는 그 수를 5로 설정했습니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ewrite.\u003cspan class=\"hljs-property\"\u003emetadata\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003edelete\u003c/span\u003e-after-commit.\u003cspan class=\"hljs-property\"\u003eenabled\u003c/span\u003e  \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\nwrite.\u003cspan class=\"hljs-property\"\u003emetadata\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eprevious\u003c/span\u003e-versions-max \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eOrphan 파일 삭제 : Orphan 파일 제거를 위해 deleteOrphanFiles 절차를 실행하여 필요 없는 파일을 저장하지 않습니다. 이러한 파일들은 정기적인 정리 프로세스에서 선택되지 않습니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e쿼리 및 분석:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e쿼리 최적화: Iceberg는 메타데이터 가지치기(metadata pruning) 및 프리디케이트 푸시다운(predicate pushdown)과 같은 기능을 지원하여 쿼리 성능을 최적화할 수 있습니다. 데이터와 메타데이터 모두에 대한 쿼리 엔진으로 Athena를 사용하고 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e메타데이터 쿼리 치트 시트 : \u003ca href=\"https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg-table-metadata.html\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://docs.aws.amazon.com/athena/latest/ug/querying-iceberg-table-metadata.html\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e실시간 분석 활성화: 스파크 ETL 프로세스에서 데이터 수집 및 업데이트가 발생하여 배치 및 스트리밍 데이터 처리에 통합된 경험을 제공합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eApache Iceberg 구현의 장점\u003c/h1\u003e\n\u003cp\u003e비용 효율성:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e저장 비용 절감: Apache Iceberg는 기본 Z-표준 (zstd) 압축을 사용하여 저장 공간 요구 사항을 크게 줄입니다. 또한 파티션 분할을 지원하여 데이터 스캔을 제한하여 저장 공간 사용을 최적화합니다.\u003c/li\u003e\n\u003cli\u003e중복 데이터 웨어하우징 솔루션 소거: Iceberg의 ACID 규정 준수로 기존 데이터 웨어하우징 솔루션이 불필요해집니다. Amazon S3의 저장 비용은 Redshift의 그것보다 상당히 낮기 때문에 Redshift 라이선싱 비용을 상당히 절약할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eApache Iceberg의 채택으로 일반 Parquet 형식으로 데이터를 저장하는 비용과 전체 S3 비용 모두 30%의 저장 비용 절감과 20%의 S3 비용 절감을 이끌었습니다.\u003c/p\u003e\n\u003cp\u003e성능 향상:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e쿼리 성능 개선: Iceberg의 최적화된 데이터 관리 및 인덱싱으로 쿼리 성능과 데이터 검색 시간이 상당히 향상되었습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e역사적 데이터 수정:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e간편화된 데이터 업데이트: 이전에는 역사적 데이터를 수정하기 위해 작은 배치 작업을 작성해야 했습니다. 아이스버그를 사용하면 몇 가지 업데이트 명령을 실행함으로써 이를 달성할 수 있어, 프로세스가 간소화되었습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e접근 제어:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e간편화된 행 수준 접근: Redshift에서 서로 다른 국가에 대한 행 수준 접근을 제공하는 것은 복잡했습니다. 아이스버그를 통해 데이터 파티셔닝을 사용하여 특정 버킷에 대한 접근 정책을 쉽게 구현할 수 있어, 접근 관리가 간소화됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eApache Iceberg를 구현함으로써 비용 효율성, 향상된 성능, 간단화된 기존 데이터 수정 및 향상된 액세스 관리를 달성했습니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e여러 데이터셋을 Apache Iceberg로 이관하는 작업을 성공적으로 완료했으며 이미 상당한 비용 및 성능 이점을 확인하고 있습니다. 레이크하우스 아키텍처로의 전환은 데이터 레이크와 데이터 웨어하우스의 최상의 기능을 활용할 수 있게 해주어 더 효율적이고 확장 가능한 데이터 인프라를 구축하게 되었습니다.\u003c/p\u003e\n\u003cp\u003e이 구현 기간 동안 빈말 야다브와 시바무 구프타에게 놀라운 헌신과 값진 기여에 진심으로 감사드립니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e사실, 한국어로 \"테이블\" 태그를 \"Markdown\" 형식으로 변환하면 되는 것 같아요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-FromDataSwampstoDataMasteryEmbracingtheLakehouseRevolutionwithApacheIceberg"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>