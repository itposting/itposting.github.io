<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>마이크로 머신러닝  합성곱 신경망 CNN | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="마이크로 머신러닝  합성곱 신경망 CNN | itposting" data-gatsby-head="true"/><meta property="og:title" content="마이크로 머신러닝  합성곱 신경망 CNN | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN" data-gatsby-head="true"/><meta name="twitter:title" content="마이크로 머신러닝  합성곱 신경망 CNN | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-20 16:55" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-0fd008072af5a644.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">마이크로 머신러닝  합성곱 신경망 CNN</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="마이크로 머신러닝  합성곱 신경망 CNN" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 20, 2024</span><span class="posts_reading_time__f7YPP">23<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>수학적 기초부터 엣지 구현까지</p>
<h1>소셜 미디어:</h1>
<p>👨🏽‍💻 Github: thommaskevin/TinyML (github.com)
👷🏾 Linkedin: Thommas Kevin | LinkedIn
📽 Youtube: Thommas Kevin — YouTube
👨🏻‍🏫 연구 그룹: Conecta.ai (ufrn.br)</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png" alt="이미지"></p>
<h2>요약</h2>
<h1>1 — 컨볼루션 신경망 역사</h1>
<p>컨볼루션 신경망(CNN)의 개념은 1980년대 금사이 후코시마의 연구로 형성되기 시작했습니다. 그는 Neocognitron을 개발했는데, 이는 동물의 시각 시스템 구조에서 영감을 받아 자가 조직화 과정을 통해 시각적 패턴을 인식할 수 있는 학습이 가능한 계층적 구조를 가졌습니다. 이 작업은 현대 CNN의 개발을 위한 중요한 선행 연구였습니다.</p>
<p>CNN의 현대 아키텍처는 얀 르쿤과 그의 동료들에 의해 1980년대 후반과 1990년대 초에 제안되었습니다. 그들은 MNIST 데이터셋에서 손으로 쓴 숫자를 인식하기 위해 설계된 컨볼루션 신경망인 LeNet-5를 개발했습니다. LeNet-5는 여러 개의 컨볼루션 레이어를 거친 후 pooling 레이어와 완전 연결 레이어로 이어지는 구조로, 오늘날 사용되는 CNN의 아키텍처의 기초를 구축했습니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_2.png" alt="image"></p>
<p>초기 성공에도 불구하고 CNN의 활용은 계산 제약과 대규모 레이블 데이터셋의 부족으로 제한되었습니다. 그러나 컴퓨팅 파워가 증가하고 GPU(그래픽 처리 장치)를 사용해 딥 네트워크를 훈련하는 기술이 실현 가능해지면서 CNN은 더 많은 관심을 끌게 되었습니다. 게다가 ImageNet과 같은 대규모 레이블 이미지 데이터베이스의 개발은 딥 네트워크를 효과적으로 훈련하기 위한 필수 자료를 제공했습니다.</p>
<p>2012년에 Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton이 개발한 AlexNet이 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 경쟁 상대들보다 큰 폭으로 우승하면서 전환점이 찾아왔습니다. AlexNet은 여러 컨볼루션 레이어, ReLU 활성화 함수, 그리고 dropout과 같은 정규화 기법을 활용하여 시각 인식 작업에 CNN의 성능을 입증했습니다. 이후로 CNN은 다양한 응용 분야에 대한 주요 도구가 되어 지속적인 혁신을 이끌어내는 데 이르렀습니다. VGGNet, GoogLeNet(Inception), ResNet과 같은 모델들은 네트워크의 깊이, 효율성, 정확도를 향상시키기 위한 새로운 아키텍처와 기법들을 소개했습니다.</p>
<p>지금은 CNN이 많은 인공지능 시스템의 필수 구성 요소입니다. 이미지 인식 뿐만 아니라 비디오 분석, 자연어 처리, 의학 진단, 자율 주행차 등 다양한 분야에서 사용됩니다. 연구는 계속해서 발전하고 있으며, 효율적인 합성곱 신경망, 깊은 신경망(DNNs), 생성적 적대 신경망(GANs) 등의 혁신이 이루어지고 있습니다.</p>
<h1>2— 합성곱 신경망 이론</h1>
<p>수학에서 "합성곱"은 한 함수가 다른 함수에 의해 변환되는 통합 연산을 나타냅니다. 그러나 신경망의 맥락에서는 이 개념이 전통적인 통계적 해석과 다릅니다.</p>
<p>기본적으로 우리는 입력 함수로 시작합니다. 우리의 경우에는 주로 이미지입니다. 또한, 필터(커널이라고도 함)를 소개합니다. 이미지는 점곱 연산을 통해 변환되는 함수로, 일반적으로 "합성곱(convolution)"이라고 합니다. 그 다음, 이러한 필터를 입력 이미지에 적용하면 "특성 맵(feature maps)"이라고 하는 출력 이미지를 얻게 됩니다.</p>
<h2>2.1 — 합성곱 계층</h2>
<p>합성곱 계층은 패턴을 감지하고 필터(커널)를 통해 특성 맵을 생성하기 위해 이미지가 처리되는 곳입니다. 이러한 특성 맵은 필터가 식별하려는 각 속성을 나타냅니다. 필터는 일반적으로 (3x3) 또는 (5x5) 행렬로 구성되어 있으며, 각 필터는 입력 이미지에서 동일한 크기의 필드를 차지합니다. 그런 다음, 필터가 한 칸씩 가로로 이동하고 같은 프로세스가 반복됩니다. 가로 끝에 도달하면 필터가 한 칸 아래로 이동하고 점곱 프로세스가 다시 수평으로 적용됩니다. 그 결과는 순서대로 출력에 추가되어 특성 맵을 생성합니다.</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/0*4UZXfXs7eQ3TT02M.gif" alt="이미지"></p>
<p>입력 이미지를 나타내는 텐서 I의 차원이 m1 x m2 x mc인 경우를 가정해 봅시다. 이 텐서에서,</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_4.png" alt="image1"></p>
<p>우리는 입력 이미지와 일치하는 채널 수를 가진 (n1 x n2 x nc) 차원을 가지는 필터를 적용합니다. 이 필터는 이미지를 왼쪽에서 오른쪽으로 움직이면서, 입력 텐서 I의 해당 영역과 요소별 곱셈을 수행하고 이러한 곱셈 결과를 합산합니다. 스트라이드 매개변수는 필터가 이미지를 횡단하는 단계 크기를 결정합니다. I와 K 사이의 이 작업의 결과는 다른 차원 (m1 - n1 + 1) x (m2 - n2 + 1) x 1을 가진 또 다른 텐서를 생성합니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_5.png" alt="image2"></p>
<p>안녕하세요,</p>
<p>특징 맵의 (i, j)번째 항목은 다음과 같이 계산됩니다:</p>
<p>다음 예를 선택했습니다. 5x5x1 차원 이미지가 3x3x1 커널로 합성되고 s=1 스트라이드가 적용됩니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_8.png" alt="image"></p>
<p>특징 맵의 (i, j)-번째 항목은 단일 채널에 대한 다음 일반 공식으로 주어집니다:</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_9.png" alt="formula"></p>
<p>위 예에서 feature map의 (1, 1)번 째 항목을 계산해 봅시다:</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_10.png" alt="image"></p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_11.png" alt="image"></p>
<p>사용할 수 없는 항목은 0으로 대체되었습니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_12.png" alt="Image"></p>
<p>마찬가지로, 남은 항목들은 동일한 공식을 사용하여 계산할 수 있습니다. 이 과정은 서로 다른 유형의 필터를 적용함으로써 반복되며, 각각이 이미지의 다른 특징을 캡처하는 것을 보여줍니다. 예를 들어, 필터 개수가 하나 이상이 될 수 있어서 스트라이드 개념이 도입됩니다.</p>
<h2>2.2— 패딩 레이어</h2>
<p>기본 CNN은 (n x n) 크기의 흑백 이미지와 (f x f) 크기의 필터/커널을 사용하여 결과를 제공하며, 출력 크기는 (n - f + 1) x (n - f + 1)이 됩니다. 예를 들어, (8 x 8) 이미지와 (3 x 3) 필터를 사용한 어떤 합성 곱 작업의 경우, 출력 이미지 크기는 (6 x 6)이 됩니다. 이러한 크기의 감소는 이미지 처리 중 일관적으로 발생하며, 레이어의 출력이 일반적으로 입력보다 작습니다. 또한, 합성 곱 작업에서 사용되는 필터는 픽셀을 횡단하면서 항상 모서리에 초점을 두지 않습니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_13.png" alt="TinyML CNN"></p>
<p>머신 러닝에서 일반적으로 사용되는 여러 유형의 패딩이 있습니다:</p>
<ul>
<li>Same 패딩: Same 패딩은 원본 이미지의 외부 프레임에 일반적으로 0과 같은 추가 요소를 추가하는 것을 포함합니다. 이 방식으로 입력을 확장함으로써, 필터가 더 넓은 영역을 스캔할 수 있게 되어 출력 이미지가 원본과 동일한 크기를 유지할 수 있습니다. 이것은 컨볼루션 작업 중 공간적 차원을 유지하는 데 유용합니다.</li>
<li>Valid 패딩: Same 패딩과는 달리, Valid 패딩은 이미지에 추가 요소를 추가하는 것을 포함하지 않습니다. 필터는 추가 요소 없이 원본 이미지를 훑어갑니다. 이것은 간격으로 인한 일부 데이터 손실이 발생할 수 있지만, valid 패딩은 출력 피쳐 맵의 크기를 줄이고자 할 때 사용됩니다. 이러한 축소는 모델의 매개변수 수를 줄이고 계산 효율성을 향상시킬 수 있습니다.</li>
<li>Causal 패딩: Causal 패딩은 주로 시퀀스-투-시퀀스 모델 및 시계열 예측에 사용되며, 특히 1차원 컨볼루션 레이어에서 사용됩니다. 이 유형의 패딩은 데이터 시퀀스의 시작 부분에 요소를 추가하여 알고리즘이 초기 시간 단계에 대한 값을 예측할 수 있게 합니다. 과거 및 현재 데이터를 예측에 포함시킴으로써, causal 패딩은 모델이 추론 중에 사용할 수 없는 미래 데이터를 활용하지 않도록 보장합니다.</li>
<li>Full 패딩: 이 유형의 패딩은 입력의 테두리 주위에 여러 레이어의 0을 추가하여 원본 이미지 크기보다 큰 출력 피쳐 맵을 생성합니다. Full 패딩은 덜 일반적이지만 더 큰 출력 크기가 필요한 특정 시나리오에서 사용할 수 있습니다.</li>
</ul>
<h2>2.3 —Pooling Layer</h2>
<p>풀링 레이어에서는 컨볼루션된 특징의 공간 차원이 일반적으로 축소되어 입력 이미지에서 주요한 특징을 추출하는 데 도움이 됩니다. 이 크기의 축소는 컨볼루션 레이어에서 얻은 출력에 풀링 함수를 적용하여 달성됩니다. 이렇게 가정해 봅시다:</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_14.png" alt="그림 1"></p>
<p>풀링된 부분의 차원은 다음과 같습니다:</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_15.png" alt="그림 2"></p>
<p>딥러닝에서는 3가지 종류의 풀링이 있어요:</p>
<p>평균 풀링: 커버된 영역 내 픽셀 값의 평균이 출력 매트릭스로 전달됩니다.</p>
<p>최대 풀링: 커버된 영역 내 픽셀 값 중 가장 높은 값이 출력 매트릭스로 전달됩니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_16.png" alt="이미지"></p>
<p>전역 최대 풀링(Global Max Pooling) : 모든 입력 크기의 픽셀 값 중 가장 높은 값이 출력 행렬로 전달됩니다. 이 유형의 풀링에서 풀 크기는 입력 크기와 동일합니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_17.png" alt="이미지"></p>
<p>sum pooling, average pooling, max pooling과 같은 다양한 유형의 풀링이 있습니다. 최대 풀링의 예는 아래에 제공됩니다. 최대 풀링은 2x2 패치에 수행됩니다. 각 패치에서 최댓값이 선택됩니다.</p>
<h2>2.4 — 플래튼 레이어</h2>
<p>플래튼 레이어는 신경망 아키텍처에서 중요한 구성 요소이며, 특히 합성곱 레이어에서 완전히 연결된 레이어로의 전환 시에 중요합니다. 이 레이어는 합성곱 및 풀링 레이어에서 생성된 다차원 피쳐 맵을 일차원 벡터로 변환하여, 분류 또는 회귀 작업을 위해 후속 완전히 연결된 레이어로 전달할 수 있습니다.</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_18.png" alt="이미지 설명"></p>
<p>다음은 플래튼 레이어의 작동 방식입니다:</p>
<ul>
<li>입력: 플래튼 레이어의 입력은 일반적으로 이전 합성곱 또는 풀링 레이어에서 생성된 피쳐 맵을 나타내는 다차원 텐서입니다. 예를 들어, 마지막 합성곱 또는 풀링 레이어가 높이, 너비, 깊이의 피쳐 맵을 생성한다면 입력 텐서는 (배치 크기, 높이, 너비, 깊이) 형태를 가질 것입니다.</li>
<li>플래팅: 플래팅 레이어는 단순히 피쳐 맵의 모든 요소를 하나의 차원을 따라 연결하여 입력 텐서를 일차원 벡터로 다시 형태화합니다. 예를 들어, 피쳐 맵이 높이, 너비, 깊이의 차원을 가진다면 플래팅 레이어는 이를 높이 * 너비 * 깊이의 길이를 가진 벡터로 변환합니다.</li>
<li>출력: 플래팅 레이어의 출력은 피쳐 맵을 플래팅한 일차원 벡터입니다. 이 벡터는 이후의 완전히 연결된 레이어의 입력으로 전달될 수 있습니다.</li>
</ul>
<p>평탄화 레이어의 목적은 특성 맵에서 캡처된 공간 정보를 완전 연결 레이어에서 처리할 수 있는 형식으로 변환하는 것입니다. 완전 연결 레이어는 일차원 입력 벡터를 필요로하므로 특성 맵을 평탄화함으로써 신경망이 데이터의 다양한 공간 위치에 걸쳐 복잡한 패턴과 관계를 효과적으로 학습할 수 있습니다. 이를 통해 더 정확한 예측을 할 수 있습니다.</p>
<p>이전의 합성곱 또는 풀링 레이어에 의해 생성된 특성 맵 𝐹 집합이 있다고 가정해봅시다. 이러한 특성 맵의 차원을 다음과 같이 표기해 봅시다:</p>
<ul>
<li>𝐻: 특성 맵의 높이</li>
<li>𝑊: 특성 맵의 너비</li>
<li>𝐷: 특성 맵의 깊이 (채널 수)</li>
<li>𝐵: 배치 크기 (배치에 포함된 샘플 수)</li>
</ul>
<p>그러면 특성 맵 𝐹의 형태는 (B,H,W,D)가 됩니다. 여기서 𝐵은 배치 크기를 나타냅니다.</p>
<p>이러한 피처 맵을 일차원 벡터로 평탄화하기 위해, 단순히 이를 길이 𝐻×𝑊×𝐷의 벡터로 재구성합니다. 수학적으로 표현하면 다음과 같습니다:</p>
<p>Flatten(𝐹)=reshape(𝐹, (𝐵, 𝐻×𝑊×𝐷))</p>
<p>이 경우, 재구성 연산은 (𝐵, 𝐻, 𝑊, 𝐷) 텐서를 (𝐵, 𝐻×𝑊×𝐷) 텐서로 재구성하여 공간 차원을 하나의 차원으로 펼치게 됩니다.</p>
<p>예를 들어, 만약 𝐹가 차원이 (4,5,5,3)인 경우 (배치 크기가 4, 높이가 5, 너비가 5, 깊이가 3인 피처 맵), 그러면 평탄화된 출력은 (4,75) 차원을 갖게 되며, 각 행은 배치의 한 샘플에 대한 평탄화된 피처 맵을 나타냅니다.</p>
<p>이 평탄화된 벡터는 신경망의 후속 완전 연결 레이어에 입력으로 전달될 수 있습니다.</p>
<h1>3 — TinyML 구현</h1>
<p>이 예제를 통해 ESP32, 아두이노, 라즈베리 파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에서 머신러닝 알고리즘을 구현할 수 있습니다.</p>
<p>3.0 — requirements.txt 파일에 나열된 라이브러리를 설치합니다.</p>
<pre><code class="hljs language-python">!pip install -r requirements.txt
</code></pre>
<p>3.1 — 라이브러리 가져오기</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_digits
<span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> accuracy_score
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
<span class="hljs-keyword">import</span> os
</code></pre>
<p>3.2 — 데이터셋 불러오기</p>
<p>MNIST은 Modified National Institute of Standards and Technology database의 줄임말로, 기공 학습 및 컴퓨터 비전 분야에서 널리 사용되는 데이터셋입니다. 이 데이터셋은 0에서 9까지의 손으로 쓴 숫자들의 모음으로, 각 숫자는 28x28 픽셀 크기의 회색 음영 이미지로 표현됩니다. 이 데이터셋에는 총 70,000개의 이미지가 포함되어 있으며, 이 중 60,000개의 이미지는 훈련에 사용되고 10,000개의 이미지는 테스트에 사용됩니다.</p>
<p>링크: <a href="https://www.nist.gov/itl/products-and-services/emnist-dataset" rel="nofollow" target="_blank">https://www.nist.gov/itl/products-and-services/emnist-dataset</a></p>
<pre><code class="hljs language-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_data</span>():
    np.random.seed(<span class="hljs-number">1337</span>)
    x_values, y_values = load_digits(return_X_y=<span class="hljs-literal">True</span>)
    x_values /= x_values.<span class="hljs-built_in">max</span>()
    <span class="hljs-comment"># reshape to (8 x 8 x 1)</span>
    x_values = x_values.reshape((<span class="hljs-built_in">len</span>(x_values), <span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">1</span>))
    <span class="hljs-comment"># split into train, validation, test</span>
    TRAIN_SPLIT = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.6</span> * <span class="hljs-built_in">len</span>(x_values))
    TEST_SPLIT = <span class="hljs-built_in">int</span>(<span class="hljs-number">0.2</span> * <span class="hljs-built_in">len</span>(x_values) + TRAIN_SPLIT)
    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])
    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])

    <span class="hljs-keyword">return</span> x_train, x_test, x_validate, y_train, y_test, y_validate
</code></pre>
<p>3.3 — 데이터 분할</p>
<pre><code class="hljs language-js">X_train, X_test, X_validate, y_train, y_test, y_validate = <span class="hljs-title function_">get_data</span>()
</code></pre>
<p>3.4 — 탐색적 데이터 분석</p>
<pre><code class="hljs language-js">X_train__ = X_train.<span class="hljs-title function_">reshape</span>(X_train.<span class="hljs-property">shape</span>[<span class="hljs-number">0</span>], <span class="hljs-number">8</span>, <span class="hljs-number">8</span>)

fig, axis = plt.<span class="hljs-title function_">subplots</span>(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">10</span>))
<span class="hljs-keyword">for</span> i, ax <span class="hljs-keyword">in</span> <span class="hljs-title function_">enumerate</span>(axis.<span class="hljs-property">flat</span>):
    ax.<span class="hljs-title function_">imshow</span>(X_train__[i], cmap=<span class="hljs-string">'binary'</span>)
    digit = y_train[i]
    ax.<span class="hljs-title function_">set</span>(title = f<span class="hljs-string">"실제 숫자는 {digit}입니다."</span>)
</code></pre>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_19.png" alt="이미지"></p>
<p>3.5— 모델 정의하기</p>
<pre><code class="hljs language-js">model = tf.<span class="hljs-property">keras</span>.<span class="hljs-title class_">Sequential</span>()
model.<span class="hljs-title function_">add</span>(layers.<span class="hljs-title class_">Conv2D</span>(<span class="hljs-number">8</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">'relu'</span>, input_shape=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">1</span>)))
model.<span class="hljs-title function_">add</span>(layers.<span class="hljs-title class_">MaxPooling2D</span>((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))
model.<span class="hljs-title function_">add</span>(layers.<span class="hljs-title class_">Flatten</span>())
model.<span class="hljs-title function_">add</span>(layers.<span class="hljs-title class_">Dense</span>(<span class="hljs-title function_">len</span>(np.<span class="hljs-title function_">unique</span>(y_train))))
</code></pre>
<pre><code class="hljs language-js">model.<span class="hljs-title function_">summary</span>()
</code></pre>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_20.png" alt="이미지"></p>
<pre><code class="hljs language-js"><span class="hljs-title function_">plot_model</span>(model, to_file=<span class="hljs-string">'./figures/model.png'</span>)
</code></pre>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_21.png" alt="Plot"></p>
<p>3.6—모델 컴파일하기</p>
<pre><code class="hljs language-js">model.<span class="hljs-title function_">compile</span>(optimizer=<span class="hljs-string">'adam'</span>, loss=tf.<span class="hljs-property">keras</span>.<span class="hljs-property">losses</span>.<span class="hljs-title class_">SparseCategoricalCrossentropy</span>(from_logits=<span class="hljs-title class_">True</span>), metrics=[<span class="hljs-string">'accuracy'</span>])
</code></pre>
<p>3.7 — 모델 훈련</p>
<pre><code class="hljs language-js">history = model.<span class="hljs-title function_">fit</span>(X_train, y_train,
                    epochs=<span class="hljs-number">50</span>,
                    batch_size=<span class="hljs-number">16</span>,
                    validation_data=(X_validate, y_validate))
</code></pre>
<pre><code class="hljs language-js">model.<span class="hljs-title function_">save</span>(<span class="hljs-string">'.\models\model.keras'</span>)
</code></pre>
<pre><code class="hljs language-js">loss = history.<span class="hljs-property">history</span>[<span class="hljs-string">'loss'</span>]
val_loss = history.<span class="hljs-property">history</span>[<span class="hljs-string">'val_loss'</span>]
epochs = <span class="hljs-title function_">range</span>(<span class="hljs-number">1</span>, <span class="hljs-title function_">len</span>(loss) + <span class="hljs-number">1</span>)
plt.<span class="hljs-title function_">plot</span>(epochs, loss, <span class="hljs-string">'r.'</span>, label=<span class="hljs-string">'훈련 손실'</span>)
plt.<span class="hljs-title function_">plot</span>(epochs, val_loss, <span class="hljs-string">'y'</span>, label=<span class="hljs-string">'검증 손실'</span>)
plt.<span class="hljs-title function_">title</span>(<span class="hljs-string">'훈련 및 검증 손실'</span>)
plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">'에포크'</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">'손실'</span>)
plt.<span class="hljs-title function_">grid</span>()
plt.<span class="hljs-title function_">legend</span>()
plt.<span class="hljs-title function_">savefig</span>(<span class="hljs-string">'.\\figures\\history_traing.png'</span>, dpi=<span class="hljs-number">300</span>, bbox_inches=<span class="hljs-string">'tight'</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p>모델 평가</p>
<p>테스트 데이터</p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">test_model</span>(model, x_test, y_test):
    x_test = (x_test / x_test.<span class="hljs-title function_">max</span>()).<span class="hljs-title function_">reshape</span>((<span class="hljs-title function_">len</span>(x_test), <span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">1</span>))
    y_pred = model.<span class="hljs-title function_">predict</span>(x_test).<span class="hljs-title function_">argmax</span>(axis=<span class="hljs-number">1</span>)
    <span class="hljs-title function_">print</span>(<span class="hljs-string">'정확도'</span>, ((y_pred == y_test).<span class="hljs-title function_">sum</span>() / <span class="hljs-title function_">len</span>(y_test))*<span class="hljs-number">100</span>, <span class="hljs-string">"%"</span>)
</code></pre>
<pre><code class="hljs language-js"><span class="hljs-title function_">test_model</span>(model, X_test, y_test)
</code></pre>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_23.png" alt="Image"></p>
<p>3.8.2 — Confusion matrix</p>
<pre><code class="hljs language-js">fig = plt.<span class="hljs-title function_">figure</span>(figsize=(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)) # <span class="hljs-title class_">Set</span> <span class="hljs-title class_">Figure</span>

y_pred = model.<span class="hljs-title function_">predict</span>(X_test) # <span class="hljs-title class_">Predict</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">probabilities</span> <span class="hljs-keyword">as</span> <span class="hljs-number">2</span> => [<span class="hljs-number">0.1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0.9</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]
Y_pred = np.<span class="hljs-title function_">argmax</span>(y_pred, <span class="hljs-number">1</span>) # <span class="hljs-title class_">Decode</span> <span class="hljs-title class_">Predicted</span> labels
mat = <span class="hljs-title function_">confusion_matrix</span>(y_test, Y_pred) # <span class="hljs-title class_">Confusion</span> matrix

# <span class="hljs-title class_">Plot</span> <span class="hljs-title class_">Confusion</span> matrix
sns.<span class="hljs-title function_">heatmap</span>(mat.<span class="hljs-property">T</span>, square=<span class="hljs-title class_">True</span>, annot=<span class="hljs-title class_">True</span>, cbar=<span class="hljs-title class_">False</span>, cmap=plt.<span class="hljs-property">cm</span>.<span class="hljs-property">Blues</span>, fmt=<span class="hljs-string">'.0f'</span>, 
            xticklabels=np.<span class="hljs-title function_">unique</span>(y_test), yticklabels=np.<span class="hljs-title function_">unique</span>(y_test), 
            annot_kws={<span class="hljs-string">"fontsize"</span>: <span class="hljs-number">14</span>}, linewidths=<span class="hljs-number">1</span>, linecolor=<span class="hljs-string">'white'</span>)

plt.<span class="hljs-title function_">xlabel</span>(<span class="hljs-string">'Predicted Values'</span>, fontsize=<span class="hljs-number">14</span>)
plt.<span class="hljs-title function_">ylabel</span>(<span class="hljs-string">'True Values'</span>, fontsize=<span class="hljs-number">14</span>)
plt.<span class="hljs-title function_">xticks</span>(fontsize=<span class="hljs-number">14</span>)
plt.<span class="hljs-title function_">yticks</span>(fontsize=<span class="hljs-number">14</span>)
plt.<span class="hljs-title function_">savefig</span>(<span class="hljs-string">'.\\figures\\confusion_matrix.png'</span>, dpi=<span class="hljs-number">300</span>, bbox_inches=<span class="hljs-string">'tight'</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_24.png" alt="이미지"></p>
<p>3.8.3— 예측 유효성 검사 결과</p>
<pre><code class="hljs language-js">y_pred = model.<span class="hljs-title function_">predict</span>(X_test)
X_test__ = X_test

fig, axis = plt.<span class="hljs-title function_">subplots</span>(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>, figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">14</span>))
<span class="hljs-keyword">for</span> i, ax <span class="hljs-keyword">in</span> <span class="hljs-title function_">enumerate</span>(axis.<span class="hljs-property">flat</span>):
    ax.<span class="hljs-title function_">imshow</span>(X_test__[i], cmap=<span class="hljs-string">'binary'</span>)
    ax.<span class="hljs-title function_">set</span>(title = f<span class="hljs-string">"실제 숫자: {y_test[i]}\n예측 숫자: {y_pred[i].argmax()}"</span>)
</code></pre>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_25.png" alt="이미지"></p>
<p>3.9 — 마이크로컨트롤러에 구현할 모델을 얻기</p>
<p>3.9.1 — C 프로그래밍을 위해 일부 16진수 값을 배열로 변환하기</p>
<pre><code class="hljs language-js"># 함수: C 프로그래밍을 위해 일부 <span class="hljs-number">16</span>진수 값을 배열로 변환
def <span class="hljs-title function_">hex_to_c_array</span>(hex_data, var_name):

  c_str = <span class="hljs-string">''</span>

  # 헤더 가드 생성
  c_str += <span class="hljs-string">'#ifdef __has_attribute\n'</span>
  c_str += <span class="hljs-string">'#define HAVE_ATTRIBUTE(x) __has_attribute(x)\n'</span>
  c_str += <span class="hljs-string">'#else\n'</span>
  c_str += <span class="hljs-string">'#define HAVE_ATTRIBUTE(x) 0\n'</span>
  c_str += <span class="hljs-string">'#endif\n'</span>
  c_str += <span class="hljs-string">'#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) &#x26;&#x26; !defined(__clang__))\n'</span>
  c_str += <span class="hljs-string">'#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\n'</span>
  c_str += <span class="hljs-string">'#else\n'</span>
  c_str += <span class="hljs-string">'#define DATA_ALIGN_ATTRIBUTE\n'</span>
  c_str += <span class="hljs-string">'#endif\n\n'</span>

  # C 변수 선언
  c_str += <span class="hljs-string">'const unsigned char '</span> + var_name + <span class="hljs-string">'[]  DATA_ALIGN_ATTRIBUTE = {'</span>
  hex_array = []
  <span class="hljs-keyword">for</span> i, val <span class="hljs-keyword">in</span> <span class="hljs-title function_">enumerate</span>(hex_data) :

    # <span class="hljs-number">16</span>진수에서 문자열로 변환
    hex_str = <span class="hljs-title function_">format</span>(val, <span class="hljs-string">'#04x'</span>)

    # 각 줄이 <span class="hljs-number">80</span>자 이내로 유지되도록 서식 지정 추가
    <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) &#x3C; <span class="hljs-title function_">len</span>(hex_data):
      hex_str += <span class="hljs-string">','</span>
    <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % <span class="hljs-number">12</span> == <span class="hljs-number">0</span>:
      hex_str += <span class="hljs-string">'\n '</span>
    hex_array.<span class="hljs-title function_">append</span>(hex_str)

  # 마지막 중괄호 추가
  c_str += <span class="hljs-string">'\n '</span> + <span class="hljs-title function_">format</span>(<span class="hljs-string">' '</span>.<span class="hljs-title function_">join</span>(hex_array)) + <span class="hljs-string">'\n};\n\n'</span>

  # 헤더 가드 종료
  c_str += <span class="hljs-string">'const int '</span> + var_name + <span class="hljs-string">'_len = '</span> + <span class="hljs-title function_">str</span>(<span class="hljs-title function_">len</span>(hex_data)) + <span class="hljs-string">';\n'</span>

  <span class="hljs-keyword">return</span> c_str
</code></pre>
<p>3.9.2—모델을 Float32와 Int8형식으로 변환하기</p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">representative_dataset</span>():
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-title function_">range</span>(<span class="hljs-title function_">len</span>(X_train)):
        input_data = np.<span class="hljs-title function_">array</span>([X_train[i]], dtype=np.<span class="hljs-property">float32</span>)
        <span class="hljs-keyword">yield</span> [input_data]

def <span class="hljs-title function_">converter_quantization_model</span>(model, model_name):

    # <span class="hljs-title class_">Convert</span> the model to float32
    converter_float32 = tf.<span class="hljs-property">lite</span>.<span class="hljs-property">TFLiteConverter</span>.<span class="hljs-title function_">from_keras_model</span>(model)
    converter_float32.<span class="hljs-property">optimizations</span> = [tf.<span class="hljs-property">lite</span>.<span class="hljs-property">Optimize</span>.<span class="hljs-property">DEFAULT</span>]
    converter_float32.<span class="hljs-property">target_spec</span>.<span class="hljs-property">supported_types</span> = [tf.<span class="hljs-property">float32</span>]
    converter_float32.<span class="hljs-property">_experimental_lower_tensor_list_ops</span> = <span class="hljs-title class_">False</span>
    converter_float32.<span class="hljs-property">supported_ops</span> = [tf.<span class="hljs-property">lite</span>.<span class="hljs-property">OpsSet</span>.<span class="hljs-property">TFLITE_BUILTINS</span>, tf.<span class="hljs-property">lite</span>.<span class="hljs-property">OpsSet</span>.<span class="hljs-property">SELECT_TF_OPS</span>]
    converter_float32.<span class="hljs-property">representative_dataset</span> = representative_dataset
    tflite_model_float32 = converter_float32.<span class="hljs-title function_">convert</span>()
    <span class="hljs-title function_">print</span>(tflite_model_float32)
    <span class="hljs-keyword">with</span> <span class="hljs-title function_">open</span>(model_name+<span class="hljs-string">'_quant_float32'</span> + <span class="hljs-string">'.h'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> <span class="hljs-attr">file</span>:
        file.<span class="hljs-title function_">write</span>(<span class="hljs-title function_">hex_to_c_array</span>(tflite_model_float32, model_name+<span class="hljs-string">'_quant_float32'</span>))
    <span class="hljs-keyword">with</span> <span class="hljs-title function_">open</span>(model_name+<span class="hljs-string">'_quant_float32.tflite'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> <span class="hljs-attr">f</span>:
        f.<span class="hljs-title function_">write</span>(tflite_model_float32)
    size_model_tflite_float32 = os.<span class="hljs-property">path</span>.<span class="hljs-title function_">getsize</span>(model_name+<span class="hljs-string">'_quant_float32.tflite'</span>)
    <span class="hljs-title function_">print</span>(model_name+f<span class="hljs-string">'_quant_float32.tflite: {size_model_tflite_float32} Bytes'</span>)

    # <span class="hljs-title class_">Convert</span> the model to <span class="hljs-title class_">Int8</span>
    converter_int8 = tf.<span class="hljs-property">lite</span>.<span class="hljs-property">TFLiteConverter</span>.<span class="hljs-title function_">from_keras_model</span>(model)
    converter_int8.<span class="hljs-property">optimizations</span> = [tf.<span class="hljs-property">lite</span>.<span class="hljs-property">Optimize</span>.<span class="hljs-property">DEFAULT</span>]
    converter_int8.<span class="hljs-property">target_spec</span>.<span class="hljs-property">supported_types</span> = [tf.<span class="hljs-property">int8</span>]
    converter_int8.<span class="hljs-property">representative_dataset</span> = representative_dataset
    converter_int8.<span class="hljs-property">target_spec</span>.<span class="hljs-property">supported_ops</span> = [
        tf.<span class="hljs-property">lite</span>.<span class="hljs-property">OpsSet</span>.<span class="hljs-property">TFLITE_BUILTINS_INT8</span>,
        tf.<span class="hljs-property">lite</span>.<span class="hljs-property">OpsSet</span>.<span class="hljs-property">SELECT_TF_OPS</span>,
    ]
    converter_int8.<span class="hljs-property">target_spec</span>.<span class="hljs-property">supported_ops</span> = [tf.<span class="hljs-property">lite</span>.<span class="hljs-property">OpsSet</span>.<span class="hljs-property">TFLITE_BUILTINS</span>]
    converter_int8.<span class="hljs-property">target_spec</span>.<span class="hljs-property">supported_ops</span> = [tf.<span class="hljs-property">lite</span>.<span class="hljs-property">OpsSet</span>.<span class="hljs-property">TFLITE_BUILTINS_INT8</span>]
    converter_int8.<span class="hljs-property">experimental_new_converter</span> = <span class="hljs-title class_">True</span>
    converter_int8.<span class="hljs-property">experimental_new_quantizer</span> = <span class="hljs-title class_">True</span>
    converter_int8.<span class="hljs-property">experimental_new_calibrator</span> = <span class="hljs-title class_">True</span>
    tflite_model_int8 = converter_int8.<span class="hljs-title function_">convert</span>()
    <span class="hljs-keyword">with</span> <span class="hljs-title function_">open</span>(model_name+<span class="hljs-string">'_quant_int8'</span> + <span class="hljs-string">'.h'</span>, <span class="hljs-string">'w'</span>) <span class="hljs-keyword">as</span> <span class="hljs-attr">file</span>:
        file.<span class="hljs-title function_">write</span>(<span class="hljs-title function_">hex_to_c_array</span>(tflite_model_int8, model_name+<span class="hljs-string">'_quant_int8'</span>))
    <span class="hljs-keyword">with</span> <span class="hljs-title function_">open</span>(model_name+<span class="hljs-string">'_quant_int8.tflite'</span>, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> <span class="hljs-attr">f</span>:
        f.<span class="hljs-title function_">write</span>(tflite_model_int8)
    size_model_tflite_int8 = os.<span class="hljs-property">path</span>.<span class="hljs-title function_">getsize</span>(model_name+<span class="hljs-string">'_quant_int8.tflite'</span>)
    <span class="hljs-title function_">print</span>(model_name+f<span class="hljs-string">'_quant_int8.tflite: {size_model_tflite_int8} Bytes'</span>)

    <span class="hljs-keyword">return</span> <span class="hljs-title class_">None</span>
</code></pre>
<pre><code class="hljs language-js">model_name=<span class="hljs-string">'.\models\model'</span>
<span class="hljs-title function_">converter_quantization_model</span>(model, model_name)
</code></pre>
<p>3.10 — Quantized Model Evaluation</p>
<pre><code class="hljs language-js">def evaluate_quantization(model_path, X_test, y_test, quantization_type):
    interpreter = tf.<span class="hljs-property">lite</span>.<span class="hljs-title class_">Interpreter</span>(model_path=model_path)
    interpreter.<span class="hljs-title function_">allocate_tensors</span>()

    # <span class="hljs-title class_">Evaluate</span> the quantized model
    input_index = interpreter.<span class="hljs-title function_">get_input_details</span>()[<span class="hljs-number">0</span>][<span class="hljs-string">'index'</span>]
    output_index = interpreter.<span class="hljs-title function_">get_output_details</span>()[<span class="hljs-number">0</span>][<span class="hljs-string">'index'</span>]
    predictions = []
    processing_times = []

    X_test = np.<span class="hljs-title function_">array</span>(X_test, dtype=np.<span class="hljs-property">float32</span>)
    
    <span class="hljs-keyword">for</span> X <span class="hljs-keyword">in</span> <span class="hljs-attr">X_test</span>:
        interpreter.<span class="hljs-title function_">set_tensor</span>(input_index, [X])       
        start_time = time.<span class="hljs-title function_">time</span>()
        interpreter.<span class="hljs-title function_">invoke</span>()
        end_time = time.<span class="hljs-title function_">time</span>()
        processing_time = end_time - start_time
        processing_times.<span class="hljs-title function_">append</span>(processing_time)
        output = interpreter.<span class="hljs-title function_">get_tensor</span>(output_index).<span class="hljs-title function_">argmax</span>(axis=<span class="hljs-number">1</span>)
        predictions.<span class="hljs-title function_">append</span>(output[<span class="hljs-number">0</span>])

    acc = <span class="hljs-title function_">accuracy_score</span>(y_test, predictions)
   
    # <span class="hljs-title class_">Calculate</span> the average and standard deviation <span class="hljs-keyword">of</span> differences
    result = { <span class="hljs-string">"Accuracy (%): "</span>:acc*<span class="hljs-number">100</span>,
                <span class="hljs-string">"Process time (s): "</span>: np.<span class="hljs-title function_">mean</span>(processing_times)
            }

    <span class="hljs-keyword">return</span> result
</code></pre>
<pre><code class="hljs language-js">model_name = <span class="hljs-string">'.\models\model'</span>
</code></pre>
<pre><code class="hljs language-js">eval_quant_float32 = evaluate_quantization(model_name + <span class="hljs-string">'_quant_float32.tflite'</span>, X_test, y_test, <span class="hljs-string">'float32'</span>)
eval_quant_float32
</code></pre>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_26.png" alt="Image"></p>
<pre><code class="hljs language-js">eval_quant_int8 = evaluate_quantization(model_name + <span class="hljs-string">'_quant_int8.tflite'</span>, X_test, y_test, <span class="hljs-string">'int8'</span>)
eval_quant_int8 
</code></pre>
<h2>3.11 — 모델 배포</h2>
<p>이 예제를 통해 ESP32, 아두이노, 아두이노 Portenta H7 with Vision Shield, 라즈베리파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에 머신러닝 알고리즘을 구현할 수 있습니다.</p>
<p>3.11.1 — EloquentTinyML 라이브러리 설치</p>
<p>도서관 폴더로 이동하여 EloquentTinyML-main을 설치해주세요.</p>
<p>3.11.2 — 완전한 아두이노 스케치</p>
<p>model_quant_float32.h 또는 model_quant_int8.h 파일을 열어서 다음에서 모든 16진수 값을 복사하세요:</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_28.png" alt="이미지"></p>
<p>아래와 같이 변경해주세요:</p>
<p>and model len</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_29.png" alt="image"></p>
<p>and cut in model.h:</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_30.png" alt="image"></p>
<p>and</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_31.png" alt="image"></p>
<p>3.11.2 — 완성된 아두이노 스케치</p>
<pre><code class="hljs language-js">#include &#x3C;<span class="hljs-title class_">EloquentTinyML</span>.<span class="hljs-property">h</span>>
#include &#x3C;eloquent_tinyml/tensorflow.<span class="hljs-property">h</span>>

<span class="hljs-comment">// sine_model.h contains the array you exported from Python with xxd or tinymlgen</span>
#include <span class="hljs-string">"model.h"</span>

#define <span class="hljs-variable constant_">N_INPUTS</span> <span class="hljs-number">64</span>
#define <span class="hljs-variable constant_">N_OUTPUTS</span> <span class="hljs-number">10</span>
<span class="hljs-comment">// in future projects you may need to tweak this value: it's a trial and error process</span>
#define <span class="hljs-variable constant_">TENSOR_ARENA_SIZE</span> <span class="hljs-number">6</span>*<span class="hljs-number">1024</span>

<span class="hljs-title class_">Eloquent</span>::<span class="hljs-title class_">TinyML</span>::<span class="hljs-title class_">TensorFlow</span>::<span class="hljs-title class_">TensorFlow</span>&#x3C;<span class="hljs-variable constant_">N_INPUTS</span>, <span class="hljs-variable constant_">N_OUTPUTS</span>, <span class="hljs-variable constant_">TENSOR_ARENA_SIZE</span>> tf;

float input[<span class="hljs-number">64</span>] = {<span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>12500000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>50000000000f, <span class="hljs-number">0.</span>56250000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>81250000000f, <span class="hljs-number">0.</span>31250000000f, <span class="hljs-number">0.</span>87500000000f, <span class="hljs-number">0.</span>50000000000f, <span class="hljs-number">0.</span>43750000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>75000000000f, <span class="hljs-number">0.</span>31250000000f, <span class="hljs-number">0.</span>12500000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>56250000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>43750000000f, <span class="hljs-number">0.</span>31250000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>18750000000f, <span class="hljs-number">0.</span>31250000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>18750000000f, <span class="hljs-number">0.</span>62500000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>12500000000f, <span class="hljs-number">0.</span>62500000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>06250000000f, <span class="hljs-number">0.</span>81250000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>06250000000f, <span class="hljs-number">0.</span>75000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>31250000000f, <span class="hljs-number">0.</span>81250000000f, <span class="hljs-number">0.</span>31250000000f, <span class="hljs-number">0.</span>56250000000f, <span class="hljs-number">0.</span>81250000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>00000000000f, <span class="hljs-number">0.</span>56250000000f, <span class="hljs-number">1.</span>00000000000f, <span class="hljs-number">1.</span>00000000000f, <span class="hljs-number">0.</span>43750000000f, <span class="hljs-number">0.</span>00000000000f};

float y_pred[<span class="hljs-number">10</span>] = {<span class="hljs-number">0</span>};

<span class="hljs-keyword">void</span> <span class="hljs-title function_">setup</span>(<span class="hljs-params"></span>) {
    <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">begin</span>(<span class="hljs-number">9600</span>);
    <span class="hljs-title function_">delay</span>(<span class="hljs-number">4000</span>);
    tf.<span class="hljs-title function_">begin</span>(model);

    <span class="hljs-comment">// check if model loaded fine</span>
    <span class="hljs-keyword">if</span> (!tf.<span class="hljs-title function_">isOk</span>()) {
      <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">print</span>(<span class="hljs-string">"ERROR: "</span>);
      <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">println</span>(tf.<span class="hljs-title function_">getErrorMessage</span>());

      <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) <span class="hljs-title function_">delay</span>(<span class="hljs-number">1000</span>);
    }
}

<span class="hljs-keyword">void</span> <span class="hljs-title function_">loop</span>(<span class="hljs-params"></span>) {

        tf.<span class="hljs-title function_">predict</span>(input, y_pred);
        <span class="hljs-keyword">for</span> (int i = <span class="hljs-number">0</span>; i &#x3C; <span class="hljs-number">10</span>; i++) {
            <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">print</span>(y_pred[i]);
            <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">print</span>(i == <span class="hljs-number">9</span> ? <span class="hljs-string">'\n'</span> : <span class="hljs-string">','</span>);
        }
    <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">print</span>(<span class="hljs-string">"Predicted class is: "</span>);
      <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">println</span>(tf.<span class="hljs-title function_">probaToClass</span>(y_pred));
      <span class="hljs-comment">// or you can skip the predict() method and call directly predictClass()</span>
      <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">print</span>(<span class="hljs-string">"Sanity check: "</span>);
      <span class="hljs-title class_">Serial</span>.<span class="hljs-title function_">println</span>(tf.<span class="hljs-title function_">predictClass</span>(input));
      <span class="hljs-title function_">delay</span>(<span class="hljs-number">2000</span>);

}
</code></pre>
<p>3.12 — 결과</p>
<p>3.12.1 — 양자화된 모델 Float32</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_32.png" alt="이미지"></p>
<p>3.12.1 — 양자화된 모델 Int8</p>
<p><img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_33.png" alt="image"></p>
<p>Full project in: <a href="https://github.com/thommaskevin/TinyML" rel="nofollow" target="_blank">TinyML/13_CNN at main · thommaskevin/TinyML</a></p>
<h2>If you like it, consider buying my coffee ☕️💰 (Bitcoin)</h2>
<p>code: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn</p>
<p><code>&#x3C;img src="/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_34.png" /></code></p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"마이크로 머신러닝  합성곱 신경망 CNN","description":"","date":"2024-06-20 16:55","slug":"2024-06-20-TinyMLConvolutionalNeuralNetworksCNN","content":"\n\n수학적 기초부터 엣지 구현까지\n\n# 소셜 미디어:\n\n👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 연구 그룹: Conecta.ai (ufrn.br)\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 요약\n\n# 1 — 컨볼루션 신경망 역사\n\n컨볼루션 신경망(CNN)의 개념은 1980년대 금사이 후코시마의 연구로 형성되기 시작했습니다. 그는 Neocognitron을 개발했는데, 이는 동물의 시각 시스템 구조에서 영감을 받아 자가 조직화 과정을 통해 시각적 패턴을 인식할 수 있는 학습이 가능한 계층적 구조를 가졌습니다. 이 작업은 현대 CNN의 개발을 위한 중요한 선행 연구였습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCNN의 현대 아키텍처는 얀 르쿤과 그의 동료들에 의해 1980년대 후반과 1990년대 초에 제안되었습니다. 그들은 MNIST 데이터셋에서 손으로 쓴 숫자를 인식하기 위해 설계된 컨볼루션 신경망인 LeNet-5를 개발했습니다. LeNet-5는 여러 개의 컨볼루션 레이어를 거친 후 pooling 레이어와 완전 연결 레이어로 이어지는 구조로, 오늘날 사용되는 CNN의 아키텍처의 기초를 구축했습니다.\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_2.png)\n\n초기 성공에도 불구하고 CNN의 활용은 계산 제약과 대규모 레이블 데이터셋의 부족으로 제한되었습니다. 그러나 컴퓨팅 파워가 증가하고 GPU(그래픽 처리 장치)를 사용해 딥 네트워크를 훈련하는 기술이 실현 가능해지면서 CNN은 더 많은 관심을 끌게 되었습니다. 게다가 ImageNet과 같은 대규모 레이블 이미지 데이터베이스의 개발은 딥 네트워크를 효과적으로 훈련하기 위한 필수 자료를 제공했습니다.\n\n2012년에 Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton이 개발한 AlexNet이 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 경쟁 상대들보다 큰 폭으로 우승하면서 전환점이 찾아왔습니다. AlexNet은 여러 컨볼루션 레이어, ReLU 활성화 함수, 그리고 dropout과 같은 정규화 기법을 활용하여 시각 인식 작업에 CNN의 성능을 입증했습니다. 이후로 CNN은 다양한 응용 분야에 대한 주요 도구가 되어 지속적인 혁신을 이끌어내는 데 이르렀습니다. VGGNet, GoogLeNet(Inception), ResNet과 같은 모델들은 네트워크의 깊이, 효율성, 정확도를 향상시키기 위한 새로운 아키텍처와 기법들을 소개했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_3.png\" /\u003e\n\n지금은 CNN이 많은 인공지능 시스템의 필수 구성 요소입니다. 이미지 인식 뿐만 아니라 비디오 분석, 자연어 처리, 의학 진단, 자율 주행차 등 다양한 분야에서 사용됩니다. 연구는 계속해서 발전하고 있으며, 효율적인 합성곱 신경망, 깊은 신경망(DNNs), 생성적 적대 신경망(GANs) 등의 혁신이 이루어지고 있습니다.\n\n# 2— 합성곱 신경망 이론\n\n수학에서 \"합성곱\"은 한 함수가 다른 함수에 의해 변환되는 통합 연산을 나타냅니다. 그러나 신경망의 맥락에서는 이 개념이 전통적인 통계적 해석과 다릅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기본적으로 우리는 입력 함수로 시작합니다. 우리의 경우에는 주로 이미지입니다. 또한, 필터(커널이라고도 함)를 소개합니다. 이미지는 점곱 연산을 통해 변환되는 함수로, 일반적으로 \"합성곱(convolution)\"이라고 합니다. 그 다음, 이러한 필터를 입력 이미지에 적용하면 \"특성 맵(feature maps)\"이라고 하는 출력 이미지를 얻게 됩니다.\n\n## 2.1 — 합성곱 계층\n\n합성곱 계층은 패턴을 감지하고 필터(커널)를 통해 특성 맵을 생성하기 위해 이미지가 처리되는 곳입니다. 이러한 특성 맵은 필터가 식별하려는 각 속성을 나타냅니다. 필터는 일반적으로 (3x3) 또는 (5x5) 행렬로 구성되어 있으며, 각 필터는 입력 이미지에서 동일한 크기의 필드를 차지합니다. 그런 다음, 필터가 한 칸씩 가로로 이동하고 같은 프로세스가 반복됩니다. 가로 끝에 도달하면 필터가 한 칸 아래로 이동하고 점곱 프로세스가 다시 수평으로 적용됩니다. 그 결과는 순서대로 출력에 추가되어 특성 맵을 생성합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/0*4UZXfXs7eQ3TT02M.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n입력 이미지를 나타내는 텐서 I의 차원이 m1 x m2 x mc인 경우를 가정해 봅시다. 이 텐서에서,\n\n![image1](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_4.png)\n\n우리는 입력 이미지와 일치하는 채널 수를 가진 (n1 x n2 x nc) 차원을 가지는 필터를 적용합니다. 이 필터는 이미지를 왼쪽에서 오른쪽으로 움직이면서, 입력 텐서 I의 해당 영역과 요소별 곱셈을 수행하고 이러한 곱셈 결과를 합산합니다. 스트라이드 매개변수는 필터가 이미지를 횡단하는 단계 크기를 결정합니다. I와 K 사이의 이 작업의 결과는 다른 차원 (m1 - n1 + 1) x (m2 - n2 + 1) x 1을 가진 또 다른 텐서를 생성합니다.\n\n![image2](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요,\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_6.png\" /\u003e\n\n특징 맵의 (i, j)번째 항목은 다음과 같이 계산됩니다:\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 예를 선택했습니다. 5x5x1 차원 이미지가 3x3x1 커널로 합성되고 s=1 스트라이드가 적용됩니다.\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_8.png)\n\n특징 맵의 (i, j)-번째 항목은 단일 채널에 대한 다음 일반 공식으로 주어집니다:\n\n![formula](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 예에서 feature map의 (1, 1)번 째 항목을 계산해 봅시다:\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_10.png)\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_11.png)\n\n사용할 수 없는 항목은 0으로 대체되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_12.png)\n\n마찬가지로, 남은 항목들은 동일한 공식을 사용하여 계산할 수 있습니다. 이 과정은 서로 다른 유형의 필터를 적용함으로써 반복되며, 각각이 이미지의 다른 특징을 캡처하는 것을 보여줍니다. 예를 들어, 필터 개수가 하나 이상이 될 수 있어서 스트라이드 개념이 도입됩니다.\n\n## 2.2— 패딩 레이어\n\n기본 CNN은 (n x n) 크기의 흑백 이미지와 (f x f) 크기의 필터/커널을 사용하여 결과를 제공하며, 출력 크기는 (n - f + 1) x (n - f + 1)이 됩니다. 예를 들어, (8 x 8) 이미지와 (3 x 3) 필터를 사용한 어떤 합성 곱 작업의 경우, 출력 이미지 크기는 (6 x 6)이 됩니다. 이러한 크기의 감소는 이미지 처리 중 일관적으로 발생하며, 레이어의 출력이 일반적으로 입력보다 작습니다. 또한, 합성 곱 작업에서 사용되는 필터는 픽셀을 횡단하면서 항상 모서리에 초점을 두지 않습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![TinyML CNN](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_13.png)\n\n머신 러닝에서 일반적으로 사용되는 여러 유형의 패딩이 있습니다:\n\n- Same 패딩: Same 패딩은 원본 이미지의 외부 프레임에 일반적으로 0과 같은 추가 요소를 추가하는 것을 포함합니다. 이 방식으로 입력을 확장함으로써, 필터가 더 넓은 영역을 스캔할 수 있게 되어 출력 이미지가 원본과 동일한 크기를 유지할 수 있습니다. 이것은 컨볼루션 작업 중 공간적 차원을 유지하는 데 유용합니다.\n- Valid 패딩: Same 패딩과는 달리, Valid 패딩은 이미지에 추가 요소를 추가하는 것을 포함하지 않습니다. 필터는 추가 요소 없이 원본 이미지를 훑어갑니다. 이것은 간격으로 인한 일부 데이터 손실이 발생할 수 있지만, valid 패딩은 출력 피쳐 맵의 크기를 줄이고자 할 때 사용됩니다. 이러한 축소는 모델의 매개변수 수를 줄이고 계산 효율성을 향상시킬 수 있습니다.\n- Causal 패딩: Causal 패딩은 주로 시퀀스-투-시퀀스 모델 및 시계열 예측에 사용되며, 특히 1차원 컨볼루션 레이어에서 사용됩니다. 이 유형의 패딩은 데이터 시퀀스의 시작 부분에 요소를 추가하여 알고리즘이 초기 시간 단계에 대한 값을 예측할 수 있게 합니다. 과거 및 현재 데이터를 예측에 포함시킴으로써, causal 패딩은 모델이 추론 중에 사용할 수 없는 미래 데이터를 활용하지 않도록 보장합니다.\n- Full 패딩: 이 유형의 패딩은 입력의 테두리 주위에 여러 레이어의 0을 추가하여 원본 이미지 크기보다 큰 출력 피쳐 맵을 생성합니다. Full 패딩은 덜 일반적이지만 더 큰 출력 크기가 필요한 특정 시나리오에서 사용할 수 있습니다.\n\n## 2.3 —Pooling Layer\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n풀링 레이어에서는 컨볼루션된 특징의 공간 차원이 일반적으로 축소되어 입력 이미지에서 주요한 특징을 추출하는 데 도움이 됩니다. 이 크기의 축소는 컨볼루션 레이어에서 얻은 출력에 풀링 함수를 적용하여 달성됩니다. 이렇게 가정해 봅시다:\n\n![그림 1](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_14.png)\n\n풀링된 부분의 차원은 다음과 같습니다:\n\n![그림 2](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_15.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n딥러닝에서는 3가지 종류의 풀링이 있어요:\n\n평균 풀링: 커버된 영역 내 픽셀 값의 평균이 출력 매트릭스로 전달됩니다.\n\n최대 풀링: 커버된 영역 내 픽셀 값 중 가장 높은 값이 출력 매트릭스로 전달됩니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_16.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전역 최대 풀링(Global Max Pooling) : 모든 입력 크기의 픽셀 값 중 가장 높은 값이 출력 행렬로 전달됩니다. 이 유형의 풀링에서 풀 크기는 입력 크기와 동일합니다.\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_17.png)\n\nsum pooling, average pooling, max pooling과 같은 다양한 유형의 풀링이 있습니다. 최대 풀링의 예는 아래에 제공됩니다. 최대 풀링은 2x2 패치에 수행됩니다. 각 패치에서 최댓값이 선택됩니다.\n\n## 2.4 — 플래튼 레이어\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n플래튼 레이어는 신경망 아키텍처에서 중요한 구성 요소이며, 특히 합성곱 레이어에서 완전히 연결된 레이어로의 전환 시에 중요합니다. 이 레이어는 합성곱 및 풀링 레이어에서 생성된 다차원 피쳐 맵을 일차원 벡터로 변환하여, 분류 또는 회귀 작업을 위해 후속 완전히 연결된 레이어로 전달할 수 있습니다.\n\n![이미지 설명](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_18.png)\n\n다음은 플래튼 레이어의 작동 방식입니다:\n\n- 입력: 플래튼 레이어의 입력은 일반적으로 이전 합성곱 또는 풀링 레이어에서 생성된 피쳐 맵을 나타내는 다차원 텐서입니다. 예를 들어, 마지막 합성곱 또는 풀링 레이어가 높이, 너비, 깊이의 피쳐 맵을 생성한다면 입력 텐서는 (배치 크기, 높이, 너비, 깊이) 형태를 가질 것입니다.\n- 플래팅: 플래팅 레이어는 단순히 피쳐 맵의 모든 요소를 하나의 차원을 따라 연결하여 입력 텐서를 일차원 벡터로 다시 형태화합니다. 예를 들어, 피쳐 맵이 높이, 너비, 깊이의 차원을 가진다면 플래팅 레이어는 이를 높이 * 너비 * 깊이의 길이를 가진 벡터로 변환합니다.\n- 출력: 플래팅 레이어의 출력은 피쳐 맵을 플래팅한 일차원 벡터입니다. 이 벡터는 이후의 완전히 연결된 레이어의 입력으로 전달될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n평탄화 레이어의 목적은 특성 맵에서 캡처된 공간 정보를 완전 연결 레이어에서 처리할 수 있는 형식으로 변환하는 것입니다. 완전 연결 레이어는 일차원 입력 벡터를 필요로하므로 특성 맵을 평탄화함으로써 신경망이 데이터의 다양한 공간 위치에 걸쳐 복잡한 패턴과 관계를 효과적으로 학습할 수 있습니다. 이를 통해 더 정확한 예측을 할 수 있습니다.\n\n이전의 합성곱 또는 풀링 레이어에 의해 생성된 특성 맵 𝐹 집합이 있다고 가정해봅시다. 이러한 특성 맵의 차원을 다음과 같이 표기해 봅시다:\n\n- 𝐻: 특성 맵의 높이\n- 𝑊: 특성 맵의 너비\n- 𝐷: 특성 맵의 깊이 (채널 수)\n- 𝐵: 배치 크기 (배치에 포함된 샘플 수)\n\n그러면 특성 맵 𝐹의 형태는 (B,H,W,D)가 됩니다. 여기서 𝐵은 배치 크기를 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 피처 맵을 일차원 벡터로 평탄화하기 위해, 단순히 이를 길이 𝐻×𝑊×𝐷의 벡터로 재구성합니다. 수학적으로 표현하면 다음과 같습니다:\n\nFlatten(𝐹)=reshape(𝐹, (𝐵, 𝐻×𝑊×𝐷))\n\n이 경우, 재구성 연산은 (𝐵, 𝐻, 𝑊, 𝐷) 텐서를 (𝐵, 𝐻×𝑊×𝐷) 텐서로 재구성하여 공간 차원을 하나의 차원으로 펼치게 됩니다.\n\n예를 들어, 만약 𝐹가 차원이 (4,5,5,3)인 경우 (배치 크기가 4, 높이가 5, 너비가 5, 깊이가 3인 피처 맵), 그러면 평탄화된 출력은 (4,75) 차원을 갖게 되며, 각 행은 배치의 한 샘플에 대한 평탄화된 피처 맵을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 평탄화된 벡터는 신경망의 후속 완전 연결 레이어에 입력으로 전달될 수 있습니다.\n\n# 3 — TinyML 구현\n\n이 예제를 통해 ESP32, 아두이노, 라즈베리 파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에서 머신러닝 알고리즘을 구현할 수 있습니다.\n\n3.0 — requirements.txt 파일에 나열된 라이브러리를 설치합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\n!pip install -r requirements.txt\n```\n\n3.1 — 라이브러리 가져오기\n\n```python\nimport numpy as np\nfrom sklearn.datasets import load_digits\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport time\nimport seaborn as sns\nimport os\n```\n\n3.2 — 데이터셋 불러오기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMNIST은 Modified National Institute of Standards and Technology database의 줄임말로, 기공 학습 및 컴퓨터 비전 분야에서 널리 사용되는 데이터셋입니다. 이 데이터셋은 0에서 9까지의 손으로 쓴 숫자들의 모음으로, 각 숫자는 28x28 픽셀 크기의 회색 음영 이미지로 표현됩니다. 이 데이터셋에는 총 70,000개의 이미지가 포함되어 있으며, 이 중 60,000개의 이미지는 훈련에 사용되고 10,000개의 이미지는 테스트에 사용됩니다.\n\n링크: [https://www.nist.gov/itl/products-and-services/emnist-dataset](https://www.nist.gov/itl/products-and-services/emnist-dataset)\n\n```python\ndef get_data():\n    np.random.seed(1337)\n    x_values, y_values = load_digits(return_X_y=True)\n    x_values /= x_values.max()\n    # reshape to (8 x 8 x 1)\n    x_values = x_values.reshape((len(x_values), 8, 8, 1))\n    # split into train, validation, test\n    TRAIN_SPLIT = int(0.6 * len(x_values))\n    TEST_SPLIT = int(0.2 * len(x_values) + TRAIN_SPLIT)\n    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n\n    return x_train, x_test, x_validate, y_train, y_test, y_validate\n```\n\n3.3 — 데이터 분할\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nX_train, X_test, X_validate, y_train, y_test, y_validate = get_data()\n```\n\n3.4 — 탐색적 데이터 분석\n\n```js\nX_train__ = X_train.reshape(X_train.shape[0], 8, 8)\n\nfig, axis = plt.subplots(1, 4, figsize=(20, 10))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_train__[i], cmap='binary')\n    digit = y_train[i]\n    ax.set(title = f\"실제 숫자는 {digit}입니다.\")\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_19.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.5— 모델 정의하기\n\n```js\nmodel = tf.keras.Sequential()\nmodel.add(layers.Conv2D(8, (3, 3), activation='relu', input_shape=(8, 8, 1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(len(np.unique(y_train))))\n```\n\n```js\nmodel.summary()\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_20.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nplot_model(model, to_file='./figures/model.png')\n```\n\n![Plot](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_21.png)\n\n3.6—모델 컴파일하기\n\n```js\nmodel.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.7 — 모델 훈련\n\n```js\nhistory = model.fit(X_train, y_train,\n                    epochs=50,\n                    batch_size=16,\n                    validation_data=(X_validate, y_validate))\n```\n\n```js\nmodel.save('.\\models\\model.keras')\n```\n\n```js\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'r.', label='훈련 손실')\nplt.plot(epochs, val_loss, 'y', label='검증 손실')\nplt.title('훈련 및 검증 손실')\nplt.xlabel('에포크')\nplt.ylabel('손실')\nplt.grid()\nplt.legend()\nplt.savefig('.\\\\figures\\\\history_traing.png', dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_22.png\" /\u003e\n\n모델 평가\n\n테스트 데이터\n\n```js\ndef test_model(model, x_test, y_test):\n    x_test = (x_test / x_test.max()).reshape((len(x_test), 8, 8, 1))\n    y_pred = model.predict(x_test).argmax(axis=1)\n    print('정확도', ((y_pred == y_test).sum() / len(y_test))*100, \"%\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\ntest_model(model, X_test, y_test)\n```\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_23.png)\n\n3.8.2 — Confusion matrix\n\n```js\nfig = plt.figure(figsize=(10, 10)) # Set Figure\n\ny_pred = model.predict(X_test) # Predict class probabilities as 2 =\u003e [0.1, 0, 0.9, 0, 0, 0, 0, 0, 0, 0]\nY_pred = np.argmax(y_pred, 1) # Decode Predicted labels\nmat = confusion_matrix(y_test, Y_pred) # Confusion matrix\n\n# Plot Confusion matrix\nsns.heatmap(mat.T, square=True, annot=True, cbar=False, cmap=plt.cm.Blues, fmt='.0f', \n            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test), \n            annot_kws={\"fontsize\": 14}, linewidths=1, linecolor='white')\n\nplt.xlabel('Predicted Values', fontsize=14)\nplt.ylabel('True Values', fontsize=14)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.savefig('.\\\\figures\\\\confusion_matrix.png', dpi=300, bbox_inches='tight')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_24.png)\n\n3.8.3— 예측 유효성 검사 결과\n\n```js\ny_pred = model.predict(X_test)\nX_test__ = X_test\n\nfig, axis = plt.subplots(4, 4, figsize=(12, 14))\nfor i, ax in enumerate(axis.flat):\n    ax.imshow(X_test__[i], cmap='binary')\n    ax.set(title = f\"실제 숫자: {y_test[i]}\\n예측 숫자: {y_pred[i].argmax()}\")\n```\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_25.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.9 — 마이크로컨트롤러에 구현할 모델을 얻기\n\n3.9.1 — C 프로그래밍을 위해 일부 16진수 값을 배열로 변환하기\n\n```js\n# 함수: C 프로그래밍을 위해 일부 16진수 값을 배열로 변환\ndef hex_to_c_array(hex_data, var_name):\n\n  c_str = ''\n\n  # 헤더 가드 생성\n  c_str += '#ifdef __has_attribute\\n'\n  c_str += '#define HAVE_ATTRIBUTE(x) __has_attribute(x)\\n'\n  c_str += '#else\\n'\n  c_str += '#define HAVE_ATTRIBUTE(x) 0\\n'\n  c_str += '#endif\\n'\n  c_str += '#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) \u0026\u0026 !defined(__clang__))\\n'\n  c_str += '#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\\n'\n  c_str += '#else\\n'\n  c_str += '#define DATA_ALIGN_ATTRIBUTE\\n'\n  c_str += '#endif\\n\\n'\n\n  # C 변수 선언\n  c_str += 'const unsigned char ' + var_name + '[]  DATA_ALIGN_ATTRIBUTE = {'\n  hex_array = []\n  for i, val in enumerate(hex_data) :\n\n    # 16진수에서 문자열로 변환\n    hex_str = format(val, '#04x')\n\n    # 각 줄이 80자 이내로 유지되도록 서식 지정 추가\n    if (i + 1) \u003c len(hex_data):\n      hex_str += ','\n    if (i + 1) % 12 == 0:\n      hex_str += '\\n '\n    hex_array.append(hex_str)\n\n  # 마지막 중괄호 추가\n  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n\n  # 헤더 가드 종료\n  c_str += 'const int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n\n  return c_str\n```\n\n3.9.2—모델을 Float32와 Int8형식으로 변환하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef representative_dataset():\n    for i in range(len(X_train)):\n        input_data = np.array([X_train[i]], dtype=np.float32)\n        yield [input_data]\n\ndef converter_quantization_model(model, model_name):\n\n    # Convert the model to float32\n    converter_float32 = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_float32.optimizations = [tf.lite.Optimize.DEFAULT]\n    converter_float32.target_spec.supported_types = [tf.float32]\n    converter_float32._experimental_lower_tensor_list_ops = False\n    converter_float32.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n    converter_float32.representative_dataset = representative_dataset\n    tflite_model_float32 = converter_float32.convert()\n    print(tflite_model_float32)\n    with open(model_name+'_quant_float32' + '.h', 'w') as file:\n        file.write(hex_to_c_array(tflite_model_float32, model_name+'_quant_float32'))\n    with open(model_name+'_quant_float32.tflite', 'wb') as f:\n        f.write(tflite_model_float32)\n    size_model_tflite_float32 = os.path.getsize(model_name+'_quant_float32.tflite')\n    print(model_name+f'_quant_float32.tflite: {size_model_tflite_float32} Bytes')\n\n    # Convert the model to Int8\n    converter_int8 = tf.lite.TFLiteConverter.from_keras_model(model)\n    converter_int8.optimizations = [tf.lite.Optimize.DEFAULT]\n    converter_int8.target_spec.supported_types = [tf.int8]\n    converter_int8.representative_dataset = representative_dataset\n    converter_int8.target_spec.supported_ops = [\n        tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n        tf.lite.OpsSet.SELECT_TF_OPS,\n    ]\n    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n    converter_int8.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n    converter_int8.experimental_new_converter = True\n    converter_int8.experimental_new_quantizer = True\n    converter_int8.experimental_new_calibrator = True\n    tflite_model_int8 = converter_int8.convert()\n    with open(model_name+'_quant_int8' + '.h', 'w') as file:\n        file.write(hex_to_c_array(tflite_model_int8, model_name+'_quant_int8'))\n    with open(model_name+'_quant_int8.tflite', 'wb') as f:\n        f.write(tflite_model_int8)\n    size_model_tflite_int8 = os.path.getsize(model_name+'_quant_int8.tflite')\n    print(model_name+f'_quant_int8.tflite: {size_model_tflite_int8} Bytes')\n\n    return None\n```\n\n```js\nmodel_name='.\\models\\model'\nconverter_quantization_model(model, model_name)\n```\n\n3.10 — Quantized Model Evaluation\n\n```js\ndef evaluate_quantization(model_path, X_test, y_test, quantization_type):\n    interpreter = tf.lite.Interpreter(model_path=model_path)\n    interpreter.allocate_tensors()\n\n    # Evaluate the quantized model\n    input_index = interpreter.get_input_details()[0]['index']\n    output_index = interpreter.get_output_details()[0]['index']\n    predictions = []\n    processing_times = []\n\n    X_test = np.array(X_test, dtype=np.float32)\n    \n    for X in X_test:\n        interpreter.set_tensor(input_index, [X])       \n        start_time = time.time()\n        interpreter.invoke()\n        end_time = time.time()\n        processing_time = end_time - start_time\n        processing_times.append(processing_time)\n        output = interpreter.get_tensor(output_index).argmax(axis=1)\n        predictions.append(output[0])\n\n    acc = accuracy_score(y_test, predictions)\n   \n    # Calculate the average and standard deviation of differences\n    result = { \"Accuracy (%): \":acc*100,\n                \"Process time (s): \": np.mean(processing_times)\n            }\n\n    return result\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nmodel_name = '.\\models\\model'\n```\n\n```js\neval_quant_float32 = evaluate_quantization(model_name + '_quant_float32.tflite', X_test, y_test, 'float32')\neval_quant_float32\n```\n\n![Image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_26.png)\n\n```js\neval_quant_int8 = evaluate_quantization(model_name + '_quant_int8.tflite', X_test, y_test, 'int8')\neval_quant_int8 \n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_27.png\" /\u003e\n\n## 3.11 — 모델 배포\n\n이 예제를 통해 ESP32, 아두이노, 아두이노 Portenta H7 with Vision Shield, 라즈베리파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에 머신러닝 알고리즘을 구현할 수 있습니다.\n\n3.11.1 — EloquentTinyML 라이브러리 설치\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n도서관 폴더로 이동하여 EloquentTinyML-main을 설치해주세요.\n\n3.11.2 — 완전한 아두이노 스케치\n\nmodel_quant_float32.h 또는 model_quant_int8.h 파일을 열어서 다음에서 모든 16진수 값을 복사하세요:\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_28.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같이 변경해주세요:\n\n\nand model len\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_29.png)\n\nand cut in model.h:\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_30.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nand\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_31.png)\n\n3.11.2 — 완성된 아두이노 스케치\n\n```js\n#include \u003cEloquentTinyML.h\u003e\n#include \u003celoquent_tinyml/tensorflow.h\u003e\n\n// sine_model.h contains the array you exported from Python with xxd or tinymlgen\n#include \"model.h\"\n\n#define N_INPUTS 64\n#define N_OUTPUTS 10\n// in future projects you may need to tweak this value: it's a trial and error process\n#define TENSOR_ARENA_SIZE 6*1024\n\nEloquent::TinyML::TensorFlow::TensorFlow\u003cN_INPUTS, N_OUTPUTS, TENSOR_ARENA_SIZE\u003e tf;\n\nfloat input[64] = {0.00000000000f, 0.12500000000f, 0.00000000000f, 0.50000000000f, 0.56250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.81250000000f, 0.31250000000f, 0.87500000000f, 0.50000000000f, 0.43750000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.75000000000f, 0.31250000000f, 0.12500000000f, 0.00000000000f, 0.56250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.43750000000f, 0.31250000000f, 0.00000000000f, 0.00000000000f, 0.18750000000f, 0.31250000000f, 0.00000000000f, 0.00000000000f, 0.18750000000f, 0.62500000000f, 0.00000000000f, 0.00000000000f, 0.12500000000f, 0.62500000000f, 0.00000000000f, 0.00000000000f, 0.06250000000f, 0.81250000000f, 0.00000000000f, 0.00000000000f, 0.06250000000f, 0.75000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.31250000000f, 0.81250000000f, 0.31250000000f, 0.56250000000f, 0.81250000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.00000000000f, 0.56250000000f, 1.00000000000f, 1.00000000000f, 0.43750000000f, 0.00000000000f};\n\nfloat y_pred[10] = {0};\n\nvoid setup() {\n    Serial.begin(9600);\n    delay(4000);\n    tf.begin(model);\n\n    // check if model loaded fine\n    if (!tf.isOk()) {\n      Serial.print(\"ERROR: \");\n      Serial.println(tf.getErrorMessage());\n\n      while (true) delay(1000);\n    }\n}\n\nvoid loop() {\n\n        tf.predict(input, y_pred);\n        for (int i = 0; i \u003c 10; i++) {\n            Serial.print(y_pred[i]);\n            Serial.print(i == 9 ? '\\n' : ',');\n        }\n    Serial.print(\"Predicted class is: \");\n      Serial.println(tf.probaToClass(y_pred));\n      // or you can skip the predict() method and call directly predictClass()\n      Serial.print(\"Sanity check: \");\n      Serial.println(tf.predictClass(input));\n      delay(2000);\n\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.12 — 결과\n\n3.12.1 — 양자화된 모델 Float32\n\n![이미지](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_32.png)\n\n3.12.1 — 양자화된 모델 Int8\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_33.png)\n\nFull project in: [TinyML/13_CNN at main · thommaskevin/TinyML](https://github.com/thommaskevin/TinyML)\n\n## If you like it, consider buying my coffee ☕️💰 (Bitcoin)\n\ncode: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n`\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_34.png\" /\u003e`","ogImage":{"url":"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png"},"coverImage":"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png","tag":["Tech"],"readingTime":23},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e수학적 기초부터 엣지 구현까지\u003c/p\u003e\n\u003ch1\u003e소셜 미디어:\u003c/h1\u003e\n\u003cp\u003e👨🏽‍💻 Github: thommaskevin/TinyML (github.com)\n👷🏾 Linkedin: Thommas Kevin | LinkedIn\n📽 Youtube: Thommas Kevin — YouTube\n👨🏻‍🏫 연구 그룹: Conecta.ai (ufrn.br)\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch2\u003e요약\u003c/h2\u003e\n\u003ch1\u003e1 — 컨볼루션 신경망 역사\u003c/h1\u003e\n\u003cp\u003e컨볼루션 신경망(CNN)의 개념은 1980년대 금사이 후코시마의 연구로 형성되기 시작했습니다. 그는 Neocognitron을 개발했는데, 이는 동물의 시각 시스템 구조에서 영감을 받아 자가 조직화 과정을 통해 시각적 패턴을 인식할 수 있는 학습이 가능한 계층적 구조를 가졌습니다. 이 작업은 현대 CNN의 개발을 위한 중요한 선행 연구였습니다.\u003c/p\u003e\n\u003cp\u003eCNN의 현대 아키텍처는 얀 르쿤과 그의 동료들에 의해 1980년대 후반과 1990년대 초에 제안되었습니다. 그들은 MNIST 데이터셋에서 손으로 쓴 숫자를 인식하기 위해 설계된 컨볼루션 신경망인 LeNet-5를 개발했습니다. LeNet-5는 여러 개의 컨볼루션 레이어를 거친 후 pooling 레이어와 완전 연결 레이어로 이어지는 구조로, 오늘날 사용되는 CNN의 아키텍처의 기초를 구축했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_2.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e초기 성공에도 불구하고 CNN의 활용은 계산 제약과 대규모 레이블 데이터셋의 부족으로 제한되었습니다. 그러나 컴퓨팅 파워가 증가하고 GPU(그래픽 처리 장치)를 사용해 딥 네트워크를 훈련하는 기술이 실현 가능해지면서 CNN은 더 많은 관심을 끌게 되었습니다. 게다가 ImageNet과 같은 대규모 레이블 이미지 데이터베이스의 개발은 딥 네트워크를 효과적으로 훈련하기 위한 필수 자료를 제공했습니다.\u003c/p\u003e\n\u003cp\u003e2012년에 Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton이 개발한 AlexNet이 ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 경쟁 상대들보다 큰 폭으로 우승하면서 전환점이 찾아왔습니다. AlexNet은 여러 컨볼루션 레이어, ReLU 활성화 함수, 그리고 dropout과 같은 정규화 기법을 활용하여 시각 인식 작업에 CNN의 성능을 입증했습니다. 이후로 CNN은 다양한 응용 분야에 대한 주요 도구가 되어 지속적인 혁신을 이끌어내는 데 이르렀습니다. VGGNet, GoogLeNet(Inception), ResNet과 같은 모델들은 네트워크의 깊이, 효율성, 정확도를 향상시키기 위한 새로운 아키텍처와 기법들을 소개했습니다.\u003c/p\u003e\n\u003cp\u003e지금은 CNN이 많은 인공지능 시스템의 필수 구성 요소입니다. 이미지 인식 뿐만 아니라 비디오 분석, 자연어 처리, 의학 진단, 자율 주행차 등 다양한 분야에서 사용됩니다. 연구는 계속해서 발전하고 있으며, 효율적인 합성곱 신경망, 깊은 신경망(DNNs), 생성적 적대 신경망(GANs) 등의 혁신이 이루어지고 있습니다.\u003c/p\u003e\n\u003ch1\u003e2— 합성곱 신경망 이론\u003c/h1\u003e\n\u003cp\u003e수학에서 \"합성곱\"은 한 함수가 다른 함수에 의해 변환되는 통합 연산을 나타냅니다. 그러나 신경망의 맥락에서는 이 개념이 전통적인 통계적 해석과 다릅니다.\u003c/p\u003e\n\u003cp\u003e기본적으로 우리는 입력 함수로 시작합니다. 우리의 경우에는 주로 이미지입니다. 또한, 필터(커널이라고도 함)를 소개합니다. 이미지는 점곱 연산을 통해 변환되는 함수로, 일반적으로 \"합성곱(convolution)\"이라고 합니다. 그 다음, 이러한 필터를 입력 이미지에 적용하면 \"특성 맵(feature maps)\"이라고 하는 출력 이미지를 얻게 됩니다.\u003c/p\u003e\n\u003ch2\u003e2.1 — 합성곱 계층\u003c/h2\u003e\n\u003cp\u003e합성곱 계층은 패턴을 감지하고 필터(커널)를 통해 특성 맵을 생성하기 위해 이미지가 처리되는 곳입니다. 이러한 특성 맵은 필터가 식별하려는 각 속성을 나타냅니다. 필터는 일반적으로 (3x3) 또는 (5x5) 행렬로 구성되어 있으며, 각 필터는 입력 이미지에서 동일한 크기의 필드를 차지합니다. 그런 다음, 필터가 한 칸씩 가로로 이동하고 같은 프로세스가 반복됩니다. 가로 끝에 도달하면 필터가 한 칸 아래로 이동하고 점곱 프로세스가 다시 수평으로 적용됩니다. 그 결과는 순서대로 출력에 추가되어 특성 맵을 생성합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/0*4UZXfXs7eQ3TT02M.gif\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e입력 이미지를 나타내는 텐서 I의 차원이 m1 x m2 x mc인 경우를 가정해 봅시다. 이 텐서에서,\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_4.png\" alt=\"image1\"\u003e\u003c/p\u003e\n\u003cp\u003e우리는 입력 이미지와 일치하는 채널 수를 가진 (n1 x n2 x nc) 차원을 가지는 필터를 적용합니다. 이 필터는 이미지를 왼쪽에서 오른쪽으로 움직이면서, 입력 텐서 I의 해당 영역과 요소별 곱셈을 수행하고 이러한 곱셈 결과를 합산합니다. 스트라이드 매개변수는 필터가 이미지를 횡단하는 단계 크기를 결정합니다. I와 K 사이의 이 작업의 결과는 다른 차원 (m1 - n1 + 1) x (m2 - n2 + 1) x 1을 가진 또 다른 텐서를 생성합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_5.png\" alt=\"image2\"\u003e\u003c/p\u003e\n\u003cp\u003e안녕하세요,\u003c/p\u003e\n\u003cp\u003e특징 맵의 (i, j)번째 항목은 다음과 같이 계산됩니다:\u003c/p\u003e\n\u003cp\u003e다음 예를 선택했습니다. 5x5x1 차원 이미지가 3x3x1 커널로 합성되고 s=1 스트라이드가 적용됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_8.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e특징 맵의 (i, j)-번째 항목은 단일 채널에 대한 다음 일반 공식으로 주어집니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_9.png\" alt=\"formula\"\u003e\u003c/p\u003e\n\u003cp\u003e위 예에서 feature map의 (1, 1)번 째 항목을 계산해 봅시다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_10.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_11.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e사용할 수 없는 항목은 0으로 대체되었습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_12.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e마찬가지로, 남은 항목들은 동일한 공식을 사용하여 계산할 수 있습니다. 이 과정은 서로 다른 유형의 필터를 적용함으로써 반복되며, 각각이 이미지의 다른 특징을 캡처하는 것을 보여줍니다. 예를 들어, 필터 개수가 하나 이상이 될 수 있어서 스트라이드 개념이 도입됩니다.\u003c/p\u003e\n\u003ch2\u003e2.2— 패딩 레이어\u003c/h2\u003e\n\u003cp\u003e기본 CNN은 (n x n) 크기의 흑백 이미지와 (f x f) 크기의 필터/커널을 사용하여 결과를 제공하며, 출력 크기는 (n - f + 1) x (n - f + 1)이 됩니다. 예를 들어, (8 x 8) 이미지와 (3 x 3) 필터를 사용한 어떤 합성 곱 작업의 경우, 출력 이미지 크기는 (6 x 6)이 됩니다. 이러한 크기의 감소는 이미지 처리 중 일관적으로 발생하며, 레이어의 출력이 일반적으로 입력보다 작습니다. 또한, 합성 곱 작업에서 사용되는 필터는 픽셀을 횡단하면서 항상 모서리에 초점을 두지 않습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_13.png\" alt=\"TinyML CNN\"\u003e\u003c/p\u003e\n\u003cp\u003e머신 러닝에서 일반적으로 사용되는 여러 유형의 패딩이 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSame 패딩: Same 패딩은 원본 이미지의 외부 프레임에 일반적으로 0과 같은 추가 요소를 추가하는 것을 포함합니다. 이 방식으로 입력을 확장함으로써, 필터가 더 넓은 영역을 스캔할 수 있게 되어 출력 이미지가 원본과 동일한 크기를 유지할 수 있습니다. 이것은 컨볼루션 작업 중 공간적 차원을 유지하는 데 유용합니다.\u003c/li\u003e\n\u003cli\u003eValid 패딩: Same 패딩과는 달리, Valid 패딩은 이미지에 추가 요소를 추가하는 것을 포함하지 않습니다. 필터는 추가 요소 없이 원본 이미지를 훑어갑니다. 이것은 간격으로 인한 일부 데이터 손실이 발생할 수 있지만, valid 패딩은 출력 피쳐 맵의 크기를 줄이고자 할 때 사용됩니다. 이러한 축소는 모델의 매개변수 수를 줄이고 계산 효율성을 향상시킬 수 있습니다.\u003c/li\u003e\n\u003cli\u003eCausal 패딩: Causal 패딩은 주로 시퀀스-투-시퀀스 모델 및 시계열 예측에 사용되며, 특히 1차원 컨볼루션 레이어에서 사용됩니다. 이 유형의 패딩은 데이터 시퀀스의 시작 부분에 요소를 추가하여 알고리즘이 초기 시간 단계에 대한 값을 예측할 수 있게 합니다. 과거 및 현재 데이터를 예측에 포함시킴으로써, causal 패딩은 모델이 추론 중에 사용할 수 없는 미래 데이터를 활용하지 않도록 보장합니다.\u003c/li\u003e\n\u003cli\u003eFull 패딩: 이 유형의 패딩은 입력의 테두리 주위에 여러 레이어의 0을 추가하여 원본 이미지 크기보다 큰 출력 피쳐 맵을 생성합니다. Full 패딩은 덜 일반적이지만 더 큰 출력 크기가 필요한 특정 시나리오에서 사용할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e2.3 —Pooling Layer\u003c/h2\u003e\n\u003cp\u003e풀링 레이어에서는 컨볼루션된 특징의 공간 차원이 일반적으로 축소되어 입력 이미지에서 주요한 특징을 추출하는 데 도움이 됩니다. 이 크기의 축소는 컨볼루션 레이어에서 얻은 출력에 풀링 함수를 적용하여 달성됩니다. 이렇게 가정해 봅시다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_14.png\" alt=\"그림 1\"\u003e\u003c/p\u003e\n\u003cp\u003e풀링된 부분의 차원은 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_15.png\" alt=\"그림 2\"\u003e\u003c/p\u003e\n\u003cp\u003e딥러닝에서는 3가지 종류의 풀링이 있어요:\u003c/p\u003e\n\u003cp\u003e평균 풀링: 커버된 영역 내 픽셀 값의 평균이 출력 매트릭스로 전달됩니다.\u003c/p\u003e\n\u003cp\u003e최대 풀링: 커버된 영역 내 픽셀 값 중 가장 높은 값이 출력 매트릭스로 전달됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_16.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e전역 최대 풀링(Global Max Pooling) : 모든 입력 크기의 픽셀 값 중 가장 높은 값이 출력 행렬로 전달됩니다. 이 유형의 풀링에서 풀 크기는 입력 크기와 동일합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_17.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003esum pooling, average pooling, max pooling과 같은 다양한 유형의 풀링이 있습니다. 최대 풀링의 예는 아래에 제공됩니다. 최대 풀링은 2x2 패치에 수행됩니다. 각 패치에서 최댓값이 선택됩니다.\u003c/p\u003e\n\u003ch2\u003e2.4 — 플래튼 레이어\u003c/h2\u003e\n\u003cp\u003e플래튼 레이어는 신경망 아키텍처에서 중요한 구성 요소이며, 특히 합성곱 레이어에서 완전히 연결된 레이어로의 전환 시에 중요합니다. 이 레이어는 합성곱 및 풀링 레이어에서 생성된 다차원 피쳐 맵을 일차원 벡터로 변환하여, 분류 또는 회귀 작업을 위해 후속 완전히 연결된 레이어로 전달할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_18.png\" alt=\"이미지 설명\"\u003e\u003c/p\u003e\n\u003cp\u003e다음은 플래튼 레이어의 작동 방식입니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e입력: 플래튼 레이어의 입력은 일반적으로 이전 합성곱 또는 풀링 레이어에서 생성된 피쳐 맵을 나타내는 다차원 텐서입니다. 예를 들어, 마지막 합성곱 또는 풀링 레이어가 높이, 너비, 깊이의 피쳐 맵을 생성한다면 입력 텐서는 (배치 크기, 높이, 너비, 깊이) 형태를 가질 것입니다.\u003c/li\u003e\n\u003cli\u003e플래팅: 플래팅 레이어는 단순히 피쳐 맵의 모든 요소를 하나의 차원을 따라 연결하여 입력 텐서를 일차원 벡터로 다시 형태화합니다. 예를 들어, 피쳐 맵이 높이, 너비, 깊이의 차원을 가진다면 플래팅 레이어는 이를 높이 * 너비 * 깊이의 길이를 가진 벡터로 변환합니다.\u003c/li\u003e\n\u003cli\u003e출력: 플래팅 레이어의 출력은 피쳐 맵을 플래팅한 일차원 벡터입니다. 이 벡터는 이후의 완전히 연결된 레이어의 입력으로 전달될 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e평탄화 레이어의 목적은 특성 맵에서 캡처된 공간 정보를 완전 연결 레이어에서 처리할 수 있는 형식으로 변환하는 것입니다. 완전 연결 레이어는 일차원 입력 벡터를 필요로하므로 특성 맵을 평탄화함으로써 신경망이 데이터의 다양한 공간 위치에 걸쳐 복잡한 패턴과 관계를 효과적으로 학습할 수 있습니다. 이를 통해 더 정확한 예측을 할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이전의 합성곱 또는 풀링 레이어에 의해 생성된 특성 맵 𝐹 집합이 있다고 가정해봅시다. 이러한 특성 맵의 차원을 다음과 같이 표기해 봅시다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e𝐻: 특성 맵의 높이\u003c/li\u003e\n\u003cli\u003e𝑊: 특성 맵의 너비\u003c/li\u003e\n\u003cli\u003e𝐷: 특성 맵의 깊이 (채널 수)\u003c/li\u003e\n\u003cli\u003e𝐵: 배치 크기 (배치에 포함된 샘플 수)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e그러면 특성 맵 𝐹의 형태는 (B,H,W,D)가 됩니다. 여기서 𝐵은 배치 크기를 나타냅니다.\u003c/p\u003e\n\u003cp\u003e이러한 피처 맵을 일차원 벡터로 평탄화하기 위해, 단순히 이를 길이 𝐻×𝑊×𝐷의 벡터로 재구성합니다. 수학적으로 표현하면 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003eFlatten(𝐹)=reshape(𝐹, (𝐵, 𝐻×𝑊×𝐷))\u003c/p\u003e\n\u003cp\u003e이 경우, 재구성 연산은 (𝐵, 𝐻, 𝑊, 𝐷) 텐서를 (𝐵, 𝐻×𝑊×𝐷) 텐서로 재구성하여 공간 차원을 하나의 차원으로 펼치게 됩니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, 만약 𝐹가 차원이 (4,5,5,3)인 경우 (배치 크기가 4, 높이가 5, 너비가 5, 깊이가 3인 피처 맵), 그러면 평탄화된 출력은 (4,75) 차원을 갖게 되며, 각 행은 배치의 한 샘플에 대한 평탄화된 피처 맵을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e이 평탄화된 벡터는 신경망의 후속 완전 연결 레이어에 입력으로 전달될 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e3 — TinyML 구현\u003c/h1\u003e\n\u003cp\u003e이 예제를 통해 ESP32, 아두이노, 라즈베리 파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에서 머신러닝 알고리즘을 구현할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e3.0 — requirements.txt 파일에 나열된 라이브러리를 설치합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e!pip install -r requirements.txt\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.1 — 라이브러리 가져오기\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.datasets \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e load_digits\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e tensorflow \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e tf\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e tensorflow.keras \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e layers\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e accuracy_score\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.metrics \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e confusion_matrix\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e matplotlib \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e time\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e seaborn \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e sns\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.2 — 데이터셋 불러오기\u003c/p\u003e\n\u003cp\u003eMNIST은 Modified National Institute of Standards and Technology database의 줄임말로, 기공 학습 및 컴퓨터 비전 분야에서 널리 사용되는 데이터셋입니다. 이 데이터셋은 0에서 9까지의 손으로 쓴 숫자들의 모음으로, 각 숫자는 28x28 픽셀 크기의 회색 음영 이미지로 표현됩니다. 이 데이터셋에는 총 70,000개의 이미지가 포함되어 있으며, 이 중 60,000개의 이미지는 훈련에 사용되고 10,000개의 이미지는 테스트에 사용됩니다.\u003c/p\u003e\n\u003cp\u003e링크: \u003ca href=\"https://www.nist.gov/itl/products-and-services/emnist-dataset\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://www.nist.gov/itl/products-and-services/emnist-dataset\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eget_data\u003c/span\u003e():\n    np.random.seed(\u003cspan class=\"hljs-number\"\u003e1337\u003c/span\u003e)\n    x_values, y_values = load_digits(return_X_y=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n    x_values /= x_values.\u003cspan class=\"hljs-built_in\"\u003emax\u003c/span\u003e()\n    \u003cspan class=\"hljs-comment\"\u003e# reshape to (8 x 8 x 1)\u003c/span\u003e\n    x_values = x_values.reshape((\u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(x_values), \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n    \u003cspan class=\"hljs-comment\"\u003e# split into train, validation, test\u003c/span\u003e\n    TRAIN_SPLIT = \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.6\u003c/span\u003e * \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(x_values))\n    TEST_SPLIT = \u003cspan class=\"hljs-built_in\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e * \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(x_values) + TRAIN_SPLIT)\n    x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n    y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e x_train, x_test, x_validate, y_train, y_test, y_validate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.3 — 데이터 분할\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eX_train, X_test, X_validate, y_train, y_test, y_validate = \u003cspan class=\"hljs-title function_\"\u003eget_data\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.4 — 탐색적 데이터 분석\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eX_train__ = X_train.\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e(X_train.\u003cspan class=\"hljs-property\"\u003eshape\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e)\n\nfig, axis = plt.\u003cspan class=\"hljs-title function_\"\u003esubplots\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e, figsize=(\u003cspan class=\"hljs-number\"\u003e20\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e))\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i, ax \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eenumerate\u003c/span\u003e(axis.\u003cspan class=\"hljs-property\"\u003eflat\u003c/span\u003e):\n    ax.\u003cspan class=\"hljs-title function_\"\u003eimshow\u003c/span\u003e(X_train__[i], cmap=\u003cspan class=\"hljs-string\"\u003e'binary'\u003c/span\u003e)\n    digit = y_train[i]\n    ax.\u003cspan class=\"hljs-title function_\"\u003eset\u003c/span\u003e(title = f\u003cspan class=\"hljs-string\"\u003e\"실제 숫자는 {digit}입니다.\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_19.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e3.5— 모델 정의하기\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003emodel = tf.\u003cspan class=\"hljs-property\"\u003ekeras\u003c/span\u003e.\u003cspan class=\"hljs-title class_\"\u003eSequential\u003c/span\u003e()\nmodel.\u003cspan class=\"hljs-title function_\"\u003eadd\u003c/span\u003e(layers.\u003cspan class=\"hljs-title class_\"\u003eConv2D\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, (\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e), activation=\u003cspan class=\"hljs-string\"\u003e'relu'\u003c/span\u003e, input_shape=(\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)))\nmodel.\u003cspan class=\"hljs-title function_\"\u003eadd\u003c/span\u003e(layers.\u003cspan class=\"hljs-title class_\"\u003eMaxPooling2D\u003c/span\u003e((\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)))\nmodel.\u003cspan class=\"hljs-title function_\"\u003eadd\u003c/span\u003e(layers.\u003cspan class=\"hljs-title class_\"\u003eFlatten\u003c/span\u003e())\nmodel.\u003cspan class=\"hljs-title function_\"\u003eadd\u003c/span\u003e(layers.\u003cspan class=\"hljs-title class_\"\u003eDense\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(np.\u003cspan class=\"hljs-title function_\"\u003eunique\u003c/span\u003e(y_train))))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003emodel.\u003cspan class=\"hljs-title function_\"\u003esummary\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_20.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-title function_\"\u003eplot_model\u003c/span\u003e(model, to_file=\u003cspan class=\"hljs-string\"\u003e'./figures/model.png'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_21.png\" alt=\"Plot\"\u003e\u003c/p\u003e\n\u003cp\u003e3.6—모델 컴파일하기\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003emodel.\u003cspan class=\"hljs-title function_\"\u003ecompile\u003c/span\u003e(optimizer=\u003cspan class=\"hljs-string\"\u003e'adam'\u003c/span\u003e, loss=tf.\u003cspan class=\"hljs-property\"\u003ekeras\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003elosses\u003c/span\u003e.\u003cspan class=\"hljs-title class_\"\u003eSparseCategoricalCrossentropy\u003c/span\u003e(from_logits=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e), metrics=[\u003cspan class=\"hljs-string\"\u003e'accuracy'\u003c/span\u003e])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.7 — 모델 훈련\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ehistory = model.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X_train, y_train,\n                    epochs=\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e,\n                    batch_size=\u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e,\n                    validation_data=(X_validate, y_validate))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003emodel.\u003cspan class=\"hljs-title function_\"\u003esave\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'.\\models\\model.keras'\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eloss = history.\u003cspan class=\"hljs-property\"\u003ehistory\u003c/span\u003e[\u003cspan class=\"hljs-string\"\u003e'loss'\u003c/span\u003e]\nval_loss = history.\u003cspan class=\"hljs-property\"\u003ehistory\u003c/span\u003e[\u003cspan class=\"hljs-string\"\u003e'val_loss'\u003c/span\u003e]\nepochs = \u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(loss) + \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(epochs, loss, \u003cspan class=\"hljs-string\"\u003e'r.'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'훈련 손실'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eplot\u003c/span\u003e(epochs, val_loss, \u003cspan class=\"hljs-string\"\u003e'y'\u003c/span\u003e, label=\u003cspan class=\"hljs-string\"\u003e'검증 손실'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'훈련 및 검증 손실'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'에포크'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'손실'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003egrid\u003c/span\u003e()\nplt.\u003cspan class=\"hljs-title function_\"\u003elegend\u003c/span\u003e()\nplt.\u003cspan class=\"hljs-title function_\"\u003esavefig\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'.\\\\figures\\\\history_traing.png'\u003c/span\u003e, dpi=\u003cspan class=\"hljs-number\"\u003e300\u003c/span\u003e, bbox_inches=\u003cspan class=\"hljs-string\"\u003e'tight'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e모델 평가\u003c/p\u003e\n\u003cp\u003e테스트 데이터\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef \u003cspan class=\"hljs-title function_\"\u003etest_model\u003c/span\u003e(model, x_test, y_test):\n    x_test = (x_test / x_test.\u003cspan class=\"hljs-title function_\"\u003emax\u003c/span\u003e()).\u003cspan class=\"hljs-title function_\"\u003ereshape\u003c/span\u003e((\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(x_test), \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e))\n    y_pred = model.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(x_test).\u003cspan class=\"hljs-title function_\"\u003eargmax\u003c/span\u003e(axis=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n    \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'정확도'\u003c/span\u003e, ((y_pred == y_test).\u003cspan class=\"hljs-title function_\"\u003esum\u003c/span\u003e() / \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(y_test))*\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"%\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-title function_\"\u003etest_model\u003c/span\u003e(model, X_test, y_test)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_23.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e3.8.2 — Confusion matrix\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003efig = plt.\u003cspan class=\"hljs-title function_\"\u003efigure\u003c/span\u003e(figsize=(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)) # \u003cspan class=\"hljs-title class_\"\u003eSet\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eFigure\u003c/span\u003e\n\ny_pred = model.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_test) # \u003cspan class=\"hljs-title class_\"\u003ePredict\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eprobabilities\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e =\u003e [\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.9\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\nY_pred = np.\u003cspan class=\"hljs-title function_\"\u003eargmax\u003c/span\u003e(y_pred, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) # \u003cspan class=\"hljs-title class_\"\u003eDecode\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003ePredicted\u003c/span\u003e labels\nmat = \u003cspan class=\"hljs-title function_\"\u003econfusion_matrix\u003c/span\u003e(y_test, Y_pred) # \u003cspan class=\"hljs-title class_\"\u003eConfusion\u003c/span\u003e matrix\n\n# \u003cspan class=\"hljs-title class_\"\u003ePlot\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eConfusion\u003c/span\u003e matrix\nsns.\u003cspan class=\"hljs-title function_\"\u003eheatmap\u003c/span\u003e(mat.\u003cspan class=\"hljs-property\"\u003eT\u003c/span\u003e, square=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, annot=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, cbar=\u003cspan class=\"hljs-title class_\"\u003eFalse\u003c/span\u003e, cmap=plt.\u003cspan class=\"hljs-property\"\u003ecm\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eBlues\u003c/span\u003e, fmt=\u003cspan class=\"hljs-string\"\u003e'.0f'\u003c/span\u003e, \n            xticklabels=np.\u003cspan class=\"hljs-title function_\"\u003eunique\u003c/span\u003e(y_test), yticklabels=np.\u003cspan class=\"hljs-title function_\"\u003eunique\u003c/span\u003e(y_test), \n            annot_kws={\u003cspan class=\"hljs-string\"\u003e\"fontsize\"\u003c/span\u003e: \u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e}, linewidths=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, linecolor=\u003cspan class=\"hljs-string\"\u003e'white'\u003c/span\u003e)\n\nplt.\u003cspan class=\"hljs-title function_\"\u003exlabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'Predicted Values'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eylabel\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'True Values'\u003c/span\u003e, fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003exticks\u003c/span\u003e(fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eyticks\u003c/span\u003e(fontsize=\u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003esavefig\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'.\\\\figures\\\\confusion_matrix.png'\u003c/span\u003e, dpi=\u003cspan class=\"hljs-number\"\u003e300\u003c/span\u003e, bbox_inches=\u003cspan class=\"hljs-string\"\u003e'tight'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_24.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e3.8.3— 예측 유효성 검사 결과\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ey_pred = model.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(X_test)\nX_test__ = X_test\n\nfig, axis = plt.\u003cspan class=\"hljs-title function_\"\u003esubplots\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003e, figsize=(\u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e14\u003c/span\u003e))\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i, ax \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eenumerate\u003c/span\u003e(axis.\u003cspan class=\"hljs-property\"\u003eflat\u003c/span\u003e):\n    ax.\u003cspan class=\"hljs-title function_\"\u003eimshow\u003c/span\u003e(X_test__[i], cmap=\u003cspan class=\"hljs-string\"\u003e'binary'\u003c/span\u003e)\n    ax.\u003cspan class=\"hljs-title function_\"\u003eset\u003c/span\u003e(title = f\u003cspan class=\"hljs-string\"\u003e\"실제 숫자: {y_test[i]}\\n예측 숫자: {y_pred[i].argmax()}\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_25.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e3.9 — 마이크로컨트롤러에 구현할 모델을 얻기\u003c/p\u003e\n\u003cp\u003e3.9.1 — C 프로그래밍을 위해 일부 16진수 값을 배열로 변환하기\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 함수: C 프로그래밍을 위해 일부 \u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e진수 값을 배열로 변환\ndef \u003cspan class=\"hljs-title function_\"\u003ehex_to_c_array\u003c/span\u003e(hex_data, var_name):\n\n  c_str = \u003cspan class=\"hljs-string\"\u003e''\u003c/span\u003e\n\n  # 헤더 가드 생성\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#ifdef __has_attribute\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#define HAVE_ATTRIBUTE(x) __has_attribute(x)\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#else\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#define HAVE_ATTRIBUTE(x) 0\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#endif\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#if HAVE_ATTRIBUTE(aligned) || (defined(__GNUC__) \u0026#x26;\u0026#x26; !defined(__clang__))\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#define DATA_ALIGN_ATTRIBUTE __attribute__((aligned(4)))\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#else\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#define DATA_ALIGN_ATTRIBUTE\\n'\u003c/span\u003e\n  c_str += \u003cspan class=\"hljs-string\"\u003e'#endif\\n\\n'\u003c/span\u003e\n\n  # C 변수 선언\n  c_str += \u003cspan class=\"hljs-string\"\u003e'const unsigned char '\u003c/span\u003e + var_name + \u003cspan class=\"hljs-string\"\u003e'[]  DATA_ALIGN_ATTRIBUTE = {'\u003c/span\u003e\n  hex_array = []\n  \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i, val \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eenumerate\u003c/span\u003e(hex_data) :\n\n    # \u003cspan class=\"hljs-number\"\u003e16\u003c/span\u003e진수에서 문자열로 변환\n    hex_str = \u003cspan class=\"hljs-title function_\"\u003eformat\u003c/span\u003e(val, \u003cspan class=\"hljs-string\"\u003e'#04x'\u003c/span\u003e)\n\n    # 각 줄이 \u003cspan class=\"hljs-number\"\u003e80\u003c/span\u003e자 이내로 유지되도록 서식 지정 추가\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (i + \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) \u0026#x3C; \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(hex_data):\n      hex_str += \u003cspan class=\"hljs-string\"\u003e','\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (i + \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e) % \u003cspan class=\"hljs-number\"\u003e12\u003c/span\u003e == \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:\n      hex_str += \u003cspan class=\"hljs-string\"\u003e'\\n '\u003c/span\u003e\n    hex_array.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(hex_str)\n\n  # 마지막 중괄호 추가\n  c_str += \u003cspan class=\"hljs-string\"\u003e'\\n '\u003c/span\u003e + \u003cspan class=\"hljs-title function_\"\u003eformat\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e' '\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ejoin\u003c/span\u003e(hex_array)) + \u003cspan class=\"hljs-string\"\u003e'\\n};\\n\\n'\u003c/span\u003e\n\n  # 헤더 가드 종료\n  c_str += \u003cspan class=\"hljs-string\"\u003e'const int '\u003c/span\u003e + var_name + \u003cspan class=\"hljs-string\"\u003e'_len = '\u003c/span\u003e + \u003cspan class=\"hljs-title function_\"\u003estr\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(hex_data)) + \u003cspan class=\"hljs-string\"\u003e';\\n'\u003c/span\u003e\n\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e c_str\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.9.2—모델을 Float32와 Int8형식으로 변환하기\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef \u003cspan class=\"hljs-title function_\"\u003erepresentative_dataset\u003c/span\u003e():\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e i \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(X_train)):\n        input_data = np.\u003cspan class=\"hljs-title function_\"\u003earray\u003c/span\u003e([X_train[i]], dtype=np.\u003cspan class=\"hljs-property\"\u003efloat32\u003c/span\u003e)\n        \u003cspan class=\"hljs-keyword\"\u003eyield\u003c/span\u003e [input_data]\n\ndef \u003cspan class=\"hljs-title function_\"\u003econverter_quantization_model\u003c/span\u003e(model, model_name):\n\n    # \u003cspan class=\"hljs-title class_\"\u003eConvert\u003c/span\u003e the model to float32\n    converter_float32 = tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eTFLiteConverter\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_keras_model\u003c/span\u003e(model)\n    converter_float32.\u003cspan class=\"hljs-property\"\u003eoptimizations\u003c/span\u003e = [tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOptimize\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eDEFAULT\u003c/span\u003e]\n    converter_float32.\u003cspan class=\"hljs-property\"\u003etarget_spec\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003esupported_types\u003c/span\u003e = [tf.\u003cspan class=\"hljs-property\"\u003efloat32\u003c/span\u003e]\n    converter_float32.\u003cspan class=\"hljs-property\"\u003e_experimental_lower_tensor_list_ops\u003c/span\u003e = \u003cspan class=\"hljs-title class_\"\u003eFalse\u003c/span\u003e\n    converter_float32.\u003cspan class=\"hljs-property\"\u003esupported_ops\u003c/span\u003e = [tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOpsSet\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eTFLITE_BUILTINS\u003c/span\u003e, tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOpsSet\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eSELECT_TF_OPS\u003c/span\u003e]\n    converter_float32.\u003cspan class=\"hljs-property\"\u003erepresentative_dataset\u003c/span\u003e = representative_dataset\n    tflite_model_float32 = converter_float32.\u003cspan class=\"hljs-title function_\"\u003econvert\u003c/span\u003e()\n    \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(tflite_model_float32)\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eopen\u003c/span\u003e(model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_float32'\u003c/span\u003e + \u003cspan class=\"hljs-string\"\u003e'.h'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'w'\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003efile\u003c/span\u003e:\n        file.\u003cspan class=\"hljs-title function_\"\u003ewrite\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003ehex_to_c_array\u003c/span\u003e(tflite_model_float32, model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_float32'\u003c/span\u003e))\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eopen\u003c/span\u003e(model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_float32.tflite'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'wb'\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ef\u003c/span\u003e:\n        f.\u003cspan class=\"hljs-title function_\"\u003ewrite\u003c/span\u003e(tflite_model_float32)\n    size_model_tflite_float32 = os.\u003cspan class=\"hljs-property\"\u003epath\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egetsize\u003c/span\u003e(model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_float32.tflite'\u003c/span\u003e)\n    \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(model_name+f\u003cspan class=\"hljs-string\"\u003e'_quant_float32.tflite: {size_model_tflite_float32} Bytes'\u003c/span\u003e)\n\n    # \u003cspan class=\"hljs-title class_\"\u003eConvert\u003c/span\u003e the model to \u003cspan class=\"hljs-title class_\"\u003eInt8\u003c/span\u003e\n    converter_int8 = tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eTFLiteConverter\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_keras_model\u003c/span\u003e(model)\n    converter_int8.\u003cspan class=\"hljs-property\"\u003eoptimizations\u003c/span\u003e = [tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOptimize\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eDEFAULT\u003c/span\u003e]\n    converter_int8.\u003cspan class=\"hljs-property\"\u003etarget_spec\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003esupported_types\u003c/span\u003e = [tf.\u003cspan class=\"hljs-property\"\u003eint8\u003c/span\u003e]\n    converter_int8.\u003cspan class=\"hljs-property\"\u003erepresentative_dataset\u003c/span\u003e = representative_dataset\n    converter_int8.\u003cspan class=\"hljs-property\"\u003etarget_spec\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003esupported_ops\u003c/span\u003e = [\n        tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOpsSet\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eTFLITE_BUILTINS_INT8\u003c/span\u003e,\n        tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOpsSet\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eSELECT_TF_OPS\u003c/span\u003e,\n    ]\n    converter_int8.\u003cspan class=\"hljs-property\"\u003etarget_spec\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003esupported_ops\u003c/span\u003e = [tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOpsSet\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eTFLITE_BUILTINS\u003c/span\u003e]\n    converter_int8.\u003cspan class=\"hljs-property\"\u003etarget_spec\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003esupported_ops\u003c/span\u003e = [tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOpsSet\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eTFLITE_BUILTINS_INT8\u003c/span\u003e]\n    converter_int8.\u003cspan class=\"hljs-property\"\u003eexperimental_new_converter\u003c/span\u003e = \u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e\n    converter_int8.\u003cspan class=\"hljs-property\"\u003eexperimental_new_quantizer\u003c/span\u003e = \u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e\n    converter_int8.\u003cspan class=\"hljs-property\"\u003eexperimental_new_calibrator\u003c/span\u003e = \u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e\n    tflite_model_int8 = converter_int8.\u003cspan class=\"hljs-title function_\"\u003econvert\u003c/span\u003e()\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eopen\u003c/span\u003e(model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_int8'\u003c/span\u003e + \u003cspan class=\"hljs-string\"\u003e'.h'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'w'\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003efile\u003c/span\u003e:\n        file.\u003cspan class=\"hljs-title function_\"\u003ewrite\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003ehex_to_c_array\u003c/span\u003e(tflite_model_int8, model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_int8'\u003c/span\u003e))\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eopen\u003c/span\u003e(model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_int8.tflite'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'wb'\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ef\u003c/span\u003e:\n        f.\u003cspan class=\"hljs-title function_\"\u003ewrite\u003c/span\u003e(tflite_model_int8)\n    size_model_tflite_int8 = os.\u003cspan class=\"hljs-property\"\u003epath\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egetsize\u003c/span\u003e(model_name+\u003cspan class=\"hljs-string\"\u003e'_quant_int8.tflite'\u003c/span\u003e)\n    \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(model_name+f\u003cspan class=\"hljs-string\"\u003e'_quant_int8.tflite: {size_model_tflite_int8} Bytes'\u003c/span\u003e)\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003emodel_name=\u003cspan class=\"hljs-string\"\u003e'.\\models\\model'\u003c/span\u003e\n\u003cspan class=\"hljs-title function_\"\u003econverter_quantization_model\u003c/span\u003e(model, model_name)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.10 — Quantized Model Evaluation\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef evaluate_quantization(model_path, X_test, y_test, quantization_type):\n    interpreter = tf.\u003cspan class=\"hljs-property\"\u003elite\u003c/span\u003e.\u003cspan class=\"hljs-title class_\"\u003eInterpreter\u003c/span\u003e(model_path=model_path)\n    interpreter.\u003cspan class=\"hljs-title function_\"\u003eallocate_tensors\u003c/span\u003e()\n\n    # \u003cspan class=\"hljs-title class_\"\u003eEvaluate\u003c/span\u003e the quantized model\n    input_index = interpreter.\u003cspan class=\"hljs-title function_\"\u003eget_input_details\u003c/span\u003e()[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e'index'\u003c/span\u003e]\n    output_index = interpreter.\u003cspan class=\"hljs-title function_\"\u003eget_output_details\u003c/span\u003e()[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e'index'\u003c/span\u003e]\n    predictions = []\n    processing_times = []\n\n    X_test = np.\u003cspan class=\"hljs-title function_\"\u003earray\u003c/span\u003e(X_test, dtype=np.\u003cspan class=\"hljs-property\"\u003efloat32\u003c/span\u003e)\n    \n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e X \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eX_test\u003c/span\u003e:\n        interpreter.\u003cspan class=\"hljs-title function_\"\u003eset_tensor\u003c/span\u003e(input_index, [X])       \n        start_time = time.\u003cspan class=\"hljs-title function_\"\u003etime\u003c/span\u003e()\n        interpreter.\u003cspan class=\"hljs-title function_\"\u003einvoke\u003c/span\u003e()\n        end_time = time.\u003cspan class=\"hljs-title function_\"\u003etime\u003c/span\u003e()\n        processing_time = end_time - start_time\n        processing_times.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(processing_time)\n        output = interpreter.\u003cspan class=\"hljs-title function_\"\u003eget_tensor\u003c/span\u003e(output_index).\u003cspan class=\"hljs-title function_\"\u003eargmax\u003c/span\u003e(axis=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n        predictions.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(output[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e])\n\n    acc = \u003cspan class=\"hljs-title function_\"\u003eaccuracy_score\u003c/span\u003e(y_test, predictions)\n   \n    # \u003cspan class=\"hljs-title class_\"\u003eCalculate\u003c/span\u003e the average and standard deviation \u003cspan class=\"hljs-keyword\"\u003eof\u003c/span\u003e differences\n    result = { \u003cspan class=\"hljs-string\"\u003e\"Accuracy (%): \"\u003c/span\u003e:acc*\u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e,\n                \u003cspan class=\"hljs-string\"\u003e\"Process time (s): \"\u003c/span\u003e: np.\u003cspan class=\"hljs-title function_\"\u003emean\u003c/span\u003e(processing_times)\n            }\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e result\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003emodel_name = \u003cspan class=\"hljs-string\"\u003e'.\\models\\model'\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eeval_quant_float32 = evaluate_quantization(model_name + \u003cspan class=\"hljs-string\"\u003e'_quant_float32.tflite'\u003c/span\u003e, X_test, y_test, \u003cspan class=\"hljs-string\"\u003e'float32'\u003c/span\u003e)\neval_quant_float32\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_26.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eeval_quant_int8 = evaluate_quantization(model_name + \u003cspan class=\"hljs-string\"\u003e'_quant_int8.tflite'\u003c/span\u003e, X_test, y_test, \u003cspan class=\"hljs-string\"\u003e'int8'\u003c/span\u003e)\neval_quant_int8 \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e3.11 — 모델 배포\u003c/h2\u003e\n\u003cp\u003e이 예제를 통해 ESP32, 아두이노, 아두이노 Portenta H7 with Vision Shield, 라즈베리파이 및 기타 다양한 마이크로컨트롤러 또는 IoT 장치에 머신러닝 알고리즘을 구현할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e3.11.1 — EloquentTinyML 라이브러리 설치\u003c/p\u003e\n\u003cp\u003e도서관 폴더로 이동하여 EloquentTinyML-main을 설치해주세요.\u003c/p\u003e\n\u003cp\u003e3.11.2 — 완전한 아두이노 스케치\u003c/p\u003e\n\u003cp\u003emodel_quant_float32.h 또는 model_quant_int8.h 파일을 열어서 다음에서 모든 16진수 값을 복사하세요:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_28.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e아래와 같이 변경해주세요:\u003c/p\u003e\n\u003cp\u003eand model len\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_29.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eand cut in model.h:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_30.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eand\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_31.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e3.11.2 — 완성된 아두이노 스케치\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e#include \u0026#x3C;\u003cspan class=\"hljs-title class_\"\u003eEloquentTinyML\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eh\u003c/span\u003e\u003e\n#include \u0026#x3C;eloquent_tinyml/tensorflow.\u003cspan class=\"hljs-property\"\u003eh\u003c/span\u003e\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e// sine_model.h contains the array you exported from Python with xxd or tinymlgen\u003c/span\u003e\n#include \u003cspan class=\"hljs-string\"\u003e\"model.h\"\u003c/span\u003e\n\n#define \u003cspan class=\"hljs-variable constant_\"\u003eN_INPUTS\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e\n#define \u003cspan class=\"hljs-variable constant_\"\u003eN_OUTPUTS\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e// in future projects you may need to tweak this value: it's a trial and error process\u003c/span\u003e\n#define \u003cspan class=\"hljs-variable constant_\"\u003eTENSOR_ARENA_SIZE\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e6\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e1024\u003c/span\u003e\n\n\u003cspan class=\"hljs-title class_\"\u003eEloquent\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eTinyML\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eTensorFlow\u003c/span\u003e::\u003cspan class=\"hljs-title class_\"\u003eTensorFlow\u003c/span\u003e\u0026#x3C;\u003cspan class=\"hljs-variable constant_\"\u003eN_INPUTS\u003c/span\u003e, \u003cspan class=\"hljs-variable constant_\"\u003eN_OUTPUTS\u003c/span\u003e, \u003cspan class=\"hljs-variable constant_\"\u003eTENSOR_ARENA_SIZE\u003c/span\u003e\u003e tf;\n\nfloat input[\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e] = {\u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e12500000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e50000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e56250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e81250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e31250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e87500000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e50000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e43750000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e75000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e31250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e12500000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e56250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e43750000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e31250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e18750000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e31250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e18750000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e62500000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e12500000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e62500000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e06250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e81250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e06250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e75000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e31250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e81250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e31250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e56250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e81250000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e56250000000f, \u003cspan class=\"hljs-number\"\u003e1.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e1.\u003c/span\u003e00000000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e43750000000f, \u003cspan class=\"hljs-number\"\u003e0.\u003c/span\u003e00000000000f};\n\nfloat y_pred[\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e] = {\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e};\n\n\u003cspan class=\"hljs-keyword\"\u003evoid\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003esetup\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003e\u003c/span\u003e) {\n    \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ebegin\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e9600\u003c/span\u003e);\n    \u003cspan class=\"hljs-title function_\"\u003edelay\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e4000\u003c/span\u003e);\n    tf.\u003cspan class=\"hljs-title function_\"\u003ebegin\u003c/span\u003e(model);\n\n    \u003cspan class=\"hljs-comment\"\u003e// check if model loaded fine\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (!tf.\u003cspan class=\"hljs-title function_\"\u003eisOk\u003c/span\u003e()) {\n      \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"ERROR: \"\u003c/span\u003e);\n      \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprintln\u003c/span\u003e(tf.\u003cspan class=\"hljs-title function_\"\u003egetErrorMessage\u003c/span\u003e());\n\n      \u003cspan class=\"hljs-keyword\"\u003ewhile\u003c/span\u003e (\u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e) \u003cspan class=\"hljs-title function_\"\u003edelay\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e);\n    }\n}\n\n\u003cspan class=\"hljs-keyword\"\u003evoid\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eloop\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003e\u003c/span\u003e) {\n\n        tf.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(input, y_pred);\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e (int i = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e; i \u0026#x3C; \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e; i++) {\n            \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(y_pred[i]);\n            \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(i == \u003cspan class=\"hljs-number\"\u003e9\u003c/span\u003e ? \u003cspan class=\"hljs-string\"\u003e'\\n'\u003c/span\u003e : \u003cspan class=\"hljs-string\"\u003e','\u003c/span\u003e);\n        }\n    \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Predicted class is: \"\u003c/span\u003e);\n      \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprintln\u003c/span\u003e(tf.\u003cspan class=\"hljs-title function_\"\u003eprobaToClass\u003c/span\u003e(y_pred));\n      \u003cspan class=\"hljs-comment\"\u003e// or you can skip the predict() method and call directly predictClass()\u003c/span\u003e\n      \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Sanity check: \"\u003c/span\u003e);\n      \u003cspan class=\"hljs-title class_\"\u003eSerial\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eprintln\u003c/span\u003e(tf.\u003cspan class=\"hljs-title function_\"\u003epredictClass\u003c/span\u003e(input));\n      \u003cspan class=\"hljs-title function_\"\u003edelay\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e2000\u003c/span\u003e);\n\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.12 — 결과\u003c/p\u003e\n\u003cp\u003e3.12.1 — 양자화된 모델 Float32\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_32.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e3.12.1 — 양자화된 모델 Int8\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_33.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eFull project in: \u003ca href=\"https://github.com/thommaskevin/TinyML\" rel=\"nofollow\" target=\"_blank\"\u003eTinyML/13_CNN at main · thommaskevin/TinyML\u003c/a\u003e\u003c/p\u003e\n\u003ch2\u003eIf you like it, consider buying my coffee ☕️💰 (Bitcoin)\u003c/h2\u003e\n\u003cp\u003ecode: bc1qzydjy4m9yhmjjrkgtrzhsgmkq79qenvcvc7qzn\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003e\u0026#x3C;img src=\"/assets/img/2024-06-20-TinyMLConvolutionalNeuralNetworksCNN_34.png\" /\u003e\u003c/code\u003e\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-20-TinyMLConvolutionalNeuralNetworksCNN"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>