<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드 | itposting" data-gatsby-head="true"/><meta property="og:title" content="LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs" data-gatsby-head="true"/><meta name="twitter:title" content="LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 19:01" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">4<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>대형 언어 모델(LLMs)은 자연 언어 처리를 혁신적으로 바꿨지만, 그들의 전체 잠재력을 이용하기 위해서는 주요 파라미터를 이해하는 것이 필요합니다.</p>
<p>본 안내서는 두 가지 핵심 설정인 온도와 상위-K를 해석해 줍니다. 온도와 상위-K가 무엇인지, 어떻게 작동하는지, 그리고 최적 결과를 얻기 위해 각각을 언제 사용해야 하는지 살펴볼 것입니다.</p>
<h1>온도란 무엇인가요?</h1>
<p>온도는 LLM의 출력의 무작위성을 제어합니다. 일반적으로 0과 1 사이로 설정됩니다.</p>
<div class="content-ad"></div>
<ul>
<li>낮은 온도(0에 가까운): 더 예측 가능하고 집중된 응답을 생성합니다.</li>
<li>높은 온도(1에 가까운): 더 다양하고 창의적이며 때로는 예측할 수 없는 출력물을 생성합니다.</li>
</ul>
<p>기술적으로 온도는 모델의 다음 토큰 예측의 확률 분포를 수정합니다. 이는 소프트맥스 함수를 적용하기 전에 로짓(정규화되지 않은 예측 점수)를 온도 값으로 나누는 방식으로 수행됩니다:</p>
<p><img src="/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png" alt="image"></p>
<p>위와 같습니다.</p>
<div class="content-ad"></div>
<ul>
<li>i는 우리가 확률을 계산하고 있는 특정 토큰을 나타냅니다.</li>
<li>j는 어휘 중 모든 토큰을 반복하는 합산에 사용됩니다.</li>
<li>x_i는 토큰 i의 로짓(unnormalized score)을 의미합니다.</li>
<li>x_j는 어휘 내 모든 토큰 j의 로짓들을 나타냅니다.</li>
<li>P(x_i)는 토큰 i의 확률을 나타냅니다.</li>
<li>T는 온도(temperature)를 의미합니다.</li>
<li>V는 어휘(vocabulary)를 나타냅니다.</li>
</ul>
<p>T가 0에 가까워질수록, 분포는 좀 더 뾰족해지며 높은 확률을 가진 토큰을 강하게 선호합니다. T가 커지면, 분포는 평평해지며 낮은 확률을 갖는 토큰들이 선택될 가능성이 높아집니다.</p>
<p><img src="/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_1.png" alt="image"></p>
<h1>Top-K란 무엇인가요?</h1>
<div class="content-ad"></div>
<p>Top-k 샘플링은 언어 모델에서 텍스트를 생성하는 데 사용되는 전략입니다. 여기에는 모든 가능한 단어를 고려하는 대신 상위 K개 가장 확률이 높은 단어에서 다음 단어를 선택하는 과정이 포함됩니다. 이 방법은 무작위성과 의미 있는 출력 사이의 균형을 도와줍니다. 아래는 이 방법이 작동하는 방식입니다:</p>
<ul>
<li>확률 분포: 모델이 시퀀스에서 다음 단어에 대한 어휘에 대한 확률 분포를 예측합니다.</li>
<li>상위 K 선택: 가장 높은 확률을 가진 상위 K개의 단어만 고려됩니다.</li>
<li>무작위 샘플링: 그 다음 이 상위 K개의 단어 중에서 단어가 그들의 확률에 기반하여 무작위로 선택됩니다.</li>
</ul>
<p><img src="/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_2.png" alt="이미지"></p>
<p>Top-K는 샘플링 풀의 크기를 제어하는 직접적인 방법을 제공합니다. K가 작을수록 보다 집중된 결과를 얻게 되지만, K가 클수록 더 다양성을 허용하지만 덜 관련성 있는 토큰을 포함할 위험이 있습니다.</p>
<div class="content-ad"></div>
<p>이 방법은 모델이 매우 불가능하거나 터무니없는 토큰을 선택하는 것을 방지하는 데 특히 효과적일 수 있습니다, 특히 K값이 비교적 낮게 설정된 경우. 그러나 이 방법은 상황에 따라 어휘 크기에 어려움을 겪을 수 있으며, 경우에 따라 너무 제한적일 수도 있고 다른 경우에는 너무 허용될 수 있습니다.</p>
<h1>온도, Top-K 또는 둘 다를 언제 사용해야 할까요?</h1>
<p>이 샘플링 방법을 적용해야 하는 시점을 이해하는 것은 귀하의 LLM 출력을 최적화하기 위해 중요합니다. 다음은 선택하는 데 도움이 되는 안내서입니다:</p>
<h2>온도</h2>
<div class="content-ad"></div>
<ul>
<li>사실적 정확성이 필요한 작업(예: 질의응답 또는 데이터 추출)에는 낮은 온도(0.1-0.3)를 사용하세요.</li>
<li>창의성과 일관성이 균형있는 일반 대화 또는 콘텐츠 생성에는 중간 온도(0.4-0.7)를 사용하세요.</li>
<li>브레인스토밍, 시에 관한 높은 온도(0.8-1.0)를 필요로 하는 시나, 최대 창의력을 요구하는 작업에는 고온도를 사용하세요.</li>
</ul>
<h3>상위-K</h3>
<ul>
<li>가장 가능성 높은 단어로 모델을 제한하고 싶을 때는 낮은 K 값(10-50)을 사용하세요. 집중적이고 결정론적인 출력에 유용합니다.</li>
<li>매우 불가능한 토큰의 선택을 방지하면서 더 많은 다양성을 허용하려면 더 높은 K 값(100-1000)을 사용하세요.</li>
<li>상위-K는 특히 짧은 시퀀스의 출력 품질을 유지하는 데 유용합니다.</li>
</ul>
<h2>온도와 상위-K 결합</h2>
<div class="content-ad"></div>
<ul>
<li>이러한 방법들을 조합하면 생성된 텍스트의 다양성과 품질을 세밀하게 조절할 수 있어요.</li>
<li>확률적으로 발생할 가능성이 낮은 토큰을 걸러내기 위해 중간 K 값 (예: 50–100)을 사용한 후, 해당 하위 집합 내에서 무작위성을 조절하기 위해 온도를 적용해주세요.</li>
<li>이 조합은 종종 각각의 방법을 단독으로 사용하는 것보다 안정적이며, 특히 더 긴 생성 작업에 적합해요.</li>
</ul>
<h2>조합 사용 지침</h2>
<ul>
<li>중간 K 값 (예: 50)와 온도 (예: 0.7)로 시작해주세요.</li>
<li>출력물이 너무 무작위적이거나 주제와 관련이 없다면 K 값을 줄이거나 온도를 낮춰주세요.</li>
<li>출력물이 너무 반복적이거나 예측 가능하다면 K 값을 늘리거나 온도를 높여주세요.</li>
<li>특정 사용 사례 및 원하는 출력 특성에 기반하여 세밀하게 조정해주세요.</li>
</ul>
<p>기억해주세요, 이상적인 설정은 작업, 모델 및 원하는 결과에 따라 다릅니다. 실험을 통해 응용 프로그램에 최적의 균형을 찾는 것이 중요해요. 결과를 모니터링하고 적절하게 조정하여 LLM 출력물에서 일관성, 관련성 및 창의성의 최적 조합을 달성해주세요.</p>
<div class="content-ad"></div>
<h1>결론</h1>
<p>온도 조절과 Top-K 샘플링을 숙달하는 것이 LLM 성능을 최적화하는 핵심입니다. 온도는 출력 무작위성을 직관적으로 조절하며, Top-K는 토큰 품질을 직접 관리합니다. 이러한 방법을 결합하면 종종 최상의 결과를 얻을 수 있으며, 창의성과 일관성 사이의 미묘한 균형을 제공합니다.</p>
<p>기억하세요, 만능 해결책은 없습니다. 이상적인 설정은 당신의 특정 작업, 모델 및 원하는 결과에 따라 다릅니다. 이러한 매개변수를 실험하여 응용 프로그램에 완벽한 균형을 찾아보세요. 연습을 통해 언어 모델의 가능성을 최대한 활용하는 기술을 개발하여 자연 언어 생성의 경계를 넓힐 수 있을 것입니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"LLMs에서 Temperature와 Top-K를 사용하는 실용 가이드","description":"","date":"2024-06-23 19:01","slug":"2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs","content":"\n\n대형 언어 모델(LLMs)은 자연 언어 처리를 혁신적으로 바꿨지만, 그들의 전체 잠재력을 이용하기 위해서는 주요 파라미터를 이해하는 것이 필요합니다.\n\n본 안내서는 두 가지 핵심 설정인 온도와 상위-K를 해석해 줍니다. 온도와 상위-K가 무엇인지, 어떻게 작동하는지, 그리고 최적 결과를 얻기 위해 각각을 언제 사용해야 하는지 살펴볼 것입니다.\n\n# 온도란 무엇인가요?\n\n온도는 LLM의 출력의 무작위성을 제어합니다. 일반적으로 0과 1 사이로 설정됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 낮은 온도(0에 가까운): 더 예측 가능하고 집중된 응답을 생성합니다.\n- 높은 온도(1에 가까운): 더 다양하고 창의적이며 때로는 예측할 수 없는 출력물을 생성합니다.\n\n기술적으로 온도는 모델의 다음 토큰 예측의 확률 분포를 수정합니다. 이는 소프트맥스 함수를 적용하기 전에 로짓(정규화되지 않은 예측 점수)를 온도 값으로 나누는 방식으로 수행됩니다:\n\n![image](/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png)\n\n위와 같습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- i는 우리가 확률을 계산하고 있는 특정 토큰을 나타냅니다.\n- j는 어휘 중 모든 토큰을 반복하는 합산에 사용됩니다.\n- x_i는 토큰 i의 로짓(unnormalized score)을 의미합니다.\n- x_j는 어휘 내 모든 토큰 j의 로짓들을 나타냅니다.\n- P(x_i)는 토큰 i의 확률을 나타냅니다.\n- T는 온도(temperature)를 의미합니다.\n- V는 어휘(vocabulary)를 나타냅니다.\n\nT가 0에 가까워질수록, 분포는 좀 더 뾰족해지며 높은 확률을 가진 토큰을 강하게 선호합니다. T가 커지면, 분포는 평평해지며 낮은 확률을 갖는 토큰들이 선택될 가능성이 높아집니다.\n\n![image](/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_1.png)\n\n# Top-K란 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTop-k 샘플링은 언어 모델에서 텍스트를 생성하는 데 사용되는 전략입니다. 여기에는 모든 가능한 단어를 고려하는 대신 상위 K개 가장 확률이 높은 단어에서 다음 단어를 선택하는 과정이 포함됩니다. 이 방법은 무작위성과 의미 있는 출력 사이의 균형을 도와줍니다. 아래는 이 방법이 작동하는 방식입니다:\n\n- 확률 분포: 모델이 시퀀스에서 다음 단어에 대한 어휘에 대한 확률 분포를 예측합니다.\n- 상위 K 선택: 가장 높은 확률을 가진 상위 K개의 단어만 고려됩니다.\n- 무작위 샘플링: 그 다음 이 상위 K개의 단어 중에서 단어가 그들의 확률에 기반하여 무작위로 선택됩니다.\n\n![이미지](/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_2.png)\n\nTop-K는 샘플링 풀의 크기를 제어하는 직접적인 방법을 제공합니다. K가 작을수록 보다 집중된 결과를 얻게 되지만, K가 클수록 더 다양성을 허용하지만 덜 관련성 있는 토큰을 포함할 위험이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 모델이 매우 불가능하거나 터무니없는 토큰을 선택하는 것을 방지하는 데 특히 효과적일 수 있습니다, 특히 K값이 비교적 낮게 설정된 경우. 그러나 이 방법은 상황에 따라 어휘 크기에 어려움을 겪을 수 있으며, 경우에 따라 너무 제한적일 수도 있고 다른 경우에는 너무 허용될 수 있습니다.\n\n# 온도, Top-K 또는 둘 다를 언제 사용해야 할까요?\n\n이 샘플링 방법을 적용해야 하는 시점을 이해하는 것은 귀하의 LLM 출력을 최적화하기 위해 중요합니다. 다음은 선택하는 데 도움이 되는 안내서입니다:\n\n## 온도\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 사실적 정확성이 필요한 작업(예: 질의응답 또는 데이터 추출)에는 낮은 온도(0.1-0.3)를 사용하세요.\n- 창의성과 일관성이 균형있는 일반 대화 또는 콘텐츠 생성에는 중간 온도(0.4-0.7)를 사용하세요.\n- 브레인스토밍, 시에 관한 높은 온도(0.8-1.0)를 필요로 하는 시나, 최대 창의력을 요구하는 작업에는 고온도를 사용하세요.\n\n### 상위-K\n\n- 가장 가능성 높은 단어로 모델을 제한하고 싶을 때는 낮은 K 값(10-50)을 사용하세요. 집중적이고 결정론적인 출력에 유용합니다.\n- 매우 불가능한 토큰의 선택을 방지하면서 더 많은 다양성을 허용하려면 더 높은 K 값(100-1000)을 사용하세요.\n- 상위-K는 특히 짧은 시퀀스의 출력 품질을 유지하는 데 유용합니다.\n\n## 온도와 상위-K 결합\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이러한 방법들을 조합하면 생성된 텍스트의 다양성과 품질을 세밀하게 조절할 수 있어요.\n- 확률적으로 발생할 가능성이 낮은 토큰을 걸러내기 위해 중간 K 값 (예: 50–100)을 사용한 후, 해당 하위 집합 내에서 무작위성을 조절하기 위해 온도를 적용해주세요.\n- 이 조합은 종종 각각의 방법을 단독으로 사용하는 것보다 안정적이며, 특히 더 긴 생성 작업에 적합해요.\n\n## 조합 사용 지침\n\n- 중간 K 값 (예: 50)와 온도 (예: 0.7)로 시작해주세요.\n- 출력물이 너무 무작위적이거나 주제와 관련이 없다면 K 값을 줄이거나 온도를 낮춰주세요.\n- 출력물이 너무 반복적이거나 예측 가능하다면 K 값을 늘리거나 온도를 높여주세요.\n- 특정 사용 사례 및 원하는 출력 특성에 기반하여 세밀하게 조정해주세요.\n\n기억해주세요, 이상적인 설정은 작업, 모델 및 원하는 결과에 따라 다릅니다. 실험을 통해 응용 프로그램에 최적의 균형을 찾는 것이 중요해요. 결과를 모니터링하고 적절하게 조정하여 LLM 출력물에서 일관성, 관련성 및 창의성의 최적 조합을 달성해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n온도 조절과 Top-K 샘플링을 숙달하는 것이 LLM 성능을 최적화하는 핵심입니다. 온도는 출력 무작위성을 직관적으로 조절하며, Top-K는 토큰 품질을 직접 관리합니다. 이러한 방법을 결합하면 종종 최상의 결과를 얻을 수 있으며, 창의성과 일관성 사이의 미묘한 균형을 제공합니다.\n\n기억하세요, 만능 해결책은 없습니다. 이상적인 설정은 당신의 특정 작업, 모델 및 원하는 결과에 따라 다릅니다. 이러한 매개변수를 실험하여 응용 프로그램에 완벽한 균형을 찾아보세요. 연습을 통해 언어 모델의 가능성을 최대한 활용하는 기술을 개발하여 자연 언어 생성의 경계를 넓힐 수 있을 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png"},"coverImage":"/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png","tag":["Tech"],"readingTime":4},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e대형 언어 모델(LLMs)은 자연 언어 처리를 혁신적으로 바꿨지만, 그들의 전체 잠재력을 이용하기 위해서는 주요 파라미터를 이해하는 것이 필요합니다.\u003c/p\u003e\n\u003cp\u003e본 안내서는 두 가지 핵심 설정인 온도와 상위-K를 해석해 줍니다. 온도와 상위-K가 무엇인지, 어떻게 작동하는지, 그리고 최적 결과를 얻기 위해 각각을 언제 사용해야 하는지 살펴볼 것입니다.\u003c/p\u003e\n\u003ch1\u003e온도란 무엇인가요?\u003c/h1\u003e\n\u003cp\u003e온도는 LLM의 출력의 무작위성을 제어합니다. 일반적으로 0과 1 사이로 설정됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e낮은 온도(0에 가까운): 더 예측 가능하고 집중된 응답을 생성합니다.\u003c/li\u003e\n\u003cli\u003e높은 온도(1에 가까운): 더 다양하고 창의적이며 때로는 예측할 수 없는 출력물을 생성합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e기술적으로 온도는 모델의 다음 토큰 예측의 확률 분포를 수정합니다. 이는 소프트맥스 함수를 적용하기 전에 로짓(정규화되지 않은 예측 점수)를 온도 값으로 나누는 방식으로 수행됩니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_0.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e위와 같습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003ei는 우리가 확률을 계산하고 있는 특정 토큰을 나타냅니다.\u003c/li\u003e\n\u003cli\u003ej는 어휘 중 모든 토큰을 반복하는 합산에 사용됩니다.\u003c/li\u003e\n\u003cli\u003ex_i는 토큰 i의 로짓(unnormalized score)을 의미합니다.\u003c/li\u003e\n\u003cli\u003ex_j는 어휘 내 모든 토큰 j의 로짓들을 나타냅니다.\u003c/li\u003e\n\u003cli\u003eP(x_i)는 토큰 i의 확률을 나타냅니다.\u003c/li\u003e\n\u003cli\u003eT는 온도(temperature)를 의미합니다.\u003c/li\u003e\n\u003cli\u003eV는 어휘(vocabulary)를 나타냅니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eT가 0에 가까워질수록, 분포는 좀 더 뾰족해지며 높은 확률을 가진 토큰을 강하게 선호합니다. T가 커지면, 분포는 평평해지며 낮은 확률을 갖는 토큰들이 선택될 가능성이 높아집니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_1.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch1\u003eTop-K란 무엇인가요?\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eTop-k 샘플링은 언어 모델에서 텍스트를 생성하는 데 사용되는 전략입니다. 여기에는 모든 가능한 단어를 고려하는 대신 상위 K개 가장 확률이 높은 단어에서 다음 단어를 선택하는 과정이 포함됩니다. 이 방법은 무작위성과 의미 있는 출력 사이의 균형을 도와줍니다. 아래는 이 방법이 작동하는 방식입니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e확률 분포: 모델이 시퀀스에서 다음 단어에 대한 어휘에 대한 확률 분포를 예측합니다.\u003c/li\u003e\n\u003cli\u003e상위 K 선택: 가장 높은 확률을 가진 상위 K개의 단어만 고려됩니다.\u003c/li\u003e\n\u003cli\u003e무작위 샘플링: 그 다음 이 상위 K개의 단어 중에서 단어가 그들의 확률에 기반하여 무작위로 선택됩니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eTop-K는 샘플링 풀의 크기를 제어하는 직접적인 방법을 제공합니다. K가 작을수록 보다 집중된 결과를 얻게 되지만, K가 클수록 더 다양성을 허용하지만 덜 관련성 있는 토큰을 포함할 위험이 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 방법은 모델이 매우 불가능하거나 터무니없는 토큰을 선택하는 것을 방지하는 데 특히 효과적일 수 있습니다, 특히 K값이 비교적 낮게 설정된 경우. 그러나 이 방법은 상황에 따라 어휘 크기에 어려움을 겪을 수 있으며, 경우에 따라 너무 제한적일 수도 있고 다른 경우에는 너무 허용될 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e온도, Top-K 또는 둘 다를 언제 사용해야 할까요?\u003c/h1\u003e\n\u003cp\u003e이 샘플링 방법을 적용해야 하는 시점을 이해하는 것은 귀하의 LLM 출력을 최적화하기 위해 중요합니다. 다음은 선택하는 데 도움이 되는 안내서입니다:\u003c/p\u003e\n\u003ch2\u003e온도\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e사실적 정확성이 필요한 작업(예: 질의응답 또는 데이터 추출)에는 낮은 온도(0.1-0.3)를 사용하세요.\u003c/li\u003e\n\u003cli\u003e창의성과 일관성이 균형있는 일반 대화 또는 콘텐츠 생성에는 중간 온도(0.4-0.7)를 사용하세요.\u003c/li\u003e\n\u003cli\u003e브레인스토밍, 시에 관한 높은 온도(0.8-1.0)를 필요로 하는 시나, 최대 창의력을 요구하는 작업에는 고온도를 사용하세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e상위-K\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e가장 가능성 높은 단어로 모델을 제한하고 싶을 때는 낮은 K 값(10-50)을 사용하세요. 집중적이고 결정론적인 출력에 유용합니다.\u003c/li\u003e\n\u003cli\u003e매우 불가능한 토큰의 선택을 방지하면서 더 많은 다양성을 허용하려면 더 높은 K 값(100-1000)을 사용하세요.\u003c/li\u003e\n\u003cli\u003e상위-K는 특히 짧은 시퀀스의 출력 품질을 유지하는 데 유용합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e온도와 상위-K 결합\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e이러한 방법들을 조합하면 생성된 텍스트의 다양성과 품질을 세밀하게 조절할 수 있어요.\u003c/li\u003e\n\u003cli\u003e확률적으로 발생할 가능성이 낮은 토큰을 걸러내기 위해 중간 K 값 (예: 50–100)을 사용한 후, 해당 하위 집합 내에서 무작위성을 조절하기 위해 온도를 적용해주세요.\u003c/li\u003e\n\u003cli\u003e이 조합은 종종 각각의 방법을 단독으로 사용하는 것보다 안정적이며, 특히 더 긴 생성 작업에 적합해요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e조합 사용 지침\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e중간 K 값 (예: 50)와 온도 (예: 0.7)로 시작해주세요.\u003c/li\u003e\n\u003cli\u003e출력물이 너무 무작위적이거나 주제와 관련이 없다면 K 값을 줄이거나 온도를 낮춰주세요.\u003c/li\u003e\n\u003cli\u003e출력물이 너무 반복적이거나 예측 가능하다면 K 값을 늘리거나 온도를 높여주세요.\u003c/li\u003e\n\u003cli\u003e특정 사용 사례 및 원하는 출력 특성에 기반하여 세밀하게 조정해주세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e기억해주세요, 이상적인 설정은 작업, 모델 및 원하는 결과에 따라 다릅니다. 실험을 통해 응용 프로그램에 최적의 균형을 찾는 것이 중요해요. 결과를 모니터링하고 적절하게 조정하여 LLM 출력물에서 일관성, 관련성 및 창의성의 최적 조합을 달성해주세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e온도 조절과 Top-K 샘플링을 숙달하는 것이 LLM 성능을 최적화하는 핵심입니다. 온도는 출력 무작위성을 직관적으로 조절하며, Top-K는 토큰 품질을 직접 관리합니다. 이러한 방법을 결합하면 종종 최상의 결과를 얻을 수 있으며, 창의성과 일관성 사이의 미묘한 균형을 제공합니다.\u003c/p\u003e\n\u003cp\u003e기억하세요, 만능 해결책은 없습니다. 이상적인 설정은 당신의 특정 작업, 모델 및 원하는 결과에 따라 다릅니다. 이러한 매개변수를 실험하여 응용 프로그램에 완벽한 균형을 찾아보세요. 연습을 통해 언어 모델의 가능성을 최대한 활용하는 기술을 개발하여 자연 언어 생성의 경계를 넓힐 수 있을 것입니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-ThePracticalGuidetoUsingTemperatureandTop-KwithLLMs"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>