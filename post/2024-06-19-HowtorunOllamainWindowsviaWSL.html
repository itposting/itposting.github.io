<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>윈도우에서 WSL을 통해 Ollama를 실행하는 방법 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-HowtorunOllamainWindowsviaWSL" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="윈도우에서 WSL을 통해 Ollama를 실행하는 방법 | itposting" data-gatsby-head="true"/><meta property="og:title" content="윈도우에서 WSL을 통해 Ollama를 실행하는 방법 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-HowtorunOllamainWindowsviaWSL" data-gatsby-head="true"/><meta name="twitter:title" content="윈도우에서 WSL을 통해 Ollama를 실행하는 방법 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 15:23" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">윈도우에서 WSL을 통해 Ollama를 실행하는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="윈도우에서 WSL을 통해 Ollama를 실행하는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">3<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-HowtorunOllamainWindowsviaWSL&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<img src="/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_0.png">
<p>안녕하세요! 올라마는 환상적인 오픈소스 프로젝트이며 어떤 기기에서든 LLM을 실행하기 가장 쉬운 방법입니다. 안타깝게도 윈도우용 올라마는 아직 개발 중입니다. 그러나 WSL 2를 사용해 실행할 수 있습니다. vscode 내에서도 작동됩니다. Windows Subsystem for Linux (WSL) 환경에서 올라마를 실행하려면 어떻게 설정해야 하는지 자세히 알아보시려면 지금 바로 찾아보세요! 이 가이드에서는 WSL 시스템에 올라마를 설정하는 단계별 프로세스를 안내해드릴 것이며, 이를 통해 어떤 오픈소스 LLM이든 원활하게 실행할 수 있습니다.</p>
<ul>
<li>가상 머신 플랫폼 및 Windows Subsystem for Linux (WSL) 활성화:
🔍 "Windows 기능 켜기/끄기" 검색</li>
</ul>
<img src="/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_1.png">
<div class="content-ad"></div>
<img src="/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_2.png">
<p>➡️ 가상 머신 플랫폼 및 Windows Subsystem for Linux을 켜세요.</p>
<p>그런 다음 다시 시작하세요.</p>
<ol start="2">
<li>우분투 배포본 설치:
Windows 터미널을 관리자 권한으로 열고 다음 명령을 실행하여 우분투를 설치하세요.</li>
</ol>
<div class="content-ad"></div>
<p>wsl -- install -d ubuntu</p>
<p>그런 다음 사용자 이름과 비밀번호를 사용하여 설정하세요. Ollama는 WSL에서만 작동합니다.</p>
<ol start="3">
<li>WSL 버전을 2로 업데이트:</li>
</ol>
<p>Ollama는 제대로 작동하기 위해 WSL 2가 필요합니다. WSL 버전을 업데이트하려면 다음 명령을 실행하세요:</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">wsl --update

wsl --set-<span class="hljs-keyword">default</span>-version <span class="hljs-number">2</span>
</code></pre>
<pre><code class="hljs language-js">wsl --set-<span class="hljs-keyword">default</span>-version ubuntu  <span class="hljs-number">2</span>
</code></pre>
<ol start="4">
<li>패키지 업데이트:</li>
</ol>
<p>관리자 권한으로 Ubuntu 배포본을 시작하고 다음을 실행하여 패키지를 업데이트하세요:</p>
<div class="content-ad"></div>
<pre><code class="hljs language-shell">sudo apt update &#x26;&#x26; sudo apt upgrade
</code></pre>
<p><img src="/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_3.png" alt="image"></p>
<ol start="5">
<li>Ollama 설치: 이제 Ollama를 설치할 시간입니다! 다음 명령을 실행하여 Linux 환경에 Ollama를 다운로드하고 설치하십시오: (Linux에서 Ollama 다운로드)</li>
</ol>
<pre><code class="hljs language-shell">curl https://ollama.ai/install.sh | sh
</code></pre>
<div class="content-ad"></div>
<p>이 작업은 올라마 및 해당 종속성을 다운로드하고 설정하는 데 몇 분이 걸릴 수 있습니다.</p>
<p>축하합니다! WSL 환경에 올라마를 성공적으로 설치했습니다. 이제 사용할 모델을 다운로드하고 실행할 준비가 되었습니다. 올라마 라이브러리에서 지원되는 모델 목록을 확인하세요. (ollama.ai)</p>
<pre><code class="hljs language-js">ollama run mistral
</code></pre>
<p><img src="/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_4.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>윈도우 환경에서 사용 가능한 옵션 중 원하는 모델의 이름(예: llama2, phi, openhermes, codellama, llava, dolphin)으로 테이블 태그를 Markdown 형식으로 변경해주세요.</p>
<p>이 단계를 따르면 Ollama가 WSL 환경에 매끄럽게 통합되어, 다양한 머신 러닝 모델을 쉽게 탐색할 수 있게 됩니다. 즐거운 사용 경험 되세요!</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"윈도우에서 WSL을 통해 Ollama를 실행하는 방법","description":"","date":"2024-06-19 15:23","slug":"2024-06-19-HowtorunOllamainWindowsviaWSL","content":"\n\n\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_0.png\" /\u003e\n\n안녕하세요! 올라마는 환상적인 오픈소스 프로젝트이며 어떤 기기에서든 LLM을 실행하기 가장 쉬운 방법입니다. 안타깝게도 윈도우용 올라마는 아직 개발 중입니다. 그러나 WSL 2를 사용해 실행할 수 있습니다. vscode 내에서도 작동됩니다. Windows Subsystem for Linux (WSL) 환경에서 올라마를 실행하려면 어떻게 설정해야 하는지 자세히 알아보시려면 지금 바로 찾아보세요! 이 가이드에서는 WSL 시스템에 올라마를 설정하는 단계별 프로세스를 안내해드릴 것이며, 이를 통해 어떤 오픈소스 LLM이든 원활하게 실행할 수 있습니다.\n\n- 가상 머신 플랫폼 및 Windows Subsystem for Linux (WSL) 활성화:\n🔍 \"Windows 기능 켜기/끄기\" 검색\n\n\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_2.png\" /\u003e\n\n➡️ 가상 머신 플랫폼 및 Windows Subsystem for Linux을 켜세요.\n\n그런 다음 다시 시작하세요.\n\n2. 우분투 배포본 설치:\nWindows 터미널을 관리자 권한으로 열고 다음 명령을 실행하여 우분투를 설치하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nwsl -- install -d ubuntu\n\n\n그런 다음 사용자 이름과 비밀번호를 사용하여 설정하세요. Ollama는 WSL에서만 작동합니다.\n\n3. WSL 버전을 2로 업데이트:\n\nOllama는 제대로 작동하기 위해 WSL 2가 필요합니다. WSL 버전을 업데이트하려면 다음 명령을 실행하세요:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nwsl --update\n\nwsl --set-default-version 2\n```\n\n```js\nwsl --set-default-version ubuntu  2\n```\n\n4. 패키지 업데이트:\n\n관리자 권한으로 Ubuntu 배포본을 시작하고 다음을 실행하여 패키지를 업데이트하세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```shell\nsudo apt update \u0026\u0026 sudo apt upgrade\n```\n\n![image](/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_3.png)\n\n5. Ollama 설치: 이제 Ollama를 설치할 시간입니다! 다음 명령을 실행하여 Linux 환경에 Ollama를 다운로드하고 설치하십시오: (Linux에서 Ollama 다운로드)\n\n```shell\ncurl https://ollama.ai/install.sh | sh\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 작업은 올라마 및 해당 종속성을 다운로드하고 설정하는 데 몇 분이 걸릴 수 있습니다.\n\n축하합니다! WSL 환경에 올라마를 성공적으로 설치했습니다. 이제 사용할 모델을 다운로드하고 실행할 준비가 되었습니다. 올라마 라이브러리에서 지원되는 모델 목록을 확인하세요. (ollama.ai)\n\n```js\nollama run mistral\n```\n\n![이미지](/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n윈도우 환경에서 사용 가능한 옵션 중 원하는 모델의 이름(예: llama2, phi, openhermes, codellama, llava, dolphin)으로 테이블 태그를 Markdown 형식으로 변경해주세요.\n\n이 단계를 따르면 Ollama가 WSL 환경에 매끄럽게 통합되어, 다양한 머신 러닝 모델을 쉽게 탐색할 수 있게 됩니다. 즐거운 사용 경험 되세요!","ogImage":{"url":"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_0.png"},"coverImage":"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_0.png","tag":["Tech"],"readingTime":3},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_0.png\"\u003e\n\u003cp\u003e안녕하세요! 올라마는 환상적인 오픈소스 프로젝트이며 어떤 기기에서든 LLM을 실행하기 가장 쉬운 방법입니다. 안타깝게도 윈도우용 올라마는 아직 개발 중입니다. 그러나 WSL 2를 사용해 실행할 수 있습니다. vscode 내에서도 작동됩니다. Windows Subsystem for Linux (WSL) 환경에서 올라마를 실행하려면 어떻게 설정해야 하는지 자세히 알아보시려면 지금 바로 찾아보세요! 이 가이드에서는 WSL 시스템에 올라마를 설정하는 단계별 프로세스를 안내해드릴 것이며, 이를 통해 어떤 오픈소스 LLM이든 원활하게 실행할 수 있습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e가상 머신 플랫폼 및 Windows Subsystem for Linux (WSL) 활성화:\n🔍 \"Windows 기능 켜기/끄기\" 검색\u003c/li\u003e\n\u003c/ul\u003e\n\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_1.png\"\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_2.png\"\u003e\n\u003cp\u003e➡️ 가상 머신 플랫폼 및 Windows Subsystem for Linux을 켜세요.\u003c/p\u003e\n\u003cp\u003e그런 다음 다시 시작하세요.\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e우분투 배포본 설치:\nWindows 터미널을 관리자 권한으로 열고 다음 명령을 실행하여 우분투를 설치하세요.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003ewsl -- install -d ubuntu\u003c/p\u003e\n\u003cp\u003e그런 다음 사용자 이름과 비밀번호를 사용하여 설정하세요. Ollama는 WSL에서만 작동합니다.\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003eWSL 버전을 2로 업데이트:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eOllama는 제대로 작동하기 위해 WSL 2가 필요합니다. WSL 버전을 업데이트하려면 다음 명령을 실행하세요:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ewsl --update\n\nwsl --set-\u003cspan class=\"hljs-keyword\"\u003edefault\u003c/span\u003e-version \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ewsl --set-\u003cspan class=\"hljs-keyword\"\u003edefault\u003c/span\u003e-version ubuntu  \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e패키지 업데이트:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e관리자 권한으로 Ubuntu 배포본을 시작하고 다음을 실행하여 패키지를 업데이트하세요:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-shell\"\u003esudo apt update \u0026#x26;\u0026#x26; sudo apt upgrade\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003eOllama 설치: 이제 Ollama를 설치할 시간입니다! 다음 명령을 실행하여 Linux 환경에 Ollama를 다운로드하고 설치하십시오: (Linux에서 Ollama 다운로드)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-shell\"\u003ecurl https://ollama.ai/install.sh | sh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 작업은 올라마 및 해당 종속성을 다운로드하고 설정하는 데 몇 분이 걸릴 수 있습니다.\u003c/p\u003e\n\u003cp\u003e축하합니다! WSL 환경에 올라마를 성공적으로 설치했습니다. 이제 사용할 모델을 다운로드하고 실행할 준비가 되었습니다. 올라마 라이브러리에서 지원되는 모델 목록을 확인하세요. (ollama.ai)\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eollama run mistral\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-HowtorunOllamainWindowsviaWSL_4.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e윈도우 환경에서 사용 가능한 옵션 중 원하는 모델의 이름(예: llama2, phi, openhermes, codellama, llava, dolphin)으로 테이블 태그를 Markdown 형식으로 변경해주세요.\u003c/p\u003e\n\u003cp\u003e이 단계를 따르면 Ollama가 WSL 환경에 매끄럽게 통합되어, 다양한 머신 러닝 모델을 쉽게 탐색할 수 있게 됩니다. 즐거운 사용 경험 되세요!\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-HowtorunOllamainWindowsviaWSL"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>