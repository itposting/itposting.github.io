<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근 | itposting" data-gatsby-head="true"/><meta property="og:title" content="시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective" data-gatsby-head="true"/><meta name="twitter:title" content="시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 18:48" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">6<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>면허가 있는 거래처 선정이 기존에서 5년 이상된 기사에 대한 후속 내용입니다:</p>
<ul>
<li>시그모이드 신경망을 사용한 다항식 제조</li>
<li>시그모이드 신경망을 사용한 다항식 제조 - 실습</li>
</ul>
<p>이 실습은 신경망의 인내 성능을 다루었습니다. 간단한 기저(알려진) 모델에 대해: y = 1 + 2<em>x + 3</em>x². 실습을 마치며, 1계층 출력 간의 높은 상관 관계가 수렴을 늦추고, 제약이 없는 모델이 훨씬 더 좋은 샘내내 성능을 보였다는 결론을 내렸습니다. 추가로 다항회귀 분석도 제약이 없는 모델의 샘내내 정확성(진정한 모델 기반)을 입증했습니다. 신경망의 스플라인 이론 관점에서 이 모든 것이 직관적으로 맞는 것이며, 두 모델 모두 유용합니다. 그러나 모델의 범위 외 성능을 놓치고 있었음을 인정하지 못했습니다. 스플라인 이론적 관점에서 이는 큰 누락이었습니다.</p>
<p>이 기사는 범위 외 성능, 진정한 모델과 일치 정도, 및 '일반화'에 대한 일부 상위 추론에 초점을 맞추겠습니다. '일반화'는 다음을 기반으로 평가됩니다:</p>
<div class="content-ad"></div>
<ul>
<li>다양한 유형의 테스트 데이터 포인트(전체, 훈련 데이터 내 범위, 훈련 데이터 외 범위)별 총 오차(MSE)</li>
<li>전체 모델의 적합성(확장된 테스트 데이터 세트에서 실제 모델과의 유사성)</li>
</ul>
<h2>테스트 데이터의 범위 외 부분 생성</h2>
<p>훈련 데이터 세트의 x1은 표준 정규 분포에서 무작위 샘플링하여 생성되었습니다. x1을 3배로 곱하여 범위를 확장한 테스트 데이터 세트가 생성되었습니다. 이로 인해 원래 훈련 세트의 범위 내에 속하는 데이터 포인트가 총 7990개, 원래 훈련 세트의 범위 외에 속하는 데이터 포인트가 2010개 생성되었습니다.</p>
<h2>모델들</h2>
<div class="content-ad"></div>
<p>모델 구조는 실습과 동일합니다</p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png" alt="image"></p>
<h1>학습 및 평가</h1>
<p>모델은 실습에서 사용된 학습 예제를 사용하여 훈련되었습니다. 따라서 모델의 가중치는 변경되지 않았습니다. 그러나 제한된 및 제한되지 않은 모델의 기저 (다항식) 표현은 새로운 테스트 데이터 집합 범위 내에서 변할 수 있습니다. 또한, 모델의 범위를 벗어난 성능은 범위 내 성능에서 예측하기 어려울 수 있습니다(두 모델 모두 학습 데이터 범위 내에서 매우 좋은 적합도를 나타냄, MSE ` 0.045).</p>
<div class="content-ad"></div>
<h2>에폭별 모델 추적</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:1280/1*jygr4njGNjkNL3enCQNVyg.gif" alt="이미지"></p>
<p><img src="https://miro.medium.com/v2/resize:fit:1280/1*hUfYQ21PQZkbE40NcVwuPA.gif" alt="이미지"></p>
<p>두 그래프에 대한 키: 파란 선 - 실제 값, 파란 점 - 훈련 범위 내에서 확장 테스트 예제에 대한 모델 예측, 빨간 점 - 훈련 범위를 벗어난 확장 테스트 예제에 대한 모델 예측.</p>
<div class="content-ad"></div>
<p>(bias) 무제한 모델이 (bias) 제한 모델보다 최종 솔루션으로 수렴하는 속도가 훨씬 빠르다는 사실은 명백하다. 그러나 모델의 가중치는 크게(직역하지 않는 용어, 통계 용어 아님) 다르다. 특히, 제한 모델 가중치가 무제한 모델의 가중치보다 거의 1차 크다는 점은 매우 명백하다. 이것은 중요한 관찰이다. 왜냐하면 편향이 없는 모델은 편향 제한 모델로 수렴할 수 있는 기회가 있었지만, 대신 샘플 내 솔루션으로 더 나은 수렴했기 때문이다.</p>
<h1>모델 (메타) 분석 - 범위 내 및 범위 외</h1>
<ul>
<li>랜덤 초기화로 인해 교육 MSE는 약 28에서 출발하여 두 모델 모두 `0.045로 점진적으로 감소한다.</li>
<li>제한 모델은 활성화된 레이어 1 출력이 교육 중에 높은 상관 관계가 있기 때문에 그레이디언트가 노이즈를 일으키는 것으로 추정되므로 훨씬 느리게 수렴한다. (코드에서 실험적으로 유효성이 검증되어야 함)</li>
<li>질적으로 제한된 최종 모델은 범위 밖에서(범위 외 MSE=1699.82) 무제한 최종 모델(범위 외 MSE=2905.67)보다 훨씬 더 우수한 성능을 발휘한다. 이 향상된 외부 범위 성능은 범위 내 성능에 큰 하락이 오지 않고 (제한 모델의 범위 내 MSE=1.38 대 무제한 모델의 범위 내 MSE=0.41) 테스트 데이터에 대한 총 성능(MSE=342.77 대 무제한 모델의 MSE=584.37)에서도 비슷하게 유지된다. 이 간접는 근려에 편향 제약이 실무에서 가치를 더하는 것으로 보이지 않았기에 저에게는 매우 놀랍다.</li>
<li>새로운 테스트 데이터에 대한 모델 적합도도 제한 모델이 무제한 모델에 비해 훨씬 우수하다.</li>
</ul>
<h1>확장 테스트 데이터 세트에서 모델 적합 결과 (x1_extended = 2<em>x1 및 실제 모델 y_extended = 1 + 2</em>x1_extended + 3*x1_extended²)</h1>
<div class="content-ad"></div>
<h2>제약이 없는 모델</h2>
<p>제약이 없는 모델 레이어 1: f1_u, f2_u = f_u(x)</p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_1.png" alt="이미지1"></p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_2.png" alt="이미지2"></p>
<div class="content-ad"></div>
<p>그래서, f1_u는 0.1094 - 0.0882<em>x + 0.0102</em>x² + 0.0002*x³입니다.</p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_3.png" alt="그림1"></p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_4.png" alt="그림2"></p>
<p>그래서, f2_u는 0.1031 + 0.0799<em>x + 0.0091</em>x² - 0.0003*x³입니다.</p>
<div class="content-ad"></div>
<p>Unconstrained model layer 2: y_pred_u = g_u(f1_u, f2_u); g_u is linear
y_pred_u ~ 7.16 + 2.66<em>x + 2.31</em>x² - 0.023*x³</p>
<h2>Constrained model</h2>
<p>Constrained model layer 1: f1_c, f2_c = f_c(x)</p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_5.png" alt="Image"></p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_6.png" alt="Image 1"></p>
<p>Hence, f1_c ~ 0.5 + 0.044<em>x - 0.00005</em>x²</p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_7.png" alt="Image 2"></p>
<p><img src="/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_8.png" alt="Image 3"></p>
<div class="content-ad"></div>
<p>따라서, f2_c ~ 0.2237 + 0.0676<em>x + 0.0041</em>x² - 0.0002*x³</p>
<p>제한된 모델 레이어 2: y_pred_c = g_c(f1_c, f2_c); g_c는 선형입니다.
y_pred_c ~ 2.95 + 6.4<em>x + 2.79</em>x² - 0.134*x³</p>
<p>참고: 실습에 포함된 추가 진단은 수행되었지만, 간결함을 위해 이 글에서는 생략되었습니다. 이러한 진단에 관심이 있는 독자는 다음 스크립트를 실행해주세요:</p>
<ul>
<li>제한된 모델을 위한 test_quadratic.py</li>
<li>제한되지 않은 모델을 위한 test_quadratic_unconstrained.py</li>
</ul>
<div class="content-ad"></div>
<h2>추가적인 추론</h2>
<p>참고: *로 표시된 추론은 세 논문 중 어느 것에도 입증되지 않았지만 이론적으로나 경험적으로 보여질 수 있으며, **로 표시된 추론은 향후 논문을 위한 가능성 있는 후보들이다.</p>
<ul>
<li>비제약 모델에 대해 f1_u와 f2_u 모두 조각선형 함수 형태<em>를 띄며 ReLU와 유사하다</em></li>
<li>제약이 있는 모델과 제약이 없는 모델에 대해 이차적합을 강제하면 다음과 같은 형태가 나온다:
y_pred_u ~ 7.22 + 2.18<em>x + 2.31</em>x²
y_pred_c ~ 3.56 + 1.98<em>x + 2.72</em>x²</li>
<li>최종 가중치가 크게 다르더라도 두 모델의 훈련 오차 차이가 크지 않다. 그러므로 MSE vs. (w1, w2, W1, W2)의 곡선은 모델의 가중치 사이에 오랜 기울기를 보인다**.</li>
</ul>
<h1>결론</h1>
<div class="content-ad"></div>
<p>제약이 있는 모델은 (MSE 및 모델 계수가 실제 모델과 얼마나 가까운지) 자유로운 모델보다 훨씬 더 일반화되는 것으로 보입니다. 이 논리를 심층 신경망에서 오버피팅을 넘어서는 일반화에 적용한다면 - 모델 아키텍처가 충분히 좋은 귀납적 편향이라고 가정하면,</p>
<ul>
<li>초기 오버피팅은 가중치 벡터가 초기화된 지점에서 최단 경로(최적화 알고리즘이 지배하는)를 통해 먼저 '가능한 해'로 수렴하기 때문에 발생할 수 있습니다.</li>
<li>그 이후에 발생하는 일반화가 더 나은 해로의 전이는 최적화 알고리즘이 가중치 벡터를 (오차 측정, 가중치의) 공간에서 새로운 영역으로 완전히 이동시키도록 강요하기 때문으로 설명될 수 있습니다.</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"시그모이드 신경망을 이용한 다항식 제조  일반화 관점에서의 새로운 접근","description":"","date":"2024-06-23 18:48","slug":"2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective","content":"\n\n면허가 있는 거래처 선정이 기존에서 5년 이상된 기사에 대한 후속 내용입니다:\n\n- 시그모이드 신경망을 사용한 다항식 제조\n- 시그모이드 신경망을 사용한 다항식 제조 - 실습\n\n이 실습은 신경망의 인내 성능을 다루었습니다. 간단한 기저(알려진) 모델에 대해: y = 1 + 2*x + 3*x². 실습을 마치며, 1계층 출력 간의 높은 상관 관계가 수렴을 늦추고, 제약이 없는 모델이 훨씬 더 좋은 샘내내 성능을 보였다는 결론을 내렸습니다. 추가로 다항회귀 분석도 제약이 없는 모델의 샘내내 정확성(진정한 모델 기반)을 입증했습니다. 신경망의 스플라인 이론 관점에서 이 모든 것이 직관적으로 맞는 것이며, 두 모델 모두 유용합니다. 그러나 모델의 범위 외 성능을 놓치고 있었음을 인정하지 못했습니다. 스플라인 이론적 관점에서 이는 큰 누락이었습니다.\n\n이 기사는 범위 외 성능, 진정한 모델과 일치 정도, 및 '일반화'에 대한 일부 상위 추론에 초점을 맞추겠습니다. '일반화'는 다음을 기반으로 평가됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 다양한 유형의 테스트 데이터 포인트(전체, 훈련 데이터 내 범위, 훈련 데이터 외 범위)별 총 오차(MSE)\n- 전체 모델의 적합성(확장된 테스트 데이터 세트에서 실제 모델과의 유사성) \n\n## 테스트 데이터의 범위 외 부분 생성\n\n훈련 데이터 세트의 x1은 표준 정규 분포에서 무작위 샘플링하여 생성되었습니다. x1을 3배로 곱하여 범위를 확장한 테스트 데이터 세트가 생성되었습니다. 이로 인해 원래 훈련 세트의 범위 내에 속하는 데이터 포인트가 총 7990개, 원래 훈련 세트의 범위 외에 속하는 데이터 포인트가 2010개 생성되었습니다.\n\n## 모델들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델 구조는 실습과 동일합니다\n\n![image](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png)\n\n# 학습 및 평가\n\n모델은 실습에서 사용된 학습 예제를 사용하여 훈련되었습니다. 따라서 모델의 가중치는 변경되지 않았습니다. 그러나 제한된 및 제한되지 않은 모델의 기저 (다항식) 표현은 새로운 테스트 데이터 집합 범위 내에서 변할 수 있습니다. 또한, 모델의 범위를 벗어난 성능은 범위 내 성능에서 예측하기 어려울 수 있습니다(두 모델 모두 학습 데이터 범위 내에서 매우 좋은 적합도를 나타냄, MSE ` 0.045).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 에폭별 모델 추적\n\n![이미지](https://miro.medium.com/v2/resize:fit:1280/1*jygr4njGNjkNL3enCQNVyg.gif)\n\n![이미지](https://miro.medium.com/v2/resize:fit:1280/1*hUfYQ21PQZkbE40NcVwuPA.gif)\n\n두 그래프에 대한 키: 파란 선 - 실제 값, 파란 점 - 훈련 범위 내에서 확장 테스트 예제에 대한 모델 예측, 빨간 점 - 훈련 범위를 벗어난 확장 테스트 예제에 대한 모델 예측.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n(bias) 무제한 모델이 (bias) 제한 모델보다 최종 솔루션으로 수렴하는 속도가 훨씬 빠르다는 사실은 명백하다. 그러나 모델의 가중치는 크게(직역하지 않는 용어, 통계 용어 아님) 다르다. 특히, 제한 모델 가중치가 무제한 모델의 가중치보다 거의 1차 크다는 점은 매우 명백하다. 이것은 중요한 관찰이다. 왜냐하면 편향이 없는 모델은 편향 제한 모델로 수렴할 수 있는 기회가 있었지만, 대신 샘플 내 솔루션으로 더 나은 수렴했기 때문이다.\n\n# 모델 (메타) 분석 - 범위 내 및 범위 외\n\n- 랜덤 초기화로 인해 교육 MSE는 약 28에서 출발하여 두 모델 모두 `0.045로 점진적으로 감소한다.\n- 제한 모델은 활성화된 레이어 1 출력이 교육 중에 높은 상관 관계가 있기 때문에 그레이디언트가 노이즈를 일으키는 것으로 추정되므로 훨씬 느리게 수렴한다. (코드에서 실험적으로 유효성이 검증되어야 함)\n- 질적으로 제한된 최종 모델은 범위 밖에서(범위 외 MSE=1699.82) 무제한 최종 모델(범위 외 MSE=2905.67)보다 훨씬 더 우수한 성능을 발휘한다. 이 향상된 외부 범위 성능은 범위 내 성능에 큰 하락이 오지 않고 (제한 모델의 범위 내 MSE=1.38 대 무제한 모델의 범위 내 MSE=0.41) 테스트 데이터에 대한 총 성능(MSE=342.77 대 무제한 모델의 MSE=584.37)에서도 비슷하게 유지된다. 이 간접는 근려에 편향 제약이 실무에서 가치를 더하는 것으로 보이지 않았기에 저에게는 매우 놀랍다.\n- 새로운 테스트 데이터에 대한 모델 적합도도 제한 모델이 무제한 모델에 비해 훨씬 우수하다.\n\n# 확장 테스트 데이터 세트에서 모델 적합 결과 (x1_extended = 2*x1 및 실제 모델 y_extended = 1 + 2*x1_extended + 3*x1_extended²)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 제약이 없는 모델\n\n제약이 없는 모델 레이어 1: f1_u, f2_u = f_u(x)\n\n![이미지1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_1.png)\n\n![이미지2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, f1_u는 0.1094 - 0.0882*x + 0.0102*x² + 0.0002*x³입니다.\n\n![그림1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_3.png)\n\n![그림2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_4.png)\n\n그래서, f2_u는 0.1031 + 0.0799*x + 0.0091*x² - 0.0003*x³입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUnconstrained model layer 2: y_pred_u = g_u(f1_u, f2_u); g_u is linear\ny_pred_u ~ 7.16 + 2.66*x + 2.31*x² - 0.023*x³\n\n## Constrained model\n\nConstrained model layer 1: f1_c, f2_c = f_c(x)\n\n![Image](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image 1](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_6.png)\n\nHence, f1_c ~ 0.5 + 0.044*x - 0.00005*x²\n\n![Image 2](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_7.png)\n\n![Image 3](/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_8.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n따라서, f2_c ~ 0.2237 + 0.0676*x + 0.0041*x² - 0.0002*x³\n\n제한된 모델 레이어 2: y_pred_c = g_c(f1_c, f2_c); g_c는 선형입니다.\ny_pred_c ~ 2.95 + 6.4*x + 2.79*x² - 0.134*x³\n\n참고: 실습에 포함된 추가 진단은 수행되었지만, 간결함을 위해 이 글에서는 생략되었습니다. 이러한 진단에 관심이 있는 독자는 다음 스크립트를 실행해주세요:\n\n- 제한된 모델을 위한 test_quadratic.py\n- 제한되지 않은 모델을 위한 test_quadratic_unconstrained.py\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 추가적인 추론\n\n참고: *로 표시된 추론은 세 논문 중 어느 것에도 입증되지 않았지만 이론적으로나 경험적으로 보여질 수 있으며, **로 표시된 추론은 향후 논문을 위한 가능성 있는 후보들이다.\n\n- 비제약 모델에 대해 f1_u와 f2_u 모두 조각선형 함수 형태*를 띄며 ReLU와 유사하다*\n- 제약이 있는 모델과 제약이 없는 모델에 대해 이차적합을 강제하면 다음과 같은 형태가 나온다:\ny_pred_u ~ 7.22 + 2.18*x + 2.31*x²\ny_pred_c ~ 3.56 + 1.98*x + 2.72*x²\n- 최종 가중치가 크게 다르더라도 두 모델의 훈련 오차 차이가 크지 않다. 그러므로 MSE vs. (w1, w2, W1, W2)의 곡선은 모델의 가중치 사이에 오랜 기울기를 보인다**.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제약이 있는 모델은 (MSE 및 모델 계수가 실제 모델과 얼마나 가까운지) 자유로운 모델보다 훨씬 더 일반화되는 것으로 보입니다. 이 논리를 심층 신경망에서 오버피팅을 넘어서는 일반화에 적용한다면 - 모델 아키텍처가 충분히 좋은 귀납적 편향이라고 가정하면,\n- 초기 오버피팅은 가중치 벡터가 초기화된 지점에서 최단 경로(최적화 알고리즘이 지배하는)를 통해 먼저 '가능한 해'로 수렴하기 때문에 발생할 수 있습니다.\n- 그 이후에 발생하는 일반화가 더 나은 해로의 전이는 최적화 알고리즘이 가중치 벡터를 (오차 측정, 가중치의) 공간에서 새로운 영역으로 완전히 이동시키도록 강요하기 때문으로 설명될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png"},"coverImage":"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png","tag":["Tech"],"readingTime":6},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e면허가 있는 거래처 선정이 기존에서 5년 이상된 기사에 대한 후속 내용입니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e시그모이드 신경망을 사용한 다항식 제조\u003c/li\u003e\n\u003cli\u003e시그모이드 신경망을 사용한 다항식 제조 - 실습\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 실습은 신경망의 인내 성능을 다루었습니다. 간단한 기저(알려진) 모델에 대해: y = 1 + 2\u003cem\u003ex + 3\u003c/em\u003ex². 실습을 마치며, 1계층 출력 간의 높은 상관 관계가 수렴을 늦추고, 제약이 없는 모델이 훨씬 더 좋은 샘내내 성능을 보였다는 결론을 내렸습니다. 추가로 다항회귀 분석도 제약이 없는 모델의 샘내내 정확성(진정한 모델 기반)을 입증했습니다. 신경망의 스플라인 이론 관점에서 이 모든 것이 직관적으로 맞는 것이며, 두 모델 모두 유용합니다. 그러나 모델의 범위 외 성능을 놓치고 있었음을 인정하지 못했습니다. 스플라인 이론적 관점에서 이는 큰 누락이었습니다.\u003c/p\u003e\n\u003cp\u003e이 기사는 범위 외 성능, 진정한 모델과 일치 정도, 및 '일반화'에 대한 일부 상위 추론에 초점을 맞추겠습니다. '일반화'는 다음을 기반으로 평가됩니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e다양한 유형의 테스트 데이터 포인트(전체, 훈련 데이터 내 범위, 훈련 데이터 외 범위)별 총 오차(MSE)\u003c/li\u003e\n\u003cli\u003e전체 모델의 적합성(확장된 테스트 데이터 세트에서 실제 모델과의 유사성)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e테스트 데이터의 범위 외 부분 생성\u003c/h2\u003e\n\u003cp\u003e훈련 데이터 세트의 x1은 표준 정규 분포에서 무작위 샘플링하여 생성되었습니다. x1을 3배로 곱하여 범위를 확장한 테스트 데이터 세트가 생성되었습니다. 이로 인해 원래 훈련 세트의 범위 내에 속하는 데이터 포인트가 총 7990개, 원래 훈련 세트의 범위 외에 속하는 데이터 포인트가 2010개 생성되었습니다.\u003c/p\u003e\n\u003ch2\u003e모델들\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모델 구조는 실습과 동일합니다\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_0.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch1\u003e학습 및 평가\u003c/h1\u003e\n\u003cp\u003e모델은 실습에서 사용된 학습 예제를 사용하여 훈련되었습니다. 따라서 모델의 가중치는 변경되지 않았습니다. 그러나 제한된 및 제한되지 않은 모델의 기저 (다항식) 표현은 새로운 테스트 데이터 집합 범위 내에서 변할 수 있습니다. 또한, 모델의 범위를 벗어난 성능은 범위 내 성능에서 예측하기 어려울 수 있습니다(두 모델 모두 학습 데이터 범위 내에서 매우 좋은 적합도를 나타냄, MSE ` 0.045).\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e에폭별 모델 추적\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1280/1*jygr4njGNjkNL3enCQNVyg.gif\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1280/1*hUfYQ21PQZkbE40NcVwuPA.gif\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e두 그래프에 대한 키: 파란 선 - 실제 값, 파란 점 - 훈련 범위 내에서 확장 테스트 예제에 대한 모델 예측, 빨간 점 - 훈련 범위를 벗어난 확장 테스트 예제에 대한 모델 예측.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e(bias) 무제한 모델이 (bias) 제한 모델보다 최종 솔루션으로 수렴하는 속도가 훨씬 빠르다는 사실은 명백하다. 그러나 모델의 가중치는 크게(직역하지 않는 용어, 통계 용어 아님) 다르다. 특히, 제한 모델 가중치가 무제한 모델의 가중치보다 거의 1차 크다는 점은 매우 명백하다. 이것은 중요한 관찰이다. 왜냐하면 편향이 없는 모델은 편향 제한 모델로 수렴할 수 있는 기회가 있었지만, 대신 샘플 내 솔루션으로 더 나은 수렴했기 때문이다.\u003c/p\u003e\n\u003ch1\u003e모델 (메타) 분석 - 범위 내 및 범위 외\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e랜덤 초기화로 인해 교육 MSE는 약 28에서 출발하여 두 모델 모두 `0.045로 점진적으로 감소한다.\u003c/li\u003e\n\u003cli\u003e제한 모델은 활성화된 레이어 1 출력이 교육 중에 높은 상관 관계가 있기 때문에 그레이디언트가 노이즈를 일으키는 것으로 추정되므로 훨씬 느리게 수렴한다. (코드에서 실험적으로 유효성이 검증되어야 함)\u003c/li\u003e\n\u003cli\u003e질적으로 제한된 최종 모델은 범위 밖에서(범위 외 MSE=1699.82) 무제한 최종 모델(범위 외 MSE=2905.67)보다 훨씬 더 우수한 성능을 발휘한다. 이 향상된 외부 범위 성능은 범위 내 성능에 큰 하락이 오지 않고 (제한 모델의 범위 내 MSE=1.38 대 무제한 모델의 범위 내 MSE=0.41) 테스트 데이터에 대한 총 성능(MSE=342.77 대 무제한 모델의 MSE=584.37)에서도 비슷하게 유지된다. 이 간접는 근려에 편향 제약이 실무에서 가치를 더하는 것으로 보이지 않았기에 저에게는 매우 놀랍다.\u003c/li\u003e\n\u003cli\u003e새로운 테스트 데이터에 대한 모델 적합도도 제한 모델이 무제한 모델에 비해 훨씬 우수하다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e확장 테스트 데이터 세트에서 모델 적합 결과 (x1_extended = 2\u003cem\u003ex1 및 실제 모델 y_extended = 1 + 2\u003c/em\u003ex1_extended + 3*x1_extended²)\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e제약이 없는 모델\u003c/h2\u003e\n\u003cp\u003e제약이 없는 모델 레이어 1: f1_u, f2_u = f_u(x)\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_1.png\" alt=\"이미지1\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_2.png\" alt=\"이미지2\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그래서, f1_u는 0.1094 - 0.0882\u003cem\u003ex + 0.0102\u003c/em\u003ex² + 0.0002*x³입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_3.png\" alt=\"그림1\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_4.png\" alt=\"그림2\"\u003e\u003c/p\u003e\n\u003cp\u003e그래서, f2_u는 0.1031 + 0.0799\u003cem\u003ex + 0.0091\u003c/em\u003ex² - 0.0003*x³입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eUnconstrained model layer 2: y_pred_u = g_u(f1_u, f2_u); g_u is linear\ny_pred_u ~ 7.16 + 2.66\u003cem\u003ex + 2.31\u003c/em\u003ex² - 0.023*x³\u003c/p\u003e\n\u003ch2\u003eConstrained model\u003c/h2\u003e\n\u003cp\u003eConstrained model layer 1: f1_c, f2_c = f_c(x)\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_5.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_6.png\" alt=\"Image 1\"\u003e\u003c/p\u003e\n\u003cp\u003eHence, f1_c ~ 0.5 + 0.044\u003cem\u003ex - 0.00005\u003c/em\u003ex²\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_7.png\" alt=\"Image 2\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective_8.png\" alt=\"Image 3\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e따라서, f2_c ~ 0.2237 + 0.0676\u003cem\u003ex + 0.0041\u003c/em\u003ex² - 0.0002*x³\u003c/p\u003e\n\u003cp\u003e제한된 모델 레이어 2: y_pred_c = g_c(f1_c, f2_c); g_c는 선형입니다.\ny_pred_c ~ 2.95 + 6.4\u003cem\u003ex + 2.79\u003c/em\u003ex² - 0.134*x³\u003c/p\u003e\n\u003cp\u003e참고: 실습에 포함된 추가 진단은 수행되었지만, 간결함을 위해 이 글에서는 생략되었습니다. 이러한 진단에 관심이 있는 독자는 다음 스크립트를 실행해주세요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e제한된 모델을 위한 test_quadratic.py\u003c/li\u003e\n\u003cli\u003e제한되지 않은 모델을 위한 test_quadratic_unconstrained.py\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e추가적인 추론\u003c/h2\u003e\n\u003cp\u003e참고: *로 표시된 추론은 세 논문 중 어느 것에도 입증되지 않았지만 이론적으로나 경험적으로 보여질 수 있으며, **로 표시된 추론은 향후 논문을 위한 가능성 있는 후보들이다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e비제약 모델에 대해 f1_u와 f2_u 모두 조각선형 함수 형태\u003cem\u003e를 띄며 ReLU와 유사하다\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003e제약이 있는 모델과 제약이 없는 모델에 대해 이차적합을 강제하면 다음과 같은 형태가 나온다:\ny_pred_u ~ 7.22 + 2.18\u003cem\u003ex + 2.31\u003c/em\u003ex²\ny_pred_c ~ 3.56 + 1.98\u003cem\u003ex + 2.72\u003c/em\u003ex²\u003c/li\u003e\n\u003cli\u003e최종 가중치가 크게 다르더라도 두 모델의 훈련 오차 차이가 크지 않다. 그러므로 MSE vs. (w1, w2, W1, W2)의 곡선은 모델의 가중치 사이에 오랜 기울기를 보인다**.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e제약이 있는 모델은 (MSE 및 모델 계수가 실제 모델과 얼마나 가까운지) 자유로운 모델보다 훨씬 더 일반화되는 것으로 보입니다. 이 논리를 심층 신경망에서 오버피팅을 넘어서는 일반화에 적용한다면 - 모델 아키텍처가 충분히 좋은 귀납적 편향이라고 가정하면,\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e초기 오버피팅은 가중치 벡터가 초기화된 지점에서 최단 경로(최적화 알고리즘이 지배하는)를 통해 먼저 '가능한 해'로 수렴하기 때문에 발생할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e그 이후에 발생하는 일반화가 더 나은 해로의 전이는 최적화 알고리즘이 가중치 벡터를 (오차 측정, 가중치의) 공간에서 새로운 영역으로 완전히 이동시키도록 강요하기 때문으로 설명될 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-Manufacturingpolynomialsusingasigmoidneuralnetworkanewlookfromageneralizationperspective"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>