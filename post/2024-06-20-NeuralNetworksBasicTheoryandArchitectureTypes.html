<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>신경망 기본 이론과 구조 유형 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="신경망 기본 이론과 구조 유형 | itposting" data-gatsby-head="true"/><meta property="og:title" content="신경망 기본 이론과 구조 유형 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes" data-gatsby-head="true"/><meta name="twitter:title" content="신경망 기본 이론과 구조 유형 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-20 19:07" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-0fd008072af5a644.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">신경망 기본 이론과 구조 유형</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="신경망 기본 이론과 구조 유형" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 20, 2024</span><span class="posts_reading_time__f7YPP">22<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>이 이야기에서는 신경망의 이론적 기초와 이로부터 파생된 기술, 그리고 PyTorch를 사용한 구현의 가장 중요한 측면을 높은 수준에서 리뷰하고 설명해보려고 합니다. 가능한 간단한 언어를 사용하여 설명하겠습니다. 또한 다른 문서에서 문서화한 사용 사례 예시를 소개할 예정입니다.</p>
<p>신경망은 이름 그대로 뉴런으로 구성된 복잡한 시스템입니다. 이 네트워크의 힘은 이 인공 뉴런들 간의 상호 연결에서 나옵니다. 이러한 NN 알고리즘은 생물학적 시스템을 모방한다고 합니다.</p>
<h1>뉴런:</h1>
<p>신경망의 핵심은 뉴런입니다. 뉴런은 단순히 입력(변수) 집합을 받아 선형 및 비선형 변환을 적용하고 수학적 다변수 함수처럼 출력을 생성하는 수학 도구입니다.</p>
<p>첫 번째 레이어의 뉴런들에 대한 입력은 원래 세트의 데이터입니다. 각 샘플은 네트워크에 의해 독립적으로 동일한 방식으로 처리됩니다.</p>
<p>네트워크의 기본 구조는 다음과 같습니다: 각각의 뉴런으로 구성된 여러 레이어로, 각 레이어마다 독립적으로 구성됩니다. 첫 번째 레이어는 데이터 원본에서 공급받고, 마지막 레이어는 출력으로 공급하며, 중간 레이어는 이전 레이어에서 공급받고 다음 레이어로 이어집니다.</p>
<p>일부 아키텍처는 레이어 간에 변형을 추가하거나 피드백 루프를 도입한 이 모델에 변형을 도입할 수 있습니다. 나중에 이에 대해 논의할 예정입니다.</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_1.png" alt="Neural Networks Basic Theory and Architecture Types 1"></p>
<p>각 뉴런은 선형 부분과 비선형 부분으로 구성됩니다. 선형 부분은 표준 선형 방정식이며, 비선형 변환은 네트워크 및 층에 따라 다를 수 있습니다.</p>
<p>구체적으로, 레이어는 입력 벡터(크기 n)로 구성되며, 이는 가중치 행렬(크기 nxm, 여기서 n은 입력의 크기이고 m은 레이어의 뉴런 수입니다)에 의해 곱해지고 결과는 크기 m인 다른 벡터로 반환됩니다. 이 결과는 자유 매개 변수 벡터에 추가됩니다. 전체 결과는 비선형 함수를 통해 전달되며, 이를 활성화 함수라고 합니다.이 프로세스의 출력은 다음 레이어로 전달됩니다.</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_2.png" alt="Neural Networks Basic Theory and Architecture Types 2"></p>
<p>또는 구체적으로:</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_3.png" alt="Neural Networks Basic Theory and Architecture Types"></p>
<p>이 시스템이 얼마나 복잡해질 수 있는지를 보여주기 위해, 두 번째 층의 출력에서 수식이 어떻게 보일지 알아보겠습니다:</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_4.png" alt="Neural Networks Basic Theory and Architecture Types"></p>
<p>실제 출력(목표 변수)를 재현하는 최적의 가중치와 자유 매개변수 값을 찾는 것이 바로 이어지는 교육 과정의 전부적인 목적입니다. 원본 값과 예측된 값 사이의 차이를 측정하기 위해 손실 함수를 도입합니다. 이로써, 모든 신경망은 근본적으로 지도 회귀 문제로 전환됩니다.</p>
<p>활성화 함수는 다양한 사용 사례를 충족하는 함수 세트에서 선택됩니다. 높은 수준에서 가장 많이 사용되는 것은 ReLU(0보다 큰 값을 유지하며 음수는 0으로 설정), Sigmoid 및 Tanh입니다.</p>
<h1>학습 과정:</h1>
<p>언급했듯이, 각 계층별로 많은 매개변수의 최적 값을 찾는 것이 목표입니다. 이를 위해 예측된 Y와 실제 Y 간의 관계를 나타내는 함수(손실 함수)가 선택됩니다. 최적화 문제와 마찬가지로 목표는 이 기능이 최소값일 때의 지점을 찾기 위해 고정됩니다. 일부 손실 함수의 예는 평균 제곱 오차, 제곱근 평균 제곱 오차, 평균 절대 오차 및 이진 교차 엔트로피가 있습니다.</p>
<p>최적화 문제를 해결하는 데 사용된 알고리즘은 그래디언트 강하법의 변형으로, 이는 다변수 적용에서 함수의 최소값을 찾는 전형적인 미적분 문제의 수치 구현입니다. 알고리즘은 각 반복에서 함수의 그래디언트 값을 추정하고 다음과 같은 방식으로 매개변수를 업데이트합니다:</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_5.png" alt="image"></p>
<p>이 프로세스는 주어진 반복 횟수(에폭)만큼 반복되며, 각 실행에서 손실 값이 감소하는지 확인합니다.</p>
<p>학습 속도는 미리 설정해야 하는 하이퍼파라미터입니다. 학습 속도에 대한 중요한 사항은 너무 높게 설정해서는 안 된다는 것입니다. 그렇지 않으면 손실 값이 진동을 시작하고 결코 함수의 최소값을 찾지 못할 수 있습니다.</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_6.png" alt="Neural Networks Theory"></p>
<p>일반적으로 매개변수는 무작위 변수를 사용하여 초기화됩니다. 이 변수는 가우시안 분포를 따릅니다. 모든 입력이 독립적이며 레이어에 무한 개수의 뉴런이 있는 이상적인 경우에는 출력과 훈련된 매개변수도 가우시안 분포를 형성합니다.</p>
<p>이러한 분포는 매개변수, 변수 또는 출력으로 형성된 다변량 공간 상의 파형패킷으로 볼 수 있습니다. 이는 양자장론에서 자유 입자를 모델링하기 위해 사용되는 수학적 구조와 유사합니다. 양자장론에서 상호작용으로 나타나는 작은 편차가 있는 것과 같이, 신경망에서는 변수간의 종속성과 레이어 당 유한 개수의 뉴런 삽입에 의해 생성됩니다. 특히, 네트워크 구성원 간의 내부 또는 보이지 않는 구조에 의해 생성되는 이러한 편차는 시스템의 예측력의 원천입니다. 그러나 이러한 편차가 너무 커지면 시스템이 발산하여 혼돈스럽게 됩니다.</p>
<p>양자장론과 마찬가지로, 자유(가우시안) 경우에서의 작은 편차로 인한 문제들에 대한 수학적 해석을 위해 섭동 이론을 사용할 수 있습니다. 물리적 입자간의 상호작용을 이해하는 데 사용되는 수학은 신경망의 내부 동작을 이해하는 데 활용됩니다.</p>
<p>이 접근 방식에 대해 더 읽고 싶다면 원본 논문을 참고할 수 있어요: [2307.03223] Neural Network Field Theories: Non-Gaussianity, Actions, and Locality (arxiv.org)</p>
<p>다시 본론으로 돌아와서, 신경망을 설계할 때 결정되어야 할 여러 가지 결정 사항 또는 하이퍼파라미터가 있어요. 이들은 다음과 같아요:</p>
<ul>
<li>각 층의 입력과 출력 수, 단, 첫 번째 층의 입력은 변수의 수, 마지막 층의 출력은 해결할 문제의 성격에 따라 정해지며 각 내부 또는 숨겨진 층의 출력은 다음 층의 입력이에요.</li>
<li>신경망의 층 수.</li>
<li>각 층의 활성화 함수.</li>
<li>손실 함수.</li>
<li>기울기 알고리즘.</li>
<li>학습률.</li>
<li>아키텍처(다음 세그먼트에서 탐구할 사항)</li>
</ul>
<p>다음으로, 가장 일반적인 신경망 아키텍처 몇 가지, 각각의 고수준 설명, 및 샘플 사용 사례를 살펴볼게요.</p>
<p>만약 신경망과 기계 학습 내부의 수학을 더 잘 이해하고 싶다면 Ian Goodfellow, Yoshua Bengio, 그리고 Aaron Courville의 책을 참고하실 수 있어요. 해당 책은 Deep Learning (deeplearningbook.org)에서 구할 수 있어요. 그리고, Goodfellow은 적대적 생성 신경망(Generative Adversarial Networks)의 발명과도 함께 언급되어 있어요.</p>
<h1>다중 계층 퍼셉트론 (MLP)</h1>
<p>이것은 신경망의 가장 기본적인 아키텍처이며, 각 계층이 이전 계층에 의존하는 선형 구조로 형성되어 있어요. 또한 변수들 사이의 특정한 관계를 고려하지 않아요. MLP는 예측 변수들이 서로 의존하지 않는 문제에서 유용하게 사용됩니다. 예를 들어, 나이, 연봉, 교육 또는 성별과 같은 요소로 구성된 데이터셋에 대해요.</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_7.png" alt="Neural Networks Basic Theory and Architecture Types"></p>
<p>아래 코드 블록은 PyTorch 패키지를 사용하여 Python에서 다층 퍼셉트론을 정의한 샘플입니다:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn

<span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleClassifier</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-built_in">super</span>(SimpleClassifier, self).__init__()
<span class="hljs-comment">#과적합을 줄이기 위해 드롭아웃 레이어를 도입합니다.</span>
<span class="hljs-comment">#드롭아웃은 신경망에게 층 사이의 데이터를 무작위로 삭제하여 변동성을 도입하도록 지시합니다.</span>
        self.dropout = nn.Dropout(<span class="hljs-number">0.1</span>)
<span class="hljs-comment">#레이어는 열의 두 배 정도로 시작하고 다음 레이어로 증가한 다음 다시 2로 감소하는 것을 권장합니다.</span>
<span class="hljs-comment">#이 경우 응답은 이진입니다.</span>
        self.layers = nn.Sequential(
            nn.Linear(input_size, <span class="hljs-number">250</span>),
            nn.Linear(<span class="hljs-number">250</span>, <span class="hljs-number">500</span>),
            nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">1000</span>),
            nn.Linear(<span class="hljs-number">1000</span>, <span class="hljs-number">1500</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">1500</span>, <span class="hljs-number">1500</span>),
            nn.Sigmoid(),
            self.dropout,
            nn.Linear(<span class="hljs-number">1500</span>, <span class="hljs-number">1500</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">1500</span>, <span class="hljs-number">1500</span>),
            nn.Sigmoid(),
            self.dropout,
            nn.Linear(<span class="hljs-number">1500</span>, <span class="hljs-number">1500</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">1500</span>, <span class="hljs-number">1500</span>),
            nn.Sigmoid(),
            self.dropout,
            nn.Linear(<span class="hljs-number">1500</span>, <span class="hljs-number">1500</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">1500</span>, <span class="hljs-number">500</span>),
            nn.Sigmoid(),
            self.dropout,
            nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">500</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">500</span>),
            nn.Sigmoid(),
            self.dropout,
<span class="hljs-comment">#마지막 레이어는 응답 변수가 이진(0, 1)이기 때문에 2를 출력합니다.</span>
<span class="hljs-comment">#다중 클래스 분류의 출력은 클래스 수와 같아야 합니다.</span>
            nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">2</span>),
        )

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):
        <span class="hljs-keyword">return</span> self.layers(x)

<span class="hljs-comment">#모델 정의</span>
model = SimpleClassifier()
</code></pre>
<p>이 모델을 사용한 전형적인 학습 루프는 다음 블록에서 나타납니다:</p>
<pre><code class="hljs language-python"><span class="hljs-comment">#모델 로드</span>
model = SimpleClassifier()
model.train()

<span class="hljs-comment">#학습 파라미터(사이클 수 및 학습률)입니다.</span>
num_epochs = <span class="hljs-number">100</span>
learning_rate = <span class="hljs-number">0.00001</span>
<span class="hljs-comment">#과적합을 줄이기 위해</span>
regularization = <span class="hljs-number">0.0000001</span>

<span class="hljs-comment">#손실 함수</span>
criterion = nn.CrossEntropyLoss()

<span class="hljs-comment">#기울기를 찾는 알고리즘</span>
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=regularization)

<span class="hljs-comment">#이 코드는 학습 루프를 수행하는 동안 최상의 모델을 유지합니다.</span>
best_model_wts = copy.deepcopy(model.state_dict())
best_acc = <span class="hljs-number">0.0</span>
best_f1 = <span class="hljs-number">0.0</span>
best_epoch = <span class="hljs-number">0</span>
phases = [<span class="hljs-string">'train'</span>, <span class="hljs-string">'val'</span>]
training_curves = {}
epoch_loss = <span class="hljs-number">1</span>
epoch_f1 = <span class="hljs-number">0</span>
epoch_acc = <span class="hljs-number">0</span>

<span class="hljs-comment">#데이터셋은 학습, 검증 및 테스트로 분할됩니다.</span>
<span class="hljs-keyword">for</span> phase <span class="hljs-keyword">in</span> phases:
    training_curves[phase+<span class="hljs-string">'_loss'</span>] = []
    training_curves[phase+<span class="hljs-string">'_acc'</span>] = []
    training_curves[phase+<span class="hljs-string">'_f1'</span>] = []

<span class="hljs-comment">#이것은 학습 루프입니다.</span>
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'\n에포크 <span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>/<span class="hljs-subst">{num_epochs}</span>'</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'-'</span> * <span class="hljs-number">10</span>)
    <span class="hljs-keyword">for</span> phase <span class="hljs-keyword">in</span> phases:
        <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'train'</span>:
            model.train()
        <span class="hljs-keyword">else</span>:
            model.<span class="hljs-built_in">eval</span>()
        running_loss = <span class="hljs-number">0.0</span>
        running_corrects = <span class="hljs-number">0</span>
        running_fp = <span class="hljs-number">0</span>
        running_tp = <span class="hljs-number">0</span>
        running_tn = <span class="hljs-number">0</span>
        running_fn = <span class="hljs-number">0</span>
        <span class="hljs-comment">#데이터 반복</span>
        <span class="hljs-keyword">for</span> inputs, labels <span class="hljs-keyword">in</span> dataloaders[phase]:
            inputs = inputs.view(inputs.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)
            inputs = inputs
            labels = labels

            <span class="hljs-comment">#매개변수의 기울기를 0으로 설정</span>
            optimizer.zero_grad()

            <span class="hljs-comment">#순방향 패스 (위의 차트 참조)</span>
            <span class="hljs-keyword">with</span> torch.set_grad_enabled(phase == <span class="hljs-string">'train'</span>):
                outputs = model(inputs)
                _, predictions = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)
                loss = criterion(outputs, labels)

                <span class="hljs-comment">#역방향 패스 (학습 중에만)</span>
                <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'train'</span>:
                    loss.backward()
                    optimizer.step()

                <span class="hljs-comment">#통계. f1 메트릭을 사용합니다.</span>
                running_loss += loss.item() * inputs.size(<span class="hljs-number">0</span>)
                running_corrects += torch.<span class="hljs-built_in">sum</span>(predictions == labels.data)
                running_fp += torch.<span class="hljs-built_in">sum</span>((predictions != labels.data) &#x26; (predictions >= <span class="hljs-number">0.5</span>))
                running_tp += torch.<span class="hljs-built_in">sum</span>((predictions == labels.data) &#x26; (predictions >= <span class="hljs-number">0.5</span>))
                running_fn += torch.<span class="hljs-built_in">sum</span>((predictions != labels.data) &#x26; (predictions &#x3C; <span class="hljs-number">0.5</span>))
                running_tn += torch.<span class="hljs-built_in">sum</span>((predictions == labels.data) &#x26; (predictions &#x3C; <span class="hljs-number">0.5</span>))
                <span class="hljs-built_in">print</span>(<span class="hljs-string">f'에포크 <span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>, <span class="hljs-subst">{phase:<span class="hljs-number">5</span>}</span> 손실: <span class="hljs-subst">{epoch_loss:<span class="hljs-number">.7</span>f}</span> F1: <span class="hljs-subst">{epoch_f1:<span class="hljs-number">.7</span>f}</span> 정확도: <span class="hljs-subst">{epoch_acc:<span class="hljs-number">.7</span>f}</span> 부분 손실: <span class="hljs-subst">{loss.item():<span class="hljs-number">.7</span>f}</span> 최상의 f1: <span class="hljs-subst">{best_f1:<span class="hljs-number">.7</span>f}</span>'</span>)

        <span class="hljs-comment">#손실, 정확도 및 f1 메트릭 계산</span>
        epoch_loss = running_loss / dataset_sizes[phase]
        epoch_acc = running_corrects.double() / dataset_sizes[phase]
        epoch_f1 = (<span class="hljs-number">2</span> * running_tp.double()) / (<span class="hljs-number">2</span> * running_tp.double() + running_fp.double() + running_fn.double() + <span class="hljs-number">0.0000000000000000000001</span>)
        training_curves[phase+<span class="hljs-string">'_loss'</span>].append(epoch_loss)
        training_curves[phase+<span class="hljs-string">'_acc'</span>].append(epoch_acc)
        training_curves[phase+<span class="hljs-string">'_f1'</span>].append(epoch_f1)

        <span class="hljs-built_in">print</span>(<span class="hljs-string">f'에포크 <span class="hljs-subst">{epoch+<span class="hljs-number">1</span>}</span>, <span class="hljs-subst">{phase:<span class="hljs-number">5</span>}</span> 손실: <span class="hljs-subst">{epoch_loss:<span class="hljs-number">.7</span>f}</span> F1: <span class="hljs-subst">{epoch_f1:<span class="hljs-number">.7</span>f}</span> 정확도: <span class="hljs-subst">{epoch_acc:<span class="hljs-number">.7</span>f}</span> 최상의 f1: <span class="hljs-subst">{best_f1:<span class="hljs-number">.7</span>f}</span>'</span>)

        <span class="hljs-keyword">if</span> phase == <span class="hljs-string">'val'</span> <span class="hljs-keyword">and</span> epoch_f1 >= best_f1:
            best_epoch = epoch
            best_acc = epoch_acc
            best_f1 = epoch_f1
            best_model_wts = copy.deepcopy(model.state_dict())

<span class="hljs-built_in">print</span>(<span class="hljs-string">f'최상의 val F1: <span class="hljs-subst">{best_f1:5f}</span>, 최상의 val 정확도: <span class="hljs-subst">{best_acc:5f}</span>, 에포크 <span class="hljs-subst">{best_epoch}</span>'</span>)

<span class="hljs-comment">#최상의 모델 가중치로드</span>
model.load_state_dict(best_model_wts)
</code></pre>
<p>아래의 글에서는 실제 데이터를 사용하여 MLP를 구현한 예시를 확인할 수 있습니다: <a href="https://medium.com" rel="nofollow" target="_blank">Neural Networks와 Pytorch를 사용하여 자동 복구 실패 예측하기 (저자: Greg Postalian-Yrausquin | 2024년 6월 | Towards AI (medium.com)</a></p>
<p>더 많은 정보는 위키피디아 페이지에서 찾을 수 있습니다: <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" rel="nofollow" target="_blank">다층 퍼셉트론 (Multilayer perceptron) — Wikipedia</a></p>
<h1>합성곱 신경망 (CNN):</h1>
<p>전형적인 다층 퍼셉트론은 입력이 필드인 경우 성능이 좋지 않습니다. 여기서 필드란 점들 간의 관계(함수, 연속성을 통해)가 있는 구조를 말합니다. 예를 들어, 금속 판의 온도는 한 지점에 열원이 연결되어 있는 경우 열원에서 더 멀리 있는 위치로 갈수록 그래디언트를 따를 것입니다. 이 2차원 예시에서 표면의 온도는 그리드(행렬)로 나타낼 수 있습니다:</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_8.png" alt="image"></p>
<p>이러한 구조들은 3D일 수도 있습니다 (여러 개가 서로 위에 쌓인 것을 상상해보세요) 또는 우리가 원하는 대로 복잡할 수 있습니다. MLPs는 훈련 중에 데이터의 내부 구조를 잃어버리므로 이를 모델링하는 데 좋지 않습니다. 그와는 반대로 CNNs는 원래의 관계를 보존합니다.</p>
<p>Python에서는 이미지가 행렬로 저장됩니다. 여기서 행과 열은 위치를 나타내고 숫자는 강도를 측정하는 값입니다. 컬러 이미지의 경우 각 이미지에 대해 RGB 색상 인코딩 형식에 대한 값을 저장하는 3개의 행렬이 사용됩니다. 수학에서 이러한 다차원 행렬은 Tensor라고 불리며 벡터 함수로도 볼 수 있습니다 (출력이 벡터의 모양으로 나오는 것), 이 경우 출력 벡터의 좌표는 RGB 색상값입니다.</p>
<p>이러한 이유로 CNN은 이미지 및 비디오 데이터를 모델링하는 데 널리 사용됩니다. CNN의 아이콘은 이미지 분류입니다. 이 기사에서는 그 목적으로 CNN 사용 예제를 볼 수 있습니다: Convolutional Neural Networks in PyTorch: Image Classification | by Greg Postalian-Yrausquin | Jun, 2024 | Towards AI (medium.com).</p>
<p>합성곱 신경망은 네트워크 내에 하나 이상의 합성 계층이 존재하는 것으로 정의됩니다. 이들은 데이터 내부에서 창 또는 행렬(커널)을 슬라이딩하여 원소별 곱셈을 수행하고 커널 내부 값의 합을 구하는 수학 연산입니다. 패딩을 도입하여 원래 데이터 매트릭스 크기의 축소를 고려할 수 있습니다.</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_9.png" alt="CNN Architecture"></p>
<p>CNN에는 다른 종류의 계층도 소개되는데, 예를 들면: Max pool (지도의 일부분의 최대값을 얻어 데이터 크기를 줄임), flatten (데이터 매트릭스를 벡터로 변환하여 네트워크 끝에 사용되거나 표준 네트워크로 계속해서 훈련) 및 unflatten (이전 과정을 역으로 수행).</p>
<p>다음 샘플 코드는 PyTorch에서 CNN 클래스의 정의입니다:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> torch.nn.modules.flatten <span class="hljs-keyword">import</span> Flatten
<span class="hljs-keyword">class</span> <span class="hljs-title class_">CNNClassifier</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-built_in">super</span>(CNNClassifier, self).__init__()
        self.dropout = nn.Dropout(<span class="hljs-number">0.05</span>)
        self.pipeline = nn.Sequential(
            <span class="hljs-comment">#in channels is 1, because the input is grayscale</span>
            nn.Conv2d(in_channels = <span class="hljs-number">1</span>, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.ReLU(),
            nn.Conv2d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.ReLU(),
            nn.Conv2d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.ReLU(),
            nn.Conv2d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">5</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.ReLU(),
            <span class="hljs-comment">#dropout to introduce randomness and reduce overfitting</span>
            self.dropout,
            <span class="hljs-comment">#reduce and flat the tensor before applying the flat layers</span>
            nn.MaxPool2d(kernel_size = <span class="hljs-number">2</span>, stride = <span class="hljs-number">2</span>),
            nn.Flatten(),
            nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">50</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">50</span>, <span class="hljs-number">50</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">50</span>, <span class="hljs-number">10</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>),
            nn.ReLU(),
            self.dropout,
            nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">5</span>),
        )

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):
        <span class="hljs-keyword">return</span> self.pipeline(x)

model = CNNClassifier()
</code></pre>
<p>CNN에 대해 더 자세히 알아보기 좋은 정보를 찾는 것을 시작하는 데 좋은 곳인 Wikipedia의 CNN에 대한 항목을 찾았어요: <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="nofollow" target="_blank">Convolutional neural network — Wikipedia</a></p>
<h1>오토인코더</h1>
<p>아키텍처의 하위 클래스로 오토인코더가 있습니다. 입력과 출력의 수가 동일한 특정 구성으로 상상할 수 있습니다. 모델은 입력된 데이터를 재현하는 방법을 학습하도록 구성되어 있으며 한 개 이상의 숨겨진 레이어를 통해 통과합니다.</p>
<p>모델은 두 부분으로 설계되어 있습니다. 입력을 다른 표현으로 변환하는 Encoder와 이 표현을 기반으로 입력의 버전을 재구성하는 Decoder입니다. 아이디어는 재구성이 초기 데이터와 가능한 한 유사해야 한다는 것입니다.</p>
<p>이 네트워크에서 목표는 동일한 입력 데이터이기 때문에 이들은 사실상 감독되지 않은 학습 방법입니다. 예를 들어 Autoencoder 아키텍처는 생성적 AI 작업의 일부로 사용됩니다.</p>
<p>자연어 처리(NLP)에서 오토인코더는 단어 또는 문장의 임베딩(표현)을 생성하는 데 사용됩니다. 이 텍스트의 숫자 표현은 그 후 분류, 거리 계산 등과 같은 하향 작업에서 사용됩니다.</p>
<p>NLP에서 오토인코더를 사용하는 한 가지 훌륭한 방법은 다음과 같습니다:</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_10.png" alt="Neural Network Example"></p>
<p>이 문서에서는 오토인코더의 정의 예시를 찾을 수 있습니다: Neural networks: encoder-decoder example (autoencoder) | 작성자 Greg Postalian-Yrausquin | 날짜 2024년 6월 | Medium. 여기서 모델이 이미지를 재구성하는 데 사용됩니다.</p>
<pre><code class="hljs language-js"># 훈련 이미지의 채널 수. 컬러 이미지의 경우 <span class="hljs-number">3</span>개입니다
nc = <span class="hljs-number">3</span>

# 표현의 크기
nr = <span class="hljs-number">1000</span>

# 디코더의 시작점의 크기
nz = <span class="hljs-number">50</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">Encdec</span>(nn.<span class="hljs-property">Module</span>):
    def <span class="hljs-title function_">__init__</span>(self, nc, nz, nr):
        <span class="hljs-variable language_">super</span>(<span class="hljs-title class_">Encdec</span>, self).<span class="hljs-title function_">__init__</span>()
# 이것이 인코더입니다
        self.<span class="hljs-property">encoder</span> = nn.<span class="hljs-title class_">Sequential</span>(
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = nc, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">1</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">Flatten</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">2916</span>, <span class="hljs-number">3000</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">3000</span>, <span class="hljs-number">1000</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">1000</span>, nr),
         )
# 이것이 디코더입니다
        self.<span class="hljs-property">decoder</span> = nn.<span class="hljs-title class_">Sequential</span>(
            nn.<span class="hljs-title class_">Linear</span>(nr, <span class="hljs-number">1000</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">1000</span>, <span class="hljs-number">500</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">500</span>, nz*<span class="hljs-number">64</span>*<span class="hljs-number">64</span>),
            nn.<span class="hljs-title class_">Unflatten</span>(<span class="hljs-number">1</span>, torch.<span class="hljs-title class_">Size</span>([nz, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>])),
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = nz, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = <span class="hljs-number">10</span>, out_channels = <span class="hljs-number">10</span>, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Conv2</span>d(in_channels = <span class="hljs-number">10</span>, out_channels = nc, kernel_size = <span class="hljs-number">5</span>, stride = <span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Flatten</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">10092</span>, <span class="hljs-number">2000</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">2000</span>, <span class="hljs-number">1000</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">1000</span>, <span class="hljs-number">500</span>),
            nn.<span class="hljs-title class_">ReLU</span>(),
            nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">500</span>, nc*<span class="hljs-number">64</span>*<span class="hljs-number">64</span>),
            nn.<span class="hljs-title class_">Unflatten</span>(<span class="hljs-number">1</span>, torch.<span class="hljs-title class_">Size</span>([nc, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>])),
            nn.<span class="hljs-title class_">Tanh</span>()
         )

    def <span class="hljs-title function_">encode</span>(self, x):
        <span class="hljs-keyword">return</span> self.<span class="hljs-title function_">encoder</span>(x)

    def <span class="hljs-title function_">decode</span>(self, x):
        <span class="hljs-keyword">return</span> self.<span class="hljs-title function_">decoder</span>(x)

    def <span class="hljs-title function_">forward</span>(self, input):
        <span class="hljs-keyword">return</span> self.<span class="hljs-title function_">decoder</span>(self.<span class="hljs-title function_">encoder</span>(input))

netEncDec = <span class="hljs-title class_">Encdec</span>(nc, nz, nr)
</code></pre>
<p>자세한 내용은 위키피디아에서 오토인코더 아키텍처에 대해 더 알아보기 시작점으로 참조할 수 있습니다: <a href="https://ko.wikipedia.org/wiki/%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94" rel="nofollow" target="_blank">오토인코더 - 위키백과</a></p>
<p>인코더-디코더 메커니즘의 일반적이고 잘 알려진 구현은 트랜스포머 입니다. 이 아키텍처는 2017년 구글의 데이터 과학자들이 발표한 “Attention is all you need” [1706.03762] 논문에서 소개되었습니다. 트랜스포머는 NLP에서 널리 사용되며, 입력 및 출력 집합에 대한 임베딩 생성부터 시작하여 여러 단계로 구성됩니다. 이 집합 모두에 대해 위치 정보를 유지할 수 있도록 처리된 후에, 초기 오토인코더에는 포함되어 있지 않은 단계가 포함됩니다. 이는 반복의 오버헤드 없이 RNN과 동일한 이점을 제공합니다. 그 다음 데이터는 인코딩 프로세스(어텐션 스택)를 거치고, 디코딩 단계(두 번째 어텐션 스택)에서 출력과 비교됩니다. 마지막 단계는 소프트맥스 변환을 적용하는 것입니다.</p>
<p><img src="/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_11.png" alt="트랜스포머 아키텍처"></p>
<p>트랜스포머 아키텍처: 원본 논문 "Attention is all you need"에서 가져온 다이어그램입니다.</p>
<p>전이 학습 패러다임의 매우 흥미로운 그리고 유용한 구현 중 하나는 Google이 만든 BERT(Bidirectional Encoder Representations for Transformers)입니다. 영어 처리를 위해 트랜스포머를 처음부터 훈련하는 것은 거대한 작업이 될 수 있지만 다행히도 다양한 용도에 맞게 사전 훈련된 모델을 다운로드하고 적용할 수 있습니다 (이러한 모델을 다운로드하고 적용하는 방법은 Huggingface 페이지를 참조하세요): 모델 다운로드 (huggingface.co)</p>
<h1>순환 신경망:</h1>
<p>RNN은 신경망의 비선형 시도로 간주될 수 있습니다. RNN에서는 한 레이어가 자신에게 영향을 미칠 수 있습니다 (역행 효과가 있습니다). 이 작용은 시퀀스 형식으로 된 데이터를 모델링하는 데 이상적이라고 할 수 있습니다. 이러한 데이터의 가장 좋은 예는 텍스트 스트림이며, 그 이유로 NLP에서 가장 효율적인 트랜스포머가 도입될 때까지 주로 사용되었습니다. RNN은 음성 및 필기 인식에도 구현되어 있습니다.</p>
<p>RNN(순환 신경망)은 계산적으로 요구가 높을 수 있는 것 외에, 비선형성에 의해 확대되는 전파 오류와 실제로 이전 단계의 매우 짧은 메모리를 유지하는 사라져버리는 그래디언트와 같은 다른 문제가 있습니다. 이러한 문제를 해결하기 위해 LSTM(Long-Short Term Memory) 및 GRU(Gated Recurrent Units)와 같은 RNN 아키텍처의 더 복잡한 파생물이 소개되었습니다.</p>
<p>RNN의 응용 예는 다음 글에서 소개됩니다: RNN: PyTorch에서 Sentiment Analysis를 위한 기본 순환 신경망 | Greg Postalian-Yrausquin 저 | 2024년 6월 | Towards AI (medium.com)</p>
<p>PyTorch에서 이 네트워크의 정의는 다음과 같습니다:</p>
<pre><code class="hljs language-python"><span class="hljs-comment"># 신경망의 정의입니다. 보시다시피 RNN 정의 하나만 있습니다.</span>
<span class="hljs-comment"># 2개의 레이어와 하나의 선형 레이어가 포함됩니다.</span>
<span class="hljs-comment"># 오버피팅을 방지하기 위해 드롭아웃 및 정규화가 도입되었습니다</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">RNNClassifier</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size</span>):
        <span class="hljs-built_in">super</span>(RNNClassifier, self).__init__()
        self.hidden_size = hidden_size
        self.RNN = nn.RNN(input_size, hidden_size, num_layers=<span class="hljs-number">2</span>, dropout=<span class="hljs-number">0.2</span>)
        self.fc = nn.Linear(hidden_size, output_size)
        <span class="hljs-keyword">pass</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):
        output, hn = self.RNN(<span class="hljs-built_in">input</span>)
        output = self.fc(output)
        <span class="hljs-keyword">return</span> output, hn

model = RNNClassifier(insize, <span class="hljs-number">8</span>, <span class="hljs-number">2</span>)
</code></pre>
<h1>생성 적대 신경망 (Generative Adversarial Networks, GAN):</h1>
<p>이것은 MLP, RNN 또는 CNN들의 조합에서 형성될 수 있는 또 다른 복합 아키텍처입니다. 2014년 Ian Goodfellow와 그의 동료들에 의해 작성되었습니다 (원본 논문은 Generative Adversarial Nets (nips.cc)에서 확인할 수 있으며 [1701.00160] NIPS 2016 Tutorial: Generative Adversarial Networks (arxiv.org)에서 튜토리얼을 참조할 수 있습니다). GAN은 두 가지 다른 모델이 훈련되는 매우 똑똑한 신경망 응용 프로그램으로, 하나는 원래 데이터셋을 기반으로 샘플을 생성하는 것을 목표로하고 다른 하나는 이 첫 번째 모델에 대항하여 샘플이 실제인지 가짜인지를 추측합니다.</p>
<p>GAN은 생성적 AI 작업(모델을 기반으로 실제 데이터를 생성하는 것)에 사용됩니다. 텍스트, 이미지 또는 비디오 생성 등이 해당될 수 있습니다. 자세한 설명은 원본 샘플을 기반으로 새로운 객체를 생성해야 하는 생성자(Generator) 네트워크 및 인공적으로 생성된 샘플과 실제 샘플을 구별하도록 훈련된 구분자(Discriminator)를 포함하고 있습니다. 학습의 여러 반복 후에 구분자가 실제 데이터와 가짜 데이터를 구분하는 데 어려움을 겪도록 함으로써 신뢰할 수 있는 제품 생성을 보장합니다.</p>
<p>이것은 PyTorch에서 두 적대적 신경망에 대한 클래스 정의 샘플입니다:</p>
<h1>트레이닝 이미지 내의 채널 수. 컬러 이미지의 경우, 채널 수는 3입니다.</h1>
<p>nc = 3</p>
<h1>z 잠재 벡터의 크기 (즉, 생성기 입력의 크기)</h1>
<p>nz = 100</p>
<h1>생성기의 특징 맵 크기</h1>
<p>ngf = 64</p>
<h1>판별자의 특징 맵 크기</h1>
<p>ndf = 64</p>
<h1>이것은 진짜와 가짜 이미지를 분리하려는 작업을 수행하는 판별자 네트워크입니다.</h1>
<p>class Discriminator(nn.Module):
def <strong>init</strong>(self, nc, ndf):
super(Discriminator, self).<strong>init</strong>()
self.pipeline = nn.Sequential(</p>
<h1>nc는 3이며, 입력은 텐서 3x64x64(64x64의 컬러 이미지이며, 각 컬러 이미지에는 3개의 텐서가 필요)입니다.</h1>
<pre><code>        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
        nn.LeakyReLU(0.2),
        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
        nn.BatchNorm2d(ndf * 2),
        nn.LeakyReLU(0.2),
        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
        nn.BatchNorm2d(ndf * 4),
        nn.LeakyReLU(0.2),
        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
        nn.BatchNorm2d(ndf * 8),
        nn.LeakyReLU(0.2),
</code></pre>
<h1>출력은 크기가 1인 벡터입니다.</h1>
<pre><code>        nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
        nn.Sigmoid()
    )

def forward(self, input):
    return self.pipeline(input)
</code></pre>
<p>class Generator(nn.Module):
def <strong>init</strong>(self, nc, nz, ngf):
super(Generator, self).<strong>init</strong>()
self.pipeline = nn.Sequential(</p>
<h1>생성기의 입력은 무작위 생성된 이미지입니다. 이 경우 채널 수가 100이므로 nz는 100입니다.</h1>
<pre><code>        nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),
        nn.BatchNorm2d(ngf * 16),
        nn.ReLU(),
        nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),
        nn.BatchNorm2d(ngf * 8),
        nn.ReLU(),
        nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
        nn.BatchNorm2d(ngf * 4),
        nn.ReLU(),
        nn.ConvTranspose2d(ngf * 4, ngf, 4, 2, 1, bias=False),
        nn.BatchNorm2d(ngf),
        nn.ReLU(),
</code></pre>
<h1>출력은 트레이닝 이미지와 동일한 차원의 이미지입니다. 따라서 출력은 크기가 nc여야 합니다.</h1>
<pre><code>        nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),
        nn.Tanh()
    )

def forward(self, input):
    return self.pipeline(input)
</code></pre>
<p>저는 다음 기사에서 이미지 생성을 위한 GAN을 구현했습니다: GAN: training a Generative Adversarial Network for image generation | by Greg Postalian-Yrausquin | Jun, 2024 | Medium</p>
<p>이것들은 머신 러닝을 위한 신경망의 기본입니다. 하지만 모든 아키텍처에 대한 완전한 설명은 아닙니다. 이 주제는 아주 거대하고 매혹적이며, 새로운 기술과 알고리즘이 지속적으로 등장하고 있는 폭발적인 성장을 이루고 있습니다. 이러한 많은 것들은 이 문서에서 설명된 아키텍처의 수정이나 결합입니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"신경망 기본 이론과 구조 유형","description":"","date":"2024-06-20 19:07","slug":"2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes","content":"\n이 이야기에서는 신경망의 이론적 기초와 이로부터 파생된 기술, 그리고 PyTorch를 사용한 구현의 가장 중요한 측면을 높은 수준에서 리뷰하고 설명해보려고 합니다. 가능한 간단한 언어를 사용하여 설명하겠습니다. 또한 다른 문서에서 문서화한 사용 사례 예시를 소개할 예정입니다.\n\n신경망은 이름 그대로 뉴런으로 구성된 복잡한 시스템입니다. 이 네트워크의 힘은 이 인공 뉴런들 간의 상호 연결에서 나옵니다. 이러한 NN 알고리즘은 생물학적 시스템을 모방한다고 합니다.\n\n# 뉴런:\n\n신경망의 핵심은 뉴런입니다. 뉴런은 단순히 입력(변수) 집합을 받아 선형 및 비선형 변환을 적용하고 수학적 다변수 함수처럼 출력을 생성하는 수학 도구입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_0.png\" /\u003e\n\n첫 번째 레이어의 뉴런들에 대한 입력은 원래 세트의 데이터입니다. 각 샘플은 네트워크에 의해 독립적으로 동일한 방식으로 처리됩니다.\n\n네트워크의 기본 구조는 다음과 같습니다: 각각의 뉴런으로 구성된 여러 레이어로, 각 레이어마다 독립적으로 구성됩니다. 첫 번째 레이어는 데이터 원본에서 공급받고, 마지막 레이어는 출력으로 공급하며, 중간 레이어는 이전 레이어에서 공급받고 다음 레이어로 이어집니다.\n\n일부 아키텍처는 레이어 간에 변형을 추가하거나 피드백 루프를 도입한 이 모델에 변형을 도입할 수 있습니다. 나중에 이에 대해 논의할 예정입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Neural Networks Basic Theory and Architecture Types 1](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_1.png)\n\n각 뉴런은 선형 부분과 비선형 부분으로 구성됩니다. 선형 부분은 표준 선형 방정식이며, 비선형 변환은 네트워크 및 층에 따라 다를 수 있습니다.\n\n구체적으로, 레이어는 입력 벡터(크기 n)로 구성되며, 이는 가중치 행렬(크기 nxm, 여기서 n은 입력의 크기이고 m은 레이어의 뉴런 수입니다)에 의해 곱해지고 결과는 크기 m인 다른 벡터로 반환됩니다. 이 결과는 자유 매개 변수 벡터에 추가됩니다. 전체 결과는 비선형 함수를 통해 전달되며, 이를 활성화 함수라고 합니다.이 프로세스의 출력은 다음 레이어로 전달됩니다.\n\n![Neural Networks Basic Theory and Architecture Types 2](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또는 구체적으로:\n\n![Neural Networks Basic Theory and Architecture Types](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_3.png)\n\n이 시스템이 얼마나 복잡해질 수 있는지를 보여주기 위해, 두 번째 층의 출력에서 수식이 어떻게 보일지 알아보겠습니다:\n\n![Neural Networks Basic Theory and Architecture Types](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실제 출력(목표 변수)를 재현하는 최적의 가중치와 자유 매개변수 값을 찾는 것이 바로 이어지는 교육 과정의 전부적인 목적입니다. 원본 값과 예측된 값 사이의 차이를 측정하기 위해 손실 함수를 도입합니다. 이로써, 모든 신경망은 근본적으로 지도 회귀 문제로 전환됩니다.\n\n활성화 함수는 다양한 사용 사례를 충족하는 함수 세트에서 선택됩니다. 높은 수준에서 가장 많이 사용되는 것은 ReLU(0보다 큰 값을 유지하며 음수는 0으로 설정), Sigmoid 및 Tanh입니다.\n\n# 학습 과정:\n\n언급했듯이, 각 계층별로 많은 매개변수의 최적 값을 찾는 것이 목표입니다. 이를 위해 예측된 Y와 실제 Y 간의 관계를 나타내는 함수(손실 함수)가 선택됩니다. 최적화 문제와 마찬가지로 목표는 이 기능이 최소값일 때의 지점을 찾기 위해 고정됩니다. 일부 손실 함수의 예는 평균 제곱 오차, 제곱근 평균 제곱 오차, 평균 절대 오차 및 이진 교차 엔트로피가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최적화 문제를 해결하는 데 사용된 알고리즘은 그래디언트 강하법의 변형으로, 이는 다변수 적용에서 함수의 최소값을 찾는 전형적인 미적분 문제의 수치 구현입니다. 알고리즘은 각 반복에서 함수의 그래디언트 값을 추정하고 다음과 같은 방식으로 매개변수를 업데이트합니다:\n\n![image](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_5.png)\n\n이 프로세스는 주어진 반복 횟수(에폭)만큼 반복되며, 각 실행에서 손실 값이 감소하는지 확인합니다.\n\n학습 속도는 미리 설정해야 하는 하이퍼파라미터입니다. 학습 속도에 대한 중요한 사항은 너무 높게 설정해서는 안 된다는 것입니다. 그렇지 않으면 손실 값이 진동을 시작하고 결코 함수의 최소값을 찾지 못할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Neural Networks Theory](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_6.png)\n\n일반적으로 매개변수는 무작위 변수를 사용하여 초기화됩니다. 이 변수는 가우시안 분포를 따릅니다. 모든 입력이 독립적이며 레이어에 무한 개수의 뉴런이 있는 이상적인 경우에는 출력과 훈련된 매개변수도 가우시안 분포를 형성합니다.\n\n이러한 분포는 매개변수, 변수 또는 출력으로 형성된 다변량 공간 상의 파형패킷으로 볼 수 있습니다. 이는 양자장론에서 자유 입자를 모델링하기 위해 사용되는 수학적 구조와 유사합니다. 양자장론에서 상호작용으로 나타나는 작은 편차가 있는 것과 같이, 신경망에서는 변수간의 종속성과 레이어 당 유한 개수의 뉴런 삽입에 의해 생성됩니다. 특히, 네트워크 구성원 간의 내부 또는 보이지 않는 구조에 의해 생성되는 이러한 편차는 시스템의 예측력의 원천입니다. 그러나 이러한 편차가 너무 커지면 시스템이 발산하여 혼돈스럽게 됩니다.\n\n양자장론과 마찬가지로, 자유(가우시안) 경우에서의 작은 편차로 인한 문제들에 대한 수학적 해석을 위해 섭동 이론을 사용할 수 있습니다. 물리적 입자간의 상호작용을 이해하는 데 사용되는 수학은 신경망의 내부 동작을 이해하는 데 활용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 접근 방식에 대해 더 읽고 싶다면 원본 논문을 참고할 수 있어요: [2307.03223] Neural Network Field Theories: Non-Gaussianity, Actions, and Locality (arxiv.org)\n\n다시 본론으로 돌아와서, 신경망을 설계할 때 결정되어야 할 여러 가지 결정 사항 또는 하이퍼파라미터가 있어요. 이들은 다음과 같아요:\n\n- 각 층의 입력과 출력 수, 단, 첫 번째 층의 입력은 변수의 수, 마지막 층의 출력은 해결할 문제의 성격에 따라 정해지며 각 내부 또는 숨겨진 층의 출력은 다음 층의 입력이에요.\n- 신경망의 층 수.\n- 각 층의 활성화 함수.\n- 손실 함수.\n- 기울기 알고리즘.\n- 학습률.\n- 아키텍처(다음 세그먼트에서 탐구할 사항)\n\n다음으로, 가장 일반적인 신경망 아키텍처 몇 가지, 각각의 고수준 설명, 및 샘플 사용 사례를 살펴볼게요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 신경망과 기계 학습 내부의 수학을 더 잘 이해하고 싶다면 Ian Goodfellow, Yoshua Bengio, 그리고 Aaron Courville의 책을 참고하실 수 있어요. 해당 책은 Deep Learning (deeplearningbook.org)에서 구할 수 있어요. 그리고, Goodfellow은 적대적 생성 신경망(Generative Adversarial Networks)의 발명과도 함께 언급되어 있어요.\n\n# 다중 계층 퍼셉트론 (MLP)\n\n이것은 신경망의 가장 기본적인 아키텍처이며, 각 계층이 이전 계층에 의존하는 선형 구조로 형성되어 있어요. 또한 변수들 사이의 특정한 관계를 고려하지 않아요. MLP는 예측 변수들이 서로 의존하지 않는 문제에서 유용하게 사용됩니다. 예를 들어, 나이, 연봉, 교육 또는 성별과 같은 요소로 구성된 데이터셋에 대해요.\n\n![Neural Networks Basic Theory and Architecture Types](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 코드 블록은 PyTorch 패키지를 사용하여 Python에서 다층 퍼셉트론을 정의한 샘플입니다:\n\n```python\nimport torch.nn as nn\n\nclass SimpleClassifier(nn.Module):\n    def __init__(self):\n        super(SimpleClassifier, self).__init__()\n#과적합을 줄이기 위해 드롭아웃 레이어를 도입합니다.\n#드롭아웃은 신경망에게 층 사이의 데이터를 무작위로 삭제하여 변동성을 도입하도록 지시합니다.\n        self.dropout = nn.Dropout(0.1)\n#레이어는 열의 두 배 정도로 시작하고 다음 레이어로 증가한 다음 다시 2로 감소하는 것을 권장합니다.\n#이 경우 응답은 이진입니다.\n        self.layers = nn.Sequential(\n            nn.Linear(input_size, 250),\n            nn.Linear(250, 500),\n            nn.Linear(500, 1000),\n            nn.Linear(1000, 1500),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(1500, 1500),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(1500, 1500),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(1500, 1500),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(1500, 1500),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(1500, 1500),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(1500, 1500),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(1500, 500),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(500, 500),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(500, 500),\n            nn.Sigmoid(),\n            self.dropout,\n#마지막 레이어는 응답 변수가 이진(0, 1)이기 때문에 2를 출력합니다.\n#다중 클래스 분류의 출력은 클래스 수와 같아야 합니다.\n            nn.Linear(500, 2),\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\n#모델 정의\nmodel = SimpleClassifier()\n```\n\n이 모델을 사용한 전형적인 학습 루프는 다음 블록에서 나타납니다:\n\n```python\n#모델 로드\nmodel = SimpleClassifier()\nmodel.train()\n\n#학습 파라미터(사이클 수 및 학습률)입니다.\nnum_epochs = 100\nlearning_rate = 0.00001\n#과적합을 줄이기 위해\nregularization = 0.0000001\n\n#손실 함수\ncriterion = nn.CrossEntropyLoss()\n\n#기울기를 찾는 알고리즘\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=regularization)\n\n#이 코드는 학습 루프를 수행하는 동안 최상의 모델을 유지합니다.\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_acc = 0.0\nbest_f1 = 0.0\nbest_epoch = 0\nphases = ['train', 'val']\ntraining_curves = {}\nepoch_loss = 1\nepoch_f1 = 0\nepoch_acc = 0\n\n#데이터셋은 학습, 검증 및 테스트로 분할됩니다.\nfor phase in phases:\n    training_curves[phase+'_loss'] = []\n    training_curves[phase+'_acc'] = []\n    training_curves[phase+'_f1'] = []\n\n#이것은 학습 루프입니다.\nfor epoch in range(num_epochs):\n    print(f'\\n에포크 {epoch+1}/{num_epochs}')\n    print('-' * 10)\n    for phase in phases:\n        if phase == 'train':\n            model.train()\n        else:\n            model.eval()\n        running_loss = 0.0\n        running_corrects = 0\n        running_fp = 0\n        running_tp = 0\n        running_tn = 0\n        running_fn = 0\n        #데이터 반복\n        for inputs, labels in dataloaders[phase]:\n            inputs = inputs.view(inputs.shape[0], -1)\n            inputs = inputs\n            labels = labels\n\n            #매개변수의 기울기를 0으로 설정\n            optimizer.zero_grad()\n\n            #순방향 패스 (위의 차트 참조)\n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(inputs)\n                _, predictions = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n\n                #역방향 패스 (학습 중에만)\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                #통계. f1 메트릭을 사용합니다.\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(predictions == labels.data)\n                running_fp += torch.sum((predictions != labels.data) \u0026 (predictions \u003e= 0.5))\n                running_tp += torch.sum((predictions == labels.data) \u0026 (predictions \u003e= 0.5))\n                running_fn += torch.sum((predictions != labels.data) \u0026 (predictions \u003c 0.5))\n                running_tn += torch.sum((predictions == labels.data) \u0026 (predictions \u003c 0.5))\n                print(f'에포크 {epoch+1}, {phase:5} 손실: {epoch_loss:.7f} F1: {epoch_f1:.7f} 정확도: {epoch_acc:.7f} 부분 손실: {loss.item():.7f} 최상의 f1: {best_f1:.7f}')\n\n        #손실, 정확도 및 f1 메트릭 계산\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n        epoch_f1 = (2 * running_tp.double()) / (2 * running_tp.double() + running_fp.double() + running_fn.double() + 0.0000000000000000000001)\n        training_curves[phase+'_loss'].append(epoch_loss)\n        training_curves[phase+'_acc'].append(epoch_acc)\n        training_curves[phase+'_f1'].append(epoch_f1)\n\n        print(f'에포크 {epoch+1}, {phase:5} 손실: {epoch_loss:.7f} F1: {epoch_f1:.7f} 정확도: {epoch_acc:.7f} 최상의 f1: {best_f1:.7f}')\n\n        if phase == 'val' and epoch_f1 \u003e= best_f1:\n            best_epoch = epoch\n            best_acc = epoch_acc\n            best_f1 = epoch_f1\n            best_model_wts = copy.deepcopy(model.state_dict())\n\nprint(f'최상의 val F1: {best_f1:5f}, 최상의 val 정확도: {best_acc:5f}, 에포크 {best_epoch}')\n\n#최상의 모델 가중치로드\nmodel.load_state_dict(best_model_wts)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래의 글에서는 실제 데이터를 사용하여 MLP를 구현한 예시를 확인할 수 있습니다: [Neural Networks와 Pytorch를 사용하여 자동 복구 실패 예측하기 (저자: Greg Postalian-Yrausquin | 2024년 6월 | Towards AI (medium.com)](https://medium.com)\n\n더 많은 정보는 위키피디아 페이지에서 찾을 수 있습니다: [다층 퍼셉트론 (Multilayer perceptron) — Wikipedia](https://en.wikipedia.org/wiki/Multilayer_perceptron)\n\n# 합성곱 신경망 (CNN):\n\n전형적인 다층 퍼셉트론은 입력이 필드인 경우 성능이 좋지 않습니다. 여기서 필드란 점들 간의 관계(함수, 연속성을 통해)가 있는 구조를 말합니다. 예를 들어, 금속 판의 온도는 한 지점에 열원이 연결되어 있는 경우 열원에서 더 멀리 있는 위치로 갈수록 그래디언트를 따를 것입니다. 이 2차원 예시에서 표면의 온도는 그리드(행렬)로 나타낼 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_8.png)\n\n이러한 구조들은 3D일 수도 있습니다 (여러 개가 서로 위에 쌓인 것을 상상해보세요) 또는 우리가 원하는 대로 복잡할 수 있습니다. MLPs는 훈련 중에 데이터의 내부 구조를 잃어버리므로 이를 모델링하는 데 좋지 않습니다. 그와는 반대로 CNNs는 원래의 관계를 보존합니다.\n\nPython에서는 이미지가 행렬로 저장됩니다. 여기서 행과 열은 위치를 나타내고 숫자는 강도를 측정하는 값입니다. 컬러 이미지의 경우 각 이미지에 대해 RGB 색상 인코딩 형식에 대한 값을 저장하는 3개의 행렬이 사용됩니다. 수학에서 이러한 다차원 행렬은 Tensor라고 불리며 벡터 함수로도 볼 수 있습니다 (출력이 벡터의 모양으로 나오는 것), 이 경우 출력 벡터의 좌표는 RGB 색상값입니다.\n\n이러한 이유로 CNN은 이미지 및 비디오 데이터를 모델링하는 데 널리 사용됩니다. CNN의 아이콘은 이미지 분류입니다. 이 기사에서는 그 목적으로 CNN 사용 예제를 볼 수 있습니다: Convolutional Neural Networks in PyTorch: Image Classification | by Greg Postalian-Yrausquin | Jun, 2024 | Towards AI (medium.com).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성곱 신경망은 네트워크 내에 하나 이상의 합성 계층이 존재하는 것으로 정의됩니다. 이들은 데이터 내부에서 창 또는 행렬(커널)을 슬라이딩하여 원소별 곱셈을 수행하고 커널 내부 값의 합을 구하는 수학 연산입니다. 패딩을 도입하여 원래 데이터 매트릭스 크기의 축소를 고려할 수 있습니다.\n\n![CNN Architecture](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_9.png)\n\nCNN에는 다른 종류의 계층도 소개되는데, 예를 들면: Max pool (지도의 일부분의 최대값을 얻어 데이터 크기를 줄임), flatten (데이터 매트릭스를 벡터로 변환하여 네트워크 끝에 사용되거나 표준 네트워크로 계속해서 훈련) 및 unflatten (이전 과정을 역으로 수행).\n\n다음 샘플 코드는 PyTorch에서 CNN 클래스의 정의입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom torch.nn.modules.flatten import Flatten\nclass CNNClassifier(nn.Module):\n    def __init__(self):\n        super(CNNClassifier, self).__init__()\n        self.dropout = nn.Dropout(0.05)\n        self.pipeline = nn.Sequential(\n            #in channels is 1, because the input is grayscale\n            nn.Conv2d(in_channels = 1, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 5, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            #dropout to introduce randomness and reduce overfitting\n            self.dropout,\n            #reduce and flat the tensor before applying the flat layers\n            nn.MaxPool2d(kernel_size = 2, stride = 2),\n            nn.Flatten(),\n            nn.Linear(500, 50),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(50, 50),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(50, 10),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(10, 10),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(10, 5),\n        )\n\n    def forward(self, x):\n        return self.pipeline(x)\n\nmodel = CNNClassifier()\n```\n\nCNN에 대해 더 자세히 알아보기 좋은 정보를 찾는 것을 시작하는 데 좋은 곳인 Wikipedia의 CNN에 대한 항목을 찾았어요: [Convolutional neural network — Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n\n# 오토인코더\n\n아키텍처의 하위 클래스로 오토인코더가 있습니다. 입력과 출력의 수가 동일한 특정 구성으로 상상할 수 있습니다. 모델은 입력된 데이터를 재현하는 방법을 학습하도록 구성되어 있으며 한 개 이상의 숨겨진 레이어를 통해 통과합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델은 두 부분으로 설계되어 있습니다. 입력을 다른 표현으로 변환하는 Encoder와 이 표현을 기반으로 입력의 버전을 재구성하는 Decoder입니다. 아이디어는 재구성이 초기 데이터와 가능한 한 유사해야 한다는 것입니다.\n\n이 네트워크에서 목표는 동일한 입력 데이터이기 때문에 이들은 사실상 감독되지 않은 학습 방법입니다. 예를 들어 Autoencoder 아키텍처는 생성적 AI 작업의 일부로 사용됩니다.\n\n자연어 처리(NLP)에서 오토인코더는 단어 또는 문장의 임베딩(표현)을 생성하는 데 사용됩니다. 이 텍스트의 숫자 표현은 그 후 분류, 거리 계산 등과 같은 하향 작업에서 사용됩니다.\n\nNLP에서 오토인코더를 사용하는 한 가지 훌륭한 방법은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Neural Network Example](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_10.png)\n\n이 문서에서는 오토인코더의 정의 예시를 찾을 수 있습니다: Neural networks: encoder-decoder example (autoencoder) | 작성자 Greg Postalian-Yrausquin | 날짜 2024년 6월 | Medium. 여기서 모델이 이미지를 재구성하는 데 사용됩니다.\n\n```js\n# 훈련 이미지의 채널 수. 컬러 이미지의 경우 3개입니다\nnc = 3\n\n# 표현의 크기\nnr = 1000\n\n# 디코더의 시작점의 크기\nnz = 50\n\nclass Encdec(nn.Module):\n    def __init__(self, nc, nz, nr):\n        super(Encdec, self).__init__()\n# 이것이 인코더입니다\n        self.encoder = nn.Sequential(\n            nn.Conv2d(in_channels = nc, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 1, kernel_size = 5, stride = 1, padding=1),\n            nn.Flatten(),\n            nn.Linear(2916, 3000),\n            nn.ReLU(),\n            nn.Linear(3000, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, nr),\n         )\n# 이것이 디코더입니다\n        self.decoder = nn.Sequential(\n            nn.Linear(nr, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, 500),\n            nn.ReLU(),\n            nn.Linear(500, nz*64*64),\n            nn.Unflatten(1, torch.Size([nz, 64, 64])),\n            nn.Conv2d(in_channels = nz, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = 10, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = 10, out_channels = nc, kernel_size = 5, stride = 1, padding=1),\n            nn.ReLU(),\n            nn.Flatten(),\n            nn.Linear(10092, 2000),\n            nn.ReLU(),\n            nn.Linear(2000, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, 1000),\n            nn.ReLU(),\n            nn.Linear(1000, 500),\n            nn.ReLU(),\n            nn.Linear(500, nc*64*64),\n            nn.Unflatten(1, torch.Size([nc, 64, 64])),\n            nn.Tanh()\n         )\n\n    def encode(self, x):\n        return self.encoder(x)\n\n    def decode(self, x):\n        return self.decoder(x)\n\n    def forward(self, input):\n        return self.decoder(self.encoder(input))\n\nnetEncDec = Encdec(nc, nz, nr)\n```\n\n자세한 내용은 위키피디아에서 오토인코더 아키텍처에 대해 더 알아보기 시작점으로 참조할 수 있습니다: [오토인코더 - 위키백과](https://ko.wikipedia.org/wiki/%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인코더-디코더 메커니즘의 일반적이고 잘 알려진 구현은 트랜스포머 입니다. 이 아키텍처는 2017년 구글의 데이터 과학자들이 발표한 “Attention is all you need” [1706.03762] 논문에서 소개되었습니다. 트랜스포머는 NLP에서 널리 사용되며, 입력 및 출력 집합에 대한 임베딩 생성부터 시작하여 여러 단계로 구성됩니다. 이 집합 모두에 대해 위치 정보를 유지할 수 있도록 처리된 후에, 초기 오토인코더에는 포함되어 있지 않은 단계가 포함됩니다. 이는 반복의 오버헤드 없이 RNN과 동일한 이점을 제공합니다. 그 다음 데이터는 인코딩 프로세스(어텐션 스택)를 거치고, 디코딩 단계(두 번째 어텐션 스택)에서 출력과 비교됩니다. 마지막 단계는 소프트맥스 변환을 적용하는 것입니다.\n\n![트랜스포머 아키텍처](/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_11.png)\n\n트랜스포머 아키텍처: 원본 논문 \"Attention is all you need\"에서 가져온 다이어그램입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전이 학습 패러다임의 매우 흥미로운 그리고 유용한 구현 중 하나는 Google이 만든 BERT(Bidirectional Encoder Representations for Transformers)입니다. 영어 처리를 위해 트랜스포머를 처음부터 훈련하는 것은 거대한 작업이 될 수 있지만 다행히도 다양한 용도에 맞게 사전 훈련된 모델을 다운로드하고 적용할 수 있습니다 (이러한 모델을 다운로드하고 적용하는 방법은 Huggingface 페이지를 참조하세요): 모델 다운로드 (huggingface.co)\n\n# 순환 신경망:\n\nRNN은 신경망의 비선형 시도로 간주될 수 있습니다. RNN에서는 한 레이어가 자신에게 영향을 미칠 수 있습니다 (역행 효과가 있습니다). 이 작용은 시퀀스 형식으로 된 데이터를 모델링하는 데 이상적이라고 할 수 있습니다. 이러한 데이터의 가장 좋은 예는 텍스트 스트림이며, 그 이유로 NLP에서 가장 효율적인 트랜스포머가 도입될 때까지 주로 사용되었습니다. RNN은 음성 및 필기 인식에도 구현되어 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_12.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRNN(순환 신경망)은 계산적으로 요구가 높을 수 있는 것 외에, 비선형성에 의해 확대되는 전파 오류와 실제로 이전 단계의 매우 짧은 메모리를 유지하는 사라져버리는 그래디언트와 같은 다른 문제가 있습니다. 이러한 문제를 해결하기 위해 LSTM(Long-Short Term Memory) 및 GRU(Gated Recurrent Units)와 같은 RNN 아키텍처의 더 복잡한 파생물이 소개되었습니다.\n\nRNN의 응용 예는 다음 글에서 소개됩니다: RNN: PyTorch에서 Sentiment Analysis를 위한 기본 순환 신경망 | Greg Postalian-Yrausquin 저 | 2024년 6월 | Towards AI (medium.com)\n\nPyTorch에서 이 네트워크의 정의는 다음과 같습니다:\n\n```python\n# 신경망의 정의입니다. 보시다시피 RNN 정의 하나만 있습니다.\n# 2개의 레이어와 하나의 선형 레이어가 포함됩니다.\n# 오버피팅을 방지하기 위해 드롭아웃 및 정규화가 도입되었습니다\n\nclass RNNClassifier(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNNClassifier, self).__init__()\n        self.hidden_size = hidden_size\n        self.RNN = nn.RNN(input_size, hidden_size, num_layers=2, dropout=0.2)\n        self.fc = nn.Linear(hidden_size, output_size)\n        pass\n\n    def forward(self, input):\n        output, hn = self.RNN(input)\n        output = self.fc(output)\n        return output, hn\n\nmodel = RNNClassifier(insize, 8, 2)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 생성 적대 신경망 (Generative Adversarial Networks, GAN):\n\n이것은 MLP, RNN 또는 CNN들의 조합에서 형성될 수 있는 또 다른 복합 아키텍처입니다. 2014년 Ian Goodfellow와 그의 동료들에 의해 작성되었습니다 (원본 논문은 Generative Adversarial Nets (nips.cc)에서 확인할 수 있으며 [1701.00160] NIPS 2016 Tutorial: Generative Adversarial Networks (arxiv.org)에서 튜토리얼을 참조할 수 있습니다). GAN은 두 가지 다른 모델이 훈련되는 매우 똑똑한 신경망 응용 프로그램으로, 하나는 원래 데이터셋을 기반으로 샘플을 생성하는 것을 목표로하고 다른 하나는 이 첫 번째 모델에 대항하여 샘플이 실제인지 가짜인지를 추측합니다.\n\nGAN은 생성적 AI 작업(모델을 기반으로 실제 데이터를 생성하는 것)에 사용됩니다. 텍스트, 이미지 또는 비디오 생성 등이 해당될 수 있습니다. 자세한 설명은 원본 샘플을 기반으로 새로운 객체를 생성해야 하는 생성자(Generator) 네트워크 및 인공적으로 생성된 샘플과 실제 샘플을 구별하도록 훈련된 구분자(Discriminator)를 포함하고 있습니다. 학습의 여러 반복 후에 구분자가 실제 데이터와 가짜 데이터를 구분하는 데 어려움을 겪도록 함으로써 신뢰할 수 있는 제품 생성을 보장합니다.\n\n이것은 PyTorch에서 두 적대적 신경망에 대한 클래스 정의 샘플입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n# 트레이닝 이미지 내의 채널 수. 컬러 이미지의 경우, 채널 수는 3입니다.\nnc = 3\n\n# z 잠재 벡터의 크기 (즉, 생성기 입력의 크기)\nnz = 100\n\n# 생성기의 특징 맵 크기\nngf = 64\n\n# 판별자의 특징 맵 크기\nndf = 64\n\n# 이것은 진짜와 가짜 이미지를 분리하려는 작업을 수행하는 판별자 네트워크입니다.\nclass Discriminator(nn.Module):\n    def __init__(self, nc, ndf):\n        super(Discriminator, self).__init__()\n        self.pipeline = nn.Sequential(\n# nc는 3이며, 입력은 텐서 3x64x64(64x64의 컬러 이미지이며, 각 컬러 이미지에는 3개의 텐서가 필요)입니다.\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2),\n# 출력은 크기가 1인 벡터입니다.\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input):\n        return self.pipeline(input)\n\n\nclass Generator(nn.Module):\n    def __init__(self, nc, nz, ngf):\n        super(Generator, self).__init__()\n        self.pipeline = nn.Sequential(\n# 생성기의 입력은 무작위 생성된 이미지입니다. 이 경우 채널 수가 100이므로 nz는 100입니다.\n            nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 16),\n            nn.ReLU(),\n            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(),\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(),\n            nn.ConvTranspose2d(ngf * 4, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(),\n# 출력은 트레이닝 이미지와 동일한 차원의 이미지입니다. 따라서 출력은 크기가 nc여야 합니다.\n            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, input):\n        return self.pipeline(input)\n\n\n저는 다음 기사에서 이미지 생성을 위한 GAN을 구현했습니다: GAN: training a Generative Adversarial Network for image generation | by Greg Postalian-Yrausquin | Jun, 2024 | Medium\n\n이것들은 머신 러닝을 위한 신경망의 기본입니다. 하지만 모든 아키텍처에 대한 완전한 설명은 아닙니다. 이 주제는 아주 거대하고 매혹적이며, 새로운 기술과 알고리즘이 지속적으로 등장하고 있는 폭발적인 성장을 이루고 있습니다. 이러한 많은 것들은 이 문서에서 설명된 아키텍처의 수정이나 결합입니다.\n","ogImage":{"url":"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_0.png"},"coverImage":"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_0.png","tag":["Tech"],"readingTime":22},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e이 이야기에서는 신경망의 이론적 기초와 이로부터 파생된 기술, 그리고 PyTorch를 사용한 구현의 가장 중요한 측면을 높은 수준에서 리뷰하고 설명해보려고 합니다. 가능한 간단한 언어를 사용하여 설명하겠습니다. 또한 다른 문서에서 문서화한 사용 사례 예시를 소개할 예정입니다.\u003c/p\u003e\n\u003cp\u003e신경망은 이름 그대로 뉴런으로 구성된 복잡한 시스템입니다. 이 네트워크의 힘은 이 인공 뉴런들 간의 상호 연결에서 나옵니다. 이러한 NN 알고리즘은 생물학적 시스템을 모방한다고 합니다.\u003c/p\u003e\n\u003ch1\u003e뉴런:\u003c/h1\u003e\n\u003cp\u003e신경망의 핵심은 뉴런입니다. 뉴런은 단순히 입력(변수) 집합을 받아 선형 및 비선형 변환을 적용하고 수학적 다변수 함수처럼 출력을 생성하는 수학 도구입니다.\u003c/p\u003e\n\u003cp\u003e첫 번째 레이어의 뉴런들에 대한 입력은 원래 세트의 데이터입니다. 각 샘플은 네트워크에 의해 독립적으로 동일한 방식으로 처리됩니다.\u003c/p\u003e\n\u003cp\u003e네트워크의 기본 구조는 다음과 같습니다: 각각의 뉴런으로 구성된 여러 레이어로, 각 레이어마다 독립적으로 구성됩니다. 첫 번째 레이어는 데이터 원본에서 공급받고, 마지막 레이어는 출력으로 공급하며, 중간 레이어는 이전 레이어에서 공급받고 다음 레이어로 이어집니다.\u003c/p\u003e\n\u003cp\u003e일부 아키텍처는 레이어 간에 변형을 추가하거나 피드백 루프를 도입한 이 모델에 변형을 도입할 수 있습니다. 나중에 이에 대해 논의할 예정입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_1.png\" alt=\"Neural Networks Basic Theory and Architecture Types 1\"\u003e\u003c/p\u003e\n\u003cp\u003e각 뉴런은 선형 부분과 비선형 부분으로 구성됩니다. 선형 부분은 표준 선형 방정식이며, 비선형 변환은 네트워크 및 층에 따라 다를 수 있습니다.\u003c/p\u003e\n\u003cp\u003e구체적으로, 레이어는 입력 벡터(크기 n)로 구성되며, 이는 가중치 행렬(크기 nxm, 여기서 n은 입력의 크기이고 m은 레이어의 뉴런 수입니다)에 의해 곱해지고 결과는 크기 m인 다른 벡터로 반환됩니다. 이 결과는 자유 매개 변수 벡터에 추가됩니다. 전체 결과는 비선형 함수를 통해 전달되며, 이를 활성화 함수라고 합니다.이 프로세스의 출력은 다음 레이어로 전달됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_2.png\" alt=\"Neural Networks Basic Theory and Architecture Types 2\"\u003e\u003c/p\u003e\n\u003cp\u003e또는 구체적으로:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_3.png\" alt=\"Neural Networks Basic Theory and Architecture Types\"\u003e\u003c/p\u003e\n\u003cp\u003e이 시스템이 얼마나 복잡해질 수 있는지를 보여주기 위해, 두 번째 층의 출력에서 수식이 어떻게 보일지 알아보겠습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_4.png\" alt=\"Neural Networks Basic Theory and Architecture Types\"\u003e\u003c/p\u003e\n\u003cp\u003e실제 출력(목표 변수)를 재현하는 최적의 가중치와 자유 매개변수 값을 찾는 것이 바로 이어지는 교육 과정의 전부적인 목적입니다. 원본 값과 예측된 값 사이의 차이를 측정하기 위해 손실 함수를 도입합니다. 이로써, 모든 신경망은 근본적으로 지도 회귀 문제로 전환됩니다.\u003c/p\u003e\n\u003cp\u003e활성화 함수는 다양한 사용 사례를 충족하는 함수 세트에서 선택됩니다. 높은 수준에서 가장 많이 사용되는 것은 ReLU(0보다 큰 값을 유지하며 음수는 0으로 설정), Sigmoid 및 Tanh입니다.\u003c/p\u003e\n\u003ch1\u003e학습 과정:\u003c/h1\u003e\n\u003cp\u003e언급했듯이, 각 계층별로 많은 매개변수의 최적 값을 찾는 것이 목표입니다. 이를 위해 예측된 Y와 실제 Y 간의 관계를 나타내는 함수(손실 함수)가 선택됩니다. 최적화 문제와 마찬가지로 목표는 이 기능이 최소값일 때의 지점을 찾기 위해 고정됩니다. 일부 손실 함수의 예는 평균 제곱 오차, 제곱근 평균 제곱 오차, 평균 절대 오차 및 이진 교차 엔트로피가 있습니다.\u003c/p\u003e\n\u003cp\u003e최적화 문제를 해결하는 데 사용된 알고리즘은 그래디언트 강하법의 변형으로, 이는 다변수 적용에서 함수의 최소값을 찾는 전형적인 미적분 문제의 수치 구현입니다. 알고리즘은 각 반복에서 함수의 그래디언트 값을 추정하고 다음과 같은 방식으로 매개변수를 업데이트합니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_5.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e이 프로세스는 주어진 반복 횟수(에폭)만큼 반복되며, 각 실행에서 손실 값이 감소하는지 확인합니다.\u003c/p\u003e\n\u003cp\u003e학습 속도는 미리 설정해야 하는 하이퍼파라미터입니다. 학습 속도에 대한 중요한 사항은 너무 높게 설정해서는 안 된다는 것입니다. 그렇지 않으면 손실 값이 진동을 시작하고 결코 함수의 최소값을 찾지 못할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_6.png\" alt=\"Neural Networks Theory\"\u003e\u003c/p\u003e\n\u003cp\u003e일반적으로 매개변수는 무작위 변수를 사용하여 초기화됩니다. 이 변수는 가우시안 분포를 따릅니다. 모든 입력이 독립적이며 레이어에 무한 개수의 뉴런이 있는 이상적인 경우에는 출력과 훈련된 매개변수도 가우시안 분포를 형성합니다.\u003c/p\u003e\n\u003cp\u003e이러한 분포는 매개변수, 변수 또는 출력으로 형성된 다변량 공간 상의 파형패킷으로 볼 수 있습니다. 이는 양자장론에서 자유 입자를 모델링하기 위해 사용되는 수학적 구조와 유사합니다. 양자장론에서 상호작용으로 나타나는 작은 편차가 있는 것과 같이, 신경망에서는 변수간의 종속성과 레이어 당 유한 개수의 뉴런 삽입에 의해 생성됩니다. 특히, 네트워크 구성원 간의 내부 또는 보이지 않는 구조에 의해 생성되는 이러한 편차는 시스템의 예측력의 원천입니다. 그러나 이러한 편차가 너무 커지면 시스템이 발산하여 혼돈스럽게 됩니다.\u003c/p\u003e\n\u003cp\u003e양자장론과 마찬가지로, 자유(가우시안) 경우에서의 작은 편차로 인한 문제들에 대한 수학적 해석을 위해 섭동 이론을 사용할 수 있습니다. 물리적 입자간의 상호작용을 이해하는 데 사용되는 수학은 신경망의 내부 동작을 이해하는 데 활용됩니다.\u003c/p\u003e\n\u003cp\u003e이 접근 방식에 대해 더 읽고 싶다면 원본 논문을 참고할 수 있어요: [2307.03223] Neural Network Field Theories: Non-Gaussianity, Actions, and Locality (arxiv.org)\u003c/p\u003e\n\u003cp\u003e다시 본론으로 돌아와서, 신경망을 설계할 때 결정되어야 할 여러 가지 결정 사항 또는 하이퍼파라미터가 있어요. 이들은 다음과 같아요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e각 층의 입력과 출력 수, 단, 첫 번째 층의 입력은 변수의 수, 마지막 층의 출력은 해결할 문제의 성격에 따라 정해지며 각 내부 또는 숨겨진 층의 출력은 다음 층의 입력이에요.\u003c/li\u003e\n\u003cli\u003e신경망의 층 수.\u003c/li\u003e\n\u003cli\u003e각 층의 활성화 함수.\u003c/li\u003e\n\u003cli\u003e손실 함수.\u003c/li\u003e\n\u003cli\u003e기울기 알고리즘.\u003c/li\u003e\n\u003cli\u003e학습률.\u003c/li\u003e\n\u003cli\u003e아키텍처(다음 세그먼트에서 탐구할 사항)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e다음으로, 가장 일반적인 신경망 아키텍처 몇 가지, 각각의 고수준 설명, 및 샘플 사용 사례를 살펴볼게요.\u003c/p\u003e\n\u003cp\u003e만약 신경망과 기계 학습 내부의 수학을 더 잘 이해하고 싶다면 Ian Goodfellow, Yoshua Bengio, 그리고 Aaron Courville의 책을 참고하실 수 있어요. 해당 책은 Deep Learning (deeplearningbook.org)에서 구할 수 있어요. 그리고, Goodfellow은 적대적 생성 신경망(Generative Adversarial Networks)의 발명과도 함께 언급되어 있어요.\u003c/p\u003e\n\u003ch1\u003e다중 계층 퍼셉트론 (MLP)\u003c/h1\u003e\n\u003cp\u003e이것은 신경망의 가장 기본적인 아키텍처이며, 각 계층이 이전 계층에 의존하는 선형 구조로 형성되어 있어요. 또한 변수들 사이의 특정한 관계를 고려하지 않아요. MLP는 예측 변수들이 서로 의존하지 않는 문제에서 유용하게 사용됩니다. 예를 들어, 나이, 연봉, 교육 또는 성별과 같은 요소로 구성된 데이터셋에 대해요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_7.png\" alt=\"Neural Networks Basic Theory and Architecture Types\"\u003e\u003c/p\u003e\n\u003cp\u003e아래 코드 블록은 PyTorch 패키지를 사용하여 Python에서 다층 퍼셉트론을 정의한 샘플입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch.nn \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e nn\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSimpleClassifier\u003c/span\u003e(nn.Module):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e(SimpleClassifier, self).__init__()\n\u003cspan class=\"hljs-comment\"\u003e#과적합을 줄이기 위해 드롭아웃 레이어를 도입합니다.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e#드롭아웃은 신경망에게 층 사이의 데이터를 무작위로 삭제하여 변동성을 도입하도록 지시합니다.\u003c/span\u003e\n        self.dropout = nn.Dropout(\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e)\n\u003cspan class=\"hljs-comment\"\u003e#레이어는 열의 두 배 정도로 시작하고 다음 레이어로 증가한 다음 다시 2로 감소하는 것을 권장합니다.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e#이 경우 응답은 이진입니다.\u003c/span\u003e\n        self.layers = nn.Sequential(\n            nn.Linear(input_size, \u003cspan class=\"hljs-number\"\u003e250\u003c/span\u003e),\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e250\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e),\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e),\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e1500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e),\n            nn.Sigmoid(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e),\n            nn.Sigmoid(),\n            self.dropout,\n\u003cspan class=\"hljs-comment\"\u003e#마지막 레이어는 응답 변수가 이진(0, 1)이기 때문에 2를 출력합니다.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e#다중 클래스 분류의 출력은 클래스 수와 같아야 합니다.\u003c/span\u003e\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e),\n        )\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, x\u003c/span\u003e):\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e self.layers(x)\n\n\u003cspan class=\"hljs-comment\"\u003e#모델 정의\u003c/span\u003e\nmodel = SimpleClassifier()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 모델을 사용한 전형적인 학습 루프는 다음 블록에서 나타납니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e#모델 로드\u003c/span\u003e\nmodel = SimpleClassifier()\nmodel.train()\n\n\u003cspan class=\"hljs-comment\"\u003e#학습 파라미터(사이클 수 및 학습률)입니다.\u003c/span\u003e\nnum_epochs = \u003cspan class=\"hljs-number\"\u003e100\u003c/span\u003e\nlearning_rate = \u003cspan class=\"hljs-number\"\u003e0.00001\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e#과적합을 줄이기 위해\u003c/span\u003e\nregularization = \u003cspan class=\"hljs-number\"\u003e0.0000001\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e#손실 함수\u003c/span\u003e\ncriterion = nn.CrossEntropyLoss()\n\n\u003cspan class=\"hljs-comment\"\u003e#기울기를 찾는 알고리즘\u003c/span\u003e\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=regularization)\n\n\u003cspan class=\"hljs-comment\"\u003e#이 코드는 학습 루프를 수행하는 동안 최상의 모델을 유지합니다.\u003c/span\u003e\nbest_model_wts = copy.deepcopy(model.state_dict())\nbest_acc = \u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e\nbest_f1 = \u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e\nbest_epoch = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\nphases = [\u003cspan class=\"hljs-string\"\u003e'train'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'val'\u003c/span\u003e]\ntraining_curves = {}\nepoch_loss = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\nepoch_f1 = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\nepoch_acc = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n\n\u003cspan class=\"hljs-comment\"\u003e#데이터셋은 학습, 검증 및 테스트로 분할됩니다.\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e phase \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e phases:\n    training_curves[phase+\u003cspan class=\"hljs-string\"\u003e'_loss'\u003c/span\u003e] = []\n    training_curves[phase+\u003cspan class=\"hljs-string\"\u003e'_acc'\u003c/span\u003e] = []\n    training_curves[phase+\u003cspan class=\"hljs-string\"\u003e'_f1'\u003c/span\u003e] = []\n\n\u003cspan class=\"hljs-comment\"\u003e#이것은 학습 루프입니다.\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e epoch \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003erange\u003c/span\u003e(num_epochs):\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'\\n에포크 \u003cspan class=\"hljs-subst\"\u003e{epoch+\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e}\u003c/span\u003e/\u003cspan class=\"hljs-subst\"\u003e{num_epochs}\u003c/span\u003e'\u003c/span\u003e)\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'-'\u003c/span\u003e * \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e phase \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e phases:\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e phase == \u003cspan class=\"hljs-string\"\u003e'train'\u003c/span\u003e:\n            model.train()\n        \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e:\n            model.\u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e()\n        running_loss = \u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e\n        running_corrects = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n        running_fp = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n        running_tp = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n        running_tn = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n        running_fn = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n        \u003cspan class=\"hljs-comment\"\u003e#데이터 반복\u003c/span\u003e\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e inputs, labels \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e dataloaders[phase]:\n            inputs = inputs.view(inputs.shape[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e], -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n            inputs = inputs\n            labels = labels\n\n            \u003cspan class=\"hljs-comment\"\u003e#매개변수의 기울기를 0으로 설정\u003c/span\u003e\n            optimizer.zero_grad()\n\n            \u003cspan class=\"hljs-comment\"\u003e#순방향 패스 (위의 차트 참조)\u003c/span\u003e\n            \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e torch.set_grad_enabled(phase == \u003cspan class=\"hljs-string\"\u003e'train'\u003c/span\u003e):\n                outputs = model(inputs)\n                _, predictions = torch.\u003cspan class=\"hljs-built_in\"\u003emax\u003c/span\u003e(outputs, \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n                loss = criterion(outputs, labels)\n\n                \u003cspan class=\"hljs-comment\"\u003e#역방향 패스 (학습 중에만)\u003c/span\u003e\n                \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e phase == \u003cspan class=\"hljs-string\"\u003e'train'\u003c/span\u003e:\n                    loss.backward()\n                    optimizer.step()\n\n                \u003cspan class=\"hljs-comment\"\u003e#통계. f1 메트릭을 사용합니다.\u003c/span\u003e\n                running_loss += loss.item() * inputs.size(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\n                running_corrects += torch.\u003cspan class=\"hljs-built_in\"\u003esum\u003c/span\u003e(predictions == labels.data)\n                running_fp += torch.\u003cspan class=\"hljs-built_in\"\u003esum\u003c/span\u003e((predictions != labels.data) \u0026#x26; (predictions \u003e= \u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e))\n                running_tp += torch.\u003cspan class=\"hljs-built_in\"\u003esum\u003c/span\u003e((predictions == labels.data) \u0026#x26; (predictions \u003e= \u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e))\n                running_fn += torch.\u003cspan class=\"hljs-built_in\"\u003esum\u003c/span\u003e((predictions != labels.data) \u0026#x26; (predictions \u0026#x3C; \u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e))\n                running_tn += torch.\u003cspan class=\"hljs-built_in\"\u003esum\u003c/span\u003e((predictions == labels.data) \u0026#x26; (predictions \u0026#x3C; \u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e))\n                \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'에포크 \u003cspan class=\"hljs-subst\"\u003e{epoch+\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e}\u003c/span\u003e, \u003cspan class=\"hljs-subst\"\u003e{phase:\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e}\u003c/span\u003e 손실: \u003cspan class=\"hljs-subst\"\u003e{epoch_loss:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e F1: \u003cspan class=\"hljs-subst\"\u003e{epoch_f1:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e 정확도: \u003cspan class=\"hljs-subst\"\u003e{epoch_acc:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e 부분 손실: \u003cspan class=\"hljs-subst\"\u003e{loss.item():\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e 최상의 f1: \u003cspan class=\"hljs-subst\"\u003e{best_f1:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e'\u003c/span\u003e)\n\n        \u003cspan class=\"hljs-comment\"\u003e#손실, 정확도 및 f1 메트릭 계산\u003c/span\u003e\n        epoch_loss = running_loss / dataset_sizes[phase]\n        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n        epoch_f1 = (\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e * running_tp.double()) / (\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e * running_tp.double() + running_fp.double() + running_fn.double() + \u003cspan class=\"hljs-number\"\u003e0.0000000000000000000001\u003c/span\u003e)\n        training_curves[phase+\u003cspan class=\"hljs-string\"\u003e'_loss'\u003c/span\u003e].append(epoch_loss)\n        training_curves[phase+\u003cspan class=\"hljs-string\"\u003e'_acc'\u003c/span\u003e].append(epoch_acc)\n        training_curves[phase+\u003cspan class=\"hljs-string\"\u003e'_f1'\u003c/span\u003e].append(epoch_f1)\n\n        \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'에포크 \u003cspan class=\"hljs-subst\"\u003e{epoch+\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e}\u003c/span\u003e, \u003cspan class=\"hljs-subst\"\u003e{phase:\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e}\u003c/span\u003e 손실: \u003cspan class=\"hljs-subst\"\u003e{epoch_loss:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e F1: \u003cspan class=\"hljs-subst\"\u003e{epoch_f1:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e 정확도: \u003cspan class=\"hljs-subst\"\u003e{epoch_acc:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e 최상의 f1: \u003cspan class=\"hljs-subst\"\u003e{best_f1:\u003cspan class=\"hljs-number\"\u003e.7\u003c/span\u003ef}\u003c/span\u003e'\u003c/span\u003e)\n\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e phase == \u003cspan class=\"hljs-string\"\u003e'val'\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eand\u003c/span\u003e epoch_f1 \u003e= best_f1:\n            best_epoch = epoch\n            best_acc = epoch_acc\n            best_f1 = epoch_f1\n            best_model_wts = copy.deepcopy(model.state_dict())\n\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'최상의 val F1: \u003cspan class=\"hljs-subst\"\u003e{best_f1:5f}\u003c/span\u003e, 최상의 val 정확도: \u003cspan class=\"hljs-subst\"\u003e{best_acc:5f}\u003c/span\u003e, 에포크 \u003cspan class=\"hljs-subst\"\u003e{best_epoch}\u003c/span\u003e'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e#최상의 모델 가중치로드\u003c/span\u003e\nmodel.load_state_dict(best_model_wts)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e아래의 글에서는 실제 데이터를 사용하여 MLP를 구현한 예시를 확인할 수 있습니다: \u003ca href=\"https://medium.com\" rel=\"nofollow\" target=\"_blank\"\u003eNeural Networks와 Pytorch를 사용하여 자동 복구 실패 예측하기 (저자: Greg Postalian-Yrausquin | 2024년 6월 | Towards AI (medium.com)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e더 많은 정보는 위키피디아 페이지에서 찾을 수 있습니다: \u003ca href=\"https://en.wikipedia.org/wiki/Multilayer_perceptron\" rel=\"nofollow\" target=\"_blank\"\u003e다층 퍼셉트론 (Multilayer perceptron) — Wikipedia\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e합성곱 신경망 (CNN):\u003c/h1\u003e\n\u003cp\u003e전형적인 다층 퍼셉트론은 입력이 필드인 경우 성능이 좋지 않습니다. 여기서 필드란 점들 간의 관계(함수, 연속성을 통해)가 있는 구조를 말합니다. 예를 들어, 금속 판의 온도는 한 지점에 열원이 연결되어 있는 경우 열원에서 더 멀리 있는 위치로 갈수록 그래디언트를 따를 것입니다. 이 2차원 예시에서 표면의 온도는 그리드(행렬)로 나타낼 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_8.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e이러한 구조들은 3D일 수도 있습니다 (여러 개가 서로 위에 쌓인 것을 상상해보세요) 또는 우리가 원하는 대로 복잡할 수 있습니다. MLPs는 훈련 중에 데이터의 내부 구조를 잃어버리므로 이를 모델링하는 데 좋지 않습니다. 그와는 반대로 CNNs는 원래의 관계를 보존합니다.\u003c/p\u003e\n\u003cp\u003ePython에서는 이미지가 행렬로 저장됩니다. 여기서 행과 열은 위치를 나타내고 숫자는 강도를 측정하는 값입니다. 컬러 이미지의 경우 각 이미지에 대해 RGB 색상 인코딩 형식에 대한 값을 저장하는 3개의 행렬이 사용됩니다. 수학에서 이러한 다차원 행렬은 Tensor라고 불리며 벡터 함수로도 볼 수 있습니다 (출력이 벡터의 모양으로 나오는 것), 이 경우 출력 벡터의 좌표는 RGB 색상값입니다.\u003c/p\u003e\n\u003cp\u003e이러한 이유로 CNN은 이미지 및 비디오 데이터를 모델링하는 데 널리 사용됩니다. CNN의 아이콘은 이미지 분류입니다. 이 기사에서는 그 목적으로 CNN 사용 예제를 볼 수 있습니다: Convolutional Neural Networks in PyTorch: Image Classification | by Greg Postalian-Yrausquin | Jun, 2024 | Towards AI (medium.com).\u003c/p\u003e\n\u003cp\u003e합성곱 신경망은 네트워크 내에 하나 이상의 합성 계층이 존재하는 것으로 정의됩니다. 이들은 데이터 내부에서 창 또는 행렬(커널)을 슬라이딩하여 원소별 곱셈을 수행하고 커널 내부 값의 합을 구하는 수학 연산입니다. 패딩을 도입하여 원래 데이터 매트릭스 크기의 축소를 고려할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_9.png\" alt=\"CNN Architecture\"\u003e\u003c/p\u003e\n\u003cp\u003eCNN에는 다른 종류의 계층도 소개되는데, 예를 들면: Max pool (지도의 일부분의 최대값을 얻어 데이터 크기를 줄임), flatten (데이터 매트릭스를 벡터로 변환하여 네트워크 끝에 사용되거나 표준 네트워크로 계속해서 훈련) 및 unflatten (이전 과정을 역으로 수행).\u003c/p\u003e\n\u003cp\u003e다음 샘플 코드는 PyTorch에서 CNN 클래스의 정의입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.nn.modules.flatten \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Flatten\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eCNNClassifier\u003c/span\u003e(nn.Module):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e(CNNClassifier, self).__init__()\n        self.dropout = nn.Dropout(\u003cspan class=\"hljs-number\"\u003e0.05\u003c/span\u003e)\n        self.pipeline = nn.Sequential(\n            \u003cspan class=\"hljs-comment\"\u003e#in channels is 1, because the input is grayscale\u003c/span\u003e\n            nn.Conv2d(in_channels = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.ReLU(),\n            nn.Conv2d(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.ReLU(),\n            \u003cspan class=\"hljs-comment\"\u003e#dropout to introduce randomness and reduce overfitting\u003c/span\u003e\n            self.dropout,\n            \u003cspan class=\"hljs-comment\"\u003e#reduce and flat the tensor before applying the flat layers\u003c/span\u003e\n            nn.MaxPool2d(kernel_size = \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e),\n            nn.Flatten(),\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e),\n            nn.ReLU(),\n            self.dropout,\n            nn.Linear(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e),\n        )\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, x\u003c/span\u003e):\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e self.pipeline(x)\n\nmodel = CNNClassifier()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCNN에 대해 더 자세히 알아보기 좋은 정보를 찾는 것을 시작하는 데 좋은 곳인 Wikipedia의 CNN에 대한 항목을 찾았어요: \u003ca href=\"https://en.wikipedia.org/wiki/Convolutional_neural_network\" rel=\"nofollow\" target=\"_blank\"\u003eConvolutional neural network — Wikipedia\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e오토인코더\u003c/h1\u003e\n\u003cp\u003e아키텍처의 하위 클래스로 오토인코더가 있습니다. 입력과 출력의 수가 동일한 특정 구성으로 상상할 수 있습니다. 모델은 입력된 데이터를 재현하는 방법을 학습하도록 구성되어 있으며 한 개 이상의 숨겨진 레이어를 통해 통과합니다.\u003c/p\u003e\n\u003cp\u003e모델은 두 부분으로 설계되어 있습니다. 입력을 다른 표현으로 변환하는 Encoder와 이 표현을 기반으로 입력의 버전을 재구성하는 Decoder입니다. 아이디어는 재구성이 초기 데이터와 가능한 한 유사해야 한다는 것입니다.\u003c/p\u003e\n\u003cp\u003e이 네트워크에서 목표는 동일한 입력 데이터이기 때문에 이들은 사실상 감독되지 않은 학습 방법입니다. 예를 들어 Autoencoder 아키텍처는 생성적 AI 작업의 일부로 사용됩니다.\u003c/p\u003e\n\u003cp\u003e자연어 처리(NLP)에서 오토인코더는 단어 또는 문장의 임베딩(표현)을 생성하는 데 사용됩니다. 이 텍스트의 숫자 표현은 그 후 분류, 거리 계산 등과 같은 하향 작업에서 사용됩니다.\u003c/p\u003e\n\u003cp\u003eNLP에서 오토인코더를 사용하는 한 가지 훌륭한 방법은 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_10.png\" alt=\"Neural Network Example\"\u003e\u003c/p\u003e\n\u003cp\u003e이 문서에서는 오토인코더의 정의 예시를 찾을 수 있습니다: Neural networks: encoder-decoder example (autoencoder) | 작성자 Greg Postalian-Yrausquin | 날짜 2024년 6월 | Medium. 여기서 모델이 이미지를 재구성하는 데 사용됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 훈련 이미지의 채널 수. 컬러 이미지의 경우 \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e개입니다\nnc = \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e\n\n# 표현의 크기\nnr = \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e\n\n# 디코더의 시작점의 크기\nnz = \u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eEncdec\u003c/span\u003e(nn.\u003cspan class=\"hljs-property\"\u003eModule\u003c/span\u003e):\n    def \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(self, nc, nz, nr):\n        \u003cspan class=\"hljs-variable language_\"\u003esuper\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eEncdec\u003c/span\u003e, self).\u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e()\n# 이것이 인코더입니다\n        self.\u003cspan class=\"hljs-property\"\u003eencoder\u003c/span\u003e = nn.\u003cspan class=\"hljs-title class_\"\u003eSequential\u003c/span\u003e(\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = nc, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eFlatten\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e2916\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e3000\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e3000\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, nr),\n         )\n# 이것이 디코더입니다\n        self.\u003cspan class=\"hljs-property\"\u003edecoder\u003c/span\u003e = nn.\u003cspan class=\"hljs-title class_\"\u003eSequential\u003c/span\u003e(\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(nr, \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e, nz*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eUnflatten\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, torch.\u003cspan class=\"hljs-title class_\"\u003eSize\u003c/span\u003e([nz, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e])),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = nz, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eConv2\u003c/span\u003ed(in_channels = \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, out_channels = nc, kernel_size = \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e, stride = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eFlatten\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e10092\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2000\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e2000\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eReLU\u003c/span\u003e(),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e, nc*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eUnflatten\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, torch.\u003cspan class=\"hljs-title class_\"\u003eSize\u003c/span\u003e([nc, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e])),\n            nn.\u003cspan class=\"hljs-title class_\"\u003eTanh\u003c/span\u003e()\n         )\n\n    def \u003cspan class=\"hljs-title function_\"\u003eencode\u003c/span\u003e(self, x):\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e self.\u003cspan class=\"hljs-title function_\"\u003eencoder\u003c/span\u003e(x)\n\n    def \u003cspan class=\"hljs-title function_\"\u003edecode\u003c/span\u003e(self, x):\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e self.\u003cspan class=\"hljs-title function_\"\u003edecoder\u003c/span\u003e(x)\n\n    def \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(self, input):\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e self.\u003cspan class=\"hljs-title function_\"\u003edecoder\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003eencoder\u003c/span\u003e(input))\n\nnetEncDec = \u003cspan class=\"hljs-title class_\"\u003eEncdec\u003c/span\u003e(nc, nz, nr)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e자세한 내용은 위키피디아에서 오토인코더 아키텍처에 대해 더 알아보기 시작점으로 참조할 수 있습니다: \u003ca href=\"https://ko.wikipedia.org/wiki/%EC%98%A4%ED%86%A0%EC%9D%B8%EC%BD%94%EB%8D%94\" rel=\"nofollow\" target=\"_blank\"\u003e오토인코더 - 위키백과\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e인코더-디코더 메커니즘의 일반적이고 잘 알려진 구현은 트랜스포머 입니다. 이 아키텍처는 2017년 구글의 데이터 과학자들이 발표한 “Attention is all you need” [1706.03762] 논문에서 소개되었습니다. 트랜스포머는 NLP에서 널리 사용되며, 입력 및 출력 집합에 대한 임베딩 생성부터 시작하여 여러 단계로 구성됩니다. 이 집합 모두에 대해 위치 정보를 유지할 수 있도록 처리된 후에, 초기 오토인코더에는 포함되어 있지 않은 단계가 포함됩니다. 이는 반복의 오버헤드 없이 RNN과 동일한 이점을 제공합니다. 그 다음 데이터는 인코딩 프로세스(어텐션 스택)를 거치고, 디코딩 단계(두 번째 어텐션 스택)에서 출력과 비교됩니다. 마지막 단계는 소프트맥스 변환을 적용하는 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes_11.png\" alt=\"트랜스포머 아키텍처\"\u003e\u003c/p\u003e\n\u003cp\u003e트랜스포머 아키텍처: 원본 논문 \"Attention is all you need\"에서 가져온 다이어그램입니다.\u003c/p\u003e\n\u003cp\u003e전이 학습 패러다임의 매우 흥미로운 그리고 유용한 구현 중 하나는 Google이 만든 BERT(Bidirectional Encoder Representations for Transformers)입니다. 영어 처리를 위해 트랜스포머를 처음부터 훈련하는 것은 거대한 작업이 될 수 있지만 다행히도 다양한 용도에 맞게 사전 훈련된 모델을 다운로드하고 적용할 수 있습니다 (이러한 모델을 다운로드하고 적용하는 방법은 Huggingface 페이지를 참조하세요): 모델 다운로드 (huggingface.co)\u003c/p\u003e\n\u003ch1\u003e순환 신경망:\u003c/h1\u003e\n\u003cp\u003eRNN은 신경망의 비선형 시도로 간주될 수 있습니다. RNN에서는 한 레이어가 자신에게 영향을 미칠 수 있습니다 (역행 효과가 있습니다). 이 작용은 시퀀스 형식으로 된 데이터를 모델링하는 데 이상적이라고 할 수 있습니다. 이러한 데이터의 가장 좋은 예는 텍스트 스트림이며, 그 이유로 NLP에서 가장 효율적인 트랜스포머가 도입될 때까지 주로 사용되었습니다. RNN은 음성 및 필기 인식에도 구현되어 있습니다.\u003c/p\u003e\n\u003cp\u003eRNN(순환 신경망)은 계산적으로 요구가 높을 수 있는 것 외에, 비선형성에 의해 확대되는 전파 오류와 실제로 이전 단계의 매우 짧은 메모리를 유지하는 사라져버리는 그래디언트와 같은 다른 문제가 있습니다. 이러한 문제를 해결하기 위해 LSTM(Long-Short Term Memory) 및 GRU(Gated Recurrent Units)와 같은 RNN 아키텍처의 더 복잡한 파생물이 소개되었습니다.\u003c/p\u003e\n\u003cp\u003eRNN의 응용 예는 다음 글에서 소개됩니다: RNN: PyTorch에서 Sentiment Analysis를 위한 기본 순환 신경망 | Greg Postalian-Yrausquin 저 | 2024년 6월 | Towards AI (medium.com)\u003c/p\u003e\n\u003cp\u003ePyTorch에서 이 네트워크의 정의는 다음과 같습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-comment\"\u003e# 신경망의 정의입니다. 보시다시피 RNN 정의 하나만 있습니다.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# 2개의 레이어와 하나의 선형 레이어가 포함됩니다.\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# 오버피팅을 방지하기 위해 드롭아웃 및 정규화가 도입되었습니다\u003c/span\u003e\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eRNNClassifier\u003c/span\u003e(nn.Module):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, input_size, hidden_size, output_size\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e(RNNClassifier, self).__init__()\n        self.hidden_size = hidden_size\n        self.RNN = nn.RNN(input_size, hidden_size, num_layers=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, dropout=\u003cspan class=\"hljs-number\"\u003e0.2\u003c/span\u003e)\n        self.fc = nn.Linear(hidden_size, output_size)\n        \u003cspan class=\"hljs-keyword\"\u003epass\u003c/span\u003e\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, \u003cspan class=\"hljs-built_in\"\u003einput\u003c/span\u003e\u003c/span\u003e):\n        output, hn = self.RNN(\u003cspan class=\"hljs-built_in\"\u003einput\u003c/span\u003e)\n        output = self.fc(output)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e output, hn\n\nmodel = RNNClassifier(insize, \u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e생성 적대 신경망 (Generative Adversarial Networks, GAN):\u003c/h1\u003e\n\u003cp\u003e이것은 MLP, RNN 또는 CNN들의 조합에서 형성될 수 있는 또 다른 복합 아키텍처입니다. 2014년 Ian Goodfellow와 그의 동료들에 의해 작성되었습니다 (원본 논문은 Generative Adversarial Nets (nips.cc)에서 확인할 수 있으며 [1701.00160] NIPS 2016 Tutorial: Generative Adversarial Networks (arxiv.org)에서 튜토리얼을 참조할 수 있습니다). GAN은 두 가지 다른 모델이 훈련되는 매우 똑똑한 신경망 응용 프로그램으로, 하나는 원래 데이터셋을 기반으로 샘플을 생성하는 것을 목표로하고 다른 하나는 이 첫 번째 모델에 대항하여 샘플이 실제인지 가짜인지를 추측합니다.\u003c/p\u003e\n\u003cp\u003eGAN은 생성적 AI 작업(모델을 기반으로 실제 데이터를 생성하는 것)에 사용됩니다. 텍스트, 이미지 또는 비디오 생성 등이 해당될 수 있습니다. 자세한 설명은 원본 샘플을 기반으로 새로운 객체를 생성해야 하는 생성자(Generator) 네트워크 및 인공적으로 생성된 샘플과 실제 샘플을 구별하도록 훈련된 구분자(Discriminator)를 포함하고 있습니다. 학습의 여러 반복 후에 구분자가 실제 데이터와 가짜 데이터를 구분하는 데 어려움을 겪도록 함으로써 신뢰할 수 있는 제품 생성을 보장합니다.\u003c/p\u003e\n\u003cp\u003e이것은 PyTorch에서 두 적대적 신경망에 대한 클래스 정의 샘플입니다:\u003c/p\u003e\n\u003ch1\u003e트레이닝 이미지 내의 채널 수. 컬러 이미지의 경우, 채널 수는 3입니다.\u003c/h1\u003e\n\u003cp\u003enc = 3\u003c/p\u003e\n\u003ch1\u003ez 잠재 벡터의 크기 (즉, 생성기 입력의 크기)\u003c/h1\u003e\n\u003cp\u003enz = 100\u003c/p\u003e\n\u003ch1\u003e생성기의 특징 맵 크기\u003c/h1\u003e\n\u003cp\u003engf = 64\u003c/p\u003e\n\u003ch1\u003e판별자의 특징 맵 크기\u003c/h1\u003e\n\u003cp\u003endf = 64\u003c/p\u003e\n\u003ch1\u003e이것은 진짜와 가짜 이미지를 분리하려는 작업을 수행하는 판별자 네트워크입니다.\u003c/h1\u003e\n\u003cp\u003eclass Discriminator(nn.Module):\ndef \u003cstrong\u003einit\u003c/strong\u003e(self, nc, ndf):\nsuper(Discriminator, self).\u003cstrong\u003einit\u003c/strong\u003e()\nself.pipeline = nn.Sequential(\u003c/p\u003e\n\u003ch1\u003enc는 3이며, 입력은 텐서 3x64x64(64x64의 컬러 이미지이며, 각 컬러 이미지에는 3개의 텐서가 필요)입니다.\u003c/h1\u003e\n\u003cpre\u003e\u003ccode\u003e        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n        nn.LeakyReLU(0.2),\n        nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 2),\n        nn.LeakyReLU(0.2),\n        nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 4),\n        nn.LeakyReLU(0.2),\n        nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ndf * 8),\n        nn.LeakyReLU(0.2),\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e출력은 크기가 1인 벡터입니다.\u003c/h1\u003e\n\u003cpre\u003e\u003ccode\u003e        nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n        nn.Sigmoid()\n    )\n\ndef forward(self, input):\n    return self.pipeline(input)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eclass Generator(nn.Module):\ndef \u003cstrong\u003einit\u003c/strong\u003e(self, nc, nz, ngf):\nsuper(Generator, self).\u003cstrong\u003einit\u003c/strong\u003e()\nself.pipeline = nn.Sequential(\u003c/p\u003e\n\u003ch1\u003e생성기의 입력은 무작위 생성된 이미지입니다. 이 경우 채널 수가 100이므로 nz는 100입니다.\u003c/h1\u003e\n\u003cpre\u003e\u003ccode\u003e        nn.ConvTranspose2d(nz, ngf * 16, 4, 1, 0, bias=False),\n        nn.BatchNorm2d(ngf * 16),\n        nn.ReLU(),\n        nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ngf * 8),\n        nn.ReLU(),\n        nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ngf * 4),\n        nn.ReLU(),\n        nn.ConvTranspose2d(ngf * 4, ngf, 4, 2, 1, bias=False),\n        nn.BatchNorm2d(ngf),\n        nn.ReLU(),\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e출력은 트레이닝 이미지와 동일한 차원의 이미지입니다. 따라서 출력은 크기가 nc여야 합니다.\u003c/h1\u003e\n\u003cpre\u003e\u003ccode\u003e        nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n        nn.Tanh()\n    )\n\ndef forward(self, input):\n    return self.pipeline(input)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e저는 다음 기사에서 이미지 생성을 위한 GAN을 구현했습니다: GAN: training a Generative Adversarial Network for image generation | by Greg Postalian-Yrausquin | Jun, 2024 | Medium\u003c/p\u003e\n\u003cp\u003e이것들은 머신 러닝을 위한 신경망의 기본입니다. 하지만 모든 아키텍처에 대한 완전한 설명은 아닙니다. 이 주제는 아주 거대하고 매혹적이며, 새로운 기술과 알고리즘이 지속적으로 등장하고 있는 폭발적인 성장을 이루고 있습니다. 이러한 많은 것들은 이 문서에서 설명된 아키텍처의 수정이나 결합입니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-20-NeuralNetworksBasicTheoryandArchitectureTypes"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>