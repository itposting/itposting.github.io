<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>ComfyUI에서 의상을 어떻게 변경하나요 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-HowtoChangeOutfitsinComfyUI" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="ComfyUI에서 의상을 어떻게 변경하나요 | itposting" data-gatsby-head="true"/><meta property="og:title" content="ComfyUI에서 의상을 어떻게 변경하나요 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-HowtoChangeOutfitsinComfyUI" data-gatsby-head="true"/><meta name="twitter:title" content="ComfyUI에서 의상을 어떻게 변경하나요 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 20:58" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">ComfyUI에서 의상을 어떻게 변경하나요</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="ComfyUI에서 의상을 어떻게 변경하나요" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">4<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-HowtoChangeOutfitsinComfyUI&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>일반적으로 ComfyUI나 Automatic1111에서 옷을 바꾸는 과정은 캐릭터 포즈를 유지하면서 원하는 스타일을 적용하는 데 조금의 프롬프트 엔지니어링이나 LoRA가 필요한 귀찮은 인페인팅과 제어넷을 필요로 합니다.</p>
<p>조금의 실험 끝에 IPAdapter의 스타일 추출과 Grounding Dino 및 Segment Anything 모델의 정확한 세분화를 결합하면 후처리를 최소화하면서 매우 정확하고 불편한 옷 갈아입기를 할 수 있습니다.</p>
<p>다음은 방법입니다:</p>
<p>작업흐름 및 상세가이드: 이 작업을 실제로 확인하고 워크플로를 다운로드하고 싶다면, Prompting Pixels 웹사이트에서 무료로 이용할 수 있습니다.</p>
<div class="content-ad"></div>
<h1>최종 결과</h1>
<p>워크플로우 세부사항에 대해 들어가기 전에, 이전과 이후의 이미지를 시각적으로 보여드립니다:</p>
<h1>작업 공간 설정</h1>
<p>세 가지 다른 그룹으로 분리하는 것이 조직적 관점과 전반적인 프로세스에서의 상황을 고려할 때 좋은 방법이라고 생각했습니다. 이 세 그룹은 다음과 같습니다: 기본 워크플로우, IPAdapter 및 세분화. 각각에서 무엇이 벌어지고 있는지 살펴보겠습니다:</p>
<div class="content-ad"></div>
<h1>기본 작업 흐름</h1>
<p>여기서 소개하는 것은 기본적으로 ComfyUI에서 시작하는 기본 작업 흐름입니다. 여기서 가장 주목할 만한 변화는 전체 이미지가 아닌 부분 이미지를 다루기 때문에, 생성 체크포인트 대신 인페인팅 체크포인트를 불러와야 한다는 것입니다.</p>
<p>그리고 추천하는 좋은 SDXL 체크포인트로는 RealVision, ICBINP XL 또는 기본 SDXL 인페인팅 체크포인트가 있습니다.</p>
<p>당신의 프롬프트에 대해, 특정 세그먼트를 변경할 것이기 때문에 무엇이 나타나길 원하는지 정의해야 합니다. 이 예시에서는 기본 셔츠를 화려한 하와이안 셔츠로 변환할 것입니다.</p>
<div class="content-ad"></div>
<h1>IPAdapter</h1>
<p>IPAdapter은 이미지 프롬프트 어댑터를 의미합니다. 기본적으로 이 노드들은 스타일이나 사람의 일반적인 특징을 모델로 전송할 수 있습니다.</p>
<p>이를 작은 LoRA나 텍스트 임베딩처럼 생각해보세요.</p>
<p>따라서 이미지를 입력으로 제공하고 이미지에서 관련 정보를 추출하는 것을 Load Image 노드를 통해 수행해야 합니다.</p>
<div class="content-ad"></div>
<p>ComfyUI에 이미지 프롬프트 어댑터(IPAdapter)를 설정하려면 CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors 및 ip-adapter-plus_sdxl_vit-h.safetensors 모델을 불러와야 합니다. 이 모델들과 관련된 다른 모델들은 IPAdapter GitHub 리포지토리에서 찾을 수 있습니다.</p>
<p>해당 디렉터리에 모델을 넣은 후 이미지 출력을 Load Image 노드에서 IPAdapter 고급 노드로 전달해야 합니다.</p>
<p>또한, CLIP 모델을 Load CLIP Vision과 IPAdapter Unified Loader를 IPAdapter 고급 노드로 가져와야 합니다. 이전에 언급된 IP 어댑터 모델을 사용하는 경우 프리셋을 PLUS(고 강도)로 설정해야 합니다.</p>
<p>마지막으로 IPAdapter Advanced에서 weight_type를 스타일 전송으로 변경해야 합니다.</p>
<div class="content-ad"></div>
<p>IPAdapter Advanced로부터의 모델 출력은 직접 KSampler 노드로 들어가게 되는데, 수정된 모델 파일은 이제 원하는 입력에 기반하여 정확하게 이미지/스타일을 그릴 수 있습니다.</p>
<h1>세분화</h1>
<p>이 프로세스 중 가장 멋진 부분 중 하나는 GroundingDino 모델의 구현입니다. 이 세분화 모델은 텍스트 프롬프트를 제공하고 해당 이미지 내에서 그것을 찾아서 그에 맞게 분할할 수 있습니다.</p>
<p>이것은 굉장히 강력한 기능입니다.</p>
<div class="content-ad"></div>
<p>저희의 작업 흐름 중에 셔츠를 세분화하는 데 사용 중인데, 실제로 모자부터 신발, 심지어 전체 배경까지 거의 모든 것을 세분화할 수 있어요. 가능성은 무한해요.</p>
<p>이를 설치하려면 Segment Anything 사용자 정의 노드를 가져와야 해요 (ComfyUI 매니저나 GitHub 저장소를 통해 이용 가능해요).</p>
<p>IPAdapter와 같이 세분화할 때 이미지가 먼저 입력이 되어야 해요.</p>
<p>그러므로 Load Image 노드를 설정하고 그 다음 GroundingDinoSAMSegment 노드로 전달하세요.</p>
<div class="content-ad"></div>
<p>또한, SAMModelLoader 노드와 GroundingDinoModelLoader의 Segment Anything 모델을 가져와야 합니다. 처음 실행할 때 이 모델 로더 노드들은 관련 모델(약 3GB)을 다운로드한 다음 GroundingDinoSAMSegment 노드로 전달합니다.</p>
<p>GroundingDinoSAMSegment 노드에는 세그먼트할 객체의 단어를 입력할 수 있는 텍스트 필드가 있습니다. 셔츠, 안경 등과 같이 세그먼트하려는 객체의 단어를 입력할 수 있습니다.</p>
<p>이제 셔츠, 안경과 같은 여러 객체를 정의할 수 있지만, 신뢰성이 거의 없다는 것을 알았습니다:</p>
<p><img src="/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>임계값에 대해 일반적으로 말하자면, 낮은 값은 모델이 선택을 더 자유롭게 할 수 있게 하지만 높은 값은 더 자신 있게 만듭니다. 값이 너무 높으면 선택된 것이 없는 오류가 발생할 수 있습니다.</p>
<p>분할한 후에는 마스크를 VAE 인코딩(인페인팅용) 노드(mask 입력)와 IPAdapter Advanced(주의 마스크 입력) 노드에 모두 전달해야 합니다. 원본 이미지는 VAE 인코딩(인페인팅용) 노드에도 전달되어야 합니다.</p>
<p>선택 사항: 마스크에 FeatherMask 노드를 추가하여 가장자리를 부드럽게 만들어 더 나은 결과를 얻을 수 있습니다.</p>
<h1>큐 프롬프트 및 결과 검토</h1>
<div class="content-ad"></div>
<p>한 번 모두 연결되면 프롬프트를 대기열에 넣고 결과를 검토할 수 있습니다. 원하는 결과물의 꽤 정확한 표현이 셔츠가 멋진 하와이안 셔츠로 변환되었음을 확인해야 합니다.</p>
<p>출력 이미지를 주의 깊게 살펴보고 원하는 결과물을 얻기 위해 필요한 대로 설정을 조정하세요.</p>
<p>완벽하게 작동하는 완벽한 조합을 찾기 위해 다양한 설정으로 실험하고 다양한 모델을 테스트할 수 있도록하려면 설정을 조정하세요.</p>
<h1>이 프로세스의 장단점</h1>
<div class="content-ad"></div>
<p>제안하는 방법에 대한 장단점을 요약해 드리겠습니다. 이 워크플로우를 잘 활용하는 데 도움이 될 수 있어요:</p>
<p>장점:</p>
<ul>
<li>GroundingDino의 Zero-shot 객체 감지 기능을 사용하면 이미지를 자동으로 분할하고 보정할 수 있습니다.</li>
<li>정확한 분할이 모델이 올바른 영역만 보정하도록 합니다.</li>
<li>'가상 시착'과 같은 소비자를 대상으로 하는 응용 프로그램이 가능합니다.</li>
</ul>
<p>단점:</p>
<div class="content-ad"></div>
<ul>
<li>Segmentation이 추가적인 몇 개의 GB VRAM을 소비하므로, ControlNets, LoRAs, AnimateDiff 등 다른 노드들과 함께 사용할 때 문제가 발생할 수 있습니다.</li>
<li>물리적인 적용이 아니라 스타일 적용만 가능합니다. 예를 들어, 긴 소매 셔츠가 IPAdapter에 입력되어도 최종 이미지는 여전히 단추 소매로 표시될 것입니다.</li>
</ul>
<p>👉 AI 예술 기술을 강화하고 싶다면, 무료 프롬프팅 픽셀 강좌를 확인해보세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"ComfyUI에서 의상을 어떻게 변경하나요","description":"","date":"2024-06-19 20:58","slug":"2024-06-19-HowtoChangeOutfitsinComfyUI","content":"\n\n일반적으로 ComfyUI나 Automatic1111에서 옷을 바꾸는 과정은 캐릭터 포즈를 유지하면서 원하는 스타일을 적용하는 데 조금의 프롬프트 엔지니어링이나 LoRA가 필요한 귀찮은 인페인팅과 제어넷을 필요로 합니다.\n\n조금의 실험 끝에 IPAdapter의 스타일 추출과 Grounding Dino 및 Segment Anything 모델의 정확한 세분화를 결합하면 후처리를 최소화하면서 매우 정확하고 불편한 옷 갈아입기를 할 수 있습니다.\n\n다음은 방법입니다:\n\n작업흐름 및 상세가이드: 이 작업을 실제로 확인하고 워크플로를 다운로드하고 싶다면, Prompting Pixels 웹사이트에서 무료로 이용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 최종 결과\n\n워크플로우 세부사항에 대해 들어가기 전에, 이전과 이후의 이미지를 시각적으로 보여드립니다:\n\n# 작업 공간 설정\n\n세 가지 다른 그룹으로 분리하는 것이 조직적 관점과 전반적인 프로세스에서의 상황을 고려할 때 좋은 방법이라고 생각했습니다. 이 세 그룹은 다음과 같습니다: 기본 워크플로우, IPAdapter 및 세분화. 각각에서 무엇이 벌어지고 있는지 살펴보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 기본 작업 흐름\n\n여기서 소개하는 것은 기본적으로 ComfyUI에서 시작하는 기본 작업 흐름입니다. 여기서 가장 주목할 만한 변화는 전체 이미지가 아닌 부분 이미지를 다루기 때문에, 생성 체크포인트 대신 인페인팅 체크포인트를 불러와야 한다는 것입니다.\n\n그리고 추천하는 좋은 SDXL 체크포인트로는 RealVision, ICBINP XL 또는 기본 SDXL 인페인팅 체크포인트가 있습니다.\n\n당신의 프롬프트에 대해, 특정 세그먼트를 변경할 것이기 때문에 무엇이 나타나길 원하는지 정의해야 합니다. 이 예시에서는 기본 셔츠를 화려한 하와이안 셔츠로 변환할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# IPAdapter\n\nIPAdapter은 이미지 프롬프트 어댑터를 의미합니다. 기본적으로 이 노드들은 스타일이나 사람의 일반적인 특징을 모델로 전송할 수 있습니다.\n\n이를 작은 LoRA나 텍스트 임베딩처럼 생각해보세요.\n\n따라서 이미지를 입력으로 제공하고 이미지에서 관련 정보를 추출하는 것을 Load Image 노드를 통해 수행해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nComfyUI에 이미지 프롬프트 어댑터(IPAdapter)를 설정하려면 CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors 및 ip-adapter-plus_sdxl_vit-h.safetensors 모델을 불러와야 합니다. 이 모델들과 관련된 다른 모델들은 IPAdapter GitHub 리포지토리에서 찾을 수 있습니다.\n\n해당 디렉터리에 모델을 넣은 후 이미지 출력을 Load Image 노드에서 IPAdapter 고급 노드로 전달해야 합니다.\n\n또한, CLIP 모델을 Load CLIP Vision과 IPAdapter Unified Loader를 IPAdapter 고급 노드로 가져와야 합니다. 이전에 언급된 IP 어댑터 모델을 사용하는 경우 프리셋을 PLUS(고 강도)로 설정해야 합니다.\n\n마지막으로 IPAdapter Advanced에서 weight_type를 스타일 전송으로 변경해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nIPAdapter Advanced로부터의 모델 출력은 직접 KSampler 노드로 들어가게 되는데, 수정된 모델 파일은 이제 원하는 입력에 기반하여 정확하게 이미지/스타일을 그릴 수 있습니다.\n\n# 세분화\n\n이 프로세스 중 가장 멋진 부분 중 하나는 GroundingDino 모델의 구현입니다. 이 세분화 모델은 텍스트 프롬프트를 제공하고 해당 이미지 내에서 그것을 찾아서 그에 맞게 분할할 수 있습니다.\n\n이것은 굉장히 강력한 기능입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희의 작업 흐름 중에 셔츠를 세분화하는 데 사용 중인데, 실제로 모자부터 신발, 심지어 전체 배경까지 거의 모든 것을 세분화할 수 있어요. 가능성은 무한해요.\n\n이를 설치하려면 Segment Anything 사용자 정의 노드를 가져와야 해요 (ComfyUI 매니저나 GitHub 저장소를 통해 이용 가능해요).\n\nIPAdapter와 같이 세분화할 때 이미지가 먼저 입력이 되어야 해요.\n\n그러므로 Load Image 노드를 설정하고 그 다음 GroundingDinoSAMSegment 노드로 전달하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, SAMModelLoader 노드와 GroundingDinoModelLoader의 Segment Anything 모델을 가져와야 합니다. 처음 실행할 때 이 모델 로더 노드들은 관련 모델(약 3GB)을 다운로드한 다음 GroundingDinoSAMSegment 노드로 전달합니다.\n\nGroundingDinoSAMSegment 노드에는 세그먼트할 객체의 단어를 입력할 수 있는 텍스트 필드가 있습니다. 셔츠, 안경 등과 같이 세그먼트하려는 객체의 단어를 입력할 수 있습니다.\n\n이제 셔츠, 안경과 같은 여러 객체를 정의할 수 있지만, 신뢰성이 거의 없다는 것을 알았습니다:\n\n![이미지](/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n임계값에 대해 일반적으로 말하자면, 낮은 값은 모델이 선택을 더 자유롭게 할 수 있게 하지만 높은 값은 더 자신 있게 만듭니다. 값이 너무 높으면 선택된 것이 없는 오류가 발생할 수 있습니다.\n\n분할한 후에는 마스크를 VAE 인코딩(인페인팅용) 노드(mask 입력)와 IPAdapter Advanced(주의 마스크 입력) 노드에 모두 전달해야 합니다. 원본 이미지는 VAE 인코딩(인페인팅용) 노드에도 전달되어야 합니다.\n\n선택 사항: 마스크에 FeatherMask 노드를 추가하여 가장자리를 부드럽게 만들어 더 나은 결과를 얻을 수 있습니다.\n\n# 큐 프롬프트 및 결과 검토\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 번 모두 연결되면 프롬프트를 대기열에 넣고 결과를 검토할 수 있습니다. 원하는 결과물의 꽤 정확한 표현이 셔츠가 멋진 하와이안 셔츠로 변환되었음을 확인해야 합니다.\n\n출력 이미지를 주의 깊게 살펴보고 원하는 결과물을 얻기 위해 필요한 대로 설정을 조정하세요.\n\n완벽하게 작동하는 완벽한 조합을 찾기 위해 다양한 설정으로 실험하고 다양한 모델을 테스트할 수 있도록하려면 설정을 조정하세요.\n\n# 이 프로세스의 장단점\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제안하는 방법에 대한 장단점을 요약해 드리겠습니다. 이 워크플로우를 잘 활용하는 데 도움이 될 수 있어요:\n\n장점:\n\n- GroundingDino의 Zero-shot 객체 감지 기능을 사용하면 이미지를 자동으로 분할하고 보정할 수 있습니다.\n- 정확한 분할이 모델이 올바른 영역만 보정하도록 합니다.\n- '가상 시착'과 같은 소비자를 대상으로 하는 응용 프로그램이 가능합니다.\n\n단점:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Segmentation이 추가적인 몇 개의 GB VRAM을 소비하므로, ControlNets, LoRAs, AnimateDiff 등 다른 노드들과 함께 사용할 때 문제가 발생할 수 있습니다.\n- 물리적인 적용이 아니라 스타일 적용만 가능합니다. 예를 들어, 긴 소매 셔츠가 IPAdapter에 입력되어도 최종 이미지는 여전히 단추 소매로 표시될 것입니다.\n\n👉 AI 예술 기술을 강화하고 싶다면, 무료 프롬프팅 픽셀 강좌를 확인해보세요.","ogImage":{"url":"/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png"},"coverImage":"/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png","tag":["Tech"],"readingTime":4},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e일반적으로 ComfyUI나 Automatic1111에서 옷을 바꾸는 과정은 캐릭터 포즈를 유지하면서 원하는 스타일을 적용하는 데 조금의 프롬프트 엔지니어링이나 LoRA가 필요한 귀찮은 인페인팅과 제어넷을 필요로 합니다.\u003c/p\u003e\n\u003cp\u003e조금의 실험 끝에 IPAdapter의 스타일 추출과 Grounding Dino 및 Segment Anything 모델의 정확한 세분화를 결합하면 후처리를 최소화하면서 매우 정확하고 불편한 옷 갈아입기를 할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e다음은 방법입니다:\u003c/p\u003e\n\u003cp\u003e작업흐름 및 상세가이드: 이 작업을 실제로 확인하고 워크플로를 다운로드하고 싶다면, Prompting Pixels 웹사이트에서 무료로 이용할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e최종 결과\u003c/h1\u003e\n\u003cp\u003e워크플로우 세부사항에 대해 들어가기 전에, 이전과 이후의 이미지를 시각적으로 보여드립니다:\u003c/p\u003e\n\u003ch1\u003e작업 공간 설정\u003c/h1\u003e\n\u003cp\u003e세 가지 다른 그룹으로 분리하는 것이 조직적 관점과 전반적인 프로세스에서의 상황을 고려할 때 좋은 방법이라고 생각했습니다. 이 세 그룹은 다음과 같습니다: 기본 워크플로우, IPAdapter 및 세분화. 각각에서 무엇이 벌어지고 있는지 살펴보겠습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e기본 작업 흐름\u003c/h1\u003e\n\u003cp\u003e여기서 소개하는 것은 기본적으로 ComfyUI에서 시작하는 기본 작업 흐름입니다. 여기서 가장 주목할 만한 변화는 전체 이미지가 아닌 부분 이미지를 다루기 때문에, 생성 체크포인트 대신 인페인팅 체크포인트를 불러와야 한다는 것입니다.\u003c/p\u003e\n\u003cp\u003e그리고 추천하는 좋은 SDXL 체크포인트로는 RealVision, ICBINP XL 또는 기본 SDXL 인페인팅 체크포인트가 있습니다.\u003c/p\u003e\n\u003cp\u003e당신의 프롬프트에 대해, 특정 세그먼트를 변경할 것이기 때문에 무엇이 나타나길 원하는지 정의해야 합니다. 이 예시에서는 기본 셔츠를 화려한 하와이안 셔츠로 변환할 것입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eIPAdapter\u003c/h1\u003e\n\u003cp\u003eIPAdapter은 이미지 프롬프트 어댑터를 의미합니다. 기본적으로 이 노드들은 스타일이나 사람의 일반적인 특징을 모델로 전송할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이를 작은 LoRA나 텍스트 임베딩처럼 생각해보세요.\u003c/p\u003e\n\u003cp\u003e따라서 이미지를 입력으로 제공하고 이미지에서 관련 정보를 추출하는 것을 Load Image 노드를 통해 수행해야 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eComfyUI에 이미지 프롬프트 어댑터(IPAdapter)를 설정하려면 CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors 및 ip-adapter-plus_sdxl_vit-h.safetensors 모델을 불러와야 합니다. 이 모델들과 관련된 다른 모델들은 IPAdapter GitHub 리포지토리에서 찾을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e해당 디렉터리에 모델을 넣은 후 이미지 출력을 Load Image 노드에서 IPAdapter 고급 노드로 전달해야 합니다.\u003c/p\u003e\n\u003cp\u003e또한, CLIP 모델을 Load CLIP Vision과 IPAdapter Unified Loader를 IPAdapter 고급 노드로 가져와야 합니다. 이전에 언급된 IP 어댑터 모델을 사용하는 경우 프리셋을 PLUS(고 강도)로 설정해야 합니다.\u003c/p\u003e\n\u003cp\u003e마지막으로 IPAdapter Advanced에서 weight_type를 스타일 전송으로 변경해야 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eIPAdapter Advanced로부터의 모델 출력은 직접 KSampler 노드로 들어가게 되는데, 수정된 모델 파일은 이제 원하는 입력에 기반하여 정확하게 이미지/스타일을 그릴 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e세분화\u003c/h1\u003e\n\u003cp\u003e이 프로세스 중 가장 멋진 부분 중 하나는 GroundingDino 모델의 구현입니다. 이 세분화 모델은 텍스트 프롬프트를 제공하고 해당 이미지 내에서 그것을 찾아서 그에 맞게 분할할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이것은 굉장히 강력한 기능입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e저희의 작업 흐름 중에 셔츠를 세분화하는 데 사용 중인데, 실제로 모자부터 신발, 심지어 전체 배경까지 거의 모든 것을 세분화할 수 있어요. 가능성은 무한해요.\u003c/p\u003e\n\u003cp\u003e이를 설치하려면 Segment Anything 사용자 정의 노드를 가져와야 해요 (ComfyUI 매니저나 GitHub 저장소를 통해 이용 가능해요).\u003c/p\u003e\n\u003cp\u003eIPAdapter와 같이 세분화할 때 이미지가 먼저 입력이 되어야 해요.\u003c/p\u003e\n\u003cp\u003e그러므로 Load Image 노드를 설정하고 그 다음 GroundingDinoSAMSegment 노드로 전달하세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e또한, SAMModelLoader 노드와 GroundingDinoModelLoader의 Segment Anything 모델을 가져와야 합니다. 처음 실행할 때 이 모델 로더 노드들은 관련 모델(약 3GB)을 다운로드한 다음 GroundingDinoSAMSegment 노드로 전달합니다.\u003c/p\u003e\n\u003cp\u003eGroundingDinoSAMSegment 노드에는 세그먼트할 객체의 단어를 입력할 수 있는 텍스트 필드가 있습니다. 셔츠, 안경 등과 같이 세그먼트하려는 객체의 단어를 입력할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이제 셔츠, 안경과 같은 여러 객체를 정의할 수 있지만, 신뢰성이 거의 없다는 것을 알았습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-HowtoChangeOutfitsinComfyUI_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e임계값에 대해 일반적으로 말하자면, 낮은 값은 모델이 선택을 더 자유롭게 할 수 있게 하지만 높은 값은 더 자신 있게 만듭니다. 값이 너무 높으면 선택된 것이 없는 오류가 발생할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e분할한 후에는 마스크를 VAE 인코딩(인페인팅용) 노드(mask 입력)와 IPAdapter Advanced(주의 마스크 입력) 노드에 모두 전달해야 합니다. 원본 이미지는 VAE 인코딩(인페인팅용) 노드에도 전달되어야 합니다.\u003c/p\u003e\n\u003cp\u003e선택 사항: 마스크에 FeatherMask 노드를 추가하여 가장자리를 부드럽게 만들어 더 나은 결과를 얻을 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e큐 프롬프트 및 결과 검토\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e한 번 모두 연결되면 프롬프트를 대기열에 넣고 결과를 검토할 수 있습니다. 원하는 결과물의 꽤 정확한 표현이 셔츠가 멋진 하와이안 셔츠로 변환되었음을 확인해야 합니다.\u003c/p\u003e\n\u003cp\u003e출력 이미지를 주의 깊게 살펴보고 원하는 결과물을 얻기 위해 필요한 대로 설정을 조정하세요.\u003c/p\u003e\n\u003cp\u003e완벽하게 작동하는 완벽한 조합을 찾기 위해 다양한 설정으로 실험하고 다양한 모델을 테스트할 수 있도록하려면 설정을 조정하세요.\u003c/p\u003e\n\u003ch1\u003e이 프로세스의 장단점\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e제안하는 방법에 대한 장단점을 요약해 드리겠습니다. 이 워크플로우를 잘 활용하는 데 도움이 될 수 있어요:\u003c/p\u003e\n\u003cp\u003e장점:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGroundingDino의 Zero-shot 객체 감지 기능을 사용하면 이미지를 자동으로 분할하고 보정할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e정확한 분할이 모델이 올바른 영역만 보정하도록 합니다.\u003c/li\u003e\n\u003cli\u003e'가상 시착'과 같은 소비자를 대상으로 하는 응용 프로그램이 가능합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e단점:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eSegmentation이 추가적인 몇 개의 GB VRAM을 소비하므로, ControlNets, LoRAs, AnimateDiff 등 다른 노드들과 함께 사용할 때 문제가 발생할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e물리적인 적용이 아니라 스타일 적용만 가능합니다. 예를 들어, 긴 소매 셔츠가 IPAdapter에 입력되어도 최종 이미지는 여전히 단추 소매로 표시될 것입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e👉 AI 예술 기술을 강화하고 싶다면, 무료 프롬프팅 픽셀 강좌를 확인해보세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-HowtoChangeOutfitsinComfyUI"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>