<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Stable Diffusion 모델 마스터하기 체크포인트, VAE, LoRA, 임베딩 및 더 많은 기능들 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Stable Diffusion 모델 마스터하기 체크포인트, VAE, LoRA, 임베딩 및 더 많은 기능들 | itposting" data-gatsby-head="true"/><meta property="og:title" content="Stable Diffusion 모델 마스터하기 체크포인트, VAE, LoRA, 임베딩 및 더 많은 기능들 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore" data-gatsby-head="true"/><meta name="twitter:title" content="Stable Diffusion 모델 마스터하기 체크포인트, VAE, LoRA, 임베딩 및 더 많은 기능들 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 20:22" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Stable Diffusion 모델 마스터하기 체크포인트, VAE, LoRA, 임베딩 및 더 많은 기능들</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Stable Diffusion 모델 마스터하기 체크포인트, VAE, LoRA, 임베딩 및 더 많은 기능들" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">8<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>안녕하세요! "Checkpoint", "VAE", "LoRA" 및 "Embedding"과 같은 용어가 혼란스러웠나요? "Stable Diffusion"을 탐험하면서 "pruned" 또는 "pruned-emaonly"와 같은 이름의 여러 버전의 체크포인트를 본 적이 있을 수도 있습니다. 어떤 것을 선택해야 할지 궁금해지기도 하죠.</p>
<p>걱정 마세요! 이 기사는 이러한 개념을 명확히 해주려는 목적으로 작성되었습니다. 초심자이든 전문가이든 여러분을 위한 내용이 준비되어 있습니다.</p>
<h1>I. Stable Diffusion에서 파일 이름 접미사 이해하기</h1>
<p>Stable Diffusion을 보다 깊게 이해하기 위해 파일 이름 접미사로 시작해보겠습니다. 이 도메인에서 .ckpt 및 .safetensors 두 가지 일반적인 접미사가 있습니다.</p>
<div class="content-ad"></div>
<h2>.ckpt: 체크포인트</h2>
<p>.ckpt 확장자는 "체크포인트"를 의미합니다. 이 형식은 TensorFlow 기계 학습 프레임워크에서 모델 매개변수를 저장하는 데 널리 사용됩니다. 종종 .ckpt 파일은 훈련 프로세스를 재개하기 위해 .meta 파일과 함께 작동합니다.</p>
<p>.ckpt 모델을 비디오 게임에서 진행상황 저장하는 것과 같다고 생각해보세요. 게임을 다양한 수준에서 저장해 진전상태를 잃지 않도록 하는 것처럼, 모델 훈련은 유사한 체크포인트를 사용합니다. 훈련 중에 가능한 중단 또는 실패로 인해 주기적으로 체크포인트가 작성됩니다—20%, 40% 등—모델의 현재 상태를 보존합니다. 이러한 실천은 마지막 체크포인트부터 훈련을 재개할 수 있도록 하여 처음부터 다시 시작하지 않도록 보장합니다.</p>
<p>.ckpt 외에도 .pt 모델 형식을 언급하는 것이 중요합니다. .ckpt는 TensorFlow에서 사용되는 반면, .pt는 PyTorch에서 모델 매개변수를 저장하는 데 사용되는 형식입니다. TensorFlow와 PyTorch는 둘 다 유명한 딥 러닝 프레임워크로, TensorFlow는 Google에 의해 개발되었고, PyTorch는 Facebook에 의해 개발되었습니다.</p>
<div class="content-ad"></div>
<p>파이토치는 모델을 저장하기 위해 .pth 및 .pkl 형식도 사용합니다. .pt와 .pth 파일 사이에는 큰 차이가 없는 반면 .pkl 파일은 Python의 pickle 모듈을 사용하여 직렬화하는 추가 단계가 필요합니다.</p>
<h2>.safetensors: 안전한 대안</h2>
<p>이제 .safetensors 모델에 대해 이야기해 봅시다. .safetensors 접미사는 Hugging Face에서 도입된 새로운 모델 저장 형식을 나타냅니다. 이 형식은 Stable Diffusion 모델을 위해 특별히 설계되었습니다.</p>
<p>.ckpt 형식은 모델 가중치, 옵티마이저 상태 및 일부 Python 코드를 포함한 상세한 훈련 정보를 저장하여 어디서든 훈련을 재개할 수 있도록 합니다.</p>
<div class="content-ad"></div>
<p>그러나 이 방법에는 두 가지 주요 단점이 있습니다. 첫째, .ckpt 파일에는 악성 코드가 포함될 수 있으므로 신뢰할 수 없는 소스에서 다운로드할 때 보안 위험이 발생할 수 있습니다. 둘째, 이러한 파일은 일반적으로 대형이며, 실제 버전의 단일 체크포인트의 경우 약 7GB, 애니메이션 버전의 경우 2-5GB 정도입니다.</p>
<p>.safetensors 형식은 모델 가중치만 저장하여 옵티마이저 상태 및 기타 정보를 제외하여 이러한 문제를 해결합니다. 이로써 최종 모델 버전에 적합하며, 성능이 주요 관심사이며 교육 과정 세부 정보는 중요하지 않은 경우에 적합합니다. .safetensors 파일은 가중치만 포함하고 코드가 없기 때문에 .ckpt 파일에 비해 안전하며 일반적으로 작고 빠르게 로드됩니다.</p>
<h2>각 형식을 사용하는 시기</h2>
<p>요약하면, Stable Diffusion 모델의 체크포인트를 세밀하게 조정하려는 경우 .ckpt 형식이 선호됩니다. 그러나 생성된 이미지의 출력 품질에만 초점을 맞추려는 경우 보안성과 효율성이 향상된 .safetensors 형식이 더 나은 선택입니다.</p>
<div class="content-ad"></div>
<h1>II. 안정적 확산에서 모델 분류하기</h1>
<p>안정적 확산에서 모델은 다섯 가지 주요 유형으로 분류됩니다: 체크포인트, VAE, LoRA, 임베딩, 그리고 하이퍼네트워크.</p>
<h2>2.1 체크포인트</h2>
<p>체크포인트 파일은 안정적 확산 프로세스에 필수적입니다.</p>
<div class="content-ad"></div>
<p>이 파일들은 모델에 대한 지식베이스 역할을 합니다. 예를 들어, 애니메이션 이미지로 체크포인트를 훈련시키면 생성된 이미지는 애니메이션 스타일을 가질 것입니다.</p>
<p>반면에, 실제 사진으로 훈련하면 더 현실적인 결과물을 얻을 수 있습니다. 훈련에 필요한 방대한 데이터로 인해, 체크포인트 파일은 일반적으로 2GB를 초과하는 크기로 큽니다. 이 파일들은 .ckpt 및 .safetensors 파일 확장자를 사용합니다.</p>
<h2>2.2 VAE</h2>
<p>VAE는 Variational Autoencoder의 약자로, 필터 효과와 비슷합니다. 이미지 생성 중, 주로 출력물의 색상 계획에 영향을 줍니다.</p>
<div class="content-ad"></div>
<p>보통 VAE 없이는 이미지가 더 어두워 보입니다. VAE를 사용하면 이미지가 밝아집니다.</p>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_0.png" alt="이미지"></p>
<p>그러나 일부 체크포인트는 훈련 중에 VAE 효과를 포함할 수 있습니다. 따라서 명시적으로 VAE를 사용하지 않더라도 생성된 이미지가 어둡게 나타나지 않을 수 있습니다.</p>
<p>가끔 VAE를 사용하면 원치 않는 효과가 발생할 수도 있습니다. 예를 들어 이미지가 파란색으로 변할 수 있습니다. 이를 피하기 위해 VAE 상태를 "자동"으로 설정할 수 있습니다.</p>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_1.png">
<h2>2.3 LoRA</h2>
<p>로라(LoRA)는 Microsoft 연구원들이 개발한 미세 조정 기술입니다. 이 방법은 대규모 모델을 특정 작업에 더 유연하고 효율적으로 만들어줍니다. 예를 들어 생성된 이미지의 스타일을 수정하는 작업과 같은 특정 작업에 대해 전체 모델을 처음부터 다시 학습시킬 필요 없이 큰 모델을 향상시키는 데 사용됩니다.</p>
<p>예를 들어, 로라 모델은 체크포인트에 반짝이는 숲 붉은수세미 효과를 추가하여 전체 체크포인트를 다시 학습시킬 필요 없이 효율성을 높일 수 있습니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_2.png" alt="이미지"></p>
<p>LoRA 모델은 독립적으로 작동하지 않고 체크포인트와 함께 사용해야 함을 기억하는 것이 중요합니다.</p>
<p>LoRA 모델은 훈련에 적은 이미지를 필요로 하기 때문에 파일 크기가 일반적으로 작으며, 수십에서 수백 MB의 범위에 있어서 디스크 공간을 절약합니다. 예를 들어 위의 예시는 100여 개의 이미지를 사용하였습니다.</p>
<p>마지막으로, 일부 LoRA 모델은 효과를 활성화하기 위해 프롬프트에 트리거 단어가 필요합니다. 예를 들어 위 LoRA의 경우 트리거 단어는 "jellyfishforest"입니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_3.png" alt="이미지"></p>
<h2>2.4 임베딩</h2>
<p>임베딩, 또는 텍스트 역변환,은 Stable Diffusion에서 사용되는 기술로 입력 프롬프트를 단일 벡터로 통합하여 이미지 생성의 안정성과 정확성을 향상시키는 기법입니다.</p>
<p>Stable Diffusion을 사용하여 D.Va의 이미지를 생성하려면 대개 여러 프롬프트를 사용하여 그의 외모를 설명해야 합니다. 이러한 프롬프트를 새로운 단일 프롬프트로 묶는 임베딩을 통해 이러한 작업을 간소화할 수 있습니다. 예를 들어, 이 새로운 프롬프트를 "D.Va"라고 합시다.</p>
<div class="content-ad"></div>
<p>임베딩 모델을 사용하면 “D.Va”를 입력하여 원하는 이미지를 생성할 수 있습니다. 이 방법을 사용하면 프롬프트를 작성하는 효율이 크게 향상됩니다.</p>
<p>임베딩 모델은 프롬프트를 통합하기 때문에 파일 크기가 매우 작으며 일반적으로 수십 KB에서 수백 KB 사이입니다.</p>
<p>아름다운 여성인 캐롤린 데어를 묘사하는 임베딩을 고려해보세요:</p>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_4.png" alt="Caroline Dare"></p>
<div class="content-ad"></div>
<p>이 임베딩과 연관된 트리거 단어를 입력하면 비슷한 이미지가 생성됩니다:</p>
<p>생성된 이미지는 사용된 체크포인트의 차이로 완전히 동일하지 않을 수 있지만, 흰 머리카락과 같은 더 분명한 특징들은 일관됩니다.</p>
<h2>2.5 하이퍼네트워크</h2>
<p>하이퍼네트워크는 다른 신경망의 매개변수를 생성하는 신경망 기반 모델로, 종종 NovelAI의 Stable Diffusion 모델에서 사용됩니다.</p>
<div class="content-ad"></div>
<p>하이퍼네트워크는 원본 모델의 핵심 구조를 변경하지 않고 출력 스타일을 수정하기 위해 작은 네트워크를 삽입하여 모델을 세밀하게 조정할 수 있습니다. 그러나 이 기능은 LoRA와 중복되어 실제로는 덜 사용됩니다.</p>
<h1>III. 가지치기 및 Emaonly 모델</h1>
<p>체크포인트를 다운로드할 때 아래 예시처럼 두 가지 버전을 만나게 될 수 있습니다: pruned 및 pruned-emaonly입니다.</p>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_5.png" alt=""></p>
<div class="content-ad"></div>
<p>훈련 중 체크포인트 파일은 두 가지 다른 가중치 세트를 저장합니다:</p>
<ul>
<li>
<p>Pruned:</p>
</li>
<li>
<p>이 버전은 모든 훈련 반복 후 모델의 최종 가중치를 포함합니다.</p>
</li>
<li>
<p>이 가중치는 추가 부드러움 없이 훈련 중 마지막 업데이트 결과를 직접 반영합니다.</p>
</li>
<li>
<p>사용 사례: 훈련 데이터의 포괄적인 표현 때문에 파인튜닝에 적합합니다.</p>
</li>
</ul>
<ol start="2">
<li>Pruned-Emaonly:</li>
</ol>
<div class="content-ad"></div>
<ul>
<li>최신 몇 번의 반복에서 가중치의 지수 이동 평균(EMA)을 사용한 버전입니다.</li>
<li>EMA 기술은 가중치를 평균화하여 단기 변동의 영향을 줄여 일반화를 개선하고 더 안정적인 성능을 제공합니다.</li>
<li>활용 사례: 안정성 및 더 작은 크기로 인해 직접 이미지를 생성하는 데 이상적이며, VRAM을 적게 사용합니다.</li>
</ul>
<h2>실용적인 영향</h2>
<p>가지치기된 모델:</p>
<ul>
<li>크기가 큼.</li>
<li>더 많은 VRAM을 사용함.</li>
<li>세밀한 조정 목적에 가장 적합함.</li>
</ul>
<div class="content-ad"></div>
<p>잘라낸 Emaonly 모델:</p>
<ul>
<li>사이즈가 작습니다.</li>
<li>VRAM을 덜 필요로 합니다.</li>
<li>이미지 생성에 최적화되어 있습니다.</li>
</ul>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_6.png" alt="이미지"></p>
<p>이러한 차이를 이해하여 귀하의 요구사항에 맞는 적절한 모델 버전을 선택할 수 있습니다 — 미세 조정을 위한 것이든 안정적인 이미지를 직접 생성하기 위한 것이든.</p>
<div class="content-ad"></div>
<h1>IV. 인기 체크포인트 소개</h1>
<p>안정된 확산 체크포인트는 여러 유형으로 분류됩니다: 공식 체크포인트, 애니메이션 체크포인트, 현실적 체크포인트, 그리고 판타지 체크포인트.</p>
<h2>4.1 공식 체크포인트</h2>
<p>공식 체크포인트는 1.X 시리즈와 2.X 시리즈로 나뉩니다.</p>
<div class="content-ad"></div>
<ol>
<li>X 시리즈: v1-1, v1-2, v1-3 및 v1-4 네 가지 버전이 있습니다. 이 체크포인트들은 Hugging Face: CompVis/stable-diffusion에서 이용 가능합니다.</li>
</ol>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_7.png" alt="이미지"></p>
<ul>
<li>추가로, 텍스트에서 비디오 생성 작업에서 뛰어난 성능으로 알려진 Runwayml이 v1-5 버전을 출시했습니다. 해당 버전은 <a href="2">Runwayml의 Stable Diffusion v1-5</a>에서 찾을 수 있습니다.</li>
</ul>
<ol start="2">
<li>X 시리즈: StabilityAI가 출시한 2-0 및 2-1 두 버전이 있습니다. 접근은 가능합니다:</li>
</ol>
<div class="content-ad"></div>
<ul>
<li>Stable Diffusion 2.0 by StabilityAI</li>
<li>Stable Diffusion 2.1 by StabilityAI</li>
</ul>
<h2>4.2 Anime Checkpoints</h2>
<p>The Anything series is a popular choice for anime-style images, with four main versions: V1, V2.1, V3, and V5, with Prt being a special version of V5. These models are versatile, not only excelling at generating anime images but also performing well with portraits, landscapes, and animals.</p>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_8.png" alt="image"></p>
<div class="content-ad"></div>
<h2>4.3 현실적인 체크포인트</h2>
<p>Realistic Vision은 고품질의 현실적 이미지를 생성하는 능력으로 유명합니다. CivitAI의 다음 이미지는 그 현실성을 보여줍니다.</p>
<p><img src="/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_9.png" alt="Realistic Image"></p>
<h2>4.4 판타지 체크포인트</h2>
<div class="content-ad"></div>
<p>판타지 체크포인트는 2D와 3D 미술 요소를 혼합하여 깊이를 더하지만 완전한 3D가 되지 않는 이미지를 만듭니다. AniVerse는 이 카테고리에서 가장 잘 알려진 모델 중 하나로, 멋진 독특한 시각적 효과를 만들어 냅니다.</p>
<h1>결론</h1>
<p>요약하자면, Stable Diffusion은 Midjourney나 DALL-E와 같은 모델보다 복잡하며 원하는 결과를 얻기 위해 다양한 체크포인트를 사용해야 합니다. 이 초기 복잡성은 다양성과 상세한 제어로 균형을 이루어, 다양한 이미지를 생성하는 강력한 도구로 만들어졌습니다.</p>
<p>— by公众号：AI技术巫</p>
<div class="content-ad"></div>
<h2>참고 자료</h2>
<ul>
<li>예시 체크포인트: Runwayml/stable-diffusion-v1-5</li>
<li>Stable Diffusion v1-5 - Runwayml의 Hugging Face Space: runwayml/stable-diffusion-v1-5</li>
</ul>
<p>💡 깊게 파보고 싶나요? 제 Stable Diffusion 컬렉션이 여러분을 기다리고 있어요.</p>
<h2>글이 마음에 드셨나요?</h2>
<div class="content-ad"></div>
<p>그렇다면:</p>
<ul>
<li>댓글을 남겨주세요</li>
<li>업데이트를 팔로우해주세요</li>
<li>무료 이메일 알림을 받아보세요</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Stable Diffusion 모델 마스터하기 체크포인트, VAE, LoRA, 임베딩 및 더 많은 기능들","description":"","date":"2024-06-23 20:22","slug":"2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore","content":"\n\n안녕하세요! \"Checkpoint\", \"VAE\", \"LoRA\" 및 \"Embedding\"과 같은 용어가 혼란스러웠나요? \"Stable Diffusion\"을 탐험하면서 \"pruned\" 또는 \"pruned-emaonly\"와 같은 이름의 여러 버전의 체크포인트를 본 적이 있을 수도 있습니다. 어떤 것을 선택해야 할지 궁금해지기도 하죠.\n\n걱정 마세요! 이 기사는 이러한 개념을 명확히 해주려는 목적으로 작성되었습니다. 초심자이든 전문가이든 여러분을 위한 내용이 준비되어 있습니다.\n\n# I. Stable Diffusion에서 파일 이름 접미사 이해하기\n\nStable Diffusion을 보다 깊게 이해하기 위해 파일 이름 접미사로 시작해보겠습니다. 이 도메인에서 .ckpt 및 .safetensors 두 가지 일반적인 접미사가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## .ckpt: 체크포인트\n\n.ckpt 확장자는 \"체크포인트\"를 의미합니다. 이 형식은 TensorFlow 기계 학습 프레임워크에서 모델 매개변수를 저장하는 데 널리 사용됩니다. 종종 .ckpt 파일은 훈련 프로세스를 재개하기 위해 .meta 파일과 함께 작동합니다.\n\n.ckpt 모델을 비디오 게임에서 진행상황 저장하는 것과 같다고 생각해보세요. 게임을 다양한 수준에서 저장해 진전상태를 잃지 않도록 하는 것처럼, 모델 훈련은 유사한 체크포인트를 사용합니다. 훈련 중에 가능한 중단 또는 실패로 인해 주기적으로 체크포인트가 작성됩니다—20%, 40% 등—모델의 현재 상태를 보존합니다. 이러한 실천은 마지막 체크포인트부터 훈련을 재개할 수 있도록 하여 처음부터 다시 시작하지 않도록 보장합니다.\n\n.ckpt 외에도 .pt 모델 형식을 언급하는 것이 중요합니다. .ckpt는 TensorFlow에서 사용되는 반면, .pt는 PyTorch에서 모델 매개변수를 저장하는 데 사용되는 형식입니다. TensorFlow와 PyTorch는 둘 다 유명한 딥 러닝 프레임워크로, TensorFlow는 Google에 의해 개발되었고, PyTorch는 Facebook에 의해 개발되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이토치는 모델을 저장하기 위해 .pth 및 .pkl 형식도 사용합니다. .pt와 .pth 파일 사이에는 큰 차이가 없는 반면 .pkl 파일은 Python의 pickle 모듈을 사용하여 직렬화하는 추가 단계가 필요합니다.\n\n## .safetensors: 안전한 대안\n\n이제 .safetensors 모델에 대해 이야기해 봅시다. .safetensors 접미사는 Hugging Face에서 도입된 새로운 모델 저장 형식을 나타냅니다. 이 형식은 Stable Diffusion 모델을 위해 특별히 설계되었습니다.\n\n.ckpt 형식은 모델 가중치, 옵티마이저 상태 및 일부 Python 코드를 포함한 상세한 훈련 정보를 저장하여 어디서든 훈련을 재개할 수 있도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이 방법에는 두 가지 주요 단점이 있습니다. 첫째, .ckpt 파일에는 악성 코드가 포함될 수 있으므로 신뢰할 수 없는 소스에서 다운로드할 때 보안 위험이 발생할 수 있습니다. 둘째, 이러한 파일은 일반적으로 대형이며, 실제 버전의 단일 체크포인트의 경우 약 7GB, 애니메이션 버전의 경우 2-5GB 정도입니다.\n\n.safetensors 형식은 모델 가중치만 저장하여 옵티마이저 상태 및 기타 정보를 제외하여 이러한 문제를 해결합니다. 이로써 최종 모델 버전에 적합하며, 성능이 주요 관심사이며 교육 과정 세부 정보는 중요하지 않은 경우에 적합합니다. .safetensors 파일은 가중치만 포함하고 코드가 없기 때문에 .ckpt 파일에 비해 안전하며 일반적으로 작고 빠르게 로드됩니다.\n\n## 각 형식을 사용하는 시기\n\n요약하면, Stable Diffusion 모델의 체크포인트를 세밀하게 조정하려는 경우 .ckpt 형식이 선호됩니다. 그러나 생성된 이미지의 출력 품질에만 초점을 맞추려는 경우 보안성과 효율성이 향상된 .safetensors 형식이 더 나은 선택입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# II. 안정적 확산에서 모델 분류하기\n\n안정적 확산에서 모델은 다섯 가지 주요 유형으로 분류됩니다: 체크포인트, VAE, LoRA, 임베딩, 그리고 하이퍼네트워크.\n\n## 2.1 체크포인트\n\n체크포인트 파일은 안정적 확산 프로세스에 필수적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 파일들은 모델에 대한 지식베이스 역할을 합니다. 예를 들어, 애니메이션 이미지로 체크포인트를 훈련시키면 생성된 이미지는 애니메이션 스타일을 가질 것입니다.\n\n반면에, 실제 사진으로 훈련하면 더 현실적인 결과물을 얻을 수 있습니다. 훈련에 필요한 방대한 데이터로 인해, 체크포인트 파일은 일반적으로 2GB를 초과하는 크기로 큽니다. 이 파일들은 .ckpt 및 .safetensors 파일 확장자를 사용합니다.\n\n## 2.2 VAE\n\nVAE는 Variational Autoencoder의 약자로, 필터 효과와 비슷합니다. 이미지 생성 중, 주로 출력물의 색상 계획에 영향을 줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n보통 VAE 없이는 이미지가 더 어두워 보입니다. VAE를 사용하면 이미지가 밝아집니다.\n\n![이미지](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_0.png)\n\n그러나 일부 체크포인트는 훈련 중에 VAE 효과를 포함할 수 있습니다. 따라서 명시적으로 VAE를 사용하지 않더라도 생성된 이미지가 어둡게 나타나지 않을 수 있습니다.\n\n가끔 VAE를 사용하면 원치 않는 효과가 발생할 수도 있습니다. 예를 들어 이미지가 파란색으로 변할 수 있습니다. 이를 피하기 위해 VAE 상태를 \"자동\"으로 설정할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_1.png\" /\u003e\n\n## 2.3 LoRA\n\n로라(LoRA)는 Microsoft 연구원들이 개발한 미세 조정 기술입니다. 이 방법은 대규모 모델을 특정 작업에 더 유연하고 효율적으로 만들어줍니다. 예를 들어 생성된 이미지의 스타일을 수정하는 작업과 같은 특정 작업에 대해 전체 모델을 처음부터 다시 학습시킬 필요 없이 큰 모델을 향상시키는 데 사용됩니다.\n\n예를 들어, 로라 모델은 체크포인트에 반짝이는 숲 붉은수세미 효과를 추가하여 전체 체크포인트를 다시 학습시킬 필요 없이 효율성을 높일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_2.png)\n\nLoRA 모델은 독립적으로 작동하지 않고 체크포인트와 함께 사용해야 함을 기억하는 것이 중요합니다.\n\nLoRA 모델은 훈련에 적은 이미지를 필요로 하기 때문에 파일 크기가 일반적으로 작으며, 수십에서 수백 MB의 범위에 있어서 디스크 공간을 절약합니다. 예를 들어 위의 예시는 100여 개의 이미지를 사용하였습니다.\n\n마지막으로, 일부 LoRA 모델은 효과를 활성화하기 위해 프롬프트에 트리거 단어가 필요합니다. 예를 들어 위 LoRA의 경우 트리거 단어는 \"jellyfishforest\"입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_3.png)\n\n## 2.4 임베딩\n\n임베딩, 또는 텍스트 역변환,은 Stable Diffusion에서 사용되는 기술로 입력 프롬프트를 단일 벡터로 통합하여 이미지 생성의 안정성과 정확성을 향상시키는 기법입니다.\n\nStable Diffusion을 사용하여 D.Va의 이미지를 생성하려면 대개 여러 프롬프트를 사용하여 그의 외모를 설명해야 합니다. 이러한 프롬프트를 새로운 단일 프롬프트로 묶는 임베딩을 통해 이러한 작업을 간소화할 수 있습니다. 예를 들어, 이 새로운 프롬프트를 \"D.Va\"라고 합시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n임베딩 모델을 사용하면 “D.Va”를 입력하여 원하는 이미지를 생성할 수 있습니다. 이 방법을 사용하면 프롬프트를 작성하는 효율이 크게 향상됩니다.\n\n임베딩 모델은 프롬프트를 통합하기 때문에 파일 크기가 매우 작으며 일반적으로 수십 KB에서 수백 KB 사이입니다.\n\n아름다운 여성인 캐롤린 데어를 묘사하는 임베딩을 고려해보세요:\n\n![Caroline Dare](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 임베딩과 연관된 트리거 단어를 입력하면 비슷한 이미지가 생성됩니다:\n\n생성된 이미지는 사용된 체크포인트의 차이로 완전히 동일하지 않을 수 있지만, 흰 머리카락과 같은 더 분명한 특징들은 일관됩니다.\n\n## 2.5 하이퍼네트워크\n\n하이퍼네트워크는 다른 신경망의 매개변수를 생성하는 신경망 기반 모델로, 종종 NovelAI의 Stable Diffusion 모델에서 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하이퍼네트워크는 원본 모델의 핵심 구조를 변경하지 않고 출력 스타일을 수정하기 위해 작은 네트워크를 삽입하여 모델을 세밀하게 조정할 수 있습니다. 그러나 이 기능은 LoRA와 중복되어 실제로는 덜 사용됩니다.\n\n# III. 가지치기 및 Emaonly 모델\n\n체크포인트를 다운로드할 때 아래 예시처럼 두 가지 버전을 만나게 될 수 있습니다: pruned 및 pruned-emaonly입니다.\n\n![](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 중 체크포인트 파일은 두 가지 다른 가중치 세트를 저장합니다:\n\n- Pruned:\n\n- 이 버전은 모든 훈련 반복 후 모델의 최종 가중치를 포함합니다.\n- 이 가중치는 추가 부드러움 없이 훈련 중 마지막 업데이트 결과를 직접 반영합니다.\n- 사용 사례: 훈련 데이터의 포괄적인 표현 때문에 파인튜닝에 적합합니다.\n\n2. Pruned-Emaonly:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 최신 몇 번의 반복에서 가중치의 지수 이동 평균(EMA)을 사용한 버전입니다.\n- EMA 기술은 가중치를 평균화하여 단기 변동의 영향을 줄여 일반화를 개선하고 더 안정적인 성능을 제공합니다.\n- 활용 사례: 안정성 및 더 작은 크기로 인해 직접 이미지를 생성하는 데 이상적이며, VRAM을 적게 사용합니다.\n\n## 실용적인 영향\n\n가지치기된 모델:\n\n- 크기가 큼.\n- 더 많은 VRAM을 사용함.\n- 세밀한 조정 목적에 가장 적합함.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n잘라낸 Emaonly 모델:\n\n- 사이즈가 작습니다.\n- VRAM을 덜 필요로 합니다.\n- 이미지 생성에 최적화되어 있습니다.\n\n![이미지](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_6.png)\n\n이러한 차이를 이해하여 귀하의 요구사항에 맞는 적절한 모델 버전을 선택할 수 있습니다 — 미세 조정을 위한 것이든 안정적인 이미지를 직접 생성하기 위한 것이든.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# IV. 인기 체크포인트 소개\n\n안정된 확산 체크포인트는 여러 유형으로 분류됩니다: 공식 체크포인트, 애니메이션 체크포인트, 현실적 체크포인트, 그리고 판타지 체크포인트.\n\n## 4.1 공식 체크포인트\n\n공식 체크포인트는 1.X 시리즈와 2.X 시리즈로 나뉩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. X 시리즈: v1-1, v1-2, v1-3 및 v1-4 네 가지 버전이 있습니다. 이 체크포인트들은 Hugging Face: CompVis/stable-diffusion에서 이용 가능합니다.\n\n![이미지](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_7.png)\n\n- 추가로, 텍스트에서 비디오 생성 작업에서 뛰어난 성능으로 알려진 Runwayml이 v1-5 버전을 출시했습니다. 해당 버전은 [Runwayml의 Stable Diffusion v1-5](2)에서 찾을 수 있습니다.\n\n2. X 시리즈: StabilityAI가 출시한 2-0 및 2-1 두 버전이 있습니다. 접근은 가능합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Stable Diffusion 2.0 by StabilityAI\n- Stable Diffusion 2.1 by StabilityAI\n\n## 4.2 Anime Checkpoints\n\nThe Anything series is a popular choice for anime-style images, with four main versions: V1, V2.1, V3, and V5, with Prt being a special version of V5. These models are versatile, not only excelling at generating anime images but also performing well with portraits, landscapes, and animals.\n\n![image](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4.3 현실적인 체크포인트\n\nRealistic Vision은 고품질의 현실적 이미지를 생성하는 능력으로 유명합니다. CivitAI의 다음 이미지는 그 현실성을 보여줍니다.\n\n![Realistic Image](/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_9.png)\n\n## 4.4 판타지 체크포인트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n판타지 체크포인트는 2D와 3D 미술 요소를 혼합하여 깊이를 더하지만 완전한 3D가 되지 않는 이미지를 만듭니다. AniVerse는 이 카테고리에서 가장 잘 알려진 모델 중 하나로, 멋진 독특한 시각적 효과를 만들어 냅니다.\n\n# 결론\n\n요약하자면, Stable Diffusion은 Midjourney나 DALL-E와 같은 모델보다 복잡하며 원하는 결과를 얻기 위해 다양한 체크포인트를 사용해야 합니다. 이 초기 복잡성은 다양성과 상세한 제어로 균형을 이루어, 다양한 이미지를 생성하는 강력한 도구로 만들어졌습니다.\n\n— by公众号：AI技术巫\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 참고 자료\n\n- 예시 체크포인트: Runwayml/stable-diffusion-v1-5\n- Stable Diffusion v1-5 - Runwayml의 Hugging Face Space: runwayml/stable-diffusion-v1-5\n\n💡 깊게 파보고 싶나요? 제 Stable Diffusion 컬렉션이 여러분을 기다리고 있어요.\n\n## 글이 마음에 드셨나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그렇다면:\n\n- 댓글을 남겨주세요\n- 업데이트를 팔로우해주세요\n- 무료 이메일 알림을 받아보세요","ogImage":{"url":"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_0.png"},"coverImage":"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_0.png","tag":["Tech"],"readingTime":8},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e안녕하세요! \"Checkpoint\", \"VAE\", \"LoRA\" 및 \"Embedding\"과 같은 용어가 혼란스러웠나요? \"Stable Diffusion\"을 탐험하면서 \"pruned\" 또는 \"pruned-emaonly\"와 같은 이름의 여러 버전의 체크포인트를 본 적이 있을 수도 있습니다. 어떤 것을 선택해야 할지 궁금해지기도 하죠.\u003c/p\u003e\n\u003cp\u003e걱정 마세요! 이 기사는 이러한 개념을 명확히 해주려는 목적으로 작성되었습니다. 초심자이든 전문가이든 여러분을 위한 내용이 준비되어 있습니다.\u003c/p\u003e\n\u003ch1\u003eI. Stable Diffusion에서 파일 이름 접미사 이해하기\u003c/h1\u003e\n\u003cp\u003eStable Diffusion을 보다 깊게 이해하기 위해 파일 이름 접미사로 시작해보겠습니다. 이 도메인에서 .ckpt 및 .safetensors 두 가지 일반적인 접미사가 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e.ckpt: 체크포인트\u003c/h2\u003e\n\u003cp\u003e.ckpt 확장자는 \"체크포인트\"를 의미합니다. 이 형식은 TensorFlow 기계 학습 프레임워크에서 모델 매개변수를 저장하는 데 널리 사용됩니다. 종종 .ckpt 파일은 훈련 프로세스를 재개하기 위해 .meta 파일과 함께 작동합니다.\u003c/p\u003e\n\u003cp\u003e.ckpt 모델을 비디오 게임에서 진행상황 저장하는 것과 같다고 생각해보세요. 게임을 다양한 수준에서 저장해 진전상태를 잃지 않도록 하는 것처럼, 모델 훈련은 유사한 체크포인트를 사용합니다. 훈련 중에 가능한 중단 또는 실패로 인해 주기적으로 체크포인트가 작성됩니다—20%, 40% 등—모델의 현재 상태를 보존합니다. 이러한 실천은 마지막 체크포인트부터 훈련을 재개할 수 있도록 하여 처음부터 다시 시작하지 않도록 보장합니다.\u003c/p\u003e\n\u003cp\u003e.ckpt 외에도 .pt 모델 형식을 언급하는 것이 중요합니다. .ckpt는 TensorFlow에서 사용되는 반면, .pt는 PyTorch에서 모델 매개변수를 저장하는 데 사용되는 형식입니다. TensorFlow와 PyTorch는 둘 다 유명한 딥 러닝 프레임워크로, TensorFlow는 Google에 의해 개발되었고, PyTorch는 Facebook에 의해 개발되었습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e파이토치는 모델을 저장하기 위해 .pth 및 .pkl 형식도 사용합니다. .pt와 .pth 파일 사이에는 큰 차이가 없는 반면 .pkl 파일은 Python의 pickle 모듈을 사용하여 직렬화하는 추가 단계가 필요합니다.\u003c/p\u003e\n\u003ch2\u003e.safetensors: 안전한 대안\u003c/h2\u003e\n\u003cp\u003e이제 .safetensors 모델에 대해 이야기해 봅시다. .safetensors 접미사는 Hugging Face에서 도입된 새로운 모델 저장 형식을 나타냅니다. 이 형식은 Stable Diffusion 모델을 위해 특별히 설계되었습니다.\u003c/p\u003e\n\u003cp\u003e.ckpt 형식은 모델 가중치, 옵티마이저 상태 및 일부 Python 코드를 포함한 상세한 훈련 정보를 저장하여 어디서든 훈련을 재개할 수 있도록 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그러나 이 방법에는 두 가지 주요 단점이 있습니다. 첫째, .ckpt 파일에는 악성 코드가 포함될 수 있으므로 신뢰할 수 없는 소스에서 다운로드할 때 보안 위험이 발생할 수 있습니다. 둘째, 이러한 파일은 일반적으로 대형이며, 실제 버전의 단일 체크포인트의 경우 약 7GB, 애니메이션 버전의 경우 2-5GB 정도입니다.\u003c/p\u003e\n\u003cp\u003e.safetensors 형식은 모델 가중치만 저장하여 옵티마이저 상태 및 기타 정보를 제외하여 이러한 문제를 해결합니다. 이로써 최종 모델 버전에 적합하며, 성능이 주요 관심사이며 교육 과정 세부 정보는 중요하지 않은 경우에 적합합니다. .safetensors 파일은 가중치만 포함하고 코드가 없기 때문에 .ckpt 파일에 비해 안전하며 일반적으로 작고 빠르게 로드됩니다.\u003c/p\u003e\n\u003ch2\u003e각 형식을 사용하는 시기\u003c/h2\u003e\n\u003cp\u003e요약하면, Stable Diffusion 모델의 체크포인트를 세밀하게 조정하려는 경우 .ckpt 형식이 선호됩니다. 그러나 생성된 이미지의 출력 품질에만 초점을 맞추려는 경우 보안성과 효율성이 향상된 .safetensors 형식이 더 나은 선택입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eII. 안정적 확산에서 모델 분류하기\u003c/h1\u003e\n\u003cp\u003e안정적 확산에서 모델은 다섯 가지 주요 유형으로 분류됩니다: 체크포인트, VAE, LoRA, 임베딩, 그리고 하이퍼네트워크.\u003c/p\u003e\n\u003ch2\u003e2.1 체크포인트\u003c/h2\u003e\n\u003cp\u003e체크포인트 파일은 안정적 확산 프로세스에 필수적입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 파일들은 모델에 대한 지식베이스 역할을 합니다. 예를 들어, 애니메이션 이미지로 체크포인트를 훈련시키면 생성된 이미지는 애니메이션 스타일을 가질 것입니다.\u003c/p\u003e\n\u003cp\u003e반면에, 실제 사진으로 훈련하면 더 현실적인 결과물을 얻을 수 있습니다. 훈련에 필요한 방대한 데이터로 인해, 체크포인트 파일은 일반적으로 2GB를 초과하는 크기로 큽니다. 이 파일들은 .ckpt 및 .safetensors 파일 확장자를 사용합니다.\u003c/p\u003e\n\u003ch2\u003e2.2 VAE\u003c/h2\u003e\n\u003cp\u003eVAE는 Variational Autoencoder의 약자로, 필터 효과와 비슷합니다. 이미지 생성 중, 주로 출력물의 색상 계획에 영향을 줍니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e보통 VAE 없이는 이미지가 더 어두워 보입니다. VAE를 사용하면 이미지가 밝아집니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e그러나 일부 체크포인트는 훈련 중에 VAE 효과를 포함할 수 있습니다. 따라서 명시적으로 VAE를 사용하지 않더라도 생성된 이미지가 어둡게 나타나지 않을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e가끔 VAE를 사용하면 원치 않는 효과가 발생할 수도 있습니다. 예를 들어 이미지가 파란색으로 변할 수 있습니다. 이를 피하기 위해 VAE 상태를 \"자동\"으로 설정할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_1.png\"\u003e\n\u003ch2\u003e2.3 LoRA\u003c/h2\u003e\n\u003cp\u003e로라(LoRA)는 Microsoft 연구원들이 개발한 미세 조정 기술입니다. 이 방법은 대규모 모델을 특정 작업에 더 유연하고 효율적으로 만들어줍니다. 예를 들어 생성된 이미지의 스타일을 수정하는 작업과 같은 특정 작업에 대해 전체 모델을 처음부터 다시 학습시킬 필요 없이 큰 모델을 향상시키는 데 사용됩니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, 로라 모델은 체크포인트에 반짝이는 숲 붉은수세미 효과를 추가하여 전체 체크포인트를 다시 학습시킬 필요 없이 효율성을 높일 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eLoRA 모델은 독립적으로 작동하지 않고 체크포인트와 함께 사용해야 함을 기억하는 것이 중요합니다.\u003c/p\u003e\n\u003cp\u003eLoRA 모델은 훈련에 적은 이미지를 필요로 하기 때문에 파일 크기가 일반적으로 작으며, 수십에서 수백 MB의 범위에 있어서 디스크 공간을 절약합니다. 예를 들어 위의 예시는 100여 개의 이미지를 사용하였습니다.\u003c/p\u003e\n\u003cp\u003e마지막으로, 일부 LoRA 모델은 효과를 활성화하기 위해 프롬프트에 트리거 단어가 필요합니다. 예를 들어 위 LoRA의 경우 트리거 단어는 \"jellyfishforest\"입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch2\u003e2.4 임베딩\u003c/h2\u003e\n\u003cp\u003e임베딩, 또는 텍스트 역변환,은 Stable Diffusion에서 사용되는 기술로 입력 프롬프트를 단일 벡터로 통합하여 이미지 생성의 안정성과 정확성을 향상시키는 기법입니다.\u003c/p\u003e\n\u003cp\u003eStable Diffusion을 사용하여 D.Va의 이미지를 생성하려면 대개 여러 프롬프트를 사용하여 그의 외모를 설명해야 합니다. 이러한 프롬프트를 새로운 단일 프롬프트로 묶는 임베딩을 통해 이러한 작업을 간소화할 수 있습니다. 예를 들어, 이 새로운 프롬프트를 \"D.Va\"라고 합시다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e임베딩 모델을 사용하면 “D.Va”를 입력하여 원하는 이미지를 생성할 수 있습니다. 이 방법을 사용하면 프롬프트를 작성하는 효율이 크게 향상됩니다.\u003c/p\u003e\n\u003cp\u003e임베딩 모델은 프롬프트를 통합하기 때문에 파일 크기가 매우 작으며 일반적으로 수십 KB에서 수백 KB 사이입니다.\u003c/p\u003e\n\u003cp\u003e아름다운 여성인 캐롤린 데어를 묘사하는 임베딩을 고려해보세요:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_4.png\" alt=\"Caroline Dare\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 임베딩과 연관된 트리거 단어를 입력하면 비슷한 이미지가 생성됩니다:\u003c/p\u003e\n\u003cp\u003e생성된 이미지는 사용된 체크포인트의 차이로 완전히 동일하지 않을 수 있지만, 흰 머리카락과 같은 더 분명한 특징들은 일관됩니다.\u003c/p\u003e\n\u003ch2\u003e2.5 하이퍼네트워크\u003c/h2\u003e\n\u003cp\u003e하이퍼네트워크는 다른 신경망의 매개변수를 생성하는 신경망 기반 모델로, 종종 NovelAI의 Stable Diffusion 모델에서 사용됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e하이퍼네트워크는 원본 모델의 핵심 구조를 변경하지 않고 출력 스타일을 수정하기 위해 작은 네트워크를 삽입하여 모델을 세밀하게 조정할 수 있습니다. 그러나 이 기능은 LoRA와 중복되어 실제로는 덜 사용됩니다.\u003c/p\u003e\n\u003ch1\u003eIII. 가지치기 및 Emaonly 모델\u003c/h1\u003e\n\u003cp\u003e체크포인트를 다운로드할 때 아래 예시처럼 두 가지 버전을 만나게 될 수 있습니다: pruned 및 pruned-emaonly입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_5.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e훈련 중 체크포인트 파일은 두 가지 다른 가중치 세트를 저장합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003ePruned:\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e이 버전은 모든 훈련 반복 후 모델의 최종 가중치를 포함합니다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e이 가중치는 추가 부드러움 없이 훈련 중 마지막 업데이트 결과를 직접 반영합니다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e사용 사례: 훈련 데이터의 포괄적인 표현 때문에 파인튜닝에 적합합니다.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003ePruned-Emaonly:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e최신 몇 번의 반복에서 가중치의 지수 이동 평균(EMA)을 사용한 버전입니다.\u003c/li\u003e\n\u003cli\u003eEMA 기술은 가중치를 평균화하여 단기 변동의 영향을 줄여 일반화를 개선하고 더 안정적인 성능을 제공합니다.\u003c/li\u003e\n\u003cli\u003e활용 사례: 안정성 및 더 작은 크기로 인해 직접 이미지를 생성하는 데 이상적이며, VRAM을 적게 사용합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e실용적인 영향\u003c/h2\u003e\n\u003cp\u003e가지치기된 모델:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e크기가 큼.\u003c/li\u003e\n\u003cli\u003e더 많은 VRAM을 사용함.\u003c/li\u003e\n\u003cli\u003e세밀한 조정 목적에 가장 적합함.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e잘라낸 Emaonly 모델:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e사이즈가 작습니다.\u003c/li\u003e\n\u003cli\u003eVRAM을 덜 필요로 합니다.\u003c/li\u003e\n\u003cli\u003e이미지 생성에 최적화되어 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_6.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e이러한 차이를 이해하여 귀하의 요구사항에 맞는 적절한 모델 버전을 선택할 수 있습니다 — 미세 조정을 위한 것이든 안정적인 이미지를 직접 생성하기 위한 것이든.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eIV. 인기 체크포인트 소개\u003c/h1\u003e\n\u003cp\u003e안정된 확산 체크포인트는 여러 유형으로 분류됩니다: 공식 체크포인트, 애니메이션 체크포인트, 현실적 체크포인트, 그리고 판타지 체크포인트.\u003c/p\u003e\n\u003ch2\u003e4.1 공식 체크포인트\u003c/h2\u003e\n\u003cp\u003e공식 체크포인트는 1.X 시리즈와 2.X 시리즈로 나뉩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003col\u003e\n\u003cli\u003eX 시리즈: v1-1, v1-2, v1-3 및 v1-4 네 가지 버전이 있습니다. 이 체크포인트들은 Hugging Face: CompVis/stable-diffusion에서 이용 가능합니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_7.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e추가로, 텍스트에서 비디오 생성 작업에서 뛰어난 성능으로 알려진 Runwayml이 v1-5 버전을 출시했습니다. 해당 버전은 \u003ca href=\"2\"\u003eRunwayml의 Stable Diffusion v1-5\u003c/a\u003e에서 찾을 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eX 시리즈: StabilityAI가 출시한 2-0 및 2-1 두 버전이 있습니다. 접근은 가능합니다:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eStable Diffusion 2.0 by StabilityAI\u003c/li\u003e\n\u003cli\u003eStable Diffusion 2.1 by StabilityAI\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e4.2 Anime Checkpoints\u003c/h2\u003e\n\u003cp\u003eThe Anything series is a popular choice for anime-style images, with four main versions: V1, V2.1, V3, and V5, with Prt being a special version of V5. These models are versatile, not only excelling at generating anime images but also performing well with portraits, landscapes, and animals.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_8.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e4.3 현실적인 체크포인트\u003c/h2\u003e\n\u003cp\u003eRealistic Vision은 고품질의 현실적 이미지를 생성하는 능력으로 유명합니다. CivitAI의 다음 이미지는 그 현실성을 보여줍니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore_9.png\" alt=\"Realistic Image\"\u003e\u003c/p\u003e\n\u003ch2\u003e4.4 판타지 체크포인트\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e판타지 체크포인트는 2D와 3D 미술 요소를 혼합하여 깊이를 더하지만 완전한 3D가 되지 않는 이미지를 만듭니다. AniVerse는 이 카테고리에서 가장 잘 알려진 모델 중 하나로, 멋진 독특한 시각적 효과를 만들어 냅니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e요약하자면, Stable Diffusion은 Midjourney나 DALL-E와 같은 모델보다 복잡하며 원하는 결과를 얻기 위해 다양한 체크포인트를 사용해야 합니다. 이 초기 복잡성은 다양성과 상세한 제어로 균형을 이루어, 다양한 이미지를 생성하는 강력한 도구로 만들어졌습니다.\u003c/p\u003e\n\u003cp\u003e— by公众号：AI技术巫\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e참고 자료\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e예시 체크포인트: Runwayml/stable-diffusion-v1-5\u003c/li\u003e\n\u003cli\u003eStable Diffusion v1-5 - Runwayml의 Hugging Face Space: runwayml/stable-diffusion-v1-5\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e💡 깊게 파보고 싶나요? 제 Stable Diffusion 컬렉션이 여러분을 기다리고 있어요.\u003c/p\u003e\n\u003ch2\u003e글이 마음에 드셨나요?\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그렇다면:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e댓글을 남겨주세요\u003c/li\u003e\n\u003cli\u003e업데이트를 팔로우해주세요\u003c/li\u003e\n\u003cli\u003e무료 이메일 알림을 받아보세요\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-MasterStableDiffusionmodelscheckpointVAELoRAembeddingandmore"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>