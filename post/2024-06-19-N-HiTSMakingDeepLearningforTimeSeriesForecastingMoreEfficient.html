<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법 | itposting" data-gatsby-head="true"/><meta property="og:title" content="N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient" data-gatsby-head="true"/><meta name="twitter:title" content="N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 18:57" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png">
<p>2020년에 N-BEATS는 시계열 예측에서 통계적 및 혼합 모델보다 뛰어난 성과를 보인 첫 딥러닝 모델이었습니다.</p>
<p>그 후 2년 뒤인 2022년에 새로운 모델이 N-BEATS를 제쳐놓았습니다. Challu와 Olivares 등이 딥 러닝 모델 N-HiTS를 발표했습니다. 이들은 N-BEATS의 긴 예측 지표에 대한 두 가지 단점을 해결했습니다:</p>
<ul>
<li>정확도의 감소 및</li>
<li>계산량의 증가.</li>
</ul>
<div class="content-ad"></div>
<p>N-HiTS는 시계열 예측을 위한 Neural Hierarchical Interpolation의 약자입니다.</p>
<p>이 모델은 N-BEATS 및 그 신경 기반 확장 아이디어에 기반을 두고 있습니다. 신경 기반 확장은 계층화된 스택을 통해 여러 블록에서 이루어집니다.</p>
<p>이 글에서는 N-HiTS 뒤에 숨겨진 구조, 특히 N-BEATS와의 차이에 대해 살펴볼 것입니다. 하지만 너무 걱정하지 마세요, 깊이 파고들기가 이해하기 쉬울 거에요. 하지만 N-HiTS 작동 방식을 이해하는 것만으로 충분하지 않습니다. 따라서 Python에서 어떻게 N-HiTS 모델을 쉽게 구현하고 하이퍼파라미터를 튜닝할 수 있는지 보여드릴 거에요.</p>
<h1>핵심 아이디어가 같다면, N-BEATS와 N-HiTS의 차이는 무엇인가요?</h1>
<div class="content-ad"></div>
<p>각 모델이 각 스택의 입력과 출력을 처리하는 방식에 차이가 있습니다. N-HiTS의 주요 아이디어는 서로 다른 시간 스케일의 예측을 결합하는 것입니다.</p>
<p>이를 위해 N-HiTS는</p>
<ul>
<li>입력의 다중 속도 데이터 샘플링 및</li>
<li>출력의 계층적 보간</li>
</ul>
<p>을 적용합니다.</p>
<p>이 방법으로 N-HiTS는 더 긴 시계열에 대해 더 나은 정확도와 낮은 계산 비용을 달성합니다.</p>
<div class="content-ad"></div>
<p>다중 비율 데이터 샘플링은 스택이 단기 또는 장기적 영향에 특화되도록 만듭니다. 이러한 스택이 각각의 구성 요소를 학습하기 쉬워집니다. 장기적 행동에 중점을 둔 것은 N-BEATS에 비해 향상된 장기적 시계열 예측을 이끌어냅니다.</p>
<p>계층적 보간은 각 블록이 서로 다른 시간 단위로 예측하도록 허용합니다. 그런 다음 모델은 각 블록의 시간 단위에 맞게 예측을 보간하여 최종 예측과 일치시킵니다. 재샘플링과 보간은 학습 가능한 매개변수의 수를 줄입니다. 이는 훈련 시간이 더 짧고 가벼운 모델로 이어집니다.</p>
<p>이제 N-HiTS가 어떤 점에서 다르게 작동하는지 알았으니, 이러한 변화가 아키텍처에 어떻게 포함되어 있는지 살펴보겠습니다.</p>
<h1>N-HiTS는 자세히 어떻게 작동하나요?</h1>
<div class="content-ad"></div>
<p>N-HiTS 모델은 다음과 같은 아키텍처를 가지고 있어요:</p>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_1.png" alt="N-HiTS 모델"></p>
<p>우리가 볼 수 있듯이, N-BEATS와 많은 유사성을 가지고 있어요.</p>
<p>첫째, N-HiTS는 시계열을 lookback 및 forecast 기간으로 분리해요. 둘째, 해당 모델은 다층 스택과 블록으로 구성되어 있어요, backcast와 forecast를 생성해요. 각 블록에서 다층 퍼셉트론은 backcast와 forecast를 위한 기저 확장 계수를 생성해요. backcast는 블록이 포착한 시계열의 일부를 보여줘요. 우리는 이전 블록의 backcast를 제거하고 시계열을 블록에 전달하기 전에요. 이를 통해 각 블록은 서로 다른 패턴을 학습하게 되어요, 블록 간에 잔차만 전달하기 때문이에요. 해당 모델은 모든 블록의 forecast를 합하여 최종 예측을 생성해요.</p>
<div class="content-ad"></div>
<p>유사한 부분에 대해서는 이 정도로 설명을 유지하겠습니다. 더 자세한 정보는 제 N-BEATS 글을 참조하시기 바랍니다.</p>
<p>하지만 차이점에 대해서는 더 깊이 파헤쳐 보겠습니다: 다중 속도 데이터 샘플링과 계층적 보간.</p>
<h2>입력의 다중 속도 신호 샘플링</h2>
<p>N-HiTS는 MaxPool 레이어를 통해 블록 수준에서 다중 속도 샘플링을 수행합니다.</p>
<div class="content-ad"></div>
<p>MaxPool 레이어는 선택된 커널 크기 내에서 가장 큰 값을 취함으로써 입력을 평활화합니다. 따라서 커널 크기가 샘플링 속도를 결정합니다. 커널 크기가 클수록 평활화가 더 강해집니다.</p>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_2.png" alt="이미지"></p>
<p>MaxPool 레이어의 커널 크기는 스택 레벨에서 정의합니다. 따라서 동일한 스택 내의 각 블록은 동일한 커널 크기를 갖습니다.</p>
<p>N-HiTS는 리샘플링을 위해 위에서 아래로 접근하는 방식을 사용합니다. 첫 번째 스택은 큰 커널 크기를 통해 장기적인 효과에 초점을 맞춥니다. 후속 스택은 작은 커널 크기를 통해 단기적인 효과에 초점을 맞춥니다.</p>
<div class="content-ad"></div>
<h2>출력의 계층 적 보간</h2>
<p>N-HiTS는 각 스택의 예측 수, 즉 기수를 줄이기 위해 계층 적 보간을 사용합니다. 더 작은 기수는 장기 예측을 위한 계산 요구 사항을 줄여줍니다.</p>
<p>이게 무슨 말인가요?</p>
<p>시계열의 다음 24시간을 예측하려고 한다고 가정해 봅시다. 우리는 우리 모델이 24개의 예측을 출력할 것을 기대합니다(각 시간당 하나). 시간당 데이터의 다음 두 주를 예측하려면 336개의 예측이 필요합니다(14 * 24). 그게 맞죠?</p>
<div class="content-ad"></div>
<p>그러나 이것이 문제가 되는 곳입니다. N-BEATS 모델을 예를 들어봅시다. 최종 예측은 각 스택의 부분 예측을 결합한 것입니다. 따라서 각 스택은 336개의 값을 예측해야 하며, 이는 계산 비용이 많이 듭니다. N-BEATS는 더 긴 예측 범위에서 같은 문제를 겪는 모델 중 하나에 불과합니다. 다른 딥러닝 접근 방식인 트랜스포머나 순환 신경망과 같은 모델들도 같은 문제에 직면하게 됩니다.</p>
<p>N-HiTS는 각 스택이 서로 다른 시간 스케일에서 예측하도록하여 이 도전을 극복합니다. N-HiTS는 각 스택의 시간 스케일을 내삽을 사용하여 최종 출력에 일치시킵니다.</p>
<p>이를 위해 N-HiTS는 표현 간격 비율 개념을 사용합니다. 이 비율은 예측 기간 내의 예측 수를 결정합니다. 작은 표현 간격 비율은 스택이 더 적은 예측을 하도록 만듭니다. 따라서 스택의 기수가 작아집니다. 예를 들어, 1/2의 표현 간격 비율을 선택합니다. 이는 스택이 최종 예측에서 원하는 매 두 번째 값을 예측하게 만듭니다.</p>
<p>표현 간격 비율은 출력을 입력의 재샘플링과 관련시킵니다. 입력의 재샘플링과 결합되어, 각 스택은 서로 다른 주파수에서 작동합니다. 따라서 각 스택은 서로 다른 속도로 시계열을 처리하는 데 전문화될 수 있습니다.</p>
<div class="content-ad"></div>
<p>N-HiTS의 저자들은 입력에 가까운 스택은 장기적 효과에 초점을 맞춰야 한다고 제안합니다. 따라서 이러한 스택은 표현 비율이 작아야 합니다. 예를 들어, 세 개의 스택을 가질 수 있습니다. 첫 번째 스택은 주간 행동에 특화되어 있고, 두 번째는 일일 행동에 특화되어 있으며, 세 번째는 시간당 행동에 특화되어 있습니다.</p>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_3.png" alt="N-HiTS"></p>
<p>하지만 표현 비율에 대한 합리적인 선택은 무엇인가요?</p>
<p>그것은 시계열에 따라 다릅니다. 저자들은 두 가지 옵션을 권장합니다.</p>
<div class="content-ad"></div>
<ul>
<li>다양한 주파수 범위를 다룰 때 매개변수의 수를 줄이기 위해 스택 간 지수적으로 증가하는 표현 비율을 사용합니다.</li>
<li>일간, 주간 등의 시계열 주기를 활용합니다.</li>
</ul>
<h1>N-HiTS를 활용한 예측 예시</h1>
<p>N-HiTS가 어떻게 작동하는지 알게 되었으니, 모델을 예측 작업에 적용해 보겠습니다.</p>
<p>N-BEATS 글에서와 마찬가지로, 우리는 독일의 도매 전기 가격을 다음 두 주 예측할 것입니다. 우리는 CC-BY-4.0 라이선스로 제공되는 "유럽 도매 전기 가격" 데이터를 사용할 것입니다. Nixtla의 neuralforecast 라이브러리에서 N-HiTS 구현을 사용할 것입니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_4.png" alt="이미지"></p>
<p>상세한 데이터 탐색을 하지 않아도 두 가지 계절성 구성 요소를 확인할 수 있습니다:</p>
<ul>
<li>일별: 전기 소비량이 이 시간대에 보통 높기 때문에 아침과 저녁 시간에 가격이 더 높습니다.</li>
<li>주간별: 전기 소비량이 평일에 더 높기 때문에 주말보다 평일에 가격이 높습니다.</li>
</ul>
<p>N-BEATS 논문에서 동일한 데이터 집합을 사용했기 때문에 데이터 준비, 훈련-테스트 분할, 결과 시각화 및 기준 모델에 대한 모든 코드를 재사용할 수 있습니다. 따라서 이곳에 코드 조각을 표시하지 않겠습니다.</p>
<div class="content-ad"></div>
<p>코드 작성에 들어가기 전에 가능한 정확한 예측을 얻으려는 것이 아니라 어떻게 N-HiTS를 적용할 수 있는지를 보여주는 것입니다.</p>
<h2>베이스라인 모델</h2>
<p>하지만, 베이스라인으로 간단한 모델부터 시작해 보겠습니다.</p>
<p>이곳에서는 이전에 N-BEATS 기사에서 사용한 계절성이 있는 단순 모델을 사용할 것입니다. 따라서 자세한 내용은 다루지 않고 결과만 보여드리겠습니다.</p>
<div class="content-ad"></div>
<p>훈련 세트의 마지막 주 데이터를 사용하여 예측하면 MAE가 17.84로 나옵니다. 이미 상당히 좋은 성적입니다.</p>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_5.png" alt="이미지"></p>
<h2>N-HiTS 모델 훈련</h2>
<p>첫 번째 N-HiTS 모델을 훈련해 봅시다. Nixtla의 neuralforecast 라이브러리를 사용하므로 구현은 간단합니다. 예측과 과거 기간을 정의하는 N-HiTS 모델을 초기화합니다. 이 경우, 과거 기간을 1주로 설정했습니다.</p>
<div class="content-ad"></div>
<p>그러면 몇 가지 사용자 정의 옵션이 있습니다.</p>
<ul>
<li>모델을 선택하여 스택 및 블록 수, MLP 레이어 크기, 활성화 함수, MaxPooling을 위한 커널 크기, 풀링 유형 등을 사용자 정의할 수 있습니다.</li>
<li>손실 함수, 학습률, 배치 크기 등을 선택하여 학습을 사용자 정의할 수 있습니다.</li>
<li>입력 데이터의 스케일링을 할 수 있습니다.</li>
</ul>
<p>Nixtla의 문서 전체 설명을 보십시오.</p>
<p>N-BEATS 모델과 대조적으로 몇 가지 차이점을 볼 수 있습니다. 우리는 모델을 사용자 정의하기 위해 더 많은 매개변수를 가지고 있습니다. 커널 크기 및 풀링 유형을 선택하여 다중 속도 데이터 샘플링을 사용자 정의할 수 있습니다. 계층적 보간은 보간 유형 및 표현성 비율을 통해 사용자 정의할 수 있습니다. 코드 스니펫에서 이미 일부 하이퍼파라미터를 조정해 보았습니다.</p>
<div class="content-ad"></div>
<p>모델을 초기화한 후에는 neuralforecast 클래스로 래핑하고 모델을 적합시킵니다. N-BEATS 기사를 읽으셨다면 이 단계에 익숙할 것입니다.</p>
<p>결과는 기준선보다 더 좋아졌습니다. MAE는 17.84에서 17.01로 낮아졌습니다.</p>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_6.png" alt="이미지"></p>
<h2>N-HiTS 모델의 하이퍼파라미터 튜닝</h2>
<div class="content-ad"></div>
<p>좋은 하이퍼파라미터를 찾기 위해 시간을 쓰지 말고 최적화를 실행할 수 있어요.</p>
<p>이것은 복잡하지 않아요. 많은 코드 줄을 추가할 필요가 없습니다. NHITS 모델을 Nixtla의 AutoNHITS 모델로 교체하기만 하면 돼요. AutoNHITS 모델이 하이퍼파라미터 튜닝을 대신 해줍니다. 우리는 백엔드(ray 또는 optuna)와 하이퍼파라미터의 탐색 범위를 선택하기만 하면 돼요.</p>
<p>이 두 가지 선택은 NHITS 모델을 실행하는 것과 달리 유일한 차이점입니다. 다른 모든 단계는 동일합니다.</p>
<p>Optuna를 선택하고 사용자 정의 구성 파일을 사용해 시작해봐요.</p>
<div class="content-ad"></div>
<p>"우리는 '최적화된' N-HiTS 모델이 베이스라인과 N-HiTS 모델에 비해 정확도가 더 낮다는 것을 알 수 있습니다 (MAE는 22.63입니다).</p>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_7.png" alt=""></p>
<p>아마도 저의 검색 공간 선택이 좋지 않았을 수도 있습니다. 따라서 더 많은 시도를 해보거나 더 나은 결과를 얻기 위해 다른 검색 공간을 사용할 수 있습니다. 또는 AutoNHITS의 기본 설정을 사용할 수도 있습니다. 모델에 구성을 전달하지 않고 바로 사용하거나 기본 설정을 약간 변경하여 사용할 수 있습니다.</p>
<h2>외생 변수가 포함된 N-HiTS"</h2>
<div class="content-ad"></div>
<p>이 기사를 마치기 전에 마지막으로 보여드릴것이 있습니다. N-HiTS 모델에서 외생 변수를 사용할 수도 있습니다. 이를 위해 초기화 동안 futr_exog_list로 외생 변수를 NHITS 모델에 전달하기만 하면 됩니다. 예를 들어, 주간 계절성이 있는 경우 모델에 요일을 전달할 수 있습니다.</p>
<p>요일을 외생 변수로 추가한 결과 MAE는 21.62가 나왔습니다. 다양한 외생 변수나 다양한 하이퍼파라미터를 시도하면 정확도를 향상시킬 수 있을 것입니다.</p>
<p><img src="/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_8.png" alt="마지막에 관해"></p>
<h1>N-HiTS에 대한 마지막 메모</h1>
<div class="content-ad"></div>
<p>N-HiTS는 논문에서 다양한 데이터 세트에서 매우 좋은 성능을 보였습니다. 그러나 이것은 모든 문제와 데이터 세트에 대해 N-HiTS가 최적의 해결책이 될 것을 의미하지는 않습니다. 특히 당신의 경우에는요.</p>
<p>예시에서 보듯이, N-HiTS가 단순한 계절성 naive baseline 모델을 거의 이길 수 있었습니다. 하지만 그것에 도달하는 데 시간이 걸렸습니다. 먼저, 모델을 설정하고 좋은 하이퍼파라미터 세트를 찾는 데 더 많은 시간을 소비했습니다. 둘째, 훈련은 기준 모델보다 30배가 넘는 시간이 걸렸습니다.</p>
<p>그래서 이것이 회사 프로젝트였다면, 나는 기준 모델을 선택했을 것입니다. 비록 N-HiTS가 약간의 정확도 향상을 제공하지만, 추가 복잡성은 고생할 가치가 없습니다.</p>
<p>따라서, N-HiTS가 사용하기 쉽고 유망한 모델처럼 보여도, 해당 모델로 프로젝트를 시작하지 마십시오. 간단한 기준 모델로 시작하십시오. 기준을 토대로하여, N-HiTS가 문제에 대한 좋은 선택인지를 결정할 수 있습니다. 예를 들어, N-HiTS가 추가된 복잡성에 비해 얼마나 가치를 더하는지를 고려할 수 있습니다.</p>
<div class="content-ad"></div>
<h1>결론</h1>
<p>이 기사는 매우 길었지만 다뤄야 할 내용이 많았습니다. 여기까지 함께 지켜주셨다면, 이제 다음 내용을 이해하실 수 있을 것입니다.</p>
<ul>
<li>N-HiTS 모델이 어떻게 작동하는지에 대해 매우 좋은 이해를 갖게 되었을 것이고,</li>
<li>N-HiTS가 N-BEATS와 어떻게 다른지를 알게 되었을 것이며,</li>
<li>실전에서 N-HiTS 모델을 사용할 수 있을 것이며,</li>
<li>하이퍼파라미터 튜닝 중에 모델의 내부 동작을 변경할 수 있을 것입니다.</li>
</ul>
<p>N-HiTS 모델에 대해 더 깊이 알아보고 싶다면 N-HiTS 논문을 확인해보세요. 그렇지 않다면, 댓글을 남기거나 다음 기사에서 만나요!</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"N-HiTS  시계열 예측을 위한 딥 러닝을 더 효율적으로 만드는 방법","description":"","date":"2024-06-19 18:57","slug":"2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient","content":"\n\n\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png\" /\u003e\n\n2020년에 N-BEATS는 시계열 예측에서 통계적 및 혼합 모델보다 뛰어난 성과를 보인 첫 딥러닝 모델이었습니다.\n\n그 후 2년 뒤인 2022년에 새로운 모델이 N-BEATS를 제쳐놓았습니다. Challu와 Olivares 등이 딥 러닝 모델 N-HiTS를 발표했습니다. 이들은 N-BEATS의 긴 예측 지표에 대한 두 가지 단점을 해결했습니다:\n\n- 정확도의 감소 및\n- 계산량의 증가.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS는 시계열 예측을 위한 Neural Hierarchical Interpolation의 약자입니다.\n\n이 모델은 N-BEATS 및 그 신경 기반 확장 아이디어에 기반을 두고 있습니다. 신경 기반 확장은 계층화된 스택을 통해 여러 블록에서 이루어집니다.\n\n이 글에서는 N-HiTS 뒤에 숨겨진 구조, 특히 N-BEATS와의 차이에 대해 살펴볼 것입니다. 하지만 너무 걱정하지 마세요, 깊이 파고들기가 이해하기 쉬울 거에요. 하지만 N-HiTS 작동 방식을 이해하는 것만으로 충분하지 않습니다. 따라서 Python에서 어떻게 N-HiTS 모델을 쉽게 구현하고 하이퍼파라미터를 튜닝할 수 있는지 보여드릴 거에요.\n\n# 핵심 아이디어가 같다면, N-BEATS와 N-HiTS의 차이는 무엇인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 모델이 각 스택의 입력과 출력을 처리하는 방식에 차이가 있습니다. N-HiTS의 주요 아이디어는 서로 다른 시간 스케일의 예측을 결합하는 것입니다.\n\n이를 위해 N-HiTS는\n\n- 입력의 다중 속도 데이터 샘플링 및\n- 출력의 계층적 보간\n\n을 적용합니다.\n\n이 방법으로 N-HiTS는 더 긴 시계열에 대해 더 나은 정확도와 낮은 계산 비용을 달성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다중 비율 데이터 샘플링은 스택이 단기 또는 장기적 영향에 특화되도록 만듭니다. 이러한 스택이 각각의 구성 요소를 학습하기 쉬워집니다. 장기적 행동에 중점을 둔 것은 N-BEATS에 비해 향상된 장기적 시계열 예측을 이끌어냅니다.\n\n계층적 보간은 각 블록이 서로 다른 시간 단위로 예측하도록 허용합니다. 그런 다음 모델은 각 블록의 시간 단위에 맞게 예측을 보간하여 최종 예측과 일치시킵니다. 재샘플링과 보간은 학습 가능한 매개변수의 수를 줄입니다. 이는 훈련 시간이 더 짧고 가벼운 모델로 이어집니다.\n\n이제 N-HiTS가 어떤 점에서 다르게 작동하는지 알았으니, 이러한 변화가 아키텍처에 어떻게 포함되어 있는지 살펴보겠습니다.\n\n# N-HiTS는 자세히 어떻게 작동하나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS 모델은 다음과 같은 아키텍처를 가지고 있어요:\n\n![N-HiTS 모델](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_1.png)\n\n우리가 볼 수 있듯이, N-BEATS와 많은 유사성을 가지고 있어요.\n\n첫째, N-HiTS는 시계열을 lookback 및 forecast 기간으로 분리해요. 둘째, 해당 모델은 다층 스택과 블록으로 구성되어 있어요, backcast와 forecast를 생성해요. 각 블록에서 다층 퍼셉트론은 backcast와 forecast를 위한 기저 확장 계수를 생성해요. backcast는 블록이 포착한 시계열의 일부를 보여줘요. 우리는 이전 블록의 backcast를 제거하고 시계열을 블록에 전달하기 전에요. 이를 통해 각 블록은 서로 다른 패턴을 학습하게 되어요, 블록 간에 잔차만 전달하기 때문이에요. 해당 모델은 모든 블록의 forecast를 합하여 최종 예측을 생성해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n유사한 부분에 대해서는 이 정도로 설명을 유지하겠습니다. 더 자세한 정보는 제 N-BEATS 글을 참조하시기 바랍니다.\n\n하지만 차이점에 대해서는 더 깊이 파헤쳐 보겠습니다: 다중 속도 데이터 샘플링과 계층적 보간.\n\n## 입력의 다중 속도 신호 샘플링\n\nN-HiTS는 MaxPool 레이어를 통해 블록 수준에서 다중 속도 샘플링을 수행합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMaxPool 레이어는 선택된 커널 크기 내에서 가장 큰 값을 취함으로써 입력을 평활화합니다. 따라서 커널 크기가 샘플링 속도를 결정합니다. 커널 크기가 클수록 평활화가 더 강해집니다.\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_2.png)\n\nMaxPool 레이어의 커널 크기는 스택 레벨에서 정의합니다. 따라서 동일한 스택 내의 각 블록은 동일한 커널 크기를 갖습니다.\n\nN-HiTS는 리샘플링을 위해 위에서 아래로 접근하는 방식을 사용합니다. 첫 번째 스택은 큰 커널 크기를 통해 장기적인 효과에 초점을 맞춥니다. 후속 스택은 작은 커널 크기를 통해 단기적인 효과에 초점을 맞춥니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 출력의 계층 적 보간\n\nN-HiTS는 각 스택의 예측 수, 즉 기수를 줄이기 위해 계층 적 보간을 사용합니다. 더 작은 기수는 장기 예측을 위한 계산 요구 사항을 줄여줍니다.\n\n이게 무슨 말인가요?\n\n시계열의 다음 24시간을 예측하려고 한다고 가정해 봅시다. 우리는 우리 모델이 24개의 예측을 출력할 것을 기대합니다(각 시간당 하나). 시간당 데이터의 다음 두 주를 예측하려면 336개의 예측이 필요합니다(14 * 24). 그게 맞죠?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 이것이 문제가 되는 곳입니다. N-BEATS 모델을 예를 들어봅시다. 최종 예측은 각 스택의 부분 예측을 결합한 것입니다. 따라서 각 스택은 336개의 값을 예측해야 하며, 이는 계산 비용이 많이 듭니다. N-BEATS는 더 긴 예측 범위에서 같은 문제를 겪는 모델 중 하나에 불과합니다. 다른 딥러닝 접근 방식인 트랜스포머나 순환 신경망과 같은 모델들도 같은 문제에 직면하게 됩니다.\n\nN-HiTS는 각 스택이 서로 다른 시간 스케일에서 예측하도록하여 이 도전을 극복합니다. N-HiTS는 각 스택의 시간 스케일을 내삽을 사용하여 최종 출력에 일치시킵니다.\n\n이를 위해 N-HiTS는 표현 간격 비율 개념을 사용합니다. 이 비율은 예측 기간 내의 예측 수를 결정합니다. 작은 표현 간격 비율은 스택이 더 적은 예측을 하도록 만듭니다. 따라서 스택의 기수가 작아집니다. 예를 들어, 1/2의 표현 간격 비율을 선택합니다. 이는 스택이 최종 예측에서 원하는 매 두 번째 값을 예측하게 만듭니다.\n\n표현 간격 비율은 출력을 입력의 재샘플링과 관련시킵니다. 입력의 재샘플링과 결합되어, 각 스택은 서로 다른 주파수에서 작동합니다. 따라서 각 스택은 서로 다른 속도로 시계열을 처리하는 데 전문화될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS의 저자들은 입력에 가까운 스택은 장기적 효과에 초점을 맞춰야 한다고 제안합니다. 따라서 이러한 스택은 표현 비율이 작아야 합니다. 예를 들어, 세 개의 스택을 가질 수 있습니다. 첫 번째 스택은 주간 행동에 특화되어 있고, 두 번째는 일일 행동에 특화되어 있으며, 세 번째는 시간당 행동에 특화되어 있습니다.\n\n![N-HiTS](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_3.png)\n\n하지만 표현 비율에 대한 합리적인 선택은 무엇인가요?\n\n그것은 시계열에 따라 다릅니다. 저자들은 두 가지 옵션을 권장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 다양한 주파수 범위를 다룰 때 매개변수의 수를 줄이기 위해 스택 간 지수적으로 증가하는 표현 비율을 사용합니다.\n- 일간, 주간 등의 시계열 주기를 활용합니다.\n\n# N-HiTS를 활용한 예측 예시\n\nN-HiTS가 어떻게 작동하는지 알게 되었으니, 모델을 예측 작업에 적용해 보겠습니다.\n\nN-BEATS 글에서와 마찬가지로, 우리는 독일의 도매 전기 가격을 다음 두 주 예측할 것입니다. 우리는 CC-BY-4.0 라이선스로 제공되는 \"유럽 도매 전기 가격\" 데이터를 사용할 것입니다. Nixtla의 neuralforecast 라이브러리에서 N-HiTS 구현을 사용할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_4.png)\n\n상세한 데이터 탐색을 하지 않아도 두 가지 계절성 구성 요소를 확인할 수 있습니다:\n\n- 일별: 전기 소비량이 이 시간대에 보통 높기 때문에 아침과 저녁 시간에 가격이 더 높습니다.\n- 주간별: 전기 소비량이 평일에 더 높기 때문에 주말보다 평일에 가격이 높습니다.\n\nN-BEATS 논문에서 동일한 데이터 집합을 사용했기 때문에 데이터 준비, 훈련-테스트 분할, 결과 시각화 및 기준 모델에 대한 모든 코드를 재사용할 수 있습니다. 따라서 이곳에 코드 조각을 표시하지 않겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드 작성에 들어가기 전에 가능한 정확한 예측을 얻으려는 것이 아니라 어떻게 N-HiTS를 적용할 수 있는지를 보여주는 것입니다.\n\n## 베이스라인 모델\n\n하지만, 베이스라인으로 간단한 모델부터 시작해 보겠습니다.\n\n이곳에서는 이전에 N-BEATS 기사에서 사용한 계절성이 있는 단순 모델을 사용할 것입니다. 따라서 자세한 내용은 다루지 않고 결과만 보여드리겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 세트의 마지막 주 데이터를 사용하여 예측하면 MAE가 17.84로 나옵니다. 이미 상당히 좋은 성적입니다.\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_5.png)\n\n## N-HiTS 모델 훈련\n\n첫 번째 N-HiTS 모델을 훈련해 봅시다. Nixtla의 neuralforecast 라이브러리를 사용하므로 구현은 간단합니다. 예측과 과거 기간을 정의하는 N-HiTS 모델을 초기화합니다. 이 경우, 과거 기간을 1주로 설정했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러면 몇 가지 사용자 정의 옵션이 있습니다.\n\n- 모델을 선택하여 스택 및 블록 수, MLP 레이어 크기, 활성화 함수, MaxPooling을 위한 커널 크기, 풀링 유형 등을 사용자 정의할 수 있습니다.\n- 손실 함수, 학습률, 배치 크기 등을 선택하여 학습을 사용자 정의할 수 있습니다.\n- 입력 데이터의 스케일링을 할 수 있습니다.\n\nNixtla의 문서 전체 설명을 보십시오.\n\nN-BEATS 모델과 대조적으로 몇 가지 차이점을 볼 수 있습니다. 우리는 모델을 사용자 정의하기 위해 더 많은 매개변수를 가지고 있습니다. 커널 크기 및 풀링 유형을 선택하여 다중 속도 데이터 샘플링을 사용자 정의할 수 있습니다. 계층적 보간은 보간 유형 및 표현성 비율을 통해 사용자 정의할 수 있습니다. 코드 스니펫에서 이미 일부 하이퍼파라미터를 조정해 보았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델을 초기화한 후에는 neuralforecast 클래스로 래핑하고 모델을 적합시킵니다. N-BEATS 기사를 읽으셨다면 이 단계에 익숙할 것입니다.\n\n결과는 기준선보다 더 좋아졌습니다. MAE는 17.84에서 17.01로 낮아졌습니다.\n\n![이미지](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_6.png)\n\n## N-HiTS 모델의 하이퍼파라미터 튜닝\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n좋은 하이퍼파라미터를 찾기 위해 시간을 쓰지 말고 최적화를 실행할 수 있어요.\n\n이것은 복잡하지 않아요. 많은 코드 줄을 추가할 필요가 없습니다. NHITS 모델을 Nixtla의 AutoNHITS 모델로 교체하기만 하면 돼요. AutoNHITS 모델이 하이퍼파라미터 튜닝을 대신 해줍니다. 우리는 백엔드(ray 또는 optuna)와 하이퍼파라미터의 탐색 범위를 선택하기만 하면 돼요.\n\n이 두 가지 선택은 NHITS 모델을 실행하는 것과 달리 유일한 차이점입니다. 다른 모든 단계는 동일합니다.\n\nOptuna를 선택하고 사용자 정의 구성 파일을 사용해 시작해봐요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"우리는 '최적화된' N-HiTS 모델이 베이스라인과 N-HiTS 모델에 비해 정확도가 더 낮다는 것을 알 수 있습니다 (MAE는 22.63입니다).\n\n![](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_7.png)\n\n아마도 저의 검색 공간 선택이 좋지 않았을 수도 있습니다. 따라서 더 많은 시도를 해보거나 더 나은 결과를 얻기 위해 다른 검색 공간을 사용할 수 있습니다. 또는 AutoNHITS의 기본 설정을 사용할 수도 있습니다. 모델에 구성을 전달하지 않고 바로 사용하거나 기본 설정을 약간 변경하여 사용할 수 있습니다.\n\n## 외생 변수가 포함된 N-HiTS\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사를 마치기 전에 마지막으로 보여드릴것이 있습니다. N-HiTS 모델에서 외생 변수를 사용할 수도 있습니다. 이를 위해 초기화 동안 futr_exog_list로 외생 변수를 NHITS 모델에 전달하기만 하면 됩니다. 예를 들어, 주간 계절성이 있는 경우 모델에 요일을 전달할 수 있습니다.\n\n요일을 외생 변수로 추가한 결과 MAE는 21.62가 나왔습니다. 다양한 외생 변수나 다양한 하이퍼파라미터를 시도하면 정확도를 향상시킬 수 있을 것입니다.\n\n![마지막에 관해](/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_8.png)\n\n# N-HiTS에 대한 마지막 메모\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nN-HiTS는 논문에서 다양한 데이터 세트에서 매우 좋은 성능을 보였습니다. 그러나 이것은 모든 문제와 데이터 세트에 대해 N-HiTS가 최적의 해결책이 될 것을 의미하지는 않습니다. 특히 당신의 경우에는요.\n\n예시에서 보듯이, N-HiTS가 단순한 계절성 naive baseline 모델을 거의 이길 수 있었습니다. 하지만 그것에 도달하는 데 시간이 걸렸습니다. 먼저, 모델을 설정하고 좋은 하이퍼파라미터 세트를 찾는 데 더 많은 시간을 소비했습니다. 둘째, 훈련은 기준 모델보다 30배가 넘는 시간이 걸렸습니다.\n\n그래서 이것이 회사 프로젝트였다면, 나는 기준 모델을 선택했을 것입니다. 비록 N-HiTS가 약간의 정확도 향상을 제공하지만, 추가 복잡성은 고생할 가치가 없습니다.\n\n따라서, N-HiTS가 사용하기 쉽고 유망한 모델처럼 보여도, 해당 모델로 프로젝트를 시작하지 마십시오. 간단한 기준 모델로 시작하십시오. 기준을 토대로하여, N-HiTS가 문제에 대한 좋은 선택인지를 결정할 수 있습니다. 예를 들어, N-HiTS가 추가된 복잡성에 비해 얼마나 가치를 더하는지를 고려할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n이 기사는 매우 길었지만 다뤄야 할 내용이 많았습니다. 여기까지 함께 지켜주셨다면, 이제 다음 내용을 이해하실 수 있을 것입니다.\n\n- N-HiTS 모델이 어떻게 작동하는지에 대해 매우 좋은 이해를 갖게 되었을 것이고,\n- N-HiTS가 N-BEATS와 어떻게 다른지를 알게 되었을 것이며,\n- 실전에서 N-HiTS 모델을 사용할 수 있을 것이며,\n- 하이퍼파라미터 튜닝 중에 모델의 내부 동작을 변경할 수 있을 것입니다.\n\nN-HiTS 모델에 대해 더 깊이 알아보고 싶다면 N-HiTS 논문을 확인해보세요. 그렇지 않다면, 댓글을 남기거나 다음 기사에서 만나요!","ogImage":{"url":"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png"},"coverImage":"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_0.png\"\u003e\n\u003cp\u003e2020년에 N-BEATS는 시계열 예측에서 통계적 및 혼합 모델보다 뛰어난 성과를 보인 첫 딥러닝 모델이었습니다.\u003c/p\u003e\n\u003cp\u003e그 후 2년 뒤인 2022년에 새로운 모델이 N-BEATS를 제쳐놓았습니다. Challu와 Olivares 등이 딥 러닝 모델 N-HiTS를 발표했습니다. 이들은 N-BEATS의 긴 예측 지표에 대한 두 가지 단점을 해결했습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e정확도의 감소 및\u003c/li\u003e\n\u003cli\u003e계산량의 증가.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eN-HiTS는 시계열 예측을 위한 Neural Hierarchical Interpolation의 약자입니다.\u003c/p\u003e\n\u003cp\u003e이 모델은 N-BEATS 및 그 신경 기반 확장 아이디어에 기반을 두고 있습니다. 신경 기반 확장은 계층화된 스택을 통해 여러 블록에서 이루어집니다.\u003c/p\u003e\n\u003cp\u003e이 글에서는 N-HiTS 뒤에 숨겨진 구조, 특히 N-BEATS와의 차이에 대해 살펴볼 것입니다. 하지만 너무 걱정하지 마세요, 깊이 파고들기가 이해하기 쉬울 거에요. 하지만 N-HiTS 작동 방식을 이해하는 것만으로 충분하지 않습니다. 따라서 Python에서 어떻게 N-HiTS 모델을 쉽게 구현하고 하이퍼파라미터를 튜닝할 수 있는지 보여드릴 거에요.\u003c/p\u003e\n\u003ch1\u003e핵심 아이디어가 같다면, N-BEATS와 N-HiTS의 차이는 무엇인가요?\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e각 모델이 각 스택의 입력과 출력을 처리하는 방식에 차이가 있습니다. N-HiTS의 주요 아이디어는 서로 다른 시간 스케일의 예측을 결합하는 것입니다.\u003c/p\u003e\n\u003cp\u003e이를 위해 N-HiTS는\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e입력의 다중 속도 데이터 샘플링 및\u003c/li\u003e\n\u003cli\u003e출력의 계층적 보간\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e을 적용합니다.\u003c/p\u003e\n\u003cp\u003e이 방법으로 N-HiTS는 더 긴 시계열에 대해 더 나은 정확도와 낮은 계산 비용을 달성합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e다중 비율 데이터 샘플링은 스택이 단기 또는 장기적 영향에 특화되도록 만듭니다. 이러한 스택이 각각의 구성 요소를 학습하기 쉬워집니다. 장기적 행동에 중점을 둔 것은 N-BEATS에 비해 향상된 장기적 시계열 예측을 이끌어냅니다.\u003c/p\u003e\n\u003cp\u003e계층적 보간은 각 블록이 서로 다른 시간 단위로 예측하도록 허용합니다. 그런 다음 모델은 각 블록의 시간 단위에 맞게 예측을 보간하여 최종 예측과 일치시킵니다. 재샘플링과 보간은 학습 가능한 매개변수의 수를 줄입니다. 이는 훈련 시간이 더 짧고 가벼운 모델로 이어집니다.\u003c/p\u003e\n\u003cp\u003e이제 N-HiTS가 어떤 점에서 다르게 작동하는지 알았으니, 이러한 변화가 아키텍처에 어떻게 포함되어 있는지 살펴보겠습니다.\u003c/p\u003e\n\u003ch1\u003eN-HiTS는 자세히 어떻게 작동하나요?\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eN-HiTS 모델은 다음과 같은 아키텍처를 가지고 있어요:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_1.png\" alt=\"N-HiTS 모델\"\u003e\u003c/p\u003e\n\u003cp\u003e우리가 볼 수 있듯이, N-BEATS와 많은 유사성을 가지고 있어요.\u003c/p\u003e\n\u003cp\u003e첫째, N-HiTS는 시계열을 lookback 및 forecast 기간으로 분리해요. 둘째, 해당 모델은 다층 스택과 블록으로 구성되어 있어요, backcast와 forecast를 생성해요. 각 블록에서 다층 퍼셉트론은 backcast와 forecast를 위한 기저 확장 계수를 생성해요. backcast는 블록이 포착한 시계열의 일부를 보여줘요. 우리는 이전 블록의 backcast를 제거하고 시계열을 블록에 전달하기 전에요. 이를 통해 각 블록은 서로 다른 패턴을 학습하게 되어요, 블록 간에 잔차만 전달하기 때문이에요. 해당 모델은 모든 블록의 forecast를 합하여 최종 예측을 생성해요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e유사한 부분에 대해서는 이 정도로 설명을 유지하겠습니다. 더 자세한 정보는 제 N-BEATS 글을 참조하시기 바랍니다.\u003c/p\u003e\n\u003cp\u003e하지만 차이점에 대해서는 더 깊이 파헤쳐 보겠습니다: 다중 속도 데이터 샘플링과 계층적 보간.\u003c/p\u003e\n\u003ch2\u003e입력의 다중 속도 신호 샘플링\u003c/h2\u003e\n\u003cp\u003eN-HiTS는 MaxPool 레이어를 통해 블록 수준에서 다중 속도 샘플링을 수행합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eMaxPool 레이어는 선택된 커널 크기 내에서 가장 큰 값을 취함으로써 입력을 평활화합니다. 따라서 커널 크기가 샘플링 속도를 결정합니다. 커널 크기가 클수록 평활화가 더 강해집니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eMaxPool 레이어의 커널 크기는 스택 레벨에서 정의합니다. 따라서 동일한 스택 내의 각 블록은 동일한 커널 크기를 갖습니다.\u003c/p\u003e\n\u003cp\u003eN-HiTS는 리샘플링을 위해 위에서 아래로 접근하는 방식을 사용합니다. 첫 번째 스택은 큰 커널 크기를 통해 장기적인 효과에 초점을 맞춥니다. 후속 스택은 작은 커널 크기를 통해 단기적인 효과에 초점을 맞춥니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e출력의 계층 적 보간\u003c/h2\u003e\n\u003cp\u003eN-HiTS는 각 스택의 예측 수, 즉 기수를 줄이기 위해 계층 적 보간을 사용합니다. 더 작은 기수는 장기 예측을 위한 계산 요구 사항을 줄여줍니다.\u003c/p\u003e\n\u003cp\u003e이게 무슨 말인가요?\u003c/p\u003e\n\u003cp\u003e시계열의 다음 24시간을 예측하려고 한다고 가정해 봅시다. 우리는 우리 모델이 24개의 예측을 출력할 것을 기대합니다(각 시간당 하나). 시간당 데이터의 다음 두 주를 예측하려면 336개의 예측이 필요합니다(14 * 24). 그게 맞죠?\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그러나 이것이 문제가 되는 곳입니다. N-BEATS 모델을 예를 들어봅시다. 최종 예측은 각 스택의 부분 예측을 결합한 것입니다. 따라서 각 스택은 336개의 값을 예측해야 하며, 이는 계산 비용이 많이 듭니다. N-BEATS는 더 긴 예측 범위에서 같은 문제를 겪는 모델 중 하나에 불과합니다. 다른 딥러닝 접근 방식인 트랜스포머나 순환 신경망과 같은 모델들도 같은 문제에 직면하게 됩니다.\u003c/p\u003e\n\u003cp\u003eN-HiTS는 각 스택이 서로 다른 시간 스케일에서 예측하도록하여 이 도전을 극복합니다. N-HiTS는 각 스택의 시간 스케일을 내삽을 사용하여 최종 출력에 일치시킵니다.\u003c/p\u003e\n\u003cp\u003e이를 위해 N-HiTS는 표현 간격 비율 개념을 사용합니다. 이 비율은 예측 기간 내의 예측 수를 결정합니다. 작은 표현 간격 비율은 스택이 더 적은 예측을 하도록 만듭니다. 따라서 스택의 기수가 작아집니다. 예를 들어, 1/2의 표현 간격 비율을 선택합니다. 이는 스택이 최종 예측에서 원하는 매 두 번째 값을 예측하게 만듭니다.\u003c/p\u003e\n\u003cp\u003e표현 간격 비율은 출력을 입력의 재샘플링과 관련시킵니다. 입력의 재샘플링과 결합되어, 각 스택은 서로 다른 주파수에서 작동합니다. 따라서 각 스택은 서로 다른 속도로 시계열을 처리하는 데 전문화될 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eN-HiTS의 저자들은 입력에 가까운 스택은 장기적 효과에 초점을 맞춰야 한다고 제안합니다. 따라서 이러한 스택은 표현 비율이 작아야 합니다. 예를 들어, 세 개의 스택을 가질 수 있습니다. 첫 번째 스택은 주간 행동에 특화되어 있고, 두 번째는 일일 행동에 특화되어 있으며, 세 번째는 시간당 행동에 특화되어 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_3.png\" alt=\"N-HiTS\"\u003e\u003c/p\u003e\n\u003cp\u003e하지만 표현 비율에 대한 합리적인 선택은 무엇인가요?\u003c/p\u003e\n\u003cp\u003e그것은 시계열에 따라 다릅니다. 저자들은 두 가지 옵션을 권장합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e다양한 주파수 범위를 다룰 때 매개변수의 수를 줄이기 위해 스택 간 지수적으로 증가하는 표현 비율을 사용합니다.\u003c/li\u003e\n\u003cli\u003e일간, 주간 등의 시계열 주기를 활용합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eN-HiTS를 활용한 예측 예시\u003c/h1\u003e\n\u003cp\u003eN-HiTS가 어떻게 작동하는지 알게 되었으니, 모델을 예측 작업에 적용해 보겠습니다.\u003c/p\u003e\n\u003cp\u003eN-BEATS 글에서와 마찬가지로, 우리는 독일의 도매 전기 가격을 다음 두 주 예측할 것입니다. 우리는 CC-BY-4.0 라이선스로 제공되는 \"유럽 도매 전기 가격\" 데이터를 사용할 것입니다. Nixtla의 neuralforecast 라이브러리에서 N-HiTS 구현을 사용할 것입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_4.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e상세한 데이터 탐색을 하지 않아도 두 가지 계절성 구성 요소를 확인할 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e일별: 전기 소비량이 이 시간대에 보통 높기 때문에 아침과 저녁 시간에 가격이 더 높습니다.\u003c/li\u003e\n\u003cli\u003e주간별: 전기 소비량이 평일에 더 높기 때문에 주말보다 평일에 가격이 높습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eN-BEATS 논문에서 동일한 데이터 집합을 사용했기 때문에 데이터 준비, 훈련-테스트 분할, 결과 시각화 및 기준 모델에 대한 모든 코드를 재사용할 수 있습니다. 따라서 이곳에 코드 조각을 표시하지 않겠습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e코드 작성에 들어가기 전에 가능한 정확한 예측을 얻으려는 것이 아니라 어떻게 N-HiTS를 적용할 수 있는지를 보여주는 것입니다.\u003c/p\u003e\n\u003ch2\u003e베이스라인 모델\u003c/h2\u003e\n\u003cp\u003e하지만, 베이스라인으로 간단한 모델부터 시작해 보겠습니다.\u003c/p\u003e\n\u003cp\u003e이곳에서는 이전에 N-BEATS 기사에서 사용한 계절성이 있는 단순 모델을 사용할 것입니다. 따라서 자세한 내용은 다루지 않고 결과만 보여드리겠습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e훈련 세트의 마지막 주 데이터를 사용하여 예측하면 MAE가 17.84로 나옵니다. 이미 상당히 좋은 성적입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_5.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch2\u003eN-HiTS 모델 훈련\u003c/h2\u003e\n\u003cp\u003e첫 번째 N-HiTS 모델을 훈련해 봅시다. Nixtla의 neuralforecast 라이브러리를 사용하므로 구현은 간단합니다. 예측과 과거 기간을 정의하는 N-HiTS 모델을 초기화합니다. 이 경우, 과거 기간을 1주로 설정했습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그러면 몇 가지 사용자 정의 옵션이 있습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e모델을 선택하여 스택 및 블록 수, MLP 레이어 크기, 활성화 함수, MaxPooling을 위한 커널 크기, 풀링 유형 등을 사용자 정의할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e손실 함수, 학습률, 배치 크기 등을 선택하여 학습을 사용자 정의할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e입력 데이터의 스케일링을 할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNixtla의 문서 전체 설명을 보십시오.\u003c/p\u003e\n\u003cp\u003eN-BEATS 모델과 대조적으로 몇 가지 차이점을 볼 수 있습니다. 우리는 모델을 사용자 정의하기 위해 더 많은 매개변수를 가지고 있습니다. 커널 크기 및 풀링 유형을 선택하여 다중 속도 데이터 샘플링을 사용자 정의할 수 있습니다. 계층적 보간은 보간 유형 및 표현성 비율을 통해 사용자 정의할 수 있습니다. 코드 스니펫에서 이미 일부 하이퍼파라미터를 조정해 보았습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모델을 초기화한 후에는 neuralforecast 클래스로 래핑하고 모델을 적합시킵니다. N-BEATS 기사를 읽으셨다면 이 단계에 익숙할 것입니다.\u003c/p\u003e\n\u003cp\u003e결과는 기준선보다 더 좋아졌습니다. MAE는 17.84에서 17.01로 낮아졌습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_6.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch2\u003eN-HiTS 모델의 하이퍼파라미터 튜닝\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e좋은 하이퍼파라미터를 찾기 위해 시간을 쓰지 말고 최적화를 실행할 수 있어요.\u003c/p\u003e\n\u003cp\u003e이것은 복잡하지 않아요. 많은 코드 줄을 추가할 필요가 없습니다. NHITS 모델을 Nixtla의 AutoNHITS 모델로 교체하기만 하면 돼요. AutoNHITS 모델이 하이퍼파라미터 튜닝을 대신 해줍니다. 우리는 백엔드(ray 또는 optuna)와 하이퍼파라미터의 탐색 범위를 선택하기만 하면 돼요.\u003c/p\u003e\n\u003cp\u003e이 두 가지 선택은 NHITS 모델을 실행하는 것과 달리 유일한 차이점입니다. 다른 모든 단계는 동일합니다.\u003c/p\u003e\n\u003cp\u003eOptuna를 선택하고 사용자 정의 구성 파일을 사용해 시작해봐요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\"우리는 '최적화된' N-HiTS 모델이 베이스라인과 N-HiTS 모델에 비해 정확도가 더 낮다는 것을 알 수 있습니다 (MAE는 22.63입니다).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_7.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e아마도 저의 검색 공간 선택이 좋지 않았을 수도 있습니다. 따라서 더 많은 시도를 해보거나 더 나은 결과를 얻기 위해 다른 검색 공간을 사용할 수 있습니다. 또는 AutoNHITS의 기본 설정을 사용할 수도 있습니다. 모델에 구성을 전달하지 않고 바로 사용하거나 기본 설정을 약간 변경하여 사용할 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e외생 변수가 포함된 N-HiTS\"\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 기사를 마치기 전에 마지막으로 보여드릴것이 있습니다. N-HiTS 모델에서 외생 변수를 사용할 수도 있습니다. 이를 위해 초기화 동안 futr_exog_list로 외생 변수를 NHITS 모델에 전달하기만 하면 됩니다. 예를 들어, 주간 계절성이 있는 경우 모델에 요일을 전달할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e요일을 외생 변수로 추가한 결과 MAE는 21.62가 나왔습니다. 다양한 외생 변수나 다양한 하이퍼파라미터를 시도하면 정확도를 향상시킬 수 있을 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient_8.png\" alt=\"마지막에 관해\"\u003e\u003c/p\u003e\n\u003ch1\u003eN-HiTS에 대한 마지막 메모\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eN-HiTS는 논문에서 다양한 데이터 세트에서 매우 좋은 성능을 보였습니다. 그러나 이것은 모든 문제와 데이터 세트에 대해 N-HiTS가 최적의 해결책이 될 것을 의미하지는 않습니다. 특히 당신의 경우에는요.\u003c/p\u003e\n\u003cp\u003e예시에서 보듯이, N-HiTS가 단순한 계절성 naive baseline 모델을 거의 이길 수 있었습니다. 하지만 그것에 도달하는 데 시간이 걸렸습니다. 먼저, 모델을 설정하고 좋은 하이퍼파라미터 세트를 찾는 데 더 많은 시간을 소비했습니다. 둘째, 훈련은 기준 모델보다 30배가 넘는 시간이 걸렸습니다.\u003c/p\u003e\n\u003cp\u003e그래서 이것이 회사 프로젝트였다면, 나는 기준 모델을 선택했을 것입니다. 비록 N-HiTS가 약간의 정확도 향상을 제공하지만, 추가 복잡성은 고생할 가치가 없습니다.\u003c/p\u003e\n\u003cp\u003e따라서, N-HiTS가 사용하기 쉽고 유망한 모델처럼 보여도, 해당 모델로 프로젝트를 시작하지 마십시오. 간단한 기준 모델로 시작하십시오. 기준을 토대로하여, N-HiTS가 문제에 대한 좋은 선택인지를 결정할 수 있습니다. 예를 들어, N-HiTS가 추가된 복잡성에 비해 얼마나 가치를 더하는지를 고려할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e이 기사는 매우 길었지만 다뤄야 할 내용이 많았습니다. 여기까지 함께 지켜주셨다면, 이제 다음 내용을 이해하실 수 있을 것입니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eN-HiTS 모델이 어떻게 작동하는지에 대해 매우 좋은 이해를 갖게 되었을 것이고,\u003c/li\u003e\n\u003cli\u003eN-HiTS가 N-BEATS와 어떻게 다른지를 알게 되었을 것이며,\u003c/li\u003e\n\u003cli\u003e실전에서 N-HiTS 모델을 사용할 수 있을 것이며,\u003c/li\u003e\n\u003cli\u003e하이퍼파라미터 튜닝 중에 모델의 내부 동작을 변경할 수 있을 것입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eN-HiTS 모델에 대해 더 깊이 알아보고 싶다면 N-HiTS 논문을 확인해보세요. 그렇지 않다면, 댓글을 남기거나 다음 기사에서 만나요!\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-N-HiTSMakingDeepLearningforTimeSeriesForecastingMoreEfficient"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>