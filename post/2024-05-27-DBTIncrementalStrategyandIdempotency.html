<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>DBT 증분 전략과 동등성 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-05-27-DBTIncrementalStrategyandIdempotency" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="DBT 증분 전략과 동등성 | itposting" data-gatsby-head="true"/><meta property="og:title" content="DBT 증분 전략과 동등성 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-27-DBTIncrementalStrategyandIdempotency_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-05-27-DBTIncrementalStrategyandIdempotency" data-gatsby-head="true"/><meta name="twitter:title" content="DBT 증분 전략과 동등성 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-27-DBTIncrementalStrategyandIdempotency_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-27 12:53" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-0fd008072af5a644.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">DBT 증분 전략과 동등성</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="DBT 증분 전략과 동등성" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 27, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-27-DBTIncrementalStrategyandIdempotency&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/assets/img/2024-05-27-DBTIncrementalStrategyandIdempotency_0.png" alt="Screenshot"></p>
<h1>배경</h1>
<p>안녕하세요, 저는 데이터 엔지니어인 Todd입니다. 저는 Nowcast에서 데이터 온보딩에 주로 관여하고 있습니다. 이 기술 블로그에서는 Nowcast에서의 ETL 파이프라인 디자인의 간략한 역사를 소개하고, Airflow와 DBT의 "Incremental Models" 사이에서 발생한 문제를 설명하고 우리가 개발한 해결책을 소개하겠습니다.</p>
<h1>Python으로 ETL</h1>
<p>역사적으로 Nowcast에서는 ETL 파이프라인을 Python을 사용하여 작성했습니다. 이 파이프라인은 AWS S3, Athena, RDBMS 등에 저장된 데이터에 변환을 적용하는 많은 Python 스크립트로 구성되어 있었습니다. 우리는 이러한 스크립트를 포함하는 도커 이미지를 작성하여 ECR에 업로드하고, Airflow에서 ECS 작업을 호출했습니다. 이러한 스크립트는 보통 데이트와 같은 파티션 필드를 매개변수로 사용하여 멱등성이 있도록 설계되었습니다. 즉, 2024-01-01을 전달하면 2024-01-01의 데이터가 처리되었습니다.</p>
<p>이러한 스크립트 중 하나를 호출할 때, 실제로 실행되는 명령은 아래와 같이 보일 것입니다. 이때 데이트 매개변수는 Airflow에서 관리됩니다:</p>
<pre><code class="hljs language-js">python transform_data.<span class="hljs-property">py</span> <span class="hljs-number">2024</span>-<span class="hljs-number">01</span>-<span class="hljs-number">01</span> --some --other --<span class="hljs-variable language_">arguments</span>
</code></pre>
<h1>Airflow</h1>
<p>Airflow은 Nowcast에서 많은 해동안 사용되어온 스케줄링 및 워크플로우 관리 도구입니다. 기본적으로 두 가지로 사용되고 있어요:</p>
<ol>
<li>작업 스케줄러</li>
<li>작업 의존성 관리</li>
</ol>
<p>역사적으로 Airflow는 매일 실행되며 여러 Python 스크립트에 '실행 날짜' 매개변수를 전달하여 데이터를 처리합니다. 문제가 발생하거나 특정 기간의 작업을 다시 실행해야 할 때는 Airflow DAG에서 해당 작업을 다시 실행할 수 있습니다. 예를 들어, 2024년 01월 01일에 어떤 데이터 변환 스크립트가 실패하면 문제를 식별하고 수정한 후 해당 스크립트를 다시 실행할 수 있어요. 이는 스크립트가 한 번에 하나의 파티션만 처리하고 날짜를 매개변수로 입력받기 때문에 가능한 일입니다.</p>
<h1>DBT에서 ETL</h1>
<p>2022년 말쯤 Python ETL 플로우를 Snowflake로 이전하기 시작했습니다. 그 결과 더 빠르고 저렴하며 깨끗한 파이프라인이 만들어졌어요. 우리는 파이프라인 실행 도구로 DBT를 사용하기로 결정했습니다 — DBT는 SQL 위에 위치한 레이어로 DB 모델 정의, 템플릿, 의존성 관리 및 데이터 회귀 테스트와 같은 다양한 기능을 포함하고 있어요. 빠르고 효율적으로 ETL 파이프라인을 구축하는 데 매우 유용한 도구입니다. 파이썬에서는 파이프라인의 각 변환을 스크립트로 작성하지만, DBT에서는 템플릿화된 SQL CTAS 쿼리로 작성됩니다. 이 쿼리들은 복잡한 수천 줄의 코드로 이루어진 스크립트와 비교했을 때 매우 읽기 쉽습니다.</p>
<p>Best practise in DBT is to use Incremental Models:</p>
<h1>Incremental Models</h1>
<p>Incremental models are an efficient way of defining how to (incrementally) add data to our SQL models — consider we have a table that describes credit card transactions — we can make a DBT model (CTAS) that looks something like this:</p>
<pre><code class="hljs language-js">{
 materialized=<span class="hljs-string">"table"</span>
}
select
 transaction_id,
 transaction_date,
 user_id,
 store_name_description,
 transaction_amount
<span class="hljs-keyword">from</span> { <span class="hljs-title function_">ref</span>(<span class="hljs-string">'external_table_transaction'</span>) }
</code></pre>
<p>이 코드는 table external_table_transaction에서 거래 데이터를 불러오는 테이블을 만듭니다. 문제는이 쿼리를 다시 실행할 때마다 전체 테이블을 다시로드한다는 것입니다. 테이블에 데이터가 많아질수록 쿼리가 느려지고 비용이 많이 발생합니다. 이 문제의 해결책은 증분 모델을 사용하는 것입니다:</p>
<pre><code class="hljs language-js">{
 <span class="hljs-title function_">config</span>(
 materialized=<span class="hljs-string">"incremental"</span>,
 unique_key=[<span class="hljs-string">"transaction_id"</span>],
 incremental_strategy=<span class="hljs-string">"delete+insert"</span>,
 )
}
select
 transaction_id,
 transaction_date,
 user_id,
 store_name_description,
 transaction_amount
<span class="hljs-keyword">from</span> { <span class="hljs-title function_">ref</span>(<span class="hljs-string">'external_table_transaction'</span>) }
 {- <span class="hljs-keyword">if</span> <span class="hljs-title function_">is_incremental</span>() }
 where transaction_date = (select <span class="hljs-title function_">max</span>(transaction_date) + <span class="hljs-number">1</span> <span class="hljs-keyword">as</span> next_date <span class="hljs-keyword">from</span> { <span class="hljs-variable language_">this</span> })
{- endif }
</code></pre>
<p>여기에서 우리는 DBT를 강력하게 만드는 일부 매크로/템플릿 기능을 볼 수 있습니다. 이제 기본적으로 하는 것은 테이블의 최신 데이터보다 1일이 더 늦은 거래 데이터만 external_table_transaction에서 로드해야 한다는 것입니다. 이것은 간단하면서도 강력합니다. 업데이트마다 계속 커지는 수십억 개의 데이터 행 처리 대신 이제 이전에 볼 수 없던 행만 처리하면 됩니다. 그리고 필요하다면 전체 갱신으로 테이블을 다시로드할 수 있는 옵션도 있습니다.</p>
<h1>문제</h1>
<p>점진적 모델은 매우 매력적입니다 — 수학적으로 아름답고 데이터 스트림을 다룰 때 매우 잘 작동합니다. 문제는 처리하려는 데이터를 제어해야 할 때 발생합니다 — 점진적 모델은 특정 파티션만 다시 실행할 수 없으며 대신에 증분 모델의 규칙에 따라 데이터를 로드합니다. 이론적으로는 문제가 되지 않을 수도 있지만, 점진적 모델이 이상적인 환경에서 실행된다면 모든 데이터가 정확히 한 번만 로드될 것입니다 — 하지만 현실은 복잡합니다 — DAG가 깨지고, 데이터가 늦게 전달되거나 아예 제공되지 않는 경우가 발생하며 때로는 역사적 기록을 다시 로드해야 할 때가 있습니다. 게다가 Airflow 파이프라인이 어떤 이유로든 실패할 경우 DBT 작업이 Airflow 실행과 동기화되지 않을 수 있습니다. Nowcast로 마이그레이션한 이후 DBT를 사용하면서 경험한 점진적 모델과 관련된 이슈 목록이 아래에 나와 있습니다:</p>
<ul>
<li>한 파이프라인에서 수리가 진행된 것이 있었는데, 이는 2년 전으로 거슬러 올라가야 했으므로 역사적 데이터를 로드해야 했는데 (증분) 데이터 파이프라인이 역사적 재실행을 처리할 수 없어서 즉시 처리해야 했습니다.</li>
<li>다른 DAG에서 상류 이슈로 3일 동안 깨졌으며, 3일 동안 데이터가 로드되지 않았고, DAG가 4일째 실행될 때 1일부터 데이터를 로드했으므로 동기화가 맞지 않았습니다.</li>
<li>세 번째 파이프라인에서 상류 스킵 날짜(데이터가 빠진 날)가 발생했고, 점진적 모델은 데이터를 로드하기 위해 데이터에서 최대 날짜에 <code>1</code>을 추가하는 방식으로 처리했으나 해당 날짜가 나타나지 않아 데이터가 로드되지 않은 채로 수동 처리가 필요해졌습니다.</li>
</ul>
<p>하지만 우리는 단순히 점진적 모델을 포기할 수 없습니다 — 일부 파이프라인은 수십억 개의 행을 처리해야 하므로, 테이블을 대량으로 처리할 쿼리를 작성하면 느리고 비용이 많이 소요될 것입니다.</p>
<h1>동형성(idempotency) 및 분할의 중요성.</h1>
<p>점진적 모델의 주요 문제는 이 모델이 멱등성을 갖지 않으며 특정 파티션에 대해 실행 구성이 불가능하다는 것입니다. 우리가 ETL 파이프라인에 대해 예전에 채택한 방식은 멱등 스크립트가 여러 번 다시 실행할 수 있는 횟수에 제한이 없는 것이었습니다. 과거 데이터에 문제가 발생하면 특정 파티션을 다시 생성할 수 있었고, 스크립트가 멱등성을 가졌기 때문에 특정한 날짜를 여러 번 실행해도 문제가 발생하지 않았습니다. 하지만 점진적 모델은 데이터의 특정 파티션을 다시 실행할 수 있는 능력이 없으며, 대신 모든 데이터를 스트림처럼 처리하여 보지 않은 데이터만을 로드합니다. 다시 말해 특정 규칙을 충족하는 데이터를 로드하는 것이죠.</p>
<p>우리가 Airflow라는 스케줄링 도구를 사용하고 있기 때문에 데이터 파이프라인은 어떤 종류의 시간적 분할과 일치해야 합니다. 시간별, 일별, 주별, 월별 등 다양한 분할 방식이 될 수 있지만 중요한 점은 Airflow가 어떤 일정에 따라 실행되고 있다는 것입니다. 만약 과거 Airflow 작업을 다시 실행한다면 해당 작업을 호출할 때 해당하는 시간적 파티션에 맞게 실행되기를 기대하지만, 점진적 모델은 항상 앞으로만 '보기' 때문에 과거의 파티션에 대해 구성되지 않습니다. 이것은 Airflow에서 작업을 실행할 때 예상하는 것과는 다릅니다.</p>
<p>하루마다 실행되는 2개의 Airflow DAG를 고려해보죠. 하나의 DAG는 매개변수로 날짜를 사용하여 해당 파티션만 실행하는 작업을 가지고 있습니다. 다른 DAG는 점진적 모델을 사용하며 실행할 때 보지 않은 데이터를 처리합니다. 둘 다 정상적으로 실행될 때 이전에 보지 못한 일별 데이터를 처리하게 되며 두 DAG는 동일하게 동작합니다. 하지만 문제가 발생하여 특정 날짜인 2024년 1월 1일을 다시 로드해야 할 때는 어떨까요? 파티션화된 DAG는 예상대로동작하여 2024년 1월 1일을 다시 실행할 것이지만, 점진적 모델은 Airflow에 전달되는 날짜와 관계없이 이전에 본 적 없는 데이터만을 로드할 것입니다.</p>
<p>점진적 모델의 한계에 대해 논평한 댓글에서는:</p>
<p>간단히 말하면 - Airflow와 같은 일정 관리 도구를 사용할 때 시간 분할을 기대하는 경우, 점진적 모델이 잘 작동하지 않습니다.</p>
<h1>해결책</h1>
<p>해결책은 간단합니다 - DBT 변수를 사용할 수 있습니다. 또한 점진적 모델의 기능을 완전히 포기할 필요가 없습니다. 하나 이상의 변수를 추가하여 하나 이상의 분할에 명시적으로 실행할 수 있습니다:</p>
<pre><code class="hljs language-js">{- set target_date = <span class="hljs-title function_">var</span>(<span class="hljs-string">"target_date"</span>, <span class="hljs-string">""</span>) }
{
 <span class="hljs-title function_">config</span>(
 materialized=<span class="hljs-string">"incremental"</span>,
 unique_key=[<span class="hljs-string">"transaction_id"</span>],
 incremental_strategy=<span class="hljs-string">"delete+insert"</span>,
 )
}
select
 transaction_id,
 transaction_date,
 user_id,
 store_name_description,
 transaction_amount
<span class="hljs-keyword">from</span> { <span class="hljs-title function_">ref</span>(<span class="hljs-string">'external_table_transaction'</span>) }
{- <span class="hljs-keyword">if</span> target_date != <span class="hljs-string">""</span> }
 where transaction_date = <span class="hljs-string">'{ target_date }'</span>
{- <span class="hljs-keyword">else</span> }
 {- <span class="hljs-keyword">if</span> <span class="hljs-title function_">is_incremental</span>() }
 where transaction_date = (select <span class="hljs-title function_">max</span>(transaction_date) + <span class="hljs-number">1</span> <span class="hljs-keyword">as</span> next_date <span class="hljs-keyword">from</span> { <span class="hljs-variable language_">this</span> })
 {- endif }
{- endif }
</code></pre>
<p>이것은 DBT 모델에 <code>target_date</code>라는 새 매개변수를 추가합니다. <code>target_date</code>가 정의되지 않은 경우 모델은 증분 동작으로 실행되지만, 변수가 전달된 경우 지정된 파티션에 대해 실행됩니다. 이 모델 구조화 방식은 Airflow에서 호출될 때 훨씬 더 잘 작동합니다.</p>
<p>게다가, 이 모델은 이제 멱등성이 생겼습니다. 즉, 원본 데이터가 동일한 경우 동일한 쿼리와 매개변수로 실행하고 동일한 결과를 얻을 수 있습니다. 반면 증분 모델의 경우 로드된 데이터는 테이블 내용 및 상위 스트림에서 발생한 변경 내용에 따라 달라집니다.</p>
<p>이 솔루션은 병렬, 증분 및 파티션화의 3가지 모드를 효과적으로 제공합니다. 따라서 Airflow와 DBT의 의도된 증분 전략과 잘 어울리며 이를 사용할 경우 잘 작동합니다. 아래와 같이 인수 없이 DBT를 실행하면 증분 모델을 사용할 것입니다:</p>
<pre><code class="hljs language-js">dbt run --select my_model
</code></pre>
<p>명시적으로 새로 고침을 실행하면 대량 적재가 발생합니다:</p>
<pre><code class="hljs language-js">dbt run --select my_model --full-refresh
</code></pre>
<p>그리고 추가한 target_date 매개변수를 전달하면 특정 파티션에 대해서만 실행되도록 할 수 있습니다:</p>
<pre><code class="hljs language-js">dbt run --select my_model  --vars <span class="hljs-string">"{target_date : '2024-01-01'}"</span>
</code></pre>
<p>이제 Airflow가 전달되는 날짜 매개변수를 제어할 수 있는 명령으로 돌아왔어요. 이렇게 하면 훨씬 더 부드러운 통합이 가능해요!</p>
<h1>참고 자료</h1>
<p>이 문제를 연구하는 데 사용된 다음 문서들입니다:</p>
<p>DBT — 증분성의 한계에 대해
Medium — DBT와 Airflow를 사용한 멱등데이터 파이프라인</p>
<h1>Nowcast의 엔지니어링</h1>
<p>만약 DBT에서 데이터 파이프라인을 구축하는 방법에 대해 알고 싶으면 아래 링크를 사용하여 친목을 돈 미팅을 예약해보세요. '문의 사항'란에 'Todd와 이야기하고 싶어요'라고 작성해주세요.</p>
<p>Nowcast는 현재 데이터 엔지니어를 채용 중입니다! 관심이 있으시면 <a href="application_link">여기에서 지원하세요</a>.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"DBT 증분 전략과 동등성","description":"","date":"2024-05-27 12:53","slug":"2024-05-27-DBTIncrementalStrategyandIdempotency","content":"\n\n![Screenshot](/assets/img/2024-05-27-DBTIncrementalStrategyandIdempotency_0.png)\n\n# 배경\n\n안녕하세요, 저는 데이터 엔지니어인 Todd입니다. 저는 Nowcast에서 데이터 온보딩에 주로 관여하고 있습니다. 이 기술 블로그에서는 Nowcast에서의 ETL 파이프라인 디자인의 간략한 역사를 소개하고, Airflow와 DBT의 \"Incremental Models\" 사이에서 발생한 문제를 설명하고 우리가 개발한 해결책을 소개하겠습니다.\n\n# Python으로 ETL\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n역사적으로 Nowcast에서는 ETL 파이프라인을 Python을 사용하여 작성했습니다. 이 파이프라인은 AWS S3, Athena, RDBMS 등에 저장된 데이터에 변환을 적용하는 많은 Python 스크립트로 구성되어 있었습니다. 우리는 이러한 스크립트를 포함하는 도커 이미지를 작성하여 ECR에 업로드하고, Airflow에서 ECS 작업을 호출했습니다. 이러한 스크립트는 보통 데이트와 같은 파티션 필드를 매개변수로 사용하여 멱등성이 있도록 설계되었습니다. 즉, 2024-01-01을 전달하면 2024-01-01의 데이터가 처리되었습니다.\n\n이러한 스크립트 중 하나를 호출할 때, 실제로 실행되는 명령은 아래와 같이 보일 것입니다. 이때 데이트 매개변수는 Airflow에서 관리됩니다:\n\n```js\npython transform_data.py 2024-01-01 --some --other --arguments\n```\n\n# Airflow\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAirflow은 Nowcast에서 많은 해동안 사용되어온 스케줄링 및 워크플로우 관리 도구입니다. 기본적으로 두 가지로 사용되고 있어요:\n\n1. 작업 스케줄러\n2. 작업 의존성 관리\n\n역사적으로 Airflow는 매일 실행되며 여러 Python 스크립트에 '실행 날짜' 매개변수를 전달하여 데이터를 처리합니다. 문제가 발생하거나 특정 기간의 작업을 다시 실행해야 할 때는 Airflow DAG에서 해당 작업을 다시 실행할 수 있습니다. 예를 들어, 2024년 01월 01일에 어떤 데이터 변환 스크립트가 실패하면 문제를 식별하고 수정한 후 해당 스크립트를 다시 실행할 수 있어요. 이는 스크립트가 한 번에 하나의 파티션만 처리하고 날짜를 매개변수로 입력받기 때문에 가능한 일입니다.\n\n# DBT에서 ETL\n\n2022년 말쯤 Python ETL 플로우를 Snowflake로 이전하기 시작했습니다. 그 결과 더 빠르고 저렴하며 깨끗한 파이프라인이 만들어졌어요. 우리는 파이프라인 실행 도구로 DBT를 사용하기로 결정했습니다 — DBT는 SQL 위에 위치한 레이어로 DB 모델 정의, 템플릿, 의존성 관리 및 데이터 회귀 테스트와 같은 다양한 기능을 포함하고 있어요. 빠르고 효율적으로 ETL 파이프라인을 구축하는 데 매우 유용한 도구입니다. 파이썬에서는 파이프라인의 각 변환을 스크립트로 작성하지만, DBT에서는 템플릿화된 SQL CTAS 쿼리로 작성됩니다. 이 쿼리들은 복잡한 수천 줄의 코드로 이루어진 스크립트와 비교했을 때 매우 읽기 쉽습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nBest practise in DBT is to use Incremental Models:\n\n# Incremental Models\n\nIncremental models are an efficient way of defining how to (incrementally) add data to our SQL models — consider we have a table that describes credit card transactions — we can make a DBT model (CTAS) that looks something like this:\n\n```js\n{\n materialized=\"table\"\n}\nselect\n transaction_id,\n transaction_date,\n user_id,\n store_name_description,\n transaction_amount\nfrom { ref('external_table_transaction') }\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 코드는 table external_table_transaction에서 거래 데이터를 불러오는 테이블을 만듭니다. 문제는이 쿼리를 다시 실행할 때마다 전체 테이블을 다시로드한다는 것입니다. 테이블에 데이터가 많아질수록 쿼리가 느려지고 비용이 많이 발생합니다. 이 문제의 해결책은 증분 모델을 사용하는 것입니다:\n\n```js\n{\n config(\n materialized=\"incremental\",\n unique_key=[\"transaction_id\"],\n incremental_strategy=\"delete+insert\",\n )\n}\nselect\n transaction_id,\n transaction_date,\n user_id,\n store_name_description,\n transaction_amount\nfrom { ref('external_table_transaction') }\n {- if is_incremental() }\n where transaction_date = (select max(transaction_date) + 1 as next_date from { this })\n{- endif }\n```\n\n여기에서 우리는 DBT를 강력하게 만드는 일부 매크로/템플릿 기능을 볼 수 있습니다. 이제 기본적으로 하는 것은 테이블의 최신 데이터보다 1일이 더 늦은 거래 데이터만 external_table_transaction에서 로드해야 한다는 것입니다. 이것은 간단하면서도 강력합니다. 업데이트마다 계속 커지는 수십억 개의 데이터 행 처리 대신 이제 이전에 볼 수 없던 행만 처리하면 됩니다. 그리고 필요하다면 전체 갱신으로 테이블을 다시로드할 수 있는 옵션도 있습니다.\n\n# 문제\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n점진적 모델은 매우 매력적입니다 — 수학적으로 아름답고 데이터 스트림을 다룰 때 매우 잘 작동합니다. 문제는 처리하려는 데이터를 제어해야 할 때 발생합니다 — 점진적 모델은 특정 파티션만 다시 실행할 수 없으며 대신에 증분 모델의 규칙에 따라 데이터를 로드합니다. 이론적으로는 문제가 되지 않을 수도 있지만, 점진적 모델이 이상적인 환경에서 실행된다면 모든 데이터가 정확히 한 번만 로드될 것입니다 — 하지만 현실은 복잡합니다 — DAG가 깨지고, 데이터가 늦게 전달되거나 아예 제공되지 않는 경우가 발생하며 때로는 역사적 기록을 다시 로드해야 할 때가 있습니다. 게다가 Airflow 파이프라인이 어떤 이유로든 실패할 경우 DBT 작업이 Airflow 실행과 동기화되지 않을 수 있습니다. Nowcast로 마이그레이션한 이후 DBT를 사용하면서 경험한 점진적 모델과 관련된 이슈 목록이 아래에 나와 있습니다:\n\n- 한 파이프라인에서 수리가 진행된 것이 있었는데, 이는 2년 전으로 거슬러 올라가야 했으므로 역사적 데이터를 로드해야 했는데 (증분) 데이터 파이프라인이 역사적 재실행을 처리할 수 없어서 즉시 처리해야 했습니다.\n- 다른 DAG에서 상류 이슈로 3일 동안 깨졌으며, 3일 동안 데이터가 로드되지 않았고, DAG가 4일째 실행될 때 1일부터 데이터를 로드했으므로 동기화가 맞지 않았습니다.\n- 세 번째 파이프라인에서 상류 스킵 날짜(데이터가 빠진 날)가 발생했고, 점진적 모델은 데이터를 로드하기 위해 데이터에서 최대 날짜에 `1`을 추가하는 방식으로 처리했으나 해당 날짜가 나타나지 않아 데이터가 로드되지 않은 채로 수동 처리가 필요해졌습니다.\n\n하지만 우리는 단순히 점진적 모델을 포기할 수 없습니다 — 일부 파이프라인은 수십억 개의 행을 처리해야 하므로, 테이블을 대량으로 처리할 쿼리를 작성하면 느리고 비용이 많이 소요될 것입니다.\n\n# 동형성(idempotency) 및 분할의 중요성.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n점진적 모델의 주요 문제는 이 모델이 멱등성을 갖지 않으며 특정 파티션에 대해 실행 구성이 불가능하다는 것입니다. 우리가 ETL 파이프라인에 대해 예전에 채택한 방식은 멱등 스크립트가 여러 번 다시 실행할 수 있는 횟수에 제한이 없는 것이었습니다. 과거 데이터에 문제가 발생하면 특정 파티션을 다시 생성할 수 있었고, 스크립트가 멱등성을 가졌기 때문에 특정한 날짜를 여러 번 실행해도 문제가 발생하지 않았습니다. 하지만 점진적 모델은 데이터의 특정 파티션을 다시 실행할 수 있는 능력이 없으며, 대신 모든 데이터를 스트림처럼 처리하여 보지 않은 데이터만을 로드합니다. 다시 말해 특정 규칙을 충족하는 데이터를 로드하는 것이죠.\n\n우리가 Airflow라는 스케줄링 도구를 사용하고 있기 때문에 데이터 파이프라인은 어떤 종류의 시간적 분할과 일치해야 합니다. 시간별, 일별, 주별, 월별 등 다양한 분할 방식이 될 수 있지만 중요한 점은 Airflow가 어떤 일정에 따라 실행되고 있다는 것입니다. 만약 과거 Airflow 작업을 다시 실행한다면 해당 작업을 호출할 때 해당하는 시간적 파티션에 맞게 실행되기를 기대하지만, 점진적 모델은 항상 앞으로만 '보기' 때문에 과거의 파티션에 대해 구성되지 않습니다. 이것은 Airflow에서 작업을 실행할 때 예상하는 것과는 다릅니다.\n\n하루마다 실행되는 2개의 Airflow DAG를 고려해보죠. 하나의 DAG는 매개변수로 날짜를 사용하여 해당 파티션만 실행하는 작업을 가지고 있습니다. 다른 DAG는 점진적 모델을 사용하며 실행할 때 보지 않은 데이터를 처리합니다. 둘 다 정상적으로 실행될 때 이전에 보지 못한 일별 데이터를 처리하게 되며 두 DAG는 동일하게 동작합니다. 하지만 문제가 발생하여 특정 날짜인 2024년 1월 1일을 다시 로드해야 할 때는 어떨까요? 파티션화된 DAG는 예상대로동작하여 2024년 1월 1일을 다시 실행할 것이지만, 점진적 모델은 Airflow에 전달되는 날짜와 관계없이 이전에 본 적 없는 데이터만을 로드할 것입니다.\n\n점진적 모델의 한계에 대해 논평한 댓글에서는:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단히 말하면 - Airflow와 같은 일정 관리 도구를 사용할 때 시간 분할을 기대하는 경우, 점진적 모델이 잘 작동하지 않습니다.\n\n# 해결책\n\n해결책은 간단합니다 - DBT 변수를 사용할 수 있습니다. 또한 점진적 모델의 기능을 완전히 포기할 필요가 없습니다. 하나 이상의 변수를 추가하여 하나 이상의 분할에 명시적으로 실행할 수 있습니다:\n\n```js\n{- set target_date = var(\"target_date\", \"\") }\n{\n config(\n materialized=\"incremental\",\n unique_key=[\"transaction_id\"],\n incremental_strategy=\"delete+insert\",\n )\n}\nselect\n transaction_id,\n transaction_date,\n user_id,\n store_name_description,\n transaction_amount\nfrom { ref('external_table_transaction') }\n{- if target_date != \"\" }\n where transaction_date = '{ target_date }'\n{- else }\n {- if is_incremental() }\n where transaction_date = (select max(transaction_date) + 1 as next_date from { this })\n {- endif }\n{- endif }\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 DBT 모델에 `target_date`라는 새 매개변수를 추가합니다. `target_date`가 정의되지 않은 경우 모델은 증분 동작으로 실행되지만, 변수가 전달된 경우 지정된 파티션에 대해 실행됩니다. 이 모델 구조화 방식은 Airflow에서 호출될 때 훨씬 더 잘 작동합니다.\n\n게다가, 이 모델은 이제 멱등성이 생겼습니다. 즉, 원본 데이터가 동일한 경우 동일한 쿼리와 매개변수로 실행하고 동일한 결과를 얻을 수 있습니다. 반면 증분 모델의 경우 로드된 데이터는 테이블 내용 및 상위 스트림에서 발생한 변경 내용에 따라 달라집니다.\n\n이 솔루션은 병렬, 증분 및 파티션화의 3가지 모드를 효과적으로 제공합니다. 따라서 Airflow와 DBT의 의도된 증분 전략과 잘 어울리며 이를 사용할 경우 잘 작동합니다. 아래와 같이 인수 없이 DBT를 실행하면 증분 모델을 사용할 것입니다:\n\n```js\ndbt run --select my_model\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n명시적으로 새로 고침을 실행하면 대량 적재가 발생합니다:\n\n```js\ndbt run --select my_model --full-refresh\n```\n\n그리고 추가한 target_date 매개변수를 전달하면 특정 파티션에 대해서만 실행되도록 할 수 있습니다:\n\n```js\ndbt run --select my_model  --vars \"{target_date : '2024-01-01'}\"\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 Airflow가 전달되는 날짜 매개변수를 제어할 수 있는 명령으로 돌아왔어요. 이렇게 하면 훨씬 더 부드러운 통합이 가능해요!\n\n# 참고 자료\n\n이 문제를 연구하는 데 사용된 다음 문서들입니다:\n\nDBT — 증분성의 한계에 대해\nMedium — DBT와 Airflow를 사용한 멱등데이터 파이프라인\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Nowcast의 엔지니어링\n\n만약 DBT에서 데이터 파이프라인을 구축하는 방법에 대해 알고 싶으면 아래 링크를 사용하여 친목을 돈 미팅을 예약해보세요. '문의 사항'란에 'Todd와 이야기하고 싶어요'라고 작성해주세요.\n\nNowcast는 현재 데이터 엔지니어를 채용 중입니다! 관심이 있으시면 [여기에서 지원하세요](application_link).\n","ogImage":{"url":"/assets/img/2024-05-27-DBTIncrementalStrategyandIdempotency_0.png"},"coverImage":"/assets/img/2024-05-27-DBTIncrementalStrategyandIdempotency_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-27-DBTIncrementalStrategyandIdempotency_0.png\" alt=\"Screenshot\"\u003e\u003c/p\u003e\n\u003ch1\u003e배경\u003c/h1\u003e\n\u003cp\u003e안녕하세요, 저는 데이터 엔지니어인 Todd입니다. 저는 Nowcast에서 데이터 온보딩에 주로 관여하고 있습니다. 이 기술 블로그에서는 Nowcast에서의 ETL 파이프라인 디자인의 간략한 역사를 소개하고, Airflow와 DBT의 \"Incremental Models\" 사이에서 발생한 문제를 설명하고 우리가 개발한 해결책을 소개하겠습니다.\u003c/p\u003e\n\u003ch1\u003ePython으로 ETL\u003c/h1\u003e\n\u003cp\u003e역사적으로 Nowcast에서는 ETL 파이프라인을 Python을 사용하여 작성했습니다. 이 파이프라인은 AWS S3, Athena, RDBMS 등에 저장된 데이터에 변환을 적용하는 많은 Python 스크립트로 구성되어 있었습니다. 우리는 이러한 스크립트를 포함하는 도커 이미지를 작성하여 ECR에 업로드하고, Airflow에서 ECS 작업을 호출했습니다. 이러한 스크립트는 보통 데이트와 같은 파티션 필드를 매개변수로 사용하여 멱등성이 있도록 설계되었습니다. 즉, 2024-01-01을 전달하면 2024-01-01의 데이터가 처리되었습니다.\u003c/p\u003e\n\u003cp\u003e이러한 스크립트 중 하나를 호출할 때, 실제로 실행되는 명령은 아래와 같이 보일 것입니다. 이때 데이트 매개변수는 Airflow에서 관리됩니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003epython transform_data.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e2024\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e01\u003c/span\u003e-\u003cspan class=\"hljs-number\"\u003e01\u003c/span\u003e --some --other --\u003cspan class=\"hljs-variable language_\"\u003earguments\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003eAirflow\u003c/h1\u003e\n\u003cp\u003eAirflow은 Nowcast에서 많은 해동안 사용되어온 스케줄링 및 워크플로우 관리 도구입니다. 기본적으로 두 가지로 사용되고 있어요:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e작업 스케줄러\u003c/li\u003e\n\u003cli\u003e작업 의존성 관리\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e역사적으로 Airflow는 매일 실행되며 여러 Python 스크립트에 '실행 날짜' 매개변수를 전달하여 데이터를 처리합니다. 문제가 발생하거나 특정 기간의 작업을 다시 실행해야 할 때는 Airflow DAG에서 해당 작업을 다시 실행할 수 있습니다. 예를 들어, 2024년 01월 01일에 어떤 데이터 변환 스크립트가 실패하면 문제를 식별하고 수정한 후 해당 스크립트를 다시 실행할 수 있어요. 이는 스크립트가 한 번에 하나의 파티션만 처리하고 날짜를 매개변수로 입력받기 때문에 가능한 일입니다.\u003c/p\u003e\n\u003ch1\u003eDBT에서 ETL\u003c/h1\u003e\n\u003cp\u003e2022년 말쯤 Python ETL 플로우를 Snowflake로 이전하기 시작했습니다. 그 결과 더 빠르고 저렴하며 깨끗한 파이프라인이 만들어졌어요. 우리는 파이프라인 실행 도구로 DBT를 사용하기로 결정했습니다 — DBT는 SQL 위에 위치한 레이어로 DB 모델 정의, 템플릿, 의존성 관리 및 데이터 회귀 테스트와 같은 다양한 기능을 포함하고 있어요. 빠르고 효율적으로 ETL 파이프라인을 구축하는 데 매우 유용한 도구입니다. 파이썬에서는 파이프라인의 각 변환을 스크립트로 작성하지만, DBT에서는 템플릿화된 SQL CTAS 쿼리로 작성됩니다. 이 쿼리들은 복잡한 수천 줄의 코드로 이루어진 스크립트와 비교했을 때 매우 읽기 쉽습니다.\u003c/p\u003e\n\u003cp\u003eBest practise in DBT is to use Incremental Models:\u003c/p\u003e\n\u003ch1\u003eIncremental Models\u003c/h1\u003e\n\u003cp\u003eIncremental models are an efficient way of defining how to (incrementally) add data to our SQL models — consider we have a table that describes credit card transactions — we can make a DBT model (CTAS) that looks something like this:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e{\n materialized=\u003cspan class=\"hljs-string\"\u003e\"table\"\u003c/span\u003e\n}\nselect\n transaction_id,\n transaction_date,\n user_id,\n store_name_description,\n transaction_amount\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e { \u003cspan class=\"hljs-title function_\"\u003eref\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'external_table_transaction'\u003c/span\u003e) }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 코드는 table external_table_transaction에서 거래 데이터를 불러오는 테이블을 만듭니다. 문제는이 쿼리를 다시 실행할 때마다 전체 테이블을 다시로드한다는 것입니다. 테이블에 데이터가 많아질수록 쿼리가 느려지고 비용이 많이 발생합니다. 이 문제의 해결책은 증분 모델을 사용하는 것입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e{\n \u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\n materialized=\u003cspan class=\"hljs-string\"\u003e\"incremental\"\u003c/span\u003e,\n unique_key=[\u003cspan class=\"hljs-string\"\u003e\"transaction_id\"\u003c/span\u003e],\n incremental_strategy=\u003cspan class=\"hljs-string\"\u003e\"delete+insert\"\u003c/span\u003e,\n )\n}\nselect\n transaction_id,\n transaction_date,\n user_id,\n store_name_description,\n transaction_amount\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e { \u003cspan class=\"hljs-title function_\"\u003eref\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'external_table_transaction'\u003c/span\u003e) }\n {- \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eis_incremental\u003c/span\u003e() }\n where transaction_date = (select \u003cspan class=\"hljs-title function_\"\u003emax\u003c/span\u003e(transaction_date) + \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e next_date \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e { \u003cspan class=\"hljs-variable language_\"\u003ethis\u003c/span\u003e })\n{- endif }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e여기에서 우리는 DBT를 강력하게 만드는 일부 매크로/템플릿 기능을 볼 수 있습니다. 이제 기본적으로 하는 것은 테이블의 최신 데이터보다 1일이 더 늦은 거래 데이터만 external_table_transaction에서 로드해야 한다는 것입니다. 이것은 간단하면서도 강력합니다. 업데이트마다 계속 커지는 수십억 개의 데이터 행 처리 대신 이제 이전에 볼 수 없던 행만 처리하면 됩니다. 그리고 필요하다면 전체 갱신으로 테이블을 다시로드할 수 있는 옵션도 있습니다.\u003c/p\u003e\n\u003ch1\u003e문제\u003c/h1\u003e\n\u003cp\u003e점진적 모델은 매우 매력적입니다 — 수학적으로 아름답고 데이터 스트림을 다룰 때 매우 잘 작동합니다. 문제는 처리하려는 데이터를 제어해야 할 때 발생합니다 — 점진적 모델은 특정 파티션만 다시 실행할 수 없으며 대신에 증분 모델의 규칙에 따라 데이터를 로드합니다. 이론적으로는 문제가 되지 않을 수도 있지만, 점진적 모델이 이상적인 환경에서 실행된다면 모든 데이터가 정확히 한 번만 로드될 것입니다 — 하지만 현실은 복잡합니다 — DAG가 깨지고, 데이터가 늦게 전달되거나 아예 제공되지 않는 경우가 발생하며 때로는 역사적 기록을 다시 로드해야 할 때가 있습니다. 게다가 Airflow 파이프라인이 어떤 이유로든 실패할 경우 DBT 작업이 Airflow 실행과 동기화되지 않을 수 있습니다. Nowcast로 마이그레이션한 이후 DBT를 사용하면서 경험한 점진적 모델과 관련된 이슈 목록이 아래에 나와 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e한 파이프라인에서 수리가 진행된 것이 있었는데, 이는 2년 전으로 거슬러 올라가야 했으므로 역사적 데이터를 로드해야 했는데 (증분) 데이터 파이프라인이 역사적 재실행을 처리할 수 없어서 즉시 처리해야 했습니다.\u003c/li\u003e\n\u003cli\u003e다른 DAG에서 상류 이슈로 3일 동안 깨졌으며, 3일 동안 데이터가 로드되지 않았고, DAG가 4일째 실행될 때 1일부터 데이터를 로드했으므로 동기화가 맞지 않았습니다.\u003c/li\u003e\n\u003cli\u003e세 번째 파이프라인에서 상류 스킵 날짜(데이터가 빠진 날)가 발생했고, 점진적 모델은 데이터를 로드하기 위해 데이터에서 최대 날짜에 \u003ccode\u003e1\u003c/code\u003e을 추가하는 방식으로 처리했으나 해당 날짜가 나타나지 않아 데이터가 로드되지 않은 채로 수동 처리가 필요해졌습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e하지만 우리는 단순히 점진적 모델을 포기할 수 없습니다 — 일부 파이프라인은 수십억 개의 행을 처리해야 하므로, 테이블을 대량으로 처리할 쿼리를 작성하면 느리고 비용이 많이 소요될 것입니다.\u003c/p\u003e\n\u003ch1\u003e동형성(idempotency) 및 분할의 중요성.\u003c/h1\u003e\n\u003cp\u003e점진적 모델의 주요 문제는 이 모델이 멱등성을 갖지 않으며 특정 파티션에 대해 실행 구성이 불가능하다는 것입니다. 우리가 ETL 파이프라인에 대해 예전에 채택한 방식은 멱등 스크립트가 여러 번 다시 실행할 수 있는 횟수에 제한이 없는 것이었습니다. 과거 데이터에 문제가 발생하면 특정 파티션을 다시 생성할 수 있었고, 스크립트가 멱등성을 가졌기 때문에 특정한 날짜를 여러 번 실행해도 문제가 발생하지 않았습니다. 하지만 점진적 모델은 데이터의 특정 파티션을 다시 실행할 수 있는 능력이 없으며, 대신 모든 데이터를 스트림처럼 처리하여 보지 않은 데이터만을 로드합니다. 다시 말해 특정 규칙을 충족하는 데이터를 로드하는 것이죠.\u003c/p\u003e\n\u003cp\u003e우리가 Airflow라는 스케줄링 도구를 사용하고 있기 때문에 데이터 파이프라인은 어떤 종류의 시간적 분할과 일치해야 합니다. 시간별, 일별, 주별, 월별 등 다양한 분할 방식이 될 수 있지만 중요한 점은 Airflow가 어떤 일정에 따라 실행되고 있다는 것입니다. 만약 과거 Airflow 작업을 다시 실행한다면 해당 작업을 호출할 때 해당하는 시간적 파티션에 맞게 실행되기를 기대하지만, 점진적 모델은 항상 앞으로만 '보기' 때문에 과거의 파티션에 대해 구성되지 않습니다. 이것은 Airflow에서 작업을 실행할 때 예상하는 것과는 다릅니다.\u003c/p\u003e\n\u003cp\u003e하루마다 실행되는 2개의 Airflow DAG를 고려해보죠. 하나의 DAG는 매개변수로 날짜를 사용하여 해당 파티션만 실행하는 작업을 가지고 있습니다. 다른 DAG는 점진적 모델을 사용하며 실행할 때 보지 않은 데이터를 처리합니다. 둘 다 정상적으로 실행될 때 이전에 보지 못한 일별 데이터를 처리하게 되며 두 DAG는 동일하게 동작합니다. 하지만 문제가 발생하여 특정 날짜인 2024년 1월 1일을 다시 로드해야 할 때는 어떨까요? 파티션화된 DAG는 예상대로동작하여 2024년 1월 1일을 다시 실행할 것이지만, 점진적 모델은 Airflow에 전달되는 날짜와 관계없이 이전에 본 적 없는 데이터만을 로드할 것입니다.\u003c/p\u003e\n\u003cp\u003e점진적 모델의 한계에 대해 논평한 댓글에서는:\u003c/p\u003e\n\u003cp\u003e간단히 말하면 - Airflow와 같은 일정 관리 도구를 사용할 때 시간 분할을 기대하는 경우, 점진적 모델이 잘 작동하지 않습니다.\u003c/p\u003e\n\u003ch1\u003e해결책\u003c/h1\u003e\n\u003cp\u003e해결책은 간단합니다 - DBT 변수를 사용할 수 있습니다. 또한 점진적 모델의 기능을 완전히 포기할 필요가 없습니다. 하나 이상의 변수를 추가하여 하나 이상의 분할에 명시적으로 실행할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e{- set target_date = \u003cspan class=\"hljs-title function_\"\u003evar\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"target_date\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e) }\n{\n \u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\n materialized=\u003cspan class=\"hljs-string\"\u003e\"incremental\"\u003c/span\u003e,\n unique_key=[\u003cspan class=\"hljs-string\"\u003e\"transaction_id\"\u003c/span\u003e],\n incremental_strategy=\u003cspan class=\"hljs-string\"\u003e\"delete+insert\"\u003c/span\u003e,\n )\n}\nselect\n transaction_id,\n transaction_date,\n user_id,\n store_name_description,\n transaction_amount\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e { \u003cspan class=\"hljs-title function_\"\u003eref\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'external_table_transaction'\u003c/span\u003e) }\n{- \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e target_date != \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e }\n where transaction_date = \u003cspan class=\"hljs-string\"\u003e'{ target_date }'\u003c/span\u003e\n{- \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e }\n {- \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eis_incremental\u003c/span\u003e() }\n where transaction_date = (select \u003cspan class=\"hljs-title function_\"\u003emax\u003c/span\u003e(transaction_date) + \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e next_date \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e { \u003cspan class=\"hljs-variable language_\"\u003ethis\u003c/span\u003e })\n {- endif }\n{- endif }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이것은 DBT 모델에 \u003ccode\u003etarget_date\u003c/code\u003e라는 새 매개변수를 추가합니다. \u003ccode\u003etarget_date\u003c/code\u003e가 정의되지 않은 경우 모델은 증분 동작으로 실행되지만, 변수가 전달된 경우 지정된 파티션에 대해 실행됩니다. 이 모델 구조화 방식은 Airflow에서 호출될 때 훨씬 더 잘 작동합니다.\u003c/p\u003e\n\u003cp\u003e게다가, 이 모델은 이제 멱등성이 생겼습니다. 즉, 원본 데이터가 동일한 경우 동일한 쿼리와 매개변수로 실행하고 동일한 결과를 얻을 수 있습니다. 반면 증분 모델의 경우 로드된 데이터는 테이블 내용 및 상위 스트림에서 발생한 변경 내용에 따라 달라집니다.\u003c/p\u003e\n\u003cp\u003e이 솔루션은 병렬, 증분 및 파티션화의 3가지 모드를 효과적으로 제공합니다. 따라서 Airflow와 DBT의 의도된 증분 전략과 잘 어울리며 이를 사용할 경우 잘 작동합니다. 아래와 같이 인수 없이 DBT를 실행하면 증분 모델을 사용할 것입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edbt run --select my_model\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e명시적으로 새로 고침을 실행하면 대량 적재가 발생합니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edbt run --select my_model --full-refresh\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그리고 추가한 target_date 매개변수를 전달하면 특정 파티션에 대해서만 실행되도록 할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edbt run --select my_model  --vars \u003cspan class=\"hljs-string\"\u003e\"{target_date : '2024-01-01'}\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이제 Airflow가 전달되는 날짜 매개변수를 제어할 수 있는 명령으로 돌아왔어요. 이렇게 하면 훨씬 더 부드러운 통합이 가능해요!\u003c/p\u003e\n\u003ch1\u003e참고 자료\u003c/h1\u003e\n\u003cp\u003e이 문제를 연구하는 데 사용된 다음 문서들입니다:\u003c/p\u003e\n\u003cp\u003eDBT — 증분성의 한계에 대해\nMedium — DBT와 Airflow를 사용한 멱등데이터 파이프라인\u003c/p\u003e\n\u003ch1\u003eNowcast의 엔지니어링\u003c/h1\u003e\n\u003cp\u003e만약 DBT에서 데이터 파이프라인을 구축하는 방법에 대해 알고 싶으면 아래 링크를 사용하여 친목을 돈 미팅을 예약해보세요. '문의 사항'란에 'Todd와 이야기하고 싶어요'라고 작성해주세요.\u003c/p\u003e\n\u003cp\u003eNowcast는 현재 데이터 엔지니어를 채용 중입니다! 관심이 있으시면 \u003ca href=\"application_link\"\u003e여기에서 지원하세요\u003c/a\u003e.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-27-DBTIncrementalStrategyandIdempotency"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>