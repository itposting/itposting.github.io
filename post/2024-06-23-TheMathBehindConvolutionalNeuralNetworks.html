<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>컨볼루션 신경망CNN의 수학적 원리 분석 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-23-TheMathBehindConvolutionalNeuralNetworks" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="컨볼루션 신경망CNN의 수학적 원리 분석 | itposting" data-gatsby-head="true"/><meta property="og:title" content="컨볼루션 신경망CNN의 수학적 원리 분석 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-23-TheMathBehindConvolutionalNeuralNetworks" data-gatsby-head="true"/><meta name="twitter:title" content="컨볼루션 신경망CNN의 수학적 원리 분석 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 18:50" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">컨볼루션 신경망CNN의 수학적 원리 분석</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="컨볼루션 신경망CNN의 수학적 원리 분석" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">26<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-TheMathBehindConvolutionalNeuralNetworks&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png" alt="이미지"></p>
<p>목차</p>
<ul>
<li>1: 소개</li>
<li>2: CNN 아키텍처 뒤의 수학
<ul>
<li>2.1: 합성곱층</li>
<li>2.2: 스트라이드</li>
<li>2.3: 패딩</li>
<li>2.4: 다중 필터 및 깊이</li>
<li>2.5: 가중치 공유</li>
<li>2.6: 특성 맵 생성</li>
<li>2.7: 풀링층</li>
<li>2.8: 완전 연결층</li>
</ul>
</li>
</ul>
<div class="content-ad"></div>
<ul>
<li>
<p>3: CNN 구축을 위한 단계별 안내</p>
<ul>
<li>3.1: 환경 설정</li>
<li>3.2: 데이터 준비</li>
<li>3.3: CNN 모델 설계</li>
<li>3.4: 모델 컴파일</li>
<li>3.5: CNN 훈련</li>
</ul>
</li>
<li>
<p>4: 모델 성능 향상</p>
<ul>
<li>4.1: 데이터 증강</li>
<li>4.2: 드롭아웃</li>
<li>4.3: 배치 정규화</li>
<li>4.4: 전이 학습</li>
</ul>
</li>
<li>
<p>5: 결론</p>
</li>
<li>
<p>추가 자료</p>
</li>
</ul>
<div class="content-ad"></div>
<h1>1: 소개</h1>
<p>합성곱 신경망, 또는 CNN(Convoluntional Neural Networks)라고도 불리는 것은 이미지 처리와 관련된 작업에서 중요한 역할을 합니다. 사진 인식이나 분류와 같이 이미지와 관련된 작업을 할 때 매우 유용합니다. 그들은 사진의 패턴과 세부 사항을 자동으로 감지하는 데 아주 뛰어나기 때문에 많은 이미지를 처리하는 프로젝트에서 선호되는 선택입니다.</p>
<p>CNN의 멋진 점은 이미지 데이터를 단순히 한 덩어리로 뭉치는 것이 아니라 이미지의 레이아웃을 유지한다는 것입니다. 이는 특정 패턴과 해당 위치를 잘 알아차릴 수 있어서 매우 유용합니다. 이 접근 방식은 이미지 처리의 어려운 부분을 훨씬 더 부드럽게 처리할 수 있도록 해줍니다.</p>
<p>CNN의 중요한 부분 중 하나는 합성곱 레이어라는 것입니다. 이 레이어는 이미지 위를 이동하면서 선, 질감, 형태와 같은 다양한 시각적 특징을 발견할 수 있습니다. 이는 사람이 그러한 특징들을 수동으로 찾아야 했던 예전 방식을 능가합니다. 이는 작업 처리를 느리게 하고 처리 과정에서 병목현상을 야기시켰던 것과 대조됩니다. 네트워크가 스스로 이러한 특징을 찾아내도록 함으로써 CNN은 더 정확해지고, 더 단순해지며, 그리고 더 큰 범위의 이미지 관련 작업에 수월하게 사용할 수 있습니다.</p>
<div class="content-ad"></div>
<h1>2: CNN 아키텍처 뒤의 수학</h1>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_1.png" alt="이미지"></p>
<p>합성곱 신경망(CNNs)의 아키텍처는 인간의 시각 시스템이 이미지를 처리하는 방식을 모방하도록 설계되어 있어 시각 인식 및 분류와 관련된 작업에 특히 강력합니다.</p>
<p>CNN은 여러 유형의 레이어로 구성되어 있으며, 각 레이어는 이미지 인식 과정에서 특정 기능을 제공합니다. 주요 레이어에는 합성곱 레이어, 활성화 함수, 풀링 레이어 및 완전 연결 레이어가 포함됩니다. 이 레이어들이 함께 작동하여 CNN이 특징을 감지하고 복잡성을 줄이며 예측을 수행할 수 있게 합니다.</p>
<div class="content-ad"></div>
<h2>2.1: 합성곱층</h2>
<p>합성곱층은 합성곱 신경망(CNN)의 중요한 요소로, 이미지로부터 가장자리, 질감, 모양과 같은 공간적인 특징을 자동적으로 효율적으로 추출하는 데 사용됩니다. 우리는 합성곱층이 작동하는 방식 및 내부 수학에 대해 자세히 알아보겠습니다.</p>
<p>합성곱 연산</p>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_2.png" alt="image"></p>
<div class="content-ad"></div>
<p>합성 곱 연산의 본질은 입력 이미지 위를 필터(또는 커널)가 슬라이딩하면서 각 위치에서 필터 값과 원래 픽셀 값의 내적을 계산하는 것입니다. 필터는 일반적으로 3x3 또는 5x5 크기의 작은 가중치 행렬로, 이미지에서 특정 피쳐를 감지하기 위해 훈련됩니다.</p>
<p>수학적으로, 합성 곱 연산은 다음과 같이 표현될 수 있습니다:</p>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_3.png" alt="convolution equation"></p>
<p>여기서:</p>
<div class="content-ad"></div>
<ul>
<li>S(i,j)은 출력 피처 맵입니다.</li>
<li>I는 입력 이미지입니다.</li>
<li>K는 커널 또는 필터입니다.</li>
<li>i,j는 피처 맵 상의 좌표입니다.</li>
<li>m,n은 커널 내의 좌표입니다.</li>
<li>∗는 합성곱 연산을 나타냅니다.</li>
</ul>
<p>이 방정식은 출력 피처 맵의 각 요소 S(i,j)가 커널 K와 현재 위치한 입력 이미지 I의 일부 사이의 요소별 곱의 합임을 알려줍니다.</p>
<p>이제 입력 이미지로 사용될 픽셀 값 행렬을 고려해 봅시다. 그것이 흑백 이미지인 경우 (위 이미지), 행렬은 단일 레이어를 가지게 될 것입니다. 컬러 이미지의 경우에는 일반적으로 세 개의 레이어 (RGB)가 있지만, 연산은 각 레이어마다 별도로 수행됩니다.</p>
<p>합성곱 연산은 행렬에 커널(필터)을 적용합니다. 여기서 커널은 입력 이미지보다 작은 다차원 행렬이며 사전에 정의된 차원 (예: 3x3)을 가지고 있습니다. 이 행렬의 값은 훈련 과정 중에 학습되는 가중치입니다. 커널은 입력 이미지 전체를 걸어다니면서 요소별 곱셈을 수행하고 합을 구합니다.</p>
<div class="content-ad"></div>
<p>컨볼류션 연산에서는 출력 특성 맵을 얻게 됩니다. 이는 커널이 입력 이미지의 특정 위치에서 감지한 특징의 존재와 강도를 나타내는 새로운 행렬입니다.</p>
<h2>2.2: 스트라이드</h2>
<p><img src="https://miro.medium.com/v2/resize:fit:1280/1*OlE3bnC0WaYt3wW1dlcMdA.gif" alt="스트라이드"></p>
<p>스트라이드는 CNN 아키텍처에서 중요한 개념입니다. 특히 컨볼루션 레이어 내에서 핵심적으로 작용합니다. 이는 커널이 입력 이미지나 특성 맵을 횡단하는 방식에 근본적인 영향을 미칩니다.</p>
<div class="content-ad"></div>
<p>Stride는 필터가 입력 이미지나 피쳐 맵을 한 단계씩 이동하는 픽셀 수를 나타냅니다. 수평 및 수직으로 모두 적용됩니다. Stride가 1이면 필터가 한 번에 한 픽셀씩 이동하여 입력을 자세하고 밀도 있게 스캔합니다. 더 큰 Stride는 필터가 픽셀을 건너뛰며 입력을 스캔하므로 더 넓고 밀도가 낮은 범위로 이어집니다.</p>
<p>Stride는 출력 피쳐 맵의 차원을 결정하는 데 직접적인 역할을 합니다:</p>
<ul>
<li>Stride가 1인 경우: 필터가 모든 픽셀을 횡단하여 출력 피쳐 맵이 패딩에 따라 상대적으로 크거나 입력과 유사한 크기가 될 수 있습니다. 패딩에 대해 다음 섹션에서 설명하겠습니다.</li>
<li>더 큰 Stride인 경우: 필터가 픽셀을 건너뛰면 입력을 적은 단계로 이동합니다. 이로 인해 출력 피쳐 맵이 작아지며 각 단계에서 필터가 적용되는 위치 간의 오버랩이 적어집니다.</li>
</ul>
<p>수학적 표현
출력 피쳐 맵의 크기 (W_out, H_out)는 입력 크기 (W_in, H_in), 필터 크기 (F), Stride (S), 패딩 (P)을 사용하여 다음 공식을 사용하여 계산할 수 있습니다:</p>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_4.png">
<p>여기서:</p>
<ul>
<li>W_out 및 H_out은 각각 출력 특성 맵의 너비와 높이입니다.</li>
<li>W_in 및 H_in은 각각 입력의 너비와 높이입니다.</li>
<li>F는 필터의 크기입니다.</li>
<li>S는 스트라이드입니다.</li>
<li>P는 패딩입니다.</li>
</ul>
<p>더 큰 스트라이드는 필터의 각 응용 영역의 시야를 증가시켜 네트워크가 더 적은 매개변수로 입력의 더 많은 전역적인 특성을 포착할 수 있게 합니다.</p>
<div class="content-ad"></div>
<p>사용하는 스트라이드를 크게 하면 출력 특성 맵의 크기를 줄이기 때문에 계산 부하와 메모리 사용량이 감소하며, 따라서 필요한 합성 곱 연산 수도 줄어듭니다.</p>
<p>공간 해상도와 커버리지 사이에는 교환관계가 있습니다. 작은 스트라이드는 공간 해상도를 보존하고 섬세한 특징을 탐지하는 데 더 좋지만, 큰 스트라이드는 디테일을 희생하면서 입력의 넓은 영역을 다룰 수 있습니다.</p>
<h2>2.3: 패딩</h2>
<p>패딩은 출력 특성 맵의 공간적 차원을 조절하여 네트워크의 아키텍처를 형성하는 데 중요한 역할을 합니다.
합성 곱 연산을 적용하기 전에 입력 이미지나 특성 맵의 가장자리 주위에 제로(또는 다른 값들이지만 일반적으로 제로입니다)의 레이어를 추가하는 것을 포함합니다. 이 기법은 다양한 이유로 적용될 수 있으며, 가장 중요한 이유는 출력 특성 맵의 크기를 제어하고 합성 곱 필터가 입력의 가장자리 픽셀에 접근할 수 있도록 하는 것입니다.</p>
<div class="content-ad"></div>
<p>그래서, 이제 우리의 입력 이미지는 다음과 같이 보일 것입니다:</p>
<img src="https://miro.medium.com/v2/resize:fit:1280/1*VwOf7sD87Yw9P1215NngRQ.gif">
<p>이전의 8x8 행렬이 이제 10x10 행렬로 바뀐 것을 볼 수 있습니다. 우리는 주변에 0으로 된 레이어를 추가했기 때문입니다.</p>
<p>패딩이 없으면 각 합성곱 연산이 피처 맵의 크기를 줄입니다. 패딩을 사용하면 입력에 필터를 적용하여 공간적 차원을 줄이지 않고 더 많은 정보를 보존할 수 있습니다. 특히 많은 합성곱 계층이 순차적으로 적용되는 심층 네트워크에서 더 많은 정보를 보존할 수 있습니다.</p>
<div class="content-ad"></div>
<p>입력을 패딩함으로써 필터가 이미지의 가장자리 픽셀을 적절하게 처리하여 네트워크의 학습 과정에서 경계에 위치한 특징을 충분히 캡처하고 활용할 수 있습니다.</p>
<p>패딩에는 주로 두 가지 유형이 있습니다:</p>
<p><strong>Valid Padding (패딩 없음)</strong>
이 경우 입력에 패딩이 적용되지 않습니다. 필터가 입력의 한계 내에 완전히 맞는 곳에서만 합성곱 작업이 수행됩니다. 이로 인해 일반적으로 출력 피처 맵 크기가 줄어듭니다.</p>
<p><strong>Same Padding (동일 패딩)</strong>
동일 패딩의 경우 입력 가장자리에 충분한 수의 제로(0)가 추가되어 출력 피처 맵이 입력과 동일한 차원을 갖도록 합니다(스트라이드가 1인 경우). 이는 입력과 출력 크기가 일관성 있게 유지되어야 하는 네트워크를 설계하는 데 특히 유용합니다.</p>
<div class="content-ad"></div>
<p>가장자리에 패딩을 추가하는 것이 출력 특성 맵 크기에 미치는 영향은 출력 특성 맵의 차원을 계산하는 데 사용되는 공식을 조정함으로써 파악할 수 있습니다:</p>
<p>W_out = (W_in - F + 2P) / S + 1
H_out = (H_in - F + 2P) / S + 1</p>
<p>여기서:</p>
<ul>
<li>W_out과 H_out은 각각 출력 특성 맵의 너비와 높이입니다.</li>
<li>W_in과 H_in은 각각 입력의 너비와 높이입니다.</li>
<li>F는 필터/커널의 크기입니다.</li>
<li>S는 스트라이드입니다.</li>
<li>P는 입력의 각 측면에 추가된 패딩의 양입니다.</li>
</ul>
<div class="content-ad"></div>
<p>패딩은 층을 통해 입력의 공간 차원을 유지하는 데 도움이 됩니다. 그러나 과도한 패딩은 계산의 비효율성을 야기하고 모델의 복잡성이 증가할 수 있습니다. 비의미 있는 입력(제로)을 계산에 추가함으로써 비효율성을 가져올 수 있습니다.</p>
<p>유효 패딩과 동일 패딩 사이의 선택은 주로 응용 프로그램의 특정 요구 사항에 따라 달라지며, 입력의 공간 차원을 보존하는 중요성이나 계산 오버헤드를 최소화해야 하는 필요성에 따라 결정됩니다.</p>
<h2>2.4: 다중 필터와 깊이</h2>
<p>CNN은 각 합성곱 층에서 여러 필터를 사용하여 입력 이미지나 특징 맵에서 다양한 특징을 캡처합니다. 이 다양성과 깊이는 네트워크가 시각 정보를 포괄적이고 세심하게 처리할 수 있는 능력에 중요한 역할을 합니다.</p>
<div class="content-ad"></div>
<p>컨볼루션 레이어의 각 필터는 입력에서 엣지, 색상, 질감 또는 더 깊은 레이어에서는 더 복잡한 모양과 같은 다양한 특징이나 패턴을 감지하도록 설계되어 있습니다. 여러 필터를 사용함으로써 CNN은 각 레이어에서 동시에 다양한 특징을 찾아 입력 데이터의 표현을 보다 풍부하게 만들 수 있습니다.</p>
<p>여러 필터를 사용한 컨볼루션 레이어의 출력은 각 필터에 대해 하나의 특징 맵으로 이루어진 스택입니다. 이 스택은 깊이가 사용된 필터의 수와 대응되는 3차원 볼륨을 형성합니다. 이 깊이는 데이터의 계층적인 표현을 구축하는 데 중요하며, 이전 레이어의 출력을 결합하여 점점 추상적인 특징을 감지할 수 있게 합니다.</p>
<p>여러 필터가 깊이를 어떻게 실현하는가
입력 이미지 또는 특징 맵이 처리됨에 따라 각 필터는 이를 슬라이딩하여 컨볼루션 작업을 수행합니다. 동일한 입력을 공유하더라도 각 필터는 고유한 가중치를 적용하여 서로 다른 측면을 강조하는 서로 다른 특징 맵을 생성합니다.</p>
<p>각 필터가 생성한 개별 특징 맵은 깊이 차원을 따라 쌓이며, 3D 볼륨을 형성합니다. 이 볼륨은 필터에 의해 감지된 다양한 특징을 포용하여 입력의 풍부하고 다면적인 표현을 제공합니다.</p>
<div class="content-ad"></div>
<p>합성곱 레이어의 깊이는 필터의 수에 의해 결정되며, 네트워크가 넓은 특징 스펙트럼을 포착할 수 있게 합니다. 초기 레이어는 가장자리와 질감과 같은 기본적인 특징을 포착할 수 있지만, 더 깊은 레이어는 이러한 기본적인 특징을 결합하여 복잡한 패턴을 해석할 수 있게 되며, 이는 네트워크의 깊이 덕분입니다.</p>
<p>깊이의 영향
더 많은 필터는 복잡한 특징을 학습할 수 있는 용량이 높은 더 깊은 네트워크를 의미합니다. 그러나 이는 또한 네트워크의 계산 복잡성과 효과적으로 학습하기 위해 필요한 데이터 양을 증가시킵니다.</p>
<p>각 필터는 모델에 매개변수를 추가합니다(필터를 정의하는 가중치). 더 많은 필터는 네트워크의 표현력을 높이지만, 총 매개변수 수를 증가시켜 학습 효율성과 과적합의 위험에 영향을 미칠 수 있습니다.</p>
<p>레이어 간 필터 할당은 전략적입니다. 입력에 가까운 레이어는 더 적고 일반적인 필터를 가질 수 있지만, 더 깊은 레이어는 데이터 내에서 고차원 특징의 복잡성과 변이를 포착하기 위해 더 많은 필터를 사용할 수 있습니다.</p>
<div class="content-ad"></div>
<h2>2.5: Weight Sharing</h2>
<p>Weight sharing(가중치 공유)는 특히 시각적 정보를 처리할 때 CNN의 효율성과 효과를 현저히 향상시킵니다. 이 개념은 모델이 입력 이미지의 공간적 위치와 관계없이 특징을 감지할 수 있도록 핵심적입니다.</p>
<p>CNN의 맥락에서, 가중치 공유란 동일한 필터(즉, 동일한 가중치 세트)를 전체 입력 이미지나 특징 맵에 걸쳐 사용하는 것을 의미합니다. 모든 가능한 위치에 대해 고유한 가중치 세트를 학습하는 대신 단일 필터가 전체 이미지를 스캔하며 각 위치에서 동일한 가중치를 적용합니다. 이 작업은 합성곱 레이어의 각 필터에서 반복됩니다.</p>
<p>입력 이미지의 서로 다른 부분에서 동일한 가중치 세트를 재사용함으로써, 가중치 공유는 모델의 매개변수 수를 급격하게 줄입니다. 이로 인해 CNN은 특히 큰 입력 크기를 다룰 때 완전히 연결된 네트워크에 비해 매개변수 효율성이 훨씬 뛰어납니다.</p>
<div class="content-ad"></div>
<p>Weight sharing은 네트워크가 입력 이미지의 위치에 관계없이 특징을 감지할 수 있도록 합니다. 필터가 에지나 특정 패턴을 인식하는 방법을 학습하면 이미지의 어느 곳에서든 해당 특징을 감지할 수 있으므로 CNN은 기본적으로 변환 불변성을 갖습니다.</p>
<p>학습할 매개변수가 적어지므로, CNN은 학습 데이터에 과적합될 가능성이 적어집니다. 이는 모델이 학습 데이터에서 실제로 관측되는 데이터로 일반화하는 능력을 향상시킴으로써, 실제 과제에서의 성능을 향상시킵니다.</p>
<p>Weight Sharing 작동 방식
순방향 전파 중에, 고정된 가중치 세트를 가진 필터가 입력 이미지를 슬라이드하며, 필터 가중치와 이미지의 지역 영역 간의 내적을 계산합니다. 이 과정은 이미지의 공간적 범위에 걸쳐 감지된 특징의 존재 및 강도를 나타내는 특징 맵을 생성합니다.</p>
<p>공간적 영역 전체에 걸쳐 가중치를 광범위하게 재사용하지만, 각각의 가중치는 적용된 위치의 모든 위치에서의 총 그래디언트를 기반으로 업데이트됩니다. 이를 통해 필터 가중치가 작업에 가장 관련성 있는 특징을 감지하도록 최적화되어, 전체 데이터셋을 기반으로 합니다.</p>
<div class="content-ad"></div>
<h2>2.6: 피처 맵 생성</h2>
<p>이전에 보았던 대로, 피처 맵은 CNN 내에서 입력 이미지나 이전 피처 맵에 필터나 커널을 적용하여 생성된 출력입니다. 입력의 공간 차원에 걸쳐 필터의 반응을 나타내며, 이미지에서 특정 피처가 어디에 어떻게 감지되었는지를 강조합니다. 이제 각 요소가 어떻게 CNN의 결과 피처 맵에 영향을 미치는지 다시 살펴봅시다.</p>
<p>피처 맵 생성의 핵심은 컨볼루션 연산에 있습니다. 여기서 학습된 가중치를 가진 필터가 입력 이미지나 이전 레이어의 피처 맵을 이전하며 슬라이딩(또는 합성)합니다. 각 위치에서 필터는 이미지의 해당 부분과 요소별 곱셈을 수행하고 결과를 합산하여 새로운 피처 맵의 단일 출력 픽셀을 생성합니다.</p>
<p>필터의 가중치는 엣지, 질감 또는 더 깊은 레이어에서 더 복잡한 패턴과 같은 피처 유형을 감지합니다. 훈련 중에 이 가중치는 역전파를 통해 조정되어 네트워크가 주어진 작업에 가장 중요한 피처를 학습할 수 있게 합니다.</p>
<div class="content-ad"></div>
<p>스트라이드의 크기와 패딩의 사용은 특징 맵의 공간적 차원에 직접적인 영향을 미칩니다. 더 큰 스트라이드는 필터 적용 사이의 중첩을 줄이는 보다 넓은 범위의 적용을 유도하여 특징 맵의 크기를 줄입니다. 패딩은 입력의 공간적 차원을 보존하기 위해 사용되며 이미지의 가장자리에 있는 특징이 손실되지 않도록 보장합니다.</p>
<p>합성곱 레이어는 일반적으로 여러 필터를 포함하며, 각각은 다른 특징을 감지하도록 설계됩니다. 각 필터의 출력은 별도의 특징 맵이며, 이러한 특징 맵은 깊이 차원을 따라 쌓여 3차원 볼륨을 만듭니다. 이 다각적인 방식은 네트워크가 입력 이미지의 풍부한 표현을 포착할 수 있도록 합니다.</p>
<p>합성곱 작업을 통해 특징 맵이 생성된 후에는 주로 ReLU와 같은 활성화 함수를 통과합니다. 이는 비선형성을 도입하여 네트워크가 보다 복잡한 패턴을 학습하고 표현할 수 있게 합니다.</p>
<p>ReLU와 다른 활성화 함수에 대해 더 알고 싶다면, 이 기사를 확인해보세요:</p>
<div class="content-ad"></div>
<p>활성화된 피처 맵은 다음 계층 또는 풀링 작업으로 진행됩니다.</p>
<h2>2.7: 풀링 레이어</h2>
<p>풀링 레이어는 피처 맵의 공간 차원을 줄이는 역할을 합니다. 이 감소는 계산 부하를 줄이고, 오버피팅을 최소화하며, 가장 중요한 정보만을 보존하는 데 중요합니다. 풀링 레이어의 구체적인 내용, 유형 및 CNN 성능에 미치는 영향에 대해 알아봅시다.</p>
<p>풀링 레이어는 피처 맵의 크기를 줄여 망에 필요한 매개변수 및 계산을 줄입니다. 이 간소화는 가장 중요한 특성에 집중하는 데 도움이 됩니다.</p>
<div class="content-ad"></div>
<p>특징 맵의 패치에서 특징의 존재를 요약함으로써, 풀링은 네트워크가 입력 이미지의 작은 변동 및 변환에 강건함을 유지하는 데 도움이 됩니다.</p>
<p>CNN을 다룰 때 알아야 할 몇 가지 종류의 풀링 기술이 있습니다:</p>
<p>최대 풀링
이것은 가장 일반적인 풀링 형태로, 특징 맵의 값 집합에서 최대값이 선택되어 다음 레이어로 전달됩니다. 최대 풀링은 특징 맵의 각 패치에서 가장 현저한 특징을 효과적으로 포착합니다.</p>
<p>우리는 특징 맵을 F로, 풀링 작업을 P_max로 표시하며, 크기가 n×n인 창으로 위치 (i,j)에서의 최대 풀링 결과는 다음과 같이 표현될 수 있습니다:</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_6.png" alt="image"></p>
<p>여기서 s는 풀링 윈도우의 보폭이며, a, b는 윈도우 차원을 반복합니다. 이 작업은 특성 맵을 가로지르는 각 윈도우 위치에 독립적으로 적용됩니다.</p>
<p>평균 풀링
최대 풀링과 달리 평균 풀링은 특성 맵의 각 패치에서 값의 평균을 취합니다. 이 방법은 보다 일반화된 특성 표현을 제공하지만, 더 작지만 의미 있는 특성의 영향을 약화시킬 수 있습니다.</p>
<p>특성 맵 F와 n×n 풀링 윈도우에 대해 위치 (i,j)에서의 평균 풀링 연산은 수학적으로 다음과 같이 표현될 수 있습니다:</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_7.png" alt="이미지"></p>
<p>맥스 풀링과 유사하게, s는 스트라이드를 나타내며, a,b는 창을 순회하는 반면, 이 연산에서는 각 창 내 값들의 평균을 계산합니다.</p>
<p>글로벌 풀링
글로벌 풀링에서는 전체 피처 맵이 각각 맥스(글로벌 맥스 풀링) 또는 평균(글로벌 평균 풀링)을 취함으로써 하나의 값으로 축소됩니다. 이 접근 방식은 종종 각 피처 맵을 완전 연결 레이어 이전에 하나의 값으로 줄이는 데 사용됩니다.</p>
<p>크기가 M×N인 피처 맵 F에 대해, 글로벌 맥스 풀링 (P_gmax) 및 글로벌 평균 풀링 (P_gavg)은 다음과 같이 정의될 수 있습니다:</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_8.png" alt="Global pooling operations"></p>
<p>전역 풀링 연산은 전체 피쳐 맵을 하나의 요약 통계치로 압축하는데 사용되며, 이는 분류를 위한 완전 연결 레이어 이전에 모델 파라미터를 줄이는 데 특히 유용합니다.</p>
<p>풀링 동작 방식
풀링 레이어는 각 피쳐 맵에 독립적으로 작동하며, 피쳐 맵을 가로지르면서 창(또는 필터)을 슬라이딩하고 해당 창 내의 값을 요약하여 한 가지 값으로 줄입니다 (사용된 풀링 전략에 따라). 이 과정은 피쳐 맵의 공간 차원을 줄입니다.</p>
<p>창의 크기와 스트라이드(창이 한 번에 이동하는 거리)는 피쳐 맵이 얼마나 줄어드는지를 결정합니다. 흔히 선택하는 것은 2x2 창과 스트라이드 2인 경우인데, 이는 피쳐 맵의 크기를 절반으로 줄입니다.</p>
<div class="content-ad"></div>
<h2>2.8: 완전 연결층</h2>
<p><img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_9.png" alt="image"></p>
<p>완전 연결층은 CNN의 끝쪽에 자주 위치합니다. 이 층들은 학습된 특징에 기반한 고수준 추론이 이루어지는 곳으로, 궁극적으로는 분류나 예측으로 이어집니다.</p>
<p>완전 연결층에서는 각 뉴런이 이전 층의 모든 활성화에 연결됩니다. 이 밀집된 연결은 층이 추출된 특징들의 전체 맥락을 갖게 해주어, 특징 맵 전체에 분산된 복잡한 패턴을 학습할 수 있게 합니다.</p>
<div class="content-ad"></div>
<p>완전 연결 계층은 합성곱 및 풀링 계층에서 식별된 공간적으로 분산된 특징을 전체 입력의 전역 표현으로 통합합니다. 이 통합은 분류와 같은 전체 입력을 이해해야 하는 작업에 중요합니다.</p>
<p>합성곱에서 완전 연결 계층으로
완전 연결 계층에 진입하기 전에, 이전 합성곱이나 풀링 계층의 출력(일반적으로 다차원 특징 맵)이 하나의 벡터로 평평하게 변환됩니다. 이 단계는 공간 구조화된 데이터를 완전 연결 계층에서 처리할 수 있도록 포맷을 변환합니다.</p>
<p>완전 연결 계층의 뉴런들은 평평한 특징 맵에 의해 제시된 전역 정보를 고려함으로써 데이터에서 고수준 패턴을 학습할 수 있습니다. 이 능력은 전체 입력 이미지를 기반으로 한 예측이나 분류를 만드는 데 기본적입니다.</p>
<p>CNN에서의 역할
많은 CNN 아키텍처에서 최종 완전 연결 계층은 분류 계층으로 기능하며, 각 뉴런은 특정 클래스를 나타냅니다. 네트워크의 예측은 일반적으로 이러한 뉴런들의 활성화에 의해 결정되며, 활성화를 확률로 변환하는 소프트맥스 함수를 통해 수행됩니다.</p>
<div class="content-ad"></div>
<p>합성곱 레이어에 의해 추출된 지역화된 추상적인 특징을 완전 연결 레이어가 입력 데이터의 일관된 이해로 합성합니다. 이러한 합성은 네트워크가 입력에 대해 전체적으로 추론하고 판단을 내릴 수 있도록 중요합니다.</p>
<h1>3: CNN 구축 단계별 안내서</h1>
<p>이제 비즈니스 쪽으로 가지고 CNN을 구축해 봅시다. MNIST 데이터셋에서 손으로 쓴 숫자의 이미지 분류를 위해 PyTorch를 사용하여 합성곱 신경망(CNN)을 설정하고 훈련 및 평가할 것입니다. [MNIST 데이터셋은 Creative Commons Attribution-Share Alike 3.0 라이선스 조건 하에 제공됩니다]</p>
<p>오늘 다룰 모든 코드가 포함된 Jupyter Notebook을 참고하시기 바랍니다:</p>
<div class="content-ad"></div>
<h2>3.1: 환경 설정하기</h2>
<p>필요한 라이브러리와 모듈을 준비해봅시다. 신경망을 구축하고 훈련하기 위해 PyTorch (torch)와 이를 위한 신경망 모듈 (nn), 최적화 모듈 (optim)이 불러와집니다. torch.nn.functional에서 ReLU 활성화 및 최대 풀링과 같은 작업에 사용되는 기능이 제공됩니다. DataLoader 유틸리티를 통해 배치 처리와 데이터 관리를 용이하게 할 수 있고, torchvision은 데이터셋 및 이미지 변환을 위해 사용됩니다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, optim
<span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader
<span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets, transforms
</code></pre>
<h2>3.2: 데이터 준비하기</h2>
<div class="content-ad"></div>
<p>MNIST 데이터셋은 이미지를 텐서 형식으로 변환한 후 픽셀 값을 정규화하는 변환 파이프라인으로 로드됩니다. 정규화 매개변수(평균=0.1307, 표준편차=0.3081)는 MNIST 데이터셋에 특별히 선택되어 그레이스케일 이미지를 표준화하여 신경망의 성능을 최적화합니다.</p>
<pre><code class="hljs language-js">transform = transforms.<span class="hljs-title class_">Compose</span>([
    transforms.<span class="hljs-title class_">ToTensor</span>(),
    transforms.<span class="hljs-title class_">Normalize</span>((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))
])
mnist_dataset = datasets.<span class="hljs-title function_">MNIST</span>(root=<span class="hljs-string">'./data'</span>, train=<span class="hljs-title class_">True</span>, download=<span class="hljs-title class_">True</span>, transform=transform)
</code></pre>
<p>데이터셋에서의 샘플 이미지를 matplotlib을 사용하여 표시하여, 네트워크가 훈련될 데이터 유형을 시각적으로 보여줍니다.</p>
<pre><code class="hljs language-js">image, label = mnist_dataset[<span class="hljs-number">0</span>]
plt.<span class="hljs-title function_">imshow</span>(image.<span class="hljs-title function_">squeeze</span>().<span class="hljs-title function_">numpy</span>(), cmap=<span class="hljs-string">'gray'</span>)
plt.<span class="hljs-title function_">title</span>(f<span class="hljs-string">'Label: {label}'</span>)
plt.<span class="hljs-title function_">show</span>()
</code></pre>
<div class="content-ad"></div>
<p>다음 이미지가 표시됩니다:</p>
<img src="/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_10.png">
<p>데이터셋은 모델 훈련 중에 효율적인 처리를 위해 배치 처리, 셔플링, 데이터셋 준비를 다루는 DataLoader 인스턴스에 의해 훈련 및 검증 세트로 나누어집니다.</p>
<pre><code class="hljs language-js">train_size = <span class="hljs-title function_">int</span>(<span class="hljs-number">0.8</span> * <span class="hljs-title function_">len</span>(mnist_dataset))
val_size = <span class="hljs-title function_">len</span>(mnist_dataset) - train_size
train_dataset, val_dataset = <span class="hljs-title function_">random_split</span>(mnist_dataset, [train_size, val_size])
</code></pre>
<div class="content-ad"></div>
<h2>3.3: CNN 모델 설계</h2>
<p>데이터 전처리를 한 후에 모델을 만들어 보겠습니다. 따라서 nn.Module에서 상속된 MyCNN 클래스를 초기화합니다. 이 상속은 PyTorch에서 모델을 정의하는 방법입니다. 이 상속을 통해 MyCNN은 PyTorch 모델의 모든 기능을 갖추게 되며, 훈련, 예측 등이 가능해집니다.</p>
<p><strong>init</strong> 함수는 MyCNN 클래스의 생성자입니다. 이 함수에서 신경망의 층들이 정의됩니다. super(MyCNN, self).<strong>init</strong>() 라인은 기본 nn.Module 클래스의 생성자를 호출하는데, 이는 PyTorch가 모든 것을 올바르게 초기화하기 위해 필요합니다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCNN</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-built_in">super</span>(MyCNN, self).__init__()
        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">32</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)
        self.conv2 = nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)
        self.fc1 = nn.Linear(<span class="hljs-number">7</span>*<span class="hljs-number">7</span>*<span class="hljs-number">64</span>, <span class="hljs-number">128</span>)
        self.fc2 = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)
</code></pre>
<div class="content-ad"></div>
<p>위의 코드에서 볼 수 있듯이, 이 네트워크에는 conv1과 conv2 두 개의 합성곱 레이어가 포함되어 있습니다.</p>
<p>conv1은 단일 채널 이미지(회색조 이미지와 같은)를 입력으로 받아 3x3 필터(또는 커널) 크기와 1의 스트라이드, 1의 패딩을 사용하여 32개의 특성 맵을 생성합니다. 패딩은 출력 특성 맵이 입력과 동일한 크기로 유지되도록 추가됩니다.</p>
<p>conv2는 conv1에서 32개의 특성 맵을 입력으로 받아 3x3 커널, 1의 스트라이드, 1의 패딩을 사용하여 64개의 특성 맵을 생성합니다. 이 레이어는 conv1에서 제공된 입력으로부터 특성을 더 추출합니다.</p>
<p>합성곱 레이어 이후에는 두 개의 완전 연결(fc) 레이어가 있습니다.</p>
<div class="content-ad"></div>
<p>fc1은 합성곱 레이어의 출력을 크기 128의 벡터로 변환하는 첫 번째 완전 연결 레이어입니다. 입력 크기는 7<em>7</em>64이며, 이는 이 레이어에 도달하기 전에 특성 맵이 단일 벡터로 펼쳐지며, 평탄화되기 전의 특성 맵의 차원이 7x7이고 64개 채널임을 의미합니다. 이 단계는 공간 특성 추출에서 해당 특성을 기반으로 결정(분류)을 내리는 것으로 전환하는 데 중요합니다.</p>
<p>fc2는 두 번째 완전 연결 레이어로, fc1에서 가져온 128차원 벡터를 가져와 10차원 벡터를 출력합니다. 이 출력 크기는 일반적으로 분류 문제의 클래스 수에 해당하며, 이 네트워크가 이미지를 10가지 범주 중 하나로 분류하는 방식으로 설계되었음을 시사합니다.</p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">_initialize_weights</span>(self):
    <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.<span class="hljs-title function_">modules</span>():
        <span class="hljs-keyword">if</span> <span class="hljs-title function_">isinstance</span>(m, nn.<span class="hljs-property">Conv2d</span>):
            nn.<span class="hljs-property">init</span>.<span class="hljs-title function_">normal_</span>(m.<span class="hljs-property">weight</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)
            <span class="hljs-keyword">if</span> m.<span class="hljs-property">bias</span> is not <span class="hljs-title class_">None</span>:
                nn.<span class="hljs-property">init</span>.<span class="hljs-title function_">constant_</span>(m.<span class="hljs-property">bias</span>, <span class="hljs-number">0</span>)
        elif <span class="hljs-title function_">isinstance</span>(m, nn.<span class="hljs-property">Linear</span>):
            nn.<span class="hljs-property">init</span>.<span class="hljs-title function_">xavier_uniform_</span>(m.<span class="hljs-property">weight</span>)
            <span class="hljs-keyword">if</span> m.<span class="hljs-property">bias</span> is not <span class="hljs-title class_">None</span>:
                nn.<span class="hljs-property">init</span>.<span class="hljs-title function_">constant_</span>(m.<span class="hljs-property">bias</span>, <span class="hljs-number">0</span>)
</code></pre>
<p>가중치 초기화는 네트워크가 경사도를 사라지게 하거나 폭발시키지 않는 범위의 가중치로 시작하도록 보장하기 위해 적용됩니다. 합성곱 레이어는 정규 분포로 초기화되고, 완전 연결 레이어는 Xavier 균일 분포 초기화를 사용합니다.</p>
<div class="content-ad"></div>
<p>제 이전 글에서 자비에 초기화 및 다른 유형의 초기화에 대해 더 알아보고 싶다면 확인해보세요:</p>
<p>MyCNN 클래스의 forward 메서드는 입력 데이터가 CNN을 통과하면서 겪는 작업 순서를 정의합니다.</p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">forward</span>(self, x):
    x = F.<span class="hljs-title function_">relu</span>(self.<span class="hljs-title function_">conv1</span>(x))
    x = F.<span class="hljs-title function_">max_pool2d</span>(x, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
    x = F.<span class="hljs-title function_">relu</span>(self.<span class="hljs-title function_">conv2</span>(x))
    x = F.<span class="hljs-title function_">max_pool2d</span>(x, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
    x = x.<span class="hljs-title function_">view</span>(x.<span class="hljs-title function_">size</span>(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)
    x = F.<span class="hljs-title function_">relu</span>(self.<span class="hljs-title function_">fc1</span>(x))
    x = self.<span class="hljs-title function_">fc2</span>(x)
    <span class="hljs-keyword">return</span> x
</code></pre>
<p>이 메서드를 단계별로 살펴보며, 각 작업에 중점을 두고 입력 이미지가 출력 예측으로 어떻게 변환되는지 이해해봅시다.</p>
<div class="content-ad"></div>
<p>첫 번째 합성곱 레이어</p>
<pre><code class="hljs language-js">x = F.<span class="hljs-title function_">relu</span>(self.<span class="hljs-title function_">conv1</span>(x))
</code></pre>
<p>이 합성곱 레이어 (conv1)를 통과하는 입력 텐서 x은 이미지의 일괄 처리를 나타냅니다. 이 레이어는 입력에 학습된 필터를 적용하여 가장자리와 질감 같은 기본 시각적 특징을 캡처합니다. 합성곱 연산 다음에 바로 인플레이스로 ReLU 활성화 함수가 적용됩니다. ReLU는 출력 텐서의 모든 음의 값을 제로로 설정하여 네트워크가 특징을 구별하는 능력을 향상시킵니다.</p>
<p>첫 번째 풀링 연산</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">x = F.<span class="hljs-title function_">max_pool2d</span>(x, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
</code></pre>
<p>첫 번째 합성곱 및 활성화를 거친 후 최대 풀링 작업이 적용됩니다. 이 작업은 풀 크기와 스트라이드로 인해 피쳐 맵의 공간 차원을 절반으로 줄입니다. 이는 피쳐 맵의 2x2 패치 내에서 가장 중요한 피쳐를 요약하는 역할을 합니다. 최대 풀링은 표현을 작은 이동 및 왜곡에 대해 다소 불변하게 만들어줍니다.</p>
<p>두 번째 합성곱 층</p>
<pre><code class="hljs language-js">x = F.<span class="hljs-title function_">relu</span>(self.<span class="hljs-title function_">conv2</span>(x))
</code></pre>
<div class="content-ad"></div>
<p>두 번째 합성곱층(conv2)으로 반복 과정이 진행됩니다. 여기서는 이제 축소된 특징 맵에 새로운 필터 세트를 적용합니다. 이 층은 일반적으로 첫 번째 층에서 식별된 기본 패턴을 기반으로 한 더 복잡한 특징을 포착합니다. 다시 한 번 ReLU 활성화가 이어져 비선형성을 유지합니다.</p>
<p>두 번째 풀링 작업</p>
<pre><code class="hljs language-js">x = F.<span class="hljs-title function_">max_pool2d</span>(x, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>)
</code></pre>
<p>다른 최대 풀링 단계를 통해 결과 특징 맵의 공간적 차원이 더욱 줄어들어 특징 표현을 간결화하고 후속 층의 계산 복잡성을 줄입니다.</p>
<div class="content-ad"></div>
<p>펼치기</p>
<pre><code class="hljs language-js">x = x.<span class="hljs-title function_">view</span>(x.<span class="hljs-title function_">size</span>(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)
</code></pre>
<p>전체 연결 계층으로 넘어가기 전에 다차원 특징 맵을 배치 내 각 이미지에 대해 단일 벡터로 펼쳐야 합니다. 이 작업은 텐서를 다시 구성하여 각 이미지의 특징 맵이 텐서의 단일 행이 되도록 만들며, 완전 연결 처리에 적합한 형식으로 모든 특징 정보를 보존합니다.</p>
<p>첫 번째 완전 연결 계층</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">x = F.<span class="hljs-title function_">relu</span>(self.<span class="hljs-title function_">fc1</span>(x))
</code></pre>
<p>평탄화된 텐서는 첫 번째 완전 연결 계층(fc1)을 통과하여 전체 특징 집합에서 복잡한 패턴을 학습할 수 있습니다. ReLU 함수가 한 번 더 적용되어 비선형성을 도입하고, 네트워크가 더 복잡한 함수를 학습하고 표현할 수 있도록 합니다.</p>
<p>두 번째 완전 연결 계층 (출력 계층)</p>
<pre><code class="hljs language-js">x = self.<span class="hljs-title function_">fc2</span>(x)
</code></pre>
<div class="content-ad"></div>
<p>마침내, 텐서는 출력 레이어 역할을 하는 두 번째 완전 연결 레이어(FC2)를 통과합니다. 이 레이어에는 예측할 클래스 수와 동일한 수의 뉴런이 있습니다(MNIST 숫자의 경우 10개). 이 레이어의 출력은 네트워크가 각 클래스에 대해 예측한 값을 나타냅니다.</p>
<h2>3.4: 모델 컴파일</h2>
<p>모델은 CrossEntropyLoss로 분류되어 있고 Adam 옵티마이저를 사용하여 가중치를 조정하며, 학습률 및 가중치 감소와 같은 특정 매개변수도 함께 사용하여 컴파일됩니다.</p>
<pre><code class="hljs language-js">criterion = nn.<span class="hljs-title class_">CrossEntropyLoss</span>()
optimizer = optim.<span class="hljs-title class_">Adam</span>(model.<span class="hljs-title function_">parameters</span>(), lr=<span class="hljs-number">1e-3</span>, weight_decay=<span class="hljs-number">1e-5</span>, amsgrad=<span class="hljs-title class_">True</span>, eps=<span class="hljs-number">1e-8</span>, betas=(<span class="hljs-number">0.9</span>, <span class="hljs-number">0.999</span>))
</code></pre>
<div class="content-ad"></div>
<p>Adam 옵티마이저는 딥러닝 모델을 훈련하는 인기 알고리즘으로, AdaGrad와 RMSProp 알고리즘의 최상의 특성을 결합하여 소음이 있는 문제에서 희소한 그래디언트를 효율적으로 처리합니다. 이는 매개변수별로 학습률을 조정하여 광범위한 작업과 모델에 매우 효과적이고 적합합니다. Adam에 대해 더 자세히 알고 싶다면, 수학적인 내용을 검토하고 처음부터 구축한 내 기사를 살펴보세요:</p>
<h2>3.5: CNN 훈련</h2>
<p>제공된 로직의 Trainer 클래스는 CNN 모델을 훈련하는 데 필요한 필수 기능을 포함하고 있습니다. 이는 순방향 패스, 역방향 패스(그래디언트 계산 및 가중치 업데이트), 훈련 및 검증 손실 모니터링, 조기 중단 구현, 학습률 조정, 그리고 모델 성능 평가를 포함합니다. 이 클래스를 분석하여 구조와 기능을 깊이 이해해 봅시다.</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Trainer</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model, criterion, optimizer, device, patience=<span class="hljs-number">7</span></span>):
        self.model = model
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device
        self.early_stopping = EarlyStopping(patience=patience)
        self.scheduler = ReduceLROnPlateau(self.optimizer, <span class="hljs-string">'min'</span>, patience=<span class="hljs-number">3</span>, verbose=<span class="hljs-literal">True</span>, factor=<span class="hljs-number">0.5</span>, min_lr=<span class="hljs-number">1e-6</span>)
        self.train_losses = []
        self.val_losses = []
        self.gradient_norms = []
</code></pre>
<div class="content-ad"></div>
<p>초기화 메서드인 __init__에서 Trainer 클래스는 CNN 모델, 손실 함수(criterion), 옵티마이저와 함께 CPU 또는 GPU에서 학습할 장치와 조기 종료를 위한 인자로 받습니다. EarlyStopping 인스턴스는 검증 손실을 모니터링하고 모델이 더 이상 개선되지 않을 경우 훈련을 중지하여 과적합을 방지합니다. 학습률 스케줄러(ReduceLROnPlateau)도 초기화되어 검증 손실을 기반으로 학습률을 동적으로 조정하여 훈련 중에 최적의 학습률을 찾도록 도와줍니다. 분석 및 디버깅 목적으로 학습 및 검증 손실 및 그레이디언트 노름을 추적하기 위한 리스트가 초기화됩니다.</p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">train</span>(self, train_loader, val_loader, epochs):
    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-title function_">range</span>(epochs):
        self.<span class="hljs-property">model</span>.<span class="hljs-title function_">train</span>()
        <span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> <span class="hljs-attr">train_loader</span>:
            images, labels = images.<span class="hljs-title function_">to</span>(self.<span class="hljs-property">device</span>), labels.<span class="hljs-title function_">to</span>(self.<span class="hljs-property">device</span>)
            self.<span class="hljs-property">optimizer</span>.<span class="hljs-title function_">zero_grad</span>()
            outputs = self.<span class="hljs-title function_">model</span>(images)
            loss = self.<span class="hljs-title function_">criterion</span>(outputs, labels)
            self.<span class="hljs-property">train_losses</span>.<span class="hljs-title function_">append</span>(loss.<span class="hljs-title function_">item</span>())
            loss.<span class="hljs-title function_">backward</span>()
            self.<span class="hljs-property">optimizer</span>.<span class="hljs-title function_">step</span>()
</code></pre>
<p>train 메서드는 지정된 에폭 수에 대한 학습 프로세스를 조율합니다. 각 에폭마다 모델을 훈련 모드로 설정하고 train_loader를 사용하여 학습 데이터셋을 반복합니다. 입력 이미지와 레이블을 지정된 장치로 이동시킵니다. 옵티마이저의 그라디언트는 이전 반복에서의 누적을 방지하기 위해 각 순방향 패스 전에 0으로 초기화됩니다. 모델의 예측을 얻고, 지정된 criterion을 사용하여 손실을 계산합니다. 손실 값은 추적을 위해 train_losses 리스트에 추가됩니다. loss.backward()를 호출하여 역전파를 수행하고, 옵티마이저는 optimizer.step()로 모델 가중치를 업데이트합니다.</p>
<pre><code class="hljs language-js">val_loss = self.evaluate(val_loader)
self.<span class="hljs-property">val_losses</span>.<span class="hljs-title function_">append</span>(val_loss)
self.<span class="hljs-property">scheduler</span>.<span class="hljs-title function_">step</span>(val_loss)
self.<span class="hljs-title function_">early_stopping</span>(val_loss)
</code></pre>
<div class="content-ad"></div>
<p>훈련 데이터를 처리한 후 모델은 평가 메서드를 사용하여 검증 데이터셋에서 평가되며, 평균 검증 손실을 계산합니다. 이 손실은 학습률을 조정하고 조기 종료 조건이 충족되었는지 확인하는 데 사용됩니다. 검증 손실은 분석을 위해 추적됩니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">if</span> self.<span class="hljs-property">early_stopping</span>.<span class="hljs-property">early_stop</span>:
    <span class="hljs-title function_">print</span>(<span class="hljs-string">"조기 종료"</span>)
    <span class="hljs-keyword">break</span>
</code></pre>
<p>조기 종료가 발생하면, 과적합을 방지하기 위해 훈련이 중지됩니다. 이 결정은 인내 매개변수로 정의된 여러 epoch 동안 검증 손실이 향상되지 않았는지에 따라 기반으로 합니다.</p>
<pre><code class="hljs language-js">def evaluate(self, test_loader):
    self.<span class="hljs-property">model</span>.<span class="hljs-built_in">eval</span>()
    total_loss = <span class="hljs-number">0</span>
    <span class="hljs-keyword">with</span> torch.<span class="hljs-title function_">no_grad</span>():
        <span class="hljs-keyword">for</span> images, labels <span class="hljs-keyword">in</span> <span class="hljs-attr">test_loader</span>:
            images, labels = images.<span class="hljs-title function_">to</span>(self.<span class="hljs-property">device</span>), labels.<span class="hljs-title function_">to</span>(self.<span class="hljs-property">device</span>)
            outputs = self.<span class="hljs-title function_">model</span>(images)
            loss = self.<span class="hljs-title function_">criterion</span>(outputs, labels)
            total_loss += loss.<span class="hljs-title function_">item</span>()
    <span class="hljs-keyword">return</span> total_loss / <span class="hljs-title function_">len</span>(test_loader)
</code></pre>
<div class="content-ad"></div>
<p>evaluate 메서드는 모델의 가중치를 업데이트하지 않고 유효성 검사 또는 테스트 데이터셋에서 평균 손실을 계산합니다. 이 메서드는 모델을 평가 모드로 설정하고 효율성을 위해 그래디언트 계산을 비활성화합니다.</p>
<h1>4: 모델 성능 향상</h1>
<p>합성곱 신경망(CNN)의 성능을 개선하고 과적합을 방지하는 것은 딥러닝 모델을 교육하는 중요한 도전 과제입니다. 제공된 코드 스니펫은 데이터 증가, 드롭아웃, 배치 정규화와 같은 기술에 대해 명시적으로 설명하지 않으며 전이 학습에 대해서도 다루지 않습니다. 그러나 이러한 전략들은 CNN을 향상시키는 데 중요하므로 이들이 훈련 과정에 통합되고 모델 성능에 미치는 잠재적인 영향에 대해 알아봅시다.</p>
<h2>4.1: 데이터 증가</h2>
<div class="content-ad"></div>
<p>데이터 증가는 기존 이미지에 임의의 변환(회전, 뒤집기, 크기 조정 등)을 적용하여 학습 데이터셋의 다양성을 인위적으로 증가시킵니다. 이 다양성은 모델이 더 많은 입력 변화 범위에서 학습함으로써 새로운 데이터에 대해 더 잘 일반화되도록 돕습니다.</p>
<p>PyTorch에서 데이터 증가를 구현하려면 데이터셋을 준비할 때 사용되는 transforms.Compose를 확장할 수 있습니다:</p>
<pre><code class="hljs language-js">transform = transforms.<span class="hljs-title class_">Compose</span>([
    transforms.<span class="hljs-title class_">RandomHorizontalFlip</span>(),
    transforms.<span class="hljs-title class_">RandomRotation</span>(<span class="hljs-number">10</span>),
    transforms.<span class="hljs-title class_">ToTensor</span>(),
    transforms.<span class="hljs-title class_">Normalize</span>((<span class="hljs-number">0.1307</span>,), (<span class="hljs-number">0.3081</span>,))
])
</code></pre>
<p>랜덤 뒤집기와 회전을 추가함으로써 훈련 데이터를 다양하게 만들어 모델이 더 견고한 특징을 학습하도록 돕습니다.</p>
<div class="content-ad"></div>
<h2>4.2: Dropout</h2>
<p>드롭아웃은 학습 중에 입력 뉴런의 일부를 무작위로 0으로 설정하여 과도한 공동 적응을 방지하는 정칙화 기술입니다. 이 무작위성은 네트워크가 다른 뉴런의 무작위 하위 집합과 함께 유용한 보다 견고한 기능을 학습하도록 강제합니다.</p>
<p>파이토치에서 CNN 모델에 드롭아웃을 추가하려면 nn.Dropout 레이어를 포함시킵니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCNN</span>(nn.<span class="hljs-property">Module</span>):
    def <span class="hljs-title function_">__init__</span>(self):
        <span class="hljs-variable language_">super</span>(<span class="hljs-title class_">MyCNN</span>, self).<span class="hljs-title function_">__init__</span>()
        # 합성곱 레이어
        self.<span class="hljs-property">fc1</span> = nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">7</span>*<span class="hljs-number">7</span>*<span class="hljs-number">64</span>, <span class="hljs-number">128</span>)
        self.<span class="hljs-property">dropout</span> = nn.<span class="hljs-title class_">Dropout</span>(<span class="hljs-number">0.5</span>)
        self.<span class="hljs-property">fc2</span> = nn.<span class="hljs-title class_">Linear</span>(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)
    def <span class="hljs-title function_">forward</span>(self, x):
        # 합성곱 및 풀링 작업
        x = x.<span class="hljs-title function_">view</span>(x.<span class="hljs-title function_">size</span>(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)
        x = F.<span class="hljs-title function_">relu</span>(self.<span class="hljs-title function_">fc1</span>(x))
        x = self.<span class="hljs-title function_">dropout</span>(x)
        x = self.<span class="hljs-title function_">fc2</span>(x)
        <span class="hljs-keyword">return</span> x
</code></pre>
<div class="content-ad"></div>
<p>마지막 완전 연결 레이어 앞에 드롭아웃 레이어를 추가하면 모델이 학습된 표현을 여러 뉴런에 분배하도록 유도하여 오버피팅을 완화하는 데 도움이 됩니다.</p>
<h2>4.3: 배치 정규화</h2>
<p>배치 정규화는 각 미니 배치에 대해 레이어의 입력을 표준화하여 학습 프로세스를 안정화시키고 딥 네트워크를 훈련하는 데 필요한 훈련 에포크 수를 크게 줄입니다.</p>
<p>모델에 배치 정규화를 포함하는 방법은 다음과 같습니다:</p>
<div class="content-ad"></div>
<pre><code class="hljs language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCNN</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-built_in">super</span>(MyCNN, self).__init__()
        <span class="hljs-comment"># Covolutional layers</span>
        self.conv1_bn = nn.BatchNorm2d(<span class="hljs-number">32</span>)
        <span class="hljs-comment"># Fully connected layers</span>
        
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):
        x = F.relu(self.conv1_bn(self.conv1(x)))
        <span class="hljs-comment"># Continue through model</span>
</code></pre>
<p>컨볼루션 레이어 다음에 배치 정규화를 적용한 후 활성화 함수를 사용하는 것은 출력을 정규화하여 수렴 속도를 높이고 전반적인 성능을 향상시켜줍니다.</p>
<h2>4.4: 전이 학습</h2>
<p>전이 학습은 한 작업에서 훈련된 모델을 다른 관련 작업에서 훈련을 위한 출발점으로 사용하는 기술을 말합니다. 새 작업에 제한된 데이터셋이 있는 경우 특히 유용합니다. PyTorch는 ImageNet과 같은 대규모 데이터셋에서 사전 훈련된 모델을 쉽게 로드하고 조정할 수 있도록 지원하여 전이 학습을 용이하게 합니다.</p>
<div class="content-ad"></div>
<p>프리 트레인 모델을 활용하는 방법은 아주 쉬워요!</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> models

model = models.resnet18(pretrained=<span class="hljs-literal">True</span>)
<span class="hljs-comment"># 마지막 완전 연결 레이어 교체하기</span>
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, <span class="hljs-number">10</span>)  <span class="hljs-comment"># 새로운 작업을 위해 10개의 클래스로 가정</span>
<span class="hljs-comment"># 마지막 완전 연결 레이어를 제외한 모든 레이어 동결하기</span>
<span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> model.parameters():
    param.requires_grad = <span class="hljs-literal">False</span>
model.fc.requires_grad = <span class="hljs-literal">True</span>
</code></pre>
<p>요기서, 사전 훈련된 ResNet-18 모델을 사용해서, 10개의 클래스를 위한 새 작업에 맞게 마지막 레이어를 대체했어요. 마지막 레이어를 제외한 모든 레이어의 가중치를 동결하면, 분류기 레이어만을 미세 조정해 원본 데이터셋에서 학습한 기능 추출 능력을 활용할 수 있어요.</p>
<p>CNN 훈련 과정에 이러한 전략을 통합시키면, 오버피팅이 줄어들 뿐만 아니라 견고한 특징 학습을 보장하고 사전 훈련된 모델로부터 지식을 활용하여 모델 성능을 향상시킬 수 있어요.</p>
<div class="content-ad"></div>
<h1>5: 결론</h1>
<p>합성곱 신경망에 대해 심층적으로 파헤쳐 보았습니다. 데이터 설정 및 준비부터 CNN 구조와 계층 분해까지 많은 내용을 다루었습니다. 이러한 모델의 작동 원리를 살펴봤습니다. 가중치 초기화와 데이터 증강, 전이 학습과 같은 기술을 사용하여 모델의 성능을 심각하게 향상시킬 수 있다는 점을 살펴보았습니다. 이러한 방법들은 모델이 더욱 똑똑하게 만들어주어, 오버피팅과 같은 일반적인 함정을 피하고 더 다양한 모델로 만들어 줍니다.</p>
<p>AI 분야에서 CNN은 거의 모든 곳에서 사용되어 얼굴을 인식하거나 의료 영상을 통해 질병을 진단하는 등 많은 일에 도움이 되고 있습니다. 시각적 단서를 잡아내는 능력으로 다양한 작업에 매우 유용합니다.</p>
<h1>추가 자료</h1>
<div class="content-ad"></div>
<ul>
<li>LeCun et al., “Gradient-Based Learning Applied to Document Recognition”
Yann LeCun과 동료들이 쓴 이 주요 논문에서는 LeNet-5를 소개하며, 최초의 합성곱 신경망 중 하나로 문서 인식 작업에 적용된 결과를 보여줍니다.
Research Gate 링크</li>
<li>Simonyan과 Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition” (VGGNet)
VGGNet을 소개한 이 연구는 CNN 아키텍처에서 깊이의 중요성을 강조하여 이미지 인식 성능을 향상시키는데 있습니다.
arXiv 링크</li>
<li>He et al., “Deep Residual Learning for Image Recognition” (ResNet)
ResNet은 잔차 학습 개념을 도입하여, 사그라들어 버리는 기울기 문제를 해결함으로써 훨씬 더 깊은 네트워크의 학습을 가능케 합니다.
arXiv 링크</li>
</ul>
<p>만약 이 기사를 좋아하셨다면 좋아요를 눌러 주시고, 최신 게시물을 받아보려면 팔로우해주세요. 저의 목표는 인기 있는 모든 알고리즘을 처음부터 다시 만들어 기계 학습을 누구에게나 쉽게 접근할 수 있게 하는 것입니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"컨볼루션 신경망CNN의 수학적 원리 분석","description":"","date":"2024-06-23 18:50","slug":"2024-06-23-TheMathBehindConvolutionalNeuralNetworks","content":"\n\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png)\n\n목차\n\n- 1: 소개\n- 2: CNN 아키텍처 뒤의 수학\n  - 2.1: 합성곱층\n  - 2.2: 스트라이드\n  - 2.3: 패딩\n  - 2.4: 다중 필터 및 깊이\n  - 2.5: 가중치 공유\n  - 2.6: 특성 맵 생성\n  - 2.7: 풀링층\n  - 2.8: 완전 연결층\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 3: CNN 구축을 위한 단계별 안내\n  - 3.1: 환경 설정\n  - 3.2: 데이터 준비\n  - 3.3: CNN 모델 설계\n  - 3.4: 모델 컴파일\n  - 3.5: CNN 훈련\n\n- 4: 모델 성능 향상\n  - 4.1: 데이터 증강\n  - 4.2: 드롭아웃\n  - 4.3: 배치 정규화\n  - 4.4: 전이 학습\n\n- 5: 결론\n\n- 추가 자료\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 1: 소개\n\n합성곱 신경망, 또는 CNN(Convoluntional Neural Networks)라고도 불리는 것은 이미지 처리와 관련된 작업에서 중요한 역할을 합니다. 사진 인식이나 분류와 같이 이미지와 관련된 작업을 할 때 매우 유용합니다. 그들은 사진의 패턴과 세부 사항을 자동으로 감지하는 데 아주 뛰어나기 때문에 많은 이미지를 처리하는 프로젝트에서 선호되는 선택입니다.\n\nCNN의 멋진 점은 이미지 데이터를 단순히 한 덩어리로 뭉치는 것이 아니라 이미지의 레이아웃을 유지한다는 것입니다. 이는 특정 패턴과 해당 위치를 잘 알아차릴 수 있어서 매우 유용합니다. 이 접근 방식은 이미지 처리의 어려운 부분을 훨씬 더 부드럽게 처리할 수 있도록 해줍니다.\n\nCNN의 중요한 부분 중 하나는 합성곱 레이어라는 것입니다. 이 레이어는 이미지 위를 이동하면서 선, 질감, 형태와 같은 다양한 시각적 특징을 발견할 수 있습니다. 이는 사람이 그러한 특징들을 수동으로 찾아야 했던 예전 방식을 능가합니다. 이는 작업 처리를 느리게 하고 처리 과정에서 병목현상을 야기시켰던 것과 대조됩니다. 네트워크가 스스로 이러한 특징을 찾아내도록 함으로써 CNN은 더 정확해지고, 더 단순해지며, 그리고 더 큰 범위의 이미지 관련 작업에 수월하게 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2: CNN 아키텍처 뒤의 수학\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_1.png)\n\n합성곱 신경망(CNNs)의 아키텍처는 인간의 시각 시스템이 이미지를 처리하는 방식을 모방하도록 설계되어 있어 시각 인식 및 분류와 관련된 작업에 특히 강력합니다.\n\nCNN은 여러 유형의 레이어로 구성되어 있으며, 각 레이어는 이미지 인식 과정에서 특정 기능을 제공합니다. 주요 레이어에는 합성곱 레이어, 활성화 함수, 풀링 레이어 및 완전 연결 레이어가 포함됩니다. 이 레이어들이 함께 작동하여 CNN이 특징을 감지하고 복잡성을 줄이며 예측을 수행할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.1: 합성곱층\n\n합성곱층은 합성곱 신경망(CNN)의 중요한 요소로, 이미지로부터 가장자리, 질감, 모양과 같은 공간적인 특징을 자동적으로 효율적으로 추출하는 데 사용됩니다. 우리는 합성곱층이 작동하는 방식 및 내부 수학에 대해 자세히 알아보겠습니다.\n\n합성곱 연산\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성 곱 연산의 본질은 입력 이미지 위를 필터(또는 커널)가 슬라이딩하면서 각 위치에서 필터 값과 원래 픽셀 값의 내적을 계산하는 것입니다. 필터는 일반적으로 3x3 또는 5x5 크기의 작은 가중치 행렬로, 이미지에서 특정 피쳐를 감지하기 위해 훈련됩니다.\n\n수학적으로, 합성 곱 연산은 다음과 같이 표현될 수 있습니다:\n\n![convolution equation](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_3.png)\n\n여기서:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- S(i,j)은 출력 피처 맵입니다.\n- I는 입력 이미지입니다.\n- K는 커널 또는 필터입니다.\n- i,j는 피처 맵 상의 좌표입니다.\n- m,n은 커널 내의 좌표입니다.\n- ∗는 합성곱 연산을 나타냅니다.\n\n이 방정식은 출력 피처 맵의 각 요소 S(i,j)가 커널 K와 현재 위치한 입력 이미지 I의 일부 사이의 요소별 곱의 합임을 알려줍니다.\n\n이제 입력 이미지로 사용될 픽셀 값 행렬을 고려해 봅시다. 그것이 흑백 이미지인 경우 (위 이미지), 행렬은 단일 레이어를 가지게 될 것입니다. 컬러 이미지의 경우에는 일반적으로 세 개의 레이어 (RGB)가 있지만, 연산은 각 레이어마다 별도로 수행됩니다.\n\n합성곱 연산은 행렬에 커널(필터)을 적용합니다. 여기서 커널은 입력 이미지보다 작은 다차원 행렬이며 사전에 정의된 차원 (예: 3x3)을 가지고 있습니다. 이 행렬의 값은 훈련 과정 중에 학습되는 가중치입니다. 커널은 입력 이미지 전체를 걸어다니면서 요소별 곱셈을 수행하고 합을 구합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨볼류션 연산에서는 출력 특성 맵을 얻게 됩니다. 이는 커널이 입력 이미지의 특정 위치에서 감지한 특징의 존재와 강도를 나타내는 새로운 행렬입니다.\n\n## 2.2: 스트라이드\n\n![스트라이드](https://miro.medium.com/v2/resize:fit:1280/1*OlE3bnC0WaYt3wW1dlcMdA.gif)\n\n스트라이드는 CNN 아키텍처에서 중요한 개념입니다. 특히 컨볼루션 레이어 내에서 핵심적으로 작용합니다. 이는 커널이 입력 이미지나 특성 맵을 횡단하는 방식에 근본적인 영향을 미칩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStride는 필터가 입력 이미지나 피쳐 맵을 한 단계씩 이동하는 픽셀 수를 나타냅니다. 수평 및 수직으로 모두 적용됩니다. Stride가 1이면 필터가 한 번에 한 픽셀씩 이동하여 입력을 자세하고 밀도 있게 스캔합니다. 더 큰 Stride는 필터가 픽셀을 건너뛰며 입력을 스캔하므로 더 넓고 밀도가 낮은 범위로 이어집니다.\n\nStride는 출력 피쳐 맵의 차원을 결정하는 데 직접적인 역할을 합니다:\n\n- Stride가 1인 경우: 필터가 모든 픽셀을 횡단하여 출력 피쳐 맵이 패딩에 따라 상대적으로 크거나 입력과 유사한 크기가 될 수 있습니다. 패딩에 대해 다음 섹션에서 설명하겠습니다.\n- 더 큰 Stride인 경우: 필터가 픽셀을 건너뛰면 입력을 적은 단계로 이동합니다. 이로 인해 출력 피쳐 맵이 작아지며 각 단계에서 필터가 적용되는 위치 간의 오버랩이 적어집니다.\n\n수학적 표현\n출력 피쳐 맵의 크기 (W_out, H_out)는 입력 크기 (W_in, H_in), 필터 크기 (F), Stride (S), 패딩 (P)을 사용하여 다음 공식을 사용하여 계산할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_4.png\" /\u003e\n\n여기서:\n\n- W_out 및 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\n- W_in 및 H_in은 각각 입력의 너비와 높이입니다.\n- F는 필터의 크기입니다.\n- S는 스트라이드입니다.\n- P는 패딩입니다.\n\n더 큰 스트라이드는 필터의 각 응용 영역의 시야를 증가시켜 네트워크가 더 적은 매개변수로 입력의 더 많은 전역적인 특성을 포착할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사용하는 스트라이드를 크게 하면 출력 특성 맵의 크기를 줄이기 때문에 계산 부하와 메모리 사용량이 감소하며, 따라서 필요한 합성 곱 연산 수도 줄어듭니다.\n\n공간 해상도와 커버리지 사이에는 교환관계가 있습니다. 작은 스트라이드는 공간 해상도를 보존하고 섬세한 특징을 탐지하는 데 더 좋지만, 큰 스트라이드는 디테일을 희생하면서 입력의 넓은 영역을 다룰 수 있습니다.\n\n## 2.3: 패딩\n\n패딩은 출력 특성 맵의 공간적 차원을 조절하여 네트워크의 아키텍처를 형성하는 데 중요한 역할을 합니다.\n합성 곱 연산을 적용하기 전에 입력 이미지나 특성 맵의 가장자리 주위에 제로(또는 다른 값들이지만 일반적으로 제로입니다)의 레이어를 추가하는 것을 포함합니다. 이 기법은 다양한 이유로 적용될 수 있으며, 가장 중요한 이유는 출력 특성 맵의 크기를 제어하고 합성 곱 필터가 입력의 가장자리 픽셀에 접근할 수 있도록 하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 이제 우리의 입력 이미지는 다음과 같이 보일 것입니다:\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1280/1*VwOf7sD87Yw9P1215NngRQ.gif\" /\u003e\n\n이전의 8x8 행렬이 이제 10x10 행렬로 바뀐 것을 볼 수 있습니다. 우리는 주변에 0으로 된 레이어를 추가했기 때문입니다.\n\n패딩이 없으면 각 합성곱 연산이 피처 맵의 크기를 줄입니다. 패딩을 사용하면 입력에 필터를 적용하여 공간적 차원을 줄이지 않고 더 많은 정보를 보존할 수 있습니다. 특히 많은 합성곱 계층이 순차적으로 적용되는 심층 네트워크에서 더 많은 정보를 보존할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n입력을 패딩함으로써 필터가 이미지의 가장자리 픽셀을 적절하게 처리하여 네트워크의 학습 과정에서 경계에 위치한 특징을 충분히 캡처하고 활용할 수 있습니다.\n\n패딩에는 주로 두 가지 유형이 있습니다:\n\n**Valid Padding (패딩 없음)**\n이 경우 입력에 패딩이 적용되지 않습니다. 필터가 입력의 한계 내에 완전히 맞는 곳에서만 합성곱 작업이 수행됩니다. 이로 인해 일반적으로 출력 피처 맵 크기가 줄어듭니다.\n\n**Same Padding (동일 패딩)**\n동일 패딩의 경우 입력 가장자리에 충분한 수의 제로(0)가 추가되어 출력 피처 맵이 입력과 동일한 차원을 갖도록 합니다(스트라이드가 1인 경우). 이는 입력과 출력 크기가 일관성 있게 유지되어야 하는 네트워크를 설계하는 데 특히 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가장자리에 패딩을 추가하는 것이 출력 특성 맵 크기에 미치는 영향은 출력 특성 맵의 차원을 계산하는 데 사용되는 공식을 조정함으로써 파악할 수 있습니다:\n\n\nW_out = (W_in - F + 2P) / S + 1\nH_out = (H_in - F + 2P) / S + 1\n\n\n여기서:\n\n- W_out과 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\n- W_in과 H_in은 각각 입력의 너비와 높이입니다.\n- F는 필터/커널의 크기입니다.\n- S는 스트라이드입니다.\n- P는 입력의 각 측면에 추가된 패딩의 양입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n패딩은 층을 통해 입력의 공간 차원을 유지하는 데 도움이 됩니다. 그러나 과도한 패딩은 계산의 비효율성을 야기하고 모델의 복잡성이 증가할 수 있습니다. 비의미 있는 입력(제로)을 계산에 추가함으로써 비효율성을 가져올 수 있습니다.\n\n유효 패딩과 동일 패딩 사이의 선택은 주로 응용 프로그램의 특정 요구 사항에 따라 달라지며, 입력의 공간 차원을 보존하는 중요성이나 계산 오버헤드를 최소화해야 하는 필요성에 따라 결정됩니다.\n\n## 2.4: 다중 필터와 깊이\n\nCNN은 각 합성곱 층에서 여러 필터를 사용하여 입력 이미지나 특징 맵에서 다양한 특징을 캡처합니다. 이 다양성과 깊이는 네트워크가 시각 정보를 포괄적이고 세심하게 처리할 수 있는 능력에 중요한 역할을 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n컨볼루션 레이어의 각 필터는 입력에서 엣지, 색상, 질감 또는 더 깊은 레이어에서는 더 복잡한 모양과 같은 다양한 특징이나 패턴을 감지하도록 설계되어 있습니다. 여러 필터를 사용함으로써 CNN은 각 레이어에서 동시에 다양한 특징을 찾아 입력 데이터의 표현을 보다 풍부하게 만들 수 있습니다.\n\n여러 필터를 사용한 컨볼루션 레이어의 출력은 각 필터에 대해 하나의 특징 맵으로 이루어진 스택입니다. 이 스택은 깊이가 사용된 필터의 수와 대응되는 3차원 볼륨을 형성합니다. 이 깊이는 데이터의 계층적인 표현을 구축하는 데 중요하며, 이전 레이어의 출력을 결합하여 점점 추상적인 특징을 감지할 수 있게 합니다.\n\n여러 필터가 깊이를 어떻게 실현하는가\n입력 이미지 또는 특징 맵이 처리됨에 따라 각 필터는 이를 슬라이딩하여 컨볼루션 작업을 수행합니다. 동일한 입력을 공유하더라도 각 필터는 고유한 가중치를 적용하여 서로 다른 측면을 강조하는 서로 다른 특징 맵을 생성합니다.\n\n각 필터가 생성한 개별 특징 맵은 깊이 차원을 따라 쌓이며, 3D 볼륨을 형성합니다. 이 볼륨은 필터에 의해 감지된 다양한 특징을 포용하여 입력의 풍부하고 다면적인 표현을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성곱 레이어의 깊이는 필터의 수에 의해 결정되며, 네트워크가 넓은 특징 스펙트럼을 포착할 수 있게 합니다. 초기 레이어는 가장자리와 질감과 같은 기본적인 특징을 포착할 수 있지만, 더 깊은 레이어는 이러한 기본적인 특징을 결합하여 복잡한 패턴을 해석할 수 있게 되며, 이는 네트워크의 깊이 덕분입니다.\n\n깊이의 영향\n더 많은 필터는 복잡한 특징을 학습할 수 있는 용량이 높은 더 깊은 네트워크를 의미합니다. 그러나 이는 또한 네트워크의 계산 복잡성과 효과적으로 학습하기 위해 필요한 데이터 양을 증가시킵니다.\n\n각 필터는 모델에 매개변수를 추가합니다(필터를 정의하는 가중치). 더 많은 필터는 네트워크의 표현력을 높이지만, 총 매개변수 수를 증가시켜 학습 효율성과 과적합의 위험에 영향을 미칠 수 있습니다.\n\n레이어 간 필터 할당은 전략적입니다. 입력에 가까운 레이어는 더 적고 일반적인 필터를 가질 수 있지만, 더 깊은 레이어는 데이터 내에서 고차원 특징의 복잡성과 변이를 포착하기 위해 더 많은 필터를 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.5: Weight Sharing\n\nWeight sharing(가중치 공유)는 특히 시각적 정보를 처리할 때 CNN의 효율성과 효과를 현저히 향상시킵니다. 이 개념은 모델이 입력 이미지의 공간적 위치와 관계없이 특징을 감지할 수 있도록 핵심적입니다.\n\nCNN의 맥락에서, 가중치 공유란 동일한 필터(즉, 동일한 가중치 세트)를 전체 입력 이미지나 특징 맵에 걸쳐 사용하는 것을 의미합니다. 모든 가능한 위치에 대해 고유한 가중치 세트를 학습하는 대신 단일 필터가 전체 이미지를 스캔하며 각 위치에서 동일한 가중치를 적용합니다. 이 작업은 합성곱 레이어의 각 필터에서 반복됩니다.\n\n입력 이미지의 서로 다른 부분에서 동일한 가중치 세트를 재사용함으로써, 가중치 공유는 모델의 매개변수 수를 급격하게 줄입니다. 이로 인해 CNN은 특히 큰 입력 크기를 다룰 때 완전히 연결된 네트워크에 비해 매개변수 효율성이 훨씬 뛰어납니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWeight sharing은 네트워크가 입력 이미지의 위치에 관계없이 특징을 감지할 수 있도록 합니다. 필터가 에지나 특정 패턴을 인식하는 방법을 학습하면 이미지의 어느 곳에서든 해당 특징을 감지할 수 있으므로 CNN은 기본적으로 변환 불변성을 갖습니다.\n\n학습할 매개변수가 적어지므로, CNN은 학습 데이터에 과적합될 가능성이 적어집니다. 이는 모델이 학습 데이터에서 실제로 관측되는 데이터로 일반화하는 능력을 향상시킴으로써, 실제 과제에서의 성능을 향상시킵니다.\n\nWeight Sharing 작동 방식\n순방향 전파 중에, 고정된 가중치 세트를 가진 필터가 입력 이미지를 슬라이드하며, 필터 가중치와 이미지의 지역 영역 간의 내적을 계산합니다. 이 과정은 이미지의 공간적 범위에 걸쳐 감지된 특징의 존재 및 강도를 나타내는 특징 맵을 생성합니다.\n\n공간적 영역 전체에 걸쳐 가중치를 광범위하게 재사용하지만, 각각의 가중치는 적용된 위치의 모든 위치에서의 총 그래디언트를 기반으로 업데이트됩니다. 이를 통해 필터 가중치가 작업에 가장 관련성 있는 특징을 감지하도록 최적화되어, 전체 데이터셋을 기반으로 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.6: 피처 맵 생성\n\n이전에 보았던 대로, 피처 맵은 CNN 내에서 입력 이미지나 이전 피처 맵에 필터나 커널을 적용하여 생성된 출력입니다. 입력의 공간 차원에 걸쳐 필터의 반응을 나타내며, 이미지에서 특정 피처가 어디에 어떻게 감지되었는지를 강조합니다. 이제 각 요소가 어떻게 CNN의 결과 피처 맵에 영향을 미치는지 다시 살펴봅시다.\n\n피처 맵 생성의 핵심은 컨볼루션 연산에 있습니다. 여기서 학습된 가중치를 가진 필터가 입력 이미지나 이전 레이어의 피처 맵을 이전하며 슬라이딩(또는 합성)합니다. 각 위치에서 필터는 이미지의 해당 부분과 요소별 곱셈을 수행하고 결과를 합산하여 새로운 피처 맵의 단일 출력 픽셀을 생성합니다.\n\n필터의 가중치는 엣지, 질감 또는 더 깊은 레이어에서 더 복잡한 패턴과 같은 피처 유형을 감지합니다. 훈련 중에 이 가중치는 역전파를 통해 조정되어 네트워크가 주어진 작업에 가장 중요한 피처를 학습할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n스트라이드의 크기와 패딩의 사용은 특징 맵의 공간적 차원에 직접적인 영향을 미칩니다. 더 큰 스트라이드는 필터 적용 사이의 중첩을 줄이는 보다 넓은 범위의 적용을 유도하여 특징 맵의 크기를 줄입니다. 패딩은 입력의 공간적 차원을 보존하기 위해 사용되며 이미지의 가장자리에 있는 특징이 손실되지 않도록 보장합니다.\n\n합성곱 레이어는 일반적으로 여러 필터를 포함하며, 각각은 다른 특징을 감지하도록 설계됩니다. 각 필터의 출력은 별도의 특징 맵이며, 이러한 특징 맵은 깊이 차원을 따라 쌓여 3차원 볼륨을 만듭니다. 이 다각적인 방식은 네트워크가 입력 이미지의 풍부한 표현을 포착할 수 있도록 합니다.\n\n합성곱 작업을 통해 특징 맵이 생성된 후에는 주로 ReLU와 같은 활성화 함수를 통과합니다. 이는 비선형성을 도입하여 네트워크가 보다 복잡한 패턴을 학습하고 표현할 수 있게 합니다.\n\nReLU와 다른 활성화 함수에 대해 더 알고 싶다면, 이 기사를 확인해보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n활성화된 피처 맵은 다음 계층 또는 풀링 작업으로 진행됩니다.\n\n## 2.7: 풀링 레이어\n\n풀링 레이어는 피처 맵의 공간 차원을 줄이는 역할을 합니다. 이 감소는 계산 부하를 줄이고, 오버피팅을 최소화하며, 가장 중요한 정보만을 보존하는 데 중요합니다. 풀링 레이어의 구체적인 내용, 유형 및 CNN 성능에 미치는 영향에 대해 알아봅시다.\n\n풀링 레이어는 피처 맵의 크기를 줄여 망에 필요한 매개변수 및 계산을 줄입니다. 이 간소화는 가장 중요한 특성에 집중하는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n특징 맵의 패치에서 특징의 존재를 요약함으로써, 풀링은 네트워크가 입력 이미지의 작은 변동 및 변환에 강건함을 유지하는 데 도움이 됩니다.\n\nCNN을 다룰 때 알아야 할 몇 가지 종류의 풀링 기술이 있습니다:\n\n최대 풀링\n이것은 가장 일반적인 풀링 형태로, 특징 맵의 값 집합에서 최대값이 선택되어 다음 레이어로 전달됩니다. 최대 풀링은 특징 맵의 각 패치에서 가장 현저한 특징을 효과적으로 포착합니다.\n\n우리는 특징 맵을 F로, 풀링 작업을 P_max로 표시하며, 크기가 n×n인 창으로 위치 (i,j)에서의 최대 풀링 결과는 다음과 같이 표현될 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_6.png)\n\n여기서 s는 풀링 윈도우의 보폭이며, a, b는 윈도우 차원을 반복합니다. 이 작업은 특성 맵을 가로지르는 각 윈도우 위치에 독립적으로 적용됩니다.\n\n평균 풀링\n최대 풀링과 달리 평균 풀링은 특성 맵의 각 패치에서 값의 평균을 취합니다. 이 방법은 보다 일반화된 특성 표현을 제공하지만, 더 작지만 의미 있는 특성의 영향을 약화시킬 수 있습니다.\n\n특성 맵 F와 n×n 풀링 윈도우에 대해 위치 (i,j)에서의 평균 풀링 연산은 수학적으로 다음과 같이 표현될 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_7.png)\n\n맥스 풀링과 유사하게, s는 스트라이드를 나타내며, a,b는 창을 순회하는 반면, 이 연산에서는 각 창 내 값들의 평균을 계산합니다.\n\n글로벌 풀링\n글로벌 풀링에서는 전체 피처 맵이 각각 맥스(글로벌 맥스 풀링) 또는 평균(글로벌 평균 풀링)을 취함으로써 하나의 값으로 축소됩니다. 이 접근 방식은 종종 각 피처 맵을 완전 연결 레이어 이전에 하나의 값으로 줄이는 데 사용됩니다.\n\n크기가 M×N인 피처 맵 F에 대해, 글로벌 맥스 풀링 (P_gmax) 및 글로벌 평균 풀링 (P_gavg)은 다음과 같이 정의될 수 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Global pooling operations](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_8.png)\n\n전역 풀링 연산은 전체 피쳐 맵을 하나의 요약 통계치로 압축하는데 사용되며, 이는 분류를 위한 완전 연결 레이어 이전에 모델 파라미터를 줄이는 데 특히 유용합니다.\n\n풀링 동작 방식\n풀링 레이어는 각 피쳐 맵에 독립적으로 작동하며, 피쳐 맵을 가로지르면서 창(또는 필터)을 슬라이딩하고 해당 창 내의 값을 요약하여 한 가지 값으로 줄입니다 (사용된 풀링 전략에 따라). 이 과정은 피쳐 맵의 공간 차원을 줄입니다.\n\n창의 크기와 스트라이드(창이 한 번에 이동하는 거리)는 피쳐 맵이 얼마나 줄어드는지를 결정합니다. 흔히 선택하는 것은 2x2 창과 스트라이드 2인 경우인데, 이는 피쳐 맵의 크기를 절반으로 줄입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.8: 완전 연결층\n\n![image](/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_9.png)\n\n완전 연결층은 CNN의 끝쪽에 자주 위치합니다. 이 층들은 학습된 특징에 기반한 고수준 추론이 이루어지는 곳으로, 궁극적으로는 분류나 예측으로 이어집니다.\n\n완전 연결층에서는 각 뉴런이 이전 층의 모든 활성화에 연결됩니다. 이 밀집된 연결은 층이 추출된 특징들의 전체 맥락을 갖게 해주어, 특징 맵 전체에 분산된 복잡한 패턴을 학습할 수 있게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n완전 연결 계층은 합성곱 및 풀링 계층에서 식별된 공간적으로 분산된 특징을 전체 입력의 전역 표현으로 통합합니다. 이 통합은 분류와 같은 전체 입력을 이해해야 하는 작업에 중요합니다.\n\n합성곱에서 완전 연결 계층으로\n완전 연결 계층에 진입하기 전에, 이전 합성곱이나 풀링 계층의 출력(일반적으로 다차원 특징 맵)이 하나의 벡터로 평평하게 변환됩니다. 이 단계는 공간 구조화된 데이터를 완전 연결 계층에서 처리할 수 있도록 포맷을 변환합니다.\n\n완전 연결 계층의 뉴런들은 평평한 특징 맵에 의해 제시된 전역 정보를 고려함으로써 데이터에서 고수준 패턴을 학습할 수 있습니다. 이 능력은 전체 입력 이미지를 기반으로 한 예측이나 분류를 만드는 데 기본적입니다.\n\nCNN에서의 역할\n많은 CNN 아키텍처에서 최종 완전 연결 계층은 분류 계층으로 기능하며, 각 뉴런은 특정 클래스를 나타냅니다. 네트워크의 예측은 일반적으로 이러한 뉴런들의 활성화에 의해 결정되며, 활성화를 확률로 변환하는 소프트맥스 함수를 통해 수행됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성곱 레이어에 의해 추출된 지역화된 추상적인 특징을 완전 연결 레이어가 입력 데이터의 일관된 이해로 합성합니다. 이러한 합성은 네트워크가 입력에 대해 전체적으로 추론하고 판단을 내릴 수 있도록 중요합니다.\n\n# 3: CNN 구축 단계별 안내서\n\n이제 비즈니스 쪽으로 가지고 CNN을 구축해 봅시다. MNIST 데이터셋에서 손으로 쓴 숫자의 이미지 분류를 위해 PyTorch를 사용하여 합성곱 신경망(CNN)을 설정하고 훈련 및 평가할 것입니다. [MNIST 데이터셋은 Creative Commons Attribution-Share Alike 3.0 라이선스 조건 하에 제공됩니다]\n\n오늘 다룰 모든 코드가 포함된 Jupyter Notebook을 참고하시기 바랍니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.1: 환경 설정하기\n\n필요한 라이브러리와 모듈을 준비해봅시다. 신경망을 구축하고 훈련하기 위해 PyTorch (torch)와 이를 위한 신경망 모듈 (nn), 최적화 모듈 (optim)이 불러와집니다. torch.nn.functional에서 ReLU 활성화 및 최대 풀링과 같은 작업에 사용되는 기능이 제공됩니다. DataLoader 유틸리티를 통해 배치 처리와 데이터 관리를 용이하게 할 수 있고, torchvision은 데이터셋 및 이미지 변환을 위해 사용됩니다.\n\n```python\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n``` \n\n## 3.2: 데이터 준비하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMNIST 데이터셋은 이미지를 텐서 형식으로 변환한 후 픽셀 값을 정규화하는 변환 파이프라인으로 로드됩니다. 정규화 매개변수(평균=0.1307, 표준편차=0.3081)는 MNIST 데이터셋에 특별히 선택되어 그레이스케일 이미지를 표준화하여 신경망의 성능을 최적화합니다.\n\n```js\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\nmnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n```\n\n데이터셋에서의 샘플 이미지를 matplotlib을 사용하여 표시하여, 네트워크가 훈련될 데이터 유형을 시각적으로 보여줍니다.\n\n```js\nimage, label = mnist_dataset[0]\nplt.imshow(image.squeeze().numpy(), cmap='gray')\nplt.title(f'Label: {label}')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 이미지가 표시됩니다:\n\n\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_10.png\" /\u003e\n\n데이터셋은 모델 훈련 중에 효율적인 처리를 위해 배치 처리, 셔플링, 데이터셋 준비를 다루는 DataLoader 인스턴스에 의해 훈련 및 검증 세트로 나누어집니다.\n\n```js\ntrain_size = int(0.8 * len(mnist_dataset))\nval_size = len(mnist_dataset) - train_size\ntrain_dataset, val_dataset = random_split(mnist_dataset, [train_size, val_size])\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 3.3: CNN 모델 설계\n\n데이터 전처리를 한 후에 모델을 만들어 보겠습니다. 따라서 nn.Module에서 상속된 MyCNN 클래스를 초기화합니다. 이 상속은 PyTorch에서 모델을 정의하는 방법입니다. 이 상속을 통해 MyCNN은 PyTorch 모델의 모든 기능을 갖추게 되며, 훈련, 예측 등이 가능해집니다.\n\n__init__ 함수는 MyCNN 클래스의 생성자입니다. 이 함수에서 신경망의 층들이 정의됩니다. super(MyCNN, self).__init__() 라인은 기본 nn.Module 클래스의 생성자를 호출하는데, 이는 PyTorch가 모든 것을 올바르게 초기화하기 위해 필요합니다.\n\n```python\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.fc1 = nn.Linear(7*7*64, 128)\n        self.fc2 = nn.Linear(128, 10)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 코드에서 볼 수 있듯이, 이 네트워크에는 conv1과 conv2 두 개의 합성곱 레이어가 포함되어 있습니다.\n\nconv1은 단일 채널 이미지(회색조 이미지와 같은)를 입력으로 받아 3x3 필터(또는 커널) 크기와 1의 스트라이드, 1의 패딩을 사용하여 32개의 특성 맵을 생성합니다. 패딩은 출력 특성 맵이 입력과 동일한 크기로 유지되도록 추가됩니다.\n\nconv2는 conv1에서 32개의 특성 맵을 입력으로 받아 3x3 커널, 1의 스트라이드, 1의 패딩을 사용하여 64개의 특성 맵을 생성합니다. 이 레이어는 conv1에서 제공된 입력으로부터 특성을 더 추출합니다.\n\n합성곱 레이어 이후에는 두 개의 완전 연결(fc) 레이어가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nfc1은 합성곱 레이어의 출력을 크기 128의 벡터로 변환하는 첫 번째 완전 연결 레이어입니다. 입력 크기는 7*7*64이며, 이는 이 레이어에 도달하기 전에 특성 맵이 단일 벡터로 펼쳐지며, 평탄화되기 전의 특성 맵의 차원이 7x7이고 64개 채널임을 의미합니다. 이 단계는 공간 특성 추출에서 해당 특성을 기반으로 결정(분류)을 내리는 것으로 전환하는 데 중요합니다.\n\nfc2는 두 번째 완전 연결 레이어로, fc1에서 가져온 128차원 벡터를 가져와 10차원 벡터를 출력합니다. 이 출력 크기는 일반적으로 분류 문제의 클래스 수에 해당하며, 이 네트워크가 이미지를 10가지 범주 중 하나로 분류하는 방식으로 설계되었음을 시사합니다.\n\n```js\ndef _initialize_weights(self):\n    for m in self.modules():\n        if isinstance(m, nn.Conv2d):\n            nn.init.normal_(m.weight, 0, 0.01)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.Linear):\n            nn.init.xavier_uniform_(m.weight)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n```\n\n가중치 초기화는 네트워크가 경사도를 사라지게 하거나 폭발시키지 않는 범위의 가중치로 시작하도록 보장하기 위해 적용됩니다. 합성곱 레이어는 정규 분포로 초기화되고, 완전 연결 레이어는 Xavier 균일 분포 초기화를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제 이전 글에서 자비에 초기화 및 다른 유형의 초기화에 대해 더 알아보고 싶다면 확인해보세요:\n\nMyCNN 클래스의 forward 메서드는 입력 데이터가 CNN을 통과하면서 겪는 작업 순서를 정의합니다.\n\n```js\ndef forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = F.max_pool2d(x, 2, 2)\n    x = F.relu(self.conv2(x))\n    x = F.max_pool2d(x, 2, 2)\n    x = x.view(x.size(0), -1)\n    x = F.relu(self.fc1(x))\n    x = self.fc2(x)\n    return x\n```\n\n이 메서드를 단계별로 살펴보며, 각 작업에 중점을 두고 입력 이미지가 출력 예측으로 어떻게 변환되는지 이해해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 합성곱 레이어\n\n```js\nx = F.relu(self.conv1(x))\n```\n\n이 합성곱 레이어 (conv1)를 통과하는 입력 텐서 x은 이미지의 일괄 처리를 나타냅니다. 이 레이어는 입력에 학습된 필터를 적용하여 가장자리와 질감 같은 기본 시각적 특징을 캡처합니다. 합성곱 연산 다음에 바로 인플레이스로 ReLU 활성화 함수가 적용됩니다. ReLU는 출력 텐서의 모든 음의 값을 제로로 설정하여 네트워크가 특징을 구별하는 능력을 향상시킵니다.\n\n첫 번째 풀링 연산\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nx = F.max_pool2d(x, 2, 2)\n```\n\n첫 번째 합성곱 및 활성화를 거친 후 최대 풀링 작업이 적용됩니다. 이 작업은 풀 크기와 스트라이드로 인해 피쳐 맵의 공간 차원을 절반으로 줄입니다. 이는 피쳐 맵의 2x2 패치 내에서 가장 중요한 피쳐를 요약하는 역할을 합니다. 최대 풀링은 표현을 작은 이동 및 왜곡에 대해 다소 불변하게 만들어줍니다.\n\n두 번째 합성곱 층\n\n```js\nx = F.relu(self.conv2(x))\n```    \n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 번째 합성곱층(conv2)으로 반복 과정이 진행됩니다. 여기서는 이제 축소된 특징 맵에 새로운 필터 세트를 적용합니다. 이 층은 일반적으로 첫 번째 층에서 식별된 기본 패턴을 기반으로 한 더 복잡한 특징을 포착합니다. 다시 한 번 ReLU 활성화가 이어져 비선형성을 유지합니다.\n\n두 번째 풀링 작업\n\n```js\nx = F.max_pool2d(x, 2, 2)\n```\n\n다른 최대 풀링 단계를 통해 결과 특징 맵의 공간적 차원이 더욱 줄어들어 특징 표현을 간결화하고 후속 층의 계산 복잡성을 줄입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n펼치기\n\n```js\nx = x.view(x.size(0), -1)\n```\n\n전체 연결 계층으로 넘어가기 전에 다차원 특징 맵을 배치 내 각 이미지에 대해 단일 벡터로 펼쳐야 합니다. 이 작업은 텐서를 다시 구성하여 각 이미지의 특징 맵이 텐서의 단일 행이 되도록 만들며, 완전 연결 처리에 적합한 형식으로 모든 특징 정보를 보존합니다.\n\n첫 번째 완전 연결 계층\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nx = F.relu(self.fc1(x))\n```\n\n평탄화된 텐서는 첫 번째 완전 연결 계층(fc1)을 통과하여 전체 특징 집합에서 복잡한 패턴을 학습할 수 있습니다. ReLU 함수가 한 번 더 적용되어 비선형성을 도입하고, 네트워크가 더 복잡한 함수를 학습하고 표현할 수 있도록 합니다.\n\n두 번째 완전 연결 계층 (출력 계층)\n\n```js\nx = self.fc2(x)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마침내, 텐서는 출력 레이어 역할을 하는 두 번째 완전 연결 레이어(FC2)를 통과합니다. 이 레이어에는 예측할 클래스 수와 동일한 수의 뉴런이 있습니다(MNIST 숫자의 경우 10개). 이 레이어의 출력은 네트워크가 각 클래스에 대해 예측한 값을 나타냅니다.\n\n## 3.4: 모델 컴파일\n\n모델은 CrossEntropyLoss로 분류되어 있고 Adam 옵티마이저를 사용하여 가중치를 조정하며, 학습률 및 가중치 감소와 같은 특정 매개변수도 함께 사용하여 컴파일됩니다.\n\n```js\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5, amsgrad=True, eps=1e-8, betas=(0.9, 0.999))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAdam 옵티마이저는 딥러닝 모델을 훈련하는 인기 알고리즘으로, AdaGrad와 RMSProp 알고리즘의 최상의 특성을 결합하여 소음이 있는 문제에서 희소한 그래디언트를 효율적으로 처리합니다. 이는 매개변수별로 학습률을 조정하여 광범위한 작업과 모델에 매우 효과적이고 적합합니다. Adam에 대해 더 자세히 알고 싶다면, 수학적인 내용을 검토하고 처음부터 구축한 내 기사를 살펴보세요:\n\n## 3.5: CNN 훈련\n\n제공된 로직의 Trainer 클래스는 CNN 모델을 훈련하는 데 필요한 필수 기능을 포함하고 있습니다. 이는 순방향 패스, 역방향 패스(그래디언트 계산 및 가중치 업데이트), 훈련 및 검증 손실 모니터링, 조기 중단 구현, 학습률 조정, 그리고 모델 성능 평가를 포함합니다. 이 클래스를 분석하여 구조와 기능을 깊이 이해해 봅시다.\n\n\n\n```python\nclass Trainer:\n    def __init__(self, model, criterion, optimizer, device, patience=7):\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.device = device\n        self.early_stopping = EarlyStopping(patience=patience)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', patience=3, verbose=True, factor=0.5, min_lr=1e-6)\n        self.train_losses = []\n        self.val_losses = []\n        self.gradient_norms = []\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n초기화 메서드인 __init__에서 Trainer 클래스는 CNN 모델, 손실 함수(criterion), 옵티마이저와 함께 CPU 또는 GPU에서 학습할 장치와 조기 종료를 위한 인자로 받습니다. EarlyStopping 인스턴스는 검증 손실을 모니터링하고 모델이 더 이상 개선되지 않을 경우 훈련을 중지하여 과적합을 방지합니다. 학습률 스케줄러(ReduceLROnPlateau)도 초기화되어 검증 손실을 기반으로 학습률을 동적으로 조정하여 훈련 중에 최적의 학습률을 찾도록 도와줍니다. 분석 및 디버깅 목적으로 학습 및 검증 손실 및 그레이디언트 노름을 추적하기 위한 리스트가 초기화됩니다.\n\n```js\ndef train(self, train_loader, val_loader, epochs):\n    for epoch in range(epochs):\n        self.model.train()\n        for images, labels in train_loader:\n            images, labels = images.to(self.device), labels.to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(images)\n            loss = self.criterion(outputs, labels)\n            self.train_losses.append(loss.item())\n            loss.backward()\n            self.optimizer.step()\n```\n\ntrain 메서드는 지정된 에폭 수에 대한 학습 프로세스를 조율합니다. 각 에폭마다 모델을 훈련 모드로 설정하고 train_loader를 사용하여 학습 데이터셋을 반복합니다. 입력 이미지와 레이블을 지정된 장치로 이동시킵니다. 옵티마이저의 그라디언트는 이전 반복에서의 누적을 방지하기 위해 각 순방향 패스 전에 0으로 초기화됩니다. 모델의 예측을 얻고, 지정된 criterion을 사용하여 손실을 계산합니다. 손실 값은 추적을 위해 train_losses 리스트에 추가됩니다. loss.backward()를 호출하여 역전파를 수행하고, 옵티마이저는 optimizer.step()로 모델 가중치를 업데이트합니다.\n\n```js\nval_loss = self.evaluate(val_loader)\nself.val_losses.append(val_loss)\nself.scheduler.step(val_loss)\nself.early_stopping(val_loss)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n훈련 데이터를 처리한 후 모델은 평가 메서드를 사용하여 검증 데이터셋에서 평가되며, 평균 검증 손실을 계산합니다. 이 손실은 학습률을 조정하고 조기 종료 조건이 충족되었는지 확인하는 데 사용됩니다. 검증 손실은 분석을 위해 추적됩니다.\n\n```js\nif self.early_stopping.early_stop:\n    print(\"조기 종료\")\n    break\n```\n\n조기 종료가 발생하면, 과적합을 방지하기 위해 훈련이 중지됩니다. 이 결정은 인내 매개변수로 정의된 여러 epoch 동안 검증 손실이 향상되지 않았는지에 따라 기반으로 합니다.\n\n```js\ndef evaluate(self, test_loader):\n    self.model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(self.device), labels.to(self.device)\n            outputs = self.model(images)\n            loss = self.criterion(outputs, labels)\n            total_loss += loss.item()\n    return total_loss / len(test_loader)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nevaluate 메서드는 모델의 가중치를 업데이트하지 않고 유효성 검사 또는 테스트 데이터셋에서 평균 손실을 계산합니다. 이 메서드는 모델을 평가 모드로 설정하고 효율성을 위해 그래디언트 계산을 비활성화합니다.\n\n# 4: 모델 성능 향상\n\n합성곱 신경망(CNN)의 성능을 개선하고 과적합을 방지하는 것은 딥러닝 모델을 교육하는 중요한 도전 과제입니다. 제공된 코드 스니펫은 데이터 증가, 드롭아웃, 배치 정규화와 같은 기술에 대해 명시적으로 설명하지 않으며 전이 학습에 대해서도 다루지 않습니다. 그러나 이러한 전략들은 CNN을 향상시키는 데 중요하므로 이들이 훈련 과정에 통합되고 모델 성능에 미치는 잠재적인 영향에 대해 알아봅시다.\n\n## 4.1: 데이터 증가\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 증가는 기존 이미지에 임의의 변환(회전, 뒤집기, 크기 조정 등)을 적용하여 학습 데이터셋의 다양성을 인위적으로 증가시킵니다. 이 다양성은 모델이 더 많은 입력 변화 범위에서 학습함으로써 새로운 데이터에 대해 더 잘 일반화되도록 돕습니다.\n\nPyTorch에서 데이터 증가를 구현하려면 데이터셋을 준비할 때 사용되는 transforms.Compose를 확장할 수 있습니다:\n\n```js\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n```\n\n랜덤 뒤집기와 회전을 추가함으로써 훈련 데이터를 다양하게 만들어 모델이 더 견고한 특징을 학습하도록 돕습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4.2: Dropout\n\n드롭아웃은 학습 중에 입력 뉴런의 일부를 무작위로 0으로 설정하여 과도한 공동 적응을 방지하는 정칙화 기술입니다. 이 무작위성은 네트워크가 다른 뉴런의 무작위 하위 집합과 함께 유용한 보다 견고한 기능을 학습하도록 강제합니다.\n\n파이토치에서 CNN 모델에 드롭아웃을 추가하려면 nn.Dropout 레이어를 포함시킵니다:\n\n```js\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        # 합성곱 레이어\n        self.fc1 = nn.Linear(7*7*64, 128)\n        self.dropout = nn.Dropout(0.5)\n        self.fc2 = nn.Linear(128, 10)\n    def forward(self, x):\n        # 합성곱 및 풀링 작업\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막 완전 연결 레이어 앞에 드롭아웃 레이어를 추가하면 모델이 학습된 표현을 여러 뉴런에 분배하도록 유도하여 오버피팅을 완화하는 데 도움이 됩니다.\n\n## 4.3: 배치 정규화\n\n배치 정규화는 각 미니 배치에 대해 레이어의 입력을 표준화하여 학습 프로세스를 안정화시키고 딥 네트워크를 훈련하는 데 필요한 훈련 에포크 수를 크게 줄입니다.\n\n모델에 배치 정규화를 포함하는 방법은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nclass MyCNN(nn.Module):\n    def __init__(self):\n        super(MyCNN, self).__init__()\n        # Covolutional layers\n        self.conv1_bn = nn.BatchNorm2d(32)\n        # Fully connected layers\n        \n    def forward(self, x):\n        x = F.relu(self.conv1_bn(self.conv1(x)))\n        # Continue through model\n```\n\n컨볼루션 레이어 다음에 배치 정규화를 적용한 후 활성화 함수를 사용하는 것은 출력을 정규화하여 수렴 속도를 높이고 전반적인 성능을 향상시켜줍니다.\n\n## 4.4: 전이 학습\n\n전이 학습은 한 작업에서 훈련된 모델을 다른 관련 작업에서 훈련을 위한 출발점으로 사용하는 기술을 말합니다. 새 작업에 제한된 데이터셋이 있는 경우 특히 유용합니다. PyTorch는 ImageNet과 같은 대규모 데이터셋에서 사전 훈련된 모델을 쉽게 로드하고 조정할 수 있도록 지원하여 전이 학습을 용이하게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프리 트레인 모델을 활용하는 방법은 아주 쉬워요!\n\n```python\nfrom torchvision import models\n\nmodel = models.resnet18(pretrained=True)\n# 마지막 완전 연결 레이어 교체하기\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 10)  # 새로운 작업을 위해 10개의 클래스로 가정\n# 마지막 완전 연결 레이어를 제외한 모든 레이어 동결하기\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.fc.requires_grad = True\n```\n\n요기서, 사전 훈련된 ResNet-18 모델을 사용해서, 10개의 클래스를 위한 새 작업에 맞게 마지막 레이어를 대체했어요. 마지막 레이어를 제외한 모든 레이어의 가중치를 동결하면, 분류기 레이어만을 미세 조정해 원본 데이터셋에서 학습한 기능 추출 능력을 활용할 수 있어요.\n\nCNN 훈련 과정에 이러한 전략을 통합시키면, 오버피팅이 줄어들 뿐만 아니라 견고한 특징 학습을 보장하고 사전 훈련된 모델로부터 지식을 활용하여 모델 성능을 향상시킬 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 5: 결론\n\n합성곱 신경망에 대해 심층적으로 파헤쳐 보았습니다. 데이터 설정 및 준비부터 CNN 구조와 계층 분해까지 많은 내용을 다루었습니다. 이러한 모델의 작동 원리를 살펴봤습니다. 가중치 초기화와 데이터 증강, 전이 학습과 같은 기술을 사용하여 모델의 성능을 심각하게 향상시킬 수 있다는 점을 살펴보았습니다. 이러한 방법들은 모델이 더욱 똑똑하게 만들어주어, 오버피팅과 같은 일반적인 함정을 피하고 더 다양한 모델로 만들어 줍니다.\n\nAI 분야에서 CNN은 거의 모든 곳에서 사용되어 얼굴을 인식하거나 의료 영상을 통해 질병을 진단하는 등 많은 일에 도움이 되고 있습니다. 시각적 단서를 잡아내는 능력으로 다양한 작업에 매우 유용합니다.\n\n# 추가 자료\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- LeCun et al., “Gradient-Based Learning Applied to Document Recognition”\nYann LeCun과 동료들이 쓴 이 주요 논문에서는 LeNet-5를 소개하며, 최초의 합성곱 신경망 중 하나로 문서 인식 작업에 적용된 결과를 보여줍니다.\nResearch Gate 링크\n- Simonyan과 Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition” (VGGNet)\nVGGNet을 소개한 이 연구는 CNN 아키텍처에서 깊이의 중요성을 강조하여 이미지 인식 성능을 향상시키는데 있습니다.\narXiv 링크\n- He et al., “Deep Residual Learning for Image Recognition” (ResNet)\nResNet은 잔차 학습 개념을 도입하여, 사그라들어 버리는 기울기 문제를 해결함으로써 훨씬 더 깊은 네트워크의 학습을 가능케 합니다.\narXiv 링크\n\n만약 이 기사를 좋아하셨다면 좋아요를 눌러 주시고, 최신 게시물을 받아보려면 팔로우해주세요. 저의 목표는 인기 있는 모든 알고리즘을 처음부터 다시 만들어 기계 학습을 누구에게나 쉽게 접근할 수 있게 하는 것입니다.","ogImage":{"url":"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png"},"coverImage":"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png","tag":["Tech"],"readingTime":26},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e목차\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e1: 소개\u003c/li\u003e\n\u003cli\u003e2: CNN 아키텍처 뒤의 수학\n\u003cul\u003e\n\u003cli\u003e2.1: 합성곱층\u003c/li\u003e\n\u003cli\u003e2.2: 스트라이드\u003c/li\u003e\n\u003cli\u003e2.3: 패딩\u003c/li\u003e\n\u003cli\u003e2.4: 다중 필터 및 깊이\u003c/li\u003e\n\u003cli\u003e2.5: 가중치 공유\u003c/li\u003e\n\u003cli\u003e2.6: 특성 맵 생성\u003c/li\u003e\n\u003cli\u003e2.7: 풀링층\u003c/li\u003e\n\u003cli\u003e2.8: 완전 연결층\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e3: CNN 구축을 위한 단계별 안내\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e3.1: 환경 설정\u003c/li\u003e\n\u003cli\u003e3.2: 데이터 준비\u003c/li\u003e\n\u003cli\u003e3.3: CNN 모델 설계\u003c/li\u003e\n\u003cli\u003e3.4: 모델 컴파일\u003c/li\u003e\n\u003cli\u003e3.5: CNN 훈련\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e4: 모델 성능 향상\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e4.1: 데이터 증강\u003c/li\u003e\n\u003cli\u003e4.2: 드롭아웃\u003c/li\u003e\n\u003cli\u003e4.3: 배치 정규화\u003c/li\u003e\n\u003cli\u003e4.4: 전이 학습\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e5: 결론\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e추가 자료\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e1: 소개\u003c/h1\u003e\n\u003cp\u003e합성곱 신경망, 또는 CNN(Convoluntional Neural Networks)라고도 불리는 것은 이미지 처리와 관련된 작업에서 중요한 역할을 합니다. 사진 인식이나 분류와 같이 이미지와 관련된 작업을 할 때 매우 유용합니다. 그들은 사진의 패턴과 세부 사항을 자동으로 감지하는 데 아주 뛰어나기 때문에 많은 이미지를 처리하는 프로젝트에서 선호되는 선택입니다.\u003c/p\u003e\n\u003cp\u003eCNN의 멋진 점은 이미지 데이터를 단순히 한 덩어리로 뭉치는 것이 아니라 이미지의 레이아웃을 유지한다는 것입니다. 이는 특정 패턴과 해당 위치를 잘 알아차릴 수 있어서 매우 유용합니다. 이 접근 방식은 이미지 처리의 어려운 부분을 훨씬 더 부드럽게 처리할 수 있도록 해줍니다.\u003c/p\u003e\n\u003cp\u003eCNN의 중요한 부분 중 하나는 합성곱 레이어라는 것입니다. 이 레이어는 이미지 위를 이동하면서 선, 질감, 형태와 같은 다양한 시각적 특징을 발견할 수 있습니다. 이는 사람이 그러한 특징들을 수동으로 찾아야 했던 예전 방식을 능가합니다. 이는 작업 처리를 느리게 하고 처리 과정에서 병목현상을 야기시켰던 것과 대조됩니다. 네트워크가 스스로 이러한 특징을 찾아내도록 함으로써 CNN은 더 정확해지고, 더 단순해지며, 그리고 더 큰 범위의 이미지 관련 작업에 수월하게 사용할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e2: CNN 아키텍처 뒤의 수학\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e합성곱 신경망(CNNs)의 아키텍처는 인간의 시각 시스템이 이미지를 처리하는 방식을 모방하도록 설계되어 있어 시각 인식 및 분류와 관련된 작업에 특히 강력합니다.\u003c/p\u003e\n\u003cp\u003eCNN은 여러 유형의 레이어로 구성되어 있으며, 각 레이어는 이미지 인식 과정에서 특정 기능을 제공합니다. 주요 레이어에는 합성곱 레이어, 활성화 함수, 풀링 레이어 및 완전 연결 레이어가 포함됩니다. 이 레이어들이 함께 작동하여 CNN이 특징을 감지하고 복잡성을 줄이며 예측을 수행할 수 있게 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e2.1: 합성곱층\u003c/h2\u003e\n\u003cp\u003e합성곱층은 합성곱 신경망(CNN)의 중요한 요소로, 이미지로부터 가장자리, 질감, 모양과 같은 공간적인 특징을 자동적으로 효율적으로 추출하는 데 사용됩니다. 우리는 합성곱층이 작동하는 방식 및 내부 수학에 대해 자세히 알아보겠습니다.\u003c/p\u003e\n\u003cp\u003e합성곱 연산\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_2.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e합성 곱 연산의 본질은 입력 이미지 위를 필터(또는 커널)가 슬라이딩하면서 각 위치에서 필터 값과 원래 픽셀 값의 내적을 계산하는 것입니다. 필터는 일반적으로 3x3 또는 5x5 크기의 작은 가중치 행렬로, 이미지에서 특정 피쳐를 감지하기 위해 훈련됩니다.\u003c/p\u003e\n\u003cp\u003e수학적으로, 합성 곱 연산은 다음과 같이 표현될 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_3.png\" alt=\"convolution equation\"\u003e\u003c/p\u003e\n\u003cp\u003e여기서:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eS(i,j)은 출력 피처 맵입니다.\u003c/li\u003e\n\u003cli\u003eI는 입력 이미지입니다.\u003c/li\u003e\n\u003cli\u003eK는 커널 또는 필터입니다.\u003c/li\u003e\n\u003cli\u003ei,j는 피처 맵 상의 좌표입니다.\u003c/li\u003e\n\u003cli\u003em,n은 커널 내의 좌표입니다.\u003c/li\u003e\n\u003cli\u003e∗는 합성곱 연산을 나타냅니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 방정식은 출력 피처 맵의 각 요소 S(i,j)가 커널 K와 현재 위치한 입력 이미지 I의 일부 사이의 요소별 곱의 합임을 알려줍니다.\u003c/p\u003e\n\u003cp\u003e이제 입력 이미지로 사용될 픽셀 값 행렬을 고려해 봅시다. 그것이 흑백 이미지인 경우 (위 이미지), 행렬은 단일 레이어를 가지게 될 것입니다. 컬러 이미지의 경우에는 일반적으로 세 개의 레이어 (RGB)가 있지만, 연산은 각 레이어마다 별도로 수행됩니다.\u003c/p\u003e\n\u003cp\u003e합성곱 연산은 행렬에 커널(필터)을 적용합니다. 여기서 커널은 입력 이미지보다 작은 다차원 행렬이며 사전에 정의된 차원 (예: 3x3)을 가지고 있습니다. 이 행렬의 값은 훈련 과정 중에 학습되는 가중치입니다. 커널은 입력 이미지 전체를 걸어다니면서 요소별 곱셈을 수행하고 합을 구합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e컨볼류션 연산에서는 출력 특성 맵을 얻게 됩니다. 이는 커널이 입력 이미지의 특정 위치에서 감지한 특징의 존재와 강도를 나타내는 새로운 행렬입니다.\u003c/p\u003e\n\u003ch2\u003e2.2: 스트라이드\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1280/1*OlE3bnC0WaYt3wW1dlcMdA.gif\" alt=\"스트라이드\"\u003e\u003c/p\u003e\n\u003cp\u003e스트라이드는 CNN 아키텍처에서 중요한 개념입니다. 특히 컨볼루션 레이어 내에서 핵심적으로 작용합니다. 이는 커널이 입력 이미지나 특성 맵을 횡단하는 방식에 근본적인 영향을 미칩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eStride는 필터가 입력 이미지나 피쳐 맵을 한 단계씩 이동하는 픽셀 수를 나타냅니다. 수평 및 수직으로 모두 적용됩니다. Stride가 1이면 필터가 한 번에 한 픽셀씩 이동하여 입력을 자세하고 밀도 있게 스캔합니다. 더 큰 Stride는 필터가 픽셀을 건너뛰며 입력을 스캔하므로 더 넓고 밀도가 낮은 범위로 이어집니다.\u003c/p\u003e\n\u003cp\u003eStride는 출력 피쳐 맵의 차원을 결정하는 데 직접적인 역할을 합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eStride가 1인 경우: 필터가 모든 픽셀을 횡단하여 출력 피쳐 맵이 패딩에 따라 상대적으로 크거나 입력과 유사한 크기가 될 수 있습니다. 패딩에 대해 다음 섹션에서 설명하겠습니다.\u003c/li\u003e\n\u003cli\u003e더 큰 Stride인 경우: 필터가 픽셀을 건너뛰면 입력을 적은 단계로 이동합니다. 이로 인해 출력 피쳐 맵이 작아지며 각 단계에서 필터가 적용되는 위치 간의 오버랩이 적어집니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e수학적 표현\n출력 피쳐 맵의 크기 (W_out, H_out)는 입력 크기 (W_in, H_in), 필터 크기 (F), Stride (S), 패딩 (P)을 사용하여 다음 공식을 사용하여 계산할 수 있습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_4.png\"\u003e\n\u003cp\u003e여기서:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eW_out 및 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\u003c/li\u003e\n\u003cli\u003eW_in 및 H_in은 각각 입력의 너비와 높이입니다.\u003c/li\u003e\n\u003cli\u003eF는 필터의 크기입니다.\u003c/li\u003e\n\u003cli\u003eS는 스트라이드입니다.\u003c/li\u003e\n\u003cli\u003eP는 패딩입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e더 큰 스트라이드는 필터의 각 응용 영역의 시야를 증가시켜 네트워크가 더 적은 매개변수로 입력의 더 많은 전역적인 특성을 포착할 수 있게 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e사용하는 스트라이드를 크게 하면 출력 특성 맵의 크기를 줄이기 때문에 계산 부하와 메모리 사용량이 감소하며, 따라서 필요한 합성 곱 연산 수도 줄어듭니다.\u003c/p\u003e\n\u003cp\u003e공간 해상도와 커버리지 사이에는 교환관계가 있습니다. 작은 스트라이드는 공간 해상도를 보존하고 섬세한 특징을 탐지하는 데 더 좋지만, 큰 스트라이드는 디테일을 희생하면서 입력의 넓은 영역을 다룰 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e2.3: 패딩\u003c/h2\u003e\n\u003cp\u003e패딩은 출력 특성 맵의 공간적 차원을 조절하여 네트워크의 아키텍처를 형성하는 데 중요한 역할을 합니다.\n합성 곱 연산을 적용하기 전에 입력 이미지나 특성 맵의 가장자리 주위에 제로(또는 다른 값들이지만 일반적으로 제로입니다)의 레이어를 추가하는 것을 포함합니다. 이 기법은 다양한 이유로 적용될 수 있으며, 가장 중요한 이유는 출력 특성 맵의 크기를 제어하고 합성 곱 필터가 입력의 가장자리 픽셀에 접근할 수 있도록 하는 것입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그래서, 이제 우리의 입력 이미지는 다음과 같이 보일 것입니다:\u003c/p\u003e\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1280/1*VwOf7sD87Yw9P1215NngRQ.gif\"\u003e\n\u003cp\u003e이전의 8x8 행렬이 이제 10x10 행렬로 바뀐 것을 볼 수 있습니다. 우리는 주변에 0으로 된 레이어를 추가했기 때문입니다.\u003c/p\u003e\n\u003cp\u003e패딩이 없으면 각 합성곱 연산이 피처 맵의 크기를 줄입니다. 패딩을 사용하면 입력에 필터를 적용하여 공간적 차원을 줄이지 않고 더 많은 정보를 보존할 수 있습니다. 특히 많은 합성곱 계층이 순차적으로 적용되는 심층 네트워크에서 더 많은 정보를 보존할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e입력을 패딩함으로써 필터가 이미지의 가장자리 픽셀을 적절하게 처리하여 네트워크의 학습 과정에서 경계에 위치한 특징을 충분히 캡처하고 활용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e패딩에는 주로 두 가지 유형이 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eValid Padding (패딩 없음)\u003c/strong\u003e\n이 경우 입력에 패딩이 적용되지 않습니다. 필터가 입력의 한계 내에 완전히 맞는 곳에서만 합성곱 작업이 수행됩니다. 이로 인해 일반적으로 출력 피처 맵 크기가 줄어듭니다.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eSame Padding (동일 패딩)\u003c/strong\u003e\n동일 패딩의 경우 입력 가장자리에 충분한 수의 제로(0)가 추가되어 출력 피처 맵이 입력과 동일한 차원을 갖도록 합니다(스트라이드가 1인 경우). 이는 입력과 출력 크기가 일관성 있게 유지되어야 하는 네트워크를 설계하는 데 특히 유용합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e가장자리에 패딩을 추가하는 것이 출력 특성 맵 크기에 미치는 영향은 출력 특성 맵의 차원을 계산하는 데 사용되는 공식을 조정함으로써 파악할 수 있습니다:\u003c/p\u003e\n\u003cp\u003eW_out = (W_in - F + 2P) / S + 1\nH_out = (H_in - F + 2P) / S + 1\u003c/p\u003e\n\u003cp\u003e여기서:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eW_out과 H_out은 각각 출력 특성 맵의 너비와 높이입니다.\u003c/li\u003e\n\u003cli\u003eW_in과 H_in은 각각 입력의 너비와 높이입니다.\u003c/li\u003e\n\u003cli\u003eF는 필터/커널의 크기입니다.\u003c/li\u003e\n\u003cli\u003eS는 스트라이드입니다.\u003c/li\u003e\n\u003cli\u003eP는 입력의 각 측면에 추가된 패딩의 양입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e패딩은 층을 통해 입력의 공간 차원을 유지하는 데 도움이 됩니다. 그러나 과도한 패딩은 계산의 비효율성을 야기하고 모델의 복잡성이 증가할 수 있습니다. 비의미 있는 입력(제로)을 계산에 추가함으로써 비효율성을 가져올 수 있습니다.\u003c/p\u003e\n\u003cp\u003e유효 패딩과 동일 패딩 사이의 선택은 주로 응용 프로그램의 특정 요구 사항에 따라 달라지며, 입력의 공간 차원을 보존하는 중요성이나 계산 오버헤드를 최소화해야 하는 필요성에 따라 결정됩니다.\u003c/p\u003e\n\u003ch2\u003e2.4: 다중 필터와 깊이\u003c/h2\u003e\n\u003cp\u003eCNN은 각 합성곱 층에서 여러 필터를 사용하여 입력 이미지나 특징 맵에서 다양한 특징을 캡처합니다. 이 다양성과 깊이는 네트워크가 시각 정보를 포괄적이고 세심하게 처리할 수 있는 능력에 중요한 역할을 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e컨볼루션 레이어의 각 필터는 입력에서 엣지, 색상, 질감 또는 더 깊은 레이어에서는 더 복잡한 모양과 같은 다양한 특징이나 패턴을 감지하도록 설계되어 있습니다. 여러 필터를 사용함으로써 CNN은 각 레이어에서 동시에 다양한 특징을 찾아 입력 데이터의 표현을 보다 풍부하게 만들 수 있습니다.\u003c/p\u003e\n\u003cp\u003e여러 필터를 사용한 컨볼루션 레이어의 출력은 각 필터에 대해 하나의 특징 맵으로 이루어진 스택입니다. 이 스택은 깊이가 사용된 필터의 수와 대응되는 3차원 볼륨을 형성합니다. 이 깊이는 데이터의 계층적인 표현을 구축하는 데 중요하며, 이전 레이어의 출력을 결합하여 점점 추상적인 특징을 감지할 수 있게 합니다.\u003c/p\u003e\n\u003cp\u003e여러 필터가 깊이를 어떻게 실현하는가\n입력 이미지 또는 특징 맵이 처리됨에 따라 각 필터는 이를 슬라이딩하여 컨볼루션 작업을 수행합니다. 동일한 입력을 공유하더라도 각 필터는 고유한 가중치를 적용하여 서로 다른 측면을 강조하는 서로 다른 특징 맵을 생성합니다.\u003c/p\u003e\n\u003cp\u003e각 필터가 생성한 개별 특징 맵은 깊이 차원을 따라 쌓이며, 3D 볼륨을 형성합니다. 이 볼륨은 필터에 의해 감지된 다양한 특징을 포용하여 입력의 풍부하고 다면적인 표현을 제공합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e합성곱 레이어의 깊이는 필터의 수에 의해 결정되며, 네트워크가 넓은 특징 스펙트럼을 포착할 수 있게 합니다. 초기 레이어는 가장자리와 질감과 같은 기본적인 특징을 포착할 수 있지만, 더 깊은 레이어는 이러한 기본적인 특징을 결합하여 복잡한 패턴을 해석할 수 있게 되며, 이는 네트워크의 깊이 덕분입니다.\u003c/p\u003e\n\u003cp\u003e깊이의 영향\n더 많은 필터는 복잡한 특징을 학습할 수 있는 용량이 높은 더 깊은 네트워크를 의미합니다. 그러나 이는 또한 네트워크의 계산 복잡성과 효과적으로 학습하기 위해 필요한 데이터 양을 증가시킵니다.\u003c/p\u003e\n\u003cp\u003e각 필터는 모델에 매개변수를 추가합니다(필터를 정의하는 가중치). 더 많은 필터는 네트워크의 표현력을 높이지만, 총 매개변수 수를 증가시켜 학습 효율성과 과적합의 위험에 영향을 미칠 수 있습니다.\u003c/p\u003e\n\u003cp\u003e레이어 간 필터 할당은 전략적입니다. 입력에 가까운 레이어는 더 적고 일반적인 필터를 가질 수 있지만, 더 깊은 레이어는 데이터 내에서 고차원 특징의 복잡성과 변이를 포착하기 위해 더 많은 필터를 사용할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e2.5: Weight Sharing\u003c/h2\u003e\n\u003cp\u003eWeight sharing(가중치 공유)는 특히 시각적 정보를 처리할 때 CNN의 효율성과 효과를 현저히 향상시킵니다. 이 개념은 모델이 입력 이미지의 공간적 위치와 관계없이 특징을 감지할 수 있도록 핵심적입니다.\u003c/p\u003e\n\u003cp\u003eCNN의 맥락에서, 가중치 공유란 동일한 필터(즉, 동일한 가중치 세트)를 전체 입력 이미지나 특징 맵에 걸쳐 사용하는 것을 의미합니다. 모든 가능한 위치에 대해 고유한 가중치 세트를 학습하는 대신 단일 필터가 전체 이미지를 스캔하며 각 위치에서 동일한 가중치를 적용합니다. 이 작업은 합성곱 레이어의 각 필터에서 반복됩니다.\u003c/p\u003e\n\u003cp\u003e입력 이미지의 서로 다른 부분에서 동일한 가중치 세트를 재사용함으로써, 가중치 공유는 모델의 매개변수 수를 급격하게 줄입니다. 이로 인해 CNN은 특히 큰 입력 크기를 다룰 때 완전히 연결된 네트워크에 비해 매개변수 효율성이 훨씬 뛰어납니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eWeight sharing은 네트워크가 입력 이미지의 위치에 관계없이 특징을 감지할 수 있도록 합니다. 필터가 에지나 특정 패턴을 인식하는 방법을 학습하면 이미지의 어느 곳에서든 해당 특징을 감지할 수 있으므로 CNN은 기본적으로 변환 불변성을 갖습니다.\u003c/p\u003e\n\u003cp\u003e학습할 매개변수가 적어지므로, CNN은 학습 데이터에 과적합될 가능성이 적어집니다. 이는 모델이 학습 데이터에서 실제로 관측되는 데이터로 일반화하는 능력을 향상시킴으로써, 실제 과제에서의 성능을 향상시킵니다.\u003c/p\u003e\n\u003cp\u003eWeight Sharing 작동 방식\n순방향 전파 중에, 고정된 가중치 세트를 가진 필터가 입력 이미지를 슬라이드하며, 필터 가중치와 이미지의 지역 영역 간의 내적을 계산합니다. 이 과정은 이미지의 공간적 범위에 걸쳐 감지된 특징의 존재 및 강도를 나타내는 특징 맵을 생성합니다.\u003c/p\u003e\n\u003cp\u003e공간적 영역 전체에 걸쳐 가중치를 광범위하게 재사용하지만, 각각의 가중치는 적용된 위치의 모든 위치에서의 총 그래디언트를 기반으로 업데이트됩니다. 이를 통해 필터 가중치가 작업에 가장 관련성 있는 특징을 감지하도록 최적화되어, 전체 데이터셋을 기반으로 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e2.6: 피처 맵 생성\u003c/h2\u003e\n\u003cp\u003e이전에 보았던 대로, 피처 맵은 CNN 내에서 입력 이미지나 이전 피처 맵에 필터나 커널을 적용하여 생성된 출력입니다. 입력의 공간 차원에 걸쳐 필터의 반응을 나타내며, 이미지에서 특정 피처가 어디에 어떻게 감지되었는지를 강조합니다. 이제 각 요소가 어떻게 CNN의 결과 피처 맵에 영향을 미치는지 다시 살펴봅시다.\u003c/p\u003e\n\u003cp\u003e피처 맵 생성의 핵심은 컨볼루션 연산에 있습니다. 여기서 학습된 가중치를 가진 필터가 입력 이미지나 이전 레이어의 피처 맵을 이전하며 슬라이딩(또는 합성)합니다. 각 위치에서 필터는 이미지의 해당 부분과 요소별 곱셈을 수행하고 결과를 합산하여 새로운 피처 맵의 단일 출력 픽셀을 생성합니다.\u003c/p\u003e\n\u003cp\u003e필터의 가중치는 엣지, 질감 또는 더 깊은 레이어에서 더 복잡한 패턴과 같은 피처 유형을 감지합니다. 훈련 중에 이 가중치는 역전파를 통해 조정되어 네트워크가 주어진 작업에 가장 중요한 피처를 학습할 수 있게 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e스트라이드의 크기와 패딩의 사용은 특징 맵의 공간적 차원에 직접적인 영향을 미칩니다. 더 큰 스트라이드는 필터 적용 사이의 중첩을 줄이는 보다 넓은 범위의 적용을 유도하여 특징 맵의 크기를 줄입니다. 패딩은 입력의 공간적 차원을 보존하기 위해 사용되며 이미지의 가장자리에 있는 특징이 손실되지 않도록 보장합니다.\u003c/p\u003e\n\u003cp\u003e합성곱 레이어는 일반적으로 여러 필터를 포함하며, 각각은 다른 특징을 감지하도록 설계됩니다. 각 필터의 출력은 별도의 특징 맵이며, 이러한 특징 맵은 깊이 차원을 따라 쌓여 3차원 볼륨을 만듭니다. 이 다각적인 방식은 네트워크가 입력 이미지의 풍부한 표현을 포착할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e합성곱 작업을 통해 특징 맵이 생성된 후에는 주로 ReLU와 같은 활성화 함수를 통과합니다. 이는 비선형성을 도입하여 네트워크가 보다 복잡한 패턴을 학습하고 표현할 수 있게 합니다.\u003c/p\u003e\n\u003cp\u003eReLU와 다른 활성화 함수에 대해 더 알고 싶다면, 이 기사를 확인해보세요:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e활성화된 피처 맵은 다음 계층 또는 풀링 작업으로 진행됩니다.\u003c/p\u003e\n\u003ch2\u003e2.7: 풀링 레이어\u003c/h2\u003e\n\u003cp\u003e풀링 레이어는 피처 맵의 공간 차원을 줄이는 역할을 합니다. 이 감소는 계산 부하를 줄이고, 오버피팅을 최소화하며, 가장 중요한 정보만을 보존하는 데 중요합니다. 풀링 레이어의 구체적인 내용, 유형 및 CNN 성능에 미치는 영향에 대해 알아봅시다.\u003c/p\u003e\n\u003cp\u003e풀링 레이어는 피처 맵의 크기를 줄여 망에 필요한 매개변수 및 계산을 줄입니다. 이 간소화는 가장 중요한 특성에 집중하는 데 도움이 됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e특징 맵의 패치에서 특징의 존재를 요약함으로써, 풀링은 네트워크가 입력 이미지의 작은 변동 및 변환에 강건함을 유지하는 데 도움이 됩니다.\u003c/p\u003e\n\u003cp\u003eCNN을 다룰 때 알아야 할 몇 가지 종류의 풀링 기술이 있습니다:\u003c/p\u003e\n\u003cp\u003e최대 풀링\n이것은 가장 일반적인 풀링 형태로, 특징 맵의 값 집합에서 최대값이 선택되어 다음 레이어로 전달됩니다. 최대 풀링은 특징 맵의 각 패치에서 가장 현저한 특징을 효과적으로 포착합니다.\u003c/p\u003e\n\u003cp\u003e우리는 특징 맵을 F로, 풀링 작업을 P_max로 표시하며, 크기가 n×n인 창으로 위치 (i,j)에서의 최대 풀링 결과는 다음과 같이 표현될 수 있습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_6.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e여기서 s는 풀링 윈도우의 보폭이며, a, b는 윈도우 차원을 반복합니다. 이 작업은 특성 맵을 가로지르는 각 윈도우 위치에 독립적으로 적용됩니다.\u003c/p\u003e\n\u003cp\u003e평균 풀링\n최대 풀링과 달리 평균 풀링은 특성 맵의 각 패치에서 값의 평균을 취합니다. 이 방법은 보다 일반화된 특성 표현을 제공하지만, 더 작지만 의미 있는 특성의 영향을 약화시킬 수 있습니다.\u003c/p\u003e\n\u003cp\u003e특성 맵 F와 n×n 풀링 윈도우에 대해 위치 (i,j)에서의 평균 풀링 연산은 수학적으로 다음과 같이 표현될 수 있습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_7.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e맥스 풀링과 유사하게, s는 스트라이드를 나타내며, a,b는 창을 순회하는 반면, 이 연산에서는 각 창 내 값들의 평균을 계산합니다.\u003c/p\u003e\n\u003cp\u003e글로벌 풀링\n글로벌 풀링에서는 전체 피처 맵이 각각 맥스(글로벌 맥스 풀링) 또는 평균(글로벌 평균 풀링)을 취함으로써 하나의 값으로 축소됩니다. 이 접근 방식은 종종 각 피처 맵을 완전 연결 레이어 이전에 하나의 값으로 줄이는 데 사용됩니다.\u003c/p\u003e\n\u003cp\u003e크기가 M×N인 피처 맵 F에 대해, 글로벌 맥스 풀링 (P_gmax) 및 글로벌 평균 풀링 (P_gavg)은 다음과 같이 정의될 수 있습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_8.png\" alt=\"Global pooling operations\"\u003e\u003c/p\u003e\n\u003cp\u003e전역 풀링 연산은 전체 피쳐 맵을 하나의 요약 통계치로 압축하는데 사용되며, 이는 분류를 위한 완전 연결 레이어 이전에 모델 파라미터를 줄이는 데 특히 유용합니다.\u003c/p\u003e\n\u003cp\u003e풀링 동작 방식\n풀링 레이어는 각 피쳐 맵에 독립적으로 작동하며, 피쳐 맵을 가로지르면서 창(또는 필터)을 슬라이딩하고 해당 창 내의 값을 요약하여 한 가지 값으로 줄입니다 (사용된 풀링 전략에 따라). 이 과정은 피쳐 맵의 공간 차원을 줄입니다.\u003c/p\u003e\n\u003cp\u003e창의 크기와 스트라이드(창이 한 번에 이동하는 거리)는 피쳐 맵이 얼마나 줄어드는지를 결정합니다. 흔히 선택하는 것은 2x2 창과 스트라이드 2인 경우인데, 이는 피쳐 맵의 크기를 절반으로 줄입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e2.8: 완전 연결층\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_9.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e완전 연결층은 CNN의 끝쪽에 자주 위치합니다. 이 층들은 학습된 특징에 기반한 고수준 추론이 이루어지는 곳으로, 궁극적으로는 분류나 예측으로 이어집니다.\u003c/p\u003e\n\u003cp\u003e완전 연결층에서는 각 뉴런이 이전 층의 모든 활성화에 연결됩니다. 이 밀집된 연결은 층이 추출된 특징들의 전체 맥락을 갖게 해주어, 특징 맵 전체에 분산된 복잡한 패턴을 학습할 수 있게 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e완전 연결 계층은 합성곱 및 풀링 계층에서 식별된 공간적으로 분산된 특징을 전체 입력의 전역 표현으로 통합합니다. 이 통합은 분류와 같은 전체 입력을 이해해야 하는 작업에 중요합니다.\u003c/p\u003e\n\u003cp\u003e합성곱에서 완전 연결 계층으로\n완전 연결 계층에 진입하기 전에, 이전 합성곱이나 풀링 계층의 출력(일반적으로 다차원 특징 맵)이 하나의 벡터로 평평하게 변환됩니다. 이 단계는 공간 구조화된 데이터를 완전 연결 계층에서 처리할 수 있도록 포맷을 변환합니다.\u003c/p\u003e\n\u003cp\u003e완전 연결 계층의 뉴런들은 평평한 특징 맵에 의해 제시된 전역 정보를 고려함으로써 데이터에서 고수준 패턴을 학습할 수 있습니다. 이 능력은 전체 입력 이미지를 기반으로 한 예측이나 분류를 만드는 데 기본적입니다.\u003c/p\u003e\n\u003cp\u003eCNN에서의 역할\n많은 CNN 아키텍처에서 최종 완전 연결 계층은 분류 계층으로 기능하며, 각 뉴런은 특정 클래스를 나타냅니다. 네트워크의 예측은 일반적으로 이러한 뉴런들의 활성화에 의해 결정되며, 활성화를 확률로 변환하는 소프트맥스 함수를 통해 수행됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e합성곱 레이어에 의해 추출된 지역화된 추상적인 특징을 완전 연결 레이어가 입력 데이터의 일관된 이해로 합성합니다. 이러한 합성은 네트워크가 입력에 대해 전체적으로 추론하고 판단을 내릴 수 있도록 중요합니다.\u003c/p\u003e\n\u003ch1\u003e3: CNN 구축 단계별 안내서\u003c/h1\u003e\n\u003cp\u003e이제 비즈니스 쪽으로 가지고 CNN을 구축해 봅시다. MNIST 데이터셋에서 손으로 쓴 숫자의 이미지 분류를 위해 PyTorch를 사용하여 합성곱 신경망(CNN)을 설정하고 훈련 및 평가할 것입니다. [MNIST 데이터셋은 Creative Commons Attribution-Share Alike 3.0 라이선스 조건 하에 제공됩니다]\u003c/p\u003e\n\u003cp\u003e오늘 다룰 모든 코드가 포함된 Jupyter Notebook을 참고하시기 바랍니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e3.1: 환경 설정하기\u003c/h2\u003e\n\u003cp\u003e필요한 라이브러리와 모듈을 준비해봅시다. 신경망을 구축하고 훈련하기 위해 PyTorch (torch)와 이를 위한 신경망 모듈 (nn), 최적화 모듈 (optim)이 불러와집니다. torch.nn.functional에서 ReLU 활성화 및 최대 풀링과 같은 작업에 사용되는 기능이 제공됩니다. DataLoader 유틸리티를 통해 배치 처리와 데이터 관리를 용이하게 할 수 있고, torchvision은 데이터셋 및 이미지 변환을 위해 사용됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e matplotlib.pyplot \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e plt\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e nn, optim\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.nn \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e functional \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e F\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.utils.data \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e DataLoader\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torchvision \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e datasets, transforms\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003e3.2: 데이터 준비하기\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eMNIST 데이터셋은 이미지를 텐서 형식으로 변환한 후 픽셀 값을 정규화하는 변환 파이프라인으로 로드됩니다. 정규화 매개변수(평균=0.1307, 표준편차=0.3081)는 MNIST 데이터셋에 특별히 선택되어 그레이스케일 이미지를 표준화하여 신경망의 성능을 최적화합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etransform = transforms.\u003cspan class=\"hljs-title class_\"\u003eCompose\u003c/span\u003e([\n    transforms.\u003cspan class=\"hljs-title class_\"\u003eToTensor\u003c/span\u003e(),\n    transforms.\u003cspan class=\"hljs-title class_\"\u003eNormalize\u003c/span\u003e((\u003cspan class=\"hljs-number\"\u003e0.1307\u003c/span\u003e,), (\u003cspan class=\"hljs-number\"\u003e0.3081\u003c/span\u003e,))\n])\nmnist_dataset = datasets.\u003cspan class=\"hljs-title function_\"\u003eMNIST\u003c/span\u003e(root=\u003cspan class=\"hljs-string\"\u003e'./data'\u003c/span\u003e, train=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, download=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, transform=transform)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e데이터셋에서의 샘플 이미지를 matplotlib을 사용하여 표시하여, 네트워크가 훈련될 데이터 유형을 시각적으로 보여줍니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eimage, label = mnist_dataset[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\nplt.\u003cspan class=\"hljs-title function_\"\u003eimshow\u003c/span\u003e(image.\u003cspan class=\"hljs-title function_\"\u003esqueeze\u003c/span\u003e().\u003cspan class=\"hljs-title function_\"\u003enumpy\u003c/span\u003e(), cmap=\u003cspan class=\"hljs-string\"\u003e'gray'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e'Label: {label}'\u003c/span\u003e)\nplt.\u003cspan class=\"hljs-title function_\"\u003eshow\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e다음 이미지가 표시됩니다:\u003c/p\u003e\n\u003cimg src=\"/assets/img/2024-06-23-TheMathBehindConvolutionalNeuralNetworks_10.png\"\u003e\n\u003cp\u003e데이터셋은 모델 훈련 중에 효율적인 처리를 위해 배치 처리, 셔플링, 데이터셋 준비를 다루는 DataLoader 인스턴스에 의해 훈련 및 검증 세트로 나누어집니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etrain_size = \u003cspan class=\"hljs-title function_\"\u003eint\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.8\u003c/span\u003e * \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(mnist_dataset))\nval_size = \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(mnist_dataset) - train_size\ntrain_dataset, val_dataset = \u003cspan class=\"hljs-title function_\"\u003erandom_split\u003c/span\u003e(mnist_dataset, [train_size, val_size])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e3.3: CNN 모델 설계\u003c/h2\u003e\n\u003cp\u003e데이터 전처리를 한 후에 모델을 만들어 보겠습니다. 따라서 nn.Module에서 상속된 MyCNN 클래스를 초기화합니다. 이 상속은 PyTorch에서 모델을 정의하는 방법입니다. 이 상속을 통해 MyCNN은 PyTorch 모델의 모든 기능을 갖추게 되며, 훈련, 예측 등이 가능해집니다.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003einit\u003c/strong\u003e 함수는 MyCNN 클래스의 생성자입니다. 이 함수에서 신경망의 층들이 정의됩니다. super(MyCNN, self).\u003cstrong\u003einit\u003c/strong\u003e() 라인은 기본 nn.Module 클래스의 생성자를 호출하는데, 이는 PyTorch가 모든 것을 올바르게 초기화하기 위해 필요합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eMyCNN\u003c/span\u003e(nn.Module):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e(MyCNN, self).__init__()\n        self.conv1 = nn.Conv2d(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e32\u003c/span\u003e, kernel_size=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, stride=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n        self.conv2 = nn.Conv2d(\u003cspan class=\"hljs-number\"\u003e32\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e, kernel_size=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, stride=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e, padding=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n        self.fc1 = nn.Linear(\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e128\u003c/span\u003e)\n        self.fc2 = nn.Linear(\u003cspan class=\"hljs-number\"\u003e128\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e위의 코드에서 볼 수 있듯이, 이 네트워크에는 conv1과 conv2 두 개의 합성곱 레이어가 포함되어 있습니다.\u003c/p\u003e\n\u003cp\u003econv1은 단일 채널 이미지(회색조 이미지와 같은)를 입력으로 받아 3x3 필터(또는 커널) 크기와 1의 스트라이드, 1의 패딩을 사용하여 32개의 특성 맵을 생성합니다. 패딩은 출력 특성 맵이 입력과 동일한 크기로 유지되도록 추가됩니다.\u003c/p\u003e\n\u003cp\u003econv2는 conv1에서 32개의 특성 맵을 입력으로 받아 3x3 커널, 1의 스트라이드, 1의 패딩을 사용하여 64개의 특성 맵을 생성합니다. 이 레이어는 conv1에서 제공된 입력으로부터 특성을 더 추출합니다.\u003c/p\u003e\n\u003cp\u003e합성곱 레이어 이후에는 두 개의 완전 연결(fc) 레이어가 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003efc1은 합성곱 레이어의 출력을 크기 128의 벡터로 변환하는 첫 번째 완전 연결 레이어입니다. 입력 크기는 7\u003cem\u003e7\u003c/em\u003e64이며, 이는 이 레이어에 도달하기 전에 특성 맵이 단일 벡터로 펼쳐지며, 평탄화되기 전의 특성 맵의 차원이 7x7이고 64개 채널임을 의미합니다. 이 단계는 공간 특성 추출에서 해당 특성을 기반으로 결정(분류)을 내리는 것으로 전환하는 데 중요합니다.\u003c/p\u003e\n\u003cp\u003efc2는 두 번째 완전 연결 레이어로, fc1에서 가져온 128차원 벡터를 가져와 10차원 벡터를 출력합니다. 이 출력 크기는 일반적으로 분류 문제의 클래스 수에 해당하며, 이 네트워크가 이미지를 10가지 범주 중 하나로 분류하는 방식으로 설계되었음을 시사합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef \u003cspan class=\"hljs-title function_\"\u003e_initialize_weights\u003c/span\u003e(self):\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e m \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e self.\u003cspan class=\"hljs-title function_\"\u003emodules\u003c/span\u003e():\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eisinstance\u003c/span\u003e(m, nn.\u003cspan class=\"hljs-property\"\u003eConv2d\u003c/span\u003e):\n            nn.\u003cspan class=\"hljs-property\"\u003einit\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enormal_\u003c/span\u003e(m.\u003cspan class=\"hljs-property\"\u003eweight\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.01\u003c/span\u003e)\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e m.\u003cspan class=\"hljs-property\"\u003ebias\u003c/span\u003e is not \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e:\n                nn.\u003cspan class=\"hljs-property\"\u003einit\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003econstant_\u003c/span\u003e(m.\u003cspan class=\"hljs-property\"\u003ebias\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\n        elif \u003cspan class=\"hljs-title function_\"\u003eisinstance\u003c/span\u003e(m, nn.\u003cspan class=\"hljs-property\"\u003eLinear\u003c/span\u003e):\n            nn.\u003cspan class=\"hljs-property\"\u003einit\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003exavier_uniform_\u003c/span\u003e(m.\u003cspan class=\"hljs-property\"\u003eweight\u003c/span\u003e)\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e m.\u003cspan class=\"hljs-property\"\u003ebias\u003c/span\u003e is not \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e:\n                nn.\u003cspan class=\"hljs-property\"\u003einit\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003econstant_\u003c/span\u003e(m.\u003cspan class=\"hljs-property\"\u003ebias\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e가중치 초기화는 네트워크가 경사도를 사라지게 하거나 폭발시키지 않는 범위의 가중치로 시작하도록 보장하기 위해 적용됩니다. 합성곱 레이어는 정규 분포로 초기화되고, 완전 연결 레이어는 Xavier 균일 분포 초기화를 사용합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e제 이전 글에서 자비에 초기화 및 다른 유형의 초기화에 대해 더 알아보고 싶다면 확인해보세요:\u003c/p\u003e\n\u003cp\u003eMyCNN 클래스의 forward 메서드는 입력 데이터가 CNN을 통과하면서 겪는 작업 순서를 정의합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(self, x):\n    x = F.\u003cspan class=\"hljs-title function_\"\u003erelu\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003econv1\u003c/span\u003e(x))\n    x = F.\u003cspan class=\"hljs-title function_\"\u003emax_pool2d\u003c/span\u003e(x, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\n    x = F.\u003cspan class=\"hljs-title function_\"\u003erelu\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003econv2\u003c/span\u003e(x))\n    x = F.\u003cspan class=\"hljs-title function_\"\u003emax_pool2d\u003c/span\u003e(x, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\n    x = x.\u003cspan class=\"hljs-title function_\"\u003eview\u003c/span\u003e(x.\u003cspan class=\"hljs-title function_\"\u003esize\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e), -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n    x = F.\u003cspan class=\"hljs-title function_\"\u003erelu\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003efc1\u003c/span\u003e(x))\n    x = self.\u003cspan class=\"hljs-title function_\"\u003efc2\u003c/span\u003e(x)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e x\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 메서드를 단계별로 살펴보며, 각 작업에 중점을 두고 입력 이미지가 출력 예측으로 어떻게 변환되는지 이해해봅시다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e첫 번째 합성곱 레이어\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ex = F.\u003cspan class=\"hljs-title function_\"\u003erelu\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003econv1\u003c/span\u003e(x))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 합성곱 레이어 (conv1)를 통과하는 입력 텐서 x은 이미지의 일괄 처리를 나타냅니다. 이 레이어는 입력에 학습된 필터를 적용하여 가장자리와 질감 같은 기본 시각적 특징을 캡처합니다. 합성곱 연산 다음에 바로 인플레이스로 ReLU 활성화 함수가 적용됩니다. ReLU는 출력 텐서의 모든 음의 값을 제로로 설정하여 네트워크가 특징을 구별하는 능력을 향상시킵니다.\u003c/p\u003e\n\u003cp\u003e첫 번째 풀링 연산\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ex = F.\u003cspan class=\"hljs-title function_\"\u003emax_pool2d\u003c/span\u003e(x, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e첫 번째 합성곱 및 활성화를 거친 후 최대 풀링 작업이 적용됩니다. 이 작업은 풀 크기와 스트라이드로 인해 피쳐 맵의 공간 차원을 절반으로 줄입니다. 이는 피쳐 맵의 2x2 패치 내에서 가장 중요한 피쳐를 요약하는 역할을 합니다. 최대 풀링은 표현을 작은 이동 및 왜곡에 대해 다소 불변하게 만들어줍니다.\u003c/p\u003e\n\u003cp\u003e두 번째 합성곱 층\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ex = F.\u003cspan class=\"hljs-title function_\"\u003erelu\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003econv2\u003c/span\u003e(x))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e두 번째 합성곱층(conv2)으로 반복 과정이 진행됩니다. 여기서는 이제 축소된 특징 맵에 새로운 필터 세트를 적용합니다. 이 층은 일반적으로 첫 번째 층에서 식별된 기본 패턴을 기반으로 한 더 복잡한 특징을 포착합니다. 다시 한 번 ReLU 활성화가 이어져 비선형성을 유지합니다.\u003c/p\u003e\n\u003cp\u003e두 번째 풀링 작업\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ex = F.\u003cspan class=\"hljs-title function_\"\u003emax_pool2d\u003c/span\u003e(x, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e다른 최대 풀링 단계를 통해 결과 특징 맵의 공간적 차원이 더욱 줄어들어 특징 표현을 간결화하고 후속 층의 계산 복잡성을 줄입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e펼치기\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ex = x.\u003cspan class=\"hljs-title function_\"\u003eview\u003c/span\u003e(x.\u003cspan class=\"hljs-title function_\"\u003esize\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e), -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e전체 연결 계층으로 넘어가기 전에 다차원 특징 맵을 배치 내 각 이미지에 대해 단일 벡터로 펼쳐야 합니다. 이 작업은 텐서를 다시 구성하여 각 이미지의 특징 맵이 텐서의 단일 행이 되도록 만들며, 완전 연결 처리에 적합한 형식으로 모든 특징 정보를 보존합니다.\u003c/p\u003e\n\u003cp\u003e첫 번째 완전 연결 계층\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ex = F.\u003cspan class=\"hljs-title function_\"\u003erelu\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003efc1\u003c/span\u003e(x))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e평탄화된 텐서는 첫 번째 완전 연결 계층(fc1)을 통과하여 전체 특징 집합에서 복잡한 패턴을 학습할 수 있습니다. ReLU 함수가 한 번 더 적용되어 비선형성을 도입하고, 네트워크가 더 복잡한 함수를 학습하고 표현할 수 있도록 합니다.\u003c/p\u003e\n\u003cp\u003e두 번째 완전 연결 계층 (출력 계층)\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ex = self.\u003cspan class=\"hljs-title function_\"\u003efc2\u003c/span\u003e(x)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e마침내, 텐서는 출력 레이어 역할을 하는 두 번째 완전 연결 레이어(FC2)를 통과합니다. 이 레이어에는 예측할 클래스 수와 동일한 수의 뉴런이 있습니다(MNIST 숫자의 경우 10개). 이 레이어의 출력은 네트워크가 각 클래스에 대해 예측한 값을 나타냅니다.\u003c/p\u003e\n\u003ch2\u003e3.4: 모델 컴파일\u003c/h2\u003e\n\u003cp\u003e모델은 CrossEntropyLoss로 분류되어 있고 Adam 옵티마이저를 사용하여 가중치를 조정하며, 학습률 및 가중치 감소와 같은 특정 매개변수도 함께 사용하여 컴파일됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ecriterion = nn.\u003cspan class=\"hljs-title class_\"\u003eCrossEntropyLoss\u003c/span\u003e()\noptimizer = optim.\u003cspan class=\"hljs-title class_\"\u003eAdam\u003c/span\u003e(model.\u003cspan class=\"hljs-title function_\"\u003eparameters\u003c/span\u003e(), lr=\u003cspan class=\"hljs-number\"\u003e1e-3\u003c/span\u003e, weight_decay=\u003cspan class=\"hljs-number\"\u003e1e-5\u003c/span\u003e, amsgrad=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, eps=\u003cspan class=\"hljs-number\"\u003e1e-8\u003c/span\u003e, betas=(\u003cspan class=\"hljs-number\"\u003e0.9\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.999\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eAdam 옵티마이저는 딥러닝 모델을 훈련하는 인기 알고리즘으로, AdaGrad와 RMSProp 알고리즘의 최상의 특성을 결합하여 소음이 있는 문제에서 희소한 그래디언트를 효율적으로 처리합니다. 이는 매개변수별로 학습률을 조정하여 광범위한 작업과 모델에 매우 효과적이고 적합합니다. Adam에 대해 더 자세히 알고 싶다면, 수학적인 내용을 검토하고 처음부터 구축한 내 기사를 살펴보세요:\u003c/p\u003e\n\u003ch2\u003e3.5: CNN 훈련\u003c/h2\u003e\n\u003cp\u003e제공된 로직의 Trainer 클래스는 CNN 모델을 훈련하는 데 필요한 필수 기능을 포함하고 있습니다. 이는 순방향 패스, 역방향 패스(그래디언트 계산 및 가중치 업데이트), 훈련 및 검증 손실 모니터링, 조기 중단 구현, 학습률 조정, 그리고 모델 성능 평가를 포함합니다. 이 클래스를 분석하여 구조와 기능을 깊이 이해해 봅시다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eTrainer\u003c/span\u003e:\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, model, criterion, optimizer, device, patience=\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e\u003c/span\u003e):\n        self.model = model\n        self.criterion = criterion\n        self.optimizer = optimizer\n        self.device = device\n        self.early_stopping = EarlyStopping(patience=patience)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, \u003cspan class=\"hljs-string\"\u003e'min'\u003c/span\u003e, patience=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e, verbose=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e, factor=\u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e, min_lr=\u003cspan class=\"hljs-number\"\u003e1e-6\u003c/span\u003e)\n        self.train_losses = []\n        self.val_losses = []\n        self.gradient_norms = []\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e초기화 메서드인 __init__에서 Trainer 클래스는 CNN 모델, 손실 함수(criterion), 옵티마이저와 함께 CPU 또는 GPU에서 학습할 장치와 조기 종료를 위한 인자로 받습니다. EarlyStopping 인스턴스는 검증 손실을 모니터링하고 모델이 더 이상 개선되지 않을 경우 훈련을 중지하여 과적합을 방지합니다. 학습률 스케줄러(ReduceLROnPlateau)도 초기화되어 검증 손실을 기반으로 학습률을 동적으로 조정하여 훈련 중에 최적의 학습률을 찾도록 도와줍니다. 분석 및 디버깅 목적으로 학습 및 검증 손실 및 그레이디언트 노름을 추적하기 위한 리스트가 초기화됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef \u003cspan class=\"hljs-title function_\"\u003etrain\u003c/span\u003e(self, train_loader, val_loader, epochs):\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e epoch \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(epochs):\n        self.\u003cspan class=\"hljs-property\"\u003emodel\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003etrain\u003c/span\u003e()\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e images, labels \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etrain_loader\u003c/span\u003e:\n            images, labels = images.\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(self.\u003cspan class=\"hljs-property\"\u003edevice\u003c/span\u003e), labels.\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(self.\u003cspan class=\"hljs-property\"\u003edevice\u003c/span\u003e)\n            self.\u003cspan class=\"hljs-property\"\u003eoptimizer\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ezero_grad\u003c/span\u003e()\n            outputs = self.\u003cspan class=\"hljs-title function_\"\u003emodel\u003c/span\u003e(images)\n            loss = self.\u003cspan class=\"hljs-title function_\"\u003ecriterion\u003c/span\u003e(outputs, labels)\n            self.\u003cspan class=\"hljs-property\"\u003etrain_losses\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(loss.\u003cspan class=\"hljs-title function_\"\u003eitem\u003c/span\u003e())\n            loss.\u003cspan class=\"hljs-title function_\"\u003ebackward\u003c/span\u003e()\n            self.\u003cspan class=\"hljs-property\"\u003eoptimizer\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estep\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003etrain 메서드는 지정된 에폭 수에 대한 학습 프로세스를 조율합니다. 각 에폭마다 모델을 훈련 모드로 설정하고 train_loader를 사용하여 학습 데이터셋을 반복합니다. 입력 이미지와 레이블을 지정된 장치로 이동시킵니다. 옵티마이저의 그라디언트는 이전 반복에서의 누적을 방지하기 위해 각 순방향 패스 전에 0으로 초기화됩니다. 모델의 예측을 얻고, 지정된 criterion을 사용하여 손실을 계산합니다. 손실 값은 추적을 위해 train_losses 리스트에 추가됩니다. loss.backward()를 호출하여 역전파를 수행하고, 옵티마이저는 optimizer.step()로 모델 가중치를 업데이트합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eval_loss = self.evaluate(val_loader)\nself.\u003cspan class=\"hljs-property\"\u003eval_losses\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(val_loss)\nself.\u003cspan class=\"hljs-property\"\u003escheduler\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estep\u003c/span\u003e(val_loss)\nself.\u003cspan class=\"hljs-title function_\"\u003eearly_stopping\u003c/span\u003e(val_loss)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e훈련 데이터를 처리한 후 모델은 평가 메서드를 사용하여 검증 데이터셋에서 평가되며, 평균 검증 손실을 계산합니다. 이 손실은 학습률을 조정하고 조기 종료 조건이 충족되었는지 확인하는 데 사용됩니다. 검증 손실은 분석을 위해 추적됩니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e self.\u003cspan class=\"hljs-property\"\u003eearly_stopping\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eearly_stop\u003c/span\u003e:\n    \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"조기 종료\"\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003ebreak\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e조기 종료가 발생하면, 과적합을 방지하기 위해 훈련이 중지됩니다. 이 결정은 인내 매개변수로 정의된 여러 epoch 동안 검증 손실이 향상되지 않았는지에 따라 기반으로 합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef evaluate(self, test_loader):\n    self.\u003cspan class=\"hljs-property\"\u003emodel\u003c/span\u003e.\u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e()\n    total_loss = \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e torch.\u003cspan class=\"hljs-title function_\"\u003eno_grad\u003c/span\u003e():\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e images, labels \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etest_loader\u003c/span\u003e:\n            images, labels = images.\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(self.\u003cspan class=\"hljs-property\"\u003edevice\u003c/span\u003e), labels.\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(self.\u003cspan class=\"hljs-property\"\u003edevice\u003c/span\u003e)\n            outputs = self.\u003cspan class=\"hljs-title function_\"\u003emodel\u003c/span\u003e(images)\n            loss = self.\u003cspan class=\"hljs-title function_\"\u003ecriterion\u003c/span\u003e(outputs, labels)\n            total_loss += loss.\u003cspan class=\"hljs-title function_\"\u003eitem\u003c/span\u003e()\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e total_loss / \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(test_loader)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eevaluate 메서드는 모델의 가중치를 업데이트하지 않고 유효성 검사 또는 테스트 데이터셋에서 평균 손실을 계산합니다. 이 메서드는 모델을 평가 모드로 설정하고 효율성을 위해 그래디언트 계산을 비활성화합니다.\u003c/p\u003e\n\u003ch1\u003e4: 모델 성능 향상\u003c/h1\u003e\n\u003cp\u003e합성곱 신경망(CNN)의 성능을 개선하고 과적합을 방지하는 것은 딥러닝 모델을 교육하는 중요한 도전 과제입니다. 제공된 코드 스니펫은 데이터 증가, 드롭아웃, 배치 정규화와 같은 기술에 대해 명시적으로 설명하지 않으며 전이 학습에 대해서도 다루지 않습니다. 그러나 이러한 전략들은 CNN을 향상시키는 데 중요하므로 이들이 훈련 과정에 통합되고 모델 성능에 미치는 잠재적인 영향에 대해 알아봅시다.\u003c/p\u003e\n\u003ch2\u003e4.1: 데이터 증가\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e데이터 증가는 기존 이미지에 임의의 변환(회전, 뒤집기, 크기 조정 등)을 적용하여 학습 데이터셋의 다양성을 인위적으로 증가시킵니다. 이 다양성은 모델이 더 많은 입력 변화 범위에서 학습함으로써 새로운 데이터에 대해 더 잘 일반화되도록 돕습니다.\u003c/p\u003e\n\u003cp\u003ePyTorch에서 데이터 증가를 구현하려면 데이터셋을 준비할 때 사용되는 transforms.Compose를 확장할 수 있습니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etransform = transforms.\u003cspan class=\"hljs-title class_\"\u003eCompose\u003c/span\u003e([\n    transforms.\u003cspan class=\"hljs-title class_\"\u003eRandomHorizontalFlip\u003c/span\u003e(),\n    transforms.\u003cspan class=\"hljs-title class_\"\u003eRandomRotation\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e),\n    transforms.\u003cspan class=\"hljs-title class_\"\u003eToTensor\u003c/span\u003e(),\n    transforms.\u003cspan class=\"hljs-title class_\"\u003eNormalize\u003c/span\u003e((\u003cspan class=\"hljs-number\"\u003e0.1307\u003c/span\u003e,), (\u003cspan class=\"hljs-number\"\u003e0.3081\u003c/span\u003e,))\n])\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e랜덤 뒤집기와 회전을 추가함으로써 훈련 데이터를 다양하게 만들어 모델이 더 견고한 특징을 학습하도록 돕습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e4.2: Dropout\u003c/h2\u003e\n\u003cp\u003e드롭아웃은 학습 중에 입력 뉴런의 일부를 무작위로 0으로 설정하여 과도한 공동 적응을 방지하는 정칙화 기술입니다. 이 무작위성은 네트워크가 다른 뉴런의 무작위 하위 집합과 함께 유용한 보다 견고한 기능을 학습하도록 강제합니다.\u003c/p\u003e\n\u003cp\u003e파이토치에서 CNN 모델에 드롭아웃을 추가하려면 nn.Dropout 레이어를 포함시킵니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eMyCNN\u003c/span\u003e(nn.\u003cspan class=\"hljs-property\"\u003eModule\u003c/span\u003e):\n    def \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(self):\n        \u003cspan class=\"hljs-variable language_\"\u003esuper\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eMyCNN\u003c/span\u003e, self).\u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e()\n        # 합성곱 레이어\n        self.\u003cspan class=\"hljs-property\"\u003efc1\u003c/span\u003e = nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e7\u003c/span\u003e*\u003cspan class=\"hljs-number\"\u003e64\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e128\u003c/span\u003e)\n        self.\u003cspan class=\"hljs-property\"\u003edropout\u003c/span\u003e = nn.\u003cspan class=\"hljs-title class_\"\u003eDropout\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e)\n        self.\u003cspan class=\"hljs-property\"\u003efc2\u003c/span\u003e = nn.\u003cspan class=\"hljs-title class_\"\u003eLinear\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e128\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)\n    def \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(self, x):\n        # 합성곱 및 풀링 작업\n        x = x.\u003cspan class=\"hljs-title function_\"\u003eview\u003c/span\u003e(x.\u003cspan class=\"hljs-title function_\"\u003esize\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e), -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n        x = F.\u003cspan class=\"hljs-title function_\"\u003erelu\u003c/span\u003e(self.\u003cspan class=\"hljs-title function_\"\u003efc1\u003c/span\u003e(x))\n        x = self.\u003cspan class=\"hljs-title function_\"\u003edropout\u003c/span\u003e(x)\n        x = self.\u003cspan class=\"hljs-title function_\"\u003efc2\u003c/span\u003e(x)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e x\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e마지막 완전 연결 레이어 앞에 드롭아웃 레이어를 추가하면 모델이 학습된 표현을 여러 뉴런에 분배하도록 유도하여 오버피팅을 완화하는 데 도움이 됩니다.\u003c/p\u003e\n\u003ch2\u003e4.3: 배치 정규화\u003c/h2\u003e\n\u003cp\u003e배치 정규화는 각 미니 배치에 대해 레이어의 입력을 표준화하여 학습 프로세스를 안정화시키고 딥 네트워크를 훈련하는 데 필요한 훈련 에포크 수를 크게 줄입니다.\u003c/p\u003e\n\u003cp\u003e모델에 배치 정규화를 포함하는 방법은 다음과 같습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eMyCNN\u003c/span\u003e(nn.Module):\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        \u003cspan class=\"hljs-built_in\"\u003esuper\u003c/span\u003e(MyCNN, self).__init__()\n        \u003cspan class=\"hljs-comment\"\u003e# Covolutional layers\u003c/span\u003e\n        self.conv1_bn = nn.BatchNorm2d(\u003cspan class=\"hljs-number\"\u003e32\u003c/span\u003e)\n        \u003cspan class=\"hljs-comment\"\u003e# Fully connected layers\u003c/span\u003e\n        \n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eforward\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, x\u003c/span\u003e):\n        x = F.relu(self.conv1_bn(self.conv1(x)))\n        \u003cspan class=\"hljs-comment\"\u003e# Continue through model\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e컨볼루션 레이어 다음에 배치 정규화를 적용한 후 활성화 함수를 사용하는 것은 출력을 정규화하여 수렴 속도를 높이고 전반적인 성능을 향상시켜줍니다.\u003c/p\u003e\n\u003ch2\u003e4.4: 전이 학습\u003c/h2\u003e\n\u003cp\u003e전이 학습은 한 작업에서 훈련된 모델을 다른 관련 작업에서 훈련을 위한 출발점으로 사용하는 기술을 말합니다. 새 작업에 제한된 데이터셋이 있는 경우 특히 유용합니다. PyTorch는 ImageNet과 같은 대규모 데이터셋에서 사전 훈련된 모델을 쉽게 로드하고 조정할 수 있도록 지원하여 전이 학습을 용이하게 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e프리 트레인 모델을 활용하는 방법은 아주 쉬워요!\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torchvision \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e models\n\nmodel = models.resnet18(pretrained=\u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e)\n\u003cspan class=\"hljs-comment\"\u003e# 마지막 완전 연결 레이어 교체하기\u003c/span\u003e\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, \u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e)  \u003cspan class=\"hljs-comment\"\u003e# 새로운 작업을 위해 10개의 클래스로 가정\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# 마지막 완전 연결 레이어를 제외한 모든 레이어 동결하기\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e param \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e model.parameters():\n    param.requires_grad = \u003cspan class=\"hljs-literal\"\u003eFalse\u003c/span\u003e\nmodel.fc.requires_grad = \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e요기서, 사전 훈련된 ResNet-18 모델을 사용해서, 10개의 클래스를 위한 새 작업에 맞게 마지막 레이어를 대체했어요. 마지막 레이어를 제외한 모든 레이어의 가중치를 동결하면, 분류기 레이어만을 미세 조정해 원본 데이터셋에서 학습한 기능 추출 능력을 활용할 수 있어요.\u003c/p\u003e\n\u003cp\u003eCNN 훈련 과정에 이러한 전략을 통합시키면, 오버피팅이 줄어들 뿐만 아니라 견고한 특징 학습을 보장하고 사전 훈련된 모델로부터 지식을 활용하여 모델 성능을 향상시킬 수 있어요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e5: 결론\u003c/h1\u003e\n\u003cp\u003e합성곱 신경망에 대해 심층적으로 파헤쳐 보았습니다. 데이터 설정 및 준비부터 CNN 구조와 계층 분해까지 많은 내용을 다루었습니다. 이러한 모델의 작동 원리를 살펴봤습니다. 가중치 초기화와 데이터 증강, 전이 학습과 같은 기술을 사용하여 모델의 성능을 심각하게 향상시킬 수 있다는 점을 살펴보았습니다. 이러한 방법들은 모델이 더욱 똑똑하게 만들어주어, 오버피팅과 같은 일반적인 함정을 피하고 더 다양한 모델로 만들어 줍니다.\u003c/p\u003e\n\u003cp\u003eAI 분야에서 CNN은 거의 모든 곳에서 사용되어 얼굴을 인식하거나 의료 영상을 통해 질병을 진단하는 등 많은 일에 도움이 되고 있습니다. 시각적 단서를 잡아내는 능력으로 다양한 작업에 매우 유용합니다.\u003c/p\u003e\n\u003ch1\u003e추가 자료\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eLeCun et al., “Gradient-Based Learning Applied to Document Recognition”\nYann LeCun과 동료들이 쓴 이 주요 논문에서는 LeNet-5를 소개하며, 최초의 합성곱 신경망 중 하나로 문서 인식 작업에 적용된 결과를 보여줍니다.\nResearch Gate 링크\u003c/li\u003e\n\u003cli\u003eSimonyan과 Zisserman, “Very Deep Convolutional Networks for Large-Scale Image Recognition” (VGGNet)\nVGGNet을 소개한 이 연구는 CNN 아키텍처에서 깊이의 중요성을 강조하여 이미지 인식 성능을 향상시키는데 있습니다.\narXiv 링크\u003c/li\u003e\n\u003cli\u003eHe et al., “Deep Residual Learning for Image Recognition” (ResNet)\nResNet은 잔차 학습 개념을 도입하여, 사그라들어 버리는 기울기 문제를 해결함으로써 훨씬 더 깊은 네트워크의 학습을 가능케 합니다.\narXiv 링크\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e만약 이 기사를 좋아하셨다면 좋아요를 눌러 주시고, 최신 게시물을 받아보려면 팔로우해주세요. 저의 목표는 인기 있는 모든 알고리즘을 처음부터 다시 만들어 기계 학습을 누구에게나 쉽게 접근할 수 있게 하는 것입니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-TheMathBehindConvolutionalNeuralNetworks"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>