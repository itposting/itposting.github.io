<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>신기한 여행 스탠포드의 매직 월드 크리에이터 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="신기한 여행 스탠포드의 매직 월드 크리에이터 | itposting" data-gatsby-head="true"/><meta property="og:title" content="신기한 여행 스탠포드의 매직 월드 크리에이터 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator" data-gatsby-head="true"/><meta name="twitter:title" content="신기한 여행 스탠포드의 매직 월드 크리에이터 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 02:53" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-0fd008072af5a644.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">신기한 여행 스탠포드의 매직 월드 크리에이터</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="신기한 여행 스탠포드의 매직 월드 크리에이터" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">4<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>제 뉴스레터에서 최근 세계적인 Fei-Fei Li의 Stanford 연구소에서 만든 최신 모델에 대해 이야기했었죠. 그 모델은 명령으로 무한한 마법의 3D 세계를 만들어냈습니다.</p>
<p>하지만 저는 그 모델의 깊은 부분까지 파헤치게 되었고, 그 모델에 너무 매료되어 세계에서 가장 진보된 텍스트/이미지-3D 모델이 어떻게 작동하는지 상세히 설명하고 싶어졌습니다.</p>
<p>이 모델은 게임, 가상 현실, 증강 현실, 혼합 현실에 혁명을 일으킬 수 있을 뿐만 아니라, Fei Fei Li 자신이 시사한 대로, AI가 우리의 세계를 더 잘 이해할 수 있는 세계 모델을 만드는 데 도움이 될 수 있습니다.</p>
<h1>마법 창조하기</h1>
<p>WonderJourney는 텍스트 설명 또는 이미지를 기반으로 무한하지만 일관된 3D 장면을 생성하는 AI 모델입니다.</p>
<p>시각적으로 완벽하지는 않지만 비디오의 모든 것이 완전히 AI로 생성된 것이라는 아이디어는 정말 놀라운 것이죠.</p>
<p>하지만 이것이 어떻게 작동하는 걸까요?</p>
<h2>모듈식 접근</h2>
<p>WonderJourney는 세 가지 구성 요소로 나뉩니다:</p>
<ul>
<li>LLM: 다음 장면을 생성하는 데 책임을 지는 대형 언어 모델(Large Language Model).</li>
<li>VSG(Visual Scene Generator): LLM의 다음 장면 텍스트 설명과 현재 장면 이미지를 입력으로 받아 다음 3D 장면을 생성하는 모델.</li>
<li>VLM validator: 새로 생성된 장면을 검사하고 품질이 충분히 높지 않은 경우 재시도를 요청하는 Vision Language Model.</li>
</ul>
<p>전체 모델의 표현은 다음과 같습니다:</p>
<p><img src="/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png" alt="WonderJourney Model"></p>
<p>이해하기 어려운 내용이죠. 다양한 기술적 구성 요소에 대해 설명하기 전에 완전한 예시를 보는 것이 좋습니다:</p>
<ul>
<li>사용자가 요청한 내용: "산속의 아늑한 마을, 자갈길과 나무집이 있는 곳. 뒤쪽에 눈을 덮은 봉우리가 솟아 있습니다."</li>
<li>LLM이 새로운 장면 생성: "아늑한 마을을 지나 숲으로 들어가면, 땅에 입체적인 그림자를 드리우는 덤불들이 보입니다."</li>
<li>Visual Scene Generator가 다음 3D 장면을 생성하며 마을을 멀리 뒤쪽에 밀어 넣어 숲으로 이동하는 느낌을 전달합니다.</li>
<li>VLM이 새로운 장면을 확인하고, 우리는 이 과정을 반복합니다.</li>
</ul>
<p><img src="/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_1.png" alt="이미지"></p>
<p>이제 전체적인 파이프라인을 이해했으니, 생각해볼 점은 이 모든 것이 어떻게 작동하는 걸까요?</p>
<h2>다양한 모델 집합</h2>
<p>원더저니의 멋진 점 중 하나는 그 구성 요소들이 모듈식이라는 것입니다. 즉, 좋아하는 LLM, VSG 또는 VLM을 사용할 수 있다는 뜻이죠. 그러나 원더저니에는 몇 가지 중요한 모델이 포함되어 있습니다.</p>
<p>따라서, 이해를 돕기 위해 3D 장면이 어떻게 생성되고 카메라의 역할에 대해 상세히 설명하면서 전반적인 내용을 설명하는 것이 좋을 것 같아요.</p>
<h2>2D에서 3D로, 그리고 그 반대로</h2>
<p>3D 장면을 논의할 때, 화상의 경우를 제외하고는 여전히 2D 화면에 표시해야 합니다 (가상 헤드셋 제외, WonderJourney의 사용 사례가 아닙니다).</p>
<p>다시 말해, 전반적인 작업의 많은 부분은 3D 장면이 "카메라"의 2D 렌즈 (사용자의 화면)로부터 어떻게 보여질지 계산하는 것입니다.</p>
<p>그러므로, 새로운 장면을 사용할 때마다, WonderJourney는 2D 이미지를 사용해서 새로운 3D 장면을 생성하지만, 결국 이 장면은 화면에 다시 2D로 투영됩니다.</p>
<p>이를 알고 나면 이제 WonderJourney가 어떻게 작동하는지 이해할 수 있습니다.</p>
<h2>깊이, 포인트 클라우드 및 투영</h2>
<p>새로운 장면을 생성하는 전체 프로세스는 다음과 같습니다:</p>
<p><img src="/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_2.png" alt="이미지"></p>
<ul>
<li>먼저, 모델은 초기 조건으로 텍스트 또는 이미지를 취하며, 사용자가 텍스트 설명만을 제공한 경우 이미지를 생성합니다.</li>
<li>이 입력을 사용하여, 먼저 이미지에서 각 요소의 깊이를 추정하며, 즉, 각 객체가 실제로 얼마나 먼지 가까운지를 추정합니다 (예: 하늘은 항상 '멀리있음'으로 추정되어야 합니다).</li>
<li>다음 단계는 깊이 추정으로부터 포인트 클라우드를 생성하는 것이며, WonderJourney는 이를 정제하여 요소 사이의 '날카로운' 경계를 보장합니다.</li>
</ul>
<p>그러나, 저희는 여전히 현재 뷰를 작업 중이며 새로운 뷰가 필요합니다. 이를 위해 2D 화면(우리)에서 3D 장면을 볼 '카메라'는 뒤로 밀려서 이전 장면이 멀리 뒤쪽에 나타나도록 하여 '우리가 그것에서 멀어지고 있다'는 아이디어를 전달합니다. 이제 다음 장면에 나타날 현재 장면의 일부가 위치하고, 새 프레임의 그 부분이 렌더링됩니다.</p>
<p>그런 다음, 이 부분적 렌더링과 다음 장면의 LLM(언어-이미지 모델) 설명을 사용하여 WonderJourney는 나머지 장면을 outpaint하는데, 이 경우에는 Stable Diffusion 모델을 사용하지만, 중요한 건 LLM의 새로운 장면이어야 하는 내용에 따라 조건이 부여된다는 것입니다.</p>
<p>마지막으로, 새 이미지를 얻었으면, 우리는 간단히 깊이 추정 및 정제 프로세스를 반복하여 필요에 따라 여러 가지 대안적인 뷰를 생성하여 새로운 포인트 클라우드를 만듭니다.</p>
<p>이 새로운 포인트 클라우드는 본질적으로 새로운 3D 뷰를 구축하며, VLM(시각 언어 모델)이 평가합니다. 품질 임계값을 충족하면, 해당 장면이 뷰어의 2D 화면에 투사되고, 프로세스가 반복됩니다.</p>
<p>여기 있어요, 끝없이 이어지고 항상 일관된 3D 여행이 마련되었습니다.</p>
<h1>모든 형태의 정복</h1>
<p>한 번 더, 학계는 사용자의 텍스트 또는 이미지 명령에 기반한 무한한 3D 장면을 생성할 수 있는 첫 번째 모델의 가능성을 확장했습니다.</p>
<p>마지막으로, Fei Fei Li의 생각을 빌리자면, 강력한 3D 생성 모델을 구축하는 것은 AI에게 우리 세상에 대한 큰 공간적 이해력을 제공할 수 있으며, 이는 그들의 지능을 향상시키는 방법으로 활용될 수 있고, 누가 알겠으나, 구체적 AI 모델, 즉 인간형 로봇의 등장을 용이하게 할 수도 있습니다.</p>
<p>현실 세계와 상호 작용할 수 있는 능력을 기계에 부여하면, 시뮬레이션 환경을 통해라도 사람들과 격차를 줄일 수 있을 것입니다. 우리는 관찰과 세상과의 상호 작용을 통해 배우기 때문에, 오늘날의 최첨단 AI 모델들을 뛰어넘는 능력을 갖게 됩니다, 어떻게 ChatGPT나 Claude가 감탄을 자아내는지와 상관없이요.</p>
<p>우리가 이것이 옳은 길이라고 주장할 수는 없겠지만, 텍스트를 단순히 모델에 던지고 AGI로 성장할 것을 바라는 것보다는 훨씬 매력적으로 보입니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"신기한 여행 스탠포드의 매직 월드 크리에이터","description":"","date":"2024-06-19 02:53","slug":"2024-06-19-WonderJourneyStanfordsMagicalWorldCreator","content":"\n\n제 뉴스레터에서 최근 세계적인 Fei-Fei Li의 Stanford 연구소에서 만든 최신 모델에 대해 이야기했었죠. 그 모델은 명령으로 무한한 마법의 3D 세계를 만들어냈습니다.\n\n하지만 저는 그 모델의 깊은 부분까지 파헤치게 되었고, 그 모델에 너무 매료되어 세계에서 가장 진보된 텍스트/이미지-3D 모델이 어떻게 작동하는지 상세히 설명하고 싶어졌습니다.\n\n이 모델은 게임, 가상 현실, 증강 현실, 혼합 현실에 혁명을 일으킬 수 있을 뿐만 아니라, Fei Fei Li 자신이 시사한 대로, AI가 우리의 세계를 더 잘 이해할 수 있는 세계 모델을 만드는 데 도움이 될 수 있습니다.\n\n# 마법 창조하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWonderJourney는 텍스트 설명 또는 이미지를 기반으로 무한하지만 일관된 3D 장면을 생성하는 AI 모델입니다.\n\n시각적으로 완벽하지는 않지만 비디오의 모든 것이 완전히 AI로 생성된 것이라는 아이디어는 정말 놀라운 것이죠.\n\n하지만 이것이 어떻게 작동하는 걸까요?\n\n## 모듈식 접근\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nWonderJourney는 세 가지 구성 요소로 나뉩니다:\n\n- LLM: 다음 장면을 생성하는 데 책임을 지는 대형 언어 모델(Large Language Model).\n- VSG(Visual Scene Generator): LLM의 다음 장면 텍스트 설명과 현재 장면 이미지를 입력으로 받아 다음 3D 장면을 생성하는 모델.\n- VLM validator: 새로 생성된 장면을 검사하고 품질이 충분히 높지 않은 경우 재시도를 요청하는 Vision Language Model.\n\n전체 모델의 표현은 다음과 같습니다:\n\n![WonderJourney Model](/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이해하기 어려운 내용이죠. 다양한 기술적 구성 요소에 대해 설명하기 전에 완전한 예시를 보는 것이 좋습니다:\n\n- 사용자가 요청한 내용: \"산속의 아늑한 마을, 자갈길과 나무집이 있는 곳. 뒤쪽에 눈을 덮은 봉우리가 솟아 있습니다.\"\n- LLM이 새로운 장면 생성: \"아늑한 마을을 지나 숲으로 들어가면, 땅에 입체적인 그림자를 드리우는 덤불들이 보입니다.\"\n- Visual Scene Generator가 다음 3D 장면을 생성하며 마을을 멀리 뒤쪽에 밀어 넣어 숲으로 이동하는 느낌을 전달합니다.\n- VLM이 새로운 장면을 확인하고, 우리는 이 과정을 반복합니다.\n\n![이미지](/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_1.png)\n\n이제 전체적인 파이프라인을 이해했으니, 생각해볼 점은 이 모든 것이 어떻게 작동하는 걸까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 다양한 모델 집합\n\n원더저니의 멋진 점 중 하나는 그 구성 요소들이 모듈식이라는 것입니다. 즉, 좋아하는 LLM, VSG 또는 VLM을 사용할 수 있다는 뜻이죠. 그러나 원더저니에는 몇 가지 중요한 모델이 포함되어 있습니다.\n\n따라서, 이해를 돕기 위해 3D 장면이 어떻게 생성되고 카메라의 역할에 대해 상세히 설명하면서 전반적인 내용을 설명하는 것이 좋을 것 같아요.\n\n## 2D에서 3D로, 그리고 그 반대로\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3D 장면을 논의할 때, 화상의 경우를 제외하고는 여전히 2D 화면에 표시해야 합니다 (가상 헤드셋 제외, WonderJourney의 사용 사례가 아닙니다).\n\n다시 말해, 전반적인 작업의 많은 부분은 3D 장면이 \"카메라\"의 2D 렌즈 (사용자의 화면)로부터 어떻게 보여질지 계산하는 것입니다.\n\n그러므로, 새로운 장면을 사용할 때마다, WonderJourney는 2D 이미지를 사용해서 새로운 3D 장면을 생성하지만, 결국 이 장면은 화면에 다시 2D로 투영됩니다.\n\n이를 알고 나면 이제 WonderJourney가 어떻게 작동하는지 이해할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 깊이, 포인트 클라우드 및 투영\n\n새로운 장면을 생성하는 전체 프로세스는 다음과 같습니다:\n\n![이미지](/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_2.png)\n\n- 먼저, 모델은 초기 조건으로 텍스트 또는 이미지를 취하며, 사용자가 텍스트 설명만을 제공한 경우 이미지를 생성합니다.\n- 이 입력을 사용하여, 먼저 이미지에서 각 요소의 깊이를 추정하며, 즉, 각 객체가 실제로 얼마나 먼지 가까운지를 추정합니다 (예: 하늘은 항상 '멀리있음'으로 추정되어야 합니다).\n- 다음 단계는 깊이 추정으로부터 포인트 클라우드를 생성하는 것이며, WonderJourney는 이를 정제하여 요소 사이의 '날카로운' 경계를 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나, 저희는 여전히 현재 뷰를 작업 중이며 새로운 뷰가 필요합니다. 이를 위해 2D 화면(우리)에서 3D 장면을 볼 '카메라'는 뒤로 밀려서 이전 장면이 멀리 뒤쪽에 나타나도록 하여 '우리가 그것에서 멀어지고 있다'는 아이디어를 전달합니다. 이제 다음 장면에 나타날 현재 장면의 일부가 위치하고, 새 프레임의 그 부분이 렌더링됩니다.\n\n그런 다음, 이 부분적 렌더링과 다음 장면의 LLM(언어-이미지 모델) 설명을 사용하여 WonderJourney는 나머지 장면을 outpaint하는데, 이 경우에는 Stable Diffusion 모델을 사용하지만, 중요한 건 LLM의 새로운 장면이어야 하는 내용에 따라 조건이 부여된다는 것입니다.\n\n마지막으로, 새 이미지를 얻었으면, 우리는 간단히 깊이 추정 및 정제 프로세스를 반복하여 필요에 따라 여러 가지 대안적인 뷰를 생성하여 새로운 포인트 클라우드를 만듭니다.\n\n이 새로운 포인트 클라우드는 본질적으로 새로운 3D 뷰를 구축하며, VLM(시각 언어 모델)이 평가합니다. 품질 임계값을 충족하면, 해당 장면이 뷰어의 2D 화면에 투사되고, 프로세스가 반복됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 있어요, 끝없이 이어지고 항상 일관된 3D 여행이 마련되었습니다.\n\n# 모든 형태의 정복\n\n한 번 더, 학계는 사용자의 텍스트 또는 이미지 명령에 기반한 무한한 3D 장면을 생성할 수 있는 첫 번째 모델의 가능성을 확장했습니다.\n\n마지막으로, Fei Fei Li의 생각을 빌리자면, 강력한 3D 생성 모델을 구축하는 것은 AI에게 우리 세상에 대한 큰 공간적 이해력을 제공할 수 있으며, 이는 그들의 지능을 향상시키는 방법으로 활용될 수 있고, 누가 알겠으나, 구체적 AI 모델, 즉 인간형 로봇의 등장을 용이하게 할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현실 세계와 상호 작용할 수 있는 능력을 기계에 부여하면, 시뮬레이션 환경을 통해라도 사람들과 격차를 줄일 수 있을 것입니다. 우리는 관찰과 세상과의 상호 작용을 통해 배우기 때문에, 오늘날의 최첨단 AI 모델들을 뛰어넘는 능력을 갖게 됩니다, 어떻게 ChatGPT나 Claude가 감탄을 자아내는지와 상관없이요.\n\n우리가 이것이 옳은 길이라고 주장할 수는 없겠지만, 텍스트를 단순히 모델에 던지고 AGI로 성장할 것을 바라는 것보다는 훨씬 매력적으로 보입니다.","ogImage":{"url":"/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png"},"coverImage":"/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png","tag":["Tech"],"readingTime":4},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e제 뉴스레터에서 최근 세계적인 Fei-Fei Li의 Stanford 연구소에서 만든 최신 모델에 대해 이야기했었죠. 그 모델은 명령으로 무한한 마법의 3D 세계를 만들어냈습니다.\u003c/p\u003e\n\u003cp\u003e하지만 저는 그 모델의 깊은 부분까지 파헤치게 되었고, 그 모델에 너무 매료되어 세계에서 가장 진보된 텍스트/이미지-3D 모델이 어떻게 작동하는지 상세히 설명하고 싶어졌습니다.\u003c/p\u003e\n\u003cp\u003e이 모델은 게임, 가상 현실, 증강 현실, 혼합 현실에 혁명을 일으킬 수 있을 뿐만 아니라, Fei Fei Li 자신이 시사한 대로, AI가 우리의 세계를 더 잘 이해할 수 있는 세계 모델을 만드는 데 도움이 될 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e마법 창조하기\u003c/h1\u003e\n\u003cp\u003eWonderJourney는 텍스트 설명 또는 이미지를 기반으로 무한하지만 일관된 3D 장면을 생성하는 AI 모델입니다.\u003c/p\u003e\n\u003cp\u003e시각적으로 완벽하지는 않지만 비디오의 모든 것이 완전히 AI로 생성된 것이라는 아이디어는 정말 놀라운 것이죠.\u003c/p\u003e\n\u003cp\u003e하지만 이것이 어떻게 작동하는 걸까요?\u003c/p\u003e\n\u003ch2\u003e모듈식 접근\u003c/h2\u003e\n\u003cp\u003eWonderJourney는 세 가지 구성 요소로 나뉩니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLLM: 다음 장면을 생성하는 데 책임을 지는 대형 언어 모델(Large Language Model).\u003c/li\u003e\n\u003cli\u003eVSG(Visual Scene Generator): LLM의 다음 장면 텍스트 설명과 현재 장면 이미지를 입력으로 받아 다음 3D 장면을 생성하는 모델.\u003c/li\u003e\n\u003cli\u003eVLM validator: 새로 생성된 장면을 검사하고 품질이 충분히 높지 않은 경우 재시도를 요청하는 Vision Language Model.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e전체 모델의 표현은 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_0.png\" alt=\"WonderJourney Model\"\u003e\u003c/p\u003e\n\u003cp\u003e이해하기 어려운 내용이죠. 다양한 기술적 구성 요소에 대해 설명하기 전에 완전한 예시를 보는 것이 좋습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e사용자가 요청한 내용: \"산속의 아늑한 마을, 자갈길과 나무집이 있는 곳. 뒤쪽에 눈을 덮은 봉우리가 솟아 있습니다.\"\u003c/li\u003e\n\u003cli\u003eLLM이 새로운 장면 생성: \"아늑한 마을을 지나 숲으로 들어가면, 땅에 입체적인 그림자를 드리우는 덤불들이 보입니다.\"\u003c/li\u003e\n\u003cli\u003eVisual Scene Generator가 다음 3D 장면을 생성하며 마을을 멀리 뒤쪽에 밀어 넣어 숲으로 이동하는 느낌을 전달합니다.\u003c/li\u003e\n\u003cli\u003eVLM이 새로운 장면을 확인하고, 우리는 이 과정을 반복합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e이제 전체적인 파이프라인을 이해했으니, 생각해볼 점은 이 모든 것이 어떻게 작동하는 걸까요?\u003c/p\u003e\n\u003ch2\u003e다양한 모델 집합\u003c/h2\u003e\n\u003cp\u003e원더저니의 멋진 점 중 하나는 그 구성 요소들이 모듈식이라는 것입니다. 즉, 좋아하는 LLM, VSG 또는 VLM을 사용할 수 있다는 뜻이죠. 그러나 원더저니에는 몇 가지 중요한 모델이 포함되어 있습니다.\u003c/p\u003e\n\u003cp\u003e따라서, 이해를 돕기 위해 3D 장면이 어떻게 생성되고 카메라의 역할에 대해 상세히 설명하면서 전반적인 내용을 설명하는 것이 좋을 것 같아요.\u003c/p\u003e\n\u003ch2\u003e2D에서 3D로, 그리고 그 반대로\u003c/h2\u003e\n\u003cp\u003e3D 장면을 논의할 때, 화상의 경우를 제외하고는 여전히 2D 화면에 표시해야 합니다 (가상 헤드셋 제외, WonderJourney의 사용 사례가 아닙니다).\u003c/p\u003e\n\u003cp\u003e다시 말해, 전반적인 작업의 많은 부분은 3D 장면이 \"카메라\"의 2D 렌즈 (사용자의 화면)로부터 어떻게 보여질지 계산하는 것입니다.\u003c/p\u003e\n\u003cp\u003e그러므로, 새로운 장면을 사용할 때마다, WonderJourney는 2D 이미지를 사용해서 새로운 3D 장면을 생성하지만, 결국 이 장면은 화면에 다시 2D로 투영됩니다.\u003c/p\u003e\n\u003cp\u003e이를 알고 나면 이제 WonderJourney가 어떻게 작동하는지 이해할 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e깊이, 포인트 클라우드 및 투영\u003c/h2\u003e\n\u003cp\u003e새로운 장면을 생성하는 전체 프로세스는 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-WonderJourneyStanfordsMagicalWorldCreator_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e먼저, 모델은 초기 조건으로 텍스트 또는 이미지를 취하며, 사용자가 텍스트 설명만을 제공한 경우 이미지를 생성합니다.\u003c/li\u003e\n\u003cli\u003e이 입력을 사용하여, 먼저 이미지에서 각 요소의 깊이를 추정하며, 즉, 각 객체가 실제로 얼마나 먼지 가까운지를 추정합니다 (예: 하늘은 항상 '멀리있음'으로 추정되어야 합니다).\u003c/li\u003e\n\u003cli\u003e다음 단계는 깊이 추정으로부터 포인트 클라우드를 생성하는 것이며, WonderJourney는 이를 정제하여 요소 사이의 '날카로운' 경계를 보장합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e그러나, 저희는 여전히 현재 뷰를 작업 중이며 새로운 뷰가 필요합니다. 이를 위해 2D 화면(우리)에서 3D 장면을 볼 '카메라'는 뒤로 밀려서 이전 장면이 멀리 뒤쪽에 나타나도록 하여 '우리가 그것에서 멀어지고 있다'는 아이디어를 전달합니다. 이제 다음 장면에 나타날 현재 장면의 일부가 위치하고, 새 프레임의 그 부분이 렌더링됩니다.\u003c/p\u003e\n\u003cp\u003e그런 다음, 이 부분적 렌더링과 다음 장면의 LLM(언어-이미지 모델) 설명을 사용하여 WonderJourney는 나머지 장면을 outpaint하는데, 이 경우에는 Stable Diffusion 모델을 사용하지만, 중요한 건 LLM의 새로운 장면이어야 하는 내용에 따라 조건이 부여된다는 것입니다.\u003c/p\u003e\n\u003cp\u003e마지막으로, 새 이미지를 얻었으면, 우리는 간단히 깊이 추정 및 정제 프로세스를 반복하여 필요에 따라 여러 가지 대안적인 뷰를 생성하여 새로운 포인트 클라우드를 만듭니다.\u003c/p\u003e\n\u003cp\u003e이 새로운 포인트 클라우드는 본질적으로 새로운 3D 뷰를 구축하며, VLM(시각 언어 모델)이 평가합니다. 품질 임계값을 충족하면, 해당 장면이 뷰어의 2D 화면에 투사되고, 프로세스가 반복됩니다.\u003c/p\u003e\n\u003cp\u003e여기 있어요, 끝없이 이어지고 항상 일관된 3D 여행이 마련되었습니다.\u003c/p\u003e\n\u003ch1\u003e모든 형태의 정복\u003c/h1\u003e\n\u003cp\u003e한 번 더, 학계는 사용자의 텍스트 또는 이미지 명령에 기반한 무한한 3D 장면을 생성할 수 있는 첫 번째 모델의 가능성을 확장했습니다.\u003c/p\u003e\n\u003cp\u003e마지막으로, Fei Fei Li의 생각을 빌리자면, 강력한 3D 생성 모델을 구축하는 것은 AI에게 우리 세상에 대한 큰 공간적 이해력을 제공할 수 있으며, 이는 그들의 지능을 향상시키는 방법으로 활용될 수 있고, 누가 알겠으나, 구체적 AI 모델, 즉 인간형 로봇의 등장을 용이하게 할 수도 있습니다.\u003c/p\u003e\n\u003cp\u003e현실 세계와 상호 작용할 수 있는 능력을 기계에 부여하면, 시뮬레이션 환경을 통해라도 사람들과 격차를 줄일 수 있을 것입니다. 우리는 관찰과 세상과의 상호 작용을 통해 배우기 때문에, 오늘날의 최첨단 AI 모델들을 뛰어넘는 능력을 갖게 됩니다, 어떻게 ChatGPT나 Claude가 감탄을 자아내는지와 상관없이요.\u003c/p\u003e\n\u003cp\u003e우리가 이것이 옳은 길이라고 주장할 수는 없겠지만, 텍스트를 단순히 모델에 던지고 AGI로 성장할 것을 바라는 것보다는 훨씬 매력적으로 보입니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-WonderJourneyStanfordsMagicalWorldCreator"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>