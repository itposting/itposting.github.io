<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Raspberry Pi에서 Stable Diffusion과 OnnxStream으로 이미지 생성하는 방법 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Raspberry Pi에서 Stable Diffusion과 OnnxStream으로 이미지 생성하는 방법 | itposting" data-gatsby-head="true"/><meta property="og:title" content="Raspberry Pi에서 Stable Diffusion과 OnnxStream으로 이미지 생성하는 방법 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi" data-gatsby-head="true"/><meta name="twitter:title" content="Raspberry Pi에서 Stable Diffusion과 OnnxStream으로 이미지 생성하는 방법 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-22 19:20" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Raspberry Pi에서 Stable Diffusion과 OnnxStream으로 이미지 생성하는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Raspberry Pi에서 Stable Diffusion과 OnnxStream으로 이미지 생성하는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 22, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h2>라즈베리 파이에서 Stable Diffusion XL Turbo를 사용하여 이미지를 생성하는 방법을 배워보세요!</h2>
<p><img src="/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_0.png" alt="이미지"></p>
<p>지난 기사에서는 라즈베리 파이에서 대형 언어 모델 및 비전 언어 모델을 실행하는 방법을 공유했습니다. 이번에는 LLM 또는 VLM이 아닌 이미지 생성 모델인 Stable Diffusion XL (SDXL) Turbo를 라즈베리 파이 5에서 실행할 것입니다. 또 다른 불가능한 일처럼 들리지만, 오픈 소스의 기이한 점들이 존재하고, 매우 리소스가 제한된 환경에서 SDXL Turbo 모델을 실행하는 것이 그 중 하나입니다.</p>
<h1>OnnxStream</h1>
<div class="content-ad"></div>
<p>OnnxStream은 Vito Plantamura가 만든 오픈 소스 프로젝트로, 초기 의도는 메모리 소비를 최소화하여 라즈베리 파이 제로 2에서 Stable Diffusion 1.5(SD1.5)를 실행하는 것이었습니다. 이로 인해 추론 대기 시간/처리량이 증가할 수 있지만 가능한 한 메모리 소비를 최소화하는 것이 목표입니다.</p>
<p>현재 상황에서 이 프로젝트는 Stable Diffusion 1.5 뿐만 아니라 Stable Diffusion XL 1.0 Base (SDXL) 및 Stable Diffusion XL Turbo 1.0도 지원하고 있습니다. 신기한 점은 GitHub 저장소에서 이미 잘 설명되어 있으므로 이 기반 기술에 대해 자세히 다루지 않겠습니다.</p>
<p>대신, 바로 작동하는 방법을 알아보겠습니다.</p>
<h1>기술적 요구 사항</h1>
<div class="content-ad"></div>
<p>다음만 있으면 됩니다:</p>
<ul>
<li>Raspberry Pi 5 — 혹은 Raspberry Pi 4 또는 다른 Raspberry Pi가 있어도 괜찮지만 이보다 느릴 것으로 예상됩니다.</li>
<li>SD 카드 — 최소 16GB, 이미 Raspbian 또는 다른 Linux 배포판이 설정되어 있어야 합니다. SDXL Turbo의 무게는 약 8GB입니다.</li>
<li>인터넷 연결</li>
</ul>
<p><img src="/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_1.png" alt="이미지"></p>
<h1>OnnxStream 설정하기</h1>
<div class="content-ad"></div>
<p>여기 안내는 GitHub 리포지토리에서 나온 것이지만, 좀 더 자세히 설명하고 있어요.</p>
<h2>1. XNNPack 빌드</h2>
<p>먼저 구글에서 제공하는 "고효율 부동 소수점 신경망 추론 연산자"를 제공하는 라이브러리인 XNNPack을 설치해야 해요. 다만 최신 버전을 가져오면 어떤 중대한 변경사항이 있을지 모르니까, 작성 당시에 OnnxStream 개발자가 작동되는 것을 확인한 버전을 가져와야 해요. 터미널에서 다음을 실행하세요:</p>
<pre><code class="hljs language-js">git clone <span class="hljs-attr">https</span>:<span class="hljs-comment">//github.com/google/XNNPACK.git</span>
cd <span class="hljs-variable constant_">XNNPACK</span>
git checkout 579de32260742a24166ecd13213d2e60af862675
mkdir build
cd build
cmake -<span class="hljs-variable constant_">DXNNPACK_BUILD_TESTS</span>=<span class="hljs-variable constant_">OFF</span> -<span class="hljs-variable constant_">DXNNPACK_BUILD_BENCHMARKS</span>=<span class="hljs-variable constant_">OFF</span> ..
cmake --build . --config <span class="hljs-title class_">Release</span>
</code></pre>
<div class="content-ad"></div>
<p>XNNPack을 빌드하는 데 몇 분 정도 소요될 것입니다. 커피 한 잔 마시거나 다른 일을 하세요.</p>
<h2>2. OnnxStream 빌드하기</h2>
<p>이제 OnnxStream을 빌드해야 합니다. 터미널에서 다음을 실행하세요:</p>
<pre><code class="hljs language-js">git clone <span class="hljs-attr">https</span>:<span class="hljs-comment">//github.com/vitoplantamura/OnnxStream.git</span>
cd <span class="hljs-title class_">OnnxStream</span>
cd src
mkdir build
cd build
cmake -<span class="hljs-variable constant_">DMAX_SPEED</span>=<span class="hljs-variable constant_">ON</span> -<span class="hljs-variable constant_">DXNNPACK_DIR</span>=<span class="xml"><span class="hljs-tag">&#x3C;<span class="hljs-name">XNNPACK이</span> <span class="hljs-attr">클론된</span> <span class="hljs-attr">디렉토리</span> <span class="hljs-attr">경로</span>></span> ..
cmake --build . --config Release
</span></code></pre>
<div class="content-ad"></div>
<p><code>DIRECTORY_WHERE_XNNPACK_WAS_CLONED</code>를 XNNPack가 복제된 경로로 교체해주세요 (빌드 폴더가 아닙니다). 제 경우에는 /home/admin/XNNPACK/에 있었습니다.</p>
<h2>3. 모델 가중치 다운로드</h2>
<p>이제 SDXL Turbo 모델 가중치를 다운로드해야 합니다. 터미널에서 다음을 실행하세요:</p>
<pre><code class="hljs language-js">git lfs install
git clone --depth=<span class="hljs-number">1</span> <span class="hljs-attr">https</span>:<span class="hljs-comment">//huggingface.co/AeroX2/stable-diffusion-xl-turbo-1.0-onnxstream</span>
</code></pre>
<div class="content-ad"></div>
<p>아직 git-lfs를 설치하지 않았다면 먼저 설치해주세요. 모델 가중치가 상당히 크기 때문에 이전 단계보다 시간이 훨씬 더 걸릴 것입니다. 점심 시간 동안 가져가세요!</p>
<p>또한 지원되는 다른 두 모델을 실행할 수도 있습니다 — Stable Diffusion 1.5와 Stable Diffusion XL 1.0 Base는 OnnxStream의 GitHub 저장소에서 제공된 링크를 통해 가중치를 다운로드하여 사용할 수 있습니다. 이 모든 모델을 다운로드하는 경우 SD 카드에 충분한 공간이 있는지 확인해주세요!</p>
<p>다 되었다면, 이제 준비가 끝났습니다! Raspberry Pi에서 이미지를 생성할 준비가 된 것입니다!</p>
<h1>이미지 생성 중</h1>
<div class="content-ad"></div>
<p>아래의 코드 블록을 실행하여 이미지를 생성하세요:</p>
<pre><code class="hljs language-js">cd ~<span class="hljs-regexp">/OnnxStream/</span>src/build/
./sd --turbo --models-path /home/admin/stable-diffusion-xl-turbo-<span class="hljs-number">1.0</span>-onnxstream --prompt <span class="hljs-string">"화성에서 말을 탄 우주 비행사"</span> --steps <span class="hljs-number">1</span> --output astronaut.<span class="hljs-property">png</span>
</code></pre>
<p>생성하고 싶은 내용에 해당하는 프롬프트로 교체하세요. 여기서는 대표적인 우주 비행사 프롬프트를 사용했습니다. 이미지를 생성하는 데 좋아보이는 이미지를 생성하기 위해 SDXL Turbo는 많은 단계가 필요하지 않으니 단계를 1로 설정했습니다.</p>
<p>SDXL Turbo를 제외한 다른 두 모델에는 네거티브 프롬프트를 위해 사용할 수 없지만, 생성 단계 수를 설정하는 --steps 및 무작위 시드를 설정하는 --seed와 같은 다른 인수도 전달할 수 있습니다.</p>
<div class="content-ad"></div>
<p>모델의 종류에 따라 필요한 인수가 변경될 수 있으니, SDXL Turbo 이외의 것을 사용하는 경우 전달해야 하는 인수의 전체 목록은 OnnxStream의 GitHub 리포지토리를 확인해 주세요.</p>
<p><img src="/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_2.png" alt="image"></p>
<p>위 이미지에서 확인할 수 있듯이, 라즈베리 파이 5에서 확산 단계마다 약 1분이 소요되며, 전처리 및 디코딩을 포함하여 한 장의 이미지를 생성하는 데 약 3분이 소요됩니다.</p>
<p><img src="/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_3.png" alt="image"></p>
<div class="content-ad"></div>
<p>여기 동일한 시드를 사용하여 1단계부터 10단계까지 동일한 프롬프트의 비교 및 진전이 있습니다. 단 한 걸음의 향상으로도 이미 생성된 이미지가 이미 매우 잘 완료되었음을 볼 수 있습니다. 이는 SDXL이나 SD1.5와는 대조적이며 해당 품질에 도달하기 위해서는 상당히 많은 단계가 필요합니다.</p>
<h1>결론</h1>
<p>이미지를 생성하는 데 최소한 몇 분이 걸리는 것을 감안하면, 그에 대한 사용 사례가 부족한지에 대한 질문이 떠오릅니다.</p>
<p><img src="/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_4.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>저에게 가장 명백하고 재미있는 사용 사례는 몇 분마다 새 이미지를 생성하는 변화무쌍한 사진 프레임입니다. 실제로 GitHub의 rvdveen이 OnnxStream을 사용한 이와 비슷한 프로젝트가 있습니다. 라즈베리 파이 제로 2 W에서 OnnxStream을 사용하여 뉴스 기사 이미지를 생성하고 전자잉크 디스플레이를 통해 사진 프레임에 표시하는 프로젝트입니다. 물론 실시간으로 보여주는 사진 프레임이 반드시 필요한 것은 아니지만, 라즈베리 파이 제로 2 W에서 이미지를 생성하는 데 약 5시간이 소요되며 SD1.5가 필요합니다.</p>
<p>또는 로컬에서 호스팅되는 이미지 생성기를 원할 수도 있습니다. 네트워크에서 주요 계산 장치를 점유하지 않고도 양호한 품질의 이미지를 생성할 수 있습니다.</p>
<p>라즈베리 파이에서 SDXL Turbo와 놀면서 즐기세요!</p>
<p>참고: 저는 OnnxStream이나 StabilityAI와 제휴 관계가 없습니다. 모든 의견은 본인의 의견이며 어떤 조직도 대표하지 않습니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Raspberry Pi에서 Stable Diffusion과 OnnxStream으로 이미지 생성하는 방법","description":"","date":"2024-06-22 19:20","slug":"2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi","content":"\n\n## 라즈베리 파이에서 Stable Diffusion XL Turbo를 사용하여 이미지를 생성하는 방법을 배워보세요!\n\n![이미지](/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_0.png)\n\n지난 기사에서는 라즈베리 파이에서 대형 언어 모델 및 비전 언어 모델을 실행하는 방법을 공유했습니다. 이번에는 LLM 또는 VLM이 아닌 이미지 생성 모델인 Stable Diffusion XL (SDXL) Turbo를 라즈베리 파이 5에서 실행할 것입니다. 또 다른 불가능한 일처럼 들리지만, 오픈 소스의 기이한 점들이 존재하고, 매우 리소스가 제한된 환경에서 SDXL Turbo 모델을 실행하는 것이 그 중 하나입니다.\n\n# OnnxStream\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOnnxStream은 Vito Plantamura가 만든 오픈 소스 프로젝트로, 초기 의도는 메모리 소비를 최소화하여 라즈베리 파이 제로 2에서 Stable Diffusion 1.5(SD1.5)를 실행하는 것이었습니다. 이로 인해 추론 대기 시간/처리량이 증가할 수 있지만 가능한 한 메모리 소비를 최소화하는 것이 목표입니다.\n\n현재 상황에서 이 프로젝트는 Stable Diffusion 1.5 뿐만 아니라 Stable Diffusion XL 1.0 Base (SDXL) 및 Stable Diffusion XL Turbo 1.0도 지원하고 있습니다. 신기한 점은 GitHub 저장소에서 이미 잘 설명되어 있으므로 이 기반 기술에 대해 자세히 다루지 않겠습니다.\n\n대신, 바로 작동하는 방법을 알아보겠습니다.\n\n# 기술적 요구 사항\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음만 있으면 됩니다:\n\n- Raspberry Pi 5 — 혹은 Raspberry Pi 4 또는 다른 Raspberry Pi가 있어도 괜찮지만 이보다 느릴 것으로 예상됩니다.\n- SD 카드 — 최소 16GB, 이미 Raspbian 또는 다른 Linux 배포판이 설정되어 있어야 합니다. SDXL Turbo의 무게는 약 8GB입니다.\n- 인터넷 연결\n\n![이미지](/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_1.png)\n\n# OnnxStream 설정하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 안내는 GitHub 리포지토리에서 나온 것이지만, 좀 더 자세히 설명하고 있어요.\n\n## 1. XNNPack 빌드\n\n먼저 구글에서 제공하는 \"고효율 부동 소수점 신경망 추론 연산자\"를 제공하는 라이브러리인 XNNPack을 설치해야 해요. 다만 최신 버전을 가져오면 어떤 중대한 변경사항이 있을지 모르니까, 작성 당시에 OnnxStream 개발자가 작동되는 것을 확인한 버전을 가져와야 해요. 터미널에서 다음을 실행하세요:\n\n```js\ngit clone https://github.com/google/XNNPACK.git\ncd XNNPACK\ngit checkout 579de32260742a24166ecd13213d2e60af862675\nmkdir build\ncd build\ncmake -DXNNPACK_BUILD_TESTS=OFF -DXNNPACK_BUILD_BENCHMARKS=OFF ..\ncmake --build . --config Release\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nXNNPack을 빌드하는 데 몇 분 정도 소요될 것입니다. 커피 한 잔 마시거나 다른 일을 하세요.\n\n## 2. OnnxStream 빌드하기\n\n이제 OnnxStream을 빌드해야 합니다. 터미널에서 다음을 실행하세요:\n\n```js\ngit clone https://github.com/vitoplantamura/OnnxStream.git\ncd OnnxStream\ncd src\nmkdir build\ncd build\ncmake -DMAX_SPEED=ON -DXNNPACK_DIR=\u003cXNNPACK이 클론된 디렉토리 경로\u003e ..\ncmake --build . --config Release\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n`DIRECTORY_WHERE_XNNPACK_WAS_CLONED`를 XNNPack가 복제된 경로로 교체해주세요 (빌드 폴더가 아닙니다). 제 경우에는 /home/admin/XNNPACK/에 있었습니다.\n\n## 3. 모델 가중치 다운로드\n\n이제 SDXL Turbo 모델 가중치를 다운로드해야 합니다. 터미널에서 다음을 실행하세요:\n\n```js\ngit lfs install\ngit clone --depth=1 https://huggingface.co/AeroX2/stable-diffusion-xl-turbo-1.0-onnxstream\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아직 git-lfs를 설치하지 않았다면 먼저 설치해주세요. 모델 가중치가 상당히 크기 때문에 이전 단계보다 시간이 훨씬 더 걸릴 것입니다. 점심 시간 동안 가져가세요!\n\n또한 지원되는 다른 두 모델을 실행할 수도 있습니다 — Stable Diffusion 1.5와 Stable Diffusion XL 1.0 Base는 OnnxStream의 GitHub 저장소에서 제공된 링크를 통해 가중치를 다운로드하여 사용할 수 있습니다. 이 모든 모델을 다운로드하는 경우 SD 카드에 충분한 공간이 있는지 확인해주세요!\n\n다 되었다면, 이제 준비가 끝났습니다! Raspberry Pi에서 이미지를 생성할 준비가 된 것입니다!\n\n# 이미지 생성 중\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래의 코드 블록을 실행하여 이미지를 생성하세요:\n\n```js\ncd ~/OnnxStream/src/build/\n./sd --turbo --models-path /home/admin/stable-diffusion-xl-turbo-1.0-onnxstream --prompt \"화성에서 말을 탄 우주 비행사\" --steps 1 --output astronaut.png\n```\n\n생성하고 싶은 내용에 해당하는 프롬프트로 교체하세요. 여기서는 대표적인 우주 비행사 프롬프트를 사용했습니다. 이미지를 생성하는 데 좋아보이는 이미지를 생성하기 위해 SDXL Turbo는 많은 단계가 필요하지 않으니 단계를 1로 설정했습니다.\n\nSDXL Turbo를 제외한 다른 두 모델에는 네거티브 프롬프트를 위해 사용할 수 없지만, 생성 단계 수를 설정하는 --steps 및 무작위 시드를 설정하는 --seed와 같은 다른 인수도 전달할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델의 종류에 따라 필요한 인수가 변경될 수 있으니, SDXL Turbo 이외의 것을 사용하는 경우 전달해야 하는 인수의 전체 목록은 OnnxStream의 GitHub 리포지토리를 확인해 주세요.\n\n![image](/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_2.png)\n\n위 이미지에서 확인할 수 있듯이, 라즈베리 파이 5에서 확산 단계마다 약 1분이 소요되며, 전처리 및 디코딩을 포함하여 한 장의 이미지를 생성하는 데 약 3분이 소요됩니다.\n\n![image](/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 동일한 시드를 사용하여 1단계부터 10단계까지 동일한 프롬프트의 비교 및 진전이 있습니다. 단 한 걸음의 향상으로도 이미 생성된 이미지가 이미 매우 잘 완료되었음을 볼 수 있습니다. 이는 SDXL이나 SD1.5와는 대조적이며 해당 품질에 도달하기 위해서는 상당히 많은 단계가 필요합니다.\n\n# 결론\n\n이미지를 생성하는 데 최소한 몇 분이 걸리는 것을 감안하면, 그에 대한 사용 사례가 부족한지에 대한 질문이 떠오릅니다.\n\n![이미지](/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저에게 가장 명백하고 재미있는 사용 사례는 몇 분마다 새 이미지를 생성하는 변화무쌍한 사진 프레임입니다. 실제로 GitHub의 rvdveen이 OnnxStream을 사용한 이와 비슷한 프로젝트가 있습니다. 라즈베리 파이 제로 2 W에서 OnnxStream을 사용하여 뉴스 기사 이미지를 생성하고 전자잉크 디스플레이를 통해 사진 프레임에 표시하는 프로젝트입니다. 물론 실시간으로 보여주는 사진 프레임이 반드시 필요한 것은 아니지만, 라즈베리 파이 제로 2 W에서 이미지를 생성하는 데 약 5시간이 소요되며 SD1.5가 필요합니다. \n\n또는 로컬에서 호스팅되는 이미지 생성기를 원할 수도 있습니다. 네트워크에서 주요 계산 장치를 점유하지 않고도 양호한 품질의 이미지를 생성할 수 있습니다.\n\n라즈베리 파이에서 SDXL Turbo와 놀면서 즐기세요!\n\n참고: 저는 OnnxStream이나 StabilityAI와 제휴 관계가 없습니다. 모든 의견은 본인의 의견이며 어떤 조직도 대표하지 않습니다.","ogImage":{"url":"/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_0.png"},"coverImage":"/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch2\u003e라즈베리 파이에서 Stable Diffusion XL Turbo를 사용하여 이미지를 생성하는 방법을 배워보세요!\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e지난 기사에서는 라즈베리 파이에서 대형 언어 모델 및 비전 언어 모델을 실행하는 방법을 공유했습니다. 이번에는 LLM 또는 VLM이 아닌 이미지 생성 모델인 Stable Diffusion XL (SDXL) Turbo를 라즈베리 파이 5에서 실행할 것입니다. 또 다른 불가능한 일처럼 들리지만, 오픈 소스의 기이한 점들이 존재하고, 매우 리소스가 제한된 환경에서 SDXL Turbo 모델을 실행하는 것이 그 중 하나입니다.\u003c/p\u003e\n\u003ch1\u003eOnnxStream\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eOnnxStream은 Vito Plantamura가 만든 오픈 소스 프로젝트로, 초기 의도는 메모리 소비를 최소화하여 라즈베리 파이 제로 2에서 Stable Diffusion 1.5(SD1.5)를 실행하는 것이었습니다. 이로 인해 추론 대기 시간/처리량이 증가할 수 있지만 가능한 한 메모리 소비를 최소화하는 것이 목표입니다.\u003c/p\u003e\n\u003cp\u003e현재 상황에서 이 프로젝트는 Stable Diffusion 1.5 뿐만 아니라 Stable Diffusion XL 1.0 Base (SDXL) 및 Stable Diffusion XL Turbo 1.0도 지원하고 있습니다. 신기한 점은 GitHub 저장소에서 이미 잘 설명되어 있으므로 이 기반 기술에 대해 자세히 다루지 않겠습니다.\u003c/p\u003e\n\u003cp\u003e대신, 바로 작동하는 방법을 알아보겠습니다.\u003c/p\u003e\n\u003ch1\u003e기술적 요구 사항\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e다음만 있으면 됩니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRaspberry Pi 5 — 혹은 Raspberry Pi 4 또는 다른 Raspberry Pi가 있어도 괜찮지만 이보다 느릴 것으로 예상됩니다.\u003c/li\u003e\n\u003cli\u003eSD 카드 — 최소 16GB, 이미 Raspbian 또는 다른 Linux 배포판이 설정되어 있어야 합니다. SDXL Turbo의 무게는 약 8GB입니다.\u003c/li\u003e\n\u003cli\u003e인터넷 연결\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003eOnnxStream 설정하기\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기 안내는 GitHub 리포지토리에서 나온 것이지만, 좀 더 자세히 설명하고 있어요.\u003c/p\u003e\n\u003ch2\u003e1. XNNPack 빌드\u003c/h2\u003e\n\u003cp\u003e먼저 구글에서 제공하는 \"고효율 부동 소수점 신경망 추론 연산자\"를 제공하는 라이브러리인 XNNPack을 설치해야 해요. 다만 최신 버전을 가져오면 어떤 중대한 변경사항이 있을지 모르니까, 작성 당시에 OnnxStream 개발자가 작동되는 것을 확인한 버전을 가져와야 해요. 터미널에서 다음을 실행하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egit clone \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//github.com/google/XNNPACK.git\u003c/span\u003e\ncd \u003cspan class=\"hljs-variable constant_\"\u003eXNNPACK\u003c/span\u003e\ngit checkout 579de32260742a24166ecd13213d2e60af862675\nmkdir build\ncd build\ncmake -\u003cspan class=\"hljs-variable constant_\"\u003eDXNNPACK_BUILD_TESTS\u003c/span\u003e=\u003cspan class=\"hljs-variable constant_\"\u003eOFF\u003c/span\u003e -\u003cspan class=\"hljs-variable constant_\"\u003eDXNNPACK_BUILD_BENCHMARKS\u003c/span\u003e=\u003cspan class=\"hljs-variable constant_\"\u003eOFF\u003c/span\u003e ..\ncmake --build . --config \u003cspan class=\"hljs-title class_\"\u003eRelease\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eXNNPack을 빌드하는 데 몇 분 정도 소요될 것입니다. 커피 한 잔 마시거나 다른 일을 하세요.\u003c/p\u003e\n\u003ch2\u003e2. OnnxStream 빌드하기\u003c/h2\u003e\n\u003cp\u003e이제 OnnxStream을 빌드해야 합니다. 터미널에서 다음을 실행하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egit clone \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//github.com/vitoplantamura/OnnxStream.git\u003c/span\u003e\ncd \u003cspan class=\"hljs-title class_\"\u003eOnnxStream\u003c/span\u003e\ncd src\nmkdir build\ncd build\ncmake -\u003cspan class=\"hljs-variable constant_\"\u003eDMAX_SPEED\u003c/span\u003e=\u003cspan class=\"hljs-variable constant_\"\u003eON\u003c/span\u003e -\u003cspan class=\"hljs-variable constant_\"\u003eDXNNPACK_DIR\u003c/span\u003e=\u003cspan class=\"xml\"\u003e\u003cspan class=\"hljs-tag\"\u003e\u0026#x3C;\u003cspan class=\"hljs-name\"\u003eXNNPACK이\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003e클론된\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003e디렉토리\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003e경로\u003c/span\u003e\u003e\u003c/span\u003e ..\ncmake --build . --config Release\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003ccode\u003eDIRECTORY_WHERE_XNNPACK_WAS_CLONED\u003c/code\u003e를 XNNPack가 복제된 경로로 교체해주세요 (빌드 폴더가 아닙니다). 제 경우에는 /home/admin/XNNPACK/에 있었습니다.\u003c/p\u003e\n\u003ch2\u003e3. 모델 가중치 다운로드\u003c/h2\u003e\n\u003cp\u003e이제 SDXL Turbo 모델 가중치를 다운로드해야 합니다. 터미널에서 다음을 실행하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003egit lfs install\ngit clone --depth=\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003ehttps\u003c/span\u003e:\u003cspan class=\"hljs-comment\"\u003e//huggingface.co/AeroX2/stable-diffusion-xl-turbo-1.0-onnxstream\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아직 git-lfs를 설치하지 않았다면 먼저 설치해주세요. 모델 가중치가 상당히 크기 때문에 이전 단계보다 시간이 훨씬 더 걸릴 것입니다. 점심 시간 동안 가져가세요!\u003c/p\u003e\n\u003cp\u003e또한 지원되는 다른 두 모델을 실행할 수도 있습니다 — Stable Diffusion 1.5와 Stable Diffusion XL 1.0 Base는 OnnxStream의 GitHub 저장소에서 제공된 링크를 통해 가중치를 다운로드하여 사용할 수 있습니다. 이 모든 모델을 다운로드하는 경우 SD 카드에 충분한 공간이 있는지 확인해주세요!\u003c/p\u003e\n\u003cp\u003e다 되었다면, 이제 준비가 끝났습니다! Raspberry Pi에서 이미지를 생성할 준비가 된 것입니다!\u003c/p\u003e\n\u003ch1\u003e이미지 생성 중\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아래의 코드 블록을 실행하여 이미지를 생성하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003ecd ~\u003cspan class=\"hljs-regexp\"\u003e/OnnxStream/\u003c/span\u003esrc/build/\n./sd --turbo --models-path /home/admin/stable-diffusion-xl-turbo-\u003cspan class=\"hljs-number\"\u003e1.0\u003c/span\u003e-onnxstream --prompt \u003cspan class=\"hljs-string\"\u003e\"화성에서 말을 탄 우주 비행사\"\u003c/span\u003e --steps \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e --output astronaut.\u003cspan class=\"hljs-property\"\u003epng\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e생성하고 싶은 내용에 해당하는 프롬프트로 교체하세요. 여기서는 대표적인 우주 비행사 프롬프트를 사용했습니다. 이미지를 생성하는 데 좋아보이는 이미지를 생성하기 위해 SDXL Turbo는 많은 단계가 필요하지 않으니 단계를 1로 설정했습니다.\u003c/p\u003e\n\u003cp\u003eSDXL Turbo를 제외한 다른 두 모델에는 네거티브 프롬프트를 위해 사용할 수 없지만, 생성 단계 수를 설정하는 --steps 및 무작위 시드를 설정하는 --seed와 같은 다른 인수도 전달할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모델의 종류에 따라 필요한 인수가 변경될 수 있으니, SDXL Turbo 이외의 것을 사용하는 경우 전달해야 하는 인수의 전체 목록은 OnnxStream의 GitHub 리포지토리를 확인해 주세요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_2.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e위 이미지에서 확인할 수 있듯이, 라즈베리 파이 5에서 확산 단계마다 약 1분이 소요되며, 전처리 및 디코딩을 포함하여 한 장의 이미지를 생성하는 데 약 3분이 소요됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기 동일한 시드를 사용하여 1단계부터 10단계까지 동일한 프롬프트의 비교 및 진전이 있습니다. 단 한 걸음의 향상으로도 이미 생성된 이미지가 이미 매우 잘 완료되었음을 볼 수 있습니다. 이는 SDXL이나 SD1.5와는 대조적이며 해당 품질에 도달하기 위해서는 상당히 많은 단계가 필요합니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e이미지를 생성하는 데 최소한 몇 분이 걸리는 것을 감안하면, 그에 대한 사용 사례가 부족한지에 대한 질문이 떠오릅니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi_4.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e저에게 가장 명백하고 재미있는 사용 사례는 몇 분마다 새 이미지를 생성하는 변화무쌍한 사진 프레임입니다. 실제로 GitHub의 rvdveen이 OnnxStream을 사용한 이와 비슷한 프로젝트가 있습니다. 라즈베리 파이 제로 2 W에서 OnnxStream을 사용하여 뉴스 기사 이미지를 생성하고 전자잉크 디스플레이를 통해 사진 프레임에 표시하는 프로젝트입니다. 물론 실시간으로 보여주는 사진 프레임이 반드시 필요한 것은 아니지만, 라즈베리 파이 제로 2 W에서 이미지를 생성하는 데 약 5시간이 소요되며 SD1.5가 필요합니다.\u003c/p\u003e\n\u003cp\u003e또는 로컬에서 호스팅되는 이미지 생성기를 원할 수도 있습니다. 네트워크에서 주요 계산 장치를 점유하지 않고도 양호한 품질의 이미지를 생성할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e라즈베리 파이에서 SDXL Turbo와 놀면서 즐기세요!\u003c/p\u003e\n\u003cp\u003e참고: 저는 OnnxStream이나 StabilityAI와 제휴 관계가 없습니다. 모든 의견은 본인의 의견이며 어떤 조직도 대표하지 않습니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-22-GeneratingImageswithStableDiffusionandOnnxStreamontheRaspberryPi"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>