<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>구글의 최신 알고리즘으로 벡터 데이터베이스 검색 속도 급상승 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="구글의 최신 알고리즘으로 벡터 데이터베이스 검색 속도 급상승 | itposting" data-gatsby-head="true"/><meta property="og:title" content="구글의 최신 알고리즘으로 벡터 데이터베이스 검색 속도 급상승 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver" data-gatsby-head="true"/><meta name="twitter:title" content="구글의 최신 알고리즘으로 벡터 데이터베이스 검색 속도 급상승 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-22 21:10" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">구글의 최신 알고리즘으로 벡터 데이터베이스 검색 속도 급상승</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="구글의 최신 알고리즘으로 벡터 데이터베이스 검색 속도 급상승" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 22, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>벡터 데이터베이스는 LLM의 인기가 높아지면서 점점 더 인기를 얻고 있어요.</p>
<p>이에 대해 처음 듣는 분들을 위해, 벡터 데이터베이스는 텍스트, 이미지, 오디오, 비디오 등과 같은 실제 세계 개체의 벡터 표현인 임베딩들의 모음이에요.</p>
<p>이러한 벡터 표현은 실제 세계 개체의 특징과 의미를 연속적인 벡터 공간에 포착하는 데 도움이 돼요.</p>
<p>이 벡터들은 다양한 머신러닝 작업을 위한 추가 처리 및 애플리케이션에 사용될 수 있어요.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_0.png" alt="Vector Databases"></p>
<h1>But First, How Do Vector Databases Work Exactly?</h1>
<p>Vector databases work by storing vector data so that it can be queried and worked with efficiently.</p>
<p>Real-world entities/data points are first converted into embeddings.</p>
<div class="content-ad"></div>
<p>그럼, 효율적인 쿼리를 위해 특수화된 인덱싱 구조를 사용하여 그들을 조직화합니다.</p>
<p>예를 들어, Hierarchical Navigable Small World (HNSW) 그래프는 Pinecone, FAISS, Weaviate와 같은 다양한 현대 벡터 데이터베이스에서 사용되는 최고의 성능을 발휘하는 인덱스 중 하나입니다.</p>
<p>벡터 데이터베이스의 핵심 기능은 쿼리 벡터와 저장된 벡터 간의 유사성 검색을 수행하고 가장 유사한 벡터를 결과로 반환하는 것입니다.</p>
<p>예를 통해 이를 더 잘 이해해봅시다.</p>
<div class="content-ad"></div>
<p>여러 요리 레시피의 임베딩을 포함하는 벡터 데이터베이스를 고려해보세요.</p>
<p>"파스타 요리법은?"과 같은 질의가 수행될 때, 먼저 텍스트를 임베딩으로 변환한 다음 유사한 검색이 실행됩니다.</p>
<p>질의 임베딩에 가장 가까운 임베딩이 결과로 반환됩니다.</p>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_1.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>이 유사성 검색은 쿼리 벡터에 가장 가까운 임베딩을 찾는 Inner/ Dot product 작업을 통해 일반적으로 수행되며 이를 Maximum Inner-Product Search 또는 MIPS라고 합니다.</p>
<p>MIPS를 통해 데이터베이스에서 쿼리 벡터와 가장 큰 내적을 가진 벡터를 찾는 것이 목표입니다.</p>
<h1>그러나 벡터 데이터베이스에서의 검색은 느릴 수 있습니다</h1>
<p>데이터 세트가 너무 커지면 데이터베이스의 각각의 임베딩과 쿼리 임베딩을 비교하는 무차별 대우 방식은 비효율적일 수 있습니다.</p>
<div class="content-ad"></div>
<p>그러므로 스케일이 커지면 더 나은 유사성 검색 방법이 필요합니다.</p>
<p>정확한 최근접 이웃을 찾는 대신 주어진 쿼리에 대한 근사 최근 이웃을 찾는 여러 검색 기술이 개발되었습니다. 이러한 방법은 연산 자원과 검색 시간을 상당히 줄이기 위해 무차별 대입 방식을 사용합니다.</p>
<p>이러한 기술 중 하나는 구글 연구원들에 의해 2019년에 발표되었으며, 그들의 오픈 소스 벡터 유사성 검색 라이브러리인 ScaNN (Scalable Nearest Neighbors)에서 사용할 수 있도록 구현되었습니다.</p>
<p>이 기술은 비슷한 기능을 가진 모든 라이브러리보다 성능이 두 배 우수하다고 발견되었습니다.</p>
<div class="content-ad"></div>
<p>다음은 어떻게 작동하는지 배워봅시다.</p>
<h2>더 빠른 MIPS를 위한 방법이 발견된 과정</h2>
<p>MIPS를 가속화하는 다양한 기술은 데이터베이스에서 벡터를 압축하여 근사 내적을 빠르게 찾는 것에 관여합니다.</p>
<p>이 압축은 학습된 양자화 과정을 사용하여 수행됩니다.</p>
<div class="content-ad"></div>
<p>이 프로세스의 아이디어는 데이터베이스 내의 벡터 세트와 대략 관련된 대표 벡터 세트를 생성하는 것입니다.</p>
<p>전체적인 프로세스는 다음과 같이 작동합니다.</p>
<p>초기에 무작위로 선택된 대표 벡터 세트를 시작으로, 양자화 알고리즘은 이를 반복적으로 업데이트합니다.</p>
<p>ScaNN에서는 K-Means 클러스터링 알고리즘이 이러한 목적으로 사용됩니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_2.png" alt="Image"></p>
<p>각 단계에서 알고리즘은 양자화 오차를 최소화하려고 합니다. 이는 원래 벡터와 그들의 양자화된 표현 사이의 차이를 의미합니다 (K 평균 클러스터 중심과 유사함).</p>
<p>Google 연구자들은 이 접근 방식에서 중요한 통찰을 발견했습니다. 때로 이러한 벡터들 사이의 높은 차이가 MIPS에서 뛰어난 성능을 보일 수 있다는 것을 알게 되었습니다.</p>
<p>따라서, 이전 접근 방식처럼 이 차이/오차의 크기만을 고려하는 것이 아니라, 이 차이/오차의 방향 또한 고려하는 것이 중요합니다.</p>
<div class="content-ad"></div>
<p>그들은 병렬 양자화 오차(직교와 비교했을 때)가 원본 벡터의 더 나쁜 근사값으로 이어지는 것을 발견했습니다. 심지어 오차 크기가 낮을 때에도 마찬가지로 그렇습니다.</p>
<p>그들은 이 기술을 이방성 벡터 양자화라고 명명했고(이방성은 양 자의 서로 다른 방향으로의 변화를 의미합니다)이것이 더 빠르게 작동하는 ScaNN 라이브러리의 기반이 되었습니다.</p>
<p>이를 더 잘 이해하기 위해 아래 예제를 살펴보십시오.</p>
<p>예제에서 데이터베이스 임베딩 x1과 x2는 클러스터 센터 c1 또는 c2로 양자화됩니다. 그들의 양자화된 버전은 각각 x̃ 1과 x̃ 2라고 하며 q가 쿼리 벡터입니다.</p>
<div class="content-ad"></div>
<p>목표는 쿼리와 임베딩 <code>q, x̃ i</code>의 내적을 원래의 내적<code> q, xi</code>와 가능한 한 유사하게 만드는 것입니다.</p>
<p>임베딩에 가장 근접한 센터를 선택하는 첫 번째 접근 방식(즉, x(1)과 x(2)가 각각 c(1) 및 c(2)로 양자화됨)은 두 임베딩의 상대적인 순위를 잘못 지정합니다. 즉, <code>q</code>, x̃ 1<code>이 </code>q, x̃ 2<code>보다 더 크지만, </code>q, x1<code>이 </code>q, x2`보다 적다는 것입니다.</p>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_3.png" alt="image"></p>
<p>다음 그림에서는 방향이 양자화에 반영됩니다. 즉, x1 및 x2는 그들의 방향이 q와 평행이 아닌 직교임에도 불구하고 더 멀리 떨어져 있는 경우(더 큰 크기)에도 c1 및 c2 센터를 선택합니다.</p>
<div class="content-ad"></div>
<p>이러한 고려 사항은 알고리즘의 정확도가 높아지도록 <code>q, x1</code>, <code>q, x̃ 1</code> 및 <code>q, x2</code>, <code>q, x̃ 2</code> 간의 낮은 내적 오류를 유발합니다.</p>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_4.png" alt="image"></p>
<h1>SOAR로 벡터 검색을 더욱 빠르게 수행하세요</h1>
<p>2024년에 Google 연구원들은 SOAR: 직교성이 증폭된 잔차와 함께 넘치게 하는 새로운 접근 방식을 통해 ScaNN을 더 개선했습니다.</p>
<div class="content-ad"></div>
<p>ScaNN의 초기 버전에서는 각 벡터가 상기 설명된 양자화 접근 방식을 사용하여 정확히 한 개의 K-means 클러스터로 근사화되었습니다.</p>
<p>검색 단계에서 클러스터 내의 벡터는 쿼리 벡터와 N개의 가장 가까운 센터 중 하나였을 때만 평가되었습니다.</p>
<p>그러나 이 방식으로는 쿼리 벡터가 원본 벡터와 클러스터 센터 벡터 사이의 차이에 평행할 때 검색 단계에서 올바른 클러스터 센터를 선택하는 데 어려움이 있었음이 밝혀졌습니다.</p>
<p>이것은 ScaNN의 양자화 방법에서의 직관과 유사할 수 있지만, SOAR는 대신 검색 단계에서 이를 사용합니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_5.png" alt="image"></p>
<p>SOAR은 Redundancy 전략을 사용하여이 문제를 해결합니다.</p>
<p>원래 ScaNN 라이브러리의 경우처럼 데이터베이스의 벡터가 하나가 아닌 여러 클러스터에 할당됩니다.</p>
<p>이로 인해 주요 클러스터에 문제가 발생할 경우 검색 프로세스 중에 백업으로 작용하는 보조 클러스터가 생성됩니다. (따라서 SOAR에서 "Spilling"이라는 용어가 사용됩니다.)</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_6.png" alt="image"></p>
<p>SOAR는 중복 벡터를 보유하는 이러한 보조 클러스터 센터를 찾는 똑똑한 방법을 가지고 있습니다.</p>
<p>이는 원본 벡터와 보조 클러스터 센터 벡터 간의 차이가 쿼리 벡터에 대해 직교에 가깝다(그리고 평행하지 않다)는 것을 찾는 경향이 있습니다. (따라서 SOAR에서 Orthogonality-Amplified Residuals라는 용어의 등장입니다.)</p>
<p>이는 쿼리 q가 r(원본 벡터와 클러스터 센터 사이의 차이)와 평행일 때 검색을 실패하는 것을 피합니다.</p>
<div class="content-ad"></div>
<p>아래 예시에서 c가 기본 클러스터 센터인 경우를 보여줍니다.</p>
<p>c'가 보조 클러스터 센터로 선택되면(r'(원래 벡터와 보조 클러스터 센터 간의 차이) 쿼리 q와 평행하기 때문에 검색 단계 중에 더 높은 실패율이 발생하여 비효율적인 중복이 발생합니다.</p>
<p>그러나 c"가 보조 클러스터 센터로 선택되면 r"이 쿼리 q와 거의 직교하기 때문에 검색 단계 중에 더 낮은 실패율을 보입니다.</p>
<div class="content-ad"></div>
<p>이는 SOAR 뒤에 있는 기본 원칙인 효과적인 중복성에 이르게 됩니다.</p>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_8.png" alt="Image"></p>
<h2>SOAR는 성능이 얼마나 우수한가요?</h2>
<p>ScaNN에 도입되었을 때, SOAR는 다른 유사한 라이브러리와 비교할 때 가장 작은 메모리 풋프린트를 가지면서도 극도로 빠른 성능을 제공합니다.</p>
<div class="content-ad"></div>
<p>ScaNN의 성능을 맞추기 위해 유사한 라이브러리들이 10배 이상의 메모리와 50배 이상의 인덱싱 시간을 요구하는 것이 잘되어 좋네요!</p>
<p><img src="/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_9.png" alt="image"></p>
<h1>ScaNN을 어떻게 사용할 수 있나요?</h1>
<p>현재 ScaNN은 오픈 소스 라이브러리로, 파이썬 프로젝트에서 pip를 사용하여 설치할 수 있습니다.</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">pip install scann
</code></pre>
<p>Vertex AI 벡터 검색의 일환으로 사용할 수도 있으며, AlloyDB(AlloyDB 인덱스용 ScaNN으로)에서도 사용할 수 있습니다.</p>
<h1>더 읽어보기</h1>
<ul>
<li>ScaNN의 GitHub 저장소</li>
<li>ArXiv에 게시된 'Anisotropic Vector Quantization으로 대규모 추론 가속화' 논문</li>
<li>ArXiv에 게시된 'SOAR: 근사 최근접 이웃 검색을 위한 개선된 인덱싱' 논문</li>
<li>Google Research 블로그 글 '효율적인 벡터 유사성 검색 ScaNN 공개'</li>
<li>Google Research 블로그 글 'ScaNN으로 더 빠른 벡터 검색을 위한 새로운 알고리즘 SOAR 공개'</li>
</ul>
<div class="content-ad"></div>
<p>벡터 데이터베이스 작업 경험은 어떠셨나요? 즐겨 사용하는 것이 있나요? 아래 댓글로 알려주세요!</p>
<h2>나의 작업과 연결 유지를 원하신다면 여기에 나의 메일링 리스트 링크를 확인해주세요 —</h2>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"구글의 최신 알고리즘으로 벡터 데이터베이스 검색 속도 급상승","description":"","date":"2024-06-22 21:10","slug":"2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver","content":"\n\n벡터 데이터베이스는 LLM의 인기가 높아지면서 점점 더 인기를 얻고 있어요.\n\n이에 대해 처음 듣는 분들을 위해, 벡터 데이터베이스는 텍스트, 이미지, 오디오, 비디오 등과 같은 실제 세계 개체의 벡터 표현인 임베딩들의 모음이에요.\n\n이러한 벡터 표현은 실제 세계 개체의 특징과 의미를 연속적인 벡터 공간에 포착하는 데 도움이 돼요.\n\n이 벡터들은 다양한 머신러닝 작업을 위한 추가 처리 및 애플리케이션에 사용될 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Vector Databases](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_0.png)\n\n# But First, How Do Vector Databases Work Exactly?\n\nVector databases work by storing vector data so that it can be queried and worked with efficiently.\n\nReal-world entities/data points are first converted into embeddings.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그럼, 효율적인 쿼리를 위해 특수화된 인덱싱 구조를 사용하여 그들을 조직화합니다.\n\n예를 들어, Hierarchical Navigable Small World (HNSW) 그래프는 Pinecone, FAISS, Weaviate와 같은 다양한 현대 벡터 데이터베이스에서 사용되는 최고의 성능을 발휘하는 인덱스 중 하나입니다.\n\n벡터 데이터베이스의 핵심 기능은 쿼리 벡터와 저장된 벡터 간의 유사성 검색을 수행하고 가장 유사한 벡터를 결과로 반환하는 것입니다.\n\n예를 통해 이를 더 잘 이해해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여러 요리 레시피의 임베딩을 포함하는 벡터 데이터베이스를 고려해보세요.\n\n\"파스타 요리법은?\"과 같은 질의가 수행될 때, 먼저 텍스트를 임베딩으로 변환한 다음 유사한 검색이 실행됩니다.\n\n질의 임베딩에 가장 가까운 임베딩이 결과로 반환됩니다.\n\n![이미지](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 유사성 검색은 쿼리 벡터에 가장 가까운 임베딩을 찾는 Inner/ Dot product 작업을 통해 일반적으로 수행되며 이를 Maximum Inner-Product Search 또는 MIPS라고 합니다.\n\nMIPS를 통해 데이터베이스에서 쿼리 벡터와 가장 큰 내적을 가진 벡터를 찾는 것이 목표입니다.\n\n# 그러나 벡터 데이터베이스에서의 검색은 느릴 수 있습니다\n\n데이터 세트가 너무 커지면 데이터베이스의 각각의 임베딩과 쿼리 임베딩을 비교하는 무차별 대우 방식은 비효율적일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러므로 스케일이 커지면 더 나은 유사성 검색 방법이 필요합니다.\n\n정확한 최근접 이웃을 찾는 대신 주어진 쿼리에 대한 근사 최근 이웃을 찾는 여러 검색 기술이 개발되었습니다. 이러한 방법은 연산 자원과 검색 시간을 상당히 줄이기 위해 무차별 대입 방식을 사용합니다.\n\n이러한 기술 중 하나는 구글 연구원들에 의해 2019년에 발표되었으며, 그들의 오픈 소스 벡터 유사성 검색 라이브러리인 ScaNN (Scalable Nearest Neighbors)에서 사용할 수 있도록 구현되었습니다.\n\n이 기술은 비슷한 기능을 가진 모든 라이브러리보다 성능이 두 배 우수하다고 발견되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 어떻게 작동하는지 배워봅시다.\n\n## 더 빠른 MIPS를 위한 방법이 발견된 과정\n\nMIPS를 가속화하는 다양한 기술은 데이터베이스에서 벡터를 압축하여 근사 내적을 빠르게 찾는 것에 관여합니다.\n\n이 압축은 학습된 양자화 과정을 사용하여 수행됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 프로세스의 아이디어는 데이터베이스 내의 벡터 세트와 대략 관련된 대표 벡터 세트를 생성하는 것입니다.\n\n전체적인 프로세스는 다음과 같이 작동합니다.\n\n초기에 무작위로 선택된 대표 벡터 세트를 시작으로, 양자화 알고리즘은 이를 반복적으로 업데이트합니다.\n\nScaNN에서는 K-Means 클러스터링 알고리즘이 이러한 목적으로 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_2.png)\n\n각 단계에서 알고리즘은 양자화 오차를 최소화하려고 합니다. 이는 원래 벡터와 그들의 양자화된 표현 사이의 차이를 의미합니다 (K 평균 클러스터 중심과 유사함).\n\nGoogle 연구자들은 이 접근 방식에서 중요한 통찰을 발견했습니다. 때로 이러한 벡터들 사이의 높은 차이가 MIPS에서 뛰어난 성능을 보일 수 있다는 것을 알게 되었습니다.\n\n따라서, 이전 접근 방식처럼 이 차이/오차의 크기만을 고려하는 것이 아니라, 이 차이/오차의 방향 또한 고려하는 것이 중요합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그들은 병렬 양자화 오차(직교와 비교했을 때)가 원본 벡터의 더 나쁜 근사값으로 이어지는 것을 발견했습니다. 심지어 오차 크기가 낮을 때에도 마찬가지로 그렇습니다.\n\n그들은 이 기술을 이방성 벡터 양자화라고 명명했고(이방성은 양 자의 서로 다른 방향으로의 변화를 의미합니다)이것이 더 빠르게 작동하는 ScaNN 라이브러리의 기반이 되었습니다.\n\n이를 더 잘 이해하기 위해 아래 예제를 살펴보십시오.\n\n예제에서 데이터베이스 임베딩 x1과 x2는 클러스터 센터 c1 또는 c2로 양자화됩니다. 그들의 양자화된 버전은 각각 x̃ 1과 x̃ 2라고 하며 q가 쿼리 벡터입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n목표는 쿼리와 임베딩 `q, x̃ i`의 내적을 원래의 내적` q, xi`와 가능한 한 유사하게 만드는 것입니다.\n\n임베딩에 가장 근접한 센터를 선택하는 첫 번째 접근 방식(즉, x(1)과 x(2)가 각각 c(1) 및 c(2)로 양자화됨)은 두 임베딩의 상대적인 순위를 잘못 지정합니다. 즉, `q`, x̃ 1`이 `q, x̃ 2`보다 더 크지만, `q, x1`이 `q, x2`보다 적다는 것입니다.\n\n![image](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_3.png)\n\n다음 그림에서는 방향이 양자화에 반영됩니다. 즉, x1 및 x2는 그들의 방향이 q와 평행이 아닌 직교임에도 불구하고 더 멀리 떨어져 있는 경우(더 큰 크기)에도 c1 및 c2 센터를 선택합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 고려 사항은 알고리즘의 정확도가 높아지도록 `q, x1`, `q, x̃ 1` 및 `q, x2`, `q, x̃ 2` 간의 낮은 내적 오류를 유발합니다.\n\n![image](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_4.png)\n\n# SOAR로 벡터 검색을 더욱 빠르게 수행하세요\n\n2024년에 Google 연구원들은 SOAR: 직교성이 증폭된 잔차와 함께 넘치게 하는 새로운 접근 방식을 통해 ScaNN을 더 개선했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nScaNN의 초기 버전에서는 각 벡터가 상기 설명된 양자화 접근 방식을 사용하여 정확히 한 개의 K-means 클러스터로 근사화되었습니다.\n\n검색 단계에서 클러스터 내의 벡터는 쿼리 벡터와 N개의 가장 가까운 센터 중 하나였을 때만 평가되었습니다.\n\n그러나 이 방식으로는 쿼리 벡터가 원본 벡터와 클러스터 센터 벡터 사이의 차이에 평행할 때 검색 단계에서 올바른 클러스터 센터를 선택하는 데 어려움이 있었음이 밝혀졌습니다.\n\n이것은 ScaNN의 양자화 방법에서의 직관과 유사할 수 있지만, SOAR는 대신 검색 단계에서 이를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_5.png)\n\nSOAR은 Redundancy 전략을 사용하여이 문제를 해결합니다.\n\n원래 ScaNN 라이브러리의 경우처럼 데이터베이스의 벡터가 하나가 아닌 여러 클러스터에 할당됩니다.\n\n이로 인해 주요 클러스터에 문제가 발생할 경우 검색 프로세스 중에 백업으로 작용하는 보조 클러스터가 생성됩니다. (따라서 SOAR에서 \"Spilling\"이라는 용어가 사용됩니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_6.png)\n\nSOAR는 중복 벡터를 보유하는 이러한 보조 클러스터 센터를 찾는 똑똑한 방법을 가지고 있습니다.\n\n이는 원본 벡터와 보조 클러스터 센터 벡터 간의 차이가 쿼리 벡터에 대해 직교에 가깝다(그리고 평행하지 않다)는 것을 찾는 경향이 있습니다. (따라서 SOAR에서 Orthogonality-Amplified Residuals라는 용어의 등장입니다.)\n\n이는 쿼리 q가 r(원본 벡터와 클러스터 센터 사이의 차이)와 평행일 때 검색을 실패하는 것을 피합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 예시에서 c가 기본 클러스터 센터인 경우를 보여줍니다.\n\nc'가 보조 클러스터 센터로 선택되면(r'(원래 벡터와 보조 클러스터 센터 간의 차이) 쿼리 q와 평행하기 때문에 검색 단계 중에 더 높은 실패율이 발생하여 비효율적인 중복이 발생합니다.\n\n그러나 c\"가 보조 클러스터 센터로 선택되면 r\"이 쿼리 q와 거의 직교하기 때문에 검색 단계 중에 더 낮은 실패율을 보입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이는 SOAR 뒤에 있는 기본 원칙인 효과적인 중복성에 이르게 됩니다.\n\n![Image](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_8.png)\n\n## SOAR는 성능이 얼마나 우수한가요?\n\nScaNN에 도입되었을 때, SOAR는 다른 유사한 라이브러리와 비교할 때 가장 작은 메모리 풋프린트를 가지면서도 극도로 빠른 성능을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nScaNN의 성능을 맞추기 위해 유사한 라이브러리들이 10배 이상의 메모리와 50배 이상의 인덱싱 시간을 요구하는 것이 잘되어 좋네요!\n\n![image](/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_9.png)\n\n# ScaNN을 어떻게 사용할 수 있나요?\n\n현재 ScaNN은 오픈 소스 라이브러리로, 파이썬 프로젝트에서 pip를 사용하여 설치할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\npip install scann\n```\n\nVertex AI 벡터 검색의 일환으로 사용할 수도 있으며, AlloyDB(AlloyDB 인덱스용 ScaNN으로)에서도 사용할 수 있습니다.\n\n# 더 읽어보기\n\n- ScaNN의 GitHub 저장소\n- ArXiv에 게시된 'Anisotropic Vector Quantization으로 대규모 추론 가속화' 논문\n- ArXiv에 게시된 'SOAR: 근사 최근접 이웃 검색을 위한 개선된 인덱싱' 논문\n- Google Research 블로그 글 '효율적인 벡터 유사성 검색 ScaNN 공개'\n- Google Research 블로그 글 'ScaNN으로 더 빠른 벡터 검색을 위한 새로운 알고리즘 SOAR 공개'\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n벡터 데이터베이스 작업 경험은 어떠셨나요? 즐겨 사용하는 것이 있나요? 아래 댓글로 알려주세요!\n\n## 나의 작업과 연결 유지를 원하신다면 여기에 나의 메일링 리스트 링크를 확인해주세요 —","ogImage":{"url":"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_0.png"},"coverImage":"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e벡터 데이터베이스는 LLM의 인기가 높아지면서 점점 더 인기를 얻고 있어요.\u003c/p\u003e\n\u003cp\u003e이에 대해 처음 듣는 분들을 위해, 벡터 데이터베이스는 텍스트, 이미지, 오디오, 비디오 등과 같은 실제 세계 개체의 벡터 표현인 임베딩들의 모음이에요.\u003c/p\u003e\n\u003cp\u003e이러한 벡터 표현은 실제 세계 개체의 특징과 의미를 연속적인 벡터 공간에 포착하는 데 도움이 돼요.\u003c/p\u003e\n\u003cp\u003e이 벡터들은 다양한 머신러닝 작업을 위한 추가 처리 및 애플리케이션에 사용될 수 있어요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_0.png\" alt=\"Vector Databases\"\u003e\u003c/p\u003e\n\u003ch1\u003eBut First, How Do Vector Databases Work Exactly?\u003c/h1\u003e\n\u003cp\u003eVector databases work by storing vector data so that it can be queried and worked with efficiently.\u003c/p\u003e\n\u003cp\u003eReal-world entities/data points are first converted into embeddings.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그럼, 효율적인 쿼리를 위해 특수화된 인덱싱 구조를 사용하여 그들을 조직화합니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, Hierarchical Navigable Small World (HNSW) 그래프는 Pinecone, FAISS, Weaviate와 같은 다양한 현대 벡터 데이터베이스에서 사용되는 최고의 성능을 발휘하는 인덱스 중 하나입니다.\u003c/p\u003e\n\u003cp\u003e벡터 데이터베이스의 핵심 기능은 쿼리 벡터와 저장된 벡터 간의 유사성 검색을 수행하고 가장 유사한 벡터를 결과로 반환하는 것입니다.\u003c/p\u003e\n\u003cp\u003e예를 통해 이를 더 잘 이해해봅시다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여러 요리 레시피의 임베딩을 포함하는 벡터 데이터베이스를 고려해보세요.\u003c/p\u003e\n\u003cp\u003e\"파스타 요리법은?\"과 같은 질의가 수행될 때, 먼저 텍스트를 임베딩으로 변환한 다음 유사한 검색이 실행됩니다.\u003c/p\u003e\n\u003cp\u003e질의 임베딩에 가장 가까운 임베딩이 결과로 반환됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 유사성 검색은 쿼리 벡터에 가장 가까운 임베딩을 찾는 Inner/ Dot product 작업을 통해 일반적으로 수행되며 이를 Maximum Inner-Product Search 또는 MIPS라고 합니다.\u003c/p\u003e\n\u003cp\u003eMIPS를 통해 데이터베이스에서 쿼리 벡터와 가장 큰 내적을 가진 벡터를 찾는 것이 목표입니다.\u003c/p\u003e\n\u003ch1\u003e그러나 벡터 데이터베이스에서의 검색은 느릴 수 있습니다\u003c/h1\u003e\n\u003cp\u003e데이터 세트가 너무 커지면 데이터베이스의 각각의 임베딩과 쿼리 임베딩을 비교하는 무차별 대우 방식은 비효율적일 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그러므로 스케일이 커지면 더 나은 유사성 검색 방법이 필요합니다.\u003c/p\u003e\n\u003cp\u003e정확한 최근접 이웃을 찾는 대신 주어진 쿼리에 대한 근사 최근 이웃을 찾는 여러 검색 기술이 개발되었습니다. 이러한 방법은 연산 자원과 검색 시간을 상당히 줄이기 위해 무차별 대입 방식을 사용합니다.\u003c/p\u003e\n\u003cp\u003e이러한 기술 중 하나는 구글 연구원들에 의해 2019년에 발표되었으며, 그들의 오픈 소스 벡터 유사성 검색 라이브러리인 ScaNN (Scalable Nearest Neighbors)에서 사용할 수 있도록 구현되었습니다.\u003c/p\u003e\n\u003cp\u003e이 기술은 비슷한 기능을 가진 모든 라이브러리보다 성능이 두 배 우수하다고 발견되었습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e다음은 어떻게 작동하는지 배워봅시다.\u003c/p\u003e\n\u003ch2\u003e더 빠른 MIPS를 위한 방법이 발견된 과정\u003c/h2\u003e\n\u003cp\u003eMIPS를 가속화하는 다양한 기술은 데이터베이스에서 벡터를 압축하여 근사 내적을 빠르게 찾는 것에 관여합니다.\u003c/p\u003e\n\u003cp\u003e이 압축은 학습된 양자화 과정을 사용하여 수행됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 프로세스의 아이디어는 데이터베이스 내의 벡터 세트와 대략 관련된 대표 벡터 세트를 생성하는 것입니다.\u003c/p\u003e\n\u003cp\u003e전체적인 프로세스는 다음과 같이 작동합니다.\u003c/p\u003e\n\u003cp\u003e초기에 무작위로 선택된 대표 벡터 세트를 시작으로, 양자화 알고리즘은 이를 반복적으로 업데이트합니다.\u003c/p\u003e\n\u003cp\u003eScaNN에서는 K-Means 클러스터링 알고리즘이 이러한 목적으로 사용됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_2.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e각 단계에서 알고리즘은 양자화 오차를 최소화하려고 합니다. 이는 원래 벡터와 그들의 양자화된 표현 사이의 차이를 의미합니다 (K 평균 클러스터 중심과 유사함).\u003c/p\u003e\n\u003cp\u003eGoogle 연구자들은 이 접근 방식에서 중요한 통찰을 발견했습니다. 때로 이러한 벡터들 사이의 높은 차이가 MIPS에서 뛰어난 성능을 보일 수 있다는 것을 알게 되었습니다.\u003c/p\u003e\n\u003cp\u003e따라서, 이전 접근 방식처럼 이 차이/오차의 크기만을 고려하는 것이 아니라, 이 차이/오차의 방향 또한 고려하는 것이 중요합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그들은 병렬 양자화 오차(직교와 비교했을 때)가 원본 벡터의 더 나쁜 근사값으로 이어지는 것을 발견했습니다. 심지어 오차 크기가 낮을 때에도 마찬가지로 그렇습니다.\u003c/p\u003e\n\u003cp\u003e그들은 이 기술을 이방성 벡터 양자화라고 명명했고(이방성은 양 자의 서로 다른 방향으로의 변화를 의미합니다)이것이 더 빠르게 작동하는 ScaNN 라이브러리의 기반이 되었습니다.\u003c/p\u003e\n\u003cp\u003e이를 더 잘 이해하기 위해 아래 예제를 살펴보십시오.\u003c/p\u003e\n\u003cp\u003e예제에서 데이터베이스 임베딩 x1과 x2는 클러스터 센터 c1 또는 c2로 양자화됩니다. 그들의 양자화된 버전은 각각 x̃ 1과 x̃ 2라고 하며 q가 쿼리 벡터입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e목표는 쿼리와 임베딩 \u003ccode\u003eq, x̃ i\u003c/code\u003e의 내적을 원래의 내적\u003ccode\u003e q, xi\u003c/code\u003e와 가능한 한 유사하게 만드는 것입니다.\u003c/p\u003e\n\u003cp\u003e임베딩에 가장 근접한 센터를 선택하는 첫 번째 접근 방식(즉, x(1)과 x(2)가 각각 c(1) 및 c(2)로 양자화됨)은 두 임베딩의 상대적인 순위를 잘못 지정합니다. 즉, \u003ccode\u003eq\u003c/code\u003e, x̃ 1\u003ccode\u003e이 \u003c/code\u003eq, x̃ 2\u003ccode\u003e보다 더 크지만, \u003c/code\u003eq, x1\u003ccode\u003e이 \u003c/code\u003eq, x2`보다 적다는 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e다음 그림에서는 방향이 양자화에 반영됩니다. 즉, x1 및 x2는 그들의 방향이 q와 평행이 아닌 직교임에도 불구하고 더 멀리 떨어져 있는 경우(더 큰 크기)에도 c1 및 c2 센터를 선택합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이러한 고려 사항은 알고리즘의 정확도가 높아지도록 \u003ccode\u003eq, x1\u003c/code\u003e, \u003ccode\u003eq, x̃ 1\u003c/code\u003e 및 \u003ccode\u003eq, x2\u003c/code\u003e, \u003ccode\u003eq, x̃ 2\u003c/code\u003e 간의 낮은 내적 오류를 유발합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_4.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch1\u003eSOAR로 벡터 검색을 더욱 빠르게 수행하세요\u003c/h1\u003e\n\u003cp\u003e2024년에 Google 연구원들은 SOAR: 직교성이 증폭된 잔차와 함께 넘치게 하는 새로운 접근 방식을 통해 ScaNN을 더 개선했습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eScaNN의 초기 버전에서는 각 벡터가 상기 설명된 양자화 접근 방식을 사용하여 정확히 한 개의 K-means 클러스터로 근사화되었습니다.\u003c/p\u003e\n\u003cp\u003e검색 단계에서 클러스터 내의 벡터는 쿼리 벡터와 N개의 가장 가까운 센터 중 하나였을 때만 평가되었습니다.\u003c/p\u003e\n\u003cp\u003e그러나 이 방식으로는 쿼리 벡터가 원본 벡터와 클러스터 센터 벡터 사이의 차이에 평행할 때 검색 단계에서 올바른 클러스터 센터를 선택하는 데 어려움이 있었음이 밝혀졌습니다.\u003c/p\u003e\n\u003cp\u003e이것은 ScaNN의 양자화 방법에서의 직관과 유사할 수 있지만, SOAR는 대신 검색 단계에서 이를 사용합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_5.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eSOAR은 Redundancy 전략을 사용하여이 문제를 해결합니다.\u003c/p\u003e\n\u003cp\u003e원래 ScaNN 라이브러리의 경우처럼 데이터베이스의 벡터가 하나가 아닌 여러 클러스터에 할당됩니다.\u003c/p\u003e\n\u003cp\u003e이로 인해 주요 클러스터에 문제가 발생할 경우 검색 프로세스 중에 백업으로 작용하는 보조 클러스터가 생성됩니다. (따라서 SOAR에서 \"Spilling\"이라는 용어가 사용됩니다.)\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_6.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eSOAR는 중복 벡터를 보유하는 이러한 보조 클러스터 센터를 찾는 똑똑한 방법을 가지고 있습니다.\u003c/p\u003e\n\u003cp\u003e이는 원본 벡터와 보조 클러스터 센터 벡터 간의 차이가 쿼리 벡터에 대해 직교에 가깝다(그리고 평행하지 않다)는 것을 찾는 경향이 있습니다. (따라서 SOAR에서 Orthogonality-Amplified Residuals라는 용어의 등장입니다.)\u003c/p\u003e\n\u003cp\u003e이는 쿼리 q가 r(원본 벡터와 클러스터 센터 사이의 차이)와 평행일 때 검색을 실패하는 것을 피합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아래 예시에서 c가 기본 클러스터 센터인 경우를 보여줍니다.\u003c/p\u003e\n\u003cp\u003ec'가 보조 클러스터 센터로 선택되면(r'(원래 벡터와 보조 클러스터 센터 간의 차이) 쿼리 q와 평행하기 때문에 검색 단계 중에 더 높은 실패율이 발생하여 비효율적인 중복이 발생합니다.\u003c/p\u003e\n\u003cp\u003e그러나 c\"가 보조 클러스터 센터로 선택되면 r\"이 쿼리 q와 거의 직교하기 때문에 검색 단계 중에 더 낮은 실패율을 보입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이는 SOAR 뒤에 있는 기본 원칙인 효과적인 중복성에 이르게 됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_8.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003ch2\u003eSOAR는 성능이 얼마나 우수한가요?\u003c/h2\u003e\n\u003cp\u003eScaNN에 도입되었을 때, SOAR는 다른 유사한 라이브러리와 비교할 때 가장 작은 메모리 풋프린트를 가지면서도 극도로 빠른 성능을 제공합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eScaNN의 성능을 맞추기 위해 유사한 라이브러리들이 10배 이상의 메모리와 50배 이상의 인덱싱 시간을 요구하는 것이 잘되어 좋네요!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver_9.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch1\u003eScaNN을 어떻게 사용할 수 있나요?\u003c/h1\u003e\n\u003cp\u003e현재 ScaNN은 오픈 소스 라이브러리로, 파이썬 프로젝트에서 pip를 사용하여 설치할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003epip install scann\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eVertex AI 벡터 검색의 일환으로 사용할 수도 있으며, AlloyDB(AlloyDB 인덱스용 ScaNN으로)에서도 사용할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e더 읽어보기\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eScaNN의 GitHub 저장소\u003c/li\u003e\n\u003cli\u003eArXiv에 게시된 'Anisotropic Vector Quantization으로 대규모 추론 가속화' 논문\u003c/li\u003e\n\u003cli\u003eArXiv에 게시된 'SOAR: 근사 최근접 이웃 검색을 위한 개선된 인덱싱' 논문\u003c/li\u003e\n\u003cli\u003eGoogle Research 블로그 글 '효율적인 벡터 유사성 검색 ScaNN 공개'\u003c/li\u003e\n\u003cli\u003eGoogle Research 블로그 글 'ScaNN으로 더 빠른 벡터 검색을 위한 새로운 알고리즘 SOAR 공개'\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e벡터 데이터베이스 작업 경험은 어떠셨나요? 즐겨 사용하는 것이 있나요? 아래 댓글로 알려주세요!\u003c/p\u003e\n\u003ch2\u003e나의 작업과 연결 유지를 원하신다면 여기에 나의 메일링 리스트 링크를 확인해주세요 —\u003c/h2\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-22-GooglesNewAlgorithmsJustMadeSearchingVectorDatabasesFasterThanEver"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>