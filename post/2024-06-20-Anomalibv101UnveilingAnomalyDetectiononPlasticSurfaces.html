<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Anomalib v101 플라스틱 표면의 이상 감지 공개 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Anomalib v101 플라스틱 표면의 이상 감지 공개 | itposting" data-gatsby-head="true"/><meta property="og:title" content="Anomalib v101 플라스틱 표면의 이상 감지 공개 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces" data-gatsby-head="true"/><meta name="twitter:title" content="Anomalib v101 플라스틱 표면의 이상 감지 공개 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-20 18:04" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Anomalib v101 플라스틱 표면의 이상 감지 공개</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Anomalib v101 플라스틱 표면의 이상 감지 공개" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 20, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h1>소개</h1>
<p><img src="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_0.png" alt="이미지"></p>
<p>컴퓨터 비전에서의 이상 감지는 긴 여정을 거쳤습니다. 다양한 이상 감지 작업이 이미 현실 응용 프로그램에서 사용되어 왔습니다. 이상 탐지의 비지도 학습 솔루션은 제품화에 도움이 되었습니다. 이상 데이터가 필요하지 않고 정상 샘플만을 사용하여 이미지의 섬세한 차이점을 식별하는 모델을 훈련할 수 있습니다.</p>
<p>본 문서에서는 OpenVINO의 Anomalib¹를 사용하여 이상 감지의 또 다른 사용 사례를 살펴보겠습니다. 다음 섹션에서는 훈련 및 테스트 단계를 다룹니다. Anomalib를 사용한 이미지 이상 감지의 최신 자습서를 찾고 계시다면 정확한 위치에 계십니다.</p>
<div class="content-ad"></div>
<h1>실험</h1>
<p>이 섹션에서는 실행 환경, 훈련에 사용된 데이터 세트, 그리고 평가를 진행하는 모델 훈련 단계에 대해 알아보겠습니다.</p>
<h2>환경</h2>
<ul>
<li>운영 체제: Windows 10 / MacOS Sonoma</li>
<li>Python: v3.10</li>
<li>Anomalib: v1.0.1</li>
</ul>
<div class="content-ad"></div>
<h2>데이터셋</h2>
<p>이 실험에서 사용한 데이터셋은 플라스틱 표면의 패치 세트입니다. 그림 1에서는 몇 가지 샘플이 제공되는데, 첫 번째 행에는 4개의 정상 샘플이 나오고 두 번째 행에는 4개의 이상 샘플이 있습니다. 전체 훈련 데이터셋은 다음과 같습니다.</p>
<ul>
<li>정상(이상 없는) 샘플 x 50</li>
<li>비정상(이상이 있는) 샘플 x 20, 반사, 홀로그램, 얼룩, 혹은 스트로크로 인해 영향을 받음</li>
</ul>
<p>단, 훈련에는 정상 50개의 케이스만 참여한다는 점을 유의해 주세요. 비정상 샘플은 검증에 사용되며 모델 수렴에 기여하지 않습니다.</p>
<div class="content-ad"></div>
<h2>데이터셋</h2>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> anomalib <span class="hljs-keyword">import</span> <span class="hljs-title class_">TaskType</span>
<span class="hljs-keyword">from</span> anomalib.<span class="hljs-property">models</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">EfficientAd</span>
<span class="hljs-keyword">from</span> anomalib.<span class="hljs-property">engine</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">Engine</span>
<span class="hljs-keyword">from</span> anomalib.<span class="hljs-property">deploy</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">ExportType</span>
<span class="hljs-keyword">from</span> anomalib.<span class="hljs-property">callbacks</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">ModelCheckpoint</span>
<span class="hljs-keyword">from</span> anomalib.<span class="hljs-property">data</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">Folder</span>

def <span class="hljs-title function_">train</span>():
    # 데이터 모듈 생성
    datamodule = <span class="hljs-title class_">Folder</span>(
        name=<span class="hljs-string">"card_stain"</span>,
        root=<span class="hljs-string">"anomalib_surface/train"</span>,
        normal_dir=<span class="hljs-string">"normal"</span>,
        abnormal_dir=<span class="hljs-string">"abnormal"</span>,
        task=<span class="hljs-title class_">TaskType</span>.<span class="hljs-property">CLASSIFICATION</span>
    )
    datamodule.<span class="hljs-title function_">setup</span>()

    model = <span class="hljs-title class_">EfficientAd</span>()
    engine = <span class="hljs-title class_">Engine</span>(max_epochs=<span class="hljs-number">350</span>, task=<span class="hljs-title class_">TaskType</span>.<span class="hljs-property">CLASSIFICATION</span>,
                    callbacks=[<span class="hljs-title class_">ModelCheckpoint</span>(dirpath=<span class="hljs-string">'checkpoint/'</span>, every_n_epochs=<span class="hljs-number">10</span>, save_last=<span class="hljs-title class_">True</span>)])

    # logger.<span class="hljs-title function_">info</span>(<span class="hljs-string">"체크포인트 경로: {}"</span>.<span class="hljs-title function_">format</span>(engine.<span class="hljs-property">trainer</span>.<span class="hljs-property">default_root_dir</span>))

    # 모델 훈련
    engine.<span class="hljs-title function_">fit</span>(datamodule=datamodule, model=model)
    engine.<span class="hljs-title function_">export</span>(export_type=<span class="hljs-title class_">ExportType</span>.<span class="hljs-property">OPENVINO</span>,
                  model=model,
                  export_root=<span class="hljs-string">'anomalib_weight'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">"__main__"</span>:
    <span class="hljs-title function_">train</span>()
</code></pre>
<p>위는 Anomalib을 기반으로 한 훈련 스크립트로, 데이터셋, 네트워크, 트레이너로 구성됩니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_1.png" alt="Anomalib"></p>
<p>Anomalib에서는 Visa, MVTec 및 Kolektor와 같은 내장 데이터 세트뿐만 아니라 Folder 클래스를 사용하여 사용자 정의 데이터 세트를 정의할 수 있는 옵션이 있습니다. Figure 2에서 보이는 대로 데이터 디렉토리를 전달하여 데이터 개체를 초기화합니다.</p>
<p>데이터 디렉토리는 root 디렉토리 root와 두 가지 필수 하위 폴더인 normal_dir, abnormal_dir로 구성되어 있으며 각각 정상 및 비정상 샘플을 저장합니다. 세분화 작업을 실행하는 경우 비정상 사례의 마스크를 위한 추가 폴더가 필요합니다.</p>
<p>Network</p>
<div class="content-ad"></div>
<p>Anomalib은 이상 감지에서 발행된 최신 네트워크를 통한 지속적인 업데이트로 유명합니다. Anomalib v1.0.1에는 이미지 이상의 17개 네트워크가 구현되어 있습니다. 이 연습에서는 2022년에 출시된 강력한 네트워크 중 하나인 EfficientAD를 선택했습니다. 이 네트워크는 높은 정확도를 보이는데 그치지 않고 효율성이 뛰어나어 GPU 없이도 학습이 가능합니다.</p>
<p>Trainer</p>
<p><img src="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_2.png" alt="Trainer"></p>
<p>Anomalib에서 학습 과정은 다른 딥러닝 프레임워크와 마찬가지로 트레이너 클래스 엔진에 의해 이끌립니다. 우리는 에포크 수, 결과를 저장할 기본 디렉토리, 콜백 및 작업 유형과 같은 학습 매개변수를 구성할 수 있습니다. 이 과정에서 두 가지 주요 기능이 있습니다:</p>
<div class="content-ad"></div>
<p>Engine.fit(): 정의된 네트워크와 데이터셋을 기반으로 학습 프로세스를 시작합니다. 학습 과정에서 처음 세 번의 에포크에 대한 로그가 그림 3에 제공됩니다. 각 에포크의 끝에는 다음 정보가 출력됩니다:</p>
<ul>
<li>학습 단계: teacher-student, teacher-autoencoder, autoencoder-student distill 학습의 단계.</li>
<li>AUROC 및 F1 점수: 학습 중 검증 결과.</li>
<li>손실: teacher-student, teacher-autoencoder, autoencoder-student distill 학습의 손실.</li>
</ul>
<p>EfficientAD 내의 세 가지 학습 내용에 대한 자세한 내용은 EfficientAD 내부의 세 네트워크(teacher, student, autoencoder)를 다루는 다른 이야기²를 참조해주세요.</p>
<p>Engine.export(): 학습 후 결과를 지정된 형식(OpenVINO/torch/onnx)으로 내보냅니다. 우리는 이 연습에서 IR 모델 및 메타데이터 파일을 포함하는 OpenVINO 형식(ExportType.OPENVINO)을 선택했습니다. 추가적으로, 학습된 가중치를 저장할 대상 디렉토리를 export_root 매개변수로 전달할 수 있습니다.</p>
<div class="content-ad"></div>
<h2>추론</h2>
<pre><code class="hljs language-js">inferencer = <span class="hljs-title class_">OpenVINOInferencer</span>(
        path=<span class="hljs-string">'anomalib_weight/weights/openvino/model.bin'</span>,  # <span class="hljs-title class_">OpenVINO</span> <span class="hljs-variable constant_">IR</span> 모델의 경로.
        metadata=<span class="hljs-string">'anomalib_weight/weights/openvino/metadata.json'</span>,  # 메타데이터 파일의 경로.
        device=<span class="hljs-string">"CPU"</span>,  # 인텔 <span class="hljs-variable constant_">CPU</span>에서 실행하고 싶습니다.
        task=<span class="hljs-title class_">TaskType</span>.<span class="hljs-property">CLASSIFICATION</span>
    )
logger.<span class="hljs-title function_">info</span>(<span class="hljs-string">'모델을 성공적으로 로드했습니다.'</span>)

test_dir = <span class="hljs-string">'anomalib_surface/test/normal/'</span>
img_paths = <span class="hljs-title function_">list</span>(<span class="hljs-title class_">Path</span>(test_dir).<span class="hljs-title function_">rglob</span>(<span class="hljs-string">'*.jpg'</span>)) + <span class="hljs-title function_">list</span>(<span class="hljs-title class_">Path</span>(test_dir).<span class="hljs-title function_">rglob</span>(<span class="hljs-string">'*.jpeg'</span>))
img_paths = <span class="hljs-title function_">list</span>(<span class="hljs-title function_">map</span>(str, img_paths))
img_paths.<span class="hljs-title function_">sort</span>()

<span class="hljs-keyword">for</span> img_path <span class="hljs-keyword">in</span> <span class="hljs-attr">img_paths</span>:
    img_name = os.<span class="hljs-property">path</span>.<span class="hljs-title function_">basename</span>(img_path)
    predictions = inferencer.<span class="hljs-title function_">predict</span>(img_path)
    logger.<span class="hljs-title function_">info</span>(<span class="hljs-string">'{}: {}, {:.4f}'</span>.<span class="hljs-title function_">format</span>(img_name, predictions.<span class="hljs-property">pred_label</span>, predictions.<span class="hljs-property">pred_score</span>))
</code></pre>
<p>추론은 학습보다는 비교적 간단합니다. Anomalib에서 각 ExportType에는 해당 추론 클래스가 있습니다. 우리는 OpenVINO를 출력 형식으로 선택했으므로 OpenVINOInferencer 추론 클래스의 생성자에서 내보낸 모델을로드합니다. .predict() 함수는 예측을 수행하고 결과를 출력 객체로 반환합니다. 우리는 pred_label 및 pred_score에서 예측된 점수와 레이블에 액세스할 수 있습니다. 이상 점수는 [0,1] 범위 내의 정규화된 값이며, 점수가 높을수록 이미지에 이상이 포함될 가능성이 더 높습니다.</p>
<h2>결과</h2>
<div class="content-ad"></div>
<p>모델 평가를 위해 16개의 샘플을 수집했습니다. 이상한 샘플들은 얼룩, 홀로그램, 그리고 스트로크가 있지만 정상 케이스에는 인식할 수 없는 이상이 포함되어 있지 않습니다. 예측된 이상 점수와 해당하는 샘플은 아래 그림 4에서 확인할 수 있습니다. 각 범주에서 모델에 의해 예측된 이상 점수를 기준으로 오름차순으로 정렬되어 있습니다.</p>
<p><img src="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_3.png" alt="Figure 4"></p>
<p>더불어, 점수 분포를 조사하기 위해 선 그래프를 그렸습니다. 정상과 이상 점수는 각각 녹색과 빨강으로 표시되어 있습니다. 두 클래스를 완벽하게 분리할 수 있는 단일 값을 기준으로 구분할 수 있는 임계값은 없다는 것을 볼 수 있습니다. 즉, 우리는 잘못된 분류를 제로로 만들어주는 임계값을 찾을 수 없습니다. 우리가 갖고 있는 최상의 임계값은 [0.49, 0.5] 범위 내에 있으며, 거짓 거부와 거짓 수락을 균형있게 유지하려면 이 범위 안에서 선택해야 합니다. 거짓 수락률과 거짓 거부율은 모두 25% (=2/8) 입니다.</p>
<p><img src="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_4.png" alt="Figure 5"></p>
<div class="content-ad"></div>
<p>한편, 수동 조작의 존재 여부를 식별할 기회를 발견하기를 원합니다. 다른 네 개의 샘플을 조작하고 원본 이미지와 수정된 이미지에 대해 추론을 실행합니다. 예상대로, 변조 후 이상 점수가 증가하는 것을 확인할 수 있습니다. 아래 그림에는 이미지와 해당 점수가 제공됩니다.</p>
<p><img src="/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_5.png" alt="이미지"></p>
<p>본 글의 동기는 실제 사용 사례에서 이상 탐지를 수행하는 방법을 공유하는 것이기 때문에 데이터 확대, 오류 분석 및 매개변수 조정과 같은 최적화 작업에 대한 추가 노력은 하지 않습니다.</p>
<p>요약하면, 훈련한 EfficentAD 모델이 목적을 제대로 수행합니다. 그림 5에서 두 클래스의 분포가 뚜렷하게 분리되어 있는 것을 확인할 수 있으며, 수동으로 조작된 이미지의 이상 점수가 그림 6에서 더 높게 나타납니다.</p>
<div class="content-ad"></div>
<h1>요약</h1>
<p>이 글에서는 플라스틱 표면에 여러 이상을 식별하는 이상 탐지 연습을 보여드립니다. Anomalib 덕분에 간결한 스크립트로 이상을 탐지하는 여행을 떠날 수 있습니다. 이 연습에 사용된 데이터셋을 다른 비즈니스에 맞춘 선호 데이터셋으로 간단히 대체하여 또 다른 맞춤형 모델을 훈련할 수 있습니다.</p>
<p>이 튜토리얼이 유용하길 바라며 읽어 주셔서 감사합니다. 피드백과 코멘트를 기다립니다.</p>
<h1>참고</h1>
<div class="content-ad"></div>
<p>[1] Anomalib 공식 저장소
[2] EFFICIENTAD 탐구: 밀리초 수준의 정확한 시각적 이상 감지: 간단한 개요</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Anomalib v101 플라스틱 표면의 이상 감지 공개","description":"","date":"2024-06-20 18:04","slug":"2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces","content":"\n\n# 소개\n\n![이미지](/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_0.png)\n\n컴퓨터 비전에서의 이상 감지는 긴 여정을 거쳤습니다. 다양한 이상 감지 작업이 이미 현실 응용 프로그램에서 사용되어 왔습니다. 이상 탐지의 비지도 학습 솔루션은 제품화에 도움이 되었습니다. 이상 데이터가 필요하지 않고 정상 샘플만을 사용하여 이미지의 섬세한 차이점을 식별하는 모델을 훈련할 수 있습니다.\n\n본 문서에서는 OpenVINO의 Anomalib¹를 사용하여 이상 감지의 또 다른 사용 사례를 살펴보겠습니다. 다음 섹션에서는 훈련 및 테스트 단계를 다룹니다. Anomalib를 사용한 이미지 이상 감지의 최신 자습서를 찾고 계시다면 정확한 위치에 계십니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 실험\n\n이 섹션에서는 실행 환경, 훈련에 사용된 데이터 세트, 그리고 평가를 진행하는 모델 훈련 단계에 대해 알아보겠습니다.\n\n## 환경\n\n- 운영 체제: Windows 10 / MacOS Sonoma\n- Python: v3.10\n- Anomalib: v1.0.1\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터셋\n\n이 실험에서 사용한 데이터셋은 플라스틱 표면의 패치 세트입니다. 그림 1에서는 몇 가지 샘플이 제공되는데, 첫 번째 행에는 4개의 정상 샘플이 나오고 두 번째 행에는 4개의 이상 샘플이 있습니다. 전체 훈련 데이터셋은 다음과 같습니다.\n\n- 정상(이상 없는) 샘플 x 50\n- 비정상(이상이 있는) 샘플 x 20, 반사, 홀로그램, 얼룩, 혹은 스트로크로 인해 영향을 받음\n\n단, 훈련에는 정상 50개의 케이스만 참여한다는 점을 유의해 주세요. 비정상 샘플은 검증에 사용되며 모델 수렴에 기여하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 데이터셋\n\n```js\nfrom anomalib import TaskType\nfrom anomalib.models import EfficientAd\nfrom anomalib.engine import Engine\nfrom anomalib.deploy import ExportType\nfrom anomalib.callbacks import ModelCheckpoint\nfrom anomalib.data import Folder\n\ndef train():\n    # 데이터 모듈 생성\n    datamodule = Folder(\n        name=\"card_stain\",\n        root=\"anomalib_surface/train\",\n        normal_dir=\"normal\",\n        abnormal_dir=\"abnormal\",\n        task=TaskType.CLASSIFICATION\n    )\n    datamodule.setup()\n\n    model = EfficientAd()\n    engine = Engine(max_epochs=350, task=TaskType.CLASSIFICATION,\n                    callbacks=[ModelCheckpoint(dirpath='checkpoint/', every_n_epochs=10, save_last=True)])\n\n    # logger.info(\"체크포인트 경로: {}\".format(engine.trainer.default_root_dir))\n\n    # 모델 훈련\n    engine.fit(datamodule=datamodule, model=model)\n    engine.export(export_type=ExportType.OPENVINO,\n                  model=model,\n                  export_root='anomalib_weight')\n\nif __name__ == \"__main__\":\n    train()\n```\n\n위는 Anomalib을 기반으로 한 훈련 스크립트로, 데이터셋, 네트워크, 트레이너로 구성됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Anomalib](/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_1.png)\n\nAnomalib에서는 Visa, MVTec 및 Kolektor와 같은 내장 데이터 세트뿐만 아니라 Folder 클래스를 사용하여 사용자 정의 데이터 세트를 정의할 수 있는 옵션이 있습니다. Figure 2에서 보이는 대로 데이터 디렉토리를 전달하여 데이터 개체를 초기화합니다.\n\n데이터 디렉토리는 root 디렉토리 root와 두 가지 필수 하위 폴더인 normal_dir, abnormal_dir로 구성되어 있으며 각각 정상 및 비정상 샘플을 저장합니다. 세분화 작업을 실행하는 경우 비정상 사례의 마스크를 위한 추가 폴더가 필요합니다.\n\nNetwork\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAnomalib은 이상 감지에서 발행된 최신 네트워크를 통한 지속적인 업데이트로 유명합니다. Anomalib v1.0.1에는 이미지 이상의 17개 네트워크가 구현되어 있습니다. 이 연습에서는 2022년에 출시된 강력한 네트워크 중 하나인 EfficientAD를 선택했습니다. 이 네트워크는 높은 정확도를 보이는데 그치지 않고 효율성이 뛰어나어 GPU 없이도 학습이 가능합니다.\n\nTrainer\n\n![Trainer](/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_2.png)\n\nAnomalib에서 학습 과정은 다른 딥러닝 프레임워크와 마찬가지로 트레이너 클래스 엔진에 의해 이끌립니다. 우리는 에포크 수, 결과를 저장할 기본 디렉토리, 콜백 및 작업 유형과 같은 학습 매개변수를 구성할 수 있습니다. 이 과정에서 두 가지 주요 기능이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEngine.fit(): 정의된 네트워크와 데이터셋을 기반으로 학습 프로세스를 시작합니다. 학습 과정에서 처음 세 번의 에포크에 대한 로그가 그림 3에 제공됩니다. 각 에포크의 끝에는 다음 정보가 출력됩니다:\n\n- 학습 단계: teacher-student, teacher-autoencoder, autoencoder-student distill 학습의 단계.\n- AUROC 및 F1 점수: 학습 중 검증 결과.\n- 손실: teacher-student, teacher-autoencoder, autoencoder-student distill 학습의 손실.\n\nEfficientAD 내의 세 가지 학습 내용에 대한 자세한 내용은 EfficientAD 내부의 세 네트워크(teacher, student, autoencoder)를 다루는 다른 이야기²를 참조해주세요.\n\nEngine.export(): 학습 후 결과를 지정된 형식(OpenVINO/torch/onnx)으로 내보냅니다. 우리는 이 연습에서 IR 모델 및 메타데이터 파일을 포함하는 OpenVINO 형식(ExportType.OPENVINO)을 선택했습니다. 추가적으로, 학습된 가중치를 저장할 대상 디렉토리를 export_root 매개변수로 전달할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 추론\n\n```js\ninferencer = OpenVINOInferencer(\n        path='anomalib_weight/weights/openvino/model.bin',  # OpenVINO IR 모델의 경로.\n        metadata='anomalib_weight/weights/openvino/metadata.json',  # 메타데이터 파일의 경로.\n        device=\"CPU\",  # 인텔 CPU에서 실행하고 싶습니다.\n        task=TaskType.CLASSIFICATION\n    )\nlogger.info('모델을 성공적으로 로드했습니다.')\n\ntest_dir = 'anomalib_surface/test/normal/'\nimg_paths = list(Path(test_dir).rglob('*.jpg')) + list(Path(test_dir).rglob('*.jpeg'))\nimg_paths = list(map(str, img_paths))\nimg_paths.sort()\n\nfor img_path in img_paths:\n    img_name = os.path.basename(img_path)\n    predictions = inferencer.predict(img_path)\n    logger.info('{}: {}, {:.4f}'.format(img_name, predictions.pred_label, predictions.pred_score))\n```\n\n추론은 학습보다는 비교적 간단합니다. Anomalib에서 각 ExportType에는 해당 추론 클래스가 있습니다. 우리는 OpenVINO를 출력 형식으로 선택했으므로 OpenVINOInferencer 추론 클래스의 생성자에서 내보낸 모델을로드합니다. .predict() 함수는 예측을 수행하고 결과를 출력 객체로 반환합니다. 우리는 pred_label 및 pred_score에서 예측된 점수와 레이블에 액세스할 수 있습니다. 이상 점수는 [0,1] 범위 내의 정규화된 값이며, 점수가 높을수록 이미지에 이상이 포함될 가능성이 더 높습니다.\n\n## 결과\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델 평가를 위해 16개의 샘플을 수집했습니다. 이상한 샘플들은 얼룩, 홀로그램, 그리고 스트로크가 있지만 정상 케이스에는 인식할 수 없는 이상이 포함되어 있지 않습니다. 예측된 이상 점수와 해당하는 샘플은 아래 그림 4에서 확인할 수 있습니다. 각 범주에서 모델에 의해 예측된 이상 점수를 기준으로 오름차순으로 정렬되어 있습니다.\n\n![Figure 4](/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_3.png)\n\n더불어, 점수 분포를 조사하기 위해 선 그래프를 그렸습니다. 정상과 이상 점수는 각각 녹색과 빨강으로 표시되어 있습니다. 두 클래스를 완벽하게 분리할 수 있는 단일 값을 기준으로 구분할 수 있는 임계값은 없다는 것을 볼 수 있습니다. 즉, 우리는 잘못된 분류를 제로로 만들어주는 임계값을 찾을 수 없습니다. 우리가 갖고 있는 최상의 임계값은 [0.49, 0.5] 범위 내에 있으며, 거짓 거부와 거짓 수락을 균형있게 유지하려면 이 범위 안에서 선택해야 합니다. 거짓 수락률과 거짓 거부율은 모두 25% (=2/8) 입니다.\n\n![Figure 5](/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한편, 수동 조작의 존재 여부를 식별할 기회를 발견하기를 원합니다. 다른 네 개의 샘플을 조작하고 원본 이미지와 수정된 이미지에 대해 추론을 실행합니다. 예상대로, 변조 후 이상 점수가 증가하는 것을 확인할 수 있습니다. 아래 그림에는 이미지와 해당 점수가 제공됩니다.\n\n![이미지](/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_5.png)\n\n본 글의 동기는 실제 사용 사례에서 이상 탐지를 수행하는 방법을 공유하는 것이기 때문에 데이터 확대, 오류 분석 및 매개변수 조정과 같은 최적화 작업에 대한 추가 노력은 하지 않습니다.\n\n요약하면, 훈련한 EfficentAD 모델이 목적을 제대로 수행합니다. 그림 5에서 두 클래스의 분포가 뚜렷하게 분리되어 있는 것을 확인할 수 있으며, 수동으로 조작된 이미지의 이상 점수가 그림 6에서 더 높게 나타납니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 요약\n\n이 글에서는 플라스틱 표면에 여러 이상을 식별하는 이상 탐지 연습을 보여드립니다. Anomalib 덕분에 간결한 스크립트로 이상을 탐지하는 여행을 떠날 수 있습니다. 이 연습에 사용된 데이터셋을 다른 비즈니스에 맞춘 선호 데이터셋으로 간단히 대체하여 또 다른 맞춤형 모델을 훈련할 수 있습니다.\n\n이 튜토리얼이 유용하길 바라며 읽어 주셔서 감사합니다. 피드백과 코멘트를 기다립니다.\n\n# 참고\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n[1] Anomalib 공식 저장소\n[2] EFFICIENTAD 탐구: 밀리초 수준의 정확한 시각적 이상 감지: 간단한 개요","ogImage":{"url":"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_0.png"},"coverImage":"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch1\u003e소개\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e컴퓨터 비전에서의 이상 감지는 긴 여정을 거쳤습니다. 다양한 이상 감지 작업이 이미 현실 응용 프로그램에서 사용되어 왔습니다. 이상 탐지의 비지도 학습 솔루션은 제품화에 도움이 되었습니다. 이상 데이터가 필요하지 않고 정상 샘플만을 사용하여 이미지의 섬세한 차이점을 식별하는 모델을 훈련할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e본 문서에서는 OpenVINO의 Anomalib¹를 사용하여 이상 감지의 또 다른 사용 사례를 살펴보겠습니다. 다음 섹션에서는 훈련 및 테스트 단계를 다룹니다. Anomalib를 사용한 이미지 이상 감지의 최신 자습서를 찾고 계시다면 정확한 위치에 계십니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e실험\u003c/h1\u003e\n\u003cp\u003e이 섹션에서는 실행 환경, 훈련에 사용된 데이터 세트, 그리고 평가를 진행하는 모델 훈련 단계에 대해 알아보겠습니다.\u003c/p\u003e\n\u003ch2\u003e환경\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e운영 체제: Windows 10 / MacOS Sonoma\u003c/li\u003e\n\u003cli\u003ePython: v3.10\u003c/li\u003e\n\u003cli\u003eAnomalib: v1.0.1\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e데이터셋\u003c/h2\u003e\n\u003cp\u003e이 실험에서 사용한 데이터셋은 플라스틱 표면의 패치 세트입니다. 그림 1에서는 몇 가지 샘플이 제공되는데, 첫 번째 행에는 4개의 정상 샘플이 나오고 두 번째 행에는 4개의 이상 샘플이 있습니다. 전체 훈련 데이터셋은 다음과 같습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e정상(이상 없는) 샘플 x 50\u003c/li\u003e\n\u003cli\u003e비정상(이상이 있는) 샘플 x 20, 반사, 홀로그램, 얼룩, 혹은 스트로크로 인해 영향을 받음\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e단, 훈련에는 정상 50개의 케이스만 참여한다는 점을 유의해 주세요. 비정상 샘플은 검증에 사용되며 모델 수렴에 기여하지 않습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e데이터셋\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e anomalib \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eTaskType\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e anomalib.\u003cspan class=\"hljs-property\"\u003emodels\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eEfficientAd\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e anomalib.\u003cspan class=\"hljs-property\"\u003eengine\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eEngine\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e anomalib.\u003cspan class=\"hljs-property\"\u003edeploy\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eExportType\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e anomalib.\u003cspan class=\"hljs-property\"\u003ecallbacks\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eModelCheckpoint\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e anomalib.\u003cspan class=\"hljs-property\"\u003edata\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eFolder\u003c/span\u003e\n\ndef \u003cspan class=\"hljs-title function_\"\u003etrain\u003c/span\u003e():\n    # 데이터 모듈 생성\n    datamodule = \u003cspan class=\"hljs-title class_\"\u003eFolder\u003c/span\u003e(\n        name=\u003cspan class=\"hljs-string\"\u003e\"card_stain\"\u003c/span\u003e,\n        root=\u003cspan class=\"hljs-string\"\u003e\"anomalib_surface/train\"\u003c/span\u003e,\n        normal_dir=\u003cspan class=\"hljs-string\"\u003e\"normal\"\u003c/span\u003e,\n        abnormal_dir=\u003cspan class=\"hljs-string\"\u003e\"abnormal\"\u003c/span\u003e,\n        task=\u003cspan class=\"hljs-title class_\"\u003eTaskType\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eCLASSIFICATION\u003c/span\u003e\n    )\n    datamodule.\u003cspan class=\"hljs-title function_\"\u003esetup\u003c/span\u003e()\n\n    model = \u003cspan class=\"hljs-title class_\"\u003eEfficientAd\u003c/span\u003e()\n    engine = \u003cspan class=\"hljs-title class_\"\u003eEngine\u003c/span\u003e(max_epochs=\u003cspan class=\"hljs-number\"\u003e350\u003c/span\u003e, task=\u003cspan class=\"hljs-title class_\"\u003eTaskType\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eCLASSIFICATION\u003c/span\u003e,\n                    callbacks=[\u003cspan class=\"hljs-title class_\"\u003eModelCheckpoint\u003c/span\u003e(dirpath=\u003cspan class=\"hljs-string\"\u003e'checkpoint/'\u003c/span\u003e, every_n_epochs=\u003cspan class=\"hljs-number\"\u003e10\u003c/span\u003e, save_last=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)])\n\n    # logger.\u003cspan class=\"hljs-title function_\"\u003einfo\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"체크포인트 경로: {}\"\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eformat\u003c/span\u003e(engine.\u003cspan class=\"hljs-property\"\u003etrainer\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003edefault_root_dir\u003c/span\u003e))\n\n    # 모델 훈련\n    engine.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(datamodule=datamodule, model=model)\n    engine.\u003cspan class=\"hljs-title function_\"\u003eexport\u003c/span\u003e(export_type=\u003cspan class=\"hljs-title class_\"\u003eExportType\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eOPENVINO\u003c/span\u003e,\n                  model=model,\n                  export_root=\u003cspan class=\"hljs-string\"\u003e'anomalib_weight'\u003c/span\u003e)\n\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e __name__ == \u003cspan class=\"hljs-string\"\u003e\"__main__\"\u003c/span\u003e:\n    \u003cspan class=\"hljs-title function_\"\u003etrain\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e위는 Anomalib을 기반으로 한 훈련 스크립트로, 데이터셋, 네트워크, 트레이너로 구성됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_1.png\" alt=\"Anomalib\"\u003e\u003c/p\u003e\n\u003cp\u003eAnomalib에서는 Visa, MVTec 및 Kolektor와 같은 내장 데이터 세트뿐만 아니라 Folder 클래스를 사용하여 사용자 정의 데이터 세트를 정의할 수 있는 옵션이 있습니다. Figure 2에서 보이는 대로 데이터 디렉토리를 전달하여 데이터 개체를 초기화합니다.\u003c/p\u003e\n\u003cp\u003e데이터 디렉토리는 root 디렉토리 root와 두 가지 필수 하위 폴더인 normal_dir, abnormal_dir로 구성되어 있으며 각각 정상 및 비정상 샘플을 저장합니다. 세분화 작업을 실행하는 경우 비정상 사례의 마스크를 위한 추가 폴더가 필요합니다.\u003c/p\u003e\n\u003cp\u003eNetwork\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eAnomalib은 이상 감지에서 발행된 최신 네트워크를 통한 지속적인 업데이트로 유명합니다. Anomalib v1.0.1에는 이미지 이상의 17개 네트워크가 구현되어 있습니다. 이 연습에서는 2022년에 출시된 강력한 네트워크 중 하나인 EfficientAD를 선택했습니다. 이 네트워크는 높은 정확도를 보이는데 그치지 않고 효율성이 뛰어나어 GPU 없이도 학습이 가능합니다.\u003c/p\u003e\n\u003cp\u003eTrainer\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_2.png\" alt=\"Trainer\"\u003e\u003c/p\u003e\n\u003cp\u003eAnomalib에서 학습 과정은 다른 딥러닝 프레임워크와 마찬가지로 트레이너 클래스 엔진에 의해 이끌립니다. 우리는 에포크 수, 결과를 저장할 기본 디렉토리, 콜백 및 작업 유형과 같은 학습 매개변수를 구성할 수 있습니다. 이 과정에서 두 가지 주요 기능이 있습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eEngine.fit(): 정의된 네트워크와 데이터셋을 기반으로 학습 프로세스를 시작합니다. 학습 과정에서 처음 세 번의 에포크에 대한 로그가 그림 3에 제공됩니다. 각 에포크의 끝에는 다음 정보가 출력됩니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e학습 단계: teacher-student, teacher-autoencoder, autoencoder-student distill 학습의 단계.\u003c/li\u003e\n\u003cli\u003eAUROC 및 F1 점수: 학습 중 검증 결과.\u003c/li\u003e\n\u003cli\u003e손실: teacher-student, teacher-autoencoder, autoencoder-student distill 학습의 손실.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEfficientAD 내의 세 가지 학습 내용에 대한 자세한 내용은 EfficientAD 내부의 세 네트워크(teacher, student, autoencoder)를 다루는 다른 이야기²를 참조해주세요.\u003c/p\u003e\n\u003cp\u003eEngine.export(): 학습 후 결과를 지정된 형식(OpenVINO/torch/onnx)으로 내보냅니다. 우리는 이 연습에서 IR 모델 및 메타데이터 파일을 포함하는 OpenVINO 형식(ExportType.OPENVINO)을 선택했습니다. 추가적으로, 학습된 가중치를 저장할 대상 디렉토리를 export_root 매개변수로 전달할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e추론\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003einferencer = \u003cspan class=\"hljs-title class_\"\u003eOpenVINOInferencer\u003c/span\u003e(\n        path=\u003cspan class=\"hljs-string\"\u003e'anomalib_weight/weights/openvino/model.bin'\u003c/span\u003e,  # \u003cspan class=\"hljs-title class_\"\u003eOpenVINO\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eIR\u003c/span\u003e 모델의 경로.\n        metadata=\u003cspan class=\"hljs-string\"\u003e'anomalib_weight/weights/openvino/metadata.json'\u003c/span\u003e,  # 메타데이터 파일의 경로.\n        device=\u003cspan class=\"hljs-string\"\u003e\"CPU\"\u003c/span\u003e,  # 인텔 \u003cspan class=\"hljs-variable constant_\"\u003eCPU\u003c/span\u003e에서 실행하고 싶습니다.\n        task=\u003cspan class=\"hljs-title class_\"\u003eTaskType\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eCLASSIFICATION\u003c/span\u003e\n    )\nlogger.\u003cspan class=\"hljs-title function_\"\u003einfo\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'모델을 성공적으로 로드했습니다.'\u003c/span\u003e)\n\ntest_dir = \u003cspan class=\"hljs-string\"\u003e'anomalib_surface/test/normal/'\u003c/span\u003e\nimg_paths = \u003cspan class=\"hljs-title function_\"\u003elist\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003ePath\u003c/span\u003e(test_dir).\u003cspan class=\"hljs-title function_\"\u003erglob\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'*.jpg'\u003c/span\u003e)) + \u003cspan class=\"hljs-title function_\"\u003elist\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003ePath\u003c/span\u003e(test_dir).\u003cspan class=\"hljs-title function_\"\u003erglob\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'*.jpeg'\u003c/span\u003e))\nimg_paths = \u003cspan class=\"hljs-title function_\"\u003elist\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003emap\u003c/span\u003e(str, img_paths))\nimg_paths.\u003cspan class=\"hljs-title function_\"\u003esort\u003c/span\u003e()\n\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e img_path \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eimg_paths\u003c/span\u003e:\n    img_name = os.\u003cspan class=\"hljs-property\"\u003epath\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ebasename\u003c/span\u003e(img_path)\n    predictions = inferencer.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(img_path)\n    logger.\u003cspan class=\"hljs-title function_\"\u003einfo\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'{}: {}, {:.4f}'\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eformat\u003c/span\u003e(img_name, predictions.\u003cspan class=\"hljs-property\"\u003epred_label\u003c/span\u003e, predictions.\u003cspan class=\"hljs-property\"\u003epred_score\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e추론은 학습보다는 비교적 간단합니다. Anomalib에서 각 ExportType에는 해당 추론 클래스가 있습니다. 우리는 OpenVINO를 출력 형식으로 선택했으므로 OpenVINOInferencer 추론 클래스의 생성자에서 내보낸 모델을로드합니다. .predict() 함수는 예측을 수행하고 결과를 출력 객체로 반환합니다. 우리는 pred_label 및 pred_score에서 예측된 점수와 레이블에 액세스할 수 있습니다. 이상 점수는 [0,1] 범위 내의 정규화된 값이며, 점수가 높을수록 이미지에 이상이 포함될 가능성이 더 높습니다.\u003c/p\u003e\n\u003ch2\u003e결과\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모델 평가를 위해 16개의 샘플을 수집했습니다. 이상한 샘플들은 얼룩, 홀로그램, 그리고 스트로크가 있지만 정상 케이스에는 인식할 수 없는 이상이 포함되어 있지 않습니다. 예측된 이상 점수와 해당하는 샘플은 아래 그림 4에서 확인할 수 있습니다. 각 범주에서 모델에 의해 예측된 이상 점수를 기준으로 오름차순으로 정렬되어 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_3.png\" alt=\"Figure 4\"\u003e\u003c/p\u003e\n\u003cp\u003e더불어, 점수 분포를 조사하기 위해 선 그래프를 그렸습니다. 정상과 이상 점수는 각각 녹색과 빨강으로 표시되어 있습니다. 두 클래스를 완벽하게 분리할 수 있는 단일 값을 기준으로 구분할 수 있는 임계값은 없다는 것을 볼 수 있습니다. 즉, 우리는 잘못된 분류를 제로로 만들어주는 임계값을 찾을 수 없습니다. 우리가 갖고 있는 최상의 임계값은 [0.49, 0.5] 범위 내에 있으며, 거짓 거부와 거짓 수락을 균형있게 유지하려면 이 범위 안에서 선택해야 합니다. 거짓 수락률과 거짓 거부율은 모두 25% (=2/8) 입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_4.png\" alt=\"Figure 5\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e한편, 수동 조작의 존재 여부를 식별할 기회를 발견하기를 원합니다. 다른 네 개의 샘플을 조작하고 원본 이미지와 수정된 이미지에 대해 추론을 실행합니다. 예상대로, 변조 후 이상 점수가 증가하는 것을 확인할 수 있습니다. 아래 그림에는 이미지와 해당 점수가 제공됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces_5.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e본 글의 동기는 실제 사용 사례에서 이상 탐지를 수행하는 방법을 공유하는 것이기 때문에 데이터 확대, 오류 분석 및 매개변수 조정과 같은 최적화 작업에 대한 추가 노력은 하지 않습니다.\u003c/p\u003e\n\u003cp\u003e요약하면, 훈련한 EfficentAD 모델이 목적을 제대로 수행합니다. 그림 5에서 두 클래스의 분포가 뚜렷하게 분리되어 있는 것을 확인할 수 있으며, 수동으로 조작된 이미지의 이상 점수가 그림 6에서 더 높게 나타납니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e요약\u003c/h1\u003e\n\u003cp\u003e이 글에서는 플라스틱 표면에 여러 이상을 식별하는 이상 탐지 연습을 보여드립니다. Anomalib 덕분에 간결한 스크립트로 이상을 탐지하는 여행을 떠날 수 있습니다. 이 연습에 사용된 데이터셋을 다른 비즈니스에 맞춘 선호 데이터셋으로 간단히 대체하여 또 다른 맞춤형 모델을 훈련할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이 튜토리얼이 유용하길 바라며 읽어 주셔서 감사합니다. 피드백과 코멘트를 기다립니다.\u003c/p\u003e\n\u003ch1\u003e참고\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e[1] Anomalib 공식 저장소\n[2] EFFICIENTAD 탐구: 밀리초 수준의 정확한 시각적 이상 감지: 간단한 개요\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-20-Anomalibv101UnveilingAnomalyDetectiononPlasticSurfaces"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>