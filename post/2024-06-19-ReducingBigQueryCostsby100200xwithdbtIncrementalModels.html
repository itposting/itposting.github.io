<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>BigQuery 비용을 dbt 증분 모델로 100-200배 절감하기 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="BigQuery 비용을 dbt 증분 모델로 100-200배 절감하기 | itposting" data-gatsby-head="true"/><meta property="og:title" content="BigQuery 비용을 dbt 증분 모델로 100-200배 절감하기 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels" data-gatsby-head="true"/><meta name="twitter:title" content="BigQuery 비용을 dbt 증분 모델로 100-200배 절감하기 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 16:23" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">BigQuery 비용을 dbt 증분 모델로 100-200배 절감하기</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="BigQuery 비용을 dbt 증분 모델로 100-200배 절감하기" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">8<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>템퍼스(Temporus)에서 제 팀이 다루는 많은 모델은 크지만 "빅 데이터" 수준은 아닙니다. 보통 우리의 테이블은 수억 행 정도를 갖고 있으며, 가끔 10억 행을 넘기기도 하지만 성능에 대해 걱정할 만큼 자주 발생하지는 않습니다. 그러나 최근에 쿼리 중 하나가 2시간 후에 타임 아웃되었고, 한 테이블이 각 실행에 거의 9,000 슬롯 시간을 사용하고 있다는 것을 깨달았습니다.</p>
<p>결국 데이터 로드 접근 방식을 변경하여 슬롯 사용량을 8,970시간에서 1.4시간으로 줄였습니다. 앞으로 몇 달 동안 다른 데이터 마트에서도 높은 성능의 점진적 모델을 전개할 예정입니다. 아래에서는 발생한 문제와 그 해결 방법에 대해 설명하겠습니다.</p>
<p>제 팀이 다루는 대부분의 데이터는 구조화되지 않은 텍스트입니다. 해당 텍스트를 분류하기 위해 알고리즘을 실행하면 구조화되지 않은 텍스트의 하나의 항목이 이름이 지정된 entity(개체)의 수십 행으로 팽창될 수 있습니다.</p>
<p>여러 해 동안 소스 데이터가 빅 데이터에서 Big Data로 커졌습니다. 수십억 건의 구조화되지 않은 텍스트 페이지와 그 결과로 더 많은 행의 테이블 데이터가 포함되어 있습니다. 우리가 많은 양의 데이터를 생성하고 있기 때문에, dbt에서 일반적으로 사용하는 완전 갱신(full-refresh) 방식에서 벗어나 점진적인 방식을 활용해야 한다고 가정했었으나, 그로 인한 결과를 고려하지 않았습니다.</p>
<div class="content-ad"></div>
<p>우리가 dbt 제한 시간인 2시간을 초과하면서, 우리는 원시 예측 이후의 테이블을 완전히 잘라내고 로드하는 현재 방식을 다시 검토해야 했습니다.</p>
<h1>문제 해결 진단</h1>
<p>우리의 테이블을 생성하는 SQL 쿼리는 절대 효율적이 아니었습니다 — 문제가 심각해지기 전까지는 그것을 깨닫지 못했습니다. 하지만 어떤 부분이 비효율적이었을까요? 쿼리를 수정함으로써 성능을 개선할 수 있을까요? 아니면 우리 전체 접근법을 바꿔야 했을까요?</p>
<p>아래는 우리가 실행하던 쿼리의 단순화된 버전입니다 —</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">{
  <span class="hljs-title function_">config</span>(
    alias=<span class="hljs-string">"ner_model"</span>,
    cluster_by=[<span class="hljs-string">"label"</span>],
    materialized=<span class="hljs-string">"incremental"</span>,
    schema=<span class="hljs-string">"warehouse"</span>,
    unique_key=[<span class="hljs-string">"attachment_id"</span>, <span class="hljs-string">"page_index"</span>, <span class="hljs-string">"ent_char_start"</span>]
  )
}

<span class="hljs-variable constant_">WITH</span>

lake <span class="hljs-variable constant_">AS</span> (
  <span class="hljs-variable constant_">SELECT</span>
    *
  <span class="hljs-variable constant_">FROM</span> { <span class="hljs-title function_">source</span>(<span class="hljs-string">'lake'</span>, <span class="hljs-string">'source_ner_predictions'</span>) }
  { <span class="hljs-keyword">if</span> <span class="hljs-title function_">is_incremental</span>() }
    <span class="hljs-variable constant_">WHERE</span> _predicted_at > (<span class="hljs-variable constant_">SELECT</span> <span class="hljs-title function_">MAX</span>(_predicted_at) <span class="hljs-variable constant_">FROM</span> { <span class="hljs-variable language_">this</span> } )
  { endif }
),

-- <span class="hljs-variable constant_">TMO</span> 우선적 리터럴 형식을 위한 열 추가
<span class="hljs-variable constant_">SELECT</span> distinct
  *
<span class="hljs-variable constant_">FROM</span> lake
<span class="hljs-variable constant_">LEFT</span> <span class="hljs-variable constant_">JOIN</span> { <span class="hljs-title function_">ref</span>(<span class="hljs-string">'tmo'</span>) } <span class="hljs-variable constant_">AS</span> tmo on tmo.<span class="hljs-property">key</span> = lake.<span class="hljs-property">key</span>
<span class="hljs-variable constant_">LEFT</span> <span class="hljs-variable constant_">JOIN</span> { <span class="hljs-title function_">ref</span>(<span class="hljs-string">'other_table'</span>) } <span class="hljs-variable constant_">AS</span> cw on lake.<span class="hljs-property">id</span> = cw.<span class="hljs-property">id</span>
</code></pre>
<p>위 쿼리에서 지연에 기여할 수 있는 별도 요소들은 다음과 같습니다:</p>
<ul>
<li>하나의 열에 Clustering.</li>
<li>세 개의 열에 Compound Unique Keys.</li>
<li>DISTINCT 문.</li>
<li>다양한 JOIN 연산.</li>
<li>WHERE 절 필터링이 있는 dbt is_incremental() 구문.</li>
</ul>
<p>이 중 주요 원인으로 눈에 띄는 항목이 있기를 바라며, 이미 dbt의 incremental 기능을 사용 중이라면 왜 쿼리에 시간이 오래 걸릴 수 있는지 살펴봅시다. 각각이 지연에 기여할 수 있는 이유를 살펴봅시다.</p>
<div class="content-ad"></div>
<h1>열 클러스터링</h1>
<p>클러스터링은 특정 열을 기준으로 표 내에서 정렬하는 것을 말합니다. 클러스터링을 통해 스캔/필터링 작업의 성능을 향상시킬 수 있습니다. 그러나 데이터베이스가 쓰기 작업 중에 클러스터 순서를 유지해야 하기 때문에 스캔이 발생하고 데이터의 처리 속도가 느려집니다. BigQuery 클러스터링은 쓰기 작업을 느리게 만들지만 읽기 작업을 빠르게 합니다.</p>
<h1>복합 고유 키 제약 조건</h1>
<p>고유 키는 BigQuery에서 기본적으로 지원되지 않는 기능입니다. 그러나 증분 모델을 사용하는 경우 dbt를 사용하여 이를 구성할 수 있습니다. 이후 dbt는 고유 키에 따라 삽입을 통해 주 키 제약 조건을 효과적으로 적용하는 코드를 컴파일합니다. dbt/BigQuery에서 고유 키의 문제는 증분 로드 시 고유 키를 가진 모든 새로운 데이터를 기존 데이터의 고유 키와 비교하기 위해 전체 테이블 스캔을 수행한다는 점입니다. 전체 테이블 스캔 및 따라서 dbt의 고유 키 제약 조건은 비용이 많이 발생하며 실행 시간이 급격히 느려집니다.</p>
<div class="content-ad"></div>
<h1>DISTINCT 문</h1>
<p>BigQuery의 DISTINCT 문은 각 열에 대해 GROUP BY를 실행하는 것보다 훨씬 빠릅니다. 그러나 기본적으로 똑같은 일을 수행합니다. 그러나 DISTINCT는 여전히 전체 테이블 스캔을 호출합니다. BigQuery에서 각 행이 고유하다/유일하다는 것을 어떻게 더 확실히 할 수 있을까요?</p>
<h1>조인 및 WHERE 절</h1>
<p>조인에는 전체 테이블 스캔이 필요하며 WHERE 절도 필요합니다. 이 부분은 조금 더 명백하며 아마도 대부분의 사람들이 처음에 찾을 곳입니다.</p>
<div class="content-ad"></div>
<p>우리는 WHERE 절이 is_incremental() 블록 안에 중첩되어 있기 때문에 쿼리가 효율적일 것으로 생각했어요. 이론적으로 BigQuery는 런타임에서 기존 테이블을 스캔하고 is_incremental() 블록에서 들어오는 새로운 데이터의 작은 하위 집합과 비교하게 될 거에요!</p>
<p>하지만 실제로는 이런 일이 벌어지고 있어요 —</p>
<p><img src="/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_0.png" alt="이미지"></p>
<p>쿼리의 다른 구성 요소 때문에 새로운 약 15백만 개의 행이 고유 키 절을 위반하는지 확인하기 위해 BigQuery가 거의 500억 개의 데이터 행을 계속 스캔하게 된 거예요. 새로운 접근 방식이 필요했답니다.</p>
<div class="content-ad"></div>
<h1>문제 해결하기</h1>
<p>성능에 영향을 미치는 조합을 찾기 위해 몇 가지 실험을 진행했지만,</p>
<p>최종적으로는 내 실험 중 어느 것도 최종 솔루션을 밝혀내지 못했어요 — 단지 약간의 힌트만 주었을 뿐이에요.</p>
<p>첫째, 우리의 실험은 파티션을 사용하는 것이 병합 작업을 돕는다는 점을 시사했습니다. 파티션을 사용하지 않은 실행의 성능이 느린 것을 볼 수 있었어요 (가장 오른쪽 및 상단 왼쪽 셀). 둘째, 데이터에서는 클러스터링이 성능을 저하시킬 수 있지만, 절대적으로 성능에 해를 끼치는 것은 아닌 것 같았어요. 마지막으로, BigQuery가 결정론적이지 않을 수 있다는 직관을 가졌는데, 여기서 일부 실행에서의 재현성 부족을 통해 그 대안을 확인했어요. 몇 가지 빠른 구글 검색 결과, LIMIT 절은 결정론적인 결과를 도출하지 않는다는 것을 알 수 있었고, 이것이 여기 일부 이상 현상을 설명해 줍니다.</p>
<div class="content-ad"></div>
<p>최종적으로 이러한 실험들은 우리 문제를 즉각적으로 해결할 수 있는 내용을 밝혀내지 않았어요. 우리가 의존할 수 있는 단 하나의 해결책은 없었죠.</p>
<p>문제에 대한 회고를 하며, 우리는 테이블의 모든 데이터가 고유해야 한다는 요구사항이 성능 저하의 주요 요인임을 깨달았어요. 우리는 그 요구사항을 의심한 적이 없었죠. 대신, 중복 데이터가 있을 것이라고 가정하고 제거해야 한다고 생각했어요.</p>
<p>그러나 근본적으로 BigQuery는 삽입/갱신/삭제 트랜잭션을 다루는 것에 적합하게 설계되지 않았어요. BigQuery는 대량 데이터에 대해 완전 갱신만 또는 추가만을 사용할 때 가장 잘 작동하는 OLAP 데이터 웨어하우스에요. DML 할당량 제한이 없어진 것은 2020년에 이루어진 일이었구요, 그 전까지는 24시간 동안 1,000개의 DML 문만 실행할 수 있었어요. 우리의 초기 설계는 BigQuery를 데이터 웨어하우스가 아닌 트랜잭션 데이터베이스처럼 취급한 것이었어요.</p>
<p>우리는 데이터 프로파일링을 수행했고, 중복 데이터가 발생한 것은 24시간 단위였음을 발견했어요. 그래서 우리는 전날 데이터를 수정할 필요가 없었고, 그 데이터를 스캔할 필요도 없었을지도 몰라요! 대부분의 경우, 우리는 unique_key라는 개념을 버리고, 대신에 가장 최신 데이터가 고유하다는 것을 확실히 하는 데 집중할 수 있었어요.</p>
<div class="content-ad"></div>
<h1>솔루션 구현</h1>
<p>우리의 솔루션은 세 가지 주요 구성 요소가 있었습니다:</p>
<ul>
<li>타임스탬프를 기반으로 파티셔닝을 강제하는 것으로, 데이터의 각 날짜를 파티션에 저장했습니다. 이렇게 하면 최신 데이터 로드에만 집중하면 되므로 효율적입니다.</li>
<li>dbt의 is_incremental() 매크로를 활용하여 최신 데이터만 가져오도록 합니다.</li>
<li>전체 테이블 스캔을 유발하는 요소를 제거하고, 작업 중인 특정 파티션에 대해 스캔을 집중합니다.</li>
</ul>
<p>그 결과는 다음과 같았습니다 —</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">{
  <span class="hljs-title function_">config</span>(
    cluster_by=[<span class="hljs-string">"label"</span>],
    materialized=<span class="hljs-string">"incremental"</span>,
    partition_by={
        <span class="hljs-string">"field"</span>: <span class="hljs-string">"_rwde_predicted_at"</span>,
        <span class="hljs-string">"data_type"</span>: <span class="hljs-string">"timestamp"</span>,
        <span class="hljs-string">"granularity"</span>: <span class="hljs-string">"day"</span>
    },
    incremental_strategy = <span class="hljs-string">'insert_overwrite'</span>
  )
}

lake_base <span class="hljs-variable constant_">AS</span> (
  <span class="hljs-variable constant_">SELECT</span>
    primary_key,
    other_columns,
    <span class="hljs-title function_">MAX</span>(_rwde_predicted_at) <span class="hljs-variable constant_">OVER</span> (<span class="hljs-variable constant_">PARTITION</span> <span class="hljs-variable constant_">BY</span> primary_key) <span class="hljs-keyword">as</span> _rwde_predicted_at
  <span class="hljs-variable constant_">FROM</span> { <span class="hljs-title function_">source</span>(<span class="hljs-string">'lake'</span>, <span class="hljs-string">'ner_model'</span>) }
  { <span class="hljs-keyword">if</span> <span class="hljs-title function_">is_incremental</span>() }
      <span class="hljs-variable constant_">WHERE</span> _rwde_predicted_at > (select <span class="hljs-title function_">max</span>(_rwde_predicted_at) <span class="hljs-keyword">from</span> {<span class="hljs-variable language_">this</span>})
  { endif }
)

<span class="hljs-variable constant_">SELECT</span> <span class="hljs-variable constant_">DISTINCT</span> * <span class="hljs-keyword">from</span> lake_base
</code></pre>
<p>여기 중요한 구성 요소가 있습니다:</p>
<ul>
<li>클러스터링 — 여전히 downstream 중요성을 향상시키는 라벨이라는 컬럼을 기준으로 클러스터링을 원합니다. 기억하세요, 클러스터링은 쓰기 및 삽입 작업에는 성능에 악영향을 미치지만 읽기 작업에는 큰 도움이 됩니다. 새로운 증분 접근 방식을 사용하여 처리되는 데이터 양을 줄였기 때문에 이제 런타임을 크게 늦출 필요 없이 클러스터화 할 수 있습니다.</li>
<li>분할 — 일별로 분할함으로써 예측값을 매일 다른 테이블로 분리하게 됩니다. 테이블을 분할하고 dbt에 기본으로 내장된 is_incremental() 플래그를 사용하여 dbt가 작은 데이터 서브셋만 읽고 스캔하도록 강제할 수 있으며 이전 데이터를 다시 처리하지 않을 수 있습니다.</li>
<li>증분 전략 — dbt에는 여기 및 여기에 증분 전략에 대한 훌륭한 문서가 있지만 insert_overwrite를 선택함으로써 전체 파티션을 교체하여기존 파티션에 스캔 및 병합하지 않도록 합니다.</li>
</ul>
<p>참고: 매일 데이터를 한 번만 가져오고 따라서 매일 예측값을 생성하는 것입니다. dbt labs의 Jerco가 가르쳐준 것처럼 —</p>
<div class="content-ad"></div>
<p>인크리멘탈 전략은 구현하기 전에 면밀히 검토하는 것이 중요합니다. 아래 다이어그램은 insert_overwrite 전략이 무엇을 하는지 보여줍니다 —</p>
<p><img src="/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_1.png" alt="이미지"></p>
<p>위 코드를 구현하면 이 특정 테이블의 BigQuery 스캔 시간이 32,295,356,894 ms (8,970 슬롯 시간)에서 5,024,974 ms (1.4 슬롯 시간)으로 줄어듭니다!!</p>
<h1>결론</h1>
<div class="content-ad"></div>
<p>빅쿼리 비용은 슬롯 사용량을 기준으로 계산됩니다. 이는 일반적으로 쿼리 실행 시간과 밀접한 관련이 있습니다. 여기에는 일부 쿼리가 병렬 처리되어 더 많은 슬롯 시간을 사용할 수 있는 경우가 있는데요. 1시간 쿼리가 30분 쿼리보다 비싼 것은 아니지만, 대부분의 경우 그렇습니다.</p>
<p>빅쿼리의 사용 방식으로 인해 매일 테이블을 스캔하여 변경된 행이나 추가된 행을 확인하는 것보다 전체 데이터를 삭제한 후 다시 로드하는 것이 훨씬 저렴할 수 있습니다. 이는 직감과 반대되는 방식일 수 있습니다. 새로운 데이터를 삽입하지 않더라도, 생성된 쿼리가 전체 테이블 스캔보다 성능이 우수하다면 해당 전체 테이블 스캔을 피해 비용을 절약할 수 있습니다.</p>
<p>우리의 경우, 비용을 줄일 것으로 가정하고 문제 모델을 점진적으로 전환했지만, 실제로는 전체 새로고침이 더 저렴했을 것입니다. 스캔을 최소화하면서 시간은 걸리지만, 비용은 더 저렴했을 것입니다. 그러나 우리의 새로운 접근 방식은 더 빠르고 저렴하기까지 합니다. 커피 한 잔 사는 것보다 더 나은 선택입니다.</p>
<p>빅쿼리 최적화에 더 관심이 있다면, 제가 작성한 이전 기사를 확인해보세요. 몇 가지 빠른 수정 사항을 강조하고 있습니다.</p>
<div class="content-ad"></div>
<h1>Stackademic</h1>
<p>끝까지 읽어 주셔서 감사합니다. 가기 전에:</p>
<ul>
<li>작가를 칭찬하고 팔로우해 주시면 감사하겠습니다! 👏</li>
<li>다음 계정을 팔로우해 주세요: X | LinkedIn | YouTube | Discord</li>
<li>다른 플랫폼도 방문해 주세요: In Plain English | CoFeed | Venture</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"BigQuery 비용을 dbt 증분 모델로 100-200배 절감하기","description":"","date":"2024-06-19 16:23","slug":"2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels","content":"\n\n템퍼스(Temporus)에서 제 팀이 다루는 많은 모델은 크지만 \"빅 데이터\" 수준은 아닙니다. 보통 우리의 테이블은 수억 행 정도를 갖고 있으며, 가끔 10억 행을 넘기기도 하지만 성능에 대해 걱정할 만큼 자주 발생하지는 않습니다. 그러나 최근에 쿼리 중 하나가 2시간 후에 타임 아웃되었고, 한 테이블이 각 실행에 거의 9,000 슬롯 시간을 사용하고 있다는 것을 깨달았습니다.\n\n결국 데이터 로드 접근 방식을 변경하여 슬롯 사용량을 8,970시간에서 1.4시간으로 줄였습니다. 앞으로 몇 달 동안 다른 데이터 마트에서도 높은 성능의 점진적 모델을 전개할 예정입니다. 아래에서는 발생한 문제와 그 해결 방법에 대해 설명하겠습니다.\n\n제 팀이 다루는 대부분의 데이터는 구조화되지 않은 텍스트입니다. 해당 텍스트를 분류하기 위해 알고리즘을 실행하면 구조화되지 않은 텍스트의 하나의 항목이 이름이 지정된 entity(개체)의 수십 행으로 팽창될 수 있습니다.\n\n여러 해 동안 소스 데이터가 빅 데이터에서 Big Data로 커졌습니다. 수십억 건의 구조화되지 않은 텍스트 페이지와 그 결과로 더 많은 행의 테이블 데이터가 포함되어 있습니다. 우리가 많은 양의 데이터를 생성하고 있기 때문에, dbt에서 일반적으로 사용하는 완전 갱신(full-refresh) 방식에서 벗어나 점진적인 방식을 활용해야 한다고 가정했었으나, 그로 인한 결과를 고려하지 않았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리가 dbt 제한 시간인 2시간을 초과하면서, 우리는 원시 예측 이후의 테이블을 완전히 잘라내고 로드하는 현재 방식을 다시 검토해야 했습니다.\n\n# 문제 해결 진단\n\n우리의 테이블을 생성하는 SQL 쿼리는 절대 효율적이 아니었습니다 — 문제가 심각해지기 전까지는 그것을 깨닫지 못했습니다. 하지만 어떤 부분이 비효율적이었을까요? 쿼리를 수정함으로써 성능을 개선할 수 있을까요? 아니면 우리 전체 접근법을 바꿔야 했을까요?\n\n아래는 우리가 실행하던 쿼리의 단순화된 버전입니다 —\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n{\n  config(\n    alias=\"ner_model\",\n    cluster_by=[\"label\"],\n    materialized=\"incremental\",\n    schema=\"warehouse\",\n    unique_key=[\"attachment_id\", \"page_index\", \"ent_char_start\"]\n  )\n}\n\nWITH\n\nlake AS (\n  SELECT\n    *\n  FROM { source('lake', 'source_ner_predictions') }\n  { if is_incremental() }\n    WHERE _predicted_at \u003e (SELECT MAX(_predicted_at) FROM { this } )\n  { endif }\n),\n\n-- TMO 우선적 리터럴 형식을 위한 열 추가\nSELECT distinct\n  *\nFROM lake\nLEFT JOIN { ref('tmo') } AS tmo on tmo.key = lake.key\nLEFT JOIN { ref('other_table') } AS cw on lake.id = cw.id\r\n```\n\n위 쿼리에서 지연에 기여할 수 있는 별도 요소들은 다음과 같습니다:\n\n- 하나의 열에 Clustering.\n- 세 개의 열에 Compound Unique Keys.\n- DISTINCT 문.\n- 다양한 JOIN 연산.\n- WHERE 절 필터링이 있는 dbt is_incremental() 구문.\n\n이 중 주요 원인으로 눈에 띄는 항목이 있기를 바라며, 이미 dbt의 incremental 기능을 사용 중이라면 왜 쿼리에 시간이 오래 걸릴 수 있는지 살펴봅시다. 각각이 지연에 기여할 수 있는 이유를 살펴봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 열 클러스터링\n\n클러스터링은 특정 열을 기준으로 표 내에서 정렬하는 것을 말합니다. 클러스터링을 통해 스캔/필터링 작업의 성능을 향상시킬 수 있습니다. 그러나 데이터베이스가 쓰기 작업 중에 클러스터 순서를 유지해야 하기 때문에 스캔이 발생하고 데이터의 처리 속도가 느려집니다. BigQuery 클러스터링은 쓰기 작업을 느리게 만들지만 읽기 작업을 빠르게 합니다.\n\n# 복합 고유 키 제약 조건\n\n고유 키는 BigQuery에서 기본적으로 지원되지 않는 기능입니다. 그러나 증분 모델을 사용하는 경우 dbt를 사용하여 이를 구성할 수 있습니다. 이후 dbt는 고유 키에 따라 삽입을 통해 주 키 제약 조건을 효과적으로 적용하는 코드를 컴파일합니다. dbt/BigQuery에서 고유 키의 문제는 증분 로드 시 고유 키를 가진 모든 새로운 데이터를 기존 데이터의 고유 키와 비교하기 위해 전체 테이블 스캔을 수행한다는 점입니다. 전체 테이블 스캔 및 따라서 dbt의 고유 키 제약 조건은 비용이 많이 발생하며 실행 시간이 급격히 느려집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# DISTINCT 문\n\nBigQuery의 DISTINCT 문은 각 열에 대해 GROUP BY를 실행하는 것보다 훨씬 빠릅니다. 그러나 기본적으로 똑같은 일을 수행합니다. 그러나 DISTINCT는 여전히 전체 테이블 스캔을 호출합니다. BigQuery에서 각 행이 고유하다/유일하다는 것을 어떻게 더 확실히 할 수 있을까요?\n\n# 조인 및 WHERE 절\n\n조인에는 전체 테이블 스캔이 필요하며 WHERE 절도 필요합니다. 이 부분은 조금 더 명백하며 아마도 대부분의 사람들이 처음에 찾을 곳입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 WHERE 절이 is_incremental() 블록 안에 중첩되어 있기 때문에 쿼리가 효율적일 것으로 생각했어요. 이론적으로 BigQuery는 런타임에서 기존 테이블을 스캔하고 is_incremental() 블록에서 들어오는 새로운 데이터의 작은 하위 집합과 비교하게 될 거에요!\n\n하지만 실제로는 이런 일이 벌어지고 있어요 —\n\n![이미지](/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_0.png)\n\n쿼리의 다른 구성 요소 때문에 새로운 약 15백만 개의 행이 고유 키 절을 위반하는지 확인하기 위해 BigQuery가 거의 500억 개의 데이터 행을 계속 스캔하게 된 거예요. 새로운 접근 방식이 필요했답니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 문제 해결하기\n\n성능에 영향을 미치는 조합을 찾기 위해 몇 가지 실험을 진행했지만,\n\n최종적으로는 내 실험 중 어느 것도 최종 솔루션을 밝혀내지 못했어요 — 단지 약간의 힌트만 주었을 뿐이에요.\n\n첫째, 우리의 실험은 파티션을 사용하는 것이 병합 작업을 돕는다는 점을 시사했습니다. 파티션을 사용하지 않은 실행의 성능이 느린 것을 볼 수 있었어요 (가장 오른쪽 및 상단 왼쪽 셀). 둘째, 데이터에서는 클러스터링이 성능을 저하시킬 수 있지만, 절대적으로 성능에 해를 끼치는 것은 아닌 것 같았어요. 마지막으로, BigQuery가 결정론적이지 않을 수 있다는 직관을 가졌는데, 여기서 일부 실행에서의 재현성 부족을 통해 그 대안을 확인했어요. 몇 가지 빠른 구글 검색 결과, LIMIT 절은 결정론적인 결과를 도출하지 않는다는 것을 알 수 있었고, 이것이 여기 일부 이상 현상을 설명해 줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최종적으로 이러한 실험들은 우리 문제를 즉각적으로 해결할 수 있는 내용을 밝혀내지 않았어요. 우리가 의존할 수 있는 단 하나의 해결책은 없었죠.\n\n문제에 대한 회고를 하며, 우리는 테이블의 모든 데이터가 고유해야 한다는 요구사항이 성능 저하의 주요 요인임을 깨달았어요. 우리는 그 요구사항을 의심한 적이 없었죠. 대신, 중복 데이터가 있을 것이라고 가정하고 제거해야 한다고 생각했어요.\n\n그러나 근본적으로 BigQuery는 삽입/갱신/삭제 트랜잭션을 다루는 것에 적합하게 설계되지 않았어요. BigQuery는 대량 데이터에 대해 완전 갱신만 또는 추가만을 사용할 때 가장 잘 작동하는 OLAP 데이터 웨어하우스에요. DML 할당량 제한이 없어진 것은 2020년에 이루어진 일이었구요, 그 전까지는 24시간 동안 1,000개의 DML 문만 실행할 수 있었어요. 우리의 초기 설계는 BigQuery를 데이터 웨어하우스가 아닌 트랜잭션 데이터베이스처럼 취급한 것이었어요.\n\n우리는 데이터 프로파일링을 수행했고, 중복 데이터가 발생한 것은 24시간 단위였음을 발견했어요. 그래서 우리는 전날 데이터를 수정할 필요가 없었고, 그 데이터를 스캔할 필요도 없었을지도 몰라요! 대부분의 경우, 우리는 unique_key라는 개념을 버리고, 대신에 가장 최신 데이터가 고유하다는 것을 확실히 하는 데 집중할 수 있었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 솔루션 구현\n\n우리의 솔루션은 세 가지 주요 구성 요소가 있었습니다:\n\n- 타임스탬프를 기반으로 파티셔닝을 강제하는 것으로, 데이터의 각 날짜를 파티션에 저장했습니다. 이렇게 하면 최신 데이터 로드에만 집중하면 되므로 효율적입니다.\n- dbt의 is_incremental() 매크로를 활용하여 최신 데이터만 가져오도록 합니다.\n- 전체 테이블 스캔을 유발하는 요소를 제거하고, 작업 중인 특정 파티션에 대해 스캔을 집중합니다.\n\n그 결과는 다음과 같았습니다 —\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n{\n  config(\n    cluster_by=[\"label\"],\n    materialized=\"incremental\",\n    partition_by={\n        \"field\": \"_rwde_predicted_at\",\n        \"data_type\": \"timestamp\",\n        \"granularity\": \"day\"\n    },\n    incremental_strategy = 'insert_overwrite'\n  )\n}\n\nlake_base AS (\n  SELECT\n    primary_key,\n    other_columns,\n    MAX(_rwde_predicted_at) OVER (PARTITION BY primary_key) as _rwde_predicted_at\n  FROM { source('lake', 'ner_model') }\n  { if is_incremental() }\n      WHERE _rwde_predicted_at \u003e (select max(_rwde_predicted_at) from {this})\n  { endif }\n)\n\nSELECT DISTINCT * from lake_base\n```\n\n여기 중요한 구성 요소가 있습니다:\n\n- 클러스터링 — 여전히 downstream 중요성을 향상시키는 라벨이라는 컬럼을 기준으로 클러스터링을 원합니다. 기억하세요, 클러스터링은 쓰기 및 삽입 작업에는 성능에 악영향을 미치지만 읽기 작업에는 큰 도움이 됩니다. 새로운 증분 접근 방식을 사용하여 처리되는 데이터 양을 줄였기 때문에 이제 런타임을 크게 늦출 필요 없이 클러스터화 할 수 있습니다.\n- 분할 — 일별로 분할함으로써 예측값을 매일 다른 테이블로 분리하게 됩니다. 테이블을 분할하고 dbt에 기본으로 내장된 is_incremental() 플래그를 사용하여 dbt가 작은 데이터 서브셋만 읽고 스캔하도록 강제할 수 있으며 이전 데이터를 다시 처리하지 않을 수 있습니다.\n- 증분 전략 — dbt에는 여기 및 여기에 증분 전략에 대한 훌륭한 문서가 있지만 insert_overwrite를 선택함으로써 전체 파티션을 교체하여기존 파티션에 스캔 및 병합하지 않도록 합니다.\n\n참고: 매일 데이터를 한 번만 가져오고 따라서 매일 예측값을 생성하는 것입니다. dbt labs의 Jerco가 가르쳐준 것처럼 —\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인크리멘탈 전략은 구현하기 전에 면밀히 검토하는 것이 중요합니다. 아래 다이어그램은 insert_overwrite 전략이 무엇을 하는지 보여줍니다 —\n\n![이미지](/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_1.png)\n\n위 코드를 구현하면 이 특정 테이블의 BigQuery 스캔 시간이 32,295,356,894 ms (8,970 슬롯 시간)에서 5,024,974 ms (1.4 슬롯 시간)으로 줄어듭니다!!\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빅쿼리 비용은 슬롯 사용량을 기준으로 계산됩니다. 이는 일반적으로 쿼리 실행 시간과 밀접한 관련이 있습니다. 여기에는 일부 쿼리가 병렬 처리되어 더 많은 슬롯 시간을 사용할 수 있는 경우가 있는데요. 1시간 쿼리가 30분 쿼리보다 비싼 것은 아니지만, 대부분의 경우 그렇습니다.\n\n빅쿼리의 사용 방식으로 인해 매일 테이블을 스캔하여 변경된 행이나 추가된 행을 확인하는 것보다 전체 데이터를 삭제한 후 다시 로드하는 것이 훨씬 저렴할 수 있습니다. 이는 직감과 반대되는 방식일 수 있습니다. 새로운 데이터를 삽입하지 않더라도, 생성된 쿼리가 전체 테이블 스캔보다 성능이 우수하다면 해당 전체 테이블 스캔을 피해 비용을 절약할 수 있습니다.\n\n우리의 경우, 비용을 줄일 것으로 가정하고 문제 모델을 점진적으로 전환했지만, 실제로는 전체 새로고침이 더 저렴했을 것입니다. 스캔을 최소화하면서 시간은 걸리지만, 비용은 더 저렴했을 것입니다. 그러나 우리의 새로운 접근 방식은 더 빠르고 저렴하기까지 합니다. 커피 한 잔 사는 것보다 더 나은 선택입니다.\n\n빅쿼리 최적화에 더 관심이 있다면, 제가 작성한 이전 기사를 확인해보세요. 몇 가지 빠른 수정 사항을 강조하고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Stackademic\n\n끝까지 읽어 주셔서 감사합니다. 가기 전에:\n\n- 작가를 칭찬하고 팔로우해 주시면 감사하겠습니다! 👏\n- 다음 계정을 팔로우해 주세요: X | LinkedIn | YouTube | Discord\n- 다른 플랫폼도 방문해 주세요: In Plain English | CoFeed | Venture","ogImage":{"url":"/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_0.png"},"coverImage":"/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_0.png","tag":["Tech"],"readingTime":8},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e템퍼스(Temporus)에서 제 팀이 다루는 많은 모델은 크지만 \"빅 데이터\" 수준은 아닙니다. 보통 우리의 테이블은 수억 행 정도를 갖고 있으며, 가끔 10억 행을 넘기기도 하지만 성능에 대해 걱정할 만큼 자주 발생하지는 않습니다. 그러나 최근에 쿼리 중 하나가 2시간 후에 타임 아웃되었고, 한 테이블이 각 실행에 거의 9,000 슬롯 시간을 사용하고 있다는 것을 깨달았습니다.\u003c/p\u003e\n\u003cp\u003e결국 데이터 로드 접근 방식을 변경하여 슬롯 사용량을 8,970시간에서 1.4시간으로 줄였습니다. 앞으로 몇 달 동안 다른 데이터 마트에서도 높은 성능의 점진적 모델을 전개할 예정입니다. 아래에서는 발생한 문제와 그 해결 방법에 대해 설명하겠습니다.\u003c/p\u003e\n\u003cp\u003e제 팀이 다루는 대부분의 데이터는 구조화되지 않은 텍스트입니다. 해당 텍스트를 분류하기 위해 알고리즘을 실행하면 구조화되지 않은 텍스트의 하나의 항목이 이름이 지정된 entity(개체)의 수십 행으로 팽창될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e여러 해 동안 소스 데이터가 빅 데이터에서 Big Data로 커졌습니다. 수십억 건의 구조화되지 않은 텍스트 페이지와 그 결과로 더 많은 행의 테이블 데이터가 포함되어 있습니다. 우리가 많은 양의 데이터를 생성하고 있기 때문에, dbt에서 일반적으로 사용하는 완전 갱신(full-refresh) 방식에서 벗어나 점진적인 방식을 활용해야 한다고 가정했었으나, 그로 인한 결과를 고려하지 않았습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e우리가 dbt 제한 시간인 2시간을 초과하면서, 우리는 원시 예측 이후의 테이블을 완전히 잘라내고 로드하는 현재 방식을 다시 검토해야 했습니다.\u003c/p\u003e\n\u003ch1\u003e문제 해결 진단\u003c/h1\u003e\n\u003cp\u003e우리의 테이블을 생성하는 SQL 쿼리는 절대 효율적이 아니었습니다 — 문제가 심각해지기 전까지는 그것을 깨닫지 못했습니다. 하지만 어떤 부분이 비효율적이었을까요? 쿼리를 수정함으로써 성능을 개선할 수 있을까요? 아니면 우리 전체 접근법을 바꿔야 했을까요?\u003c/p\u003e\n\u003cp\u003e아래는 우리가 실행하던 쿼리의 단순화된 버전입니다 —\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e{\n  \u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\n    alias=\u003cspan class=\"hljs-string\"\u003e\"ner_model\"\u003c/span\u003e,\n    cluster_by=[\u003cspan class=\"hljs-string\"\u003e\"label\"\u003c/span\u003e],\n    materialized=\u003cspan class=\"hljs-string\"\u003e\"incremental\"\u003c/span\u003e,\n    schema=\u003cspan class=\"hljs-string\"\u003e\"warehouse\"\u003c/span\u003e,\n    unique_key=[\u003cspan class=\"hljs-string\"\u003e\"attachment_id\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"page_index\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"ent_char_start\"\u003c/span\u003e]\n  )\n}\n\n\u003cspan class=\"hljs-variable constant_\"\u003eWITH\u003c/span\u003e\n\nlake \u003cspan class=\"hljs-variable constant_\"\u003eAS\u003c/span\u003e (\n  \u003cspan class=\"hljs-variable constant_\"\u003eSELECT\u003c/span\u003e\n    *\n  \u003cspan class=\"hljs-variable constant_\"\u003eFROM\u003c/span\u003e { \u003cspan class=\"hljs-title function_\"\u003esource\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'lake'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'source_ner_predictions'\u003c/span\u003e) }\n  { \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eis_incremental\u003c/span\u003e() }\n    \u003cspan class=\"hljs-variable constant_\"\u003eWHERE\u003c/span\u003e _predicted_at \u003e (\u003cspan class=\"hljs-variable constant_\"\u003eSELECT\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eMAX\u003c/span\u003e(_predicted_at) \u003cspan class=\"hljs-variable constant_\"\u003eFROM\u003c/span\u003e { \u003cspan class=\"hljs-variable language_\"\u003ethis\u003c/span\u003e } )\n  { endif }\n),\n\n-- \u003cspan class=\"hljs-variable constant_\"\u003eTMO\u003c/span\u003e 우선적 리터럴 형식을 위한 열 추가\n\u003cspan class=\"hljs-variable constant_\"\u003eSELECT\u003c/span\u003e distinct\n  *\n\u003cspan class=\"hljs-variable constant_\"\u003eFROM\u003c/span\u003e lake\n\u003cspan class=\"hljs-variable constant_\"\u003eLEFT\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eJOIN\u003c/span\u003e { \u003cspan class=\"hljs-title function_\"\u003eref\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'tmo'\u003c/span\u003e) } \u003cspan class=\"hljs-variable constant_\"\u003eAS\u003c/span\u003e tmo on tmo.\u003cspan class=\"hljs-property\"\u003ekey\u003c/span\u003e = lake.\u003cspan class=\"hljs-property\"\u003ekey\u003c/span\u003e\n\u003cspan class=\"hljs-variable constant_\"\u003eLEFT\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eJOIN\u003c/span\u003e { \u003cspan class=\"hljs-title function_\"\u003eref\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'other_table'\u003c/span\u003e) } \u003cspan class=\"hljs-variable constant_\"\u003eAS\u003c/span\u003e cw on lake.\u003cspan class=\"hljs-property\"\u003eid\u003c/span\u003e = cw.\u003cspan class=\"hljs-property\"\u003eid\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e위 쿼리에서 지연에 기여할 수 있는 별도 요소들은 다음과 같습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e하나의 열에 Clustering.\u003c/li\u003e\n\u003cli\u003e세 개의 열에 Compound Unique Keys.\u003c/li\u003e\n\u003cli\u003eDISTINCT 문.\u003c/li\u003e\n\u003cli\u003e다양한 JOIN 연산.\u003c/li\u003e\n\u003cli\u003eWHERE 절 필터링이 있는 dbt is_incremental() 구문.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 중 주요 원인으로 눈에 띄는 항목이 있기를 바라며, 이미 dbt의 incremental 기능을 사용 중이라면 왜 쿼리에 시간이 오래 걸릴 수 있는지 살펴봅시다. 각각이 지연에 기여할 수 있는 이유를 살펴봅시다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e열 클러스터링\u003c/h1\u003e\n\u003cp\u003e클러스터링은 특정 열을 기준으로 표 내에서 정렬하는 것을 말합니다. 클러스터링을 통해 스캔/필터링 작업의 성능을 향상시킬 수 있습니다. 그러나 데이터베이스가 쓰기 작업 중에 클러스터 순서를 유지해야 하기 때문에 스캔이 발생하고 데이터의 처리 속도가 느려집니다. BigQuery 클러스터링은 쓰기 작업을 느리게 만들지만 읽기 작업을 빠르게 합니다.\u003c/p\u003e\n\u003ch1\u003e복합 고유 키 제약 조건\u003c/h1\u003e\n\u003cp\u003e고유 키는 BigQuery에서 기본적으로 지원되지 않는 기능입니다. 그러나 증분 모델을 사용하는 경우 dbt를 사용하여 이를 구성할 수 있습니다. 이후 dbt는 고유 키에 따라 삽입을 통해 주 키 제약 조건을 효과적으로 적용하는 코드를 컴파일합니다. dbt/BigQuery에서 고유 키의 문제는 증분 로드 시 고유 키를 가진 모든 새로운 데이터를 기존 데이터의 고유 키와 비교하기 위해 전체 테이블 스캔을 수행한다는 점입니다. 전체 테이블 스캔 및 따라서 dbt의 고유 키 제약 조건은 비용이 많이 발생하며 실행 시간이 급격히 느려집니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eDISTINCT 문\u003c/h1\u003e\n\u003cp\u003eBigQuery의 DISTINCT 문은 각 열에 대해 GROUP BY를 실행하는 것보다 훨씬 빠릅니다. 그러나 기본적으로 똑같은 일을 수행합니다. 그러나 DISTINCT는 여전히 전체 테이블 스캔을 호출합니다. BigQuery에서 각 행이 고유하다/유일하다는 것을 어떻게 더 확실히 할 수 있을까요?\u003c/p\u003e\n\u003ch1\u003e조인 및 WHERE 절\u003c/h1\u003e\n\u003cp\u003e조인에는 전체 테이블 스캔이 필요하며 WHERE 절도 필요합니다. 이 부분은 조금 더 명백하며 아마도 대부분의 사람들이 처음에 찾을 곳입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e우리는 WHERE 절이 is_incremental() 블록 안에 중첩되어 있기 때문에 쿼리가 효율적일 것으로 생각했어요. 이론적으로 BigQuery는 런타임에서 기존 테이블을 스캔하고 is_incremental() 블록에서 들어오는 새로운 데이터의 작은 하위 집합과 비교하게 될 거에요!\u003c/p\u003e\n\u003cp\u003e하지만 실제로는 이런 일이 벌어지고 있어요 —\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e쿼리의 다른 구성 요소 때문에 새로운 약 15백만 개의 행이 고유 키 절을 위반하는지 확인하기 위해 BigQuery가 거의 500억 개의 데이터 행을 계속 스캔하게 된 거예요. 새로운 접근 방식이 필요했답니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e문제 해결하기\u003c/h1\u003e\n\u003cp\u003e성능에 영향을 미치는 조합을 찾기 위해 몇 가지 실험을 진행했지만,\u003c/p\u003e\n\u003cp\u003e최종적으로는 내 실험 중 어느 것도 최종 솔루션을 밝혀내지 못했어요 — 단지 약간의 힌트만 주었을 뿐이에요.\u003c/p\u003e\n\u003cp\u003e첫째, 우리의 실험은 파티션을 사용하는 것이 병합 작업을 돕는다는 점을 시사했습니다. 파티션을 사용하지 않은 실행의 성능이 느린 것을 볼 수 있었어요 (가장 오른쪽 및 상단 왼쪽 셀). 둘째, 데이터에서는 클러스터링이 성능을 저하시킬 수 있지만, 절대적으로 성능에 해를 끼치는 것은 아닌 것 같았어요. 마지막으로, BigQuery가 결정론적이지 않을 수 있다는 직관을 가졌는데, 여기서 일부 실행에서의 재현성 부족을 통해 그 대안을 확인했어요. 몇 가지 빠른 구글 검색 결과, LIMIT 절은 결정론적인 결과를 도출하지 않는다는 것을 알 수 있었고, 이것이 여기 일부 이상 현상을 설명해 줍니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e최종적으로 이러한 실험들은 우리 문제를 즉각적으로 해결할 수 있는 내용을 밝혀내지 않았어요. 우리가 의존할 수 있는 단 하나의 해결책은 없었죠.\u003c/p\u003e\n\u003cp\u003e문제에 대한 회고를 하며, 우리는 테이블의 모든 데이터가 고유해야 한다는 요구사항이 성능 저하의 주요 요인임을 깨달았어요. 우리는 그 요구사항을 의심한 적이 없었죠. 대신, 중복 데이터가 있을 것이라고 가정하고 제거해야 한다고 생각했어요.\u003c/p\u003e\n\u003cp\u003e그러나 근본적으로 BigQuery는 삽입/갱신/삭제 트랜잭션을 다루는 것에 적합하게 설계되지 않았어요. BigQuery는 대량 데이터에 대해 완전 갱신만 또는 추가만을 사용할 때 가장 잘 작동하는 OLAP 데이터 웨어하우스에요. DML 할당량 제한이 없어진 것은 2020년에 이루어진 일이었구요, 그 전까지는 24시간 동안 1,000개의 DML 문만 실행할 수 있었어요. 우리의 초기 설계는 BigQuery를 데이터 웨어하우스가 아닌 트랜잭션 데이터베이스처럼 취급한 것이었어요.\u003c/p\u003e\n\u003cp\u003e우리는 데이터 프로파일링을 수행했고, 중복 데이터가 발생한 것은 24시간 단위였음을 발견했어요. 그래서 우리는 전날 데이터를 수정할 필요가 없었고, 그 데이터를 스캔할 필요도 없었을지도 몰라요! 대부분의 경우, 우리는 unique_key라는 개념을 버리고, 대신에 가장 최신 데이터가 고유하다는 것을 확실히 하는 데 집중할 수 있었어요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e솔루션 구현\u003c/h1\u003e\n\u003cp\u003e우리의 솔루션은 세 가지 주요 구성 요소가 있었습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e타임스탬프를 기반으로 파티셔닝을 강제하는 것으로, 데이터의 각 날짜를 파티션에 저장했습니다. 이렇게 하면 최신 데이터 로드에만 집중하면 되므로 효율적입니다.\u003c/li\u003e\n\u003cli\u003edbt의 is_incremental() 매크로를 활용하여 최신 데이터만 가져오도록 합니다.\u003c/li\u003e\n\u003cli\u003e전체 테이블 스캔을 유발하는 요소를 제거하고, 작업 중인 특정 파티션에 대해 스캔을 집중합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e그 결과는 다음과 같았습니다 —\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e{\n  \u003cspan class=\"hljs-title function_\"\u003econfig\u003c/span\u003e(\n    cluster_by=[\u003cspan class=\"hljs-string\"\u003e\"label\"\u003c/span\u003e],\n    materialized=\u003cspan class=\"hljs-string\"\u003e\"incremental\"\u003c/span\u003e,\n    partition_by={\n        \u003cspan class=\"hljs-string\"\u003e\"field\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"_rwde_predicted_at\"\u003c/span\u003e,\n        \u003cspan class=\"hljs-string\"\u003e\"data_type\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"timestamp\"\u003c/span\u003e,\n        \u003cspan class=\"hljs-string\"\u003e\"granularity\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"day\"\u003c/span\u003e\n    },\n    incremental_strategy = \u003cspan class=\"hljs-string\"\u003e'insert_overwrite'\u003c/span\u003e\n  )\n}\n\nlake_base \u003cspan class=\"hljs-variable constant_\"\u003eAS\u003c/span\u003e (\n  \u003cspan class=\"hljs-variable constant_\"\u003eSELECT\u003c/span\u003e\n    primary_key,\n    other_columns,\n    \u003cspan class=\"hljs-title function_\"\u003eMAX\u003c/span\u003e(_rwde_predicted_at) \u003cspan class=\"hljs-variable constant_\"\u003eOVER\u003c/span\u003e (\u003cspan class=\"hljs-variable constant_\"\u003ePARTITION\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eBY\u003c/span\u003e primary_key) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e _rwde_predicted_at\n  \u003cspan class=\"hljs-variable constant_\"\u003eFROM\u003c/span\u003e { \u003cspan class=\"hljs-title function_\"\u003esource\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'lake'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'ner_model'\u003c/span\u003e) }\n  { \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003eis_incremental\u003c/span\u003e() }\n      \u003cspan class=\"hljs-variable constant_\"\u003eWHERE\u003c/span\u003e _rwde_predicted_at \u003e (select \u003cspan class=\"hljs-title function_\"\u003emax\u003c/span\u003e(_rwde_predicted_at) \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e {\u003cspan class=\"hljs-variable language_\"\u003ethis\u003c/span\u003e})\n  { endif }\n)\n\n\u003cspan class=\"hljs-variable constant_\"\u003eSELECT\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eDISTINCT\u003c/span\u003e * \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e lake_base\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e여기 중요한 구성 요소가 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e클러스터링 — 여전히 downstream 중요성을 향상시키는 라벨이라는 컬럼을 기준으로 클러스터링을 원합니다. 기억하세요, 클러스터링은 쓰기 및 삽입 작업에는 성능에 악영향을 미치지만 읽기 작업에는 큰 도움이 됩니다. 새로운 증분 접근 방식을 사용하여 처리되는 데이터 양을 줄였기 때문에 이제 런타임을 크게 늦출 필요 없이 클러스터화 할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e분할 — 일별로 분할함으로써 예측값을 매일 다른 테이블로 분리하게 됩니다. 테이블을 분할하고 dbt에 기본으로 내장된 is_incremental() 플래그를 사용하여 dbt가 작은 데이터 서브셋만 읽고 스캔하도록 강제할 수 있으며 이전 데이터를 다시 처리하지 않을 수 있습니다.\u003c/li\u003e\n\u003cli\u003e증분 전략 — dbt에는 여기 및 여기에 증분 전략에 대한 훌륭한 문서가 있지만 insert_overwrite를 선택함으로써 전체 파티션을 교체하여기존 파티션에 스캔 및 병합하지 않도록 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e참고: 매일 데이터를 한 번만 가져오고 따라서 매일 예측값을 생성하는 것입니다. dbt labs의 Jerco가 가르쳐준 것처럼 —\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e인크리멘탈 전략은 구현하기 전에 면밀히 검토하는 것이 중요합니다. 아래 다이어그램은 insert_overwrite 전략이 무엇을 하는지 보여줍니다 —\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e위 코드를 구현하면 이 특정 테이블의 BigQuery 스캔 시간이 32,295,356,894 ms (8,970 슬롯 시간)에서 5,024,974 ms (1.4 슬롯 시간)으로 줄어듭니다!!\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e빅쿼리 비용은 슬롯 사용량을 기준으로 계산됩니다. 이는 일반적으로 쿼리 실행 시간과 밀접한 관련이 있습니다. 여기에는 일부 쿼리가 병렬 처리되어 더 많은 슬롯 시간을 사용할 수 있는 경우가 있는데요. 1시간 쿼리가 30분 쿼리보다 비싼 것은 아니지만, 대부분의 경우 그렇습니다.\u003c/p\u003e\n\u003cp\u003e빅쿼리의 사용 방식으로 인해 매일 테이블을 스캔하여 변경된 행이나 추가된 행을 확인하는 것보다 전체 데이터를 삭제한 후 다시 로드하는 것이 훨씬 저렴할 수 있습니다. 이는 직감과 반대되는 방식일 수 있습니다. 새로운 데이터를 삽입하지 않더라도, 생성된 쿼리가 전체 테이블 스캔보다 성능이 우수하다면 해당 전체 테이블 스캔을 피해 비용을 절약할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e우리의 경우, 비용을 줄일 것으로 가정하고 문제 모델을 점진적으로 전환했지만, 실제로는 전체 새로고침이 더 저렴했을 것입니다. 스캔을 최소화하면서 시간은 걸리지만, 비용은 더 저렴했을 것입니다. 그러나 우리의 새로운 접근 방식은 더 빠르고 저렴하기까지 합니다. 커피 한 잔 사는 것보다 더 나은 선택입니다.\u003c/p\u003e\n\u003cp\u003e빅쿼리 최적화에 더 관심이 있다면, 제가 작성한 이전 기사를 확인해보세요. 몇 가지 빠른 수정 사항을 강조하고 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eStackademic\u003c/h1\u003e\n\u003cp\u003e끝까지 읽어 주셔서 감사합니다. 가기 전에:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e작가를 칭찬하고 팔로우해 주시면 감사하겠습니다! 👏\u003c/li\u003e\n\u003cli\u003e다음 계정을 팔로우해 주세요: X | LinkedIn | YouTube | Discord\u003c/li\u003e\n\u003cli\u003e다른 플랫폼도 방문해 주세요: In Plain English | CoFeed | Venture\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-ReducingBigQueryCostsby100200xwithdbtIncrementalModels"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>