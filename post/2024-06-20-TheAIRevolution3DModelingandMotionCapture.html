<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>AI 혁명 3D 모델링과 모션 캡처 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-20-TheAIRevolution3DModelingandMotionCapture" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="AI 혁명 3D 모델링과 모션 캡처 | itposting" data-gatsby-head="true"/><meta property="og:title" content="AI 혁명 3D 모델링과 모션 캡처 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-20-TheAIRevolution3DModelingandMotionCapture" data-gatsby-head="true"/><meta name="twitter:title" content="AI 혁명 3D 모델링과 모션 캡처 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-20 16:33" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">AI 혁명 3D 모델링과 모션 캡처</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="AI 혁명 3D 모델링과 모션 캡처" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 20, 2024</span><span class="posts_reading_time__f7YPP">10<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-20-TheAIRevolution3DModelingandMotionCapture&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_0.png" alt="이미지"></p>
<p>3D 기술과 인공지능(AI)의 결합에 의해 디지턈 제작 분야에서 혁신의 새 시대가 열리고 있습니다. Mindplex Podcast의 이번 에피소드, '신기한 AI 3D 혁명'에서 전문가인 라이언 스턴리히트가 AI가 3D 스캐닝, 모델링 및 모션 캡처를 혁신하는 잠재력에 대해 논의합니다.</p>
<p>이 에피소드는 게임 개발자 컨퍼런스(GDC)에서 볼 수 있는 혁신적인 혁신에 대한 흥미로운 통찰을 제공합니다.</p>
<p>라이언에 따르면, 인공지능 덕분에 3D 스캐닝 및 렌더링 기술이 상당히 발전했습니다. 새로운 기술을 사용하면 이제 사람들이 스마트폰을 사용하여 고품질 스캔물을 만들고 심지어 인공지능을 이용하여 모델을 개선할 수 있습니다.</p>
<div class="content-ad"></div>
<p>라이언은 AI, VR, 뉴로테크 및 3D 제조 분야를 전문으로 하는 전문가로, 최신 3D 스캐닝 개발에 대한 통찰을 공유합니다. 특히 포토그램메트리를 사용하여 사진으로부터 3D 모델을 만드는 것을 강조하며, 이 기술이 비디오 게임 및 역사 보존을 포함한 다양한 응용 분야에서의 중요성을 강조했습니다.</p>
<p><img src="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_1.png" alt="이미지"></p>
<p>라이언은 지난 몇 년간 3D 스캐닝 기술의 발전에 대해 논의합니다. 그는 2013년에 여러 방법으로 자신의 머리를 스캔한 경험을 공유하며, 이 작업에 약 주일이 걸렸다고 말합니다. 지금은 C 엔진과 같은 새로운 도구들이 있어서 핸드폰 카메라를 사용하여 데이터를 캡처하고 고품질 3D 스캔을 위해 클라우드에서 처리할 수 있습니다.</p>
<p>이 기술은 작은 물체 스캔, 방 스캔, 심지어 텍스처 및 물리적 기반 렌더링(PBR)을 포함한 다양한 스캔 파이프라인을 처리할 수 있어서 스캔물이 더욱 현실적으로 보입니다. 그는 대부분의 핸드폰이 3D 스캔을 직접 처리할 수 없기 때문에 클라우드로 데이터를 업로드해 처리하는 것이 필요하다고 언급했습니다.</p>
<div class="content-ad"></div>
<p>몇 년 전에는 중대한 처리 요구 사항 때문에 불가능했지만, 이제 회사들이 3D 스캔의 무료 익스포트를 제공하여 프로세스가 더 접근 가능해졌습니다.</p>
<h1>인공지능이 3D 스캔 및 모델링에 미치는 영향</h1>
<p>Ryan Sternlicht의 인사이트는 인공지능 기술에 기반한 3D 스캔 기술의 혁명적인 영향을 보여줍니다. 포토그램메트리와 같은 기술을 통해 인공지능은 일반 사진으로부터 고품질 3D 모델을 생성하게 하여 전통적인 방법의 한계를 넘어서게 합니다.</p>
<p>스마트폰 기반 스캐닝에서 인공지능의 원활한 통합, 스캐닝 파이프라인의 정교화, 그리고 인공지능 생성 포토그램메트리 모델의 등장으로 3D 스캔의 환경이 재구성되어, 이전보다 더 접근 가능하고 효율적으로 만들어졌습니다.</p>
<div class="content-ad"></div>
<p>라이언은 3D 스캔 기술의 발전에 대해 이야기하며 특히 무료와 유료 모델 간의 차이점을 집중적으로 다루고 있습니다. 무료 버전은 가벼운 공간 스캔과 로우 폴리 변환 사용이 가능하며, 유료 버전에는 쿼드 메쉬와 PBR 소재를 포함한 리탑로지, AI 기반의 무특징 물체 모드가 포함되어 있습니다.</p>
<p>라이언은 또한 반사, 투명 및 반투명 물질을 스캔하는 데 있던 역사적인 어려움과 NVIDIA 및 Microsoft에서 사용하는 신경 반경장치와 같은 AI 기술의 발전이 3D 스캔 프로세스를 크게 개선하여 더 빠르고 효율적으로 만들었음을 언급합니다. 이러한 새로운 AI 기반 포토그램메트리 모델은 3D 스캔 워크플로우를 혁신적으로 바꾸어 이미지로부터 몇 시간만에 고품질 3D 모델을 만들 수 있도록 했습니다.</p>
<p><img src="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_2.png" alt="이미지"></p>
<h2>NeRF 소개</h2>
<div class="content-ad"></div>
<p>라이언은 3D 스캔 기술의 발전, 특히 NeRF (신경 방사 조연체)에 대해 이야기합니다. 이 기술은 처리를 보다 효율적으로 만들어 GPU 부담을 줄여 프로세스를 혁신했습니다. 이 새로운 방법을 사용하여 과거의 3D 스캔 및 사진을 재처리할 수 있기 때문에 거꾸로 호환됩니다.</p>
<p>NeRF는 정확히 확대하는 것이 아니라 기존 데이터를 개선하여 처리를 더 효율적으로 만들어 더 나은 모델과 부드러운 렌더링을 제공합니다. 이 기술은 여전히 GPU 부담이 있지만 처리 시간을 크게 줄여 충돌 및 기타 문제에 쉽게 노출되지 않도록 했습니다.</p>
<p>NeRF는 고급 AI 주도의 사진측량 방법론이며 전통적인 사진측량과 유사점이 있지만 그 하위 집합은 아닙니다. 대신, 각 이미지의 시점을 처리하기 전에 결정하는 사진측량 과정의 다음 단계를 나타냅니다.</p>
<h1>3D 프린팅 및 모델링 혁신</h1>
<div class="content-ad"></div>
<p>AI는 3D 프린팅 프로세스를 간소화하고 오류 교정 메커니즘을 강화하며 모델 생성을 가속화하는 데 어떤 역할을 하는지 심층적인 대화가 이어지고 있어요.</p>
<p>AI를 통한 실시간 오류 교정 및 AI 알고리즘을 3D 프린팅 기계에 통합함으로써 부가 제조 분야에서 얼마나 성취할 수 있는지의 경계가 더욱 넓혀지고 있어요. 게다가 이미지 및 텍스트에서 생성된 AI 3D 모델의 등장은 창의력을 위한 새로운 길을 여는데, 사용자들에게 전례없는 편의와 속도로 아이디어를 현실로 구현할 수 있게 돕고 있어요.</p>
<p>라이언은 VR 기술을 사용하여 3D 객체를 스캔하는 데에 대해 논의하고 있어요. 그것이 내부 또는 외부의 관점에서든, 라이언은 이 기술이 포인트 클라우드와 포토그래메트리를 포함하며 색상과 반사를 잃은 무광의 외형을 가져올 수 있다고 설명하고 있어요.</p>
<h2>3D 가우시안 스플레팅 소개</h2>
<div class="content-ad"></div>
<p>그러나 AI 기술은 발전하여 분실된 정보를 검색하고 새로운 데이터를 추론하는 것이 가능해졌으며, 3D 가우시안 스플래팅과 같은 더 효율적인 기술의 개발을 이끌었습니다. 지난해 8월에 소개된 이 기술은 머신 러닝을 사용하여 이전의 NeRF 스캐닝과 같은 방법보다 정보를 더 효율적이고 효과적으로 처리합니다. 가상 세계에서 객체를 생성하는 데 사용되는 다양한 방법에도 불구하고, 렌더링된 후에는 환경 내의 보통 객체처럼 나타납니다.</p>
<p>그들은 3D 스캐닝 및 포토그램메트리를 위한 특정 이미지 세트가 있으며, 비교를 위한 기준 역할을 한다고 설명합니다. 라이언은 다양한 툴셋 및 peak signal-to-noise ratio (PSNR) 및 렌더링 시간과 같은 메트릭을 사용하여 동일한 자전거 장면을 렌더링하는 다른 시스템을 비교합니다.</p>
<p>이들은 이전에 사용된 myip NeRF와 같은 구식 방법은 3D 스캔을 학습하고 처리하는 데 48시간이 걸렸지만, 최근에 개발된 AI 기반 방법은 모델 품질이 더 좋게 높여 51분만에 같은 작업을 수행할 수 있다고 언급합니다. 이러한 기술들 사이의 출시 날짜 차는 약 8개월로, 처리 속도의 상당한 향상을 대표합니다. 이 비교는 가우시안 스플래팅과 Nerfing 사이의 것이며, 전자가 이 경우에는 더 빠른 옵션임을 나타냅니다. 라이언은 이러한 모델 중 많은 것들이 GitHub를 통해 쉽게 접근할 수 있다는 것을 언급하며 결론을 지었습니다.</p>
<p><img src="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_3.png" alt="이미지"></p>
<div class="content-ad"></div>
<h1>아바타 생성 및 실시간 렌더링</h1>
<p>Deemos Tech과 같은 기업들은 AI로 생성된 아바타의 개발을 선도하며, AI 파이프라인을 활용하여 초현실적인 디지털 펄소나를 만들어냅니다. AI를 아바타 생성에 접목함으로써 시각적인 충실도를 높이는데 그치지 않고, 이를 더 많은 사람들이 이용할 수 있도록 하는 데 기여하고 있습니다.</p>
<p>라이언은 최근 AI로 생성된 3D 모델의 발전에 대해 논의하며, 새로운 방법론을 활용하여 장면의 특정 부분에서 발생하는 흐릿한 문제에 대응하고 있습니다. 이 방법은 장면의 특정 영역의 처리를 개선하고 모델을 약간 수정하여 누락된 정보를 보완하는 것을 포함합니다. 라이언은 이 방법론이 업스케일링과 유사하다고 언급하며, 이는 해당 영역에 존재하지 않는 정보를 보충함으로써 실현됩니다.</p>
<h2>NeRFs, 3D Gaussian Splatting 및 SMERF가 사진측량 및 AI 모델 혁명을 일으킵니다</h2>
<div class="content-ad"></div>
<p>실시간 렌더링 기술의 발전으로 Neural Radiance Fields (NeRF) 및 3D Gaussian splatting과 같은 기술이 3D 모델 시각화를 혁신하며, 이에 따른 현실감과 상호작용성이 향상되고 있습니다.</p>
<p>이 토론은 NeRF를 위한 실시간 대규모 시각화용으로 수정된 SMERF에 대해서도 다루고 있습니다. 모바일 기기에서 전체 3D 스캔을 실시간으로 돌아다니며 살펴볼 수 있는 기술을 제공함으로써 이제 폰에서 실행되며 사용자가 실시간으로 3D 스캔을 탐험할 수 있는 SMERF의 혁신에 대해 다루고 있습니다.</p>
<p>라이언은 NeRF (Neural Radiance Fields)와 3D Gaussian splatting에 중점을 두어 3D 모델링 기술의 발전을 논의합니다. 이전에는 모바일 기기에서 3D 모델을 보기 위해 MP4 파일을 생성해야 했지만, 이제는 헤드셋을 사용하거나 브라우저에서도 실시간으로 모델을 볼 수 있습니다.</p>
<p>라이언은 이를 실시간으로 랩탑과 브라우저에서 보여줌으로써 각종 씬들이 실행되는 모습을 시연합니다. 이 모델에 사용된 파일 형식은 네이티브가 아니지만, Unity와 같은 다양한 도구를 사용하여 생성할 수 있습니다. NeRF와 3D Gaussian splatting은 전통적인 포토그래메트리에 비해 투명도와 반사 처리 등에서 상당한 개선을 제공하며, 이전에는 불가능했던 처리도 가능합니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_4.png" alt="2024-06-20-TheAIRevolution3DModelingandMotionCapture_4"></p>
<p>Ryan씨는 또한 이 스캔에 빌트인된 실시간 물리학의 발전을 언급하며 빛 상호작용과 반사를 더 잘 이해할 수 있게 되었다고 설명합니다. 이전에는 와인 잔과 같은 투명한 물체가 정확하게 스캔되지 못하고 불투명하게 보였지만, 이제는 올바르게 스캔 및 렌더링할 수 있다고 합니다.</p>
<p>Ryan은 3D 프린팅 모델의 실시간 오류 보정 기술에 대한 발전을 논의하고 이것이 3D 프린팅 산업과의 관계에 대해 설명합니다. Ryan은 실시간 물리학과 기계 학습 알고리즘의 결합이 보다 빠르고 품질 좋은 3D 프린팅을 가능하게 한다고 설명하며, 이전에 어려웠거나 불가능했던 물체를 만들 수 있게 되었다고 합니다.</p>
<p>Ryan은 속도보트 경주를 언급하기도 하는데, 가장 빨리 표준 3D 모델을 인쇄하는 경쟁이며, 현재 세계 기록은 딱 2분이라고 합니다. 기계 학습을 주로 기반으로 한 오류 보정 과정이 프린팅 중에 발생하는 오류를 예측하고 조정하므로 품질이 향상되고 생산 시간이 빨라집니다.</p>
<div class="content-ad"></div>
<p>라이언은 3D 프린팅 기술의 발전에 대해 이야기했어요. 특히, AI 알고리즘이 내장된 400달러짜리 기계로 빠르게 만드는 과정을 소개했어요. 이 기계는 속도가 빨라 카메라가 속도를 촬영하기 어렵다고 해요. 또한, 3D 프린팅된 물체와 웨어러블 또는 가상 의류 간의 연결에 대해 언급했어요. Marvelous Designers와 Style 3D 같은 기업들이 AI를 사용하여 옷 이미지를 3D 모델로 변환하여 비디오 게임 캐릭터에 입히는 작업을 진행 중이라고 해요. 게다가, 비디오 게임에서 AI 기술을 사용하여 아바타를 개선하는 데 초점을 맞추고 있다고 해요. 라이언은 GDC 컨퍼런스에서 이에 대한 인상적인 시연을 보았다고 전했어요.</p>
<p>라이언은 Deemos Tech에 대해 언급했어요. 이 회사는 AI가 생성한 아바타 분야의 발전으로 유명하다고 해요. Deemos Tech은 GDC에서 자사의 기술을 선보였는데, 이들의 아바타 생성기를 게임 "Earth Revival"에 통합했다고 해요. 시스템은 얼굴 교체 및 재구성을 위한 Dream Face, 이미지에서 3D 모델로 변환하는 도구 등을 포함해 세 가지 다른 AI 파이프라인을 사용한다고 해요. VFX 산업에서의 Deemos Tech의 배경과 다양한 얼굴 3D 스캔을 통해 그들은 고급 아바타를 생성할 수 있었다고 해요. Hyper Human 도구를 사용하면 사용자가 업로드한 이미지로부터 모델을 생성할 수 있어 작업이 더 쉬워졌다.</p>
<p>라이언은 이미지와 텍스트에서 3D 모델을 생성하기 위해 AI를 사용하는 것에 대해 이야기했어요. 라이언은 사진으로부터 3D 모델을 생성하는 경험을 공유했는데, 좋은 결과를 얻기 위해 명확하고 정면의 이미지의 중요성을 강조했어요. 또한 텍스트에서 3D 모델을 생성하는 가능성에 대해 언급했지만 시도하려면 로그인이 필요하다고 하였다. 그 비디오는 베타 버전의 멀티모달 3D 검색 엔진을 소개하는데, 이는 사용자가 이미지를 업로드하고 온라인에서 유사한 3D 모델을 검색할 수 있게 해줍니다. 얼굴 래깅 및 실시간 얼굴 캡처 도구로 3D 모델을 생성 및 처리하기 위한 파이프라인이 더 자동화되어 작업이 덜 복잡해졌다고 해요. 라이언은 이 발전을 V튜빙의 인기와 더 사실적인 아바타에 대한 열망에 귀속시켰다.</p>
<div class="content-ad"></div>
<p>토론은 마커리스 동작 캡처 기술까지 확장되었는데, 인공지능 알고리즘이 비싼 장비와 마커의 필요성을 없애고 있습니다.</p>
<p>AR-51의 마커리스 추적 시스템과 같은 혁신적인 솔루션을 통해 전신 모션 캡처가 더욱 접근 가능하고 비용 효율적으로 구현되어 현실감 넘치는 가상 경험을 열어 주고 있습니다. 또한, 소프트웨어 발전에 의해 가능해진 독립 3D 디스플레이의 잠재력은 실시간 홀로그래피 및 시각에 독립적인 3D 콘텐츠에 대한 새로운 가능성을 제공하고 있습니다.</p>
<p>라이언은 약 10년전 Face Ring과 Apple의 아이폰 10의 얼굴 해제 시스템과 같은 앱으로 시작된 실시간 모션 캡처 기술의 발전에 대해 논의합니다. 인공지능은 얼굴 특징을 식별하고 실시간으로 추적하는 데 중요한 역할을 합니다.</p>
<p>라이언은 또한 특히 GDC에서 AR 51의 기술을 소개한 마커리스 모션 캡처에 대해 언급하며, 마커나 비싼 슈트가 필요 없이 전신 모션 캡처가 가능하다는 것을 강조합니다. Vicon과 OptiTrack과 같은 전통적인 모션 캡처 시스템은 카메라가 움직임을 추적할 수 있도록 몸에 마커를 사용하지만 이러한 시스템은 비용이 많이 들 수 있습니다. 라이언은 3D 프린팅이 더 비용 효율적인 해결책이 될 수 있다고 제안합니다.</p>
<div class="content-ad"></div>
<p>라이언은 AI를 활용한 마커 없는 동작 캡처 기술의 발전에 대해 이야기합니다. 마커 없는 동작 캡처 기술은 반사 마커와 비싼 장비가 필요 없어 IMU(관성 측정 장치) 기반 동작 캡처에 비해 비용 효율적인 대안이 됩니다.</p>
<p>라이언은 IMU 기반 시스템이 추적 정확도가 높지만, 드리프트에 취약하다고 언급합니다. 드리프트는 시스템이 물체의 3D 공간 내 위치를 이해하지 못하는 문제로, 지구의 자력과 전자 기기로 인해 추적에 사용되는 자력계에 영향을 줍니다.</p>
<h1>결론</h1>
<p>토론은 가상 현실(VR)에서 전신 동작 추적을 실시하는 도전과 AI 알고리즘 및 저렴한 카메라를 활용한 마커 없는 추적의 잠재적 해결책에 관한 내용으로 진행됩니다.</p>
<div class="content-ad"></div>
<p>라이언은 GDC에서 14대의 고급 카메라를 이용한 모션 트래킹 부스를 만난 경험을 언급합니다. 이는 대부분의 개인들에게 비용적으로 부담스럽고 비현실적이라고 합니다. 그러나 최근 AI 기술의 발전으로 싱글 웹캠과 거울만 사용하여 저렴한 비용으로 전신 모션 트래킹을 할 수 있게 되었다고 합니다.</p>
<p>라이언은 또한 이 설정에 대한 소프트웨어가 일반적으로 GitHub과 같은 오픈 소스로 작성된 Python이라고 밝힙니다.</p>
<p>라이언은 14대의 카메라를 이용해 실시간으로 여러 물체를 추적할 수 있는 새로운 AI 시스템의 능력에 대해 이야기합니다. 현재 전체 영역을 추적하는 데 9밀리초의 지연 시간이 걸리고 있으며, 이 시스템은 개인의 3D 모델을 생성할 수 있으며 알고리즘이 발전함에 따라 가격 및 처리 요구 사항 면에서 향상될 가능성이 있다고 합니다.</p>
<p>라이언은 최근 출시된 4K PTZ 웹캠 'Tail Pro'에 대한 언급도 합니다. 이 제품은 AI 추적 및 제스처 기반 제어 기능을 제공하며 500달러 정도로 가격이 비싼 회의실용 카메라 대안으로 더 저렴한 선택지가 될 수 있다고 합니다.</p>
<div class="content-ad"></div>
<p>라이언은 AR-51의 마커리스 모션 캡처 기술에 대해 이야기합니다. 이 기술은 특별한 수트나 마커 없이 실시간으로 사람들의 움직임을 추적할 수 있습니다. 이 기술은 저가 및 고가 카메라에 모두 사용되며 VR 설정을 포함합니다. 또한 마커 모션 캡처보다 상당히 저렴합니다.</p>
<p>라이언은 주변 카메라들이 실시간으로 두 사람이 VR에서 가위바위보를 하는 모습을 보여주며 기술을 시연합니다. 이 기술은 게임 개발과 같은 모션 캡처가 필요한 산업에 매우 유용할 것으로 예상되며, 기술 자체의 가격 하락으로 인해 스튜디오 임대 비용이 훨씬 낮아질 것으로 예상됩니다.</p>
<p>라이언은 한 번 설정한 후 추가 비용이 없어서 모션 캡처 요구 사항에 대한 비용 효율적인 해결책이 될 것이라고 언급합니다.</p>
<p>라이언은 3D 디스플레이 분야의 하드웨어 현황을 논의하며 독립형 3D 디스플레이의 미래에 대한 열정을 토로합니다. 그는 소프트웨어의 발전으로 실시간 홀로그래피 및 뷰에 독립적인 3D 콘텐츠의 표시가 쉬워질 것이므로 하드웨어 개선이 필요하지 않을 수 있다고 언급합니다.</p>
<div class="content-ad"></div>
<p>라이언은 5월에 열리는 디스플레이 위크 컨퍼런스를 기대하고 있습니다. 그곳에서는 더 나은 처리 및 라이트 필드 기술을 통해 이 분야에서의 진전을 보고 싶어합니다. 그는 VR을 위한 더 나은 디스플레이의 중요성을 강조하며, 현재의 디스플레이들은 밝은 빛에서 심지어 고급 제품들도 고전하는 것을 지적했습니다.</p>
<h1>Mindplex 소개</h1>
<p><img src="/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_5.png" alt="이미지"></p>
<p>아무리 고급 제품들도 밝은 빛에서 고전한다는 사실을 감안할 때, 디스플레이 개선이 무엇보다도 중요함을 잊지 말아주세요.</p>
<div class="content-ad"></div>
<p>Mindplex 팟캐스트 팀에서 여러분을 초대합니다. 함께 이 매혹적인 세상에 대해 사색하고 배우게 될 것입니다. 서로 돕고 이해를 돕는 것을 기대하며, 함께하면서 백인으로 일하는 도중에 마주친 모든 도전의 진정한 본질을 이해하고자 합니다.</p>
<p>Mindplex 팟캐스트와 Mindplex 매거진은 모두 SingularityNet에 의해 제공된 Mindplex 탈중앙화 미디어 플랫폼 파생입니다.</p>
<p>Mindplex 웹사이트를 방문하여 프로필을 설정하고 매거진에 기고할 수도 있습니다.</p>
<h1>팔로우해 주세요:</h1>
<div class="content-ad"></div>
<ul>
<li>Mindplex Magazine을 방문해주세요</li>
<li>저희 텔레그램에 가입해주세요</li>
<li>Mindplex 소셜에 가입해주세요</li>
<li>디스코드에 가입해주세요</li>
<li>트위터, 링크드인에서 팔로우해주세요</li>
<li>페이스북에서 좋아요를 눌러주세요</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"AI 혁명 3D 모델링과 모션 캡처","description":"","date":"2024-06-20 16:33","slug":"2024-06-20-TheAIRevolution3DModelingandMotionCapture","content":"\n\n![이미지](/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_0.png)\n\n3D 기술과 인공지능(AI)의 결합에 의해 디지턈 제작 분야에서 혁신의 새 시대가 열리고 있습니다. Mindplex Podcast의 이번 에피소드, '신기한 AI 3D 혁명'에서 전문가인 라이언 스턴리히트가 AI가 3D 스캐닝, 모델링 및 모션 캡처를 혁신하는 잠재력에 대해 논의합니다.\n\n이 에피소드는 게임 개발자 컨퍼런스(GDC)에서 볼 수 있는 혁신적인 혁신에 대한 흥미로운 통찰을 제공합니다.\n\n라이언에 따르면, 인공지능 덕분에 3D 스캐닝 및 렌더링 기술이 상당히 발전했습니다. 새로운 기술을 사용하면 이제 사람들이 스마트폰을 사용하여 고품질 스캔물을 만들고 심지어 인공지능을 이용하여 모델을 개선할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 AI, VR, 뉴로테크 및 3D 제조 분야를 전문으로 하는 전문가로, 최신 3D 스캐닝 개발에 대한 통찰을 공유합니다. 특히 포토그램메트리를 사용하여 사진으로부터 3D 모델을 만드는 것을 강조하며, 이 기술이 비디오 게임 및 역사 보존을 포함한 다양한 응용 분야에서의 중요성을 강조했습니다.\n\n![이미지](/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_1.png)\n\n라이언은 지난 몇 년간 3D 스캐닝 기술의 발전에 대해 논의합니다. 그는 2013년에 여러 방법으로 자신의 머리를 스캔한 경험을 공유하며, 이 작업에 약 주일이 걸렸다고 말합니다. 지금은 C 엔진과 같은 새로운 도구들이 있어서 핸드폰 카메라를 사용하여 데이터를 캡처하고 고품질 3D 스캔을 위해 클라우드에서 처리할 수 있습니다.\n\n이 기술은 작은 물체 스캔, 방 스캔, 심지어 텍스처 및 물리적 기반 렌더링(PBR)을 포함한 다양한 스캔 파이프라인을 처리할 수 있어서 스캔물이 더욱 현실적으로 보입니다. 그는 대부분의 핸드폰이 3D 스캔을 직접 처리할 수 없기 때문에 클라우드로 데이터를 업로드해 처리하는 것이 필요하다고 언급했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n몇 년 전에는 중대한 처리 요구 사항 때문에 불가능했지만, 이제 회사들이 3D 스캔의 무료 익스포트를 제공하여 프로세스가 더 접근 가능해졌습니다.\n\n# 인공지능이 3D 스캔 및 모델링에 미치는 영향\n\nRyan Sternlicht의 인사이트는 인공지능 기술에 기반한 3D 스캔 기술의 혁명적인 영향을 보여줍니다. 포토그램메트리와 같은 기술을 통해 인공지능은 일반 사진으로부터 고품질 3D 모델을 생성하게 하여 전통적인 방법의 한계를 넘어서게 합니다.\n\n스마트폰 기반 스캐닝에서 인공지능의 원활한 통합, 스캐닝 파이프라인의 정교화, 그리고 인공지능 생성 포토그램메트리 모델의 등장으로 3D 스캔의 환경이 재구성되어, 이전보다 더 접근 가능하고 효율적으로 만들어졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 3D 스캔 기술의 발전에 대해 이야기하며 특히 무료와 유료 모델 간의 차이점을 집중적으로 다루고 있습니다. 무료 버전은 가벼운 공간 스캔과 로우 폴리 변환 사용이 가능하며, 유료 버전에는 쿼드 메쉬와 PBR 소재를 포함한 리탑로지, AI 기반의 무특징 물체 모드가 포함되어 있습니다.\n\n라이언은 또한 반사, 투명 및 반투명 물질을 스캔하는 데 있던 역사적인 어려움과 NVIDIA 및 Microsoft에서 사용하는 신경 반경장치와 같은 AI 기술의 발전이 3D 스캔 프로세스를 크게 개선하여 더 빠르고 효율적으로 만들었음을 언급합니다. 이러한 새로운 AI 기반 포토그램메트리 모델은 3D 스캔 워크플로우를 혁신적으로 바꾸어 이미지로부터 몇 시간만에 고품질 3D 모델을 만들 수 있도록 했습니다.\n\n![이미지](/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_2.png)\n\n## NeRF 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 3D 스캔 기술의 발전, 특히 NeRF (신경 방사 조연체)에 대해 이야기합니다. 이 기술은 처리를 보다 효율적으로 만들어 GPU 부담을 줄여 프로세스를 혁신했습니다. 이 새로운 방법을 사용하여 과거의 3D 스캔 및 사진을 재처리할 수 있기 때문에 거꾸로 호환됩니다.\n\nNeRF는 정확히 확대하는 것이 아니라 기존 데이터를 개선하여 처리를 더 효율적으로 만들어 더 나은 모델과 부드러운 렌더링을 제공합니다. 이 기술은 여전히 GPU 부담이 있지만 처리 시간을 크게 줄여 충돌 및 기타 문제에 쉽게 노출되지 않도록 했습니다.\n\nNeRF는 고급 AI 주도의 사진측량 방법론이며 전통적인 사진측량과 유사점이 있지만 그 하위 집합은 아닙니다. 대신, 각 이미지의 시점을 처리하기 전에 결정하는 사진측량 과정의 다음 단계를 나타냅니다.\n\n# 3D 프린팅 및 모델링 혁신\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI는 3D 프린팅 프로세스를 간소화하고 오류 교정 메커니즘을 강화하며 모델 생성을 가속화하는 데 어떤 역할을 하는지 심층적인 대화가 이어지고 있어요.\n\nAI를 통한 실시간 오류 교정 및 AI 알고리즘을 3D 프린팅 기계에 통합함으로써 부가 제조 분야에서 얼마나 성취할 수 있는지의 경계가 더욱 넓혀지고 있어요. 게다가 이미지 및 텍스트에서 생성된 AI 3D 모델의 등장은 창의력을 위한 새로운 길을 여는데, 사용자들에게 전례없는 편의와 속도로 아이디어를 현실로 구현할 수 있게 돕고 있어요.\n\n라이언은 VR 기술을 사용하여 3D 객체를 스캔하는 데에 대해 논의하고 있어요. 그것이 내부 또는 외부의 관점에서든, 라이언은 이 기술이 포인트 클라우드와 포토그래메트리를 포함하며 색상과 반사를 잃은 무광의 외형을 가져올 수 있다고 설명하고 있어요.\n\n## 3D 가우시안 스플레팅 소개\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 AI 기술은 발전하여 분실된 정보를 검색하고 새로운 데이터를 추론하는 것이 가능해졌으며, 3D 가우시안 스플래팅과 같은 더 효율적인 기술의 개발을 이끌었습니다. 지난해 8월에 소개된 이 기술은 머신 러닝을 사용하여 이전의 NeRF 스캐닝과 같은 방법보다 정보를 더 효율적이고 효과적으로 처리합니다. 가상 세계에서 객체를 생성하는 데 사용되는 다양한 방법에도 불구하고, 렌더링된 후에는 환경 내의 보통 객체처럼 나타납니다.\n\n그들은 3D 스캐닝 및 포토그램메트리를 위한 특정 이미지 세트가 있으며, 비교를 위한 기준 역할을 한다고 설명합니다. 라이언은 다양한 툴셋 및 peak signal-to-noise ratio (PSNR) 및 렌더링 시간과 같은 메트릭을 사용하여 동일한 자전거 장면을 렌더링하는 다른 시스템을 비교합니다.\n\n이들은 이전에 사용된 myip NeRF와 같은 구식 방법은 3D 스캔을 학습하고 처리하는 데 48시간이 걸렸지만, 최근에 개발된 AI 기반 방법은 모델 품질이 더 좋게 높여 51분만에 같은 작업을 수행할 수 있다고 언급합니다. 이러한 기술들 사이의 출시 날짜 차는 약 8개월로, 처리 속도의 상당한 향상을 대표합니다. 이 비교는 가우시안 스플래팅과 Nerfing 사이의 것이며, 전자가 이 경우에는 더 빠른 옵션임을 나타냅니다. 라이언은 이러한 모델 중 많은 것들이 GitHub를 통해 쉽게 접근할 수 있다는 것을 언급하며 결론을 지었습니다.\n\n![이미지](/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 아바타 생성 및 실시간 렌더링\n\nDeemos Tech과 같은 기업들은 AI로 생성된 아바타의 개발을 선도하며, AI 파이프라인을 활용하여 초현실적인 디지털 펄소나를 만들어냅니다. AI를 아바타 생성에 접목함으로써 시각적인 충실도를 높이는데 그치지 않고, 이를 더 많은 사람들이 이용할 수 있도록 하는 데 기여하고 있습니다.\n\n라이언은 최근 AI로 생성된 3D 모델의 발전에 대해 논의하며, 새로운 방법론을 활용하여 장면의 특정 부분에서 발생하는 흐릿한 문제에 대응하고 있습니다. 이 방법은 장면의 특정 영역의 처리를 개선하고 모델을 약간 수정하여 누락된 정보를 보완하는 것을 포함합니다. 라이언은 이 방법론이 업스케일링과 유사하다고 언급하며, 이는 해당 영역에 존재하지 않는 정보를 보충함으로써 실현됩니다.\n\n## NeRFs, 3D Gaussian Splatting 및 SMERF가 사진측량 및 AI 모델 혁명을 일으킵니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실시간 렌더링 기술의 발전으로 Neural Radiance Fields (NeRF) 및 3D Gaussian splatting과 같은 기술이 3D 모델 시각화를 혁신하며, 이에 따른 현실감과 상호작용성이 향상되고 있습니다.\n\n이 토론은 NeRF를 위한 실시간 대규모 시각화용으로 수정된 SMERF에 대해서도 다루고 있습니다. 모바일 기기에서 전체 3D 스캔을 실시간으로 돌아다니며 살펴볼 수 있는 기술을 제공함으로써 이제 폰에서 실행되며 사용자가 실시간으로 3D 스캔을 탐험할 수 있는 SMERF의 혁신에 대해 다루고 있습니다.\n\n라이언은 NeRF (Neural Radiance Fields)와 3D Gaussian splatting에 중점을 두어 3D 모델링 기술의 발전을 논의합니다. 이전에는 모바일 기기에서 3D 모델을 보기 위해 MP4 파일을 생성해야 했지만, 이제는 헤드셋을 사용하거나 브라우저에서도 실시간으로 모델을 볼 수 있습니다.\n\n라이언은 이를 실시간으로 랩탑과 브라우저에서 보여줌으로써 각종 씬들이 실행되는 모습을 시연합니다. 이 모델에 사용된 파일 형식은 네이티브가 아니지만, Unity와 같은 다양한 도구를 사용하여 생성할 수 있습니다. NeRF와 3D Gaussian splatting은 전통적인 포토그래메트리에 비해 투명도와 반사 처리 등에서 상당한 개선을 제공하며, 이전에는 불가능했던 처리도 가능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![2024-06-20-TheAIRevolution3DModelingandMotionCapture_4](/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_4.png)\n\nRyan씨는 또한 이 스캔에 빌트인된 실시간 물리학의 발전을 언급하며 빛 상호작용과 반사를 더 잘 이해할 수 있게 되었다고 설명합니다. 이전에는 와인 잔과 같은 투명한 물체가 정확하게 스캔되지 못하고 불투명하게 보였지만, 이제는 올바르게 스캔 및 렌더링할 수 있다고 합니다.\n\nRyan은 3D 프린팅 모델의 실시간 오류 보정 기술에 대한 발전을 논의하고 이것이 3D 프린팅 산업과의 관계에 대해 설명합니다. Ryan은 실시간 물리학과 기계 학습 알고리즘의 결합이 보다 빠르고 품질 좋은 3D 프린팅을 가능하게 한다고 설명하며, 이전에 어려웠거나 불가능했던 물체를 만들 수 있게 되었다고 합니다.\n\nRyan은 속도보트 경주를 언급하기도 하는데, 가장 빨리 표준 3D 모델을 인쇄하는 경쟁이며, 현재 세계 기록은 딱 2분이라고 합니다. 기계 학습을 주로 기반으로 한 오류 보정 과정이 프린팅 중에 발생하는 오류를 예측하고 조정하므로 품질이 향상되고 생산 시간이 빨라집니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 3D 프린팅 기술의 발전에 대해 이야기했어요. 특히, AI 알고리즘이 내장된 400달러짜리 기계로 빠르게 만드는 과정을 소개했어요. 이 기계는 속도가 빨라 카메라가 속도를 촬영하기 어렵다고 해요. 또한, 3D 프린팅된 물체와 웨어러블 또는 가상 의류 간의 연결에 대해 언급했어요. Marvelous Designers와 Style 3D 같은 기업들이 AI를 사용하여 옷 이미지를 3D 모델로 변환하여 비디오 게임 캐릭터에 입히는 작업을 진행 중이라고 해요. 게다가, 비디오 게임에서 AI 기술을 사용하여 아바타를 개선하는 데 초점을 맞추고 있다고 해요. 라이언은 GDC 컨퍼런스에서 이에 대한 인상적인 시연을 보았다고 전했어요.\n\n라이언은 Deemos Tech에 대해 언급했어요. 이 회사는 AI가 생성한 아바타 분야의 발전으로 유명하다고 해요. Deemos Tech은 GDC에서 자사의 기술을 선보였는데, 이들의 아바타 생성기를 게임 \"Earth Revival\"에 통합했다고 해요. 시스템은 얼굴 교체 및 재구성을 위한 Dream Face, 이미지에서 3D 모델로 변환하는 도구 등을 포함해 세 가지 다른 AI 파이프라인을 사용한다고 해요. VFX 산업에서의 Deemos Tech의 배경과 다양한 얼굴 3D 스캔을 통해 그들은 고급 아바타를 생성할 수 있었다고 해요. Hyper Human 도구를 사용하면 사용자가 업로드한 이미지로부터 모델을 생성할 수 있어 작업이 더 쉬워졌다.\n\n라이언은 이미지와 텍스트에서 3D 모델을 생성하기 위해 AI를 사용하는 것에 대해 이야기했어요. 라이언은 사진으로부터 3D 모델을 생성하는 경험을 공유했는데, 좋은 결과를 얻기 위해 명확하고 정면의 이미지의 중요성을 강조했어요. 또한 텍스트에서 3D 모델을 생성하는 가능성에 대해 언급했지만 시도하려면 로그인이 필요하다고 하였다. 그 비디오는 베타 버전의 멀티모달 3D 검색 엔진을 소개하는데, 이는 사용자가 이미지를 업로드하고 온라인에서 유사한 3D 모델을 검색할 수 있게 해줍니다. 얼굴 래깅 및 실시간 얼굴 캡처 도구로 3D 모델을 생성 및 처리하기 위한 파이프라인이 더 자동화되어 작업이 덜 복잡해졌다고 해요. 라이언은 이 발전을 V튜빙의 인기와 더 사실적인 아바타에 대한 열망에 귀속시켰다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토론은 마커리스 동작 캡처 기술까지 확장되었는데, 인공지능 알고리즘이 비싼 장비와 마커의 필요성을 없애고 있습니다.\n\nAR-51의 마커리스 추적 시스템과 같은 혁신적인 솔루션을 통해 전신 모션 캡처가 더욱 접근 가능하고 비용 효율적으로 구현되어 현실감 넘치는 가상 경험을 열어 주고 있습니다. 또한, 소프트웨어 발전에 의해 가능해진 독립 3D 디스플레이의 잠재력은 실시간 홀로그래피 및 시각에 독립적인 3D 콘텐츠에 대한 새로운 가능성을 제공하고 있습니다.\n\n라이언은 약 10년전 Face Ring과 Apple의 아이폰 10의 얼굴 해제 시스템과 같은 앱으로 시작된 실시간 모션 캡처 기술의 발전에 대해 논의합니다. 인공지능은 얼굴 특징을 식별하고 실시간으로 추적하는 데 중요한 역할을 합니다.\n\n라이언은 또한 특히 GDC에서 AR 51의 기술을 소개한 마커리스 모션 캡처에 대해 언급하며, 마커나 비싼 슈트가 필요 없이 전신 모션 캡처가 가능하다는 것을 강조합니다. Vicon과 OptiTrack과 같은 전통적인 모션 캡처 시스템은 카메라가 움직임을 추적할 수 있도록 몸에 마커를 사용하지만 이러한 시스템은 비용이 많이 들 수 있습니다. 라이언은 3D 프린팅이 더 비용 효율적인 해결책이 될 수 있다고 제안합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 AI를 활용한 마커 없는 동작 캡처 기술의 발전에 대해 이야기합니다. 마커 없는 동작 캡처 기술은 반사 마커와 비싼 장비가 필요 없어 IMU(관성 측정 장치) 기반 동작 캡처에 비해 비용 효율적인 대안이 됩니다.\n\n라이언은 IMU 기반 시스템이 추적 정확도가 높지만, 드리프트에 취약하다고 언급합니다. 드리프트는 시스템이 물체의 3D 공간 내 위치를 이해하지 못하는 문제로, 지구의 자력과 전자 기기로 인해 추적에 사용되는 자력계에 영향을 줍니다.\n\n# 결론\n\n토론은 가상 현실(VR)에서 전신 동작 추적을 실시하는 도전과 AI 알고리즘 및 저렴한 카메라를 활용한 마커 없는 추적의 잠재적 해결책에 관한 내용으로 진행됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 GDC에서 14대의 고급 카메라를 이용한 모션 트래킹 부스를 만난 경험을 언급합니다. 이는 대부분의 개인들에게 비용적으로 부담스럽고 비현실적이라고 합니다. 그러나 최근 AI 기술의 발전으로 싱글 웹캠과 거울만 사용하여 저렴한 비용으로 전신 모션 트래킹을 할 수 있게 되었다고 합니다.\n\n라이언은 또한 이 설정에 대한 소프트웨어가 일반적으로 GitHub과 같은 오픈 소스로 작성된 Python이라고 밝힙니다.\n\n라이언은 14대의 카메라를 이용해 실시간으로 여러 물체를 추적할 수 있는 새로운 AI 시스템의 능력에 대해 이야기합니다. 현재 전체 영역을 추적하는 데 9밀리초의 지연 시간이 걸리고 있으며, 이 시스템은 개인의 3D 모델을 생성할 수 있으며 알고리즘이 발전함에 따라 가격 및 처리 요구 사항 면에서 향상될 가능성이 있다고 합니다.\n\n라이언은 최근 출시된 4K PTZ 웹캠 'Tail Pro'에 대한 언급도 합니다. 이 제품은 AI 추적 및 제스처 기반 제어 기능을 제공하며 500달러 정도로 가격이 비싼 회의실용 카메라 대안으로 더 저렴한 선택지가 될 수 있다고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 AR-51의 마커리스 모션 캡처 기술에 대해 이야기합니다. 이 기술은 특별한 수트나 마커 없이 실시간으로 사람들의 움직임을 추적할 수 있습니다. 이 기술은 저가 및 고가 카메라에 모두 사용되며 VR 설정을 포함합니다. 또한 마커 모션 캡처보다 상당히 저렴합니다.\n\n라이언은 주변 카메라들이 실시간으로 두 사람이 VR에서 가위바위보를 하는 모습을 보여주며 기술을 시연합니다. 이 기술은 게임 개발과 같은 모션 캡처가 필요한 산업에 매우 유용할 것으로 예상되며, 기술 자체의 가격 하락으로 인해 스튜디오 임대 비용이 훨씬 낮아질 것으로 예상됩니다.\n\n라이언은 한 번 설정한 후 추가 비용이 없어서 모션 캡처 요구 사항에 대한 비용 효율적인 해결책이 될 것이라고 언급합니다.\n\n라이언은 3D 디스플레이 분야의 하드웨어 현황을 논의하며 독립형 3D 디스플레이의 미래에 대한 열정을 토로합니다. 그는 소프트웨어의 발전으로 실시간 홀로그래피 및 뷰에 독립적인 3D 콘텐츠의 표시가 쉬워질 것이므로 하드웨어 개선이 필요하지 않을 수 있다고 언급합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이언은 5월에 열리는 디스플레이 위크 컨퍼런스를 기대하고 있습니다. 그곳에서는 더 나은 처리 및 라이트 필드 기술을 통해 이 분야에서의 진전을 보고 싶어합니다. 그는 VR을 위한 더 나은 디스플레이의 중요성을 강조하며, 현재의 디스플레이들은 밝은 빛에서 심지어 고급 제품들도 고전하는 것을 지적했습니다.\n\n# Mindplex 소개\n\n![이미지](/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_5.png)\n\n아무리 고급 제품들도 밝은 빛에서 고전한다는 사실을 감안할 때, 디스플레이 개선이 무엇보다도 중요함을 잊지 말아주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMindplex 팟캐스트 팀에서 여러분을 초대합니다. 함께 이 매혹적인 세상에 대해 사색하고 배우게 될 것입니다. 서로 돕고 이해를 돕는 것을 기대하며, 함께하면서 백인으로 일하는 도중에 마주친 모든 도전의 진정한 본질을 이해하고자 합니다. \n\nMindplex 팟캐스트와 Mindplex 매거진은 모두 SingularityNet에 의해 제공된 Mindplex 탈중앙화 미디어 플랫폼 파생입니다.\n\nMindplex 웹사이트를 방문하여 프로필을 설정하고 매거진에 기고할 수도 있습니다.\n\n# 팔로우해 주세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Mindplex Magazine을 방문해주세요\n- 저희 텔레그램에 가입해주세요\n- Mindplex 소셜에 가입해주세요\n- 디스코드에 가입해주세요\n- 트위터, 링크드인에서 팔로우해주세요\n- 페이스북에서 좋아요를 눌러주세요","ogImage":{"url":"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_0.png"},"coverImage":"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_0.png","tag":["Tech"],"readingTime":10},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e3D 기술과 인공지능(AI)의 결합에 의해 디지턈 제작 분야에서 혁신의 새 시대가 열리고 있습니다. Mindplex Podcast의 이번 에피소드, '신기한 AI 3D 혁명'에서 전문가인 라이언 스턴리히트가 AI가 3D 스캐닝, 모델링 및 모션 캡처를 혁신하는 잠재력에 대해 논의합니다.\u003c/p\u003e\n\u003cp\u003e이 에피소드는 게임 개발자 컨퍼런스(GDC)에서 볼 수 있는 혁신적인 혁신에 대한 흥미로운 통찰을 제공합니다.\u003c/p\u003e\n\u003cp\u003e라이언에 따르면, 인공지능 덕분에 3D 스캐닝 및 렌더링 기술이 상당히 발전했습니다. 새로운 기술을 사용하면 이제 사람들이 스마트폰을 사용하여 고품질 스캔물을 만들고 심지어 인공지능을 이용하여 모델을 개선할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 AI, VR, 뉴로테크 및 3D 제조 분야를 전문으로 하는 전문가로, 최신 3D 스캐닝 개발에 대한 통찰을 공유합니다. 특히 포토그램메트리를 사용하여 사진으로부터 3D 모델을 만드는 것을 강조하며, 이 기술이 비디오 게임 및 역사 보존을 포함한 다양한 응용 분야에서의 중요성을 강조했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e라이언은 지난 몇 년간 3D 스캐닝 기술의 발전에 대해 논의합니다. 그는 2013년에 여러 방법으로 자신의 머리를 스캔한 경험을 공유하며, 이 작업에 약 주일이 걸렸다고 말합니다. 지금은 C 엔진과 같은 새로운 도구들이 있어서 핸드폰 카메라를 사용하여 데이터를 캡처하고 고품질 3D 스캔을 위해 클라우드에서 처리할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이 기술은 작은 물체 스캔, 방 스캔, 심지어 텍스처 및 물리적 기반 렌더링(PBR)을 포함한 다양한 스캔 파이프라인을 처리할 수 있어서 스캔물이 더욱 현실적으로 보입니다. 그는 대부분의 핸드폰이 3D 스캔을 직접 처리할 수 없기 때문에 클라우드로 데이터를 업로드해 처리하는 것이 필요하다고 언급했습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e몇 년 전에는 중대한 처리 요구 사항 때문에 불가능했지만, 이제 회사들이 3D 스캔의 무료 익스포트를 제공하여 프로세스가 더 접근 가능해졌습니다.\u003c/p\u003e\n\u003ch1\u003e인공지능이 3D 스캔 및 모델링에 미치는 영향\u003c/h1\u003e\n\u003cp\u003eRyan Sternlicht의 인사이트는 인공지능 기술에 기반한 3D 스캔 기술의 혁명적인 영향을 보여줍니다. 포토그램메트리와 같은 기술을 통해 인공지능은 일반 사진으로부터 고품질 3D 모델을 생성하게 하여 전통적인 방법의 한계를 넘어서게 합니다.\u003c/p\u003e\n\u003cp\u003e스마트폰 기반 스캐닝에서 인공지능의 원활한 통합, 스캐닝 파이프라인의 정교화, 그리고 인공지능 생성 포토그램메트리 모델의 등장으로 3D 스캔의 환경이 재구성되어, 이전보다 더 접근 가능하고 효율적으로 만들어졌습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 3D 스캔 기술의 발전에 대해 이야기하며 특히 무료와 유료 모델 간의 차이점을 집중적으로 다루고 있습니다. 무료 버전은 가벼운 공간 스캔과 로우 폴리 변환 사용이 가능하며, 유료 버전에는 쿼드 메쉬와 PBR 소재를 포함한 리탑로지, AI 기반의 무특징 물체 모드가 포함되어 있습니다.\u003c/p\u003e\n\u003cp\u003e라이언은 또한 반사, 투명 및 반투명 물질을 스캔하는 데 있던 역사적인 어려움과 NVIDIA 및 Microsoft에서 사용하는 신경 반경장치와 같은 AI 기술의 발전이 3D 스캔 프로세스를 크게 개선하여 더 빠르고 효율적으로 만들었음을 언급합니다. 이러한 새로운 AI 기반 포토그램메트리 모델은 3D 스캔 워크플로우를 혁신적으로 바꾸어 이미지로부터 몇 시간만에 고품질 3D 모델을 만들 수 있도록 했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch2\u003eNeRF 소개\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 3D 스캔 기술의 발전, 특히 NeRF (신경 방사 조연체)에 대해 이야기합니다. 이 기술은 처리를 보다 효율적으로 만들어 GPU 부담을 줄여 프로세스를 혁신했습니다. 이 새로운 방법을 사용하여 과거의 3D 스캔 및 사진을 재처리할 수 있기 때문에 거꾸로 호환됩니다.\u003c/p\u003e\n\u003cp\u003eNeRF는 정확히 확대하는 것이 아니라 기존 데이터를 개선하여 처리를 더 효율적으로 만들어 더 나은 모델과 부드러운 렌더링을 제공합니다. 이 기술은 여전히 GPU 부담이 있지만 처리 시간을 크게 줄여 충돌 및 기타 문제에 쉽게 노출되지 않도록 했습니다.\u003c/p\u003e\n\u003cp\u003eNeRF는 고급 AI 주도의 사진측량 방법론이며 전통적인 사진측량과 유사점이 있지만 그 하위 집합은 아닙니다. 대신, 각 이미지의 시점을 처리하기 전에 결정하는 사진측량 과정의 다음 단계를 나타냅니다.\u003c/p\u003e\n\u003ch1\u003e3D 프린팅 및 모델링 혁신\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eAI는 3D 프린팅 프로세스를 간소화하고 오류 교정 메커니즘을 강화하며 모델 생성을 가속화하는 데 어떤 역할을 하는지 심층적인 대화가 이어지고 있어요.\u003c/p\u003e\n\u003cp\u003eAI를 통한 실시간 오류 교정 및 AI 알고리즘을 3D 프린팅 기계에 통합함으로써 부가 제조 분야에서 얼마나 성취할 수 있는지의 경계가 더욱 넓혀지고 있어요. 게다가 이미지 및 텍스트에서 생성된 AI 3D 모델의 등장은 창의력을 위한 새로운 길을 여는데, 사용자들에게 전례없는 편의와 속도로 아이디어를 현실로 구현할 수 있게 돕고 있어요.\u003c/p\u003e\n\u003cp\u003e라이언은 VR 기술을 사용하여 3D 객체를 스캔하는 데에 대해 논의하고 있어요. 그것이 내부 또는 외부의 관점에서든, 라이언은 이 기술이 포인트 클라우드와 포토그래메트리를 포함하며 색상과 반사를 잃은 무광의 외형을 가져올 수 있다고 설명하고 있어요.\u003c/p\u003e\n\u003ch2\u003e3D 가우시안 스플레팅 소개\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그러나 AI 기술은 발전하여 분실된 정보를 검색하고 새로운 데이터를 추론하는 것이 가능해졌으며, 3D 가우시안 스플래팅과 같은 더 효율적인 기술의 개발을 이끌었습니다. 지난해 8월에 소개된 이 기술은 머신 러닝을 사용하여 이전의 NeRF 스캐닝과 같은 방법보다 정보를 더 효율적이고 효과적으로 처리합니다. 가상 세계에서 객체를 생성하는 데 사용되는 다양한 방법에도 불구하고, 렌더링된 후에는 환경 내의 보통 객체처럼 나타납니다.\u003c/p\u003e\n\u003cp\u003e그들은 3D 스캐닝 및 포토그램메트리를 위한 특정 이미지 세트가 있으며, 비교를 위한 기준 역할을 한다고 설명합니다. 라이언은 다양한 툴셋 및 peak signal-to-noise ratio (PSNR) 및 렌더링 시간과 같은 메트릭을 사용하여 동일한 자전거 장면을 렌더링하는 다른 시스템을 비교합니다.\u003c/p\u003e\n\u003cp\u003e이들은 이전에 사용된 myip NeRF와 같은 구식 방법은 3D 스캔을 학습하고 처리하는 데 48시간이 걸렸지만, 최근에 개발된 AI 기반 방법은 모델 품질이 더 좋게 높여 51분만에 같은 작업을 수행할 수 있다고 언급합니다. 이러한 기술들 사이의 출시 날짜 차는 약 8개월로, 처리 속도의 상당한 향상을 대표합니다. 이 비교는 가우시안 스플래팅과 Nerfing 사이의 것이며, 전자가 이 경우에는 더 빠른 옵션임을 나타냅니다. 라이언은 이러한 모델 중 많은 것들이 GitHub를 통해 쉽게 접근할 수 있다는 것을 언급하며 결론을 지었습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e아바타 생성 및 실시간 렌더링\u003c/h1\u003e\n\u003cp\u003eDeemos Tech과 같은 기업들은 AI로 생성된 아바타의 개발을 선도하며, AI 파이프라인을 활용하여 초현실적인 디지털 펄소나를 만들어냅니다. AI를 아바타 생성에 접목함으로써 시각적인 충실도를 높이는데 그치지 않고, 이를 더 많은 사람들이 이용할 수 있도록 하는 데 기여하고 있습니다.\u003c/p\u003e\n\u003cp\u003e라이언은 최근 AI로 생성된 3D 모델의 발전에 대해 논의하며, 새로운 방법론을 활용하여 장면의 특정 부분에서 발생하는 흐릿한 문제에 대응하고 있습니다. 이 방법은 장면의 특정 영역의 처리를 개선하고 모델을 약간 수정하여 누락된 정보를 보완하는 것을 포함합니다. 라이언은 이 방법론이 업스케일링과 유사하다고 언급하며, 이는 해당 영역에 존재하지 않는 정보를 보충함으로써 실현됩니다.\u003c/p\u003e\n\u003ch2\u003eNeRFs, 3D Gaussian Splatting 및 SMERF가 사진측량 및 AI 모델 혁명을 일으킵니다\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e실시간 렌더링 기술의 발전으로 Neural Radiance Fields (NeRF) 및 3D Gaussian splatting과 같은 기술이 3D 모델 시각화를 혁신하며, 이에 따른 현실감과 상호작용성이 향상되고 있습니다.\u003c/p\u003e\n\u003cp\u003e이 토론은 NeRF를 위한 실시간 대규모 시각화용으로 수정된 SMERF에 대해서도 다루고 있습니다. 모바일 기기에서 전체 3D 스캔을 실시간으로 돌아다니며 살펴볼 수 있는 기술을 제공함으로써 이제 폰에서 실행되며 사용자가 실시간으로 3D 스캔을 탐험할 수 있는 SMERF의 혁신에 대해 다루고 있습니다.\u003c/p\u003e\n\u003cp\u003e라이언은 NeRF (Neural Radiance Fields)와 3D Gaussian splatting에 중점을 두어 3D 모델링 기술의 발전을 논의합니다. 이전에는 모바일 기기에서 3D 모델을 보기 위해 MP4 파일을 생성해야 했지만, 이제는 헤드셋을 사용하거나 브라우저에서도 실시간으로 모델을 볼 수 있습니다.\u003c/p\u003e\n\u003cp\u003e라이언은 이를 실시간으로 랩탑과 브라우저에서 보여줌으로써 각종 씬들이 실행되는 모습을 시연합니다. 이 모델에 사용된 파일 형식은 네이티브가 아니지만, Unity와 같은 다양한 도구를 사용하여 생성할 수 있습니다. NeRF와 3D Gaussian splatting은 전통적인 포토그래메트리에 비해 투명도와 반사 처리 등에서 상당한 개선을 제공하며, 이전에는 불가능했던 처리도 가능합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_4.png\" alt=\"2024-06-20-TheAIRevolution3DModelingandMotionCapture_4\"\u003e\u003c/p\u003e\n\u003cp\u003eRyan씨는 또한 이 스캔에 빌트인된 실시간 물리학의 발전을 언급하며 빛 상호작용과 반사를 더 잘 이해할 수 있게 되었다고 설명합니다. 이전에는 와인 잔과 같은 투명한 물체가 정확하게 스캔되지 못하고 불투명하게 보였지만, 이제는 올바르게 스캔 및 렌더링할 수 있다고 합니다.\u003c/p\u003e\n\u003cp\u003eRyan은 3D 프린팅 모델의 실시간 오류 보정 기술에 대한 발전을 논의하고 이것이 3D 프린팅 산업과의 관계에 대해 설명합니다. Ryan은 실시간 물리학과 기계 학습 알고리즘의 결합이 보다 빠르고 품질 좋은 3D 프린팅을 가능하게 한다고 설명하며, 이전에 어려웠거나 불가능했던 물체를 만들 수 있게 되었다고 합니다.\u003c/p\u003e\n\u003cp\u003eRyan은 속도보트 경주를 언급하기도 하는데, 가장 빨리 표준 3D 모델을 인쇄하는 경쟁이며, 현재 세계 기록은 딱 2분이라고 합니다. 기계 학습을 주로 기반으로 한 오류 보정 과정이 프린팅 중에 발생하는 오류를 예측하고 조정하므로 품질이 향상되고 생산 시간이 빨라집니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 3D 프린팅 기술의 발전에 대해 이야기했어요. 특히, AI 알고리즘이 내장된 400달러짜리 기계로 빠르게 만드는 과정을 소개했어요. 이 기계는 속도가 빨라 카메라가 속도를 촬영하기 어렵다고 해요. 또한, 3D 프린팅된 물체와 웨어러블 또는 가상 의류 간의 연결에 대해 언급했어요. Marvelous Designers와 Style 3D 같은 기업들이 AI를 사용하여 옷 이미지를 3D 모델로 변환하여 비디오 게임 캐릭터에 입히는 작업을 진행 중이라고 해요. 게다가, 비디오 게임에서 AI 기술을 사용하여 아바타를 개선하는 데 초점을 맞추고 있다고 해요. 라이언은 GDC 컨퍼런스에서 이에 대한 인상적인 시연을 보았다고 전했어요.\u003c/p\u003e\n\u003cp\u003e라이언은 Deemos Tech에 대해 언급했어요. 이 회사는 AI가 생성한 아바타 분야의 발전으로 유명하다고 해요. Deemos Tech은 GDC에서 자사의 기술을 선보였는데, 이들의 아바타 생성기를 게임 \"Earth Revival\"에 통합했다고 해요. 시스템은 얼굴 교체 및 재구성을 위한 Dream Face, 이미지에서 3D 모델로 변환하는 도구 등을 포함해 세 가지 다른 AI 파이프라인을 사용한다고 해요. VFX 산업에서의 Deemos Tech의 배경과 다양한 얼굴 3D 스캔을 통해 그들은 고급 아바타를 생성할 수 있었다고 해요. Hyper Human 도구를 사용하면 사용자가 업로드한 이미지로부터 모델을 생성할 수 있어 작업이 더 쉬워졌다.\u003c/p\u003e\n\u003cp\u003e라이언은 이미지와 텍스트에서 3D 모델을 생성하기 위해 AI를 사용하는 것에 대해 이야기했어요. 라이언은 사진으로부터 3D 모델을 생성하는 경험을 공유했는데, 좋은 결과를 얻기 위해 명확하고 정면의 이미지의 중요성을 강조했어요. 또한 텍스트에서 3D 모델을 생성하는 가능성에 대해 언급했지만 시도하려면 로그인이 필요하다고 하였다. 그 비디오는 베타 버전의 멀티모달 3D 검색 엔진을 소개하는데, 이는 사용자가 이미지를 업로드하고 온라인에서 유사한 3D 모델을 검색할 수 있게 해줍니다. 얼굴 래깅 및 실시간 얼굴 캡처 도구로 3D 모델을 생성 및 처리하기 위한 파이프라인이 더 자동화되어 작업이 덜 복잡해졌다고 해요. 라이언은 이 발전을 V튜빙의 인기와 더 사실적인 아바타에 대한 열망에 귀속시켰다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e토론은 마커리스 동작 캡처 기술까지 확장되었는데, 인공지능 알고리즘이 비싼 장비와 마커의 필요성을 없애고 있습니다.\u003c/p\u003e\n\u003cp\u003eAR-51의 마커리스 추적 시스템과 같은 혁신적인 솔루션을 통해 전신 모션 캡처가 더욱 접근 가능하고 비용 효율적으로 구현되어 현실감 넘치는 가상 경험을 열어 주고 있습니다. 또한, 소프트웨어 발전에 의해 가능해진 독립 3D 디스플레이의 잠재력은 실시간 홀로그래피 및 시각에 독립적인 3D 콘텐츠에 대한 새로운 가능성을 제공하고 있습니다.\u003c/p\u003e\n\u003cp\u003e라이언은 약 10년전 Face Ring과 Apple의 아이폰 10의 얼굴 해제 시스템과 같은 앱으로 시작된 실시간 모션 캡처 기술의 발전에 대해 논의합니다. 인공지능은 얼굴 특징을 식별하고 실시간으로 추적하는 데 중요한 역할을 합니다.\u003c/p\u003e\n\u003cp\u003e라이언은 또한 특히 GDC에서 AR 51의 기술을 소개한 마커리스 모션 캡처에 대해 언급하며, 마커나 비싼 슈트가 필요 없이 전신 모션 캡처가 가능하다는 것을 강조합니다. Vicon과 OptiTrack과 같은 전통적인 모션 캡처 시스템은 카메라가 움직임을 추적할 수 있도록 몸에 마커를 사용하지만 이러한 시스템은 비용이 많이 들 수 있습니다. 라이언은 3D 프린팅이 더 비용 효율적인 해결책이 될 수 있다고 제안합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 AI를 활용한 마커 없는 동작 캡처 기술의 발전에 대해 이야기합니다. 마커 없는 동작 캡처 기술은 반사 마커와 비싼 장비가 필요 없어 IMU(관성 측정 장치) 기반 동작 캡처에 비해 비용 효율적인 대안이 됩니다.\u003c/p\u003e\n\u003cp\u003e라이언은 IMU 기반 시스템이 추적 정확도가 높지만, 드리프트에 취약하다고 언급합니다. 드리프트는 시스템이 물체의 3D 공간 내 위치를 이해하지 못하는 문제로, 지구의 자력과 전자 기기로 인해 추적에 사용되는 자력계에 영향을 줍니다.\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e토론은 가상 현실(VR)에서 전신 동작 추적을 실시하는 도전과 AI 알고리즘 및 저렴한 카메라를 활용한 마커 없는 추적의 잠재적 해결책에 관한 내용으로 진행됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 GDC에서 14대의 고급 카메라를 이용한 모션 트래킹 부스를 만난 경험을 언급합니다. 이는 대부분의 개인들에게 비용적으로 부담스럽고 비현실적이라고 합니다. 그러나 최근 AI 기술의 발전으로 싱글 웹캠과 거울만 사용하여 저렴한 비용으로 전신 모션 트래킹을 할 수 있게 되었다고 합니다.\u003c/p\u003e\n\u003cp\u003e라이언은 또한 이 설정에 대한 소프트웨어가 일반적으로 GitHub과 같은 오픈 소스로 작성된 Python이라고 밝힙니다.\u003c/p\u003e\n\u003cp\u003e라이언은 14대의 카메라를 이용해 실시간으로 여러 물체를 추적할 수 있는 새로운 AI 시스템의 능력에 대해 이야기합니다. 현재 전체 영역을 추적하는 데 9밀리초의 지연 시간이 걸리고 있으며, 이 시스템은 개인의 3D 모델을 생성할 수 있으며 알고리즘이 발전함에 따라 가격 및 처리 요구 사항 면에서 향상될 가능성이 있다고 합니다.\u003c/p\u003e\n\u003cp\u003e라이언은 최근 출시된 4K PTZ 웹캠 'Tail Pro'에 대한 언급도 합니다. 이 제품은 AI 추적 및 제스처 기반 제어 기능을 제공하며 500달러 정도로 가격이 비싼 회의실용 카메라 대안으로 더 저렴한 선택지가 될 수 있다고 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 AR-51의 마커리스 모션 캡처 기술에 대해 이야기합니다. 이 기술은 특별한 수트나 마커 없이 실시간으로 사람들의 움직임을 추적할 수 있습니다. 이 기술은 저가 및 고가 카메라에 모두 사용되며 VR 설정을 포함합니다. 또한 마커 모션 캡처보다 상당히 저렴합니다.\u003c/p\u003e\n\u003cp\u003e라이언은 주변 카메라들이 실시간으로 두 사람이 VR에서 가위바위보를 하는 모습을 보여주며 기술을 시연합니다. 이 기술은 게임 개발과 같은 모션 캡처가 필요한 산업에 매우 유용할 것으로 예상되며, 기술 자체의 가격 하락으로 인해 스튜디오 임대 비용이 훨씬 낮아질 것으로 예상됩니다.\u003c/p\u003e\n\u003cp\u003e라이언은 한 번 설정한 후 추가 비용이 없어서 모션 캡처 요구 사항에 대한 비용 효율적인 해결책이 될 것이라고 언급합니다.\u003c/p\u003e\n\u003cp\u003e라이언은 3D 디스플레이 분야의 하드웨어 현황을 논의하며 독립형 3D 디스플레이의 미래에 대한 열정을 토로합니다. 그는 소프트웨어의 발전으로 실시간 홀로그래피 및 뷰에 독립적인 3D 콘텐츠의 표시가 쉬워질 것이므로 하드웨어 개선이 필요하지 않을 수 있다고 언급합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e라이언은 5월에 열리는 디스플레이 위크 컨퍼런스를 기대하고 있습니다. 그곳에서는 더 나은 처리 및 라이트 필드 기술을 통해 이 분야에서의 진전을 보고 싶어합니다. 그는 VR을 위한 더 나은 디스플레이의 중요성을 강조하며, 현재의 디스플레이들은 밝은 빛에서 심지어 고급 제품들도 고전하는 것을 지적했습니다.\u003c/p\u003e\n\u003ch1\u003eMindplex 소개\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-TheAIRevolution3DModelingandMotionCapture_5.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e아무리 고급 제품들도 밝은 빛에서 고전한다는 사실을 감안할 때, 디스플레이 개선이 무엇보다도 중요함을 잊지 말아주세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eMindplex 팟캐스트 팀에서 여러분을 초대합니다. 함께 이 매혹적인 세상에 대해 사색하고 배우게 될 것입니다. 서로 돕고 이해를 돕는 것을 기대하며, 함께하면서 백인으로 일하는 도중에 마주친 모든 도전의 진정한 본질을 이해하고자 합니다.\u003c/p\u003e\n\u003cp\u003eMindplex 팟캐스트와 Mindplex 매거진은 모두 SingularityNet에 의해 제공된 Mindplex 탈중앙화 미디어 플랫폼 파생입니다.\u003c/p\u003e\n\u003cp\u003eMindplex 웹사이트를 방문하여 프로필을 설정하고 매거진에 기고할 수도 있습니다.\u003c/p\u003e\n\u003ch1\u003e팔로우해 주세요:\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eMindplex Magazine을 방문해주세요\u003c/li\u003e\n\u003cli\u003e저희 텔레그램에 가입해주세요\u003c/li\u003e\n\u003cli\u003eMindplex 소셜에 가입해주세요\u003c/li\u003e\n\u003cli\u003e디스코드에 가입해주세요\u003c/li\u003e\n\u003cli\u003e트위터, 링크드인에서 팔로우해주세요\u003c/li\u003e\n\u003cli\u003e페이스북에서 좋아요를 눌러주세요\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-20-TheAIRevolution3DModelingandMotionCapture"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>