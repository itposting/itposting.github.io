<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까 | itposting" data-gatsby-head="true"/><meta property="og:title" content="대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems" data-gatsby-head="true"/><meta name="twitter:title" content="대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-22 20:52" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_buildManifest.js" defer=""></script><script src="/_next/static/QYe6gFAUryFKFgjKBoIfo/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 22, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>이 게시물의 한국어 버전을 다음 링크에서 찾을 수 있습니다. 😊</p>
<p>해당 글은 대형 언어 모델에 대한 이해 시리즈(3/4)의 세 번째 글입니다.</p>
<p>요즘에는 대형 언어 모델이 거의 모든 문제를 해결할 수 있다는 것 같아요. 사람들과 대화를 나눌 수도 있고, 질문에 답변하고, 소설을 쓰고, 음악을 작곡하며, 심지어 강의 자료를 디자인할 수도 있어요.</p>
<p>하지만 대형 언어 모델이 이 모든 기능을 어떻게 수행하는 걸까요? 지난 몇 년 동안 어떤 일이 일어나서 가능해졌을까요? 이 글에서는 대형 언어 모델이 일상생활에서 우리가 마주하는 다양한 문제들을 어떻게 해결하는지 살펴보고, 모든 이러한 기능을 통합하는 중요한 모델링 접근 방식을 소개할 거에요. 🚀</p>
<div class="content-ad"></div>
<h1>LLM 이전의 AI 대 LLM 기반 AI</h1>
<h2>LLM 이전의 AI</h2>
<p>먼저 LLM 이전에 AI가 일반적으로 사용되던 방식을 살펴보겠습니다. 간단한 감성 분석 작업을 예로 들어보겠습니다. 일반적인 과정은 다음과 같을 수 있습니다:</p>
<ul>
<li>감정 유형 정의</li>
<li>예를 들어, 긍정적, 부정적, 중립, 혼합된 네 가지 감정 유형이 있다고 가정합시다.</li>
<li>충분한 감성 데이터 수집 및 해당 감정 유형에 대한 태깅</li>
<li>다양한 출처에서 데이터 수집하고 각 데이터 조각에 대해 감정을 수동으로 태깅합니다.</li>
<li>NLP 모델 선택 (예: BERT, Electra, RoBERTa 등)</li>
<li>수집된 태깅된 데이터를 사용하여 선택한 NLP 모델을 세밀하게 조정합니다.</li>
<li>모델에 데이터 입력</li>
<li>감정 분석을 위한 데이터를 모델에 입력합니다.</li>
<li>출력 벡터 해석</li>
<li>모델에 의한 출력 벡터를 해석하여 각 감정 클래스에 대한 확률 값을 계산합니다.</li>
<li>이러한 확률 값에 따라 최고값을 가진 감정 클래스를 결정하여 최종 감정 클래스를 결정합니다.</li>
<li>최종 서비스 구축</li>
<li>세밀하게 조정된 모델을 사용하여 최종 감성 분석 서비스를 구축하고, 웹 서비스 또는 API로 제공할 수 있습니다.</li>
</ul>
<div class="content-ad"></div>
<p>LLM 이전에 AI를 사용하는 과정은 특정 작업을 수행하기 위해 많은 단계와 많은 수동 작업을 필요로 했습니다. 충분한 훈련 데이터를 수집해야 했고, 모델링 프로세스를 진행해야 했으며, 입력과 출력이 기존 모델의 형식과 일치해야 했습니다. 다시 말해, 데이터 파이프라인은 문제 자체가 아닌 모델의 입출력 형식을 중심으로 구축되어야 했습니다.</p>
<p>이 내용은 다음과 같이 요약할 수 있습니다:</p>
<p><img src="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png" alt="UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0"></p>
<p>요컨데, 개발자들은 문제와 데이터를 모델의 강점에 맞게 맞춰야 했습니다.</p>
<div class="content-ad"></div>
<h2>LLM 기반 AI</h2>
<p>LLM은 문제 해결 과정을 간소화합니다. 특히 GPT와 같은 디코더를 포함한 언어 모델을 사용하면 어떤 "언어" 입력이든 처리하여 "언어" 출력을 생성할 수 있습니다. 이 생성 능력은 모든 문제를 크게 간소화합니다.</p>
<p>생성 언어 모델을 사용하여 감성 분석 문제를 다시 살펴보겠습니다.</p>
<ul>
<li>감성 분석 문제 정의하기.</li>
<li>사용자가 텍스트를 입력하면 해당 텍스트의 감성을 분석하고 결과를 출력합니다.</li>
<li>사전 훈련된 LLM 모델 선택하기.</li>
<li>예를 들어 GPT-3 모델을 선택하십시오.</li>
<li>모델에 데이터 입력하기.</li>
<li>모델에 텍스트 데이터를 용도에 맞게 입력합니다.</li>
<li>예를 들어, 분석 문장이 "This is a movie I want to watch again" 인 경우,</li>
<li>프롬프트는 다음과 같을 것입니다:</li>
<li>프롬프트: “다음 문장을 다음 네 가지 범주 중 하나로 분류하십시오: 긍정적, 부정적, 중립, 혼합. 문장=This is a movie I want to watch again.</li>
<li>모델의 출력 해석하기.</li>
<li>모델이 출력한 텍스트를 직접 사용하거나 해석하여 감성을 분류합니다.</li>
<li>최종 서비스 구축하기.</li>
<li>LLM을 사용하여 감성 분석 서비스를 구축하고 웹 서비스나 API로 제공할 수 있습니다.</li>
</ul>
<div class="content-ad"></div>
<p>위에 표시된 대로, LLM을 사용하면 복잡한 전처리, 모델 선택 또는 세부 조정 과정 없이 감성 분석을 쉽게 수행할 수 있습니다. 모든 과정은 통합 모델에 의해 처리될 수 있어 개발자와 사용자에 대한 부담을 크게 줄일 수 있습니다. 가장 큰 장점은 입력과 출력이 모두 '텍스트'로 통합된다는 점으로, 복잡한 벡터 해석이나 처리가 필요 없다는 점입니다. 이는 다음과 같이 설명할 수 있습니다:</p>
<p><img src="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_1.png" alt="이미지"></p>
<h1>LLM이 문제를 해결하는 방법</h1>
<p>이제 LLM, 특히 디코더를 사용하는 생성 모델이 통합적인 관점에서 다양한 문제를 해결하는 방법을 살펴보겠습니다.</p>
<div class="content-ad"></div>
<p>난 생성 모델 LLM이 특정 목표로 훈련되고 예측하는 방식을 알아볼 거야.</p>
<h2>트랜스포머-디코더 훈련</h2>
<p>디코더 전용 언어 모델을 다음과 같이 훈련해:</p>
<ul>
<li>디코더 입력 데이터를 준비해.</li>
<li>예시: <code>s</code>, A, B, C</li>
<li>여기서 <code>s</code>는 문장의 시작을 의미해.</li>
<li>디코더 출력 데이터를 준비해.</li>
<li>예시: A, B, C</li>
<li>Transformer를 통해 피드포워드 진행해.</li>
<li>각 타임스텝에서 예측된 기호가 출력 시점의 기호와 일치하는지 확인해.</li>
<li><code>s</code>가 있는 타임스텝은 A를 생성해야 해.</li>
<li>A가 있는 타임스텝은 B를 생성해야 해.</li>
<li>각 타임스텝에서 손실을 계산하고 누적해, 이를 기반으로 트랜스포머를 훈련해.</li>
</ul>
<div class="content-ad"></div>
<p>이 과정은 다음과 같이 시각화될 수 있습니다:</p>
<p><img src="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_2.png" alt="image"></p>
<p>이 교육 과정 중에는 확률 모델링의 네 가지 인스턴스가 발생합니다. 각 타임스텝에서 미래 정보가 보이지 않도록 디코더의 교육 과정 중에 가림 마스크를 적용합니다. 예를 들어:</p>
<ul>
<li>P(A | <code>S</code>)</li>
<li>P(B | <code>S</code>, A)</li>
<li>P(C | <code>S</code>, A, B)</li>
<li>P(<code>/S</code> | <code>S</code>, A, B, C)</li>
</ul>
<div class="content-ad"></div>
<p>그래서 우리의 "생성 언어 모델"은 궁극적으로 다음 목표를 완성하는 데 최적화되어 있어요.</p>
<p>이를 직관적으로 이해하기 위해, 우리의 사고를 한 단계씩 확장해 봅시다.</p>
<h2>트랜스포머 디코더로 생성하기</h2>
<p>[문장 완성]
저희 언어 모델은 기본적으로 문장을 완성하도록 훈련되어 있어요.</p>
<div class="content-ad"></div>
<p>위의 예시에서 보는 것처럼, Transformer 디코더는 입력 "This is a wonderful" 후에 가장 타당한 단어 "world"을 생성합니다. 그런 다음 "This is a wonderful world" 후에 "isn't"를, 그리고 "This is a wonderful world, isn't" 후에 "it?"을 생성합니다. 기본적으로 문장의 시작이 주어지면 가장 타당한 나머지 부분을 완성합니다.</p>
<p>[문단 완성]
이를 확장할 수 있을까요? 실제로, 우리의 Transformer는 문장과 문단을 구분하지 않습니다; 그저 점점 더 많아지는 토큰을 보는 것뿐입니다.</p>
<p><img src="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_4.png" alt=""></p>
<div class="content-ad"></div>
<p>생성 언어 모델은 문장뿐만 아니라 단락도 완성할 수 있습니다. 초기 내용을 바탕으로 단락의 나머지 부분을 완성합니다.</p>
<p>문장에서 단락으로 확장할 때 모델 구조를 변경했나요? 아니요, 우리는 정확히 같은 모델 구조를 사용했습니다. 입력의 규모만 변경되었습니다. 마찬가지로 입력을 확장하면 다음과 같은 작업을 자연스럽게 수행할 수 있습니다:</p>
<ul>
<li>페이지 완성</li>
<li>챕터 완성</li>
<li>전체 책 완성</li>
</ul>
<p>간단히 다양한 정보 규모를 문서로 설명하면, 우리는 LLM을 주어진 문서 조각에 가장 적합한 나머지 조각을 생성하는 엔진으로 정의할 수 있습니다.</p>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_5.png">
<p>위의 그림처럼, 큰 언어 모델(Large Language Models, LLMs)은 주어진 문서 조각 Dₚ를 기반으로 남은 부분 Dₙ을 완성하는 것 이상의 것도 이하의 것도 아닙니다. 음악 작곡, 소설쓰기, 시험 문제 해결 등, 문제 해결의 근본적인 방법은 그냥 빠진 부분을 “가능성 있게” 완성하는 것뿐입니다.</p>
<p>이 과정에는 철학적, 윤리적, 도덕적, 심리적 고려 사항이 내재적으로 내장되어 있지 않습니다. LLMs를 그저 매우 대규모의 “자동 완성 기계”로 생각하는 것이 적절합니다. 이 자동 완성 기계는 방대한 양의 데이터로 훈련되어 가능성 있는 결과를 생성합니다.</p>
<h2>LLMs의 핵심 — 가능성</h2>
<div class="content-ad"></div>
<p>LLM들이 Q/A 및 번역과 같은 다양한 응용 프로그램을 처리하기 위해 이 자동완성 기능을 사용하는 방법은 데이터의 힘에 있습니다.</p>
<p>두 가지 응용 프로그램, Q/A 및 번역을 고려해 봅시다.</p>
<p>[Q/A]</p>
<p>질문 Q에 대한 답변 A를 제공하는 것은 Q/A 시스템을 형성합니다. 교육을 위해 우리는 Q/A 쌍을 단일 문서로 생각할 수 있습니다:</p>
<div class="content-ad"></div>
<ul>
<li>문서 D = [Q;A]</li>
</ul>
<p>LLM(Language Model)이 수십억 개의 이러한 Q/A 문서로 훈련받는다면, 그들은 Q/A 문서를 완성하는 법을 배울 것입니다. Q/A LLM에서 "합리성"은 Q를 따르는 A를 생성하는 것을 의미합니다.</p>
<p>사용자가 질문 Q를 입력할 때:</p>
<ul>
<li>LLM(Dₚ=Q) -` Dₙ</li>
</ul>
<div class="content-ad"></div>
<p>표 태그를 Markdown 형식으로 변경해주세요.</p>
<div class="content-ad"></div>
<p>시스템적으로 보면 다음과 같습니다:</p>
<ul>
<li>문맥 C: “다음 내용을 영어에서 한국어로 번역하세요. 번역할 내용은:”</li>
<li>원본 S: “The weather is beautiful today.”</li>
<li>번역본 T: “오늘 날씨가 아름답습니다.”</li>
</ul>
<p>실제로 언어 모델을 훈련하는 과정에서는 다음과 같이 처리됩니다:</p>
<ul>
<li>D = [C; S; T]</li>
</ul>
<div class="content-ad"></div>
<p>수십억 건의 번역 요청 및 결과 문서를 사용하여 훈련된 언어 모델은 자연스럽게 Dₚ = [C; S]를 Dₙ = T와 함께 완성할 수 있는 능력을 개발합니다. 본질적으로 번역기를 생성하는 대신, 우리는 번역 문서의 일부를 가져와 입력하고 자동 완성 기곕이 나머지를 채우도록 허용했습니다.</p>
<p>하지만 사용자에게는 훌륭한 번역이 이루어졌고 실용적으로 사용할 수 있다고 보입니다.</p>
<p>최종적으로 LLM(Large Language Models)이 문제를 해결하는 한 가지 방법은 가장 타당한 방식으로 남은 부분을 완성함으로써입니다. 너무 간단하게 보일 수 있지만, 조금의 상상력을 발휘하면 이 방법이 거의 모든 것을 해결할 수 있다는 것을 알 수 있습니다.</p>
<p>음악 작곡, 소설 쓰기, 영화 제작, 시험 문제 제출 및 해결, 경제 시뮬레이션, 수학 문제 해결, 철학적 논쟁, 인류의 미래 예측 - 우리가 가진 거의 모든 질문은 "가장 타당한" 결과를 제공함으로써 답변될 수 있습니다. 그리고 그 타당한 결과가 바로 LLM, 자동완성 기곕이 제공하는 것입니다.</p>
<div class="content-ad"></div>
<h1>결론</h1>
<p>이 글에서 우리는 대형 언어 모델이 세상의 다양한 문제들을 해결하는 핵심 원리에 대해 탐구했습니다. 간단히 말해, LLM은 자동 완성 기계입니다. 이 엔진은 훈련된 데이터를 기반으로 전체 문서의 전반부가 주어졌을 때, 후반부를 타당하게 완성하는 최적화된 엔진입니다.</p>
<p>이 원리는 간단하지만, LLM은 훈련 중 노출된 데이터의 유형과 구성을 다양화함으로써 새로운 응용 프로그램을 끝없이 만들어낼 수 있는 강력한 도구입니다.</p>
<p>다음 글에서는 이 자동 완성 기계의 "대규모" 측면이 우리에게 미치는 영향에 대해 설명할 것입니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"대형 언어 모델 LLMs 이해하기  어떻게 문제를 해결할까","description":"","date":"2024-06-22 20:52","slug":"2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems","content":"\n\n이 게시물의 한국어 버전을 다음 링크에서 찾을 수 있습니다. 😊\n\n해당 글은 대형 언어 모델에 대한 이해 시리즈(3/4)의 세 번째 글입니다.\n\n요즘에는 대형 언어 모델이 거의 모든 문제를 해결할 수 있다는 것 같아요. 사람들과 대화를 나눌 수도 있고, 질문에 답변하고, 소설을 쓰고, 음악을 작곡하며, 심지어 강의 자료를 디자인할 수도 있어요.\n\n하지만 대형 언어 모델이 이 모든 기능을 어떻게 수행하는 걸까요? 지난 몇 년 동안 어떤 일이 일어나서 가능해졌을까요? 이 글에서는 대형 언어 모델이 일상생활에서 우리가 마주하는 다양한 문제들을 어떻게 해결하는지 살펴보고, 모든 이러한 기능을 통합하는 중요한 모델링 접근 방식을 소개할 거에요. 🚀\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# LLM 이전의 AI 대 LLM 기반 AI\n\n## LLM 이전의 AI\n\n먼저 LLM 이전에 AI가 일반적으로 사용되던 방식을 살펴보겠습니다. 간단한 감성 분석 작업을 예로 들어보겠습니다. 일반적인 과정은 다음과 같을 수 있습니다:\n\n- 감정 유형 정의\n- 예를 들어, 긍정적, 부정적, 중립, 혼합된 네 가지 감정 유형이 있다고 가정합시다.\n- 충분한 감성 데이터 수집 및 해당 감정 유형에 대한 태깅\n- 다양한 출처에서 데이터 수집하고 각 데이터 조각에 대해 감정을 수동으로 태깅합니다.\n- NLP 모델 선택 (예: BERT, Electra, RoBERTa 등)\n- 수집된 태깅된 데이터를 사용하여 선택한 NLP 모델을 세밀하게 조정합니다.\n- 모델에 데이터 입력\n- 감정 분석을 위한 데이터를 모델에 입력합니다.\n- 출력 벡터 해석\n- 모델에 의한 출력 벡터를 해석하여 각 감정 클래스에 대한 확률 값을 계산합니다.\n- 이러한 확률 값에 따라 최고값을 가진 감정 클래스를 결정하여 최종 감정 클래스를 결정합니다.\n- 최종 서비스 구축\n- 세밀하게 조정된 모델을 사용하여 최종 감성 분석 서비스를 구축하고, 웹 서비스 또는 API로 제공할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM 이전에 AI를 사용하는 과정은 특정 작업을 수행하기 위해 많은 단계와 많은 수동 작업을 필요로 했습니다. 충분한 훈련 데이터를 수집해야 했고, 모델링 프로세스를 진행해야 했으며, 입력과 출력이 기존 모델의 형식과 일치해야 했습니다. 다시 말해, 데이터 파이프라인은 문제 자체가 아닌 모델의 입출력 형식을 중심으로 구축되어야 했습니다.\n\n이 내용은 다음과 같이 요약할 수 있습니다:\n\n![UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png)\n\n요컨데, 개발자들은 문제와 데이터를 모델의 강점에 맞게 맞춰야 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## LLM 기반 AI\n\nLLM은 문제 해결 과정을 간소화합니다. 특히 GPT와 같은 디코더를 포함한 언어 모델을 사용하면 어떤 \"언어\" 입력이든 처리하여 \"언어\" 출력을 생성할 수 있습니다. 이 생성 능력은 모든 문제를 크게 간소화합니다.\n\n생성 언어 모델을 사용하여 감성 분석 문제를 다시 살펴보겠습니다.\n\n- 감성 분석 문제 정의하기.\n- 사용자가 텍스트를 입력하면 해당 텍스트의 감성을 분석하고 결과를 출력합니다.\n- 사전 훈련된 LLM 모델 선택하기.\n- 예를 들어 GPT-3 모델을 선택하십시오.\n- 모델에 데이터 입력하기.\n- 모델에 텍스트 데이터를 용도에 맞게 입력합니다.\n- 예를 들어, 분석 문장이 \"This is a movie I want to watch again\" 인 경우,\n- 프롬프트는 다음과 같을 것입니다:\n- 프롬프트: “다음 문장을 다음 네 가지 범주 중 하나로 분류하십시오: 긍정적, 부정적, 중립, 혼합. 문장=This is a movie I want to watch again.\n- 모델의 출력 해석하기.\n- 모델이 출력한 텍스트를 직접 사용하거나 해석하여 감성을 분류합니다.\n- 최종 서비스 구축하기.\n- LLM을 사용하여 감성 분석 서비스를 구축하고 웹 서비스나 API로 제공할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에 표시된 대로, LLM을 사용하면 복잡한 전처리, 모델 선택 또는 세부 조정 과정 없이 감성 분석을 쉽게 수행할 수 있습니다. 모든 과정은 통합 모델에 의해 처리될 수 있어 개발자와 사용자에 대한 부담을 크게 줄일 수 있습니다. 가장 큰 장점은 입력과 출력이 모두 '텍스트'로 통합된다는 점으로, 복잡한 벡터 해석이나 처리가 필요 없다는 점입니다. 이는 다음과 같이 설명할 수 있습니다:\n\n![이미지](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_1.png)\n\n# LLM이 문제를 해결하는 방법\n\n이제 LLM, 특히 디코더를 사용하는 생성 모델이 통합적인 관점에서 다양한 문제를 해결하는 방법을 살펴보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n난 생성 모델 LLM이 특정 목표로 훈련되고 예측하는 방식을 알아볼 거야.\n\n## 트랜스포머-디코더 훈련\n\n디코더 전용 언어 모델을 다음과 같이 훈련해:\n\n- 디코더 입력 데이터를 준비해.\n- 예시: `s`, A, B, C\n- 여기서 `s`는 문장의 시작을 의미해.\n- 디코더 출력 데이터를 준비해.\n- 예시: A, B, C\n- Transformer를 통해 피드포워드 진행해.\n- 각 타임스텝에서 예측된 기호가 출력 시점의 기호와 일치하는지 확인해.\n- `s`가 있는 타임스텝은 A를 생성해야 해.\n- A가 있는 타임스텝은 B를 생성해야 해.\n- 각 타임스텝에서 손실을 계산하고 누적해, 이를 기반으로 트랜스포머를 훈련해.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 과정은 다음과 같이 시각화될 수 있습니다:\n\n![image](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_2.png)\n\n이 교육 과정 중에는 확률 모델링의 네 가지 인스턴스가 발생합니다. 각 타임스텝에서 미래 정보가 보이지 않도록 디코더의 교육 과정 중에 가림 마스크를 적용합니다. 예를 들어:\n\n- P(A | `S`)\n- P(B | `S`, A)\n- P(C | `S`, A, B)\n- P(`/S` | `S`, A, B, C)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 우리의 \"생성 언어 모델\"은 궁극적으로 다음 목표를 완성하는 데 최적화되어 있어요.\n\n이를 직관적으로 이해하기 위해, 우리의 사고를 한 단계씩 확장해 봅시다.\n\n## 트랜스포머 디코더로 생성하기\n\n[문장 완성]\n저희 언어 모델은 기본적으로 문장을 완성하도록 훈련되어 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 예시에서 보는 것처럼, Transformer 디코더는 입력 \"This is a wonderful\" 후에 가장 타당한 단어 \"world\"을 생성합니다. 그런 다음 \"This is a wonderful world\" 후에 \"isn't\"를, 그리고 \"This is a wonderful world, isn't\" 후에 \"it?\"을 생성합니다. 기본적으로 문장의 시작이 주어지면 가장 타당한 나머지 부분을 완성합니다.\n\n[문단 완성]\n이를 확장할 수 있을까요? 실제로, 우리의 Transformer는 문장과 문단을 구분하지 않습니다; 그저 점점 더 많아지는 토큰을 보는 것뿐입니다.\n\n![](/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_4.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n생성 언어 모델은 문장뿐만 아니라 단락도 완성할 수 있습니다. 초기 내용을 바탕으로 단락의 나머지 부분을 완성합니다.\n\n문장에서 단락으로 확장할 때 모델 구조를 변경했나요? 아니요, 우리는 정확히 같은 모델 구조를 사용했습니다. 입력의 규모만 변경되었습니다. 마찬가지로 입력을 확장하면 다음과 같은 작업을 자연스럽게 수행할 수 있습니다:\n\n- 페이지 완성\n- 챕터 완성\n- 전체 책 완성\n\n간단히 다양한 정보 규모를 문서로 설명하면, 우리는 LLM을 주어진 문서 조각에 가장 적합한 나머지 조각을 생성하는 엔진으로 정의할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_5.png\" /\u003e\n\n위의 그림처럼, 큰 언어 모델(Large Language Models, LLMs)은 주어진 문서 조각 Dₚ를 기반으로 남은 부분 Dₙ을 완성하는 것 이상의 것도 이하의 것도 아닙니다. 음악 작곡, 소설쓰기, 시험 문제 해결 등, 문제 해결의 근본적인 방법은 그냥 빠진 부분을 “가능성 있게” 완성하는 것뿐입니다.\n\n이 과정에는 철학적, 윤리적, 도덕적, 심리적 고려 사항이 내재적으로 내장되어 있지 않습니다. LLMs를 그저 매우 대규모의 “자동 완성 기계”로 생각하는 것이 적절합니다. 이 자동 완성 기계는 방대한 양의 데이터로 훈련되어 가능성 있는 결과를 생성합니다.\n\n## LLMs의 핵심 — 가능성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM들이 Q/A 및 번역과 같은 다양한 응용 프로그램을 처리하기 위해 이 자동완성 기능을 사용하는 방법은 데이터의 힘에 있습니다.\n\n두 가지 응용 프로그램, Q/A 및 번역을 고려해 봅시다.\n\n[Q/A]\n\n질문 Q에 대한 답변 A를 제공하는 것은 Q/A 시스템을 형성합니다. 교육을 위해 우리는 Q/A 쌍을 단일 문서로 생각할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 문서 D = [Q;A]\n\nLLM(Language Model)이 수십억 개의 이러한 Q/A 문서로 훈련받는다면, 그들은 Q/A 문서를 완성하는 법을 배울 것입니다. Q/A LLM에서 \"합리성\"은 Q를 따르는 A를 생성하는 것을 의미합니다.\n\n사용자가 질문 Q를 입력할 때:\n\n- LLM(Dₚ=Q) -` Dₙ\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템적으로 보면 다음과 같습니다:\n\n- 문맥 C: “다음 내용을 영어에서 한국어로 번역하세요. 번역할 내용은:”\n- 원본 S: “The weather is beautiful today.”\n- 번역본 T: “오늘 날씨가 아름답습니다.”\n\n실제로 언어 모델을 훈련하는 과정에서는 다음과 같이 처리됩니다:\n\n- D = [C; S; T]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수십억 건의 번역 요청 및 결과 문서를 사용하여 훈련된 언어 모델은 자연스럽게 Dₚ = [C; S]를 Dₙ = T와 함께 완성할 수 있는 능력을 개발합니다. 본질적으로 번역기를 생성하는 대신, 우리는 번역 문서의 일부를 가져와 입력하고 자동 완성 기곕이 나머지를 채우도록 허용했습니다.\n\n하지만 사용자에게는 훌륭한 번역이 이루어졌고 실용적으로 사용할 수 있다고 보입니다.\n\n최종적으로 LLM(Large Language Models)이 문제를 해결하는 한 가지 방법은 가장 타당한 방식으로 남은 부분을 완성함으로써입니다. 너무 간단하게 보일 수 있지만, 조금의 상상력을 발휘하면 이 방법이 거의 모든 것을 해결할 수 있다는 것을 알 수 있습니다.\n\n음악 작곡, 소설 쓰기, 영화 제작, 시험 문제 제출 및 해결, 경제 시뮬레이션, 수학 문제 해결, 철학적 논쟁, 인류의 미래 예측 - 우리가 가진 거의 모든 질문은 \"가장 타당한\" 결과를 제공함으로써 답변될 수 있습니다. 그리고 그 타당한 결과가 바로 LLM, 자동완성 기곕이 제공하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n이 글에서 우리는 대형 언어 모델이 세상의 다양한 문제들을 해결하는 핵심 원리에 대해 탐구했습니다. 간단히 말해, LLM은 자동 완성 기계입니다. 이 엔진은 훈련된 데이터를 기반으로 전체 문서의 전반부가 주어졌을 때, 후반부를 타당하게 완성하는 최적화된 엔진입니다.\n\n이 원리는 간단하지만, LLM은 훈련 중 노출된 데이터의 유형과 구성을 다양화함으로써 새로운 응용 프로그램을 끝없이 만들어낼 수 있는 강력한 도구입니다.\n\n다음 글에서는 이 자동 완성 기계의 \"대규모\" 측면이 우리에게 미치는 영향에 대해 설명할 것입니다.","ogImage":{"url":"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png"},"coverImage":"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e이 게시물의 한국어 버전을 다음 링크에서 찾을 수 있습니다. 😊\u003c/p\u003e\n\u003cp\u003e해당 글은 대형 언어 모델에 대한 이해 시리즈(3/4)의 세 번째 글입니다.\u003c/p\u003e\n\u003cp\u003e요즘에는 대형 언어 모델이 거의 모든 문제를 해결할 수 있다는 것 같아요. 사람들과 대화를 나눌 수도 있고, 질문에 답변하고, 소설을 쓰고, 음악을 작곡하며, 심지어 강의 자료를 디자인할 수도 있어요.\u003c/p\u003e\n\u003cp\u003e하지만 대형 언어 모델이 이 모든 기능을 어떻게 수행하는 걸까요? 지난 몇 년 동안 어떤 일이 일어나서 가능해졌을까요? 이 글에서는 대형 언어 모델이 일상생활에서 우리가 마주하는 다양한 문제들을 어떻게 해결하는지 살펴보고, 모든 이러한 기능을 통합하는 중요한 모델링 접근 방식을 소개할 거에요. 🚀\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eLLM 이전의 AI 대 LLM 기반 AI\u003c/h1\u003e\n\u003ch2\u003eLLM 이전의 AI\u003c/h2\u003e\n\u003cp\u003e먼저 LLM 이전에 AI가 일반적으로 사용되던 방식을 살펴보겠습니다. 간단한 감성 분석 작업을 예로 들어보겠습니다. 일반적인 과정은 다음과 같을 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e감정 유형 정의\u003c/li\u003e\n\u003cli\u003e예를 들어, 긍정적, 부정적, 중립, 혼합된 네 가지 감정 유형이 있다고 가정합시다.\u003c/li\u003e\n\u003cli\u003e충분한 감성 데이터 수집 및 해당 감정 유형에 대한 태깅\u003c/li\u003e\n\u003cli\u003e다양한 출처에서 데이터 수집하고 각 데이터 조각에 대해 감정을 수동으로 태깅합니다.\u003c/li\u003e\n\u003cli\u003eNLP 모델 선택 (예: BERT, Electra, RoBERTa 등)\u003c/li\u003e\n\u003cli\u003e수집된 태깅된 데이터를 사용하여 선택한 NLP 모델을 세밀하게 조정합니다.\u003c/li\u003e\n\u003cli\u003e모델에 데이터 입력\u003c/li\u003e\n\u003cli\u003e감정 분석을 위한 데이터를 모델에 입력합니다.\u003c/li\u003e\n\u003cli\u003e출력 벡터 해석\u003c/li\u003e\n\u003cli\u003e모델에 의한 출력 벡터를 해석하여 각 감정 클래스에 대한 확률 값을 계산합니다.\u003c/li\u003e\n\u003cli\u003e이러한 확률 값에 따라 최고값을 가진 감정 클래스를 결정하여 최종 감정 클래스를 결정합니다.\u003c/li\u003e\n\u003cli\u003e최종 서비스 구축\u003c/li\u003e\n\u003cli\u003e세밀하게 조정된 모델을 사용하여 최종 감성 분석 서비스를 구축하고, 웹 서비스 또는 API로 제공할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eLLM 이전에 AI를 사용하는 과정은 특정 작업을 수행하기 위해 많은 단계와 많은 수동 작업을 필요로 했습니다. 충분한 훈련 데이터를 수집해야 했고, 모델링 프로세스를 진행해야 했으며, 입력과 출력이 기존 모델의 형식과 일치해야 했습니다. 다시 말해, 데이터 파이프라인은 문제 자체가 아닌 모델의 입출력 형식을 중심으로 구축되어야 했습니다.\u003c/p\u003e\n\u003cp\u003e이 내용은 다음과 같이 요약할 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0.png\" alt=\"UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_0\"\u003e\u003c/p\u003e\n\u003cp\u003e요컨데, 개발자들은 문제와 데이터를 모델의 강점에 맞게 맞춰야 했습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003eLLM 기반 AI\u003c/h2\u003e\n\u003cp\u003eLLM은 문제 해결 과정을 간소화합니다. 특히 GPT와 같은 디코더를 포함한 언어 모델을 사용하면 어떤 \"언어\" 입력이든 처리하여 \"언어\" 출력을 생성할 수 있습니다. 이 생성 능력은 모든 문제를 크게 간소화합니다.\u003c/p\u003e\n\u003cp\u003e생성 언어 모델을 사용하여 감성 분석 문제를 다시 살펴보겠습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e감성 분석 문제 정의하기.\u003c/li\u003e\n\u003cli\u003e사용자가 텍스트를 입력하면 해당 텍스트의 감성을 분석하고 결과를 출력합니다.\u003c/li\u003e\n\u003cli\u003e사전 훈련된 LLM 모델 선택하기.\u003c/li\u003e\n\u003cli\u003e예를 들어 GPT-3 모델을 선택하십시오.\u003c/li\u003e\n\u003cli\u003e모델에 데이터 입력하기.\u003c/li\u003e\n\u003cli\u003e모델에 텍스트 데이터를 용도에 맞게 입력합니다.\u003c/li\u003e\n\u003cli\u003e예를 들어, 분석 문장이 \"This is a movie I want to watch again\" 인 경우,\u003c/li\u003e\n\u003cli\u003e프롬프트는 다음과 같을 것입니다:\u003c/li\u003e\n\u003cli\u003e프롬프트: “다음 문장을 다음 네 가지 범주 중 하나로 분류하십시오: 긍정적, 부정적, 중립, 혼합. 문장=This is a movie I want to watch again.\u003c/li\u003e\n\u003cli\u003e모델의 출력 해석하기.\u003c/li\u003e\n\u003cli\u003e모델이 출력한 텍스트를 직접 사용하거나 해석하여 감성을 분류합니다.\u003c/li\u003e\n\u003cli\u003e최종 서비스 구축하기.\u003c/li\u003e\n\u003cli\u003eLLM을 사용하여 감성 분석 서비스를 구축하고 웹 서비스나 API로 제공할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e위에 표시된 대로, LLM을 사용하면 복잡한 전처리, 모델 선택 또는 세부 조정 과정 없이 감성 분석을 쉽게 수행할 수 있습니다. 모든 과정은 통합 모델에 의해 처리될 수 있어 개발자와 사용자에 대한 부담을 크게 줄일 수 있습니다. 가장 큰 장점은 입력과 출력이 모두 '텍스트'로 통합된다는 점으로, 복잡한 벡터 해석이나 처리가 필요 없다는 점입니다. 이는 다음과 같이 설명할 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003eLLM이 문제를 해결하는 방법\u003c/h1\u003e\n\u003cp\u003e이제 LLM, 특히 디코더를 사용하는 생성 모델이 통합적인 관점에서 다양한 문제를 해결하는 방법을 살펴보겠습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e난 생성 모델 LLM이 특정 목표로 훈련되고 예측하는 방식을 알아볼 거야.\u003c/p\u003e\n\u003ch2\u003e트랜스포머-디코더 훈련\u003c/h2\u003e\n\u003cp\u003e디코더 전용 언어 모델을 다음과 같이 훈련해:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e디코더 입력 데이터를 준비해.\u003c/li\u003e\n\u003cli\u003e예시: \u003ccode\u003es\u003c/code\u003e, A, B, C\u003c/li\u003e\n\u003cli\u003e여기서 \u003ccode\u003es\u003c/code\u003e는 문장의 시작을 의미해.\u003c/li\u003e\n\u003cli\u003e디코더 출력 데이터를 준비해.\u003c/li\u003e\n\u003cli\u003e예시: A, B, C\u003c/li\u003e\n\u003cli\u003eTransformer를 통해 피드포워드 진행해.\u003c/li\u003e\n\u003cli\u003e각 타임스텝에서 예측된 기호가 출력 시점의 기호와 일치하는지 확인해.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003es\u003c/code\u003e가 있는 타임스텝은 A를 생성해야 해.\u003c/li\u003e\n\u003cli\u003eA가 있는 타임스텝은 B를 생성해야 해.\u003c/li\u003e\n\u003cli\u003e각 타임스텝에서 손실을 계산하고 누적해, 이를 기반으로 트랜스포머를 훈련해.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 과정은 다음과 같이 시각화될 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_2.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e이 교육 과정 중에는 확률 모델링의 네 가지 인스턴스가 발생합니다. 각 타임스텝에서 미래 정보가 보이지 않도록 디코더의 교육 과정 중에 가림 마스크를 적용합니다. 예를 들어:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eP(A | \u003ccode\u003eS\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003eP(B | \u003ccode\u003eS\u003c/code\u003e, A)\u003c/li\u003e\n\u003cli\u003eP(C | \u003ccode\u003eS\u003c/code\u003e, A, B)\u003c/li\u003e\n\u003cli\u003eP(\u003ccode\u003e/S\u003c/code\u003e | \u003ccode\u003eS\u003c/code\u003e, A, B, C)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e그래서 우리의 \"생성 언어 모델\"은 궁극적으로 다음 목표를 완성하는 데 최적화되어 있어요.\u003c/p\u003e\n\u003cp\u003e이를 직관적으로 이해하기 위해, 우리의 사고를 한 단계씩 확장해 봅시다.\u003c/p\u003e\n\u003ch2\u003e트랜스포머 디코더로 생성하기\u003c/h2\u003e\n\u003cp\u003e[문장 완성]\n저희 언어 모델은 기본적으로 문장을 완성하도록 훈련되어 있어요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e위의 예시에서 보는 것처럼, Transformer 디코더는 입력 \"This is a wonderful\" 후에 가장 타당한 단어 \"world\"을 생성합니다. 그런 다음 \"This is a wonderful world\" 후에 \"isn't\"를, 그리고 \"This is a wonderful world, isn't\" 후에 \"it?\"을 생성합니다. 기본적으로 문장의 시작이 주어지면 가장 타당한 나머지 부분을 완성합니다.\u003c/p\u003e\n\u003cp\u003e[문단 완성]\n이를 확장할 수 있을까요? 실제로, 우리의 Transformer는 문장과 문단을 구분하지 않습니다; 그저 점점 더 많아지는 토큰을 보는 것뿐입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_4.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e생성 언어 모델은 문장뿐만 아니라 단락도 완성할 수 있습니다. 초기 내용을 바탕으로 단락의 나머지 부분을 완성합니다.\u003c/p\u003e\n\u003cp\u003e문장에서 단락으로 확장할 때 모델 구조를 변경했나요? 아니요, 우리는 정확히 같은 모델 구조를 사용했습니다. 입력의 규모만 변경되었습니다. 마찬가지로 입력을 확장하면 다음과 같은 작업을 자연스럽게 수행할 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e페이지 완성\u003c/li\u003e\n\u003cli\u003e챕터 완성\u003c/li\u003e\n\u003cli\u003e전체 책 완성\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e간단히 다양한 정보 규모를 문서로 설명하면, 우리는 LLM을 주어진 문서 조각에 가장 적합한 나머지 조각을 생성하는 엔진으로 정의할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems_5.png\"\u003e\n\u003cp\u003e위의 그림처럼, 큰 언어 모델(Large Language Models, LLMs)은 주어진 문서 조각 Dₚ를 기반으로 남은 부분 Dₙ을 완성하는 것 이상의 것도 이하의 것도 아닙니다. 음악 작곡, 소설쓰기, 시험 문제 해결 등, 문제 해결의 근본적인 방법은 그냥 빠진 부분을 “가능성 있게” 완성하는 것뿐입니다.\u003c/p\u003e\n\u003cp\u003e이 과정에는 철학적, 윤리적, 도덕적, 심리적 고려 사항이 내재적으로 내장되어 있지 않습니다. LLMs를 그저 매우 대규모의 “자동 완성 기계”로 생각하는 것이 적절합니다. 이 자동 완성 기계는 방대한 양의 데이터로 훈련되어 가능성 있는 결과를 생성합니다.\u003c/p\u003e\n\u003ch2\u003eLLMs의 핵심 — 가능성\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eLLM들이 Q/A 및 번역과 같은 다양한 응용 프로그램을 처리하기 위해 이 자동완성 기능을 사용하는 방법은 데이터의 힘에 있습니다.\u003c/p\u003e\n\u003cp\u003e두 가지 응용 프로그램, Q/A 및 번역을 고려해 봅시다.\u003c/p\u003e\n\u003cp\u003e[Q/A]\u003c/p\u003e\n\u003cp\u003e질문 Q에 대한 답변 A를 제공하는 것은 Q/A 시스템을 형성합니다. 교육을 위해 우리는 Q/A 쌍을 단일 문서로 생각할 수 있습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e문서 D = [Q;A]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLLM(Language Model)이 수십억 개의 이러한 Q/A 문서로 훈련받는다면, 그들은 Q/A 문서를 완성하는 법을 배울 것입니다. Q/A LLM에서 \"합리성\"은 Q를 따르는 A를 생성하는 것을 의미합니다.\u003c/p\u003e\n\u003cp\u003e사용자가 질문 Q를 입력할 때:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLLM(Dₚ=Q) -` Dₙ\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e표 태그를 Markdown 형식으로 변경해주세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e시스템적으로 보면 다음과 같습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e문맥 C: “다음 내용을 영어에서 한국어로 번역하세요. 번역할 내용은:”\u003c/li\u003e\n\u003cli\u003e원본 S: “The weather is beautiful today.”\u003c/li\u003e\n\u003cli\u003e번역본 T: “오늘 날씨가 아름답습니다.”\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e실제로 언어 모델을 훈련하는 과정에서는 다음과 같이 처리됩니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eD = [C; S; T]\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e수십억 건의 번역 요청 및 결과 문서를 사용하여 훈련된 언어 모델은 자연스럽게 Dₚ = [C; S]를 Dₙ = T와 함께 완성할 수 있는 능력을 개발합니다. 본질적으로 번역기를 생성하는 대신, 우리는 번역 문서의 일부를 가져와 입력하고 자동 완성 기곕이 나머지를 채우도록 허용했습니다.\u003c/p\u003e\n\u003cp\u003e하지만 사용자에게는 훌륭한 번역이 이루어졌고 실용적으로 사용할 수 있다고 보입니다.\u003c/p\u003e\n\u003cp\u003e최종적으로 LLM(Large Language Models)이 문제를 해결하는 한 가지 방법은 가장 타당한 방식으로 남은 부분을 완성함으로써입니다. 너무 간단하게 보일 수 있지만, 조금의 상상력을 발휘하면 이 방법이 거의 모든 것을 해결할 수 있다는 것을 알 수 있습니다.\u003c/p\u003e\n\u003cp\u003e음악 작곡, 소설 쓰기, 영화 제작, 시험 문제 제출 및 해결, 경제 시뮬레이션, 수학 문제 해결, 철학적 논쟁, 인류의 미래 예측 - 우리가 가진 거의 모든 질문은 \"가장 타당한\" 결과를 제공함으로써 답변될 수 있습니다. 그리고 그 타당한 결과가 바로 LLM, 자동완성 기곕이 제공하는 것입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e이 글에서 우리는 대형 언어 모델이 세상의 다양한 문제들을 해결하는 핵심 원리에 대해 탐구했습니다. 간단히 말해, LLM은 자동 완성 기계입니다. 이 엔진은 훈련된 데이터를 기반으로 전체 문서의 전반부가 주어졌을 때, 후반부를 타당하게 완성하는 최적화된 엔진입니다.\u003c/p\u003e\n\u003cp\u003e이 원리는 간단하지만, LLM은 훈련 중 노출된 데이터의 유형과 구성을 다양화함으로써 새로운 응용 프로그램을 끝없이 만들어낼 수 있는 강력한 도구입니다.\u003c/p\u003e\n\u003cp\u003e다음 글에서는 이 자동 완성 기계의 \"대규모\" 측면이 우리에게 미치는 영향에 대해 설명할 것입니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-22-UnderstandingLargeLanguageModelsLLMsHowDoTheySolveProblems"},"buildId":"QYe6gFAUryFKFgjKBoIfo","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>