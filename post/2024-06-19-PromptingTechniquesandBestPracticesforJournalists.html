<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>기자들을 위한 프롬프팅 기술과 모범 사례 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-PromptingTechniquesandBestPracticesforJournalists" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="기자들을 위한 프롬프팅 기술과 모범 사례 | itposting" data-gatsby-head="true"/><meta property="og:title" content="기자들을 위한 프롬프팅 기술과 모범 사례 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-PromptingTechniquesandBestPracticesforJournalists" data-gatsby-head="true"/><meta name="twitter:title" content="기자들을 위한 프롬프팅 기술과 모범 사례 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 19:35" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-0fd008072af5a644.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">기자들을 위한 프롬프팅 기술과 모범 사례</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="기자들을 위한 프롬프팅 기술과 모범 사례" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-PromptingTechniquesandBestPracticesforJournalists&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>참고: 이 게시물은 Michael Crystal, Mona Gomaa 및 Nick Diakopoulos와 공동 저술되었습니다.</p>
<p>Associated Press의 최근 조사에 따르면, 콘텐츠 제작과 관련된 작업에 대한 생성 AI 사용에 대한 주요 관심이 드러났습니다. 이러한 작업으로는 정보 수집, 데이터 분석, 멀티미디어 콘텐츠 제작(예: 이미지 생성), 텍스트 요약, 번역, 그리고 필기가 해당됩니다. 분명히 대형 언어 모델(LLMs)은 언론사가 뉴스 매체를 위해 콘텐츠를 작성하는 방식을 뒤바꿀 수 있지만, 언론인들이 이러한 모델을 다양한 언론 사용 사례에 맞게 적응시키기 위해서는 효과적인 방법이 필요합니다. 이를 위한 한 가지 방법은 뉴스 작업을 위해 모델을 교육하는 것인데, 최근 그중 하나는 비용이 많이 들 수 있다고 주장했습니다. 시작하기 쉬운 다른 접근법은 프롬프트 엔지니어링이지만, 이는 뛰어난 기술과 시간 투자도 필요할 수 있습니다.</p>
<p>본 기사에서는 LLM이 언론에서의 작업에 대한 원하는 출력을 유도하는 데 다양한 프롬프팅 기술을 사용하여 제어하는 방법에 대한 몇 가지 모범 사례를 설명합니다. 우선 프롬프트 엔지니어링에 대한 배경 정보를 제공한 뒤, 뉴스 제작에서 몇 가지 다른 프롬프팅 기술에 대해 자세히 설명하고 관련 예시를 제시합니다. 마지막으로 프롬프트 검증 및 출력 품질 평가에 대한 몇 가지 아이디어를 제시합니다.</p>
<h1>프롬프트 엔지니어링이란 무엇인가요?</h1>
<p>프롬프트 엔지니어링은 사용자와 LLM(언어 모델 대규모 언어 모델) 간의 부상하는 커뮤니케이션 기술로, LLM에서 원하는 응답을 유도하기 위해 질문과 지침을 만드는 기법입니다. 프롬프트 엔지니어링은 표면상으로는 간단해 보이지만, LLM의 혜택을 완전히 누리기 위해 다양한 프롬프팅 기술에 대한 도메인 전문 지식이 필요합니다. 예를 들어, 이 안내서는 프롬프팅에 대한 17가지 다양한 접근 방식을 나열하고 있으며, 이 중 일부는 상당히 체계적이고 복잡할 수 있습니다. 게다가, 다른 모델은 최상의 성능을 얻기 위해 서로 다른 프롬프트 형식이나 기술이 필요할 수 있습니다.</p>
<h1>효과적인 프롬프트의 특징</h1>
<p>LLM으로부터 더 나은 결과를 얻기 위해서는 모든 프롬프트가 전체 문장으로 표현되어야 하며, 모델이 작업을 완료할 때 따라야 할(때로는 따라서는 안 될) 지침을 명확하게 표현해야 합니다. 게다가, 모델에게 자체 단계나 해결책을 찾도록 지시하여 결론에 이를 때까지 스스로 과정이나 해결책을 찾게 하는 것이, 특히 추론이 필요한 분석 작업에 대한 더 나은 결과 생성 능력을 향상시키는 데 도움이 된다는 것이 입증되었습니다. 또한, 좋은 프롬프트의 또 다른 중요한 특징은 특정 작업에 대한 프롬프트를 범위 설정하는 것입니다. 아주 포괄적이고 열린 작업에 대해 프롬프트하면(예: "온라인 뉴스 사이트 생성"), 해당 전체 목표의 작업 및 하위 작업을 개별적으로 다루기 위해 세분화하지 않는 한 효과적이지 않습니다. 모델이 주어진 지침에서 벗어나는 가능성을 최소화하기 위해서, OpenAI의 프롬프팅 안내서는 복잡한 작업을 서로 다른 프롬프트를 가진 하위 작업으로 분할하는 것을 권장합니다.</p>
<p>일반적으로 좋은 프롬프트는 프롬프트 텍스트와 컨텍스트를 포함한 구조로 구성됩니다 (Joe Amditis의 초보자용 프롬프트 핸드북 3장 참조). 그러나 작업에 따라 이 구조를 확장하여 생성된 텍스트의 길이와 같은 제약 조건, 외부 서비스나 데이터 소스에 액세스하는 도구 (예: Yahoo Finance API) 또는 추가 지시사항 (예: 어조나 글쓰기 스타일 지정)를 포함할 수도 있습니다.</p>
<p>예를 들어 사실에 관한 정보가 필요한 작업의 경우, 프롬프트가 출력물을 근거로 하는 데 도움이 되도록 신뢰할 수 있는 참조 텍스트를 컨텍스트에 포함하는 것이 좋습니다.</p>
<p>책임감 있는 프롬프팅 측면에서 주의할 점 중 하나는 프롬프트 컨텍스트에 기밀 정보나 개인 식별 가능 정보(PII)를 포함할 때 해당 정보가 제3자 AI 플랫폼(예: OpenAI 또는 Anthropic)과 공유되는 경우 조심해야 한다는 것입니다. PII 문제를 해결하기 위해 구체적인 정보를 일반적으로 익명화된 정보(예: "월터 스미스"를 프롬프트에서 "<code>이름</code>"으로 대체)로 대체한 후 서비스로부터 응답을 받은 후 원래의 이름으로 다시 대체할 수 있습니다. 또 다른 접근 방법은 외부 파티와 프롬프트 컨텍스트를 공유하지 않도록 로컬에 호스팅된 모델을 사용하는 것입니다.</p>
<p>일부 모델은 시스템 프롬프트의 사용을 지원하기도 하는데, 이는 시스템이 어조, 스타일 또는 컨텍스트에 포함된 자료에서 그대로 설정된 대로 반응하는 전반적인 무대 설정이 될 수 있습니다. 예를 들어 "귀하의 응답은 항상 귀하에게 제공된 특정 문서에 기초합니다."라는 시스템 프롬프트를 포함하여 모델이 응답을 제공할 때 문맥에 포함된 정보에만 작동하도록 유도할 수 있습니다. 그러나 시스템 프롬프트와 마찬가지로 모델이 항상 지시에 완벽하게 따르지 않을 수 있으므로 출력물을 확인하는 것이 여전히 필요합니다.</p>
<p>다음으로, 이러한 특성들이 다른 프롬프팅 기술에 어떻게 적용될 수 있는지에 대해 논의하겠습니다.</p>
<h1>주요 프롬프팅 기술 개요</h1>
<h2>제로샷 프롬프팅</h2>
<p>제로샷 프롬프팅은 모델에게 작업을 완료하도록 지시하지만 작업이나 출력물에 대한 예제나 시연을 제공하지 않고 수행하는 기술입니다 (즉, “제로”는 제로샷에서 제공된 예제의 수가 제로를 의미합니다). 이러한 종류의 프롬프팅은 아이디에이션(예: Figure 1에 설명된 같은 브레인스토밍 인터뷰 질문 작성), 콘텐츠 생성(예: 헤드라인 초안 작성) 및 번역이 필요한 작업에 유용할 수 있습니다. 그러나 이 기술은 원하는 출력물에 도달하기 위해 기본 프롬프트를 반복해서 필요한 세부 정보를 포함해야 한다는 것을 의미합니다. 이는 과연 LLMs의 통계적 성질에 기인하여 작업을 수행하는 동안 모델의 정확한 응답과 형식을 일관되게 예측하기 어렵게 만드는 요소일 수 있습니다.</p>
<p>최신 뉴스 요약 등 사실적인 답변이 필요한 사례에서는 제로샷 프롬프팅이, 다른 맥락 없이 사용되면 모델의 훈련 데이터만을 활용해 응답을 제공한다는 한계가 있습니다. 따라서, 최소한의 지시에 제로샷 프롬프팅을 사용할 때는, 모델이 생성한 출력물이 모델의 훈련 데이터에 포함된 지식만을 반영할 수 있으며 이는 과거의 것일 수 있기 때문에 기자들은 특히 모델의 생성물에 대해 조심해야 합니다. 모델이 생성한 텍스트가 작업과 관련이 있는지 확인하는 한 가지 방법은, 모델에게 해당 발췌문을 기반으로 재미있는 헤드라인을 생성하도록 요청할 때와 같이 프롬프트에 관련 맥락을 포함시키는 것입니다. 때로는 GPT-4o와 같은 최첨단 모델은 제로샷 프롬프팅을 수행하고 이후 인터넷을 둘러다니면서 최신 소스에 접근하여 맥락을 제공할 수도 있습니다(Figures 2A 및 2B).</p>
<p><img src="/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_1.png" alt="Prompting Techniques and Best Practices for Journalists 1"></p>
<p><img src="/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_2.png" alt="Prompting Techniques and Best Practices for Journalists 2"></p>
<p><img src="/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_3.png" alt="Prompting Techniques and Best Practices for Journalists 3"></p>
<h2>Few-shot Prompting</h2>
<p>추가적인 세부 정보, 구조, 및 서식화된 응답이 필요한 사용 사례에는 zero-shot prompting 대안으로 몇 가지 예시를 사용하는 것이 도움이 됩니다. Few-shot prompting은 zero-shot prompting을 기반으로 하여 prompt 문맥의 일부로 작업의 예시나 출력 서식을 포함함으로써 발전된 기술입니다 (Figure 3에 설명되어 있음). 이를 통해 모델은 생성된 텍스트에 반영해야 하는 원하는 패턴과 행동을 인식할 수 있습니다. 예를 들어, 기자들은 LLM에 부정적인 및 긍정적인 코멘트의 몇 가지 예시와 해당 레이블을 제공하여 뉴스 기사에 대한 사용자 코멘트를 분류하기 위해 few-shot prompt를 사용할 수 있습니다. 이는 기자들이 교두보 기사에 대한 청중의 반응을 이해하는 쉬운 방법을 갖도록 도울 수 있습니다. 비슷하게, few-shot prompting은 정보 추출(예: 사람이나 장소와 같은 명명된 엔티티 추출)이나 분류(예: 스키마에 따라 콘텐츠 레이블링) 사용 사례에 유용할 수 있습니다. 효과적인 few-shot prompting의 주요 도전 과제는 모델이 과업을 어떻게 완료해야 하는지를 보여주는 예시를 개발하는 것입니다.</p>
<h2>Chain-of-Thought Prompting (CoT)</h2>
<p>Chain of Thought prompting 기술을 통해 모델은 중간 단계를 통해 복잡한 과제에 대해 "추론"할 수 있습니다. 그러나 이는 지금까지 설명한 다른 prompt 기술과 상호 배타적인 기술은 아닙니다. 가장 기본적인 형태에서는 zero-shot 및 few-shot prompt를 포함하여 어떤 prompt에도 "한 단계씩 생각해 봅시다"를 추가할 수 있습니다. 이 방법이 작동하는 이유는 과제에 대한 대응 결과를 도와줄 수 있는 문맥을 출력하기 전에 모델이 작업에 착수하기 때문입니다. 이 prompt 기술은 텍스트에서 양적 질문에 답하는 것과 같은 분석적 작업에 유용하며, 이전에 추론이 필요한 복잡한 작업에 대해 더 나은 결과를 얻기 위해 few-shot prompting과 조합될 수 있습니다.</p>
<p>Figure 4A와 4B에서 볼 수 있듯이, 제로샷 프롬프팅을 사용하여 모델에게 스텝바이스텝 사고하도록 지시하고 이를 CoT 결과와 결합하면, 동일한 작업에 대해 제로샷 프롬프팅만 사용하는 것보다 더 세밀한 답변이 나옵니다. 중간 출력은 모델이 최종 출력에 도달하는 과정을 이해하기 쉽도록 몇몇 정보를 제공하는 추가적인 이점이 있습니다. 다만, 제3자 모델에 프롬프트하는 API를 사용할 때 유의할 점은, CoT 프롬프팅이 더 많은 (중간) 출력 토큰을 생성하므로 비용이 더 발생할 수 있다는 점입니다.</p>
<p><img src="/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_5.png" alt="PromptingTechniquesandBestPracticesforJournalists_5"></p>
<p><img src="/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_6.png" alt="PromptingTechniquesandBestPracticesforJournalists_6"></p>
<h2>프롬프팅에서의 효과적인 품질 관리</h2>
<p>프롬프트 품질을 효과적으로 제어하는 데는 두 가지 기본적인 접근 방법이 있습니다: (1) 강건성을 확립하기 위해 미리 프롬프트를 유효성 검사하고, (2) 각종 품질 기준에 따라 작업별로 요구되는 출력을 평가하는 것입니다.</p>
<h2>프롬프트 유효성 검사</h2>
<p>프롬프트를 작성하는 것은 LLMs의 힘에 진입하는 가장 쉬운 방법 중 하나일 수 있지만, 고품질의 출력을 생성할 수 있도록 프롬프트를 다듬는 데는 많은 반복과 시간이 필요할 수 있습니다. 이런 의미에서, 개발 중인 프롬프트의 성능을 평가하기 위한 유효성 검사 프로세스에 대해 생각하는 것이 도움이 될 수 있습니다. 그 프롬프트가 효과적인 프롬프트인지 어떻게 알 수 있을까요?</p>
<p>각 작업을 대상으로 하려는 경우 준비해야 할 두 개의 데이터 세트가 필요한 방식을 권장합니다: 개발 중인 프롬프트의 성능을 평가하기 위한 데이터 세트인 개발 세트와 개발 세트에서 가능한 한 최적화한 후에만 프롬프트를 평가하는 데 사용하는 별도의 테스트 세트입니다. 이상적인 경우 두 데이터 세트 모두 무작위 샘플이므로 어느 쪽에도 기저 선택 편향이 없어야 합니다. 두 세트를 가지고 있는 것은 개발 세트와 잘 작동하도록 개발 및 다듬은 프롬프트가 테스트 세트에도 일반화되어 여전히 잘 작동하는지 이해하는 데 도움이 됩니다. 개발 및 테스트 세트가 크고 다양할수록 프롬프트가 다양한 조건에서 잘 작동하고 있는지 더 자신할 수 있습니다. 다만 주의해야 할 점은 모델을 교체하거나 제공 업체가 모델을 업데이트할 때마다 이 유효성 검사를 다시 실행해야 한다는 것입니다!</p>
<p>프롬프트 유효성 검사 과정 중 LLMs의 통계적 변동성을 고려하는 것이 중요합니다. 이는 각 프롬프트 반복에 해당하는 텍스트를 생성할 때 고려해야 합니다. 이 블로그 글에 포함된 예시는 ChatGPT 사용자 인터페이스를 이용하여 생성되었지만, 프롬프트를 개발하고 검증할 때 OpenAI의 Playground를 사용할 것을 권장합니다. Playground를 사용하면 이 유효성 검증에 유용한 여러 매개변수를 제어할 수 있습니다.</p>
<p>가장 중요한 매개변수는 온도(temperature)입니다. 이것은 생성된 텍스트의 난수성 vs. 결정론성 수준을 제어합니다. LLMs는 한 번에 하나의 토큰을 생성하는 방식으로 작동하며, 높은 온도는 모델에 다음 토큰을 선택할 여지를 더 많이 줍니다. OpenAI 모델들의 경우, 이 값은 기본적으로 1이며 범위는 0에서 2까지입니다. 프롬프트의 제공된 문맥과 굳이 밀접하게 연결되어야 하는 작업(예: 생성된 요약이 기본 문서를 벗어나지 않도록 보장)의 경우 온도를 0에 가깝게 설정해야 합니다. 반면, 아이디어 발상이나 헤드라인 아이디어화와 같이 더 "창의적"이거나 "자세한" 텍스트가 필요한 경우, 온도 값을 2에 가깝게 설정하면 동일한 프롬프트에 대해 더 높은 창조적인 텍스트 변형이 나올 것입니다. 물론, 온도가 높을수록 출력물의 변동성도 더 크며, 따라서 유효성을 평가하기 위해 더 많은 시행을 해야 할 것입니다.</p>
<p>프롬프트 유효성 검사는 특정 작업에 제작된 프롬프트를 대규모로 사용하기 전에 고려해야 하는 프롬프트 엔지니어링의 과소평가된 복잡성 중 하나입니다. 동시에 체계적인 방법으로 검증된 후에는 조직 내에서 프롬프트를 공유할 때 보다 자신 있게 할 수 있으며, 뉴스룸의 모든 사람이 자신의 버전을 창출하는 중복된 노력을 줄일 수 있습니다. 또한 프롬프트의 개발 과정을 문서화하고 벤치마크 개발 및 테스트 데이터셋을 설정함으로써, 작업 및 뉴스룸 간에 보다 투명하고 재현 가능하며 확장 가능한 프롬프트 엔지니어링 및 유효성 검사 방법에 기여할 것입니다.</p>
<h2>AI 생성 콘텐츠의 품질 평가하기</h2>
<p>지금쯤 LLM을 사용하는 많은 사람들은 그들이 환각에 빠질 가능성이 있다는 것을 알고 있을 것입니다. 즉, 그들이 출력물을 생성하는 방식의 통계적 특성 때문에 현실에 근거를 두지 않은 정보를 만들어 내는 것입니다. 이러한 점이 저널리즘에서 고려되지 않을 경우, 뉴스의 진실성과 신뢰에 영향을 미칠 수 있습니다.</p>
<p>LLM을 사용하는 작업에 따라 평가 기준이 다를 수 있지만, 일반적으로 우리는 기자들이 정보 정확도와 편향과 관련된 차원을 최소한으로 고려해야 한다고 제안합니다. 여기에는 정치적 및 대표적 편향(과잉 또는 미달된 그룹의 표현)을 포함합니다. 또한 생성된 텍스트의 언어에 대한 추가적인 질적 차원도 평가과정에 고려될 수 있습니다. 가독성(생성된 텍스트에 불완전하거나 명확하지 않은 문장이 있는가?), 세분성(생성된 텍스트의 언어가 얼마나 자세한가?), 적절성(생성된 텍스트가 프롬프트에 설명된 요청과 얼마나 관련이 있는가?)이 있습니다. 물론 이것들은 다양한 기준 중 몇 가지에 불과하며, 여러분이 평가할 수 있는 기준들 중에서 더 많은 작업 특정 기준들을 개발할 것을 장려합니다. 기자들이 기술자나 사회과학자와 협업하여 다양한 뉴스 관련 작업에서 LLM 출력물의 성공을 평가할 수 있는 견고하고 신뢰할 수 있는 평가 지표와 기준을 설정하는 한 가지 방법이 될 수 있습니다.</p>
<p>하지만 우리는 이러한 평가를 일반적으로 더 높은 품질의 출력물을 생성하는 경향이 있는 프롬프트를 보여주는 지표로 추천하더라도, 책임 있는 사용 관점에서 많은 사용 사례에 사람을 계속 참여시키는 것이 현명하다는 것을 강조합니다. 모델의 출력물이 청중에게 직접 제시될 때와 같은 정확도와 같은 차원에서 특히 중요합니다.</p>
<h1>프롬프트를 더욱 향상하는 방법</h1>
<p>LLM(Large Language Models)의 능력이 계속해서 발전함에 따라, 최신 프롬프팅 기술 및 응용 프로그램에 대해 최신 정보를 유지하기 위해 주기적으로 제3자 모델과 관련된 프롬프트 가이드 및 라이브러리를 확인하는 것을 권장합니다. 아래는 프롬프팅을 위한 추가 참고 자료들로 책갈피해두고 싶은 몇 가지 자원을 나열해봤습니다:</p>
<ul>
<li>Prompt Engineering — OpenAI</li>
<li>Prompt Examples — OpenAI</li>
<li>Intro to prompting — Anthropic</li>
<li>Prompt Library — Anthropic</li>
<li>Beginner’s prompt handbook: ChatGPT for local news publishers</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"기자들을 위한 프롬프팅 기술과 모범 사례","description":"","date":"2024-06-19 19:35","slug":"2024-06-19-PromptingTechniquesandBestPracticesforJournalists","content":"\n\n\u003cimg src=\"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_0.png\" /\u003e\n\n참고: 이 게시물은 Michael Crystal, Mona Gomaa 및 Nick Diakopoulos와 공동 저술되었습니다.\n\nAssociated Press의 최근 조사에 따르면, 콘텐츠 제작과 관련된 작업에 대한 생성 AI 사용에 대한 주요 관심이 드러났습니다. 이러한 작업으로는 정보 수집, 데이터 분석, 멀티미디어 콘텐츠 제작(예: 이미지 생성), 텍스트 요약, 번역, 그리고 필기가 해당됩니다. 분명히 대형 언어 모델(LLMs)은 언론사가 뉴스 매체를 위해 콘텐츠를 작성하는 방식을 뒤바꿀 수 있지만, 언론인들이 이러한 모델을 다양한 언론 사용 사례에 맞게 적응시키기 위해서는 효과적인 방법이 필요합니다. 이를 위한 한 가지 방법은 뉴스 작업을 위해 모델을 교육하는 것인데, 최근 그중 하나는 비용이 많이 들 수 있다고 주장했습니다. 시작하기 쉬운 다른 접근법은 프롬프트 엔지니어링이지만, 이는 뛰어난 기술과 시간 투자도 필요할 수 있습니다.\n\n본 기사에서는 LLM이 언론에서의 작업에 대한 원하는 출력을 유도하는 데 다양한 프롬프팅 기술을 사용하여 제어하는 방법에 대한 몇 가지 모범 사례를 설명합니다. 우선 프롬프트 엔지니어링에 대한 배경 정보를 제공한 뒤, 뉴스 제작에서 몇 가지 다른 프롬프팅 기술에 대해 자세히 설명하고 관련 예시를 제시합니다. 마지막으로 프롬프트 검증 및 출력 품질 평가에 대한 몇 가지 아이디어를 제시합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 프롬프트 엔지니어링이란 무엇인가요?\n\n프롬프트 엔지니어링은 사용자와 LLM(언어 모델 대규모 언어 모델) 간의 부상하는 커뮤니케이션 기술로, LLM에서 원하는 응답을 유도하기 위해 질문과 지침을 만드는 기법입니다. 프롬프트 엔지니어링은 표면상으로는 간단해 보이지만, LLM의 혜택을 완전히 누리기 위해 다양한 프롬프팅 기술에 대한 도메인 전문 지식이 필요합니다. 예를 들어, 이 안내서는 프롬프팅에 대한 17가지 다양한 접근 방식을 나열하고 있으며, 이 중 일부는 상당히 체계적이고 복잡할 수 있습니다. 게다가, 다른 모델은 최상의 성능을 얻기 위해 서로 다른 프롬프트 형식이나 기술이 필요할 수 있습니다.\n\n# 효과적인 프롬프트의 특징\n\nLLM으로부터 더 나은 결과를 얻기 위해서는 모든 프롬프트가 전체 문장으로 표현되어야 하며, 모델이 작업을 완료할 때 따라야 할(때로는 따라서는 안 될) 지침을 명확하게 표현해야 합니다. 게다가, 모델에게 자체 단계나 해결책을 찾도록 지시하여 결론에 이를 때까지 스스로 과정이나 해결책을 찾게 하는 것이, 특히 추론이 필요한 분석 작업에 대한 더 나은 결과 생성 능력을 향상시키는 데 도움이 된다는 것이 입증되었습니다. 또한, 좋은 프롬프트의 또 다른 중요한 특징은 특정 작업에 대한 프롬프트를 범위 설정하는 것입니다. 아주 포괄적이고 열린 작업에 대해 프롬프트하면(예: \"온라인 뉴스 사이트 생성\"), 해당 전체 목표의 작업 및 하위 작업을 개별적으로 다루기 위해 세분화하지 않는 한 효과적이지 않습니다. 모델이 주어진 지침에서 벗어나는 가능성을 최소화하기 위해서, OpenAI의 프롬프팅 안내서는 복잡한 작업을 서로 다른 프롬프트를 가진 하위 작업으로 분할하는 것을 권장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적으로 좋은 프롬프트는 프롬프트 텍스트와 컨텍스트를 포함한 구조로 구성됩니다 (Joe Amditis의 초보자용 프롬프트 핸드북 3장 참조). 그러나 작업에 따라 이 구조를 확장하여 생성된 텍스트의 길이와 같은 제약 조건, 외부 서비스나 데이터 소스에 액세스하는 도구 (예: Yahoo Finance API) 또는 추가 지시사항 (예: 어조나 글쓰기 스타일 지정)를 포함할 수도 있습니다. \n\n예를 들어 사실에 관한 정보가 필요한 작업의 경우, 프롬프트가 출력물을 근거로 하는 데 도움이 되도록 신뢰할 수 있는 참조 텍스트를 컨텍스트에 포함하는 것이 좋습니다.\n\n책임감 있는 프롬프팅 측면에서 주의할 점 중 하나는 프롬프트 컨텍스트에 기밀 정보나 개인 식별 가능 정보(PII)를 포함할 때 해당 정보가 제3자 AI 플랫폼(예: OpenAI 또는 Anthropic)과 공유되는 경우 조심해야 한다는 것입니다. PII 문제를 해결하기 위해 구체적인 정보를 일반적으로 익명화된 정보(예: \"월터 스미스\"를 프롬프트에서 \"`이름`\"으로 대체)로 대체한 후 서비스로부터 응답을 받은 후 원래의 이름으로 다시 대체할 수 있습니다. 또 다른 접근 방법은 외부 파티와 프롬프트 컨텍스트를 공유하지 않도록 로컬에 호스팅된 모델을 사용하는 것입니다.\n\n일부 모델은 시스템 프롬프트의 사용을 지원하기도 하는데, 이는 시스템이 어조, 스타일 또는 컨텍스트에 포함된 자료에서 그대로 설정된 대로 반응하는 전반적인 무대 설정이 될 수 있습니다. 예를 들어 \"귀하의 응답은 항상 귀하에게 제공된 특정 문서에 기초합니다.\"라는 시스템 프롬프트를 포함하여 모델이 응답을 제공할 때 문맥에 포함된 정보에만 작동하도록 유도할 수 있습니다. 그러나 시스템 프롬프트와 마찬가지로 모델이 항상 지시에 완벽하게 따르지 않을 수 있으므로 출력물을 확인하는 것이 여전히 필요합니다.\n\n다음으로, 이러한 특성들이 다른 프롬프팅 기술에 어떻게 적용될 수 있는지에 대해 논의하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 주요 프롬프팅 기술 개요\n\n## 제로샷 프롬프팅\n\n제로샷 프롬프팅은 모델에게 작업을 완료하도록 지시하지만 작업이나 출력물에 대한 예제나 시연을 제공하지 않고 수행하는 기술입니다 (즉, “제로”는 제로샷에서 제공된 예제의 수가 제로를 의미합니다). 이러한 종류의 프롬프팅은 아이디에이션(예: Figure 1에 설명된 같은 브레인스토밍 인터뷰 질문 작성), 콘텐츠 생성(예: 헤드라인 초안 작성) 및 번역이 필요한 작업에 유용할 수 있습니다. 그러나 이 기술은 원하는 출력물에 도달하기 위해 기본 프롬프트를 반복해서 필요한 세부 정보를 포함해야 한다는 것을 의미합니다. 이는 과연 LLMs의 통계적 성질에 기인하여 작업을 수행하는 동안 모델의 정확한 응답과 형식을 일관되게 예측하기 어렵게 만드는 요소일 수 있습니다.\n\n최신 뉴스 요약 등 사실적인 답변이 필요한 사례에서는 제로샷 프롬프팅이, 다른 맥락 없이 사용되면 모델의 훈련 데이터만을 활용해 응답을 제공한다는 한계가 있습니다. 따라서, 최소한의 지시에 제로샷 프롬프팅을 사용할 때는, 모델이 생성한 출력물이 모델의 훈련 데이터에 포함된 지식만을 반영할 수 있으며 이는 과거의 것일 수 있기 때문에 기자들은 특히 모델의 생성물에 대해 조심해야 합니다. 모델이 생성한 텍스트가 작업과 관련이 있는지 확인하는 한 가지 방법은, 모델에게 해당 발췌문을 기반으로 재미있는 헤드라인을 생성하도록 요청할 때와 같이 프롬프트에 관련 맥락을 포함시키는 것입니다. 때로는 GPT-4o와 같은 최첨단 모델은 제로샷 프롬프팅을 수행하고 이후 인터넷을 둘러다니면서 최신 소스에 접근하여 맥락을 제공할 수도 있습니다(Figures 2A 및 2B).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Prompting Techniques and Best Practices for Journalists 1](/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_1.png)\n\n![Prompting Techniques and Best Practices for Journalists 2](/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_2.png)\n\n![Prompting Techniques and Best Practices for Journalists 3](/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_3.png)\n\n## Few-shot Prompting\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n추가적인 세부 정보, 구조, 및 서식화된 응답이 필요한 사용 사례에는 zero-shot prompting 대안으로 몇 가지 예시를 사용하는 것이 도움이 됩니다. Few-shot prompting은 zero-shot prompting을 기반으로 하여 prompt 문맥의 일부로 작업의 예시나 출력 서식을 포함함으로써 발전된 기술입니다 (Figure 3에 설명되어 있음). 이를 통해 모델은 생성된 텍스트에 반영해야 하는 원하는 패턴과 행동을 인식할 수 있습니다. 예를 들어, 기자들은 LLM에 부정적인 및 긍정적인 코멘트의 몇 가지 예시와 해당 레이블을 제공하여 뉴스 기사에 대한 사용자 코멘트를 분류하기 위해 few-shot prompt를 사용할 수 있습니다. 이는 기자들이 교두보 기사에 대한 청중의 반응을 이해하는 쉬운 방법을 갖도록 도울 수 있습니다. 비슷하게, few-shot prompting은 정보 추출(예: 사람이나 장소와 같은 명명된 엔티티 추출)이나 분류(예: 스키마에 따라 콘텐츠 레이블링) 사용 사례에 유용할 수 있습니다. 효과적인 few-shot prompting의 주요 도전 과제는 모델이 과업을 어떻게 완료해야 하는지를 보여주는 예시를 개발하는 것입니다.\n\n## Chain-of-Thought Prompting (CoT)\n\nChain of Thought prompting 기술을 통해 모델은 중간 단계를 통해 복잡한 과제에 대해 \"추론\"할 수 있습니다. 그러나 이는 지금까지 설명한 다른 prompt 기술과 상호 배타적인 기술은 아닙니다. 가장 기본적인 형태에서는 zero-shot 및 few-shot prompt를 포함하여 어떤 prompt에도 \"한 단계씩 생각해 봅시다\"를 추가할 수 있습니다. 이 방법이 작동하는 이유는 과제에 대한 대응 결과를 도와줄 수 있는 문맥을 출력하기 전에 모델이 작업에 착수하기 때문입니다. 이 prompt 기술은 텍스트에서 양적 질문에 답하는 것과 같은 분석적 작업에 유용하며, 이전에 추론이 필요한 복잡한 작업에 대해 더 나은 결과를 얻기 위해 few-shot prompting과 조합될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nFigure 4A와 4B에서 볼 수 있듯이, 제로샷 프롬프팅을 사용하여 모델에게 스텝바이스텝 사고하도록 지시하고 이를 CoT 결과와 결합하면, 동일한 작업에 대해 제로샷 프롬프팅만 사용하는 것보다 더 세밀한 답변이 나옵니다. 중간 출력은 모델이 최종 출력에 도달하는 과정을 이해하기 쉽도록 몇몇 정보를 제공하는 추가적인 이점이 있습니다. 다만, 제3자 모델에 프롬프트하는 API를 사용할 때 유의할 점은, CoT 프롬프팅이 더 많은 (중간) 출력 토큰을 생성하므로 비용이 더 발생할 수 있다는 점입니다.\n\n![PromptingTechniquesandBestPracticesforJournalists_5](/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_5.png)\n\n![PromptingTechniquesandBestPracticesforJournalists_6](/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_6.png)\n\n## 프롬프팅에서의 효과적인 품질 관리\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프롬프트 품질을 효과적으로 제어하는 데는 두 가지 기본적인 접근 방법이 있습니다: (1) 강건성을 확립하기 위해 미리 프롬프트를 유효성 검사하고, (2) 각종 품질 기준에 따라 작업별로 요구되는 출력을 평가하는 것입니다.\n\n## 프롬프트 유효성 검사\n\n프롬프트를 작성하는 것은 LLMs의 힘에 진입하는 가장 쉬운 방법 중 하나일 수 있지만, 고품질의 출력을 생성할 수 있도록 프롬프트를 다듬는 데는 많은 반복과 시간이 필요할 수 있습니다. 이런 의미에서, 개발 중인 프롬프트의 성능을 평가하기 위한 유효성 검사 프로세스에 대해 생각하는 것이 도움이 될 수 있습니다. 그 프롬프트가 효과적인 프롬프트인지 어떻게 알 수 있을까요?\n\n각 작업을 대상으로 하려는 경우 준비해야 할 두 개의 데이터 세트가 필요한 방식을 권장합니다: 개발 중인 프롬프트의 성능을 평가하기 위한 데이터 세트인 개발 세트와 개발 세트에서 가능한 한 최적화한 후에만 프롬프트를 평가하는 데 사용하는 별도의 테스트 세트입니다. 이상적인 경우 두 데이터 세트 모두 무작위 샘플이므로 어느 쪽에도 기저 선택 편향이 없어야 합니다. 두 세트를 가지고 있는 것은 개발 세트와 잘 작동하도록 개발 및 다듬은 프롬프트가 테스트 세트에도 일반화되어 여전히 잘 작동하는지 이해하는 데 도움이 됩니다. 개발 및 테스트 세트가 크고 다양할수록 프롬프트가 다양한 조건에서 잘 작동하고 있는지 더 자신할 수 있습니다. 다만 주의해야 할 점은 모델을 교체하거나 제공 업체가 모델을 업데이트할 때마다 이 유효성 검사를 다시 실행해야 한다는 것입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프롬프트 유효성 검사 과정 중 LLMs의 통계적 변동성을 고려하는 것이 중요합니다. 이는 각 프롬프트 반복에 해당하는 텍스트를 생성할 때 고려해야 합니다. 이 블로그 글에 포함된 예시는 ChatGPT 사용자 인터페이스를 이용하여 생성되었지만, 프롬프트를 개발하고 검증할 때 OpenAI의 Playground를 사용할 것을 권장합니다. Playground를 사용하면 이 유효성 검증에 유용한 여러 매개변수를 제어할 수 있습니다.\n\n가장 중요한 매개변수는 온도(temperature)입니다. 이것은 생성된 텍스트의 난수성 vs. 결정론성 수준을 제어합니다. LLMs는 한 번에 하나의 토큰을 생성하는 방식으로 작동하며, 높은 온도는 모델에 다음 토큰을 선택할 여지를 더 많이 줍니다. OpenAI 모델들의 경우, 이 값은 기본적으로 1이며 범위는 0에서 2까지입니다. 프롬프트의 제공된 문맥과 굳이 밀접하게 연결되어야 하는 작업(예: 생성된 요약이 기본 문서를 벗어나지 않도록 보장)의 경우 온도를 0에 가깝게 설정해야 합니다. 반면, 아이디어 발상이나 헤드라인 아이디어화와 같이 더 \"창의적\"이거나 \"자세한\" 텍스트가 필요한 경우, 온도 값을 2에 가깝게 설정하면 동일한 프롬프트에 대해 더 높은 창조적인 텍스트 변형이 나올 것입니다. 물론, 온도가 높을수록 출력물의 변동성도 더 크며, 따라서 유효성을 평가하기 위해 더 많은 시행을 해야 할 것입니다.\n\n프롬프트 유효성 검사는 특정 작업에 제작된 프롬프트를 대규모로 사용하기 전에 고려해야 하는 프롬프트 엔지니어링의 과소평가된 복잡성 중 하나입니다. 동시에 체계적인 방법으로 검증된 후에는 조직 내에서 프롬프트를 공유할 때 보다 자신 있게 할 수 있으며, 뉴스룸의 모든 사람이 자신의 버전을 창출하는 중복된 노력을 줄일 수 있습니다. 또한 프롬프트의 개발 과정을 문서화하고 벤치마크 개발 및 테스트 데이터셋을 설정함으로써, 작업 및 뉴스룸 간에 보다 투명하고 재현 가능하며 확장 가능한 프롬프트 엔지니어링 및 유효성 검사 방법에 기여할 것입니다.\n\n## AI 생성 콘텐츠의 품질 평가하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금쯤 LLM을 사용하는 많은 사람들은 그들이 환각에 빠질 가능성이 있다는 것을 알고 있을 것입니다. 즉, 그들이 출력물을 생성하는 방식의 통계적 특성 때문에 현실에 근거를 두지 않은 정보를 만들어 내는 것입니다. 이러한 점이 저널리즘에서 고려되지 않을 경우, 뉴스의 진실성과 신뢰에 영향을 미칠 수 있습니다.\n\nLLM을 사용하는 작업에 따라 평가 기준이 다를 수 있지만, 일반적으로 우리는 기자들이 정보 정확도와 편향과 관련된 차원을 최소한으로 고려해야 한다고 제안합니다. 여기에는 정치적 및 대표적 편향(과잉 또는 미달된 그룹의 표현)을 포함합니다. 또한 생성된 텍스트의 언어에 대한 추가적인 질적 차원도 평가과정에 고려될 수 있습니다. 가독성(생성된 텍스트에 불완전하거나 명확하지 않은 문장이 있는가?), 세분성(생성된 텍스트의 언어가 얼마나 자세한가?), 적절성(생성된 텍스트가 프롬프트에 설명된 요청과 얼마나 관련이 있는가?)이 있습니다. 물론 이것들은 다양한 기준 중 몇 가지에 불과하며, 여러분이 평가할 수 있는 기준들 중에서 더 많은 작업 특정 기준들을 개발할 것을 장려합니다. 기자들이 기술자나 사회과학자와 협업하여 다양한 뉴스 관련 작업에서 LLM 출력물의 성공을 평가할 수 있는 견고하고 신뢰할 수 있는 평가 지표와 기준을 설정하는 한 가지 방법이 될 수 있습니다.\n\n하지만 우리는 이러한 평가를 일반적으로 더 높은 품질의 출력물을 생성하는 경향이 있는 프롬프트를 보여주는 지표로 추천하더라도, 책임 있는 사용 관점에서 많은 사용 사례에 사람을 계속 참여시키는 것이 현명하다는 것을 강조합니다. 모델의 출력물이 청중에게 직접 제시될 때와 같은 정확도와 같은 차원에서 특히 중요합니다.\n\n# 프롬프트를 더욱 향상하는 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM(Large Language Models)의 능력이 계속해서 발전함에 따라, 최신 프롬프팅 기술 및 응용 프로그램에 대해 최신 정보를 유지하기 위해 주기적으로 제3자 모델과 관련된 프롬프트 가이드 및 라이브러리를 확인하는 것을 권장합니다. 아래는 프롬프팅을 위한 추가 참고 자료들로 책갈피해두고 싶은 몇 가지 자원을 나열해봤습니다:\n\n- Prompt Engineering — OpenAI\n- Prompt Examples — OpenAI\n- Intro to prompting — Anthropic\n- Prompt Library — Anthropic\n- Beginner’s prompt handbook: ChatGPT for local news publishers","ogImage":{"url":"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_0.png"},"coverImage":"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e참고: 이 게시물은 Michael Crystal, Mona Gomaa 및 Nick Diakopoulos와 공동 저술되었습니다.\u003c/p\u003e\n\u003cp\u003eAssociated Press의 최근 조사에 따르면, 콘텐츠 제작과 관련된 작업에 대한 생성 AI 사용에 대한 주요 관심이 드러났습니다. 이러한 작업으로는 정보 수집, 데이터 분석, 멀티미디어 콘텐츠 제작(예: 이미지 생성), 텍스트 요약, 번역, 그리고 필기가 해당됩니다. 분명히 대형 언어 모델(LLMs)은 언론사가 뉴스 매체를 위해 콘텐츠를 작성하는 방식을 뒤바꿀 수 있지만, 언론인들이 이러한 모델을 다양한 언론 사용 사례에 맞게 적응시키기 위해서는 효과적인 방법이 필요합니다. 이를 위한 한 가지 방법은 뉴스 작업을 위해 모델을 교육하는 것인데, 최근 그중 하나는 비용이 많이 들 수 있다고 주장했습니다. 시작하기 쉬운 다른 접근법은 프롬프트 엔지니어링이지만, 이는 뛰어난 기술과 시간 투자도 필요할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e본 기사에서는 LLM이 언론에서의 작업에 대한 원하는 출력을 유도하는 데 다양한 프롬프팅 기술을 사용하여 제어하는 방법에 대한 몇 가지 모범 사례를 설명합니다. 우선 프롬프트 엔지니어링에 대한 배경 정보를 제공한 뒤, 뉴스 제작에서 몇 가지 다른 프롬프팅 기술에 대해 자세히 설명하고 관련 예시를 제시합니다. 마지막으로 프롬프트 검증 및 출력 품질 평가에 대한 몇 가지 아이디어를 제시합니다.\u003c/p\u003e\n\u003ch1\u003e프롬프트 엔지니어링이란 무엇인가요?\u003c/h1\u003e\n\u003cp\u003e프롬프트 엔지니어링은 사용자와 LLM(언어 모델 대규모 언어 모델) 간의 부상하는 커뮤니케이션 기술로, LLM에서 원하는 응답을 유도하기 위해 질문과 지침을 만드는 기법입니다. 프롬프트 엔지니어링은 표면상으로는 간단해 보이지만, LLM의 혜택을 완전히 누리기 위해 다양한 프롬프팅 기술에 대한 도메인 전문 지식이 필요합니다. 예를 들어, 이 안내서는 프롬프팅에 대한 17가지 다양한 접근 방식을 나열하고 있으며, 이 중 일부는 상당히 체계적이고 복잡할 수 있습니다. 게다가, 다른 모델은 최상의 성능을 얻기 위해 서로 다른 프롬프트 형식이나 기술이 필요할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e효과적인 프롬프트의 특징\u003c/h1\u003e\n\u003cp\u003eLLM으로부터 더 나은 결과를 얻기 위해서는 모든 프롬프트가 전체 문장으로 표현되어야 하며, 모델이 작업을 완료할 때 따라야 할(때로는 따라서는 안 될) 지침을 명확하게 표현해야 합니다. 게다가, 모델에게 자체 단계나 해결책을 찾도록 지시하여 결론에 이를 때까지 스스로 과정이나 해결책을 찾게 하는 것이, 특히 추론이 필요한 분석 작업에 대한 더 나은 결과 생성 능력을 향상시키는 데 도움이 된다는 것이 입증되었습니다. 또한, 좋은 프롬프트의 또 다른 중요한 특징은 특정 작업에 대한 프롬프트를 범위 설정하는 것입니다. 아주 포괄적이고 열린 작업에 대해 프롬프트하면(예: \"온라인 뉴스 사이트 생성\"), 해당 전체 목표의 작업 및 하위 작업을 개별적으로 다루기 위해 세분화하지 않는 한 효과적이지 않습니다. 모델이 주어진 지침에서 벗어나는 가능성을 최소화하기 위해서, OpenAI의 프롬프팅 안내서는 복잡한 작업을 서로 다른 프롬프트를 가진 하위 작업으로 분할하는 것을 권장합니다.\u003c/p\u003e\n\u003cp\u003e일반적으로 좋은 프롬프트는 프롬프트 텍스트와 컨텍스트를 포함한 구조로 구성됩니다 (Joe Amditis의 초보자용 프롬프트 핸드북 3장 참조). 그러나 작업에 따라 이 구조를 확장하여 생성된 텍스트의 길이와 같은 제약 조건, 외부 서비스나 데이터 소스에 액세스하는 도구 (예: Yahoo Finance API) 또는 추가 지시사항 (예: 어조나 글쓰기 스타일 지정)를 포함할 수도 있습니다.\u003c/p\u003e\n\u003cp\u003e예를 들어 사실에 관한 정보가 필요한 작업의 경우, 프롬프트가 출력물을 근거로 하는 데 도움이 되도록 신뢰할 수 있는 참조 텍스트를 컨텍스트에 포함하는 것이 좋습니다.\u003c/p\u003e\n\u003cp\u003e책임감 있는 프롬프팅 측면에서 주의할 점 중 하나는 프롬프트 컨텍스트에 기밀 정보나 개인 식별 가능 정보(PII)를 포함할 때 해당 정보가 제3자 AI 플랫폼(예: OpenAI 또는 Anthropic)과 공유되는 경우 조심해야 한다는 것입니다. PII 문제를 해결하기 위해 구체적인 정보를 일반적으로 익명화된 정보(예: \"월터 스미스\"를 프롬프트에서 \"\u003ccode\u003e이름\u003c/code\u003e\"으로 대체)로 대체한 후 서비스로부터 응답을 받은 후 원래의 이름으로 다시 대체할 수 있습니다. 또 다른 접근 방법은 외부 파티와 프롬프트 컨텍스트를 공유하지 않도록 로컬에 호스팅된 모델을 사용하는 것입니다.\u003c/p\u003e\n\u003cp\u003e일부 모델은 시스템 프롬프트의 사용을 지원하기도 하는데, 이는 시스템이 어조, 스타일 또는 컨텍스트에 포함된 자료에서 그대로 설정된 대로 반응하는 전반적인 무대 설정이 될 수 있습니다. 예를 들어 \"귀하의 응답은 항상 귀하에게 제공된 특정 문서에 기초합니다.\"라는 시스템 프롬프트를 포함하여 모델이 응답을 제공할 때 문맥에 포함된 정보에만 작동하도록 유도할 수 있습니다. 그러나 시스템 프롬프트와 마찬가지로 모델이 항상 지시에 완벽하게 따르지 않을 수 있으므로 출력물을 확인하는 것이 여전히 필요합니다.\u003c/p\u003e\n\u003cp\u003e다음으로, 이러한 특성들이 다른 프롬프팅 기술에 어떻게 적용될 수 있는지에 대해 논의하겠습니다.\u003c/p\u003e\n\u003ch1\u003e주요 프롬프팅 기술 개요\u003c/h1\u003e\n\u003ch2\u003e제로샷 프롬프팅\u003c/h2\u003e\n\u003cp\u003e제로샷 프롬프팅은 모델에게 작업을 완료하도록 지시하지만 작업이나 출력물에 대한 예제나 시연을 제공하지 않고 수행하는 기술입니다 (즉, “제로”는 제로샷에서 제공된 예제의 수가 제로를 의미합니다). 이러한 종류의 프롬프팅은 아이디에이션(예: Figure 1에 설명된 같은 브레인스토밍 인터뷰 질문 작성), 콘텐츠 생성(예: 헤드라인 초안 작성) 및 번역이 필요한 작업에 유용할 수 있습니다. 그러나 이 기술은 원하는 출력물에 도달하기 위해 기본 프롬프트를 반복해서 필요한 세부 정보를 포함해야 한다는 것을 의미합니다. 이는 과연 LLMs의 통계적 성질에 기인하여 작업을 수행하는 동안 모델의 정확한 응답과 형식을 일관되게 예측하기 어렵게 만드는 요소일 수 있습니다.\u003c/p\u003e\n\u003cp\u003e최신 뉴스 요약 등 사실적인 답변이 필요한 사례에서는 제로샷 프롬프팅이, 다른 맥락 없이 사용되면 모델의 훈련 데이터만을 활용해 응답을 제공한다는 한계가 있습니다. 따라서, 최소한의 지시에 제로샷 프롬프팅을 사용할 때는, 모델이 생성한 출력물이 모델의 훈련 데이터에 포함된 지식만을 반영할 수 있으며 이는 과거의 것일 수 있기 때문에 기자들은 특히 모델의 생성물에 대해 조심해야 합니다. 모델이 생성한 텍스트가 작업과 관련이 있는지 확인하는 한 가지 방법은, 모델에게 해당 발췌문을 기반으로 재미있는 헤드라인을 생성하도록 요청할 때와 같이 프롬프트에 관련 맥락을 포함시키는 것입니다. 때로는 GPT-4o와 같은 최첨단 모델은 제로샷 프롬프팅을 수행하고 이후 인터넷을 둘러다니면서 최신 소스에 접근하여 맥락을 제공할 수도 있습니다(Figures 2A 및 2B).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_1.png\" alt=\"Prompting Techniques and Best Practices for Journalists 1\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_2.png\" alt=\"Prompting Techniques and Best Practices for Journalists 2\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_3.png\" alt=\"Prompting Techniques and Best Practices for Journalists 3\"\u003e\u003c/p\u003e\n\u003ch2\u003eFew-shot Prompting\u003c/h2\u003e\n\u003cp\u003e추가적인 세부 정보, 구조, 및 서식화된 응답이 필요한 사용 사례에는 zero-shot prompting 대안으로 몇 가지 예시를 사용하는 것이 도움이 됩니다. Few-shot prompting은 zero-shot prompting을 기반으로 하여 prompt 문맥의 일부로 작업의 예시나 출력 서식을 포함함으로써 발전된 기술입니다 (Figure 3에 설명되어 있음). 이를 통해 모델은 생성된 텍스트에 반영해야 하는 원하는 패턴과 행동을 인식할 수 있습니다. 예를 들어, 기자들은 LLM에 부정적인 및 긍정적인 코멘트의 몇 가지 예시와 해당 레이블을 제공하여 뉴스 기사에 대한 사용자 코멘트를 분류하기 위해 few-shot prompt를 사용할 수 있습니다. 이는 기자들이 교두보 기사에 대한 청중의 반응을 이해하는 쉬운 방법을 갖도록 도울 수 있습니다. 비슷하게, few-shot prompting은 정보 추출(예: 사람이나 장소와 같은 명명된 엔티티 추출)이나 분류(예: 스키마에 따라 콘텐츠 레이블링) 사용 사례에 유용할 수 있습니다. 효과적인 few-shot prompting의 주요 도전 과제는 모델이 과업을 어떻게 완료해야 하는지를 보여주는 예시를 개발하는 것입니다.\u003c/p\u003e\n\u003ch2\u003eChain-of-Thought Prompting (CoT)\u003c/h2\u003e\n\u003cp\u003eChain of Thought prompting 기술을 통해 모델은 중간 단계를 통해 복잡한 과제에 대해 \"추론\"할 수 있습니다. 그러나 이는 지금까지 설명한 다른 prompt 기술과 상호 배타적인 기술은 아닙니다. 가장 기본적인 형태에서는 zero-shot 및 few-shot prompt를 포함하여 어떤 prompt에도 \"한 단계씩 생각해 봅시다\"를 추가할 수 있습니다. 이 방법이 작동하는 이유는 과제에 대한 대응 결과를 도와줄 수 있는 문맥을 출력하기 전에 모델이 작업에 착수하기 때문입니다. 이 prompt 기술은 텍스트에서 양적 질문에 답하는 것과 같은 분석적 작업에 유용하며, 이전에 추론이 필요한 복잡한 작업에 대해 더 나은 결과를 얻기 위해 few-shot prompting과 조합될 수 있습니다.\u003c/p\u003e\n\u003cp\u003eFigure 4A와 4B에서 볼 수 있듯이, 제로샷 프롬프팅을 사용하여 모델에게 스텝바이스텝 사고하도록 지시하고 이를 CoT 결과와 결합하면, 동일한 작업에 대해 제로샷 프롬프팅만 사용하는 것보다 더 세밀한 답변이 나옵니다. 중간 출력은 모델이 최종 출력에 도달하는 과정을 이해하기 쉽도록 몇몇 정보를 제공하는 추가적인 이점이 있습니다. 다만, 제3자 모델에 프롬프트하는 API를 사용할 때 유의할 점은, CoT 프롬프팅이 더 많은 (중간) 출력 토큰을 생성하므로 비용이 더 발생할 수 있다는 점입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_5.png\" alt=\"PromptingTechniquesandBestPracticesforJournalists_5\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-PromptingTechniquesandBestPracticesforJournalists_6.png\" alt=\"PromptingTechniquesandBestPracticesforJournalists_6\"\u003e\u003c/p\u003e\n\u003ch2\u003e프롬프팅에서의 효과적인 품질 관리\u003c/h2\u003e\n\u003cp\u003e프롬프트 품질을 효과적으로 제어하는 데는 두 가지 기본적인 접근 방법이 있습니다: (1) 강건성을 확립하기 위해 미리 프롬프트를 유효성 검사하고, (2) 각종 품질 기준에 따라 작업별로 요구되는 출력을 평가하는 것입니다.\u003c/p\u003e\n\u003ch2\u003e프롬프트 유효성 검사\u003c/h2\u003e\n\u003cp\u003e프롬프트를 작성하는 것은 LLMs의 힘에 진입하는 가장 쉬운 방법 중 하나일 수 있지만, 고품질의 출력을 생성할 수 있도록 프롬프트를 다듬는 데는 많은 반복과 시간이 필요할 수 있습니다. 이런 의미에서, 개발 중인 프롬프트의 성능을 평가하기 위한 유효성 검사 프로세스에 대해 생각하는 것이 도움이 될 수 있습니다. 그 프롬프트가 효과적인 프롬프트인지 어떻게 알 수 있을까요?\u003c/p\u003e\n\u003cp\u003e각 작업을 대상으로 하려는 경우 준비해야 할 두 개의 데이터 세트가 필요한 방식을 권장합니다: 개발 중인 프롬프트의 성능을 평가하기 위한 데이터 세트인 개발 세트와 개발 세트에서 가능한 한 최적화한 후에만 프롬프트를 평가하는 데 사용하는 별도의 테스트 세트입니다. 이상적인 경우 두 데이터 세트 모두 무작위 샘플이므로 어느 쪽에도 기저 선택 편향이 없어야 합니다. 두 세트를 가지고 있는 것은 개발 세트와 잘 작동하도록 개발 및 다듬은 프롬프트가 테스트 세트에도 일반화되어 여전히 잘 작동하는지 이해하는 데 도움이 됩니다. 개발 및 테스트 세트가 크고 다양할수록 프롬프트가 다양한 조건에서 잘 작동하고 있는지 더 자신할 수 있습니다. 다만 주의해야 할 점은 모델을 교체하거나 제공 업체가 모델을 업데이트할 때마다 이 유효성 검사를 다시 실행해야 한다는 것입니다!\u003c/p\u003e\n\u003cp\u003e프롬프트 유효성 검사 과정 중 LLMs의 통계적 변동성을 고려하는 것이 중요합니다. 이는 각 프롬프트 반복에 해당하는 텍스트를 생성할 때 고려해야 합니다. 이 블로그 글에 포함된 예시는 ChatGPT 사용자 인터페이스를 이용하여 생성되었지만, 프롬프트를 개발하고 검증할 때 OpenAI의 Playground를 사용할 것을 권장합니다. Playground를 사용하면 이 유효성 검증에 유용한 여러 매개변수를 제어할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e가장 중요한 매개변수는 온도(temperature)입니다. 이것은 생성된 텍스트의 난수성 vs. 결정론성 수준을 제어합니다. LLMs는 한 번에 하나의 토큰을 생성하는 방식으로 작동하며, 높은 온도는 모델에 다음 토큰을 선택할 여지를 더 많이 줍니다. OpenAI 모델들의 경우, 이 값은 기본적으로 1이며 범위는 0에서 2까지입니다. 프롬프트의 제공된 문맥과 굳이 밀접하게 연결되어야 하는 작업(예: 생성된 요약이 기본 문서를 벗어나지 않도록 보장)의 경우 온도를 0에 가깝게 설정해야 합니다. 반면, 아이디어 발상이나 헤드라인 아이디어화와 같이 더 \"창의적\"이거나 \"자세한\" 텍스트가 필요한 경우, 온도 값을 2에 가깝게 설정하면 동일한 프롬프트에 대해 더 높은 창조적인 텍스트 변형이 나올 것입니다. 물론, 온도가 높을수록 출력물의 변동성도 더 크며, 따라서 유효성을 평가하기 위해 더 많은 시행을 해야 할 것입니다.\u003c/p\u003e\n\u003cp\u003e프롬프트 유효성 검사는 특정 작업에 제작된 프롬프트를 대규모로 사용하기 전에 고려해야 하는 프롬프트 엔지니어링의 과소평가된 복잡성 중 하나입니다. 동시에 체계적인 방법으로 검증된 후에는 조직 내에서 프롬프트를 공유할 때 보다 자신 있게 할 수 있으며, 뉴스룸의 모든 사람이 자신의 버전을 창출하는 중복된 노력을 줄일 수 있습니다. 또한 프롬프트의 개발 과정을 문서화하고 벤치마크 개발 및 테스트 데이터셋을 설정함으로써, 작업 및 뉴스룸 간에 보다 투명하고 재현 가능하며 확장 가능한 프롬프트 엔지니어링 및 유효성 검사 방법에 기여할 것입니다.\u003c/p\u003e\n\u003ch2\u003eAI 생성 콘텐츠의 품질 평가하기\u003c/h2\u003e\n\u003cp\u003e지금쯤 LLM을 사용하는 많은 사람들은 그들이 환각에 빠질 가능성이 있다는 것을 알고 있을 것입니다. 즉, 그들이 출력물을 생성하는 방식의 통계적 특성 때문에 현실에 근거를 두지 않은 정보를 만들어 내는 것입니다. 이러한 점이 저널리즘에서 고려되지 않을 경우, 뉴스의 진실성과 신뢰에 영향을 미칠 수 있습니다.\u003c/p\u003e\n\u003cp\u003eLLM을 사용하는 작업에 따라 평가 기준이 다를 수 있지만, 일반적으로 우리는 기자들이 정보 정확도와 편향과 관련된 차원을 최소한으로 고려해야 한다고 제안합니다. 여기에는 정치적 및 대표적 편향(과잉 또는 미달된 그룹의 표현)을 포함합니다. 또한 생성된 텍스트의 언어에 대한 추가적인 질적 차원도 평가과정에 고려될 수 있습니다. 가독성(생성된 텍스트에 불완전하거나 명확하지 않은 문장이 있는가?), 세분성(생성된 텍스트의 언어가 얼마나 자세한가?), 적절성(생성된 텍스트가 프롬프트에 설명된 요청과 얼마나 관련이 있는가?)이 있습니다. 물론 이것들은 다양한 기준 중 몇 가지에 불과하며, 여러분이 평가할 수 있는 기준들 중에서 더 많은 작업 특정 기준들을 개발할 것을 장려합니다. 기자들이 기술자나 사회과학자와 협업하여 다양한 뉴스 관련 작업에서 LLM 출력물의 성공을 평가할 수 있는 견고하고 신뢰할 수 있는 평가 지표와 기준을 설정하는 한 가지 방법이 될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e하지만 우리는 이러한 평가를 일반적으로 더 높은 품질의 출력물을 생성하는 경향이 있는 프롬프트를 보여주는 지표로 추천하더라도, 책임 있는 사용 관점에서 많은 사용 사례에 사람을 계속 참여시키는 것이 현명하다는 것을 강조합니다. 모델의 출력물이 청중에게 직접 제시될 때와 같은 정확도와 같은 차원에서 특히 중요합니다.\u003c/p\u003e\n\u003ch1\u003e프롬프트를 더욱 향상하는 방법\u003c/h1\u003e\n\u003cp\u003eLLM(Large Language Models)의 능력이 계속해서 발전함에 따라, 최신 프롬프팅 기술 및 응용 프로그램에 대해 최신 정보를 유지하기 위해 주기적으로 제3자 모델과 관련된 프롬프트 가이드 및 라이브러리를 확인하는 것을 권장합니다. 아래는 프롬프팅을 위한 추가 참고 자료들로 책갈피해두고 싶은 몇 가지 자원을 나열해봤습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePrompt Engineering — OpenAI\u003c/li\u003e\n\u003cli\u003ePrompt Examples — OpenAI\u003c/li\u003e\n\u003cli\u003eIntro to prompting — Anthropic\u003c/li\u003e\n\u003cli\u003ePrompt Library — Anthropic\u003c/li\u003e\n\u003cli\u003eBeginner’s prompt handbook: ChatGPT for local news publishers\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-PromptingTechniquesandBestPracticesforJournalists"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>