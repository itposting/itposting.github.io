<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>안정적인 확산 모델 비교하기 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-ComparingStableDiffusionModels" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="안정적인 확산 모델 비교하기 | itposting" data-gatsby-head="true"/><meta property="og:title" content="안정적인 확산 모델 비교하기 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-ComparingStableDiffusionModels" data-gatsby-head="true"/><meta name="twitter:title" content="안정적인 확산 모델 비교하기 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 21:01" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">안정적인 확산 모델 비교하기</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="안정적인 확산 모델 비교하기" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-ComparingStableDiffusionModels&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>안녕하세요! 저희의 오픈소스 텍스트-이미지 모델 'Stable Diffusion'은 Stability AI에서 출시되었고, 생성적 AI 분야를 혁신했습니다.</p>
<p>2022년 첫 출시 이후 몇 년 동안 여러번의 반복과 개선이 이루어졌습니다.</p>
<p>주요 릴리스에 대해 알아야 할 내용은 다음과 같습니다:</p>





















































<table><thead><tr><th>버전 번호</th><th>릴리스 날짜</th></tr></thead><tbody><tr><td>1.1</td><td>2022년 6월</td></tr><tr><td>1.2</td><td>2022년 6월</td></tr><tr><td>1.3</td><td>2022년 6월</td></tr><tr><td>1.4</td><td>2022년 8월</td></tr><tr><td>1.5</td><td>2022년 10월</td></tr><tr><td>2.0</td><td>2022년 11월</td></tr><tr><td>2.1</td><td>2022년 12월</td></tr><tr><td>XL 1.0</td><td>2023년 7월</td></tr><tr><td>XL Turbo</td><td>2023년 11월</td></tr><tr><td>Cascade</td><td>2024년 2월</td></tr><tr><td>3.0</td><td>곧 출시 예정</td></tr></tbody></table>
<p>더 필요한 정보가 있거나 궁금한 점이 있으면 언제든지 물어주세요!</p>
<div class="content-ad"></div>
<h1>Stable Diffusion 1.x 모델</h1>
<p>Stable Diffusion 모델의 첫 번째 세대인 1.x 시리즈는 1.1, 1.2, 1.3, 1.4 및 1.5 버전을 포함합니다.</p>
<p>이러한 모델은 512x512 픽셀의 해상도를 가지며 텍스트 조건부로 ViT-L/14 CLIP 모델을 사용합니다.</p>
<p>1.x 모델은 총 8억 6000만 개의 매개변수를 가지고 있습니다.</p>
<div class="content-ad"></div>
<h1>샘플 출력</h1>
<h1>주요 사항</h1>
<ul>
<li>해상도 (픽셀): 512x512</li>
<li>모델 카드</li>
<li>라이선스: Creative ML OpenRAIL-M — 상업적 및 비상업적 사용 가능</li>
</ul>
<p>이 모델을 사용하는 좋은 사례: 다양한 스타일과 주제를 생성합니다. 상대적으로 낮은 계산 요구 사항입니다.</p>
<div class="content-ad"></div>
<p>이 모델의 부적절한 사용 사례: 약한 프롬프트 이해와 해결. 변형된 주제. 평평해 보이는 이미지.</p>
<h2>세밀하게 조정된 모델</h2>
<p>알고 보면 Stable Diffusion 1.5가 그리 좋아 보이지 않는 결과물을 제공하지만, 오픈 소스 커뮤니티에는 훨씬 뛰어난 모델이 많이 있습니다.</p>
<p>포토 리얼리즘, 만화, 애니메이션 이미지 등을 포함한 수천 가지 특정 사용 사례에 대한 모델이 있습니다.</p>
<div class="content-ad"></div>
<p>예를 들어, DreamShaper, Juggernaut 및 RealCartoon은 안정적 확산 1.5를 기본 모델로 사용하지만 놀라운 결과를 제공하는 몇 가지 모델 중의 몇 가지입니다:</p>
<h2>안정적 확산 2.x 모델</h2>
<p>2022년 말에 출시된 2.x 시리즈에는 2.0 및 2.1 버전이 포함됩니다. 이러한 모델은 768x768 픽셀의 해상도를 갖추고, ViT-H/14라는 다른 CLIP 모델을 사용하여 프롬프트를 더 표현적으로 만듭니다.</p>
<p>2.x에서 사용된 다른 CLIP 모델로 인해 사람들이 1.x에서 마이그레이션하는 것이 어려워졌습니다. 사실 프롬프트가 그렇게 잘 전환되지 않아서 오픈 소스 커뮤니티에서의 널리 사용이 급격히 줄었습니다.</p>
<div class="content-ad"></div>
<p>아래는 텍스트를 친절한 한국어로 번역한 것입니다.</p>
<p>이 모델들의 매개변수 개수는 GitHub Readme에 따르면 1.5억개로 동일합니다.</p>
<h1>샘플 출력</h1>
<h1>주요 사항</h1>
<ul>
<li>해상도 (픽셀): 768x768</li>
<li>모델 카드</li>
<li>라이선스: CreativeML Open RAIL++-M — 상업적 및 비상업적 사용</li>
</ul>
<div class="content-ad"></div>
<p>이 모델의 좋은 사용 사례: 1.x 모델과 비교하여 더 높은 해상도의 출력물. 복잡하고 표현력이 풍부한 프롬프트를 효율적으로 처리. 사람보다는 건축물과 풍경 소재에 대한 성능이 뛰어남. 다양한 색상의 동적 범위를 제공함.</p>
<p>이 모델의 부적합한 사용 사례: 세대에 제약이 많음. 유명인과 미술 양식에 대한 검열이 있음.</p>
<h1>세분화된 모델</h1>
<p>안정적인 확산 2.0 및 2.1은 오픈 소스 커뮤니티에서 1.5만큼 널리 채택되지 않았습니다. 그러나 세분화된 모델은 일부 존재합니다.</p>
<div class="content-ad"></div>
<h1>Stable Diffusion XL 1.0</h1>
<p>2023년에 출시된 SDXL 1.0은 중간단계와 Dall-E 수준의 결과물을 소비자용 하드웨어에서 실행할 수 있습니다. 1024x1024 픽셀의 해상도를 제공하며 텍스트 조건부로 OpenCLIP-ViT/G 및 CLIP-ViT/L을 활용하는 SDXL을 통해 원하는 결과를 훨씬 쉽게 얻을 수 있습니다.</p>
<p>초기 출시인 Stability AI의 SDXL 1.0은 35억 개의 기본 모델 파라미터와 66억 개의 모델 앙상블 파이프라인을 갖추고 있습니다:</p>
<p><img src="/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png" alt="Stable Diffusion Models"></p>
<div class="content-ad"></div>
<h1>샘플 출력</h1>
<h1>주요 사항</h1>
<ul>
<li>해상도 (픽셀): 1024x1024</li>
<li>모델 카드</li>
<li>라이선스: CreativeML Open RAIL++-M 라이선스 — 상업적 및 비상업적 사용 가능</li>
</ul>
<p>이 모델의 좋은 사용 사례: 안정적인 확산 모델 중에서 가장 높은 해상도 출력. 개선된 색상 깊이, 구성, 전체 이미지 품질. 복잡한 프롬프트와 개념의 이해가 더 좋아짐.</p>
<div class="content-ad"></div>
<p>이 모델의 적합하지 않은 사용 사례: 로컬에서 실행하려면 상당한 계산 자원이 필요합니다. 소비자급 하드웨어에서 실행하기 어려울 수도 있습니다. 손과 같은 것들은 아직 완벽하지 않을 수 있습니다.</p>
<h1>세밀하게 조정된 모델</h1>
<p>오픈 소스 커뮤니티는 SDXL을 환영하고 SDXL로 품질 높은 출력물을 생산하는 몇 가지 세밀하게 조정된 모델을 출시했습니다.</p>
<p>Juggernaut XL, DreamShaper XL, RealVisXL, Animagine XL 등이 인기가 많으며 다양한 사용 사례를 제공할 수 있습니다:</p>
<div class="content-ad"></div>
<h1>SDXL Turbo</h1>
<p>SDXL Turbo은 SD XL 1.0의 간추린 버전으로, 512x512 픽셀 이미지를 빠르게 생성하기 위해 설계되었습니다. SD XL 1.0과 동일한 텍스트 조건 모델을 사용하며 35억 개의 매개변수를 갖고 있습니다. SDXL Turbo는 단 한 단계만으로 이미지를 생성할 수 있습니다.</p>
<h1>샘플 출력</h1>
<h1>주요 사실:</h1>
<div class="content-ad"></div>
<ul>
<li>해상도 (픽셀): 512x512</li>
<li>모델 카드</li>
<li>라이선스: 비상용 소프트웨어 — 비상업적 사용만 가능</li>
</ul>
<p><strong>이 모델을 잘 활용할 수 있는 경우:</strong> 짧은 시간 안에 좋은 결과물을 제공합니다. 프로토타입 애플리케이션 및 워크플로에 유용합니다. 실시간 실험에 적합합니다.</p>
<p><strong>이 모델을 잘 활용하지 못하는 경우:</strong> 비상업용 라이선스로 개인 및/또는 연구용으로만 사용이 가능합니다.</p>
<h1>세밀하게 조정된 모델</h1>
<div class="content-ad"></div>
<p>2.1처럼 SDXL Turbo의 오픈 소스 모델 생태계는 제한적입니다. 모델은 존재하지만, 대부분의 제작자들이 SDXL 및 SD 1.5와 같이 더 인기 있는 기본 모델에 노력을 기울이고 있습니다.</p>
<h1>Stable Cascade</h1>
<p>Stable Cascade은 Würstchen 아키텍처를 사용하는 독특한 모델로, 더 효율적인 훈련 및 추론을 가능케 합니다. 3단계(C, B, A)로 작동하며, 압축 계수는 42입니다:</p>
<p><img src="/assets/img/2024-06-19-ComparingStableDiffusionModels_1.png" alt="Stable Cascade"></p>
<div class="content-ad"></div>
<p>Stages C (10억 또는 36억 개의 매개변수) 및 B (7억 또는 15억 개의 매개변수)은 상호 교환 가능하며 하드웨어 요구 사항 및/또는 제한에 따라 다양한 모델을 사용할 수 있습니다.</p>
<p>SDXL Turbo와 마찬가지로 Stable Cascade은 연구용 모델입니다.</p>
<h2>샘플 출력</h2>
<h2>주요 사실:</h2>
<div class="content-ad"></div>
<ul>
<li>해상도 (픽셀): 1024x1024</li>
<li>모델 카드</li>
<li>라이선스: 소유권 제한 - 비상업적 사용만 허용</li>
</ul>
<p>이 모델의 좋은 사용 사례: SDXL 품질의 출력물과 더 나은 프롬프트 이해를 제공합니다. 사용된 모델에 따라 더 빠른 출력을 제공할 수 있습니다. 손가락, 이빨 등의 세부사항을 더 잘 생성합니다.</p>
<p>이 모델의 부적합한 사용 사례: 모델을 불러오려면 상당한 VRAM이 필요합니다. 오픈 소스 커뮤니티의 광범위한 지원이 아직 확인되지 않았습니다.</p>
<h1>세밀하게 조정된 모델들</h1>
<div class="content-ad"></div>
<p>현재 Stable Cascade에 대해 Fein-tuned 모델은 매우 적습니다.</p>
<h1>Stable Diffusion 3.0</h1>
<p>2024년 3월 발표된 Stable Diffusion 패밀리의 최신 버전인 Stable Diffusion 3.0입니다. 자세한 내용은 아직 부족하지만, 초기 결과로는 프롬프트 정렬 및 전체 이미지 품질에서 상당한 개선이 나타났습니다.</p>
<p>만약 Stable Diffusion 3이 출시되면 이 섹션을 업데이트하겠습니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"안정적인 확산 모델 비교하기","description":"","date":"2024-06-19 21:01","slug":"2024-06-19-ComparingStableDiffusionModels","content":"\n\n안녕하세요! 저희의 오픈소스 텍스트-이미지 모델 'Stable Diffusion'은 Stability AI에서 출시되었고, 생성적 AI 분야를 혁신했습니다.\n\n2022년 첫 출시 이후 몇 년 동안 여러번의 반복과 개선이 이루어졌습니다.\n\n주요 릴리스에 대해 알아야 할 내용은 다음과 같습니다:\n\n\n| 버전 번호    | 릴리스 날짜     |\n|-------------|----------------|\n| 1.1         | 2022년 6월     |\n| 1.2         | 2022년 6월     |\n| 1.3         | 2022년 6월     |\n| 1.4         | 2022년 8월     |\n| 1.5         | 2022년 10월    |\n| 2.0         | 2022년 11월    |\n| 2.1         | 2022년 12월    |\n| XL 1.0      | 2023년 7월     |\n| XL Turbo    | 2023년 11월    |\n| Cascade     | 2024년 2월     |\n| 3.0         | 곧 출시 예정    |\n\n\n더 필요한 정보가 있거나 궁금한 점이 있으면 언제든지 물어주세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Stable Diffusion 1.x 모델\n\nStable Diffusion 모델의 첫 번째 세대인 1.x 시리즈는 1.1, 1.2, 1.3, 1.4 및 1.5 버전을 포함합니다.\n\n이러한 모델은 512x512 픽셀의 해상도를 가지며 텍스트 조건부로 ViT-L/14 CLIP 모델을 사용합니다.\n\n1.x 모델은 총 8억 6000만 개의 매개변수를 가지고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 샘플 출력\n\n# 주요 사항\n\n- 해상도 (픽셀): 512x512\n- 모델 카드\n- 라이선스: Creative ML OpenRAIL-M — 상업적 및 비상업적 사용 가능\n\n이 모델을 사용하는 좋은 사례: 다양한 스타일과 주제를 생성합니다. 상대적으로 낮은 계산 요구 사항입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 모델의 부적절한 사용 사례: 약한 프롬프트 이해와 해결. 변형된 주제. 평평해 보이는 이미지.\n\n## 세밀하게 조정된 모델\n\n알고 보면 Stable Diffusion 1.5가 그리 좋아 보이지 않는 결과물을 제공하지만, 오픈 소스 커뮤니티에는 훨씬 뛰어난 모델이 많이 있습니다.\n\n포토 리얼리즘, 만화, 애니메이션 이미지 등을 포함한 수천 가지 특정 사용 사례에 대한 모델이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, DreamShaper, Juggernaut 및 RealCartoon은 안정적 확산 1.5를 기본 모델로 사용하지만 놀라운 결과를 제공하는 몇 가지 모델 중의 몇 가지입니다:\n\n## 안정적 확산 2.x 모델\n\n2022년 말에 출시된 2.x 시리즈에는 2.0 및 2.1 버전이 포함됩니다. 이러한 모델은 768x768 픽셀의 해상도를 갖추고, ViT-H/14라는 다른 CLIP 모델을 사용하여 프롬프트를 더 표현적으로 만듭니다.\n\n2.x에서 사용된 다른 CLIP 모델로 인해 사람들이 1.x에서 마이그레이션하는 것이 어려워졌습니다. 사실 프롬프트가 그렇게 잘 전환되지 않아서 오픈 소스 커뮤니티에서의 널리 사용이 급격히 줄었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 텍스트를 친절한 한국어로 번역한 것입니다.\n\n이 모델들의 매개변수 개수는 GitHub Readme에 따르면 1.5억개로 동일합니다.\n\n# 샘플 출력\n\n# 주요 사항\n\n- 해상도 (픽셀): 768x768\n- 모델 카드\n- 라이선스: CreativeML Open RAIL++-M — 상업적 및 비상업적 사용\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 모델의 좋은 사용 사례: 1.x 모델과 비교하여 더 높은 해상도의 출력물. 복잡하고 표현력이 풍부한 프롬프트를 효율적으로 처리. 사람보다는 건축물과 풍경 소재에 대한 성능이 뛰어남. 다양한 색상의 동적 범위를 제공함.\n\n이 모델의 부적합한 사용 사례: 세대에 제약이 많음. 유명인과 미술 양식에 대한 검열이 있음.\n\n# 세분화된 모델\n\n안정적인 확산 2.0 및 2.1은 오픈 소스 커뮤니티에서 1.5만큼 널리 채택되지 않았습니다. 그러나 세분화된 모델은 일부 존재합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Stable Diffusion XL 1.0\n\n2023년에 출시된 SDXL 1.0은 중간단계와 Dall-E 수준의 결과물을 소비자용 하드웨어에서 실행할 수 있습니다. 1024x1024 픽셀의 해상도를 제공하며 텍스트 조건부로 OpenCLIP-ViT/G 및 CLIP-ViT/L을 활용하는 SDXL을 통해 원하는 결과를 훨씬 쉽게 얻을 수 있습니다.\n\n초기 출시인 Stability AI의 SDXL 1.0은 35억 개의 기본 모델 파라미터와 66억 개의 모델 앙상블 파이프라인을 갖추고 있습니다:\n\n![Stable Diffusion Models](/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 샘플 출력\n\n# 주요 사항\n\n- 해상도 (픽셀): 1024x1024\n- 모델 카드  \n- 라이선스: CreativeML Open RAIL++-M 라이선스 — 상업적 및 비상업적 사용 가능\n\n이 모델의 좋은 사용 사례: 안정적인 확산 모델 중에서 가장 높은 해상도 출력. 개선된 색상 깊이, 구성, 전체 이미지 품질. 복잡한 프롬프트와 개념의 이해가 더 좋아짐.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 모델의 적합하지 않은 사용 사례: 로컬에서 실행하려면 상당한 계산 자원이 필요합니다. 소비자급 하드웨어에서 실행하기 어려울 수도 있습니다. 손과 같은 것들은 아직 완벽하지 않을 수 있습니다.\n\n# 세밀하게 조정된 모델\n\n오픈 소스 커뮤니티는 SDXL을 환영하고 SDXL로 품질 높은 출력물을 생산하는 몇 가지 세밀하게 조정된 모델을 출시했습니다.\n\nJuggernaut XL, DreamShaper XL, RealVisXL, Animagine XL 등이 인기가 많으며 다양한 사용 사례를 제공할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# SDXL Turbo\n\nSDXL Turbo은 SD XL 1.0의 간추린 버전으로, 512x512 픽셀 이미지를 빠르게 생성하기 위해 설계되었습니다. SD XL 1.0과 동일한 텍스트 조건 모델을 사용하며 35억 개의 매개변수를 갖고 있습니다. SDXL Turbo는 단 한 단계만으로 이미지를 생성할 수 있습니다.\n\n# 샘플 출력\n\n# 주요 사실:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 해상도 (픽셀): 512x512\n- 모델 카드\n- 라이선스: 비상용 소프트웨어 — 비상업적 사용만 가능\n\n**이 모델을 잘 활용할 수 있는 경우:** 짧은 시간 안에 좋은 결과물을 제공합니다. 프로토타입 애플리케이션 및 워크플로에 유용합니다. 실시간 실험에 적합합니다.\n\n**이 모델을 잘 활용하지 못하는 경우:** 비상업용 라이선스로 개인 및/또는 연구용으로만 사용이 가능합니다.\n\n# 세밀하게 조정된 모델\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2.1처럼 SDXL Turbo의 오픈 소스 모델 생태계는 제한적입니다. 모델은 존재하지만, 대부분의 제작자들이 SDXL 및 SD 1.5와 같이 더 인기 있는 기본 모델에 노력을 기울이고 있습니다.\n\n# Stable Cascade\n\nStable Cascade은 Würstchen 아키텍처를 사용하는 독특한 모델로, 더 효율적인 훈련 및 추론을 가능케 합니다. 3단계(C, B, A)로 작동하며, 압축 계수는 42입니다:\n\n![Stable Cascade](/assets/img/2024-06-19-ComparingStableDiffusionModels_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStages C (10억 또는 36억 개의 매개변수) 및 B (7억 또는 15억 개의 매개변수)은 상호 교환 가능하며 하드웨어 요구 사항 및/또는 제한에 따라 다양한 모델을 사용할 수 있습니다.\n\nSDXL Turbo와 마찬가지로 Stable Cascade은 연구용 모델입니다.\n\n## 샘플 출력\n\n## 주요 사실:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 해상도 (픽셀): 1024x1024\n- 모델 카드\n- 라이선스: 소유권 제한 - 비상업적 사용만 허용\n\n이 모델의 좋은 사용 사례: SDXL 품질의 출력물과 더 나은 프롬프트 이해를 제공합니다. 사용된 모델에 따라 더 빠른 출력을 제공할 수 있습니다. 손가락, 이빨 등의 세부사항을 더 잘 생성합니다.\n\n이 모델의 부적합한 사용 사례: 모델을 불러오려면 상당한 VRAM이 필요합니다. 오픈 소스 커뮤니티의 광범위한 지원이 아직 확인되지 않았습니다.\n\n# 세밀하게 조정된 모델들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n현재 Stable Cascade에 대해 Fein-tuned 모델은 매우 적습니다.\n\n# Stable Diffusion 3.0\n\n2024년 3월 발표된 Stable Diffusion 패밀리의 최신 버전인 Stable Diffusion 3.0입니다. 자세한 내용은 아직 부족하지만, 초기 결과로는 프롬프트 정렬 및 전체 이미지 품질에서 상당한 개선이 나타났습니다.\n\n만약 Stable Diffusion 3이 출시되면 이 섹션을 업데이트하겠습니다.","ogImage":{"url":"/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png"},"coverImage":"/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e안녕하세요! 저희의 오픈소스 텍스트-이미지 모델 'Stable Diffusion'은 Stability AI에서 출시되었고, 생성적 AI 분야를 혁신했습니다.\u003c/p\u003e\n\u003cp\u003e2022년 첫 출시 이후 몇 년 동안 여러번의 반복과 개선이 이루어졌습니다.\u003c/p\u003e\n\u003cp\u003e주요 릴리스에 대해 알아야 할 내용은 다음과 같습니다:\u003c/p\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003e버전 번호\u003c/th\u003e\u003cth\u003e릴리스 날짜\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e1.1\u003c/td\u003e\u003ctd\u003e2022년 6월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e1.2\u003c/td\u003e\u003ctd\u003e2022년 6월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e1.3\u003c/td\u003e\u003ctd\u003e2022년 6월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e1.4\u003c/td\u003e\u003ctd\u003e2022년 8월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e1.5\u003c/td\u003e\u003ctd\u003e2022년 10월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e2.0\u003c/td\u003e\u003ctd\u003e2022년 11월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e2.1\u003c/td\u003e\u003ctd\u003e2022년 12월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eXL 1.0\u003c/td\u003e\u003ctd\u003e2023년 7월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eXL Turbo\u003c/td\u003e\u003ctd\u003e2023년 11월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eCascade\u003c/td\u003e\u003ctd\u003e2024년 2월\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e3.0\u003c/td\u003e\u003ctd\u003e곧 출시 예정\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e더 필요한 정보가 있거나 궁금한 점이 있으면 언제든지 물어주세요!\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eStable Diffusion 1.x 모델\u003c/h1\u003e\n\u003cp\u003eStable Diffusion 모델의 첫 번째 세대인 1.x 시리즈는 1.1, 1.2, 1.3, 1.4 및 1.5 버전을 포함합니다.\u003c/p\u003e\n\u003cp\u003e이러한 모델은 512x512 픽셀의 해상도를 가지며 텍스트 조건부로 ViT-L/14 CLIP 모델을 사용합니다.\u003c/p\u003e\n\u003cp\u003e1.x 모델은 총 8억 6000만 개의 매개변수를 가지고 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e샘플 출력\u003c/h1\u003e\n\u003ch1\u003e주요 사항\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e해상도 (픽셀): 512x512\u003c/li\u003e\n\u003cli\u003e모델 카드\u003c/li\u003e\n\u003cli\u003e라이선스: Creative ML OpenRAIL-M — 상업적 및 비상업적 사용 가능\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 모델을 사용하는 좋은 사례: 다양한 스타일과 주제를 생성합니다. 상대적으로 낮은 계산 요구 사항입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 모델의 부적절한 사용 사례: 약한 프롬프트 이해와 해결. 변형된 주제. 평평해 보이는 이미지.\u003c/p\u003e\n\u003ch2\u003e세밀하게 조정된 모델\u003c/h2\u003e\n\u003cp\u003e알고 보면 Stable Diffusion 1.5가 그리 좋아 보이지 않는 결과물을 제공하지만, 오픈 소스 커뮤니티에는 훨씬 뛰어난 모델이 많이 있습니다.\u003c/p\u003e\n\u003cp\u003e포토 리얼리즘, 만화, 애니메이션 이미지 등을 포함한 수천 가지 특정 사용 사례에 대한 모델이 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e예를 들어, DreamShaper, Juggernaut 및 RealCartoon은 안정적 확산 1.5를 기본 모델로 사용하지만 놀라운 결과를 제공하는 몇 가지 모델 중의 몇 가지입니다:\u003c/p\u003e\n\u003ch2\u003e안정적 확산 2.x 모델\u003c/h2\u003e\n\u003cp\u003e2022년 말에 출시된 2.x 시리즈에는 2.0 및 2.1 버전이 포함됩니다. 이러한 모델은 768x768 픽셀의 해상도를 갖추고, ViT-H/14라는 다른 CLIP 모델을 사용하여 프롬프트를 더 표현적으로 만듭니다.\u003c/p\u003e\n\u003cp\u003e2.x에서 사용된 다른 CLIP 모델로 인해 사람들이 1.x에서 마이그레이션하는 것이 어려워졌습니다. 사실 프롬프트가 그렇게 잘 전환되지 않아서 오픈 소스 커뮤니티에서의 널리 사용이 급격히 줄었습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아래는 텍스트를 친절한 한국어로 번역한 것입니다.\u003c/p\u003e\n\u003cp\u003e이 모델들의 매개변수 개수는 GitHub Readme에 따르면 1.5억개로 동일합니다.\u003c/p\u003e\n\u003ch1\u003e샘플 출력\u003c/h1\u003e\n\u003ch1\u003e주요 사항\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e해상도 (픽셀): 768x768\u003c/li\u003e\n\u003cli\u003e모델 카드\u003c/li\u003e\n\u003cli\u003e라이선스: CreativeML Open RAIL++-M — 상업적 및 비상업적 사용\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 모델의 좋은 사용 사례: 1.x 모델과 비교하여 더 높은 해상도의 출력물. 복잡하고 표현력이 풍부한 프롬프트를 효율적으로 처리. 사람보다는 건축물과 풍경 소재에 대한 성능이 뛰어남. 다양한 색상의 동적 범위를 제공함.\u003c/p\u003e\n\u003cp\u003e이 모델의 부적합한 사용 사례: 세대에 제약이 많음. 유명인과 미술 양식에 대한 검열이 있음.\u003c/p\u003e\n\u003ch1\u003e세분화된 모델\u003c/h1\u003e\n\u003cp\u003e안정적인 확산 2.0 및 2.1은 오픈 소스 커뮤니티에서 1.5만큼 널리 채택되지 않았습니다. 그러나 세분화된 모델은 일부 존재합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eStable Diffusion XL 1.0\u003c/h1\u003e\n\u003cp\u003e2023년에 출시된 SDXL 1.0은 중간단계와 Dall-E 수준의 결과물을 소비자용 하드웨어에서 실행할 수 있습니다. 1024x1024 픽셀의 해상도를 제공하며 텍스트 조건부로 OpenCLIP-ViT/G 및 CLIP-ViT/L을 활용하는 SDXL을 통해 원하는 결과를 훨씬 쉽게 얻을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e초기 출시인 Stability AI의 SDXL 1.0은 35억 개의 기본 모델 파라미터와 66억 개의 모델 앙상블 파이프라인을 갖추고 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-ComparingStableDiffusionModels_0.png\" alt=\"Stable Diffusion Models\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e샘플 출력\u003c/h1\u003e\n\u003ch1\u003e주요 사항\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e해상도 (픽셀): 1024x1024\u003c/li\u003e\n\u003cli\u003e모델 카드\u003c/li\u003e\n\u003cli\u003e라이선스: CreativeML Open RAIL++-M 라이선스 — 상업적 및 비상업적 사용 가능\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 모델의 좋은 사용 사례: 안정적인 확산 모델 중에서 가장 높은 해상도 출력. 개선된 색상 깊이, 구성, 전체 이미지 품질. 복잡한 프롬프트와 개념의 이해가 더 좋아짐.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 모델의 적합하지 않은 사용 사례: 로컬에서 실행하려면 상당한 계산 자원이 필요합니다. 소비자급 하드웨어에서 실행하기 어려울 수도 있습니다. 손과 같은 것들은 아직 완벽하지 않을 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e세밀하게 조정된 모델\u003c/h1\u003e\n\u003cp\u003e오픈 소스 커뮤니티는 SDXL을 환영하고 SDXL로 품질 높은 출력물을 생산하는 몇 가지 세밀하게 조정된 모델을 출시했습니다.\u003c/p\u003e\n\u003cp\u003eJuggernaut XL, DreamShaper XL, RealVisXL, Animagine XL 등이 인기가 많으며 다양한 사용 사례를 제공할 수 있습니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eSDXL Turbo\u003c/h1\u003e\n\u003cp\u003eSDXL Turbo은 SD XL 1.0의 간추린 버전으로, 512x512 픽셀 이미지를 빠르게 생성하기 위해 설계되었습니다. SD XL 1.0과 동일한 텍스트 조건 모델을 사용하며 35억 개의 매개변수를 갖고 있습니다. SDXL Turbo는 단 한 단계만으로 이미지를 생성할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e샘플 출력\u003c/h1\u003e\n\u003ch1\u003e주요 사실:\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e해상도 (픽셀): 512x512\u003c/li\u003e\n\u003cli\u003e모델 카드\u003c/li\u003e\n\u003cli\u003e라이선스: 비상용 소프트웨어 — 비상업적 사용만 가능\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003e이 모델을 잘 활용할 수 있는 경우:\u003c/strong\u003e 짧은 시간 안에 좋은 결과물을 제공합니다. 프로토타입 애플리케이션 및 워크플로에 유용합니다. 실시간 실험에 적합합니다.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e이 모델을 잘 활용하지 못하는 경우:\u003c/strong\u003e 비상업용 라이선스로 개인 및/또는 연구용으로만 사용이 가능합니다.\u003c/p\u003e\n\u003ch1\u003e세밀하게 조정된 모델\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e2.1처럼 SDXL Turbo의 오픈 소스 모델 생태계는 제한적입니다. 모델은 존재하지만, 대부분의 제작자들이 SDXL 및 SD 1.5와 같이 더 인기 있는 기본 모델에 노력을 기울이고 있습니다.\u003c/p\u003e\n\u003ch1\u003eStable Cascade\u003c/h1\u003e\n\u003cp\u003eStable Cascade은 Würstchen 아키텍처를 사용하는 독특한 모델로, 더 효율적인 훈련 및 추론을 가능케 합니다. 3단계(C, B, A)로 작동하며, 압축 계수는 42입니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-ComparingStableDiffusionModels_1.png\" alt=\"Stable Cascade\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eStages C (10억 또는 36억 개의 매개변수) 및 B (7억 또는 15억 개의 매개변수)은 상호 교환 가능하며 하드웨어 요구 사항 및/또는 제한에 따라 다양한 모델을 사용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003eSDXL Turbo와 마찬가지로 Stable Cascade은 연구용 모델입니다.\u003c/p\u003e\n\u003ch2\u003e샘플 출력\u003c/h2\u003e\n\u003ch2\u003e주요 사실:\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e해상도 (픽셀): 1024x1024\u003c/li\u003e\n\u003cli\u003e모델 카드\u003c/li\u003e\n\u003cli\u003e라이선스: 소유권 제한 - 비상업적 사용만 허용\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 모델의 좋은 사용 사례: SDXL 품질의 출력물과 더 나은 프롬프트 이해를 제공합니다. 사용된 모델에 따라 더 빠른 출력을 제공할 수 있습니다. 손가락, 이빨 등의 세부사항을 더 잘 생성합니다.\u003c/p\u003e\n\u003cp\u003e이 모델의 부적합한 사용 사례: 모델을 불러오려면 상당한 VRAM이 필요합니다. 오픈 소스 커뮤니티의 광범위한 지원이 아직 확인되지 않았습니다.\u003c/p\u003e\n\u003ch1\u003e세밀하게 조정된 모델들\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e현재 Stable Cascade에 대해 Fein-tuned 모델은 매우 적습니다.\u003c/p\u003e\n\u003ch1\u003eStable Diffusion 3.0\u003c/h1\u003e\n\u003cp\u003e2024년 3월 발표된 Stable Diffusion 패밀리의 최신 버전인 Stable Diffusion 3.0입니다. 자세한 내용은 아직 부족하지만, 초기 결과로는 프롬프트 정렬 및 전체 이미지 품질에서 상당한 개선이 나타났습니다.\u003c/p\u003e\n\u003cp\u003e만약 Stable Diffusion 3이 출시되면 이 섹션을 업데이트하겠습니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-ComparingStableDiffusionModels"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>