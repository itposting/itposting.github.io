<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>BERT 미세 조정으로 텍스트 분류하는 방법 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-23-FinetuneBERTfortextclassification" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="BERT 미세 조정으로 텍스트 분류하는 방법 | itposting" data-gatsby-head="true"/><meta property="og:title" content="BERT 미세 조정으로 텍스트 분류하는 방법 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-FinetuneBERTfortextclassification_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-23-FinetuneBERTfortextclassification" data-gatsby-head="true"/><meta name="twitter:title" content="BERT 미세 조정으로 텍스트 분류하는 방법 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-FinetuneBERTfortextclassification_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 19:32" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">BERT 미세 조정으로 텍스트 분류하는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="BERT 미세 조정으로 텍스트 분류하는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">8<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-FinetuneBERTfortextclassification&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>섬세 조정은 대형 언어 모델이 사용자 지정 데이터에 적응하고 텍스트 분류와 같은 하향 작업을 잘 수행할 수 있도록 돕는 중요한 기술입니다.</p>
<p>본 문서는 섬세 조정의 기본에 초점을 맞추고, LORA, QLORA 등 다른 기술에 대해 깊게 다루지는 않습니다. 시작하는 가장 좋은 방법은 BERT로 실험을 해보는 것입니다.</p>
<p>주로 두 가지 방법으로 이 작업을 수행할 수 있습니다:</p>
<ul>
<li>허깅페이스 트레이너 API 사용: 사용하기 쉽지만 매우 사용자 정의가 어려움</li>
<li>PyTorch 사용: 트레이너보다 조금 어려우나 프로세스에 대한 더 많은 사용자 정의와 제어를 제공합니다</li>
</ul>
<div class="content-ad"></div>
<p>데이터셋</p>
<p>우리는 Hugging Face에서 제공하는 Yelp Reviews 데이터셋을 사용할 예정입니다. 이 데이터셋은 다음 두 열로 구성되어 있습니다:</p>
<ul>
<li>레이블: 1부터 5까지의 별표가 부여된 등급입니다.</li>
<li>텍스트: 리뷰 내용입니다.</li>
</ul>
<p>저희의 목표는 리뷰 텍스트로부터 별의 개수를 예측할 수 있는 모델을 훈련하는 것입니다.</p>
<div class="content-ad"></div>
<p>휍핑페이스 트레이너 API를 사용하여 파인튜닝하기</p>
<ul>
<li>모든 라이브러리를 설치하세요 :</li>
</ul>
<pre><code class="hljs language-js">!pip install --upgrade transformers datasets evaluate huggingface_hub torch
</code></pre>
<p>참고: 이 라이브러리들의 최신 버전을 항상 사용하도록 하세요.</p>
<div class="content-ad"></div>
<ol start="2">
<li>데이터셋 로드: Hugging Face에서 제공하는 datasets 라이브러리를 사용하여 데이터셋을 로드할 수 있어요.</li>
</ol>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
dataset = load_dataset(<span class="hljs-string">"yelp_review_full"</span>)
</code></pre>
<p>데이터셋을 확인해봐요. 어떤 데이터를 다루게 될지 알아봅시다.</p>
<pre><code class="hljs language-python">dataset[<span class="hljs-string">"train"</span>][<span class="hljs-number">1</span>]
</code></pre>
<div class="content-ad"></div>
<p>우리 데이터가 어떻게 보이는지 확인해보세요.</p>
<pre><code class="hljs language-js">{<span class="hljs-string">'label'</span>: <span class="hljs-number">1</span>,
 <span class="hljs-string">'text'</span>: <span class="hljs-string">"안타깝게도 Dr. 골트버그의 환자로서 느끼는 좌절은 뉴욕의 다른 많은 의사들과 겪어온 경험의 반복입니다 - 좋은 의사, 하지만 최악의 스태프. 그의 스텝은 단순히 전화를 받지 않는 것 같습니다. 답변을 받으려면 보통 반복적인 전화로 2시간이 걸립니다. 누가 그런 시간을 가진 사람이며 누가 그것과 소통하길 원하겠습니까? 다른 많은 의사들과도 이 문제를 겪어왔고, 이해가 안 가네요. 사무원이 있고 의료 필요가 있는 환자가 있는데, 왜 전화를 받는 사람이 없는 건지요? 이해할 수 없고, 신경질만 나게 합니다. Dr. 골트버그에게 2점을 주어야 하는 점이 유감입니다."</span>}
</code></pre>
<ol start="3">
<li>토크나이저를 로드하고 텍스트를 토큰화하는 함수를 만들어보세요:</li>
</ol>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> <span class="hljs-title class_">AutoTokenizer</span>

tokenizer = <span class="hljs-title class_">AutoTokenizer</span>.<span class="hljs-title function_">from_pretrained</span>(<span class="hljs-string">"google-bert/bert-base-cased"</span>)


def <span class="hljs-title function_">tokenize_function</span>(examples):
    <span class="hljs-keyword">return</span> <span class="hljs-title function_">tokenizer</span>(examples[<span class="hljs-string">"text"</span>], padding=<span class="hljs-string">"max_length"</span>, truncation=<span class="hljs-title class_">True</span>)


tokenized_datasets = dataset.<span class="hljs-title function_">map</span>(tokenize_function, batched=<span class="hljs-title class_">True</span>)
</code></pre>
<div class="content-ad"></div>
<p>토크나이저는 텍스트를 입력_ids, 토큰_유형_ids 및 어텐션_마스크로 이해할 수 있는 세 개의 열로 변환합니다.</p>
<p>데이터셋에서 작은 배치를 만들기(선택 사항)</p>
<pre><code class="hljs language-js">small_train_dataset = tokenized_datasets[<span class="hljs-string">"train"</span>].<span class="hljs-title function_">shuffle</span>(seed=<span class="hljs-number">42</span>).<span class="hljs-title function_">select</span>(<span class="hljs-title function_">range</span>(<span class="hljs-number">1000</span>))
small_eval_dataset = tokenized_datasets[<span class="hljs-string">"test"</span>].<span class="hljs-title function_">shuffle</span>(seed=<span class="hljs-number">42</span>).<span class="hljs-title function_">select</span>(<span class="hljs-title function_">range</span>(<span class="hljs-number">1000</span>))
</code></pre>
<ol start="4">
<li>모델 불러오기:</li>
</ol>
<div class="content-ad"></div>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">"google-bert/bert-base-cased"</span>, num_labels=<span class="hljs-number">5</span>)
</code></pre>
<p>분류할 레이블 수를 초기화하려면 num_labels 매개변수를 사용하세요.</p>
<ol start="5">
<li>훈련 인수 초기화</li>
</ol>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

training_args = TrainingArguments(output_dir=<span class="hljs-string">"test_trainer"</span>)
</code></pre>
<div class="content-ad"></div>
<p><a href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments%EC%97%90%EC%84%9C" rel="nofollow" target="_blank">https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments에서</a> 제공되는 매개변수에 대한 자세한 정보를 확인할 수 있습니다.</p>
<ol start="6">
<li>메트릭 계산 함수 설정:</li>
</ol>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> evaluate

metric = evaluate.<span class="hljs-title function_">load</span>(<span class="hljs-string">"accuracy"</span>)
def <span class="hljs-title function_">compute_metrics</span>(eval_pred):
    logits, labels = eval_pred
    predictions = np.<span class="hljs-title function_">argmax</span>(logits, axis=-<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> metric.<span class="hljs-title function_">compute</span>(predictions=predictions, references=labels)
</code></pre>
<ol start="7">
<li>학습 시작:</li>
</ol>
<div class="content-ad"></div>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> <span class="hljs-title class_">Trainer</span>
trainer = <span class="hljs-title class_">Trainer</span>(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
)
trainer.<span class="hljs-title function_">train</span>()
</code></pre>
<p>트레이닝을 시작하려면 wandb 키를 입력하라는 프롬프트가 나타납니다. 키를 입력하면 트레이닝 프로세스가 시작됩니다. 트레이닝이 완료되면 아래와 같은 결과를 보게 될 것입니다.</p>
<p><img src="/assets/img/2024-06-23-FinetuneBERTfortextclassification_0.png" alt="트레이닝 결과"></p>
<p>선택적으로 노트북에서 허깅페이스로 모델을 저장할 수도 있습니다.</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> login
<span class="hljs-title function_">login</span>()
model.<span class="hljs-title function_">push_to_hub</span>(<span class="hljs-string">"HuggingfaceUsername/yourModelName"</span>)
</code></pre>
<ol start="8">
<li>추론 실행:</li>
</ol>
<p>모델을 테스트하려면 PyTorch를 사용할 수 있습니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.<span class="hljs-property">nn</span>.<span class="hljs-property">functional</span> <span class="hljs-keyword">as</span> F
# <span class="hljs-title class_">Load</span> model directly
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> <span class="hljs-title class_">AutoTokenizer</span>, <span class="hljs-title class_">AutoModelForSequenceClassification</span>

tokenizer = <span class="hljs-title class_">AutoTokenizer</span>.<span class="hljs-title function_">from_pretrained</span>(<span class="hljs-string">"google-bert/bert-base-cased"</span>)
model = <span class="hljs-title class_">AutoModelForSequenceClassification</span>.<span class="hljs-title function_">from_pretrained</span>(<span class="hljs-string">"HuggingfaceUsername/yourModelName"</span>)
s=<span class="hljs-string">"The was awesome and I loved it"</span>
tt=<span class="hljs-title function_">tokenizer</span>(s,return_tensors=<span class="hljs-string">"pt"</span>, padding=<span class="hljs-title class_">True</span>, truncation=<span class="hljs-title class_">True</span>)
</code></pre>
<div class="content-ad"></div>
<p>모델을 평가 모드로 설정하면 더 이상 가중치를 업데이트할 필요가 없어지고, 이제 분류 작업에 사용할 수 있습니다.</p>
<pre><code class="hljs language-python">model.<span class="hljs-built_in">eval</span>()
<span class="hljs-keyword">with</span> torch.no_grad():
    outputs = model(**tt)
</code></pre>
<p>결과를 확인해보겠습니다.</p>
<pre><code class="hljs language-python">SequenceClassifierOutput(loss=<span class="hljs-literal">None</span>, logits=tensor([[-<span class="hljs-number">2.3995</span>, -<span class="hljs-number">2.0111</span>, -<span class="hljs-number">0.8381</span>,  <span class="hljs-number">2.4683</span>,  <span class="hljs-number">2.8968</span>]]), hidden_states=<span class="hljs-literal">None</span>, attentions=<span class="hljs-literal">None</span>)
</code></pre>
<div class="content-ad"></div>
<p>여기서 중요한 변수는 로짓 변수입니다. 이 경우 로짓은 텍스트가 특정 클래스에 속할 확률을 나타냅니다. 현재 로짓은 이해하기 어려운 형식으로 표시됩니다. 이를 이해할 수 있는 형식으로 변환하려면 이해할 수 있는 숫자로 변환해야 합니다.</p>
<pre><code class="hljs language-js">logits = outputs.<span class="hljs-property">logits</span>
<span class="hljs-title function_">print</span>(<span class="hljs-string">"로짓:"</span>, logits)

# 소프트맥스를 사용하여 로짓을 확률로 변환합니다
probabilities = F.<span class="hljs-title function_">softmax</span>(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-title function_">print</span>(<span class="hljs-string">"확률:"</span>, probabilities)

# 예측된 클래스를 결정합니다
predicted_class = torch.<span class="hljs-title function_">argmax</span>(probabilities, dim=-<span class="hljs-number">1</span>)
<span class="hljs-title function_">print</span>(<span class="hljs-string">"예측된 클래스:"</span>, predicted_class.<span class="hljs-title function_">item</span>())
</code></pre>
<p>여기서 출력은 4입니다.</p>
<p>PyTorch를 사용한 파인 튜닝</p>
<div class="content-ad"></div>
<p>모델이 이해할 수 있도록 몇 가지 전처리 단계가 필요합니다.</p>
<ul>
<li>열 삭제</li>
</ul>
<pre><code class="hljs language-js">tokenized_datasets = tokenized_datasets.<span class="hljs-title function_">remove_columns</span>([<span class="hljs-string">"text"</span>])
tokenized_datasets = tokenized_datasets.<span class="hljs-title function_">rename_column</span>(<span class="hljs-string">"label"</span>, <span class="hljs-string">"labels"</span>)
tokenized_datasets.<span class="hljs-title function_">set_format</span>(<span class="hljs-string">"torch"</span>)
small_train_dataset = tokenized_datasets[<span class="hljs-string">"train"</span>].<span class="hljs-title function_">shuffle</span>(seed=<span class="hljs-number">42</span>).<span class="hljs-title function_">select</span>(<span class="hljs-title function_">range</span>(<span class="hljs-number">1000</span>))
small_eval_dataset = tokenized_datasets[<span class="hljs-string">"test"</span>].<span class="hljs-title function_">shuffle</span>(seed=<span class="hljs-number">42</span>).<span class="hljs-title function_">select</span>(<span class="hljs-title function_">range</span>(<span class="hljs-number">1000</span>))
</code></pre>
<ol start="2">
<li>데이터로더(Dataloader) 생성</li>
</ol>
<div class="content-ad"></div>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.<span class="hljs-property">utils</span>.<span class="hljs-property">data</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">DataLoader</span>
traindataloader=<span class="hljs-title class_">DataLoader</span>(small_train_dataset,batch_size=<span class="hljs-number">8</span>,shuffle=<span class="hljs-title class_">True</span>)
testdataloader=<span class="hljs-title class_">DataLoader</span>(small_eval_dataset,batch_size=<span class="hljs-number">8</span>)
</code></pre>
<ol start="3">
<li>모델을 다운로드하고 GPU에 로드해주세요.</li>
</ol>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> <span class="hljs-title class_">AutoModelForSequenceClassification</span>
model=<span class="hljs-title class_">AutoModelForSequenceClassification</span>.<span class="hljs-title function_">from_pretrained</span>(<span class="hljs-string">"google-bert/bert-base-cased"</span>, num_labels=<span class="hljs-number">5</span>)
device = torch.<span class="hljs-title function_">device</span>(<span class="hljs-string">"cuda"</span>) <span class="hljs-keyword">if</span> torch.<span class="hljs-property">cuda</span>.<span class="hljs-title function_">is_available</span>() <span class="hljs-keyword">else</span> torch.<span class="hljs-title function_">device</span>(<span class="hljs-string">"cpu"</span>)
model.<span class="hljs-title function_">to</span>(device)
</code></pre>
<ol start="4">
<li>옵티마이저(optimizer)와 학습률 스케줄러(learning rate scheduler)를 생성하세요.</li>
</ol>
<div class="content-ad"></div>
<pre><code class="hljs language-python"><span class="hljs-keyword">from</span> torch.optim <span class="hljs-keyword">import</span> AdamW, SGD
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> get_scheduler
optimizer = SGD(model.parameters(), lr=<span class="hljs-number">5e-5</span>)
num_epochs = <span class="hljs-number">3</span>
num_training_steps = num_epochs * <span class="hljs-built_in">len</span>(traindataloader)
lr_scheduler = get_scheduler(
    name=<span class="hljs-string">"linear"</span>, optimizer=optimizer, num_warmup_steps=<span class="hljs-number">0</span>, num_training_steps=num_training_steps
)
</code></pre>
<p>원하는 옵티마이저와 학습률 스케줄러를 조정하여 가장 적합한 것을 선택할 수 있어요.</p>
<ol start="5">
<li>학습 및 평가</li>
</ol>
<p>모델을 model.train()을 사용하여 학습 모드로 설정해주세요.</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> tqdm.<span class="hljs-property">auto</span> <span class="hljs-keyword">import</span> tqdm

progress_bar = <span class="hljs-title function_">tqdm</span>(<span class="hljs-title function_">range</span>(num_training_steps))

model.<span class="hljs-title function_">train</span>()
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-title function_">range</span>(num_epochs):
    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> <span class="hljs-attr">traindataloader</span>:
        batch = {<span class="hljs-attr">k</span>: v.<span class="hljs-title function_">to</span>(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.<span class="hljs-title function_">items</span>()}
        outputs = <span class="hljs-title function_">model</span>(**batch)
        loss = outputs.<span class="hljs-property">loss</span>
        loss.<span class="hljs-title function_">backward</span>()

        optimizer.<span class="hljs-title function_">step</span>()
        lr_scheduler.<span class="hljs-title function_">step</span>()
        optimizer.<span class="hljs-title function_">zero_grad</span>()
        progress_bar.<span class="hljs-title function_">update</span>(<span class="hljs-number">1</span>)
</code></pre>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> evaluate

metric = evaluate.<span class="hljs-title function_">load</span>(<span class="hljs-string">"accuracy"</span>)
model.<span class="hljs-built_in">eval</span>()
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> <span class="hljs-attr">testdataloader</span>:
    b = {<span class="hljs-attr">k</span>: v.<span class="hljs-title function_">to</span>(device) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.<span class="hljs-title function_">items</span>()}
    <span class="hljs-keyword">with</span> torch.<span class="hljs-title function_">no_grad</span>():
        outputs = <span class="hljs-title function_">model</span>(**b)

    logits = outputs.<span class="hljs-property">logits</span>
    predictions = torch.<span class="hljs-title function_">argmax</span>(logits, dim=-<span class="hljs-number">1</span>)
    metric.<span class="hljs-title function_">add_batch</span>(predictions=predictions, references=batch[<span class="hljs-string">"labels"</span>])

metric.<span class="hljs-title function_">compute</span>()
</code></pre>
<p>제 Kaggle 노트북에서 스크립트를 확인할 수 있습니다. <a href="https://www.kaggle.com/code/exterminator11/finetune-bert" rel="nofollow" target="_blank">https://www.kaggle.com/code/exterminator11/finetune-bert</a>. 행운을 빕니다!</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"BERT 미세 조정으로 텍스트 분류하는 방법","description":"","date":"2024-06-23 19:32","slug":"2024-06-23-FinetuneBERTfortextclassification","content":"\n\n섬세 조정은 대형 언어 모델이 사용자 지정 데이터에 적응하고 텍스트 분류와 같은 하향 작업을 잘 수행할 수 있도록 돕는 중요한 기술입니다.\n\n본 문서는 섬세 조정의 기본에 초점을 맞추고, LORA, QLORA 등 다른 기술에 대해 깊게 다루지는 않습니다. 시작하는 가장 좋은 방법은 BERT로 실험을 해보는 것입니다.\n\n주로 두 가지 방법으로 이 작업을 수행할 수 있습니다:\n\n- 허깅페이스 트레이너 API 사용: 사용하기 쉽지만 매우 사용자 정의가 어려움\n- PyTorch 사용: 트레이너보다 조금 어려우나 프로세스에 대한 더 많은 사용자 정의와 제어를 제공합니다\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터셋\n\n우리는 Hugging Face에서 제공하는 Yelp Reviews 데이터셋을 사용할 예정입니다. 이 데이터셋은 다음 두 열로 구성되어 있습니다:\n\n- 레이블: 1부터 5까지의 별표가 부여된 등급입니다.\n- 텍스트: 리뷰 내용입니다.\n\n저희의 목표는 리뷰 텍스트로부터 별의 개수를 예측할 수 있는 모델을 훈련하는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n휍핑페이스 트레이너 API를 사용하여 파인튜닝하기\n\n- 모든 라이브러리를 설치하세요 :\n\n```js\n!pip install --upgrade transformers datasets evaluate huggingface_hub torch\n```\n\n참고: 이 라이브러리들의 최신 버전을 항상 사용하도록 하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. 데이터셋 로드: Hugging Face에서 제공하는 datasets 라이브러리를 사용하여 데이터셋을 로드할 수 있어요.\n\n```python\nfrom datasets import load_dataset\ndataset = load_dataset(\"yelp_review_full\")\n```\n\n데이터셋을 확인해봐요. 어떤 데이터를 다루게 될지 알아봅시다.\n\n```python\ndataset[\"train\"][1]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 데이터가 어떻게 보이는지 확인해보세요.\n\n```js\n{'label': 1,\n 'text': \"안타깝게도 Dr. 골트버그의 환자로서 느끼는 좌절은 뉴욕의 다른 많은 의사들과 겪어온 경험의 반복입니다 - 좋은 의사, 하지만 최악의 스태프. 그의 스텝은 단순히 전화를 받지 않는 것 같습니다. 답변을 받으려면 보통 반복적인 전화로 2시간이 걸립니다. 누가 그런 시간을 가진 사람이며 누가 그것과 소통하길 원하겠습니까? 다른 많은 의사들과도 이 문제를 겪어왔고, 이해가 안 가네요. 사무원이 있고 의료 필요가 있는 환자가 있는데, 왜 전화를 받는 사람이 없는 건지요? 이해할 수 없고, 신경질만 나게 합니다. Dr. 골트버그에게 2점을 주어야 하는 점이 유감입니다.\"}\n```\n\n3. 토크나이저를 로드하고 텍스트를 토큰화하는 함수를 만들어보세요:\n\n```js\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토크나이저는 텍스트를 입력_ids, 토큰_유형_ids 및 어텐션_마스크로 이해할 수 있는 세 개의 열로 변환합니다.\n\n데이터셋에서 작은 배치를 만들기(선택 사항)\n\n```js\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n```\n\n4. 모델 불러오기:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)\n```\n\n분류할 레이블 수를 초기화하려면 num_labels 매개변수를 사용하세요.\n\n5. 훈련 인수 초기화\n\n```python\nfrom transformers import TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\"test_trainer\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttps://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments에서 제공되는 매개변수에 대한 자세한 정보를 확인할 수 있습니다.\n\n6. 메트릭 계산 함수 설정:\n\n```js\nimport numpy as np\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n```\n\n7. 학습 시작:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom transformers import Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\ntrainer.train()\n```\n\n트레이닝을 시작하려면 wandb 키를 입력하라는 프롬프트가 나타납니다. 키를 입력하면 트레이닝 프로세스가 시작됩니다. 트레이닝이 완료되면 아래와 같은 결과를 보게 될 것입니다.\n\n![트레이닝 결과](/assets/img/2024-06-23-FinetuneBERTfortextclassification_0.png)\n\n선택적으로 노트북에서 허깅페이스로 모델을 저장할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nfrom huggingface_hub import login\nlogin()\nmodel.push_to_hub(\"HuggingfaceUsername/yourModelName\")\n```\n\n8. 추론 실행:\n\n모델을 테스트하려면 PyTorch를 사용할 수 있습니다.\n\n```js\nimport torch\nimport torch.nn.functional as F\n# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"HuggingfaceUsername/yourModelName\")\ns=\"The was awesome and I loved it\"\ntt=tokenizer(s,return_tensors=\"pt\", padding=True, truncation=True)\n```\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델을 평가 모드로 설정하면 더 이상 가중치를 업데이트할 필요가 없어지고, 이제 분류 작업에 사용할 수 있습니다.\n\n```python\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(**tt)\n```\n\n결과를 확인해보겠습니다.\n\n```python\nSequenceClassifierOutput(loss=None, logits=tensor([[-2.3995, -2.0111, -0.8381,  2.4683,  2.8968]]), hidden_states=None, attentions=None)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 중요한 변수는 로짓 변수입니다. 이 경우 로짓은 텍스트가 특정 클래스에 속할 확률을 나타냅니다. 현재 로짓은 이해하기 어려운 형식으로 표시됩니다. 이를 이해할 수 있는 형식으로 변환하려면 이해할 수 있는 숫자로 변환해야 합니다.\n\n```js\nlogits = outputs.logits\nprint(\"로짓:\", logits)\n\n# 소프트맥스를 사용하여 로짓을 확률로 변환합니다\nprobabilities = F.softmax(logits, dim=-1)\nprint(\"확률:\", probabilities)\n\n# 예측된 클래스를 결정합니다\npredicted_class = torch.argmax(probabilities, dim=-1)\nprint(\"예측된 클래스:\", predicted_class.item())\n```\n\n여기서 출력은 4입니다.\n\nPyTorch를 사용한 파인 튜닝\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델이 이해할 수 있도록 몇 가지 전처리 단계가 필요합니다.\n\n- 열 삭제\n\n```js\ntokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\ntokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\ntokenized_datasets.set_format(\"torch\")\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\nsmall_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))\n```\n\n2. 데이터로더(Dataloader) 생성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport torch\nfrom torch.utils.data import DataLoader\ntraindataloader=DataLoader(small_train_dataset,batch_size=8,shuffle=True)\ntestdataloader=DataLoader(small_eval_dataset,batch_size=8)\n```\n\n3. 모델을 다운로드하고 GPU에 로드해주세요.\n\n```js\nfrom transformers import AutoModelForSequenceClassification\nmodel=AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n```\n\n4. 옵티마이저(optimizer)와 학습률 스케줄러(learning rate scheduler)를 생성하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom torch.optim import AdamW, SGD\nfrom transformers import get_scheduler\noptimizer = SGD(model.parameters(), lr=5e-5)\nnum_epochs = 3\nnum_training_steps = num_epochs * len(traindataloader)\nlr_scheduler = get_scheduler(\n    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n)\n```\n\n원하는 옵티마이저와 학습률 스케줄러를 조정하여 가장 적합한 것을 선택할 수 있어요.\n\n5. 학습 및 평가\n\n모델을 model.train()을 사용하여 학습 모드로 설정해주세요.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom tqdm.auto import tqdm\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in traindataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n```\n\n```js\nimport evaluate\n\nmetric = evaluate.load(\"accuracy\")\nmodel.eval()\nfor batch in testdataloader:\n    b = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**b)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\nmetric.compute()\n```\n\n제 Kaggle 노트북에서 스크립트를 확인할 수 있습니다. https://www.kaggle.com/code/exterminator11/finetune-bert. 행운을 빕니다!","ogImage":{"url":"/assets/img/2024-06-23-FinetuneBERTfortextclassification_0.png"},"coverImage":"/assets/img/2024-06-23-FinetuneBERTfortextclassification_0.png","tag":["Tech"],"readingTime":8},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e섬세 조정은 대형 언어 모델이 사용자 지정 데이터에 적응하고 텍스트 분류와 같은 하향 작업을 잘 수행할 수 있도록 돕는 중요한 기술입니다.\u003c/p\u003e\n\u003cp\u003e본 문서는 섬세 조정의 기본에 초점을 맞추고, LORA, QLORA 등 다른 기술에 대해 깊게 다루지는 않습니다. 시작하는 가장 좋은 방법은 BERT로 실험을 해보는 것입니다.\u003c/p\u003e\n\u003cp\u003e주로 두 가지 방법으로 이 작업을 수행할 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e허깅페이스 트레이너 API 사용: 사용하기 쉽지만 매우 사용자 정의가 어려움\u003c/li\u003e\n\u003cli\u003ePyTorch 사용: 트레이너보다 조금 어려우나 프로세스에 대한 더 많은 사용자 정의와 제어를 제공합니다\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e데이터셋\u003c/p\u003e\n\u003cp\u003e우리는 Hugging Face에서 제공하는 Yelp Reviews 데이터셋을 사용할 예정입니다. 이 데이터셋은 다음 두 열로 구성되어 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e레이블: 1부터 5까지의 별표가 부여된 등급입니다.\u003c/li\u003e\n\u003cli\u003e텍스트: 리뷰 내용입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e저희의 목표는 리뷰 텍스트로부터 별의 개수를 예측할 수 있는 모델을 훈련하는 것입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e휍핑페이스 트레이너 API를 사용하여 파인튜닝하기\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e모든 라이브러리를 설치하세요 :\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e!pip install --upgrade transformers datasets evaluate huggingface_hub torch\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e참고: 이 라이브러리들의 최신 버전을 항상 사용하도록 하세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e데이터셋 로드: Hugging Face에서 제공하는 datasets 라이브러리를 사용하여 데이터셋을 로드할 수 있어요.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e datasets \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e load_dataset\ndataset = load_dataset(\u003cspan class=\"hljs-string\"\u003e\"yelp_review_full\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e데이터셋을 확인해봐요. 어떤 데이터를 다루게 될지 알아봅시다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003edataset[\u003cspan class=\"hljs-string\"\u003e\"train\"\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e우리 데이터가 어떻게 보이는지 확인해보세요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e{\u003cspan class=\"hljs-string\"\u003e'label'\u003c/span\u003e: \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e,\n \u003cspan class=\"hljs-string\"\u003e'text'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"안타깝게도 Dr. 골트버그의 환자로서 느끼는 좌절은 뉴욕의 다른 많은 의사들과 겪어온 경험의 반복입니다 - 좋은 의사, 하지만 최악의 스태프. 그의 스텝은 단순히 전화를 받지 않는 것 같습니다. 답변을 받으려면 보통 반복적인 전화로 2시간이 걸립니다. 누가 그런 시간을 가진 사람이며 누가 그것과 소통하길 원하겠습니까? 다른 많은 의사들과도 이 문제를 겪어왔고, 이해가 안 가네요. 사무원이 있고 의료 필요가 있는 환자가 있는데, 왜 전화를 받는 사람이 없는 건지요? 이해할 수 없고, 신경질만 나게 합니다. Dr. 골트버그에게 2점을 주어야 하는 점이 유감입니다.\"\u003c/span\u003e}\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e토크나이저를 로드하고 텍스트를 토큰화하는 함수를 만들어보세요:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eAutoTokenizer\u003c/span\u003e\n\ntokenizer = \u003cspan class=\"hljs-title class_\"\u003eAutoTokenizer\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_pretrained\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"google-bert/bert-base-cased\"\u003c/span\u003e)\n\n\ndef \u003cspan class=\"hljs-title function_\"\u003etokenize_function\u003c/span\u003e(examples):\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003etokenizer\u003c/span\u003e(examples[\u003cspan class=\"hljs-string\"\u003e\"text\"\u003c/span\u003e], padding=\u003cspan class=\"hljs-string\"\u003e\"max_length\"\u003c/span\u003e, truncation=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\n\n\ntokenized_datasets = dataset.\u003cspan class=\"hljs-title function_\"\u003emap\u003c/span\u003e(tokenize_function, batched=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e토크나이저는 텍스트를 입력_ids, 토큰_유형_ids 및 어텐션_마스크로 이해할 수 있는 세 개의 열로 변환합니다.\u003c/p\u003e\n\u003cp\u003e데이터셋에서 작은 배치를 만들기(선택 사항)\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003esmall_train_dataset = tokenized_datasets[\u003cspan class=\"hljs-string\"\u003e\"train\"\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eshuffle\u003c/span\u003e(seed=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003eselect\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e))\nsmall_eval_dataset = tokenized_datasets[\u003cspan class=\"hljs-string\"\u003e\"test\"\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eshuffle\u003c/span\u003e(seed=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003eselect\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e모델 불러오기:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\u003cspan class=\"hljs-string\"\u003e\"google-bert/bert-base-cased\"\u003c/span\u003e, num_labels=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e분류할 레이블 수를 초기화하려면 num_labels 매개변수를 사용하세요.\u003c/p\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003e훈련 인수 초기화\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e TrainingArguments\n\ntraining_args = TrainingArguments(output_dir=\u003cspan class=\"hljs-string\"\u003e\"test_trainer\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003ca href=\"https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments%EC%97%90%EC%84%9C\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments에서\u003c/a\u003e 제공되는 매개변수에 대한 자세한 정보를 확인할 수 있습니다.\u003c/p\u003e\n\u003col start=\"6\"\u003e\n\u003cli\u003e메트릭 계산 함수 설정:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e numpy \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e np\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e evaluate\n\nmetric = evaluate.\u003cspan class=\"hljs-title function_\"\u003eload\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"accuracy\"\u003c/span\u003e)\ndef \u003cspan class=\"hljs-title function_\"\u003ecompute_metrics\u003c/span\u003e(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.\u003cspan class=\"hljs-title function_\"\u003eargmax\u003c/span\u003e(logits, axis=-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e metric.\u003cspan class=\"hljs-title function_\"\u003ecompute\u003c/span\u003e(predictions=predictions, references=labels)\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"7\"\u003e\n\u003cli\u003e학습 시작:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eTrainer\u003c/span\u003e\ntrainer = \u003cspan class=\"hljs-title class_\"\u003eTrainer\u003c/span\u003e(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    eval_dataset=small_eval_dataset,\n    compute_metrics=compute_metrics,\n)\ntrainer.\u003cspan class=\"hljs-title function_\"\u003etrain\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e트레이닝을 시작하려면 wandb 키를 입력하라는 프롬프트가 나타납니다. 키를 입력하면 트레이닝 프로세스가 시작됩니다. 트레이닝이 완료되면 아래와 같은 결과를 보게 될 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-FinetuneBERTfortextclassification_0.png\" alt=\"트레이닝 결과\"\u003e\u003c/p\u003e\n\u003cp\u003e선택적으로 노트북에서 허깅페이스로 모델을 저장할 수도 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e huggingface_hub \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e login\n\u003cspan class=\"hljs-title function_\"\u003elogin\u003c/span\u003e()\nmodel.\u003cspan class=\"hljs-title function_\"\u003epush_to_hub\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"HuggingfaceUsername/yourModelName\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"8\"\u003e\n\u003cli\u003e추론 실행:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e모델을 테스트하려면 PyTorch를 사용할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch.\u003cspan class=\"hljs-property\"\u003enn\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003efunctional\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e F\n# \u003cspan class=\"hljs-title class_\"\u003eLoad\u003c/span\u003e model directly\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eAutoTokenizer\u003c/span\u003e, \u003cspan class=\"hljs-title class_\"\u003eAutoModelForSequenceClassification\u003c/span\u003e\n\ntokenizer = \u003cspan class=\"hljs-title class_\"\u003eAutoTokenizer\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_pretrained\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"google-bert/bert-base-cased\"\u003c/span\u003e)\nmodel = \u003cspan class=\"hljs-title class_\"\u003eAutoModelForSequenceClassification\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_pretrained\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"HuggingfaceUsername/yourModelName\"\u003c/span\u003e)\ns=\u003cspan class=\"hljs-string\"\u003e\"The was awesome and I loved it\"\u003c/span\u003e\ntt=\u003cspan class=\"hljs-title function_\"\u003etokenizer\u003c/span\u003e(s,return_tensors=\u003cspan class=\"hljs-string\"\u003e\"pt\"\u003c/span\u003e, padding=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, truncation=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모델을 평가 모드로 설정하면 더 이상 가중치를 업데이트할 필요가 없어지고, 이제 분류 작업에 사용할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003emodel.\u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e()\n\u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e torch.no_grad():\n    outputs = model(**tt)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e결과를 확인해보겠습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eSequenceClassifierOutput(loss=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e, logits=tensor([[-\u003cspan class=\"hljs-number\"\u003e2.3995\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e2.0111\u003c/span\u003e, -\u003cspan class=\"hljs-number\"\u003e0.8381\u003c/span\u003e,  \u003cspan class=\"hljs-number\"\u003e2.4683\u003c/span\u003e,  \u003cspan class=\"hljs-number\"\u003e2.8968\u003c/span\u003e]]), hidden_states=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e, attentions=\u003cspan class=\"hljs-literal\"\u003eNone\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기서 중요한 변수는 로짓 변수입니다. 이 경우 로짓은 텍스트가 특정 클래스에 속할 확률을 나타냅니다. 현재 로짓은 이해하기 어려운 형식으로 표시됩니다. 이를 이해할 수 있는 형식으로 변환하려면 이해할 수 있는 숫자로 변환해야 합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003elogits = outputs.\u003cspan class=\"hljs-property\"\u003elogits\u003c/span\u003e\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"로짓:\"\u003c/span\u003e, logits)\n\n# 소프트맥스를 사용하여 로짓을 확률로 변환합니다\nprobabilities = F.\u003cspan class=\"hljs-title function_\"\u003esoftmax\u003c/span\u003e(logits, dim=-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"확률:\"\u003c/span\u003e, probabilities)\n\n# 예측된 클래스를 결정합니다\npredicted_class = torch.\u003cspan class=\"hljs-title function_\"\u003eargmax\u003c/span\u003e(probabilities, dim=-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"예측된 클래스:\"\u003c/span\u003e, predicted_class.\u003cspan class=\"hljs-title function_\"\u003eitem\u003c/span\u003e())\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e여기서 출력은 4입니다.\u003c/p\u003e\n\u003cp\u003ePyTorch를 사용한 파인 튜닝\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모델이 이해할 수 있도록 몇 가지 전처리 단계가 필요합니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e열 삭제\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003etokenized_datasets = tokenized_datasets.\u003cspan class=\"hljs-title function_\"\u003eremove_columns\u003c/span\u003e([\u003cspan class=\"hljs-string\"\u003e\"text\"\u003c/span\u003e])\ntokenized_datasets = tokenized_datasets.\u003cspan class=\"hljs-title function_\"\u003erename_column\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"label\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"labels\"\u003c/span\u003e)\ntokenized_datasets.\u003cspan class=\"hljs-title function_\"\u003eset_format\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"torch\"\u003c/span\u003e)\nsmall_train_dataset = tokenized_datasets[\u003cspan class=\"hljs-string\"\u003e\"train\"\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eshuffle\u003c/span\u003e(seed=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003eselect\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e))\nsmall_eval_dataset = tokenized_datasets[\u003cspan class=\"hljs-string\"\u003e\"test\"\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eshuffle\u003c/span\u003e(seed=\u003cspan class=\"hljs-number\"\u003e42\u003c/span\u003e).\u003cspan class=\"hljs-title function_\"\u003eselect\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e데이터로더(Dataloader) 생성\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.\u003cspan class=\"hljs-property\"\u003eutils\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003edata\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eDataLoader\u003c/span\u003e\ntraindataloader=\u003cspan class=\"hljs-title class_\"\u003eDataLoader\u003c/span\u003e(small_train_dataset,batch_size=\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e,shuffle=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\ntestdataloader=\u003cspan class=\"hljs-title class_\"\u003eDataLoader\u003c/span\u003e(small_eval_dataset,batch_size=\u003cspan class=\"hljs-number\"\u003e8\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e모델을 다운로드하고 GPU에 로드해주세요.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eAutoModelForSequenceClassification\u003c/span\u003e\nmodel=\u003cspan class=\"hljs-title class_\"\u003eAutoModelForSequenceClassification\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_pretrained\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"google-bert/bert-base-cased\"\u003c/span\u003e, num_labels=\u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e)\ndevice = torch.\u003cspan class=\"hljs-title function_\"\u003edevice\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"cuda\"\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e torch.\u003cspan class=\"hljs-property\"\u003ecuda\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eis_available\u003c/span\u003e() \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e torch.\u003cspan class=\"hljs-title function_\"\u003edevice\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"cpu\"\u003c/span\u003e)\nmodel.\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(device)\n\u003c/code\u003e\u003c/pre\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e옵티마이저(optimizer)와 학습률 스케줄러(learning rate scheduler)를 생성하세요.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e torch.optim \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e AdamW, SGD\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e get_scheduler\noptimizer = SGD(model.parameters(), lr=\u003cspan class=\"hljs-number\"\u003e5e-5\u003c/span\u003e)\nnum_epochs = \u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e\nnum_training_steps = num_epochs * \u003cspan class=\"hljs-built_in\"\u003elen\u003c/span\u003e(traindataloader)\nlr_scheduler = get_scheduler(\n    name=\u003cspan class=\"hljs-string\"\u003e\"linear\"\u003c/span\u003e, optimizer=optimizer, num_warmup_steps=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e, num_training_steps=num_training_steps\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e원하는 옵티마이저와 학습률 스케줄러를 조정하여 가장 적합한 것을 선택할 수 있어요.\u003c/p\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003e학습 및 평가\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e모델을 model.train()을 사용하여 학습 모드로 설정해주세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e tqdm.\u003cspan class=\"hljs-property\"\u003eauto\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e tqdm\n\nprogress_bar = \u003cspan class=\"hljs-title function_\"\u003etqdm\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(num_training_steps))\n\nmodel.\u003cspan class=\"hljs-title function_\"\u003etrain\u003c/span\u003e()\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e epoch \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003erange\u003c/span\u003e(num_epochs):\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e batch \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etraindataloader\u003c/span\u003e:\n        batch = {\u003cspan class=\"hljs-attr\"\u003ek\u003c/span\u003e: v.\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(device) \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e k, v \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e batch.\u003cspan class=\"hljs-title function_\"\u003eitems\u003c/span\u003e()}\n        outputs = \u003cspan class=\"hljs-title function_\"\u003emodel\u003c/span\u003e(**batch)\n        loss = outputs.\u003cspan class=\"hljs-property\"\u003eloss\u003c/span\u003e\n        loss.\u003cspan class=\"hljs-title function_\"\u003ebackward\u003c/span\u003e()\n\n        optimizer.\u003cspan class=\"hljs-title function_\"\u003estep\u003c/span\u003e()\n        lr_scheduler.\u003cspan class=\"hljs-title function_\"\u003estep\u003c/span\u003e()\n        optimizer.\u003cspan class=\"hljs-title function_\"\u003ezero_grad\u003c/span\u003e()\n        progress_bar.\u003cspan class=\"hljs-title function_\"\u003eupdate\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e evaluate\n\nmetric = evaluate.\u003cspan class=\"hljs-title function_\"\u003eload\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"accuracy\"\u003c/span\u003e)\nmodel.\u003cspan class=\"hljs-built_in\"\u003eeval\u003c/span\u003e()\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e batch \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003etestdataloader\u003c/span\u003e:\n    b = {\u003cspan class=\"hljs-attr\"\u003ek\u003c/span\u003e: v.\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(device) \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e k, v \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e batch.\u003cspan class=\"hljs-title function_\"\u003eitems\u003c/span\u003e()}\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e torch.\u003cspan class=\"hljs-title function_\"\u003eno_grad\u003c/span\u003e():\n        outputs = \u003cspan class=\"hljs-title function_\"\u003emodel\u003c/span\u003e(**b)\n\n    logits = outputs.\u003cspan class=\"hljs-property\"\u003elogits\u003c/span\u003e\n    predictions = torch.\u003cspan class=\"hljs-title function_\"\u003eargmax\u003c/span\u003e(logits, dim=-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n    metric.\u003cspan class=\"hljs-title function_\"\u003eadd_batch\u003c/span\u003e(predictions=predictions, references=batch[\u003cspan class=\"hljs-string\"\u003e\"labels\"\u003c/span\u003e])\n\nmetric.\u003cspan class=\"hljs-title function_\"\u003ecompute\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e제 Kaggle 노트북에서 스크립트를 확인할 수 있습니다. \u003ca href=\"https://www.kaggle.com/code/exterminator11/finetune-bert\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://www.kaggle.com/code/exterminator11/finetune-bert\u003c/a\u003e. 행운을 빕니다!\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-FinetuneBERTfortextclassification"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>