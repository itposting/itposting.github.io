<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>온라인 플랫폼에서 참여 예측을 위한 딥 러닝 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="온라인 플랫폼에서 참여 예측을 위한 딥 러닝 | itposting" data-gatsby-head="true"/><meta property="og:title" content="온라인 플랫폼에서 참여 예측을 위한 딥 러닝 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms" data-gatsby-head="true"/><meta name="twitter:title" content="온라인 플랫폼에서 참여 예측을 위한 딥 러닝 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 06:44" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">온라인 플랫폼에서 참여 예측을 위한 딥 러닝</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="온라인 플랫폼에서 참여 예측을 위한 딥 러닝" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">11<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png" alt="image"></p>
<h1>요약</h1>
<p>에딘버러 대학에서 MSc 논문의 일환으로, 저는 딥러닝 기술을 사용하여 준니버스의 사용자 참여를 예측했습니다. 준니버스는 비과학자들이 행성 탐사와 같은 특정 분야에 기여할 수 있는 온라인 시민 과학 플랫폼입니다. 준니버스는 100편 이상의 논문 발표에 기여했습니다. 실제 환경에서 시민 과학자들은 영국의 농업 유출물이 영국 강의 안전 한 한계를 초과하는 수위의 오염 증가를 입증했습니다.</p>
<p>이 문맥에서 참여는 이전 행동을 고려할 때 플랫폼의 미래 사용을 예측할 수 있는지 여부입니다. 이는 여러 형태로 나타날 수 있습니다, 예를 들면:</p>
<div class="content-ad"></div>
<ul>
<li>시간 기준 내에서 완료할 작업의 예상 수</li>
<li>현재 작업 세션에서 머무를 시간의 양</li>
</ul>
<p>우리는 섹션 정의에 초점을 맞추고 사용자가 10, 20 또는 30분 동안 계속 작업할지를 예측하기 위해 노력했습니다. 이는 사용자 작업 T를 작업 세션 W로 그룹화하여 계산되었습니다.</p>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_1.png" alt="이미지"></p>
<p>이 정의는 유연성과 Zooniverse, StackOverflow 및 Coursera에서의 이전 사용을 위해 사용됩니다.</p>
<div class="content-ad"></div>
<p>이 접근 방식의 주의 사항 중 하나는 생산적인 온라인 시스템의 한 속성인 플랫폼 시간만을 예측한다는 것입니다. 예를 들어, 올바른 기여를 하는 동기부여된 참여자들을 갖는 것은 고려되지 않습니다. 온라인 시스템에 참여하는 동기를 측정하는 것은 활발한 연구 분야입니다. 심리적 상태인 좌절감과 이해도와 같은 것들이 학습되어 맞춤형 교육 개입에 활용될 수 있는 잠재적인 작업이 있습니다.</p>
<h1>데이터 및 세션 버킷 알고리즘</h1>
<p>Zooniverse는 친철하게 2021년 10월 19일에서 2022년 8월 14일까지 시민 과학자들의 클릭스트림 데이터를 제공해 주었습니다. 이 데이터는 미국, 중국, 싱가포르 및 핀란드의 시민 과학자들을 다루었습니다.</p>
<p>원시 데이터 세트에는 다음과 같은 열이 포함되어 있습니다.</p>
<div class="content-ad"></div>























































<table><thead><tr><th>Column Name</th><th>Column Desc</th><th>Column Type</th></tr></thead><tbody><tr><td>id</td><td>클릭스트림 항목을 식별하는 고유 식별자</td><td>bigint</td></tr><tr><td>user_id</td><td>사용자를 식별하는 고유 식별자</td><td>bigint</td></tr><tr><td>project_id</td><td>프로젝트를 식별하는 고유 식별자</td><td>bigint</td></tr><tr><td>workflow_id</td><td>워크플로우를 식별하는 고유 식별자</td><td>bigint</td></tr><tr><td>subject_ids</td><td>고유한 작업 식별자</td><td>bigint</td></tr><tr><td>country</td><td>국가 이름</td><td>str</td></tr><tr><td>latitude</td><td>국가 위도</td><td>float</td></tr><tr><td>longitude</td><td>국가 경도</td><td>float</td></tr><tr><td>timestamp</td><td>클릭스트림 타임스탬프</td><td>bigint</td></tr></tbody></table>
<p>Zooniverse의 계층 구조에서 각 행은 다음 거래를 나타냅니다.</p>
<ul>
<li>사용자가 시스템에 로그인하고 참여할 프로젝트를 선택합니다.</li>
<li>프로젝트는 여러 워크플로우를 포함하며 태스크 그룹화를 수행합니다.</li>
<li>사용자는 프로젝트에 연관된 작업을 수행합니다. 작업에는 여러 주제가 포함될 수 있습니다 (하지만 대부분은 하나만 포함합니다).</li>
</ul>
<img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_2.png">
<div class="content-ad"></div>
<h1>특성 선택</h1>
<p>데이터에는 약 38,500,990개의 고유 이벤트가 포함되어 있습니다. 서로 다른 지역별 이벤트 분포는 다음과 같습니다:</p>

























<table><thead><tr><th>국가명</th><th>백분율</th></tr></thead><tbody><tr><td>핀란드</td><td>59.4</td></tr><tr><td>미국</td><td>25.5</td></tr><tr><td>싱가포르</td><td>10.8</td></tr><tr><td>중국</td><td>4.3</td></tr></tbody></table>
<p>위도와 경도는 국가 정보를 중복해서 나타내므로 제거되었습니다. 주제 ID 및 작업 ID도 제거되었는데, 이 정보의 세분화가 참여 패턴 학습에 기여하지 않았기 때문입니다.</p>
<div class="content-ad"></div>
<p>우리 연구에서는 이전 연구에서 강조된 주요 변수가 부족했습니다. 예를 들어, Semenov et al.은 로그인한 사용자들이 더 오랜 시간 동안 작업하고 작업 세션에 대해 더 높은 투자 수준을 나타내는 것으로 발견했습니다. 또한, Mao et al.은 투표 엔트로피가 감소하는 경우, 사용자가 목록에서 반복해서 동일한 옵션을 선택하는 것이 지루함과 참여하지 않음의 유용한 대리자로 작용할 수 있다고 밝혀냈습니다. 이러한 연구 결과는 사용자 참여도를 효과적으로 측정할 수 있는데 사용자 로그인 상태와 투표 패턴을 통해 이를 할 수 있음을 시사했으며, 이러한 측면들이 우리의 현재 분석에는 고려되지 않았습니다.</p>
<p>따라서 우리는 이러한 특성을 근사화하는 데 사용될 수 있는 다양한 속도에서 통계치를 계산해야 했습니다. 이에는 다음이 포함되었습니다:</p>
<ul>
<li>사용자 세션 수의 롤링 번호</li>
<li>현재 세션 내의 시간 및 이벤트 수</li>
<li>과거 세션 간의 평균 시간 및 이벤트 수</li>
<li>이전 세션에서 소비한 시간 및 이전 세션의 이벤트 수</li>
<li>마지막 이벤트로부터의 시간 차 및 과거 이벤트의 평균 시간 차</li>
</ul>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_3.png" alt="image"></p>
<div class="content-ad"></div>
<h1><strong>The Feature Long Tail</strong></h1>
<p>Zooniverse 및 Coursera, StackOverflow, Snap과 같은 다른 온라인 플랫폼의 분석 결과를 보면, 매우 소수의 사용자가 플랫폼 활동의 대부분을 지나치게 책임지는 거대한 권한 분포가 있다는 것을 알 수 있습니다. 이 현상은 소수의 고도로 활발한 사용자가 플랫폼 기여를 주도하고 대부분의 사용자는 비교적 활동이 적다는 것을 나타냅니다.</p>
<p>저희의 데이터는 권한 분포에 부합되어, 사용자의 25%만이 세 번 이상의 세션을 완료하였으며, 작업 세션의 68%는 30분 미만으로 지속되었습니다. 이 분포는 사용자 참여의 불균형을 강조하며, 소수의 고도로 활발한 사용자가 플랫폼에서의 활동을 지배하고 있음을 보여줍니다.</p>
<p>많은 사용자에게 시간 순서 채널은 중복될 수 있습니다. 사용자가 단 한 번의 세션만 완료하는 경우, 과거 세션 계산은 일정한 0으로 유지됩니다. 마찬가지로 세션 간 시간과 같은 채널의 경우, 사용자가 두 번의 세션만 완료하는 경우, 과거 세션 채널은 첫 번째 세션에 대해서는 0으로 일정하게 유지되거나 이전 세션 통계의 일정한 값이 될 것입니다. 이 중복성은 드물게 사용하는 사용자에게는 이러한 메트릭이 의미 있는 통찰력을 제공하지 않을 수 있으며, 참여를 효과적으로 평가하기 위해 대안적인 측정 방법이 필요할 수 있다는 것을 시사합니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_4.png" alt="image"></p>
<p>The feature space was designed to represent user information over various time intervals. Because many users only completed two sessions, a lot of data would be repeated for these users. Any model for predicting user behavior would need to be carefully interrogated to ensure it did not memorize these aspects of user behavior and project results that mimicked the most likely user, rather than the projection of users.</p>
<p>Therefore, it was important to design experiments that enabled differentiation between the small number of highly active users and the large population of inactive, short-term contributors.</p>
<h1>Experiments</h1>
<div class="content-ad"></div>
<p>실험 결과 다음 질문에 대한 대답을 제공했습니다. 사용자의 클릭 스트림에 기록된 항목이 주어졌을 때 사용자가 10, 20 또는 30분 동안 계속 작업을 할 것인가?</p>
<p>클릭 스트림의 각 행은 사용자가 지정된 시간대(10, 20 또는 30분) 동안 계속 작업할지 여부를 나타내는 레이블 yiy_iyi로 표시되었습니다. 데이터가 시계열을 따르고 사용자 행동이 이전 이력에 의존한다는 점을 감안하여, 클릭 스트림 F(X_i, Y_i)의 예측은 과거 정보를 포함하여 확장되었습니다. 따라서 예측 함수는 F(X_i, Y_i, | X_i-1, X_i-2, ..., X_0)가 되었습니다.</p>
<p>장기 단기 메모리(Long Short-Term Memory, LSTM) 네트워크는 과거와 현재 정보를 제어하고 가중시키도록 설계된 것으로 이러한 종류의 분석에 적합합니다. 이들은 다른 시계열 작업으로도 효과적으로 적용되어 왔으며, 활동 인식, 행동 인식 및 지진 예측과 같은 작업에 사용되었습니다.</p>
<p>사용자 세션 창을 통해 이러한 함수를 쌓는 과정에서, 모델이 세션 통계, 사용자 동작 변화 및 예상된 참여 사이의 관계를 학습할 수 있을 것으로 기대했습니다¹.</p>
<div class="content-ad"></div>
<p>다음 질문에 대답하려고 실험을 진행했습니다:</p>
<ul>
<li>단기 또는 장기 행동을 예측하는 것이 더 쉬운지 여부.</li>
<li>데이터 창 크기를 확장하면 참여 측정에 기여하는지 여부.</li>
</ul>
<p>또한 실험에서는 각 이벤트를 독립적으로 고려하는 대신 네트워크 아키텍처와 종속성을 포착하는 것이 모델 성능에 영향을 미치는지 확인하기 위해 RandomForest 분류에 대해 베이스라인을 설정했습니다.</p>
<p>사용자가 현재 세션에서 계속 작업하는지 여부는 이진적입니다. 따라서 RandomForest를 구성하고 LSTM 매개변수 최적화를 위해 유전 알고리즘과 경사 하강법을 적용할 수 있었고, 바이너리 크로스 엔트로피를 사용하여 꼭 맞추었습니다.</p>
<div class="content-ad"></div>
<p>일괄 처리된 N개의 관측치에 대한 손실 함수는 다음과 같습니다:</p>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_5.png" alt="Loss Function"></p>
<p>목표는 yi(실제 예측값)와 네트워크 출력인 y^i 사이의 거리를 최소화하는 것입니다.</p>
<h1>구현</h1>
<div class="content-ad"></div>
<p>데이터는 타임스탬프에 따라 정렬되고 훈련, 테스트 및 평가 파티션으로 분할되었습니다. 이미지 분류 실험과는 달리 시계열 관측 사이의 관계가 중요하기 때문에 데이터를 섞으면 시퀀스의 일관성이 깨질 수 있습니다. 따라서 데이터를 섞으면 훈련에 후속 관측사항이 포함될 수 있습니다. 예를 들어, 모델이 작업 세션이 10분만 계속된다는 정보를 받기 전에 작업 세션의 1분과 2분의 관측을 받는다면 결과적으로 선견지명을 얻을 수 있습니다.</p>
<p>장기 단기 메모리 (LSTM) 네트워크가 사용자 관측 윈도우의 길이 1, 10, 20, 30, 40에 대해 생성되고 훈련되었습니다. PyTorch Lightning을 사용하여 네트워크를 훈련했는데, 이를 통해 편리한 래퍼(wrapper)를 제공하여 훈련 루프 구현, 로깅 및 메트릭 처리를 감싸줍니다. 10, 20, 30분 동안의 지속을 예측하기 위한 별도의 실험이 수행되었습니다.</p>
<p>첫 번째의 출력이 두 번째로 전파되는 두 개의 LSTM 네트워크를 쌓는 것이 가장 성능이 좋았습니다. 두 번째 레이어는 선형 레이어를 따라, 기능을 하나의 대상 변수로 변환하여 사용자의 세션 지속 확률을 정의했습니다. 최종 선형 레이어 다음의 엔트로피에서 역전파가 계산되었고, 이를 통해 네트워크 전체의 가중치가 업데이트되었습니다.</p>
<div class="content-ad"></div>
<h1>결과</h1>
<p>실험을 통해 성과가 좋은 모델을 분석했습니다. 각 실험에 대한 정밀도, 재현율 및 AUC를 플롯했습니다. AUC는 분류 임계값 범위에서 실제 양성 비율(재현율)과 거짓 양성 비율(1-정밀도)을 집계합니다.</p>
<p>검증 및 테스트 데이터셋 간의 균형은 모델이 특정 시간 역학에 기반하지 않고 패턴을 학습하고 있다는 것을 나타냅니다. 따라서 참여 패턴이 크게 변하지 않는 한, 새로운 데이터에 적용될 때 모델의 동작을 예측할 수 있을 가능성이 높습니다.</p>
<p>결과는 장기적 예측에서 일반적으로 더 일관성있게 나타납니다. 정밀도는 검증 데이터셋에서 68%에서 70%로, 테스트 데이터셋에서 71%에서 74%로 범위가 확장됩니다. 모든 창에서 재현율은 57%에서 59%까지 범위가 확장됩니다.</p>
<div class="content-ad"></div>
<p>단기 행동을 예측하는 실험들은 데이터 윈도우의 크기에 민감합니다. 10분 동안의 실험에서, 검증 데이터셋의 정밀도는 64%에서 80%로 범위가 나타나며, 테스트 데이터셋의 경우 66%에서 89%까지 변동합니다. 재현율은 89%에서 30%까지 범위가 나타나며, 최적의 균형을 얻으려면 20개에서 30개의 이벤트 윈도우를 사용하는 것이 좋습니다.</p>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_7.png" alt="Image 7"></p>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_8.png" alt="Image 8"></p>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_9.png" alt="Image 9"></p>
<div class="content-ad"></div>
<p>모델의 다양한 행동 양상은 짧은, 중간, 그리고 장기적인 참여를 예측하는 것이 서로 다른 접근 방식이 필요한 다른 도전이라는 것을 보여줍니다. 더 높은 정밀도는 단기적으로 참여하는 사용자를 놓치지 않을 가능성을 보여줍니다. 그러나 장기간의 참여가 떨어질 것으로 예측하는 것은 더 어려운 과제입니다.</p>
<p>실제 상황에서 모델의 선택은 참여하지 않은 사용자를 놓치는 것을 우선시해야 하는지, 아니면 동기를 부여받은 사용자를 잘못 분류하는 것을 우선시해야 하는지를 고려해야 합니다.</p>
<p>30분 참여 예측과 데이터 창의 30개 이전 관측치를 사용한 우수한 모델/실험 구성이 우리의 최고의 성과를 냈습니다. 이 모델은 AUC 스코어가 0.748을 달성했습니다. 이는 Mao Et Al이 30분 예측에서 약 0.76을 달성한 것보다 약간 떨어지는 성과입니다. 이는 데이터의 분산 부족으로 인한 것으로 여겨집니다. 예를 들어, 첫 번째 사용자 세션에는 많은 동일한 변수들이 포함되어 있습니다. 이들은 다음을 포함합니다:</p>
<ul>
<li>누적 플랫폼 시간 및 누적 세션 시간.</li>
<li>플랫폼과 세션 전체 이벤트 수.</li>
<li>이전 세션 통계.</li>
</ul>
<div class="content-ad"></div>
<p><strong>사용자 세그먼트별 평가</strong></p>
<p>플랫폼에 작은 기여만 한 사용자를 고려해 역사적 정보를 포함시키면 많은 중복이 발생한다는 것을 알고 있습니다. 이는 대부분의 사용자들에 해당합니다.</p>
<p>다양한 세션 길이 별 성능을 이해하기 위해 사용자 작업 세션에서 지낸 누적 시간에 따른 정확도, 재현율 및 AUC를 검토합니다. 평가와 테스트 세션을 유사성으로 통합합니다. 정밀도와 재현율의 가장 큰 요인은 사용자가 작업 세션에서 얼마나 시간을 보내는지에 달려 있습니다. 데이터 창 크기에 관계 없이, 사용자가 작업 세션에서 60분을 보낸 후에는 모델의 효과가 극적으로 향상됩니다.</p>
<p><img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_10.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>기존 온라인 플랫폼 연구와 일관성 있는 결과를 보여주었으며, 최소한의 히스토리로 사용자에 대한 추론의 어려움을 보여줍니다. 이는 사용자 행동에 대한 우리 이전 분석을 뒷받침합니다.</p>
<p>산키 다이어그램에 의하면, 한 번 사용자 행동이 시작되면 짧은 기간 내에는 비교적 예측 가능합니다. 사용자가 20분 미만의 세션에 참여하면 다음 세션이 또한 20분 미만인 확률이 66.7%이고, 40분을 넘는 세션이 될 확률은 15.4%에 불과합니다. 20분에서 40분 사이의 세션을 가진 사용자는 다음 세션이 20분을 넘을 확률이 약 50%입니다. 이는 사용자가 참여하면 더 오래 플랫폼에 투자하게 되는 경향을 나타냅니다.</p>
<p>사용자의 역사가 거의 없는 사용자 행동을 예측하는 어려움이 분명합니다. 사용자가 5회 세션을 완료하거나 세션이 40분을 초과하면 성능이 일반적으로 향상되며, 가장 안정적인 결과는 20~30 이벤트의 데이터 창을 포함합니다. 이 정보는 Zooniverse 및 다른 온라인 플랫폼의 행동 예측 모델을 개선하는 데 도움이 될 수 있습니다. 모델이 빈번한 기여자에게는 효과적이지 않으므로, 이 그룹의 참여 증가를 위한 개입 시기를 결정하는 데 사용해서는 안 됩니다.</p>
<div class="content-ad"></div>
<h1>결론</h1>
<p>연구 결과에서 알 수 있듯이, LSTMs는 시계열 작업 모델링에 효과적입니다. 모든 실험과 모델 구성에서, 사용자가 현재 작업 세션에서 탈락하는지 여부를 학습할 수 있었습니다. 복잡한 특징 집계 대신, 데이터 창을 사용하여 데이터 전체의 의존 관계를 학습했습니다. 이는 GPU를 필요로하며 계산적으로 더 많은 비용이 소요됩니다만, 고전적인 머신 러닝보다 훨씬 적은 시간과 도메인 지식이 필요합니다.</p>
<p>모델은 두 가지 요인으로 제한되었습니다. 첫 번째는 사용자가 언제 탈락할 지 나타내는 기능의 부족이었습니다. 미래 실험에서는 Mao et al.의 연구에서 설명된 특징을 사용하여 모델 성능이 향상되는지 확인해야합니다.</p>
<p>두 번째 제한은 극복하기 어렵습니다. 최소한의 데이터로 사용자에 대해 일반화하는 것은 어렵습니다. 대부분의 Zooniverse 사용자가 단기적이거나 "관심을 끄는 사람"이기 때문에 Zooniverse에서 행동을 모델링하는 것은 도전적입니다. 최소한의 경험이있는 사용자에 대한 모델의 한계를 밝히고 설명하는 것은 이전 데이터 분석과 플랫폼 사용 방법 조사만이 가능합니다.</p>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_12.png">
<p>머신 러닝을 시작하기 전에 데이터와 문제를 명확히 이해하는 것이 중요함을 강조합니다. 초기 분석을 통해 모델의 효과에 대한 사전 확률을 설정할 수 있었고, 해당 분석을 통해 이를 확인할 수 있었습니다.</p>
<p>실제 산업 환경에서 모델이 Zooniverse에 대한 개입(뱃지 또는 메시지와 같은)을 시간화하는 데 사용된다면, 하이브리드 접근 방식을 권장합니다. 짧은 기간 사용자에게는 규칙 기반 논리를 사용하여 개입을 타이밍하고, 장기 사용자에게는 모델이 개입을 안내하는 데 효과적일 수 있습니다.</p>
<h1>각주</h1>
<div class="content-ad"></div>
<ul>
<li>LSTMs가 어떻게 작동하는지 멋진 설명을 찾으려면 Colah의 LSTMs에 대한 블로그 포스트를 확인하시기를 추천합니다. LSTMs의 역전파 알고리즘을 이해하고 싶다면 Goodfellow Et Al의 "Deep Learning"의 10장을 살펴보시는 걸 추천드립니다.</li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"온라인 플랫폼에서 참여 예측을 위한 딥 러닝","description":"","date":"2024-06-19 06:44","slug":"2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms","content":"\n\n\n![image](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png)\n\n# 요약\n\n에딘버러 대학에서 MSc 논문의 일환으로, 저는 딥러닝 기술을 사용하여 준니버스의 사용자 참여를 예측했습니다. 준니버스는 비과학자들이 행성 탐사와 같은 특정 분야에 기여할 수 있는 온라인 시민 과학 플랫폼입니다. 준니버스는 100편 이상의 논문 발표에 기여했습니다. 실제 환경에서 시민 과학자들은 영국의 농업 유출물이 영국 강의 안전 한 한계를 초과하는 수위의 오염 증가를 입증했습니다.\n\n이 문맥에서 참여는 이전 행동을 고려할 때 플랫폼의 미래 사용을 예측할 수 있는지 여부입니다. 이는 여러 형태로 나타날 수 있습니다, 예를 들면:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 시간 기준 내에서 완료할 작업의 예상 수\n- 현재 작업 세션에서 머무를 시간의 양\n\n우리는 섹션 정의에 초점을 맞추고 사용자가 10, 20 또는 30분 동안 계속 작업할지를 예측하기 위해 노력했습니다. 이는 사용자 작업 T를 작업 세션 W로 그룹화하여 계산되었습니다.\n\n![이미지](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_1.png)\n\n이 정의는 유연성과 Zooniverse, StackOverflow 및 Coursera에서의 이전 사용을 위해 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 접근 방식의 주의 사항 중 하나는 생산적인 온라인 시스템의 한 속성인 플랫폼 시간만을 예측한다는 것입니다. 예를 들어, 올바른 기여를 하는 동기부여된 참여자들을 갖는 것은 고려되지 않습니다. 온라인 시스템에 참여하는 동기를 측정하는 것은 활발한 연구 분야입니다. 심리적 상태인 좌절감과 이해도와 같은 것들이 학습되어 맞춤형 교육 개입에 활용될 수 있는 잠재적인 작업이 있습니다.\n\n# 데이터 및 세션 버킷 알고리즘\n\nZooniverse는 친철하게 2021년 10월 19일에서 2022년 8월 14일까지 시민 과학자들의 클릭스트림 데이터를 제공해 주었습니다. 이 데이터는 미국, 중국, 싱가포르 및 핀란드의 시민 과학자들을 다루었습니다.\n\n원시 데이터 세트에는 다음과 같은 열이 포함되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n| Column Name |               Column Desc               | Column Type |\n|-------------|-----------------------------------------|-------------|\n| id          | 클릭스트림 항목을 식별하는 고유 식별자  | bigint      |\n| user_id     | 사용자를 식별하는 고유 식별자           | bigint      |\n| project_id  | 프로젝트를 식별하는 고유 식별자         | bigint      |\n| workflow_id | 워크플로우를 식별하는 고유 식별자       | bigint      |\n| subject_ids | 고유한 작업 식별자                      | bigint      |\n| country     | 국가 이름                               | str         |\n| latitude    | 국가 위도                               | float       |\n| longitude   | 국가 경도                               | float       |\n| timestamp   | 클릭스트림 타임스탬프                   | bigint      |\n\n\nZooniverse의 계층 구조에서 각 행은 다음 거래를 나타냅니다.\n\n- 사용자가 시스템에 로그인하고 참여할 프로젝트를 선택합니다.\n- 프로젝트는 여러 워크플로우를 포함하며 태스크 그룹화를 수행합니다.\n- 사용자는 프로젝트에 연관된 작업을 수행합니다. 작업에는 여러 주제가 포함될 수 있습니다 (하지만 대부분은 하나만 포함합니다).\n\n\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_2.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 특성 선택\n\n데이터에는 약 38,500,990개의 고유 이벤트가 포함되어 있습니다. 서로 다른 지역별 이벤트 분포는 다음과 같습니다:\n\n\n| 국가명        | 백분율     |\n|---------------|------------|\n| 핀란드         | 59.4       |\n| 미국           | 25.5       |\n| 싱가포르       | 10.8       |\n| 중국           | 4.3        |\n\n\n위도와 경도는 국가 정보를 중복해서 나타내므로 제거되었습니다. 주제 ID 및 작업 ID도 제거되었는데, 이 정보의 세분화가 참여 패턴 학습에 기여하지 않았기 때문입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 연구에서는 이전 연구에서 강조된 주요 변수가 부족했습니다. 예를 들어, Semenov et al.은 로그인한 사용자들이 더 오랜 시간 동안 작업하고 작업 세션에 대해 더 높은 투자 수준을 나타내는 것으로 발견했습니다. 또한, Mao et al.은 투표 엔트로피가 감소하는 경우, 사용자가 목록에서 반복해서 동일한 옵션을 선택하는 것이 지루함과 참여하지 않음의 유용한 대리자로 작용할 수 있다고 밝혀냈습니다. 이러한 연구 결과는 사용자 참여도를 효과적으로 측정할 수 있는데 사용자 로그인 상태와 투표 패턴을 통해 이를 할 수 있음을 시사했으며, 이러한 측면들이 우리의 현재 분석에는 고려되지 않았습니다.\n\n따라서 우리는 이러한 특성을 근사화하는 데 사용될 수 있는 다양한 속도에서 통계치를 계산해야 했습니다. 이에는 다음이 포함되었습니다:\n\n- 사용자 세션 수의 롤링 번호\n- 현재 세션 내의 시간 및 이벤트 수\n- 과거 세션 간의 평균 시간 및 이벤트 수\n- 이전 세션에서 소비한 시간 및 이전 세션의 이벤트 수\n- 마지막 이벤트로부터의 시간 차 및 과거 이벤트의 평균 시간 차\n\n![image](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# **The Feature Long Tail**\n\nZooniverse 및 Coursera, StackOverflow, Snap과 같은 다른 온라인 플랫폼의 분석 결과를 보면, 매우 소수의 사용자가 플랫폼 활동의 대부분을 지나치게 책임지는 거대한 권한 분포가 있다는 것을 알 수 있습니다. 이 현상은 소수의 고도로 활발한 사용자가 플랫폼 기여를 주도하고 대부분의 사용자는 비교적 활동이 적다는 것을 나타냅니다.\n\n저희의 데이터는 권한 분포에 부합되어, 사용자의 25%만이 세 번 이상의 세션을 완료하였으며, 작업 세션의 68%는 30분 미만으로 지속되었습니다. 이 분포는 사용자 참여의 불균형을 강조하며, 소수의 고도로 활발한 사용자가 플랫폼에서의 활동을 지배하고 있음을 보여줍니다.\n\n많은 사용자에게 시간 순서 채널은 중복될 수 있습니다. 사용자가 단 한 번의 세션만 완료하는 경우, 과거 세션 계산은 일정한 0으로 유지됩니다. 마찬가지로 세션 간 시간과 같은 채널의 경우, 사용자가 두 번의 세션만 완료하는 경우, 과거 세션 채널은 첫 번째 세션에 대해서는 0으로 일정하게 유지되거나 이전 세션 통계의 일정한 값이 될 것입니다. 이 중복성은 드물게 사용하는 사용자에게는 이러한 메트릭이 의미 있는 통찰력을 제공하지 않을 수 있으며, 참여를 효과적으로 평가하기 위해 대안적인 측정 방법이 필요할 수 있다는 것을 시사합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_4.png)\n\nThe feature space was designed to represent user information over various time intervals. Because many users only completed two sessions, a lot of data would be repeated for these users. Any model for predicting user behavior would need to be carefully interrogated to ensure it did not memorize these aspects of user behavior and project results that mimicked the most likely user, rather than the projection of users.\n\nTherefore, it was important to design experiments that enabled differentiation between the small number of highly active users and the large population of inactive, short-term contributors.\n\n# Experiments\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실험 결과 다음 질문에 대한 대답을 제공했습니다. 사용자의 클릭 스트림에 기록된 항목이 주어졌을 때 사용자가 10, 20 또는 30분 동안 계속 작업을 할 것인가?\n\n클릭 스트림의 각 행은 사용자가 지정된 시간대(10, 20 또는 30분) 동안 계속 작업할지 여부를 나타내는 레이블 yiy_iyi로 표시되었습니다. 데이터가 시계열을 따르고 사용자 행동이 이전 이력에 의존한다는 점을 감안하여, 클릭 스트림 F(X_i, Y_i)의 예측은 과거 정보를 포함하여 확장되었습니다. 따라서 예측 함수는 F(X_i, Y_i, | X_i-1, X_i-2, ..., X_0)가 되었습니다.\n\n장기 단기 메모리(Long Short-Term Memory, LSTM) 네트워크는 과거와 현재 정보를 제어하고 가중시키도록 설계된 것으로 이러한 종류의 분석에 적합합니다. 이들은 다른 시계열 작업으로도 효과적으로 적용되어 왔으며, 활동 인식, 행동 인식 및 지진 예측과 같은 작업에 사용되었습니다.\n\n사용자 세션 창을 통해 이러한 함수를 쌓는 과정에서, 모델이 세션 통계, 사용자 동작 변화 및 예상된 참여 사이의 관계를 학습할 수 있을 것으로 기대했습니다¹.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 질문에 대답하려고 실험을 진행했습니다:\n\n- 단기 또는 장기 행동을 예측하는 것이 더 쉬운지 여부.\n- 데이터 창 크기를 확장하면 참여 측정에 기여하는지 여부.\n\n또한 실험에서는 각 이벤트를 독립적으로 고려하는 대신 네트워크 아키텍처와 종속성을 포착하는 것이 모델 성능에 영향을 미치는지 확인하기 위해 RandomForest 분류에 대해 베이스라인을 설정했습니다.\n\n사용자가 현재 세션에서 계속 작업하는지 여부는 이진적입니다. 따라서 RandomForest를 구성하고 LSTM 매개변수 최적화를 위해 유전 알고리즘과 경사 하강법을 적용할 수 있었고, 바이너리 크로스 엔트로피를 사용하여 꼭 맞추었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일괄 처리된 N개의 관측치에 대한 손실 함수는 다음과 같습니다:\n\n![Loss Function](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_5.png)\n\n목표는 yi(실제 예측값)와 네트워크 출력인 y^i 사이의 거리를 최소화하는 것입니다.\n\n# 구현\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터는 타임스탬프에 따라 정렬되고 훈련, 테스트 및 평가 파티션으로 분할되었습니다. 이미지 분류 실험과는 달리 시계열 관측 사이의 관계가 중요하기 때문에 데이터를 섞으면 시퀀스의 일관성이 깨질 수 있습니다. 따라서 데이터를 섞으면 훈련에 후속 관측사항이 포함될 수 있습니다. 예를 들어, 모델이 작업 세션이 10분만 계속된다는 정보를 받기 전에 작업 세션의 1분과 2분의 관측을 받는다면 결과적으로 선견지명을 얻을 수 있습니다.\n\n장기 단기 메모리 (LSTM) 네트워크가 사용자 관측 윈도우의 길이 1, 10, 20, 30, 40에 대해 생성되고 훈련되었습니다. PyTorch Lightning을 사용하여 네트워크를 훈련했는데, 이를 통해 편리한 래퍼(wrapper)를 제공하여 훈련 루프 구현, 로깅 및 메트릭 처리를 감싸줍니다. 10, 20, 30분 동안의 지속을 예측하기 위한 별도의 실험이 수행되었습니다.\n\n첫 번째의 출력이 두 번째로 전파되는 두 개의 LSTM 네트워크를 쌓는 것이 가장 성능이 좋았습니다. 두 번째 레이어는 선형 레이어를 따라, 기능을 하나의 대상 변수로 변환하여 사용자의 세션 지속 확률을 정의했습니다. 최종 선형 레이어 다음의 엔트로피에서 역전파가 계산되었고, 이를 통해 네트워크 전체의 가중치가 업데이트되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결과\n\n실험을 통해 성과가 좋은 모델을 분석했습니다. 각 실험에 대한 정밀도, 재현율 및 AUC를 플롯했습니다. AUC는 분류 임계값 범위에서 실제 양성 비율(재현율)과 거짓 양성 비율(1-정밀도)을 집계합니다.\n\n검증 및 테스트 데이터셋 간의 균형은 모델이 특정 시간 역학에 기반하지 않고 패턴을 학습하고 있다는 것을 나타냅니다. 따라서 참여 패턴이 크게 변하지 않는 한, 새로운 데이터에 적용될 때 모델의 동작을 예측할 수 있을 가능성이 높습니다.\n\n결과는 장기적 예측에서 일반적으로 더 일관성있게 나타납니다. 정밀도는 검증 데이터셋에서 68%에서 70%로, 테스트 데이터셋에서 71%에서 74%로 범위가 확장됩니다. 모든 창에서 재현율은 57%에서 59%까지 범위가 확장됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단기 행동을 예측하는 실험들은 데이터 윈도우의 크기에 민감합니다. 10분 동안의 실험에서, 검증 데이터셋의 정밀도는 64%에서 80%로 범위가 나타나며, 테스트 데이터셋의 경우 66%에서 89%까지 변동합니다. 재현율은 89%에서 30%까지 범위가 나타나며, 최적의 균형을 얻으려면 20개에서 30개의 이벤트 윈도우를 사용하는 것이 좋습니다.\n\n![Image 7](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_7.png)\n\n![Image 8](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_8.png)\n\n![Image 9](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델의 다양한 행동 양상은 짧은, 중간, 그리고 장기적인 참여를 예측하는 것이 서로 다른 접근 방식이 필요한 다른 도전이라는 것을 보여줍니다. 더 높은 정밀도는 단기적으로 참여하는 사용자를 놓치지 않을 가능성을 보여줍니다. 그러나 장기간의 참여가 떨어질 것으로 예측하는 것은 더 어려운 과제입니다.\n\n실제 상황에서 모델의 선택은 참여하지 않은 사용자를 놓치는 것을 우선시해야 하는지, 아니면 동기를 부여받은 사용자를 잘못 분류하는 것을 우선시해야 하는지를 고려해야 합니다.\n\n30분 참여 예측과 데이터 창의 30개 이전 관측치를 사용한 우수한 모델/실험 구성이 우리의 최고의 성과를 냈습니다. 이 모델은 AUC 스코어가 0.748을 달성했습니다. 이는 Mao Et Al이 30분 예측에서 약 0.76을 달성한 것보다 약간 떨어지는 성과입니다. 이는 데이터의 분산 부족으로 인한 것으로 여겨집니다. 예를 들어, 첫 번째 사용자 세션에는 많은 동일한 변수들이 포함되어 있습니다. 이들은 다음을 포함합니다:\n\n- 누적 플랫폼 시간 및 누적 세션 시간.\n- 플랫폼과 세션 전체 이벤트 수.\n- 이전 세션 통계.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n**사용자 세그먼트별 평가**\n\n플랫폼에 작은 기여만 한 사용자를 고려해 역사적 정보를 포함시키면 많은 중복이 발생한다는 것을 알고 있습니다. 이는 대부분의 사용자들에 해당합니다.\n\n다양한 세션 길이 별 성능을 이해하기 위해 사용자 작업 세션에서 지낸 누적 시간에 따른 정확도, 재현율 및 AUC를 검토합니다. 평가와 테스트 세션을 유사성으로 통합합니다. 정밀도와 재현율의 가장 큰 요인은 사용자가 작업 세션에서 얼마나 시간을 보내는지에 달려 있습니다. 데이터 창 크기에 관계 없이, 사용자가 작업 세션에서 60분을 보낸 후에는 모델의 효과가 극적으로 향상됩니다.\n\n![이미지](/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_10.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기존 온라인 플랫폼 연구와 일관성 있는 결과를 보여주었으며, 최소한의 히스토리로 사용자에 대한 추론의 어려움을 보여줍니다. 이는 사용자 행동에 대한 우리 이전 분석을 뒷받침합니다.\n\n산키 다이어그램에 의하면, 한 번 사용자 행동이 시작되면 짧은 기간 내에는 비교적 예측 가능합니다. 사용자가 20분 미만의 세션에 참여하면 다음 세션이 또한 20분 미만인 확률이 66.7%이고, 40분을 넘는 세션이 될 확률은 15.4%에 불과합니다. 20분에서 40분 사이의 세션을 가진 사용자는 다음 세션이 20분을 넘을 확률이 약 50%입니다. 이는 사용자가 참여하면 더 오래 플랫폼에 투자하게 되는 경향을 나타냅니다.\n\n사용자의 역사가 거의 없는 사용자 행동을 예측하는 어려움이 분명합니다. 사용자가 5회 세션을 완료하거나 세션이 40분을 초과하면 성능이 일반적으로 향상되며, 가장 안정적인 결과는 20~30 이벤트의 데이터 창을 포함합니다. 이 정보는 Zooniverse 및 다른 온라인 플랫폼의 행동 예측 모델을 개선하는 데 도움이 될 수 있습니다. 모델이 빈번한 기여자에게는 효과적이지 않으므로, 이 그룹의 참여 증가를 위한 개입 시기를 결정하는 데 사용해서는 안 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n연구 결과에서 알 수 있듯이, LSTMs는 시계열 작업 모델링에 효과적입니다. 모든 실험과 모델 구성에서, 사용자가 현재 작업 세션에서 탈락하는지 여부를 학습할 수 있었습니다. 복잡한 특징 집계 대신, 데이터 창을 사용하여 데이터 전체의 의존 관계를 학습했습니다. 이는 GPU를 필요로하며 계산적으로 더 많은 비용이 소요됩니다만, 고전적인 머신 러닝보다 훨씬 적은 시간과 도메인 지식이 필요합니다.\n\n모델은 두 가지 요인으로 제한되었습니다. 첫 번째는 사용자가 언제 탈락할 지 나타내는 기능의 부족이었습니다. 미래 실험에서는 Mao et al.의 연구에서 설명된 특징을 사용하여 모델 성능이 향상되는지 확인해야합니다.\n\n두 번째 제한은 극복하기 어렵습니다. 최소한의 데이터로 사용자에 대해 일반화하는 것은 어렵습니다. 대부분의 Zooniverse 사용자가 단기적이거나 \"관심을 끄는 사람\"이기 때문에 Zooniverse에서 행동을 모델링하는 것은 도전적입니다. 최소한의 경험이있는 사용자에 대한 모델의 한계를 밝히고 설명하는 것은 이전 데이터 분석과 플랫폼 사용 방법 조사만이 가능합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_12.png\" /\u003e\n\n머신 러닝을 시작하기 전에 데이터와 문제를 명확히 이해하는 것이 중요함을 강조합니다. 초기 분석을 통해 모델의 효과에 대한 사전 확률을 설정할 수 있었고, 해당 분석을 통해 이를 확인할 수 있었습니다.\n\n실제 산업 환경에서 모델이 Zooniverse에 대한 개입(뱃지 또는 메시지와 같은)을 시간화하는 데 사용된다면, 하이브리드 접근 방식을 권장합니다. 짧은 기간 사용자에게는 규칙 기반 논리를 사용하여 개입을 타이밍하고, 장기 사용자에게는 모델이 개입을 안내하는 데 효과적일 수 있습니다.\n\n# 각주\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- LSTMs가 어떻게 작동하는지 멋진 설명을 찾으려면 Colah의 LSTMs에 대한 블로그 포스트를 확인하시기를 추천합니다. LSTMs의 역전파 알고리즘을 이해하고 싶다면 Goodfellow Et Al의 \"Deep Learning\"의 10장을 살펴보시는 걸 추천드립니다.","ogImage":{"url":"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png"},"coverImage":"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png","tag":["Tech"],"readingTime":11},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_0.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch1\u003e요약\u003c/h1\u003e\n\u003cp\u003e에딘버러 대학에서 MSc 논문의 일환으로, 저는 딥러닝 기술을 사용하여 준니버스의 사용자 참여를 예측했습니다. 준니버스는 비과학자들이 행성 탐사와 같은 특정 분야에 기여할 수 있는 온라인 시민 과학 플랫폼입니다. 준니버스는 100편 이상의 논문 발표에 기여했습니다. 실제 환경에서 시민 과학자들은 영국의 농업 유출물이 영국 강의 안전 한 한계를 초과하는 수위의 오염 증가를 입증했습니다.\u003c/p\u003e\n\u003cp\u003e이 문맥에서 참여는 이전 행동을 고려할 때 플랫폼의 미래 사용을 예측할 수 있는지 여부입니다. 이는 여러 형태로 나타날 수 있습니다, 예를 들면:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e시간 기준 내에서 완료할 작업의 예상 수\u003c/li\u003e\n\u003cli\u003e현재 작업 세션에서 머무를 시간의 양\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e우리는 섹션 정의에 초점을 맞추고 사용자가 10, 20 또는 30분 동안 계속 작업할지를 예측하기 위해 노력했습니다. 이는 사용자 작업 T를 작업 세션 W로 그룹화하여 계산되었습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e이 정의는 유연성과 Zooniverse, StackOverflow 및 Coursera에서의 이전 사용을 위해 사용됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 접근 방식의 주의 사항 중 하나는 생산적인 온라인 시스템의 한 속성인 플랫폼 시간만을 예측한다는 것입니다. 예를 들어, 올바른 기여를 하는 동기부여된 참여자들을 갖는 것은 고려되지 않습니다. 온라인 시스템에 참여하는 동기를 측정하는 것은 활발한 연구 분야입니다. 심리적 상태인 좌절감과 이해도와 같은 것들이 학습되어 맞춤형 교육 개입에 활용될 수 있는 잠재적인 작업이 있습니다.\u003c/p\u003e\n\u003ch1\u003e데이터 및 세션 버킷 알고리즘\u003c/h1\u003e\n\u003cp\u003eZooniverse는 친철하게 2021년 10월 19일에서 2022년 8월 14일까지 시민 과학자들의 클릭스트림 데이터를 제공해 주었습니다. 이 데이터는 미국, 중국, 싱가포르 및 핀란드의 시민 과학자들을 다루었습니다.\u003c/p\u003e\n\u003cp\u003e원시 데이터 세트에는 다음과 같은 열이 포함되어 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eColumn Name\u003c/th\u003e\u003cth\u003eColumn Desc\u003c/th\u003e\u003cth\u003eColumn Type\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eid\u003c/td\u003e\u003ctd\u003e클릭스트림 항목을 식별하는 고유 식별자\u003c/td\u003e\u003ctd\u003ebigint\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003euser_id\u003c/td\u003e\u003ctd\u003e사용자를 식별하는 고유 식별자\u003c/td\u003e\u003ctd\u003ebigint\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eproject_id\u003c/td\u003e\u003ctd\u003e프로젝트를 식별하는 고유 식별자\u003c/td\u003e\u003ctd\u003ebigint\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eworkflow_id\u003c/td\u003e\u003ctd\u003e워크플로우를 식별하는 고유 식별자\u003c/td\u003e\u003ctd\u003ebigint\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003esubject_ids\u003c/td\u003e\u003ctd\u003e고유한 작업 식별자\u003c/td\u003e\u003ctd\u003ebigint\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003ecountry\u003c/td\u003e\u003ctd\u003e국가 이름\u003c/td\u003e\u003ctd\u003estr\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003elatitude\u003c/td\u003e\u003ctd\u003e국가 위도\u003c/td\u003e\u003ctd\u003efloat\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003elongitude\u003c/td\u003e\u003ctd\u003e국가 경도\u003c/td\u003e\u003ctd\u003efloat\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003etimestamp\u003c/td\u003e\u003ctd\u003e클릭스트림 타임스탬프\u003c/td\u003e\u003ctd\u003ebigint\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003eZooniverse의 계층 구조에서 각 행은 다음 거래를 나타냅니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e사용자가 시스템에 로그인하고 참여할 프로젝트를 선택합니다.\u003c/li\u003e\n\u003cli\u003e프로젝트는 여러 워크플로우를 포함하며 태스크 그룹화를 수행합니다.\u003c/li\u003e\n\u003cli\u003e사용자는 프로젝트에 연관된 작업을 수행합니다. 작업에는 여러 주제가 포함될 수 있습니다 (하지만 대부분은 하나만 포함합니다).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_2.png\"\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e특성 선택\u003c/h1\u003e\n\u003cp\u003e데이터에는 약 38,500,990개의 고유 이벤트가 포함되어 있습니다. 서로 다른 지역별 이벤트 분포는 다음과 같습니다:\u003c/p\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003e국가명\u003c/th\u003e\u003cth\u003e백분율\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e핀란드\u003c/td\u003e\u003ctd\u003e59.4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e미국\u003c/td\u003e\u003ctd\u003e25.5\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e싱가포르\u003c/td\u003e\u003ctd\u003e10.8\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e중국\u003c/td\u003e\u003ctd\u003e4.3\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003cp\u003e위도와 경도는 국가 정보를 중복해서 나타내므로 제거되었습니다. 주제 ID 및 작업 ID도 제거되었는데, 이 정보의 세분화가 참여 패턴 학습에 기여하지 않았기 때문입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e우리 연구에서는 이전 연구에서 강조된 주요 변수가 부족했습니다. 예를 들어, Semenov et al.은 로그인한 사용자들이 더 오랜 시간 동안 작업하고 작업 세션에 대해 더 높은 투자 수준을 나타내는 것으로 발견했습니다. 또한, Mao et al.은 투표 엔트로피가 감소하는 경우, 사용자가 목록에서 반복해서 동일한 옵션을 선택하는 것이 지루함과 참여하지 않음의 유용한 대리자로 작용할 수 있다고 밝혀냈습니다. 이러한 연구 결과는 사용자 참여도를 효과적으로 측정할 수 있는데 사용자 로그인 상태와 투표 패턴을 통해 이를 할 수 있음을 시사했으며, 이러한 측면들이 우리의 현재 분석에는 고려되지 않았습니다.\u003c/p\u003e\n\u003cp\u003e따라서 우리는 이러한 특성을 근사화하는 데 사용될 수 있는 다양한 속도에서 통계치를 계산해야 했습니다. 이에는 다음이 포함되었습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e사용자 세션 수의 롤링 번호\u003c/li\u003e\n\u003cli\u003e현재 세션 내의 시간 및 이벤트 수\u003c/li\u003e\n\u003cli\u003e과거 세션 간의 평균 시간 및 이벤트 수\u003c/li\u003e\n\u003cli\u003e이전 세션에서 소비한 시간 및 이전 세션의 이벤트 수\u003c/li\u003e\n\u003cli\u003e마지막 이벤트로부터의 시간 차 및 과거 이벤트의 평균 시간 차\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e\u003cstrong\u003eThe Feature Long Tail\u003c/strong\u003e\u003c/h1\u003e\n\u003cp\u003eZooniverse 및 Coursera, StackOverflow, Snap과 같은 다른 온라인 플랫폼의 분석 결과를 보면, 매우 소수의 사용자가 플랫폼 활동의 대부분을 지나치게 책임지는 거대한 권한 분포가 있다는 것을 알 수 있습니다. 이 현상은 소수의 고도로 활발한 사용자가 플랫폼 기여를 주도하고 대부분의 사용자는 비교적 활동이 적다는 것을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e저희의 데이터는 권한 분포에 부합되어, 사용자의 25%만이 세 번 이상의 세션을 완료하였으며, 작업 세션의 68%는 30분 미만으로 지속되었습니다. 이 분포는 사용자 참여의 불균형을 강조하며, 소수의 고도로 활발한 사용자가 플랫폼에서의 활동을 지배하고 있음을 보여줍니다.\u003c/p\u003e\n\u003cp\u003e많은 사용자에게 시간 순서 채널은 중복될 수 있습니다. 사용자가 단 한 번의 세션만 완료하는 경우, 과거 세션 계산은 일정한 0으로 유지됩니다. 마찬가지로 세션 간 시간과 같은 채널의 경우, 사용자가 두 번의 세션만 완료하는 경우, 과거 세션 채널은 첫 번째 세션에 대해서는 0으로 일정하게 유지되거나 이전 세션 통계의 일정한 값이 될 것입니다. 이 중복성은 드물게 사용하는 사용자에게는 이러한 메트릭이 의미 있는 통찰력을 제공하지 않을 수 있으며, 참여를 효과적으로 평가하기 위해 대안적인 측정 방법이 필요할 수 있다는 것을 시사합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_4.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eThe feature space was designed to represent user information over various time intervals. Because many users only completed two sessions, a lot of data would be repeated for these users. Any model for predicting user behavior would need to be carefully interrogated to ensure it did not memorize these aspects of user behavior and project results that mimicked the most likely user, rather than the projection of users.\u003c/p\u003e\n\u003cp\u003eTherefore, it was important to design experiments that enabled differentiation between the small number of highly active users and the large population of inactive, short-term contributors.\u003c/p\u003e\n\u003ch1\u003eExperiments\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e실험 결과 다음 질문에 대한 대답을 제공했습니다. 사용자의 클릭 스트림에 기록된 항목이 주어졌을 때 사용자가 10, 20 또는 30분 동안 계속 작업을 할 것인가?\u003c/p\u003e\n\u003cp\u003e클릭 스트림의 각 행은 사용자가 지정된 시간대(10, 20 또는 30분) 동안 계속 작업할지 여부를 나타내는 레이블 yiy_iyi로 표시되었습니다. 데이터가 시계열을 따르고 사용자 행동이 이전 이력에 의존한다는 점을 감안하여, 클릭 스트림 F(X_i, Y_i)의 예측은 과거 정보를 포함하여 확장되었습니다. 따라서 예측 함수는 F(X_i, Y_i, | X_i-1, X_i-2, ..., X_0)가 되었습니다.\u003c/p\u003e\n\u003cp\u003e장기 단기 메모리(Long Short-Term Memory, LSTM) 네트워크는 과거와 현재 정보를 제어하고 가중시키도록 설계된 것으로 이러한 종류의 분석에 적합합니다. 이들은 다른 시계열 작업으로도 효과적으로 적용되어 왔으며, 활동 인식, 행동 인식 및 지진 예측과 같은 작업에 사용되었습니다.\u003c/p\u003e\n\u003cp\u003e사용자 세션 창을 통해 이러한 함수를 쌓는 과정에서, 모델이 세션 통계, 사용자 동작 변화 및 예상된 참여 사이의 관계를 학습할 수 있을 것으로 기대했습니다¹.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e다음 질문에 대답하려고 실험을 진행했습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e단기 또는 장기 행동을 예측하는 것이 더 쉬운지 여부.\u003c/li\u003e\n\u003cli\u003e데이터 창 크기를 확장하면 참여 측정에 기여하는지 여부.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e또한 실험에서는 각 이벤트를 독립적으로 고려하는 대신 네트워크 아키텍처와 종속성을 포착하는 것이 모델 성능에 영향을 미치는지 확인하기 위해 RandomForest 분류에 대해 베이스라인을 설정했습니다.\u003c/p\u003e\n\u003cp\u003e사용자가 현재 세션에서 계속 작업하는지 여부는 이진적입니다. 따라서 RandomForest를 구성하고 LSTM 매개변수 최적화를 위해 유전 알고리즘과 경사 하강법을 적용할 수 있었고, 바이너리 크로스 엔트로피를 사용하여 꼭 맞추었습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e일괄 처리된 N개의 관측치에 대한 손실 함수는 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_5.png\" alt=\"Loss Function\"\u003e\u003c/p\u003e\n\u003cp\u003e목표는 yi(실제 예측값)와 네트워크 출력인 y^i 사이의 거리를 최소화하는 것입니다.\u003c/p\u003e\n\u003ch1\u003e구현\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e데이터는 타임스탬프에 따라 정렬되고 훈련, 테스트 및 평가 파티션으로 분할되었습니다. 이미지 분류 실험과는 달리 시계열 관측 사이의 관계가 중요하기 때문에 데이터를 섞으면 시퀀스의 일관성이 깨질 수 있습니다. 따라서 데이터를 섞으면 훈련에 후속 관측사항이 포함될 수 있습니다. 예를 들어, 모델이 작업 세션이 10분만 계속된다는 정보를 받기 전에 작업 세션의 1분과 2분의 관측을 받는다면 결과적으로 선견지명을 얻을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e장기 단기 메모리 (LSTM) 네트워크가 사용자 관측 윈도우의 길이 1, 10, 20, 30, 40에 대해 생성되고 훈련되었습니다. PyTorch Lightning을 사용하여 네트워크를 훈련했는데, 이를 통해 편리한 래퍼(wrapper)를 제공하여 훈련 루프 구현, 로깅 및 메트릭 처리를 감싸줍니다. 10, 20, 30분 동안의 지속을 예측하기 위한 별도의 실험이 수행되었습니다.\u003c/p\u003e\n\u003cp\u003e첫 번째의 출력이 두 번째로 전파되는 두 개의 LSTM 네트워크를 쌓는 것이 가장 성능이 좋았습니다. 두 번째 레이어는 선형 레이어를 따라, 기능을 하나의 대상 변수로 변환하여 사용자의 세션 지속 확률을 정의했습니다. 최종 선형 레이어 다음의 엔트로피에서 역전파가 계산되었고, 이를 통해 네트워크 전체의 가중치가 업데이트되었습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e결과\u003c/h1\u003e\n\u003cp\u003e실험을 통해 성과가 좋은 모델을 분석했습니다. 각 실험에 대한 정밀도, 재현율 및 AUC를 플롯했습니다. AUC는 분류 임계값 범위에서 실제 양성 비율(재현율)과 거짓 양성 비율(1-정밀도)을 집계합니다.\u003c/p\u003e\n\u003cp\u003e검증 및 테스트 데이터셋 간의 균형은 모델이 특정 시간 역학에 기반하지 않고 패턴을 학습하고 있다는 것을 나타냅니다. 따라서 참여 패턴이 크게 변하지 않는 한, 새로운 데이터에 적용될 때 모델의 동작을 예측할 수 있을 가능성이 높습니다.\u003c/p\u003e\n\u003cp\u003e결과는 장기적 예측에서 일반적으로 더 일관성있게 나타납니다. 정밀도는 검증 데이터셋에서 68%에서 70%로, 테스트 데이터셋에서 71%에서 74%로 범위가 확장됩니다. 모든 창에서 재현율은 57%에서 59%까지 범위가 확장됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e단기 행동을 예측하는 실험들은 데이터 윈도우의 크기에 민감합니다. 10분 동안의 실험에서, 검증 데이터셋의 정밀도는 64%에서 80%로 범위가 나타나며, 테스트 데이터셋의 경우 66%에서 89%까지 변동합니다. 재현율은 89%에서 30%까지 범위가 나타나며, 최적의 균형을 얻으려면 20개에서 30개의 이벤트 윈도우를 사용하는 것이 좋습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_7.png\" alt=\"Image 7\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_8.png\" alt=\"Image 8\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_9.png\" alt=\"Image 9\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모델의 다양한 행동 양상은 짧은, 중간, 그리고 장기적인 참여를 예측하는 것이 서로 다른 접근 방식이 필요한 다른 도전이라는 것을 보여줍니다. 더 높은 정밀도는 단기적으로 참여하는 사용자를 놓치지 않을 가능성을 보여줍니다. 그러나 장기간의 참여가 떨어질 것으로 예측하는 것은 더 어려운 과제입니다.\u003c/p\u003e\n\u003cp\u003e실제 상황에서 모델의 선택은 참여하지 않은 사용자를 놓치는 것을 우선시해야 하는지, 아니면 동기를 부여받은 사용자를 잘못 분류하는 것을 우선시해야 하는지를 고려해야 합니다.\u003c/p\u003e\n\u003cp\u003e30분 참여 예측과 데이터 창의 30개 이전 관측치를 사용한 우수한 모델/실험 구성이 우리의 최고의 성과를 냈습니다. 이 모델은 AUC 스코어가 0.748을 달성했습니다. 이는 Mao Et Al이 30분 예측에서 약 0.76을 달성한 것보다 약간 떨어지는 성과입니다. 이는 데이터의 분산 부족으로 인한 것으로 여겨집니다. 예를 들어, 첫 번째 사용자 세션에는 많은 동일한 변수들이 포함되어 있습니다. 이들은 다음을 포함합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e누적 플랫폼 시간 및 누적 세션 시간.\u003c/li\u003e\n\u003cli\u003e플랫폼과 세션 전체 이벤트 수.\u003c/li\u003e\n\u003cli\u003e이전 세션 통계.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cstrong\u003e사용자 세그먼트별 평가\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e플랫폼에 작은 기여만 한 사용자를 고려해 역사적 정보를 포함시키면 많은 중복이 발생한다는 것을 알고 있습니다. 이는 대부분의 사용자들에 해당합니다.\u003c/p\u003e\n\u003cp\u003e다양한 세션 길이 별 성능을 이해하기 위해 사용자 작업 세션에서 지낸 누적 시간에 따른 정확도, 재현율 및 AUC를 검토합니다. 평가와 테스트 세션을 유사성으로 통합합니다. 정밀도와 재현율의 가장 큰 요인은 사용자가 작업 세션에서 얼마나 시간을 보내는지에 달려 있습니다. 데이터 창 크기에 관계 없이, 사용자가 작업 세션에서 60분을 보낸 후에는 모델의 효과가 극적으로 향상됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_10.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e기존 온라인 플랫폼 연구와 일관성 있는 결과를 보여주었으며, 최소한의 히스토리로 사용자에 대한 추론의 어려움을 보여줍니다. 이는 사용자 행동에 대한 우리 이전 분석을 뒷받침합니다.\u003c/p\u003e\n\u003cp\u003e산키 다이어그램에 의하면, 한 번 사용자 행동이 시작되면 짧은 기간 내에는 비교적 예측 가능합니다. 사용자가 20분 미만의 세션에 참여하면 다음 세션이 또한 20분 미만인 확률이 66.7%이고, 40분을 넘는 세션이 될 확률은 15.4%에 불과합니다. 20분에서 40분 사이의 세션을 가진 사용자는 다음 세션이 20분을 넘을 확률이 약 50%입니다. 이는 사용자가 참여하면 더 오래 플랫폼에 투자하게 되는 경향을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e사용자의 역사가 거의 없는 사용자 행동을 예측하는 어려움이 분명합니다. 사용자가 5회 세션을 완료하거나 세션이 40분을 초과하면 성능이 일반적으로 향상되며, 가장 안정적인 결과는 20~30 이벤트의 데이터 창을 포함합니다. 이 정보는 Zooniverse 및 다른 온라인 플랫폼의 행동 예측 모델을 개선하는 데 도움이 될 수 있습니다. 모델이 빈번한 기여자에게는 효과적이지 않으므로, 이 그룹의 참여 증가를 위한 개입 시기를 결정하는 데 사용해서는 안 됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e연구 결과에서 알 수 있듯이, LSTMs는 시계열 작업 모델링에 효과적입니다. 모든 실험과 모델 구성에서, 사용자가 현재 작업 세션에서 탈락하는지 여부를 학습할 수 있었습니다. 복잡한 특징 집계 대신, 데이터 창을 사용하여 데이터 전체의 의존 관계를 학습했습니다. 이는 GPU를 필요로하며 계산적으로 더 많은 비용이 소요됩니다만, 고전적인 머신 러닝보다 훨씬 적은 시간과 도메인 지식이 필요합니다.\u003c/p\u003e\n\u003cp\u003e모델은 두 가지 요인으로 제한되었습니다. 첫 번째는 사용자가 언제 탈락할 지 나타내는 기능의 부족이었습니다. 미래 실험에서는 Mao et al.의 연구에서 설명된 특징을 사용하여 모델 성능이 향상되는지 확인해야합니다.\u003c/p\u003e\n\u003cp\u003e두 번째 제한은 극복하기 어렵습니다. 최소한의 데이터로 사용자에 대해 일반화하는 것은 어렵습니다. 대부분의 Zooniverse 사용자가 단기적이거나 \"관심을 끄는 사람\"이기 때문에 Zooniverse에서 행동을 모델링하는 것은 도전적입니다. 최소한의 경험이있는 사용자에 대한 모델의 한계를 밝히고 설명하는 것은 이전 데이터 분석과 플랫폼 사용 방법 조사만이 가능합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms_12.png\"\u003e\n\u003cp\u003e머신 러닝을 시작하기 전에 데이터와 문제를 명확히 이해하는 것이 중요함을 강조합니다. 초기 분석을 통해 모델의 효과에 대한 사전 확률을 설정할 수 있었고, 해당 분석을 통해 이를 확인할 수 있었습니다.\u003c/p\u003e\n\u003cp\u003e실제 산업 환경에서 모델이 Zooniverse에 대한 개입(뱃지 또는 메시지와 같은)을 시간화하는 데 사용된다면, 하이브리드 접근 방식을 권장합니다. 짧은 기간 사용자에게는 규칙 기반 논리를 사용하여 개입을 타이밍하고, 장기 사용자에게는 모델이 개입을 안내하는 데 효과적일 수 있습니다.\u003c/p\u003e\n\u003ch1\u003e각주\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eLSTMs가 어떻게 작동하는지 멋진 설명을 찾으려면 Colah의 LSTMs에 대한 블로그 포스트를 확인하시기를 추천합니다. LSTMs의 역전파 알고리즘을 이해하고 싶다면 Goodfellow Et Al의 \"Deep Learning\"의 10장을 살펴보시는 걸 추천드립니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-DeepLearningtoPredictEngagementinOnlinePlatforms"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>