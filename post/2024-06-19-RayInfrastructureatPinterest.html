<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Pinterest의 Ray 인프라 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-RayInfrastructureatPinterest" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Pinterest의 Ray 인프라 | itposting" data-gatsby-head="true"/><meta property="og:title" content="Pinterest의 Ray 인프라 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-RayInfrastructureatPinterest_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-RayInfrastructureatPinterest" data-gatsby-head="true"/><meta name="twitter:title" content="Pinterest의 Ray 인프라 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-RayInfrastructureatPinterest_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 03:39" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Pinterest의 Ray 인프라</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Pinterest의 Ray 인프라" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">14<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-RayInfrastructureatPinterest&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>

































<table><thead><tr><th>이름</th><th>직급</th></tr></thead><tbody><tr><td>Chia-Wei Chen</td><td>주임 소프트웨어 엔지니어</td></tr><tr><td>Raymond Lee</td><td>주임 소프트웨어 엔지니어</td></tr><tr><td>Alex Wang</td><td>소프트웨어 엔지니어 I</td></tr><tr><td>Saurabh Vishwas Joshi</td><td>주임 스태프 소프트웨어 엔지니어</td></tr><tr><td>Karthik Anantha Padmanabhan</td><td>주임 엔지니어 관리자</td></tr><tr><td>Se Won Jang</td><td>주임 엔지니어 관리자</td></tr></tbody></table>
<h1>우리 Ray 인프라의 여정</h1>
<p>저희 블로그 시리즈의 제1부에서는 Ray에 투자하여 비즈니스의 핵심적인 문제를 해결하기 위해 동기부여를 받았던 이유에 대해 논의했습니다. 이 블로그 포스트에서는 Pinterest와 같은 웹 규모 회사에 Ray를 통합하는 데 필요한 단계에 대해 더 자세히 설명하겠습니다. 우리는 새로운 기술을 받아들이기 위해 다양한 고유한 제약 조건과 도전에 직면한 Pinterest와 같은 기업에 Ray를 통합하는 데 필요한 것들을 논의할 것입니다. 이는 Ray 인프라 부분에 대한 더 포괄적인 버전으로, 우리가 Ray 설명에서 발표한 Last Mile Data Processing for ML Training using Ray in Ray Summit 2023의 일환입니다.</p>
<p>저희의 사용 사례에서 KubeRay가 제공하는 Ray 클러스터를 프로비저닝할 수 있는 능력이 Ray 인프라를 성숙화하는 일의 일부일 뿐입니다. 회사들은 Ray 및 다른 특정 요구사항을 준수해야 하며, 이는 로그, 메트릭 지속성, 네트워크 격리, 최적의 하드웨어 인스턴스 식별, 보안, 트래픽 설정 및 기타 내부 서비스 통합을 포함한 모든 다른 모베스트 관행을 따라야 합니다.</p>
<div class="content-ad"></div>
<p>2023년에 여정이 시작되었어요. 전문 엔지니어 한 명이 이 프로젝트에 50%의 시간을 투자했어요:</p>
<ul>
<li>2023년 1분기: Anyscale 파트너의 지원을 받아 프로토타이핑 단계가 시작되었어요</li>
<li>2023년 2분기: Ray Infra MVP가 완료되었고, 시스템 로깅, 메트릭, UI, 및 애플리케이션을 위한 CLI와 같은 필수 도구들이 반복되고 향상되었어요</li>
<li>2023년 3분기: 첫 번째 프로덕션 유즈 케이스에 중점을 두어 내부 시스템을 통합하여 서비스 안정성을 향상시켰어요</li>
<li>2023년 4분기: 프로덕션 준비에 중점을 두어 보안 문제 대응, 네트워크 안정성 향상, Ray-optimized Kubernetes 환경으로의 전환 평가가 진행되었어요</li>
</ul>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_0.png" alt="이미지"></p>
<h1>직면한 도전들</h1>
<div class="content-ad"></div>
<p>핀터레스트에서 Ray 인프라를 구축할 때 몇 가지 중요한 도전 과제가 발생했습니다. 이러한 도전 과제를 해결해야 했습니다:</p>
<ul>
<li>K8s API 접근 제한: 핀터레스트의 일반 목적의 연합 Kubernetes 클러스터인 PinCompute에서 작동 중이었기 때문에 KubeRay와 같은 필수 오퍼레이터와 해당 사용자 정의 정의를 설치하는 것이 제한되었습니다.</li>
<li>일시적인 로깅 및 메트릭: Ray 클러스터가 활성 상태인 경우 Ray 대시보드를 통해 로깅과 메트릭을 확인할 수 있었지만, 리소스 집약적인 Ray 클러스터를 디버깅 목적으로 유지하는 것은 현실적이지 않았습니다. Ray 작업 부하의 수명 주기를 영속화하고 다시 재생하는 해결책을 찾았습니다.</li>
<li>메트릭 통합: 회사는 프로메테우스와 그라파나와 같은 인기 있는 오픈 소스 솔루션과 달리 자체의 시계열 데이터베이스와 시각화 도구를 보유하고 있었습니다.</li>
<li>인증, 권한 부여, 감사 (AAA) 가이드라인: 회사 표준에 따라 K8s에서 실행되는 서비스에 AAA를 보장해야 했고, 핀터레스트에서 AAA를 빌드하기 위해 Envoy를 서비스 메시로 사용하는 것이 권장되었습니다.</li>
<li>다양한 개발 환경: Jupyter와 CLI 액세스와 같은 상호 작용하는 옵션과 다양한 개발자 요구를 충족하기 위해 Dev 서버에서 CLI 액세스와 같은 다양한 개발 경험이 구축되었습니다.</li>
<li>비용 최적화 및 자원 낭비: 유휴 상태의 Ray 클러스터는 상당한 비용이 발생할 수 있습니다. 팀의 인식을 높이고 자원 낭비를 줄이기 위해 가비지 컬렉션 정책과 비용 할당이 필요했습니다.</li>
<li>오프라인 데이터 분석: 오프라인 분석을 위해 모든 Ray 클러스터 관련 메트릭을 대규모 데이터 형식 (예: 하이브, 파케)으로 내보내는 것이 우선되었습니다. 이 데이터에는 GPU 활용률과 같은 메트릭이 포함되어 있어 개선 영역을 식별하고 응용 프로그램 및 인프라의 안정성을 시간 경과에 따라 추적할 수 있습니다.</li>
</ul>
<h2>쿠버네티스 기반</h2>
<p>K8s API 액세스 제한으로 인해 우리 환경에 KubeRay를 쉽게 설치할 수 없어 K8s에서 Ray 클러스터를 운영하기 어려웠습니다. 또한, 핀터레스트 K8s 클러스터 내에서 비밀 관리, 트래픽 처리 및 로그 회전과 같은 작업을 위해 다른 팀에서 관리되는 특정 사이드카가 필요했습니다. 버그 수정이나 보안 패치와 같은 필수 사이드카 업데이트를 중앙 제어하기 위해 특정 제한 사항에 따라 준수해야 했습니다.</p>
<div class="content-ad"></div>
<p>Ray 클러스터에 필요한 필수 구성 요소를 프로토타입으로 만드는 중입니다(On-Premise Cluster 가이드에서 설명된 대로), 필요한 사이드카를 통합하기 위해 Pinterest 특정 CRD를 사용하기로 결정했습니다. 이는 오픈 소스 Kubeflow PyTorchJob 위에 구축된 래퍼입니다.</p>
<p>최초 반복에서는 Ray 헤드 및 Ray worker를 클라이언트 측에서 만들어 간단하게 유지하기로 하였습니다. 각 구성 요소에 대해 다른 명령을 사용하고 클라이언트 측에서 실행될 사용자 정의 스크립트를 작성하는 것을 포함했습니다.</p>
<pre><code class="hljs language-js">def <span class="hljs-title function_">launch_ray_cluster</span>(<span class="hljs-attr">configs</span>: <span class="hljs-title class_">RayClusterConfig</span>) -> <span class="hljs-attr">str</span>:
    # resources, instance_type, command, envs_vars 등 정의
    configs = <span class="hljs-title class_">RayClusterAndJobConfigs</span>()
    <span class="hljs-keyword">with</span> <span class="hljs-title class_">ThreadPoolExecutor</span>() <span class="hljs-keyword">as</span> <span class="hljs-attr">executor</span>:  
        # 함수를 실행자에 제출
        ray_head = executor.<span class="hljs-title function_">submit</span>(<span class="hljs-title function_">launch_ray_head</span>(configs)).<span class="hljs-title function_">result</span>()
        ray_workers = executor.<span class="hljs-title function_">submit</span>(<span class="hljs-title function_">launch_ray_workers</span>(configs).<span class="hljs-title function_">result</span>()
    <span class="hljs-keyword">return</span> <span class="hljs-title function_">check_up_and_running</span>(ray_head, ray_workers)
</code></pre>
<p>이 단계에는 개선할 여지가 많이 있습니다. 주요 단점은 클라이언트 측 실행이 네트워크 오류나 만료된 자격 증명과 같은 다양한 이유로 중단될 수 있어 K8s에서 자원을 낭비하는 좀비 Ray 클러스터가 발생할 수 있다는 것입니다. 이 접근 방식은 Ray 사용자들이 Ray에서 놀 수 있도록 막는 데 충분하지만 Ray 클러스터를 효율적으로 관리하기 위해 설계된 플랫폼에 적합하지는 않습니다.</p>
<div class="content-ad"></div>
<h1>API Gateway &#x26; Controller</h1>
<p>두 번째 반복에서는 클라이언트 측에서 Ray 클러스터를 관리하는 방식에서 KubeRay와 유사한 컨트롤러를 개발하여 서버 측 접근 방식으로 전환되었습니다. 우리의 솔루션은 사용자와 K8s 사이에 중간 계층을 생성하여 API 서버, Ray 클러스터/작업 컨트롤러 및 MySQL 데이터베이스로 구성된 여러 구성 요소를 포함했습니다.</p>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_1.png" alt="이미지"></p>
<ul>
<li>API 서버: 이 구성 요소는 요청 유효성 검사, 인증 및 권한 부여를 용이하게 합니다. 클라이언트 측에서 K8s의 복잡성을 추상화하여 사용자가 플랫폼 API 인터페이스와 상호 작용할 수 있도록 하며, 특히 나중 섹션에서 TLS 관련 구현을 강화하는 데 특히 유용합니다.</li>
<li>MySQL 데이터베이스: 데이터베이스는 Ray 클러스터와 관련된 상태 정보를 저장하여 K8s 측에서 필요한 일시적 상태를 다시 생성할 수 있게 합니다. 또한 API 서버와 Ray 클러스터 컨트롤러 간의 데이터 흐름을 분리하고 오프라인 분석을 위해 Hive로 데이터 덤프를 수행하는 추가 혜택이 있습니다.</li>
<li>Ray 클러스터 컨트롤러: 이 구성 요소는 Ray 클러스터의 수명 주기 관리를 위해 K8s를 지속적으로 쿼리합니다. Ray 헤드 및 워커 노드 프로비저닝, Ray 클러스터 상태 모니터링 및 필요에 따른 정리 작업을 수행하는 역할을 합니다.</li>
<li>Ray 작업 컨트롤러: Ray 클러스터 컨트롤러와 유사하게, Ray 작업 컨트롤러는 Ray 작업 수명 주기 관리에 초점을 맞춥니다. RayJobs를 제출하기 위한 주요 엔티티로 작용하여 시스템 내에서 적절한 인증 및 권한 부여 프로토콜을 보장합니다. 또한 컨트롤러는 동일한 Ray 클러스터에 여러 Ray 작업을 제출할 수 있도록 지원함으로써 사용자가 각 작업 제출마다 새 Ray 클러스터 프로비저닝을 기다릴 필요 없이 더 효율적으로 반복할 수 있도록 합니다.</li>
</ul>
<div class="content-ad"></div>
<p>여기는 테이블 태그를 마크다운 형식으로 변경한 것입니다.</p>
<p>이 방식은 사용자와 Kubernetes 사이에 가치 있는 추상화 계층을 제공하여 사용자가 복잡한 Kubernetes 자산을 이해할 필요가 없게 합니다. 대신, 플랫폼에서 제공하는 사용자 대면 라이브러리를 활용할 수 있습니다. 클라이언트 측에서 프로비저닝 단계의 부담을 옮기면 프로세스가 간소화되어 단계가 단순화되고 전반적인 사용자 경험이 향상됩니다.</p>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_2.png" alt="이미지"></p>
<p>우리 자체 컨트롤러를 구현하는 동안, 우리는 모듈화를 보장하여 나중에 KubeRay로의 원활한 전환을 가능하게 했습니다. 이 방식은 Ray 클러스터를 시작하는 데 사용되는 방법을 손쉽게 바꿀 수 있어, 내부 Kubernetes 기본 도구에서 KubeRay로의 전환이 원활하게 이루어집니다.</p>
<pre><code class="hljs language-python">Class Controller:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reconcile</span>(<span class="hljs-params">self, ray_cluster: RayClusterRecord</span>):
        <span class="hljs-comment"># 이 부분은 내부 기본 도구에서 KubeRay로 교체 가능합니다.</span>
        status, k8s_meta = self.launch_and_monitor_ray_cluster(ray_cluster.configs)
        db.update(ray_cluster, status=status, k8s_meta=k8s_meta)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):
        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
            ray_clusters = db.get_ray_cluster_to_dispatch()
            <span class="hljs-keyword">for</span> ray_cluster <span class="hljs-keyword">in</span> ray_clusters:
                self.reconcile(ray_cluster)
            sleep(<span class="hljs-number">1</span>)
   
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">launch_and_monitor_ray_cluster</span>(<span class="hljs-params">self, configs</span>) -> <span class="hljs-type">Tuple</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Dict</span>]:
        <span class="hljs-keyword">return</span> get_actual_k8s_related_status(ray_identifier=configs.ray_identifier)
</code></pre>
<div class="content-ad"></div>
<p>가능한 한 Observable성을 고려해보세요. Ray 클러스터의 기존 Ray 대시보드는 클러스터가 활성화된 상태에서만 접근할 수 있고 로그 또는 메트릭 재생을 위한 기능이 없습니다. 따라서 우리는 지속적인 로깅 및 메트릭 기능을 통합하는 전용 사용자 인터페이스를 개발하기로 결정했습니다. 이 사용자 인터페이스는 이전에 구축한 API Gateway에 의해 지원되며, 실시간으로 Ray 클러스터 및 Ray 작업 상태에 대한 통찰력을 제공합니다. 모든 메타데이터, 이벤트 및 로그는 데이터베이스 또는 S3에 저장되므로 이 전략은 Ray 클러스터를 유지하지 않고도 로그 분석을 가능하게 함으로써 GPU와 같은 유휴 리소스로 인한 비용을 완화할 수 있습니다.</p>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_3.png" alt="image"></p>
<p>다양한 회사들이 자체 시계열 메트릭 솔루션을 가지고 있다는 것은 사실일 것입니다. Pinterest에서는 Goku라는 자체 시계열 데이터베이스를 활용하고 있으며, 이는 OpenTSDB와 호환되는 API를 가지고 있습니다. 우리는 prometheus 메트릭을 스크랩하고 내부 시스템과 호환되도록 재구성하는 추가 사이드카를 실행하고 있습니다. 로깅에 관해서는 Ray의 권고사항을 따라 로그를 AWS S3에 지속 저장하고 있습니다. 이러한 로그는 API 서버에서 소비되어 Ray 클러스터 UI에 표시됩니다.</p>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_4.png">
<h2>Ray Application Stats</h2>
<p>동일한 Grafana 차트를 회사 내 시각화 도구인 Statsboard로 번역했습니다. 또한 Pinterest의 ML 엔지니어에게 유용한 dcgm GPU 메트릭 및 dataloader 메트릭과 같은 더 많은 애플리케이션별 기능을 추가했습니다. 이를 통해 Ray 애플리케이션의 병목 현상과 문제를 식별할 수 있습니다.</p>
<img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_5.png">
<div class="content-ad"></div>
<h2>Ray Infrastructure Stats</h2>
<p>인프라 수준의 모든 메트릭을 모니터링하는 것은 효과적인 모니터링 구현, 알림 생성, 그리고 역사적 데이터를 기반으로 한 SLO/SLA 벤치마킹을 설정하는 데 중요합니다. 예를 들어, 레이 클러스터 대기 시간의 종단 간 추적 및 레이 작업의 롤링 성공률 모니터링은 시스템 성능을 평가하고 유지하는 데 중요합니다. 또한, 레이 클러스터 프로비저닝 실패로 이어질 수 있는 플랫폼 측의 오류를 식별하는 것은 운영 효율을 유지하는 데 중요합니다.</p>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_6.png" alt="Ray Infrastructure"></p>
<h1>개발 및 운영 인터페이스</h1>
<div class="content-ad"></div>
<p>핀터레스트에서 Ray 애플리케이션을 개발하는 세 가지 옵션을 제공합니다. Dev 서버, 주피터, Spinner 워크플로우가 있습니다. 모든 옵션은 ML 플랫폼의 RESTful API를 사용하여 구동됩니다.</p>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_7.png" alt="이미지"></p>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_8.png" alt="이미지"></p>
<p>Airflow에서 PythonOperator를 활용하여 사용자가 작업 구성을 제공하고, 우리는 그것을 MLP 서버로 향하는 RayJob 요청으로 변환하는 사용자 정의 연산자를 구성합니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_9.png" alt="이미지"></p>
<h1>테스트</h1>
<p>유닛 테스트 및 통합 테스트</p>
<p>레이 애플리케이션을 개발할 때 이용할 수 있는 두 가지 유형의 테스트를 제공합니다:</p>
<div class="content-ad"></div>
<ul>
<li>Unittest을 사용하는 것을 권장하는 것은 하위 수준 Ray 코어나 Ray 데이터 라이브러리를 활용하는 플랫폼 라이브러리 소유자들에게 좋습니다. 통합 테스트가 적합합니다. Ray 프로그램을 테스트하는 팁을 따르고 동일한 테스트 스위트 내에서 ray 클러스터를 가능한 한 많이 재사용하기 위해 pytest fixtures를 사용합니다.</li>
<li>완전한 Ray 작업을 실행하여 코드 변경이나 라이브러리 업데이트로 인해 발생할 수 있는 잘못된 부분을 식별하고 해결하려는 사용자들에게는 통합 테스트가 적합합니다. 비즈니스에 중요한 Ray 응용 프로그램의 건강 상태를 주기적으로 모니터링하기 위해 통합 테스트도 실행합니다.</li>
</ul>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_10.png" alt="Ray Infrastructure at Pinterest"></p>
<h2>네트워크 및 보안</h2>
<p>Ray는 컴퓨팅 플랫폼으로 개발자가 API를 통해 쉽게 워크로드를 실행할 수 있는 유연성을 제공하지만, 이는 보안 취약점(CVE-2023-48022)으로 이어질 수 있습니다. Shadowray 기사에서 강조하는 것과 같이 Ray 자체가 적절한 인증 및 권한 부여 방법을 제공하지 않기 때문에 Ray 대시보드 API에 액세스 권한이 있는 모든 사용자가 유효성 검사나 제어 없이 원격으로 코드를 실행할 수 있습니다.</p>
<div class="content-ad"></div>
<p>핀터레스트에서는 이 보안 문제를 심각하게 취급하고 적절히 대응했습니다. 우리는 레이 클러스터에 올바른 인증 및 권한 부여가 적용되어야 한다는 것을 확실히 하기 위해 한 발 더 나아갔습니다. 따라서 사용자가 적절한 권한을 갖고 있지 않은 경우 해당 Ray 클러스터를 사용할 수 없도록 했습니다.</p>
<p>그러나 이 문제의 복잡성은 핀터레스트의 연방 쿠버네티스 클러스터 아키텍처로 인해 더욱 악화되었는데, 이는 군집 간 기능을 군집 내 환경에 적용하는 데 어려움을 겪게 했습니다. 예를 들어 K8s 클러스터 간의 입력 및 출력 흐름을 제어하기 위해 NetworkPolicy를 사용할 수 없기 때문에, 하드웨어 가용성을 극대화하기 위해 Pod가 K8s 클러스터 전체에 흩어질 수 있는 경우, 네트워크 격리를 실현하기 위한 대안적인 방법이 필요합니다.</p>
<ul>
<li>HTTP: 핀터레스트에서는 쿠버네티스 환경에서 서비스 메쉬로 Envoy를 사용합니다. 레이 대시보드를 Envoy 뒤의 localhost에 배포하고 핀터레스트에서의 인증 및 권한 부여 표준 방식을 따릅니다. 이를 통해 UI에서 사용자를 위한 OAuth 또는 서비스를 위한 mTLS로 레이 대시보드에 액세스 범위를 제한할 수 있습니다.</li>
</ul>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_11.png" alt="이미지"></p>
<div class="content-ad"></div>
<ol start="2">
<li>gRPC: K8s 환경에서 임의의 Pod이 활성 상태의 Ray Cluster에 연결하는 것을 방지하기 위해, Ray 클러스터 부트스트랩 시에 Ray TLS를 일부 사용자 정의와 함께 이용합니다. 자세히 말하면, 각 Ray 클러스터마다 고유한 쌍(개인 키, 인증서) 인증서 기관(CA)를 생성합니다. 이를 통해 CA와 특정 Ray 클러스터 간에 1:1 매핑을 보장합니다. 상호 인증의 첫 번째 단계는 클라이언트(Ray Pods)의 접근을 해당 CA로 제한하여 서버 측에서 적절한 AuthN / AuthZ로 수행함으로써 완료됩니다. 이렇게 함으로써 특정 Ray 클러스터를 나타내는 해당 CA에 의해 서명된 인증서를 수령할 수 있는 Pod의 하위 집합만 이를 수행할 수 있습니다. 두 번째 단계는 발급된 인증서를 사용하여 통신하는 Pod들이 예상된 Ray 클러스터에 해당하는 CA에 의해 서명되었는지 확인하는 것입니다. 게다가, Ray Pods에 대한 잎 인증서의 서명 및 발급에 대한 모든 암호화 작업은 클라이언트, 즉 Ray head 및 worker pods이 CA 개인 키에 액세스할 수 없도록 서버 측(MLP 서버)에서 수행되어야 합니다.</li>
</ol>
<p><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_12.png" alt="이미지"></p>
<h1>교훈</h1>
<p>점진적 개선:</p>
<div class="content-ad"></div>
<ul>
<li>단순한 방식으로 Ray 클러스터를 배포한 후에는 프로덕션 환경이나 클라우드 환경에서 자동화 및 확장 프로세스에 초점을 맞추세요.</li>
<li>MVP 개발 시 휠을 재발명할 필요를 최소화하기 위해 회사의 기존 인프라를 활용하세요. 저희는 Kubeflow 오퍼레이터를 활용하며 기존의 ML 특화 인프라 논리는 개발 프로세스를 간소화할 수 있습니다.</li>
<li>프로토 타입이 완료된 후 회사 전체의 최고 권고 사항에 따라 보안 문제 및 다른 규정 준수 문제 등 인프라를 개선하세요.</li>
<li>고객과 정기적으로 회의를 진행하여 도전 과제 및 개선 영역에 대한 초기 피드백을 수집하세요.</li>
<li>Pinterest의 Ray 이니셔티브의 현재 성공을 고려할 때, ML 전용 K8s 클러스터로 이동할 때 KubeRay 통합과 같은 더 많은 개선 사항을 찾고 있습니다.</li>
</ul>
<p>클라이언트와 Kubernetes 클러스터 사이의 중간 계층:</p>
<ul>
<li>API 서버는 클라이언트와 Kubernetes 간의 다리 역할을 하는 추상화 계층을 제공합니다.</li>
<li>Ray 클러스터의 생애 주기 이벤트가 Kubernetes에서 사용자 정의 리소스가 제거된 후에도 지속적으로 기록되도록 보장하세요.</li>
<li>플랫폼은 비즈니스 로직, 즉 추가 유효성 검사 및 사용자 인증, 인가, 사용자를 위한 Ray 대시보드 API 액세스 제한과 같은 사용자 지정을 구현할 수 있는 기회가 있습니다.</li>
<li>Ray 클러스터를 제공하는 실제 방법을 분리함으로써 KubeRay 및 전용 K8s 클러스터로 전환하는 것이 훨씬 쉬워지며 앞으로 계획하는 것과 같이 필요에 따라 다른 노드 제공자로 전환할 수 있습니다.</li>
</ul>
<div class="content-ad"></div>
<ul>
<li>사용자에게 충분한 인프라 관련 정보를 제공하지 않으면 Ray 클러스터 프로비저닝의 실패 또는 지연과 관련된 혼란이 발생할 수 있습니다.</li>
<li>동시에 수십 개 또는 수백 개의 Ray 클러스터를 운영하려면 플랫폼 측에서 모니터링 및 경보가 중요합니다. Ray 인프라의 초기 단계에 있으며 신속한 변화로 애플리케이션 측에 장애가 발생할 수 있으므로 경보 설정에 성실해야 하며 프로덕션 환경으로 배포하기 전에 스테이징 환경에서 철저한 테스트를 수행해야 합니다.</li>
</ul>
<h1>사용법</h1>
<p>우리는 2023년 2분기부터 Ray 인프라 사용량을 수집하기 시작했고, 지난 마일스톤 데이터 처리 응용 프로그램 GA 및 추가 사용자들이 Ray 프레임워크에 참여하면서 2023년 4분기에 급증을 관찰했습니다. 우리는 현재 배치 추론 및 adhoc Ray Serve 개발과 같은 다양한 Ray 응용 프로그램을 탐색하기 위해 Ray 기반으로 이전한 사용자들에게 도움을 주고 있습니다. 우리는 아직 네이티브 PyTorch 기반 애플리케이션에서 Ray 기반 애플리케이션으로 이동하는 초기 단계에 있으나, 더 고급화된 사용 사례로 전환하기 위해 고객들과 열심히 협력하고 있습니다.</p>
<img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_13.png">
<div class="content-ad"></div>
<p>아래는 Markdown 형식으로 표로 변환하였습니다.</p>

















<table><thead><tr><th align="center">파일</th><th align="center">이미지</th></tr></thead><tbody><tr><td align="center">2024-06-19-RayInfrastructureatPinterest_14.png</td><td align="center"><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_14.png"></td></tr><tr><td align="center">2024-06-19-RayInfrastructureatPinterest_15.png</td><td align="center"><img src="/assets/img/2024-06-19-RayInfrastructureatPinterest_15.png"></td></tr></tbody></table>
<h1>사용 사례</h1>
<p>Ray 인프라는 제품 ML 사용 사례에 대해 배포되었으며 새로운 응용 프로그램의 신속한 실험을 위해 사용되었습니다.</p>
<div class="content-ad"></div>
<h2>Ray Train</h2>
<ul>
<li>여러 추천 시스템 모델 교육이 Ray로 이관되었으며, 나머지 사용 사례를 적극적으로 도입 중입니다.</li>
<li>현재 Ray를 사용하여 매월 5000개 이상의 교육 작업을 실행 중입니다.</li>
<li>이러한 교육 실행은 이질적인 CPU / GPU 클러스터를 활용합니다.</li>
</ul>
<h2>핵심 이점:</h2>
<p>확장성:</p>
<div class="content-ad"></div>
<ul>
<li>Ray는 교육 실행을 가능한 서로 다른 교육기 인스턴스를 넘어 데이터 로딩 및 전처리를 확장할 수 있도록 합니다.</li>
<li>p4d.24xlarge와 같은 단일 GPU 노드는 고정된 12:1 CPU:GPU 비율을 가지고 있어 데이터 로더를 확장하고 GPU를 포화시키는 것을 방해합니다.</li>
<li>Ray를 사용하면 p4d 인스턴스 외부에서 데이터 로더를 확장할 수 있습니다. 이는 CPU만 있는 인스턴스를 사용하여 더 저렴하게 처리할 수 있습니다.</li>
</ul>
<p>Dev-velocity</p>
<ul>
<li>확장성 이외에도 Ray는 개발 속도를 크게 높일 수 있습니다.</li>
<li>머신 러닝 엔지니어들의 일상적인 작업 중 상당 부분은 모델 변경을 구현하고 로컬 코드를 사용하여 개발 훈련을 실행하는 것입니다.</li>
<li>Ray를 사용하면 Ray 컴퓨팅 클러스터를 상호작용적으로 사용하여 주피터 노트북을 통해 작업을 제출할 수 있습니다.</li>
</ul>
<h2>일괄 추론</h2>
<div class="content-ad"></div>
<ul>
<li>Pinterest는 과거 PySpark 기반의 일괄 추론 솔루션을 활용했습니다.</li>
<li>Ray를 사용하여, ray.data.Dataset에서 map_batches 구현으로 설계된 새 BatchInference 솔루션을 재구현했습니다.</li>
<li>우리는 현재 이 솔루션을 세 가지 프로덕션 유즈 케이스에 사용하고 있습니다.</li>
<li>현재 우리는 Ray를 사용하여 매달 300개 이상의 일괄 추론 작업을 실행 중입니다.</li>
</ul>
<h2>핵심 이점:</h2>
<p>효율성:</p>
<ul>
<li>이전 구현과는 달리, Ray는 전처리, GPU 추론 및 출력 파일 쓰기의 파이프라이닝을 가능케 합니다.</li>
<li>더불어, 자동으로 이 세 단계를 이종 CPU 및 GPU 노드에서 실행할 수 있게 분리할 수 있습니다.</li>
<li>이들을 합쳐, 우리의 프로덕션 GPU 추론 작업의 작업 실행 시간이 4배 감소했습니다 (1시간 → 15분).</li>
</ul>
<div class="content-ad"></div>
<p>Unlocked Opportunity:</p>
<ul>
<li>Ray와 함께 프로그래밍하는 쉬움과 파이프라이닝으로 얻는 효율성 덕분에 GPU 기반 모델에 대한 특성 소거 도구를 채택할 수 있었습니다.</li>
</ul>
<h2>실험적 워크로드</h2>
<ul>
<li>Ray는 Ray Serve를 포함한 다양한 도구 생태계를 제공합니다.</li>
<li>Ray Serve는 모델 서빙을 위한 내장된 라우팅 및 자동 스케일링 기능을 제공하며, 모델을 빠르게 평가하기 위해 매우 편리합니다.</li>
<li>Ray Serve가 없는 경우 클라이언트는 RPC 서버, 배포 파이프라인, 서비스 검색 및 자동 스케일링을 수동으로 설정해야 합니다.</li>
</ul>
<div class="content-ad"></div>
<h2>주요 성과:</h2>
<ul>
<li>내부 해커톤에서 팀이 몇 시간 만에 오픈 소스 대규모 모델을 설정하고 사용할 수 있었습니다.</li>
<li>Ray가 없었다면 이러한 인프라를 구축하는 데 몇 일에서 몇 주가 걸렸을 것입니다.</li>
</ul>
<h1>다음 계획</h1>
<ul>
<li>Pinterest에서 Ray Batch Inference에 대해 깊이 파고들기</li>
<li>Pinterest에서 Ray Tune</li>
<li>Pinterest에서 Ray 어플리케이션의 독특한 도전 현황</li>
</ul>
<div class="content-ad"></div>
<h1>인사말</h1>
<p>Cloud Runtime Team: Jiajun Wang, Harry Zhang</p>
<p>Traffic Team: James Fish, Bruno Palermo, Kuo-Chung Hsu</p>
<p>Security Team: Jeremy Krach, Cedric Staub</p>
<div class="content-ad"></div>
<p>ML 플랫폼: Qingxian Lai, Lei Pan</p>
<p>Anyscale: Zhe Zhang, Kai-Hsun Chen, SangBin Cho</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Pinterest의 Ray 인프라","description":"","date":"2024-06-19 03:39","slug":"2024-06-19-RayInfrastructureatPinterest","content":"\n\n| 이름 | 직급 |  \n| --- | --- |  \n| Chia-Wei Chen | 주임 소프트웨어 엔지니어 |  \n| Raymond Lee | 주임 소프트웨어 엔지니어 |  \n| Alex Wang | 소프트웨어 엔지니어 I |  \n| Saurabh Vishwas Joshi | 주임 스태프 소프트웨어 엔지니어 |  \n| Karthik Anantha Padmanabhan | 주임 엔지니어 관리자 |  \n| Se Won Jang | 주임 엔지니어 관리자 |  \n\n# 우리 Ray 인프라의 여정\n\n저희 블로그 시리즈의 제1부에서는 Ray에 투자하여 비즈니스의 핵심적인 문제를 해결하기 위해 동기부여를 받았던 이유에 대해 논의했습니다. 이 블로그 포스트에서는 Pinterest와 같은 웹 규모 회사에 Ray를 통합하는 데 필요한 단계에 대해 더 자세히 설명하겠습니다. 우리는 새로운 기술을 받아들이기 위해 다양한 고유한 제약 조건과 도전에 직면한 Pinterest와 같은 기업에 Ray를 통합하는 데 필요한 것들을 논의할 것입니다. 이는 Ray 인프라 부분에 대한 더 포괄적인 버전으로, 우리가 Ray 설명에서 발표한 Last Mile Data Processing for ML Training using Ray in Ray Summit 2023의 일환입니다.\n\n저희의 사용 사례에서 KubeRay가 제공하는 Ray 클러스터를 프로비저닝할 수 있는 능력이 Ray 인프라를 성숙화하는 일의 일부일 뿐입니다. 회사들은 Ray 및 다른 특정 요구사항을 준수해야 하며, 이는 로그, 메트릭 지속성, 네트워크 격리, 최적의 하드웨어 인스턴스 식별, 보안, 트래픽 설정 및 기타 내부 서비스 통합을 포함한 모든 다른 모베스트 관행을 따라야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2023년에 여정이 시작되었어요. 전문 엔지니어 한 명이 이 프로젝트에 50%의 시간을 투자했어요:\n\n- 2023년 1분기: Anyscale 파트너의 지원을 받아 프로토타이핑 단계가 시작되었어요\n- 2023년 2분기: Ray Infra MVP가 완료되었고, 시스템 로깅, 메트릭, UI, 및 애플리케이션을 위한 CLI와 같은 필수 도구들이 반복되고 향상되었어요\n- 2023년 3분기: 첫 번째 프로덕션 유즈 케이스에 중점을 두어 내부 시스템을 통합하여 서비스 안정성을 향상시켰어요\n- 2023년 4분기: 프로덕션 준비에 중점을 두어 보안 문제 대응, 네트워크 안정성 향상, Ray-optimized Kubernetes 환경으로의 전환 평가가 진행되었어요\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_0.png)\n\n# 직면한 도전들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n핀터레스트에서 Ray 인프라를 구축할 때 몇 가지 중요한 도전 과제가 발생했습니다. 이러한 도전 과제를 해결해야 했습니다:\n\n- K8s API 접근 제한: 핀터레스트의 일반 목적의 연합 Kubernetes 클러스터인 PinCompute에서 작동 중이었기 때문에 KubeRay와 같은 필수 오퍼레이터와 해당 사용자 정의 정의를 설치하는 것이 제한되었습니다.\n- 일시적인 로깅 및 메트릭: Ray 클러스터가 활성 상태인 경우 Ray 대시보드를 통해 로깅과 메트릭을 확인할 수 있었지만, 리소스 집약적인 Ray 클러스터를 디버깅 목적으로 유지하는 것은 현실적이지 않았습니다. Ray 작업 부하의 수명 주기를 영속화하고 다시 재생하는 해결책을 찾았습니다.\n- 메트릭 통합: 회사는 프로메테우스와 그라파나와 같은 인기 있는 오픈 소스 솔루션과 달리 자체의 시계열 데이터베이스와 시각화 도구를 보유하고 있었습니다.\n- 인증, 권한 부여, 감사 (AAA) 가이드라인: 회사 표준에 따라 K8s에서 실행되는 서비스에 AAA를 보장해야 했고, 핀터레스트에서 AAA를 빌드하기 위해 Envoy를 서비스 메시로 사용하는 것이 권장되었습니다.\n- 다양한 개발 환경: Jupyter와 CLI 액세스와 같은 상호 작용하는 옵션과 다양한 개발자 요구를 충족하기 위해 Dev 서버에서 CLI 액세스와 같은 다양한 개발 경험이 구축되었습니다.\n- 비용 최적화 및 자원 낭비: 유휴 상태의 Ray 클러스터는 상당한 비용이 발생할 수 있습니다. 팀의 인식을 높이고 자원 낭비를 줄이기 위해 가비지 컬렉션 정책과 비용 할당이 필요했습니다.\n- 오프라인 데이터 분석: 오프라인 분석을 위해 모든 Ray 클러스터 관련 메트릭을 대규모 데이터 형식 (예: 하이브, 파케)으로 내보내는 것이 우선되었습니다. 이 데이터에는 GPU 활용률과 같은 메트릭이 포함되어 있어 개선 영역을 식별하고 응용 프로그램 및 인프라의 안정성을 시간 경과에 따라 추적할 수 있습니다.\n\n## 쿠버네티스 기반\n\nK8s API 액세스 제한으로 인해 우리 환경에 KubeRay를 쉽게 설치할 수 없어 K8s에서 Ray 클러스터를 운영하기 어려웠습니다. 또한, 핀터레스트 K8s 클러스터 내에서 비밀 관리, 트래픽 처리 및 로그 회전과 같은 작업을 위해 다른 팀에서 관리되는 특정 사이드카가 필요했습니다. 버그 수정이나 보안 패치와 같은 필수 사이드카 업데이트를 중앙 제어하기 위해 특정 제한 사항에 따라 준수해야 했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRay 클러스터에 필요한 필수 구성 요소를 프로토타입으로 만드는 중입니다(On-Premise Cluster 가이드에서 설명된 대로), 필요한 사이드카를 통합하기 위해 Pinterest 특정 CRD를 사용하기로 결정했습니다. 이는 오픈 소스 Kubeflow PyTorchJob 위에 구축된 래퍼입니다.\n\n최초 반복에서는 Ray 헤드 및 Ray worker를 클라이언트 측에서 만들어 간단하게 유지하기로 하였습니다. 각 구성 요소에 대해 다른 명령을 사용하고 클라이언트 측에서 실행될 사용자 정의 스크립트를 작성하는 것을 포함했습니다.\n\n```js\ndef launch_ray_cluster(configs: RayClusterConfig) -\u003e str:\n    # resources, instance_type, command, envs_vars 등 정의\n    configs = RayClusterAndJobConfigs()\n    with ThreadPoolExecutor() as executor:  \n        # 함수를 실행자에 제출\n        ray_head = executor.submit(launch_ray_head(configs)).result()\n        ray_workers = executor.submit(launch_ray_workers(configs).result()\n    return check_up_and_running(ray_head, ray_workers)\n```\n\n이 단계에는 개선할 여지가 많이 있습니다. 주요 단점은 클라이언트 측 실행이 네트워크 오류나 만료된 자격 증명과 같은 다양한 이유로 중단될 수 있어 K8s에서 자원을 낭비하는 좀비 Ray 클러스터가 발생할 수 있다는 것입니다. 이 접근 방식은 Ray 사용자들이 Ray에서 놀 수 있도록 막는 데 충분하지만 Ray 클러스터를 효율적으로 관리하기 위해 설계된 플랫폼에 적합하지는 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# API Gateway \u0026 Controller\n\n두 번째 반복에서는 클라이언트 측에서 Ray 클러스터를 관리하는 방식에서 KubeRay와 유사한 컨트롤러를 개발하여 서버 측 접근 방식으로 전환되었습니다. 우리의 솔루션은 사용자와 K8s 사이에 중간 계층을 생성하여 API 서버, Ray 클러스터/작업 컨트롤러 및 MySQL 데이터베이스로 구성된 여러 구성 요소를 포함했습니다.\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_1.png)\n\n- API 서버: 이 구성 요소는 요청 유효성 검사, 인증 및 권한 부여를 용이하게 합니다. 클라이언트 측에서 K8s의 복잡성을 추상화하여 사용자가 플랫폼 API 인터페이스와 상호 작용할 수 있도록 하며, 특히 나중 섹션에서 TLS 관련 구현을 강화하는 데 특히 유용합니다.\n- MySQL 데이터베이스: 데이터베이스는 Ray 클러스터와 관련된 상태 정보를 저장하여 K8s 측에서 필요한 일시적 상태를 다시 생성할 수 있게 합니다. 또한 API 서버와 Ray 클러스터 컨트롤러 간의 데이터 흐름을 분리하고 오프라인 분석을 위해 Hive로 데이터 덤프를 수행하는 추가 혜택이 있습니다.\n- Ray 클러스터 컨트롤러: 이 구성 요소는 Ray 클러스터의 수명 주기 관리를 위해 K8s를 지속적으로 쿼리합니다. Ray 헤드 및 워커 노드 프로비저닝, Ray 클러스터 상태 모니터링 및 필요에 따른 정리 작업을 수행하는 역할을 합니다.\n- Ray 작업 컨트롤러: Ray 클러스터 컨트롤러와 유사하게, Ray 작업 컨트롤러는 Ray 작업 수명 주기 관리에 초점을 맞춥니다. RayJobs를 제출하기 위한 주요 엔티티로 작용하여 시스템 내에서 적절한 인증 및 권한 부여 프로토콜을 보장합니다. 또한 컨트롤러는 동일한 Ray 클러스터에 여러 Ray 작업을 제출할 수 있도록 지원함으로써 사용자가 각 작업 제출마다 새 Ray 클러스터 프로비저닝을 기다릴 필요 없이 더 효율적으로 반복할 수 있도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기는 테이블 태그를 마크다운 형식으로 변경한 것입니다.\n\n이 방식은 사용자와 Kubernetes 사이에 가치 있는 추상화 계층을 제공하여 사용자가 복잡한 Kubernetes 자산을 이해할 필요가 없게 합니다. 대신, 플랫폼에서 제공하는 사용자 대면 라이브러리를 활용할 수 있습니다. 클라이언트 측에서 프로비저닝 단계의 부담을 옮기면 프로세스가 간소화되어 단계가 단순화되고 전반적인 사용자 경험이 향상됩니다.\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_2.png)\n\n우리 자체 컨트롤러를 구현하는 동안, 우리는 모듈화를 보장하여 나중에 KubeRay로의 원활한 전환을 가능하게 했습니다. 이 방식은 Ray 클러스터를 시작하는 데 사용되는 방법을 손쉽게 바꿀 수 있어, 내부 Kubernetes 기본 도구에서 KubeRay로의 전환이 원활하게 이루어집니다.\n\n```python\nClass Controller:\n    def reconcile(self, ray_cluster: RayClusterRecord):\n        # 이 부분은 내부 기본 도구에서 KubeRay로 교체 가능합니다.\n        status, k8s_meta = self.launch_and_monitor_ray_cluster(ray_cluster.configs)\n        db.update(ray_cluster, status=status, k8s_meta=k8s_meta)\n\n    def run(self):\n        while True:\n            ray_clusters = db.get_ray_cluster_to_dispatch()\n            for ray_cluster in ray_clusters:\n                self.reconcile(ray_cluster)\n            sleep(1)\n   \n    def launch_and_monitor_ray_cluster(self, configs) -\u003e Tuple[str, Dict]:\n        return get_actual_k8s_related_status(ray_identifier=configs.ray_identifier)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가능한 한 Observable성을 고려해보세요. Ray 클러스터의 기존 Ray 대시보드는 클러스터가 활성화된 상태에서만 접근할 수 있고 로그 또는 메트릭 재생을 위한 기능이 없습니다. 따라서 우리는 지속적인 로깅 및 메트릭 기능을 통합하는 전용 사용자 인터페이스를 개발하기로 결정했습니다. 이 사용자 인터페이스는 이전에 구축한 API Gateway에 의해 지원되며, 실시간으로 Ray 클러스터 및 Ray 작업 상태에 대한 통찰력을 제공합니다. 모든 메타데이터, 이벤트 및 로그는 데이터베이스 또는 S3에 저장되므로 이 전략은 Ray 클러스터를 유지하지 않고도 로그 분석을 가능하게 함으로써 GPU와 같은 유휴 리소스로 인한 비용을 완화할 수 있습니다.\n\n![image](/assets/img/2024-06-19-RayInfrastructureatPinterest_3.png)\n\n다양한 회사들이 자체 시계열 메트릭 솔루션을 가지고 있다는 것은 사실일 것입니다. Pinterest에서는 Goku라는 자체 시계열 데이터베이스를 활용하고 있으며, 이는 OpenTSDB와 호환되는 API를 가지고 있습니다. 우리는 prometheus 메트릭을 스크랩하고 내부 시스템과 호환되도록 재구성하는 추가 사이드카를 실행하고 있습니다. 로깅에 관해서는 Ray의 권고사항을 따라 로그를 AWS S3에 지속 저장하고 있습니다. 이러한 로그는 API 서버에서 소비되어 Ray 클러스터 UI에 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_4.png\" /\u003e\n\n## Ray Application Stats\n\n동일한 Grafana 차트를 회사 내 시각화 도구인 Statsboard로 번역했습니다. 또한 Pinterest의 ML 엔지니어에게 유용한 dcgm GPU 메트릭 및 dataloader 메트릭과 같은 더 많은 애플리케이션별 기능을 추가했습니다. 이를 통해 Ray 애플리케이션의 병목 현상과 문제를 식별할 수 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_5.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Ray Infrastructure Stats\n\n인프라 수준의 모든 메트릭을 모니터링하는 것은 효과적인 모니터링 구현, 알림 생성, 그리고 역사적 데이터를 기반으로 한 SLO/SLA 벤치마킹을 설정하는 데 중요합니다. 예를 들어, 레이 클러스터 대기 시간의 종단 간 추적 및 레이 작업의 롤링 성공률 모니터링은 시스템 성능을 평가하고 유지하는 데 중요합니다. 또한, 레이 클러스터 프로비저닝 실패로 이어질 수 있는 플랫폼 측의 오류를 식별하는 것은 운영 효율을 유지하는 데 중요합니다.\n\n![Ray Infrastructure](/assets/img/2024-06-19-RayInfrastructureatPinterest_6.png)\n\n# 개발 및 운영 인터페이스\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n핀터레스트에서 Ray 애플리케이션을 개발하는 세 가지 옵션을 제공합니다. Dev 서버, 주피터, Spinner 워크플로우가 있습니다. 모든 옵션은 ML 플랫폼의 RESTful API를 사용하여 구동됩니다.\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_7.png)\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_8.png)\n\nAirflow에서 PythonOperator를 활용하여 사용자가 작업 구성을 제공하고, 우리는 그것을 MLP 서버로 향하는 RayJob 요청으로 변환하는 사용자 정의 연산자를 구성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_9.png)\n\n# 테스트\n\n유닛 테스트 및 통합 테스트\n\n레이 애플리케이션을 개발할 때 이용할 수 있는 두 가지 유형의 테스트를 제공합니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Unittest을 사용하는 것을 권장하는 것은 하위 수준 Ray 코어나 Ray 데이터 라이브러리를 활용하는 플랫폼 라이브러리 소유자들에게 좋습니다. 통합 테스트가 적합합니다. Ray 프로그램을 테스트하는 팁을 따르고 동일한 테스트 스위트 내에서 ray 클러스터를 가능한 한 많이 재사용하기 위해 pytest fixtures를 사용합니다.\n- 완전한 Ray 작업을 실행하여 코드 변경이나 라이브러리 업데이트로 인해 발생할 수 있는 잘못된 부분을 식별하고 해결하려는 사용자들에게는 통합 테스트가 적합합니다. 비즈니스에 중요한 Ray 응용 프로그램의 건강 상태를 주기적으로 모니터링하기 위해 통합 테스트도 실행합니다.\n\n![Ray Infrastructure at Pinterest](/assets/img/2024-06-19-RayInfrastructureatPinterest_10.png)\n\n## 네트워크 및 보안\n\nRay는 컴퓨팅 플랫폼으로 개발자가 API를 통해 쉽게 워크로드를 실행할 수 있는 유연성을 제공하지만, 이는 보안 취약점(CVE-2023-48022)으로 이어질 수 있습니다. Shadowray 기사에서 강조하는 것과 같이 Ray 자체가 적절한 인증 및 권한 부여 방법을 제공하지 않기 때문에 Ray 대시보드 API에 액세스 권한이 있는 모든 사용자가 유효성 검사나 제어 없이 원격으로 코드를 실행할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n핀터레스트에서는 이 보안 문제를 심각하게 취급하고 적절히 대응했습니다. 우리는 레이 클러스터에 올바른 인증 및 권한 부여가 적용되어야 한다는 것을 확실히 하기 위해 한 발 더 나아갔습니다. 따라서 사용자가 적절한 권한을 갖고 있지 않은 경우 해당 Ray 클러스터를 사용할 수 없도록 했습니다.\n\n그러나 이 문제의 복잡성은 핀터레스트의 연방 쿠버네티스 클러스터 아키텍처로 인해 더욱 악화되었는데, 이는 군집 간 기능을 군집 내 환경에 적용하는 데 어려움을 겪게 했습니다. 예를 들어 K8s 클러스터 간의 입력 및 출력 흐름을 제어하기 위해 NetworkPolicy를 사용할 수 없기 때문에, 하드웨어 가용성을 극대화하기 위해 Pod가 K8s 클러스터 전체에 흩어질 수 있는 경우, 네트워크 격리를 실현하기 위한 대안적인 방법이 필요합니다.\n\n- HTTP: 핀터레스트에서는 쿠버네티스 환경에서 서비스 메쉬로 Envoy를 사용합니다. 레이 대시보드를 Envoy 뒤의 localhost에 배포하고 핀터레스트에서의 인증 및 권한 부여 표준 방식을 따릅니다. 이를 통해 UI에서 사용자를 위한 OAuth 또는 서비스를 위한 mTLS로 레이 대시보드에 액세스 범위를 제한할 수 있습니다.\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. gRPC: K8s 환경에서 임의의 Pod이 활성 상태의 Ray Cluster에 연결하는 것을 방지하기 위해, Ray 클러스터 부트스트랩 시에 Ray TLS를 일부 사용자 정의와 함께 이용합니다. 자세히 말하면, 각 Ray 클러스터마다 고유한 쌍(개인 키, 인증서) 인증서 기관(CA)를 생성합니다. 이를 통해 CA와 특정 Ray 클러스터 간에 1:1 매핑을 보장합니다. 상호 인증의 첫 번째 단계는 클라이언트(Ray Pods)의 접근을 해당 CA로 제한하여 서버 측에서 적절한 AuthN / AuthZ로 수행함으로써 완료됩니다. 이렇게 함으로써 특정 Ray 클러스터를 나타내는 해당 CA에 의해 서명된 인증서를 수령할 수 있는 Pod의 하위 집합만 이를 수행할 수 있습니다. 두 번째 단계는 발급된 인증서를 사용하여 통신하는 Pod들이 예상된 Ray 클러스터에 해당하는 CA에 의해 서명되었는지 확인하는 것입니다. 게다가, Ray Pods에 대한 잎 인증서의 서명 및 발급에 대한 모든 암호화 작업은 클라이언트, 즉 Ray head 및 worker pods이 CA 개인 키에 액세스할 수 없도록 서버 측(MLP 서버)에서 수행되어야 합니다.\n\n![이미지](/assets/img/2024-06-19-RayInfrastructureatPinterest_12.png)\n\n# 교훈\n\n점진적 개선:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n-  단순한 방식으로 Ray 클러스터를 배포한 후에는 프로덕션 환경이나 클라우드 환경에서 자동화 및 확장 프로세스에 초점을 맞추세요.\n- MVP 개발 시 휠을 재발명할 필요를 최소화하기 위해 회사의 기존 인프라를 활용하세요. 저희는 Kubeflow 오퍼레이터를 활용하며 기존의 ML 특화 인프라 논리는 개발 프로세스를 간소화할 수 있습니다.\n- 프로토 타입이 완료된 후 회사 전체의 최고 권고 사항에 따라 보안 문제 및 다른 규정 준수 문제 등 인프라를 개선하세요.\n- 고객과 정기적으로 회의를 진행하여 도전 과제 및 개선 영역에 대한 초기 피드백을 수집하세요.\n- Pinterest의 Ray 이니셔티브의 현재 성공을 고려할 때, ML 전용 K8s 클러스터로 이동할 때 KubeRay 통합과 같은 더 많은 개선 사항을 찾고 있습니다.\n\n클라이언트와 Kubernetes 클러스터 사이의 중간 계층:\n\n- API 서버는 클라이언트와 Kubernetes 간의 다리 역할을 하는 추상화 계층을 제공합니다.\n- Ray 클러스터의 생애 주기 이벤트가 Kubernetes에서 사용자 정의 리소스가 제거된 후에도 지속적으로 기록되도록 보장하세요.\n- 플랫폼은 비즈니스 로직, 즉 추가 유효성 검사 및 사용자 인증, 인가, 사용자를 위한 Ray 대시보드 API 액세스 제한과 같은 사용자 지정을 구현할 수 있는 기회가 있습니다.\n- Ray 클러스터를 제공하는 실제 방법을 분리함으로써 KubeRay 및 전용 K8s 클러스터로 전환하는 것이 훨씬 쉬워지며 앞으로 계획하는 것과 같이 필요에 따라 다른 노드 제공자로 전환할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 사용자에게 충분한 인프라 관련 정보를 제공하지 않으면 Ray 클러스터 프로비저닝의 실패 또는 지연과 관련된 혼란이 발생할 수 있습니다.\n- 동시에 수십 개 또는 수백 개의 Ray 클러스터를 운영하려면 플랫폼 측에서 모니터링 및 경보가 중요합니다. Ray 인프라의 초기 단계에 있으며 신속한 변화로 애플리케이션 측에 장애가 발생할 수 있으므로 경보 설정에 성실해야 하며 프로덕션 환경으로 배포하기 전에 스테이징 환경에서 철저한 테스트를 수행해야 합니다.\n\n# 사용법\n\n우리는 2023년 2분기부터 Ray 인프라 사용량을 수집하기 시작했고, 지난 마일스톤 데이터 처리 응용 프로그램 GA 및 추가 사용자들이 Ray 프레임워크에 참여하면서 2023년 4분기에 급증을 관찰했습니다. 우리는 현재 배치 추론 및 adhoc Ray Serve 개발과 같은 다양한 Ray 응용 프로그램을 탐색하기 위해 Ray 기반으로 이전한 사용자들에게 도움을 주고 있습니다. 우리는 아직 네이티브 PyTorch 기반 애플리케이션에서 Ray 기반 애플리케이션으로 이동하는 초기 단계에 있으나, 더 고급화된 사용 사례로 전환하기 위해 고객들과 열심히 협력하고 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_13.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 Markdown 형식으로 표로 변환하였습니다.\n\n\n| 파일 | 이미지 |\n|:-------------------------:|:-------------------------:|\n| 2024-06-19-RayInfrastructureatPinterest_14.png | \u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_14.png\" /\u003e |\n| 2024-06-19-RayInfrastructureatPinterest_15.png | \u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_15.png\" /\u003e |\n\n\n# 사용 사례\n\nRay 인프라는 제품 ML 사용 사례에 대해 배포되었으며 새로운 응용 프로그램의 신속한 실험을 위해 사용되었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Ray Train\n\n- 여러 추천 시스템 모델 교육이 Ray로 이관되었으며, 나머지 사용 사례를 적극적으로 도입 중입니다.\n- 현재 Ray를 사용하여 매월 5000개 이상의 교육 작업을 실행 중입니다.\n- 이러한 교육 실행은 이질적인 CPU / GPU 클러스터를 활용합니다.\n\n## 핵심 이점:\n\n확장성:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Ray는 교육 실행을 가능한 서로 다른 교육기 인스턴스를 넘어 데이터 로딩 및 전처리를 확장할 수 있도록 합니다.\n- p4d.24xlarge와 같은 단일 GPU 노드는 고정된 12:1 CPU:GPU 비율을 가지고 있어 데이터 로더를 확장하고 GPU를 포화시키는 것을 방해합니다.\n- Ray를 사용하면 p4d 인스턴스 외부에서 데이터 로더를 확장할 수 있습니다. 이는 CPU만 있는 인스턴스를 사용하여 더 저렴하게 처리할 수 있습니다.\n\nDev-velocity\n\n- 확장성 이외에도 Ray는 개발 속도를 크게 높일 수 있습니다.\n- 머신 러닝 엔지니어들의 일상적인 작업 중 상당 부분은 모델 변경을 구현하고 로컬 코드를 사용하여 개발 훈련을 실행하는 것입니다.\n- Ray를 사용하면 Ray 컴퓨팅 클러스터를 상호작용적으로 사용하여 주피터 노트북을 통해 작업을 제출할 수 있습니다.\n\n## 일괄 추론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Pinterest는 과거 PySpark 기반의 일괄 추론 솔루션을 활용했습니다.\n- Ray를 사용하여, ray.data.Dataset에서 map_batches 구현으로 설계된 새 BatchInference 솔루션을 재구현했습니다.\n- 우리는 현재 이 솔루션을 세 가지 프로덕션 유즈 케이스에 사용하고 있습니다.\n- 현재 우리는 Ray를 사용하여 매달 300개 이상의 일괄 추론 작업을 실행 중입니다.\n\n## 핵심 이점:\n\n효율성:\n\n- 이전 구현과는 달리, Ray는 전처리, GPU 추론 및 출력 파일 쓰기의 파이프라이닝을 가능케 합니다.\n- 더불어, 자동으로 이 세 단계를 이종 CPU 및 GPU 노드에서 실행할 수 있게 분리할 수 있습니다.\n- 이들을 합쳐, 우리의 프로덕션 GPU 추론 작업의 작업 실행 시간이 4배 감소했습니다 (1시간 → 15분).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nUnlocked Opportunity:\n\n- Ray와 함께 프로그래밍하는 쉬움과 파이프라이닝으로 얻는 효율성 덕분에 GPU 기반 모델에 대한 특성 소거 도구를 채택할 수 있었습니다.\n\n## 실험적 워크로드\n\n- Ray는 Ray Serve를 포함한 다양한 도구 생태계를 제공합니다.\n- Ray Serve는 모델 서빙을 위한 내장된 라우팅 및 자동 스케일링 기능을 제공하며, 모델을 빠르게 평가하기 위해 매우 편리합니다.\n- Ray Serve가 없는 경우 클라이언트는 RPC 서버, 배포 파이프라인, 서비스 검색 및 자동 스케일링을 수동으로 설정해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 주요 성과:\n\n- 내부 해커톤에서 팀이 몇 시간 만에 오픈 소스 대규모 모델을 설정하고 사용할 수 있었습니다.\n- Ray가 없었다면 이러한 인프라를 구축하는 데 몇 일에서 몇 주가 걸렸을 것입니다.\n\n# 다음 계획\n\n- Pinterest에서 Ray Batch Inference에 대해 깊이 파고들기\n- Pinterest에서 Ray Tune\n- Pinterest에서 Ray 어플리케이션의 독특한 도전 현황\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 인사말\n\nCloud Runtime Team: Jiajun Wang, Harry Zhang\n\nTraffic Team: James Fish, Bruno Palermo, Kuo-Chung Hsu\n\nSecurity Team: Jeremy Krach, Cedric Staub\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nML 플랫폼: Qingxian Lai, Lei Pan\n\nAnyscale: Zhe Zhang, Kai-Hsun Chen, SangBin Cho","ogImage":{"url":"/assets/img/2024-06-19-RayInfrastructureatPinterest_0.png"},"coverImage":"/assets/img/2024-06-19-RayInfrastructureatPinterest_0.png","tag":["Tech"],"readingTime":14},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003e이름\u003c/th\u003e\u003cth\u003e직급\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eChia-Wei Chen\u003c/td\u003e\u003ctd\u003e주임 소프트웨어 엔지니어\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eRaymond Lee\u003c/td\u003e\u003ctd\u003e주임 소프트웨어 엔지니어\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eAlex Wang\u003c/td\u003e\u003ctd\u003e소프트웨어 엔지니어 I\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eSaurabh Vishwas Joshi\u003c/td\u003e\u003ctd\u003e주임 스태프 소프트웨어 엔지니어\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eKarthik Anantha Padmanabhan\u003c/td\u003e\u003ctd\u003e주임 엔지니어 관리자\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eSe Won Jang\u003c/td\u003e\u003ctd\u003e주임 엔지니어 관리자\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003ch1\u003e우리 Ray 인프라의 여정\u003c/h1\u003e\n\u003cp\u003e저희 블로그 시리즈의 제1부에서는 Ray에 투자하여 비즈니스의 핵심적인 문제를 해결하기 위해 동기부여를 받았던 이유에 대해 논의했습니다. 이 블로그 포스트에서는 Pinterest와 같은 웹 규모 회사에 Ray를 통합하는 데 필요한 단계에 대해 더 자세히 설명하겠습니다. 우리는 새로운 기술을 받아들이기 위해 다양한 고유한 제약 조건과 도전에 직면한 Pinterest와 같은 기업에 Ray를 통합하는 데 필요한 것들을 논의할 것입니다. 이는 Ray 인프라 부분에 대한 더 포괄적인 버전으로, 우리가 Ray 설명에서 발표한 Last Mile Data Processing for ML Training using Ray in Ray Summit 2023의 일환입니다.\u003c/p\u003e\n\u003cp\u003e저희의 사용 사례에서 KubeRay가 제공하는 Ray 클러스터를 프로비저닝할 수 있는 능력이 Ray 인프라를 성숙화하는 일의 일부일 뿐입니다. 회사들은 Ray 및 다른 특정 요구사항을 준수해야 하며, 이는 로그, 메트릭 지속성, 네트워크 격리, 최적의 하드웨어 인스턴스 식별, 보안, 트래픽 설정 및 기타 내부 서비스 통합을 포함한 모든 다른 모베스트 관행을 따라야 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e2023년에 여정이 시작되었어요. 전문 엔지니어 한 명이 이 프로젝트에 50%의 시간을 투자했어요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e2023년 1분기: Anyscale 파트너의 지원을 받아 프로토타이핑 단계가 시작되었어요\u003c/li\u003e\n\u003cli\u003e2023년 2분기: Ray Infra MVP가 완료되었고, 시스템 로깅, 메트릭, UI, 및 애플리케이션을 위한 CLI와 같은 필수 도구들이 반복되고 향상되었어요\u003c/li\u003e\n\u003cli\u003e2023년 3분기: 첫 번째 프로덕션 유즈 케이스에 중점을 두어 내부 시스템을 통합하여 서비스 안정성을 향상시켰어요\u003c/li\u003e\n\u003cli\u003e2023년 4분기: 프로덕션 준비에 중점을 두어 보안 문제 대응, 네트워크 안정성 향상, Ray-optimized Kubernetes 환경으로의 전환 평가가 진행되었어요\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003e직면한 도전들\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e핀터레스트에서 Ray 인프라를 구축할 때 몇 가지 중요한 도전 과제가 발생했습니다. 이러한 도전 과제를 해결해야 했습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eK8s API 접근 제한: 핀터레스트의 일반 목적의 연합 Kubernetes 클러스터인 PinCompute에서 작동 중이었기 때문에 KubeRay와 같은 필수 오퍼레이터와 해당 사용자 정의 정의를 설치하는 것이 제한되었습니다.\u003c/li\u003e\n\u003cli\u003e일시적인 로깅 및 메트릭: Ray 클러스터가 활성 상태인 경우 Ray 대시보드를 통해 로깅과 메트릭을 확인할 수 있었지만, 리소스 집약적인 Ray 클러스터를 디버깅 목적으로 유지하는 것은 현실적이지 않았습니다. Ray 작업 부하의 수명 주기를 영속화하고 다시 재생하는 해결책을 찾았습니다.\u003c/li\u003e\n\u003cli\u003e메트릭 통합: 회사는 프로메테우스와 그라파나와 같은 인기 있는 오픈 소스 솔루션과 달리 자체의 시계열 데이터베이스와 시각화 도구를 보유하고 있었습니다.\u003c/li\u003e\n\u003cli\u003e인증, 권한 부여, 감사 (AAA) 가이드라인: 회사 표준에 따라 K8s에서 실행되는 서비스에 AAA를 보장해야 했고, 핀터레스트에서 AAA를 빌드하기 위해 Envoy를 서비스 메시로 사용하는 것이 권장되었습니다.\u003c/li\u003e\n\u003cli\u003e다양한 개발 환경: Jupyter와 CLI 액세스와 같은 상호 작용하는 옵션과 다양한 개발자 요구를 충족하기 위해 Dev 서버에서 CLI 액세스와 같은 다양한 개발 경험이 구축되었습니다.\u003c/li\u003e\n\u003cli\u003e비용 최적화 및 자원 낭비: 유휴 상태의 Ray 클러스터는 상당한 비용이 발생할 수 있습니다. 팀의 인식을 높이고 자원 낭비를 줄이기 위해 가비지 컬렉션 정책과 비용 할당이 필요했습니다.\u003c/li\u003e\n\u003cli\u003e오프라인 데이터 분석: 오프라인 분석을 위해 모든 Ray 클러스터 관련 메트릭을 대규모 데이터 형식 (예: 하이브, 파케)으로 내보내는 것이 우선되었습니다. 이 데이터에는 GPU 활용률과 같은 메트릭이 포함되어 있어 개선 영역을 식별하고 응용 프로그램 및 인프라의 안정성을 시간 경과에 따라 추적할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e쿠버네티스 기반\u003c/h2\u003e\n\u003cp\u003eK8s API 액세스 제한으로 인해 우리 환경에 KubeRay를 쉽게 설치할 수 없어 K8s에서 Ray 클러스터를 운영하기 어려웠습니다. 또한, 핀터레스트 K8s 클러스터 내에서 비밀 관리, 트래픽 처리 및 로그 회전과 같은 작업을 위해 다른 팀에서 관리되는 특정 사이드카가 필요했습니다. 버그 수정이나 보안 패치와 같은 필수 사이드카 업데이트를 중앙 제어하기 위해 특정 제한 사항에 따라 준수해야 했습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eRay 클러스터에 필요한 필수 구성 요소를 프로토타입으로 만드는 중입니다(On-Premise Cluster 가이드에서 설명된 대로), 필요한 사이드카를 통합하기 위해 Pinterest 특정 CRD를 사용하기로 결정했습니다. 이는 오픈 소스 Kubeflow PyTorchJob 위에 구축된 래퍼입니다.\u003c/p\u003e\n\u003cp\u003e최초 반복에서는 Ray 헤드 및 Ray worker를 클라이언트 측에서 만들어 간단하게 유지하기로 하였습니다. 각 구성 요소에 대해 다른 명령을 사용하고 클라이언트 측에서 실행될 사용자 정의 스크립트를 작성하는 것을 포함했습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003edef \u003cspan class=\"hljs-title function_\"\u003elaunch_ray_cluster\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003econfigs\u003c/span\u003e: \u003cspan class=\"hljs-title class_\"\u003eRayClusterConfig\u003c/span\u003e) -\u003e \u003cspan class=\"hljs-attr\"\u003estr\u003c/span\u003e:\n    # resources, instance_type, command, envs_vars 등 정의\n    configs = \u003cspan class=\"hljs-title class_\"\u003eRayClusterAndJobConfigs\u003c/span\u003e()\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eThreadPoolExecutor\u003c/span\u003e() \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eexecutor\u003c/span\u003e:  \n        # 함수를 실행자에 제출\n        ray_head = executor.\u003cspan class=\"hljs-title function_\"\u003esubmit\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003elaunch_ray_head\u003c/span\u003e(configs)).\u003cspan class=\"hljs-title function_\"\u003eresult\u003c/span\u003e()\n        ray_workers = executor.\u003cspan class=\"hljs-title function_\"\u003esubmit\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003elaunch_ray_workers\u003c/span\u003e(configs).\u003cspan class=\"hljs-title function_\"\u003eresult\u003c/span\u003e()\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003echeck_up_and_running\u003c/span\u003e(ray_head, ray_workers)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이 단계에는 개선할 여지가 많이 있습니다. 주요 단점은 클라이언트 측 실행이 네트워크 오류나 만료된 자격 증명과 같은 다양한 이유로 중단될 수 있어 K8s에서 자원을 낭비하는 좀비 Ray 클러스터가 발생할 수 있다는 것입니다. 이 접근 방식은 Ray 사용자들이 Ray에서 놀 수 있도록 막는 데 충분하지만 Ray 클러스터를 효율적으로 관리하기 위해 설계된 플랫폼에 적합하지는 않습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eAPI Gateway \u0026#x26; Controller\u003c/h1\u003e\n\u003cp\u003e두 번째 반복에서는 클라이언트 측에서 Ray 클러스터를 관리하는 방식에서 KubeRay와 유사한 컨트롤러를 개발하여 서버 측 접근 방식으로 전환되었습니다. 우리의 솔루션은 사용자와 K8s 사이에 중간 계층을 생성하여 API 서버, Ray 클러스터/작업 컨트롤러 및 MySQL 데이터베이스로 구성된 여러 구성 요소를 포함했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAPI 서버: 이 구성 요소는 요청 유효성 검사, 인증 및 권한 부여를 용이하게 합니다. 클라이언트 측에서 K8s의 복잡성을 추상화하여 사용자가 플랫폼 API 인터페이스와 상호 작용할 수 있도록 하며, 특히 나중 섹션에서 TLS 관련 구현을 강화하는 데 특히 유용합니다.\u003c/li\u003e\n\u003cli\u003eMySQL 데이터베이스: 데이터베이스는 Ray 클러스터와 관련된 상태 정보를 저장하여 K8s 측에서 필요한 일시적 상태를 다시 생성할 수 있게 합니다. 또한 API 서버와 Ray 클러스터 컨트롤러 간의 데이터 흐름을 분리하고 오프라인 분석을 위해 Hive로 데이터 덤프를 수행하는 추가 혜택이 있습니다.\u003c/li\u003e\n\u003cli\u003eRay 클러스터 컨트롤러: 이 구성 요소는 Ray 클러스터의 수명 주기 관리를 위해 K8s를 지속적으로 쿼리합니다. Ray 헤드 및 워커 노드 프로비저닝, Ray 클러스터 상태 모니터링 및 필요에 따른 정리 작업을 수행하는 역할을 합니다.\u003c/li\u003e\n\u003cli\u003eRay 작업 컨트롤러: Ray 클러스터 컨트롤러와 유사하게, Ray 작업 컨트롤러는 Ray 작업 수명 주기 관리에 초점을 맞춥니다. RayJobs를 제출하기 위한 주요 엔티티로 작용하여 시스템 내에서 적절한 인증 및 권한 부여 프로토콜을 보장합니다. 또한 컨트롤러는 동일한 Ray 클러스터에 여러 Ray 작업을 제출할 수 있도록 지원함으로써 사용자가 각 작업 제출마다 새 Ray 클러스터 프로비저닝을 기다릴 필요 없이 더 효율적으로 반복할 수 있도록 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기는 테이블 태그를 마크다운 형식으로 변경한 것입니다.\u003c/p\u003e\n\u003cp\u003e이 방식은 사용자와 Kubernetes 사이에 가치 있는 추상화 계층을 제공하여 사용자가 복잡한 Kubernetes 자산을 이해할 필요가 없게 합니다. 대신, 플랫폼에서 제공하는 사용자 대면 라이브러리를 활용할 수 있습니다. 클라이언트 측에서 프로비저닝 단계의 부담을 옮기면 프로세스가 간소화되어 단계가 단순화되고 전반적인 사용자 경험이 향상됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e우리 자체 컨트롤러를 구현하는 동안, 우리는 모듈화를 보장하여 나중에 KubeRay로의 원활한 전환을 가능하게 했습니다. 이 방식은 Ray 클러스터를 시작하는 데 사용되는 방법을 손쉽게 바꿀 수 있어, 내부 Kubernetes 기본 도구에서 KubeRay로의 전환이 원활하게 이루어집니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003eClass Controller:\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ereconcile\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, ray_cluster: RayClusterRecord\u003c/span\u003e):\n        \u003cspan class=\"hljs-comment\"\u003e# 이 부분은 내부 기본 도구에서 KubeRay로 교체 가능합니다.\u003c/span\u003e\n        status, k8s_meta = self.launch_and_monitor_ray_cluster(ray_cluster.configs)\n        db.update(ray_cluster, status=status, k8s_meta=k8s_meta)\n\n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003erun\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself\u003c/span\u003e):\n        \u003cspan class=\"hljs-keyword\"\u003ewhile\u003c/span\u003e \u003cspan class=\"hljs-literal\"\u003eTrue\u003c/span\u003e:\n            ray_clusters = db.get_ray_cluster_to_dispatch()\n            \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e ray_cluster \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e ray_clusters:\n                self.reconcile(ray_cluster)\n            sleep(\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e)\n   \n    \u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003elaunch_and_monitor_ray_cluster\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eself, configs\u003c/span\u003e) -\u003e \u003cspan class=\"hljs-type\"\u003eTuple\u003c/span\u003e[\u003cspan class=\"hljs-built_in\"\u003estr\u003c/span\u003e, \u003cspan class=\"hljs-type\"\u003eDict\u003c/span\u003e]:\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e get_actual_k8s_related_status(ray_identifier=configs.ray_identifier)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e가능한 한 Observable성을 고려해보세요. Ray 클러스터의 기존 Ray 대시보드는 클러스터가 활성화된 상태에서만 접근할 수 있고 로그 또는 메트릭 재생을 위한 기능이 없습니다. 따라서 우리는 지속적인 로깅 및 메트릭 기능을 통합하는 전용 사용자 인터페이스를 개발하기로 결정했습니다. 이 사용자 인터페이스는 이전에 구축한 API Gateway에 의해 지원되며, 실시간으로 Ray 클러스터 및 Ray 작업 상태에 대한 통찰력을 제공합니다. 모든 메타데이터, 이벤트 및 로그는 데이터베이스 또는 S3에 저장되므로 이 전략은 Ray 클러스터를 유지하지 않고도 로그 분석을 가능하게 함으로써 GPU와 같은 유휴 리소스로 인한 비용을 완화할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e다양한 회사들이 자체 시계열 메트릭 솔루션을 가지고 있다는 것은 사실일 것입니다. Pinterest에서는 Goku라는 자체 시계열 데이터베이스를 활용하고 있으며, 이는 OpenTSDB와 호환되는 API를 가지고 있습니다. 우리는 prometheus 메트릭을 스크랩하고 내부 시스템과 호환되도록 재구성하는 추가 사이드카를 실행하고 있습니다. 로깅에 관해서는 Ray의 권고사항을 따라 로그를 AWS S3에 지속 저장하고 있습니다. 이러한 로그는 API 서버에서 소비되어 Ray 클러스터 UI에 표시됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_4.png\"\u003e\n\u003ch2\u003eRay Application Stats\u003c/h2\u003e\n\u003cp\u003e동일한 Grafana 차트를 회사 내 시각화 도구인 Statsboard로 번역했습니다. 또한 Pinterest의 ML 엔지니어에게 유용한 dcgm GPU 메트릭 및 dataloader 메트릭과 같은 더 많은 애플리케이션별 기능을 추가했습니다. 이를 통해 Ray 애플리케이션의 병목 현상과 문제를 식별할 수 있습니다.\u003c/p\u003e\n\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_5.png\"\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003eRay Infrastructure Stats\u003c/h2\u003e\n\u003cp\u003e인프라 수준의 모든 메트릭을 모니터링하는 것은 효과적인 모니터링 구현, 알림 생성, 그리고 역사적 데이터를 기반으로 한 SLO/SLA 벤치마킹을 설정하는 데 중요합니다. 예를 들어, 레이 클러스터 대기 시간의 종단 간 추적 및 레이 작업의 롤링 성공률 모니터링은 시스템 성능을 평가하고 유지하는 데 중요합니다. 또한, 레이 클러스터 프로비저닝 실패로 이어질 수 있는 플랫폼 측의 오류를 식별하는 것은 운영 효율을 유지하는 데 중요합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_6.png\" alt=\"Ray Infrastructure\"\u003e\u003c/p\u003e\n\u003ch1\u003e개발 및 운영 인터페이스\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e핀터레스트에서 Ray 애플리케이션을 개발하는 세 가지 옵션을 제공합니다. Dev 서버, 주피터, Spinner 워크플로우가 있습니다. 모든 옵션은 ML 플랫폼의 RESTful API를 사용하여 구동됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_7.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_8.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003eAirflow에서 PythonOperator를 활용하여 사용자가 작업 구성을 제공하고, 우리는 그것을 MLP 서버로 향하는 RayJob 요청으로 변환하는 사용자 정의 연산자를 구성합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_9.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003e테스트\u003c/h1\u003e\n\u003cp\u003e유닛 테스트 및 통합 테스트\u003c/p\u003e\n\u003cp\u003e레이 애플리케이션을 개발할 때 이용할 수 있는 두 가지 유형의 테스트를 제공합니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eUnittest을 사용하는 것을 권장하는 것은 하위 수준 Ray 코어나 Ray 데이터 라이브러리를 활용하는 플랫폼 라이브러리 소유자들에게 좋습니다. 통합 테스트가 적합합니다. Ray 프로그램을 테스트하는 팁을 따르고 동일한 테스트 스위트 내에서 ray 클러스터를 가능한 한 많이 재사용하기 위해 pytest fixtures를 사용합니다.\u003c/li\u003e\n\u003cli\u003e완전한 Ray 작업을 실행하여 코드 변경이나 라이브러리 업데이트로 인해 발생할 수 있는 잘못된 부분을 식별하고 해결하려는 사용자들에게는 통합 테스트가 적합합니다. 비즈니스에 중요한 Ray 응용 프로그램의 건강 상태를 주기적으로 모니터링하기 위해 통합 테스트도 실행합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_10.png\" alt=\"Ray Infrastructure at Pinterest\"\u003e\u003c/p\u003e\n\u003ch2\u003e네트워크 및 보안\u003c/h2\u003e\n\u003cp\u003eRay는 컴퓨팅 플랫폼으로 개발자가 API를 통해 쉽게 워크로드를 실행할 수 있는 유연성을 제공하지만, 이는 보안 취약점(CVE-2023-48022)으로 이어질 수 있습니다. Shadowray 기사에서 강조하는 것과 같이 Ray 자체가 적절한 인증 및 권한 부여 방법을 제공하지 않기 때문에 Ray 대시보드 API에 액세스 권한이 있는 모든 사용자가 유효성 검사나 제어 없이 원격으로 코드를 실행할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e핀터레스트에서는 이 보안 문제를 심각하게 취급하고 적절히 대응했습니다. 우리는 레이 클러스터에 올바른 인증 및 권한 부여가 적용되어야 한다는 것을 확실히 하기 위해 한 발 더 나아갔습니다. 따라서 사용자가 적절한 권한을 갖고 있지 않은 경우 해당 Ray 클러스터를 사용할 수 없도록 했습니다.\u003c/p\u003e\n\u003cp\u003e그러나 이 문제의 복잡성은 핀터레스트의 연방 쿠버네티스 클러스터 아키텍처로 인해 더욱 악화되었는데, 이는 군집 간 기능을 군집 내 환경에 적용하는 데 어려움을 겪게 했습니다. 예를 들어 K8s 클러스터 간의 입력 및 출력 흐름을 제어하기 위해 NetworkPolicy를 사용할 수 없기 때문에, 하드웨어 가용성을 극대화하기 위해 Pod가 K8s 클러스터 전체에 흩어질 수 있는 경우, 네트워크 격리를 실현하기 위한 대안적인 방법이 필요합니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHTTP: 핀터레스트에서는 쿠버네티스 환경에서 서비스 메쉬로 Envoy를 사용합니다. 레이 대시보드를 Envoy 뒤의 localhost에 배포하고 핀터레스트에서의 인증 및 권한 부여 표준 방식을 따릅니다. 이를 통해 UI에서 사용자를 위한 OAuth 또는 서비스를 위한 mTLS로 레이 대시보드에 액세스 범위를 제한할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_11.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003egRPC: K8s 환경에서 임의의 Pod이 활성 상태의 Ray Cluster에 연결하는 것을 방지하기 위해, Ray 클러스터 부트스트랩 시에 Ray TLS를 일부 사용자 정의와 함께 이용합니다. 자세히 말하면, 각 Ray 클러스터마다 고유한 쌍(개인 키, 인증서) 인증서 기관(CA)를 생성합니다. 이를 통해 CA와 특정 Ray 클러스터 간에 1:1 매핑을 보장합니다. 상호 인증의 첫 번째 단계는 클라이언트(Ray Pods)의 접근을 해당 CA로 제한하여 서버 측에서 적절한 AuthN / AuthZ로 수행함으로써 완료됩니다. 이렇게 함으로써 특정 Ray 클러스터를 나타내는 해당 CA에 의해 서명된 인증서를 수령할 수 있는 Pod의 하위 집합만 이를 수행할 수 있습니다. 두 번째 단계는 발급된 인증서를 사용하여 통신하는 Pod들이 예상된 Ray 클러스터에 해당하는 CA에 의해 서명되었는지 확인하는 것입니다. 게다가, Ray Pods에 대한 잎 인증서의 서명 및 발급에 대한 모든 암호화 작업은 클라이언트, 즉 Ray head 및 worker pods이 CA 개인 키에 액세스할 수 없도록 서버 측(MLP 서버)에서 수행되어야 합니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_12.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003e교훈\u003c/h1\u003e\n\u003cp\u003e점진적 개선:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e단순한 방식으로 Ray 클러스터를 배포한 후에는 프로덕션 환경이나 클라우드 환경에서 자동화 및 확장 프로세스에 초점을 맞추세요.\u003c/li\u003e\n\u003cli\u003eMVP 개발 시 휠을 재발명할 필요를 최소화하기 위해 회사의 기존 인프라를 활용하세요. 저희는 Kubeflow 오퍼레이터를 활용하며 기존의 ML 특화 인프라 논리는 개발 프로세스를 간소화할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e프로토 타입이 완료된 후 회사 전체의 최고 권고 사항에 따라 보안 문제 및 다른 규정 준수 문제 등 인프라를 개선하세요.\u003c/li\u003e\n\u003cli\u003e고객과 정기적으로 회의를 진행하여 도전 과제 및 개선 영역에 대한 초기 피드백을 수집하세요.\u003c/li\u003e\n\u003cli\u003ePinterest의 Ray 이니셔티브의 현재 성공을 고려할 때, ML 전용 K8s 클러스터로 이동할 때 KubeRay 통합과 같은 더 많은 개선 사항을 찾고 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e클라이언트와 Kubernetes 클러스터 사이의 중간 계층:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAPI 서버는 클라이언트와 Kubernetes 간의 다리 역할을 하는 추상화 계층을 제공합니다.\u003c/li\u003e\n\u003cli\u003eRay 클러스터의 생애 주기 이벤트가 Kubernetes에서 사용자 정의 리소스가 제거된 후에도 지속적으로 기록되도록 보장하세요.\u003c/li\u003e\n\u003cli\u003e플랫폼은 비즈니스 로직, 즉 추가 유효성 검사 및 사용자 인증, 인가, 사용자를 위한 Ray 대시보드 API 액세스 제한과 같은 사용자 지정을 구현할 수 있는 기회가 있습니다.\u003c/li\u003e\n\u003cli\u003eRay 클러스터를 제공하는 실제 방법을 분리함으로써 KubeRay 및 전용 K8s 클러스터로 전환하는 것이 훨씬 쉬워지며 앞으로 계획하는 것과 같이 필요에 따라 다른 노드 제공자로 전환할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e사용자에게 충분한 인프라 관련 정보를 제공하지 않으면 Ray 클러스터 프로비저닝의 실패 또는 지연과 관련된 혼란이 발생할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e동시에 수십 개 또는 수백 개의 Ray 클러스터를 운영하려면 플랫폼 측에서 모니터링 및 경보가 중요합니다. Ray 인프라의 초기 단계에 있으며 신속한 변화로 애플리케이션 측에 장애가 발생할 수 있으므로 경보 설정에 성실해야 하며 프로덕션 환경으로 배포하기 전에 스테이징 환경에서 철저한 테스트를 수행해야 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e사용법\u003c/h1\u003e\n\u003cp\u003e우리는 2023년 2분기부터 Ray 인프라 사용량을 수집하기 시작했고, 지난 마일스톤 데이터 처리 응용 프로그램 GA 및 추가 사용자들이 Ray 프레임워크에 참여하면서 2023년 4분기에 급증을 관찰했습니다. 우리는 현재 배치 추론 및 adhoc Ray Serve 개발과 같은 다양한 Ray 응용 프로그램을 탐색하기 위해 Ray 기반으로 이전한 사용자들에게 도움을 주고 있습니다. 우리는 아직 네이티브 PyTorch 기반 애플리케이션에서 Ray 기반 애플리케이션으로 이동하는 초기 단계에 있으나, 더 고급화된 사용 사례로 전환하기 위해 고객들과 열심히 협력하고 있습니다.\u003c/p\u003e\n\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_13.png\"\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e아래는 Markdown 형식으로 표로 변환하였습니다.\u003c/p\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth align=\"center\"\u003e파일\u003c/th\u003e\u003cth align=\"center\"\u003e이미지\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd align=\"center\"\u003e2024-06-19-RayInfrastructureatPinterest_14.png\u003c/td\u003e\u003ctd align=\"center\"\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_14.png\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd align=\"center\"\u003e2024-06-19-RayInfrastructureatPinterest_15.png\u003c/td\u003e\u003ctd align=\"center\"\u003e\u003cimg src=\"/assets/img/2024-06-19-RayInfrastructureatPinterest_15.png\"\u003e\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003ch1\u003e사용 사례\u003c/h1\u003e\n\u003cp\u003eRay 인프라는 제품 ML 사용 사례에 대해 배포되었으며 새로운 응용 프로그램의 신속한 실험을 위해 사용되었습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003eRay Train\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e여러 추천 시스템 모델 교육이 Ray로 이관되었으며, 나머지 사용 사례를 적극적으로 도입 중입니다.\u003c/li\u003e\n\u003cli\u003e현재 Ray를 사용하여 매월 5000개 이상의 교육 작업을 실행 중입니다.\u003c/li\u003e\n\u003cli\u003e이러한 교육 실행은 이질적인 CPU / GPU 클러스터를 활용합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e핵심 이점:\u003c/h2\u003e\n\u003cp\u003e확장성:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eRay는 교육 실행을 가능한 서로 다른 교육기 인스턴스를 넘어 데이터 로딩 및 전처리를 확장할 수 있도록 합니다.\u003c/li\u003e\n\u003cli\u003ep4d.24xlarge와 같은 단일 GPU 노드는 고정된 12:1 CPU:GPU 비율을 가지고 있어 데이터 로더를 확장하고 GPU를 포화시키는 것을 방해합니다.\u003c/li\u003e\n\u003cli\u003eRay를 사용하면 p4d 인스턴스 외부에서 데이터 로더를 확장할 수 있습니다. 이는 CPU만 있는 인스턴스를 사용하여 더 저렴하게 처리할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDev-velocity\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e확장성 이외에도 Ray는 개발 속도를 크게 높일 수 있습니다.\u003c/li\u003e\n\u003cli\u003e머신 러닝 엔지니어들의 일상적인 작업 중 상당 부분은 모델 변경을 구현하고 로컬 코드를 사용하여 개발 훈련을 실행하는 것입니다.\u003c/li\u003e\n\u003cli\u003eRay를 사용하면 Ray 컴퓨팅 클러스터를 상호작용적으로 사용하여 주피터 노트북을 통해 작업을 제출할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e일괄 추론\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003ePinterest는 과거 PySpark 기반의 일괄 추론 솔루션을 활용했습니다.\u003c/li\u003e\n\u003cli\u003eRay를 사용하여, ray.data.Dataset에서 map_batches 구현으로 설계된 새 BatchInference 솔루션을 재구현했습니다.\u003c/li\u003e\n\u003cli\u003e우리는 현재 이 솔루션을 세 가지 프로덕션 유즈 케이스에 사용하고 있습니다.\u003c/li\u003e\n\u003cli\u003e현재 우리는 Ray를 사용하여 매달 300개 이상의 일괄 추론 작업을 실행 중입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e핵심 이점:\u003c/h2\u003e\n\u003cp\u003e효율성:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e이전 구현과는 달리, Ray는 전처리, GPU 추론 및 출력 파일 쓰기의 파이프라이닝을 가능케 합니다.\u003c/li\u003e\n\u003cli\u003e더불어, 자동으로 이 세 단계를 이종 CPU 및 GPU 노드에서 실행할 수 있게 분리할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e이들을 합쳐, 우리의 프로덕션 GPU 추론 작업의 작업 실행 시간이 4배 감소했습니다 (1시간 → 15분).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eUnlocked Opportunity:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eRay와 함께 프로그래밍하는 쉬움과 파이프라이닝으로 얻는 효율성 덕분에 GPU 기반 모델에 대한 특성 소거 도구를 채택할 수 있었습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e실험적 워크로드\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRay는 Ray Serve를 포함한 다양한 도구 생태계를 제공합니다.\u003c/li\u003e\n\u003cli\u003eRay Serve는 모델 서빙을 위한 내장된 라우팅 및 자동 스케일링 기능을 제공하며, 모델을 빠르게 평가하기 위해 매우 편리합니다.\u003c/li\u003e\n\u003cli\u003eRay Serve가 없는 경우 클라이언트는 RPC 서버, 배포 파이프라인, 서비스 검색 및 자동 스케일링을 수동으로 설정해야 합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e주요 성과:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e내부 해커톤에서 팀이 몇 시간 만에 오픈 소스 대규모 모델을 설정하고 사용할 수 있었습니다.\u003c/li\u003e\n\u003cli\u003eRay가 없었다면 이러한 인프라를 구축하는 데 몇 일에서 몇 주가 걸렸을 것입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e다음 계획\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003ePinterest에서 Ray Batch Inference에 대해 깊이 파고들기\u003c/li\u003e\n\u003cli\u003ePinterest에서 Ray Tune\u003c/li\u003e\n\u003cli\u003ePinterest에서 Ray 어플리케이션의 독특한 도전 현황\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e인사말\u003c/h1\u003e\n\u003cp\u003eCloud Runtime Team: Jiajun Wang, Harry Zhang\u003c/p\u003e\n\u003cp\u003eTraffic Team: James Fish, Bruno Palermo, Kuo-Chung Hsu\u003c/p\u003e\n\u003cp\u003eSecurity Team: Jeremy Krach, Cedric Staub\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eML 플랫폼: Qingxian Lai, Lei Pan\u003c/p\u003e\n\u003cp\u003eAnyscale: Zhe Zhang, Kai-Hsun Chen, SangBin Cho\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-RayInfrastructureatPinterest"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>