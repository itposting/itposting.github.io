<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>LLM을 위한 지시어 파인 튜닝에 대한 포괄적인 소개 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="LLM을 위한 지시어 파인 튜닝에 대한 포괄적인 소개 | itposting" data-gatsby-head="true"/><meta property="og:title" content="LLM을 위한 지시어 파인 튜닝에 대한 포괄적인 소개 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs" data-gatsby-head="true"/><meta name="twitter:title" content="LLM을 위한 지시어 파인 튜닝에 대한 포괄적인 소개 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 03:09" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-0fd008072af5a644.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">LLM을 위한 지시어 파인 튜닝에 대한 포괄적인 소개</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="LLM을 위한 지시어 파인 튜닝에 대한 포괄적인 소개" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>지시 튜닝은 큰 언어 모델(LLM)의 능력을 특정 지시를 따르도록 개선하기 위해 사용되는 과정입니다. InstructGPT의 작업은 먼저 지시 미세 조정에 대한 작업을 소개했습니다.</p>
<p>InstructGPT는 인간 지시를 더 잘 따르도록 GPT-3를 미세 조정하여 학습되었습니다. 인간이 모델의 응답을 평가한 데이터셋에서 GPT-3를 조정하는 것은 ChatGPT를 만드는 방향으로 큰 발전이었습니다.</p>
<p>이 문서에서는 기존 LLM의 성능을 향상시키기 위해 지시 미세 조정하는 과정과 결과를 배우게 됩니다. 또한 미세 조정한 LLM의 성능을 평가하고 기본 모델과의 개선 정도를 양적으로 측정할 수 있는 중요한 지표에 대해 알게 될 것입니다.</p>
<p><img src="/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_0.png" alt="image"></p>
<h2>목차:</h2>
<ul>
<li>지시사항 프롬프트를 사용한 LLMs 세밀조정</li>
<li>세밀조정 과정</li>
<li>지시 데이터 세트 준비</li>
<li>지시 세밀조정 프로세스</li>
<li>평가 및 성능 측정 지표</li>
</ul>
<h1>1. 지시 프롬프트를 활용한 LLMs 세밀조정</h1>
<p>큰 LLMs 및 GPT3와 같은 기본 모델들은 프롬프트에 포함된 지시사항을 식별하고 올바르게 zero-shot 추론을 수행할 수 있지만, 더 작은 LLMs와 같은 다른 모델들은 작업을 수행하지 못할 수도 있습니다.</p>
<p>예를 들어, "불어로 이 문장을 번역해주세요: '안녕, 어떻게 지내세요?'"라는 지시를 받으면 능력있는 LLM은 비슷한 번역 예시를 볼 필요 없이 올바른 번역 "Bonjour, comment ça va?"를 생성할 수 있습니다.</p>
<p>그러나 더 작은 LLM들이나 덜 포괄적인 훈련 데이터를 갖고 있는 LLM들은 또는 더 복잡한 작업에 대해서 적절한 작업을 제대로 수행하기 위해 안내 없이 어려움을 겪을 수 있습니다. 이를 해결하기 위해 one-shot 및 few-shot 추론 기술이 사용되는데, 여기서 한 번 또는 몇 가지 예제가 모델이 작업을 이해하는 데 도움이 됩니다.</p>
<p>예시: One-Shot 추론</p>
<ul>
<li>프롬프트: "이 문장을 독일어로 번역해주세요: '좋은 아침.' 예시: '어떻게 지내세요?' - ` 'Wie geht es dir?'""</li>
<li>모델 출력: "Guten Morgen."</li>
</ul>
<p>여기서 모델은 제공된 예시를 사용하여 "Good morning"을 올바르게 번역하는 방법을 추론합니다.</p>
<p>예시: Few-Shot 추론</p>
<ul>
<li>프롬프트: "다음 문장을 프랑스어로 번역하십시오: '안녕히 가세요.' 예시: '안녕' -<code> 'Bonjour'. '고맙습니다' -</code> 'Merci'."</li>
<li>모델 출력: "Au revoir."</li>
</ul>
<p>몇 가지 예시를 제공함으로써, 모델은 번역 작업에 대한 더 나은 이해를 얻고 정확한 결과를 내놓습니다. 파인 튜닝은 LLM의 가중치를 업데이트하기 위해 레이블이 지정된 예시를 사용하여 기본 모델을 더 학습시키는 솔루션을 제공합니다.</p>
<h1>2. 지시 사항 세부 조정 과정</h1>
<p>이전에 대비해서, 선행 교육에서는 LLM을 자기 지도 학습을 통해 거대한 양의 비구조화된 텍스트 데이터를 사용하여 훈련했지만, 지시 사항 세부 조정은 레이블이 지정된 예제 데이터 세트를 사용하여 LLM의 가중치를 업데이트하는 지도 학습 과정입니다.</p>
<p>레이블이 지정된 예제는 프롬프트-완료 쌍이며, 세부 조정 프로세스는 모델의 훈련을 확장하여 특정 작업에 대한 좋은 완료를 생성할 수 있는 능력을 향상시킵니다.</p>
<p>다양한 작업에 대한 지시 사항 세부 조정 예시:</p>
<ul>
<li>
<p>텍스트 분류:</p>
<ul>
<li>작업: 영화 리뷰의 감정 분류</li>
<li>프롬프트: "이 리뷰의 감정을 분류하세요: '나는 이 영화를 정말 좋아했어요! 처음부터 끝까지 멋있었어요.'"</li>
<li>완료: "감정: 긍정적"</li>
</ul>
</li>
</ul>
<ol start="2">
<li>
<p>텍스트 요약:</p>
<ul>
<li>작업: 기사 요약</li>
<li>프롬프트: "다음 기사를 요약하세요: '주식 시장은 역대급 성장을 보여주었으며, 주요 지수가 사상 최고치를 기록했습니다. 투자자들은 경제의 회복에 대해 낙관적입니다.'"</li>
<li>완료: "요약: 경제 회복에 대한 낙관주의 속에서 주식 시장이 사상 최고치를 경신했습니다."</li>
</ul>
</li>
</ol>
<ol start="3">
<li>번역:</li>
</ol>
<ul>
<li>작업: 영어 문장을 프랑스어로 번역하십시오.</li>
<li>프롬프트: “다음 문장을 프랑스어로 번역하십시오: ‘The weather is nice today.’”</li>
<li>완료: “Le temps est agréable aujourd’hui.”</li>
</ul>
<ol start="4">
<li>질의응답:</li>
</ol>
<ul>
<li>작업: 주어진 텍스트를 기반으로 질문에 답하십시오.</li>
<li>프롬프트: “다음 글을 읽고 질문에 답하십시오: ‘중국의 만리장성은 세계에서 가장 유명한 구조물 중 하나입니다. 침입으로부터 보호하기 위해 건설되었습니다.’ 질문: 만리장성은 왜 지어졌습니까?”</li>
<li>완료: “만리장성은 침입으로부터 보호하기 위해 건설되었습니다.”</li>
</ul>
<ol start="5">
<li>Named Entity Recognition (NER):</li>
</ol>
<ul>
<li>Task: 명명된 Entity(개체)를 식별하고 분류합니다. 예를 들어, 사람, 조직, 위치 등</li>
<li>지시문: "다음 문장에서 Entity(개체)를 식별하고 분류하세요: 'Barack Obama was born in Hawaii and served as the President of the United States.'"</li>
<li>완성: "Barack Obama: 사람, Hawaii: 위치, President of the United States: 직책"</li>
</ul>
<p>지시서 파인튜닝은 특정 지시에 대한 모델의 반응을 보여주는 예시를 사용하여 다양한 작업에서 모델의 성능을 향상시키는 데 특히 좋습니다. 지시서 파인튜닝의 가장 중요한 장점 중 세 가지는 다음과 같습니다:</p>
<ul>
<li>작업별 전문 지식: 레이블이 지정된 예시를 통해 특정 작업에 대해 직접 학습함으로써 모델이 해당 작업에서 높은 능숙도를 갖게 됩니다.</li>
<li>향상된 정확도: 파인튜닝은 모델이 훈련된 작업에 대한 정확도를 크게 향상시키며 명확한 지침과 예시를 통해 학습합니다.</li>
<li>문맥 처리 효율: 파인튜닝 후에는 프롬프트 내에서 여러 예시를 요구하지 않아도 되므로, 문맥 창에서 다른 관련 정보를 위한 공간을 절약할 수 있습니다.</li>
</ul>
<h1>3. 지시 데이터 세트 준비</h1>
<p>지시 미세 조정 작업의 한 가지 어려움은 많은 공개 데이터 세트가 내용은 풍부하지만 지시 프롬프트로 사용하기에 적합하게 구조화되어 있지 않다는 것입니다. 예를 들어, 언어 모델 사전 훈련에 사용되는 데이터 세트는 특정 지시나 프롬프트 없이 원시 텍스트 단락으로 구성될 수 있습니다.</p>
<p>이러한 어려움을 해결하기 위해 연구원들과 개발자들은 지시 프롬프트 데이터 세트로 변환하기 위해 기존 데이터 세트를 변환하는 미리 정의된 템플릿을 포함하는 라이브러리와 도구를 선별해 왔습니다. 예를 들어, 지시 프롬프트 라이브러리 및 예시를 포함한 Template Libraries, 예를 들면:</p>
<ul>
<li>Hugging Face의 NLP Datasets: Hugging Face는 자연어 처리 (NLP) 데이터 세트의 방대한 컬렉션을 제공하며, 이 중 많은 데이터 세트에 미리 정의된 프롬프트 템플릿이 함께 제공됩니다. 이 템플릿을 사용하면 사용자가 원시 데이터 세트를 지시 기반 프롬프트 형식으로 변환할 수 있습니다.</li>
<li>OpenAI의 GPT Prompt Engineering: OpenAI는 지시 엔지니어링을 위한 자원과 도구를 제공하며, 특정 작업에 맞춘 프롬프트 라이브러리를 포함합니다. 이러한 라이브러리는 분류, 텍스트 생성 및 요약과 같은 작업을 위한 사용 준비가 완료된 템플릿을 제공합니다.</li>
</ul>
<p>이 라이브러리와 도구를 사용하면 지시용 데이터 세트를 만들 수 있습니다:</p>
<ul>
<li>Amazon 제품 리뷰 데이터 세트: 개발자는 Amazon 제품 리뷰 데이터 세트를 활용하여 언어 모델을 감정 분석이나 제품 분류를 위해 세밀하게 조정할 수 있습니다. "이 리뷰의 감정을 분류하십시오" 또는 "제품 평가를 예측하십시오"와 같은 프롬프트 템플릿을 적용하여, 개발자는 원시 리뷰를 세부 조정을 위한 지시 프롬프트로 변환할 수 있습니다.</li>
<li>Stanford Sentiment Treebank (SST): SST는 감정(긍정적 또는 부정적)으로 분류된 영화 리뷰를 포함하는 데이터셋입니다. 적절한 프롬프트 템플릿을 사용하면 연구자들은 SST를 감정 분석 세밀 조정 작업용 지시 프롬프트 데이터 세트로 변환할 수 있습니다.</li>
<li>CNN/Daily Mail 데이터 세트: 이 데이터 세트는 뉴스 기사와 글머리 기사 요약이 짝지어진 것입니다. "이 기사에 대한 요약 생성"과 같은 프롬프트 템플릿을 활용하여 개발자는 텍스트 요약 세밀 조정용 지시 데이터 세트를 준비할 수 있습니다.</li>
<li>WMT 번역 작업 데이터 세트: WMT(기계 번역 워크샵)은 기계 번역 모델을 훈련하기 위한 데이터 세트를 제공합니다. "이 문장을 프랑스어로 번역하십시오"와 같은 프롬프트 템플릿을 사용하여 연구자는 번역 세밀 조정 작업용 지시 프롬프트를 생성할 수 있습니다.</li>
</ul>
<h1>4. 지시 세밀 조정 프로세스</h1>
<p>지시 데이터 세트를 준비했다면, 이를 훈련, 검증 및 테스트 세트로 나눕니다. 세밀 조정 중에는 훈련 데이터 세트에서 프롬프트를 선택하고 LLM에 전달하여 완성본을 생성합니다.</p>
<p>LLM 완성 결과를 교육 데이터에 지정된 응답과 비교하여 표준 교차 엔트로피 함수를 사용하여 손실을 계산하고 역전파를 통해 모델 가중치를 업데이트하십시오.</p>
<p>모델의 성능을 향상시키기 위해 여러 배치의 프롬프트-완성 쌍을 여러 번의 epoch 동안 반복합니다.</p>
<h1>5. 평가 및 성능 지표</h1>
<p>표준 지도 학습과 마찬가지로, 보유 검증 데이터 세트를 사용하여 LLM 성능을 측정하는 별도의 평가 단계를 정의하여 검증 정확도를 얻습니다.</p>
<p>미세 조정을 완료한 후, 테스트 정확도를 얻기 위해 홀드아웃 테스트 데이터셋을 사용하여 최종 성능 평가를 수행하십시오. 이때, 이메일 보완보상평가(BLEU) 및 ROUGE(Recall-Oriented Understudy for Gisting Evaluation)은 긴 통역모델 (LLM) 지침 미세 조정을 평가하는 데 사용되는 인기있는 두 평가 지표 중 하나입니다.</p>
<ul>
<li>
<p>BLEU (이중 언어 평가 보조) 스코어:</p>
</li>
<li>
<p>정의: 한 언어에서 다른 언어로 기계 번역된 텍스트의 품질을 평가하기 위한 지표로, 이를 인간이 만든 번역과 비교합니다.</p>
</li>
<li>
<p>예시: 번역 작업에서 모델이 "The weather is nice today"을 정확하게 "Le temps est agréable aujourd’hui"로 번역했을 때, 인간 번역과 비교하여 BLEU 스코어가 높게 나타납니다.</p>
</li>
</ul>
<ol start="2">
<li>ROUGE (Recall-Oriented Understudy for Gisting Evaluation) 스코어:</li>
</ol>
<ul>
<li>정의: 자동 요약 및 기계 번역을 평가하는 메트릭스 세트입니다. 이는 모델 출력물과 참조 텍스트 간의 n-gram의 중첩을 측정합니다.</li>
<li>예시: 요약 작업의 경우, 높은 ROUGE 점수는 모델이 생성한 요약과 인간이 작성한 요약 간에 높은 중첩이 있음을 나타냅니다.</li>
</ul>
<p>세밀 조정 과정은 기반 모델의 새 버전을 만들어내며 이를 보통 가르침 모델이라고 합니다. 이는 당신이 관심 있는 작업에 더 적합한 모델입니다.</p>
<p>지시 프롬프트로 세밀 조정하는 것이 오늘날 LLM을 세밀 조정하는 가장 흔한 방법입니다. 본 문서에서는 이 중요한 주제에 대해 간략히 소개되었으니 이제 손을 더럽히고 LLM을 조금 만지작거리며 조정해보는 것이 시간입니다.</p>
<h2>만약 이 문서를 좋아하셨고 저를 지원하고 싶으시다면, 확인해주십시오:</h2>
<ul>
<li>👏 이 이야기에 박수를 보내주세요 (50번 클랩!) 이 기사가 주목받을 수 있도록 도와주세요</li>
<li>To Data &#x26; Beyond 뉴스레터를 구독해주세요</li>
<li>제 Medium 계정을 팔로우해주세요</li>
<li>📰 제 Medium 프로필에서 더 많은 콘텐츠를 확인해주세요</li>
<li>🔔 팔로우하기: LinkedIn | Youtube | GitHub | Twitter</li>
</ul>
<h2>제 뉴스레터 'To Data &#x26; Beyond'를 구독하여 제 글을 완전히 그리고 일찍 볼 수 있습니다:</h2>
<h2>데이터 과학과 AI 분야에서 커리어를 시작하고 방향을 모를 때 도움이 필요하신가요? 저는 데이터 과학 멘토링 세션과 장기적 커리어 멘토링을 제공합니다:</h2>
<ul>
<li>멘토링 세션: <a href="https://lnkd.in/dXeg3KPW" rel="nofollow" target="_blank">링크</a></li>
<li>장기적 멘토링: <a href="https://lnkd.in/dtdUYBrM" rel="nofollow" target="_blank">링크</a></li>
</ul>
<p><img src="/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_1.png" alt="Image"></p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"LLM을 위한 지시어 파인 튜닝에 대한 포괄적인 소개","description":"","date":"2024-06-19 03:09","slug":"2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs","content":"\n\n지시 튜닝은 큰 언어 모델(LLM)의 능력을 특정 지시를 따르도록 개선하기 위해 사용되는 과정입니다. InstructGPT의 작업은 먼저 지시 미세 조정에 대한 작업을 소개했습니다.\n\nInstructGPT는 인간 지시를 더 잘 따르도록 GPT-3를 미세 조정하여 학습되었습니다. 인간이 모델의 응답을 평가한 데이터셋에서 GPT-3를 조정하는 것은 ChatGPT를 만드는 방향으로 큰 발전이었습니다.\n\n이 문서에서는 기존 LLM의 성능을 향상시키기 위해 지시 미세 조정하는 과정과 결과를 배우게 됩니다. 또한 미세 조정한 LLM의 성능을 평가하고 기본 모델과의 개선 정도를 양적으로 측정할 수 있는 중요한 지표에 대해 알게 될 것입니다.\n\n![image](/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 목차:\n\n- 지시사항 프롬프트를 사용한 LLMs 세밀조정\n- 세밀조정 과정\n- 지시 데이터 세트 준비\n- 지시 세밀조정 프로세스\n- 평가 및 성능 측정 지표\n\n# 1. 지시 프롬프트를 활용한 LLMs 세밀조정\n\n큰 LLMs 및 GPT3와 같은 기본 모델들은 프롬프트에 포함된 지시사항을 식별하고 올바르게 zero-shot 추론을 수행할 수 있지만, 더 작은 LLMs와 같은 다른 모델들은 작업을 수행하지 못할 수도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, \"불어로 이 문장을 번역해주세요: '안녕, 어떻게 지내세요?'\"라는 지시를 받으면 능력있는 LLM은 비슷한 번역 예시를 볼 필요 없이 올바른 번역 \"Bonjour, comment ça va?\"를 생성할 수 있습니다.\n\n그러나 더 작은 LLM들이나 덜 포괄적인 훈련 데이터를 갖고 있는 LLM들은 또는 더 복잡한 작업에 대해서 적절한 작업을 제대로 수행하기 위해 안내 없이 어려움을 겪을 수 있습니다. 이를 해결하기 위해 one-shot 및 few-shot 추론 기술이 사용되는데, 여기서 한 번 또는 몇 가지 예제가 모델이 작업을 이해하는 데 도움이 됩니다.\n\n예시: One-Shot 추론\n\n- 프롬프트: \"이 문장을 독일어로 번역해주세요: '좋은 아침.' 예시: '어떻게 지내세요?' - ` 'Wie geht es dir?'\"\"\n- 모델 출력: \"Guten Morgen.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 모델은 제공된 예시를 사용하여 \"Good morning\"을 올바르게 번역하는 방법을 추론합니다.\n\n예시: Few-Shot 추론\n\n- 프롬프트: \"다음 문장을 프랑스어로 번역하십시오: '안녕히 가세요.' 예시: '안녕' -` 'Bonjour'. '고맙습니다' -` 'Merci'.\"\n- 모델 출력: \"Au revoir.\"\n\n몇 가지 예시를 제공함으로써, 모델은 번역 작업에 대한 더 나은 이해를 얻고 정확한 결과를 내놓습니다. 파인 튜닝은 LLM의 가중치를 업데이트하기 위해 레이블이 지정된 예시를 사용하여 기본 모델을 더 학습시키는 솔루션을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2. 지시 사항 세부 조정 과정\n\n이전에 대비해서, 선행 교육에서는 LLM을 자기 지도 학습을 통해 거대한 양의 비구조화된 텍스트 데이터를 사용하여 훈련했지만, 지시 사항 세부 조정은 레이블이 지정된 예제 데이터 세트를 사용하여 LLM의 가중치를 업데이트하는 지도 학습 과정입니다.\n\n레이블이 지정된 예제는 프롬프트-완료 쌍이며, 세부 조정 프로세스는 모델의 훈련을 확장하여 특정 작업에 대한 좋은 완료를 생성할 수 있는 능력을 향상시킵니다.\n\n다양한 작업에 대한 지시 사항 세부 조정 예시:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 텍스트 분류:\n\n   - 작업: 영화 리뷰의 감정 분류\n   - 프롬프트: \"이 리뷰의 감정을 분류하세요: '나는 이 영화를 정말 좋아했어요! 처음부터 끝까지 멋있었어요.'\"\n   - 완료: \"감정: 긍정적\"\n\n2. 텍스트 요약:\n\n   - 작업: 기사 요약\n   - 프롬프트: \"다음 기사를 요약하세요: '주식 시장은 역대급 성장을 보여주었으며, 주요 지수가 사상 최고치를 기록했습니다. 투자자들은 경제의 회복에 대해 낙관적입니다.'\"\n   - 완료: \"요약: 경제 회복에 대한 낙관주의 속에서 주식 시장이 사상 최고치를 경신했습니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 번역:\n\n- 작업: 영어 문장을 프랑스어로 번역하십시오.\n- 프롬프트: “다음 문장을 프랑스어로 번역하십시오: ‘The weather is nice today.’”\n- 완료: “Le temps est agréable aujourd’hui.”\n\n4. 질의응답:\n\n- 작업: 주어진 텍스트를 기반으로 질문에 답하십시오.\n- 프롬프트: “다음 글을 읽고 질문에 답하십시오: ‘중국의 만리장성은 세계에서 가장 유명한 구조물 중 하나입니다. 침입으로부터 보호하기 위해 건설되었습니다.’ 질문: 만리장성은 왜 지어졌습니까?”\n- 완료: “만리장성은 침입으로부터 보호하기 위해 건설되었습니다.”\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. Named Entity Recognition (NER):\n\n- Task: 명명된 Entity(개체)를 식별하고 분류합니다. 예를 들어, 사람, 조직, 위치 등\n- 지시문: \"다음 문장에서 Entity(개체)를 식별하고 분류하세요: 'Barack Obama was born in Hawaii and served as the President of the United States.'\"\n- 완성: \"Barack Obama: 사람, Hawaii: 위치, President of the United States: 직책\"\n\n지시서 파인튜닝은 특정 지시에 대한 모델의 반응을 보여주는 예시를 사용하여 다양한 작업에서 모델의 성능을 향상시키는 데 특히 좋습니다. 지시서 파인튜닝의 가장 중요한 장점 중 세 가지는 다음과 같습니다:\n\n- 작업별 전문 지식: 레이블이 지정된 예시를 통해 특정 작업에 대해 직접 학습함으로써 모델이 해당 작업에서 높은 능숙도를 갖게 됩니다.\n- 향상된 정확도: 파인튜닝은 모델이 훈련된 작업에 대한 정확도를 크게 향상시키며 명확한 지침과 예시를 통해 학습합니다.\n- 문맥 처리 효율: 파인튜닝 후에는 프롬프트 내에서 여러 예시를 요구하지 않아도 되므로, 문맥 창에서 다른 관련 정보를 위한 공간을 절약할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3. 지시 데이터 세트 준비\n\n지시 미세 조정 작업의 한 가지 어려움은 많은 공개 데이터 세트가 내용은 풍부하지만 지시 프롬프트로 사용하기에 적합하게 구조화되어 있지 않다는 것입니다. 예를 들어, 언어 모델 사전 훈련에 사용되는 데이터 세트는 특정 지시나 프롬프트 없이 원시 텍스트 단락으로 구성될 수 있습니다.\n\n이러한 어려움을 해결하기 위해 연구원들과 개발자들은 지시 프롬프트 데이터 세트로 변환하기 위해 기존 데이터 세트를 변환하는 미리 정의된 템플릿을 포함하는 라이브러리와 도구를 선별해 왔습니다. 예를 들어, 지시 프롬프트 라이브러리 및 예시를 포함한 Template Libraries, 예를 들면:\n\n- Hugging Face의 NLP Datasets: Hugging Face는 자연어 처리 (NLP) 데이터 세트의 방대한 컬렉션을 제공하며, 이 중 많은 데이터 세트에 미리 정의된 프롬프트 템플릿이 함께 제공됩니다. 이 템플릿을 사용하면 사용자가 원시 데이터 세트를 지시 기반 프롬프트 형식으로 변환할 수 있습니다.\n- OpenAI의 GPT Prompt Engineering: OpenAI는 지시 엔지니어링을 위한 자원과 도구를 제공하며, 특정 작업에 맞춘 프롬프트 라이브러리를 포함합니다. 이러한 라이브러리는 분류, 텍스트 생성 및 요약과 같은 작업을 위한 사용 준비가 완료된 템플릿을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 라이브러리와 도구를 사용하면 지시용 데이터 세트를 만들 수 있습니다:\n\n- Amazon 제품 리뷰 데이터 세트: 개발자는 Amazon 제품 리뷰 데이터 세트를 활용하여 언어 모델을 감정 분석이나 제품 분류를 위해 세밀하게 조정할 수 있습니다. \"이 리뷰의 감정을 분류하십시오\" 또는 \"제품 평가를 예측하십시오\"와 같은 프롬프트 템플릿을 적용하여, 개발자는 원시 리뷰를 세부 조정을 위한 지시 프롬프트로 변환할 수 있습니다.\n- Stanford Sentiment Treebank (SST): SST는 감정(긍정적 또는 부정적)으로 분류된 영화 리뷰를 포함하는 데이터셋입니다. 적절한 프롬프트 템플릿을 사용하면 연구자들은 SST를 감정 분석 세밀 조정 작업용 지시 프롬프트 데이터 세트로 변환할 수 있습니다.\n- CNN/Daily Mail 데이터 세트: 이 데이터 세트는 뉴스 기사와 글머리 기사 요약이 짝지어진 것입니다. \"이 기사에 대한 요약 생성\"과 같은 프롬프트 템플릿을 활용하여 개발자는 텍스트 요약 세밀 조정용 지시 데이터 세트를 준비할 수 있습니다.\n- WMT 번역 작업 데이터 세트: WMT(기계 번역 워크샵)은 기계 번역 모델을 훈련하기 위한 데이터 세트를 제공합니다. \"이 문장을 프랑스어로 번역하십시오\"와 같은 프롬프트 템플릿을 사용하여 연구자는 번역 세밀 조정 작업용 지시 프롬프트를 생성할 수 있습니다.\n\n# 4. 지시 세밀 조정 프로세스\n\n지시 데이터 세트를 준비했다면, 이를 훈련, 검증 및 테스트 세트로 나눕니다. 세밀 조정 중에는 훈련 데이터 세트에서 프롬프트를 선택하고 LLM에 전달하여 완성본을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM 완성 결과를 교육 데이터에 지정된 응답과 비교하여 표준 교차 엔트로피 함수를 사용하여 손실을 계산하고 역전파를 통해 모델 가중치를 업데이트하십시오.\n\n모델의 성능을 향상시키기 위해 여러 배치의 프롬프트-완성 쌍을 여러 번의 epoch 동안 반복합니다.\n\n# 5. 평가 및 성능 지표\n\n표준 지도 학습과 마찬가지로, 보유 검증 데이터 세트를 사용하여 LLM 성능을 측정하는 별도의 평가 단계를 정의하여 검증 정확도를 얻습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n미세 조정을 완료한 후, 테스트 정확도를 얻기 위해 홀드아웃 테스트 데이터셋을 사용하여 최종 성능 평가를 수행하십시오. 이때, 이메일 보완보상평가(BLEU) 및 ROUGE(Recall-Oriented Understudy for Gisting Evaluation)은 긴 통역모델 (LLM) 지침 미세 조정을 평가하는 데 사용되는 인기있는 두 평가 지표 중 하나입니다.\n\n- BLEU (이중 언어 평가 보조) 스코어:\n\n- 정의: 한 언어에서 다른 언어로 기계 번역된 텍스트의 품질을 평가하기 위한 지표로, 이를 인간이 만든 번역과 비교합니다.\n- 예시: 번역 작업에서 모델이 \"The weather is nice today\"을 정확하게 \"Le temps est agréable aujourd’hui\"로 번역했을 때, 인간 번역과 비교하여 BLEU 스코어가 높게 나타납니다.\n\n2. ROUGE (Recall-Oriented Understudy for Gisting Evaluation) 스코어:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 정의: 자동 요약 및 기계 번역을 평가하는 메트릭스 세트입니다. 이는 모델 출력물과 참조 텍스트 간의 n-gram의 중첩을 측정합니다.\n- 예시: 요약 작업의 경우, 높은 ROUGE 점수는 모델이 생성한 요약과 인간이 작성한 요약 간에 높은 중첩이 있음을 나타냅니다.\n\n세밀 조정 과정은 기반 모델의 새 버전을 만들어내며 이를 보통 가르침 모델이라고 합니다. 이는 당신이 관심 있는 작업에 더 적합한 모델입니다.\n\n지시 프롬프트로 세밀 조정하는 것이 오늘날 LLM을 세밀 조정하는 가장 흔한 방법입니다. 본 문서에서는 이 중요한 주제에 대해 간략히 소개되었으니 이제 손을 더럽히고 LLM을 조금 만지작거리며 조정해보는 것이 시간입니다.\n\n## 만약 이 문서를 좋아하셨고 저를 지원하고 싶으시다면, 확인해주십시오:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 👏 이 이야기에 박수를 보내주세요 (50번 클랩!) 이 기사가 주목받을 수 있도록 도와주세요\n- To Data \u0026 Beyond 뉴스레터를 구독해주세요\n- 제 Medium 계정을 팔로우해주세요\n- 📰 제 Medium 프로필에서 더 많은 콘텐츠를 확인해주세요\n- 🔔 팔로우하기: LinkedIn | Youtube | GitHub | Twitter\n\n## 제 뉴스레터 'To Data \u0026 Beyond'를 구독하여 제 글을 완전히 그리고 일찍 볼 수 있습니다:\n\n## 데이터 과학과 AI 분야에서 커리어를 시작하고 방향을 모를 때 도움이 필요하신가요? 저는 데이터 과학 멘토링 세션과 장기적 커리어 멘토링을 제공합니다:\n\n- 멘토링 세션: [링크](https://lnkd.in/dXeg3KPW)\n- 장기적 멘토링: [링크](https://lnkd.in/dtdUYBrM)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![Image](/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_1.png)","ogImage":{"url":"/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_0.png"},"coverImage":"/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e지시 튜닝은 큰 언어 모델(LLM)의 능력을 특정 지시를 따르도록 개선하기 위해 사용되는 과정입니다. InstructGPT의 작업은 먼저 지시 미세 조정에 대한 작업을 소개했습니다.\u003c/p\u003e\n\u003cp\u003eInstructGPT는 인간 지시를 더 잘 따르도록 GPT-3를 미세 조정하여 학습되었습니다. 인간이 모델의 응답을 평가한 데이터셋에서 GPT-3를 조정하는 것은 ChatGPT를 만드는 방향으로 큰 발전이었습니다.\u003c/p\u003e\n\u003cp\u003e이 문서에서는 기존 LLM의 성능을 향상시키기 위해 지시 미세 조정하는 과정과 결과를 배우게 됩니다. 또한 미세 조정한 LLM의 성능을 평가하고 기본 모델과의 개선 정도를 양적으로 측정할 수 있는 중요한 지표에 대해 알게 될 것입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_0.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch2\u003e목차:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e지시사항 프롬프트를 사용한 LLMs 세밀조정\u003c/li\u003e\n\u003cli\u003e세밀조정 과정\u003c/li\u003e\n\u003cli\u003e지시 데이터 세트 준비\u003c/li\u003e\n\u003cli\u003e지시 세밀조정 프로세스\u003c/li\u003e\n\u003cli\u003e평가 및 성능 측정 지표\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e1. 지시 프롬프트를 활용한 LLMs 세밀조정\u003c/h1\u003e\n\u003cp\u003e큰 LLMs 및 GPT3와 같은 기본 모델들은 프롬프트에 포함된 지시사항을 식별하고 올바르게 zero-shot 추론을 수행할 수 있지만, 더 작은 LLMs와 같은 다른 모델들은 작업을 수행하지 못할 수도 있습니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, \"불어로 이 문장을 번역해주세요: '안녕, 어떻게 지내세요?'\"라는 지시를 받으면 능력있는 LLM은 비슷한 번역 예시를 볼 필요 없이 올바른 번역 \"Bonjour, comment ça va?\"를 생성할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e그러나 더 작은 LLM들이나 덜 포괄적인 훈련 데이터를 갖고 있는 LLM들은 또는 더 복잡한 작업에 대해서 적절한 작업을 제대로 수행하기 위해 안내 없이 어려움을 겪을 수 있습니다. 이를 해결하기 위해 one-shot 및 few-shot 추론 기술이 사용되는데, 여기서 한 번 또는 몇 가지 예제가 모델이 작업을 이해하는 데 도움이 됩니다.\u003c/p\u003e\n\u003cp\u003e예시: One-Shot 추론\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e프롬프트: \"이 문장을 독일어로 번역해주세요: '좋은 아침.' 예시: '어떻게 지내세요?' - ` 'Wie geht es dir?'\"\"\u003c/li\u003e\n\u003cli\u003e모델 출력: \"Guten Morgen.\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e여기서 모델은 제공된 예시를 사용하여 \"Good morning\"을 올바르게 번역하는 방법을 추론합니다.\u003c/p\u003e\n\u003cp\u003e예시: Few-Shot 추론\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e프롬프트: \"다음 문장을 프랑스어로 번역하십시오: '안녕히 가세요.' 예시: '안녕' -\u003ccode\u003e 'Bonjour'. '고맙습니다' -\u003c/code\u003e 'Merci'.\"\u003c/li\u003e\n\u003cli\u003e모델 출력: \"Au revoir.\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e몇 가지 예시를 제공함으로써, 모델은 번역 작업에 대한 더 나은 이해를 얻고 정확한 결과를 내놓습니다. 파인 튜닝은 LLM의 가중치를 업데이트하기 위해 레이블이 지정된 예시를 사용하여 기본 모델을 더 학습시키는 솔루션을 제공합니다.\u003c/p\u003e\n\u003ch1\u003e2. 지시 사항 세부 조정 과정\u003c/h1\u003e\n\u003cp\u003e이전에 대비해서, 선행 교육에서는 LLM을 자기 지도 학습을 통해 거대한 양의 비구조화된 텍스트 데이터를 사용하여 훈련했지만, 지시 사항 세부 조정은 레이블이 지정된 예제 데이터 세트를 사용하여 LLM의 가중치를 업데이트하는 지도 학습 과정입니다.\u003c/p\u003e\n\u003cp\u003e레이블이 지정된 예제는 프롬프트-완료 쌍이며, 세부 조정 프로세스는 모델의 훈련을 확장하여 특정 작업에 대한 좋은 완료를 생성할 수 있는 능력을 향상시킵니다.\u003c/p\u003e\n\u003cp\u003e다양한 작업에 대한 지시 사항 세부 조정 예시:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e텍스트 분류:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e작업: 영화 리뷰의 감정 분류\u003c/li\u003e\n\u003cli\u003e프롬프트: \"이 리뷰의 감정을 분류하세요: '나는 이 영화를 정말 좋아했어요! 처음부터 끝까지 멋있었어요.'\"\u003c/li\u003e\n\u003cli\u003e완료: \"감정: 긍정적\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e\n\u003cp\u003e텍스트 요약:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e작업: 기사 요약\u003c/li\u003e\n\u003cli\u003e프롬프트: \"다음 기사를 요약하세요: '주식 시장은 역대급 성장을 보여주었으며, 주요 지수가 사상 최고치를 기록했습니다. 투자자들은 경제의 회복에 대해 낙관적입니다.'\"\u003c/li\u003e\n\u003cli\u003e완료: \"요약: 경제 회복에 대한 낙관주의 속에서 주식 시장이 사상 최고치를 경신했습니다.\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e번역:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e작업: 영어 문장을 프랑스어로 번역하십시오.\u003c/li\u003e\n\u003cli\u003e프롬프트: “다음 문장을 프랑스어로 번역하십시오: ‘The weather is nice today.’”\u003c/li\u003e\n\u003cli\u003e완료: “Le temps est agréable aujourd’hui.”\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e질의응답:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e작업: 주어진 텍스트를 기반으로 질문에 답하십시오.\u003c/li\u003e\n\u003cli\u003e프롬프트: “다음 글을 읽고 질문에 답하십시오: ‘중국의 만리장성은 세계에서 가장 유명한 구조물 중 하나입니다. 침입으로부터 보호하기 위해 건설되었습니다.’ 질문: 만리장성은 왜 지어졌습니까?”\u003c/li\u003e\n\u003cli\u003e완료: “만리장성은 침입으로부터 보호하기 위해 건설되었습니다.”\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"5\"\u003e\n\u003cli\u003eNamed Entity Recognition (NER):\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003eTask: 명명된 Entity(개체)를 식별하고 분류합니다. 예를 들어, 사람, 조직, 위치 등\u003c/li\u003e\n\u003cli\u003e지시문: \"다음 문장에서 Entity(개체)를 식별하고 분류하세요: 'Barack Obama was born in Hawaii and served as the President of the United States.'\"\u003c/li\u003e\n\u003cli\u003e완성: \"Barack Obama: 사람, Hawaii: 위치, President of the United States: 직책\"\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e지시서 파인튜닝은 특정 지시에 대한 모델의 반응을 보여주는 예시를 사용하여 다양한 작업에서 모델의 성능을 향상시키는 데 특히 좋습니다. 지시서 파인튜닝의 가장 중요한 장점 중 세 가지는 다음과 같습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e작업별 전문 지식: 레이블이 지정된 예시를 통해 특정 작업에 대해 직접 학습함으로써 모델이 해당 작업에서 높은 능숙도를 갖게 됩니다.\u003c/li\u003e\n\u003cli\u003e향상된 정확도: 파인튜닝은 모델이 훈련된 작업에 대한 정확도를 크게 향상시키며 명확한 지침과 예시를 통해 학습합니다.\u003c/li\u003e\n\u003cli\u003e문맥 처리 효율: 파인튜닝 후에는 프롬프트 내에서 여러 예시를 요구하지 않아도 되므로, 문맥 창에서 다른 관련 정보를 위한 공간을 절약할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e3. 지시 데이터 세트 준비\u003c/h1\u003e\n\u003cp\u003e지시 미세 조정 작업의 한 가지 어려움은 많은 공개 데이터 세트가 내용은 풍부하지만 지시 프롬프트로 사용하기에 적합하게 구조화되어 있지 않다는 것입니다. 예를 들어, 언어 모델 사전 훈련에 사용되는 데이터 세트는 특정 지시나 프롬프트 없이 원시 텍스트 단락으로 구성될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이러한 어려움을 해결하기 위해 연구원들과 개발자들은 지시 프롬프트 데이터 세트로 변환하기 위해 기존 데이터 세트를 변환하는 미리 정의된 템플릿을 포함하는 라이브러리와 도구를 선별해 왔습니다. 예를 들어, 지시 프롬프트 라이브러리 및 예시를 포함한 Template Libraries, 예를 들면:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eHugging Face의 NLP Datasets: Hugging Face는 자연어 처리 (NLP) 데이터 세트의 방대한 컬렉션을 제공하며, 이 중 많은 데이터 세트에 미리 정의된 프롬프트 템플릿이 함께 제공됩니다. 이 템플릿을 사용하면 사용자가 원시 데이터 세트를 지시 기반 프롬프트 형식으로 변환할 수 있습니다.\u003c/li\u003e\n\u003cli\u003eOpenAI의 GPT Prompt Engineering: OpenAI는 지시 엔지니어링을 위한 자원과 도구를 제공하며, 특정 작업에 맞춘 프롬프트 라이브러리를 포함합니다. 이러한 라이브러리는 분류, 텍스트 생성 및 요약과 같은 작업을 위한 사용 준비가 완료된 템플릿을 제공합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 라이브러리와 도구를 사용하면 지시용 데이터 세트를 만들 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAmazon 제품 리뷰 데이터 세트: 개발자는 Amazon 제품 리뷰 데이터 세트를 활용하여 언어 모델을 감정 분석이나 제품 분류를 위해 세밀하게 조정할 수 있습니다. \"이 리뷰의 감정을 분류하십시오\" 또는 \"제품 평가를 예측하십시오\"와 같은 프롬프트 템플릿을 적용하여, 개발자는 원시 리뷰를 세부 조정을 위한 지시 프롬프트로 변환할 수 있습니다.\u003c/li\u003e\n\u003cli\u003eStanford Sentiment Treebank (SST): SST는 감정(긍정적 또는 부정적)으로 분류된 영화 리뷰를 포함하는 데이터셋입니다. 적절한 프롬프트 템플릿을 사용하면 연구자들은 SST를 감정 분석 세밀 조정 작업용 지시 프롬프트 데이터 세트로 변환할 수 있습니다.\u003c/li\u003e\n\u003cli\u003eCNN/Daily Mail 데이터 세트: 이 데이터 세트는 뉴스 기사와 글머리 기사 요약이 짝지어진 것입니다. \"이 기사에 대한 요약 생성\"과 같은 프롬프트 템플릿을 활용하여 개발자는 텍스트 요약 세밀 조정용 지시 데이터 세트를 준비할 수 있습니다.\u003c/li\u003e\n\u003cli\u003eWMT 번역 작업 데이터 세트: WMT(기계 번역 워크샵)은 기계 번역 모델을 훈련하기 위한 데이터 세트를 제공합니다. \"이 문장을 프랑스어로 번역하십시오\"와 같은 프롬프트 템플릿을 사용하여 연구자는 번역 세밀 조정 작업용 지시 프롬프트를 생성할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e4. 지시 세밀 조정 프로세스\u003c/h1\u003e\n\u003cp\u003e지시 데이터 세트를 준비했다면, 이를 훈련, 검증 및 테스트 세트로 나눕니다. 세밀 조정 중에는 훈련 데이터 세트에서 프롬프트를 선택하고 LLM에 전달하여 완성본을 생성합니다.\u003c/p\u003e\n\u003cp\u003eLLM 완성 결과를 교육 데이터에 지정된 응답과 비교하여 표준 교차 엔트로피 함수를 사용하여 손실을 계산하고 역전파를 통해 모델 가중치를 업데이트하십시오.\u003c/p\u003e\n\u003cp\u003e모델의 성능을 향상시키기 위해 여러 배치의 프롬프트-완성 쌍을 여러 번의 epoch 동안 반복합니다.\u003c/p\u003e\n\u003ch1\u003e5. 평가 및 성능 지표\u003c/h1\u003e\n\u003cp\u003e표준 지도 학습과 마찬가지로, 보유 검증 데이터 세트를 사용하여 LLM 성능을 측정하는 별도의 평가 단계를 정의하여 검증 정확도를 얻습니다.\u003c/p\u003e\n\u003cp\u003e미세 조정을 완료한 후, 테스트 정확도를 얻기 위해 홀드아웃 테스트 데이터셋을 사용하여 최종 성능 평가를 수행하십시오. 이때, 이메일 보완보상평가(BLEU) 및 ROUGE(Recall-Oriented Understudy for Gisting Evaluation)은 긴 통역모델 (LLM) 지침 미세 조정을 평가하는 데 사용되는 인기있는 두 평가 지표 중 하나입니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eBLEU (이중 언어 평가 보조) 스코어:\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e정의: 한 언어에서 다른 언어로 기계 번역된 텍스트의 품질을 평가하기 위한 지표로, 이를 인간이 만든 번역과 비교합니다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e예시: 번역 작업에서 모델이 \"The weather is nice today\"을 정확하게 \"Le temps est agréable aujourd’hui\"로 번역했을 때, 인간 번역과 비교하여 BLEU 스코어가 높게 나타납니다.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003eROUGE (Recall-Oriented Understudy for Gisting Evaluation) 스코어:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul\u003e\n\u003cli\u003e정의: 자동 요약 및 기계 번역을 평가하는 메트릭스 세트입니다. 이는 모델 출력물과 참조 텍스트 간의 n-gram의 중첩을 측정합니다.\u003c/li\u003e\n\u003cli\u003e예시: 요약 작업의 경우, 높은 ROUGE 점수는 모델이 생성한 요약과 인간이 작성한 요약 간에 높은 중첩이 있음을 나타냅니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e세밀 조정 과정은 기반 모델의 새 버전을 만들어내며 이를 보통 가르침 모델이라고 합니다. 이는 당신이 관심 있는 작업에 더 적합한 모델입니다.\u003c/p\u003e\n\u003cp\u003e지시 프롬프트로 세밀 조정하는 것이 오늘날 LLM을 세밀 조정하는 가장 흔한 방법입니다. 본 문서에서는 이 중요한 주제에 대해 간략히 소개되었으니 이제 손을 더럽히고 LLM을 조금 만지작거리며 조정해보는 것이 시간입니다.\u003c/p\u003e\n\u003ch2\u003e만약 이 문서를 좋아하셨고 저를 지원하고 싶으시다면, 확인해주십시오:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e👏 이 이야기에 박수를 보내주세요 (50번 클랩!) 이 기사가 주목받을 수 있도록 도와주세요\u003c/li\u003e\n\u003cli\u003eTo Data \u0026#x26; Beyond 뉴스레터를 구독해주세요\u003c/li\u003e\n\u003cli\u003e제 Medium 계정을 팔로우해주세요\u003c/li\u003e\n\u003cli\u003e📰 제 Medium 프로필에서 더 많은 콘텐츠를 확인해주세요\u003c/li\u003e\n\u003cli\u003e🔔 팔로우하기: LinkedIn | Youtube | GitHub | Twitter\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e제 뉴스레터 'To Data \u0026#x26; Beyond'를 구독하여 제 글을 완전히 그리고 일찍 볼 수 있습니다:\u003c/h2\u003e\n\u003ch2\u003e데이터 과학과 AI 분야에서 커리어를 시작하고 방향을 모를 때 도움이 필요하신가요? 저는 데이터 과학 멘토링 세션과 장기적 커리어 멘토링을 제공합니다:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e멘토링 세션: \u003ca href=\"https://lnkd.in/dXeg3KPW\" rel=\"nofollow\" target=\"_blank\"\u003e링크\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e장기적 멘토링: \u003ca href=\"https://lnkd.in/dtdUYBrM\" rel=\"nofollow\" target=\"_blank\"\u003e링크\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs_1.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-AComprehensiveIntroductiontoInstructionFine-TuningforLLMs"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>