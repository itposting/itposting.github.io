<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>대형 언어 모델 완벽 이해  두 번째 이야기 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-22-LargeLanguageModelsExplainedII" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="대형 언어 모델 완벽 이해  두 번째 이야기 | itposting" data-gatsby-head="true"/><meta property="og:title" content="대형 언어 모델 완벽 이해  두 번째 이야기 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-22-LargeLanguageModelsExplainedII" data-gatsby-head="true"/><meta name="twitter:title" content="대형 언어 모델 완벽 이해  두 번째 이야기 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-22 20:33" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_buildManifest.js" defer=""></script><script src="/_next/static/8coAiP0lmiEK5aH6nkQkj/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">대형 언어 모델 완벽 이해  두 번째 이야기</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="대형 언어 모델 완벽 이해  두 번째 이야기" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 22, 2024</span><span class="posts_reading_time__f7YPP">7<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-22-LargeLanguageModelsExplainedII&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>ChatGPT의 추상적 진화와 LLM의 일반적인 세부 정보가 'Large Language Models Explained — I'에서 제공되었습니다. 이전 글에서 몇 가지 질문으로 글을 마무리했습니다. 이 글에서는 해당 질문에 대한 답을 논의하고 LLM의 기본 프로그래밍 측면부터 시작하겠습니다.</p>
<p>이전 글에서 언급했듯이, ChatGPT는 GPT(Generative Pre-trained Transformer)라는 LLM을 사용하며, LLM이란 단순히 여러 신경망의 조합일 뿐입니다. 결국 LLM은 딥러닝 모델이나 기계 학습 모델과 유사한 모델에 불과합니다. 그러므로 사용자가 ChatGPT에 질문을 하면 미리 훈련된 모델을 테스트하는 것과 유사합니다(기계 학습 모델을 사용할 때와 같은 방식입니다). 예를 들어, KNN 모델을 훈련하고 sklearn 패키지를 사용하는 경우 다음과 같이 작성할 수 있습니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> sklearn.<span class="hljs-property">neighbors</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">KNeighborsClassifier</span>
neigh = <span class="hljs-title class_">KNeighborsClassifier</span>(n_neighbors=<span class="hljs-number">3</span>)
neigh.<span class="hljs-title function_">fit</span>(X, y) ##모델을 훈련하기 위해 사용되는 <span class="hljs-variable constant_">LINE</span>
neigh.<span class="hljs-title function_">predict</span>([[<span class="hljs-number">1.1</span>]]) ##모델을 테스트하기 위해 사용되는 <span class="hljs-variable constant_">LINE</span>
</code></pre>
<p>위의 코드에서 'neigh.fit()' 함수는 KNN 분류기를 훈련하는 데 사용되고, 'neigh.predict()'는 주어진 테스트 데이터의 출력을 예측하는 데 사용됩니다. 비슷하게 ChatGPT에 묻는 질문은 Transformer 아키텍처를 기반으로 한 GPT 모델에 입력되어 문장의 끝에 도달할 때까지 다음 단어를 예측하게 됩니다. 우리가 KNN과 같은 분류기를 훈련하기 위해 작은 양의 데이터를 사용하는 것과 달리, GPT는 많은 양의 데이터로 훈련되었고 실행에 많은 메모리가 필요한 거대한 모델입니다. (참고: 이때 진짜 영웅 GPU가 필요합니다. GPU에 대해 자세히 설명하지는 않았지만 원한다면 여기서 배울 수 있습니다.)</p>
<div class="content-ad"></div>
<p>이제 이러한 LLM을 실행하기 위해 필요한 메모리 양은 상상 이상으로 많습니다. Openai 및 Google과 같은 몇 개의 회사만이 이러한 대규모 메모리를 확보할 수 있습니다. 만약 우리가 우리의 컴퓨터에서 이러한 거대한 LLM을 실행할 수 없다면, 어떻게 접근하고 그들을 활용할 수 있을까요? 이 질문의 답은 약간 까다롭습니다.<br>
우선 openai.com에 로그인하면 ChatGPT에 무료 액세스할 수 있습니다. 거기서 질문을 하고 채팅할 수 있습니다. Openai는 이러한 무거운 부하를 관리할 수 있는 강력한 백엔드(부하 분산)를 갖고 있습니다. 회사는 GPT가 실행 중인 서버를 항상 켜놓기 때문에 원하는 때에 질문할 수 있습니다.<br>
둘째로, 애플리케이션을 구축하는 데 LLM을 활용할 수 있습니다. 여러분이 애플리케이션을 구축하기 시작할 수 있는 기본 아이디어를 제공하겠습니다.</p>
<p>다음과 같은 방식으로 기본적인 API에 대한 개념을 가지고 있어야 합니다. 간단히 말해 Application Programming Interface(API)는 두 대 이상의 컴퓨터가 통신하는 방법입니다. 우리의 경우, 클라이언트는 애플리케이션을 구축하려는 사용자이며, 서버는 LLM이 실행 중인 곳입니다. 이 두 대 사이에 채널을 구축하려면 API를 사용해야 합니다. API는 키 형식으로 제공됩니다(일반적으로 알파벳과 숫자의 혼합).<br>
이제 서버와 통신하기 위한 API 키를 어떻게 얻을까요?</p>
<ol>
<li>openai.com에 방문합니다.</li>
<li>제품으로 이동합니다.</li>
<li>API 로그인으로 이동합니다. 세부 정보를 제공하고 로그인(또는 회원 가입)합니다.</li>
</ol>
<p><img src="/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png" alt="이미지"></p>
<ol start="4">
<li>API로 이동(OpenAI 모델을 응용 프로그램이나 비즈니스에 통합).</li>
<li>대시보드로 이동합니다.</li>
</ol>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-22-LargeLanguageModelsExplainedII_1.png" alt="이미지"></p>
<ol start="6">
<li>왼쪽 패널에서 API 키로 이동합니다.</li>
</ol>
<p><img src="/assets/img/2024-06-22-LargeLanguageModelsExplainedII_2.png" alt="이미지"></p>
<ol start="7">
<li>휴대폰 번호로 등록한 후 '새 비밀 키 생성' 옵션을 볼 수 있습니다. 해당 옵션을 클릭하여 키를 복사하고, 다른 곳에 키를 저장해주세요. 그렇지 않으면 '확인'을 클릭한 후 키가 보이지 않을 수 있습니다.</li>
</ol>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-22-LargeLanguageModelsExplainedII_3.png">
<p>와우! 이제 챗지피티 서버와 시스템 간의 통신 경로를 구축할 API 키가 있습니다.</p>
<p>중요한 노트:
GITHUB나 LINKEDIN을 포함하여 인터넷 상 어디에도 API 키를 노출시키지 마십시오. OPENAI에서 키 액세스를 취소하고 계정을 차단할 수 있습니다.
— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p>
<p>우리는 이제 LLMs를 사용한 애플리케이션을 구축하는 방법에 도달했습니다. Langchain은 Large Language Models (LLM)을 사용한 애플리케이션 생성을 간소화하기 위해 설계된 프레임워크입니다. Langchain은 Python 및 Javascript 언어로 사용할 수 있습니다. 이 기사에서는 Python 언어를 통해 langchain을 소개하고 모델을 사용하여 애플리케이션을 구축하는 방법을 소개하겠습니다.
여기서 Visual Studio Code 내부의 Python 노트북을 사용했습니다. 사용하고자 하는 편집기를 선택하실 수 있습니다.
먼저 새 폴더를 생성하고 해당 폴더를 Visual Studio Code에서 엽니다. 가상 환경을 생성하고 해당 환경 내에서 필요한 모든 라이브러리를 설치합니다.
가상 환경을 생성하려면,</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">pip install virtualenv
</code></pre>
<p>그런 다음 터미널에서,</p>
<p>virtualenv <code>env_name</code>를 입력하고 <code>env_name</code>\Scripts\activate를 실행하세요.</p>
<ul>
<li>필수 라이브러리 설치하기</li>
</ul>
<div class="content-ad"></div>
<pre><code class="hljs language-js">pip install langchain openai langchain_community ipykernel
</code></pre>
<p>노트북에서,</p>
<p>2.기본 쿼리</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> langchain.<span class="hljs-property">llms</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span>
api_key=<span class="hljs-string">"&#x3C;your_api_key>"</span>
llm=<span class="hljs-title class_">OpenAI</span>(model=<span class="hljs-string">"gpt-3.5-turbo"</span>,openai_api_key=api_key,temperature=<span class="hljs-number">0.5</span>)
llm.<span class="hljs-title function_">predict</span>(<span class="hljs-string">"Who is the Prime Minister of India?"</span>)
</code></pre>
<div class="content-ad"></div>
<p>먼저, langchain에서 OpenAI 모듈을 가져와서 모델 이름, API 키, 온도로 모델을 초기화합니다. 온도는 LLM의 창의성을 결정하는 것입니다. 온도가 낮을수록 LLM은 매번 유사한 답변을 생성하지만, 온도가 높으면 LLM은 더 창의적이 되어 다양한 답변을 제공합니다. llm.predict()은 최종 답변을 제공합니다.</p>
<ol start="3">
<li>체인과 프롬프트 템플릿</li>
</ol>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> langchain.<span class="hljs-property">prompts</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">PromptTemplate</span>
<span class="hljs-keyword">from</span> langchain.<span class="hljs-property">chains</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">LLMChain</span>
<span class="hljs-keyword">from</span> langchain.<span class="hljs-property">chains</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">SimpleSequentialChain</span>

template_1=<span class="hljs-title class_">PromptTemplate</span>(input_variables=[<span class="hljs-string">'country'</span>],
template=<span class="hljs-string">"Tell me the president of {country}"</span>)

chain_1=<span class="hljs-title class_">LLMChain</span>(llm=llm,prompt=template_1)

template_2=<span class="hljs-title class_">PromptTemplate</span>(input_variables=[<span class="hljs-string">'president'</span>],
template=<span class="hljs-string">"Give me the list of changes made by the {president}"</span>)

chain_2=<span class="hljs-title class_">LLMChain</span>(llm=llm,prompt=template_2)

chain=<span class="hljs-title class_">SimpleSequentialChain</span>(chains=[chain_1,chain_2])
chain.<span class="hljs-title function_">run</span>(<span class="hljs-string">"United States of America"</span>)
</code></pre>
<p>아마 궁금하실거에요. 위 코드에서 두 가지 중요한 것들을 눈치채실 수 있어요. 프롬프트 템플릿과 체인입니다.
영어 웅변 대회에 참가 중이라고 상상해보세요. 심사위원들이 '나렌드라 모디'라는 주제를 주고 "인도는 민주국가이며 현재 나렌드라 모디 총리가 이끄는 중입니다"라고 시작해서 이어가라고 하면 쉬울 거에요. 단순히 주제만 주고 계속 이어가라고 하면 조금 어려울 수도 있어요.
이게 바로 프롬프트 템플릿이에요. 이는 ChatGPT에 답변을 제시하도록 모델을 유도하는 템플릿과 같아요. 이 코드에서는 "Tell me the president of 'country'"와 같은 프롬프트를 제공했는데, run() 함수에서 국가 이름을 언제든지 변경할 수 있어요.
이제 하나의 템플릿의 답변을 다른 템플릿으로 전달하고 싶다면, 다른 질문의 답변에 의존하는 경우에는 체인이라는 개념을 사용해야 해요. 체인은 LLM에 대한 단일 API 호출을 넘어 여러 호출을 순차적으로 연결할 수 있게 해줘요. 여기서 LLMChain은 LLM과 해당 템플릿을 묶는 데 사용됩니다. 여기서 사용한 것은 2개 이상의 LLMChain(체인 1, 체인 2)을 사용하는 간단한 순차 체인이며, 하나의 입력(United States of America)에 기반한 답변을 제공합니다.
요약하면, 이 간단한 코드 조각은 프롬프트 템플릿과 체인의 사용법을 보여줍니다. 여기서는 Langchain에서 직접 가져온 SimpleSequentialChain과 Prompt Template의 사용법을 보여줬어요. 첫 번째 템플릿은 "Who is the president of United States of America"이며, 답은 "Joe Biden"이고, 이는 다음 템플릿인 "List the changes made by Joe Biden"에 입력으로 전달되어 마지막 답변이 표시됩니다.</p>
<div class="content-ad"></div>
<hr>
<p>이 기사에서는 대형 언어 모델에 대한 토론을 이어가겠습니다. ChatGPT의 추상 작동 방식으로 시작하여 GPT를 API 키를 통해 대형 언어 모델로 사용하는 방법에 대해 설명했습니다. 마지막으로 API 키를 사용하고 Langchain이라는 프레임워크를 활용하여 LLM에 쿼리하는 기본 아이디어를 소개했습니다. 모든 LLM을 활용하고 커스텀 애플리케이션을 구축하는 경우가 많이 있습니다. 또한 이곳에서 논의되지 않은 LLM의 많은 구성 요소가 있습니다. 본 기사는 ChatGPT와 Langchain의 작동 방식에 대한 스타터 팩을 제공하는 것을 목표로 합니다. 본 기사에서 언급한 모든 기술 용어에 대해 자세히 논의할 내용이 더 많습니다. 이전 기사에서 받은 질문에 대한 답변을 통해 적절히 대답했기를 바랍니다.
모든 것을 천천히 다룰 것을 약속합니다. 그때까지 '계속 배우기'!
감사합니다!</p>
<hr>
<ul>
<li><a href="https://openai.com/" rel="nofollow" target="_blank">https://openai.com/</a></li>
<li><a href="https://python.langchain.com/v0.2/docs/tutorials/llm_chain/" rel="nofollow" target="_blank">https://python.langchain.com/v0.2/docs/tutorials/llm_chain/</a></li>
<li><a href="https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/llms" rel="nofollow" target="_blank">https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/llms</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar" rel="nofollow" target="_blank">https://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar</a></li>
</ul>
<div class="content-ad"></div>
<hr>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"대형 언어 모델 완벽 이해  두 번째 이야기","description":"","date":"2024-06-22 20:33","slug":"2024-06-22-LargeLanguageModelsExplainedII","content":"\n\nChatGPT의 추상적 진화와 LLM의 일반적인 세부 정보가 'Large Language Models Explained — I'에서 제공되었습니다. 이전 글에서 몇 가지 질문으로 글을 마무리했습니다. 이 글에서는 해당 질문에 대한 답을 논의하고 LLM의 기본 프로그래밍 측면부터 시작하겠습니다.\n\n이전 글에서 언급했듯이, ChatGPT는 GPT(Generative Pre-trained Transformer)라는 LLM을 사용하며, LLM이란 단순히 여러 신경망의 조합일 뿐입니다. 결국 LLM은 딥러닝 모델이나 기계 학습 모델과 유사한 모델에 불과합니다. 그러므로 사용자가 ChatGPT에 질문을 하면 미리 훈련된 모델을 테스트하는 것과 유사합니다(기계 학습 모델을 사용할 때와 같은 방식입니다). 예를 들어, KNN 모델을 훈련하고 sklearn 패키지를 사용하는 경우 다음과 같이 작성할 수 있습니다.\n\n```js\nfrom sklearn.neighbors import KNeighborsClassifier\nneigh = KNeighborsClassifier(n_neighbors=3)\nneigh.fit(X, y) ##모델을 훈련하기 위해 사용되는 LINE\nneigh.predict([[1.1]]) ##모델을 테스트하기 위해 사용되는 LINE\n```\n\n위의 코드에서 'neigh.fit()' 함수는 KNN 분류기를 훈련하는 데 사용되고, 'neigh.predict()'는 주어진 테스트 데이터의 출력을 예측하는 데 사용됩니다. 비슷하게 ChatGPT에 묻는 질문은 Transformer 아키텍처를 기반으로 한 GPT 모델에 입력되어 문장의 끝에 도달할 때까지 다음 단어를 예측하게 됩니다. 우리가 KNN과 같은 분류기를 훈련하기 위해 작은 양의 데이터를 사용하는 것과 달리, GPT는 많은 양의 데이터로 훈련되었고 실행에 많은 메모리가 필요한 거대한 모델입니다. (참고: 이때 진짜 영웅 GPU가 필요합니다. GPU에 대해 자세히 설명하지는 않았지만 원한다면 여기서 배울 수 있습니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 이러한 LLM을 실행하기 위해 필요한 메모리 양은 상상 이상으로 많습니다. Openai 및 Google과 같은 몇 개의 회사만이 이러한 대규모 메모리를 확보할 수 있습니다. 만약 우리가 우리의 컴퓨터에서 이러한 거대한 LLM을 실행할 수 없다면, 어떻게 접근하고 그들을 활용할 수 있을까요? 이 질문의 답은 약간 까다롭습니다.  \n우선 openai.com에 로그인하면 ChatGPT에 무료 액세스할 수 있습니다. 거기서 질문을 하고 채팅할 수 있습니다. Openai는 이러한 무거운 부하를 관리할 수 있는 강력한 백엔드(부하 분산)를 갖고 있습니다. 회사는 GPT가 실행 중인 서버를 항상 켜놓기 때문에 원하는 때에 질문할 수 있습니다.  \n둘째로, 애플리케이션을 구축하는 데 LLM을 활용할 수 있습니다. 여러분이 애플리케이션을 구축하기 시작할 수 있는 기본 아이디어를 제공하겠습니다.  \n\n다음과 같은 방식으로 기본적인 API에 대한 개념을 가지고 있어야 합니다. 간단히 말해 Application Programming Interface(API)는 두 대 이상의 컴퓨터가 통신하는 방법입니다. 우리의 경우, 클라이언트는 애플리케이션을 구축하려는 사용자이며, 서버는 LLM이 실행 중인 곳입니다. 이 두 대 사이에 채널을 구축하려면 API를 사용해야 합니다. API는 키 형식으로 제공됩니다(일반적으로 알파벳과 숫자의 혼합).  \n이제 서버와 통신하기 위한 API 키를 어떻게 얻을까요?  \n1) openai.com에 방문합니다.  \n2) 제품으로 이동합니다.  \n3) API 로그인으로 이동합니다. 세부 정보를 제공하고 로그인(또는 회원 가입)합니다.  \n\n![이미지](/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png)\n\n4) API로 이동(OpenAI 모델을 응용 프로그램이나 비즈니스에 통합).  \n5) 대시보드로 이동합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-22-LargeLanguageModelsExplainedII_1.png)\n\n6) 왼쪽 패널에서 API 키로 이동합니다.\n\n![이미지](/assets/img/2024-06-22-LargeLanguageModelsExplainedII_2.png)\n\n7) 휴대폰 번호로 등록한 후 '새 비밀 키 생성' 옵션을 볼 수 있습니다. 해당 옵션을 클릭하여 키를 복사하고, 다른 곳에 키를 저장해주세요. 그렇지 않으면 '확인'을 클릭한 후 키가 보이지 않을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_3.png\" /\u003e\n\n와우! 이제 챗지피티 서버와 시스템 간의 통신 경로를 구축할 API 키가 있습니다.\n\n중요한 노트:\nGITHUB나 LINKEDIN을 포함하여 인터넷 상 어디에도 API 키를 노출시키지 마십시오. OPENAI에서 키 액세스를 취소하고 계정을 차단할 수 있습니다.\n— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\n\n우리는 이제 LLMs를 사용한 애플리케이션을 구축하는 방법에 도달했습니다. Langchain은 Large Language Models (LLM)을 사용한 애플리케이션 생성을 간소화하기 위해 설계된 프레임워크입니다. Langchain은 Python 및 Javascript 언어로 사용할 수 있습니다. 이 기사에서는 Python 언어를 통해 langchain을 소개하고 모델을 사용하여 애플리케이션을 구축하는 방법을 소개하겠습니다.\n여기서 Visual Studio Code 내부의 Python 노트북을 사용했습니다. 사용하고자 하는 편집기를 선택하실 수 있습니다.\n먼저 새 폴더를 생성하고 해당 폴더를 Visual Studio Code에서 엽니다. 가상 환경을 생성하고 해당 환경 내에서 필요한 모든 라이브러리를 설치합니다.\n가상 환경을 생성하려면,\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\npip install virtualenv\n```\n\n그런 다음 터미널에서,\n\nvirtualenv `env_name`를 입력하고 `env_name`\\Scripts\\activate를 실행하세요.\n\n- 필수 라이브러리 설치하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\npip install langchain openai langchain_community ipykernel\n```\n\n노트북에서,\n\n2.기본 쿼리\n\n```js\nfrom langchain.llms import OpenAI\napi_key=\"\u003cyour_api_key\u003e\"\nllm=OpenAI(model=\"gpt-3.5-turbo\",openai_api_key=api_key,temperature=0.5)\nllm.predict(\"Who is the Prime Minister of India?\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, langchain에서 OpenAI 모듈을 가져와서 모델 이름, API 키, 온도로 모델을 초기화합니다. 온도는 LLM의 창의성을 결정하는 것입니다. 온도가 낮을수록 LLM은 매번 유사한 답변을 생성하지만, 온도가 높으면 LLM은 더 창의적이 되어 다양한 답변을 제공합니다. llm.predict()은 최종 답변을 제공합니다.\n\n3. 체인과 프롬프트 템플릿\n\n```js\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain.chains import SimpleSequentialChain\n\ntemplate_1=PromptTemplate(input_variables=['country'],\ntemplate=\"Tell me the president of {country}\")\n\nchain_1=LLMChain(llm=llm,prompt=template_1)\n\ntemplate_2=PromptTemplate(input_variables=['president'],\ntemplate=\"Give me the list of changes made by the {president}\")\n\nchain_2=LLMChain(llm=llm,prompt=template_2)\n\nchain=SimpleSequentialChain(chains=[chain_1,chain_2])\nchain.run(\"United States of America\")\n```\n\n아마 궁금하실거에요. 위 코드에서 두 가지 중요한 것들을 눈치채실 수 있어요. 프롬프트 템플릿과 체인입니다.\n영어 웅변 대회에 참가 중이라고 상상해보세요. 심사위원들이 '나렌드라 모디'라는 주제를 주고 \"인도는 민주국가이며 현재 나렌드라 모디 총리가 이끄는 중입니다\"라고 시작해서 이어가라고 하면 쉬울 거에요. 단순히 주제만 주고 계속 이어가라고 하면 조금 어려울 수도 있어요.\n이게 바로 프롬프트 템플릿이에요. 이는 ChatGPT에 답변을 제시하도록 모델을 유도하는 템플릿과 같아요. 이 코드에서는 \"Tell me the president of 'country'\"와 같은 프롬프트를 제공했는데, run() 함수에서 국가 이름을 언제든지 변경할 수 있어요.\n이제 하나의 템플릿의 답변을 다른 템플릿으로 전달하고 싶다면, 다른 질문의 답변에 의존하는 경우에는 체인이라는 개념을 사용해야 해요. 체인은 LLM에 대한 단일 API 호출을 넘어 여러 호출을 순차적으로 연결할 수 있게 해줘요. 여기서 LLMChain은 LLM과 해당 템플릿을 묶는 데 사용됩니다. 여기서 사용한 것은 2개 이상의 LLMChain(체인 1, 체인 2)을 사용하는 간단한 순차 체인이며, 하나의 입력(United States of America)에 기반한 답변을 제공합니다.\n요약하면, 이 간단한 코드 조각은 프롬프트 템플릿과 체인의 사용법을 보여줍니다. 여기서는 Langchain에서 직접 가져온 SimpleSequentialChain과 Prompt Template의 사용법을 보여줬어요. 첫 번째 템플릿은 \"Who is the president of United States of America\"이며, 답은 \"Joe Biden\"이고, 이는 다음 템플릿인 \"List the changes made by Joe Biden\"에 입력으로 전달되어 마지막 답변이 표시됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---\n\n이 기사에서는 대형 언어 모델에 대한 토론을 이어가겠습니다. ChatGPT의 추상 작동 방식으로 시작하여 GPT를 API 키를 통해 대형 언어 모델로 사용하는 방법에 대해 설명했습니다. 마지막으로 API 키를 사용하고 Langchain이라는 프레임워크를 활용하여 LLM에 쿼리하는 기본 아이디어를 소개했습니다. 모든 LLM을 활용하고 커스텀 애플리케이션을 구축하는 경우가 많이 있습니다. 또한 이곳에서 논의되지 않은 LLM의 많은 구성 요소가 있습니다. 본 기사는 ChatGPT와 Langchain의 작동 방식에 대한 스타터 팩을 제공하는 것을 목표로 합니다. 본 기사에서 언급한 모든 기술 용어에 대해 자세히 논의할 내용이 더 많습니다. 이전 기사에서 받은 질문에 대한 답변을 통해 적절히 대답했기를 바랍니다. \n모든 것을 천천히 다룰 것을 약속합니다. 그때까지 '계속 배우기'!\n감사합니다!\n\n--- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- ---\n\n- https://openai.com/\n- https://python.langchain.com/v0.2/docs/tutorials/llm_chain/\n- https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/llms\n- https://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n---","ogImage":{"url":"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png"},"coverImage":"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png","tag":["Tech"],"readingTime":7},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003eChatGPT의 추상적 진화와 LLM의 일반적인 세부 정보가 'Large Language Models Explained — I'에서 제공되었습니다. 이전 글에서 몇 가지 질문으로 글을 마무리했습니다. 이 글에서는 해당 질문에 대한 답을 논의하고 LLM의 기본 프로그래밍 측면부터 시작하겠습니다.\u003c/p\u003e\n\u003cp\u003e이전 글에서 언급했듯이, ChatGPT는 GPT(Generative Pre-trained Transformer)라는 LLM을 사용하며, LLM이란 단순히 여러 신경망의 조합일 뿐입니다. 결국 LLM은 딥러닝 모델이나 기계 학습 모델과 유사한 모델에 불과합니다. 그러므로 사용자가 ChatGPT에 질문을 하면 미리 훈련된 모델을 테스트하는 것과 유사합니다(기계 학습 모델을 사용할 때와 같은 방식입니다). 예를 들어, KNN 모델을 훈련하고 sklearn 패키지를 사용하는 경우 다음과 같이 작성할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e sklearn.\u003cspan class=\"hljs-property\"\u003eneighbors\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eKNeighborsClassifier\u003c/span\u003e\nneigh = \u003cspan class=\"hljs-title class_\"\u003eKNeighborsClassifier\u003c/span\u003e(n_neighbors=\u003cspan class=\"hljs-number\"\u003e3\u003c/span\u003e)\nneigh.\u003cspan class=\"hljs-title function_\"\u003efit\u003c/span\u003e(X, y) ##모델을 훈련하기 위해 사용되는 \u003cspan class=\"hljs-variable constant_\"\u003eLINE\u003c/span\u003e\nneigh.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e([[\u003cspan class=\"hljs-number\"\u003e1.1\u003c/span\u003e]]) ##모델을 테스트하기 위해 사용되는 \u003cspan class=\"hljs-variable constant_\"\u003eLINE\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e위의 코드에서 'neigh.fit()' 함수는 KNN 분류기를 훈련하는 데 사용되고, 'neigh.predict()'는 주어진 테스트 데이터의 출력을 예측하는 데 사용됩니다. 비슷하게 ChatGPT에 묻는 질문은 Transformer 아키텍처를 기반으로 한 GPT 모델에 입력되어 문장의 끝에 도달할 때까지 다음 단어를 예측하게 됩니다. 우리가 KNN과 같은 분류기를 훈련하기 위해 작은 양의 데이터를 사용하는 것과 달리, GPT는 많은 양의 데이터로 훈련되었고 실행에 많은 메모리가 필요한 거대한 모델입니다. (참고: 이때 진짜 영웅 GPU가 필요합니다. GPU에 대해 자세히 설명하지는 않았지만 원한다면 여기서 배울 수 있습니다.)\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이제 이러한 LLM을 실행하기 위해 필요한 메모리 양은 상상 이상으로 많습니다. Openai 및 Google과 같은 몇 개의 회사만이 이러한 대규모 메모리를 확보할 수 있습니다. 만약 우리가 우리의 컴퓨터에서 이러한 거대한 LLM을 실행할 수 없다면, 어떻게 접근하고 그들을 활용할 수 있을까요? 이 질문의 답은 약간 까다롭습니다.\u003cbr\u003e\n우선 openai.com에 로그인하면 ChatGPT에 무료 액세스할 수 있습니다. 거기서 질문을 하고 채팅할 수 있습니다. Openai는 이러한 무거운 부하를 관리할 수 있는 강력한 백엔드(부하 분산)를 갖고 있습니다. 회사는 GPT가 실행 중인 서버를 항상 켜놓기 때문에 원하는 때에 질문할 수 있습니다.\u003cbr\u003e\n둘째로, 애플리케이션을 구축하는 데 LLM을 활용할 수 있습니다. 여러분이 애플리케이션을 구축하기 시작할 수 있는 기본 아이디어를 제공하겠습니다.\u003c/p\u003e\n\u003cp\u003e다음과 같은 방식으로 기본적인 API에 대한 개념을 가지고 있어야 합니다. 간단히 말해 Application Programming Interface(API)는 두 대 이상의 컴퓨터가 통신하는 방법입니다. 우리의 경우, 클라이언트는 애플리케이션을 구축하려는 사용자이며, 서버는 LLM이 실행 중인 곳입니다. 이 두 대 사이에 채널을 구축하려면 API를 사용해야 합니다. API는 키 형식으로 제공됩니다(일반적으로 알파벳과 숫자의 혼합).\u003cbr\u003e\n이제 서버와 통신하기 위한 API 키를 어떻게 얻을까요?\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eopenai.com에 방문합니다.\u003c/li\u003e\n\u003cli\u003e제품으로 이동합니다.\u003c/li\u003e\n\u003cli\u003eAPI 로그인으로 이동합니다. 세부 정보를 제공하고 로그인(또는 회원 가입)합니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003eAPI로 이동(OpenAI 모델을 응용 프로그램이나 비즈니스에 통합).\u003c/li\u003e\n\u003cli\u003e대시보드로 이동합니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003col start=\"6\"\u003e\n\u003cli\u003e왼쪽 패널에서 API 키로 이동합니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003col start=\"7\"\u003e\n\u003cli\u003e휴대폰 번호로 등록한 후 '새 비밀 키 생성' 옵션을 볼 수 있습니다. 해당 옵션을 클릭하여 키를 복사하고, 다른 곳에 키를 저장해주세요. 그렇지 않으면 '확인'을 클릭한 후 키가 보이지 않을 수 있습니다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-22-LargeLanguageModelsExplainedII_3.png\"\u003e\n\u003cp\u003e와우! 이제 챗지피티 서버와 시스템 간의 통신 경로를 구축할 API 키가 있습니다.\u003c/p\u003e\n\u003cp\u003e중요한 노트:\nGITHUB나 LINKEDIN을 포함하여 인터넷 상 어디에도 API 키를 노출시키지 마십시오. OPENAI에서 키 액세스를 취소하고 계정을 차단할 수 있습니다.\n— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —\u003c/p\u003e\n\u003cp\u003e우리는 이제 LLMs를 사용한 애플리케이션을 구축하는 방법에 도달했습니다. Langchain은 Large Language Models (LLM)을 사용한 애플리케이션 생성을 간소화하기 위해 설계된 프레임워크입니다. Langchain은 Python 및 Javascript 언어로 사용할 수 있습니다. 이 기사에서는 Python 언어를 통해 langchain을 소개하고 모델을 사용하여 애플리케이션을 구축하는 방법을 소개하겠습니다.\n여기서 Visual Studio Code 내부의 Python 노트북을 사용했습니다. 사용하고자 하는 편집기를 선택하실 수 있습니다.\n먼저 새 폴더를 생성하고 해당 폴더를 Visual Studio Code에서 엽니다. 가상 환경을 생성하고 해당 환경 내에서 필요한 모든 라이브러리를 설치합니다.\n가상 환경을 생성하려면,\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003epip install virtualenv\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그런 다음 터미널에서,\u003c/p\u003e\n\u003cp\u003evirtualenv \u003ccode\u003eenv_name\u003c/code\u003e를 입력하고 \u003ccode\u003eenv_name\u003c/code\u003e\\Scripts\\activate를 실행하세요.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e필수 라이브러리 설치하기\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003epip install langchain openai langchain_community ipykernel\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e노트북에서,\u003c/p\u003e\n\u003cp\u003e2.기본 쿼리\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain.\u003cspan class=\"hljs-property\"\u003ellms\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eOpenAI\u003c/span\u003e\napi_key=\u003cspan class=\"hljs-string\"\u003e\"\u0026#x3C;your_api_key\u003e\"\u003c/span\u003e\nllm=\u003cspan class=\"hljs-title class_\"\u003eOpenAI\u003c/span\u003e(model=\u003cspan class=\"hljs-string\"\u003e\"gpt-3.5-turbo\"\u003c/span\u003e,openai_api_key=api_key,temperature=\u003cspan class=\"hljs-number\"\u003e0.5\u003c/span\u003e)\nllm.\u003cspan class=\"hljs-title function_\"\u003epredict\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Who is the Prime Minister of India?\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e먼저, langchain에서 OpenAI 모듈을 가져와서 모델 이름, API 키, 온도로 모델을 초기화합니다. 온도는 LLM의 창의성을 결정하는 것입니다. 온도가 낮을수록 LLM은 매번 유사한 답변을 생성하지만, 온도가 높으면 LLM은 더 창의적이 되어 다양한 답변을 제공합니다. llm.predict()은 최종 답변을 제공합니다.\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e체인과 프롬프트 템플릿\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain.\u003cspan class=\"hljs-property\"\u003eprompts\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003ePromptTemplate\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain.\u003cspan class=\"hljs-property\"\u003echains\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eLLMChain\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain.\u003cspan class=\"hljs-property\"\u003echains\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSimpleSequentialChain\u003c/span\u003e\n\ntemplate_1=\u003cspan class=\"hljs-title class_\"\u003ePromptTemplate\u003c/span\u003e(input_variables=[\u003cspan class=\"hljs-string\"\u003e'country'\u003c/span\u003e],\ntemplate=\u003cspan class=\"hljs-string\"\u003e\"Tell me the president of {country}\"\u003c/span\u003e)\n\nchain_1=\u003cspan class=\"hljs-title class_\"\u003eLLMChain\u003c/span\u003e(llm=llm,prompt=template_1)\n\ntemplate_2=\u003cspan class=\"hljs-title class_\"\u003ePromptTemplate\u003c/span\u003e(input_variables=[\u003cspan class=\"hljs-string\"\u003e'president'\u003c/span\u003e],\ntemplate=\u003cspan class=\"hljs-string\"\u003e\"Give me the list of changes made by the {president}\"\u003c/span\u003e)\n\nchain_2=\u003cspan class=\"hljs-title class_\"\u003eLLMChain\u003c/span\u003e(llm=llm,prompt=template_2)\n\nchain=\u003cspan class=\"hljs-title class_\"\u003eSimpleSequentialChain\u003c/span\u003e(chains=[chain_1,chain_2])\nchain.\u003cspan class=\"hljs-title function_\"\u003erun\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"United States of America\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e아마 궁금하실거에요. 위 코드에서 두 가지 중요한 것들을 눈치채실 수 있어요. 프롬프트 템플릿과 체인입니다.\n영어 웅변 대회에 참가 중이라고 상상해보세요. 심사위원들이 '나렌드라 모디'라는 주제를 주고 \"인도는 민주국가이며 현재 나렌드라 모디 총리가 이끄는 중입니다\"라고 시작해서 이어가라고 하면 쉬울 거에요. 단순히 주제만 주고 계속 이어가라고 하면 조금 어려울 수도 있어요.\n이게 바로 프롬프트 템플릿이에요. 이는 ChatGPT에 답변을 제시하도록 모델을 유도하는 템플릿과 같아요. 이 코드에서는 \"Tell me the president of 'country'\"와 같은 프롬프트를 제공했는데, run() 함수에서 국가 이름을 언제든지 변경할 수 있어요.\n이제 하나의 템플릿의 답변을 다른 템플릿으로 전달하고 싶다면, 다른 질문의 답변에 의존하는 경우에는 체인이라는 개념을 사용해야 해요. 체인은 LLM에 대한 단일 API 호출을 넘어 여러 호출을 순차적으로 연결할 수 있게 해줘요. 여기서 LLMChain은 LLM과 해당 템플릿을 묶는 데 사용됩니다. 여기서 사용한 것은 2개 이상의 LLMChain(체인 1, 체인 2)을 사용하는 간단한 순차 체인이며, 하나의 입력(United States of America)에 기반한 답변을 제공합니다.\n요약하면, 이 간단한 코드 조각은 프롬프트 템플릿과 체인의 사용법을 보여줍니다. 여기서는 Langchain에서 직접 가져온 SimpleSequentialChain과 Prompt Template의 사용법을 보여줬어요. 첫 번째 템플릿은 \"Who is the president of United States of America\"이며, 답은 \"Joe Biden\"이고, 이는 다음 템플릿인 \"List the changes made by Joe Biden\"에 입력으로 전달되어 마지막 답변이 표시됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003cp\u003e이 기사에서는 대형 언어 모델에 대한 토론을 이어가겠습니다. ChatGPT의 추상 작동 방식으로 시작하여 GPT를 API 키를 통해 대형 언어 모델로 사용하는 방법에 대해 설명했습니다. 마지막으로 API 키를 사용하고 Langchain이라는 프레임워크를 활용하여 LLM에 쿼리하는 기본 아이디어를 소개했습니다. 모든 LLM을 활용하고 커스텀 애플리케이션을 구축하는 경우가 많이 있습니다. 또한 이곳에서 논의되지 않은 LLM의 많은 구성 요소가 있습니다. 본 기사는 ChatGPT와 Langchain의 작동 방식에 대한 스타터 팩을 제공하는 것을 목표로 합니다. 본 기사에서 언급한 모든 기술 용어에 대해 자세히 논의할 내용이 더 많습니다. 이전 기사에서 받은 질문에 대한 답변을 통해 적절히 대답했기를 바랍니다.\n모든 것을 천천히 다룰 것을 약속합니다. 그때까지 '계속 배우기'!\n감사합니다!\u003c/p\u003e\n\u003chr\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://openai.com/\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://openai.com/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://python.langchain.com/v0.2/docs/tutorials/llm_chain/\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://python.langchain.com/v0.2/docs/tutorials/llm_chain/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/llms\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://github.com/langchain-ai/langchain/tree/master/libs/langchain/langchain/llms\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://www.youtube.com/playlist?list=PLZoTAELRMXVORE4VF7WQ_fAl0L1Gljtar\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-22-LargeLanguageModelsExplainedII"},"buildId":"8coAiP0lmiEK5aH6nkQkj","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>