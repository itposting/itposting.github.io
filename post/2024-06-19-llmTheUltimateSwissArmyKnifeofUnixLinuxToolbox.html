<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>LLM Unix Linux 도구상자의 궁극적인 스위스 아미 나이프 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="LLM Unix Linux 도구상자의 궁극적인 스위스 아미 나이프 | itposting" data-gatsby-head="true"/><meta property="og:title" content="LLM Unix Linux 도구상자의 궁극적인 스위스 아미 나이프 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox" data-gatsby-head="true"/><meta name="twitter:title" content="LLM Unix Linux 도구상자의 궁극적인 스위스 아미 나이프 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 03:35" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">LLM Unix Linux 도구상자의 궁극적인 스위스 아미 나이프</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="LLM Unix Linux 도구상자의 궁극적인 스위스 아미 나이프" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">2<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h2>멋진 도구로 명령줄 작업을 더욱 효율적으로!</h2>
<p>최근에 Simon Willison이 만든 llm 명령줄 도구를 발견하게 되었습니다.</p>
<p>그는 최근에 이 도구를 어떻게 사용하는지에 대해 이야기했는데, 이를 일상적으로 사용하는 다른 명령줄 도구와 함께 어떻게 활용하는지를 보여주었습니다.</p>
<h2>이 도구는 무엇을 할까요?</h2>
<div class="content-ad"></div>
<p>간단히 말해서, 이 도구를 사용하면 워크플로우 중간에 LLM (대형 언어 모델)을 호출하고 강력한 방법으로 출력을 변환할 수 있습니다.</p>
<p>빠른 예시:</p>
<p>Github에서 더 많은 예시와 데모를 찾을 수 있습니다.</p>
<h2>왜 이것이 중요한가요?</h2>
<div class="content-ad"></div>
<p>여기서 인용하자면:</p>
<p>기존 애플리케이션 및 업무에 AI를 통합하는 것은 도전적입니다. 예를 들어, Github Copilot과 같은 솔루션이 이 기능을 지원하려면 각 IDE에 플러그인이 필요합니다. ChatGPT를 사용하는 동안에도 LLM 응답이 필요할 때마다 파일을 드래그 앤 드롭하거나 복사하여 붙여넣어야 하므로 데이터를 이동하는 데 더 많은 노력과 시간이 필요합니다.</p>
<h2>왜 이것이 뛰어난 아이디어인가요?</h2>
<p>이 도구는 Unix 철학에서의 주요 아이디어를 상쾌하게 부활시키는 것입니다.</p>
<div class="content-ad"></div>
<ul>
<li>하나의 기능을 잘 수행하는 프로그램을 작성하세요.</li>
<li>프로그램들이 함께 작동할 수 있도록 작성하세요.</li>
<li>모든 프로그램들이 텍스트 스트림을 처리하도록 작성하세요. 왜냐하면 그것이 보편적인 인터페이스이기 때문입니다.</li>
</ul>
<p>마지막으로, 위 세 번째 점은 LLMs이 이 목적에 적합하게 만들어진 이유입니다. 왜냐하면 그들은 프롬프트에 기반하여 하나의 텍스트를 다른 텍스트로 효과적으로 변환하는 데 우수하기 때문입니다.</p>
<p>좋은 상호 운용성을 위해서, 각 프로그램에 깔끔한 입출력 인터페이스가 있다면 좋고, 다른 프로그램의 출력을 표준 입력(stdin)을 통해 입력으로 받아 들이게 하는 것은 점 [2]로부터 따라온다.</p>
<h2>키 기능의 빠른 개요</h2>
<div class="content-ad"></div>
<ul>
<li>플러그인을 통한 로컬 및 원격 모델 지원: Ollama와 같은 도구를 통해 LLMs의 로컬 배포로 비용을 관리하세요.</li>
<li>템플릿 지원: Fabric과 같은 대체 도구는 "패턴"이라고 하는 템플릿을 커맨드 라인 도구로 제공하기 시작했습니다.</li>
</ul>
<p>전체 토크를 YouTube에서 시청하는 것을 적극 추천합니다.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"LLM Unix Linux 도구상자의 궁극적인 스위스 아미 나이프","description":"","date":"2024-06-19 03:35","slug":"2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox","content":"\n\n## 멋진 도구로 명령줄 작업을 더욱 효율적으로!\n\n최근에 Simon Willison이 만든 llm 명령줄 도구를 발견하게 되었습니다.\n\n그는 최근에 이 도구를 어떻게 사용하는지에 대해 이야기했는데, 이를 일상적으로 사용하는 다른 명령줄 도구와 함께 어떻게 활용하는지를 보여주었습니다.\n\n## 이 도구는 무엇을 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단히 말해서, 이 도구를 사용하면 워크플로우 중간에 LLM (대형 언어 모델)을 호출하고 강력한 방법으로 출력을 변환할 수 있습니다.\n\n빠른 예시:\n\nGithub에서 더 많은 예시와 데모를 찾을 수 있습니다.\n\n## 왜 이것이 중요한가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 인용하자면:\n\n기존 애플리케이션 및 업무에 AI를 통합하는 것은 도전적입니다. 예를 들어, Github Copilot과 같은 솔루션이 이 기능을 지원하려면 각 IDE에 플러그인이 필요합니다. ChatGPT를 사용하는 동안에도 LLM 응답이 필요할 때마다 파일을 드래그 앤 드롭하거나 복사하여 붙여넣어야 하므로 데이터를 이동하는 데 더 많은 노력과 시간이 필요합니다.\n\n## 왜 이것이 뛰어난 아이디어인가요?\n\n이 도구는 Unix 철학에서의 주요 아이디어를 상쾌하게 부활시키는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 하나의 기능을 잘 수행하는 프로그램을 작성하세요.\n- 프로그램들이 함께 작동할 수 있도록 작성하세요.\n- 모든 프로그램들이 텍스트 스트림을 처리하도록 작성하세요. 왜냐하면 그것이 보편적인 인터페이스이기 때문입니다.\n\n마지막으로, 위 세 번째 점은 LLMs이 이 목적에 적합하게 만들어진 이유입니다. 왜냐하면 그들은 프롬프트에 기반하여 하나의 텍스트를 다른 텍스트로 효과적으로 변환하는 데 우수하기 때문입니다.\n\n좋은 상호 운용성을 위해서, 각 프로그램에 깔끔한 입출력 인터페이스가 있다면 좋고, 다른 프로그램의 출력을 표준 입력(stdin)을 통해 입력으로 받아 들이게 하는 것은 점 [2]로부터 따라온다. \n\n## 키 기능의 빠른 개요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 플러그인을 통한 로컬 및 원격 모델 지원: Ollama와 같은 도구를 통해 LLMs의 로컬 배포로 비용을 관리하세요.\n- 템플릿 지원: Fabric과 같은 대체 도구는 \"패턴\"이라고 하는 템플릿을 커맨드 라인 도구로 제공하기 시작했습니다.\n\n전체 토크를 YouTube에서 시청하는 것을 적극 추천합니다.","ogImage":{"url":"/assets/img/2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox_0.png"},"coverImage":"/assets/img/2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox_0.png","tag":["Tech"],"readingTime":2},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch2\u003e멋진 도구로 명령줄 작업을 더욱 효율적으로!\u003c/h2\u003e\n\u003cp\u003e최근에 Simon Willison이 만든 llm 명령줄 도구를 발견하게 되었습니다.\u003c/p\u003e\n\u003cp\u003e그는 최근에 이 도구를 어떻게 사용하는지에 대해 이야기했는데, 이를 일상적으로 사용하는 다른 명령줄 도구와 함께 어떻게 활용하는지를 보여주었습니다.\u003c/p\u003e\n\u003ch2\u003e이 도구는 무엇을 할까요?\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e간단히 말해서, 이 도구를 사용하면 워크플로우 중간에 LLM (대형 언어 모델)을 호출하고 강력한 방법으로 출력을 변환할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e빠른 예시:\u003c/p\u003e\n\u003cp\u003eGithub에서 더 많은 예시와 데모를 찾을 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e왜 이것이 중요한가요?\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기서 인용하자면:\u003c/p\u003e\n\u003cp\u003e기존 애플리케이션 및 업무에 AI를 통합하는 것은 도전적입니다. 예를 들어, Github Copilot과 같은 솔루션이 이 기능을 지원하려면 각 IDE에 플러그인이 필요합니다. ChatGPT를 사용하는 동안에도 LLM 응답이 필요할 때마다 파일을 드래그 앤 드롭하거나 복사하여 붙여넣어야 하므로 데이터를 이동하는 데 더 많은 노력과 시간이 필요합니다.\u003c/p\u003e\n\u003ch2\u003e왜 이것이 뛰어난 아이디어인가요?\u003c/h2\u003e\n\u003cp\u003e이 도구는 Unix 철학에서의 주요 아이디어를 상쾌하게 부활시키는 것입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e하나의 기능을 잘 수행하는 프로그램을 작성하세요.\u003c/li\u003e\n\u003cli\u003e프로그램들이 함께 작동할 수 있도록 작성하세요.\u003c/li\u003e\n\u003cli\u003e모든 프로그램들이 텍스트 스트림을 처리하도록 작성하세요. 왜냐하면 그것이 보편적인 인터페이스이기 때문입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e마지막으로, 위 세 번째 점은 LLMs이 이 목적에 적합하게 만들어진 이유입니다. 왜냐하면 그들은 프롬프트에 기반하여 하나의 텍스트를 다른 텍스트로 효과적으로 변환하는 데 우수하기 때문입니다.\u003c/p\u003e\n\u003cp\u003e좋은 상호 운용성을 위해서, 각 프로그램에 깔끔한 입출력 인터페이스가 있다면 좋고, 다른 프로그램의 출력을 표준 입력(stdin)을 통해 입력으로 받아 들이게 하는 것은 점 [2]로부터 따라온다.\u003c/p\u003e\n\u003ch2\u003e키 기능의 빠른 개요\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e플러그인을 통한 로컬 및 원격 모델 지원: Ollama와 같은 도구를 통해 LLMs의 로컬 배포로 비용을 관리하세요.\u003c/li\u003e\n\u003cli\u003e템플릿 지원: Fabric과 같은 대체 도구는 \"패턴\"이라고 하는 템플릿을 커맨드 라인 도구로 제공하기 시작했습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e전체 토크를 YouTube에서 시청하는 것을 적극 추천합니다.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-llmTheUltimateSwissArmyKnifeofUnixLinuxToolbox"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>