<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>Code Llamaë¡œ ë‚˜ë§Œì˜ LLM ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“œëŠ” ë°©ë²•  | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="Code Llamaë¡œ ë‚˜ë§Œì˜ LLM ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“œëŠ” ë°©ë²•  | itposting" data-gatsby-head="true"/><meta property="og:title" content="Code Llamaë¡œ ë‚˜ë§Œì˜ LLM ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“œëŠ” ë°©ë²•  | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama" data-gatsby-head="true"/><meta name="twitter:title" content="Code Llamaë¡œ ë‚˜ë§Œì˜ LLM ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“œëŠ” ë°©ë²•  | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-22 21:36" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">Code Llamaë¡œ ë‚˜ë§Œì˜ LLM ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“œëŠ” ë°©ë²• </h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="Code Llamaë¡œ ë‚˜ë§Œì˜ LLM ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“œëŠ” ë°©ë²• " loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 22, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>ì´ ì‹¤ìŠµì—ì„œëŠ” ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê³  ë¡œì»¬ GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” AI ì½”ë“œ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬í˜„í•  ì˜ˆì •ì…ë‹ˆë‹¤.</p>
<p>ì±—ë´‡ì— ì§ˆë¬¸ì„ í•˜ë©´ ìì—°ì–´ë¡œ ë‹µë³€í•˜ë©° ì—¬ëŸ¬ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ì½”ë“œë„ ì œê³µí•©ë‹ˆë‹¤.</p>
<p>ìš°ë¦¬ëŠ” Hugging Face transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì„ êµ¬í˜„í•˜ê³  Chatbot í”„ë¡ íŠ¸ ì—”ë“œì—ëŠ” Streamlitì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.</p>
<h1>LLMì´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?</h1>
<div class="content-ad"></div>
<p>ë””ì½”ë” ì „ìš© íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì¸ GPT ê³„ì—´ì€ ì£¼ì–´ì§„ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ í…ìŠ¤íŠ¸ ìƒì„±ì— ì•„ì£¼ ëŠ¥ìˆ™í•©ë‹ˆë‹¤.</p>
<p><img src="/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_0.png" alt="ì´ë¯¸ì§€"></p>
<p>ì¶©ë¶„í•œ í›ˆë ¨ ë°ì´í„°ê°€ ì œê³µëœë‹¤ë©´, ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒë„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. IDEì—ì„œ ì½”ë“œë¥¼ ì±„ìš°ëŠ” ë°©ì‹ì´ë‚˜ ì±—ë´‡ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤.</p>
<p>GitHub Copilotì€ ìƒìš© ì˜ˆì‹œë¡œì„œ AI í˜ì–´ í”„ë¡œê·¸ë˜ë¨¸ì˜ í•œ ì˜ˆì…ë‹ˆë‹¤. Meta AIì˜ Code Llama ëª¨ë¸ì€ ìœ ì‚¬í•œ ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆì§€ë§Œ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<div class="content-ad"></div>
<h1>ì½”ë“œ ëŒë§ˆë€ ë¬´ì—‡ì¸ê°€ìš”?</h1>
<p>ì½”ë“œ ëŒë§ˆëŠ” Meta AIê°€ ë§Œë“¤ê³  2023ë…„ 8ì›”ì— ì²˜ìŒìœ¼ë¡œ ì¶œì‹œí•œ ì½”ë“œ ì „ìš© LLM ê³„ì—´ì˜ íŠ¹ë³„í•œ ì œí’ˆì…ë‹ˆë‹¤.</p>
<p><img src="/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_1.png" alt="ì´ë¯¸ì§€"></p>
<p>Meta AIëŠ” ê¸°ë³¸ ëª¨ë¸ Llama 2(ë””ì½”ë” ì „ìš© Transformer ëª¨ë¸ë¡œ GPT-4ì™€ ìœ ì‚¬í•¨)ì„ ì‹œì‘ìœ¼ë¡œ, ëŒ€ë¶€ë¶„ ì½”ë“œë¡œ ì´ë£¨ì–´ì§„ 500B í† í°ì˜ êµìœ¡ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¶”ê°€ êµìœ¡ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.</p>
<div class="content-ad"></div>
<p>ê·¸ ì´í›„ë¡œ Code Llamaì— ëŒ€í•œ ì„¸ ê°€ì§€ ë²„ì „ì´ ë„¤ ê°€ì§€ ë‹¤ë¥¸ í¬ê¸°ë¡œ ì œê³µë©ë‹ˆë‹¤.</p>
<p>Code Llama ëª¨ë¸ì€ ì—°êµ¬ ë° ìƒì—…ì  ì‚¬ìš©ì„ ìœ„í•´ ë¬´ë£Œì…ë‹ˆë‹¤.</p>
<p><img src="/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_2.png" alt="ì´ë¯¸ì§€"></p>
<h2>Code Llama</h2>
<div class="content-ad"></div>
<p>ì½”ë“œ LlamaëŠ” ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ê¸°ë°˜ ëª¨ë¸ì…ë‹ˆë‹¤. ì½”ë“œ Llama ëª¨ë¸ì€ infill ëª©ì ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ IDE ë‚´ì—ì„œ ì½”ë“œ ì™„ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
<h2>ì½”ë“œ Llama â€” Instruct</h2>
<p>Instruct ë²„ì „ì€ ì¸ê°„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì§€ì‹œ ë°ì´í„°ì…‹ì— ë§ì¶° ì„¸ë°€í•˜ê²Œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ChatGPTì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.</p>
<h2>ì½”ë“œ Llama â€” Python</h2>
<div class="content-ad"></div>
<p>íŒŒì´ì¬ ë²„ì „ì€ ì¶”ê°€ ë°ì´í„°ì…‹ì¸ 100B í† í°ì˜ íŒŒì´ì¬ ì½”ë“œë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ì€ ì½”ë“œ ìƒì„±ì„ ìœ„í•´ ì˜ë„ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
<h1>LLM ì±—ë´‡ ì½”ë”©</h1>
<p>ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Instruct ë²„ì „ ì¤‘ ê°€ì¥ ì‘ì€ ëª¨ë¸ì¸ CodeLlama-7b-Instruct â€” hfë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ìì—°ì–´ ì§ˆë¬¸ì— ë‹µë³€í•˜ë„ë¡ ì„¸ë°€í•˜ê²Œ íŠœë‹ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ì±—ë´‡ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>ê°€ì¥ ì‘ì€ ëª¨ë¸ì¡°ì°¨ë„ ì—¬ì „íˆ 7B ë§¤ê°œë³€ìˆ˜ë¡œ ìƒë‹¹íˆ í½ë‹ˆë‹¤. ë§¤ê°œë³€ìˆ˜ì˜ 16ë¹„íŠ¸ ë°˜ì •ë°€ë„ë¥¼ ì‚¬ìš©í•˜ë©´, ëª¨ë¸ì€ ì•½ 14 GBì˜ GPU ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ë©´, ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì„ ì•½ 3.5 GB ì •ë„ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<div class="content-ad"></div>
<h2>ëª¨ë¸ êµ¬í˜„í•˜ê¸°</h2>
<p>ìš°ë¦¬ëŠ” ë¨¼ì € Hugging Faceì—ì„œ Code Llama ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ê¸°ë°˜í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ChatModel í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.</p>
<p>ìš°ë¦¬ëŠ” 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ìœ„í•´ BitsAndBytesConfigë¥¼ ì‚¬ìš©í•˜ë©°, ëª¨ë¸ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ AutoModelForCausalLMì„ ì‚¬ìš©í•˜ê³  ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° í† í° ì„ë² ë”©ì„ ìƒì„±í•˜ê¸° ìœ„í•´ AutoTokenizerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> <span class="hljs-title class_">AutoTokenizer</span>, <span class="hljs-title class_">AutoModelForCausalLM</span>, <span class="hljs-title class_">BitsAndBytesConfig</span>

<span class="hljs-keyword">class</span> <span class="hljs-title class_">ChatModel</span>:
    def <span class="hljs-title function_">__init__</span>(self, model=<span class="hljs-string">"codellama/CodeLlama-7b-Instruct-hf"</span>):
        quantization_config = <span class="hljs-title class_">BitsAndBytesConfig</span>(
            load_in_4bit=<span class="hljs-title class_">True</span>, # <span class="hljs-number">4</span>ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©
            bnb_4bit_compute_dtype=torch.<span class="hljs-property">float16</span>,
            bnb_4bit_use_double_quant=<span class="hljs-title class_">True</span>,
        )
        self.<span class="hljs-property">model</span> = <span class="hljs-title class_">AutoModelForCausalLM</span>.<span class="hljs-title function_">from_pretrained</span>(
            model,
            quantization_config=quantization_config,
            device_map=<span class="hljs-string">"cuda"</span>,
            cache_dir=<span class="hljs-string">"./models"</span>, # ëª¨ë¸ì„ models í´ë”ì— ë‹¤ìš´ë¡œë“œ
        )
        self.<span class="hljs-property">tokenizer</span> = <span class="hljs-title class_">AutoTokenizer</span>.<span class="hljs-title function_">from_pretrained</span>(
            model, use_fast=<span class="hljs-title class_">True</span>, padding_side=<span class="hljs-string">"left"</span>
        )
</code></pre>
<div class="content-ad"></div>
<p>ë˜í•œ, ì‚¬ìš©ìì˜ ì´ì „ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ AIê°€ ìƒì„±í•œ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ê³ ì • ê¸¸ì´ì˜ íˆìŠ¤í† ë¦¬ ëª©ë¡ì„ ë§Œë“­ë‹ˆë‹¤. ì´ëŠ” ëŒ€í™”ì˜ ê¸°ì–µì„ ì œê³µí•˜ì—¬ LLMì—ê²Œ ëŒ€í™”ì˜ ê¸°ì–µì„ ë¶€ì—¬í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.</p>
<pre><code class="hljs language-js">self.<span class="hljs-property">history</span> = []
self.<span class="hljs-property">history_length</span> = <span class="hljs-number">1</span>
</code></pre>
<p>Code Llamaì€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì•ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.</p>
<p>ê¸°ë³¸ì ìœ¼ë¡œ, codellama-13b-chat ì˜ˆì œì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js">self.<span class="hljs-property">DEFAULT_SYSTEM_PROMPT</span> = <span class="hljs-string">""</span><span class="hljs-string">"\
ë‹¹ì‹ ì€ ì½”ë“œì™€ ì†Œí”„íŠ¸ì›¨ì–´ ë””ìì¸ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§„, ë„ì›€ì´ ë˜ëŠ”, ì˜ˆì˜ ë°”ë¥´ê³  ì •ì§í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í•­ìƒ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ í•´ì•¼ í•˜ë©°, ì•ˆì „í•˜ê³  ì‹ ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤. ë‹µë³€ì— í•´ë¡œìš´, ë¶€ì •í•œ, ì¸ì¢… ì°¨ë³„ì , ì„± ì°¨ë³„ì , ìœ í•´í•œ, ìœ„í—˜í•œ, ë˜ëŠ” ë¶ˆë²•ì ì¸ ë‚´ìš©ì„ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ë‹µë³€ì´ ì‚¬íšŒì ìœ¼ë¡œ í¸í–¥ë˜ê±°ë‚˜ ë¶€ì •ì ì´ì—¬ì„  ì•ˆë©ë‹ˆë‹¤.\n\në§Œì•½ ì§ˆë¬¸ì´ ì´í•´í•  ìˆ˜ ì—†ê±°ë‚˜ ì‚¬ì‹¤ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ì—†ë‹¤ë©´, ì˜¬ë°”ë¥¸ ëŒ€ë‹µ ëŒ€ì‹  ì™œ ì˜ëª»ëœ ê²ƒì¸ì§€ ì„¤ëª…í•˜ì„¸ìš”. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì„ ëª¨ë¥´ë©´, ê°€ì§œ ì •ë³´ë¥¼ ê³µìœ í•˜ì§€ ë§ê³  ëŒ€ì‹  ë§í•´ì£¼ì„¸ìš”.\
        "</span><span class="hljs-string">""</span>
</code></pre>
<p>ì´ì œ self.historyì— í˜„ì¬ ëŒ€í™”ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ë´…ì‹œë‹¤.</p>
<p>LLM(ì–´ë¼ìš´ë“œ  ëª¨ë¸)ì€ í•œì •ëœ ë¬¸ë§¥ ê¸¸ì´ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ë©”ëª¨ë¦¬ì— ì •ë³´ë¥¼ í•œì •ì ìœ¼ë¡œ ë³´ê´€í•  ìˆ˜ë°–ì— ì—†ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” self.history_length = 1 ê°œì˜ ì§ˆë¬¸ê³¼ ëŒ€ë‹µë§Œ ìµœëŒ€í•œ ë³´ê´€í•©ë‹ˆë‹¤.</p>
<pre><code class="hljs language-js">    def <span class="hljs-title function_">append_to_history</span>(self, user_prompt, response):
        self.<span class="hljs-property">history</span>.<span class="hljs-title function_">append</span>((user_prompt, response))
        <span class="hljs-keyword">if</span> <span class="hljs-title function_">len</span>(self.<span class="hljs-property">history</span>) > self.<span class="hljs-property">history_length</span>:
            self.<span class="hljs-property">history</span>.<span class="hljs-title function_">pop</span>(<span class="hljs-number">0</span>)
</code></pre>
<div class="content-ad"></div>
<p>ë§ˆì¹¨ë‚´ ìš°ë¦¬ëŠ” ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ê¸°ë°˜í•œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” generate í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.</p>
<p>ê° LLMì—ëŠ” í›ˆë ¨ì— ì‚¬ìš©ëœ íŠ¹ì • í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ìˆìŠµë‹ˆë‹¤. Code Llamaì˜ ê²½ìš° codellama-13b-chatì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì°¸ì¡°ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.</p>
<pre><code class="hljs language-js">    def <span class="hljs-title function_">generate</span>(
        self, user_prompt, system_prompt, top_p=<span class="hljs-number">0.9</span>, temperature=<span class="hljs-number">0.1</span>, max_new_tokens=<span class="hljs-number">512</span>
    ):

        texts = [f<span class="hljs-string">"&#x3C;s>[INST] &#x3C;&#x3C;SYS>>\n{system_prompt}\n&#x3C;&#x3C;/SYS>>\n\n"</span>]
        do_strip = <span class="hljs-title class_">False</span>
        <span class="hljs-keyword">for</span> old_prompt, old_response <span class="hljs-keyword">in</span> self.<span class="hljs-property">history</span>:
            old_prompt = old_prompt.<span class="hljs-title function_">strip</span>() <span class="hljs-keyword">if</span> do_strip <span class="hljs-keyword">else</span> old_prompt
            do_strip = <span class="hljs-title class_">True</span>
            texts.<span class="hljs-title function_">append</span>(f<span class="hljs-string">"{old_prompt} [/INST] {old_response.strip()} &#x3C;/s>&#x3C;s>[INST] "</span>)
        user_prompt = user_prompt.<span class="hljs-title function_">strip</span>() <span class="hljs-keyword">if</span> do_strip <span class="hljs-keyword">else</span> user_prompt
        texts.<span class="hljs-title function_">append</span>(f<span class="hljs-string">"{user_prompt} [/INST]"</span>)
        prompt = <span class="hljs-string">""</span>.<span class="hljs-title function_">join</span>(texts)

        inputs = self.<span class="hljs-title function_">tokenizer</span>(
            prompt, return_tensors=<span class="hljs-string">"pt"</span>, add_special_tokens=<span class="hljs-title class_">False</span>
        ).<span class="hljs-title function_">to</span>(<span class="hljs-string">"cuda"</span>)

        output = self.<span class="hljs-property">model</span>.<span class="hljs-title function_">generate</span>(
            inputs[<span class="hljs-string">"input_ids"</span>],
            attention_mask=inputs[<span class="hljs-string">"attention_mask"</span>],
            pad_token_id=self.<span class="hljs-property">tokenizer</span>.<span class="hljs-property">eos_token_id</span>,
            max_new_tokens=max_new_tokens,
            do_sample=<span class="hljs-title class_">True</span>,
            top_p=top_p,
            top_k=<span class="hljs-number">50</span>,
            temperature=temperature,
        )
        output = output[<span class="hljs-number">0</span>].<span class="hljs-title function_">to</span>(<span class="hljs-string">"cpu"</span>)
        response = self.<span class="hljs-property">tokenizer</span>.<span class="hljs-title function_">decode</span>(output[inputs[<span class="hljs-string">"input_ids"</span>].<span class="hljs-property">shape</span>[<span class="hljs-number">1</span>] : -<span class="hljs-number">1</span>])
        self.<span class="hljs-title function_">append_to_history</span>(user_prompt, response)
        <span class="hljs-keyword">return</span> response
</code></pre>
<p>ì‘ë‹µì€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë‹µë³€ì˜ ì°½ì˜ì„±ì€ top_p ë° temperatureì™€ ê°™ì€ ë§¤ê°œë³€ìˆ˜ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.</p>
<div class="content-ad"></div>
<p>top_pë¥¼ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ í† í°ì˜ í™•ë¥  ê°’ì„ ì œí•œí•˜ì—¬ ë„ˆë¬´ ë“œë¬¼ê²Œ ë°œìƒí•˜ëŠ” í† í°ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ í”¼í•  ìˆ˜ ìˆì–´ìš”:</p>
<p>temperatureë¥¼ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ í† í°ì˜ í™•ë¥  ë¶„í¬ë¥¼ í‰í‰í•˜ê²Œ í•˜ê±°ë‚˜ ë‚ ì¹´ë¡­ê²Œ í•  ìˆ˜ ìˆì–´ìš”:</p>
<p>í”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§„í–‰í•˜ê¸° ì „ì— ChatModelì„ í…ŒìŠ¤íŠ¸í•´ë³´ì£ .</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> <span class="hljs-title class_">ChatModel</span> <span class="hljs-keyword">import</span> *

model = <span class="hljs-title class_">ChatModel</span>()
response = model.<span class="hljs-title function_">generate</span>(
    user_prompt=<span class="hljs-string">"C++ì—ì„œ hello world í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•´ë´"</span>, 
    system_prompt=model.<span class="hljs-property">DEFAULT_SYSTEM_PROMPT</span>
)
<span class="hljs-title function_">print</span>(response)
</code></pre>
<div class="content-ad"></div>
<pre><code class="hljs language-js">ë‹¹ì‹ ì´ ìš”ì²­í•œ ì‘ì—…ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ í…Œì´ë¸” íƒœê·¸ê°€ <span class="hljs-title class_">Markdown</span> í˜•ì‹ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.
</code></pre>
<div class="content-ad"></div>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> streamlit <span class="hljs-keyword">as</span> st
<span class="hljs-keyword">from</span> <span class="hljs-title class_">ChatModel</span> <span class="hljs-keyword">import</span> *

st.<span class="hljs-title function_">title</span>(<span class="hljs-string">"Code Llama Assistant"</span>)


@st.<span class="hljs-property">cache_resource</span>
def <span class="hljs-title function_">load_model</span>():
    model = <span class="hljs-title class_">ChatModel</span>()
    <span class="hljs-keyword">return</span> model


model = <span class="hljs-title function_">load_model</span>()  # load our <span class="hljs-title class_">ChatModel</span> once and then cache it
</code></pre>
<p>ë‹¤ìŒìœ¼ë¡œ generate í•¨ìˆ˜ë¥¼ ìœ„í•œ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì…ë ¥ ì œì–´í•˜ëŠ” ì‚¬ì´ë“œë°”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">with</span> st.<span class="hljs-property">sidebar</span>:
    temperature = st.<span class="hljs-title function_">slider</span>(<span class="hljs-string">"ì˜¨ë„"</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">0.1</span>)
    top_p = st.<span class="hljs-title function_">slider</span>(<span class="hljs-string">"top_p"</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.9</span>)
    max_new_tokens = st.<span class="hljs-title function_">number_input</span>(<span class="hljs-string">"max_new_tokens"</span>, <span class="hljs-number">128</span>, <span class="hljs-number">4096</span>, <span class="hljs-number">256</span>)
    system_prompt = st.<span class="hljs-title function_">text_area</span>(
        <span class="hljs-string">"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"</span>, value=model.<span class="hljs-property">DEFAULT_SYSTEM_PROMPT</span>, height=<span class="hljs-number">500</span>
    )
</code></pre>
<p>ê·¸ë¦¬ê³  ì±—ë´‡ ë©”ì‹œì§€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.</p>
<div class="content-ad"></div>
<pre><code class="hljs language-js"># ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
<span class="hljs-keyword">if</span> <span class="hljs-string">"messages"</span> not <span class="hljs-keyword">in</span> st.<span class="hljs-property">session_state</span>:
    st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span> = []

# ì•± ì¬ì‹¤í–‰ì‹œ ê¸°ë¡ëœ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
<span class="hljs-keyword">for</span> message <span class="hljs-keyword">in</span> st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span>:
    <span class="hljs-keyword">with</span> st.<span class="hljs-title function_">chat_message</span>(message[<span class="hljs-string">"role"</span>]):
        st.<span class="hljs-title function_">markdown</span>(message[<span class="hljs-string">"content"</span>])

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
<span class="hljs-keyword">if</span> prompt := st.<span class="hljs-title function_">chat_input</span>(<span class="hljs-string">"ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"</span>):
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
    st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span>.<span class="hljs-title function_">append</span>({<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: prompt})
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆì— í‘œì‹œ
    <span class="hljs-keyword">with</span> st.<span class="hljs-title function_">chat_message</span>(<span class="hljs-string">"user"</span>):
        st.<span class="hljs-title function_">markdown</span>(prompt)

    # ì±—ë´‡ ì‘ë‹µì„ ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆì— í‘œì‹œ
    <span class="hljs-keyword">with</span> st.<span class="hljs-title function_">chat_message</span>(<span class="hljs-string">"assistant"</span>):
        user_prompt = st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span>[-<span class="hljs-number">1</span>][<span class="hljs-string">"content"</span>]
        answer = model.<span class="hljs-title function_">generate</span>(
            user_prompt,
            top_p=top_p,
            temperature=temperature,
            max_new_tokens=max_new_tokens,
            system_prompt=system_prompt,
        )
        response = st.<span class="hljs-title function_">write</span>(answer)
    st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span>.<span class="hljs-title function_">append</span>({<span class="hljs-string">"role"</span>: <span class="hljs-string">"assistant"</span>, <span class="hljs-string">"content"</span>: answer})
</code></pre>
<p>ìŠ¤íŠ¸ë¦¼ë¦¿ ì•±ì„ streamlit run app.pyë¡œ ì‹¤í–‰í•˜ì—¬ ë¸Œë¼ìš°ì €ê°€ ì—´ë¦½ë‹ˆë‹¤.</p>
<p>ì´ì œ ì±—ë´‡ì— ì½”ë”© ê´€ë ¨ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<h1>ê²°ë¡ </h1>
<div class="content-ad"></div>
<p>ì €í¬ëŠ” Meta AIì˜ Code Llama LLMì„ í™œìš©í•˜ì—¬ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬í˜„í–ˆì–´ìš”. ê·¸ë¦¬ê³  Hugging Faceì˜ transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ Streamlitì„ ì‚¬ìš©í•´ì„œ í”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ì—ˆì–´ìš”.</p>
<p>6GBì˜ GPU ë©”ëª¨ë¦¬ë¥¼ ê°–ì¶˜ ë…¸íŠ¸ë¶ìœ¼ë¡œëŠ” 4ë¹„íŠ¸ ì–‘ìí™”ëœ Code Llama ëª¨ë¸ì„ 7B ë§¤ê°œë³€ìˆ˜ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ë°–ì— ì—†ì—ˆì–´ìš”. ë” í° GPUë¥¼ ì‚¬ìš©í•˜ë©´ 16ë¹„íŠ¸ ë²„ì „ì´ë‚˜ ë” í° ëª¨ë¸ì´ ë” ì˜ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.</p>
<p>P.S. Code Llamaë¡œë¶€í„° ì œê°€ ë°›ì€ ë†ë‹´ë³´ë‹¤ ë” ì¬ë¯¸ìˆëŠ” ë†ë‹´ë“¤ì„ ê¸°ëŒ€í•´ë´…ë‹ˆë‹¤ ğŸ¤¡.</p>
<p>ë” ë§ì€ LLMì— ê´€ì‹¬ì´ ìˆìœ¼ì‹œë‹¤ë©´, ìµœê·¼ì— ê³µê°œëœ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì— ëŒ€í•œ ê°œìš”ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”:</p>
<div class="content-ad"></div>
<h1>ì°¸ê³  ìë£Œ</h1>
<p>[1] B. RoziÃ¨re ì™¸: Code Llama: ì½”ë“œë¥¼ ìœ„í•œ ì˜¤í”ˆ ê¸°ë°˜ ëª¨ë¸ (2023), arXiv:2308.12950</p>
<h1>ìì›</h1>
<ul>
<li>Streamlit ì±„íŒ… ì•± ì˜ˆì œ: ê¸°ë³¸ LLM ì±„íŒ… ì•± êµ¬ì¶•</li>
<li>Hugging Face Code Llama gradio êµ¬í˜„: codellama-13b-chat</li>
<li>ì´ ë¬¸ì„œì˜ ì „ì²´ ì‘ì—… ì½”ë“œ: <a href="https://github.com/leoneversberg/codellama-chatbot" rel="nofollow" target="_blank">https://github.com/leoneversberg/codellama-chatbot</a></li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Code Llamaë¡œ ë‚˜ë§Œì˜ LLM ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“œëŠ” ë°©ë²• ","description":"","date":"2024-06-22 21:36","slug":"2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama","content":"\n\nì´ ì‹¤ìŠµì—ì„œëŠ” ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê³  ë¡œì»¬ GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” AI ì½”ë“œ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬í˜„í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n\nì±—ë´‡ì— ì§ˆë¬¸ì„ í•˜ë©´ ìì—°ì–´ë¡œ ë‹µë³€í•˜ë©° ì—¬ëŸ¬ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ì½”ë“œë„ ì œê³µí•©ë‹ˆë‹¤.\n\nìš°ë¦¬ëŠ” Hugging Face transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì„ êµ¬í˜„í•˜ê³  Chatbot í”„ë¡ íŠ¸ ì—”ë“œì—ëŠ” Streamlitì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\n\n# LLMì´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\në””ì½”ë” ì „ìš© íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì¸ GPT ê³„ì—´ì€ ì£¼ì–´ì§„ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ í…ìŠ¤íŠ¸ ìƒì„±ì— ì•„ì£¼ ëŠ¥ìˆ™í•©ë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_0.png)\n\nì¶©ë¶„í•œ í›ˆë ¨ ë°ì´í„°ê°€ ì œê³µëœë‹¤ë©´, ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒë„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. IDEì—ì„œ ì½”ë“œë¥¼ ì±„ìš°ëŠ” ë°©ì‹ì´ë‚˜ ì±—ë´‡ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\nGitHub Copilotì€ ìƒìš© ì˜ˆì‹œë¡œì„œ AI í˜ì–´ í”„ë¡œê·¸ë˜ë¨¸ì˜ í•œ ì˜ˆì…ë‹ˆë‹¤. Meta AIì˜ Code Llama ëª¨ë¸ì€ ìœ ì‚¬í•œ ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆì§€ë§Œ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# ì½”ë“œ ëŒë§ˆë€ ë¬´ì—‡ì¸ê°€ìš”?\n\nì½”ë“œ ëŒë§ˆëŠ” Meta AIê°€ ë§Œë“¤ê³  2023ë…„ 8ì›”ì— ì²˜ìŒìœ¼ë¡œ ì¶œì‹œí•œ ì½”ë“œ ì „ìš© LLM ê³„ì—´ì˜ íŠ¹ë³„í•œ ì œí’ˆì…ë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_1.png)\n\nMeta AIëŠ” ê¸°ë³¸ ëª¨ë¸ Llama 2(ë””ì½”ë” ì „ìš© Transformer ëª¨ë¸ë¡œ GPT-4ì™€ ìœ ì‚¬í•¨)ì„ ì‹œì‘ìœ¼ë¡œ, ëŒ€ë¶€ë¶„ ì½”ë“œë¡œ ì´ë£¨ì–´ì§„ 500B í† í°ì˜ êµìœ¡ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¶”ê°€ êµìœ¡ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nê·¸ ì´í›„ë¡œ Code Llamaì— ëŒ€í•œ ì„¸ ê°€ì§€ ë²„ì „ì´ ë„¤ ê°€ì§€ ë‹¤ë¥¸ í¬ê¸°ë¡œ ì œê³µë©ë‹ˆë‹¤.\n\nCode Llama ëª¨ë¸ì€ ì—°êµ¬ ë° ìƒì—…ì  ì‚¬ìš©ì„ ìœ„í•´ ë¬´ë£Œì…ë‹ˆë‹¤.\n\n![ì´ë¯¸ì§€](/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_2.png)\n\n## Code Llama\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nì½”ë“œ LlamaëŠ” ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ê¸°ë°˜ ëª¨ë¸ì…ë‹ˆë‹¤. ì½”ë“œ Llama ëª¨ë¸ì€ infill ëª©ì ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ IDE ë‚´ì—ì„œ ì½”ë“œ ì™„ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n## ì½”ë“œ Llama â€” Instruct\n\nInstruct ë²„ì „ì€ ì¸ê°„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì§€ì‹œ ë°ì´í„°ì…‹ì— ë§ì¶° ì„¸ë°€í•˜ê²Œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ChatGPTì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.\n\n## ì½”ë“œ Llama â€” Python\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\níŒŒì´ì¬ ë²„ì „ì€ ì¶”ê°€ ë°ì´í„°ì…‹ì¸ 100B í† í°ì˜ íŒŒì´ì¬ ì½”ë“œë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ì€ ì½”ë“œ ìƒì„±ì„ ìœ„í•´ ì˜ë„ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n# LLM ì±—ë´‡ ì½”ë”©\n\në³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Instruct ë²„ì „ ì¤‘ ê°€ì¥ ì‘ì€ ëª¨ë¸ì¸ CodeLlama-7b-Instruct â€” hfë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ìì—°ì–´ ì§ˆë¬¸ì— ë‹µë³€í•˜ë„ë¡ ì„¸ë°€í•˜ê²Œ íŠœë‹ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ì±—ë´‡ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\nê°€ì¥ ì‘ì€ ëª¨ë¸ì¡°ì°¨ë„ ì—¬ì „íˆ 7B ë§¤ê°œë³€ìˆ˜ë¡œ ìƒë‹¹íˆ í½ë‹ˆë‹¤. ë§¤ê°œë³€ìˆ˜ì˜ 16ë¹„íŠ¸ ë°˜ì •ë°€ë„ë¥¼ ì‚¬ìš©í•˜ë©´, ëª¨ë¸ì€ ì•½ 14 GBì˜ GPU ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ë©´, ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì„ ì•½ 3.5 GB ì •ë„ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## ëª¨ë¸ êµ¬í˜„í•˜ê¸°\n\nìš°ë¦¬ëŠ” ë¨¼ì € Hugging Faceì—ì„œ Code Llama ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ê¸°ë°˜í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ChatModel í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.\n\nìš°ë¦¬ëŠ” 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ìœ„í•´ BitsAndBytesConfigë¥¼ ì‚¬ìš©í•˜ë©°, ëª¨ë¸ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ AutoModelForCausalLMì„ ì‚¬ìš©í•˜ê³  ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° í† í° ì„ë² ë”©ì„ ìƒì„±í•˜ê¸° ìœ„í•´ AutoTokenizerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\n```js\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nclass ChatModel:\n    def __init__(self, model=\"codellama/CodeLlama-7b-Instruct-hf\"):\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True, # 4ë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©\n            bnb_4bit_compute_dtype=torch.float16,\n            bnb_4bit_use_double_quant=True,\n        )\n        self.model = AutoModelForCausalLM.from_pretrained(\n            model,\n            quantization_config=quantization_config,\n            device_map=\"cuda\",\n            cache_dir=\"./models\", # ëª¨ë¸ì„ models í´ë”ì— ë‹¤ìš´ë¡œë“œ\n        )\n        self.tokenizer = AutoTokenizer.from_pretrained(\n            model, use_fast=True, padding_side=\"left\"\n        )\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\në˜í•œ, ì‚¬ìš©ìì˜ ì´ì „ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ AIê°€ ìƒì„±í•œ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ê³ ì • ê¸¸ì´ì˜ íˆìŠ¤í† ë¦¬ ëª©ë¡ì„ ë§Œë“­ë‹ˆë‹¤. ì´ëŠ” ëŒ€í™”ì˜ ê¸°ì–µì„ ì œê³µí•˜ì—¬ LLMì—ê²Œ ëŒ€í™”ì˜ ê¸°ì–µì„ ë¶€ì—¬í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\n\n```js\nself.history = []\nself.history_length = 1\n```\n\nCode Llamaì€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì•ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\nê¸°ë³¸ì ìœ¼ë¡œ, codellama-13b-chat ì˜ˆì œì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nself.DEFAULT_SYSTEM_PROMPT = \"\"\"\\\në‹¹ì‹ ì€ ì½”ë“œì™€ ì†Œí”„íŠ¸ì›¨ì–´ ë””ìì¸ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§„, ë„ì›€ì´ ë˜ëŠ”, ì˜ˆì˜ ë°”ë¥´ê³  ì •ì§í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í•­ìƒ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ í•´ì•¼ í•˜ë©°, ì•ˆì „í•˜ê³  ì‹ ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤. ë‹µë³€ì— í•´ë¡œìš´, ë¶€ì •í•œ, ì¸ì¢… ì°¨ë³„ì , ì„± ì°¨ë³„ì , ìœ í•´í•œ, ìœ„í—˜í•œ, ë˜ëŠ” ë¶ˆë²•ì ì¸ ë‚´ìš©ì„ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ë‹µë³€ì´ ì‚¬íšŒì ìœ¼ë¡œ í¸í–¥ë˜ê±°ë‚˜ ë¶€ì •ì ì´ì—¬ì„  ì•ˆë©ë‹ˆë‹¤.\\n\\në§Œì•½ ì§ˆë¬¸ì´ ì´í•´í•  ìˆ˜ ì—†ê±°ë‚˜ ì‚¬ì‹¤ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ì—†ë‹¤ë©´, ì˜¬ë°”ë¥¸ ëŒ€ë‹µ ëŒ€ì‹  ì™œ ì˜ëª»ëœ ê²ƒì¸ì§€ ì„¤ëª…í•˜ì„¸ìš”. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì„ ëª¨ë¥´ë©´, ê°€ì§œ ì •ë³´ë¥¼ ê³µìœ í•˜ì§€ ë§ê³  ëŒ€ì‹  ë§í•´ì£¼ì„¸ìš”.\\\n        \"\"\"\n```\n\nì´ì œ self.historyì— í˜„ì¬ ëŒ€í™”ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ë´…ì‹œë‹¤.\n\nLLM(ì–´ë¼ìš´ë“œ  ëª¨ë¸)ì€ í•œì •ëœ ë¬¸ë§¥ ê¸¸ì´ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ë©”ëª¨ë¦¬ì— ì •ë³´ë¥¼ í•œì •ì ìœ¼ë¡œ ë³´ê´€í•  ìˆ˜ë°–ì— ì—†ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” self.history_length = 1 ê°œì˜ ì§ˆë¬¸ê³¼ ëŒ€ë‹µë§Œ ìµœëŒ€í•œ ë³´ê´€í•©ë‹ˆë‹¤.\n\n```js\n    def append_to_history(self, user_prompt, response):\n        self.history.append((user_prompt, response))\n        if len(self.history) \u003e self.history_length:\n            self.history.pop(0)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\në§ˆì¹¨ë‚´ ìš°ë¦¬ëŠ” ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ê¸°ë°˜í•œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” generate í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n\nê° LLMì—ëŠ” í›ˆë ¨ì— ì‚¬ìš©ëœ íŠ¹ì • í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ìˆìŠµë‹ˆë‹¤. Code Llamaì˜ ê²½ìš° codellama-13b-chatì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì°¸ì¡°ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n\n```js\n    def generate(\n        self, user_prompt, system_prompt, top_p=0.9, temperature=0.1, max_new_tokens=512\n    ):\n\n        texts = [f\"\u003cs\u003e[INST] \u003c\u003cSYS\u003e\u003e\\n{system_prompt}\\n\u003c\u003c/SYS\u003e\u003e\\n\\n\"]\n        do_strip = False\n        for old_prompt, old_response in self.history:\n            old_prompt = old_prompt.strip() if do_strip else old_prompt\n            do_strip = True\n            texts.append(f\"{old_prompt} [/INST] {old_response.strip()} \u003c/s\u003e\u003cs\u003e[INST] \")\n        user_prompt = user_prompt.strip() if do_strip else user_prompt\n        texts.append(f\"{user_prompt} [/INST]\")\n        prompt = \"\".join(texts)\n\n        inputs = self.tokenizer(\n            prompt, return_tensors=\"pt\", add_special_tokens=False\n        ).to(\"cuda\")\n\n        output = self.model.generate(\n            inputs[\"input_ids\"],\n            attention_mask=inputs[\"attention_mask\"],\n            pad_token_id=self.tokenizer.eos_token_id,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            top_p=top_p,\n            top_k=50,\n            temperature=temperature,\n        )\n        output = output[0].to(\"cpu\")\n        response = self.tokenizer.decode(output[inputs[\"input_ids\"].shape[1] : -1])\n        self.append_to_history(user_prompt, response)\n        return response\n```\n\nì‘ë‹µì€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë‹µë³€ì˜ ì°½ì˜ì„±ì€ top_p ë° temperatureì™€ ê°™ì€ ë§¤ê°œë³€ìˆ˜ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\ntop_pë¥¼ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ í† í°ì˜ í™•ë¥  ê°’ì„ ì œí•œí•˜ì—¬ ë„ˆë¬´ ë“œë¬¼ê²Œ ë°œìƒí•˜ëŠ” í† í°ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ í”¼í•  ìˆ˜ ìˆì–´ìš”:\n\ntemperatureë¥¼ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ í† í°ì˜ í™•ë¥  ë¶„í¬ë¥¼ í‰í‰í•˜ê²Œ í•˜ê±°ë‚˜ ë‚ ì¹´ë¡­ê²Œ í•  ìˆ˜ ìˆì–´ìš”:\n\ní”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§„í–‰í•˜ê¸° ì „ì— ChatModelì„ í…ŒìŠ¤íŠ¸í•´ë³´ì£ .\n\n```js\nfrom ChatModel import *\n\nmodel = ChatModel()\nresponse = model.generate(\n    user_prompt=\"C++ì—ì„œ hello world í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•´ë´\", \n    system_prompt=model.DEFAULT_SYSTEM_PROMPT\n)\nprint(response)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\në‹¹ì‹ ì´ ìš”ì²­í•œ ì‘ì—…ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ í…Œì´ë¸” íƒœê·¸ê°€ Markdown í˜•ì‹ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nimport streamlit as st\nfrom ChatModel import *\n\nst.title(\"Code Llama Assistant\")\n\n\n@st.cache_resource\ndef load_model():\n    model = ChatModel()\n    return model\n\n\nmodel = load_model()  # load our ChatModel once and then cache it\r\n```\n\në‹¤ìŒìœ¼ë¡œ generate í•¨ìˆ˜ë¥¼ ìœ„í•œ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì…ë ¥ ì œì–´í•˜ëŠ” ì‚¬ì´ë“œë°”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n\n```js\r\nwith st.sidebar:\n    temperature = st.slider(\"ì˜¨ë„\", 0.0, 2.0, 0.1)\n    top_p = st.slider(\"top_p\", 0.0, 1.0, 0.9)\n    max_new_tokens = st.number_input(\"max_new_tokens\", 128, 4096, 256)\n    system_prompt = st.text_area(\n        \"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\", value=model.DEFAULT_SYSTEM_PROMPT, height=500\n    )\r\n```\n\nê·¸ë¦¬ê³  ì±—ë´‡ ë©”ì‹œì§€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\n# ì•± ì¬ì‹¤í–‰ì‹œ ê¸°ë¡ëœ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"]):\n        st.markdown(message[\"content\"])\n\n# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°\nif prompt := st.chat_input(\"ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!\"):\n    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆì— í‘œì‹œ\n    with st.chat_message(\"user\"):\n        st.markdown(prompt)\n\n    # ì±—ë´‡ ì‘ë‹µì„ ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆì— í‘œì‹œ\n    with st.chat_message(\"assistant\"):\n        user_prompt = st.session_state.messages[-1][\"content\"]\n        answer = model.generate(\n            user_prompt,\n            top_p=top_p,\n            temperature=temperature,\n            max_new_tokens=max_new_tokens,\n            system_prompt=system_prompt,\n        )\n        response = st.write(answer)\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": answer})\r\n```\n\nìŠ¤íŠ¸ë¦¼ë¦¿ ì•±ì„ streamlit run app.pyë¡œ ì‹¤í–‰í•˜ì—¬ ë¸Œë¼ìš°ì €ê°€ ì—´ë¦½ë‹ˆë‹¤.\n\nì´ì œ ì±—ë´‡ì— ì½”ë”© ê´€ë ¨ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n# ê²°ë¡ \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nì €í¬ëŠ” Meta AIì˜ Code Llama LLMì„ í™œìš©í•˜ì—¬ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬í˜„í–ˆì–´ìš”. ê·¸ë¦¬ê³  Hugging Faceì˜ transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ Streamlitì„ ì‚¬ìš©í•´ì„œ í”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ì—ˆì–´ìš”.\n\n6GBì˜ GPU ë©”ëª¨ë¦¬ë¥¼ ê°–ì¶˜ ë…¸íŠ¸ë¶ìœ¼ë¡œëŠ” 4ë¹„íŠ¸ ì–‘ìí™”ëœ Code Llama ëª¨ë¸ì„ 7B ë§¤ê°œë³€ìˆ˜ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ë°–ì— ì—†ì—ˆì–´ìš”. ë” í° GPUë¥¼ ì‚¬ìš©í•˜ë©´ 16ë¹„íŠ¸ ë²„ì „ì´ë‚˜ ë” í° ëª¨ë¸ì´ ë” ì˜ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.\n\nP.S. Code Llamaë¡œë¶€í„° ì œê°€ ë°›ì€ ë†ë‹´ë³´ë‹¤ ë” ì¬ë¯¸ìˆëŠ” ë†ë‹´ë“¤ì„ ê¸°ëŒ€í•´ë´…ë‹ˆë‹¤ ğŸ¤¡.\n\në” ë§ì€ LLMì— ê´€ì‹¬ì´ ìˆìœ¼ì‹œë‹¤ë©´, ìµœê·¼ì— ê³µê°œëœ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì— ëŒ€í•œ ê°œìš”ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# ì°¸ê³  ìë£Œ\n\n[1] B. RoziÃ¨re ì™¸: Code Llama: ì½”ë“œë¥¼ ìœ„í•œ ì˜¤í”ˆ ê¸°ë°˜ ëª¨ë¸ (2023), arXiv:2308.12950\n\n# ìì›\n\n- Streamlit ì±„íŒ… ì•± ì˜ˆì œ: ê¸°ë³¸ LLM ì±„íŒ… ì•± êµ¬ì¶•\n- Hugging Face Code Llama gradio êµ¬í˜„: codellama-13b-chat\n- ì´ ë¬¸ì„œì˜ ì „ì²´ ì‘ì—… ì½”ë“œ: [https://github.com/leoneversberg/codellama-chatbot](https://github.com/leoneversberg/codellama-chatbot)","ogImage":{"url":"/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_0.png"},"coverImage":"/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003eì´ ì‹¤ìŠµì—ì„œëŠ” ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê³  ë¡œì»¬ GPUì—ì„œ ì‹¤í–‰ë˜ëŠ” AI ì½”ë“œ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬í˜„í•  ì˜ˆì •ì…ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eì±—ë´‡ì— ì§ˆë¬¸ì„ í•˜ë©´ ìì—°ì–´ë¡œ ë‹µë³€í•˜ë©° ì—¬ëŸ¬ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ ì½”ë“œë„ ì œê³µí•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eìš°ë¦¬ëŠ” Hugging Face transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LLMì„ êµ¬í˜„í•˜ê³  Chatbot í”„ë¡ íŠ¸ ì—”ë“œì—ëŠ” Streamlitì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.\u003c/p\u003e\n\u003ch1\u003eLLMì´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eë””ì½”ë” ì „ìš© íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì¸ GPT ê³„ì—´ì€ ì£¼ì–´ì§„ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ í…ìŠ¤íŠ¸ ìƒì„±ì— ì•„ì£¼ ëŠ¥ìˆ™í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_0.png\" alt=\"ì´ë¯¸ì§€\"\u003e\u003c/p\u003e\n\u003cp\u003eì¶©ë¶„í•œ í›ˆë ¨ ë°ì´í„°ê°€ ì œê³µëœë‹¤ë©´, ì½”ë“œë¥¼ ìƒì„±í•˜ëŠ” ê²ƒë„ ë°°ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. IDEì—ì„œ ì½”ë“œë¥¼ ì±„ìš°ëŠ” ë°©ì‹ì´ë‚˜ ì±—ë´‡ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eGitHub Copilotì€ ìƒìš© ì˜ˆì‹œë¡œì„œ AI í˜ì–´ í”„ë¡œê·¸ë˜ë¨¸ì˜ í•œ ì˜ˆì…ë‹ˆë‹¤. Meta AIì˜ Code Llama ëª¨ë¸ì€ ìœ ì‚¬í•œ ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆì§€ë§Œ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eì½”ë“œ ëŒë§ˆë€ ë¬´ì—‡ì¸ê°€ìš”?\u003c/h1\u003e\n\u003cp\u003eì½”ë“œ ëŒë§ˆëŠ” Meta AIê°€ ë§Œë“¤ê³  2023ë…„ 8ì›”ì— ì²˜ìŒìœ¼ë¡œ ì¶œì‹œí•œ ì½”ë“œ ì „ìš© LLM ê³„ì—´ì˜ íŠ¹ë³„í•œ ì œí’ˆì…ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_1.png\" alt=\"ì´ë¯¸ì§€\"\u003e\u003c/p\u003e\n\u003cp\u003eMeta AIëŠ” ê¸°ë³¸ ëª¨ë¸ Llama 2(ë””ì½”ë” ì „ìš© Transformer ëª¨ë¸ë¡œ GPT-4ì™€ ìœ ì‚¬í•¨)ì„ ì‹œì‘ìœ¼ë¡œ, ëŒ€ë¶€ë¶„ ì½”ë“œë¡œ ì´ë£¨ì–´ì§„ 500B í† í°ì˜ êµìœ¡ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì¶”ê°€ êµìœ¡ì„ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eê·¸ ì´í›„ë¡œ Code Llamaì— ëŒ€í•œ ì„¸ ê°€ì§€ ë²„ì „ì´ ë„¤ ê°€ì§€ ë‹¤ë¥¸ í¬ê¸°ë¡œ ì œê³µë©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eCode Llama ëª¨ë¸ì€ ì—°êµ¬ ë° ìƒì—…ì  ì‚¬ìš©ì„ ìœ„í•´ ë¬´ë£Œì…ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama_2.png\" alt=\"ì´ë¯¸ì§€\"\u003e\u003c/p\u003e\n\u003ch2\u003eCode Llama\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eì½”ë“œ LlamaëŠ” ì½”ë“œ ìƒì„±ì„ ìœ„í•œ ê¸°ë°˜ ëª¨ë¸ì…ë‹ˆë‹¤. ì½”ë“œ Llama ëª¨ë¸ì€ infill ëª©ì ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ IDE ë‚´ì—ì„œ ì½”ë“œ ì™„ì„±ì„ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003ch2\u003eì½”ë“œ Llama â€” Instruct\u003c/h2\u003e\n\u003cp\u003eInstruct ë²„ì „ì€ ì¸ê°„ì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì§€ì‹œ ë°ì´í„°ì…‹ì— ë§ì¶° ì„¸ë°€í•˜ê²Œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ëŠ” ChatGPTì™€ ìœ ì‚¬í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003ch2\u003eì½”ë“œ Llama â€” Python\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eíŒŒì´ì¬ ë²„ì „ì€ ì¶”ê°€ ë°ì´í„°ì…‹ì¸ 100B í† í°ì˜ íŒŒì´ì¬ ì½”ë“œë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ë“¤ì€ ì½”ë“œ ìƒì„±ì„ ìœ„í•´ ì˜ë„ë˜ì—ˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003ch1\u003eLLM ì±—ë´‡ ì½”ë”©\u003c/h1\u003e\n\u003cp\u003eë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Instruct ë²„ì „ ì¤‘ ê°€ì¥ ì‘ì€ ëª¨ë¸ì¸ CodeLlama-7b-Instruct â€” hfë¥¼ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ìì—°ì–´ ì§ˆë¬¸ì— ë‹µë³€í•˜ë„ë¡ ì„¸ë°€í•˜ê²Œ íŠœë‹ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ì±—ë´‡ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eê°€ì¥ ì‘ì€ ëª¨ë¸ì¡°ì°¨ë„ ì—¬ì „íˆ 7B ë§¤ê°œë³€ìˆ˜ë¡œ ìƒë‹¹íˆ í½ë‹ˆë‹¤. ë§¤ê°œë³€ìˆ˜ì˜ 16ë¹„íŠ¸ ë°˜ì •ë°€ë„ë¥¼ ì‚¬ìš©í•˜ë©´, ëª¨ë¸ì€ ì•½ 14 GBì˜ GPU ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ì‚¬ìš©í•˜ë©´, ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì„ ì•½ 3.5 GB ì •ë„ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003eëª¨ë¸ êµ¬í˜„í•˜ê¸°\u003c/h2\u003e\n\u003cp\u003eìš°ë¦¬ëŠ” ë¨¼ì € Hugging Faceì—ì„œ Code Llama ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ê¸°ë°˜í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ChatModel í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eìš°ë¦¬ëŠ” 4ë¹„íŠ¸ ì–‘ìí™”ë¥¼ ìœ„í•´ BitsAndBytesConfigë¥¼ ì‚¬ìš©í•˜ë©°, ëª¨ë¸ì„ ë¡œë“œí•˜ê¸° ìœ„í•´ AutoModelForCausalLMì„ ì‚¬ìš©í•˜ê³  ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° í† í° ì„ë² ë”©ì„ ìƒì„±í•˜ê¸° ìœ„í•´ AutoTokenizerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e torch\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eAutoTokenizer\u003c/span\u003e, \u003cspan class=\"hljs-title class_\"\u003eAutoModelForCausalLM\u003c/span\u003e, \u003cspan class=\"hljs-title class_\"\u003eBitsAndBytesConfig\u003c/span\u003e\n\n\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eChatModel\u003c/span\u003e:\n    def \u003cspan class=\"hljs-title function_\"\u003e__init__\u003c/span\u003e(self, model=\u003cspan class=\"hljs-string\"\u003e\"codellama/CodeLlama-7b-Instruct-hf\"\u003c/span\u003e):\n        quantization_config = \u003cspan class=\"hljs-title class_\"\u003eBitsAndBytesConfig\u003c/span\u003e(\n            load_in_4bit=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, # \u003cspan class=\"hljs-number\"\u003e4\u003c/span\u003eë¹„íŠ¸ ì–‘ìí™” ì‚¬ìš©\n            bnb_4bit_compute_dtype=torch.\u003cspan class=\"hljs-property\"\u003efloat16\u003c/span\u003e,\n            bnb_4bit_use_double_quant=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e,\n        )\n        self.\u003cspan class=\"hljs-property\"\u003emodel\u003c/span\u003e = \u003cspan class=\"hljs-title class_\"\u003eAutoModelForCausalLM\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_pretrained\u003c/span\u003e(\n            model,\n            quantization_config=quantization_config,\n            device_map=\u003cspan class=\"hljs-string\"\u003e\"cuda\"\u003c/span\u003e,\n            cache_dir=\u003cspan class=\"hljs-string\"\u003e\"./models\"\u003c/span\u003e, # ëª¨ë¸ì„ models í´ë”ì— ë‹¤ìš´ë¡œë“œ\n        )\n        self.\u003cspan class=\"hljs-property\"\u003etokenizer\u003c/span\u003e = \u003cspan class=\"hljs-title class_\"\u003eAutoTokenizer\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_pretrained\u003c/span\u003e(\n            model, use_fast=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e, padding_side=\u003cspan class=\"hljs-string\"\u003e\"left\"\u003c/span\u003e\n        )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eë˜í•œ, ì‚¬ìš©ìì˜ ì´ì „ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ AIê°€ ìƒì„±í•œ ì‘ë‹µì„ ì €ì¥í•˜ëŠ” ê³ ì • ê¸¸ì´ì˜ íˆìŠ¤í† ë¦¬ ëª©ë¡ì„ ë§Œë“­ë‹ˆë‹¤. ì´ëŠ” ëŒ€í™”ì˜ ê¸°ì–µì„ ì œê³µí•˜ì—¬ LLMì—ê²Œ ëŒ€í™”ì˜ ê¸°ì–µì„ ë¶€ì—¬í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eself.\u003cspan class=\"hljs-property\"\u003ehistory\u003c/span\u003e = []\nself.\u003cspan class=\"hljs-property\"\u003ehistory_length\u003c/span\u003e = \u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eCode Llamaì€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì•ì— ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eê¸°ë³¸ì ìœ¼ë¡œ, codellama-13b-chat ì˜ˆì œì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eself.\u003cspan class=\"hljs-property\"\u003eDEFAULT_SYSTEM_PROMPT\u003c/span\u003e = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\u003cspan class=\"hljs-string\"\u003e\"\\\në‹¹ì‹ ì€ ì½”ë“œì™€ ì†Œí”„íŠ¸ì›¨ì–´ ë””ìì¸ì— ëŒ€í•œ ê¹Šì€ ì§€ì‹ì„ ê°€ì§„, ë„ì›€ì´ ë˜ëŠ”, ì˜ˆì˜ ë°”ë¥´ê³  ì •ì§í•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. í•­ìƒ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë‹µë³€ì„ í•´ì•¼ í•˜ë©°, ì•ˆì „í•˜ê³  ì‹ ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤. ë‹µë³€ì— í•´ë¡œìš´, ë¶€ì •í•œ, ì¸ì¢… ì°¨ë³„ì , ì„± ì°¨ë³„ì , ìœ í•´í•œ, ìœ„í—˜í•œ, ë˜ëŠ” ë¶ˆë²•ì ì¸ ë‚´ìš©ì„ í¬í•¨í•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤. ë‹µë³€ì´ ì‚¬íšŒì ìœ¼ë¡œ í¸í–¥ë˜ê±°ë‚˜ ë¶€ì •ì ì´ì—¬ì„  ì•ˆë©ë‹ˆë‹¤.\\n\\në§Œì•½ ì§ˆë¬¸ì´ ì´í•´í•  ìˆ˜ ì—†ê±°ë‚˜ ì‚¬ì‹¤ì ìœ¼ë¡œ ì¼ê´€ì„±ì´ ì—†ë‹¤ë©´, ì˜¬ë°”ë¥¸ ëŒ€ë‹µ ëŒ€ì‹  ì™œ ì˜ëª»ëœ ê²ƒì¸ì§€ ì„¤ëª…í•˜ì„¸ìš”. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µì„ ëª¨ë¥´ë©´, ê°€ì§œ ì •ë³´ë¥¼ ê³µìœ í•˜ì§€ ë§ê³  ëŒ€ì‹  ë§í•´ì£¼ì„¸ìš”.\\\n        \"\u003c/span\u003e\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eì´ì œ self.historyì— í˜„ì¬ ëŒ€í™”ë¥¼ ì¶”ê°€í•˜ëŠ” í•¨ìˆ˜ë¥¼ êµ¬í˜„í•´ë´…ì‹œë‹¤.\u003c/p\u003e\n\u003cp\u003eLLM(ì–´ë¼ìš´ë“œ  ëª¨ë¸)ì€ í•œì •ëœ ë¬¸ë§¥ ê¸¸ì´ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ë©”ëª¨ë¦¬ì— ì •ë³´ë¥¼ í•œì •ì ìœ¼ë¡œ ë³´ê´€í•  ìˆ˜ë°–ì— ì—†ìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” self.history_length = 1 ê°œì˜ ì§ˆë¬¸ê³¼ ëŒ€ë‹µë§Œ ìµœëŒ€í•œ ë³´ê´€í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e    def \u003cspan class=\"hljs-title function_\"\u003eappend_to_history\u003c/span\u003e(self, user_prompt, response):\n        self.\u003cspan class=\"hljs-property\"\u003ehistory\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e((user_prompt, response))\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(self.\u003cspan class=\"hljs-property\"\u003ehistory\u003c/span\u003e) \u003e self.\u003cspan class=\"hljs-property\"\u003ehistory_length\u003c/span\u003e:\n            self.\u003cspan class=\"hljs-property\"\u003ehistory\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003epop\u003c/span\u003e(\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eë§ˆì¹¨ë‚´ ìš°ë¦¬ëŠ” ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ê¸°ë°˜í•œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” generate í•¨ìˆ˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eê° LLMì—ëŠ” í›ˆë ¨ì— ì‚¬ìš©ëœ íŠ¹ì • í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ìˆìŠµë‹ˆë‹¤. Code Llamaì˜ ê²½ìš° codellama-13b-chatì˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì°¸ì¡°ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e    def \u003cspan class=\"hljs-title function_\"\u003egenerate\u003c/span\u003e(\n        self, user_prompt, system_prompt, top_p=\u003cspan class=\"hljs-number\"\u003e0.9\u003c/span\u003e, temperature=\u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e, max_new_tokens=\u003cspan class=\"hljs-number\"\u003e512\u003c/span\u003e\n    ):\n\n        texts = [f\u003cspan class=\"hljs-string\"\u003e\"\u0026#x3C;s\u003e[INST] \u0026#x3C;\u0026#x3C;SYS\u003e\u003e\\n{system_prompt}\\n\u0026#x3C;\u0026#x3C;/SYS\u003e\u003e\\n\\n\"\u003c/span\u003e]\n        do_strip = \u003cspan class=\"hljs-title class_\"\u003eFalse\u003c/span\u003e\n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e old_prompt, old_response \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e self.\u003cspan class=\"hljs-property\"\u003ehistory\u003c/span\u003e:\n            old_prompt = old_prompt.\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e() \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e do_strip \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e old_prompt\n            do_strip = \u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e\n            texts.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"{old_prompt} [/INST] {old_response.strip()} \u0026#x3C;/s\u003e\u0026#x3C;s\u003e[INST] \"\u003c/span\u003e)\n        user_prompt = user_prompt.\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e() \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e do_strip \u003cspan class=\"hljs-keyword\"\u003eelse\u003c/span\u003e user_prompt\n        texts.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e\"{user_prompt} [/INST]\"\u003c/span\u003e)\n        prompt = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ejoin\u003c/span\u003e(texts)\n\n        inputs = self.\u003cspan class=\"hljs-title function_\"\u003etokenizer\u003c/span\u003e(\n            prompt, return_tensors=\u003cspan class=\"hljs-string\"\u003e\"pt\"\u003c/span\u003e, add_special_tokens=\u003cspan class=\"hljs-title class_\"\u003eFalse\u003c/span\u003e\n        ).\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"cuda\"\u003c/span\u003e)\n\n        output = self.\u003cspan class=\"hljs-property\"\u003emodel\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egenerate\u003c/span\u003e(\n            inputs[\u003cspan class=\"hljs-string\"\u003e\"input_ids\"\u003c/span\u003e],\n            attention_mask=inputs[\u003cspan class=\"hljs-string\"\u003e\"attention_mask\"\u003c/span\u003e],\n            pad_token_id=self.\u003cspan class=\"hljs-property\"\u003etokenizer\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003eeos_token_id\u003c/span\u003e,\n            max_new_tokens=max_new_tokens,\n            do_sample=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e,\n            top_p=top_p,\n            top_k=\u003cspan class=\"hljs-number\"\u003e50\u003c/span\u003e,\n            temperature=temperature,\n        )\n        output = output[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003eto\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"cpu\"\u003c/span\u003e)\n        response = self.\u003cspan class=\"hljs-property\"\u003etokenizer\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003edecode\u003c/span\u003e(output[inputs[\u003cspan class=\"hljs-string\"\u003e\"input_ids\"\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003eshape\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e] : -\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e])\n        self.\u003cspan class=\"hljs-title function_\"\u003eappend_to_history\u003c/span\u003e(user_prompt, response)\n        \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e response\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eì‘ë‹µì€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤. ë‹µë³€ì˜ ì°½ì˜ì„±ì€ top_p ë° temperatureì™€ ê°™ì€ ë§¤ê°œë³€ìˆ˜ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003etop_pë¥¼ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ í† í°ì˜ í™•ë¥  ê°’ì„ ì œí•œí•˜ì—¬ ë„ˆë¬´ ë“œë¬¼ê²Œ ë°œìƒí•˜ëŠ” í† í°ì„ ìƒì„±í•˜ëŠ” ê²ƒì„ í”¼í•  ìˆ˜ ìˆì–´ìš”:\u003c/p\u003e\n\u003cp\u003etemperatureë¥¼ ì‚¬ìš©í•˜ë©´ ì¶œë ¥ í† í°ì˜ í™•ë¥  ë¶„í¬ë¥¼ í‰í‰í•˜ê²Œ í•˜ê±°ë‚˜ ë‚ ì¹´ë¡­ê²Œ í•  ìˆ˜ ìˆì–´ìš”:\u003c/p\u003e\n\u003cp\u003eí”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì§„í–‰í•˜ê¸° ì „ì— ChatModelì„ í…ŒìŠ¤íŠ¸í•´ë³´ì£ .\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eChatModel\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e *\n\nmodel = \u003cspan class=\"hljs-title class_\"\u003eChatModel\u003c/span\u003e()\nresponse = model.\u003cspan class=\"hljs-title function_\"\u003egenerate\u003c/span\u003e(\n    user_prompt=\u003cspan class=\"hljs-string\"\u003e\"C++ì—ì„œ hello world í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•´ë´\"\u003c/span\u003e, \n    system_prompt=model.\u003cspan class=\"hljs-property\"\u003eDEFAULT_SYSTEM_PROMPT\u003c/span\u003e\n)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(response)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003eë‹¹ì‹ ì´ ìš”ì²­í•œ ì‘ì—…ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ í…Œì´ë¸” íƒœê·¸ê°€ \u003cspan class=\"hljs-title class_\"\u003eMarkdown\u003c/span\u003e í˜•ì‹ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e streamlit \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e st\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eChatModel\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e *\n\nst.\u003cspan class=\"hljs-title function_\"\u003etitle\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Code Llama Assistant\"\u003c/span\u003e)\n\n\n@st.\u003cspan class=\"hljs-property\"\u003ecache_resource\u003c/span\u003e\ndef \u003cspan class=\"hljs-title function_\"\u003eload_model\u003c/span\u003e():\n    model = \u003cspan class=\"hljs-title class_\"\u003eChatModel\u003c/span\u003e()\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e model\n\n\nmodel = \u003cspan class=\"hljs-title function_\"\u003eload_model\u003c/span\u003e()  # load our \u003cspan class=\"hljs-title class_\"\u003eChatModel\u003c/span\u003e once and then cache it\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eë‹¤ìŒìœ¼ë¡œ generate í•¨ìˆ˜ë¥¼ ìœ„í•œ ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ë¥¼ ì…ë ¥ ì œì–´í•˜ëŠ” ì‚¬ì´ë“œë°”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-property\"\u003esidebar\u003c/span\u003e:\n    temperature = st.\u003cspan class=\"hljs-title function_\"\u003eslider\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"ì˜¨ë„\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2.0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.1\u003c/span\u003e)\n    top_p = st.\u003cspan class=\"hljs-title function_\"\u003eslider\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"top_p\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e1.0\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0.9\u003c/span\u003e)\n    max_new_tokens = st.\u003cspan class=\"hljs-title function_\"\u003enumber_input\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"max_new_tokens\"\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e128\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e4096\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e256\u003c/span\u003e)\n    system_prompt = st.\u003cspan class=\"hljs-title function_\"\u003etext_area\u003c/span\u003e(\n        \u003cspan class=\"hljs-string\"\u003e\"ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\"\u003c/span\u003e, value=model.\u003cspan class=\"hljs-property\"\u003eDEFAULT_SYSTEM_PROMPT\u003c/span\u003e, height=\u003cspan class=\"hljs-number\"\u003e500\u003c/span\u003e\n    )\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eê·¸ë¦¬ê³  ì±—ë´‡ ë©”ì‹œì§€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"messages\"\u003c/span\u003e not \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e:\n    st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e = []\n\n# ì•± ì¬ì‹¤í–‰ì‹œ ê¸°ë¡ëœ ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e message \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e:\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-title function_\"\u003echat_message\u003c/span\u003e(message[\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e]):\n        st.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(message[\u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e])\n\n# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e prompt := st.\u003cspan class=\"hljs-title function_\"\u003echat_input\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!\"\u003c/span\u003e):\n    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€\n    st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e({\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: prompt})\n    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆì— í‘œì‹œ\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-title function_\"\u003echat_message\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e):\n        st.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(prompt)\n\n    # ì±—ë´‡ ì‘ë‹µì„ ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆì— í‘œì‹œ\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-title function_\"\u003echat_message\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"assistant\"\u003c/span\u003e):\n        user_prompt = st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e[-\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e]\n        answer = model.\u003cspan class=\"hljs-title function_\"\u003egenerate\u003c/span\u003e(\n            user_prompt,\n            top_p=top_p,\n            temperature=temperature,\n            max_new_tokens=max_new_tokens,\n            system_prompt=system_prompt,\n        )\n        response = st.\u003cspan class=\"hljs-title function_\"\u003ewrite\u003c/span\u003e(answer)\n    st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e({\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"assistant\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: answer})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eìŠ¤íŠ¸ë¦¼ë¦¿ ì•±ì„ streamlit run app.pyë¡œ ì‹¤í–‰í•˜ì—¬ ë¸Œë¼ìš°ì €ê°€ ì—´ë¦½ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eì´ì œ ì±—ë´‡ì— ì½”ë”© ê´€ë ¨ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\u003c/p\u003e\n\u003ch1\u003eê²°ë¡ \u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eì €í¬ëŠ” Meta AIì˜ Code Llama LLMì„ í™œìš©í•˜ì—¬ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ êµ¬í˜„í–ˆì–´ìš”. ê·¸ë¦¬ê³  Hugging Faceì˜ transformer ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ Streamlitì„ ì‚¬ìš©í•´ì„œ í”„ë¡ íŠ¸ì—”ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“¤ì—ˆì–´ìš”.\u003c/p\u003e\n\u003cp\u003e6GBì˜ GPU ë©”ëª¨ë¦¬ë¥¼ ê°–ì¶˜ ë…¸íŠ¸ë¶ìœ¼ë¡œëŠ” 4ë¹„íŠ¸ ì–‘ìí™”ëœ Code Llama ëª¨ë¸ì„ 7B ë§¤ê°œë³€ìˆ˜ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ë°–ì— ì—†ì—ˆì–´ìš”. ë” í° GPUë¥¼ ì‚¬ìš©í•˜ë©´ 16ë¹„íŠ¸ ë²„ì „ì´ë‚˜ ë” í° ëª¨ë¸ì´ ë” ì˜ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤.\u003c/p\u003e\n\u003cp\u003eP.S. Code Llamaë¡œë¶€í„° ì œê°€ ë°›ì€ ë†ë‹´ë³´ë‹¤ ë” ì¬ë¯¸ìˆëŠ” ë†ë‹´ë“¤ì„ ê¸°ëŒ€í•´ë´…ë‹ˆë‹¤ ğŸ¤¡.\u003c/p\u003e\n\u003cp\u003eë” ë§ì€ LLMì— ê´€ì‹¬ì´ ìˆìœ¼ì‹œë‹¤ë©´, ìµœê·¼ì— ê³µê°œëœ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ì— ëŒ€í•œ ê°œìš”ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003eì°¸ê³  ìë£Œ\u003c/h1\u003e\n\u003cp\u003e[1] B. RoziÃ¨re ì™¸: Code Llama: ì½”ë“œë¥¼ ìœ„í•œ ì˜¤í”ˆ ê¸°ë°˜ ëª¨ë¸ (2023), arXiv:2308.12950\u003c/p\u003e\n\u003ch1\u003eìì›\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eStreamlit ì±„íŒ… ì•± ì˜ˆì œ: ê¸°ë³¸ LLM ì±„íŒ… ì•± êµ¬ì¶•\u003c/li\u003e\n\u003cli\u003eHugging Face Code Llama gradio êµ¬í˜„: codellama-13b-chat\u003c/li\u003e\n\u003cli\u003eì´ ë¬¸ì„œì˜ ì „ì²´ ì‘ì—… ì½”ë“œ: \u003ca href=\"https://github.com/leoneversberg/codellama-chatbot\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://github.com/leoneversberg/codellama-chatbot\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-22-HowtoBuildYourOwnLLMCodingAssistantWithCodeLlama"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>