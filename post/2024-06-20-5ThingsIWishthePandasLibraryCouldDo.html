<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>판다 라이브러리가 할 수 있는 5가지를 소개합니다 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-20-5ThingsIWishthePandasLibraryCouldDo" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="판다 라이브러리가 할 수 있는 5가지를 소개합니다 | itposting" data-gatsby-head="true"/><meta property="og:title" content="판다 라이브러리가 할 수 있는 5가지를 소개합니다 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-20-5ThingsIWishthePandasLibraryCouldDo" data-gatsby-head="true"/><meta name="twitter:title" content="판다 라이브러리가 할 수 있는 5가지를 소개합니다 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-20 15:50" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-0fd008072af5a644.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_buildManifest.js" defer=""></script><script src="/_next/static/FH3Qr-mLAesqA0X5IFRQr/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">판다 라이브러리가 할 수 있는 5가지를 소개합니다</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="판다 라이브러리가 할 수 있는 5가지를 소개합니다" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 20, 2024</span><span class="posts_reading_time__f7YPP">8<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-20-5ThingsIWishthePandasLibraryCouldDo&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>아래는 해당 기사에 대한 코드를 찾을 수 있습니다.</p>
<p>Pandas 라이브러리 덕분에 파이썬에서의 표 데이터 처리, 분석 및 처리가 오늘날 이렇게 쉽고 간단히 수행되는 일은 없습니다.</p>
<p>현재, Pandas API는 표 데이터 관리에 필요한 다양한 기능을 제공하여 거의 모든 데이터 과학 프로젝트를 지원하고 있습니다. 예를 들어:</p>
<ul>
<li>입력 및 출력 작업</li>
<li>데이터 필터링</li>
<li>테이블 조인</li>
<li>데이터 시각화</li>
<li>중복 데이터 처리 등과 같은 여러 기능이 있습니다. 자세한 내용은 여기를 참조해 주세요.</li>
</ul>
<p>판다스는 실제로 표 형식의 데이터를 다루는 대부분의 데이터 과학자들에게 선택되는 도구이지만, 제 프로젝트에서 이를 활용하면서 판다스의 주요 단점/제약 조건 몇 가지를 깨달았습니다. 이 글에서는 이에 대해 논의하고자 합니다.</p>
<p>따라서, 이 글에서는 현실 세계에서의 표 데이터셋에서 판다스가 해낼 수 있다고 희망하는 다섯 가지 기능을 제시합니다.</p>
<p>이 기사의 하이라이트는 다음과 같습니다:</p>
<p>#1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면 좋겠어요
#2 Pandas가 한 번에 여러 CSV 파일을 읽을 수 있다면 좋겠어요
#3 Pandas 데이터프레임이 더 적은 메모리를 사용하면 좋겠어요
#4 Pandas가 대규모 데이터셋에 사용될 수 있다면 좋겠어요
#5 Pandas가 SQL처럼 조건부 조인을 지원한다면 좋겠어요</p>
<p>시작해봐요 🚀!</p>
<h2>#1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면</h2>
<p>안타깝게도, Pandas의 CSV 파일에서/로의 입출력 작업은 직렬화되어 있어 Pandas에는 내재 된 멀티 쓰레딩 지원이 없습니다.</p>
<p>우선, CSV 파일을 읽는 문맥에서의 직렬화는 판다스가 CSV 데이터를 한 번에 한 행(또는 한 줄)만 읽는 것을 의미합니다. 아래 애니메이션에서 이것이 설명되어 있습니다:</p>
<p><img src="https://miro.medium.com/v2/resize:fit:780/1*2cE0tW6MpSL9o21DzWvsIw.gif" alt="serialization"></p>
<p>입력 작업과 비슷하게, 출력 작업 또한 좋지 않습니다. 판다스는 데이터프레임을 CSV 파일에 직렬화된 방식으로 저장합니다.</p>
<p>직렬화된 입력 및 출력 작업의 과정은 굉장히 비효율적이고 시간이 많이 소요되는 작업입니다.</p>
<h2>가능한 대안</h2>
<p>제 탐색 결과, 전체 입력-출력 실행 시간을 개선하기 위한 두 가지 잠재적인 해결책이 있습니다.</p>
<ul>
<li>Pickle, Parquet 및 Feather와 같은 다른 파일 형식을 사용하여 데이터프레임을 읽고 저장하는 것이 좋습니다.</li>
</ul>
<p>빠르면서도 디스크에 데이터를 저장하기 위해 적은 메모리를 사용하는 이러한 형식에 대해 더 자세히 알아보려면 아래 블로그에서 확인해주세요:</p>
<ul>
<li>Pandas와는 달리 병렬화 기능을 갖춘 DataTable과 같은 라이브러리를 사용하세요.</li>
</ul>
<p>아래 블로그에서 DataTable에 대해 더 읽어보세요:</p>
<h2>#2 Pandas가 동시에 여러 CSV 파일을 읽을 수 있다면 좋겠다</h2>
<p>여러 개의 CSV 파일이 포함된 폴더가 있고, 이를 Pandas DataFrame으로 읽고 가져와야 한다고 상상해보세요.</p>
<p>판다스에서 이 작업을 수행하는 유일한 방법은 파일 목록을 반복하고 하나씩 읽는 것입니다. 아래에서 보여진 것처럼:</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/1*9cPCbiuow73SBR4kWHlpAg.gif" alt="이미지"></p>
<p>위의 그림은 다음과 같이 프로그래밍적으로 시연될 수 있습니다:</p>
<p>판다스에서 멀티스레딩을 지원하지 않기 때문에 병렬로 읽을 수 있는 파일 세트는 한 번에 하나씩 읽어야 하며, 이로 인해 실행 시간이 늘어나고 자원이 비효율적으로 사용될 수 있습니다.</p>
<h2>가능한 대안</h2>
<p>DataTable 라이브러리는 다시 한 번 이 제한 사항을 해결하기 위한 Pandas의 좋은 대안으로 자리를 잡고 있습니다.</p>
<p>DataTable을 사용하면 여러 CSV 파일을 효율적으로 읽을 수 있습니다. 아래에서 이를 확인해보세요:</p>
<p>아래 블로그에서 런타임 성능에 대해 더 많이 알아보세요:</p>
<h1>#3 판다 데이터프레임이 더 적은 메모리를 사용하도록 했으면 좋겠어요</h1>
<p>판다 데이터프레임은 작업에 있어서 굉장히 비효율적이고 메모리를 많이 소비합니다. 예를 들어, 아래에 보여지는 두 개의 열로 이루어진 데이터프레임을 생성한다고 가정해 봅시다:</p>
<p>이제, 위의 데이터프레임 df의 두 열에 판다가 할당한 데이터 유형을 알아보기 위해 dtypes 속성을 사용해 봅시다:</p>
<p>기본적으로, 판다는 항상 열에 가장 큰 메모리 데이터 유형을 할당합니다. 예를 들어, 판다가 위에서 colA를 정수 값으로 해석했을 때, 선택할 수 있는 4가지 하위 카테고리가 있었습니다.</p>
<ul>
<li>int8: 8비트 정수 데이터 유형으로 [-2⁷, 2⁷] 범위의 정수를 포함합니다.</li>
<li>int16: 16비트 정수 데이터 유형으로 [-2¹⁵, 2¹⁵] 범위의 정수를 포함합니다.</li>
<li>int32: 32비트 정수 데이터 유형으로 [-2³¹, 2³¹] 범위의 정수를 포함합니다.</li>
<li>int64: 64비트 정수 데이터 유형으로 [-2⁶³, 2⁶³] 범위의 정수를 포함합니다.</li>
</ul>
<p>그러나 판다스는 해당 열의 현재 값 범위와 관계없이 정수 값 열의 데이터 유형을 int64로 할당했습니다. 우리는 colB와 유사한 데이터 유형 행동을 발견했습니다.</p>
<h2>가능한 대안</h2>
<p>메모리 활용을 최적화하기 위해, "민맥스 감소 분석(min-max-reduce analysis)"이라고 부르는 방향이 있을 수 있습니다.</p>
<p>우선, 관심 있는 열에서 최소값과 최대값을 찾는 것부터 시작해요.</p>
<p>마지막 단계는 열의 데이터 유형을 축약(줄이기)하는 것이에요.</p>
<p>현재 값의 범위를 int16 데이터 유형으로 압축할 수 있기 때문에 (왜냐하면 -2¹⁵<code> 10000 (min)</code> 30000 (max) `2¹⁵), 아래에 보여지는 것처럼 astype() 메서드를 사용하여 데이터 유형을 int64에서 int16으로 변환할 거예요:</p>
<p>이 간단한 한 줄짜리 데이터 유형 변환으로 colA 열이 사용하는 총 메모리가 약 40% 정도 감소했어요.</p>
<p>비슷한 최소-최대-축소 분석을 통해 다른 정수 및 부동 소수점 값 열의 데이터 유형을 변경할 수도 있습니다.</p>
<p>아래 블로그에서 메모리 최적화 기술에 대해 더 읽어보세요:</p>
<h1>#4 파이썬 Pandas를 대규모 데이터셋에 사용할 수 있다면 좋겠어요</h1>
<p>위에서 논의한 대로, Pandas에는 내재적인 멀티 스레딩 지원이 없습니다. 결과적으로 데이터 규모와 관계없이 Pandas는 항상 단일 코어를 활용하므로 데이터 크기에 비례한 실행 시간 증가가 발생합니다.</p>
<p><img src="/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_1.png" alt="image"></p>
<p>For instance, consider an experiment to study the correlation between DataFrame size and the run-time to execute a function on the DataFrame.</p>
<p>We start with a random DataFrame comprising a thousand rows and two columns.</p>
<p>Next, we define a function that takes a row of the DataFrame and returns its sum. This function is implemented below:</p>
<p>각 반복마다 DataFrame의 각 행의 합을 계산하는 데 걸리는 시간을 결정합니다. 무작위성을 제거하기 위해 각 반복을 run 번 반복할 것입니다. 각 반복의 끝에서 DataFrame의 크기를 두 배로 증가시킬 것입니다.</p>
<p>다음에 실험이 구현되어 있습니다:</p>
<p>아래 플롯은 반복 대 실행 시간 그래프를 나타냅니다. 각 반복마다 DataFrame의 크기가 두 배씩 증가하고 Pandas의 실행 시간도 그렇게 늘어납니다. 이는 Pandas의 실행 시간이 항상 DataFrame의 크기에 비례하며 병렬 처리를 채택하지 않는다는 것을 나타냅니다.</p>
<h2>가능한 대안</h2>
<p>Pandas는 작은 데이터셋에서 작업하기에 매우 좋습니다. 그러나 데이터 규모와 파이프라인의 복잡성이 증가함에 따라 데이터 과학자로서는 상기한 실행 시간 문제 때문에 활용을 자제해야 합니다.</p>
<p>프로젝트를 제품화하는 것이 목표라면 PySpark가 이상적입니다. 다른 대안으로는 Terality, Vaex, DataTable 및 Dask가 있습니다 — 주로 대용량 데이터셋에 대한 Pandas보다 지역 계산을 권장합니다.</p>
<h1>#5 Pandas가 SQL과 유사한 조인 조건을 지원했으면 좋겠네요 (어떤 방식으로든)</h1>
<p>SQL 작업을 하는 사람들은 테이블을 병합하기 위해 복잡한 조인 조건을 쓰는 것을 즐기지 않나요?</p>
<p>이름에서 알 수 있듯이 조건부 조인은 단순한 등가성 기반의 병합 조건을 넘어섭니다. 다시 말해, 여러 테이블에서 필드 간의 등가성 이외의 조건을 기반으로 조인을 설정할 수 있습니다.</p>
<p>예를 들어, table1과 table2라는 두 테이블이 있다고 가정해 봅시다:</p>
<p>다음 조건에 따라 이 두 테이블을 결합하는 것이 목적입니다.</p>
<pre><code class="hljs language-sql">(table1.col1 <span class="hljs-operator">=</span> table2.col1 <span class="hljs-operator">+</span> <span class="hljs-number">2</span>) 그리고 (table2.col2 <span class="hljs-operator">>=</span> table2.col2 <span class="hljs-operator">-</span> <span class="hljs-number">2</span>) 그리고 (table2.col2 <span class="hljs-operator">&#x3C;=</span> table2.col2 <span class="hljs-operator">+</span> <span class="hljs-number">2</span>)
</code></pre>
<h2>SQL 조인</h2>
<p>위의 조건부 조인은 SQL에서 매우 간단하게 작업할 수 있습니다. 아래에 구현된 SQL 쿼리가 출력을 생성합니다:</p>
<h2>판다스 조인</h2>
<p>판다는 데이터프레임에서 동일성을 기반으로 한 조인만 수행할 수 있습니다. 다시 말하면, 판다의 merge() 메소드는 조인 열의 값이 동일할 때에만 두 레코드를 조인하는 것이 가능하며, 조건부 조인의 가능성이 없어집니다.</p>
<p>따라서, 판다의 merge() 메소드를 사용하여 조건부 조인을 수행하는 몇 가지 방법은 다음과 같습니다:</p>
<ul>
<li>조인 조건에서 정의된 연산을 사용하여 조인 열을 생성하고, 새 열에 대해 merge를 실행합니다.</li>
<li>교차 조인을 수행하고 데이터프레임을 필터링합니다. 이는 대규모 데이터셋의 경우에 매우 어려울 수 있습니다.</li>
</ul>
<p>아래에서 접근 방법 1과 접근 방법 2를 조합한 예시가 제시되어 있습니다.</p>
<p>먼저, 병합할 두 데이터프레임을 만들고 join 조건을 정의합니다.</p>
<pre><code class="hljs language-js">(table1.<span class="hljs-property">col1</span> = table2.<span class="hljs-property">col3</span> + <span class="hljs-number">2</span>) and (table2.<span class="hljs-property">col2</span> >= table2.<span class="hljs-property">col4</span> - <span class="hljs-number">2</span>) and (table2.<span class="hljs-property">col2</span> &#x3C;= table2.<span class="hljs-property">col4</span> + <span class="hljs-number">2</span>)
</code></pre>
<p>join 조건이 부등식으로 이루어져 있기 때문에 일단 부등식들을 잠시 두고, 처음에는 동등식 (table1.col1 = table2.col3 + 2) 에 따라 먼저 join을 수행합니다. 그런 다음 결과를 필터링하여 다음 두 조건을 반영할 것입니다.</p>
<p>먼저, table2에 새로운 열을 생성할 것입니다. 이를 col3_1이라고 해보죠.</p>
<p>이제 table1의 col1과 table2의 col3_1을 기준으로 조인을 수행하고, 조인 조건으로부터 남은 조건을 기반으로 얻은 레코드를 필터링할 것입니다. 아래에서 구현되어 있습니다:</p>
<h2>가능한 대안</h2>
<p>PandaSQL은 Pandas와 SQL을 혼합한 인기 있는 Python 패키지로, SQL 문법의 강력함을 파이썬 환경에서 활용할 수 있습니다.</p>
<p>따라서, PandaSQL을 사용하면 SQL 문법을 사용하여 pandas 데이터프레임을 쿼리할 수 있습니다. SQL과 유사한 조인을 실행하려면 PandaSQL을 탐색해보세요.</p>
<p>SQL을 Pandas DataFrames와 함께 사용하는 쉬움은 실행 시간이라는 대가를 지는데요. 이에 대해 이전 블로그 글에서 다뤄보았습니다:</p>
<h1>결론</h1>
<p>이번 포스트에서 다뤄본 바와 같이, Pandas의 주요 제한 사항 다섯 가지와 이러한 상황에서 갇힌 경우 대처 방법을 논의했습니다.</p>
<p>Pandas는 일상적인 탭형 데이터 분석, 관리 및 처리 작업에 놀라울 정도로 유용합니다.</p>
<p>하지만, 제작 수준의 솔루션을 개발하거나 처리할 데이터가 많을 경우, Pandas는 병렬화와 자원 활용에 제한이 있어 도움이 되지 않을 수 있습니다.</p>
<p>읽어 주셔서 감사합니다!</p>
<p>🚀 무료 데이터 과학 PDF(550페이지 이상)를 받아보세요. 매일 뉴스레터를 구독하시면 320개 이상의 게시물을 만나볼 수 있습니다:</p>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/0*6rHTrx_iItXjC1hm.gif" alt="image"></p>
<p><img src="/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_3.png" alt="image"></p>
<p>Visit us at DataDrivenInvestor.com</p>
<p>Subscribe to DDIntel <a href="link_here">here</a>.</p>
<p>Have a unique story to share? Submit to DDIntel <a href="link_here">here</a>.</p>
<p>저희 창조자 생태계에 참여해 주세요.</p>
<p>DDIntel은 주요 사이트와 인기 있는 DDI Medium 출판물에서 가장 주목할 만한 내용을 담고 있습니다. 커뮤니티에서 더 많은 통찰력 있는 작업을 확인해보세요.</p>
<p>DDI 공식 텔레그램 채널: <a href="https://t.me/+tafUp6ecEys4YjQ1" rel="nofollow" target="_blank">https://t.me/+tafUp6ecEys4YjQ1</a></p>
<p>LinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해 주세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"판다 라이브러리가 할 수 있는 5가지를 소개합니다","description":"","date":"2024-06-20 15:50","slug":"2024-06-20-5ThingsIWishthePandasLibraryCouldDo","content":"\n\n아래는 해당 기사에 대한 코드를 찾을 수 있습니다.\n\nPandas 라이브러리 덕분에 파이썬에서의 표 데이터 처리, 분석 및 처리가 오늘날 이렇게 쉽고 간단히 수행되는 일은 없습니다.\n\n현재, Pandas API는 표 데이터 관리에 필요한 다양한 기능을 제공하여 거의 모든 데이터 과학 프로젝트를 지원하고 있습니다. 예를 들어:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 입력 및 출력 작업\n- 데이터 필터링\n- 테이블 조인\n- 데이터 시각화\n- 중복 데이터 처리 등과 같은 여러 기능이 있습니다. 자세한 내용은 여기를 참조해 주세요.\n\n판다스는 실제로 표 형식의 데이터를 다루는 대부분의 데이터 과학자들에게 선택되는 도구이지만, 제 프로젝트에서 이를 활용하면서 판다스의 주요 단점/제약 조건 몇 가지를 깨달았습니다. 이 글에서는 이에 대해 논의하고자 합니다.\n\n따라서, 이 글에서는 현실 세계에서의 표 데이터셋에서 판다스가 해낼 수 있다고 희망하는 다섯 가지 기능을 제시합니다.\n\n이 기사의 하이라이트는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n#1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면 좋겠어요\n#2 Pandas가 한 번에 여러 CSV 파일을 읽을 수 있다면 좋겠어요\n#3 Pandas 데이터프레임이 더 적은 메모리를 사용하면 좋겠어요\n#4 Pandas가 대규모 데이터셋에 사용될 수 있다면 좋겠어요\n#5 Pandas가 SQL처럼 조건부 조인을 지원한다면 좋겠어요\n\n시작해봐요 🚀!\n\n## #1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면\n\n안타깝게도, Pandas의 CSV 파일에서/로의 입출력 작업은 직렬화되어 있어 Pandas에는 내재 된 멀티 쓰레딩 지원이 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우선, CSV 파일을 읽는 문맥에서의 직렬화는 판다스가 CSV 데이터를 한 번에 한 행(또는 한 줄)만 읽는 것을 의미합니다. 아래 애니메이션에서 이것이 설명되어 있습니다:\n\n![serialization](https://miro.medium.com/v2/resize:fit:780/1*2cE0tW6MpSL9o21DzWvsIw.gif)\n\n입력 작업과 비슷하게, 출력 작업 또한 좋지 않습니다. 판다스는 데이터프레임을 CSV 파일에 직렬화된 방식으로 저장합니다.\n\n직렬화된 입력 및 출력 작업의 과정은 굉장히 비효율적이고 시간이 많이 소요되는 작업입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가능한 대안\n\n제 탐색 결과, 전체 입력-출력 실행 시간을 개선하기 위한 두 가지 잠재적인 해결책이 있습니다.\n\n- Pickle, Parquet 및 Feather와 같은 다른 파일 형식을 사용하여 데이터프레임을 읽고 저장하는 것이 좋습니다.\n\n빠르면서도 디스크에 데이터를 저장하기 위해 적은 메모리를 사용하는 이러한 형식에 대해 더 자세히 알아보려면 아래 블로그에서 확인해주세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Pandas와는 달리 병렬화 기능을 갖춘 DataTable과 같은 라이브러리를 사용하세요.\n\n아래 블로그에서 DataTable에 대해 더 읽어보세요:\n\n## #2 Pandas가 동시에 여러 CSV 파일을 읽을 수 있다면 좋겠다\n\n여러 개의 CSV 파일이 포함된 폴더가 있고, 이를 Pandas DataFrame으로 읽고 가져와야 한다고 상상해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n판다스에서 이 작업을 수행하는 유일한 방법은 파일 목록을 반복하고 하나씩 읽는 것입니다. 아래에서 보여진 것처럼:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*9cPCbiuow73SBR4kWHlpAg.gif)\n\n위의 그림은 다음과 같이 프로그래밍적으로 시연될 수 있습니다:\n\n판다스에서 멀티스레딩을 지원하지 않기 때문에 병렬로 읽을 수 있는 파일 세트는 한 번에 하나씩 읽어야 하며, 이로 인해 실행 시간이 늘어나고 자원이 비효율적으로 사용될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가능한 대안\n\nDataTable 라이브러리는 다시 한 번 이 제한 사항을 해결하기 위한 Pandas의 좋은 대안으로 자리를 잡고 있습니다.\n\nDataTable을 사용하면 여러 CSV 파일을 효율적으로 읽을 수 있습니다. 아래에서 이를 확인해보세요:\n\n아래 블로그에서 런타임 성능에 대해 더 많이 알아보세요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# #3 판다 데이터프레임이 더 적은 메모리를 사용하도록 했으면 좋겠어요\n\n판다 데이터프레임은 작업에 있어서 굉장히 비효율적이고 메모리를 많이 소비합니다. 예를 들어, 아래에 보여지는 두 개의 열로 이루어진 데이터프레임을 생성한다고 가정해 봅시다:\n\n이제, 위의 데이터프레임 df의 두 열에 판다가 할당한 데이터 유형을 알아보기 위해 dtypes 속성을 사용해 봅시다:\n\n기본적으로, 판다는 항상 열에 가장 큰 메모리 데이터 유형을 할당합니다. 예를 들어, 판다가 위에서 colA를 정수 값으로 해석했을 때, 선택할 수 있는 4가지 하위 카테고리가 있었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- int8: 8비트 정수 데이터 유형으로 [-2⁷, 2⁷] 범위의 정수를 포함합니다.\n- int16: 16비트 정수 데이터 유형으로 [-2¹⁵, 2¹⁵] 범위의 정수를 포함합니다.\n- int32: 32비트 정수 데이터 유형으로 [-2³¹, 2³¹] 범위의 정수를 포함합니다.\n- int64: 64비트 정수 데이터 유형으로 [-2⁶³, 2⁶³] 범위의 정수를 포함합니다.\n\n그러나 판다스는 해당 열의 현재 값 범위와 관계없이 정수 값 열의 데이터 유형을 int64로 할당했습니다. 우리는 colB와 유사한 데이터 유형 행동을 발견했습니다.\n\n## 가능한 대안\n\n메모리 활용을 최적화하기 위해, \"민맥스 감소 분석(min-max-reduce analysis)\"이라고 부르는 방향이 있을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우선, 관심 있는 열에서 최소값과 최대값을 찾는 것부터 시작해요.\n\n마지막 단계는 열의 데이터 유형을 축약(줄이기)하는 것이에요.\n\n현재 값의 범위를 int16 데이터 유형으로 압축할 수 있기 때문에 (왜냐하면 -2¹⁵` 10000 (min)` 30000 (max) `2¹⁵), 아래에 보여지는 것처럼 astype() 메서드를 사용하여 데이터 유형을 int64에서 int16으로 변환할 거예요:\n\n이 간단한 한 줄짜리 데이터 유형 변환으로 colA 열이 사용하는 총 메모리가 약 40% 정도 감소했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비슷한 최소-최대-축소 분석을 통해 다른 정수 및 부동 소수점 값 열의 데이터 유형을 변경할 수도 있습니다.\n\n아래 블로그에서 메모리 최적화 기술에 대해 더 읽어보세요:\n\n# #4 파이썬 Pandas를 대규모 데이터셋에 사용할 수 있다면 좋겠어요\n\n위에서 논의한 대로, Pandas에는 내재적인 멀티 스레딩 지원이 없습니다. 결과적으로 데이터 규모와 관계없이 Pandas는 항상 단일 코어를 활용하므로 데이터 크기에 비례한 실행 시간 증가가 발생합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_1.png)\n\nFor instance, consider an experiment to study the correlation between DataFrame size and the run-time to execute a function on the DataFrame.\n\nWe start with a random DataFrame comprising a thousand rows and two columns.\n\nNext, we define a function that takes a row of the DataFrame and returns its sum. This function is implemented below:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 반복마다 DataFrame의 각 행의 합을 계산하는 데 걸리는 시간을 결정합니다. 무작위성을 제거하기 위해 각 반복을 run 번 반복할 것입니다. 각 반복의 끝에서 DataFrame의 크기를 두 배로 증가시킬 것입니다.\n\n다음에 실험이 구현되어 있습니다:\n\n아래 플롯은 반복 대 실행 시간 그래프를 나타냅니다. 각 반복마다 DataFrame의 크기가 두 배씩 증가하고 Pandas의 실행 시간도 그렇게 늘어납니다. 이는 Pandas의 실행 시간이 항상 DataFrame의 크기에 비례하며 병렬 처리를 채택하지 않는다는 것을 나타냅니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_2.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 가능한 대안\n\nPandas는 작은 데이터셋에서 작업하기에 매우 좋습니다. 그러나 데이터 규모와 파이프라인의 복잡성이 증가함에 따라 데이터 과학자로서는 상기한 실행 시간 문제 때문에 활용을 자제해야 합니다.\n\n프로젝트를 제품화하는 것이 목표라면 PySpark가 이상적입니다. 다른 대안으로는 Terality, Vaex, DataTable 및 Dask가 있습니다 — 주로 대용량 데이터셋에 대한 Pandas보다 지역 계산을 권장합니다.\n\n# #5 Pandas가 SQL과 유사한 조인 조건을 지원했으면 좋겠네요 (어떤 방식으로든)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSQL 작업을 하는 사람들은 테이블을 병합하기 위해 복잡한 조인 조건을 쓰는 것을 즐기지 않나요?\n\n이름에서 알 수 있듯이 조건부 조인은 단순한 등가성 기반의 병합 조건을 넘어섭니다. 다시 말해, 여러 테이블에서 필드 간의 등가성 이외의 조건을 기반으로 조인을 설정할 수 있습니다.\n\n예를 들어, table1과 table2라는 두 테이블이 있다고 가정해 봅시다:\n\n다음 조건에 따라 이 두 테이블을 결합하는 것이 목적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sql\n(table1.col1 = table2.col1 + 2) 그리고 (table2.col2 \u003e= table2.col2 - 2) 그리고 (table2.col2 \u003c= table2.col2 + 2)\n```\n\n## SQL 조인\n\n위의 조건부 조인은 SQL에서 매우 간단하게 작업할 수 있습니다. 아래에 구현된 SQL 쿼리가 출력을 생성합니다:\n\n## 판다스 조인\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n판다는 데이터프레임에서 동일성을 기반으로 한 조인만 수행할 수 있습니다. 다시 말하면, 판다의 merge() 메소드는 조인 열의 값이 동일할 때에만 두 레코드를 조인하는 것이 가능하며, 조건부 조인의 가능성이 없어집니다.\n\n따라서, 판다의 merge() 메소드를 사용하여 조건부 조인을 수행하는 몇 가지 방법은 다음과 같습니다:\n\n- 조인 조건에서 정의된 연산을 사용하여 조인 열을 생성하고, 새 열에 대해 merge를 실행합니다.\n- 교차 조인을 수행하고 데이터프레임을 필터링합니다. 이는 대규모 데이터셋의 경우에 매우 어려울 수 있습니다.\n\n아래에서 접근 방법 1과 접근 방법 2를 조합한 예시가 제시되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 병합할 두 데이터프레임을 만들고 join 조건을 정의합니다.\n\n```js\n(table1.col1 = table2.col3 + 2) and (table2.col2 \u003e= table2.col4 - 2) and (table2.col2 \u003c= table2.col4 + 2)\n```\n\njoin 조건이 부등식으로 이루어져 있기 때문에 일단 부등식들을 잠시 두고, 처음에는 동등식 (table1.col1 = table2.col3 + 2) 에 따라 먼저 join을 수행합니다. 그런 다음 결과를 필터링하여 다음 두 조건을 반영할 것입니다.\n\n먼저, table2에 새로운 열을 생성할 것입니다. 이를 col3_1이라고 해보죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 table1의 col1과 table2의 col3_1을 기준으로 조인을 수행하고, 조인 조건으로부터 남은 조건을 기반으로 얻은 레코드를 필터링할 것입니다. 아래에서 구현되어 있습니다:\n\n## 가능한 대안\n\nPandaSQL은 Pandas와 SQL을 혼합한 인기 있는 Python 패키지로, SQL 문법의 강력함을 파이썬 환경에서 활용할 수 있습니다.\n\n따라서, PandaSQL을 사용하면 SQL 문법을 사용하여 pandas 데이터프레임을 쿼리할 수 있습니다. SQL과 유사한 조인을 실행하려면 PandaSQL을 탐색해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nSQL을 Pandas DataFrames와 함께 사용하는 쉬움은 실행 시간이라는 대가를 지는데요. 이에 대해 이전 블로그 글에서 다뤄보았습니다:\n\n# 결론\n\n이번 포스트에서 다뤄본 바와 같이, Pandas의 주요 제한 사항 다섯 가지와 이러한 상황에서 갇힌 경우 대처 방법을 논의했습니다.\n\nPandas는 일상적인 탭형 데이터 분석, 관리 및 처리 작업에 놀라울 정도로 유용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만, 제작 수준의 솔루션을 개발하거나 처리할 데이터가 많을 경우, Pandas는 병렬화와 자원 활용에 제한이 있어 도움이 되지 않을 수 있습니다.\n\n읽어 주셔서 감사합니다!\n\n🚀 무료 데이터 과학 PDF(550페이지 이상)를 받아보세요. 매일 뉴스레터를 구독하시면 320개 이상의 게시물을 만나볼 수 있습니다:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/0*6rHTrx_iItXjC1hm.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_3.png)\n\nVisit us at DataDrivenInvestor.com\n\nSubscribe to DDIntel [here](link_here).\n\nHave a unique story to share? Submit to DDIntel [here](link_here).\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 창조자 생태계에 참여해 주세요.\n\nDDIntel은 주요 사이트와 인기 있는 DDI Medium 출판물에서 가장 주목할 만한 내용을 담고 있습니다. 커뮤니티에서 더 많은 통찰력 있는 작업을 확인해보세요.\n\nDDI 공식 텔레그램 채널: [https://t.me/+tafUp6ecEys4YjQ1](https://t.me/+tafUp6ecEys4YjQ1)\n\nLinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해 주세요.","ogImage":{"url":"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_0.png"},"coverImage":"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_0.png","tag":["Tech"],"readingTime":8},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e아래는 해당 기사에 대한 코드를 찾을 수 있습니다.\u003c/p\u003e\n\u003cp\u003ePandas 라이브러리 덕분에 파이썬에서의 표 데이터 처리, 분석 및 처리가 오늘날 이렇게 쉽고 간단히 수행되는 일은 없습니다.\u003c/p\u003e\n\u003cp\u003e현재, Pandas API는 표 데이터 관리에 필요한 다양한 기능을 제공하여 거의 모든 데이터 과학 프로젝트를 지원하고 있습니다. 예를 들어:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e입력 및 출력 작업\u003c/li\u003e\n\u003cli\u003e데이터 필터링\u003c/li\u003e\n\u003cli\u003e테이블 조인\u003c/li\u003e\n\u003cli\u003e데이터 시각화\u003c/li\u003e\n\u003cli\u003e중복 데이터 처리 등과 같은 여러 기능이 있습니다. 자세한 내용은 여기를 참조해 주세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e판다스는 실제로 표 형식의 데이터를 다루는 대부분의 데이터 과학자들에게 선택되는 도구이지만, 제 프로젝트에서 이를 활용하면서 판다스의 주요 단점/제약 조건 몇 가지를 깨달았습니다. 이 글에서는 이에 대해 논의하고자 합니다.\u003c/p\u003e\n\u003cp\u003e따라서, 이 글에서는 현실 세계에서의 표 데이터셋에서 판다스가 해낼 수 있다고 희망하는 다섯 가지 기능을 제시합니다.\u003c/p\u003e\n\u003cp\u003e이 기사의 하이라이트는 다음과 같습니다:\u003c/p\u003e\n\u003cp\u003e#1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면 좋겠어요\n#2 Pandas가 한 번에 여러 CSV 파일을 읽을 수 있다면 좋겠어요\n#3 Pandas 데이터프레임이 더 적은 메모리를 사용하면 좋겠어요\n#4 Pandas가 대규모 데이터셋에 사용될 수 있다면 좋겠어요\n#5 Pandas가 SQL처럼 조건부 조인을 지원한다면 좋겠어요\u003c/p\u003e\n\u003cp\u003e시작해봐요 🚀!\u003c/p\u003e\n\u003ch2\u003e#1 Pandas가 CSV 파일을 병렬로 읽을 수 있다면\u003c/h2\u003e\n\u003cp\u003e안타깝게도, Pandas의 CSV 파일에서/로의 입출력 작업은 직렬화되어 있어 Pandas에는 내재 된 멀티 쓰레딩 지원이 없습니다.\u003c/p\u003e\n\u003cp\u003e우선, CSV 파일을 읽는 문맥에서의 직렬화는 판다스가 CSV 데이터를 한 번에 한 행(또는 한 줄)만 읽는 것을 의미합니다. 아래 애니메이션에서 이것이 설명되어 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:780/1*2cE0tW6MpSL9o21DzWvsIw.gif\" alt=\"serialization\"\u003e\u003c/p\u003e\n\u003cp\u003e입력 작업과 비슷하게, 출력 작업 또한 좋지 않습니다. 판다스는 데이터프레임을 CSV 파일에 직렬화된 방식으로 저장합니다.\u003c/p\u003e\n\u003cp\u003e직렬화된 입력 및 출력 작업의 과정은 굉장히 비효율적이고 시간이 많이 소요되는 작업입니다.\u003c/p\u003e\n\u003ch2\u003e가능한 대안\u003c/h2\u003e\n\u003cp\u003e제 탐색 결과, 전체 입력-출력 실행 시간을 개선하기 위한 두 가지 잠재적인 해결책이 있습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePickle, Parquet 및 Feather와 같은 다른 파일 형식을 사용하여 데이터프레임을 읽고 저장하는 것이 좋습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e빠르면서도 디스크에 데이터를 저장하기 위해 적은 메모리를 사용하는 이러한 형식에 대해 더 자세히 알아보려면 아래 블로그에서 확인해주세요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ePandas와는 달리 병렬화 기능을 갖춘 DataTable과 같은 라이브러리를 사용하세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e아래 블로그에서 DataTable에 대해 더 읽어보세요:\u003c/p\u003e\n\u003ch2\u003e#2 Pandas가 동시에 여러 CSV 파일을 읽을 수 있다면 좋겠다\u003c/h2\u003e\n\u003cp\u003e여러 개의 CSV 파일이 포함된 폴더가 있고, 이를 Pandas DataFrame으로 읽고 가져와야 한다고 상상해보세요.\u003c/p\u003e\n\u003cp\u003e판다스에서 이 작업을 수행하는 유일한 방법은 파일 목록을 반복하고 하나씩 읽는 것입니다. 아래에서 보여진 것처럼:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*9cPCbiuow73SBR4kWHlpAg.gif\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e위의 그림은 다음과 같이 프로그래밍적으로 시연될 수 있습니다:\u003c/p\u003e\n\u003cp\u003e판다스에서 멀티스레딩을 지원하지 않기 때문에 병렬로 읽을 수 있는 파일 세트는 한 번에 하나씩 읽어야 하며, 이로 인해 실행 시간이 늘어나고 자원이 비효율적으로 사용될 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e가능한 대안\u003c/h2\u003e\n\u003cp\u003eDataTable 라이브러리는 다시 한 번 이 제한 사항을 해결하기 위한 Pandas의 좋은 대안으로 자리를 잡고 있습니다.\u003c/p\u003e\n\u003cp\u003eDataTable을 사용하면 여러 CSV 파일을 효율적으로 읽을 수 있습니다. 아래에서 이를 확인해보세요:\u003c/p\u003e\n\u003cp\u003e아래 블로그에서 런타임 성능에 대해 더 많이 알아보세요:\u003c/p\u003e\n\u003ch1\u003e#3 판다 데이터프레임이 더 적은 메모리를 사용하도록 했으면 좋겠어요\u003c/h1\u003e\n\u003cp\u003e판다 데이터프레임은 작업에 있어서 굉장히 비효율적이고 메모리를 많이 소비합니다. 예를 들어, 아래에 보여지는 두 개의 열로 이루어진 데이터프레임을 생성한다고 가정해 봅시다:\u003c/p\u003e\n\u003cp\u003e이제, 위의 데이터프레임 df의 두 열에 판다가 할당한 데이터 유형을 알아보기 위해 dtypes 속성을 사용해 봅시다:\u003c/p\u003e\n\u003cp\u003e기본적으로, 판다는 항상 열에 가장 큰 메모리 데이터 유형을 할당합니다. 예를 들어, 판다가 위에서 colA를 정수 값으로 해석했을 때, 선택할 수 있는 4가지 하위 카테고리가 있었습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eint8: 8비트 정수 데이터 유형으로 [-2⁷, 2⁷] 범위의 정수를 포함합니다.\u003c/li\u003e\n\u003cli\u003eint16: 16비트 정수 데이터 유형으로 [-2¹⁵, 2¹⁵] 범위의 정수를 포함합니다.\u003c/li\u003e\n\u003cli\u003eint32: 32비트 정수 데이터 유형으로 [-2³¹, 2³¹] 범위의 정수를 포함합니다.\u003c/li\u003e\n\u003cli\u003eint64: 64비트 정수 데이터 유형으로 [-2⁶³, 2⁶³] 범위의 정수를 포함합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e그러나 판다스는 해당 열의 현재 값 범위와 관계없이 정수 값 열의 데이터 유형을 int64로 할당했습니다. 우리는 colB와 유사한 데이터 유형 행동을 발견했습니다.\u003c/p\u003e\n\u003ch2\u003e가능한 대안\u003c/h2\u003e\n\u003cp\u003e메모리 활용을 최적화하기 위해, \"민맥스 감소 분석(min-max-reduce analysis)\"이라고 부르는 방향이 있을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e우선, 관심 있는 열에서 최소값과 최대값을 찾는 것부터 시작해요.\u003c/p\u003e\n\u003cp\u003e마지막 단계는 열의 데이터 유형을 축약(줄이기)하는 것이에요.\u003c/p\u003e\n\u003cp\u003e현재 값의 범위를 int16 데이터 유형으로 압축할 수 있기 때문에 (왜냐하면 -2¹⁵\u003ccode\u003e 10000 (min)\u003c/code\u003e 30000 (max) `2¹⁵), 아래에 보여지는 것처럼 astype() 메서드를 사용하여 데이터 유형을 int64에서 int16으로 변환할 거예요:\u003c/p\u003e\n\u003cp\u003e이 간단한 한 줄짜리 데이터 유형 변환으로 colA 열이 사용하는 총 메모리가 약 40% 정도 감소했어요.\u003c/p\u003e\n\u003cp\u003e비슷한 최소-최대-축소 분석을 통해 다른 정수 및 부동 소수점 값 열의 데이터 유형을 변경할 수도 있습니다.\u003c/p\u003e\n\u003cp\u003e아래 블로그에서 메모리 최적화 기술에 대해 더 읽어보세요:\u003c/p\u003e\n\u003ch1\u003e#4 파이썬 Pandas를 대규모 데이터셋에 사용할 수 있다면 좋겠어요\u003c/h1\u003e\n\u003cp\u003e위에서 논의한 대로, Pandas에는 내재적인 멀티 스레딩 지원이 없습니다. 결과적으로 데이터 규모와 관계없이 Pandas는 항상 단일 코어를 활용하므로 데이터 크기에 비례한 실행 시간 증가가 발생합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_1.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eFor instance, consider an experiment to study the correlation between DataFrame size and the run-time to execute a function on the DataFrame.\u003c/p\u003e\n\u003cp\u003eWe start with a random DataFrame comprising a thousand rows and two columns.\u003c/p\u003e\n\u003cp\u003eNext, we define a function that takes a row of the DataFrame and returns its sum. This function is implemented below:\u003c/p\u003e\n\u003cp\u003e각 반복마다 DataFrame의 각 행의 합을 계산하는 데 걸리는 시간을 결정합니다. 무작위성을 제거하기 위해 각 반복을 run 번 반복할 것입니다. 각 반복의 끝에서 DataFrame의 크기를 두 배로 증가시킬 것입니다.\u003c/p\u003e\n\u003cp\u003e다음에 실험이 구현되어 있습니다:\u003c/p\u003e\n\u003cp\u003e아래 플롯은 반복 대 실행 시간 그래프를 나타냅니다. 각 반복마다 DataFrame의 크기가 두 배씩 증가하고 Pandas의 실행 시간도 그렇게 늘어납니다. 이는 Pandas의 실행 시간이 항상 DataFrame의 크기에 비례하며 병렬 처리를 채택하지 않는다는 것을 나타냅니다.\u003c/p\u003e\n\u003ch2\u003e가능한 대안\u003c/h2\u003e\n\u003cp\u003ePandas는 작은 데이터셋에서 작업하기에 매우 좋습니다. 그러나 데이터 규모와 파이프라인의 복잡성이 증가함에 따라 데이터 과학자로서는 상기한 실행 시간 문제 때문에 활용을 자제해야 합니다.\u003c/p\u003e\n\u003cp\u003e프로젝트를 제품화하는 것이 목표라면 PySpark가 이상적입니다. 다른 대안으로는 Terality, Vaex, DataTable 및 Dask가 있습니다 — 주로 대용량 데이터셋에 대한 Pandas보다 지역 계산을 권장합니다.\u003c/p\u003e\n\u003ch1\u003e#5 Pandas가 SQL과 유사한 조인 조건을 지원했으면 좋겠네요 (어떤 방식으로든)\u003c/h1\u003e\n\u003cp\u003eSQL 작업을 하는 사람들은 테이블을 병합하기 위해 복잡한 조인 조건을 쓰는 것을 즐기지 않나요?\u003c/p\u003e\n\u003cp\u003e이름에서 알 수 있듯이 조건부 조인은 단순한 등가성 기반의 병합 조건을 넘어섭니다. 다시 말해, 여러 테이블에서 필드 간의 등가성 이외의 조건을 기반으로 조인을 설정할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, table1과 table2라는 두 테이블이 있다고 가정해 봅시다:\u003c/p\u003e\n\u003cp\u003e다음 조건에 따라 이 두 테이블을 결합하는 것이 목적입니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-sql\"\u003e(table1.col1 \u003cspan class=\"hljs-operator\"\u003e=\u003c/span\u003e table2.col1 \u003cspan class=\"hljs-operator\"\u003e+\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e) 그리고 (table2.col2 \u003cspan class=\"hljs-operator\"\u003e\u003e=\u003c/span\u003e table2.col2 \u003cspan class=\"hljs-operator\"\u003e-\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e) 그리고 (table2.col2 \u003cspan class=\"hljs-operator\"\u003e\u0026#x3C;=\u003c/span\u003e table2.col2 \u003cspan class=\"hljs-operator\"\u003e+\u003c/span\u003e \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2\u003eSQL 조인\u003c/h2\u003e\n\u003cp\u003e위의 조건부 조인은 SQL에서 매우 간단하게 작업할 수 있습니다. 아래에 구현된 SQL 쿼리가 출력을 생성합니다:\u003c/p\u003e\n\u003ch2\u003e판다스 조인\u003c/h2\u003e\n\u003cp\u003e판다는 데이터프레임에서 동일성을 기반으로 한 조인만 수행할 수 있습니다. 다시 말하면, 판다의 merge() 메소드는 조인 열의 값이 동일할 때에만 두 레코드를 조인하는 것이 가능하며, 조건부 조인의 가능성이 없어집니다.\u003c/p\u003e\n\u003cp\u003e따라서, 판다의 merge() 메소드를 사용하여 조건부 조인을 수행하는 몇 가지 방법은 다음과 같습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e조인 조건에서 정의된 연산을 사용하여 조인 열을 생성하고, 새 열에 대해 merge를 실행합니다.\u003c/li\u003e\n\u003cli\u003e교차 조인을 수행하고 데이터프레임을 필터링합니다. 이는 대규모 데이터셋의 경우에 매우 어려울 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e아래에서 접근 방법 1과 접근 방법 2를 조합한 예시가 제시되어 있습니다.\u003c/p\u003e\n\u003cp\u003e먼저, 병합할 두 데이터프레임을 만들고 join 조건을 정의합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e(table1.\u003cspan class=\"hljs-property\"\u003ecol1\u003c/span\u003e = table2.\u003cspan class=\"hljs-property\"\u003ecol3\u003c/span\u003e + \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e) and (table2.\u003cspan class=\"hljs-property\"\u003ecol2\u003c/span\u003e \u003e= table2.\u003cspan class=\"hljs-property\"\u003ecol4\u003c/span\u003e - \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e) and (table2.\u003cspan class=\"hljs-property\"\u003ecol2\u003c/span\u003e \u0026#x3C;= table2.\u003cspan class=\"hljs-property\"\u003ecol4\u003c/span\u003e + \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ejoin 조건이 부등식으로 이루어져 있기 때문에 일단 부등식들을 잠시 두고, 처음에는 동등식 (table1.col1 = table2.col3 + 2) 에 따라 먼저 join을 수행합니다. 그런 다음 결과를 필터링하여 다음 두 조건을 반영할 것입니다.\u003c/p\u003e\n\u003cp\u003e먼저, table2에 새로운 열을 생성할 것입니다. 이를 col3_1이라고 해보죠.\u003c/p\u003e\n\u003cp\u003e이제 table1의 col1과 table2의 col3_1을 기준으로 조인을 수행하고, 조인 조건으로부터 남은 조건을 기반으로 얻은 레코드를 필터링할 것입니다. 아래에서 구현되어 있습니다:\u003c/p\u003e\n\u003ch2\u003e가능한 대안\u003c/h2\u003e\n\u003cp\u003ePandaSQL은 Pandas와 SQL을 혼합한 인기 있는 Python 패키지로, SQL 문법의 강력함을 파이썬 환경에서 활용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e따라서, PandaSQL을 사용하면 SQL 문법을 사용하여 pandas 데이터프레임을 쿼리할 수 있습니다. SQL과 유사한 조인을 실행하려면 PandaSQL을 탐색해보세요.\u003c/p\u003e\n\u003cp\u003eSQL을 Pandas DataFrames와 함께 사용하는 쉬움은 실행 시간이라는 대가를 지는데요. 이에 대해 이전 블로그 글에서 다뤄보았습니다:\u003c/p\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e이번 포스트에서 다뤄본 바와 같이, Pandas의 주요 제한 사항 다섯 가지와 이러한 상황에서 갇힌 경우 대처 방법을 논의했습니다.\u003c/p\u003e\n\u003cp\u003ePandas는 일상적인 탭형 데이터 분석, 관리 및 처리 작업에 놀라울 정도로 유용합니다.\u003c/p\u003e\n\u003cp\u003e하지만, 제작 수준의 솔루션을 개발하거나 처리할 데이터가 많을 경우, Pandas는 병렬화와 자원 활용에 제한이 있어 도움이 되지 않을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e읽어 주셔서 감사합니다!\u003c/p\u003e\n\u003cp\u003e🚀 무료 데이터 과학 PDF(550페이지 이상)를 받아보세요. 매일 뉴스레터를 구독하시면 320개 이상의 게시물을 만나볼 수 있습니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/0*6rHTrx_iItXjC1hm.gif\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-20-5ThingsIWishthePandasLibraryCouldDo_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003eVisit us at DataDrivenInvestor.com\u003c/p\u003e\n\u003cp\u003eSubscribe to DDIntel \u003ca href=\"link_here\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eHave a unique story to share? Submit to DDIntel \u003ca href=\"link_here\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e저희 창조자 생태계에 참여해 주세요.\u003c/p\u003e\n\u003cp\u003eDDIntel은 주요 사이트와 인기 있는 DDI Medium 출판물에서 가장 주목할 만한 내용을 담고 있습니다. 커뮤니티에서 더 많은 통찰력 있는 작업을 확인해보세요.\u003c/p\u003e\n\u003cp\u003eDDI 공식 텔레그램 채널: \u003ca href=\"https://t.me/+tafUp6ecEys4YjQ1\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://t.me/+tafUp6ecEys4YjQ1\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해 주세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-20-5ThingsIWishthePandasLibraryCouldDo"},"buildId":"FH3Qr-mLAesqA0X5IFRQr","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>