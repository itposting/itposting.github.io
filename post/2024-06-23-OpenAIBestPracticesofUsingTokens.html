<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>OpenAI  토큰을 사용하는 최고의 방법 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-23-OpenAIBestPracticesofUsingTokens" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="OpenAI  토큰을 사용하는 최고의 방법 | itposting" data-gatsby-head="true"/><meta property="og:title" content="OpenAI  토큰을 사용하는 최고의 방법 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-23-OpenAIBestPracticesofUsingTokens" data-gatsby-head="true"/><meta name="twitter:title" content="OpenAI  토큰을 사용하는 최고의 방법 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-23 18:58" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_buildManifest.js" defer=""></script><script src="/_next/static/kkckKPyxcjJp_o8wb2unW/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">OpenAI  토큰을 사용하는 최고의 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="OpenAI  토큰을 사용하는 최고의 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 23, 2024</span><span class="posts_reading_time__f7YPP">6<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-23-OpenAIBestPracticesofUsingTokens&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<img src="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png">
<h1>오픈AI 토큰이란</h1>
<p>오픈AI의 고급 언어 모델인 GPT-3.5 및 GPT-4와 같은 분야에서 "토큰"이란 텍스트에서 함께 자주 나타나는 문자 시퀀스를 가리킵니다. 이러한 모델은 이러한 토큰 간의 통계적 관계를 이해하고 예측하는 데 설계되어 있습니다.</p>
<p>텍스트를 토큰으로 분해하는 프로세스는 다른 모델 간에 다를 수 있습니다. 예를 들어, GPT-3.5와 GPT-4는 이전 모델과 달리 다른 토큰화 프로세스를 사용하여 입력 텍스트에 대해 다른 토큰을 생성합니다.</p>
<div class="content-ad"></div>
<p>일반적으로 한 토큰은 영어 텍스트의 네 문자에 해당하는 양으로, 대략 세 분의 삼분의 이 하나의 단어와 거의 비슷합니다. 따라서, 100개의 토큰은 대략 75단어에 해당합니다.</p>
<p>예를 들어, "OpenAI is great!"이라는 문장을 생각해 봅시다. 이 문장에서 토큰은 다음과 같이 분리될 수 있습니다:</p>
<p>[“Open”, “AI”, “ is”, “ great”, “!”]</p>
<p><img src="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_1.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>여기 각각이 토큰으로 간주됩니다. 모델에서 사용하는 구체적인 토큰화 프로세스에 따라 정확한 분할이 다를 수 있습니다. 예를 들어, 일부 모델은 "OpenAI"를 하나의 토큰으로 처리할 수 있지만, 다른 모델은 "Open"과 "AI"로 분할할 수도 있습니다. 마찬가지로, 공백과 구두점은 종종 별도의 토큰으로 처리됩니다. 그래서 이 예시에서는 다섯 개의 토큰이 있습니다: "Open", "AI", " is", " great", 그리고 "!".</p>
<p>토큰 길이 개념을 이해하기 위한 유용한 가이드라인을 제시해드리겠습니다:</p>
<ul>
<li>1 토큰은 대략 영어로 4자와 동일합니다.</li>
<li>1 토큰은 대략 단어의 3/4에 해당합니다.</li>
<li>100 토큰은 약 75단어에 해당합니다.</li>
</ul>
<p>또는,</p>
<div class="content-ad"></div>
<h1>토큰 인코딩</h1>
<p>토큰 인코딩은 자연어 처리(NLP) 및 기계 학습에서 중요한 단계입니다. 이는 기계가 이해하고 작업할 수 있는 형식인 고정 차원의 수치 벡터로 변환하는 과정입니다.</p>
<p>다른 토큰 인코딩은 서로 다른 모델에 연결되어 있으므로 텍스트를 토큰으로 변환할 때 어떤 모델을 사용할 지 고려해야 합니다.</p>
<div class="content-ad"></div>
<p>주어진 텍스트 문자열 (예: "OpenAI is great!")과 인코딩 (예: "cl100k_base")으로 토크나이저가 텍스트 문자열을 토큰 목록으로 분할할 수 있습니다 (예: ["Open", "AI", " is", " great", "!"]).</p>
<p>다음 표는 토큰 인코딩 방법과 OpenAI 모델 간의 매핑을 보여줍니다:</p>





















<table><thead><tr><th>토큰 인코딩 방법</th><th>OpenAI 모델</th></tr></thead><tbody><tr><td>cl100k_base</td><td>모델 1</td></tr><tr><td>cl200k_base</td><td>모델 2</td></tr><tr><td>cl500k_base</td><td>모델 3</td></tr></tbody></table>
<h1>토큰화</h1>
<div class="content-ad"></div>
<p>OpenAI의 맥락에서 토큰화는 텍스트를 더 작은 조각, 즉 토큰으로 분리하는 방법입니다. 이 토큰들은 텍스트에서 함께 자주 나타나는 문자 시퀀스로, OpenAI의 대형 언어 모델인 GPT-3.5 및 GPT-4 등에서 사용되어 텍스트를 처리하고 이해하는 데 활용됩니다.</p>
<p>Tiktoken은 OpenAI가 만든 기반 Python 도구입니다. 이 도구는 주로 OpenAI의 GPT-4와 같은 모델과 함께 작동하도록 설계된 빠른 바이트 페어 인코딩 (BPE) 토크나이저입니다. Tiktoken의 주요 기능은 텍스트를 더 작은 조각으로 나누어 모델이 텍스트를 처리하고 이해할 수 있도록 하는 것입니다.</p>
<p>오픈 소스 도구인 Tiktoken은 pip install tiktoken 명령을 사용하여 PyPI에서 쉽게 설치할 수 있습니다. 또한 JavaScript 환경에서 사용할 수 있는 커뮤니티 지원 버전도 있습니다.</p>
<p>Tiktoken의 주요 기능 중 하나는 교육용 하위 모듈인데, 이 모듈은 BPE의 작동 방식을 이해하고 사용자가 토큰화 프로세스를 시각화할 수 있도록 도와줍니다. 또한 Tiktoken은 유연하며 새로운 인코딩 지원을 추가할 수 있도록 사용자에게 허용합니다.</p>
<div class="content-ad"></div>
<p>예제 하나가 이렇게 보일 거예요:</p>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> tiktoken

encoding = tiktoken.get_encoding(<span class="hljs-string">"cl100k_base"</span>)
<span class="hljs-comment"># 특정 모델 이름에 해당하는 올바른 인코딩을 자동으로 로드하기 위해</span>
encoding = tiktoken.encoding_for_model(<span class="hljs-string">"gpt-3.5-turbo"</span>)

<span class="hljs-built_in">print</span>(encoding.encode(<span class="hljs-string">"OpenAI is great!"</span>))
</code></pre>
<p>출력은 이렇게 보일 거예요:</p>
<pre><code class="hljs language-python">[<span class="hljs-number">5109</span>, <span class="hljs-number">15836</span>, <span class="hljs-number">374</span>, <span class="hljs-number">2294</span>, <span class="hljs-number">0</span>]
</code></pre>
<div class="content-ad"></div>
<p>토큰을 세는 방법은 .encode()로 반환된 리스트의 길이를 세면 됩니다.</p>
<h1>토큰 한도</h1>
<p>요청에 사용할 수 있는 토큰의 최대 수는 선택한 모델에 따라 다르며, 입력 프롬프트 및 생성된 출력(gpt-3.5-turbo)에 대한 4096개의 토큰이라는 결합한 한도가 있습니다. 따라서, 입력에 4000개의 토큰을 할당하면 출력에는 최대 96개의 토큰이 남게 됩니다.</p>
<p>이 제약은 주로 기술적인 이유로 인해 발생합니다. 그러나, 입력을 더 간결하게 요약하거나 콘텐츠를 더 작은 세그먼트로 나누는 등 이러한 제한 내에서 효과적으로 작업하는 다양한 전략이 존재합니다.</p>
<div class="content-ad"></div>
<p>GPT4의 토큰 한도</p>
<p><img src="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_3.png" alt="Image"></p>
<p>더 많은 정보를 알고 싶다면 openai의 공식 웹사이트를 방문해보세요: <a href="https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo" rel="nofollow" target="_blank">여기를 클릭하세요</a></p>
<h1>토큰 가격 설정</h1>
<div class="content-ad"></div>
<p>OpenAI API는 다양한 모델 유형을 제공하며 각 모델은 다른 가격 수준에서 사용할 수 있습니다. 이러한 모델들은 능력이 다양하며 가장 진보된 것은 다빈치이고, 가장 빠른 것은 에이다입니다. 요청을 만드는 데 드는 비용은 이러한 모델에 따라 달라집니다.</p>
<p>예를 들어, GPT-4 Turbo 모델의 경우, 입력 기준으로 $0.01/1K 토큰, 출력 기준으로 $0.03/1K 토큰이 듭니다.</p>
<p>표:</p>
<p><img src="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_4.png" alt="OpenAI 모델 비용"></p>
<p>그리고 OpenAI에 따르면:</p>
<div class="content-ad"></div>
<p>Cobus Greyling님은 OpenAI 토큰 비용에 대한 멋진 차트를 보유하고 계시네요:</p>
<p><img src="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_5.png" alt="OpenAI Token Cost Chart"></p>
<h1>가격 계산기</h1>
<p>다음 "OpenAI 및 다른 LLM API 가격 계산기"를 활용하여 계산을 할 수 있습니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_6.png" alt="Image"></p>
<p>위는 1000개의 입력 단어, 500개의 출력 단어 및 100회의 API 호출에 대한 총 비용을 보여줍니다.</p>
<h1>Best Practices</h1>
<p>OpenAI 토큰을 사용할 때는 최적의 방법을 채택하여 효율성을 극대화하고 비용을 최소화하며 OpenAI의 API와의 상호 작용을 효과적이고 안전하게 보장할 수 있습니다. 다음은 추천하는 최상의 방법론입니다:</p>
<div class="content-ad"></div>
<h2>토큰 이코노믹스 이해하기</h2>
<p>사용하는 맥락에서 어떻게 토큰이 계산되는지, 그리고 토큰을 구성하는 것이 무엇인지 이해하세요. 다양한 입력 길이에 대한 대략적인 토큰 수를 알면 사용량과 비용을 보다 정확하게 추정하는 데 도움이 됩니다.</p>
<h2>프롬프트 디자인 최적화</h2>
<p>모델이 원하는 출력 생성 방향으로 이끌 수 있도록 프롬프트를 간결하면서도 충분히 구체적으로 디자인하세요. 이 균형을 유지하면 사용된 토큰 수를 줄이고 유용한 응답을 받을 확률을 높일 수 있습니다.</p>
<div class="content-ad"></div>
<h2>효율적인 토큰 관리 활용하기</h2>
<p>예상치 못한 비용을 피하기 위해 토큰 사용량을 추적하세요. 플랫폼이나 응용 프로그램에서 지원한다면 알림이나 제한을 구현하여 소비량을 모니터링하세요.</p>
<h2>가능한 경우 일괄 요청 처리하기</h2>
<p>사용 사례가 허용한다면 일괄 처리는 한 번에 한 요청을 처리하는 것보다 더 효율적일 수 있습니다. 이 방법은 비용 절감에도 도움이 될 수 있습니다.</p>
<div class="content-ad"></div>
<h2>작업에 적합한 모델 활용하기</h2>
<p>작업에 가장 적합한 모델을 선택하세요. Davinci와 같이 큰 모델은 더 강력하지만, Ada나 Babbage와 같은 작은 모델은 깊은 이해나 창의력이 필요하지 않은 작업에 대해 더 비용 효율적일 수 있어서 토큰을 절약할 수 있습니다.</p>
<h2>빈번한 요청에 대한 캐싱 구현하기</h2>
<p>응용 프로그램이 동일하거나 유사한 프롬프트로 반복적인 요청을 수행하는 경우, 응답을 캐싱하여 토큰을 절약할 수 있습니다. 캐시가 안전하게 관리되고 개인정보 및 데이터 보호 요구 사항을 준수하는지 확인하세요.</p>
<div class="content-ad"></div>
<h2>API 키 보호하기</h2>
<p>OpenAI API 키를 안전하게 보호하여 무단 사용을 방지하고, 토큰 낭비 및 예상치 못한 요금 부과를 방지하세요. 접근 제어를 구현하고 정기적으로 키를 변경하세요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"OpenAI  토큰을 사용하는 최고의 방법","description":"","date":"2024-06-23 18:58","slug":"2024-06-23-OpenAIBestPracticesofUsingTokens","content":"\n\n\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png\" /\u003e\n\n# 오픈AI 토큰이란\n\n오픈AI의 고급 언어 모델인 GPT-3.5 및 GPT-4와 같은 분야에서 \"토큰\"이란 텍스트에서 함께 자주 나타나는 문자 시퀀스를 가리킵니다. 이러한 모델은 이러한 토큰 간의 통계적 관계를 이해하고 예측하는 데 설계되어 있습니다.\n\n텍스트를 토큰으로 분해하는 프로세스는 다른 모델 간에 다를 수 있습니다. 예를 들어, GPT-3.5와 GPT-4는 이전 모델과 달리 다른 토큰화 프로세스를 사용하여 입력 텍스트에 대해 다른 토큰을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일반적으로 한 토큰은 영어 텍스트의 네 문자에 해당하는 양으로, 대략 세 분의 삼분의 이 하나의 단어와 거의 비슷합니다. 따라서, 100개의 토큰은 대략 75단어에 해당합니다.\n\n예를 들어, \"OpenAI is great!\"이라는 문장을 생각해 봅시다. 이 문장에서 토큰은 다음과 같이 분리될 수 있습니다:\n\n[“Open”, “AI”, “ is”, “ great”, “!”]\n\n![이미지](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 각각이 토큰으로 간주됩니다. 모델에서 사용하는 구체적인 토큰화 프로세스에 따라 정확한 분할이 다를 수 있습니다. 예를 들어, 일부 모델은 \"OpenAI\"를 하나의 토큰으로 처리할 수 있지만, 다른 모델은 \"Open\"과 \"AI\"로 분할할 수도 있습니다. 마찬가지로, 공백과 구두점은 종종 별도의 토큰으로 처리됩니다. 그래서 이 예시에서는 다섯 개의 토큰이 있습니다: \"Open\", \"AI\", \" is\", \" great\", 그리고 \"!\".\n\n토큰 길이 개념을 이해하기 위한 유용한 가이드라인을 제시해드리겠습니다:\n\n- 1 토큰은 대략 영어로 4자와 동일합니다.\n- 1 토큰은 대략 단어의 3/4에 해당합니다.\n- 100 토큰은 약 75단어에 해당합니다.\n\n또는,\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 토큰 인코딩\n\n토큰 인코딩은 자연어 처리(NLP) 및 기계 학습에서 중요한 단계입니다. 이는 기계가 이해하고 작업할 수 있는 형식인 고정 차원의 수치 벡터로 변환하는 과정입니다.\n\n다른 토큰 인코딩은 서로 다른 모델에 연결되어 있으므로 텍스트를 토큰으로 변환할 때 어떤 모델을 사용할 지 고려해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주어진 텍스트 문자열 (예: \"OpenAI is great!\")과 인코딩 (예: \"cl100k_base\")으로 토크나이저가 텍스트 문자열을 토큰 목록으로 분할할 수 있습니다 (예: [\"Open\", \"AI\", \" is\", \" great\", \"!\"]).\n\n다음 표는 토큰 인코딩 방법과 OpenAI 모델 간의 매핑을 보여줍니다:\n\n\n| 토큰 인코딩 방법 | OpenAI 모델 |\n|------------------|-------------|\n| cl100k_base      | 모델 1      |\n| cl200k_base      | 모델 2      |\n| cl500k_base      | 모델 3      |\n\n\n# 토큰화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOpenAI의 맥락에서 토큰화는 텍스트를 더 작은 조각, 즉 토큰으로 분리하는 방법입니다. 이 토큰들은 텍스트에서 함께 자주 나타나는 문자 시퀀스로, OpenAI의 대형 언어 모델인 GPT-3.5 및 GPT-4 등에서 사용되어 텍스트를 처리하고 이해하는 데 활용됩니다.\n\nTiktoken은 OpenAI가 만든 기반 Python 도구입니다. 이 도구는 주로 OpenAI의 GPT-4와 같은 모델과 함께 작동하도록 설계된 빠른 바이트 페어 인코딩 (BPE) 토크나이저입니다. Tiktoken의 주요 기능은 텍스트를 더 작은 조각으로 나누어 모델이 텍스트를 처리하고 이해할 수 있도록 하는 것입니다.\n\n오픈 소스 도구인 Tiktoken은 pip install tiktoken 명령을 사용하여 PyPI에서 쉽게 설치할 수 있습니다. 또한 JavaScript 환경에서 사용할 수 있는 커뮤니티 지원 버전도 있습니다.\n\nTiktoken의 주요 기능 중 하나는 교육용 하위 모듈인데, 이 모듈은 BPE의 작동 방식을 이해하고 사용자가 토큰화 프로세스를 시각화할 수 있도록 도와줍니다. 또한 Tiktoken은 유연하며 새로운 인코딩 지원을 추가할 수 있도록 사용자에게 허용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예제 하나가 이렇게 보일 거예요:\n\n```python\nimport tiktoken\n\nencoding = tiktoken.get_encoding(\"cl100k_base\")\n# 특정 모델 이름에 해당하는 올바른 인코딩을 자동으로 로드하기 위해\nencoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n\nprint(encoding.encode(\"OpenAI is great!\"))\n```\n\n출력은 이렇게 보일 거예요:\n\n```python\n[5109, 15836, 374, 2294, 0]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n토큰을 세는 방법은 .encode()로 반환된 리스트의 길이를 세면 됩니다.\n\n# 토큰 한도\n\n요청에 사용할 수 있는 토큰의 최대 수는 선택한 모델에 따라 다르며, 입력 프롬프트 및 생성된 출력(gpt-3.5-turbo)에 대한 4096개의 토큰이라는 결합한 한도가 있습니다. 따라서, 입력에 4000개의 토큰을 할당하면 출력에는 최대 96개의 토큰이 남게 됩니다.\n\n이 제약은 주로 기술적인 이유로 인해 발생합니다. 그러나, 입력을 더 간결하게 요약하거나 콘텐츠를 더 작은 세그먼트로 나누는 등 이러한 제한 내에서 효과적으로 작업하는 다양한 전략이 존재합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nGPT4의 토큰 한도\n\n![Image](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_3.png)\n\n더 많은 정보를 알고 싶다면 openai의 공식 웹사이트를 방문해보세요: [여기를 클릭하세요](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\n\n# 토큰 가격 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nOpenAI API는 다양한 모델 유형을 제공하며 각 모델은 다른 가격 수준에서 사용할 수 있습니다. 이러한 모델들은 능력이 다양하며 가장 진보된 것은 다빈치이고, 가장 빠른 것은 에이다입니다. 요청을 만드는 데 드는 비용은 이러한 모델에 따라 달라집니다.\n\n예를 들어, GPT-4 Turbo 모델의 경우, 입력 기준으로 $0.01/1K 토큰, 출력 기준으로 $0.03/1K 토큰이 듭니다.\n\n표:\n\n![OpenAI 모델 비용](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_4.png)\n\n그리고 OpenAI에 따르면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCobus Greyling님은 OpenAI 토큰 비용에 대한 멋진 차트를 보유하고 계시네요:\n\n![OpenAI Token Cost Chart](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_5.png)\n\n# 가격 계산기\n\n다음 \"OpenAI 및 다른 LLM API 가격 계산기\"를 활용하여 계산을 할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Image](/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_6.png)\n\n위는 1000개의 입력 단어, 500개의 출력 단어 및 100회의 API 호출에 대한 총 비용을 보여줍니다.\n\n# Best Practices\n\nOpenAI 토큰을 사용할 때는 최적의 방법을 채택하여 효율성을 극대화하고 비용을 최소화하며 OpenAI의 API와의 상호 작용을 효과적이고 안전하게 보장할 수 있습니다. 다음은 추천하는 최상의 방법론입니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 토큰 이코노믹스 이해하기\n\n사용하는 맥락에서 어떻게 토큰이 계산되는지, 그리고 토큰을 구성하는 것이 무엇인지 이해하세요. 다양한 입력 길이에 대한 대략적인 토큰 수를 알면 사용량과 비용을 보다 정확하게 추정하는 데 도움이 됩니다.\n\n## 프롬프트 디자인 최적화\n\n모델이 원하는 출력 생성 방향으로 이끌 수 있도록 프롬프트를 간결하면서도 충분히 구체적으로 디자인하세요. 이 균형을 유지하면 사용된 토큰 수를 줄이고 유용한 응답을 받을 확률을 높일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 효율적인 토큰 관리 활용하기\n\n예상치 못한 비용을 피하기 위해 토큰 사용량을 추적하세요. 플랫폼이나 응용 프로그램에서 지원한다면 알림이나 제한을 구현하여 소비량을 모니터링하세요.\n\n## 가능한 경우 일괄 요청 처리하기\n\n사용 사례가 허용한다면 일괄 처리는 한 번에 한 요청을 처리하는 것보다 더 효율적일 수 있습니다. 이 방법은 비용 절감에도 도움이 될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 작업에 적합한 모델 활용하기\n\n작업에 가장 적합한 모델을 선택하세요. Davinci와 같이 큰 모델은 더 강력하지만, Ada나 Babbage와 같은 작은 모델은 깊은 이해나 창의력이 필요하지 않은 작업에 대해 더 비용 효율적일 수 있어서 토큰을 절약할 수 있습니다.\n\n## 빈번한 요청에 대한 캐싱 구현하기\n\n응용 프로그램이 동일하거나 유사한 프롬프트로 반복적인 요청을 수행하는 경우, 응답을 캐싱하여 토큰을 절약할 수 있습니다. 캐시가 안전하게 관리되고 개인정보 및 데이터 보호 요구 사항을 준수하는지 확인하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## API 키 보호하기\n\nOpenAI API 키를 안전하게 보호하여 무단 사용을 방지하고, 토큰 낭비 및 예상치 못한 요금 부과를 방지하세요. 접근 제어를 구현하고 정기적으로 키를 변경하세요.","ogImage":{"url":"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png"},"coverImage":"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png","tag":["Tech"],"readingTime":6},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_0.png\"\u003e\n\u003ch1\u003e오픈AI 토큰이란\u003c/h1\u003e\n\u003cp\u003e오픈AI의 고급 언어 모델인 GPT-3.5 및 GPT-4와 같은 분야에서 \"토큰\"이란 텍스트에서 함께 자주 나타나는 문자 시퀀스를 가리킵니다. 이러한 모델은 이러한 토큰 간의 통계적 관계를 이해하고 예측하는 데 설계되어 있습니다.\u003c/p\u003e\n\u003cp\u003e텍스트를 토큰으로 분해하는 프로세스는 다른 모델 간에 다를 수 있습니다. 예를 들어, GPT-3.5와 GPT-4는 이전 모델과 달리 다른 토큰화 프로세스를 사용하여 입력 텍스트에 대해 다른 토큰을 생성합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e일반적으로 한 토큰은 영어 텍스트의 네 문자에 해당하는 양으로, 대략 세 분의 삼분의 이 하나의 단어와 거의 비슷합니다. 따라서, 100개의 토큰은 대략 75단어에 해당합니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, \"OpenAI is great!\"이라는 문장을 생각해 봅시다. 이 문장에서 토큰은 다음과 같이 분리될 수 있습니다:\u003c/p\u003e\n\u003cp\u003e[“Open”, “AI”, “ is”, “ great”, “!”]\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기 각각이 토큰으로 간주됩니다. 모델에서 사용하는 구체적인 토큰화 프로세스에 따라 정확한 분할이 다를 수 있습니다. 예를 들어, 일부 모델은 \"OpenAI\"를 하나의 토큰으로 처리할 수 있지만, 다른 모델은 \"Open\"과 \"AI\"로 분할할 수도 있습니다. 마찬가지로, 공백과 구두점은 종종 별도의 토큰으로 처리됩니다. 그래서 이 예시에서는 다섯 개의 토큰이 있습니다: \"Open\", \"AI\", \" is\", \" great\", 그리고 \"!\".\u003c/p\u003e\n\u003cp\u003e토큰 길이 개념을 이해하기 위한 유용한 가이드라인을 제시해드리겠습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e1 토큰은 대략 영어로 4자와 동일합니다.\u003c/li\u003e\n\u003cli\u003e1 토큰은 대략 단어의 3/4에 해당합니다.\u003c/li\u003e\n\u003cli\u003e100 토큰은 약 75단어에 해당합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e또는,\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e토큰 인코딩\u003c/h1\u003e\n\u003cp\u003e토큰 인코딩은 자연어 처리(NLP) 및 기계 학습에서 중요한 단계입니다. 이는 기계가 이해하고 작업할 수 있는 형식인 고정 차원의 수치 벡터로 변환하는 과정입니다.\u003c/p\u003e\n\u003cp\u003e다른 토큰 인코딩은 서로 다른 모델에 연결되어 있으므로 텍스트를 토큰으로 변환할 때 어떤 모델을 사용할 지 고려해야 합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e주어진 텍스트 문자열 (예: \"OpenAI is great!\")과 인코딩 (예: \"cl100k_base\")으로 토크나이저가 텍스트 문자열을 토큰 목록으로 분할할 수 있습니다 (예: [\"Open\", \"AI\", \" is\", \" great\", \"!\"]).\u003c/p\u003e\n\u003cp\u003e다음 표는 토큰 인코딩 방법과 OpenAI 모델 간의 매핑을 보여줍니다:\u003c/p\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003e토큰 인코딩 방법\u003c/th\u003e\u003cth\u003eOpenAI 모델\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003ecl100k_base\u003c/td\u003e\u003ctd\u003e모델 1\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003ecl200k_base\u003c/td\u003e\u003ctd\u003e모델 2\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003ecl500k_base\u003c/td\u003e\u003ctd\u003e모델 3\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n\u003ch1\u003e토큰화\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eOpenAI의 맥락에서 토큰화는 텍스트를 더 작은 조각, 즉 토큰으로 분리하는 방법입니다. 이 토큰들은 텍스트에서 함께 자주 나타나는 문자 시퀀스로, OpenAI의 대형 언어 모델인 GPT-3.5 및 GPT-4 등에서 사용되어 텍스트를 처리하고 이해하는 데 활용됩니다.\u003c/p\u003e\n\u003cp\u003eTiktoken은 OpenAI가 만든 기반 Python 도구입니다. 이 도구는 주로 OpenAI의 GPT-4와 같은 모델과 함께 작동하도록 설계된 빠른 바이트 페어 인코딩 (BPE) 토크나이저입니다. Tiktoken의 주요 기능은 텍스트를 더 작은 조각으로 나누어 모델이 텍스트를 처리하고 이해할 수 있도록 하는 것입니다.\u003c/p\u003e\n\u003cp\u003e오픈 소스 도구인 Tiktoken은 pip install tiktoken 명령을 사용하여 PyPI에서 쉽게 설치할 수 있습니다. 또한 JavaScript 환경에서 사용할 수 있는 커뮤니티 지원 버전도 있습니다.\u003c/p\u003e\n\u003cp\u003eTiktoken의 주요 기능 중 하나는 교육용 하위 모듈인데, 이 모듈은 BPE의 작동 방식을 이해하고 사용자가 토큰화 프로세스를 시각화할 수 있도록 도와줍니다. 또한 Tiktoken은 유연하며 새로운 인코딩 지원을 추가할 수 있도록 사용자에게 허용합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e예제 하나가 이렇게 보일 거예요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e tiktoken\n\nencoding = tiktoken.get_encoding(\u003cspan class=\"hljs-string\"\u003e\"cl100k_base\"\u003c/span\u003e)\n\u003cspan class=\"hljs-comment\"\u003e# 특정 모델 이름에 해당하는 올바른 인코딩을 자동으로 로드하기 위해\u003c/span\u003e\nencoding = tiktoken.encoding_for_model(\u003cspan class=\"hljs-string\"\u003e\"gpt-3.5-turbo\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(encoding.encode(\u003cspan class=\"hljs-string\"\u003e\"OpenAI is great!\"\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e출력은 이렇게 보일 거예요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e[\u003cspan class=\"hljs-number\"\u003e5109\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e15836\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e374\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e2294\u003c/span\u003e, \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e토큰을 세는 방법은 .encode()로 반환된 리스트의 길이를 세면 됩니다.\u003c/p\u003e\n\u003ch1\u003e토큰 한도\u003c/h1\u003e\n\u003cp\u003e요청에 사용할 수 있는 토큰의 최대 수는 선택한 모델에 따라 다르며, 입력 프롬프트 및 생성된 출력(gpt-3.5-turbo)에 대한 4096개의 토큰이라는 결합한 한도가 있습니다. 따라서, 입력에 4000개의 토큰을 할당하면 출력에는 최대 96개의 토큰이 남게 됩니다.\u003c/p\u003e\n\u003cp\u003e이 제약은 주로 기술적인 이유로 인해 발생합니다. 그러나, 입력을 더 간결하게 요약하거나 콘텐츠를 더 작은 세그먼트로 나누는 등 이러한 제한 내에서 효과적으로 작업하는 다양한 전략이 존재합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eGPT4의 토큰 한도\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_3.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e더 많은 정보를 알고 싶다면 openai의 공식 웹사이트를 방문해보세요: \u003ca href=\"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\" rel=\"nofollow\" target=\"_blank\"\u003e여기를 클릭하세요\u003c/a\u003e\u003c/p\u003e\n\u003ch1\u003e토큰 가격 설정\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eOpenAI API는 다양한 모델 유형을 제공하며 각 모델은 다른 가격 수준에서 사용할 수 있습니다. 이러한 모델들은 능력이 다양하며 가장 진보된 것은 다빈치이고, 가장 빠른 것은 에이다입니다. 요청을 만드는 데 드는 비용은 이러한 모델에 따라 달라집니다.\u003c/p\u003e\n\u003cp\u003e예를 들어, GPT-4 Turbo 모델의 경우, 입력 기준으로 $0.01/1K 토큰, 출력 기준으로 $0.03/1K 토큰이 듭니다.\u003c/p\u003e\n\u003cp\u003e표:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_4.png\" alt=\"OpenAI 모델 비용\"\u003e\u003c/p\u003e\n\u003cp\u003e그리고 OpenAI에 따르면:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eCobus Greyling님은 OpenAI 토큰 비용에 대한 멋진 차트를 보유하고 계시네요:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_5.png\" alt=\"OpenAI Token Cost Chart\"\u003e\u003c/p\u003e\n\u003ch1\u003e가격 계산기\u003c/h1\u003e\n\u003cp\u003e다음 \"OpenAI 및 다른 LLM API 가격 계산기\"를 활용하여 계산을 할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-23-OpenAIBestPracticesofUsingTokens_6.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e위는 1000개의 입력 단어, 500개의 출력 단어 및 100회의 API 호출에 대한 총 비용을 보여줍니다.\u003c/p\u003e\n\u003ch1\u003eBest Practices\u003c/h1\u003e\n\u003cp\u003eOpenAI 토큰을 사용할 때는 최적의 방법을 채택하여 효율성을 극대화하고 비용을 최소화하며 OpenAI의 API와의 상호 작용을 효과적이고 안전하게 보장할 수 있습니다. 다음은 추천하는 최상의 방법론입니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e토큰 이코노믹스 이해하기\u003c/h2\u003e\n\u003cp\u003e사용하는 맥락에서 어떻게 토큰이 계산되는지, 그리고 토큰을 구성하는 것이 무엇인지 이해하세요. 다양한 입력 길이에 대한 대략적인 토큰 수를 알면 사용량과 비용을 보다 정확하게 추정하는 데 도움이 됩니다.\u003c/p\u003e\n\u003ch2\u003e프롬프트 디자인 최적화\u003c/h2\u003e\n\u003cp\u003e모델이 원하는 출력 생성 방향으로 이끌 수 있도록 프롬프트를 간결하면서도 충분히 구체적으로 디자인하세요. 이 균형을 유지하면 사용된 토큰 수를 줄이고 유용한 응답을 받을 확률을 높일 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e효율적인 토큰 관리 활용하기\u003c/h2\u003e\n\u003cp\u003e예상치 못한 비용을 피하기 위해 토큰 사용량을 추적하세요. 플랫폼이나 응용 프로그램에서 지원한다면 알림이나 제한을 구현하여 소비량을 모니터링하세요.\u003c/p\u003e\n\u003ch2\u003e가능한 경우 일괄 요청 처리하기\u003c/h2\u003e\n\u003cp\u003e사용 사례가 허용한다면 일괄 처리는 한 번에 한 요청을 처리하는 것보다 더 효율적일 수 있습니다. 이 방법은 비용 절감에도 도움이 될 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e작업에 적합한 모델 활용하기\u003c/h2\u003e\n\u003cp\u003e작업에 가장 적합한 모델을 선택하세요. Davinci와 같이 큰 모델은 더 강력하지만, Ada나 Babbage와 같은 작은 모델은 깊은 이해나 창의력이 필요하지 않은 작업에 대해 더 비용 효율적일 수 있어서 토큰을 절약할 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e빈번한 요청에 대한 캐싱 구현하기\u003c/h2\u003e\n\u003cp\u003e응용 프로그램이 동일하거나 유사한 프롬프트로 반복적인 요청을 수행하는 경우, 응답을 캐싱하여 토큰을 절약할 수 있습니다. 캐시가 안전하게 관리되고 개인정보 및 데이터 보호 요구 사항을 준수하는지 확인하세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003eAPI 키 보호하기\u003c/h2\u003e\n\u003cp\u003eOpenAI API 키를 안전하게 보호하여 무단 사용을 방지하고, 토큰 낭비 및 예상치 못한 요금 부과를 방지하세요. 접근 제어를 구현하고 정기적으로 키를 변경하세요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-23-OpenAIBestPracticesofUsingTokens"},"buildId":"kkckKPyxcjJp_o8wb2unW","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>