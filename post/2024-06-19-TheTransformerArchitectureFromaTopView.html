<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>위에서 바라본 Transformer 구조 | itposting</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://itposting.github.io///post/2024-06-19-TheTransformerArchitectureFromaTopView" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="위에서 바라본 Transformer 구조 | itposting" data-gatsby-head="true"/><meta property="og:title" content="위에서 바라본 Transformer 구조 | itposting" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://itposting.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://itposting.github.io///post/2024-06-19-TheTransformerArchitectureFromaTopView" data-gatsby-head="true"/><meta name="twitter:title" content="위에서 바라본 Transformer 구조 | itposting" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | itposting" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 20:35" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-23YXDLKDCL"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
          
            gtag('config', 'G-23YXDLKDCL');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-d849684d6d83f07a.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_buildManifest.js" defer=""></script><script src="/_next/static/CYQjEY3HhSkRTiL0gewc0/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">IT Posting</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">위에서 바라본 Transformer 구조</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="위에서 바라본 Transformer 구조" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">IT Posting</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">6<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-TheTransformerArchitectureFromaTopView&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>지금까지 사용되던 최신 언어 처리(NLP) 모델은 다른 모델들 중에서 순환 신경망(RNN)이었습니다.</p>
<p>그런데 그 이후로 트랜스포머가 등장했습니다.</p>
<p>트랜스포머 아키텍처는 이전 RNN과 비교하여 자연어 처리 성능을 크게 향상시켰습니다.</p>
<p>2017년 Vaswani 등이 발표한 논문 "Attention is All You Need"에서 개발된 트랜스포머는 자가 주의 메커니즘을 활용하여 문장 내 모든 단어의 관련성과 문맥을 학습할 수 있게 되어 NLP를 혁신했습니다.</p>
<div class="content-ad"></div>
<p>RNN(Recurrent Neural Networks)이 데이터를 순차적으로 처리하는 것과는 달리, Transformer는 문장의 모든 부분을 동시에 분석합니다. 이 병렬 처리 능력 덕분에 Transformer는 문장이나 문서에서 각 단어의 맥락과 관련성을 모든 다른 단어에 대해 학습할 수 있습니다. 이는 RNN에서 발견되는 장기 의존성과 계산 효율성과 관련된 한계를 극복하는 데 도움이 됩니다.</p>
<p>하지만 이 아키텍처를 단계별로 살펴보겠습니다.</p>
<p><img src="/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png" alt="Transformer Architecture"></p>
<ul>
<li>Transformer 아키텍처에는 두 가지 구성 요소가 있습니다: 인코더(Encoder)와 디코더(Decoder).</li>
<li>이러한 구성 요소들은 함께 작동하며 여러 유사성을 공유합니다.</li>
<li>인코더: 토큰 시퀀스의 입력을 각 토큰의 맥락을 포착하는 풍부하고 연속적인 표현으로 변환합니다. 그 출력은 임베딩 벡터의 시퀀스이며, 종종 숨겨진 상태 또는 컨텍스트로 불립니다.</li>
<li>디코더: 인코더의 숨겨진 상태를 사용하여 반복적으로 한 번에 하나씩 토큰의 출력 시퀀스를 생성합니다.</li>
</ul>
<div class="content-ad"></div>
<p>Transformer 아키텍처에는 Encoder와 Decoder 두 가지가 모두 존재하지만, Encoder만 사용하는 경우, Decoder만 사용하는 경우, 또는 둘 다 사용하는 경우 등 3가지 유형의 트랜스포머가 있습니다.</p>
<h2>Encoder-only Transformers</h2>
<ul>
<li>이러한 모델은 텍스트 블록을 깊게 이해하고 해석할 수 있는 전문가 분석가로 생각할 수 있습니다.</li>
<li>이러한 모델은 텍스트 입력 시퀀스를 풍부한 숫자 표현으로 변환하여 텍스트 분류나 명명된 개체 인식(NER)과 같은 작업에 적합합니다.</li>
<li>BERT 및 RoBERTa, DistilBERT와 같은 변형들은 이러한 아키텍처 클래스에 속합니다.</li>
<li>이러한 모델은 양방향 어텐션을 사용합니다. 단어 주변의 전체 문맥에 주의를 기울이도록 설계되었습니다.</li>
</ul>
<h2>Decoder-only Transformers</h2>
<div class="content-ad"></div>
<ul>
<li>여기서 모델들을 느슨하게 번역의 역할을 수행하는 창의적인 이야기꾼으로 상상해봅시다.</li>
<li>"트랜스포머를 학습하는 것은..."과 같은 텍스트 자극이 주어지면, 이러한 모델들은 가장 가능성 있는 다음 단어를 예측하며 시퀀스를 자동으로 완성합니다 (바람직하게는 "즐겁다").</li>
<li>GPT 모델 패밀리는 이 범주에 속합니다.</li>
<li>이 구조에서 주어진 토큰에 대해 계산된 표현은 미래를 예측하기 위해(자기 회귀적 주의라고도 함) 한 부분에 의존함과 동시에 왼쪽 컨텍스트(지금까지의 이야기)에만 의존합니다.</li>
</ul>
<h2>인코더-디코더 트랜스포머</h2>
<ul>
<li>이들은 변환기 패밀리의 다재다능한 멀티태스커입니다. 하나의 형태에서 텍스트를 다른 형태로 변환하는 능력이 있습니다.</li>
<li>입력 텍스트를 먼저 소화하여, 그 본질과 뉘앙스를 잡는 것(인코더 덕분)을 하고 이를 깊이 이해하여 디코더 부분에서 새로운 텍스트 조각을 응답으로 만들어냅니다.</li>
<li>기계 번역 및 요약 작업에 적합합니다.</li>
<li>이 범주에 속하는 트랜스포머 모델로는 T5와 BART가 있습니다.</li>
</ul>
<h1>1. 토크나이저</h1>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_1.png">
<ul>
<li>모델로 텍스트를 처리하기 전에 첫 번째 단계는 토큰화입니다.</li>
<li>이 단계는 컴퓨터가 단어를 해석할 수 있도록 돕습니다. 각 고유한 토큰은 고유한 번호를 갖게 됩니다.</li>
<li>모델을 학습시키기 위해 토크나이저를 선택했다면, 텍스트를 생성할 때도 동일한 토크나이저를 사용해야 합니다.</li>
<li>이제 입력을 임베딩 레이어에 전달할 수 있습니다.</li>
</ul>
<h1>2. 임베딩 레이어</h1>
<img src="/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_2.png">
<div class="content-ad"></div>
<p>위의 이미지를 참고하면 내부에는 하나의 임베딩 레이어를 엿볼 수 있지만 두 레이어가 동일합니다.</p>
<ul>
<li>임베딩 레이어는 토큰화된 숫자 표현을 밀도 있는 벡터 임베딩으로 변환합니다.</li>
<li>학습 가능한 벡터 임베딩 공간은 각 토큰이 벡터로 표현되고 해당 공간 내에서 고유한 위치를 차지하는 고차원 공간입니다.</li>
<li>어휘 사전의 각 토큰은 다차원 벡터에 매칭되며(예: 크기가 512인), 이러한 벡터는 입력 시퀀스의 개별 토큰의 의미와 맥락을 인코딩하는 것을 학습하는 것입니다.</li>
</ul>
<h2>포지셔널 임베딩</h2>
<ul>
<li>원시 임베딩과 결합하여 위치 정보를 추가합니다.</li>
<li>모델은 각 입력 토큰을 병렬로 처리합니다.</li>
<li>포지셔널 임베딩을 통해 모델은 단어 순서에 대한 정보를 얻으며, 텍스트를 이해하려고 할 때 매우 중요합니다.</li>
</ul>
<div class="content-ad"></div>
<h1>3. 인코더</h1>
<p><img src="/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_3.png" alt="이미지"></p>
<ul>
<li>먼저, 트랜스포머에는 단일 인코더가 아니라 서로 옆에 많은 인코더 스택이 있는 것이 중요합니다. 모든 인코더는 동일합니다. 예를 들어, BERT는 24개의 인코더 스택을 가지고 있습니다.</li>
<li>임베드 레이어에서의 임베딩 시퀀스는 인코더의 입력이며, 먼저 멀티 헤드 셀프 어텐션 레이어에 공급되고 그 다음에 완전히 연결된 피드포워드 레이어에 공급됩니다.</li>
<li>출력은 토크나이저 사전의 각 가능한 토큰에 대한 확률 점수에 비례하는 로짓의 벡터입니다.</li>
</ul>
<h2>멀티 헤드 셀프 어텐션</h2>
<div class="content-ad"></div>
<ul>
<li>인코더 내부의 이 레이어는 특정 작업을 수행합니다: 문장 속 각 단어를 그 자체로 이해하는 것뿐만 아니라 다른 모든 단어와도 함께 이해하는 것입니다.</li>
</ul>
<p>그럼, 왜 "다중 헤드"일까요?</p>
<ul>
<li>단순히 이 관계를 한 가지 방법으로만 보지 않기 때문입니다. 대신, 다중 "헤드"를 갖고 있어서 각각이 문장을 다른 관점에서 바라볼 수 있습니다.</li>
<li>한 헤드는 문법 구조에 집중할 수 있고, 다른 헤드는 특정 용어의 의미에 초점을 맞출 수 있으며, 또 다른 헤드는 문장의 어조에 집중할 수 있습니다.</li>
<li>이러한 다양한 측면을 동시에 검토함으로써, 모델은 텍스트를 더 깊이 이해할 수 있습니다.</li>
</ul>
<h2>전방향</h2>
<div class="content-ad"></div>
<ul>
<li>이는 두 층으로 구성된 완전 연결 (밀집) 신경망 구조입니다.</li>
<li>임베딩 시퀀스 전체를 하나의 벡터로 처리하지 않습니다.</li>
<li>각 임베딩은 개별적으로 처리됩니다.</li>
<li>변환된 임베딩이 출력됩니다.</li>
<li>그런 다음, Transformer의 최종 출력 계층을 통해 (이 전방향 계층 자체 내부가 아닌) 로짓이 생성되며, 이는 전체 모델 구조의 문맥 내 토큰 확률에 비례합니다.</li>
<li>다른 신경망과 마찬가지로 활성화 함수를 사용해야 합니다. 이 경우 GELU가 사용됩니다.</li>
<li>GELU는 자연어 처리에서 만나는 데이터 분포 유형에 특히 효과적인 방식으로 선형 및 비선형 변환 사이의 균형을 유지하면서 비선형성을 도입할 수 있습니다.</li>
</ul>
<h1>4. 디코더</h1>
<p><img src="/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_4.png" alt="그림"></p>
<p>인코더와 유사하게 디코더도 많은 디코더들의 스택으로 구성되어 있으며(인코더-디코더 모델의 인코더 수와 동일), 서로 동일합니다. 예를 들어 (디코더 전용인) GPT-2 Extra Large 모델은 48개의 디코더 레이어 스택을 가지고 있습니다.</p>
<div class="content-ad"></div>
<p>👋 디코더와 인코더의 주요 차이점은 디코더에는 두 가지 어텐션 서브레이어가 있다는 것입니다:</p>
<h3>마스킹된 멀티헤드 셀프 어텐션</h3>
<ul>
<li>각 시간 단계에서 생성되는 토큰이 과거 출력 및 현재 예측 중인 토큰에만 기초함을 보장합니다. 이것이 "마스킹" 뒤의 개념입니다.</li>
<li>이것이 없으면 디코더가 훈련 중에 간단히 대상 번역을 복사함으로써 속일 수 있습니다.</li>
<li>멀티헤드는 인코더와 동일합니다. 각 헤드는 데이터의 다른 측면을 배우며 시퀀스의 다른 부분에 초점을 맞추고 토큰 사이의 다양한 관계를 고려합니다.</li>
</ul>
<h3>인코더-디코더 어텐션</h3>
<div class="content-ad"></div>
<ul>
<li>이 레이어는 각 출력 시퀀스 토큰을 생성하는 동안 입력 시퀀스의 서로 다른 부분(두 가지 다른 언어 같은)에 초점을 맞출 수 있도록 디코더에 가능하게 합니다.</li>
<li>디코더는 출력 시퀀스에서 다음 토큰을 생성하면서 현재 문맥과 지금까지 생성한 내용을 고려합니다.</li>
<li>이를 통해 디코더는 다음 출력 토큰의 생성에 영향을 미쳐야 할 가장 관련성 높은 입력 시퀀스 부분을 파악할 수 있습니다.</li>
</ul>
<p>디코더의 출력은 토큰화 사전에 있는 각 토큰의 확률 점수(모두 1에 모두 더해짐)이며 더 높은 확률을 가진 토큰이 반환됩니다.</p>
<h1>연락을 유지하자</h1>
<p>➥이와 같은 콘텐츠 더 보려면 Medium에서 팔로우하세요.
➥LinkedIn이나 𝕏에서 연결합시다.
➥제 GitHub을 확인하세요.</p>
<div class="content-ad"></div>
<h1>다음에 무엇을 읽을지 고민이세요? 여기 두 가지 추천이 있어요:</h1>
<h2>이 주제에 대해 더 깊게 알아갈 수 있는 멋진 참고 자료와 자원:</h2>
<ul>
<li>Tunstall, Lewis, Leandro Von Werra, 그리고 Thomas Wolf. Natural language processing with transformers. “ O’Reilly Media, Inc.”, 2022.</li>
<li><a href="https://jalammar.github.io/illustrated-transformer/" rel="nofollow" target="_blank">Illustrated Transformer</a></li>
<li><a href="https://youtu.be/-QH8fRhqFHM?si=GWPYodFv60vQFNEb" rel="nofollow" target="_blank">YouTube - Illustrated Transformer</a></li>
</ul>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"위에서 바라본 Transformer 구조","description":"","date":"2024-06-19 20:35","slug":"2024-06-19-TheTransformerArchitectureFromaTopView","content":"\n\n지금까지 사용되던 최신 언어 처리(NLP) 모델은 다른 모델들 중에서 순환 신경망(RNN)이었습니다.\n\n그런데 그 이후로 트랜스포머가 등장했습니다.\n\n트랜스포머 아키텍처는 이전 RNN과 비교하여 자연어 처리 성능을 크게 향상시켰습니다.\n\n2017년 Vaswani 등이 발표한 논문 \"Attention is All You Need\"에서 개발된 트랜스포머는 자가 주의 메커니즘을 활용하여 문장 내 모든 단어의 관련성과 문맥을 학습할 수 있게 되어 NLP를 혁신했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRNN(Recurrent Neural Networks)이 데이터를 순차적으로 처리하는 것과는 달리, Transformer는 문장의 모든 부분을 동시에 분석합니다. 이 병렬 처리 능력 덕분에 Transformer는 문장이나 문서에서 각 단어의 맥락과 관련성을 모든 다른 단어에 대해 학습할 수 있습니다. 이는 RNN에서 발견되는 장기 의존성과 계산 효율성과 관련된 한계를 극복하는 데 도움이 됩니다.\n\n하지만 이 아키텍처를 단계별로 살펴보겠습니다.\n\n![Transformer Architecture](/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png)\n\n- Transformer 아키텍처에는 두 가지 구성 요소가 있습니다: 인코더(Encoder)와 디코더(Decoder).\n- 이러한 구성 요소들은 함께 작동하며 여러 유사성을 공유합니다.\n- 인코더: 토큰 시퀀스의 입력을 각 토큰의 맥락을 포착하는 풍부하고 연속적인 표현으로 변환합니다. 그 출력은 임베딩 벡터의 시퀀스이며, 종종 숨겨진 상태 또는 컨텍스트로 불립니다.\n- 디코더: 인코더의 숨겨진 상태를 사용하여 반복적으로 한 번에 하나씩 토큰의 출력 시퀀스를 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nTransformer 아키텍처에는 Encoder와 Decoder 두 가지가 모두 존재하지만, Encoder만 사용하는 경우, Decoder만 사용하는 경우, 또는 둘 다 사용하는 경우 등 3가지 유형의 트랜스포머가 있습니다.\n\n## Encoder-only Transformers\n\n- 이러한 모델은 텍스트 블록을 깊게 이해하고 해석할 수 있는 전문가 분석가로 생각할 수 있습니다.\n- 이러한 모델은 텍스트 입력 시퀀스를 풍부한 숫자 표현으로 변환하여 텍스트 분류나 명명된 개체 인식(NER)과 같은 작업에 적합합니다.\n- BERT 및 RoBERTa, DistilBERT와 같은 변형들은 이러한 아키텍처 클래스에 속합니다.\n- 이러한 모델은 양방향 어텐션을 사용합니다. 단어 주변의 전체 문맥에 주의를 기울이도록 설계되었습니다.\n\n## Decoder-only Transformers\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 여기서 모델들을 느슨하게 번역의 역할을 수행하는 창의적인 이야기꾼으로 상상해봅시다.\n- \"트랜스포머를 학습하는 것은...\"과 같은 텍스트 자극이 주어지면, 이러한 모델들은 가장 가능성 있는 다음 단어를 예측하며 시퀀스를 자동으로 완성합니다 (바람직하게는 \"즐겁다\").\n- GPT 모델 패밀리는 이 범주에 속합니다.\n- 이 구조에서 주어진 토큰에 대해 계산된 표현은 미래를 예측하기 위해(자기 회귀적 주의라고도 함) 한 부분에 의존함과 동시에 왼쪽 컨텍스트(지금까지의 이야기)에만 의존합니다.\n\n## 인코더-디코더 트랜스포머\n\n- 이들은 변환기 패밀리의 다재다능한 멀티태스커입니다. 하나의 형태에서 텍스트를 다른 형태로 변환하는 능력이 있습니다.\n- 입력 텍스트를 먼저 소화하여, 그 본질과 뉘앙스를 잡는 것(인코더 덕분)을 하고 이를 깊이 이해하여 디코더 부분에서 새로운 텍스트 조각을 응답으로 만들어냅니다.\n- 기계 번역 및 요약 작업에 적합합니다.\n- 이 범주에 속하는 트랜스포머 모델로는 T5와 BART가 있습니다.\n\n# 1. 토크나이저\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_1.png\" /\u003e\n\n- 모델로 텍스트를 처리하기 전에 첫 번째 단계는 토큰화입니다.\n- 이 단계는 컴퓨터가 단어를 해석할 수 있도록 돕습니다. 각 고유한 토큰은 고유한 번호를 갖게 됩니다.\n- 모델을 학습시키기 위해 토크나이저를 선택했다면, 텍스트를 생성할 때도 동일한 토크나이저를 사용해야 합니다.\n- 이제 입력을 임베딩 레이어에 전달할 수 있습니다.\n\n# 2. 임베딩 레이어\n\n\u003cimg src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_2.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 이미지를 참고하면 내부에는 하나의 임베딩 레이어를 엿볼 수 있지만 두 레이어가 동일합니다.\n\n- 임베딩 레이어는 토큰화된 숫자 표현을 밀도 있는 벡터 임베딩으로 변환합니다.\n- 학습 가능한 벡터 임베딩 공간은 각 토큰이 벡터로 표현되고 해당 공간 내에서 고유한 위치를 차지하는 고차원 공간입니다.\n- 어휘 사전의 각 토큰은 다차원 벡터에 매칭되며(예: 크기가 512인), 이러한 벡터는 입력 시퀀스의 개별 토큰의 의미와 맥락을 인코딩하는 것을 학습하는 것입니다.\n\n## 포지셔널 임베딩\n\n- 원시 임베딩과 결합하여 위치 정보를 추가합니다.\n- 모델은 각 입력 토큰을 병렬로 처리합니다.\n- 포지셔널 임베딩을 통해 모델은 단어 순서에 대한 정보를 얻으며, 텍스트를 이해하려고 할 때 매우 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3. 인코더\n\n![이미지](/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_3.png)\n\n- 먼저, 트랜스포머에는 단일 인코더가 아니라 서로 옆에 많은 인코더 스택이 있는 것이 중요합니다. 모든 인코더는 동일합니다. 예를 들어, BERT는 24개의 인코더 스택을 가지고 있습니다.\n- 임베드 레이어에서의 임베딩 시퀀스는 인코더의 입력이며, 먼저 멀티 헤드 셀프 어텐션 레이어에 공급되고 그 다음에 완전히 연결된 피드포워드 레이어에 공급됩니다.\n- 출력은 토크나이저 사전의 각 가능한 토큰에 대한 확률 점수에 비례하는 로짓의 벡터입니다.\n\n## 멀티 헤드 셀프 어텐션\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 인코더 내부의 이 레이어는 특정 작업을 수행합니다: 문장 속 각 단어를 그 자체로 이해하는 것뿐만 아니라 다른 모든 단어와도 함께 이해하는 것입니다.\n\n그럼, 왜 \"다중 헤드\"일까요?\n\n- 단순히 이 관계를 한 가지 방법으로만 보지 않기 때문입니다. 대신, 다중 \"헤드\"를 갖고 있어서 각각이 문장을 다른 관점에서 바라볼 수 있습니다.\n- 한 헤드는 문법 구조에 집중할 수 있고, 다른 헤드는 특정 용어의 의미에 초점을 맞출 수 있으며, 또 다른 헤드는 문장의 어조에 집중할 수 있습니다.\n- 이러한 다양한 측면을 동시에 검토함으로써, 모델은 텍스트를 더 깊이 이해할 수 있습니다.\n\n## 전방향\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이는 두 층으로 구성된 완전 연결 (밀집) 신경망 구조입니다.\n- 임베딩 시퀀스 전체를 하나의 벡터로 처리하지 않습니다.\n- 각 임베딩은 개별적으로 처리됩니다.\n- 변환된 임베딩이 출력됩니다.\n- 그런 다음, Transformer의 최종 출력 계층을 통해 (이 전방향 계층 자체 내부가 아닌) 로짓이 생성되며, 이는 전체 모델 구조의 문맥 내 토큰 확률에 비례합니다.\n- 다른 신경망과 마찬가지로 활성화 함수를 사용해야 합니다. 이 경우 GELU가 사용됩니다.\n- GELU는 자연어 처리에서 만나는 데이터 분포 유형에 특히 효과적인 방식으로 선형 및 비선형 변환 사이의 균형을 유지하면서 비선형성을 도입할 수 있습니다.\n\n# 4. 디코더\n\n![그림](/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_4.png)\n\n인코더와 유사하게 디코더도 많은 디코더들의 스택으로 구성되어 있으며(인코더-디코더 모델의 인코더 수와 동일), 서로 동일합니다. 예를 들어 (디코더 전용인) GPT-2 Extra Large 모델은 48개의 디코더 레이어 스택을 가지고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n👋 디코더와 인코더의 주요 차이점은 디코더에는 두 가지 어텐션 서브레이어가 있다는 것입니다:\n\n### 마스킹된 멀티헤드 셀프 어텐션\n\n- 각 시간 단계에서 생성되는 토큰이 과거 출력 및 현재 예측 중인 토큰에만 기초함을 보장합니다. 이것이 \"마스킹\" 뒤의 개념입니다.\n- 이것이 없으면 디코더가 훈련 중에 간단히 대상 번역을 복사함으로써 속일 수 있습니다.\n- 멀티헤드는 인코더와 동일합니다. 각 헤드는 데이터의 다른 측면을 배우며 시퀀스의 다른 부분에 초점을 맞추고 토큰 사이의 다양한 관계를 고려합니다.\n\n### 인코더-디코더 어텐션\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이 레이어는 각 출력 시퀀스 토큰을 생성하는 동안 입력 시퀀스의 서로 다른 부분(두 가지 다른 언어 같은)에 초점을 맞출 수 있도록 디코더에 가능하게 합니다.\n- 디코더는 출력 시퀀스에서 다음 토큰을 생성하면서 현재 문맥과 지금까지 생성한 내용을 고려합니다.\n- 이를 통해 디코더는 다음 출력 토큰의 생성에 영향을 미쳐야 할 가장 관련성 높은 입력 시퀀스 부분을 파악할 수 있습니다.\n\n디코더의 출력은 토큰화 사전에 있는 각 토큰의 확률 점수(모두 1에 모두 더해짐)이며 더 높은 확률을 가진 토큰이 반환됩니다.\n\n# 연락을 유지하자\n\n➥이와 같은 콘텐츠 더 보려면 Medium에서 팔로우하세요.\n➥LinkedIn이나 𝕏에서 연결합시다.\n➥제 GitHub을 확인하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 다음에 무엇을 읽을지 고민이세요? 여기 두 가지 추천이 있어요:\n\n## 이 주제에 대해 더 깊게 알아갈 수 있는 멋진 참고 자료와 자원:\n\n- Tunstall, Lewis, Leandro Von Werra, 그리고 Thomas Wolf. Natural language processing with transformers. “ O’Reilly Media, Inc.”, 2022.\n- [Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)\n- [YouTube - Illustrated Transformer](https://youtu.be/-QH8fRhqFHM?si=GWPYodFv60vQFNEb)","ogImage":{"url":"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png"},"coverImage":"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png","tag":["Tech"],"readingTime":6},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e지금까지 사용되던 최신 언어 처리(NLP) 모델은 다른 모델들 중에서 순환 신경망(RNN)이었습니다.\u003c/p\u003e\n\u003cp\u003e그런데 그 이후로 트랜스포머가 등장했습니다.\u003c/p\u003e\n\u003cp\u003e트랜스포머 아키텍처는 이전 RNN과 비교하여 자연어 처리 성능을 크게 향상시켰습니다.\u003c/p\u003e\n\u003cp\u003e2017년 Vaswani 등이 발표한 논문 \"Attention is All You Need\"에서 개발된 트랜스포머는 자가 주의 메커니즘을 활용하여 문장 내 모든 단어의 관련성과 문맥을 학습할 수 있게 되어 NLP를 혁신했습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eRNN(Recurrent Neural Networks)이 데이터를 순차적으로 처리하는 것과는 달리, Transformer는 문장의 모든 부분을 동시에 분석합니다. 이 병렬 처리 능력 덕분에 Transformer는 문장이나 문서에서 각 단어의 맥락과 관련성을 모든 다른 단어에 대해 학습할 수 있습니다. 이는 RNN에서 발견되는 장기 의존성과 계산 효율성과 관련된 한계를 극복하는 데 도움이 됩니다.\u003c/p\u003e\n\u003cp\u003e하지만 이 아키텍처를 단계별로 살펴보겠습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_0.png\" alt=\"Transformer Architecture\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTransformer 아키텍처에는 두 가지 구성 요소가 있습니다: 인코더(Encoder)와 디코더(Decoder).\u003c/li\u003e\n\u003cli\u003e이러한 구성 요소들은 함께 작동하며 여러 유사성을 공유합니다.\u003c/li\u003e\n\u003cli\u003e인코더: 토큰 시퀀스의 입력을 각 토큰의 맥락을 포착하는 풍부하고 연속적인 표현으로 변환합니다. 그 출력은 임베딩 벡터의 시퀀스이며, 종종 숨겨진 상태 또는 컨텍스트로 불립니다.\u003c/li\u003e\n\u003cli\u003e디코더: 인코더의 숨겨진 상태를 사용하여 반복적으로 한 번에 하나씩 토큰의 출력 시퀀스를 생성합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eTransformer 아키텍처에는 Encoder와 Decoder 두 가지가 모두 존재하지만, Encoder만 사용하는 경우, Decoder만 사용하는 경우, 또는 둘 다 사용하는 경우 등 3가지 유형의 트랜스포머가 있습니다.\u003c/p\u003e\n\u003ch2\u003eEncoder-only Transformers\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e이러한 모델은 텍스트 블록을 깊게 이해하고 해석할 수 있는 전문가 분석가로 생각할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e이러한 모델은 텍스트 입력 시퀀스를 풍부한 숫자 표현으로 변환하여 텍스트 분류나 명명된 개체 인식(NER)과 같은 작업에 적합합니다.\u003c/li\u003e\n\u003cli\u003eBERT 및 RoBERTa, DistilBERT와 같은 변형들은 이러한 아키텍처 클래스에 속합니다.\u003c/li\u003e\n\u003cli\u003e이러한 모델은 양방향 어텐션을 사용합니다. 단어 주변의 전체 문맥에 주의를 기울이도록 설계되었습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eDecoder-only Transformers\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e여기서 모델들을 느슨하게 번역의 역할을 수행하는 창의적인 이야기꾼으로 상상해봅시다.\u003c/li\u003e\n\u003cli\u003e\"트랜스포머를 학습하는 것은...\"과 같은 텍스트 자극이 주어지면, 이러한 모델들은 가장 가능성 있는 다음 단어를 예측하며 시퀀스를 자동으로 완성합니다 (바람직하게는 \"즐겁다\").\u003c/li\u003e\n\u003cli\u003eGPT 모델 패밀리는 이 범주에 속합니다.\u003c/li\u003e\n\u003cli\u003e이 구조에서 주어진 토큰에 대해 계산된 표현은 미래를 예측하기 위해(자기 회귀적 주의라고도 함) 한 부분에 의존함과 동시에 왼쪽 컨텍스트(지금까지의 이야기)에만 의존합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e인코더-디코더 트랜스포머\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e이들은 변환기 패밀리의 다재다능한 멀티태스커입니다. 하나의 형태에서 텍스트를 다른 형태로 변환하는 능력이 있습니다.\u003c/li\u003e\n\u003cli\u003e입력 텍스트를 먼저 소화하여, 그 본질과 뉘앙스를 잡는 것(인코더 덕분)을 하고 이를 깊이 이해하여 디코더 부분에서 새로운 텍스트 조각을 응답으로 만들어냅니다.\u003c/li\u003e\n\u003cli\u003e기계 번역 및 요약 작업에 적합합니다.\u003c/li\u003e\n\u003cli\u003e이 범주에 속하는 트랜스포머 모델로는 T5와 BART가 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e1. 토크나이저\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_1.png\"\u003e\n\u003cul\u003e\n\u003cli\u003e모델로 텍스트를 처리하기 전에 첫 번째 단계는 토큰화입니다.\u003c/li\u003e\n\u003cli\u003e이 단계는 컴퓨터가 단어를 해석할 수 있도록 돕습니다. 각 고유한 토큰은 고유한 번호를 갖게 됩니다.\u003c/li\u003e\n\u003cli\u003e모델을 학습시키기 위해 토크나이저를 선택했다면, 텍스트를 생성할 때도 동일한 토크나이저를 사용해야 합니다.\u003c/li\u003e\n\u003cli\u003e이제 입력을 임베딩 레이어에 전달할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e2. 임베딩 레이어\u003c/h1\u003e\n\u003cimg src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_2.png\"\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e위의 이미지를 참고하면 내부에는 하나의 임베딩 레이어를 엿볼 수 있지만 두 레이어가 동일합니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e임베딩 레이어는 토큰화된 숫자 표현을 밀도 있는 벡터 임베딩으로 변환합니다.\u003c/li\u003e\n\u003cli\u003e학습 가능한 벡터 임베딩 공간은 각 토큰이 벡터로 표현되고 해당 공간 내에서 고유한 위치를 차지하는 고차원 공간입니다.\u003c/li\u003e\n\u003cli\u003e어휘 사전의 각 토큰은 다차원 벡터에 매칭되며(예: 크기가 512인), 이러한 벡터는 입력 시퀀스의 개별 토큰의 의미와 맥락을 인코딩하는 것을 학습하는 것입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e포지셔널 임베딩\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e원시 임베딩과 결합하여 위치 정보를 추가합니다.\u003c/li\u003e\n\u003cli\u003e모델은 각 입력 토큰을 병렬로 처리합니다.\u003c/li\u003e\n\u003cli\u003e포지셔널 임베딩을 통해 모델은 단어 순서에 대한 정보를 얻으며, 텍스트를 이해하려고 할 때 매우 중요합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e3. 인코더\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e먼저, 트랜스포머에는 단일 인코더가 아니라 서로 옆에 많은 인코더 스택이 있는 것이 중요합니다. 모든 인코더는 동일합니다. 예를 들어, BERT는 24개의 인코더 스택을 가지고 있습니다.\u003c/li\u003e\n\u003cli\u003e임베드 레이어에서의 임베딩 시퀀스는 인코더의 입력이며, 먼저 멀티 헤드 셀프 어텐션 레이어에 공급되고 그 다음에 완전히 연결된 피드포워드 레이어에 공급됩니다.\u003c/li\u003e\n\u003cli\u003e출력은 토크나이저 사전의 각 가능한 토큰에 대한 확률 점수에 비례하는 로짓의 벡터입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e멀티 헤드 셀프 어텐션\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e인코더 내부의 이 레이어는 특정 작업을 수행합니다: 문장 속 각 단어를 그 자체로 이해하는 것뿐만 아니라 다른 모든 단어와도 함께 이해하는 것입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e그럼, 왜 \"다중 헤드\"일까요?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e단순히 이 관계를 한 가지 방법으로만 보지 않기 때문입니다. 대신, 다중 \"헤드\"를 갖고 있어서 각각이 문장을 다른 관점에서 바라볼 수 있습니다.\u003c/li\u003e\n\u003cli\u003e한 헤드는 문법 구조에 집중할 수 있고, 다른 헤드는 특정 용어의 의미에 초점을 맞출 수 있으며, 또 다른 헤드는 문장의 어조에 집중할 수 있습니다.\u003c/li\u003e\n\u003cli\u003e이러한 다양한 측면을 동시에 검토함으로써, 모델은 텍스트를 더 깊이 이해할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e전방향\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e이는 두 층으로 구성된 완전 연결 (밀집) 신경망 구조입니다.\u003c/li\u003e\n\u003cli\u003e임베딩 시퀀스 전체를 하나의 벡터로 처리하지 않습니다.\u003c/li\u003e\n\u003cli\u003e각 임베딩은 개별적으로 처리됩니다.\u003c/li\u003e\n\u003cli\u003e변환된 임베딩이 출력됩니다.\u003c/li\u003e\n\u003cli\u003e그런 다음, Transformer의 최종 출력 계층을 통해 (이 전방향 계층 자체 내부가 아닌) 로짓이 생성되며, 이는 전체 모델 구조의 문맥 내 토큰 확률에 비례합니다.\u003c/li\u003e\n\u003cli\u003e다른 신경망과 마찬가지로 활성화 함수를 사용해야 합니다. 이 경우 GELU가 사용됩니다.\u003c/li\u003e\n\u003cli\u003eGELU는 자연어 처리에서 만나는 데이터 분포 유형에 특히 효과적인 방식으로 선형 및 비선형 변환 사이의 균형을 유지하면서 비선형성을 도입할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e4. 디코더\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-TheTransformerArchitectureFromaTopView_4.png\" alt=\"그림\"\u003e\u003c/p\u003e\n\u003cp\u003e인코더와 유사하게 디코더도 많은 디코더들의 스택으로 구성되어 있으며(인코더-디코더 모델의 인코더 수와 동일), 서로 동일합니다. 예를 들어 (디코더 전용인) GPT-2 Extra Large 모델은 48개의 디코더 레이어 스택을 가지고 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e👋 디코더와 인코더의 주요 차이점은 디코더에는 두 가지 어텐션 서브레이어가 있다는 것입니다:\u003c/p\u003e\n\u003ch3\u003e마스킹된 멀티헤드 셀프 어텐션\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e각 시간 단계에서 생성되는 토큰이 과거 출력 및 현재 예측 중인 토큰에만 기초함을 보장합니다. 이것이 \"마스킹\" 뒤의 개념입니다.\u003c/li\u003e\n\u003cli\u003e이것이 없으면 디코더가 훈련 중에 간단히 대상 번역을 복사함으로써 속일 수 있습니다.\u003c/li\u003e\n\u003cli\u003e멀티헤드는 인코더와 동일합니다. 각 헤드는 데이터의 다른 측면을 배우며 시퀀스의 다른 부분에 초점을 맞추고 토큰 사이의 다양한 관계를 고려합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e인코더-디코더 어텐션\u003c/h3\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e이 레이어는 각 출력 시퀀스 토큰을 생성하는 동안 입력 시퀀스의 서로 다른 부분(두 가지 다른 언어 같은)에 초점을 맞출 수 있도록 디코더에 가능하게 합니다.\u003c/li\u003e\n\u003cli\u003e디코더는 출력 시퀀스에서 다음 토큰을 생성하면서 현재 문맥과 지금까지 생성한 내용을 고려합니다.\u003c/li\u003e\n\u003cli\u003e이를 통해 디코더는 다음 출력 토큰의 생성에 영향을 미쳐야 할 가장 관련성 높은 입력 시퀀스 부분을 파악할 수 있습니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e디코더의 출력은 토큰화 사전에 있는 각 토큰의 확률 점수(모두 1에 모두 더해짐)이며 더 높은 확률을 가진 토큰이 반환됩니다.\u003c/p\u003e\n\u003ch1\u003e연락을 유지하자\u003c/h1\u003e\n\u003cp\u003e➥이와 같은 콘텐츠 더 보려면 Medium에서 팔로우하세요.\n➥LinkedIn이나 𝕏에서 연결합시다.\n➥제 GitHub을 확인하세요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e다음에 무엇을 읽을지 고민이세요? 여기 두 가지 추천이 있어요:\u003c/h1\u003e\n\u003ch2\u003e이 주제에 대해 더 깊게 알아갈 수 있는 멋진 참고 자료와 자원:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTunstall, Lewis, Leandro Von Werra, 그리고 Thomas Wolf. Natural language processing with transformers. “ O’Reilly Media, Inc.”, 2022.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://jalammar.github.io/illustrated-transformer/\" rel=\"nofollow\" target=\"_blank\"\u003eIllustrated Transformer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://youtu.be/-QH8fRhqFHM?si=GWPYodFv60vQFNEb\" rel=\"nofollow\" target=\"_blank\"\u003eYouTube - Illustrated Transformer\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-TheTransformerArchitectureFromaTopView"},"buildId":"CYQjEY3HhSkRTiL0gewc0","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>