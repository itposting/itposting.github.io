---
title: "대형 언어 모델LLM의 미스테리 코딩은 잘하지만 숫자 세기는 어려운 이유"
description: ""
coverImage: "/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_0.png"
date: 2024-06-22 20:54
ogImage: 
  url: /assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_0.png
tag: Tech
originalTitle: "The Curious Case of LLMs: LLMs Can Code but Not Count"
link: "https://medium.com/@gcentulani/the-curious-case-of-llms-llms-can-code-but-not-count-14513d9532e1"
---


<img src="/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_0.png" />

언어 학습 모델(LLMs)은 인공 지능 분야에서 강력한 도구로 등장했습니다. 인간과 유사한 텍스트를 이해하고 생성할 수 있는 놀라운 능력을 갖추고 있습니다. 이러한 모델은 질문에 대한 답변, 텍스트 생성, 복잡한 쓰기 및 분석 작업을 지원하는 등 다양한 작업에서 놀라운 능력을 발휘했습니다. 많은 측면에서, LLMs은 지능적인 언어 동반자로 작용하여 다양한 도메인에서 사용자에게 가치 있는 지원을 제공합니다.

그러나 그들이 놀라운 성과를 보이는 가운데, LLMs은 특정 문제를 해결하기 위해 코드를 생성할 수 있지만, 가끔은 자체적으로 보이기에 간단한 작업을 수행하는 데 어려움을 겪기도 합니다.

이 역설은 LLMs의 본질과 그들의 근본적인 추론 과정에 대해 흥미로운 질문을 던집니다.

<div class="content-ad"></div>

본 문서에서는 이 모순을 강조하는 매력적인 사례 연구를 제시할 것입니다. 특정 작업을 위한 코드를 생성하도록 LLM에 요청한 실험을 살펴보겠습니다 - 주어진 텍스트에서 특정 문자의 발생 횟수를 세는 것입니다. LLM은 코드 솔루션을 성공적으로 작성할 수 있지만, 동일한 작업을 직접 실행하려고 할 때 어려움에 직면합니다.

본 탐구를 통해 LLM의 복잡성과 언어 추론에 대해 알아보고자 합니다. 코딩 능력과 자가 실행 사이의 차이에 기여하는 요소들을 조사하고, LLM의 개발 및 응용에 대한 함의를 논의할 것입니다.

# 실험

LLM의 흥미로운 모순을 탐구하기 위해, 특정 작업을 처리하는 능력과 한계를 드러내는 실험을 설계했습니다.

<div class="content-ad"></div>

실험은 LLM에 텍스트 기반 도전 과제를 제공하고 생성된 코드를 생성하고 과제를 직접 실행하는 성능을 관찰하는 것을 중심으로 진행됩니다.

![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_1.png)

LLM에게 과제 제시하기

LLM에게 제시된 과제는 세 가지 주요 구성요소로 구성되어 있습니다:

<div class="content-ad"></div>

- 텍스트의 총 문자 수 세는 것: 첫 번째 목표는 주어진 텍스트 샘플 내의 총 문자 수를 결정하는 것입니다. 이는 모든 알파벳 및 숫자, 공백, 그리고 구두점을 포함합니다. LLM은 텍스트의 전체 문자 길이를 정확하게 세는 것으로 예상됩니다.

- 문자 "a"의 발생 횟수 세기: 두 번째 목표는 텍스트 분석의 더 구체적인 측면에 집중합니다. LLM은 주어진 텍스트 내에서 소문자 "a"의 발생을 식별하고 세는 것으로 요청됩니다. 이는 모델이 대문자와 소문자 문자를 구별하고 "a"가 나타나는 횟수를 정확하게 계산해야 합니다.

- "a" 발생을 강조하고 센 원본 텍스트 생성: 세 번째 목표는 이전 두 작업을 결합하고 시각화 구성 요소를 추가합니다. LLM은 "a"의 각 발생을 강조하고 해당 수를 제공하면서 원본 텍스트를 생성하도록 지시됩니다. 예를 들어, 텍스트에서 "a"가 세 번 나타나면 출력은 텍스트 내 "a(1)", "a(2)", "a(3)"와 같이 표시해야 합니다.

LLM에 이 세 가지 목표를 제시함으로써, LLM이 문자 및 문자 수준에서 텍스트를 분석하고 조작하는 능력을 평가하고자 합니다. 이 실험은 LLM이 작업 요구 사항을 이해하고 적절한 코드 솔루션을 생성하며 직접 작업을 수행하는 능력을 강조합니다.

다음 섹션에서는 이 실험에 대한 LLM의 응답을 탐색하며, 코드 생성 기능 및 지정된 작업의 자가 수행 능력을 평가할 것입니다. 이 분석을 통해 LLM의 기저 메커니즘에 대한 통찰을 얻고, 코딩 능력과 직접 작업 실행에 대한 제약 사항에 대한 파라독스에 빛을 발향하고자 합니다.

LLM에 코드 솔루션을 제공하도록 요청하기

<div class="content-ad"></div>

LLM의 코딩 능력을 평가하기 위해 주어진 작업에 대한 코드 솔루션을 생성하는 프롬프트를 준비했습니다. LLM은 실험에서 설명된대로 문자 계산, "a" 문자 계산 및 텍스트 강조 테스크를 정확하게 수행하는 기능적인 코드 스니펫을 생성하기를 기대했습니다.

![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_2.png)

LLM으로부터 코드 솔루션을 받은 후, 구조, 논리 및 구문을 주의 깊게 검토했습니다. 생성된 코드가 작업의 세 가지 구성 요소를 정확하게 다루며 필요한 프로그래밍 규칙을 따르는지를 평가했습니다.

결과물의 형식이 요청한 대로 되지 않아 몇 번의 수정을 거쳤지만 솔직히 말해서 제공한 지시사항이 많지 않았습니다. 이것이 최종 결과물이었습니다:

<div class="content-ad"></div>


![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_3.png)

나는 이 테스트에 사용한 Claude 3 Opus (LLM)가 문제를 이해하고 일관되고 효과적인 코드를 생성할 수 있는 능력을 강조한 작업의 설명과 이유를 제공했습니다.

![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_4.png)

제시된 2가지 예제를 보면 결과가 실제로 옳았음을 알 수 있습니다.


<div class="content-ad"></div>


![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_5.png)

LLM의 문자 계산 능력을 테스트 중입니다.

LLM으로부터 코드 솔루션을 얻은 후, 동일한 문제를 프롬프트로 테스트하기로 했습니다. 코드 생성 단계에서 사용된 동일한 텍스트 샘플을 LLM에 제공하고, 생성된 코드에 의존하지 않고 문자 수 세기, "a" 문자 수 세기 및 텍스트 강조 테스크를 직접 수행하도록 요청했습니다.

![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_6.png)


<div class="content-ad"></div>

작업을 위해 코드를 생성할 수 있는 LLM에 있어서 문자를 정확히 세는, "a"라는 글자의 발생을 식별하는 데 어려움을 겪었거나 텍스트 내에서 "a"를 제대로 강조하고 세는 데 어려움을 겪고 있습니다.

응답에서 볼 수 있듯이, "a"라는 글자가 10번 발생했다고 쓰여 있지만 실제로는 17번 발생했음을 알 수 있습니다.

LLM의 코딩 능력과 스스로 실행하는 능력 사이의 이러한 불일치는 실험의 핵심에서 역설을 더욱 부각시킵니다. 이는 LLM의 근본적인 추론 과정과 글자 수준에서 직접 텍스트를 조작하고 분석하는 능력에 대한 의문을 던집니다.

<div class="content-ad"></div>

LLM의 성능을 코드 생성 및 직접 작업 실행 두 가지 측면에서 살펴보며, 언어 모델링의 복잡성과 LLM이 문자 수준 추론을 필요로 하는 간단한 작업에 직면했을 때 발생하는 어려움에 대해 알아보려고 합니다.

## 역설 이해

![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_8.png)

LLM에서의 토큰 기반 추론

<div class="content-ad"></div>

실험에서 관측된 역설을 이해하기 위해서는 LLMs가 어떻게 언어를 처리하고 이해하는지를 이해하는 것이 중요합니다.

LLMs는 "토큰"이라 불리는 기본 단위에서 작동합니다. 토큰은 일반적으로 모델이 인식하고 처리하는 단어, 하위단어 또는 문자입니다. 입력 텍스트가 LLM에 제공되면 먼저 토큰화되어, 이러한 개별적인 토큰으로 분해됩니다.

언어 이해와 생성을 위한 효율적인 토큰 기반 추론: 토큰 기반 추론을 통해 LLMs는 효율적으로 인간과 유사한 텍스트를 처리하고 생성할 수 있습니다.

LLMs가 토큰과 함께 작업함으로써 언어 내에서 패턴, 관계 및 종속성을 포착하고 학습할 수 있습니다. 이 접근법을 통해 LLMs는 맥락을 이해하고 일관된 응답을 생성하며 다양한 언어 작업을 높은 능률로 수행할 수 있습니다. 토큰 기반 추론은 LLMs가 자연어 상호작용에 참여하는 핵심입니다.

<div class="content-ad"></div>

토큰 기반 추론의 한계

문자 수준 작업 다루기에 대한 도전: 토큰 기반 추론은 많은 언어 작업에 대해 매우 효과적이지만, 문자 수준 작업을 처리할 때 어려움을 겪을 수 있습니다.

내가 진행한 실험에서 LLM은 문자를 정확하게 계산하고 텍스트 내에서 특정 문자 발생을 식별하는 데 어려움을 겪었습니다. 이 한계는 모델이 주로 개별 문자 수준이 아닌 토큰 수준에서 언어를 이해하고 생성하는 데 초점을 맞추기 때문에 발생합니다.

특정 시나리오에서 문자 수준 정밀도의 필요성: 실험에서 제시된 것과 같이 특정 작업은 정확한 문자 수준 조작과 분석을 필요로 합니다.

<div class="content-ad"></div>

문자 수를 세거나 특정 글자의 발생을 식별하고 텍스트 내에서 강조하는 것은 토큰 기반 추론이 제공하지 못하는 세밀함을 요구합니다.

이러한 시나리오는 LLM이 토큰 수준 처리를 넘어 개별 문자에 대해 더 정교한 제어를 가능하게 하고 처리 능력을 개발해야 한다는 필요성을 강조합니다.

코딩 능력과 자체 실행 사이의 괴리

LLM의 코드 이해 및 생성 능력: 실험의 흥미로운 측면 중 하나는 주어진 작업에 대한 코드 생성 능력이었습니다.

<div class="content-ad"></div>

코든 솔루션을 제공하라는 요청에 대해, LLM은 문제를 이해하고 기능적인 코드 스니펫을 생성했습니다. 이는 모델이 프로그래밍 개념, 구문 및 논리를 이해하고 지정된 요구 사항을 해결하는 코드를 생성할 수 있는 능력을 보여줍니다.

내부적으로 생성된 코드를 확인하고 실행하는 것에 어려움이 있습니다. 그러나 실험은 LLM의 코딩 능력과 생성된 코드를 자체 실행하는 능력 사이에 연결이 없음을 보여주었습니다.

코드 솔루션을 성공적으로 생성했지만, LLM은 문자 카운팅 및 텍스트 강조 작업을 직접 수행하는 데 어려움을 겪었습니다. 이는 모델의 코드 이해와 생성 능력이 내부적으로 코드의 기능을 실행하고 확인하는 능력과 반드시 연결되지 않음을 시사합니다.

실험에서 강조된 이 모순은 LLM의 추론 프로세스의 본질과 토큰 기반 방법의 한계에 대한 중요한 질문을 제기합니다.

<div class="content-ad"></div>

코드 능력과 자체 실행 간의 간극을 좁히기 위해 추가 연구 및 개발이 필요함을 강조하며, LLM이 코드를 생성하는 능력뿐만 아니라 필요한 경우 문자 수준에서 효과적으로 추론하고 작동할 수 있도록 하는 것이 중요합니다.

다음 섹션에서는 이러한 제한 사항을 해결하고 문자 수준 작업을 더 정밀하고 일관성 있게 처리할 수 있는 LLM의 잠재적인 미래 방향과 발전을 탐구할 것입니다.

# 전망: LLM의 진화

![이미지](/assets/img/2024-06-22-TheCuriousCaseofLLMsLLMsCanCodebutNotCount_9.png)

<div class="content-ad"></div>

미래 LLM이 문자 수준 추론을 다루는 능력을 개선할 가능성에 대해 논할 수 있습니다.

모델 아키텍처와 훈련 기술의 발전: 자연어 처리 분야가 계속 발전함에 따라, 미래 LLM이 문자 수준 추론의 제약을 극복할 수 있는 엄청난 가능성이 있습니다.

연구자와 개발자들은 LLM이 문자 수준 정밀도를 요구하는 작업을 다루는 능력을 향상시킬 수 있는 새로운 모델 아키텍처와 훈련 기술을 적극적으로 탐구하고 있습니다.

이러한 발전은 문자 수준 임베딩, 주의 메커니즘 또는 다른 기술을 통합하여 LLM이 토큰 및 문자 수준에서 효과적으로 추론할 수 있도록 하는 것을 포함할 수 있습니다.

<div class="content-ad"></div>

문자 수준의 추론과 토큰 기반 처리의 통합: 미래 LLM에 대한 한 가지 유망한 방법은 문자 수준의 추론 기능을 기존의 토큰 기반 처리와 통합하는 것입니다. 토큰 수준과 문자 수준의 추론 두 가지 강점을 활용한 혼합 접근 방식을 개발함으로써, LLM은 언어에 대한 보다 포괄적인 이해를 달성할 수 있습니다.

이러한 통합은 LLM이 효율적인 토큰 기반 처리를 유지하면서 필요할 때 문자 수준의 세부 내용을 탐구할 수 있는 능력을 갖게 해주어, 더 정확하고 미묘한 언어 이해와 생성이 가능해집니다.

토큰 기반 효율성과 문자 수준 정확성을 균형있게 유지하는 중요성.

LLM이 계속 발전함에 따라, 토큰 기반 효율성과 문자 수준 정확성 사이의 균형을 맞추는 것이 중요해질 것입니다. 토큰 기반 추론이 여러 언어 작업에 매우 효과적이라는 것은 확인되었지만, 문자 수준의 정확성에 대한 필요성도 간과해서는 안 됩니다.

<div class="content-ad"></div>

미래 LLM들은 토큰 기반 처리의 강점을 활용하면서 필요할 때 문자 수준의 추론 능력을 통합하여 조화롭게 통합하도록 노력해야 합니다. 이 균형은 LLM이 효율성과 정확성을 갖추며 다양한 어플리케이션과 사용 사례의 다양한 요구에 부응할 수 있도록 할 것입니다.

GPT-5 및 Claude 4와 같은 LLM의 지속적인 발전

기대되는 문자 수준 추론 능력의 향상: GPT-5 및 Claude 4와 같은 고급 LLM의 개발이 진행됨에 따라, 이러한 모델들은 문자 수준 추론 능력에서 상당한 개선이 예상됩니다.

각 반복에서, LLM은 정확한 문자 수준 조작과 분석이 필요한 작업을 처리하는 데 보다 능숙해질 것으로 예상됩니다. 미래 모델의 개발에서 문자 수준 추론의 통합은 토큰 기반 처리와 함께 주요 초점이 될 것으로 예상되며, 언어 이해와 생성에서 더 높은 정확도와 다재다능성을 달성하도록 돕게 될 것입니다.

<div class="content-ad"></div>

**다양한 응용 및 사용 사례에 미칠 잠재적인 영향**

미래 LLM의 문자 수준 추론 능력의 발전은 각 영역과 응용프로그램에 걸쳐 광범위한 영향을 미칠 것으로 예상됩니다.

텍스트 분석 및 정보 검색부터 언어 번역 및 콘텐츠 생성에 이르기까지, 문자 수준에서 효과적으로 추론하는 능력은 새로운 가능성을 열고 LLM의 성능을 다양한 사용 사례에서 향상시킬 것입니다. 의료, 금융 및 교육 분야를 비롯한 다양한 산업은 문자 수준 작업을 높은 정밀도로 처리할 수 있는 LLM으로부터 혜택을 입을 것으로 기대됩니다. 이는 보다 정확하고 신뢰할 수 있는 언어 기반 솔루션을 가능하게 합니다.

## 결론

<div class="content-ad"></div>

LLM이 코딩은 할 수 있지만 계산은 못 하는 신기한 사례는 그들의 추론 능력에 대한 모순을 드러냅니다.

LLM은 언어 이해와 생성에서 놀라운 능력을 보여주었지만, 문자 수준의 추론 능력의 제한은 제가 진행한 실험을 통해 분명해졌습니다. 이 모순은 LLM 아키텍처와 훈련 기술을 더 발전시켜 문자 수준의 추론을 효과적으로 다루기 위한 필요성을 강조합니다.

자연어 처리 분야가 계속 발전함에 따라, GPT-5, Claude 4, Gemini 2와 같은 미래 LLM의 발전은 이러한 제한을 극복하는 데 유망합니다. 미래 LLM은 문자 수준의 추론을 토큰 기반 처리와 효율성과 정확도 사이의 균형을 맞추어 통합함으로써 더 포괄적이고 정확한 언어 이해와 생성을 이룰 수 있는 잠재력을 가지고 있습니다.

토큰과 문자 수준에서 효과적으로 추론하는 능력은 다양한 응용 분야와 사용 사례에 중요한 영향을 미치며, LLM은 더욱 정확하고 신뢰할 수 있는 언어 작업을 다양하게 수행할 수 있는 기회를 얻을 것입니다.

<div class="content-ad"></div>

이 분야의 연구 및 개발이 진행됨에 따라 LLMs가 문자 수준 작업을 처리하는 능력이 점점 더 향상될 것으로 기대됩니다.이는 자연어 처리의 새로운 가능성을 개척하고 언어 기반 AI 시스템으로 달성 가능한 영역을 넓히게 될 것입니다.