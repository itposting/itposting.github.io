---
title: "AI 대거들 양자화하기 대형 AI 모델 양자화의 방법 및 장점"
description: ""
coverImage: "/assets/img/2024-06-22-QuantizingtheAIColossi_0.png"
date: 2024-06-22 19:57
ogImage: 
  url: /assets/img/2024-06-22-QuantizingtheAIColossi_0.png
tag: Tech
originalTitle: "Quantizing the AI Colossi"
link: "https://medium.com/towards-data-science/quantizing-the-ai-colossi-017e121a27c5"
---


## 거장들의 작업 간소화 파트 2: 신경망 양자화

최근 몇 년 동안, 트랜스포머 신경망 구조와 다양한 문제를 자기 지도형 순차 예측 작업으로 포장하는 강력한 연합이 형성되었습니다. 이 결합은 연구자들이 순차적으로 레이블이 지정되지 않은 대량의 데이터를 사용하여 전례 없이 거대한 기반 모델을 훈련할 수 있게 되었고, 이러한 모델은 여러 영역에서 인간 수준의 지능을 긴밀하게 모사하는 놀라운 신생 능력을 보여주었습니다. 새로운 실용적인 유용성의 정점에 도달함으로써 인공지능(AI)은 대중적인 생활과 대화 속으로 활주했으며, 오늘날 많은 사람들이 한때 허구의 영역이었던 실리콘 기반 지능이 이제 매우 현실적이고 실제적이라는 것을 알지 못하는 사람은 거의 없습니다.

그러나 AI 능력의 폭발적인 성장과 밀접하게 연결되어 온 것은 수백억 개(경우에 따라 수조)의 파라미터로 모델 크기가 급속히 팽창한 것입니다. 강력한 새로운 기술이 세상에 공개되었지만 중요한 것은 대규모 하드웨어 클러스터를 사용해야만 제공될 수 있었습니다. 이전 AI 시대의 도전 과제들의 메아리를 일으키며, 이러한 미리 학습된 거물로 압축하는 동기가 강하며, 이를 즉각적으로 압축하는 동기가 강했습니다. 이와 동시에 공급 자원 개선, 양자화, 지식 증류, 파라미터 효율적 미세 화등 다양한 잘 정립된 기술들을 다시 살아나게 했습니다.

'Streamlining Giants' 시리즈의 첫 번째 부분에서, 대형 언어 모델(Large Language Models; LLMs)의 성능을 모델 압축을 통해 민주화하는 논의를 시작했습니다. 신경망 할머니 연구의 풍부한 유산을 탐험함으로써 처음부터 LLMs에 포함된 수십억 또는 수백억 개의 파라미터를 포함하는 엘엠엠을 최근까지 신경망 가지치기에 대한 응용까지 살펴봤습니다. 이 과정에서 대량 모델이 네트워크에서 가장 중요하지 않은 매개 변수를 구조적으로 제거하거나 비구조적으로 제거함으로써 압축 할 수 있음을 발견했습니다. 또한, 가지치기는 자원 제약 환경에서 작동할 수 있는 조밀한 모델을 생성하며, 과거에는 성능을 복구하기 위해 그래디언트 정보를 계산하거나 모델을 다시 훈련해야 했습니다. 이는 가지치기를 통한 모델 압축의 수단을 가지고자 했던 사람들에게는 필요하지 않은 계산 자원이 필요하다는 것을 의미했습니다. 이 경우, LLMs의 경우 수백만 달러가 됩니다. 이것이 처음에는 그 모델을 훈련하는 데 필요한 계산 자원이 있는 사람들에게는 접근할 수 없었다는 것을 의미했습니다. 그러나 최근의 연구에서는 접근성이 높은 접근 방법을 제안하여 저위험 그래디언트 또는 심지어 정방향 통과 정보 만 사용할 수 있었습니다. 또한 매개변수가 효율적으로 세밀하게 개선되는 방법의 동시적인 발전을 통해 대형 모델의 재훈련이 사용자 하드웨어를 통해 이루어질 수 있으며, 이제 소비자 하드웨어를 사용하여 가지치기를 수행할 수 있게 되었습니다.

<div class="content-ad"></div>

이번 설치물에서는 모델 압축에 대한 직교적인 접근 방식을 조사합니다: 양자화는 네트워크에서 저장되고 작동되는 숫자의 정밀도를 줄이는 것을 통해 모델의 계산 효율성과 메모리 요구 사항을 개선하려고 합니다. 이는 가중치, 활성화 또는 둘 다를 포함할 수 있습니다. 양자화는 정밀도의 감소를 의미할 수 있지만, 예를 들어 32비트에서 16비트 부동 소수점으로의 변경과 같이 양자화는 종종 정수 공간으로의 전환을 수반하며 소비자 하드웨어에서 가속화된 작동 및 배포를 제공합니다. 양자화는 LLMs를 압축하는 매우 강력한 방법으로, 계산 오버헤드와 하드웨어 요구 사항의 큰 감소를 제공하면서 성능의 작은 부분적인 또는 존재하지 않는 하락만으로 대가를 치룸으로써 오늘날 대형 모델의 세계에서 가장 널리 사용되는 모델 압축 기술이 됩니다. 더 나아가 숫자 정밀도의 수준을 다양화함으로써 사용 사례에 대한 정확성/효율성 교환을 조정할 수 있습니다.

이 여정을 통해 우리는 양자화가 이전에 만난 가지치기 기술들과 조화롭게 작동하며, 앞으로 살펴볼 지식 증류 및 매개변수 효율적 인 세부 조정 방법과도 조화를 이루는 것을 볼 것입니다. 이는 Streamlining Giants 시리즈에서 조사할 주제를 엿볼 수 있게 해줍니다. "잔치에 무료 점심은 없다"는 유명한 속담이 있지만, 가지치기에 대해 조사한 바에 따르면, 모델 압축과 관련해 때로는 그런 것이 있습니다. 가지치기와 마찬가지로, 양자화는 신경망을 더 견고하고 일반화 가능하게 만드는 정규화 형태로 작용하며, 이 기술들의 적절한 적용은 종종 모델을 압축하고 성능을 향상시키는 것을 의미합니다. 이 글에서는 문헌을 조사하고 "무료 점심" 압축의 여러 예시를 살펴볼 것입니다. 마지막에는 비록 의심하는 독자라도 네트워크 양자화가 품질의 저하를 내포한다는 관념이 틀렸다는 것을 깨달을 것입니다. 연구를 검토한 후, 우리는 오픈 소스 소프트웨어를 사용하여 이러한 기술을 적용하는 도구를 탐구할 것입니다. 이제 우리는 흥미진진한 신경망 양자화 분야로 들어가 봅시다.

# 양자화

LLM 배포에 있어 양자화의 성공과 필요성을 증명하는 방법으로, 오늘날 인기 있는 오픈 소스 LLM 서빙 솔루션마다 양자화된 모델에 쉽게 접근할 수 있도록 제공되는 경우가 많으며, 종종 기본 선택 사항입니다. 예를 들어, 최근 Ollama에서 즐겁게 사용하여 오픈 소스 음성-음성 다국어 언어 학습 보조 프로그램을 작성하는 데 큰 도움을 받은 인기 있는 Ollama는, 소비자 하드웨어에서 양자화된 LLM의 최적화된 배포를 실현하기 위해 개발된 순수 C/C++ 라이브러리인 llama.cpp를 기반으로 구축되었습니다. 저전력 하드웨어를 사용하는 로봇과 같은 실시간 비전-언어 애플리케이션에서는 이러한 유형의 하드웨어 최적화된 서빙 백엔드로 양자화된 모델을 배포하는 것이 필수적입니다. 그렇다면 양자화는 정확히 무엇이며 신경망을 압축하는 데 어떻게 효과적인지 알아보겠습니다.

<div class="content-ad"></div>

양자화는 연속적인 실수 공간을 고정된 집합의 이산 숫자로 매핑하는 것을 가리키며, 보다 넓은 의미로는 어떠한 숫자 공간을 낮은 정밀도의 표현으로 전이시키는 것을 말합니다. 예를 들어, 32비트 "싱글" 또는 "풀" 정밀도 부동 소수점 값, 또는 고해상도인 64비트 "더블" 부동 소수점 값을 살펴보면, 이러한 데이터 유형은 운반할 수 있는 소수점 자리수가 제한적입니다. 따라서 이러한 데이터 유형들은 양자화된 분포의 예시이며, 각각의 "단계" 사이에 표현할 수 없는 무한한 수의 값이 있는데, 이는 디지털 세계의 명확한 "계단식" 패턴을 만들어냅니다. 사실, 이산 시스템에서 연속 값을 효과적으로 처리하는 과제는 디지털 컴퓨터 과학이 시작된 시점부터 고민되어온 과제입니다. 심지어 부동 소수점 숫자조차도 내부적으로는 정수로 분해되는데, 이는 디지털 컴퓨터가 본질적으로 이산 정보를 처리하기 때문입니다. 따라서 신경망에서는 기술적으로 "양자화되었느냐"라는 문제가 아니라 "얼마나 양자화되었느냐"라는 질문이 더 적합합니다.

신호 처리와 같은 양자화의 다른 응용과는 달리, 신경망 양자화에서의 최종 목표는 매우 정밀한 수치를 표현하는 것이 아닌, 매개 변수를 가능한 한 낮은 정밀도로 이산화시켜도 그들의 집합 상호작용으로부터 동일한 출력을 유지하는 것입니다. 신경망은 매우 많은 수의 매개 변수를 가지고 있으며, 따라서 손실 기울기 공간에 많은 가능한 해를 포함하는 최적의 매개 변수의 다양한 매니폴드를 갖고 있습니다. 따라서 개별 가중치는 양자화 과정에서 원래의 값에서 상당히 멀어질 수 있지만, 전체적 상호작용이 이 해 매니폴드에 유지되는 한 모델 매개 변수를 최적화할 수 있는 기회가 제공됩니다. 이를 양자화 관련 훈련(Quantization-Aware Training, QAT)이라고 합니다.

QAT를 수행할 때는 주로 시뮬레이션된 또는 가짜 양자화를 사용하는데, 여기서 매개변수는 낮은 정밀도로 저장되지만 연산은 여전히 부동 소수점 산술을 사용합니다. QAT의 경우 부동 소수점으로 계산을 수행하면 경사하강을 위한 조건을 제공하지만(이 때문에 "STE(직선 통과 추정기)"와 같이 경사에 대한 둘레 함수의 파괴적 영향을 무시하는 방법이 필요함), 일부 방법은 런타임 가속보다는 저장 효율성에 초점을 맞춘 추론 시에 시뮬레이션된 양자화를 사용할 수도 있습니다.

시뮬레이션된 양자화는 모든 연산이 낮은 정밀도 산술을 사용하는 정수 전용이나 고정 소수점 양자화와 대조적입니다. 정수 전용 양자화는 지연 시간 및 전력 소비에서의 모든 이점이 있는데, 하드웨어에 따라 고려 사항이 달라질 수 있습니다. 최신 GPU는 고도로 최적화된 부동 소수점 유닛을 사용하는 반면, 엣지 장치는 정수 산술이 더 효율적일 수 있습니다. 시뮬레이션된 또는 정수 전용 양자화 사용은 사용 사례에 따라 달라지는데, 예를 들어, 하드웨어 구현에 신경 쓰지 않고 다양한 양자화 수준에 대한 네트워크 구성 요소의 민감도를 반복적으로 테스트하려면 시뮬레이션된 양자화가 좋은 선택이고, 엣지에서 최적화된 배포를 위해 정수 전용 양자화가 가장 적합할 것입니다.

<div class="content-ad"></div>

QAT은 양자화 효과를 교육 과정에 반영하여 최적의 결과를 얻지만, 우리가 가지고 있던 가지치기 조사 중에 이전에 마주한 동일한 도전에 직면합니다: LLM과 같은 매우 큰 모델을 압축하려면 교육 데이터에 액세스할 수 없거나 GPU 시간에 백만 달러를 쓰려 하지 않는 등 여러 이유로 재교육 단계를 피하고 싶습니다. 그래서 QAT의 엄청난 결과를 포기하고 대신 작은 보정 데이터셋만 필요로 하는 사후 교육 양자화(PTQ) 방법을 살펴보게 되었고, 결국에는 데이터를 전혀 사용하지 않는 이상적인 시나리오를 탐색하는 Zero-Shot 양자화(ZSQ) 방법의 성공을 희망하게 되었습니다. 최근 연구는 PTQ를 뛰어난 정확도 수준으로 끌어 올렸고, 낮은 비트 설정에서도 전체 정밀도 기준치에 근접하여 상당히 성공적이 되었으며, 오픈 소스 연구와 코드 노력 덕분에 매우 접근하기 쉽게 되었습니다.

양자화의 이점은 압축을 넘어 신경망에게 확장됩니다. 가지치기와 마찬가지로 양자화는 신경망에서 고유 매개변수의 수를 줄이는 방식으로 규제의 형태로 작용하여, 적절하게 적용될 때 성능 및 일반화 능력을 증가시킬 수 있습니다. 이러한 방식으로 양자화는 신경망을 위한 또 다른 "무료 점심" 압축 방법으로 가지치기와 결합되어, 모델 크기와 복잡성의 상당한 축소로 인해 결과가 조정되는 경우에도 성능이 향상될 수 있습니다. 디지털화의 이점을 고려하면, 신경망의 표현이 부동 소수점으로만 필요한 것인지, 교육 중 그라디언트 강하를 유도하기 위해 필요한 개발의 유추 단계에 불과한 것으로 보일 수 있습니다. 그리고 진행 추세가 계속되면, 최적화된 정수 계산만 사용하여 교육 결과를 최종적으로 달성할 수 있으며, 이렇게 하면 고정밀도 신경망의 필요성에서 해방될 수도 있습니다.

양자화는 교육부터 배포까지 LLM 개발의 모든 부분에 영향을 미치며, 대규모 모델의 메모리, 전력 및 계산 효율성을 개선하기 위한 다양한 기법을 포괄합니다. 예를 들어, 민감하지 않은 계산은 전체 32비트 부동 소수점 대신 반정밀도(16비트 부동 소수점)에서 수행되는 혼합 정밀도로 LLM을 교육하는 것이 흔한 실천이 되었으며, 결과에 큰 영향을 미치지 않고 메모리 크기를 뚜렷하게 축소하여 운영에 필요한 전력을 현저히 줄이게 되었습니다. 이와 같은 수정은 우리가 모델을 보다 자유롭게 반복하고 발전시킬 수 있을 뿐만 아니라, 대규모 모델 교육의 환경적 영향을 넓게 미치며, LLM의 경우 CO2 톤으로 측정할 수 있는 것입니다.

<div class="content-ad"></div>

정말, 자원의 일부만 사용하여 동등한 수학적 결과를 얻을 수 있는 경우에는 패자가 없으며 매우 큰 이익을 얻을 수 있습니다. 이 약속은 수십 년에 걸쳐 뉴럴 네트워크 양자화에 대한 엄청난 연구 코퍼스를 영감을 주었으며, 우리가 얘기하는 동안에도 계속해서 힘을 얻고 있습니다. 이는 이 탐구가 포괄적이고 완전한 것을 염두에 둔다는 의미이므로, 우리는 이를 기억에 맞추기 위해 어느 정도의 세부 사항을 살짝 빼야 할 것입니다. 야심찬 독자들은 최근과 완전한 Gholami 등의 2021 조사 또는 역사적으로 중점을 둔 Gray & Neuhoff 1998 조사를 참조해야 합니다.

## 개요

뉴럴 네트워크 양자화 주제에 대한 정보화된 이해의 최단 경로를 제공하려고 노력하는 이 기사의 나머지 부분은 다음과 같이 진행될 것입니다: 먼저, 양자화의 기초가 되는 수학에 친숙해지고 우리가 이야기하는 내용을 기초로 삼습니다. 그런 다음, 우리는 1990년대 초반의 뉴럴 네트워크 양자화 연구의 뿌리를 발견하고, 이를 2012년 이미지 분류 작업에서 증명된 AlexNet의 성공을 따른 "딥 러닝 혁명" 기간의 노력들과 연결합니다. 이에 따라 우리는 현대의 양자화 연구가 컴퓨터 비전에서 먼저 번식하고 그 다음에 자연어 처리에 들어가는 것을 목격할 것이며, 이 때문에 우리는 오늘날 LLMs의 세계에서 양자화의 응용 프로그램을 논할 준비가 되어야 할 것입니다. 마지막으로 우리는 우리의 연구 결과를 반영하고, 미래 작업 방향을 논의할 것입니다.

이 기사는 장(chapters)으로 구성되어 특정한 부분으로 명확하게 읽을 수 있습니다. 독자는 정보를 찾기 위해 급하게 섹션을 건너뛰도록 선택할 수 있지만, 만나게 될 용어가 이전 장에서 정의되었을 수 있음을 염두에 두세요. 이러한 섹션들이 뉴럴 네트워크 양자화 주제의 상당히 독립적인 리뷰를 구성하며, 열정적인 머신 러닝 실무자부터 전문가까지 깊은 지식을 제공하여 자신의 작업 흐름을 최적화할 수 있는 것을 목표로 합니다. 기사는 LLM 양자화를 위한 구현 가이드로 마감되며, 시간이 제한된 독자들은 직접 거기로 건너 뛸 수 있습니다.

<div class="content-ad"></div>

- 양자화의 메커니즘
  - 비트 폭
  - 균일 양자화
  - 비균일 양자화
  - 혼합 정밀도 양자화
  - 스칼라 vs. 벡터 양자화
  - 양자화 효과 보상
- 신경망 양자화의 역사
  - 신경망 양자화 초기 연구
  - 알렉스넷 시대 이후의 양자화
    - CNN의 양자화 인식 훈련
    - 혼합 정밀도 양자화의 부상
    - CNN의 후훈련 양자화
    - 극한 양자화: 이진 및 삼진 네트워크
- LLM의 양자화
  - 트랜스포머 초기 시대의 양자화
  - LLM의 후훈련 양자화
  - LLM의 양자화 인식 훈련
    - LLM의 극한 양자화
- 실무가를 위한 LLM 양자화 가이드
  - LLM 양자화 결정 트리
- 결론
  - 미래 작업

# 양자화의 메커니즘

사실 "양자화" 하면 무엇을 의미하는지 정확히 생각하는 것이 중요합니다. 우리는 이미 양자화를 통해 고정밀 값 집합을 가져와 더 낮은 정밀도로 매핑하고, 이를 최대한 보존하는 관계를 유지한다고 이야기해 왔습니다. 그러나 이 작업의 메커니즘에 대해 자세히 다룬 적은 없습니다. 놀랍게도, 우리는 값들을 양자화된 공간으로 다시 매핑하는 방법에 대한 세심한 설계 선택과 세부 사항이 있다는 것을 발견할 것입니다. 사용 사례에 따라 다양하게 변하는 이 선택사항을 이해하려고 이 섹션에서는 양자화 프로세스를 안내하는 조정 장치와 레버를 파악하여 연구를 더 잘 이해하고, 배포 시 교육된 결정을 내리도록 자신을 갖추고자 합니다.

## 비트 폭

<div class="content-ad"></div>

양자화에 대한 논의 동안, 우리는 양자화된 값의 비트 폭에 대해 언급할 것입니다. 이는 값 표현에 사용 가능한 비트 수를 나타냅니다. 하나의 비트는 0 또는 1의 이진 값을 저장할 수 있지만, 비트 세트는 그 조합을 증가하는 정수로 해석할 수 있습니다. 예를 들어, 2 비트가 있는 경우 4개의 총 조합('0, 0', '0, 1', '1, 0', '1, 1')을 표현할 수 있으며, 이는 [0, 3] 범위의 정수를 나타낼 수 있습니다. N 비트를 추가함으로써 가능한 조합은 2의 N제곱이 되기 때문에, 8비트 정수는 256개의 숫자를 나타낼 수 있습니다. 부호 없는 정수는 0부터 최대값까지 계산하지만, 부호 있는 정수는 첫 번째 비트를 +/- 부호로 해석하여 0을 범위 중앙에 두게 됩니다. 따라서, 부호 없는 8비트 정수는 [0, 255] 범위를 가지며, 부호 있는 8비트 정수는 [-128, 127]로 확장됩니다.

비트가 정보를 어떻게 나타내는지에 대한 이 기본 지식은 우리가 연구하는 기술에서 부동 소수 값을 매핑되는 숫자 공간을 맥락에 맞게 이해하는 데 도움이 될 것입니다. 4비트로 양자화된 네트워크 레이어를 듣게 되었을 때, 목적지 공간이 2의 4승 (16) 개의 이산 값이 있음을 이해합니다. 양자화에서 이러한 값들은 양자화된 가중치의 정수 값을 반드시 나타내지 않고, 종종 양자화 수준의 인덱스를 나타냅니다 — 입력 분포의 값이 매핑되는 "버켓"입니다. 각 인덱스는 사전 정의된 숫자 공간 내의 특정 양자화된 값을 나타내는 코드워드에 해당합니다. 이 코드워드들은 코드북을 형성하며, 코드북에서 얻은 값은 수행할 산술 연산의 유형에 따라 부동 소수 또는 정수 값일 수 있습니다. 버켓을 정의하는 임계값은 선택한 양자화 함수에 따라 다를 수 있습니다. 코드워드와 코드북은 일반적인 용어이며, 대부분의 경우 코드북에서 반환된 값이 코드워드와 동일할 것입니다.

## 부동 소수점, 고정 소수점 및 정수 전용 양자화

이제 비트 폭을 이해했으므로, 부동 소수점, 고정 소수점 및 정수 전용 양자화 사이의 차이를 이해해야 합니다. 이진 비트로 정수를 나타내는 것은 간단하지만, 소수 부분을 가진 숫자를 처리하는 것은 조금 더 복잡합니다. 부동 소수점과 고정 소수점 데이터 유형은 이를 수행하기 위해 설계되었으며, 이들 중에서 선택하는 것은 배포 하드웨어와 원하는 정확성-효율성의 상충 관곈에 따라 다릅니다. 모든 하드웨어가 부동 소수점 연산을 지원하지는 않으며, 고정 소수점 산술은 수치 범위와 정밀도가 감소하는 대신 전력 효율성이 높을 수 있습니다.

<div class="content-ad"></div>

부동 소수점 숫자는 비트를 사용하여 부호, 지수 및 유효숫자를 나타내는 세 가지 정보를 할당하여 그 값들에 대한 효율적인 비트 조작을 가능하게 합니다. 지수의 비트 수는 숫자 범위의 크기를 결정하고 유효숫자의 비트 수는 정밀도를 정의합니다. 예를 들어, 32비트 부동 소수점(FP32)에 대한 IEEE 754 표준은 첫 번째 비트를 부호에, 8비트를 지수에, 나머지 23비트를 유효숫자에 할당합니다. 부동소수점 값은 "부동"이라고 불리는데, 각 개별 숫자에 대해 지수를 저장하기 때문에 소수점의 위치를 "부동"시킬 수 있습니다. 이는 10진법의 과학적 표기법과 유사하지만, 컴퓨터가 2진법(이진법)에서 작동한다는 점에서 다릅니다. 이 유연성은 다양한 값들의 정밀한 표현을 가능하게 하며, 특히 0 부근의 경우에 중요한 정규화의 중요성을 강조합니다.

반면에 "고정" 소수점 정밀도는 동적 스케일링 요소를 사용하지 않으며, 대신 부호, 정수 및 분수(종종 유효숫자로도 지칭) 구성요소로 비트를 할당합니다. 이는 더 높은 효율성과 전력 절약 작업을 의미하지만, 동적 범위와 정밀도가 저하됩니다. 이를 이해하기 위해 가능한 한 0에 가까운 숫자를 표현하고 싶다고 상상해보세요. 그렇게 하려면 소수점을 최대한 멀리 가져가야 합니다. 부동 소수점은 소수점을 왼쪽으로 더 멀리 밀어내기 위해 점점 더 음의 지수를 사용할 수 있으며, 이 상황에서 추가 해상도를 제공할 수 있지만, 고정 소수점 값은 고정된 수의 분수 비트로 제공되는 정밀도로 제한됩니다.

정수는 분수 구성요소에 대해 비트를 제공받지 않는 고정 소수점의 극단적인 경우로 볼 수 있습니다. 실제로 고정 소수점 비트는 정수인 것처럼 직접 조작할 수 있고, 결과는 소프트웨어를 사용하여 적절한 고정 소수점 결과를 얻기 위해 다시 조절될 수 있습니다. 정수 산술은 하드웨어에서 전력을 더 효율적으로 사용하므로, 신경망 양자화 연구는 정수만 양자화를 선호하며, 원래 부동 소수점 값을 정수로 변환하여 수행하므로 정수 산술은 궁극적으로 동등할지라도 정수만 산술은 더 효과적으로 수행할 수 있습니다. 이것은 배터리로 구동되는 장치에 배포하는 데 특히 중요합니다. 이 장치들은 종종 정수 산술만 지원하는 하드웨어를 포함하고 있습니다.

<div class="content-ad"></div>

일련의 숫자를 양자화하려면 먼저 양자화 함수 Q(r)를 정의해야 합니다. 여기서 r은 양자화할 실수(가중치 또는 활성화)입니다. 가장 일반적인 양자화 함수는 아래와 같습니다:

![image](/assets/img/2024-06-22-QuantizingtheAIColossi_1.png)

이 공식에서 Z는 정수 제로 포인트를 나타내고, S는 스케일링 팩터입니다. 대칭 양자화에서 Z는 단순히 0으로 설정되어 식에서 취소되며, 비대칭 양자화의 경우 Z를 사용하여 제로 포인트를 오프셋할 수 있어 입력 분포의 양수 또는 음수 측면 중 어느 한 쪽에 양자화 범위를 더 집중할 수 있습니다. 이렇게 함으로써 특정 경우에 매우 유용할 수 있습니다. 예를 들어, 양자화된 post-ReLU 활성화 신호를 다룰 때, 이 신호는 양수만 포함하므로 비대칭 양자화가 유용할 수 있습니다. Int(·) 함수는 정수에 가중치가 부여된 연속 값을 할당하는데, 일반적으로 반올림을 통해 할당하지만, 때로는 더 복잡한 절차를 따르기도 합니다.

올바른 스케일링 팩터(S)를 선택하는 것은 쉽지 않으며, 양자화할 값들의 분포를 신중하게 고려해야 합니다. 양자화된 출력 공간은 입력을 매핑하는 유한한 값 범위(또는 양자화 레벨)를 가지므로, 수신되는 값 분포에 적합한 좋은 맞춤 범위 [α, β]를 제공하는 클리핑 범위를 설정해야 합니다. 선택된 클리핑 범위는 극단적인 입력값을 지나치게 클램핑하거나 긴 꼬리에 너무 많은 비트를 할당하여 양자화 레벨을 과다로 포화하지 않는 중요한 균형을 유지해야 합니다. 우선은 양량화의 고려 범위인 균일 양자화를 고려하며, bucketing 임계값 또는 양자화 단계가 일정한 간격으로 배치된다는 것을 고려합니다. 스케일링 팩터의 계산은 다음과 같습니다:

<div class="content-ad"></div>

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_2.png" />

훈련된 매개변수 분포의 모양은 네트워크 간에 크게 다를 수 있으며 여러 요인에 영향을 받습니다. 해당 가중치에 의해 생성된 활성화 신호는 더욱 동적이고 예측할 수 없으므로 올바른 클리핑 범위에 대한 어떠한 가정도 어렵습니다. 이것이 우리가 모델 및 데이터를 기반으로 클리핑 범위를 교정해야 하는 이유입니다. 최상의 정확성을 위해 실무자는 추론 중에 활성화에 대한 클리핑 범위를 온라인으로 교정하는 동적 양자화라고도 하는 것을 선택할 수 있습니다. 예상대로 이 방법은 추가적인 계산 오버헤드가 발생하며, 따라서 클리핑 범위가 미리 교정되고 추론 중에 고정되는 정적 양자화보다 훨씬 인기가 적습니다.

디양자화
우리는 양자화된 값들을 원래의 숫자 공간으로 디코딩하는 역 균일 양자화 작업을 수행합니다. 그러나 라운딩 연산은 되돌릴 수 없기 때문에 이것은 불완전하게 수행됩니다. 우리는 다음 공식을 사용하여 근사값을 디코딩할 수 있습니다:

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_3.png" />

<div class="content-ad"></div>

## 비등간격 양자화

안내적인 독자라면 아마도 동일한 간격의 버킷 경계를 지정하는 것이 균일하지 않은 모양의 입력 분포에서는 일부 비트가 다른 비트보다 훨씬 더 포화되게 될 것이라는 점을 알아챘을 것입니다. 그리고 이러한 폭을 조정하여 분포의 밀도가 높은 영역에 더 많은 비트를 집중시키면 입력 신호의 미묘한 차이를 더 정확하게 잡을 수 있습니다. 이 개념은 비등간격 양자화의 연구에서 조사되었으며, 신호의 충성도에서 이점을 보여주었지만, 균일 양자화로 가능한 하드웨어 최적화된 계산으로 인해 이를 사실상의 신경망 양자화 방법으로 만들었습니다. 아래의 식은 비등간격 양자화 과정을 설명합니다:

![image](/assets/img/2024-06-22-QuantizingtheAIColossi_4.png)

비균일 양자화의 많은 작업은 입력 분포의 클러스터 중심을 나타내는 중심점을 학습하는 것을 언급하며, 주변 값들이 양자화 과정을 통해 매핑되는 분포 내 클러스터의 중심을 나타냅니다. 다른 방식으로 생각해보면, 입력 분포 상의 경계가 균일하게 간격을 두고 있는 균일 양자화에서는 중심점이 단순히 버킷 경계 사이에 직접 있는 값들입니다.

<div class="content-ad"></div>

## 혼합 정밀도 양자화

우리는 가지치기와 마찬가지로, 훈련된 신경망의 성능은 일부 레이어 및 서브모듈에서 다른 것보다 민감하게 변화하는 것을 볼 수 있습니다. 이러한 민감도를 측정하여 전체 신경망의 일부를 제거할 수 있으며, 이렇게 함으로써 오차에 별다른 영향을 주지 않고 제거할 수 있습니다. 직관적으로, 같은 것이 양자화 수준이 다른 경우에도 마찬가지이며, 네트워크 구성 요소 중 일부는 동료보다 훨씬 낮은 비트 폭으로 다시 매핑될 수 있습니다. 우리가 이미 언급한 이에 가장 기본적인 예는 훈련 중 메모리 풋프린트를 크게 줄일 수 있는 덜 민감한 네트워크 작업에서 16비트 부동 소수점 수를 사용하는 것입니다. 하지만 혼합 정밀도 양자화는 네트워크 전체에 걸쳐 다양한 양자화 수준의 조합을 의미할 수 있습니다.

혼합 정밀도 양자화 개념과 관련된 것은 양자화의 세분성이며, 이것은 레이어별, 그룹별, 채널별 또는 하위 채널별일 수 있으며, 구별된 양자화 매개변수 세트의 규모를 설명합니다. 직관적으로, 세분성이 높을수록 계산 부담이 높아지며, 정확도/효율성 교환이 발생합니다. 예를 들어, 합성곱 신경망(CNN)에서 채널별 세분성이 종종 선택하는 방법이며, 하위 채널별(즉, 필터 별) 양자화는 너무 복잡할 것입니다.

## 스칼라 대 벡터 양자화

<div class="content-ad"></div>

대부분의 양자화 연구는 역사적으로 행렬 내 개별 값들의 양자화에 초점을 맞춰 왔지만, 다차원 중심을 학습하는 것도 가능합니다. 이는 행렬을 벡터로 분할할 수 있고, 그러한 각각의 벡터에는 가장 가까운 중심을 가리키는 코드워드가 할당될 수 있음을 의미합니다. 이를 통해 단일 코드북 조회에서 행렬 전체를 복구할 수 있는 새로운 가능성이 열리고, 여러 숫자를 단일 값에 저장하며 압축 수준을 크게 향상시킬 수 있습니다. 이를 벡터 양자화라고 하며 제공하는 장점으로 인해 많은 관심을 끌고 있습니다. “벡터 양자화”는 일반적으로 행렬을 열 벡터로 분할하는 것을 의미하지만, 이들 벡터는 제품 양자화라는 연습으로 하위 벡터로 더 분할될 수 있습니다. 이는 코드북에서 반환된 중심 벡터 조립이 상대적으로 작은 구조의 저장된 코드워드를 사용하여 원본의 더 큰 행렬을 정확하게 재현할 것이라는 아이디어입니다. 이것이 실제로 매우 강력한 모델 압축 기술임이 입증되었음을 볼 것입니다.

## 양자화의 영향 보상

신경망의 가중치를 각기 다른 해상도로 반올림하여 여전히 제대로 작동할 것으로 예상하는 것은 합리적이지 않다는 것은 자명합니다. 따라서 양자화 과정으로 인한 불안정성을 보상하는 계획을 세워야 합니다. 앞서 배운 것처럼, 양자화된 환경에서 모델을 훈련하거나 세밀하게 조정하여 양자화 양을 크게 증가시키고도 성능에 영향을 미치지 않는 기술인 양자화 주의 훈련(QAT)을 통해 훈련하는 것이 가능합니다. 단, QAT를 수행하기 위해서는 모델을 훈련하기 위한 하드웨어와 데이터가 필요합니다. 이는 오늘날의 대규모 모델인 LLMs와 같은 경우에는 자주 불가능합니다. 이 문제를 해결하기 위해 사후 훈련 양자화(PTQ) 기법은 훈련을 피하고 양자화 함수를 보정하기 위한 소량의 레이블되지 않은 데이터만 필요로 합니다. 그리고 Zero-Shot 양자화(ZSQ)는 보정을 위해 데이터가 필요하지 않은 이상적인 시나리오를 탐구합니다.

이러한 기술들이 문헌 속에서 자세히 소개되니 각각의 기법에 대해 자세히 알아보겠습니다. 이제 시간 여행 버스에 탑승하여 말세로 돌아가 년들에, 하드웨어 한계를 초과하는 신경망의 힘에 매료되고, 이러한 복잡한 모델을 모바일 하드웨어에 배포하는 방법에 대해 처음으로 고민하기 시작했던 연구원들을 만나러 떠나 봅시다.

<div class="content-ad"></div>

# 신경망 양자화의 역사

## 신경망 양자화의 초기 연구

모델 압축 기술 가족 중에서 신경망 양자화는 가위로 잘라내기와 얼추 비슷한 연관성을 가진 더 낮은 수준의 기술로, 뒤지기도 일찍이 1980년대 말 백프로프 훈련된 신경망의 형성 연도까지 거슬러 올라간다. 이 당시의 전산 하드웨어 발전 시대에서는 신경망 연구에 대한 관심이 다시 살아나게 되었지만, 하드웨어 제약으로 인해 여전히 신경망이 가장 적합한 사용 사례들을 제한하게 됐다. 연구자들은 수치 정밀도 문제에 대한 고려를 수십 년 동안 함축적으로 다뤄 왔지만, 이러한 계산 제약사항이 강조되면서 수치 정밀도를 줄여 최적화하는 새로운 방향에 주목했다. 이는 1990년대 초반에 걸쳐 방대한 양의 연구를 유발했다.

1989년에 베이커와 해머스트롬은 하드웨어 최적화 가능성을 염두에 둔 채로 줄인 수치 정밀도가 네트워크 성능에 미치는 영향을 체계적으로 연구한 최초의 연구자들이었다. 그들의 작품 "인공 신경망 알고리즘의 특성화"는 32비트 부동 소수점 연산이 네트워크 성능을 보존하기 위해 반드시 필요하다는 관행적 지혜에 도전했으며, 줄인 정밀도 계산을 사용하여 백프로프에 의해 네트워크를 성공적으로 훈련하는 초기 사례였다. 같은 해에 홀리스 등이 12비트 정밀도 주변에서 백프로프 네트워크 훈련에 대한 정밀도 제약이 미치는 영향을 더욱 심층적으로 연구했으며, 1990년에는 다음의 연구에서 이전 연구를 발전시킨 다른 하머스트롬은 고정 정밀도 계산을 위해 명시적으로 최적화된 새로운 하드웨어 유닛의 설계를 조사하였다. 이 결과로 16비트 또는 8비트 정밀도를 사용하여 성능에 용인 가능한 정도의 감소와 함께 효율성의 상당한 향상이 얻어진다는 것을 입증함으로써, 신경망 양자화와 하드웨어 최적화에 대한 향후 연구 기초를 다지게 되었다.

<div class="content-ad"></div>

신경망을 최적화하기 위해 낮은 비트 폭과 특수 하드웨어를 활용하는 연구는 백프롭이 신경망 학습 알고리즘의 무전한 챔피언이 되기 전에도 진행되고 있었다. 1992년의 중요한 연구에서 Hoehfeld와 Fahlman은 한정된 숫자 정밀도가 카스케이드-상관 알고리즘(Fahlman & Lebiere, 1991)으로 네트워크를 학습하는데 미치는 영향을 조사하여, 이 학습 알고리즘이 고정 정밀도에서도 효과적임을 입증했습니다. 그들의 성공의 일환으로, 저자들은 수렴을 가능하게 하는 동적 재척도 및 확률론적 반올림 기술을 소개했는데, 이는 훈련에 훨씬 낮은 정밀도(그들의 경우 6비트)에서도 적용 가능하며, 그레이디언트 기반 학습 알고리즘에 적용할 수 있습니다.

네트워크 양자화 탐구의 이 기초적인 시기는 오늘날의 거대한 기술 세계를 가득 채우는 정교한 기술과 하드웨어 특화 최적화를 발견하는 길을 밝혔습니다. 줄어든 정밀도 연산의 실현 가능성과 혜택을 시연함으로써, 이 초기 연구는 신경망 응용의 가능성을 확대시키고, 더 효율적이고 확장 가능한 AI 시스템을 개발하기 위한 강력한 방법을 제공했습니다. 오늘날, 우리가 다양한 플랫폼에서 널리 통용되는 AI 통합의 선도자로 서 있는 것은 이 선구적인 노력의 유산이 더욱 중요합니다. 이 노력은 모델 압축과 양자화를 통한 효율적인 계산의 잠재력뿐만 아니라, 신경망 설계 및 최적화에서 혁신을 지속적으로 불러일으켰습니다.

## 알렉스넷 시대 이후의 양자화

2012년에 출시된 알렉스넷의 저자들은 데이터 이용 가능성과 계산 하드웨어의 주요 발전이 우연히 엮인 상황을 이용하여, ImageNet 대규모 시각 인식 챌린지(ILSVRC)에서 과거 최첨단 접근법의 성능을 능가하는 성과를 이루었습니다. 이 역사적인 성공을 가능케 한 두 가지 중요한 요소는 다음과 같습니다: 1) 프린스턴 대학의 Fei-Fei Li 및 그녀의 팀이 세곅 최초의 대규모 취합 이미지 데이터셋을 제공하고, 2) 게임 산업 수익을 토대로 한 GPU 기술의 재정적 발전이 우연히도 딥러닝의 행렬 연산을 가속하는 데 필요한 동시 계산 유형을 지원하는 하드웨어를 생산하는 것입니다.

<div class="content-ad"></div>

주어진 이 성급한 상황에서, Alex Krizhevsky와 그의 팀은 6230만 개의 매개변수로 구성된 상당한 합성곱 신경망(CNN)을 훈련시켜 경쟁자들을 능가하며 정확도에서 10%의 우위를 차지했습니다. 이것은 신경망 연구에 있어 수적 PR 순간을 표시하고 "딥 러닝 혁명"으로 자주 지칭되는 지속적인 관심과 자금 풍요한 시기를 시작했습니다. 그러나 회복된 신경망은 빠르게 예전 적의 문제점인 하드웨어 제한에 부딪혔습니다. GPU 가속 훈련의 현저한 이점에도 불구하고, AlexNet의 저자들은 하드웨어 제약이 접근법의 성공에 한계를 가하고 결과가 더 좋아질 가능성이 높다고 인정했습니다. 연구 커뮤니티는 모델 압축의 미수렴 가능성을 인식하고 행동에 나섰습니다. 이 CNN 중심 기간 동안 얻게 된 정보들은 서로 다른 유형의 네트워크 구성 요소들 사이의 민감도 수준에 대한 강한 기반을 제공하여 향후 트랜스포머에 대한 조사를 위한 강력한 기초를 마련했습니다.

사실, AlexNet이 세계를 뒤흔들기 전에 이미 신경망을 엣지에서 배치할 욕망이 들려왔습니다. Vanhoucke 등의 2011년의 중요한 연구는 x86 CPU에서의 신경망 가속화를 탐구했습니다. AI 커뮤니티가 GPU에 투자할 것인지 아니면 전통적인 CPU로부터 더 많은 성능을 추출할 것인지에 대한 논쟁의 시기에 작성된 이 논문은 Intel 및 AMD CPU에서의 신경망 작업을 최적화하는 데 중요한 안내를 제공했습니다. AlexNet이 도입한 GPU 우위 시대 이전에, Vanhoucke 등은 SIMD 명령어와 메모리 정렬 기법을 포함한 정밀한 최적화를 통해 CPU의 잠재력을 자세히 소개했습니다. 이 최적화 기법을 사용하여 저자들은 상당한 성능 향상을 이룩하고 CPU 하드웨어에서의 신경망 효율적인 훈련 및 배포에 대한 곧 나올 연구의 기초를 마련했습니다.

AlexNet의 성공 이후 CNNs은 적층 연구의 급속히 확장되는 작물의 새로운 토양이 되었습니다. 연구자들은 다양한 유형의 네트워크 레이어를 양자화하는 세심한 연구를 펼치며 제공할 수 있는 다양한 민감도 수준과 장점을 씻겼습니다. 예를 들어, CNNs의 대부분의 FLOP는 합성곱 레이어에서 발생하기 때문에 그것을 양자화하는 것이 속도 향상을 가장 많이 제공합니다. 그러나 이러한 레이어들은 특징 추출에 매우 중요한 매개변수를 포함하고 있어 변경에 특히 민감합니다. 반면에, 완전 연결 레이어는 압축하기가 훨씬 쉽지만, 그렇게 하는 것은 대부분 저장 공간 크기 측면에서 유리하며 전체 계산 그래프에 대한 기여가 적습니다.

저장 공간 전용과 완전 한 효율 향상의 기법 사이의 차이뿐만 아니라, 후자 그룹에서는 훈련과 추론 모두 가속화하는 기법과 추론만 가속화하려는 기법 사이에도 명백한 차이가 있습니다. 이 기간 동안 QAT 개념이 탄생했으며, 많은 기술들은 훈련 중에 시뮬레이션된 양자화를 사용하도록 선택하지만, 다른 사람들은 네트워크 양자화의 뿌리에 더 가까이 머물며 훈련과 추론 중에 고정 소수점 또는 정수만 산술을 사용하여 엣지에서의 최종적인 신경망 개발을 추구했습니다.

<div class="content-ad"></div>

이러한 다양한 CNN 압축 방법 중 양자화를 통한 CNN 압축에 대한 두 가지 초기 예시로 Denton 등의 2014년 "효율적인 평가를 위해 합성곱 네트워크 내에서 선형 구조를 활용" 방법은 합성곱 레이어에서 매트릭스 인수분해를 적용하여 PTQ 또는 QAT 프로시저로 계산 효율성을 개선하고, Gong 등의 2014년 "벡터 양자화를 사용한 깊은 합성곱 네트워크 압축"은 QAT 환경에서 다양한 벡터 양자화 방법을 사용하여 완전 연결 레이어를 압축하여 저장 공간 최적화를 달성하는 데 초점을 맞추며, 제품 양자화의 뚜렷한 우월성을 강조했습니다.

본 섹션에서는 AlexNet에 의해 시작된 CNN 지배 시대 중 양자화 분야가 역동적으로 발전하는 과정을 관찰하게 될 것입니다. 성장의 형성 기간 동안 QAT, 혼합 정밀도 양자화, PTQ, 그리고 1 또는 2 비트까지의 극단적 양자화가 오늘날 대형 모델 시대의 이러한 기법의 성숙화로 이어지도록 새롭게 정의된 연구 분야로 자리잡을 것입니다.

## CNN의 양자화 인식 훈련

AlexNet 시대 이후, QAT는 양자화 연구의 독립적인 영역으로서 본격적으로 형성되었습니다. 이전 시대에는 거의 모든 양자화 작업이 상대적으로 작은 네트워크 때문에 가중치 양자화를 최적화하기 위해 훈련 프로세스를 사용했었습니다. GPU 가속 훈련에서 유발된 인공 지능 성장 후에도 모델은 여전히 상당한 자원을 사용하여 훈련할 수 있었으며, 양자화된 네트워크 재훈련의 필요성을 피하는 문제는 주로 모바일 배치 및 데이터 접근/개인 정보 보호 우려에서 비롯되었습니다. 그럼에도 불구하고, 이 시대에 PTQ의 가치가 명확해지고 두 분야 간의 구분이 명확해지면서, 양자화 연구의 주된 부분은 QAT 기반의 접근에 머물렀습니다. 이 섹션에서는 CNN 시대에 QAT 접근법의 발전을 살펴보겠습니다.

<div class="content-ad"></div>

2014년 말에 시작된 Courbariaux 및 다른 연구자들의 연구에서 "곱셈 연산자는 딥 뉴럴 네트워크의 디지턜 구현에서 공간과 전력을 많이 소비하는 산술 연산자이다" 라고 발견했으며, 이러한 연산의 정밀도를 줄여 효율성을 증대하기 위해 연구를 진행했습니다. 다른 연산자들의 비용이 비트 폭에 비례해 제곱으로 증가하는 반면에 곱셈-덧셈기 연산의 다른 연산자들인 가산기와 누산기는 선형으로 증가하므로 상대적으로 저렴합니다. 특히, 그들의 연구는 "반 정밀도 부동 소수점 형식을 사용해도 신경망의 훈련에 별다른 영향이 없다"고 보여졌습니다. 더욱이 저자들은 "매우 낮은 정밀도만으로 훈련된 신경망을 실행하는 데 뿐만 아니라 훈련까지 할 수 있다"고 발견했으며, 현재까지의 "매우 낮은 정밀도"는 10비트 곱셈을 의미하며, 이는 이 분야가 얼마나 빠르게 변화하는지를 보여주는 상징입니다.

2015년 IBM의 Gupta 및 다른 연구자들이 “Deep Learning with Limited Numerical Precision”를 발표하면서, 확률적 반올림을 사용한 16비트 고정 소수점 산술을 통해 딥 뉴럴 네트워크를 훈련하는 기존 방법을 소개했습니다. 이 방법은 숫자를 가장 가까운 양자화 지점 중 하나로 반올림하는 확률이 그 두 지점 간의 근접성에 비례하는 확률적 반올림을 사용하여 소프트웨어를 개선했습니다. 이 반올림 방법은 양자화 오차의 기대값(편향)을 제로로 만드는 잡음을 도입함으로써 가장 가까운 반올림 방식을 능가합니다. 풀 정밀도 부동 소수점 연산에 의존하는 기존의 QAT 방법과 달리, Gupta 및 다른 연구자들의 전략은 모든 훈련 연산을 낮은 정밀도에서 실행하는 것을 포함합니다. 고정 소수점 산술의 사용은 더 빠르고, 공간과 전력을 효율적으로 사용하는 연산 장치를 사용할 수 있게 해주며, 저자들은 하드웨어 공동 설계를 탐구하기 위해 혁신적인 에너지 효율적 하드웨어 가속기를 시연했습니다. 중요한 점은 확률적 반올림의 사용으로 심한 기울기 값도 훈련 과정에 기여하도록 보장하여 기울기 근사 방법인 Straight-Through Estimator (STE)와 같은 방법에 대한 의존을 줄입니다.

한국어로 번역했습니다. 계속해주시면 다양한 주제에 대해 도와드릴게요!

<div class="content-ad"></div>

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_6.png" />

"Deep Compression"에서 나온 결과는 놀라운데요, 해당 방법으로 CNN을 원본 크기의 1/35 미만으로 압축하면서 베이스라인 참조와 동등하거나 더 높은 정확도를 보여줍니다. 그러나 중요한 점은 연구된 AlexNet과 VGG 구조가 성능을 극대화하기 위해 의도적으로 초매개변수화되었다는 것을 기억하는 것입니다. 두 구조 모두 매개변수 밀도가 높지만 비교적 민감하지 않은 완전 연결 레이어를 갖고 있습니다. 이 방법은 주로 모델의 저장 공간 효율성을 향상시키는 데 초점을 맞추고 있지만 작은 저장 공간은 가속 작업을 의미하기도 합니다. 가중치를 저장하고 가져오기 위한 작업량이 적어지고, 따라서 메모리 대역폭 요구 사항도 줄어듭니다. 특히 모델 크기가 충분히 작아져서 SRAM(Static Random Access Memory)에 저장될 수 있게 되면 DRAM(Dynamic RAM)과 SRAM 사이를 왔다갔다 하는 것보다 더 효율적입니다. 게다가 저자들은 ‘효율적 추론 엔진 (EIE)’ 개념을 소개했는데 이는 가지치기로 인한 희소성을 활용하기 위해 설계된 하드웨어 가속기로, 이에 대한 논문이 곧 발표될 예정입니다.

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_7.png" />

2017년 초, Zhou 등의 Incremental Network Quantization (INQ) 접근 방식이 Deep Compression에서 보이던 압축 수준을 능가했습니다. 저자들은 가지치기와 양자화를 결합하여 Huffman 코딩을 사용하지는 않았지만, AlexNet에 대해 53배의 압축률을 달성하면서 top-1 정확도를 잃지 않았으며, 놀라운 89배의 압축을 달성했지만 손실은 최소한 (`1.5%)을 유지했습니다. 이들의 전략은 네트워크 가중치의 일부를 점진적으로 양자화하고 나머지 정밀도 가중치를 재훈련하여 인도된 오차를 보상하며, 모든 가중치가 양자화될 때 까지 반복하는 것입니다. 가중치는 0 또는 2의 거듭제곱(음의 거듭제곱이라고 생각할 수 있음)이어야 합니다. 저자들이 설명한대로 이 전략의 이점은 “원래의 부동소수점 곱셈 연산을 FPGA와 같은 전용 하드웨어에서 더 저렴한 이진 비트 시프트 연산으로 대체할 수 있다”는 것입니다. 이를 위해 이들은 가변 길이 인코딩을 사용하는데, 1비트는 제로 값을 나타내고 남은 비트는 주어진 비트 폭과 스케일링 요인에 대한 가능한 양자화 값을 인덱싱하는 코드 워드를 나타냅니다. 이들의 방법은 5비트 정밀도로 FP32 AlexNet 성능 기준을 약간 초과하며, 아래 차트에서 확인할 수 있듯이 3비트까지 동등한 정확도를 보여줍니다. INQ에 대한 코드는 GitHub에서 이용할 수 있습니다.

<div class="content-ad"></div>

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_8.png" />

2017년 말, Google의 Jacob 및 동료들이 휴대용 장치 CPU에서 효율적인 정수 전용 추론을 가능하게 하는 데 초점을 맞추었습니다. 저자들은 AlexNet 및 VGG와 같이 고의로 과잉 매개변수화된 모델을 사용하여 모델 압축 기술을 벤치마킹하는 것은 쉬운 대상을 만든다고 주장하며, 대신 MobileNets를 사용하여 접근 방식을 테스트하기로 결정했습니다. 이러한 콤팩트 모델은 이미 매개변수 효율성을 극대화하도록 설계되어 있기 때문에 쉽게 압축할 수 있는 "죽은 무게(dead weight)"가 적고, 이들의 매개변수는 더 민감하게 변조됩니다. QAT의 형성 작업으로 고려된 Jacob 및 동료들의 접근 방식은 가중치 및 활성화를 8비트 정수로 양자화하고, 보다 정밀성이 더 필요한 편향을 32비트 정수로 양자화합니다. 그들의 방법은 훈련 중에 부동 소수점 산술을 사용하며, QAT에 대한 시뮬레이션 양자화 사용의 초기 예로서의 역할을 합니다. 저자들은 SIMD 하드웨어에서 순수한 산술보다 성능이 떨어지는 경향이 있는 조회 테이블을 필요로 하는 양자화 체계를 피하고, 대신 가중치를 정수 공간으로의 아핀 변환으로 대체합니다. 저자들은 QAT 방법을 보완하기 위해 훈련된 모델을 정수 전용 하드웨어에서 변환하고 실행하는 프레임워크를 함께 설계하며, 실제 엣지 하드웨어에서의 효율 향상을 증명하는 많은 이전 작업보다 한 걸음 더 나아갑니다.

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_9.png" />

지금까지 본 기술들은 모델의 계층을 균일한 정밀도 수준으로 양자화했습니다. 이는 하드웨어 가속화를 위한 최적 조건이며, 특히 저전력 하드웨어의 엣지에서는 더욱 중요합니다. 하지만 이전의 가지치기 탐구에서 배운 것처럼, 일부 네트워크 계층은 다른 것들보다 민감도가 낮아 변경에 덜 민감하므로 성능에 영향을 미치지 않으면서 더 강력하게 압축할 수 있습니다. 그래서 혼합 정밀도 양자화 접근방식은 네트워크 구성요소에 다양한 수준의 압축을 적용하고(일반적으로 계층별로), 그들의 민감도에 기초하여 메모리 풋프린트를 더 작게 만들고, 엣지에서 모델 운영의 데이터 전송 및 전력 비용을 감소시킵니다. 다음 섹션에서는 민감도 분석의 익숙한 주제가 수치 정밀도의 변수 할당에 영향을 미치는 Neural Network 구성 요소 전반에 걸친 모델 압축을 극대화하기 위한 양자화를 안내할 것입니다.

<div class="content-ad"></div>

## 혼합 정밀도 양자화의 부상

양자화로 인한 조각의 변동에 대한 네트워크 레이어 간 민감도 수준을 고려하기 위해, 각 네트워크 구성 요소의 민감도에 따라 정확도 수준을 맞추는 혼합 정밀도 양자화는 깊은 신경망의 양자화를 통해 가능한 압축 수준을 극대화하는 인기 있는 방법이 되었습니다. 혼합 정밀도 설정의 방대한 검색 공간은 네트워크 레이어 수와 지수적으로 증가하기 때문에 도전적입니다. 또한, 레이어 별 양자화와 세분화의 최적 순서를 찾는 데 목적을 두는 방법의 경우, 복잡성이 조합적으로 증가합니다. 이에 따라 연구자들은 깊은 신경망을 위한 최적 혼합 정밀도 설정의 검색과 선택을 자동화하기 위해 다양한 효과적인 알고리즘을 제안해왔습니다. 이는 무차별 탐색의 불가능성을 피하는 데 도움이 됩니다. 앞으로 살펴볼 것은 신경 구조 탐색(NAS), 강화 학습 (RL), 2차 해선 정보 및 기타 유형의 솔버를 활용하여 이 문제를 해결하기 위해 연구자들이 제안한 다양한 알고리즘들이 놀라운 결과를 산출하며 양자화를 통한 효율성 향상이 가능한 새로운 수준을 확립하고 있다는 것입니다.

2018년 말, Wu 등이 "Differentiable Neural Architecture Search (DNAS)를 통한 ConvNets의 혼합 정밀도 양자화" 방법을 발표했습니다. 이들의 접근 방식은 모든 레이어에 대한 모든 가능한 정밀도 설정을 포함하는 완전한 미분 가능한 슈퍼 네트워크 안에 서브넷을 정의하는 네트워크 아키텍처 매개변수 θ 세트를 생성합니다. θ 매개변수는 이 서브넷의 그래프 내 각 엣지를 샘플링하는 확률을 제어하며 경사하강법을 통해 직접 최적화할 수 있습니다. 이 기술을 사용하여 저자들은 몇몇 레이어에서 가중치를 극단적으로 압축(일부 레이어에서는 1비트까지)한 모델을 생성하였는데, 이 모델들은 완전한 정밀도 기준선을 능가할 수 있었습니다. DNAS 방법은 21.1배 작은 공간과 103.9배 낮은 계산 비용을 가진 ResNet 모델을 생성했는데, 이 모델들은 완전한 정밀도 모델과 동등한 성능을 발휘했습니다. 저자들은 이 방법이 다른 네트워크 파라미터화에도 확장 가능한 일반 아키텍처 탐색 프레임워크임을 언급했지만 이는 향후 작업으로 남겨두었습니다.

![image](/assets/img/2024-06-22-QuantizingtheAIColossi_10.png)

<div class="content-ad"></div>

2018년 Wang 외 (2018)의 "HAQ: Hardware-Aware Automated Quantization with Mixed Precision" 논문은 계산 효율성을 위해 프록시 메트릭스 (예: FLOPs)의 사용을 배제하고 대신 하드웨어 시뮬레이터에서의 신호를 사용하여 최적의 혼합 정밀도 설정을 찾기 위해 강화 학습 (RL) 알고리즘에 입력하는 방식을 택했습니다. 그들의 접근 방식은 지능적인 모델 압축의 한계에 도전하지만, RL 정책을 훈련하여 주어진 네트워크 아키텍처 및 하드웨어 장치에 대한 올바른 혼합 정밀도 설정을 예측하는 것에 따라 복잡성, 계산 비용 및 일반화 부족과 관련된 약점을 겪고 있습니다.


![그림: 2024-06-22-QuantizingtheAIColossi_11](/assets/img/2024-06-22-QuantizingtheAIColossi_11.png)


2019년에는 Hessian AWare Quantization (HAWQ) 논문이 혼합 정밀도 양자화에 대한 두 가지 주요 도전 과제를 해결했습니다. 각 네트워크 레이어의 최적 정밀도 수준을 결정하는 지수적 탐색 공간 및 이러한 레이어 간 최적의 QAT 순서를 결정하는 계승 복잡성은 깊은 신경망에서 이러한 값들의 무차별적인 탐색을 불가능하게 만듭니다. 저자들은 둘째로, 2차 헤시안 정보의 상위 고유값이 감도 분석을 제공하여 올바른 양자화 수준과 네트워크 레이어 간의 미세 조정 순서를 안내하는 것을 시연했습니다. 이는 LeCun 외 (1989)의 Optimal Brain Damage에 기반을 둔 가지치기 접근 방법과 유사합니다. 여기서 헤시안 정보는 네트워크 구성요소의 중요성(즉, 감도)을 측정하는 데 사용되며, 큰 값은 특정 네트워크 구성 요소의 가지치기 또는 양자화가 성능에 더 큰 영향을 줄 것임을 나타냅니다. HAWQ는 2비트 가중치와 4비트 활성화를 사용하여 DNAS의 성능을 넘어서며, 이로 인해 더 높은 전반적인 압축성을 달성했습니다.

2019년 HAWQ로부터 7개월 후, Dong 외가 HAWQ-V2를 발표하여 이전 연구에서 식별한 세 가지 주요 한계를 해결했습니다: 1) 감도 분석을 위해 상위 고유값만 사용하여 헤시안 스펙트럼의 나머지 부분을 무시한 것, 2) 상대적인 레이어별 감도 측정만 결정했으므로 수동 정밀도 할당이 필요한 것, 3) 활성화에 대한 혼합 정밀도 양자화를 고려하지 않은 것. 첫 번째 문제에 대해, 저자들은 모든 헤시안 고유값의 평균을 레이어별 감도의 우수한 측도로 결론지었습니다. 둘째로, 저자들은 정확한 레이어별 비트 정밀도를 자동으로 선택하기 위해 파레토 프론티어 기반 방법을 제시했습니다. 세 번째로, 저자들은 "혼합 정밀도 활성화 양자화에 대한 헤시안 분석을 확장"합니다. 이러한 조정으로 HAWQ-V2는 CNN 양자화에서 새로운 최첨단 벤치마크를 설정했습니다.


<div class="content-ad"></div>

2020년 말, HAWQ 저자들은 세 번째 버전인 HAWQ-V3를 발표했습니다. 이 작업은 이전의 방법을 개선하여 네트워크 작업의 모든 부분에 정수 연산을 보장하였습니다. 배치 정규화 레이어와 잔여 연결을 포함한 이전에는 정확도를 유지하기 위해 float32로 유지되던 부분들도 정수만을 사용하도록 변환하여 경량 기기에서 일반적으로 사용되는 정수 전용 하드웨어에 배포 할 수 있도록 했습니다. HAWQ-V3는 층별 비트 정밀도를 결정하기 위해 "정수 선형 프로그래밍(ILP) 문제를 사용하는 새로운 하드웨어 인식 혼합 정밀도 양자화 공식"을 사용하며, 이를 통해 "모델의 변동과 제약(예: 메모리 풋프린트 및 지연 시간) 사이의 균형을 유지"합니다. 이 접근 방식은 최강의 사용 가능한 완전 정밀 베이스라인의 성능을 넘어서는 8비트 정수 추론 모델을 생성하며, "무료 점심" 압축을 보여주며 4비트 정밀도까지 고정한 상태로 높은 정확도를 유지합니다.

![이미지](/assets/img/2024-06-22-QuantizingtheAIColossi_12.png)

이 섹션에서 다루는 기술들은 감도 분석을 기반으로 한 층별 정밀도 할당 조정의 힘을 보여주며, 감도가 적은 층을 더 공격적으로 양자화하고 민감한 층에서 더 높은 정밀도를 유지하는 것을 허용합니다. 그러나 엣지 디바이스에서 혼합 정밀도 양자화 체계를 구현하기 위해 더욱 어려운 작업일 수 있다는 점을 강조해야 합니다. 따라서 HAWQ-V3 결과에서 강력한 고정 정밀 벤치마크를 볼 수 있어 안심스럽습니다. 다음 섹션에서는 훈련된 완전 정밀 CNN에 대한 양자화를 수행하는 기술에 대해 논의할 것이며, 이는 나중에 논의할 LLMs의 양자화를 위한 선행 작업으로 매우 관련이 높습니다.

## CNN의 사후 훈련 양자화

<div class="content-ad"></div>

알고 계신 분은 CNN 시대의 양자화 섹션에서 대부분의 작품이 QAT 범주에 속한다는 것을 알게 될 것입니다. 이 기간 동안 연구된 모델들은 양자화 설정에서 쉽게 세밀 조정할 수 있었기 때문입니다. 그런데, 신경망 크기가 급격히 증가하기 전에도 PTQ의 실용적 이점에 이미 주목하고 있었던 연구자들은, 양자화 모델 개발자들이 원본 훈련 데이터에 접근할 필요 없이 모델을 중요한 시간과 자원을 재훈련하는 데 소요되는 시간과 자원을 절약할 수 있다는 PTQ의 약속에 이미 열렬한 반응을 보이고 있었습니다. 따라서 2019년경 PTQ 연구에 대한 타이밍 적인 관심이 높아졌고, 이는 아직 다가올 대형 언어 모델에 중점을 맞춘 연구를 위한 환영받는 기초를 마련했습니다.

크리슈나무르티는 2018년 중반에 CNN 양자화와 관련해 중요한 백서를 발표했습니다. 그들의 접근 방식은 가중값의 채널별 비대칭 균일 양자화와 활성화 값의 레이어별 고정 정밀도를 8비트로 유지하면서 정확도를 기준선 수준의 2% 이내로 유지합니다. 저자는 신경망의 가중치만 8비트로 양자화하는 것은 저장 용량을 압축하는 간단한 방법이지만, 효율적인 추론을 가능케하기 위해서는 활성화도 양자화해야 하며, 이를 위해서는 네트워크 레이어 전체의 활성화의 동적 범위를 계산하기 위해 보정 데이터를 사용하여 올바른 레이어별 양자화 매개변수를 발견해야 하는 점을 관찰했습니다. 아래 차트에서 저자는 다양한 CNN에서 레이어별 및 채널별 가중치 양자화 체계가 미치는 영향을 비교했습니다. 왼쪽에 있는 효율 지향적인 MobileNets보다 오른쪽에 있는 크고 매개 변수가 과도하게 많은 CNN이 레이어별 양자화 매개변수의 낮은 세분화에 더 수용적임을 주목하세요.

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_13.png" />

2018년 10월, Banner 등의 "빠른 배포를 위한 합성곱 신경망의 후 훈련 4비트 양자화" 논문은 PTQ의 사용성을 8비트 미만의 정밀도로 확장하는 데 초점을 맞췄습니다. 그들의 접근 방식은 감내 가능한 성능 하락과 함께 4비트 데이터 무료 혼합 정밀도 PTQ를 효율적으로 달성합니다. 이를 위해 저자들은 신경망 분포가 평균 주변에 종 모양을 이룬다는 지식을 활용하여 자신들의 양자화 체계를 튜닝하여 텐서 수준에서 평균 제곱 양자화 오차를 최소화하도록 한 것으로, 재훈련의 필요성을 피할 수 있게 했습니다. 양자화 공간으로의 지식 이전을 보다 잘 허용하기 위해 저자들은 1) 정수 양자화에 대한 제안된 분석 클리핑 기술(aciq)을 사용하여 활성화 텐서 이상치를 최적의 포화점에 따라 잘라내어 스펙트럼의 더 밀도 높은 영역에서 라운딩 오차를 줄였습니다. 2) 채널별 최적의 비트 할당을 분석적으로 결정하여 주어진 채널에 대한 최적의 양자화 단계 크기를 그 채널 범위의 2/3 제곱에 비례하도록 찾았으며, 3) 양자화 후 가중치에 도입된 편향을 보상하기 위해 간단한 편향 보정 방법을 제안하여 채널별 평균 및 분산의 예상 변화를 양자화 매개변수에 반영했습니다.

<div class="content-ad"></div>

ACIQ 방법론은 작은 보정 세트에서 네트워크 활성화의 통계 분석을 요구하기 때문에 교육 데이터에 액세스하지 않아도 되지만, 실행 중에 만날 분포를 대표하는 보정 세트를 보장하는 것이 중요합니다. 그렇지 않으면 양자화 매개변수가 잘못된 분포에 과적합될 위험이 있습니다. 또한 채널별 비트 폭의 사용은 하드웨어와 소프트웨어가 믹스드 프리시전을 지원할 수 있게끔 조정되어야 하므로 실제 응용 프로그램에 많은 문제를 일으킵니다. 그렇지 않으면 양자화된 네트워크를 실행하는 것이 비효율적이거나 불가능할 수 있습니다. 그러나 네트워크 구성 요소의 최적 비트 폭을 직접 계산하는 폐쇄형 분석 솔루션의 정식화는 양자화 연구에서 중요한 이정표입니다. 더 나아가 편향 보정 매개변수에 대한 폐쇄형 PTQ 솔루션 및 이러한 매개변수를 기존 계산에 효율적으로 흡수하는 접근 방식은 또 다른 중요한 기여입니다. Banner et al.의 방법 코드는 GitHub에서 이용 가능합니다.

![image](/assets/img/2024-06-22-QuantizingtheAIColossi_14.png)

Nagel et al.의 2019년도 “Weight Equalization과 Bias Correction을 통한 데이터 없는 양자화” (DFQ)는 보정 데이터, 세밀 조정 또는 하이퍼파라미터 조정이 필요하지 않은 데이터 없는 PTQ에 대한 혁신적인 접근 방법을 소개했습니다. 저자들은 가중치를 조정하여 양자화에 “쉽게 적용 가능하도록” 만들기 위해 척도를 적응시키고, 양자화로 인해 도입된 편향을 보정하기 위한 방법을 제안했으며, 그들의 방법이 QAT의 보조 전처리 단계로 사용될 수 있다고 언급했습니다. 위의 Krishnamoorthi 및 Banner et al. 방법과 달리 각 채널에 대한 양자화 매개변수를 저장해야 하는 것을 필요로 하지 않는 DFQ는 그 층의 각 채널에 대한 적합성을 극대화하는 값을 결정하여 각 층의 가중치 텐서에 대해 단일 척도 및 오프셋 값을 저장합니다. DFQ는 ReLU 활성화 기능의 척도 동질성을 이용하고, 스케일링과 유도된 편향을 다음 층으로 흡수하여 수학적으로 전체적으로 등가관계를 유지합니다. 저자들은 활성화 양자화에 대한 보정 데이터의 필요성을 교정 데이터 없이 모델에서 보존된 배치 정규화 통계를 사용하여 해당 층에서 예상하는 양자화 오차, 그리고 층 활성화에 도입된 편향을 보정하기 위해 해당 예상 오차를 층 편향 매개변수에서 차감하는 방법으로 대비했습니다. 저자들이 명시적으로 이 용어를 사용하지는 않지만, DFQ는 양자화 연구에서 보정 데이터가 필요하지 않은 제로샷 양자화(ZSQ)의 설립 작업으로 볼 수 있습니다.

![image](/assets/img/2024-06-22-QuantizingtheAIColossi_15.png)

<div class="content-ad"></div>

Choukroun et al.의 2019 OMSE 방법은 커널별 양자화 매개변수를 찾아 양자화된 가중치/활성 텐서와 원본 간의 평균 제곱 오차(MSE)를 최소화합니다. 이는 최초의 4비트 양자화를 달성하는 PTQ 접근법으로, 정확도 손실을 최소화했습니다(상위 1 ImageNet 분류의 3% 감소). 저자들은 가장 효율적인 대칭 균일 양자화를 사용하기로 결정하여 옵셋 사용으로 인한 추가 계산을 절약했습니다. 주어진 커널에 대한 양자화로 인한 MSE와 스케일링 요소 사이의 관계는 비볼록적이기 때문에 저자들은 최적 값들을 찾기 위해 선 탐색 방법을 사용했습니다. 민감한 네트워크 레이어의 표현력을 유지하기 위해 혼합 정밀도를 사용하지 않기 위해, 저자들은 이러한 "핵심" 레이어를 여러 저정밀 텐서를 사용하여 나타내는 것을 제안했지만, 이 방법의 복잡성으로 인해 이를 작은 텐서에만 사용하는 것이 필요하며, 이 경우 CNN의 경우 컨볼루션 커널이 가장 민감한 구성 요소이기 때문에 작동이 잘 되지만, 큰 중요한 구성 요소가 있는 아키텍처에서는 잘 확장되지 못할 수 있습니다.

2020년 초, HAWQ 논문의 저자들은 이전의 최첨단 ZSQ 벤치마크를 이긴 ZeroQ를 발표했습니다. 그들의 접근 방식은 새로운 파레토 프런티어 기반 방법을 통해 혼합 정밀도 양자화를 달성했으며, 이 방법은 수동 검색 없이 최적의 혼합 정밀도 설정을 자동으로 결정합니다. 훈련 또는 보정 데이터에 접근을 요구하지 않고, ZeroQ는 배치 정규화 레이어의 통계를 일치시킨 합성 데이터 세트를 생성하고, 이 데이터에 의해 생성된 활성을 사용하여 양자화 매개변수를 보정하고 레이어별 민감도 분석을 수행합니다. 이 민감도 값은 파레토 프런티어 선택 프로세스에 공급되어 특정 모델 크기나 원하는 정확도 수준에 대한 최적 설정을 찾습니다. 저자들은 대부분의 PTQ 작업이 일반적으로 복잡한 작업을 고려하지 않고 이미지 분류 정확도만 평가한다는 사실을 지적하여, 자신들의 방법이 더 어려운 물체 감지 작업에서도 성능을 유지한다는 것을 증명합니다. ZeroQ는 오픈 소스이며 계산 효율이 뛰어나며, 네트워크 양자화에 대한 진입 장벽이 낮습니다.

그 후, 2020년에 AdaRound의 저자들은 반올림 접근법이 이전의 양자화 작업에서 우월했음에도 불구하고 최적이 아닌 라운드 스킴이 우세했음을 지적했습니다. 그들은 입력 데이터와 작업 손실의 특성을 모두 고려하는 반올림 효과를 분석하기 위한 프레임워크를 제안했으며, 반올림을 계층별 이차 제한 이진 최적화(QUBO) 문제로 공식화했습니다. 이들은 태스크 손실에 대한 가중치 변동의 변화를 둘째 순서 테일러 급수 전개를 사용하여 근사했으며, 다른 작품들이 민감도를 측정하기 위해 헤시안 정보를 사용하는 것과 같은 방식을 사용했습니다(Optimal Brain Damage (OBD)의 경우 1989년). Optimal Brain Surgeon (OBS)와 마찬가지로, 그들은 비대각 성분 헤시안 값을 깊게 이론적으로 분석하여 그들의 방법을 발전시켰습니다. 그들은 단순한 반올림 접근법을 헤시안의 대각 성분만 고려하는 것으로 동일시하여, 변동이 작업 손실에 대한 기여에 어떤 상호 의존성도 없다고 가정하여, 따라서 개별 크기의 감소만 중요하다고 주장합니다(즉, 반올림). 그러나 가중치 변동의 효과는 상호 관련되어 있으며, 비대각 정보가 중요하므로, 변동 조합이 실제로 손실에 유용할 때를 신호합니다. AdaRound는 소량의 레이블되지 않은 데이터만을 필요로하며, 1% 베이스라인 성능 내에서 ResNet 모델을 4비트로 압축하여 CNN에 대한 PTQ 최첨단 기술을 설정했습니다.

AdaRound의 저자들은 명료하게 보여주기 위해 Gupta et al.(2015)의 확률적 반올림 방법을 사용하여 ResNet의 첫 번째 레이어에 대해 100가지 무작위 변형 세트를 생성하고, 이를 가장 가까운 반올림 변형과 비교했습니다. 100개의 샘플 레이어 변형 중 48개가 반올림에 비해 더 나은 성능을 제공했으며, 일부는 10% 이상의 정확도 향상을 제공했습니다. 이는 양자화 공간에 많은 더 나은 솔루션이 있음을 보여주며, PTQ의 정확성을 높이기 위해 이러한 솔루션을 타겟하는 방법이 있어야 한다는 명확한 신호를 제공합니다.

<div class="content-ad"></div>

위의 차트를 보면, 두 번째 차수 테일러 급수 항과 반올림 후 정확도 감소 간의 명확한 상관 관계를 볼 수 있습니다. 이는 양자화로 인한 작업 손실을 최적화하는 좋은 프록시라는 것을 나타냅니다. 그러나 네트워크 가중치 간의 교차 레이어 상호작용을 무시하더라도, 이차 헤시안은 여전히 대규모 네트워크 레이어에 대해 계산 비용이 지나치게 많이들어간다. 아래 결과는 AdaRound의 W4A8 구성이 FP32 기준선과 W8A8 DFQ 성능에 근접할 수 있는 것을 보여줍니다. 그러나 이 비교에서 중요한 점은, AdaRound가 DFQ 처럼 데이터 무료 또는 "제로 샷" 접근 방식이 아니라는 것입니다.

2020년 중반에 AdaRound 후 며칠 후만에, AdaQuant은 더 나아가서 ResNet50을 사용하여 1% 미만의 ImageNet 상위 1 정확도 저하를 유지하면서 가중치와 활성화를 4 비트로 양자화할 수있는 새로운 PTQ 방법을 선보였습니다. 저자들은 AdaRound의 한계를 우회하는데 작은 보정 세트를 사용하여 가중치와 활성화 각 레이어에 대해 한 번에 한 층씩 채널 단위로 최소한의 계층별 양자화 MSE를 최소화합니다. 양자화 프로세스가 배치 정규화 통계에 내재된 편향과 분산을 도입한다는 것을 강조하며, 제안된 배치 정규화 튜닝 (BNT) 접근 방식으로 이러한 통계를 재추정하여 성능 저하를 복구하기로합니다. 저자들은 AdaQuant의 혼합 및 고정 정밀도 변형 모두를 제공하며, 해당 코드는 GitHub에서 이용할 수 있습니다.

<div class="content-ad"></div>

이 섹션에서는 AlexNet 시대 이후 PTQ 방법에 대한 주목이 높아졌다는 것을 보았습니다. 이 시기의 PTQ 주요 동기는 보통 가장자리 배포와 데이터 개인 정보 보호에 대한 우려였지만, 여기에서 다룬 작업은 앞으로 급격히 증가할 모델 크기에 따른 PTQ 접근 방식에 대한 중요한 기초를 제공했습니다. CNN 시대를 마치기 전에 우리가 다뤄야 할 더 이상의 연구 동향 하나가 있습니다. 이것은 엣지에서 작동하고자 하는 욕망에 의해 동기부여되었던 또 다른 변화이며, 이것은 신경망을 1비트(이진 네트워크) 또는 2비트(삼진 네트워크)로 극단적으로 양자화하는 추세였습니다.

## 극단적 양자화: 이진 및 삼진 네트워크

극단적 양자화란  ≤2 비트로 압축하는 것을 의미하며, 이는 삼진(2비트)이나 이진(1비트)을 의미합니다. 모델을 이러한 정밀도 수준으로 효율적으로 압축하는 능력에는 명백한 장점이 있습니다. 모델은 FP32 대비 16–32배 작아지므로 더 적은 전력을 사용하여 더 작은 엣지 장치에 배포하고, 계산 속도를 최적화하기 위해 가치 있는 칩 실용면적을 절약할 수 있습니다. 신경망의 정밀도를 이렇게 낮추면 표현 능력이 상실되어 동일하게 극한의 도전과 함께 따라옵니다. 그러나 네트워크 계산에서의 비용이 막대하던 곱셈-누적(MAC) 연산은 이진 및 삼진 네트워크에서 훨씬 더 효율적인 덧셈/뺄셈 및 비트 시프트 연산으로 완전히 대체될 수 있어 잠재적 이득이 급격하게 증가하고, 이에 대한 도전에 동기를 부여하게 됩니다. 이 섹션에서 우리는 CNN 시대 중 극단적 네트워크 양자화 분야에서 발전한 흥미로운 결과를 확인하고, 낮은 비트 네트워크의 탁월한 효율성으로 인해 왜 매혹적이고 자주 인용되는 분야가 되었는지 알아볼 것입니다. 더불어, 이진 네트워크가 등가 비트 수를 사용하여 이진 산술의 모든 이점을 유지하며 성능을 초월할 수 있도록 앙상블을 형성할 수 있다는 점을 살펴볼 것입니다. 먼저, 우리는 2014년으로 되돌아가서 낮은 정밀도 네트워크에 대한 이해를 천천히 쌓아 보겠습니다.

극단적 양자화의 선구적인 연구로서, 서울대학교의 황 및 성(2014)에 의한 연구 "Weights +1, 0, and -1을 사용한 고정점 피드포워드 딥 신경망 설계"는 성능 손실이 미미한 삼진(2비트) 가중치와 3비트 활성화 신호를 얻는 QAT 접근 방식입니다. 반면, 저자들은 편향은 성능을 보존하기 위해 8비트 정밀도로 할당되어야 한다는 사실을 관찰했습니다. 양자화 임계값은 원래 텐서와 양자화된 텐서 간의 MSE를 최소화하기 위해 초기에 선택되고, 그런 다음 각 계층에서 초기 제안을 연구하여 네트워크 출력 오류를 최소화하는 최적값으로 조정하기 위해 각각 계층별로 철저한 검색이 수행됩니다. 마지막으로, 양자화된 가중치는 양자화를 처리하기 위해 수정된 고정점 역전파 방식을 사용하여 세밀하게 조정됩니다. 저자들은 극단적 신경망 양자화 분야에서 기초적 선례를 만들었지만, 완전 탐색의 사용은 당시 작은 모델 크기의 예로 보여지며, 이후 커지는 모델 크기에 대한 확장 가능한 솔루션이 필요해질 것임을 시사합니다.

<div class="content-ad"></div>

2015년에 Courbariaux 등이 "BinaryConnect" 알고리즘을 제안했습니다. 이름에서 알 수 있듯이 이들의 방법은 가중치를 -1 또는 1로 제한하는 이진화된 네트워크를 생성합니다. 저자들은 노이즈 가중치, 즉 확률론적 반올림 방식을 사용하여 이산화된 가중치가 "확률적 경사 하강법(SGD)과 잘 호환된다"고 언급하며, Gupta 등의 2015 논문에서 본 스토캐스틱 반올림에 관한 연구도 있습니다. Hwang & Sung의 방법과 같이 저자들은 양자화된 가중치에서 발생한 손실에서의 기울기를 적용하여 전체 정밀도 가중치(별도로 저장된)를 업데이트하며, 양자화된 가중치는 각 전방향 통과마다 전체 정밀도 가중치의 현재 상태에서 유도됩니다. 저자들은 결정론적 이진화(가중치의 부호를 단순히 취함)와 확률론적 이진화(가중치 크기를 활용하여 확률을 유도) 모두가 규제 메커니즘으로 잘 작동함을 보여주며(드롭아웃과 유사), 비 규제된 전체 정밀도 기준선과 비교하여 낮은 최종 검증 오류와 더 느린 수렴 곡선을 보여줍니다. 이러한 결과는 매우 흥미로우나 당시 기준에 따르면 CIFAR-10 데이터 집합이나 연구에서 훈련 중인 CNN이 특별히 복잡하다는 점을 고려해야 합니다. 따라서 현재 이러한 결과가 더 깊은 네트워크나 더 어려운 작업을 사용하여 유지될지 여부는 명확하지 않습니다. BinaryConnect의 코드는 GitHub에서 사용할 수 있습니다.

![image](/assets/img/2024-06-22-QuantizingtheAIColossi_18.png)

동일년도에 Lin 등의 "Multiplications이 적은 신경망"은 BinaryConnect의 작업과 코드베이스를 향상시켜 원본 저장소의 포크에 이진화된 가중치 및 활성화를 훈련시키기 위해 활성화 중 이진화되는 것을 가능하게 한 "Binarized Neural Networks: Training Neural Networks with Weights and Activations Constrained to +1 or −1”(BNN)으로, 저자들은 다시 결정론적이 vs 확률론적 이진화를 비교하며, 확률적 이진화가 이론적으로도 경험적으로도 우수함을 관찰하고, 훈련 중에 랜덤 비트를 생성할 필요가 없어진다는 단순함으로 결정론적 이진화가 매력적이라고 생각합니다. 따라서 저자들은 훈련 중에 활성화에만 확률적 이진화를 사용하는 최상을 지향합니다. 더 나아가, 신경망에서 배치 정규화(BN) 레이어에 필요한 비용이 많은 곱셈에 대한 접근도 다루어, 비용이 많이 드는 연산을 피하고 비트 시프트 연산을 통해 네트워크 연산의 이진화 성질을 유지하는 방법을 제안합니다. 이에 더해, 저자들은 아담 옵티마이저에 의해 보편적으로 사용되는 곱셈을 피하기 위한 비용이 많이 드는 곱셈을 피하는 방법을 제안하며, 이러한 근사치에 의해 도입된 노이즈가 훈련 결과에 영향을 주지 않음을 보여줍니다. CIFAR-10 데이터 집합의 기본 CNN를 다시 한번 테스트한 결과, 저자들은 가중치와 활성화를 이용하여 신경망을 훈련하는 데 강력한 결과를 보여줍니다. Binarized Neural Networks (BNNs)의 훈련을 위한 코드와 사용자 정의 GPU 커널이 함께 제공됩니다.

<div class="content-ad"></div>

![이미지](/assets/img/2024-06-22-QuantizingtheAIColossi_19.png)

2016년 Rastegari 및 다른 연구자들의 XNOR-Net 논문은 대규모 ImageNet 데이터셋에서 CNN 이진화를 테스트한 첫 번째 논문으로, BinaryConnect 및 BNN (aka BinaryNet)이 이러한 규모에서 잘 작동하지 않음을 보여주었습니다. 저자들은 가중치 이진화의 새로운 방법을 도입하여 BNN 결과를 이상 준 16.3%로 개선하였습니다. 가중치 스케일링을 통합하는 이진화 방법을 도입하며, 주어진 가중치 행렬에 대한 최적 스케일링 요인을 그것의 절대값의 평균으로 확인했습니다. BinaryConnect 및 BNN과 유사하게, 저자들은 단순화된 전방 통과를 통해 계산된 기울기를 사용하여 별도의 정밀 가중치 세트를 업데이트하며, BN과 Adam에 대한 시프트 기반 근사화를 사용하지 않았습니다. 그들의 Binary-Weight-Network (BWN) 설정으로부터 XNOR-Net 설정으로의 성능 하락은 ImageNet과 같은 복잡한 작업에서 활성화 신호를 이산화하는 어려움을 강조하지만, 이러한 표현을 이진화하는 것은 특히 야심찹니다. 그럼에도 불구하고, 가중치 전용 이진화가 기본 CNN과 같은 성능을 달성할 수 있다는 사실은 “무료 점심” 압축에 대한 또 다른 유망한 기회인 것으로 보입니다. 또한, XNOR-Net 버전이 신호 전체 이진화로도 합리적인 성능을 달성할 수 있는 사실은 설득력이 있습니다. XNOR-Net의 코드도 GitHub에서 제공됩니다.

![이미지](/assets/img/2024-06-22-QuantizingtheAIColossi_20.png)

2016년 Li 및 다른 연구자들의 “Ternary Weight Networks” (TWN)은 처음부터 삼진 네트워크를 훈련하는 QAT 접근 방식입니다. 그들의 양자화 방법은 학습된 레이어별 스케일링 요소와 각각의 가중치 텐서 당 평균 크기의 3/4로 설정된 삼진화 임계값을 사용하여 양자화된 가중치와 원시 가중치 간의 유클리드 거리를 최소화하려고 합니다. 저자들은 삼진 네트워크가 “이진 정밀도 대응물보다 더 나은 표현 능력을 보여준다”고 관찰하고, 이 개념을 이진 대 삼진 3x3 합성 필터의 예를 통해 증명했습니다. 이러한 실험은 이 추가적인 표현 능력이 MNIST, CIFAR-10, ImageNet 및 Pascal VOC 객체 감지 작업을 포함한 다양한 작업에서 유용하다는 것을 증명했습니다. 아래 결과에서 우리는 삼진 네트워크의 이 추가적인 표현 능력이 ImageNet 및 Pascal VOC 작업과 같이 더 어려운 작업에서 특히 유용하다는 것을 볼 수 있습니다. 이 복잡성이 커지면 위에서 보았던 덜 복잡한 모델과 작업에서의 매우 유망한 이진화 결과에서 느껴던 희망론이 지속되지 않을 수도 있다는 신호일지 모릅니다.

<div class="content-ad"></div>

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_21.png" />

2016년 말, 후, 요, 그리고 궉이 "Loss-aware Binarization of Deep Networks" (LAB)를 발표했습니다. 이 연구는 이전 방법들이 비트 이진화 과정을 비용 함수에 대한 직접적인 영향을 최적화하지 않았던 빈 연구 분야를 채웠습니다. 비용 함수를 최소화하는 방식으로 네트워크를 이진화하기 위해 저자들은 Adam 옵티마이저에서 포착된 2차 그래디언트 정보를 사용하여 대각 헤시안 근사치를 효율적으로 추출하기 위해 근사 뉴턴 알고리즘을 해결합니다. 저자들은 자신들의 방법이 "넓고 깊은 네트워크에 대해 보다 견고하다"고 보여주었으며, 또한 Recurrent-Neural Networks (RNNs)를 사용한 NLP 작업으로 연장되었습니다. 그 후 2018년 초, 후와 궉은 LAB 알고리즘을 확장하여 "Loss-Aware Weight Quantization of Deep Networks" (LAQ 또는 삼항 경우의 LAT)를 생성하여 제안된 방법이 LAB가 제공하는 이진화보다 더 개선된 결과를 보여 주었습니다.

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_22.png" />

2017년에 동 등이 확률 양자화 알고리즘을 제안했습니다: 하나의 층 또는 필터의 양자화 비율에 반비례하게 양자화 오류에 대해 네트워크 요소/필터의 일부만 양자화하여 각 훈련 단계마다 따로 업데이트하고 완전 정밀 가중치에서 별도로 업데이트합니다. 훈련이 진행되면 결국 모든 가중치가 양자화되고 결과적으로 저비트 네트워크는 해당하는 BWN 및 TWN 모델보다 훨씬 뛰어난 정확도를 유지합니다.

<div class="content-ad"></div>


![INQ](/assets/img/2024-06-22-QuantizingtheAIColossi_23.png)

이전에 CNNs 섹션에서 본 2017 증분 네트워크 양자화(INQ) 논문은 2015년 Deep Compression에 의해 설정된 모델 압축의 이전 최고 수준을 초과했습니다. 또한, 이들의 방법이 삼진 네트워크를 작성하는 데의 타당성을 조사했습니다. 아래 차트에서, ImageNet 분류 작업에 학습된 ResNet-18에서 TWN보다 INQ 방법이 더 강력함을 확인할 수 있습니다. TWN의 36.18% 상위 1위 오류율을 2% 이상 내리는 것을 볼 수 있습니다.

![ABC-Net](/assets/img/2024-06-22-QuantizingtheAIColossi_24.png)

나중에 2017년 Lin 등의 '정확한 이진 합성곱 신경망으로'라는 논문에서는 이진 네트워크의 표현력 부족을 극복하기 위해 여러 세트의 이진 가중치 또는 활성화를 결합하여 더 정확하게 고정밀 값을 나타냈습니다. 3-5개의 가중치 베이스 및 5개의 이진 활성화를 사용함으로써 ImageNet에서의 정확도 저하를 5%로 낮출 수 있다고 보여주었습니다. 저자들은 이것이 더 많은 비트를 필요로 하지만 더 복잡한 산술 연산자 사용을 피하기 때문에 고정비트 고정소수점 표현 대신에 선호되는 방법임을 강조했습니다. 이들의 연구는 이진 신경망이 ImageNet에서 완전 정확도 기준선과 유사한 성능을 처음으로 달성한 것을 나타냅니다. 그러나 이들의 솔루션은 기준 BNN 복잡성을 O(k * l)만큼 높이기 때문에 효율성에 상당한 손실이 있습니다.


<div class="content-ad"></div>

![2024-06-22-QuantizingtheAIColossi_25.png](/assets/img/2024-06-22-QuantizingtheAIColossi_25.png)

2018년 Zhu 등의 '이진 앙상블 신경망: 네트워크 당 더 많은 비트 또는 비트 당 더 많은 네트워크?' (BENN) 논문은 BNN의 한계가 이진화 프로세스의 추가 최적화를 통해 해결할 수 없다고 주장했습니다. 이는 이진 공간의 표현 능력 부족에서 비롯된 것이라고 밝혔습니다. 저자들은 이진 네트워크를 사용할 때 예측 분산을 줄이고 잡음에 대한 강건성을 향상시키기 위해 부스팅 또는 배깅을 사용하여 여러 BNN 앙상블을 만들었습니다. 실험 결과 앙상블 분류기의 통계적 특성이 개선되고 성능이 급격하게 향상되었음을 보여줍니다. 이러한 앙상블을 실행하는 추가 복잡성은 O(k)이며 ABC-Net의 실행 효율성을 l의 배로 향상시키면서 ImageNet에서 그것을 크게 앞섰다. 또한 앙상블을 병렬화할 수 있기 때문에 솔루션은 O(1)의 추가 복잡성을 가질 수 있으며, 기준이 되는 BNN과 동일한 속도로 실행될 수 있습니다.

![2024-06-22-QuantizingtheAIColossi_26.png](/assets/img/2024-06-22-QuantizingtheAIColossi_26.png)

이 부분에서는 2012년 AlexNet의 대성공 이후 시작된 대형 CNN의 등장으로 인해 극단적인 신경망 양자화에 대한 관심이 폭발적으로 증가했습니다. 이 시대의 모델링 능력의 높은 정점을 에지 장치에 저전력 하드웨어로 배치하고 싶다는 강력한 충동은 매혹적이었습니다. 이것이 많은 딥러닝의 실용적인 응용 분야가 존재하는 곳입니다. 이 부분의 대부분 방법은 사전 훈련 된 가중치의 양자화 없이 로우-비트 네트워크를 처음부터 훈련하는 것을 볼 수 있습니다. 이는 그들의 탁월한 효율성으로 완전히 양자화된 방법으로 더 쉽게 처리될 수 있습니다. 나중에 우리는 이런 극단적인 양자화 방법론의 이 인상적인 시기가 미래의 앞길을 이룰 재발견의 유망한 토양으로 성숙해 나갈 것임을 볼 것입니다.

<div class="content-ad"></div>

지금은 CNN 시대에 대한 장을 닫습니다. 이제는 AlexNet의 성공 이후 깊은 학습 분야로 인재와 자금이 대량으로 유입되면서 양자화 연구의 여러 독특한 분야가 형성되는 것을 목도하는 것을 보았습니다. 우리는 가중치 양자화를 세밀하게 조정하여 성능을 잃지 않고 압축 수준이 높아지는 QAT 접근 방식, 민감도 분석을 양자화 과정에 통합함으로써 새로운 수준의 압축을 달성하는 혼합 정밀도 기법, 재훈련 없이 8 또는 4 비트의 정밀도에서 기준 성능에 근접하는 PTQ 접근 방식(특히 ZSQ의 경우 보정 데이터를 사용하지 않음), 그리고 극도의 양자화 연구의 부상을 보았습니다. 이제 우리는 CNN 시대에서 2017년 트랜스포머 아키텍처의 성공으로부터 태어난 NLP에 대한 연구 관심의 물결로 초점을 옮깁니다.

# LLM 양자화

이제 우리가 양자화의 기능적 세부 정보와 역사에 익숙해졌으므로 오늘날의 대형 언어 모델(LLMs)을 양자화하는 논의를 진행할 수 있습니다. 가지치기와 마찬가지로, 대형 모델로 진입함에 따라 AlexNet의 성공 작위가 아닌 모델 훈련을 필요로하는 압축 기술을 적용할 희망은 대규모 피팅 이상의 회사를 제외하고는 희망이 점점 사라짐을 볼 것입니다. 따라서 우리는 PTQ의 더 가벼운 방법에 대한 연구 초점의 변화를 볼 것이지만, 대규모 환경에서의 고유한 도전에도 불구하고 연구 공동체의 독창성이 QAT의 혜택 활용 방법을 찾는 방법을 막지 않았음을 볼 것입니다. 이 섹션에서는 먼저 2017 논문 "Attention is All You Need"에서 트랜스포머의 발표 이후부터 2020년에 175억(몇난 파라미터) GPT-3의 방대한 출시로 점지된 LLM 시대에 발생한 양자화 노력을 검토합니다. 그런 다음 LLM 시대에서의 PTQ 기법의 확산을 검토한 후, LLM용 QAT 접근 방식으로 초점을 옮기고, 마지막으로 LLM의 극도의 양자화를 검토함으로써 조사를 마무리합니다. 이 섹션은 양자화에 대한 교육을 완료하여 다음 섹션의 구현 가이드로 나아가고, 우리 자신의 작업 흐름에서 신경망 양자화를 적용하기 시작할 준비를 마칩니다.

## 트랜스포머 초기 시대의 양자화

<div class="content-ad"></div>

지난 섹션에서 보았듯이, 컴퓨터 비전에서의 AlexNet의 성공은 효율적인 배포를 위해 CNN을 양자화하는 연구에 대한 관심 폭발을 일으켰지만, 양자화의 적용에 대한 연구는 몇 년 후에야 언어 모델에서 속도를 내게 되었습니다. 카탈리스트적 순간은 트랜스포머 아키텍처의 놀라운 성공이었습니다. 2020년 GPT-3의 출시와 함께 시작된 언어 모델 크기의 폭발적인 성장 이전에는 트랜스포머를 사용한 NLP의 더 합리적인 크기의 탐구가 이루어졌으며, 그러나 이러한 모델이 점점 커질수록 성능이 계속 향상되는 경향이 명확해지고 있었습니다. 여기서 우리는 트랜스포머 기반 언어 모델의 양자화 연구 형성기간을 검토하며, 트랜스포머의 출현과 수십억 개 매개변수 트랜스포머 네트워크의 부상 사이의 형성 기간 동안 발생한 양자화 연구를 살펴볼 것입니다. 이제 볼 것처럼 이 새로운 네트워크 아키텍처는 특히 낮은 비트 폭에서 양자화에 독특한 도전 과제를 제기했고, 연구자들은 신속히 이를 이해하고 극복하기 위해 노력했습니다.

2018년 말 Google이 발표한 중요한 양방향 인코딩 표현 트랜스포머(BERT)는 여전히 매우 영향력 있는 트랜스포머 기반 언어 모델입니다. BERT는 가려진 언어 모델링(MLM) 목적으로 학습하여 입력 토큰 이후와 이전의 정보를 고려하는 임베딩을 생성하는 방법을 학습하여 양방향 콘텍스트를 인코딩하는 방법을 학습합니다. 결과적으로 이러한 표현은 깊은 맥락 이해를 포함하며, 감정 분류 및 질문 응답과 같은 작업에 유용합니다. BERT는 인코더만 사용하는 트랜스포머 아키텍처의 변형을 사용하여 이러한 양방향 인코딩 표현을 생성하는 반면, OpenAI의 유명한 Generative Pretrained Transformer (GPT) 모델은 디코더만 사용하여 바이트-페어 인코딩 (BPE) 텍스트의 자기 회귀 모델링 작업을 수행합니다. 시퀀스의 이전 토큰만 고려하며 다음 토큰을 반복적으로 예측합니다. GPT-2 논문에서 이루어진 자가 회귀 디코더 전용 트랜스포머 및 그들의 미탐색 사전 훈련 데이터셋에 대한 잠재적 확장성에 대한 발견은 결국 2020년 175B GPT-3 거대한 모델의 출시를 영감으로 삼았지만, 우리가 보게 될 것처럼, 트랜스포머 양자화 연구는 이미 그때부터 이미 즐비하게 진행 중이었습니다.

UC 버클리의 Shen 등은 2019년 말에 Q-BERT를 발표했습니다. 이 방법은 HAWQ의 헤시안 기반 민감도 분석을 확장하여 교육 데이터 하위 샘플 전체의 평균뿐만 아니라 헤시안 스펙트럼의 분산을 고려하는 방식이었습니다. Q-BERT는 이 향상된 민감도 측정을 사용하여 계층별 혼합 정밀도 양자화 체계를 수립하고, 그룹 단위의 세분화를 사용하여 각 계층을 해당 비트 폭에 맞게 양자화한 후, 각 계층에 대해 자체 양자화 범위와 룩업 테이블을 가지는 하위 단위로 행렬을 분할합니다. 저자들은 이 방법을 사용하여 가중치 압축률을 13배, 활성화 크기를 4배 작게하고, 임베딩 크기를 4배 줄이면서 베이스라인 BERT에서 최대 정확도 감소율이 2.3%를 달성했습니다. 대부분의 QAT 기술과 마찬가지로 Q-BERT는 비가역적 양자화 함수를 통해 그레이디언트를 근사하기 위해 STE를 사용합니다.

혼합 정밀도를 사용하여 압축을 극대화하는 데 중점을 둔 Q-BERT와 대조적으로, Intel의 Zafrir 등이 2019년 말 동시에 발표한 Q8BERT는 모델과 활성화 사이에서 균일한 8비트 양자화를 적용하는 데 초점을 맞췄습니다. 이는 하드웨어 최적화 관점에서 더 유리하며, 혼합 정밀도 연산은 오버헤드가 추가되고 일반화된 하드웨어 가속에 적합하지 않기 때문입니다. 이 방법은 학습된 BERT 모델에 대한 QAT를 미세 조정 단계로 수행하여, 이전에 CNN 양자화 섹션에서 보았던 Jacob 등의 2017 논문을 기반으로 한 시뮬레이션 양자화 접근법을 사용하여 1% 이하의 최소 정확도 손실과 함께 4배의 압축을 달성합니다. 가중치의 스케일링 요소는 최대 절대 가중치 값에 대해 보정되고, 활성화의 스케일링 요소는 학습 중 누적된 지수 이동 평균에 기초합니다.

<div class="content-ad"></div>

2020년에 팬과 다른 분이 Quant-Noise를 소개했어요. 이 기술은 모델 압축률을 높이기 위한 QAT 기법으로, 훈련 중 각 순방향 패스에서 네트워크 가중치의 일부만 무작위로 양자화하여 가중치의 대부분이 STE 근사치에 의해 도입된 오차 없이 업데이트를 받게 합니다. 이렇게 하면 가중치의 값이 양자화된 부분의 영향을 줄이는 방식으로 더 정확하게 변화할 수 있어 시간이 지날수록 네트워크 가중치 전체에 QAT를 동시에 적용할 때보다 우수한 결과를 얻을 수 있어요. Quant-Noise는 다중 가중치를 단일 코드 워드로 함께 양자화하는 Product Quantization (PQ)의 사용을 탐구하며, 상대적으로 낮은 성능 하락으로 매우 높은 수준의 압축을 가능하게 합니다. 이 방법은 네트워크 구조에 의해 유도된 가중치 간의 상관 관계를 활용해요.

2020년에 토론토 대학교의 자데 분이 GOBO를 발표했어요. 이는 어텐션 기반 모델을 위한 사전 정의된 사전을 사용하는 PTQ 방법으로, BERT의 거의 모든 FP32 가중치를 정확도를 손상시키지 않고 3비트로 압축할 수 있게 합니다. GOBO 방법은 가우시안 분포 적합을 사용하여 이상값을 보전하고 나머지 가중치는 대표적인 FP32 센트로이드가 있는 소규모 세트(3비트의 경우 8)를 인덱싱하는 3비트 코드 워드로 저장합니다. 일반 하드웨어는 3비트 값에 직접 작업할 수 없기 때문에 GOBO 저자들은 양자화 방법을 보완하기 위해 효율적인 3비트 계산 가속을 가능하게 하는 혁신적인 하드웨어 아키텍처를 개발했어요. 이 가속화 이점은 전용 하드웨어를 사용해야 완전히 활용할 수 있지만, 3비트 양자화 모델의 감소된 메모리 풋프린트는 일반적인 하드웨어에서 메모리 저장 및 트래픽을 줄여 추론 대기 시간과 에너지 소비를 일부 개선할 것입니다. GOBO 방법은 'Deep Compression'에서 본 몇 개 대표값 (센트로이드)의 사전 내 Huffman 부호화된 가중치 저장을 영감으로 한 것이지만, 가중치 이상값을 양자화하지 않고 정확도를 크게 향상시키고, K-평균보다 9배 빨리 수렴하는 신속한 "센트로이드 선정 알고리즘을 사용합니다.

장과 다른 분의 2020 TernaryBERT는 지식 증류 (TinyBERT에서 영감을 받은)와 삼진화 양자화를 결합한 distillation-aware ternarization을 통해 full-precision과 동일한 크기의 선생님 모델에 학생 모델로서 삼진화된 모델을 취급하는 방식입니다. 그들의 증류 방법은 transformer 층의 임베딩 레이어, 출력 및 어텐션 점수, 소프트 교차 엔트로피를 사용하여 선생님과 학생 간의 MSE 최소화를 포함합니다. TernaryBERT는 full-precision 베이스라인과 비교 가능한 성능을 달성하면서 14.9배 작아졌어요. 저자들은 BERT 활성화에 대해 min-max 8비트 양자화가 가장 잘 작동한다고 발견했으며, 특히 초기 층에서 BERT 활성화의 분포가 음 값으로 치우쳐 있다는 점을 발견했어요. 그들의 QAT 프로세스는 가중치를 full-precision 모델에서 초기화하고, 양자화 함수를 통해 그레이디언트를 근사하는 STE를 사용합니다. 

2020년에 BinaryBERT는 BERT 양자화를 극단으로 가져가려고 하지만, 이진 BERT 모델은 고도로 불규칙한 손실 랜드스케이프 때문에 직접 훈련하기 어렵다는 것을 관찰했어요. 따라서 저자들은 반대로 반씩 줄어든 삼진 네트워크를 훈련하고, 자신들이 제안한 삼진 가중치 분할 방법을 통해 이를 이진 네트워크로 변환한 후 결과물을 미세 조정하여 BERT가 24배 압축되었을 때 성능 하락을 최소화합니다. 이 개념을 적응 분할을 포함하여 확장하여 중요한 레이어를 분할하고 민감하지 않은 레이어를 이진 형태로 기술함으로써 다양한 모델 크기 제약에 유연성을 줍니다. 대부분의 QAT 방법들처럼 BinaryBERT는 STE을 사용하여 훈련합니다.

<div class="content-ad"></div>

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_27.png" />

## 사후 훈련 양자화 (PTQ)에 대한 LLMs

이 기사를 읽는 많은 분들에게, 이것은 가장 관련성이 높은 연구 섹션일 것입니다. 여기서는 대부분의 사람들이 이들 사전 훈련된 거대 모델에서 사용할 수 있는 유일한 양자화 유형인 LLMs의 PTQ를 검토합니다. 마침내 LLM 양자화로 전환하면, 이 거대한 모델들은 일반적으로 FP16으로 훈련되므로 "전체 정밀도"의 정의가 이 시대에 FP16을 의미하게 되므로 중요합니다. FP32를 사용하면 성능 향상이 미미한 대신 미니멈한 스토리지 요구 사항이 두 배로 증가하기 때문에 FP16에서 훈련되고 있습니다. 그러므로 LLMs의 압축률을 논의할 때 무엇이냐면, 8비트 정수 양자화는 “전체 정밀도” 베이스라인 대비 메모리 풋프린트를 2배로 줄일 뿐입니다. 게다가, 양자화에 어려움을 겪는 이러한 규모의 네트워크는 드물지만 매우 중요한 outlier들이 활성화되어 나타난다는 점을 알게 될 것입니다. 그러므로 LLMs가 더 쉽게 압축할 수 있는 대형 CNNs 만큼 매개변수가 과다하다는 사실에도 불구하고, 이들의 특이점으로 양자화하기가 더 어려워집니다. 다행히도 연구 커뮤니티는 빠르게 문제를 진단하고 LLMs의 효율적이고 정확한 PTQ를 극복할 수 있는 공식을 제안했습니다.

2020년에 OpenAI에 의해 폐쇄 소스 175B GPT-3가 출시된 두 년 후인 2022년 중반, 가장 큰 오픈 소스 모델은 GPT-J 6B와 GPT-NeoX 20B였으며, 175B 규모의 OPT와 BLOOM 모델은 아직 공개되지 않았습니다. 이 기간에 Microsoft의 Yao et al.은 GPT-3 스타일 transformer 모델의 양자화에 대한 조기 조사인 ZeroQuant를 발표했습니다. 그들의 방법론은 가중치와 활성화에 대해 INT8 양자화를 사용하여 FP16 모델과 유사한 정확도를 달성할 뿐 아니라 효율성을 5.2배 높일 수 있었습니다. 저자들은 또한 덜 민감한 가중치를 레이어별 지식 증류(LKD) 접근법을 제안하여 훈련 데이터가 필요 없이 4비트로 더 압축할 수 있도록 하였습니다. 이로써 FP16 모델보다 3배 더 작은 메모리 풋프린트를 갖게 되었습니다. 크기가 큰 transformer 모델에 PTQ를 적용할 때 관찰된 성능 급격한 하락을 조사하기 위해 저자들은 레이어들 간에 발생하는 활성화(토큰)의 매우 동적 범위를 살펴보고, 레이어별 최솟값/최댓값에 의해 조절된 균일한 양자화 범위를 적용하면 이러한 분포의 밀집 영역에서 효과적인 표현력을 잃게 됨을 지적합니다. 마찬가지로, 가중치 행렬은 로우-테일 범위를 갖고 있어 소수의 균일 간격 양자화 수준에서 미세한 세부 사항을 잃게 될 것입니다. 아래 차트는 이러한 레이어별 특성을 나타내며, 이러한 범위를 균일한 그리드로 잘라낼 경우 많은 정보가 손실됨을 보여줍니다.

<div class="content-ad"></div>

이러한 범위의 분산을 다루기 위해 저자들은 가중치의 그룹별 양자화와 활성화 함수의 토큰별 양자화를 사용하기로 제안했습니다. 이들은 또한 이러한 대규모 트랜스포머 모델의 활성화 범위의 큰 분산을 고려하여 재보정 데이터 집합을 사용한 정적 양자화 설정에서 범위를 보정하는 것이 문제를 일으킬 가능성이 높다는 점을 지적했습니다. 그래서 그들은 추론 중에 동적으로 토큰별 최소/최대 범위를 보정하기로 선택했습니다. 토큰별 양자화에 따른 데이터 이동 오버헤드를 극복하기 위해, 저자들은 커널 퓨전 기술을 사용하여 최적화된 추론 백엔드를 구축했습니다. 이 기술은 각 양자화 오퍼레이터를 이전 오퍼레이터(예: 레이어 정규화)와 퓨전시킴으로써 작동합니다. 저자들은 LKD 방법론을 구성하여 매우 큰 모델의 지식 증류의 세 가지 제약을 해결하였습니다. 즉, 두 모델을 모두 메모리에 보관해야 하는 필요성, 학생을 완전히 교육해야 하는 필요성, 그리고 원본 훈련 데이터가 필요한 제약 등이 있었습니다. 이 문제들을 해결하기 위해, 저자들은 양자화 모델의 단일 레이어를 최적화하고, 양자화된 레이어와 대응되는 전체 정밀도 레이어를 통해 가짜 레이블을 생성하는 데 같은 선생님 활성화 집합을 사용합니다. 이렇게 레이어별로 생성된 가짜 레이블만 사용되기 때문에 LKD 프로세스에 레이블이 필요하지 않으며, 원래의 훈련 데이터를 사용할 필요가 없음을 보여주었습니다. ZeroQuant은 DeepSpeed 라이브러리의 일부로 공개되었으며, 이는 Hugging Face의 Transformers 라이브러리에 통합되어 있습니다.

2022년 Tim Dettmers와 그의 동료들은 LLM.int8(), 즉 GPT3.int8()을 소개하였습니다. 이는 ≥175B 파라미터 규모의 LLM에 대해 정확도를 보존하는 8비트 정수 PTQ 방법입니다. 먼저, 이들은 대부분의 특징들을 벡터별 양자화 정밀도를 사용하여 양자화하였습니다. 행/열 단위 내적 중에 각기 다른 정규화 상수를 사용하여 행렬 곱셈을 했습니다. 두 번째로, 저자들은 기존의 PTQ 방법이 ≥6.7B 파라미터가 포함된 트랜스포머에는 실패하는 이유는 이 규모에서 발생하는 변압기 계층의 극단적인 이상치의 증가 때문이라는 사실을 발견하였습니다. 이러한 이상치는 변경에 예민하여 제거하면 모델 성능이 저하됩니다. 따라서 저자들은 두 번째 단계로서 이상치를 별도로 처리하기로 선택하였고 혼합 정밀도 분해를 사용하여 이러한 이상치를 처리하고 8비트 양자화된 모델 성능을 수백 억 개의 파라미터까지 유지됨을 입증하였습니다. 이 코드는 bitsandbytes 라이브러리에 공개되었으며, 이는 Hugging Face 생태계에도 통합되어 있습니다.

<div class="content-ad"></div>

GPTQ은 가중치만 양자화하므로 비양자화된 활성화와 혼합 정밀도 상호작용으로 인해 곱셈 작업의 효율성 향상을 제공하지 않습니다. 그러나 감소된 메모리 풋프린트는 추론을 위해 필요한 GPU 하드웨어의 크기를 줄이는 데 중요합니다. 저자들은 오픈 소스 GPT-3 동등 버전인 OPT-175B를 처음으로 단일 A100 GPU에서 실행할 수 있었으며, Nvidia GPU에서 테스트된 GPU 커널의 릴리스를 통해 추론을 대략 4배 빠르게 할 수 있었습니다. GPTQ는 오픈 소스이며, Hugging Face를 포함한 여러 인기 있는 LLM 배포 프레임워크로 널리 채택되었습니다.

2022년 말 MIT(Massachusetts Institute of Technology)와 Nvidia 사이의 협업에서 SmoothQuant는 완전히 양자화된 활성화를 갖는 대규모 모델에서 LLM.int8()의 8비트 PTQ 성능과 일치하는 메서드를 보여주었습니다. 고정밀도 이상치를 유지하기 위한 필요성을 바이어스의 가중치로 이동시켜 높은 균일성과 양자화하기가 쉽다는 점에서 이 방법이 가능했습니다. 아래 다이어그램은 이 개념에 대한 직관적 시각적 참조를 제공합니다.

![다이어그램](/assets/img/2024-06-22-QuantizingtheAIColossi_29.png)

SmoothQuant의 저자들은 LLM에서 토큰별 양자화가 활성화 이상치와 부합하지 않기 때문에 거의 이익이 없다고 제안했습니다. 이들은 채널별 양자화를 사용하여 LLM 정확도를 대부분 쉽게 유지할 수 있음을 보여주었습니다. 그러나 채널별 양자화는 하드웨어 가속화된 INT8 일반 행렬 곱셈(GEMM) 커널과 호환되지 않기 때문에, 저자들은 예측 가능한 채널별 이상치 표현을 활용하여 이에 대응하는 가중치를 조정하여 이를 이상치 값을 줄이고 활성화 텐서를 양자화하기에 더 적합하게 만드는 방법을 사용합니다.

<div class="content-ad"></div>

SmoothQuant의 세 가지 구성 (O1-O3)이 테스트되었습니다. 이들은 모두 텐서별 가중치 양자화를 사용하지만 활성화를 양자화하는 방식이 다릅니다. O3는 활성화에 대해 텐서별 정적 양자화를 사용하여 스케일링 요소가 오프라인에서 보정된 가장 낮은 복잡성을 가집니다. O2도 텐서별 활성화 양자화를 사용하지만 실행시 통계를 사용하여 온라인에서 스케일링 매개변수를 보정하는 동적 양자화를 사용하여 성능을 향상시킵니다. O1은 보다 복잡한 토큰별 동적 양자화를 탐구하지만 O2보다 약간 더 나은 결과를 달성할 뿐입니다. SmoothQuant 방법에서 LayerNorm 및 SoftMax 레이어는 여전히 FP16에서 계산되므로 정수 전용이 아니며 8비트 미만에서는 작동하지 않습니다. 그러나 이것은 LLM의 양자화를 어렵게 만드는 특수성을 극복하는 중요한 진전을 나타냅니다.

중간 2023년에 ZeroQuant의 저자들은 ZeroQuant-V2로 돌아와 양자화 오차를 줄이기 위해 과도한 세분화를 증가시키는 Fine-Grained Quantization (FGQ) 접근법을 제안했습니다. 여기서 블록-k 양자화라고 불리는 블록-k 양자화, 가중치 행의 각 서브 벡터에 대해 스케일링 요소와/또는 제로 지점을 설정합니다. 또한 저자들은 층별 양자화 오차를 상쇄하기 위해 작은 학습 가능한 저랭크 행렬을 사용하는 Low-Rank Compensation (LoRC)를 적용합니다.

Lin 등의 중간 2023년 성명 "Activation-aware Weight Quantization for LLM Compression and Acceleration" (AWQ)는 가중치만을 대상으로 한 저비트 양자화 방법입니다. 저자들은 GPTQ가 매우 효과적이지만 교정 세트에 과적합될 가능성이 있어 LLM과 같은 종합적 모델에는 문제가 될 수 있다고 지적합니다. 모든 가중치가 동등하게 중요하지 않다는 것과 매우 중요한 네트워크 가중치의 0.1-1%를 양자화하지 않으면 양자화로 인한 성능 저하가 크게 감소한다는 것을 저자들은 지적합니다. 저자들은 중요한 가중치를 식별하기 위해 가중치 자체가 아닌 활성화 신호를 살펴보고 양자화 오차를 최소화하기 위해 채널별 스케일링을 적용합니다. 저자들은 "AWQ는 역전파나 재구성에 의존하지 않으므로 검교합 집합에 과적합되지 않고 LLM의 일반화 능력을 다양한 도메인 및 모달리티에서 잘 보존할 수 있습니다." 라고 언급합니다. 저자들은 이 일반화가 Vicuna와 같은 명령어에 튜닝된 LLM과 OpenFlamingo와 같은 다중 모달 LMs (LMMs)의 성능 유지에 중요하다는 점을 보여줍니다. 저들의 방법은 Llama-2-70B 모델을 64GB Jetson Orin AGX에 맞출 수 있게 하거나 13B 규모의 모델을 8GB RTX-4070 GPU에서 "초당 30개의 토큰으로 상호 작용하는 속도로 실행"할 수 있게 합니다. AWQ의 효과가 인기있는 오픈 소스 LLM 서비스 소프트웨어에서 널리 채택되었습니다. (실행 가이드에서 더 자세히 다룰 예정)

<div class="content-ad"></div>

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_31.png" />

2023년 중반, SqueezeLLM은 GPTQ와 AWQ의 성능을 능가했습니다. 저자들은 최적의 비트 정밀도 할당을 찾기 위해 민감도 기반의 비균질 양자화와 "이상값 및 민감한 가중치 값을 효율적인 희소 형식으로 저장하는" Dense-and-Sparse 분해를 제안했습니다. 3-bit 환경에서 SqueezeLLM은 다른 최신 PTQ 방법과 비교하여 복잡성의 증가를 절반으로 줄였습니다. 게다가 양자화된 모델은 FP16 기준보다 2.3배 빠른 추론 속도를 제공합니다. 대부분의 방법이 간단한 응용프로그램을 제공한다는 간단한 적용 사례에 의해 주도되는 다양한 입방체의 매개변수로 통제되는 균일 양자화를 사용한다는 점을 감안할 때, SqueezeLLM은 가중치 분포가 명확한 비균일 패턴을 보여준다고 지적하며, 비균일 양자화가 자연히 더 나은 표현을 제공할 것이라고 주장합니다. 더 나아가 저자들은 대부분의 작업이 가중치만 양자화하고 FP16에서 산술을 수행하기 때문에 균일 양자화의 장점이 결국 제대로 이해되지 않는다고하며, 표현 능력을 낮은 정밀도로 보존하는 이상값에 미치는 영향이 적은 비균일 양자화가 선호된다고 주장합니다. 게다가 저자들은 가중치 이상값을 효율적인 희소 표현으로 분해하고 격리시킴으로써 분포를 양자화하기 쉽도록 만들었으며, 이를 통해 양자화가 더욱 용이해졌습니다. SqueezeLLM의 코드는 GitHub에서 이용할 수 있습니다.

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_32.png" />

2023년 말에 Mobius Labs GmbH가 매우 효율적이고 정확한 제로샷 PTQ 접근방식인 Half-Quadratic Quantization (HQQ)을 오픈소스로 공개했습니다. 이 방법은 매우 낮은 정밀도까지 잘 작동하는 대형 LLaMA-2-70B 모델을 GPTQ보다 50배 빠르게 양자화하며 테스트한 GPU에서는 5분이 소요됩니다. 저자들은 GPTQ와 AWQ의 한계가 레이어 출력 간 오류를 최소화하기 위한 교정 데이터가 필요하다는 것이며, 이는 교정 세트에 과적합되어 계산 시간과 자원을 필요로 한다는 점을 지적합니다. 이를 피하기 위해 HQQ는 활성화가 아닌 가중치의 양자화 오류를 최소화하나, 희소성을 촉진하는 손실 함수를 사용하여 이상값의 영향을 더 정확하게 포착하며, Half-Quadratic 솔버를 사용하여 그룹-k 양자화 매개변수에 대한 최적 솔루션을 반복적으로 도출함으로써 솔루션을 닫힌 형태로 찾아내어 데이터 없이 두 하위 문제의 대안 최적화를 수행합니다. bitsandbytes의 인기 있는 데이터 없이 LLM.int8() 방법과 비교했을 때, HQQ는 꾸준히 복잡성이 낮은 모델을 생성합니다. 또한, HQQ는 GPTQ보다 50배, AWQ보다 약 25배 더 빠르지만, 결과는 4비트 미만의 정밀도를 사용할 때 특히 데이터 종속적인 방법보다 나은 또는 동등합니다. HQQ 코드는 오픈소스로 공개되었으며, 일부 사전 양자화된 모델은 Hugging Face hub에서 제공됩니다. Hugging Face 생태계 내에서 HQQ 모델을 사용하는 것은 간단하지만, 최적화된 vLLM 추론 엔진 내의 HQQ 통합은 본 작성 시점에서 "실험적"입니다.

<div class="content-ad"></div>

![원도수](/자원/그림/2024-06-22-QuantizingtheAIColossi_33.png)

![원도수](/자원/그림/2024-06-22-QuantizingtheAIColossi_34.png)

2023년 12월, SmoothQuant+가 4비트 균일 PTQ에서 최신 기술을 세웠습니다. 저자들은 AWQ의 한계에 대해 다루었는데, 이는 층 수에 비례하는 탐색 공간을 가지고 있으며, 오류 누적 문제를 "탐색 과정 중에 고려하지 않기 때문에 검색 속도가 느려지고 모델 정확도가 저하된다"고 합니다. 더 나아가, 가중치 양자화 손실은 활성화 이상치에 의해 증폭되며, 이들 값을 가중치 조정으로 평활화하면 전체 양자화 오류를 크게 줄일 수 있다고 주장합니다. 저자들은 인기 있는 vLLM 추론 엔진을 위해 사용자 정의 W4A16 커널을 제공하고, SmoothQuant+ 구현을 사용자가 사전 처리 단계를 필요로하지 않도록 설계하여 사용자가 Hugging Face 허브에서 직접 FP16 모델을 로드하고 모델이 GPU로 이동될 때 자동으로 양자화 프로세스를 적용할 수 있도록 했습니다. 아쉽게도, 이 작성 시점에서 SmoothQuant+ 알고리즘 코드는 아직 공개 GitHub 페이지에 등록되지 않았으며, vLLM 통합도 아직 온라인에 공개되지 않았습니다.

![원도수](/자원/그림/2024-06-22-QuantizingtheAIColossi_35.png)

<div class="content-ad"></div>

2024년 4월, Park 등이 그들의 LUT-GEMM 논문의 최신 버전을 발표했습니다. 이 작품에서 저자들은 가중치만 양자화하는 것이 가중치와 활성화 모두 양자화하는 것보다 주로 가중치에 의해 메모리 트래픽이 지배되고 활성화는 양자화에 민감하기 때문에 주어진 정확도 수준에서 더 높은 압축률을 가능하게 한다고 지적했습니다. 하지만 이에는 정수만을 사용하는 이점을 잃게 되고 곱셈 전에 가중치를 비양자화하는 과정이 필요합니다. 이를 해결하기 위해, LUT-GEMM은 양자화된 가중치와 양자화되지 않은 FP16 활성화 간에 직접 행렬 곱셈을 수행할 수 있도록 설계된 커널입니다.


![이미지](/assets/img/2024-06-22-QuantizingtheAIColossi_36.png)


LUT-GEMM은 XNOR-Net에서 사용된 바이너리 코딩 양자화(BCQ) 형식을 확장하였는데, 이는 간단한 산술 연산의 사용을 가능하게 합니다. BCQ는 원래 비균일 양자화를 위해 설계되었지만, 저자들은 편향 항목 추가를 통해 균일 양자화로 일반화됨을 입증했으며, 이는 표현 능력을 크게 증가시킵니다. 저자들은 가능한 하위 벡터 곱셈의 LUT를 구성하고, 실행 시간에 발생하는 하위 벡터를 인덱싱하여 생성하는 연산을 수행하는 대신 효율성을 크게 향상시켰습니다. 그들의 양자화 방식을 사용하여, 단일 GPU에서 GPTQ에 비해 2.1배의 추론 가속화 효과를 시연했습니다. LUT-GEMM은 강력한 MLC-LLM 추론 엔진에서 사용되는 기본 양자화 방식이며, 나중에 자세히 알아볼 것입니다.

이 섹션에서 우리는 PTQ의 유산이 LLM 시대에 실현되는 것을 보았습니다. 이러한 거대한 모델들은 훈련 비용이 매우 높으며, 그 결과 이전보다는 효율적인 원샷 또는 제로샷 양자화 접근 방식의 혁신이 필요합니다. 그에 따라 연구자들은 bitsandbytes(LMM.int8), GPTQ, AWQ가 특히 인기가 있어지고 최근 출시된 HQQ가 강력한 새로운 데이터 프리 대안을 제공했습니다. 실행 가이드에서는 이러한 양자화 알고리즘 중 어떤 것을 선택해야 하는지에 대한 비교 장단점을 검토할 것입니다. 하지만 먼저, LLM의 QAT를 탐험해야할 때가 왔습니다. 왜냐하면 QAT가 본질적으로 뛰어난 양자화 결과를 달성하기 때문에, 실제로 이러한 방법 중 일부가 얼마나 접근하기 쉬운지에 대해 기쁘게 놀라게 될지도 모릅니다.

<div class="content-ad"></div>

## LLMs의 양자화 인식 훈련 (QAT)

최종 연구 섹션에서는 LLMs에 대한 QAT 방법에 대해 검토합니다. LLaMA-2의 비용이 2천만 달러 이상 들었다고 하니, 우리는 여기에 참여해야 할까요? 여기의 일부 접근 방법은 우리 개인에게 접근하기 어려울 수 있지만, 가능한 것에 대한 보다 광범위한 이해를 위해 중요합니다. QAT가 양자화를 통합하여 효율적이고 저비트 모델을 생성하는 가장 효과적인 방법이라면, 수십 억 달러를 들여 오픈 소스 기반 모델을 훈련하는 기업들은 왜 이러한 기술을 자사의 출시 전략의 구성 요소로 사용하지 않아야 할까요? LLaMA-2 사용자 중 얼마나 많은 사람이 완전 정밀도 가중치를 사용하고 있을까요? 대규모 모델을 양자화에 더 잘 대응할 수 있도록 만드는 것이 더 좋지 않을까요, 대부분의 배포가 이를 사용할 것이라는 점을 알고 있기 때문에요? 이 섹션은 우리가 이러한 문제들에 대한 더 교육된 견해를 형성하는 데 도움이 될 수 있습니다.

Liu 등의 2023년 중반 "LLM-QAT"은 LLMs에서의 QAT 탐구의 첫 번째 시도였습니다. 저자들은 현재 최첨단 PTQ 접근 방식이 정확도를 8비트 미만의 정밀도로 보호하지 못한다는 점을 지적했으며, 낮은 정밀도에서 성능을 보존하기 위해 QAT가 필요할 것으로 생각되지만, 이전의 작업에서는 이미 알고 있는 이유로 LLMs의 QAT를 조사한 적이 없었다: 방대한 양의 데이터와 계산 뿐만 아니라, 조정된 명령어를 기반으로 한 LLMs의 훈련 과정을 복제하는 어려움과 같은 보다 세심한 이유들까지 있습니다. 이러한 도전을 극복하기 위해 저자들은 사전 학습된 모델의 생성을 사용하여 훈련 데이터로 사용하는 데이터가 없는 지식 증류 방법을 소개하여, 원본 훈련 데이터의 큰 하위 집합으로 훈련하는 것과 비교했을 때 출력 분포를 더 잘 보존하도록 합니다.

![물론 대체 텍스트](/assets/img/2024-06-22-QuantizingtheAIColossi_37.png)

<div class="content-ad"></div>

LLM-QAT 작성자들은 상대적으로 작은 100k개의 합성 샘플 세트가 양자화된 모델을 축소하는 데 충분하며, 합리적인 양의 컴퓨팅을 사용하여 이 작업이 수행될 수 있다고 발견했습니다. 그들은 각 생성 단계에서 가장 확률이 높은 토큰을 확률적으로 샘플링하는 것이 데이터에 노이즈를 추가하는 데 중요하다고 발견했습니다. LLM-QAT는 트랜스포머 양자화 이전의 대부분의 이전 연구와는 달리, 특히 긴 시퀀스에서 이점이 있는 KV 캐시에 저장된 중간 활성화 벡터의 양자화를 조사했습니다. 작성자들이 자신의 조사를 LLaMA 모델 ≤30B 매개변수로 제한한다는 사실은 QAT의 기본적 비용을 반영합니다; 그렇다고 해도, 저자들은 연구에서 다양한 혼합 정밀도 구성을 벤치마킹하여, 자신들의 방법이 낮은 비트 설정에서 GPTQ 및 SmoothQuant보다 LLM 성능을 유지하는 데 상당히 더 좋다는 것을 보여주었습니다. 그러나 더 높은 정밀도에서는 결과가 대부분 동등하며, 이는 고정밀도가 허용되는 경우 PTQ 접근 방식이 더 간단하므로 더 유리하다는 것을 나타냅니다. 그럼에도 불구하고, LLM-QAT가 훈련 데이터 없이 LLM을 효율적으로 낮은 비트 설정으로 다시 훈련하고 성능을 유지하는 능력은 매우 흥미롭습니다, 특히 LLM이 보다 매개변수 효율적으로 되는 상황에서. 코드는 GitHub에서 제공됩니다.

2023년에 Xi 등의 간단한 제목인 “4비트 정수로 트랜스포머 훈련하기”라는 논문은 모든 곱셈을 4비트 정수 산술로 처리하는 방법을 소개했습니다. 작성자들은 이를 위해 순방향 패스 중 활성화 중요 이상치를 처리하기 위해 제안한 Hadamard 양자화기를 사용하여 각 활성화 행렬의 블록 대각 Hadamard 행렬 변환을 양자화했습니다. 이 변환이 이점이 있는 이유는 이상치 정보를 인접 행렬 항목으로 퍼뜨려 숫자 범위를 줄이고 양자화할 수 있게 만든다는 것입니다. 역전파 중에 작성자는 활성화의 작은 기울기 행의 계산을 저장하여, 가장 정보가 풍부한 기울기를 낮은 4비트와 높은 4비트로 나누어 해당 세부 정보를 보존하기 위해 두 행을 사용하여 8비트 표현을 생성합니다. 이 방법을 사용하여 저자들은 현대 하드웨어에서 게인을 실현할 수 있기 때문에, 사용자 지정 숫자 형식을 필요로하지 않고, 최신 4비트 산술을 사용하여 트랜스포머를 정확하게 훈련했습니다. 작성자들은 자신들의 INT4 행렬 곱셈 연산자가 FP16 훈련보다 2.2배 빠르고 총 훈련 시간을 35.1% 줄였으며, 다양한 과업과 트랜스포머 모델에서 기본 성능과 거의 맞먹는 성과를 거두었습니다. 이 연구는 LLM 대신 BERT와 비전 트랜스포머(ViT)에 초점을 맞추었지만, 대규모 트랜스포머 모델의 저정밀 훈련에 있어서 주요 기준을 보여주기 때문에 이 부분에서 인용하는 것이 적절합니다. 또한 어떤 기법이 LLM에 적용될 때까지는 오직 시간문제일 뿐입니다. 저자들은 자신들의 코드를 GitHub에 공개했습니다.

유명한 2023년에 Tim Dettmers와 워싱턴 대학의 동료들은 QLoRA로 새로운 지평을 열었습니다. QLoRA는 효율적인 저랭크 조정 미세조정 기술을 사용하여 얼린 양자화된 4비트 LLM에서 기계적인 저랭크 행렬을 통해 그레이디언트를 역전파하여 단일 48GB GPU로 65B 모델을 24시간만에 미세조정하는 과정을 유지하면서 기준 FP16 성능을 유지했습니다. QLoRA는 LLM을 미세조정하기 위해 필요한 하드웨어 양을 크게 줄였으며, 이는 이 기술의 민주화에서 중요한 이정표를 세우고 있습니다. 이를 달성하기 위해 작성자들은 정규 분포를 양자화하는 데 이론적으로 최적인 새로운 4비트 NormalFloat(NF4) 데이터 유형을 사용하여, INT4 또는 FP4 유형보다 더 나은 경험적 결과를 달성했습니다. 저자들은 또한 양자화 매개변수도 양자화하는 이중 양자화의 사용을 조사하여, 1개 매개변수당 평균 0.37비트(65B 모델에서 약 3GB)를 절약했습니다. 저자들의 방법의 효율성을 강조하기 위해, 저자들은 다양한 명령 조정 데이터세트를 사용하여 1000개 이상의 모델에서 QLoRA를 철저히 시험했습니다. 저자들은 자신들의 QLoRA 방법을 사용하여 Guanaco 모델 패밀리를 훈련했습니다. LoRA의 임의 변형을 사용하는 주요 장점은 사전 훈련된 모델이 변경되지 않으면서, 미세조정이 모두 저랭크 어댑터 행렬에 완전하게 포착된다는 것입니다. 이는 이 adaptors의 여러 세트가 전체 모델 재훈련 없이 여러 용도에 대해 훈련될 수 있다는 것을 의미합니다. QLoRA로 미세조정하는 것은 Hugging Face Transformers를 통해 bitsandbytes 라이브러리를 통해 가능하며, 원래 QLoRA 리포지토리는 GitHub에서 사용 가능합니다.

![이미지](/assets/img/2024-06-22-QuantizingtheAIC

<div class="content-ad"></div>

## LLM의 극도의 양자화

최근에는 극도의 양자화가 LLM 연구에도 영향을 미치고 있습니다. 이전에 CNN 양자화 섹션에서 본 것처럼, 신경망은 바이너리 또는 터너리 가중치로도 놀랍도록 잘 수행될 수 있으며 메모리 트래픽과 계산 복잡성이 크게 감소합니다. 가중치가 훨씬 적은 비트를 차지하고 곱셈 연산을 덧셈과 뺄셈으로 대체할 수 있기 때문입니다. LLM의 극도의 양자화는 아직 어린 분야이지만, 최근의 연구에서는 이러한 방법론을 성숙한 방향으로 발전시킬 것을 확신시킬만한 흥미로운 결과를 보여주었습니다. 본 섹션에서는 저비트 LLM 교육의 미래를 예감할 수 있는 가능성을 살펴볼 것입니다.

2023년에 BitNet의 저자들은 LLM에서 사용할 수 있는 1비트 트랜스포머 아키텍처를 소개했습니다. nn.Linear 레이어 대신 사용할 수 있는 BitLinear 레이어를 도입하고 이진 가중치를 처음부터 훈련하여 완전 정밀성 베이스라인과 경쟁력 있는 성능을 달성하는 바람직한 결과를 얻었습니다. 이 때 결과로 나타난 트랜스포머들은 소비 전력이 훨씬 적게 필요한 연산을 사용하면서 완전 정밀성 버전과 유사한 스케일링 법칙을 나타냅니다. 활성화는 8비트로 양자화되며 옵티마이저 상태 및 기울기는 여전히 완전 정밀성으로 수행됩니다. 저자들은 구현이 FP16/BF16에서 작동하기 때문에 실제로 교육 가속화가 없다고 인정하지만, 전방향 및 역방향 통과를 가속화하기 위해 저비트 FP8 GEMM CUDA 커널을 사용할 수 있다고 제안하지만 이 작업을 미래에 미루기로 합니다.

<img src="/assets/img/2024-06-22-QuantizingtheAIColossi_39.png" />

<div class="content-ad"></div>

2024년에 공개된 BitNet b1.58에 관해 팔로우하고 있습니다. 이 버전은 삼중체 '-1, 0, 1' 가중치를 사용하는 게 새롭게 도입되었고, 1비트 BitNet 시스템에 영(0) 값을 추가하면서 작은 값들을 영(0)으로 클램핑하는 γ 임계값 매개변수를 조정했습니다. 우리가 삼중체 CNN에서 배운 대로, 가중치에 0 값을 추가하는 것은 운용 복잡성에 증가를 일으키지 않습니다. 왜냐하면 곱셈은 여전히 덧셈/뺄셈으로 대체될 수 있기 때문이지만, 이러한 접근은 가중치가 "특징 필터링"을 수행할 수 있도록 해 성능을 현저히 향상시킵니다. 다만, 가중치 당 비트 수가 1에서 2로 증가하는 비용이 듭니다. 어쨌든, 가중치가 작기 때문에 DRAM에서 SRAM으로의 전송이 쉽고 메모리 트래픽이 줄어듭니다. 저자는 낮은 커널 최적화를 위해 대칭 양자화를 사용하고 활성화를 8비트로 양자화하며 KV 캐시를 4비트로 양자화합니다. 이 접근을 통해 저자들은 기본 FP16 성능과 헷갈릴 정도의 perplexity 및 과제 성능을 일치시키며 삼중체 네트워크를 처음부터 훈련시켰습니다.

BitNet b1 (binary) 및 b1.58 (ternary) 방법의 코드 및 구현에 대한 자세한 내용은 교육 지침, 코드 및 FAQ PDF 파일을 참고하시기 바랍니다. 그러나 거기서 제공되는 코드는 추론에 사용할 저비트 커널의 세부 정보를 포함하고 있지 않습니다. 다행히 오픈 소스 커뮤니티는 이 GitHub 저장소를 개발하여 완벽한 구현, 사용자 정의 커널 및 pip 설치를 제공합니다. LLM의 극한 양자화로 나아가는 BitNet이 강력한 단계임을 강조하고자 합니다. 그러나 이러한 구현에서 이진화 및 삼진화는 완전히 활용되지 않고 있습니다. 왜냐하면 훈련 중에 여전히 반정밀도에서 곱셈이 수행되고 있으며, 추론을 가속화하기 위해 사용되는 사용자 정의 커널은 FP8입니다. 그러나 우리는 이전에 가중치를 이진화/삼진화하는 것의 가장 큰 이점은 행렬 곱셈이 훨씬 효율적인 정수 덧셈/뺄셈 연산으로 대체될 수 있다는 것이었음을 배웠습니다. 이것은 직접 더 빠른 계산으로 이어지지만, 이는 훈련이나 추론을 위해 여기서 탐구되지 않았으며, 미래 작업에 대한 미개척 영역으로 남아 있습니다.

아래는 BitNet b1.58의 이미지입니다.

![BitNet b1.58](/assets/img/2024-06-22-QuantizingtheAIColossi_40.png)

# 실무자를 위한 LLM 양자화 안내

<div class="content-ad"></div>

이 섹션에서는 워크플로를 최적화하기 위해 양자화를 실용적으로 구현하는 방법에 대해 논의하겠습니다. 우리가 알아본 대로, 양자화는 학습 중이나 모델 개발의 후처리 단계로 적용될 수 있으며 이는 모델 및 사용 사례에 따라 달라집니다. 양자화된 워크플로의 교육된 전문가가 되기 위해 먼저 사용할 수있는 현재의 도구 세트를 검토하고 그 강점과 약점을 살펴보겠습니다. 그런 다음 우리는 배운 내용을 활용하여 목표와 사용 가능한 방법을 조율하는 데 도움이 되는 의사 결정 트리를 개발할 것입니다.

트랜스포머 개발 및 추론을 실험하는 인기 있는 간단한 방법은 Hugging Face Transformers 라이브러리를 사용하는 것입니다(그들의 모델 허브와 함께, 이는 깊은 학습 모델을위한 GitHub 저장소와 같이 작동하여 모델 체크포인트를 쉽게 푸시하고 몇 줄의 코드로 다른 기기에서 사용할 수 있도록 끌어올릴 수 있습니다. 이는 파이썬 코드를 다룰 수있는 사람들에게는 놀라운 인터페이스이지만 모델을 사용하는 비코드 사용자 인터페이스 (UI)를 제공하지는 않으며, 이 라이브러리는 일반적으로 더 빠른 백엔드 서빙을 제공하는 최적화된 라이브러리로 백엔드 서빙에 더욱 효과적이지만 우리가 볼 것입니다. 그러나 훈련 측면에서, Hugging Face의 Transformers 라이브러리의 직관적 인터페이스를 통해 효율적인 양자화 훈련을 가능하게 하는 bitsandbytes 라이브러리의 통합은 모델 개발에 아주 강력한 도구로 만듭니다.

2019년 7월부터 Nvidia는 트랜스포머 모델의 추론 처리량을 최적화하기 위해 FasterTransformer 라이브러리를 제공하였으며 (원래 BERT에 중점을 둔), 이를 사용하여 기기용 TensorRT SDK를 백엔드로 사용했습니다. 그 후, 이 프로젝트는 TensorRT-LLM(aka TRT-LLM)으로 발전하여 파이썬 API가 PyTorch와 유사한 형태로 구축되었으며 GPTQ, AWQ를 지원하고 SmoothQuant 기술의 구현을 포함하고 있습니다. 이러한 라이브러리는 Nvidia 하드웨어 또는 Triton 추론 서버에서 추론을 최적화하기 위해 특별히 설계되었으므로 이를 사용하는 사람들에게는 매우 효과적이지만 일반적인 목적의 양자화 라이브러리는 아닙니다. 그럼에도 불구하고 Nvidia 하드웨어를 사용하는 다중 GPU 설정을 원하는 사람들에게는 적절한 선택일 수 있습니다. 라이브러리에는 많은 인기있는 오픈소스 모델의 미리 빌드된 버전이 포함되어 있지만 사용자는 API를 사용하여 사용자 지정 모델을 양자화할 수도 있습니다.

한편 Georgi Gerganov의 머신러닝 라이브러리(GGML)는 2022년 9월에 만들어져 Apple 장치에서 LLM 추론을 가속화하기 위해 설계된 순수한 C 라이브러리이며, 이후 지속적으로 발전해왔습니다. GGML은 구조화된 이진 모델 파일을 생성하여 다양한 하드웨어에서 최적화된 텐서 계산을 수행하는 데 사용할 수 있는 양자화를 사용합니다. 이 라이브러리는 특히 Apple 실리콘을 위해 특별히 설계되었지만 x86 아키텍처 및 GPU에서 추론 가속을 지원하도록 제공됩니다. GGML 라이브러리는 대표적인 llama.cpp 추론 라이브러리의 백엔드를 제공하며, 이는 다시 Ollama 및 LM Studio와 같은 프론트엔드 라이브러리를 위한 백엔드 지원을 제공합니다. GGML 라이브러리가 제공하는 GGUF는 새롭고 개선된 파일 형식입니다. 이러한 압축 형식을 사용하는 단점은 llama.cpp로 추론해야한다는 것이지만, 많은 하드웨어 아키텍처, 특히 비-Apple 장치에 적합하지 않다는 점입니다. 그러나 llama.cpp는 다중 GPU/CUDA 하드웨어 설정을 지원하고 있으므로 Ollama와 같은 사용자 친화적인 도구는 매우 효과적입니다, 비록 가장 빠르지는 않을지라도.

<div class="content-ad"></div>

vLLM은 Kwon et al. 2023에서 소개된 강력한 추론 엔진으로, Nvidia 및 AMD GPU에서 성능을 가속화하기 위해 최적화된 CUDA 커널을 사용합니다. 저자들은 LLM의 한 번에 하나씩 순차적으로 토큰을 생성하는 과정이 메모리에 의존하며, 결과적으로 GPU의 계산 파워를 제대로 활용하지 못한다는 점을 강조합니다. 이를 해결하기 위해, 저자들은 제안된 PagedAttention 알고리즘 위에 vLLM 서빙 엔진을 구축했는데, 이는 KV 캐시의 메모리 효율성을 향상시켜 공간을 낭비하지 않으며, 주어진 하드웨어에서의 최대 배치 크기 증가에 중요합니다. FasterTransformer보다 2~4배 더 나은 처리량을 보여주며, 모델 크기가 크고 복잡하며 더 큰 시퀀스일 때 더 두드러집니다. vLLM은 Hugging Face 모델과 매끄럽게 통합되며, 다중 GPU 워크플로를 지원합니다. GPTQ, AWQ, SqueezeLLM, FP8 KV 캐시 양자화와 원활한 모델 양자화(SmoothQuant+) 통합이 곧 예정되어 있습니다.

MLC-LLM은 최적화된 양자화 모델의 원시 배포를 다양한 유형의 하드웨어(Apple, Nvidia, AMD, Intel, 모바일 장치)에서 가능하게 하는 강력한 범용 배포 솔루션입니다. 본 글작성 시점에는 가장 빠르고 일반적인 서빙 엔진으로 보이며, Jetson AI Lab에서 우수한 처리량으로 선호됩니다. MLC-LLM 라이브러리는 사전 제작된 모델 세트를 제공하며, 라이브러리와 함께 사용할 수 있는 새로운 모델을 컴파일하는 옵션도 제공합니다.

![QuantizingtheAIColossi_41](/assets/img/2024-06-22-QuantizingtheAIColossi_41.png)

## LLM 양자화 의사결정 트리

<div class="content-ad"></div>

이 기사에서는 사상이 어지럽히도록 다양한 양자화 디자인 옵션을 만드는 다양한 방법론을 다루었습니다. 다행히도 일부 오픈 소스 추론 엔진들이 이러한 도구 중 가장 유용한 것을 직관적인 형태로 우리 손끝에 제공하고 있습니다. 이 의사 결정 트리는 사용 목적과 배포 환경을 기반으로 한 매우 기본적인 가이드로 사용될 수 있지만, 고려해야 할 사항의 철저한 목록은 아닙니다. 이는 실무자들에게 양자화를 구현하는 데 출발점을 제공하기 위한 것입니다.

- 질문: CPU 또는 가장자리 장치에 사전 학습된 모델을 배포하고 있습니까?
답변: 예 - Apple 사용자의 경우 GGML 기반 추론(llama.cpp, Ollama, LM Studio)을 선택하십시오. Android 및 x86 하드웨어의 경우 MLC-LLM을 사용하십시오.
아니요 - 다음 질문으로 이동합니다.
- 질문: 동시 배치 요청을 서비스하게 됩니까?
답변: 예 - vLLM을 사용하십시오. 이는 이를 위해 특별히 최적화되었습니다.
아니요 - 다음 질문으로 이동합니다.
- 질문: GPU에 사전 학습된 모델을 배포하고 있습니까?
답변: 예 - Nvidia 및 AMD GPU에서 MLC-LLM이 최신 처리량을 제공한다고 보입니다. Apple GPU도 지원하지만, llama.cpp는 Apple 하드웨어용으로 최적화되었다는 저희가 작성한 것이 있어 비교가 필요할 것입니다. Nvidia 및 AMD GPU의 경우, vLLM 라이브러리에 포함될 예정인 SmoothQuant+의 통합은 테스트가 가치 있을 것입니다.
아니요 - 다음 질문으로 이동합니다.
- 질문: 양자화된 LLM을 화강함하고 있습니까?
답변: 예 - QLoRA를 사용하십시오. 이것은 양자화된 LLM이 새로운 작업을 수행하거나 양자화로 인해 성능이 손실된 것을 복구하는 가장 효율적인 방법입니다. Hugging Face Transformers에서 쉽게 사용할 수 있습니다.
아니요 - 다음 질문으로 이동합니다.
- 질문: 기초 모델을 훈련 중인가요?
답변: 예 - BitNet을 사용하여 기초 모델을 프로토타입 또는 개발하는 것을 시도해보십시오. 훈련 비용이 훨씬 저렴하고 완전 정밀도 기준선에 대비하여 경쟁력 있는 성능을 제공합니다. 더 좋은 점은, 이러한 저비트 모델들을 합성해 보는 것입니다.

이 체크리스트는 특정 상황에서 사용자들이 참고해야 할 좋은 가이드를 제공해야 합니다. LLM 추론 프레임워크에 대한 더 포괄적인 안내를 위해서는 Sergei Savvov의 이 포스트를 확인해보세요.

# 결론

<div class="content-ad"></div>

이 기사에서는 양자화 연구에서 놀라운 성과들을 살펴보았습니다. 우리는 무손실 8비트 양자화가 지루한 기준으로 성장하는 것을 보았고, 이진 CNN이 완전 정밀도에 거의 필적하는 것을 확인했습니다. 4비트 정밀도로 훈련된 대규모 트랜스포머 모델과 LLMs에서의 극한 양자화의 부상도 보았습니다. INT8 PTQ가 완전히 성숙하며 완전 정밀도 기준과 쉽게 맞먹어서 대부분의 오픈소스 라이브러리에 널리 통합되어 있기 때문에 누구도 부동 소수점 데이터 유형을 사용하는 모델을 제공해서는 안 될 수도 있다는 주장이 가능합니다. LLMs의 경우, FP16로 자주 출시되는 것에 비해 무손실 INT8 양자화는 메모리 풋프린트를 절반으로 줄이고 "무료 점심" 압축을 제공합니다. 더 나아가 더 낮은 정밀도에서 양자화하는 것은 최소의 성능 손실로 이루어졌으며, 많은 실용적인 사용 사례에서는 약간의 정확도 감소와 교환할 가속화된 원활한 사용자 경험이 환영받을 것입니다. BENN 논문에서 본 것처럼 극히 낮은 비트 네트워크를 앙상블링하는 아이디어는 매우 설득력 있는데, 특히 LLMs에서 극한 양자화의 부상을 보고 있다는 것을 감안하면 이 방법이 곧 이롭게 된다는 점을 확인할 수 있습니다.

우리는 다양한 양자화 접근 방식을 살펴보았는데, 마찬가지로 다양한 복잡성을 가진 다양한 사용 사례에 맞추어 수요에 따라 발전되어 온 것을 볼 수 있었습니다. PTQ와 ZSQ가 매우 효과적으로 사용되었지만, QAT는 여전히 가장 성능이 우수한 방법입니다. 왜냐하면 이것은 네트워크 훈련 과정에 양자화를 통합하기 때문입니다. 이것은 훨씬 더 리소스 집약적이며, 일반 사용자에 의해 LLMs에 사용됨을 방지할 것 같지만, QLoRA의 창의성은 작은 비율의 매개변수만을 훈련하여 양자화로 인한 손실을 복구하는 저랭크 행렬에 양자화를 허용함으로써 PTQ와 QAT 사이의 구분선을 흐리게 할 수 있도록 했습니다. 최근 HQQ 방법을 통해 PTQ가 2비트 정밀도까지 효과적으로 사용되는 것을 확인했으며, 이진 및 삼항 LLMs가 지금부터 거의 완전 정밀도와 맞먹는 성능을 낼 수 있도록 처음부터 훈련된 것을 보았습니다.

이 지점에 도달한 것을 축하합니다. 이 기사에서 검토된 작품에 익숙해진 당신은 이제 신경망 양자화에 대한 전문 지식을 보유하고 있습니다. 이 조사는 소극적인 타입을 위한 것이 아니었지만, 2024년의 양자화 방법에 대한 피상적인 요약은 필요하지 않았습니다. 올바른 머신 러닝 실천을 위해 우리는 가능한 모든 옵션을 고려하여 교육된 결정을 내릴 수 있도록 모든 잠재적인 옵션들과 선택한 방법론의 장단점을 고려해야 합니다. 신경망 양자화는 매우 다양한 연구 분야로, 풍요로운 전통 위에 구축된 것이기 때문에 전체적인 이해를 얻고자 하는 사람들에게는 어려운 연구 과제가 될 수 있습니다. 바람직한 사용 사례를 위해 어떤 도구가 가장 적합한지에 대한 효과적인 제안과 함께 이 기사가 분야에서 활동하는 실무자들에게 접근 가능하고 자체 포괄적인 자원을 제공할 수 있기를 희망합니다.

## 미래 작업

<div class="content-ad"></div>

BitNet은 훈련 중에 저정밀 연산을 사용하지 않으며 가중치의 이진화 또는 삼진화를 완전히 활용하지 않습니다. 이는 곱셈을 덧셈/뺄셈 연산으로 대체하지 않기 때문에 본래의 가치를 실현하는 능력을 저해하고 있습니다. CNNs의 극단적 양자화에 대한 업적은 BitNet이 더 효율적인 연산을 수행하도록 하기 위해 실제 수학을 이진화하는 데 적용되어야 합니다. 더욱이, BitNet을 위해 최적화된 커널이 확립된 후에는 이러한 낮은 비트 LLM들의 앙상블 조사를 시작해야 합니다. 우리는 BENN 논문에서 CNNs와 함께 이것이 매우 효과적임을 보았습니다.

HQQ는 정확한 데이터 무관(zero-shot) PTQ를 위한 매우 효율적인 알고리즘입니다. 그러나 지금까지 최적화된 추론 엔진(vLLM) 하나만이 이러한 모델을 실행하는 실험 지원을 시작했습니다. 더 나아가 HQQ를 사용하여 양자화된 모델의 추론 처리량을 다른 방법과 비교한 벤치마크는 현재 없습니다. 이 두 가지는 향후 연구를 위한 오픈 영역입니다.