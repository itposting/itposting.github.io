---
title: "플라토닉 인공 지능 모든 인공 지능이 같아지고 있는가"
description: ""
coverImage: "/assets/img/2024-06-19-PlatonicAIAreAllAIsBecomingtheSame_0.png"
date: 2024-06-19 03:43
ogImage: 
  url: /assets/img/2024-06-19-PlatonicAIAreAllAIsBecomingtheSame_0.png
tag: Tech
originalTitle: "Platonic AI: Are All AIs Becoming the Same?"
link: "https://medium.com/@ignacio.de.gregorio.noblejas/platonic-ai-are-all-ais-becoming-the-same-4c5bab63471b"
---


몇 일 전에 AI와 철학을 결합한 새로운 이론을 발견했어요: "AI가 모두 같은 것이 되고 있는 걸까?" 시사하는 것은, 앞으로 모든 AI 모델이 동일해질까요?

실제로 연구자들은 이미 이것이 벌어지고 있다는 명확한 증거를 발견했습니다. 모든 모델들이 '플라톤적' 표현을 향해 수렴하는 것처럼 보이죠:

세계를 이해하는 하나의 독특한 방법.

만약 이게 사실이라면, 경제학적으로나 철학적으로 엄청난 파장을 불러올 수 있습니다. 왜냐하면 이것은 AI가, 기초 모델 덕분에 현실 자체를 발견, 설명하고, 중요한 것은 예측하기 시작하고 있다는 신호가 될 수 있기 때문이죠.

<div class="content-ad"></div>

# 표현

이 질문을 제기하는 연구자들을 이해하기 위해 우리는 모델이 세계를 해석하는 방법을 이해해야 합니다.

그리고 그것이 바로 표현을 통해 이루어집니다.

## 인공지능에서 가장 중요한 단어

<div class="content-ad"></div>

세상의 모든 개념을 학습할 때마다, AI 모델들은 키 속성을 포착하는 방식으로 그것을 설명하는 요약된 표현을 만듭니다.

특히, AI 모델들은 모든 개념을 임베딩으로 변환하여 벡터 형태로 표현합니다.

그런데 왜 벡터인 걸까요? 세상의 모든 것을 벡터로 만들면 두 가지 이점이 있습니다:
- 숫자 형태의 개념: 기계는 숫자만 해석할 수 있습니다. 따라서 모든 것을 숫자 형태로 어떤 방식으로든 해석해야 합니다.
- 유사성: 모든 것을 벡터로 만들어두면, 그들 사이의 거리를 측정할 수 있습니다.

<div class="content-ad"></div>

따라서 모델은 OpenAI가 정의한 관련성이라는 원칙에 의해 지배되는 세계 개념의 고차원(벡터 당 많은 숫자) 공간을 구축합니다.

이 내부 세계에서 두 실제 세계 개념이 더 유사할수록, 이 공간에서 그들의 벡터가 더 가까워져야 합니다.

예를 들어 이 공간에서 '개'와 '고양이'는 '개'와 '창문'보다 가깝지만 '개'와 '비둘기'보다도 가깝습니다. 왜냐하면 '개'와 '고양이'가 더 의미론적으로 관련되어 있기 때문입니다(비행하지 않는, 네 다리, 가정적 등).

![image](/assets/img/2024-06-19-PlatonicAIAreAllAIsBecomingtheSame_0.png)

<div class="content-ad"></div>

미지공간(이렇게 불리는 공간들)의 매력적인 점은 양방향으로 작동한다는 것입니다. AI 모델에게 세계의 개념을 가르치는 데 도움을 주는 것뿐만 아니라, 아직까지 인간들이 깨닫지 못한 세계 패턴들을 발견하는 데도 도움을 줄 수 있습니다.

예를 들어:

- 미지 공간을 중심으로 한 의미 공간 이론은 Hume.ai에 의해 인간 감정의 새로운 매핑을 발견하는 데 도움이 되고 있습니다.
- Osmo.ai가 이끄는 연구는 세계의 냄새를 매핑하고 새로운 냄새를 발견하기 위해 보간하는 것이 도움이 되고 있습니다.

![이미지](/assets/img/2024-06-19-PlatonicAIAreAllAIsBecomingtheSame_1.png)

<div class="content-ad"></div>

하지만 이게 어떻게 가능한 걸까요?

사실 AI는 인간보다 패턴 매칭에서 뛰어나며, 우리에게는 무의식적으로 보였거나 우리가 인식하기에 너무 편향되었던 데이터의 주요 패턴을 찾아냅니다 (AI는 서양 문화와 다른 문화를 이어주는 역할을 합니다; 예를 들어, 서양이 아닌 국가의 사람들은 특정 감정을 다르게 표현합니다).

따라서, 만약 AI가 현실에 대한 '편향되지 않은' 시각을 갖추고 있다면, 그들은 현실을 그대로 관찰할 수 있는 능력을 갖고 있을까요?

연구자들이 추측한 대답은 네, 라고 합니다.

<div class="content-ad"></div>

# 동굴의 애니콜

AI들이 모든 관찰이나 사건을 일으키는 현실의 진정한 본성을 배우는 것이 가능할까요?

## 거리가 중요합니다

만약 그게 가능하다면, 우리는 AI 교육을 충분히 성숙시켜서 우리의 기초 모델들이 현실을 해석하는 진정한 방법이 하나뿐이라는 동일한 모델로 진화될 수 있을까요?

<div class="content-ad"></div>

이 이론을 검증하기 위해 연구원들은 이러한 모델들의 표현이 모두 세계에 대한 단일 표현으로 수렴해야 한다고 주장했습니다. 이는 현실을 표현하는 객관적이고 보편적인 방법입니다.

하지만 이게 일어나고 있는지 어떻게 테스트할 수 있을까요? 이를 위해 연구원들은 여러 인기 모델의 잠재 공간을 비교했습니다.

우리가 기억한다면, AI 모델의 세계 표현은 고차원 공간입니다 (이전 다이어그램에서 간단히 세 개의 차원으로 표현됨) 비슷한 것들이 가까이에 있고, 다른 개념들은 멀리 밀려 있습니다.

그러나 개념 표현의 전체 분포뿐만 아니라 거리도 중요합니다.

<div class="content-ad"></div>

그것은 하나의 모델이 '빨간색'에 할당하는 표현이 동일한 모드(다른 LLMs와 비교) 내 다른 모델과 유사해야 할뿐만 아니라 언어 모델과 시각 모델이 '적색'을 해석하는 방식도 유사해야 한다는 뜻입니다.

간단히 말해, 모델 간 '적색'과 '파란색' 사이의 거리가 동일해야 하며, 이렇게 함으로써 각 모델이 현실이 제시하는 색 '빨간색'을 어떻게 해석하는지가 동일함을 입증하게 됩니다. 이렇게 두 모델이 '빨간색'이라는 개념으로 수렴하고 있다는 것을 증명하는 것이죠.

그런데 왜 ‘플라톤적 표현’이라고 부를까요?

**현실의 부분적 관점**

<div class="content-ad"></div>

특히, 연구자들은 플라톤의 동굴 비유를 인용합니다. 현재 모델에 공급하는 데이터는 그림자이며, 이는 현실의 모호한 대표물입니다. 이전 AI 시스템은 그림자를 지켜보는 사람들로, 이는 그들이 삶의 부분적인 면밖에 알지 못한다는 것을 의미합니다.

하지만 규모와 강제적인 다중 작업을 통해, 기초 모델들은 그들의 데이터를 초월하여 결국 동굴에서 나와 진정한 현실의 본질을 깨달을 것입니다.

그러나 이것이 의미하는 것은 무엇일까요?

<div class="content-ad"></div>

아래 이미지를 살펴보면, fimage와 ftext는 동일한 개념의 세계를 관찰하기 때문에, 그들의 표현 - 즉 벡터 -은 동일해야합니다.

![이미지](/assets/img/2024-06-19-PlatonicAIAreAllAIsBecomingtheSame_3.png)

모든 것이 좋아 보이지만, 이것이 일어나고 있는지 어떤 지표가 있을까요?

# 수렴

<div class="content-ad"></div>

매혹적으로, 기반 모델들은 수렴하고 있습니다.

비전 모델들과 LLM 세트를 비교할 때, 내부 표현의 유사성인 정렬(alignment)은 LLM 성능과 비전 모델 간의 거의 1대1 상관 관계를 갖습니다.

쉽게 말해, 우리 LLM이 더 잘 수행할수록, 다른 강력한 비전 모델들과의 표현이 얼마나 유사해지는지가 증가하며 완전히 다른 형태로 제시되었음에도 불구하고 유사해집니다. 이것은 또 다른 말로,

LLM이 더 나아질수록, 그들의 세계 이해가 비전 모델로 수렴한다는 신호입니다. 모델이 커짐에 따라, 그들의 모드나 사용된 데이터에 관계없이, 모든 것이 동일한 표현, 동일한 현실에 대한 이해로 수렴하며 그 결과 더 똑똑해집니다.

<div class="content-ad"></div>


![Platonic AI: Are All AIs Becoming the Same](/assets/img/2024-06-19-PlatonicAIAreAllAIsBecomingtheSame_4.png)

이러한 경향이 발생하는 이유는 아래 이미지에서 명확하게 나타났습니다: 모델이 더 많은 문제를 해결하기 위한 공통적인 방법을 찾아야 하므로 두 작업에 대한 가능한 해결책 공간이 줄어듭니다:

![Platonic AI: Are All AIs Becoming the Same](/assets/img/2024-06-19-PlatonicAIAreAllAIsBecomingtheSame_5.png)

결국, 모델이 더 크고 훈련되는 기술 집합이 더 광범위할수록 이러한 모델들은 서로 수렴하는 경향이 있습니다. 사용된 모달리티와 데이터셋과는 독립적으로, 어느 날 언젠가 우리 모두의 선도 연구소가 동일한 모델을 만들어내도록 수렴할 가능성을 그려낼 것입니다.


<div class="content-ad"></div>

## 중요한 질문하기

인공지능과 철학의 만남.

나에게 있어 가장 중요한 관심사는 이것이 시장에 엄청난 재화화 효과를 줄 수 있다는 사실 외에도, 이것이 우리 인간들이 세계 모델을 만드는 방향으로 다가가고 있다는 첫 번째 신호일 수 있다는 점입니다. 세계 모델은 로봇이 언젠가 우리 세상에서 살아가는 모습을 상상하는 등 거의 모든 인공지능 분야에서 절대적으로 중요하다고 생각됩니다.

<div class="content-ad"></div>

세계 모델은 인공 지능에게 환경을 관찰하고 적응할 수 있는 능력을 제공합니다. 인간 뇌는 계속해서 다음에 일어날 일을 추론(예측)하고 있습니다.

만약 인간들이 진정으로 일반적인 세계 모델을 훈련하는 방법을 알아낸다면, 인공 지능이 어떻게 변할지를 말로 표현하기 어려울 것입니다. 가장 강력한 모델들이 세계의 동일한 표현으로 수렴되는 것을 보면, 적어도 해결책에 접근하고 있다는 신호로 받아들일 수 있습니다.