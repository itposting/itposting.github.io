---
title: "자율 에이전트의 흥망성쇠 그 발전과 한계 "
description: ""
coverImage: "/assets/img/2024-06-23-TheRiseandFallofAutonomousAgents_0.png"
date: 2024-06-23 19:30
ogImage: 
  url: /assets/img/2024-06-23-TheRiseandFallofAutonomousAgents_0.png
tag: Tech
originalTitle: "The Rise and Fall of (Autonomous) Agents"
link: "https://medium.com/@lukas.kowejsza/the-rise-and-fall-of-autonomous-agents-18360625067e"
---


2023년 ChatGPT가 인기를 끌자, 창조적 AI 공간에서 골드 러시 분위기가 등장했습니다. 전 세계적으로 사람들은 미래에 대한 AI의 변혁적 잠재력을 인식했습니다. 이 골드 러시적 마인드셋은 우리를 핵심 질문으로 이끕니다: 여기에는 골드가 어디에 있을까요?

다른 말로 하면, 미래에는 어떤 일이 일어날까요? 보통 우리에게는 미래로 멀리 전망하는 것이 어려우며, 다가오는 변화를 예측하기 위해 짧은 시간대에 초점을 맞추는 것이 더 좋습니다. 그러나 창조적 AI 분야에서는 이것이 다르다고 보이죠. 우리가 향하는 방향을 알 수는 있겠지만, 다음에 무엇이 올지 예측하는 것은 널리 어렵습니다.

2023년 4월, AutoGPT와 BabyAGI와 같은 자율 에이전트 워크플로우가 GitHub에서 인기를 얻기 시작했습니다. 인기가 폭증하며, AutoGPT는 딱 한 달 만에 5만 명 이상의 프로그래머들의 주목을 끌었습니다.

![이미지](/assets/img/2024-06-23-TheRiseandFallofAutonomousAgents_0.png)

<div class="content-ad"></div>

# 자율 에이전트 워크플로 이해

자율 에이전트 워크플로의 구체적인 내용을 알아보기 전에 먼저 '에이전트'가 무엇을 의미하는지 명확히 해보겠습니다. '에이전트'라는 용어는 컴퓨터 과학의 맥락에서 20세기로 거슬러 올라가는 뿌리를 가지며, 1980년대 후반에 큰 인기를 얻었습니다.

일반적으로, 에이전트는 "행동"이 가능한 개체입니다 (‘agency' 개념에서 파생됨). 에이전트는 다음과 같은 세 가지 주요 기능으로 정의될 수 있습니다:

- 지각: 센서 또는 텍스트 입력을 통해.
- 결정: 인식에 기반한 결정을 내림.
- 행동: 그 결정에 기반한 행동을 실행함.

<div class="content-ad"></div>

2023년 초에 발표된 논문 'ReAct: 언어 모델에서의 추론과 실행의 시너지 효과'는 특히 대규모 언어 모델의 맥락에서 마일스톤을 달성했습니다. 인기 있는 프레임워크인 LangChain은 ReAct 로직을 구현하여 자료와 관련된 테마에 상당 부분의 리포지토리를 할애했습니다. 이 접근 방식은 에이전트 논리를 보다 넓은 관중에게 접근 가능하게 만들면서 에이전트 논리의 최신 발전을 통합했습니다.

에이전트를 뛰어넘게 하는 것은 에이전트에게 일련의 도구를 제공하여 대규모 언어 모델의 훈련 데이터의 한계를 극복하는 능력입니다. 이러한 도구는 본질적으로 소프트웨어 함수로, 에이전트가 API 요청(예: Google 검색 쿼리 실행), 웹 사이트 읽기, 프로젝트 보드에 액세스, 계산 수행, 데이터베이스에서 SQL 쿼리 실행 또는 보호된 환경에서 코드 작성 및 실행과 같은 작업을 수행할 수 있게 합니다. 도구는 대규모 모델이 외부 세계와 상호작용할 수 있게 합니다. 모델은 원하는 결과를 달성하기 위해 실행할 함수를 결정할 수 있습니다.

ReAct 로직은 각 언어 모델 프로세스 단계에서 'Thought', 'Act/Action' 및 'Observation' 요소를 포함합니다. 'Thought'는 추론을 통해 다음 작업과 그 근간에 있는 결정을 향상시킵니다. 'Action'은 어떤 도구를 사용할지와 어떤 매개변수를 사용할지를 지정하며, 'Observation'은 'Action'에 따라 도구 실행 결과를 포함합니다. 초기 조사에 대한 답변을 위해 이러한 단계들이 필요한 정보가 수집될 때까지 반복됩니다.

![이미지](/assets/img/2024-06-23-TheRiseandFallofAutonomousAgents_1.png)

<div class="content-ad"></div>

# OpenAI에서 구현됨

OpenAI의 중요한 역할은 에이전트의 잠재력에 대한 인식으로 두드러지며, 이를 기능으로 통합하여 ChatGPT 플러그인 스토어를 열어두었습니다. 또한, GPT-XX-0631 이후의 OpenAI 모델 업데이트는 JSON 출력을 더 잘 제공할 수 있도록 지속적으로 개선되었습니다. 이 향상은 도구, 플러그인 또는 기능을 신뢰할 수 있게 실행하는 데 주로 필수적입니다. 그 이후 API는 또한 GPT 모델 쿼리에서 반환된 텍스트 블록과 별도로 함수의 정의 및 실행을 허용합니다. 일반적으로 JSON 출력은 함수 실행에 필요한 매개변수를 정의하므로, 전통적인 오픈 소스 프로젝트의 경우 (MistralAI와 같이 API 클라이언트에서 함수 호출을 제공하는 몇 가지 예외를 제외하고) 출력에서 추출해야 합니다.

# 자율 에이전트 워크플로우

자율 에이전트로 돌아와서, 클래식 ReAct 에이전트가 특정 작업이나 질문을 다루는 데 설계되었다면, 자율 에이전트 워크플로우는 한 걸음 더 나아갑니다. 작은 작업이 아니라 넓은 목표가 초기 입력으로 표현됩니다. 일반적으로 단일 프로세스 단계는 다음과 같습니다:

<div class="content-ad"></div>

- (LLM) - 작업/목표를 하위 작업으로 분해합니다.
- 작업을 작업 풀에 추가합니다.
- (LLM) - 작업 풀을 우선 순위로 나열합니다.
- 가장 중요한 작업을 선택합니다.
- (LLM-Agent) - 가장 중요한 작업을 완료합니다.
- (LLM-Agent) - 다음 작업을 정의합니다.

다시 말해, '에이전트'들은 이제 '프로젝트 관리 에이전트'에 의해 조정되며 큰 작업을 목표를 달성할 때까지 처리 가능한 작은 작업으로 나누어줍니다. 이 프로세스는 새로운 도구를 만들고, 새로운 에이전트를 조정하고, 정보를 단기 또는 장기 기억에 저장하는 것을 포함합니다. 이 이터레이션 프로세스는 이론적으로 거의 모든 작업을 해결할 수 있습니다. 사용자들은 대형 언어 모델 (GPT-4)에 의해 생성된 창의적인 솔루션을 보고했습니다. 워크플로는 웹사이트나 프로필을 생성할 때 캡차를 우회하기 위해 작업에 막혔는데, '인간'을 위해 작업 플랫폼 (Fiverr)에 작업을 게시하여 문제를 해결했습니다.

# 다중 에이전트 협업 워크플로

우리는 독립적인 에이전트 워크플로가 개별 에이전트의 능력을 활용하여 특정 기능을 수행하는 능력을 증진함으로써 복잡한 작업을 해결할 수 있는 능력을 크게 향상시켰다는 것을 보았습니다. 그러나 이러한 기술의 진정한 잠재력은 독립적인 에이전트보다는 다중 에이전트의 협력 노력에 더 명백해집니다.

<div class="content-ad"></div>

다중 에이전트 협업은 특화된 역량을 갖춘 각종 에이전트들이 협력하여 단일 에이전트 시스템으로는 해결할 수 없는 복잡한 목표를 달성하는 것을 포함합니다. 이 방식은 여러 에이전트의 집단적 강점을 활용하여 도전적인 문제에 대한 더 정교하고 확장 가능하며 유연한 해결책을 제공합니다. 성공적인 다중 에이전트 협업의 핵심은 다양한 에이전트의 행동을 조율하고 공통 목표를 향한 효과적인 의사 소통과 협력을 보장하는 능력에 있습니다.

AutoGen은 대규모 언어 모델(LLMs)을 활용하는 워크플로의 조율, 최적화 및 자동화를 촉진하는 Microsoft의 프레임워크입니다. AutoGen의 핵심 아이디어는 특화된 역할과 기능을 갖춘 각 에이전트들이 더 효과적으로 협력할 수 있는 시스템 설계를 용이하게 하는 것입니다. 이러한 에이전트들은 자율적으로 작업을 수행하거나 서로 간 대화를 나누며, 프로그래밍 및 사람 사용자 또는 다른 도구로부터의 입력을 바탕으로 결정을 내릴 수 있습니다. 이는 단일 에이전트나 순수히 인간 팀이 다루기 어려운 복잡한 문제를 해결하는 더 동적이고 유연한 방식을 가능케 합니다.

AutoGen은 두 가지 주요 기능을 통해 이를 실현합니다:

- 개발자가 특화된 기능과 역할을 갖춘 에이전트들의 집합을 정의함으로써, 이러한 에이전트들의 모듈화와 재사용성을 강화합니다.
- 에이전트 간 상호작용 행동을 위한 프레임워크를 수립하여, 미리 정의된 프로토콜 또는 자동화된 채팅을 통해 효과적으로 소통하고 협력할 수 있도록 합니다.

<div class="content-ad"></div>

![이미지](/assets/img/2024-06-23-TheRiseandFallofAutonomousAgents_2.png)

# 도전과 제한 사항

클래식 ReAct 에이전트와 비슷한 원칙으로 디자인된 에이전트들은 능력에 제한이 있습니다. 이 제한은 토큰 창문 제약 때문에 발생하는데, 여기서는 어떻게 그리고 언제 사용해야 하는지에 대한 설명이 정의될 수 있는 기능의 수가 제한됩니다. 단일 작업 또는 도구로 구비된 에이전트는 만족스러운 결과를 산출할 수 있지만, 도구의 수가 증가함에 따라 신뢰성이 감소합니다.

토큰 창문의 확장이 있더라도, "중간" 문제가 지속됩니다. 즉, 입력 프롬프트의 중간에 위치한 정보가 덜 주목을 받습니다. 따라서 16,000 토큰을 초과하는 문맥 창문 내에 수백 개의 도구를 수용할 수 있는 잠재력이 있더라도 대부분은 여전히 간과됩니다. 게다가, 의사 결정은 여전히 과정에서 중요한 도전 과제입니다. 제한된 도구 수가 있더라도, MultiActionAgents는 적합한 도구를 선택하거나 모든 가능한 도구를 활용해야 한다고 믿는 것에 어려움을 겪습니다.

<div class="content-ad"></div>

# 자율 에이전트의 과제

자율 에이전트 개발이 미진한 이유 중 하나는 그들이 만들어내는 오픈 루프 시스템에 따른 비용 때문입니다. 보통 이러한 워크플로우는 가장 효율적인 해결책으로 이끌어주지 않습니다. 대신 계속하여 새로운 작업을 정의합니다. 오케스트레이션 에이전트들은 작업 풀을 모니터링하는 데 어려움을 겪어야 합니다. 한 번 이상으로 정의된 작업이 없도록 보장하는 것이 중요합니다. 동시에 최선의 결과를 얻으려면 최신 모델인 GPT-4를 사용해야 하며, 간단한 목표조차도 수천 번의 LLM 호출을 유발할 수 있어 빠르게 비용이 증가할 수 있습니다.

뿐만 아니라, 시스템은 종종 막다른 곳에 이르게 되어 폐쇄 루프를 만들어냅니다:

- 작업 A는 작업 B와 C에 의해 완료되어야 하며,
- 그리고 작업 C의 분할 결과로써 작업 A가 다시 정의되는 일이 발생합니다.

<div class="content-ad"></div>

모델 업데이트의 관찰 가능한 저하와 게으름으로 문제가 악화되고 있습니다. 저는 연구를 수행하고 발견물로부터 PowerPoint 프레젠테이션을 작성할 수 있는 반자동 워크플로우를 개발했었는데, GPT-3.5 turbo로 시도 중 3번 중 2번은 성공했습니다. 하지만 GPT-4에서는 이러한 결과를 재현할 수 없었습니다.

LangChain의 미리 정의된 agent + 도구킷에서도 비슷한 상황이 나타납니다. 예를 들어, Pandas 및 SQL agent는 2023년 중반까지 신뢰할 수 있는 결과를 제공했지만 이제 80%의 경우에 오류로 이어지고 있습니다. 이는 agent의 인기가 점차 감소하거나 적어도 침체로 이어지고 있다는 것을 보여줍니다.

# 해결 방안

덜 발전된 모델일지라도 실행 로직과 프롬프트 엔지니어링을 통해 개선의 여지가 있습니다. 한 가지 전략은 MultiActionAgent를 사용하는 대신 agent가 수행할 수 있는 작업 범위를 좁히는 것입니다. 각 도구에 대해 SingleActionAgent가 생성되고, 적합한 SingleActionAgent를 선택하는 Routing Agent가 지정됩니다. 이 방법은 GPT-3.5 turbo와 같이 강력하지 않은 모델에도 만족스러운 결과를 얻을 수 있습니다.

<div class="content-ad"></div>

그러나 이 방법은 이전의 종단 간 에이전트 전략과 비교해 개발 노력이 상당히 많이 필요합니다. 더 비용 효율적인 모델을 활용하도록 솔루션을 분해하면 재정적으로 한 번에 더 많은 LLM 호출을 할 수 있습니다. 이를 통해 주요 투표의 실행이나 자가 비평 방법을 사용하여 하나의 LLM 호출에 대한 고려 사항의 반복적인 유효성 검증이 가능해집니다.

프로세스를 분할하는 것이 가장 합리적인 해결책 중 하나로 보입니다. 현재 에이전트 워크플로우는 한 프롬프트 접근 방식에 의존하며, 결정, 문제 해결 및 추가 프로세스는 반복적으로 해결되고 동일한 프롬프트로 이루어지도록 의도되어 있습니다. 프롬프트 엔지니어링에 익숙한 사람들은 특정 상황에는 특정 프롬프트가 필요하다는 것을 알고 있습니다.

# 전망

현재 직면한 문제들이 시간이 지남에 따라 완화될 것입니다. 더 강력한 모델이 시장에 등장하고 오늘날의 최고 모델들이 더 저렴해질 것입니다. 시장이 많은 비판하는 점진적인 악화를 수정할 수 있는 능력을 가지고 있다고 확신합니다. 필요한 곳에는 해결책이 따를 것입니다. 의심의 여지 없이, 생성모델의 다음 성취는 우리의 능력을 혁신할 것입니다.

<div class="content-ad"></div>

현재 사용성이 매우 낮고 신뢰할 수 없지만, 미래는 모든 종류의 프로세스에서 활용될 AI 엔티티(에이전트)에 의해 형성될 것입니다. 컴퓨터 과학 분야의 최근 논문은 에이전트 프로세스(시행착오 학습)에 보상 학습 모델을 통합하는 해결책을 탐구하고 있습니다. 이는 에이전트가 보상 모델을 정의하고 훈련시킨 다음, 극도로 복잡한 작업을 해결하는 도구로 사용할 수 있다는 것을 의미합니다.

에이전트와 자율 에이전트는 의심의 여지 없이 인공 일반 지능(AGI) 달성을 향한 여정에서 중요한 역할을 할 것입니다.

## 출처:

- Xi, Z., Chen, W., Guo, X., He, W., Ding, Y., Hong, B., Zhang, M., Wang, J., Jin, S., & Zhou, E. (2023). The Rise and Potential of Large Language Model Based Agents: A Survey. arXiv:2309.07864에서 검색됨
- Yao, S., et al. (2022). REACT: Synergizing Reasoning and Acting in Language Models. arXiv:2210.03629에서 검색됨
- LangChain. (n.d.). 에이전트 유형: REACT. LangChain 문서에서 확인됨
- Significant-Gravitas. (n.d.). AutoGPT. GitHub에서 확인됨
- Microsoft Research. (n.d.). AutoGen: 다음 세대 대형 언어 모델 애플리케이션 활성화. Microsoft Research 블로그에서 확인됨
- Microsoft Research. (n.d.). AutoGen 프로젝트 페이지. Microsoft Research 프로젝트에서 확인됨