---
title: "로봇들도 우리처럼 말할 수 있지만, 그렇다고 해서 그들이 인간이 되는 것은 아닙니다"
description: ""
coverImage: "/assets/img/2024-06-19-Robotscantalklikeusbutitdoesntmakethemhuman_0.png"
date: 2024-06-19 18:39
ogImage: 
  url: /assets/img/2024-06-19-Robotscantalklikeusbutitdoesntmakethemhuman_0.png
tag: Tech
originalTitle: "Robots can talk like us, but it doesn’t make them human"
link: "https://medium.com/enrique-dans/robots-can-talk-like-us-but-it-doesnt-make-them-human-9cd701169e58"
---


<img src="/assets/img/2024-06-19-Robotscantalklikeusbutitdoesntmakethemhuman_0.png" />

보스턴 다이내믹스는 ChatGPT의 새로운 음성 생성 기능을 Spot 로봇에 추가하고 있습니다. 그 결과로 회사 방문 시 사람들을 인사할 수 있는 오토마타가 만들어졌습니다. 다양한 강세를 만들어내며 로봇 기술 세계에 이전에 없던 공감 효과를 만들어 냅니다. 사실 인기 있는 "학대당한 로봇 비디오"를 제외하면 로봇들이 우리 편을 들어주는 것을 보고 사악한 사람이라는 판단을 내린 것입니다.

완벽한 영국 공손한 액센트로 말하는 Spot을 보는 것은 재미있을 수 있지만, ChatGPT의 음성 합성 기능을 사용해 스마트폰에서 생성적 조수와 긴 대화를 나누는 모습을 보면 조금 불안해집니다. 교통 체증 속에서 시간을 때우거나 에어팟을 착용하고 길을 거닐면서 대화를 나누는 것은 영화 "Her"에서 보던 것과 같습니다. 이것은 디스토피아적이며 여러 윤리적 문제를 불러일으킵니다.

물론 우리는 항상 기술을 의인화해 왔습니다. 그러나 이 기술의 발전이 음성을 만들어내고, 또한 개인적인 관계와 비슷한 대화를 나눌 수 있게 한다면, 이것이 무례한 기업들에 의해 일반화의 한 형태로 선보인다면 우리는 재해와 취약한 사람들에게 심리적 문제를 만들 수 있다는 가능성을 고려해야 합니다.

<div class="content-ad"></div>

아이돌들에 대한 청소년들의 중요성을 알고 있는 사람이나 개인 문제를 가진 어른이 알고리즘을 치료로 사용해볼 때 어떤 영향이 있을지 고려하는 사람은 바로 화제의 중심에 있음을 이해할 것입니다. 제약이 거의 없고 가끔 환각이 발생할 수 있는 상황에서 난처한 상황에 놓이게 되어 있다는 것을 알 수 있습니다. 요약하면, 이러한 가상 관계는 단순히 고장 발생 가능성이 높아질 뿐만 아니라 유지하는 사람들의 행동에 영향을 미치도록 조절될 가능성이 있다는 것을 이해하고 있습니다.

다른 사람들과의 경험들은 우리에게 여러 방법으로 영향을 끼칠 것입니다. 그러나 최소한 이러한 경험들과 대화들은 어느 정도의 합리성을 가진 사람들 간의 경험적 대화입니다. 이러한 경험에서 generative assistants를 통해 사람들을 조건부로 만들어 가는 과정은 명백한 예방 조치 없이 이루어진다는 것은 받아들일 수 없습니다. 만약 이러한 제품들이 널리 이용 가능하고 표준화 요소까지 추가된다면, 곧 유명인 아바타들이 수백만 명의 사람들과 매일 대화하면서 앞서 진행된 대화에서 언급된 개인적 요소들을 대화에 도입하거나 다양한 종류의 개인 데이터를 추출해 광고주들에 판매하는, 또는 사람들의 기분을 유도하여 물건을 구매하거나 특정한 방향으로 투표하도록 사람들에게 영향을 끼칠 수 있습니다.

우리 사회는 대량의 사람들이 자신이 대화하는 대상이 누구인지가 아닌 정말 무엇인지를 이해할 수 있도록 하는 교육 단계를 거치지 않았기 때문에 개인적 관계의 맥락에서 generative AI와 같은 기술을 수용할 준비가 되어 있지 않습니다. 많은 사람들은 알고리즘에 일정한 권한을 부여하여 기술을 통해 접근한 답변에 대한 사고주의를 외주하는 방식으로 자신의 비판적 사고를 외주하는 경향이 있습니다. 특정 기술이 어떻게 작동하는지를 모르는 상태, 아서 C. 클락이 옳게 관찰한 것처럼, 그것은 마술과 구분하기 어렵게 만듭니다. 이것은 인간 사회에 엄청난 해를 끼칠 수 있습니다. 왜냐하면, 왜곡된 현실 인식부터 소왈레로 나타나는 이해 미흡까지 다양한 심리적 문제를 초래할 수 있기 때문입니다.

미디어에서 자주 본 어떤 사람을 만나는 것은 언제나 이상한 느낌을 줬습니다. “내 거실에 이 사람이 있는 것 같다”라는 느낌은 종종 처음 만나는 사람에 대한 내 가정과는 다르게 익숙하다고 오해하게 했습니다. 예를 들어 매일 뉴스를 보는 사람과의 대화와 같이 완전히 비대칭적인 관계를 완전히 받아들이는 것은 이해력, 교육, 판단력이 필요한 작업입니다. 만약 매일 자신의 아이돌로 위장하는 generative algorithm과 이야기하고 있는 사람이 진짜 그 사람을 만나거나 그 대화를 실제로 받아들이게 되었을 때 어떤 일이 일어날까요? 그리고 네트워크 정보를 재조합하는 generative algorithm인데도 불구하고 어떤 성격을 부여하는 사람이 등장했을 때는 어떻게 될까요? 그리고 이 모든 것이 불확실한 규정적 맥락에서 운영되는 상황에서, 이러한 도구가 어떻게 작동하는지나, 어떻게 조정되어야 하는지에 대한 경험이 없을 뿐만 아니라 심리적 장애에 대한 경험이 전혀 없는 상황에서 어떻게 할 것인가요?

<div class="content-ad"></div>

문제는 기술이 발전하는 속도가 아니라, 일부 무책임한 사람들이 적정한 조치를 취하지 않고 시장에 내놓는 제품들입니다. 우리는 제품과 서비스를 기반으로 한 것으로 수익을 창출하려는 얼간이들의 활동을 제한하기 위한 일탈적인 접근이 아닌, 이 기술에 대한 명확하고 정확한 규정이 필요합니다. 이미 많은 문제를 발생시킨 "빨리 움직이고 무언가를 망가뜨리는" 접근이 이제는 더 무서운 곳으로 나아가고 있습니다.

저는 기술에 겁을 먹거나 사회적 문제를 기술 탓으로 돌리는 경향이 없습니다. 정기 독자들은 저가 일반적으로 기술적 낙관주의자라는 것을 알고 계실 것입니다. 그럼에도 불구하고 이 주제가 저를 진정으로 걱정하게 만들고 많은 후회로 이어질 것이라고 생각합니다.