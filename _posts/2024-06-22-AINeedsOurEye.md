---
title: "AI, 우리 눈이 필요한 이유"
description: ""
coverImage: "/assets/img/2024-06-22-AINeedsOurEye_0.png"
date: 2024-06-22 20:42
ogImage: 
  url: /assets/img/2024-06-22-AINeedsOurEye_0.png
tag: Tech
originalTitle: "AI Needs Our Eye"
link: "https://medium.com/brain-labs/ai-needs-our-eye-581c699bdfa6"
---


## 우리 자신을 위해 어떻게 생각하는지 잊지 말아요

![image](/assets/img/2024-06-22-AINeedsOurEye_0.png)

우리는 인공 지능(AI)이 우리의 소중한 지적 성취물에 따라잡음에 따라 불안하게 어깨를 돌리곤 합니다. AI 챗봇은 바 및 의료 면허 시험을 통과하며, 논문 작성, 주문에 따른 이미지 생성, 회의록부터 과학 논문 요약까지 다양한 작업을 수행할 수 있습니다. 멸망을 예견하는 이들은 일자리와 인간의 목적의 상실 뿐만 아니라 인류 자체의 파괴까지 두려워합니다. 우리 기계가 자기보증을 목표로 배우면, 어쩌면 우리가 그들을 끄는 것을 방해할 정도로 완벽하게 통제에서 벗어날 수도 있습니다.

멸망을 의심하는 사람들은 걱정하지 말라고 말합니다. 오늘날의 AI는 실제로 사고하지 않습니다. 강력한 챗봇은 단지 당신의 질의에 대한 다음 단어 추측을 기반으로 하여 인간과 유사한 응답을 만들도록 훈련됩니다. 내일의 AI가 더 나은 일을 할지라도, 본질적으로 다르지 않을 것입니다. 당신의 마음을 읽을 수 있다 하더라도, 그것은 입력을 받아 응답을 만드는 것 이상의 일을 하지 않을 것입니다.

<div class="content-ad"></div>

그래서 뭐 어때요 — 우리는 불에 놀까요 아니면 여기 볼 게 없을까요? 아마 둘 다일지도 모릅니다. 2001년 '스페이스 오디세이'에서 HAL 9000이라는 감성적이고 살인적인 AI를 만들 수 있는지 여부는 불분명하지만, 생존을 중시하는 인간들은 AI를 통해 자신들의 멸종을 일으키지 않을 것이라는 합리적인 가정을 해 봅시다. 하지만 만약 우리가 컴퓨터로부터 스스로를 보호한다 해도, 우리 자신으로부터 안전한가요?

비관론자들이 옳게 강조한 것처럼, AI 능력이 폭발적으로 증가하고 있는 속도를 과소평가해서는 안 됩니다. 그렇습니다, 대형 언어 모델(Large Language Models, LLMs)의 기본 원리는 단순할지 모르지만, 인간의 사고도 신경 신호의 생물학적 본질로 축소될 때 또한 단순합니다. 인지는 다양한 조직 계층에서 상호작용하는 방대한 수의 뉴런으로부터 발생합니다. 마찬가지로, LLM은 단어 사이의 의미와 관계를 포착하기 위해 고차원 공간에서 조직된 수십억 개의 텍스트 구성 요소(토큰)를 활용합니다. 인간과 LLM 모두에게 이러한 고수준 조직은 가변적이며 학습을 통해 발전합니다. 쌓인 인간 지식의 상당한 부분을 학습한 후, LLM 기반 챗봇은 인간과 유사한 추론 능력과 맥락 인식을 효과적으로 시연하거나 시뮬레이트합니다. 실제로 추론을 하지 않더라도 잘 하는 모습을 보입니다. 더욱 놀라운 것은, 그들이 창의성을 나타낼 수 있다는 점인데 — 기존 것을 종합하는 대신 새로운 아이디어를 발명하는 능력은 지성의 기준일 수 있습니다. 일상 물품에 대한 대체 사용법을 고안하기 위한 공통적인 창의성 시험에서 챗봇이 대부분의 인간을 능가합니다. 최근 AI는 계산 기하학의 오랫동안 난제에 대해 (인간) 수학자보다 나은 해결책을 찾아내었습니다.

하지만 모든 질문에 대한 답을 알고 있다고 해서 똑똑한 것은 아닙니다, 그저 편리할 뿐입니다. 인간들을 괴롭히는 문제들 — 갈등부터 질병, 서식지 파괴까지 — 은 간단히 해결할 수 있는 방법이 없습니다. 어려운 문제들은 종종 중요한 피해를 방지할 수 없을 정도로 인지되지 않습니다. AI는 배운 것만 알 수 있고, 인간의 문제가 풍부한 영역에 진입할 수 없습니다. 유아들은 모험가고, 동료 및 낯선 어른들로 이상한 세상에서 길을 찾아가면서 배워야 할 것을 배우기 때문에 AI보다 지혜롭고 위험합니다. ChatGPT는 즐거움을 위해 화를 내거나 양침을 하지 않을 것입니다.

AI는 특정 유형의 작업을 처리하는 데 가장 적합하며 — LLM을 제외하고 — 일반적으로 특정 유형의 작업을 처리하도록 개발됩니다. 모든 AI는 인간 창조자들에 의해 이미 어려운 문제 클래스로 인정된 문제유형에 존재합니다. "딥 러닝"은 복잡한 입력에서 패턴을 탐지하고 특징을 추출하기 위해 뇌와 유사한 여러 계층을 사용합니다. 음성을 인식하고 번역하며 사진에서 고양이를 찾고 질병을 진단하는 다양한 애플리케이션을 만드는 데 이러한 기술이 사용되었습니다. 이 모든 것들은 공통의 조상 패러다임인 '퍼셉트론'에서 비롯되었으며, 이는 물체를 분류하기 위해 제2차 세계 대전 중에 등장했습니다. 초기에는 뉴런 하나의 퍼셉트론이 그가 분류할 수 있는 물체를 이해하는 능력과 혼동되지 않았을 것입니다. 오늘날의 신경망은 단일 뉴런 퍼셉트론의 환상적으로 복잡한 후속 모델로, 인간인식을 회피하고 초인지를 감지하거나 능가할 정도로 미묘한 패턴을 탐지할 수 있습니다. AI는 "기계 속에 귀신" 분위기를 풍깁니다. 이것은 지난 세대부터 특수 기술과 지식을 보유한 사람들에게 맡겨져온 작업을 컴퓨터가 실행하는 모습으로 나타납니다. 

<div class="content-ad"></div>

AI의 문제는 전문가 수준으로 수행하지 않고 단지 전문가 수준에서 패턴을 인식한다는 것입니다. 저는 AI와 함께 일하는 과정 중에 의료 이미지를 분석하여 암의 징후를 확인하는 작업을 하고 있습니다. 부업으로, 미술사인 제 아내와 함께 그림과 드로잉 작품의 진품과 저작권 문제를 해결하기 위해 AI를 활용합니다. 두 가지 노력은 유사한 AI 아키텍처와 이미지 전처리 전략을 사용합니다. 어느 경우에도 AI는 관련 분야에 대해 "알지" 못합니다. 더 중요한 것은, AI가 어떻게 악성과 양성을 구별하거나, 렘브란트와 위조작가를 구별하는지에 대해 우리도 모르고 알 수 없습니다. AI의 판단의 기초는 식별할 수 있지만, 그 판단의 근거는 아직은 알 수 없습니다. "설명 가능한" AI를 개발하기 위한 노력은 AI 모델의 복잡성이 늘어남에 따라 실패했습니다.

AI는 우리가 절대로 보지 못할 패턴을 인식하는 데 아주 뛰어나지만, 세계나 그 일부분의 특수성에 대해 아무것도 알지 못하기 때문에, AI는 바라는 대로 지혜롭지 않습니다. 그 판단의 근거를 제공하기 위해서는 너무 똑똑하지 않습니다. 결과적으로, 우리의 AI에 대한 신뢰는 그 성공 이력에서 거의 완전히 비롯됩니다. 이러한 성적은 전문가의 역량을 훼손시킬 수 있으며, AI 지원에 과도하게 의존하는 결과를 초래할 수 있습니다. 의료 분야에서 의사들은 의심스러운 AI 출력물에 직면할 때, 그것을 수정하는 데 필요한 임상 지식을 상실할 수도 있습니다. 어떻게 보면 오류에도 온전히 의존할 수 있습니다. 어떤 AI 시스템도 완벽하지 않습니다. 오류 가능성은 항상 존재하며, 그로 인해 과도한 의존 가능성도 존재합니다.

<div class="content-ad"></div>


![Image1](/assets/img/2024-06-22-AINeedsOurEye_1.png)
