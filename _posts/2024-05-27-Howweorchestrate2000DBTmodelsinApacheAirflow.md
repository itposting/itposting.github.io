---
title: "어떻게 Apache Airflow에서 2000개 이상의 DBT 모델을 조율하는지"
description: ""
coverImage: "/assets/img/2024-05-27-Howweorchestrate2000DBTmodelsinApacheAirflow_0.png"
date: 2024-05-27 12:49
ogImage: 
  url: /assets/img/2024-05-27-Howweorchestrate2000DBTmodelsinApacheAirflow_0.png
tag: Tech
originalTitle: "How we orchestrate 2000+ DBT models in Apache Airflow"
link: "https://medium.com/@aleexmagno/how-we-orchestrate-2000-dbt-models-in-apache-airflow-90901504032d"
---


![How we orchestrate 2000 DBT models in Apache Airflow](/assets/img/2024-05-27-Howweorchestrate2000DBTmodelsinApacheAirflow_0.png)

요즘에는 DBT (Data Build Tool)가 매우 표현력 있는 SQL과 Jinja 템플릿을 사용하여 변환을 선언하는 방식을 통해 다양한 처리 엔진에 연결되는 데이터 변환 워크플로우로 자리 잡았습니다. 이에 더불어 DBT는 문서 작성, 테스트, 그리고 기본 기능을 확장하는 커뮤니티 제작 패키지에 대한 좋은 지원을 제공합니다. ELT에서의 T를 훨씬 더 쉽고 즐겁게 만들었습니다.

DBT Core는 모델 간의 계보를 다루지만, 프로덕션 환경에서 실행되어야 하는 위치와 시기에 대한 솔루션을 제공하지 않습니다. 다시 말해, 오케스트레이션은 기본적으로 제공되지 않습니다.

본 글에서는 Airflow를 활용하여 DBT Core 프로젝트를 오케스트레이션하는 방법을 살펴볼 수 있습니다. 이를 통해 데이터 분석가 및 심지어 제품 소유자도 자신만의 데이터 모델을 생성하고 유지할 수 있는 직관적인 파이프라인을 만들었습니다. SQL과 Git의 기본 지식만 있으면, 비즈니스의 다양한 사람들이 몇 분 만에 자신의 모델을 Airflow DAG로 전환하여 분산 및 확장 가능한 환경에서 실행할 수 있습니다. 이는 경보, 데이터 품질 테스트, 그리고 내장된 액세스 제어와 함께, Airflow DAG가 무엇인지 알 필요 없이 UI에서 상호 작용할 수 있습니다 😄

<div class="content-ad"></div>

주요 부분으로 나눠 보겠습니다:

- Mono vs Multi DAG 접근 방식
- 프로젝트 구조 및 DAG 레이아웃
- DAG 생성 파이프라인
- DBTOperator를 생성한 방법과 이유
- 결론 및 앞으로의 계획

# Mono vs Multi DAG 접근 방식

이 문제에 대한 직관적인 방법은 전체 DBT 프로젝트를 "하나의 큰 DAG"로 모델링하는 것입니다. 이는 DBT 계보를 고려하여 작업을 연결하기 쉽게 만들어주며 Airflow에서 전체 DBT 프로젝트의 멋진 계보 뷰를 제공합니다.

<div class="content-ad"></div>

하지만 Monon DAG 방식에는 이 프로젝트를 시작할 때 우리에게 중요한 몇 가지 단점이 있습니다:

- DAG 레벨에서 일정이 설정되므로 프로젝트 전체가 동일한 일정으로 실행됩니다. 이는 프로젝트 전체에서 모델에 대해 다른 SLA가 있는 경우 문제가 될 수 있습니다.
- 큰 DAG는 탐색하기 어려울 수 있습니다. 프로젝트에 2000개 이상의 모델이 있는 경우 이 거대한 DAG를 통해 길을 찾는 것은 분석가나 비즈니스 사용자들에게 특히 Airflow에 익숙하지 않은 사람들에게 도전이 될 수 있습니다.
- 접근 제어에 효율적이지 않습니다. 서로 다른 팀이 DBT 프로젝트의 다른 부분을 소유하고 있기 때문에 Airflow에서도 이 분리를 활용해야 합니다. 예를 들어, 당신의 팀만 당신의 모델을 수동으로 트리거하거나 완전한 새로 고침을 수행할 수 있어야 합니다. 하나의 큰 DAG만 있는 것은 전체 프로젝트에 대한 하나의 접근 제어 계층을 의미합니다.
- 모델 실패의 경우 알림을 분할하기가 어려울 수 있습니다. 다시 말하지만, 모델 실패의 경우 관련 팀에만 알림을 보내기를 원했습니다.

매우 중요한 참고: DBT는 여러 프로젝트를 네이티브로 지원하기 전에 프로젝트를 시작했습니다. DBT 코어에서 완전히 지원되지 않았지만, DBT 매쉬는 프로젝트를 분할하고 프로젝트 당 하나의 DAG를 갖는 경험을 보다 수월하게 만들 수 있는 방법일 수 있습니다.

## DBT 프로젝트를 여러 DAG로 분리하기

<div class="content-ad"></div>

위에서 언급한 문제를 해결하기 위해, 우리는 조직에 맞는 그룹화 규칙에 따라 프로젝트를 다른 DAG로 나누기로 결정했습니다. 이를 통해 프로젝트의 다른 부분에 대해 서로 다른 SLA를 가질 수 있고, DAG 수준에서 액세스 제어 및 콜백 함수에서 알림/알림 대상을 다르게 설정할 수 있습니다. 또한, 팀은 자신들의 DAG만 쉽게 필터링할 수 있으며, Airflow에서 모델을 더 잘 탐색할 수 있습니다.

그러나, 어떤 모델을 어떤 DAG에 그룹화할지 결정하는 방법 및 종속 DAG를 어떻게 연결할지에 대한 자연스러운 질문들이 제기됩니다.

이 중요한 질문들은 우리를 오늘날의 솔루션을 개발하는 데 이끌었습니다. 여기에서 언급해야 할 중요한 점은 Airflow에서 DBT 라인어지 전체를 볼 수 있는 것이 우리에게 그다지 중요하지 않다는 점입니다. 우리는 데이터 탐색을 위해 Datahub를 사용하며, 이는 매우 좋은 라인어지보기를 제공합니다. 따라서, 우리는 Airflow를 가능한 가장 효율적인 방법으로 모델 실행을 관리하기 위한 도구로 사용하기로 결정했으며, 데이터 발견 도구로 사용하지는 않기로 했습니다.

# 프로젝트 구조 및 DAG 배치

<div class="content-ad"></div>

이전에 언급된 질문들을 고려할 때, 우리는 모델 그룹 개념을 고안해냈습니다. 모델 그룹은 서로 깊게 관련된 데이터 변환의 집합입니다. 예를 들어 함께 새로 고쳐져야하고 단위로서만 의미가 있는 같은 데이터 마트의 테이블들입니다. 또한, 이러한 테이블들은 단일 팀에 의해 소유되고 유지보수됩니다. 모델 그룹은 비즈니스 목표를 달성하기 위해 고안되었습니다. 중간 변환 수행 및 테이블 그룹 준비, 데이터 마트 생성, KPI 계산 등을 수행합니다.

따라서, 우리는 각 모델 그룹 당 하나의 DAG를 가지기로 결정했습니다. 모델들이 서로 밀접하게 관련되어 있고 함께 스케줄되어야하기 때문입니다.

아래에 제시된 최소주의 프로젝트 구조는 레이아웃을 이해하는 데 도움이 될 수 있습니다.

![이미지](/assets/img/2024-05-27-Howweorchestrate2000DBTmodelsinApacheAirflow_1.png)

<div class="content-ad"></div>

다음과 같이 설명해보겠습니다:

- dbt_project.yml: 이것은 프로젝트의 루트에 있는 일반 dbt_project 파일입니다. 여기에는 특별한 내용이 없습니다.
- deployment.yml: 이 파일에는 배포할 모델 그룹을 등록합니다. 즉, 모델 그룹을 DAG로 변환하기 위한 작업을 수행합니다. 실행 일정, 태그, 소유자 등을 지정합니다. 다음과 같이 보일 것입니다:

```js
# deployment.yml
---
model_groups:
  - name: model_group_a # 폴더의 이름입니다.
    schedule: 0 0 * * * # DAG 일정입니다.
    owner: Team_A # Airflow에서 DAG의 소유자 (역할)입니다.
    tags: [tag1, tag2] # Airflow DAG용 태그입니다.
    description: 추가 변환을 위해 테이블을 준비합니다. # DAG 설명입니다.

  - name: model_group_b
    schedule: 0 2 * * *
    owner: Team_A
    tags: [tag1, tag2]
    description: 여러 테이블을 조인하여 데이터 마트를 생성합니다.
```

- model_group_a 및 model_group_b: SQL 모델(동일한 방식으로 DBT Python 모델도 작동합니다)이 포함된 폴더입니다. 이 예제에서는 model_group_a의 model2.sql이 종속성으로 model_group_a의 model1.sql을 참조한다고 가정합니다. 모델 그룹은 DBT 프로젝트의 폴더이며 모델을 포함합니다. 원하는 만큼 모델을 넣을 수 있으며 하위 폴더에 대한 DAG 생성도 허용합니다.

<div class="content-ad"></div>

Airflow에서는 이 구조가 다음과 같이 보일 것입니다.

이 구조를 통해 몇 가지 중요한 점을 보장할 수 있습니다:

- 의존하는 DAG는 센서로 연결됩니다: 이를 통해 각 모델 그룹이 다른 일정에 따라 실행되도록하고 동시에 실패가 하향으로 전파되는 것을 방지할 수 있습니다. 센서 검사에 실패하면 하향 모델은 건너뛰게 됩니다. 여기 중요한 점은 우리가 기본 Airflow 외부 작업 센서를 분기시켜야 했단 점입니다. 이는 우리가 상류 모델 실행의 최종 상태를 확인하려고 했기 때문입니다. 기본 센서는 특정 실행 날짜만 터치할 수 있기 때문입니다.
- 동일한 DAG 내에서 실행의 계통은 dbt-test 작업을 기반으로 합니다: 이는 데이터 품질 오류가 하향으로 전파되는 것을 방지하여, 데이터 품질 문제가 계속 악화되는 눈덩이 효과를 피할 수 있습니다.
- 각 DAG (모델 그룹)에는 소유자가 있습니다: 이는 해당 DAG에서 수동 작업(전체 갱신 실행 트리거, 작업 지우기 등)을 취할 수 있는 사람이 적합한 팀 멤버뿐이라는 것을 의미합니다.
- DAG의 수와 크기는 유연하며, DBT 프로젝트 레이아웃을 따릅니다: 모든 DAG가 모델 그룹을 기준으로 동적으로 생성되기 때문에, 그 크기나 세분성은 원하는 대로 조절할 수 있습니다. DBT 프로젝트 안의 모델 그룹에 포함된 모델 수가 DAG 레이아웃을 지배합니다.

# DAG 생성 파이프라인

<div class="content-ad"></div>

이제 팀원이 DBT 저장소에서 PR을 생성하는 순간부터 어떤 일이 발생하는지 살펴보겠습니다. 간단히 말해서, DBT 프로젝트의 배포 파이프라인은 다음과 같습니다.

![DBT 프로젝트 배포 파이프라인](/assets/img/2024-05-27-Howweorchestrate2000DBTmodelsinApacheAirflow_2.png)

매 PR에 CI 단계로서 아래 두 가지 매우 중요한 요소가 도입되었습니다:

- 조직 거버넌스 요구 사항 확인: 각 모델은 소유자와 적절한 태그, 설명 등을 가져야 합니다. 이는 매우 중요한데, 데이터 카탈로그를 풍부하고 의미 있는 것으로 만들어주기 때문입니다.
- 스테이징 환경에서 업데이트된 모델 실행: 이를 통해 도입되는 변경 사항이 업데이트된 모델 및 하위 종속성에 대한 성공적인 실행을 보장합니다. DBT CI 실행을 위한 우리의 스테이징 영역에는 생산 모델의 대표적인 샘플이 포함되어 있어 CI 테스트 실행 비용을 최소화합니다. DBT 모델을 CI에서 적절히 테스트하는 것은 별도의 포스트가 필요하며 이에 대해 별도의 글이 필요할 것입니다.

<div class="content-ad"></div>

PR이 병합되면 DAG 생성 프로세스가 시작됩니다. 이 프로세스는 DBT manifest.json 파일을 구문 분석하여 전체 그래프를 가져오는 방식으로 작동합니다. 그런 다음 deployment.yaml에 정의된 모델 그룹 규칙에 따라 다른 DAG가 생성됩니다.

여기서 중요한 개념은 DBT manifest를 구문 분석할 때 "내부" 및 "외부" 모델을 구분하는 것입니다. 내부 모델은 해당 모델 그룹에 포함된 모델이며, 외부 모델은 주어진 모델 그룹 외부의 종속성입니다. 이 구분을 통해 외부 최신 작업 센서인 ExternalLatestTaskSensor를 사용하여 적절한 센서를 할당할 수 있습니다. 이 센서는 Airflow 외부 작업 센서의 파생 버전입니다. 우리는 메타데이터 데이터베이스 쿼리를 수정하여 상위 작업의 최신 상태를 가져와서 (실행 날짜별로 정렬) 센서가 상위 작업의 최신 dbt-test 결과를 확인할 수 있도록 했습니다.

따라서 각 모델 그룹은 개별 일정에 따라 실행될 수 있도록 센서로 연결됩니다. 우리가 고려한 다른 옵션은 TriggerDagRunOperator를 사용하는 것이었지만, 이는 상위 최상위 모델에서만 일정을 설정할 수 있도록 했습니다.

이미지 소스:
![How we orchestrate 2000 DBT models in Apache Airflow](/assets/img/2024-05-27-Howweorchestrate2000DBTmodelsinApacheAirflow_3.png)

<div class="content-ad"></div>

흐름그림(DAGs)을 생성하는 작업 자체는 Jinja를 사용한 템플릿화를 통해 이루어집니다. 결국 우리는 단지 Python 파일들을 생성하는 것이니까요 😃. 특정 DAG에 포함할 모델들, 그들의 "내부" 선조 및 "외부" 모델 의존성(센서)을 결정하면 됩니다.

마지막으로 생성 작업이 완료되면, DAG와 DBT 프로젝트 자산은 Airflow의 자산 버킷에 푸시됩니다. 거기서 다른 프로세스(Airflow에서 실행 중)가 이를 가져갈 것입니다. Airflow 측면에서 작동 방식을 알고 싶다면, 저의 Airflow 글을 참조해주세요.

# 우리가 DBTOperator를 만든 방법과 이유

Airflow에서 DBT를 실행 중이라면 BashOperator를 사용하여 dbt 명령을 실행하거나, 그 작업을 처리할 DBTOperator를 생성할 수 있습니다. 후자의 옵션은 전자보다 많은 이점을 가지고 있으며, 왜 여러분이 자체 DBTOperator를 만들어야 하는지 설명하겠습니다.

<div class="content-ad"></div>

저희는 airflow-dbt 프로젝트의 오픈 소스 구현을 사용하여 DBTOperator 여정을 시작했습니다. 몇 달 동안 잘 사용해 왔지만, 우리만의 Operator를 만드는 것이 가장 좋을 것이라는 것을 깨달았습니다.

우리는 서브프로세스 명령이 아닌 DBT 프로그래밍 방식의 호출을 사용하고 싶었습니다. 이는 실행 결과를 더 잘 처리하는 방법을 제공하며 또한 모범 사례를 준수합니다. dbt cli를 위한 Python 진입점을 사용한 후 코드가 더 깔끔하고 가독성이 향상되었습니다.

가장 중요한 것은 DBT Orchestration 솔루션의 명백한 제한 사항을 해결하고자 했습니다, 특히 버그 수정을 위한 수동 개입을 처리할 때입니다. 이러한 제한 사항 중 일부는 아래에 나열되어 있습니다.

## 증분 모델의 스키마 변경

<div class="content-ad"></div>

DBT에서 기본으로 제공하는 on_schema_change 옵션 중 우리 문제를 해결하는 데는 거의 모든 경우에서 부가 정보를 백필할 필요가 있기 때문에 문제 해결이 되지 않았습니다. 예를 들어 열이 추가될 때 정보를 백필해야 하는 경우가 대부분이었습니다. 그래서 스키마 변경 시 유일한 옵션은 전체 새로 고침을 트리거하는 것이었습니다. 우리는 예상된 소스 스키마 변경으로 인해 많은 모델이 실패했고, 그 당시 "트리거"를 하려면 Snowflake에서 테이블을 삭제해야 했습니다 😅.

물론, 이것은 이상적이지 않습니다. 그래서 우리가 처음으로 구현한 것 중 하나는 사용자 지정 DBTOperator에서 실행이 실패한 후 dbt-run 실행 로그를 구문 분석하여 실패가 스키마 변경으로 인한 것인지 감지하면 --full-refresh 플래그를 전달하여 해당 모델을 자동으로 다시 트리거하는 기능이었습니다. 이 간단한 기능 덕분에 DBT 모델의 일일 유지 보수 시간이 단축되었습니다.

## 대규모 모델이나 전체 새로 고침의 초기 처리

가끔 아주 큰 모델의 초기 처리를 할 때나 여러 이유로 수동으로 전체 새로 고침을 트리거할 때, Snowflake DBT Warehouse를 과부하시키는 경우가 있습니다. 그를 피하기 위해 DBTOperator에 기능을 만들어서 해당 모델을 실행하는 데 사용하는 웨어하우스를 동적으로 변경하고 크기(소형, 중형, 대형 등)를 설정하는 기능을 만들었습니다.

<div class="content-ad"></div>

이렇게 함으로써, 모든 기본적인 작은 증분 모델을 동시에 동일한 DBT Warehouse에서 실행할 수 있으면서, 전용 리소스가 할당된 격리된 Warehouse에서 대규모 실행을 수행할 수 있습니다. 이는 Snowflake 쿼리 실행 대기열의 증가를 방지합니다.

또한, 데이터 분석가들이 Airflow 인터페이스에서 직접 전체 새로 고침을 트리거할 수 있게하여, 테이블을 삭제할 필요가 없습니다. DBTOperator가 하는 일은 적절할 때 dbt run 명령에 --full-refresh 플래그를 전달하는 것 뿐입니다.

## 모델 그룹에서 개별 모델 수동 트리거

때로는 데이터 분석가들이 DAG의 모델 그룹에서 하나 또는 두 개의 모델만 실행하도록 트리거해야 할 필요가 있습니다. 가끔 이러한 실행은 지정된 모델의 전체 새로 고침이어야 할 수도 있습니다.

<div class="content-ad"></div>

위 문제를 해결하기 위해, Airflow DAG의 매개변수로 사용 가능한 옵션을 만들어 선택한 분석가가 DAG에서 특정 모델만 트리거할 수 있도록 했습니다. 그 특정 DagRun에 선택되지 않은 다른 모든 모델은 건너뛰게 됩니다. 이 접근 방식은 한 두 개의 모델만 실행해야 할 때 모든 모델을 실행하여 리소스를 낭비하는 것을 방지합니다.

Airflow의 clear task 옵션을 사용하는 것도 해결책이지만, 사용자가 전체 리프레시를 실행하거나 그 모델을 실행하는 데이터 웨어하우스를 변경해야 하는 경우에는 제한적입니다. Airflow에서 작업을 지우기만 해서 매개변수로 실행을 사용자 정의할 수는 없습니다. 이 사용자 정의 옵션을 통해 분석가가 더 정확하게 그들의 요구 사항을 지정할 수 있어 모델 실행의 효율성과 유연성을 향상시킬 수 있습니다.

## 모델 수정 후 하류 종속성의 트리거

우리의 Airflow-DBT 구조에서 모델 그룹에 따라 많은 DAG가 있으며, 일부 모델은 4~5개의 DAG로 구성된 긴 종속성 체인을 가지고 있습니다. 그 체인의 첫 번째 DAG에서 모델 실행(실행 또는 테스트)이 실패하면 다른 DAG에서의 모든 하류 모델이 오류 전파를 방지하기 위해 건너뛰게 됩니다. 첫 번째 모델이 수정된 후에도 우리는 모든 하류 DAG를 다시 실행할 수 있도록 어떻게 보장할 수 있을까요?

<div class="content-ad"></div>

이전에는 이 작업을 수동으로 처리했었어요 😞. 데이터 분석가들은 모델 수정이 적용된 후 재시작해야 하는 하향 DAG들을 계속 추적해야 했어요. 이 과정은 시간이 많이 소요되고 오류가 발생하기 쉬웠어요.

이 문제를 해결하기 위해, 우리는 Airflow DAG에서 사용되는 DBTOperator의 사용자 정의 로직에 의해 구동되는 하향 트리거 옵션을 만들었어요. DAG 실행 시 이 값을 설정하면 모든 모델이 성공하면 DAG는 자동으로 모든 하향 종속성을 인지하고 해당 종속성들의 DagRun을 트리거합니다. 이를 통해 버그 수정 후 DAG를 수동으로 트리거하는 프로세스가 불필요해졌어요.

우리는 dbt ls 명령을 사용하여 종속성 그래프에 있는 모델을 나열하는데 구현이 간단했어요. 그런 다음, 해당 모델을 DAG와 매핑하고 Airflow의 trigger_dag() 함수를 사용하여 하향 실행을 자동으로 트리거했어요.

더 중요한 것은, 이 프로세스가 "체인 반응"으로 자동으로 계속된다는 것이에요: 트리거된 DAG는 완료되면 하향 종속성도 트리거하도록 인수 플래그를 받아 이 프로세스는 체인에서 마지막 DAG가 완료될 때까지 계속됩니다.

<div class="content-ad"></div>

## DAG 매개변수를 통한 DBT 실행 인터페이스

DBTOperator에 위에서 언급한 솔루션들을 구현한 후, 우리는 또한 DAG 매개변수를 생성하여 일부 구성을 사용자에게 노출시켜 수동 실행을 사용자 정의할 수 있도록 했습니다.

![image](/assets/img/2024-05-27-Howweorchestrate2000DBTmodelsinApacheAirflow_4.png)

이로써 데이터 분석가들과 분석 엔지니어들의 일상에 큰 변화가 생겼습니다. 이제 필요할 때 수동 실행을 완전히 사용자 정의할 수 있게 되었습니다.

<div class="content-ad"></div>

이러한 모든 매개변수는 이전에 설명한 대로 DAG를 자동으로 생성할 때 템플릿에 동적으로 추가됩니다. 따라서 예를 들어, 해당 모델 그룹의 사용 가능한 모델을 사용하여 Models 드롭다운을 채우게 됩니다.

또한 DAG 생성 파이프라인에서 사용되는 "매개변수 주입" 방법은 매우 확장 가능하여 미래에 필요에 따라 더 많은 매개변수를 생성할 수 있습니다. 

# 결론과 앞으로의 방향

저는 이 게시물이 Airflow에서 DBT 오케스트레이션에 대한 다른 관점을 제공할 수 있기를 바랍니다. 이 구현은 2년이 지난 후에도 여전히 우리의 요구를 충족시키지만, 완벽하거나 이상적이지는 않으며 개선할 수 있습니다.

<div class="content-ad"></div>

비슷한 오픈 소스 구현으로는 뛰어난 Astronomer Cosmos 프로젝트를 찾을 수 있어요. 여기서 재미있는 기능은 각 모델에 대한 실행 및 테스트를 결합하기 위해 작업 그룹을 사용한다는 점이에요 (우리도 그랬죠 😍) 그리고 프로젝트 구성을 통해 매우 쉽고 깔끔하게 DbtDag를 선언하는 방식이에요.

프로젝트를 둘 이상의 DAG로 분할하는 것도 가능해요, 생성자가 dbt select 인수를 허용하기 때문에요. 따라서 태그를 전달하고 다른 태그에 따라 프로젝트를 분할할 수 있어요. 그러나 저는 DAG 간의 가능한 상호 작용 (모델 참조)을 어떻게 다루는지는 분명하지 않아요. DBT 조정 여정을 시작한다면 매우 깔끔한 추상화를 제공하기 때문에 꼭 확인해보세요.

지금은 우리 앞에 있는 것이 데이터 계약의 구현이며 그것이 우리가 DBT와 상호 작용하는 방식에 큰 영향을 미치고 있어요. 소스 시스템과 데이터 레이크의 테이블 사이를 잇기 위해 계약을 사용함으로써 연결자(데이터 추출기)의 프로비저닝과 업무 지식이 필요하지 않은 초기(기본) 변환(유형 캐스팅, 열 이름 표준화, 복잡한 필드의 언네스팅)을 수행하는 DBT 모델을 자동화할 수 있어요. 결과적으로, 이전에 설명한 일부 모델 그룹은 데이터 계약을 기반으로 완전히 자동화된 방식으로 생성되고 있어요.

DBT-Airflow 구현에 대해 더 논의할 준비가 되어 있고 커뮤니티가 이 문제를 해결하는 방법에 대해 듣는 것에 매우 열려 있어요. 따라서 유사한 구현이 있다면 어떻게 하는지 알려주세요 😆. 진정으로 높은 가치를 제공하는 멋진 솔루션을 만들 수 있는 것은 연결된 커뮤니티 덕분이에요.