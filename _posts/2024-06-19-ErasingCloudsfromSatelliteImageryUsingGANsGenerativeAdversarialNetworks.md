---
title: "ìœ„ì„± ì´ë¯¸ì§€ì—ì„œ GANsì ëŒ€ì  ìƒì„± ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ êµ¬ë¦„ ì œê±°í•˜ê¸°"
description: ""
coverImage: "/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png"
date: 2024-06-19 18:49
ogImage: 
  url: /assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png
tag: Tech
originalTitle: "Erasing Clouds from Satellite Imagery Using GANs (Generative Adversarial Networks)"
link: "https://medium.com/towards-data-science/erasing-clouds-from-satellite-imagery-using-gans-generative-adversarial-networks-2d7f8467ef2e"
---


## íŒŒì´ì¬ìœ¼ë¡œë¶€í„° GAN(Generative Adversarial Networks) ë§Œë“¤ì–´ ë³´ê¸°

![ì´ë¯¸ì§€](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_0.png)

GAN(Generative Adversarial Networks)ì´ë¼ëŠ” ì•„ì´ë””ì–´ëŠ” 2014ë…„ Goodfellowì™€ ê·¸ ë™ë£Œë“¤ì— ì˜í•´ ì†Œê°œë˜ì—ˆê³ , ê³§ ê·¸ ì´í›„ì— ì»´í“¨í„° ë¹„ì „ ë° ì´ë¯¸ì§€ ìƒì„± ë¶„ì•¼ì—ì„œ ê·¹ë„ë¡œ ì¸ê¸°ë¥¼ ëŒê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì—ì„œì˜ ê¸‰ì†í•œ ë°œì „ê³¼ ìƒˆë¡œìš´ ì•Œê³ ë¦¬ì¦˜ì˜ ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ë”ë¼ë„, ì´ ê°œë…ì˜ ë‹¨ìˆœí•¨ê³¼ ì°½ì˜ì„±ì€ ì—¬ì „íˆ ë§¤ìš° ì¸ìƒì ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ì˜¤ëŠ˜ì€ ì´ëŸ¬í•œ ë„¤íŠ¸ì›Œí¬ê°€ ì–¼ë§ˆë‚˜ ê°•ë ¥í•  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ìœ„ì„± RGB(ë¹¨ê°•, ë…¹ìƒ‰, íŒŒë‘) ì´ë¯¸ì§€ì—ì„œ êµ¬ë¦„ì„ ì œê±°í•˜ëŠ” ì‹œë„ë¥¼ í•´ë³´ë ¤ê³  í•©ë‹ˆë‹¤.

ì ì ˆíˆ ê· í˜• ì¡íˆê³  ì¶©ë¶„íˆ í¬ë©° ì˜¬ë°”ë¥´ê²Œ ì „ì²˜ë¦¬ëœ ì»´í“¨í„° ë¹„ì „ ë°ì´í„°ì…‹ì„ ì¤€ë¹„í•˜ëŠ” ë°ì—ëŠ” ìƒë‹¹í•œ ì‹œê°„ì´ ì†Œìš”ë˜ë¯€ë¡œ, ì €ëŠ” Kaggleì— ì–´ë–¤ ê²ƒì´ ìˆëŠ”ì§€ ì‚´í´ë³´ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤. ì´ ì‘ì—…ì— ê°€ì¥ ì í•©í•˜ë‹¤ê³  ìƒê°í•œ ë°ì´í„°ì…‹ì€ EuroSatì´ë©°, ì´ëŠ” ì˜¤í”ˆ ë¼ì´ì„ ìŠ¤ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ì…‹ì€ Sentinel-2ì—ì„œ 64x64 í”½ì…€ì˜ 27000ê°œì˜ ë ˆì´ë¸”ì´ ì§€ì •ëœ RGB ì´ë¯¸ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆê³ , ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.

<div class="content-ad"></div>


![ì´ë¯¸ì§€](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_1.png)

ìš°ë¦¬ëŠ” ë¶„ë¥˜ ìì²´ì— í¥ë¯¸ê°€ ì—†ì§€ë§Œ EuroSat ë°ì´í„°ì…‹ì˜ ì£¼ìš” ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” ëª¨ë“  ì´ë¯¸ì§€ì— ë§‘ì€ í•˜ëŠ˜ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ê²ƒì´ ì •í™•íˆ ìš°ë¦¬ê°€ í•„ìš”í•œ ê²ƒì…ë‹ˆë‹¤. [3]ì—ì„œ ì´ ì ‘ê·¼ë²•ì„ ì±„íƒí•˜ì—¬, ìš°ë¦¬ëŠ” ì´ Sentinel-2 ìƒ·ì„ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ì…ë ¥ì„ ì¶”ê°€í•˜ì—¬ (êµ¬ë¦„) ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•  ê²ƒì…ë‹ˆë‹¤.

ê·¸ë˜ì„œ ìš°ë¦¬ê°€ GANsì— ëŒ€í•´ ì‹¤ì œë¡œ ì´ì•¼ê¸°í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ ì¤€ë¹„í•´ ë´…ì‹œë‹¤. ìš°ì„ , ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ëª¨ë“  í´ë˜ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ë””ë ‰í† ë¦¬ë¡œ ë³‘í•©í•´ì•¼ í•©ë‹ˆë‹¤.

ğŸì „ì²´ Python ì½”ë“œ: GitHub.


<div class="content-ad"></div>

```js
import numpy as np
import pandas as pd
import random

from os import listdir, mkdir, rename
from os.path import join, exists
import shutil
import datetime

import matplotlib.pyplot as plt
from highlight_text import ax_text, fig_text
from PIL import Image

import warnings

warnings.filterwarnings('ignore')
```

```js
classes = listdir('./EuroSat')
path_target = './EuroSat/all_targets'
path_input = './EuroSat/all_inputs'

"""UNPACKí•œ ì•„ì¹´ì´ë¸Œ íŒŒì¼ì˜ íŒŒì¼ ì´ë¦„ì„ ë³€ê²½í•˜ê¸° ìœ„í•´ ë‹¨ í•œ ë²ˆë§Œ ì‹¤í–‰í•˜ì„¸ìš”"""
mkdir(path_input)
mkdir(path_target)
k = 1
for kind in classes:
  path = join('./EuroSat', str(kind))
  for i, f in enumerate(listdir(path)):
    shutil.copyfile(join(path, f),
                  join(path_target, f))
    rename(join(path_target, f), join(path_target, f'{k}.jpg'))
    k += 1
```

ì¤‘ìš”í•œ ë‘ ë²ˆì§¸ ë‹¨ê³„ëŠ” ë…¸ì´ì¦ˆ ìƒì„±ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ì˜ˆë¥¼ ë“¤ì–´ ì¼ë¶€ í”½ì…€ì„ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•˜ê±°ë‚˜ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ëŠ” ë“±ì˜ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ê¸€ì—ì„œëŠ” ì €ëŠ” ìƒˆë¡œìš´ ë°©ì‹ì¸ Perlin ë…¸ì´ì¦ˆë¥¼ ì‹œë„í•´ ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤. Perlin ë…¸ì´ì¦ˆëŠ” 80ë…„ëŒ€ì— Ken Perlinì´ ì˜í™” ì—°ê¸° íš¨ê³¼ë¥¼ ê°œë°œí•  ë•Œ ë°œëª…í–ˆìŠµë‹ˆë‹¤. ì´ ì¢…ë¥˜ì˜ ë…¸ì´ì¦ˆëŠ” ì¼ë°˜ì ì¸ ëœë¤ ë…¸ì´ì¦ˆì— ë¹„í•´ ë” ìœ ê¸°ì ì¸ ì™¸ê´€ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì €ì—ê²Œ ì´ë¥¼ ì¦ëª…í•˜ëŠ” ê¸°íšŒë¥¼ ì£¼ì„¸ìš”.

```js
def generate_perlin_noise(width, height, scale, octaves, persistence, lacunarity):
    noise = np.zeros((height, width))
    for i in range(height):
        for j in range(width):
            noise[i][j] = pnoise2(i / scale,
                                  j / scale,
                                  octaves=octaves,
                                  persistence=persistence,
                                  lacunarity=lacunarity,
                                  repeatx=width,
                                  repeaty=height,
                                  base=0)
    return noise

def normalize_noise(noise):
    min_val = noise.min()
    max_val = noise.max()
    return (noise - min_val) / (max_val - min_val)

def generate_clouds(width, height, base_scale, octaves, persistence, lacunarity):
    clouds = np.zeros((height, width))
    for octave in range(1, octaves + 1):
        scale = base_scale / octave
        layer = generate_perlin_noise(width, height, scale, 1, persistence, lacunarity)
        clouds += layer * (persistence ** octave)

    clouds = normalize_noise(clouds)
    return clouds

def overlay_clouds(image, clouds, alpha=0.5):

    clouds_rgb = np.stack([clouds] * 3, axis=-1)

    image = image.astype(float) / 255.0
    clouds_rgb = clouds_rgb.astype(float)

    blended = image * (1 - alpha) + clouds_rgb * alpha

    blended = (blended * 255).astype(np.uint8)
    return blended
```

<div class="content-ad"></div>

```js
ê°€ë¡œ, ì„¸ë¡œ = 64, 64
ì˜¥íƒ€ë¸Œ = 12  # í•©ì³ì§€ëŠ” ì¡ìŒ ë ˆì´ì–´ì˜ ìˆ˜
ì§€ì†ì„± = 0.5  # ë‚®ì€ ì§€ì†ì„±ì€ ë†’ì€ ì£¼íŒŒìˆ˜ ì˜¥íƒ€ë¸Œì˜ ì§„í­ì„ ì¤„ì…ë‹ˆë‹¤.
ë¼ì¿ ë‚˜ë¦¬í‹° = 2  # ë†’ì€ ë¼ì¿ ë‚˜ë¦¬í‹°ëŠ” ë†’ì€ ì£¼íŒŒìˆ˜ ì˜¥íƒ€ë¸Œì˜ ì£¼íŒŒìˆ˜ë¥¼ ëŠ˜ë¦½ë‹ˆë‹¤.
for i in range(len(listdir(path_target))):
  ê¸°ë³¸_ìŠ¤ì¼€ì¼ = random.uniform(5, 120)  # ì¡ìŒ ì£¼íŒŒìˆ˜
  ì•ŒíŒŒ = random.uniform(0, 1)  # íˆ¬ëª…ë„

  êµ¬ë¦„ = generate_clouds(ê°€ë¡œ, ì„¸ë¡œ, ê¸°ë³¸_ìŠ¤ì¼€ì¼, ì˜¥íƒ€ë¸Œ, ì§€ì†ì„±, ë¼ì¿ ë‚˜ë¦¬í‹°)

  ì´ë¯¸ì§€ = np.asarray(Image.open(join(path_target, f'{i+1}.jpg')))
  ì´ë¯¸ì§€ = Image.fromarray(overlay_clouds(ì´ë¯¸ì§€, êµ¬ë¦„, ì•ŒíŒŒ))
  ì´ë¯¸ì§€.save(join(path_input, f'{i+1}.jpg'))
  print(f'{i+1}/{len(listdir(path_target))}ë²ˆì§¸ ì²˜ë¦¬ ì™„ë£Œ')
```

```js
ì¸ë±ìŠ¤ = np.random.randint(27000)
fig, ax = plt.subplots(1,2)
ax[0].imshow(np.asarray(Image.open(join(path_target, f'{ì¸ë±ìŠ¤}.jpg')))
ax[1].imshow(np.asarray(Image.open(join(path_input, f'{ì¸ë±ìŠ¤}.jpg')))
ax[0].set_title("ì›ë³¸")
ax[0].axis('off')
ax[1].set_title("ì…ë ¥")
ax[1].axis('off')
plt.show()
```

<img src="/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_2.png" />

ìœ„ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ì´ ì´ë¯¸ì§€ì˜ êµ¬ë¦„ì€ ë§¤ìš° í˜„ì‹¤ì ì´ë©° ë‹¤ì–‘í•œ "ë°€ë„"ì™€ ì§ˆê°ì„ ê°€ì§€ë©° ì‹¤ì œ êµ¬ë¦„ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤.

<div class="content-ad"></div>

ë§Œì•½ ì €ì²˜ëŸ¼ Perlin ì†ŒìŒì— í¥ë¯¸ë¥¼ ëŠë‚€ë‹¤ë©´, ê²Œì„ ê°œë°œ ì‚°ì—…ì—ì„œ ì´ ì†ŒìŒì´ ì–´ë–»ê²Œ ì ìš©ë  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ ì •ë§ ë©‹ì§„ ë¹„ë””ì˜¤ê°€ ìˆì–´ìš”!

ì´ì œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ëœ ë°ì´í„°ì…‹ì´ ìˆìœ¼ë‹ˆ, GANsì— ëŒ€í•´ ì´ì•¼ê¸°í•´ ë³´ê² ìŠµë‹ˆë‹¤.

# ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§

ì´ ì•„ì´ë””ì–´ë¥¼ ë” ì˜ ì„¤ëª…í•˜ê¸° ìœ„í•´, ë™ë‚¨ì•„ì‹œì•„ë¥¼ ì—¬í–‰í•˜ë‹¤ê°€ ë°–ì´ ë„ˆë¬´ ì¶¥ë‹¤ê³  ëŠë‚„ ë•Œ í›„ë””ê°€ ì ˆì‹¤í•˜ê²Œ í•„ìš”í•˜ë‹¤ê³  ìƒìƒí•´ ë³´ì„¸ìš”. ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬ ì‹œì¥ì— ê°€ë³´ë‹ˆ, ëª‡ ê°€ì§€ ë¸Œëœë“œ ì˜ë¥˜ê°€ ìˆëŠ” ì‘ì€ ê°€ê²Œë¥¼ ë°œê²¬í–ˆì–´ìš”. íŒë§¤ìê°€ ìœ ëª…í•œ ë¸Œëœë“œ ExpensiveButNotWorthItì˜ í›„ë””ë¥¼ ì‹œë„í•´ë³´ë¼ë©° ê´œì°®ì€ í›„ë””ë¥¼ ê°€ì ¸ë‹¤ì¤ë‹ˆë‹¤. ë” ìì„¸íˆ ì‚´í´ë³´ê³  ë¶„ëª…íˆ ê°€ì§œë¼ê³  ê²°ë¡  ë‚´ë¦¬ê²Œ ë©ë‹ˆë‹¤. íŒë§¤ìê°€ ë§í•©ë‹ˆë‹¤: 'ì ì‹œë§Œìš”, ì§„ì§œ ê²ƒì´ ìˆì–´ìš”.' ê·¸ê°€ ë‹¤ë¥¸ í›„ë””ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë°, ë¸Œëœë“œ ì œí’ˆê³¼ ë” ë‹®ì•˜ì§€ë§Œ ì—¬ì „íˆ ê°€ì§œì…ë‹ˆë‹¤. ì´ì™€ ê°™ì€ ë°˜ë³µ ì‘ì—…ì„ ëª‡ ë²ˆ ê±°ì¹œ í›„, íŒë§¤ìê°€ ì „ì„¤ì ì¸ ExpensiveButNotWorthItì˜ êµ¬ë³„ì´ ì–´ë ¤ìš´ ì‚¬ë³¸ì„ ê°€ì ¸ì™€ ì—¬ëŸ¬ë¶„ì€ ê¸°êº¼ì´ êµ¬ë§¤í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ê²ƒì´ ë°”ë¡œ GANsê°€ ì‘ë™í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤!

<div class="content-ad"></div>

GANì˜ ê²½ìš°, ë‹¹ì‹ ì€ íŒë³„ì(D)ë¼ê³  ë¶ˆë¦½ë‹ˆë‹¤. íŒë³„ìì˜ ëª©í‘œëŠ” ì§„ì§œ ë¬¼ì²´ì™€ ê°€ì§œ ë¬¼ì²´ë¥¼ êµ¬ë³„í•˜ê±°ë‚˜ ì´ì§„ ë¶„ë¥˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ì— ë°˜í•´, ìƒì„±ì(G)ëŠ” ë†’ì€ í’ˆì§ˆì˜ ê°€ì§œë¥¼ ìƒì„±í•˜ë ¤ê³  í•˜ëŠ” íŒë§¤ìë¼ê³  ë¶ˆë¦½ë‹ˆë‹¤. íŒë³„ìì™€ ìƒì„±ìëŠ” ì„œë¡œ ëŠ¥ê°€í•˜ê¸° ìœ„í•´ ë…ë¦½ì ìœ¼ë¡œ í›ˆë ¨ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ìµœì¢…ì ìœ¼ë¡œ ìš°ë¦¬ëŠ” ë†’ì€ í’ˆì§ˆì˜ ê°€ì§œë¥¼ ì–»ìŠµë‹ˆë‹¤.

![ì´ë¯¸ì§€](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_3.png)

í›ˆë ¨ ê³¼ì •ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰ë©ë‹ˆë‹¤:

- ì…ë ¥ ë…¸ì´ì¦ˆë¥¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤ (ìš°ë¦¬ì˜ ê²½ìš° êµ¬ë¦„ì´ ìˆëŠ” ì´ë¯¸ì§€).
- ë…¸ì´ì¦ˆë¥¼ ìƒì„±ì(G)ì— ê³µê¸‰í•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
- D ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. Gì˜ ì¶œë ¥ì— ëŒ€í•œ í•˜ë‚˜ì™€ ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•œ ë‹¤ë¥¸ ì˜ˆì¸¡ì„ ì–»ì–´ì„œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
- Dì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
- ë‹¤ì‹œ ì…ë ¥ ë…¸ì´ì¦ˆë¥¼ ìƒ˜í”Œë§í•©ë‹ˆë‹¤.
- ë…¸ì´ì¦ˆë¥¼ ìƒì„±ì(G)ì— ê³µê¸‰í•˜ê³  ì˜ˆì¸¡ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
- G ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. Gì˜ ì˜ˆì¸¡ì„ Dì— ê³µê¸‰í•˜ì—¬ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
- Gì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.

<div class="content-ad"></div>


![Erasing Clouds from Satellite Imagery Using GANs](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_4.png)

In other words, we can define a value function V(G,D):

![Value function V(G,D)](/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_5.png)

where we want to minimize the term log(1-D(G(z))) to train G and maximize log D(x) to train D (in this notation x â€” real data sample and z â€” noise).


<div class="content-ad"></div>

ì´ì œ íŒŒì´í† ì¹˜ì—ì„œ êµ¬í˜„í•´ ë´…ì‹œë‹¤!

ì›ë³¸ ë…¼ë¬¸ì—ì„œ ì €ìë“¤ì€ Multilayer Perceptron (MLP)ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì— ëŒ€í•´ ì–¸ê¸‰í•©ë‹ˆë‹¤; ì´ê²ƒì€ ANNìœ¼ë¡œ ê°„ë‹¨íˆë„ ë¶ˆë¦½ë‹ˆë‹¤ë§Œ, ì €ëŠ” ë¯¸ì„¸í•œ ì ‘ê·¼ì„ ì‹œë„í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤ â€” Generatorë¡œ UNet [5] ì•„í‚¤í…ì²˜ë¥¼ ì‚¬ìš©í•˜ê³ , Discriminatorë¡œëŠ” ResNet [6]ì„ ì‚¬ìš©í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. ì´ë“¤ì€ ë‘˜ ë‹¤ ì˜ ì•Œë ¤ì§„ CNN ì•„í‚¤í…ì²˜ì´ê¸° ë•Œë¬¸ì— ì—¬ê¸°ì„œ ì„¤ëª…í•˜ì§€ëŠ” ì•Šê² ìŠµë‹ˆë‹¤ (ëŒ“ê¸€ì—ì„œ ë³„ë„ì˜ ê¸€ì„ ì“¸ì§€ ì—¬ë¶€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”).

ì´ì œ êµ¬ì¶•í•´ ë´…ì‹œë‹¤. Discriminator:

```python
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from torch.utils.data import Subset
```

<div class="content-ad"></div>

```js
class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Sequential(
                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),
                        nn.BatchNorm2d(out_channels),
                        nn.ReLU())
        self.conv2 = nn.Sequential(
                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),
                        nn.BatchNorm2d(out_channels))
        self.downsample = downsample
        self.relu = nn.ReLU()
        self.out_channels = out_channels

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.conv2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


class ResNet(nn.Module):
    def __init__(self, block=ResidualBlock, all_connections=[3,4,6,3]):
        super(ResNet, self).__init__()
        self.inputs = 16
        self.conv1 = nn.Sequential(
                        nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1),
                        nn.BatchNorm2d(16),
                        nn.ReLU()) #16x64x64
        self.maxpool = nn.MaxPool2d(kernel_size = 2, stride = 2) #16x32x32


        self.layer0 = self.makeLayer(block, 16, all_connections[0], stride = 1) #connections = 3, shape: 16x32x32
        self.layer1 = self.makeLayer(block, 32, all_connections[1], stride = 2)#connections = 4, shape: 32x16x16
        self.layer2 = self.makeLayer(block, 128, all_connections[2], stride = 2)#connections = 6, shape: 1281x8x8
        self.layer3 = self.makeLayer(block, 256, all_connections[3], stride = 2)#connections = 3, shape: 256x4x4
        self.avgpool = nn.AvgPool2d(4, stride=1)
        self.fc = nn.Linear(256, 1)

    def makeLayer(self, block, outputs, connections, stride=1):
        downsample = None
        if stride != 1 or self.inputs != outputs:
            downsample = nn.Sequential(
                nn.Conv2d(self.inputs, outputs, kernel_size=1, stride=stride),
                nn.BatchNorm2d(outputs),
            )
        layers = []
        layers.append(block(self.inputs, outputs, stride, downsample))
        self.inputs = outputs
        for i in range(1, connections):
            layers.append(block(self.inputs, outputs))

        return nn.Sequential(*layers)


    def forward(self, x):
        x = self.conv1(x)
        x = self.maxpool(x)
        x = self.layer0(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.avgpool(x)
        x = x.view(-1, 256)
        x = self.fc(x).flatten()
        return F.sigmoid(x)
```

Generator:

```js
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

class UNet(nn.Module):
    def __init__(self):
      super().__init__()
      self.conv_1 = DoubleConv(3, 32) # 32x64x64
      self.pool_1 = nn.MaxPool2d(kernel_size=2, stride=2) # 32x32x32

      self.conv_2 = DoubleConv(32, 64)  #64x32x32
      self.pool_2 = nn.MaxPool2d(kernel_size=2, stride=2) #64x16x16

      self.conv_3 = DoubleConv(64, 128)  #128x16x16
      self.pool_3 = nn.MaxPool2d(kernel_size=2, stride=2) #128x8x8

      self.conv_4 = DoubleConv(128, 256)  #256x8x8
      self.pool_4 = nn.MaxPool2d(kernel_size=2, stride=2) #256x4x4

      self.conv_5 = DoubleConv(256, 512)  #512x2x2

      #DECODER
      self.upconv_1 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2) #256x4x4
      self.conv_6 = DoubleConv(512, 256) #256x4x4


      self.upconv_2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2) #128x8x8
      self.conv_7 = DoubleConv(256, 128)  #128x8x8

      self.upconv_3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2) #64x16x16
      self.conv_8 = DoubleConv(128, 64)  #64x16x16

      self.upconv_4 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2) #32x32x32
      self.conv_9 = DoubleConv(64, 32)  #32x32x32

      self.output = nn.Conv2d(32, 3, kernel_size = 3, stride = 1, padding = 1) #3x64x64

    def forward(self, batch):

      conv_1_out = self.conv_1(batch)
      conv_2_out = self.conv_2(self.pool_1(conv_1_out))
      conv_3_out = self.conv_3(self.pool_2(conv_2_out))
      conv_4_out = self.conv_4(self.pool_3(conv_3_out))
      conv_5_out = self.conv_5(self.pool_4(conv_4_out))

      conv_6_out = self.conv_6(torch.cat([self.upconv_1(conv_5_out), conv_4_out], dim=1))
      conv_7_out = self.conv_7(torch.cat([self.upconv_2(conv_6_out), conv_3_out], dim=1))
      conv_8_out = self.conv_8(torch.cat([self.upconv_3(conv_7_out), conv_2_out], dim=1))
      conv_9_out = self.conv_9(torch.cat([self.upconv_4(conv_8_out), conv_1_out], dim=1))

      output = self.output(conv_9_out)


      return F.sigmoid(output)
```

ì´ì œ ë°ì´í„°ë¥¼ í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• í•˜ê³  torch ë°ì´í„° ì„¸íŠ¸ë¡œ ë˜í•‘í•´ì•¼í•©ë‹ˆë‹¤:

<div class="content-ad"></div>

```python
class dataset(Dataset):
    def __init__(self, batch_size, images_paths, targets, img_size=64):
        self.batch_size = batch_size
        self.img_size = img_size
        self.images_paths = images_paths
        self.targets = targets
        self.len = len(self.images_paths) // batch_size

        self.transform = transforms.Compose([
            transforms.ToTensor(),
        ])

        self.batch_im = [self.images_paths[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]
        self.batch_t = [self.targets[idx * self.batch_size:(idx + 1) * self.batch_size] for idx in range(self.len)]

    def __getitem__(self, idx):
        pred = torch.stack([
            self.transform(Image.open(join(path_input, file_name)))
            for file_name in self.batch_im[idx]
        ])
        target = torch.stack([
            self.transform(Image.open(join(path_target, file_name)))
            for file_name in self.batch_im[idx]
        ])
        return pred, target

    def __len__(self):
        return self.len
```

ë©‹ì ¸ìš”. ì´ì œ í›ˆë ¨ ë£¨í”„ë¥¼ ì‘ì„±í•  ì‹œê°„ì…ë‹ˆë‹¤. ê·¸ ì „ì— ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•´ ë´…ì‹œë‹¤:

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

batch_size = 64
num_epochs = 15
learning_rate_D = 1e-5
learning_rate_G = 1e-4

discriminator = ResNet()
generator = UNet()

bce = nn.BCEWithLogitsLoss()
l1loss = nn.L1Loss()

optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate_D)
optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate_G)

scheduler_D = optim.lr_scheduler.StepLR(optimizer_D, step_size=10, gamma=0.1)
scheduler_G = optim.lr_scheduler.StepLR(optimizer_G, step_size=10, gamma=0.1)
```

ì´ì „ GAN ì•Œê³ ë¦¬ì¦˜ ê·¸ë¦¼ì˜ ì†ì‹¤ í•¨ìˆ˜ì™€ëŠ” ë‹¤ë¥¸ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ L1 ì†ì‹¤ì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ì´ ì•„ì´ë””ì–´ëŠ” ìš°ë¦¬ê°€ ë¬´ì‘ìœ„ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ì…ë ¥ì—ì„œ ëŒ€ë¶€ë¶„ì˜ ì •ë³´ë¥¼ ìœ ì§€í•˜ê³  ë…¸ì´ì¦ˆë§Œ ì œê±°í•˜ë ¤ê³  í•œë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ë”°ë¼ì„œ G ì†ì‹¤ì€ ë‹¤ìŒê³¼ ê°™ì„ ê²ƒì…ë‹ˆë‹¤:

<div class="content-ad"></div>


G_loss = log(1 âˆ’ D(G(z))) + ğ€ |G(z)-y|

instead of just

G_loss = log(1 âˆ’ D(G(z)))

ğ€ is an arbitrary coefficient, which balances two components of the losses.


<div class="content-ad"></div>

ì´ì œ ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ í›ˆë ¨ ê³¼ì •ì„ ì‹œì‘í•´ë´…ì‹œë‹¤:

```js
test_ratio, train_ratio = 0.3, 0.7
num_test = int(len(listdir(path_target)) * test_ratio)
num_train = int((int(len(listdir(path_target))) - num_test))

img_size = (64, 64)

print("í›ˆë ¨ ìƒ˜í”Œ ìˆ˜:", num_train)
print("í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜:", num_test)

random.seed(231)
train_idxs = np.array(random.sample(range(num_test + num_train), num_train))
mask = np.ones(num_train + num_test, dtype=bool)
mask[train_idxs] = False

images = {}
features = random.sample(listdir(path_input), num_test + num_train)
targets = random.sample(listdir(path_target), num_test + num_train)

random.Random(231).shuffle(features)
random.Random(231).shuffle(targets)

train_input_img_paths = np.array(features)[train_idxs]
train_target_img_path = np.array(targets)[train_idxs]
test_input_img_paths = np.array(features)[mask]
test_target_img_path = np.array(targets)[mask]

train_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=train_input_img_paths, targets=train_target_img_path)
test_loader = dataset(batch_size=batch_size, img_size=img_size, images_paths=test_input_img_paths, targets=test_target_img_path)
```

ì´ì œ í›ˆë ¨ ë£¨í”„ë¥¼ ì‹¤í–‰í•´ë´…ì‹œë‹¤:

```js
train_loss_G, train_loss_D, val_loss_G, val_loss_D = [], [], [], []
all_loss_G, all_loss_D = [], []
best_generator_epoch_val_loss, best_discriminator_epoch_val_loss = -np.inf, -np.inf
for epoch in range(num_epochs):

    discriminator.train()
    generator.train()

    discriminator_epoch_loss, generator_epoch_loss = 0, 0

    for inputs, targets in train_loader:
        inputs, true = inputs, targets

        '''1. íŒë³„ì (ResNet) í›ˆë ¨í•˜ê¸°'''
        optimizer_D.zero_grad()

        fake = generator(inputs).detach()

        pred_fake = discriminator(fake).to(device)
        loss_fake = bce(pred_fake, torch.zeros(batch_size, device=device))

        pred_real = discriminator(true).to(device)
        loss_real = bce(pred_real, torch.ones(batch_size, device=device))

        loss_D = (loss_fake + loss_real) / 2

        loss_D.backward()
        optimizer_D.step()

        discriminator_epoch_loss += loss_D.item()
        all_loss_D.append(loss_D.item())

        '''2. ìƒì„±ì (UNet) í›ˆë ¨í•˜ê¸°'''
        optimizer_G.zero_grad()

        fake = generator(inputs)
        pred_fake = discriminator(fake).to(device)

        loss_G_bce = bce(pred_fake, torch.ones_like(pred_fake, device=device))
        loss_G_l1 = l1loss(fake, targets) * 100
        loss_G = loss_G_bce + loss_G_l1
        loss_G.backward()
        optimizer_G.step()

        generator_epoch_loss += loss_G.item()
        all_loss_G.append(loss_G.item())

    discriminator_epoch_loss /= len(train_loader)
    generator_epoch_loss /= len(train_loader)
    train_loss_D.append(discriminator_epoch_loss)
    train_loss_G.append(generator_epoch_loss)

    discriminator.eval()
    generator.eval()

    discriminator_epoch_val_loss, generator_epoch_val_loss = 0, 0

    with torch.no_grad():
        for inputs, targets in test_loader:
            inputs, targets = inputs, targets

            fake = generator(inputs)
            pred = discriminator(fake).to(device)

            loss_G_bce = bce(fake, torch.ones_like(fake, device=device))
            loss_G_l1 = l1loss(fake, targets) * 100
            loss_G = loss_G_bce + loss_G_l1
            loss_D = bce(pred.to(device), torch.zeros(batch_size, device=device))

            discriminator_epoch_val_loss += loss_D.item()
            generator_epoch_val_loss += loss_G.item()

    discriminator_epoch_val_loss /= len(test_loader)
    generator_epoch_val_loss /= len(test_loader)

    val_loss_D.append(discriminator_epoch_val_loss)
    val_loss_G.append(generator_epoch_val_loss)

    print(f"------ì—í¬í¬ [{epoch+1}/{num_epochs}]------\ní›ˆë ¨ ì†ì‹¤ D: {discriminator_epoch_loss:.4f}, ê²€ì¦ ì†ì‹¤ D: {discriminator_epoch_val_loss:.4f}")
    print(f'í›ˆë ¨ ì†ì‹¤ G: {generator_epoch_loss:.4f}, ê²€ì¦ ì†ì‹¤ G: {generator_epoch_val_loss:.4f}')

    if discriminator_epoch_val_loss > best_discriminator_epoch_val_loss:
        discriminator_epoch_val_loss = best_discriminator_epoch_val_loss
        torch.save(discriminator.state_dict(), "discriminator.pth")
    if generator_epoch_val_loss > best_generator_epoch_val_loss:
        generator_epoch_val_loss = best_generator_epoch_val_loss
        torch.save(generator.state_dict(), "generator.pth")

    fig, ax = plt.subplots(1,3)
    ax[0].imshow(np.transpose(inputs.numpy()[7], (1,2,0)))
    ax[1].imshow(np.transpose(targets.numpy()[7], (1,2,0)))
    ax[2].imshow(np.transpose(fake.detach().numpy()[7], (1,2,0)))
    plt.show()
```

<div class="content-ad"></div>

ì½”ë“œê°€ ëë‚˜ë©´ ì†ì‹¤ì„ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë³¼ ìˆ˜ ìˆì–´ìš”. ì´ ì½”ë“œëŠ” ì´ ë©‹ì§„ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì¼ë¶€ ì±„íƒë˜ì—ˆì–´ìš”:

```js
from matplotlib.font_manager import FontProperties

background_color = '#001219'
font = FontProperties(fname='LexendDeca-VariableFont_wght.ttf')
fig, ax = plt.subplots(1, 2, figsize=(16, 9))
fig.set_facecolor(background_color)
ax[0].set_facecolor(background_color)
ax[1].set_facecolor(background_color)

ax[0].plot(range(len(all_loss_G)), all_loss_G, color='#bc6c25', lw=0.5) 
ax[1].plot(range(len(all_loss_D)), all_loss_D, color='#00b4d8', lw=0.5)

ax[0].scatter(
      [np.array(all_loss_G).argmax(), np.array(all_loss_G).argmin()],
      [np.array(all_loss_G).max(), np.array(all_loss_G).min()],
      s=30, color='#bc6c25',
   )
ax[1].scatter(
      [np.array(all_loss_D).argmax(), np.array(all_loss_D).argmin()],
      [np.array(all_loss_D).max(), np.array(all_loss_D).min()],
      s=30, color='#00b4d8',
   )

ax.text(
      np.array(all_loss_G).argmax()+60, np.array(all_loss_G).max()+0.1,
      f'{round(np.array(all_loss_G).max(),1)}',
      fontsize=13, color='#bc6c25',
      font=font,
      ax=ax[0]
   )
ax.text(
      np.array(all_loss_G).argmin()+60, np.array(all_loss_G).min()-0.1,
      f'{round(np.array(all_loss_G).min(),1)}',
      fontsize=13, color='#bc6c25',
      font=font,
      ax=ax[0]
   )

ax.text(
      np.array(all_loss_D).argmax()+60, np.array(all_loss_D).max()+0.01,
      f'{round(np.array(all_loss_D).max(),1)}',
      fontsize=13, color='#00b4d8',
      font=font,
      ax=ax[1]
   )
ax.text(
      np.array(all_loss_D).argmin()+60, np.array(all_loss_D).min()-0.005,
      f'{round(np.array(all_loss_D).min(),1)}',
      fontsize=13, color='#00b4d8',
      font=font,
      ax=ax[1]
   )
for i in range(2):
    ax[i].tick_params(axis='x', colors='white')
    ax[i].tick_params(axis='y', colors='white')
    ax[i].spines['left'].set_color('white') 
    ax[i].spines['bottom'].set_color('white') 
    ax[i].set_xlabel('Epoch', color='white', fontproperties=font, fontsize=13)
    ax[i].set_ylabel('Loss', color='white', fontproperties=font, fontsize=13)

ax[0].set_title('Generator', color='white', fontproperties=font, fontsize=18)
ax[1].set_title('Discriminator', color='white', fontproperties=font, fontsize=18)
plt.savefig('Loss.jpg')
plt.show()
# ax[0].set_axis_off()
# ax[1].set_axis_off()
```

ë˜í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ì„ì˜ì˜ ìƒ˜í”Œì„ ì‹œê°í™”í• ê²Œìš”:

```js
random.Random(2).shuffle(test_target_img_path)
random.Random(2).shuffle(test_input_img_paths)
subset_loader = dataset(batch_size=5, img_size=img_size, images_paths=test_input_img_paths,
                        targets=test_target_img_path)
generator = UNet()
generator.load_state_dict(torch.load('generator.pth'))

generator.eval()
for X, y in subset_loader:
    fig, axes = plt.subplots(5, 3, figsize=(9, 9))

    for i in range(5):
        axes[i, 0].imshow(np.transpose(X.numpy()[i], (1, 2, 0)))
        axes[i, 0].set_title("Input")
        axes[i, 0].axis('off')
        
        axes[i, 1].imshow(np.transpose(y.numpy()[i], (1, 2, 0)))
        axes[i, 1].set_title("Target")
        axes[i, 1].axis('off')
        
        generated_image = generator(X[i].unsqueeze(0)).detach().numpy()[0]
        axes[i, 2].imshow(np.transpose(generated_image, (1, 2, 0)))
        axes[i, 2].set_title("Generated")
        axes[i, 2].axis('off')
    
    # ë ˆì´ì•„ì›ƒ ì¡°ì •
    plt.tight_layout()
    plt.savefig('Test.jpg')
    plt.show()
    break 
```

<div class="content-ad"></div>

<img src="/assets/img/2024-06-19-ErasingCloudsfromSatelliteImageryUsingGANsGenerativeAdversarialNetworks_6.png" />

ì—¬ê¸°ì„œ ë³´ì‹œë‹¤ì‹œí”¼, ê²°ê³¼ëŠ” ì™„ë²½í•˜ì§€ ì•Šê³  ë•…ì»¤ë²„ ìœ í˜•ì— ë§¤ìš° ì˜ì¡´í•©ë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , êµ¬ì¶•ëœ ëª¨ë¸ì€ ì´ë¯¸ì§€ì—ì„œ êµ¬ë¦„ì„ ì œê±°í•˜ë©°, G ë° D ê¹Šì´ë¥¼ ëŠ˜ë¦¬ëŠ” ê²ƒìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìœ ë§í•œ ì „ëµì€ ì„œë¡œ ë‹¤ë¥¸ ë•…ì»¤ë²„ ìœ í˜•ì„ ìœ„í•´ ë³„ë„ì˜ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‘ë¬¼ë°­ê³¼ ë¬¼ íˆ¬êµ¬ëŠ” ë¶„ëª…íˆ ë‹¤ë¥¸ ê³µê°„ì  íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì— ì¼ë°˜í™” ëª¨ë¸ì˜ ëŠ¥ë ¥ì— ì˜í–¥ì„ ì£¼ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤.

ì´ ê¸°ì‚¬ê°€ ì§€ë¦¬ì •ë³´ ë„ë©”ì¸ì—ì„œ ì‹¬ì¸µ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ëŠ” ë° ìƒˆë¡œìš´ ì‹œê°ì„ ì œê³µí•´ ë“œë ¸ê¸°ë¥¼ ë°”ëë‹ˆë‹¤. ë‚´ ìƒê°ì—ëŠ”, GANsëŠ” ë°ì´í„° ê³¼í•™ìê°€ í™œìš©í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ê°•ë ¥í•œ ë„êµ¬ ì¤‘ í•˜ë‚˜ì´ë©°, ì—¬ëŸ¬ë¶„ì˜ ë„êµ¬ ìƒìì˜ í•„ìˆ˜ì ì¸ ë¶€ë¶„ì´ ë˜ê¸¸ í¬ë§í•©ë‹ˆë‹¤!

===========================================

<div class="content-ad"></div>

ì°¸ê³ ë¬¸í—Œ:

1. Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville ë° Yoshua Bengio. â€œGenerative adversarial nets.â€ Advances in neural information processing systems 27 (2014). [ë…¼ë¬¸ ë§í¬](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)

2. Helber, Patrick, Benjamin Bischke, Andreas Dengel ë° Damian Borth. â€œEurosat: A novel dataset and deep learning benchmark for land use and land cover classification.â€ IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing 12, no. 7 (2019): 2217â€“2226. [ë…¼ë¬¸ ë§í¬](https://arxiv.org/pdf/1709.00029)

3. Wen, Xue, Zongxu Pan, Yuxin Hu ë° Jiayin Liu. â€œGenerative adversarial learning in YUV color space for thin cloud removal on satellite imagery.â€ Remote Sensing 13, no. 6 (2021): 1079. [ë…¼ë¬¸ ë§í¬](https://www.mdpi.com/2072-4292/13/6/1079)

<div class="content-ad"></div>

5. Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. â€œU-net: Convolutional networks for biomedical image segmentation.â€ In Medical image computing and computer-assisted interventionâ€“MICCAI 2015: 18th international conference, Munich, Germany, October 5â€“9, 2015, proceedings, part III 18, pp. 234â€“241. Springer International Publishing, 2015. [Link](https://arxiv.org/pdf/1505.04597)

6. He, Kaiming, et al. â€œDeep residual learning for image recognition.â€ Proceedings of the IEEE conference on computer vision and pattern recognition. 2016. [Link](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

===========================================

<div class="content-ad"></div>

ì œ Mediumì˜ ëª¨ë“  ê²Œì‹œë¬¼ì€ ë¬´ë£Œì´ë©° ê³µê°œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì—¬ê¸°ì„œ ì €ë¥¼ íŒ”ë¡œìš°í•´ ì£¼ì‹œë©´ ì •ë§ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!

P.s. ì €ëŠ” (ì§€ë¦¬)ë°ì´í„° ê³¼í•™, ë¨¸ì‹  ëŸ¬ë‹/ì¸ê³µì§€ëŠ¥, ê¸°í›„ ë³€í™”ì— ëŒ€í•´ ì—´ì •ì ìœ¼ë¡œ ê´€ì‹¬ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë˜ì„œ ì–´ë–¤ í”„ë¡œì íŠ¸ì—ì„œ í•¨ê»˜ ì‘ì—…í•˜ê³  ì‹¶ë‹¤ë©´ LinkedInì—ì„œ ì—°ë½ ì£¼ì„¸ìš”.

ğŸ›°ï¸ë” ë§ì€ ì†Œì‹ì„ ë°›ì•„ë³´ë ¤ë©´ íŒ”ë¡œìš°í•˜ì„¸ìš”!ğŸ›°ï¸