---
title: "대형 언어 모델LLM 작동 방식 완벽 가이드 기초부터 고급까지"
description: ""
coverImage: "/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_0.png"
date: 2024-06-22 20:56
ogImage: 
  url: /assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_0.png
tag: Tech
originalTitle: "How Large Language Model Works (LLMs: Zero-to-Hero)"
link: "https://medium.com/@waylandzhang/how-large-language-model-works-llms-zero-to-hero-d2a8c1ac0e1e"
---


제 ‘제로 투 히어로’ 시리즈의 두 번째 기사입니다. 이 기사에서는 대형 언어 모델 (LLM)이 작동하는 방식을 쉽게 설명해 드릴 예정입니다.

# LLM 작동 방식

먼저 문서 완성 모델이 어떻게 작동하는지 살펴봅시다:

![이미지](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_0.png)

<div class="content-ad"></div>

사용자 프롬프트:

```js
바나나는
```

모델 응답:

```js
납작하고 먹을 수 있는 과일
```

<div class="content-ad"></div>

그럼, 문서 생성기 모델은 이렇게 작동합니다:

![image](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_1.png)

사용자 프롬프트:

```js
나는 새 차를 사고 싶어요
```

<div class="content-ad"></div>

"테이블 태그를 Markdown 형식으로 바꿔주세요."

위의 두 가지 사항 사이의 차이점을 주목해주세요.

첫 번째 모델은 문서 완성기로, 다음 문자가 될 가능성이 가장 높은 것을 찾아서 프롬프트만 완성합니다. 이 모델은 인터넷 데이터의 일부분을 학습한 것으로, 기본 모델이라고 불립니다.

<div class="content-ad"></div>

두 번째 모델은 문서 생성기입니다. 이 모델은 프롬프트 질문을 기반으로 한 인간과 유사한 응답을 생성합니다. 이것은 ChatGPT 모델입니다.

ChatGPT 모델은 프롬프트 질문을 기반으로 한 응답을 생성할 수 있는 추론 모델입니다. 저는 이 모델이 99% 베이스 모델이지만 두 가지 추가 단계인 파인튜닝 단계와 인간 피드백에서의 강화 학습 단계가 있습니다.

# 사전 훈련: 베이스 모델

이것은 인공 지능 혁명의 핵심이자 실제 마법이 일어나는 곳입니다.

<div class="content-ad"></div>

모델을 훈련하는 것은 많은 데이터를 제공하고 그것으로부터 배우는 과정입니다.

GPT-3 논문에 설명된 대로, 기본 모델은 인터넷 데이터의 대량을 바탕으로 훈련됩니다. 그것은 여러분과 같은 일반인에게는 쉬운 일이 아닙니다. 데이터를 획득하는 것 뿐만 아니라 GPU 및 TPU와 같은 많은 컴퓨팅 파워도 필요합니다.

하지만 걱정 마세요. 우리 자신의 컴퓨터에서 작은 GPT 모델을 훈련하는 방법을 여전히 배울 수 있습니다. 다음 주제에서 어떻게 하느지 보여 드리겠습니다.

LLM 훈련 뒤에 있는 혁신은 Transformer 아키텍처의 도입에 있습니다. 이를 통해 모델은 광범위한 데이터에서 배우면서 입력의 서로 다른 부분 간의 중요한 맥락적 관골을 유지할 수 있습니다.

<div class="content-ad"></div>

이러한 연결을 유지함으로써 모델은 제공된 문맥을 기반으로 새로운 통찰력을 효과적으로 추론할 수 있습니다. 이 문맥은 개별 단어, 문장, 문단 또는 그 이상일 수 있습니다. 이 능력을 통해 LLM 훈련은 자연어 처리 및 생성 작업에 대한 새로운 기회를 열어주어 기계가 인간의 의사 소통에 더 잘 이해하고 응답할 수 있도록 합니다.

기본 모델을 훈련하는 데 사용된 트랜스포머 아키텍처는 아래에 표시됩니다:


![LLM](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_2.png)


이는 일부 이전 및 새로운 기법을 사용하여 훈련된 신경망 모델입니다: 토큰화, 임베딩, 위치 인코딩, 피드포워드, 정규화, 소프트맥스, 선형 변환 및 가장 중요한 것은 멀티헤드 어텐션입니다.

<div class="content-ad"></div>

이 부분은 당신과 저 모두가 대부분 관심을 가지고 있는 부분이에요. 우리는 아키텍처 뒤의 아이디어와 교육 과정이 정확히 어떻게 이루어졌는지 명확하게 이해하고 싶어해요. 그래서 다음 글부터는 논문, 코드, 그리고 기본 모델을 훈련하는 데 사용된 수학적인 부분을 자세히 살펴볼 거에요.

# Fine-tuning: 어시스턴트 훈련하기

Fine-tuning은 아주 똑똑한 구현이에요. 아마 OpenAI에 의해 처음 수행된 것 같아요. 아이디어는 아주 간단하지만 지능적으로 작동해요: 인간 라벨러를 고용하여 수많은 Q&A 대화쌍을 생성하게 해요(예: 10만 대화). 그런 다음 모델에 대화쌍을 주입시켜 이를 통해 학습시키는 거죠.

이 과정을 Fine-tuning이라고 해요. 그 10만 개의 대화 샘플 데이터가 모델에 훈련되면 뭔 일이 벌어질까요? 모델이 인간처럼 응답하기 시작할 거에요!

<div class="content-ad"></div>

위의 샘플 레이블 대화를 살펴보겠습니다:

```js
인간 레이블된 Q&A

Q: 이름이 뭐에요?
A: 제 이름은 존입니다.
```

```js
인간 레이블된 Q&A

Q: 중국의 수도는 무엇인가요?
A: 중국의 수도는 북경입니다.
```

```js
인간 레이블된 Q&A

Q: 영화 타이타닉의 줄거리를 요약해주세요.
A: 영화 타이타닉은 바다에서 침몰하는 배에 관한 이야기입니다.
```

<div class="content-ad"></div>

와, 이 샘플 Q&A들은 우리가 서로 대화하는 방식을 조롱하고 있는 것 같아요.

모델에게 이러한 응답 스타일을 가르쳐주면, 관련된 맥락에 대한 응답 확률이 매우 높아지며 사용자의 질문에 응답할 수 있게 될 거예요. 모델을 여러 대화 스타일로 훈련시킴으로써, 관련성이 높고 맥락에 맞는 응답을 제공할 가능성이 높아집니다.

이것이 언어 모델이 얼마나 지적이고 인간 같아 보일 수 있는지; 실제 대화의 리듬과 패턴을 모방하면, 사용자와의 대화를 흐름 있게 시뮬레이션할 수 있어요.

우리는 여기서 어시스턴트 모델을 얻었다고 말할 수 있어요.

<div class="content-ad"></div>

아래는 기본 모델을 사전 훈련에서 보조 모델을 미세 조정하는 과정 중 일부 강조 사항을 보여주는 다이어그램입니다:

![다이어그램](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_3.png)

# RLHF: 인간 피드백으로부터 강화 학습

2022년 1월, OpenAI는 언어 모델을 지시 사항을 따르도록 조정하는 연구를 발표했습니다. 블로그 게시물에서 그들은 모델이 인간 피드백으로 더욱 미세하게 조정된 방법을 설명했습니다.

<div class="content-ad"></div>


![이미지](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_4.png)

이 부분은 조금 까다로울 수 있어요. 아이디어는 모델이 인간 피드백에서 배울 수 있게 하는 것입니다. 약 10만 개의 레이블이 지정된 Q&A 쌍을 제공하는 대신, 사용자의 프롬프트와 모델 응답을 수집한 다음 사람들이 순위 매기도록 합니다. 이 순위 정리된 대화를 가장 원하는 Q&A 샘플로 삼아 다시 모델에 피드하고 전반적인 성능을 향상시키도록 합니다.

이 프로세스는 OpenAI의 블로그에서 소개되었습니다.

우리 모델을 보다 안전하고 유용하며 일치하게 만들기 위해 기존 기술인 인간 피드백 강화 학습 (RLHF)을 사용합니다. API에 고객이 제출한 프롬프트에서, 우리의 레이블러는 원하는 모델 행동을 시연하고 모델에서 여러 출력을 순위 매깁니다. 그런 다음 우리는 이 데이터를 사용하여 GPT-3를 세밀하게 조정합니다.

<div class="content-ad"></div>

여기에 베이스 모델 대 미세 조정/RLHF 응답 비교가 있어요:

![Comparison](/assets/img/2024-06-22-HowLargeLanguageModelWorksLLMsZero-to-Hero_5.png)

미세 조정 및 RLHF 없이 모델은 단순히 문서 완성기일 뿐임을 확인할 수 있어요.

# 프롬프트 엔지니어링

<div class="content-ad"></div>

더 세밀한 조정과 RLHF를 사용하더라도 모델은 여전히 원하는 응답을 얻기 위해 도움이 필요합니다. 그리고 이것이 바로 프롬프트 엔지니어링이 필요한 이유입니다.

간단히 말해, 우리는 모델로부터 원하는 응답을 얻기 위해 프롬프트를 신중하게 디자인할 수 있습니다 (때로는 세밀한 조정 없이도).

수학과 코드에 너무 깊이 들어가지 않으려는 경우, 프롬프트 엔지니어링이 주목할 가치가 있는 방법입니다. 왜냐하면 더 나은 프롬프트를 입력함으로써 LLM 모델에서 최상의 결과를 얻을 수 있기 때문입니다.

이제 예시를 살펴보겠습니다:

<div class="content-ad"></div>

```js
The sky is
```

blue.

<div class="content-ad"></div>

아래 테이블을 Markdown 형식으로 변경해 주세요.

| 이름 | 나이 | 성별 |
|------|-----|-----|
| 민수 | 25 | 남성 |
| 지영 | 22 | 여성 |

<div class="content-ad"></div>

```js
낮에는 파란색이고 밤에는 어두운 색입니다.
```

프롬프트에 일부 지침을 포함하면 모델이 무엇을 해야 하는지와 어떻게 응답해야 하는지 알 수 있습니다.

또 다른 흥미로운 예제를 살펴보겠습니다:

프롬프트:

<div class="content-ad"></div>


6살 때 내 언니 나이의 절반이었어. 지금 나는 70살, 내 언니 몇 살일까? 


결과:

```js
35
```

답은 틀렸어요. 정답은 67살이에요. 모델은 질문을 이해하는 것 같지만 논리적 추론 대신 수학 계산을 참고한 것 같네요.

<div class="content-ad"></div>

미세 조정 및 RLHF 없이도 프롬프트에 더 많은 예제 지침을 추가하는 것만으로도 올바른 답을 얻을 수 있습니다:

프롬프트:

```js
Q: 수목원에는 15 그루의 나무가 있습니다. 오늘 나무원 작업자들이 나무를 심을 것입니다. 작업을 마치고 나면, 21 그루의 나무가 될 것입니다. 나무원 작업자들은 오늘 몇 그루의 나무를 심었습니까?
A: 우리는 15 그루의 나무로 시작합니다. 나중에는 21 그루의 나무가 있습니다. 차이는 그들이 심은 나무의 수여야 합니다. 따라서, 그들은 21 - 15 = 6 그루의 나무를 심었을 것입니다. 정답은 6입니다.
Q: 주차장에 차가 3대 있고 더 2대의 차가 도착한다면, 주차장에는 몇 대의 차가 있습니까?
A: 주차장에는 이미 3대의 차가 있습니다. 2대가 추가로 도착합니다. 이제 차가 3 + 2 = 5대 있습니다. 정답은 5입니다.
Q: 리아는 초콜릿 32개를 가지고 있었고, 그녀의 여동생은 42개를 가지고 있었습니다. 그들이 35개를 먹었다면, 두 사람이 남은 총 조각 수는 얼마입니까?
A: 리아는 초콜릿 32개를 가지고 있었고, 리아의 여동생은 42개를 가지고 있었습니다. 이는 원래 32 + 42 = 74개의 초콜릿이 있었음을 의미합니다. 35개가 먹혔습니다. 그래서 총으로 계산하면 74 - 35 = 39개의 초콜릿이 남게 됩니다. 정답은 39입니다.
Q: 제이슨은 막대사탕 20개를 가지고 있었습니다. 그는 덴니에게 일부 막대사탕을 주었습니다. 지금은 제이슨이 막대사탕 12개를 가지고 있습니다. 제이슨이 덴니에게 몇 개의 막대사탕을 주었습니까?
A: 제이슨은 막대사탕 20개를 가지고 있었습니다. 지금은 12개밖에 없으므로, 나머지를 덴니에게 줬을 것입니다. 따라서, 덴니에게 준 막대사탕 수는 20 - 12 = 8개입니다. 정답은 8입니다.
Q: 숀은 5개의 장난감을 가지고 있습니다. 크리스마스 때, 엄마와 아빠로부터 각각 2개의 장난감을 받았습니다. 지금은 몇 개의 장난감이 있습니까?
A: 그는 5개의 장난감을 가지고 있습니다. 엄마로부터 2개를 받았으므로, 이후 그는 5 + 2 = 7개의 장난감을 가지고 있습니다. 그리고 아빠로부터 또 2개를 받았으므로 총으로 계산하면 7 + 2 = 9개의 장난감이 있습니다. 정답은 9입니다.
Q: 서버실에는 컴퓨터가 9대 있었습니다. 월요일부터 목요일까지 매일 추가로 5대의 컴퓨터가 설치되었습니다. 지금 서버실에는 몇 대의 컴퓨터가 있습니까?
A: 월요일부터 목요일까지는 4일이 있습니다. 매일 5대의 컴퓨터가 추가되었습니다. 이는 총 4 * 5 = 20대의 컴퓨터가 추가되었음을 의미합니다. 처음에는 9대의 컴퓨터가 있었으므로, 현재 서버실에는 9 + 20 = 29대의 컴퓨터가 있습니다. 정답은 29입니다.
Q: 마이클은 골프공 58개를 가지고 있습니다. 화요일에 23개의 골프공을 잃었습니다. 수요일에 또 2개를 잃었습니다. 수요일 종료 시에는 몇 개의 골프공이 있습니까?
A: 마이클은 처음에 58개의 골프공을 가지고 있었습니다. 화요일에 23개를 잃었으므로, 그 후에는 58 - 23 = 35개의 골프공을 가지고 있습니다. 수요일에 2개를 더 잃었으므로, 이제 35 - 2 = 33개의 골프공이 있습니다. 정답은 33입니다.
Q: 올리비아는 $23을 가지고 있습니다. 그녀는 각각 $3에 5개의 베이글을 샀습니다. 그녀가 남은 돈은 얼마입니까?
A: 그녀는 각각 $3에 5개의 베이글을 샀습니다. 이는 총 $15를 소비한 것을 의미합니다. 그녀는 $8을 남겼습니다.
Q: 제가 6살이었을 때, 내 여동생은 내 나이의 절반이었습니다. 지금 저는 70살입니다. 내 여동생은 몇 살입니까?
A:
```

결과:

<div class="content-ad"></div>

```js
6살 때 내 언니는 저의 나이의 절반, 즉 3살이어서 3살이었습니다. 이제 저는 70살이므로, 언니는 70 - 3 = 67살입니다. 정답은 67입니다.
```

output 2:

```js
이야기의 주인공이 6살일 때, 그의 언니는 그의 나이의 절반인 3살이었습니다. 이제 주인공이 70살이 되었으므로, 언니는 70 - 3 = 67세가 될 것입니다. 정답은 67입니다.
```

두 번째 답변도 정확합니다! 우리는 문제에 대한 논리적 설명 예시를 추가하여 모델이 질문을 이해하고 올바르게 답변할 수 있도록 했습니다.

<div class="content-ad"></div>

위의 예시는 Wang 등(2022)에 의해 소개된 것으로, 최종 답안을 계산하는 과정은 몇 단계로 이루어져 있습니다.

강력한 프롬프트는 모델이 수학 문제 해결이나 텍스트 요약과 같은 복잡한 작업을 수행하는 데 도움이 될 수 있습니다. 따라서 프롬프트 엔지니어링은 LLM 생태계의 매우 중요한 역할을 합니다.

프롬프트 엔지니어링에 대해 더 알고 싶다면, 여기 좋은 프롬프트 가이드 튜토리얼이 있습니다.

# 요약

<div class="content-ad"></div>

여기까지 읽어주셔서 정말 감사합니다. 특히 LLM 세계에 처음 접하는 분들에게는 모든 정보를 소화하는 데 시간이 걸릴 것이라고 확신합니다.

이제 기본 개념과 배경 정보에 대해 충분한 내용을 다루었다고 믿습니다. 이제 우리 자신의 대형 언어 모델을 구축하기 위한 준비를 시작할 때입니다. 이론에는 지겨워했으니, 다음 기사에서는 Transformers 아키텍처의 중요한 구성 요소로 나아갈 것입니다.