---
title: "인간의 모든 것을 의인화하는 습관"
description: ""
coverImage: "/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_0.png"
date: 2024-06-23 19:12
ogImage: 
  url: /assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_0.png
tag: Tech
originalTitle: "Our human habit of anthropomorphizing everything"
link: "https://medium.com/user-experience-design-1/our-human-habit-of-anthropomorphizing-everything-dd2d79488ea4"
---



![image](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_0.png)

People tend to anthropomorphize everything. We attribute human traits and emotions to animals, objects, and even software.

"Today Gmail is being a little moody."

"I think my cat purposely vomited on the rug to get back at me."


<div class="content-ad"></div>

"Siri 가 가끔 바보같이 동작하기도 해."

사실 동물 행동과 인간 행동이 항상 일치하지는 않습니다. 소프트웨어와 AI는 "행동"하지 않고, 대신에 그들의 코드에 따라 작동합니다. 사회적 동물로서, 우리는 특정 출력을 "행동"으로 해석하기 쉽게 찾습니다. 우리가 사용하는 기술을 인간화시키면 더 이해하기 쉬워집니다.

그러나 사물을 인간화하는 것이 잘못될 수 있습니다. AI와 같은 복잡한 시스템들을 이해하기 쉽게 만든다는 목적보다, 기술을 인간화시키는 것은 실제로 더 큰 이해 부족과 오해를 야기할 수 있습니다.

![이미지](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_1.png)

<div class="content-ad"></div>

# 인격화란 무엇인가요?

ChatGPT의 질적 가용성 연구 중에, Nielsen Norman 그룹은 사용자 행동의 네 가지 패턴을 관찰했습니다. 이 패턴들은 AI에 인간 특성을 할당하는 것입니다.

- 예의
- 강화
- 놀이
- 동반자

![이미지](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_2.png)

<div class="content-ad"></div>

## 친절함

대부분의 사람들은 기본적인 예의로 AI를 대하곤 합니다. "부탁합니다"나 "고마워요"는 필수는 아니지만, 습관적으로 사용자들은 대화를 공손하게 이끌어내곤 합니다. Siri와 같은 음성 비서는 대화 가능하도록 디자인되어 있으며, 대화는 일반적으로 쿼리에 대한 응답 후의 "고마워요"와 같은 사회적 예의를 포함합니다. Siri는 우리가 "그녀"에게 도움을 주셨을 때 감사의 말을 하지 않아도 불평하지는 않지만, 우리의 사회적 습관 때문에 일반적인 예의가 표현됩니다.

![이미지](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_3.png)

## 강화

<div class="content-ad"></div>

Nielsen Norman Group은 reinforcement(강화)을 정의할 때 챗봇이 정확한 대답을 할 때 칭찬하거나 훈육하는 것으로 설명합니다. 인간에게는 긍정적인 reinforcement(강화)가 중요하다는 것을 알고 있습니다 — 바라는 행동이나 결과를 확립시킵니다. 좋은 성적을 칭찬하고 훌륭한 작업에 대해 상을 주는 것과 같습니다. 나쁜 행동을 꾸짖고 실수를 바로잡으려고 합니다.

그러나 그것은 인간 행동입니다. AI 챗봇에게 긍정적이거나 부정적인 reinforcement(강화)를 제공하는 이유는 무엇일까요? 연구에서 참가자들은 "잘 했어요!"라고 칭찬하는 것에 대해 두 가지 다른 동기를 설명했습니다.

- 긍정적인 reinforcement(강화)가 미래에 비슷한 결과를 재창출하는 데 도움이 될 것으로 생각되어 AI에게 “잘한 일”을 보여줌으로써 알려줄 수 있다.
- AI는 인간의 태도와 행동을 반영하므로 사용자로서 긍정적이면 챗봇도 긍정적이고 친근한 인터페이스가 될 것입니다.

이것은 일반적인 예의를 넘어서는 것이지만, 여전히 사회화 과정에서 형성된 습관으로 해석될 수 있습니다.

<div class="content-ad"></div>

## 롤플레이

![Roleplay](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_4.png)

롤플레이는 제품 사용자가 ChatGPT와 같은 제품의 봇에게 특정 역할을 맡도록 요청하는 경우 발생합니다. 예를 들어, 사용자는 ChatGPT에게 "화기발랄한 소셜 미디어 매니저 역할을 맡고 새로운 게임 출시를 위한 뉴스레터를 작성해 달라"고 요청할 수 있습니다.

Nielsen Norman에 따르면, "대화 봇에 역할을 할당하는 것은 자주 권장되는 프롬프트 엔지니어링 전략 중 하나입니다." 롤플레이 프롬프트는 인공지능에게 소셜 미디어 매니저와 같은 직책이나 환희한(happy)과 같은 태도와 같은 인간적인 특성을 가정하도록 요청합니다. 이는 제품의 입체적인 의인화인데, 그것이 때로는 과제가 요구하는 것일 수도 있습니다. 사용자의 요구를 충족시키기 위해, 인공지능은 도구(tool)보다는 동료로서 더 많이 행동해야 할 수도 있습니다.

<div class="content-ad"></div>

## 동반자

![이미지](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_5.png)

동반자심은 사용자가 AI를 동료나 사람처럼 대하기 시작하는 지점입니다. 사용자들은 AI를 친구로 취급하며 예의 바르고 애정을 담아 대화를 나눕니다. 이는 사용자가 반드시 AI가 공감과 친절 같은 인간적인 특성을 가지고 있다고 믿는다는 뜻은 아닙니다. 그러나 ChatGPT와 같은 챗봇은 사용자의 입력 스타일을 대부분 따르기 때문에 친절하게 대하면 친절한 답변을 받을 수 있습니다.

AI와 친근하게 대화하는 것은 외로움을 조금 완화시키고 독자가 픽셔널 캐릭터를 즐기는 것과 비슷한 위로를 줄 수 있습니다. 그들이 "실제"가 아니더라도 AI와 긍정적인 상호작용에서 느껴지는 감정은 실제입니다.

<div class="content-ad"></div>

# 모든 것을 의인화하는 이유는 무엇일까요?

![image](https://miro.medium.com/v2/resize:fit:1400/0*RcwtzrUztbWi9nve.gif)

왜 AI에게 인간처럼 말을 걸까요? 우리는 AI에게 특정한 방식으로 행동하길 원할까요? 그것이 더 인간적이기를 원할까요? 아니면 우리는 그 특성을 그냥 부여하는 걸까요?

이전에 언급한 것처럼, 인간들은 비인간적인 동물과 물체에 인간적인 특성을 부여하여 인간적 시각을 통해 그들을 이해하려고 합니다. AI는 특히 신비로운 존재이므로, 우리는 그 기술을 해소하기 위해 우리가 할 수 있는 일을 합니다.

<div class="content-ad"></div>

인공지능이 어떻게 작동하는지에 대한 기본적인 오해가 기술에 대한 의도를 흔들어놓을 수 있습니다. Nielsen Norman의 연구에 따르면 참가자들은 ChatGPT와 같은 플랫폼과 어떻게 상호 작용해야 하는지 확실하지 않았으며 다른 소스에서 들은 내용에 따라 행동합니다. "따라서, AI가 가장 잘 작동하는 방법에 대한 소문이 퍼지는데, 이 중 많은 것들이 인간화의 정도를 포함하고 있습니다."

이제 우리가 사람들이 왜 인공지능을 인간화한 채로 다가오는지, 즉 주로 인간화를 고려한 상태에서 다가오는지 알았으니, 우리는 인공지능을 인간화하는 방향으로 나아갈지에 대해 생각해 볼 필요가 있을까요? 사용자들에게 ChatGPT와 같은 AI와 대화할 때 동료나 친구와 대화하는 것처럼 대화를 나누도록 격려해야 할까요?

그렇지 않습니다. AI를 "마법 같은" 것으로 표현하는 것이 문제가 될 수 있는 것과 마찬가지로, 인간처럼 다뤄서는 안 되며 그렇게 한다면 당황과 오해를 불러일으킬 것입니다.

# 인간화는 해결책이 아닙니다

<div class="content-ad"></div>


![Image](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_6.png)

고양이의 행동을 "교묘한 동기"로 설명하면 고양이가 꾀를 부리거나 악의를 품고 있다고 생각하는 오해를 낳을 수 있습니다. (가끔 그렇게 보일 수 있지만, 사실은 아닙니다!) 동물 행동을 연구하고 넘어서서 우리는 이것이 사실이 아님을 알고 있습니다. 다시 말해, 동물들은 본능에 따라 행동합니다. 인간들은 본능과 사회적 기대에 따라 행동합니다. ChatGPT와 같은 디지털 제품은 그 코드에 기반하여 기능합니다.

따라서 AI를 사람처럼 인식하는 것은 최선의 경우 오해를 낳을 수 있고, 최악의 경우 전혀 잘못된 이해를 야기할 수 있습니다. AI에 인간적인 특성을 부여함으로써 사람들은 그 작동 방식에 대한 잘못된 생각을 형성할 수 있습니다. 이해하기 어렵게 만들기가 목표라면 (그렇게하면 좋습니다), AI를 인간화하는 것은 해결책에 반대로 작용합니다.

Raspberry Pi는 인간화 언어를 사용하지 않고 AI를 어떻게 언급해야 하는지 몇 가지 예를 제시합니다.


<div class="content-ad"></div>

- “It listens/it learns” → “AI is designed to.../AI 개발자들은 ...어플리케이션을 만듭니다…”

이로 인해 AI를 독립적인 존재로서가 아닌 특정 용도를 위해 인간에 의해 설계된 기술로서의 존재로 초점이 옮겨집니다.

- “see/look/create/recognize/make” → “detect/input/pattern match/generate/produce”

처음에 나열된 동사 목록은 사람에게도 적용될 수 있어 AI에 인간적인 품질을 내포하고 있음을 시사합니다. “look” 대신 “detect”와 같은 더 정확한 언어는 AI를 엔티티보다는 기술로서 확립하는 데 도움이 됩니다.

<div class="content-ad"></div>

- "인공 지능/기계 학습"과 같은 용어를 셀 수 있는 명사로 사용하지 마세요. 예: "2022년에 새로운 인공 지능이 나타났다" → '인공 지능/기계 학습'을 생물학 용어처럼 과학적 분야로 참조하세요.

이렇게 하면 AI/ML이 사람들에 의해 개발된 것이라는 사실에 근거를 두어 자기 자신에서 출현한 힘이나 자체적인 동기가 아니라는 것을 보여줍니다.

# 인간화에 더 초점을 맞추기

![이미지](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_7.png)

<div class="content-ad"></div>

하지만 기다려봐요! AI 챗봇에 인격을 부여하는 기업에 대해 어떻게 생각하시나요? Meta는 챗봇을 인간 용어로 언급하는 것을 넘어서 28개의 독특하고 매우 인간적인 성격을 가진 챗봇을 만들었습니다. 일부는 심지어 Snoop Dogg나 Kendall Jenner와 같은 실제 유명인을 바탕으로 만들어졌어요.

각 챗봇은 특정 역할을 맡고 있으며 특정 전문 영역을 갖고 있습니다. 이는 사용자의 목표를 달성하는 데 도움이 되는 챗봇을 쉽게 찾을 수 있도록 돕습니다. 예를 들어, "Billie" (Kendall Jenner)는 언니 같은 존재로, 삶과 사랑에 관한 조언이 필요한 사용자들은 그녀에게 찾아갈 거예요. 또한 Dwayne Wade와 같은 운동 선수를 바탕으로 한 다른 챗봇은 "Billie"보다 운동과 스포츠에 대한 정보가 더 많을 거예요.

이것은 AI와 함께 롤플레잉하는 명백한 예시로, 친밀한 관계로 발전하고 있어요. 친근한 성격을 가진 여러분을 통해 정보를 제공하는 것은 디자인적인 측면에서 합리적일 수 있지만, 불행히도 이는 AI에 대한 혼란을 야기할 수 있어요. Snoop Dogg가 챗봇이 하는 말에 모두 동의하는 걸까요? 사용자에게 부정확하거나 모욕적인 답변이 주어진다면, 그것을 기술의 한계가 아닌 유명인의 성격 때문이라고 생각할 수도 있어요. 

# TL;DR — AI는 마법도, 인간도, Snoop Dogg도 아닙니다

<div class="content-ad"></div>


![image](/assets/img/2024-06-23-Ourhumanhabitofanthropomorphizingeverything_8.png)

전기를 마법으로 생각하지 않습니다. 또한 그것이 기분, 감정 또는 선호도를 갖고 있다고 가정하지도 않습니다. 그렇다면 왜 인공지능에 대해 그러한 가정을 해야 하는 것일까요? 이렇게 하면 기술이 작동하는 방식에 대한 기본적인 오해를 야기할 수 있으며, 인공지능의 능력에 대한 기대를 만들어내기 어렵게 만들 수 있습니다.

우리는 동물, 차량, 기술 등과 같이 함께 작업하는 것에 대해 의식적으로 사람화하는 경향이 있으므로, AI의 사람화는 피할 수 없는 것처럼 보입니다. 이를 Nielsen Norman Group의 ChatGPT 연구에서의 예의, 강조, 롤플레이 및 동반자성에서 관찰할 수 있습니다.

그러나 인공지능의 사람화에 너무 많이 의존한다면 기술이 작동하는 방식에 대한 오해를 만들어낼 수 있으며, 실제로 인공지능은 자체 동기를 갖춘 존재가 아닌 기술이라는 사실을 알아차리기 어렵게 만들 수 있습니다.


<div class="content-ad"></div>

이러한 기술들이 인류의 미래에서 중요한 부분을 차지하려면 인공 지능과 기계 학습에 대한 보다 강력한 교육이 필요합니다. 그렇지 않으면 사용자들은 AI가 어떻게 작동하는지에 대한 기본적인 오해를 갖게 될 것입니다. 이것은 디자이너들이 완화하거나 제거하기 위해 의도된 불만의 원인이 될 수 있습니다.

## 추가 읽을거리: