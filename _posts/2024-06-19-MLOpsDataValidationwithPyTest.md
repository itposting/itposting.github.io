---
title: "MLOps - PyTest를 사용한 데이터 검증"
description: ""
coverImage: "/assets/img/2024-06-19-MLOpsDataValidationwithPyTest_0.png"
date: 2024-06-19 20:05
ogImage: 
  url: /assets/img/2024-06-19-MLOpsDataValidationwithPyTest_0.png
tag: Tech
originalTitle: "MLOps — Data Validation with PyTest"
link: "https://medium.com/towards-data-science/mlops-data-validation-with-pytest-749641874871"
---


<img src="/assets/img/2024-06-19-MLOpsDataValidationwithPyTest_0.png" />

# 소개

MLOps 파이프라인에서는 가능한 한 많은 단계를 자동화하려고 노력합니다. 프로그래머의 직접적인 개입으로 발생할 수 있는 오류의 수를 최소화하는 것이 목표입니다. 또한 데이터셋 유효성 검사에 유의하는 것도 중요합니다. 누구나 기계 학습의 제1 규칙에 대해 익숙할 것입니다: 쓰레기를 넣으면 쓰레기가 나옵니다. 우리가 개발하는 모델이 얼마나 정교하든, 데이터셋의 관리가 제대로 이루어지지 않으면 높은 확률로 나쁜 결과를 얻을 것입니다.

이 기사에서는 PyTest를 사용하여 데이터셋에 대한 자동 검증을 수행하는 방법을 살펴보겠습니다.

<div class="content-ad"></div>

저는 Deepnote을 사용하여 이 기사의 스크립트를 실행하고 있어요. Deepnote은 협업형 데이터 과학 프로젝트와 프로토타이핑에 좋은 클라우드 노트북 서비스에요.

## ETL에 대하여

처음으로 머신 러닝에 접근하는 사람들은 대부분 Kaggle에서 볼 수 있는 도전 과제를 해결해야 하는데요. 이러한 도전 과제에서는 거의 항상 시간이 지나도 변하지 않는 정적인 데이터셋을 다루게 됩니다. 하지만 실제 세계에서는 이것이 완전히 사실이라고 할 수 없어요.

실제 머신 러닝 제품을 개발할 때에는 데이터가 지속적으로 변할 수 있어요. 그 결과 데이터는 데이터 추출, 데이터 변환, 데이터 로딩의 초기 단계를 거쳐 얻어지게 됩니다.

<div class="content-ad"></div>

이 세 단계는 일반적으로 ETL 이라는 약어로 요약됩니다. 간단히 말해서, 데이터 수집을 수행하여 모델 훈련을 진행할 충분한 데이터 양을 확보해야 한다고 상상해보세요. 데이터를 어딘가에서 추출해야 하는데, 예를 들어 스크래핑하거나 오픈 소스 데이터가 어떻게 도움이 될 수 있는지 분석해야 합니다(추출).

데이터는 다양한 형식으로 제공될 수 있습니다. CSV 파일 몇 개, JSON 파일, 그리고 몇 개의 txt 파일을 모았을 수도 있습니다. 따라서 데이터를 균일하게 변환해야 합니다.

마지막으로, 데이터 과학자들이 쉽게 사용할 수 있도록 데이터를 쉽게 활용할 수 있어야 합니다. 예를 들어 다운로드하기 쉽도록 시스템에 업로드할 수 있어야 합니다(예: Hugging Face, AWS).

![이미지](/assets/img/2024-06-19-MLOpsDataValidationwithPyTest_1.png)

<div class="content-ad"></div>

이 기사에서는 ETL 최상의 실천 방법에 대해 읽을 수 있습니다.

## 무엇이 잘못될 수 있을까요?

이제 데이터가 수집되는 방법을 알게 되었으니, 데이터 과학자가 데이터 유효성 검사를 다루어야 하는 이유와 방법에 대해 이해해 봅시다. 데이터셋에서 몇 가지 잘못된 부분이 생길 수 있습니다.

- 주변 세계는 동적이며 변하기 때문에 데이터의 분포도 변합니다. 티셔츠 가격에 대해 예측하는 모델을 생각해보세요. XXL 사이즈는 아무도 구매하지 않았기 때문에 매우 낮은 가격으로 예측되었습니다. 그러나 세대가 지남에 따라 사람들이 점점 키가 커지기 때문에 미래에는 큰 사이즈에 더 중요성을 부여하는 모델을 다시 훈련해야 할 수도 있습니다.
- 소스 데이터에 변경 사항이 있었지만 우리에게 알려지지 않았습니다. ETL 파이프라인을 담당하는 팀이 영화 평점 시스템을 변경하여 1에서 5점까지 범위로 구성된 시스템에서 10점까지의 시스템으로 전환했습니다.
- ETL 중에 데이터 흡수에 버그가 있었을 수 있습니다. 실수가 있고 cm로 표현된 데이터에서 km로 표현된 데이터로 변경되었을 수도 있습니다.

<div class="content-ad"></div>

데이터 유효성 검사는 데이터를 분할한 후(splitting data into train and test)에 수행할 수도 있고 그 전에도 할 수 있습니다. 어디서 하는 것이 가장 좋은지 명확하지 않으며 두 가지 방법에 대한 장단점이 있습니다.

## PyTest 소개

PyTest는 다양한 종류의 테스트를 실행하는 데 널리 사용되는 파이썬 라이브러리입니다. 일반적으로 코드 베이스 내에 tests라는 폴더를 생성하고 여기에 실행하려는 여러 테스트 파일들을 수집합니다. 각 파일의 이름은 test_xx.py와 같이 지정됩니다. 따라서 tests 폴더 안에서 test_data.py 또는 test_model.py와 같은 파일들을 생성할 수 있습니다.

<div class="content-ad"></div>

테스트를 수행하는 데 주요한 Python 명령어는 assert입니다. 이 명령어는 특정 조건이 충족되었는지 확인하고, 그렇지 않으면 오류가 발생합니다. 조건 뒤에 문자열로 오류를 정의할 수 있습니다. 예시를 살펴보겠습니다.

PyTest는 파일 내에서 감지된 모든 테스트 함수를 실행하고, 모든 단언문이 True를 반환하는지 확인합니다. 그렇지 않을 경우 터미널에 실패한 테스트를 표시합니다. 테스트 함수의 예시는 다음과 같습니다.

여기서 첫 번째 문제가 발생합니다. 이전 함수에서 주어진 입력의 값은 무엇인가요? 테스트 단계에서 이러한 변수를 어떻게 지정할까요? 우리는 픽스처(fixtures)에서 도움을 받습니다!

## PyTest의 픽스처(Fixtures)

<div class="content-ad"></div>

많은 경우 (위의 경우와 같이) 테스트에는 단언을 만들기 위한 입력 데이터(예: 데이터)가 필요합니다. 이 입력 데이터는 PyTest의 fixtures를 사용하여 제공할 수 있습니다. Fixtures를 사용하면 더 이상 할당할 필요 없이 테스트 내에서 사용될 변수를 선언할 수 있습니다. 그러나 fixtures를 정의하는 함수는 테스트 함수의 입력 변수와 동일한 이름을 가져야 합니다. 예를 살펴봅시다.

위의 코드 블록에서 보는 것처럼, 우리는 data(함수 이름을 따름)라는 fixture를 구현하여 df라는 데이터프레임을 출력값으로 반환합니다.
따라서 test_data_length 테스트에서는 입력 데이터가 fixture의 값을 취할 것이므로 df 데이터프레임과 일치할 것입니다.

Fixture의 범위를 지정할 수 있으므로, fixture가 파괴될 때를 결정할 수 있습니다. 예를 들어, 범위가 "session"인 경우 동일한 fixture가 전체 세션 동안 유지됩니다. 이것은 첫 번째 테스트가 데이터 값을 변경할 수 있고, 그 값을 두 번째 테스트로 전달할 수 있도록 합니다.

대신 "function" 범위를 사용하면, 각 테스트가 fixture의 새로운 및 변경되지 않은 복사본을 입력으로 사용합니다.

<div class="content-ad"></div>

PyTest 문서에서는 다양한 범위에 대해 읽을 수 있어요.

머신러닝 데이터셋에 대한 테스트 작성은 전통적인 소프트웨어 엔지니어링에 대한 테스트 작성보다 복잡할 수 있어요. 전통적인 소프트웨어에서는 각 기능에 대해 기대 출력이 있기 때문에 테스트가 기대한 것과 다른 결과를 반환하면 명백히 오류가 있다고 볼 수 있어요.

반면, 데이터셋에서는 무엇을 기대해야 하는지 확신할 수 없어요. 예를 들어 데이터셋에서 기능 "키"의 평균이 1.70cm일 것으로 가정해봅시다. 하지만 테스트 결과 평균이 "1.75"라고 나타나면 어떻게 해야 할까요? 오류가 있는 걸까요? 아니면 정말로 키가 큰 사람들의 데이터를 추가해서 평균을 높인 것일까요?

그래서 데이터셋에서 할 수 있는 몇 가지 간단한 결정론적 테스트부터 시작해보고, 확정적이지 않은 테스트에 대해도 살펴보겠어요.

<div class="content-ad"></div>

## 결정론적 테스트

결정론적 테스트 작성은 매우 간단합니다. 데이터셋에서 무엇이 결정론적인가요? 예를 들어, 열의 수가 정확하게 X여야 하거나 행의 수가 N 이상이어야 충분한 데이터가 있는 것과 같은 경우입니다.

범주형 변수의 경우, 값이 특정 범위 내에 있는지 확인할 수 있습니다. 예를 들어, "색상" 특성이 [빨강, 초록, 파랑] 값만을 가질 수 있는지 확인할 수 있습니다.

이러한 유형의 테스트를 위한 예제 파일을 살펴보겠습니다.

<div class="content-ad"></div>

이 코드에서는 다음과 같은 함수들을 찾을 수 있습니다:

- data: 이 함수에서는 데이터프레임을 포함하는 변수를 노출하는 fixture가 있습니다.
- test_column_presence_and_type: 이 함수에서는 [age, salary, name, genre] 네 개의 열이 데이터셋에 존재하고 올바른 유형인지 확인합니다.
- test_class_names: 이 함수는 장르 값이 알려진 값들 중에 있는지 확인합니다. 예상치 않은 값들을 찾지 않도록 보장합니다.
- test_column_ranges: 여기서는 숫자 변수들이 특정 범위에 있는지 확인합니다. 예를 들어, 나이는 절대 음수가 될 수 없습니다!

## 확률론적 테스트

확률론적 테스트에서 우리가 하고 싶은 것은 불확실성을 고려하여 값들을 측정하는 것입니다. 불확실성에 대해 이야기할 때 확률과 통계가 관련되며, 우리는 여기서도 그들을 활용할 것입니다.

<div class="content-ad"></div>

현재 작업 중인 데이터셋의 값을 평가하기 위해 이전 버전과 비교하는 것이 일반적인 관행입니다.

데이터셋에서 수행할 수 있는 몇 가지 예시 확인 사항은 다음과 같습니다:

- 이상값의 존재 확인
- 하나 이상의 열 값 분포 확인
- 하나 이상의 열 또는 모든 열과 목표 열(예측 대상) 사이의 상관 관계 확인
- 다양한 열의 평균 및 표준 편차 확인

이미 언급한 바와 같이, 결정론적 테스트에서는 통계가 사용되며 일반적으로 과거 데이터가 예시로 취해져 현재 데이터와 비교됩니다. 따라서 가설 검정이 어떻게 작동하는지 이해하고, 이러한 비교를 위해 어떻게 사용할 수 있는지 이해하는 것이 중요합니다.

<div class="content-ad"></div>

이 글에서는 가설 검정의 기본 개념을 간단히 살펴볼 예정이에요. 더 깊이 알고 싶으시다면 이 영상을 보시는 걸 추천해요:

가설 검정을 다룰 때는 항상 대립 가설에 대한 귀무 가설을 검정하게 되어요.

- 귀무 가설 (H_0): 과학 커뮤니티에서 널리 받아들여지는 가정이에요. 저희의 경우, 데이터에 관한 가정일 수 있어요.
- 대립 가설 (H_a): 저의 새로운 가설로 받아들여지길 원하는 것으로, 귀무 가설과 반대되는 가설이에요. 제가 새로운 가설을 받아들여지게 하려면 제 가설을 확인하는 데이터를 제시해야 하죠. 이렇게 하면 새로운 가설이 옳다는 것을 모두를 설득하는 것이 더 쉬워져요.

대표적인 예시는:

<div class="content-ad"></div>

- 영가설 (H_0): 두 개의 샘플은 동일한 평균을 가진 정규 분포에서 나온 것이다.
- 대립가설: 두 개의 샘플은 서로 다른 평균을 가진 정규 분포에서 나왔다.

가정에 따라 사용할 수 있는 다양한 통계 검정 방법이 있습니다. 각 통계 검정은 가정과 관련이 있습니다. 따라서 올바른 검정을 선택하는 것이 매우 중요합니다. 올바른 통계 검정을 선택하는 데 도움이 될 수 있는 적절한 논문을 알려드리겠습니다.

이 예제에서는 t-검정을 사용할 것입니다.

우리가 해야 할 일은, 샘플을 시작으로 알려진 공식을 사용하여 테스트 통계량이라는 값을 계산하는 것입니다. 테스트 통계량으로부터 곡선 아래 영역에 해당하는 p-값이라는 다른 값을 계산합니다 (나중에 자세히 살펴보겠습니다). p-값이 미리 선택한 임계값 (알파)보다 크면 우리는 영가설을 기각할 수 없으며 영가설은 여전히 진실이 유지됩니다. 그 대신에 p-값이 작으면 영가설을 기각할 수 있고 새로운 (대립) 가설을 주장할 수 있습니다.

<div class="content-ad"></div>

당연히 이 거절에 대한 신뢰도는 미리 선택한 임계값에 의해 결정됩니다. 일반적인 임계값은 0.1, 0.5 및 0.001입니다. 이 값이 작을수록 더 확신이 있습니다.

![이미지](/assets/img/2024-06-19-MLOpsDataValidationwithPyTest_2.png)

아직 완전히 이해가 안 된다면 걱정하지 마세요, 이 전체 설명은 몇 줄의 Python 코드로 번역됩니다! t-테스트에 대한 Scipy 함수는 직접 검정 통계값과 p-값을 반환합니다. 우리가 해야 할 일은 알파 값을 선택하고 결정만 내리는 것뿐입니다.

기계 학습에서는 참조 데이터 세트를 보유하고 이를 새로 얻은 데이터 세트와 비교하여 데이터 분포가 동일한지 이해하는 것이 최적일 것입니다. 유감스럽게도 우리가 사용 가능한 데이터 세트가 그리 많지 않기 때문에 보통 테스트 데이터 세트를 훈련 데이터 세트와 비교하는 것이 일반적입니다.

<div class="content-ad"></div>

자주 수행하는 테스트 중 하나는 두 기능이 동일한 확률 분포에서 나왔는지 확인하는 것입니다. 물론, 테스트 데이터 세트에서 사용하는 열이 교육 데이터와 동일한 분포를 가져야 합니다. 그렇지 않으면 모델이 학습한 패턴은 테스트에서 완전히 쓸모 없게 될 것입니다!

이를 위해 Kolmogorov-Smirnov 테스트라는 테스트를 사용할 수 있습니다. 이 테스트는 scipy 라이브러리에서도 제공됩니다.

이 시점에서 PyTest로 이러한 확인을 구현할 수 있어야 합니다.

사실 데이터 세트의 다른 열에 대해 여러 가설 검정을 실행할 때, 선택한 알파에 본페로니 교정이 필요합니다. 이에 대해 다음 기사에서 살펴볼 것입니다.

<div class="content-ad"></div>

# 결론

이 기사에서는 데이터 입력 파이프라인의 주요 구성 요소인 ETL에 대해 이야기했습니다. ETL은 추출(extraction), 변환(transformation), 로드(load)의 약어입니다. 또한 데이터 과학자가 작업 중인 데이터를 유효성 검사하는 중요성에 대해 이야기했습니다. 이 유효성 검사는 우리가 사전에 예측한 예상 출력을 알고 있는 결정론적 테스트로 수행되거나, 우리의 가정을 통계적 테스트로 확인할 수 있는 비결정론적 테스트로 이루어집니다. 이러한 테스트는 모두 모든 데이터 과학자에게 매우 중요한 도구인 PyTets를 사용하여 실행되며, 이는 코드를 깨끗하게 유지하고 코드 내의 오류를 최소화하는 데 도움이 됩니다.

이 기사가 마음에 든다면 Medium에서 제 팔로우 하세요! 😁

💼 Linkedin ️| 🐦 X (Twitter) | 💻 Website