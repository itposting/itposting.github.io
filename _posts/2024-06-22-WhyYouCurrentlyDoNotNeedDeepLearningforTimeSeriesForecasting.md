---
title: "시계열 예측에 딥러닝이 필요 없는 이유 현재 기준"
description: ""
coverImage: "/assets/img/2024-06-22-WhyYouCurrentlyDoNotNeedDeepLearningforTimeSeriesForecasting_0.png"
date: 2024-06-22 20:17
ogImage: 
  url: /assets/img/2024-06-22-WhyYouCurrentlyDoNotNeedDeepLearningforTimeSeriesForecasting_0.png
tag: Tech
originalTitle: "Why You (Currently) Do Not Need Deep Learning for Time Series Forecasting"
link: "https://medium.com/towards-data-science/why-you-currently-do-not-need-deep-learning-for-time-series-forecasting-0de57f2bc0ed"
---


<img src="/assets/img/2024-06-22-WhyYouCurrentlyDoNotNeedDeepLearningforTimeSeriesForecasting_0.png" />

시계열 예측을 위한 딥러닝이 많은 관심을 받고 있습니다. 많은 문서와 과학 논문들이 최신 딥러닝 모델에 대해 언급하며 이 모델이 모든 기계 학습 또는 통계 모델보다 훨씬 우수하다고 언급합니다. 이는 딥러닝이 시계열 예측을 위한 모든 문제를 해결해 줄 것이라는 인상을 줍니다. 특히 이 분야의 새로운 사람들에게 말이죠.

그러나 제 경험상 딥러닝은 필수적인 것이 아닙니다. 다른 것들이 더 중요하며 시계열 예측에 더 잘 작동합니다.

그래서 이 기사에서는 여러분에게 어떤 것이 작동하는지 보여드리고 싶습니다. 여러 가지 방법을 소개해 드릴 것이며 이들은 다양한 방법으로 검증되었습니다. Makridakis M5 대회 및 Kaggle AI 보고서 2023의 연구 결과를 활용해 제 경험과 비교해 보겠습니다.

<div class="content-ad"></div>

마크리다키스 대회는 실제 데이터 세트에서 예측 방법을 비교합니다. 실제로 어떤 것이 효과적인지를 보여줍니다. 거의 40년 전에 시작된 이 대회의 연구 결과는 변화했습니다. 처음 세 개의 대회(M1 ~ M3)에서는 통계 모델이 우세했습니다. M4 대회에서는 기계 학습 모델이 혼합 접근법의 형태로 잠재력을 드러냈는데, 해당 방법은 기계 학습 모델과 통계적 방법을 결합한 것입니다.

M5 대회에서는 참가자들이 월마트의 계층적 판매량을 예측해야 했습니다. 대회는 정확도 대회와 불확실성 대회로 분할되었습니다. 정확도 대회의 목표는 각 시계열에 대한 최상의 점 예측을 찾는 것이었습니다. 불확실성 대회는 확률적 예측에 초점을 맞췄습니다. 이를 위해 참가자들은 미래 판매의 전체 분포를 설명하는 아홉 가지 다른 분위수를 예측해야 했습니다.

한편, 캐글 AI 보고서는 캐글 대회의 일환으로 캐글 커뮤니티가 작성한 에세이 모음입니다. 일반적으로 최근 고성능 솔루션에서 주요 배움과 추세를 정리합니다.

추신으로, 캐글이 M5 대회를 주최했습니다. 따라서 이 대회는 다른 캐글 대회에 참가한 많은 사람들의 관심을 끌었습니다. 결과적으로 캐글 AI 보고서와 M5 대회의 결과가 매우 유사한 이유가 될 수 있습니다.

<div class="content-ad"></div>

하지만 결과를 한 번 살펴볼까요?

# 머신 러닝 모델이 우수한 성능을 보여줍니다

지난 몇 년 동안 머신 러닝 접근 방식은 시계열 예측 분야를 선점해 왔습니다. 2020년 M4 대회에서는 하이브리드 방식의 일부로 중요해지기 시작했고, 그러나 2년 후인 M5 대회에서는 머신 러닝이 대회를 지배했습니다. 모든 성능이 좋은 솔루션은 순수한 머신 러닝 방식으로, 모든 통계 기준을 능가했습니다.

특히 Gradient Boosting Machines (GBMs)는 M5와 캐글 대회에서 모두 우세합니다. 가장 성공적인 것들은 LightGBM, XGBoost 및 CatBoost입니다. 많은 피쳐의 효과적인 처리, 거의 또는 전혀 데이터 전처리와 변환이 필요하지 않은 점, 빠른 학습 속도 및 피쳐 중요성을 정량화하는 능력 등은 최근 몇 년간 최고의 공급 모델 중 하나로 만들어줍니다.

<div class="content-ad"></div>

실험하기에 매우 편리하며 빠른 반복이 가능하여 최적의 특징을 식별하는 데 중요합니다. 또한 몇 가지 하이퍼파라미터만 최적화하면 됩니다. 종종 기본 설정만으로도 좋은 성능을 얻을 수 있습니다. 따라서 많은 시계열 문제에서 주로 사용되는 알고리즘이 되어갔습니다.

또한 이러한 방식은 성능과 학습 시간에서 딥러닝 모델을 이긴다. 그래서 딥러닝 모델은 인기가 떨어졌습니다.

나의 첫 번째 선택 역시 위에서 언급한 장점들 때문에 GBM입니다. 시간이 흐름에 따라 XGBoost에서 CatBoost로, 그리고 또 LightGBM로 옮겼습니다. 많은 문제에서 LightGBM이 더 나은 성능과 짧은 학습 시간을 보였습니다. 또 LightGBM은 작은 데이터 세트에 더 능숙했습니다. 예를 들어 한 문제에서 동일한 특징과 손실 함수를 사용하여 CatBoost 모델과 LightGBM 모델을 학습했습니다. CatBoost는 학습하는 데 대략 50% 더 많은 시간이 소요되었으며 LightGBM에서 얻은 MAE보다 2% 더 많았습니다.

# 통계적 방법은 여전히 가치가 있습니다

<div class="content-ad"></div>

ML 방법은 종종 통계 모델보다 우수한 성능을 보이지만, 우리는 통계 모델을 잊어서는 안 됩니다. M5 정확도 대회에서 팀 중 92.5%가 기존의 예측 방법인 간단한 기준선 방법을 이기지 못했습니다. ML 모델을 사용한다고 해서 최상의 성능이 보장되는 것은 아닙니다. 더구나, 이러한 모델을 개발하는 데 더 많은 시간이 걸립니다.

그러므로, 어떤 ML 모델을 시작하기 전에 항상 간단한 모델부터 시작해야 합니다. 이러한 모델을 기준선 모델로 활용해 의사 결정을 지원할 수 있습니다. 예를 들어, ML 모델이 복잡성을 상쇄할만큼 충분한 가치를 추가하는지 확인할 수 있습니다.

기준선 모델에 대해 자세히 알아보고, 왜 그것으로 시작해야 하는지 궁금하시다면 제 논문을 확인해보세요.

저는 보통 기준선으로 가장 간단한 모델부터 시작합니다. 제 경험 상, 간단한 통계 기준선 모델은 종종 이길 수 없는 경우가 많습니다. 게다가, ML 모델을 개발하는 데 필요한 시간 대비 매우 짧은 시간이 걸립니다.

<div class="content-ad"></div>

# 앙상블은 성능을 향상시킵니다

M5와 카글 대회에서 다양한 모델을 결합하면 종종 더 나은 예측 정확도를 얻을 수 있음을 보여줍니다. 앙상블은 개별 모델이 상관 관계가 없는 오류를 만들 때 특히 성공적입니다. 예를 들어, M5 대회의 일부 팀들은 훈련 데이터의 하위 집합 및 다른 손실 함수로 훈련된 모델을 결합했습니다.

우리는 간단한 평균화(블렌딩), 복잡한 블렌딩 또는 스택 방식을 통해 앙상블을 구축할 수 있습니다. 그러나 종종 동일한 가중치를 부여하는 것이 충분합니다.

앙상블은 모델 성능을 향상시키지만 실제 응용 프로그램에서는 단점이 있습니다. 복잡성이 늘어나면 설명 가능성이 감소하고 프로덕션 환경에서 유지하기가 더 어려워집니다. 그러므로 매우 복잡한 앙상블은 종종 사용되지 않습니다. 일반적으로 더 간단한 대안은 충분히 좋은 결과를 제공하면서 유지보수하기가 더 쉽습니다.

<div class="content-ad"></div>

실제 응용 프로그램에서 앙상블 사용의 이점을 보았어요. 저에게는 보통 두 가지 접근 방식이 가장 잘 작동했어요. 하나는 LightGBM과 같은 동일 유형의 모델을 결합하는 접근 방식이에요. 이 모델들은 서로 다른 손실 함수로 훈련되죠. 다른 하나는 서로 다른 특성으로 훈련된 모델을 사용하는 접근 방식이에요. 이 두 가지 접근 방식을 선호하는데, 구현하기 쉽고 빠르게 테스트할 수 있기 때문이죠. 손실 함수를 바꾸거나 모델 입력을 변경할 뿐 나머지 파이프라인은 동일한 채로 유지할 수 있어요.

또한, 복잡성을 최소화하기 위해 보통 간단한 앙상블에 집중해요. 보통 간단한 평균화를 사용해요. 그러나 앙상블의 이점은 충분히 커야만 실제 제품으로 이어갈 수 있어야 해요. 보통 앙상블이 성능을 충분히 향상시키지 못해요.

# 과학 문헌이 적용된 시계열 예측에 미치는 영향은 작았어요

과학 문헌과 적용된 기계 학습 시계열 예측 간에 간극이 보여요. 과학 문헌은 주로 딥러닝 모델에 초점을 맞추지만, 실무에서는 잘 사용되지 않아요.

<div class="content-ad"></div>

하지만 왜 그런 큰 격차가 있는 걸까요? 논문들은 그들의 모델이 기계 학습 및 통계 모델들을 이기는 것을 보여줍니다. 그럼에도 불구하고 왜 아무도 그것들을 사용하지 않을까요? 왜냐하면 딥 러닝 접근법은 종종 현실 세계 응용에서 성공적이지 않을 수도 있기 때문입니다. 게다가, 그들을 훈련하는 데 매우 비용이 많이 들 수도 있습니다.

그러나 왜 과학 문헌이 딥 러닝에 그토록 집중되어 있는 걸까요, 실용적이지 않다면?

음, 제 추측만 할 수 있지만, 딥 러닝은 다른 기계 학습 모델들보다 더 많은 관심을 끕니다. N-BEATS 및 N-HiTS에 대한 두 기사에서 이를 본 적이 있습니다. 모두가 NLP를 위한 LLM의 큰 성공 이후에 딥 러닝에 일하고 싶어합니다.

Transformer와 같은 딥 러닝 접근법은 NLP에 대해 잘 작동하지만 시계열에 대해서는 그렇지 않습니다. 두 작업 모두 값들의 순서로 보이기는 하지만, 실제로는 그렇지 않습니다. NLP에서는 맥락이 중요하지만, 시계열에서는 순서가 중요합니다. 이것은 잘 작동하는 접근법에 큰 영향을 미치는 작은 차이입니다.

<div class="content-ad"></div>

그러므로 깊은 학습 모델을 훈련시키는 것이 가치가 있는지, 아마도 기계 학습 모델보다 더 낮은 성능을 낼 것이라는 생각을 할 수 있습니다. N-BEATS 및 N-HiTS와 같은 접근 방식을 시도해 보았지만, 이러한 모델들은 항상 성능이 떨어지고 ML 모델보다 훈련하는 데 훨씬 더 오랜 시간이 걸렸습니다. 그래서, 저는 이러한 모델들을 실제 예측 작업에 성공적으로 적용해 본 적이 없습니다.

이제 어떤 모델이 작동하고 어느 것이 그렇지 않은지에 대해 많이 얘기했습니다. 하지만 모델에만 집중하는 것으로는 충분하지 않습니다. 올바른 모델을 선택하는 것보다 더 중요한 것들이 있습니다. Kaggle AI 보고서 및 M5 대회는 좋은 피처 엔지니어링이 모델보다 더 중요하다고 결론 내렸습니다. 새로운 모델을 개발할 때 아마도 가장 중요한 측면일 것입니다.

# 피처 엔지니어링이 모델보다 더 중요합니다.

실제 세계 데이터는 지저분하고 유용하게 사용하려면 많은 정리가 필요합니다. 그러므로, 좋은 피처를 찾기 위해 데이터를 정리하고 이해하는 데 많은 시간이 필요합니다. 이것이 저가 모델을 개발할 때 대부분의 시간을 보내는 곳입니다.

<div class="content-ad"></div>

Kaggle 대회에서는 특성 공학이 중요하다는 것이 반복적으로 증명되었습니다. 종종 특성의 품질이 해결 방법을 결정하는 중요한 요소가 됩니다. 데이터에서 가장 많은 정보를 추출하고 특성 간에 더 큰 차이를 만들어내는 팀들이 더 좋은 성능의 모델을 갖게 됩니다. 그러므로 특성을 만들고 선택하며 변형하는 데 시간을 소비하는 것은 중요합니다.

하지만 특성 공학에 좋은 접근법은 무엇일까요?

제 경험 상, 단일 최상의 접근법은 없습니다. 오히려 다양한 특성과 특성 조합을 시도하는 시행착오 접근법입니다. 좋은 특징을 찾는 데 도움이 된 것은 창의적이고 융통성 있게 고려하며 데이터 기반의 교차 검증 전략을 사용하는 것입니다.

때로는 다양한 특성을 생성하는 넓은 접근법이 도움이 될 수 있습니다. 예를 들어, 많은 외생 변수와 외부 데이터 소스가 제공되는 경우, 보통 변환 없이 그대로 사용하여 시작합니다. 여기서 변수 선택은 설명적 데이터 분석 결과와 그 안에서 찾은 내용에 따라 결정됩니다.

<div class="content-ad"></div>

가끔 하나의 기능에 집중하고 여러 방법으로 확장하는 것이 더 나을 수 있어요. 예를 들어, 한정된 양의 데이터를 가지고 있다면요. 어떻게 하나의 기능을 확장할지는 해결하고자 하는 문제에 따라 다를 거에요. 평균, 표준편차, 최소값 및 최대값과 같은 창 기능을 사용하면 성능이 향상될 수 있어요. 때로는 다른 시차 기능만을 사용하는 것도 충분할 수 있어요.

M5 및 Kaggle 대회를 통해 도메인 지식이 좋은 기능을 찾는 데 필요하지 않다는 것을 알 수 있어요. 그러나 도메인 지식은 종종 데이터를 더 빨리 이해하고 더 나은 기능을 도출하는 데 도움이 되었어요.

# 외생/설명 변수로 성능 향상

외부 데이터 사용은 예측 성능을 향상시키는 데 중요해요. 이들은 모델의 성능을 크게 향상시킬 수 있어요. M5 대회에서 외부 데이터를 사용한 모델이 오직 과거 데이터에만 의존한 모델보다 더 나은 성과를 거뒀어요. 이에 따라 이러한 설명 변수를 찾는 것이 현실 세계 응용 프로그램에서 중요해요.

<div class="content-ad"></div>

가능한 한 많은 외부 요인을 식별하려고 노력합니다. 그런 다음 이러한 요인을 특성 엔지니어링 과정 중에 테스트합니다. 이는 공휴일과 같은 간단한 날짜 및 시간 관련 특성이나 다른 소스에서 가져온 데이터와 같이 될 수 있습니다. 제 선택은 추론 중에 데이터의 이용 가능성과 접근성에 따라 다릅니다.

실제로, 성능이 크게 향상된 것을 확인했을 때는 외부 변수를 추가했을 때였습니다. 대부분의 실제 응용 프로그램에서 예측하려는 시계열의 행동은 외부 요소에 따라 달라집니다. 예를 들어 전력 가격을 예측하려면 전력 소비 및 생산을 특성으로 사용하면 성능이 크게 향상됩니다. 왜냐하면 전력 소비가 증가하거나 전력 생산이 감소할 때 전력 가격이 보통 상승하기 때문입니다.

# 가능한 빨리 반복하기

일반적으로 우리는 모델 개발 과정에서 많은 특성을 시도하므로 가능한 빨리 진행해야 합니다. 새로운 특성을 추가하는 것이 도움이 되는지 확인하기 위해 오래 기다리고 싶지 않습니다. 예를 들어, M5 정확도 대회에서 우승한 솔루션은 220개의 모델을 테스트했습니다.

<div class="content-ad"></div>

따라서, Kagglers는 모델 학습이 매우 빠르기 때문에 LightGBM을 주로 사용합니다. 따라서, 그들은 짧은 기간에 많은 실험을 실행할 수 있습니다.

다시 한번, 저도 이 연구 결과에 동의합니다. 테스트할 수 있는 것이 많을수록 더 나은 결과를 얻는 경향이 있습니다. 더 많은 기능, 다른 기능 조합 및 다른 손실 함수. 빠르게 진행되는 것이 나에게 많은 가설을 짧은 시간 내에 테스트할 수 있도록 도와줍니다.

그러나 성능을 향상시키는 기능을 결정하기 위해서는 모델의 우수성을 반복적으로 평가해야 합니다. 우리가 신뢰할 수 있고 최적의 기능과 모델을 식별하는 데 도움이 되는 접근 방식이 필요합니다.

# 효과적인 교차 검증 전략이 중요합니다

<div class="content-ad"></div>

효과적인 교차 검증 전략은 최상의 모델을 객관적으로 선택하는 데 중요합니다. 교차 검증을 활용한 로컬 검증 프로세스를 구축하여

- 모델 성능이 신뢰할 만큼 향상되었는지 이해할 수 있습니다
- 모델이 오류를 만들거나 신뢰할 수 없는 예측을 하는 영역을 발견할 수 있습니다
- 피쳐 엔지니어링에 유용한 정보를 얻을 수 있습니다
- 사후 표본 정확도를 시뮬레이션할 수 있습니다
- 테스트 데이터에서 오버피팅을 피할 수 있습니다
- 불확실성을 완화할 수 있습니다
- 모델의 하이퍼파라미터를 튜닝할 수 있습니다

M5와 캐글 경쟁은 이 중요성을 보여줍니다. M5 대회에서 많은 팀이 최종 제출을 위한 최상의 모델을 선택하는 데 실패했습니다. 캐글 대회에서는 공개 리더보드에서 최상의 모델이 항상 우승자가 되지 않는 경우가 많습니다.

하지만 좋은 교차 검증 전략을 선택하는 것은 어려울 수 있습니다. 다양한 옵션이 있기 때문이죠.

<div class="content-ad"></div>

- 어떤 기간을 선택해야 하는가요?
- 검증 창의 크기는 얼마인가요?
- 창을 어떻게 업데이트해야 하나요?
- 예측 성능을 요약하는 데 사용하는 기준/지표는 무엇인가요?

그러므로 전략은 항상 문제에 따라 달라져야 합니다.

# 각 문제마다 독특한 접근 방식이 필요합니다

Kaggle 및 M5 대회의 결과는 모든 데이터 세트와 문제에 대해 독특한 접근 방식이 필요하다는 것을 보여줍니다. 일반적인 해결책은 없습니다.

<div class="content-ad"></div>

어떤 접근 방식이 동작하는지 결정하려면 우리의 지식과 경험이 필요합니다.

예측 작업의 복잡성을 기반으로 모델을 조정해야 합니다. 이에는 위에서 논의한 모든 요소가 포함됩니다. 특성 공학부터 교차 검증, 그리고 모델 선택까지 모두요.

예를 들어 M5 정확도 대회에서 각 시계열의 최상의 모델을 결합하면 우승 솔루션을 대략 2% 정도 이기는 결과를 얻을 수 있습니다.

이로 인해 딥러닝 모델이 현재 실제 응용 프로그램에서 작동하지 않습니다. 그들은 상세한 특성 공학이 필요한 문제에 대해 일반적인 해결책을 제시하려고 시도합니다. 딥러닝 모델은 상세한 특성 공학이 필요한 필요성을 없애주어 우리 삶을 더 쉽게 만들어 줄 것을 약속합니다. 예를 들어, N-BEATS와 N-HiTS는 시계열에서 계절성 및 추세 구성 요소를 자동으로 찾는 것을 약속하지만, 시계열의 독특한 복잡성을 찾아내지는 못합니다. 반면, 우리의 지식으로는 이러한 복잡성을 찾아내어 ML 모델이 사용할 수 있는 특성으로 인코딩할 수 있으며, 이를 통해 딥러닝 모델을 이길 수 있습니다.

<div class="content-ad"></div>

# 결론

M5 대회와 2023 Kaggle AI 보고서는 시계열 예측에 중요한 것과 잘 작동하는 요소에 동의합니다. 저는 실제 시계열 예측 작업에서 경험하며 그 결론을 지지할 뿐입니다.

가장 중요한 요소는 다음과 같습니다:

- 머신러닝 모델이 우수한 성능을 보임
- 통계적 방법은 여전히 가치가 있음
- 앙상블이 성능을 향상시킴
- 학술 문헌은 시계열 예측에 미치는 영향이 작음
- 모델보다 특성 엔지니어링이 더 중요함
- 외생적/설명 변수는 성능을 높일 수 있음
- 가능한 한 빨리 반복
- 효과적인 교차 검증 전략이 중요함
- 각 문제마다 고유한 접근이 필요함

<div class="content-ad"></div>

딥 러닝이 목록에 포함되어 있지 않다는 것을 확인할 수 있어요.

현재 딥 러닝은 아직 충분히 성숙하지 않습니다. 이러한 모델들이 문학적인 영역에서 현실 세계의 문제로 성공적으로 전이되지 못했습니다. 그러나 미래에는 변할 수도 있습니다. 오랫동안 시계열 예측을 지배해 온 통계 모델로부터 ML 모델로의 전환을 보았습니다. 앞으로 딥 러닝 모델로의 전환이 일어날 수도 있습니다. 그러므로 딥 러닝의 발전에 대해 계속해서 주목하는 것이 좋습니다. 하지만 현재는 현실 세계의 응용에 유용하지 않다고 할 수 있습니다.

따라서, 딥 러닝 영역 뿐만 아니라 ML 영역에서도 추가 연구와 개선 가능성이 여전히 많이 남아 있습니다.

이 글에서 유익한 정보를 많이 찾으셨으면 좋겠어요. 다음 시계열 예측 모델의 성능 향상에 도움이 되길 바랍니다!

<div class="content-ad"></div>

다음 글에서 뵙겠습니다. 댓글도 남겨주세요!