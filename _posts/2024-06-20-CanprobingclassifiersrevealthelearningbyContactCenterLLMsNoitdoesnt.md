---
title: "탐사 분류기를 사용하여 연락 센터 LLMs의 학습 내용을 밝힐 수 있을까요 아니요, 불가능합니다"
description: ""
coverImage: "/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png"
date: 2024-06-20 18:44
ogImage: 
  url: /assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png
tag: Tech
originalTitle: "Can probing classifiers reveal the learning by Contact Center LLMs?: No, it doesn’t!"
link: "https://medium.com/@digvijay.ingle16/can-probing-classifiers-reveal-the-learning-by-contact-center-llms-no-it-doesnt-d9124540e4d9"
---


이 블로그는 2024년 NAACL에서 수락된 기술 논문에 대한 참조입니다. 이 논문은 멕시코시티에서 개최된 5번째 맞춤형 결과로부터의 통찰력 워크샵(NLP@NAACL)에서 발표되었습니다.

![이미지](/assets/img/2024-06-20-CanprobingclassifiersrevealthelearningbyContactCenterLLMsNoitdoesnt_0.png)

## 소개

고객 서비스의 빠른 세상에서, 연락 센터는 기술 지원부터 청구 문의까지 모든 분야의 고객 상호 작용의 최전선으로 기능합니다. 기술이 발전함에 따라 대규모 언어 모델(LLMs)이 연락 센터에 통합되면 고객 지원의 제공 방식을 혁신화할 수 있습니다. 다만, 이러한 모델의 효과는 연락 센터 상호 작용의 특정 세부 사항을 이해하고 처리할 수 있는 능력에 크게 의존합니다. 저희 논문인 "프로빙 분류기가 연락 센터 대규모 언어 모델의 학습을 밝혀 줄까요?: 아니요, 그렇지 않습니다!"에서는 연락 센터 도메인을 위해 특별히 선별된 LLMs의 학습을 프로빙 분류기가 밝혀낼 수 있는지 조사합니다.

<div class="content-ad"></div>

## 동기

본 연구의 동기는 접촉 센터를 포함한 다양한 영역에서 LLMs에 대한 의존도가 점점 증가하고 있다는 점에서 비롯됩니다. 접촉 센터는 고객 지원 및 서비스에 중요한 역할을 하며 기술적 문제부터 청구 관련 문제까지 다양한 쿼리를 처리합니다. 그러나 이러한 상호 작용의 즉흥적이고 소음이 많은 특성은 LLMs에게 중요한 도전 요소가 됩니다. 도메인별 데이터로 LLMs를 세밀하게 조정하면 성능을 향상시킬 수 있지만, 이 과정에서 이러한 모델이 실제로 무엇을 배우는지 이해하는 것이 중요합니다. 기존에는 탐사 분류기가 LLMs의 내부 표현을 해석하고 이해하는 데 사용되어 왔지만, 이들이 도메인별 학습의 세부 사항을 밝히는 데 얼마나 효과적인지는 여전히 불분명합니다. 본 연구는 접촉 센터 응용 프로그램을 위해 세밀하게 조정된 LLMs가 습득하는 핵심적인 특성을 평가함으로써 이 갭을 메우고자 합니다.

## 도메인별 세밀한 조정의 중요성

OpenAI 및 Google과 같은 대규모 언어 모델은 인간과 유사한 텍스트를 생성하는 놀라운 능력을 보여주고 있습니다. 이러한 모델의 성능을 재정 및 생명공학과 같은 특정 도메인에서 더욱 향상시키기 위해 이러한 모델은 종종 도메인별 데이터로 세밀하게 조정됩니다. 이 방법은 다양한 분야에서 성공적인 것으로 입증되었지만, 접촉 센터 도메인에는 소음이 많은 쿼리, 즉흥 대화 및 특정 용어와 같은 독특한 도전 요소가 있습니다.

<div class="content-ad"></div>

## 방법론

본 연구에서는 30억부터 130억 개 파라미터까지 다양한 크기의 두 가지 인기 있는 LLM 아키텍처인 Flan-T5와 Llama에 중점을 두었습니다. 저희는 내선 작업에서의 효과를 측정하기 위해 연락센터 대화의 독점 데이터셋으로 이러한 모델들을 세밀하게 조정합니다. 또한 이 연락센터(CC) 도메인 특화 지시 LLM들이 기본 설정 버전과 비교했을 때 배운 근본적 특성을 평가합니다. 이를 위해 저희는 대화, 채널, 자동 음성 인식(ASR) 속성을 평가하는 점검 작업을 정의하여 무엇을 배우고 그것이 연락센터 도메인에서 실제 성능으로 어떻게 변환되는지 알아봅니다.

## 주요 발견

- 내선 작업에서의 성능 향상: CC-LLMs는 내선 작업에서 상당한 성능 향상을 보였습니다. 특히, OOB 모델과 비교하여 응답 수용성이 48% 이상 향상되었습니다. 이는 도메인 특화 세밀 조정이 연락센터에서 LLM의 실용성을 향상시키는 데 효과적임을 강조합니다.
- 점검 분류기의 차이 미미: 내선 작업에서의 성능 향상에도 불구하고, 점검 분류기는 세세한 차이를 보이지 않았습니다. 이는 전통적인 점검 작업이 모델 내에서 발생하는 미묘한 학습을 효과적으로 포착하지 못할 수 있다는 것을 시사합니다.
- 아키텍처와 크기의 중요성: 시험한 모델 중에서 T5 모델이 다양한 설정에서 일반적으로 Llama 모델보다 우수한 성능을 보였습니다. 흥미로운 점은 작은 CC-Flan-T5(110억) 모델이 종종 큰 CC-Llama(130억)보다 우수한 성능을 보인다는 것인데, 이는 모델 아키텍처가 모델 크기보다 더 중요할 수 있다는 것을 시사합니다.
- 일반 언어 특성: 세밀 조정 이후, CC-Flan-T5와 CC-Llama 모델은 SentEval suite의 일반 언어 점검 작업에서 점수가 낮아졌으며, 일반 언어 특성에서 도메인 특화 능력으로의 초점 이동을 나타냅니다.

<div class="content-ad"></div>

## 함의 및 향후 방향

연구 결과는 LLMs가 학습한 근본적인 특성들을 신뢰할 수 있는 방식으로 드러낼 수 있는 것이라는 가정에 도전하고 있습니다. 세부적으로 조정된 모델들은 특정 작업에서 우수한 성과를 보이지만, 기존의 조사 메커니즘은 모델의 학습에서 변경된 기본적인 특성을 발견하는 데 충분하지 않아 보입니다.

이는 우리가 어떻게 조사 작업을 설계하고 활용하는지 재검토할 필요가 있음을 시사합니다. 컨택 센터의 대화의 동적이고 맥락 의존적인 성격은 보다 정교하고 맥락을 인지하는 조사 전략이 필요할 수도 있습니다. 게다가, 연구는 언어 생성 중의 디코딩 전략이 중요한 역할을 하며 향후 연구의 중점이 되어야 함을 제안합니다.

마무리로, 컨택 센터와 같은 특정 도메인에 LLMs를 세부 조정함으로써 실용적 작업에서 성능을 크게 향상시킬 수 있지만, 기존의 조사 분류기는 이러한 개선 사항을 밝히는 데 한계가 있습니다. 이 연구는 더 효과적인 조사 방법에 대한 연구를 위한 새로운 방향을 제시하며, 높은 성과를 내는 LLMs 개발 시 아키텍처와 세부 조정 전략을 모두 고려하는 중요성을 강조합니다.

<div class="content-ad"></div>

세계 곳곳의 연락센터를 위해 대화 인텔리전스를 변화시키는 Observe.AI에서 더 많은 정보를 확인해보세요.