---
title: "데이터 수집 - 파트 1 아키텍처 패턴"
description: ""
coverImage: "/assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_0.png"
date: 2024-06-20 15:30
ogImage: 
  url: /assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_0.png
tag: Tech
originalTitle: "Data Ingestion — Part 1: Architectural Patterns"
link: "https://medium.com/the-modern-scientist/the-art-of-data-ingestion-powering-analytics-from-operational-sources-467552d6c9a2"
---


두 편의 기사를 통해 데이터 수집에 대해 철저히 탐구해 보겠습니다. 데이터 수집은 운영 및 분석 세계를 연결하는 기본적인 프로세스입니다. 다양한 출처에서 데이터를 수집하여 원래의 운영 환경인 '운영 평면'에서 분석 평면 또는 '분석 평면'으로 운송하는 것이 중요합니다. 이 전환이 분석 권한의 완전한 잠재력을 발휘하는 데 필수적입니다.

이 권한의 본질은 다양한 데이터 소스를 기반으로 데이터 기반 통찰력을 생성하고 인공 지능 모델을 구현하는 능력입니다. 조직의 분석 능력은 종종 효과적으로 분석할 수 있는 데이터 소스의 수와 직접적으로 관련이 있습니다. 따라서 올바른 데이터 수집 전략을 선택하는 것이 중요합니다. 이러한 전략은 CRM, ERP, 금융 시스템과 같은 표준 운영 응용 프로그램부터 IoT 센서, API, 스크래핑된 문서, 이미지, 비디오와 같은 다양한 형식까지의 관련 데이터 소스를 처리할 수 있는 견고함이 있어야 합니다.

<div class="content-ad"></div>

보다 넓은 시야를 가지고 보면, 데이터 수집은 하나의 요소에 불과하지만, 조직 내에서 더 큰 데이터 플랫폼 퍼즐의 중요한 구성 요소인 것이 분명해집니다. 일반적으로 이 데이터 플랫폼은 디지털 변혁 이니셔티브의 중심 역할을 하며, 조직이 비즈니스 목표를 달성하는 데 도움을 줍니다. 데이터 플랫폼은 다양한 아키텍처 패턴과 다양한 도구로 구성되어 있으며, 각각이 그 기능성과 효율성에 중요한 역할을 합니다.

데이터 수집에 헌정된 두 개의 글 중 첫 번째 글에서는 적합한 데이터 수집 기술의 선택을 안내하는 아키텍처 패러다임을 탐구합니다. 제 목표는 각 패턴을 그 본질로 단순하게 요약하고, 데이터 수집 프로세스에 대한 전략적인 함의를 밝히는 것입니다. 이러한 패턴들을 제시하는 목적은, 이론적으로 가장 간단하지만 절대 필수적인 작업인 데이터를 분석적 프레임워크 내에 통합하는 데 종종 복잡성을 초래하는걸 극복하는 데 있습니다. 데이터 수집의 전략적 중요성을 인식하는 것은 조직의 데이터 에코시스템의 광범위한 범위 내에서 데이터를 순차적으로 사용하기 위한 효과적인 전환을 보장하는 데 필수적입니다.

# 패턴 1: 통합된 데이터 저장소

저희가 살펴볼 첫 번째 아키텍처 접근 방식은 통합된 데이터 저장소 패턴입니다. 이곳에서 단일 저장 시스템이 운영 응용 프로그램 요구 사항과 분석 처리를 모두 처리합니다. 일반적으로 이 시스템은 관계형 데이터베이스 관리 시스템(RDBMS)입니다. 이러한 설정에서는 같은 데이터베이스가 일상적인 운영 및 데이터 분석에 모두 사용되어, 서로 다른 저장 솔루션 간의 데이터 전송이 필요 없어집니다.

<div class="content-ad"></div>


![이미지](/assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_2.png)

이 접근 방식 안에서 두 가지 주요 하위 패턴이 있습니다:

- 가상화 — 이것은 데이터베이스 내 작업 테이블 위에 분석적 시각을 제공하는 가상 데이터베이스 레이어 또는 뷰를 생성하는 것을 포함합니다. 이는 데이터를 물리적으로 변경하거나 복제하지 않고도 분석적 렌즈를 통해 데이터를 '볼' 수 있는 방법입니다.
- 복제 및 변환 — 여기서 작업 데이터는 분석에 보다 적합한 형식으로 복제됩니다. 이는 저장 프로시저, 머티얼라이즈드 뷰 또는 작업 응용 프로그램의 저장 레이어 내에서 구현될 수 있으며, 효율적인 분석 쿼리를 위해 최적화된 데이터의 병렬 버전을 생성합니다.

이 모델은 데이터 관리의 간소화와 원시 데이터의 가용성을 제공하지만, 상당한 제한 사항이 있습니다:


<div class="content-ad"></div>

- 데이터 통합 도전 과제 — 이 모델은 복수의 물리적 데이터베이스로부터 데이터를 통합하는 데 어려움을 겪는데, 단일 저장 시스템에 의존하기 때문입니다. 이를 극복하기 위해 연결된 서버나 크로스 데이터베이스 쿼리와 같은 기술을 활용할 수 있지만, 추가 복잡성을 도입하기 쉽고 일반적으로 선호되지 않습니다.
- 시스템 간 간섭 가능성 — 동시에 운영 및 분석 프로세스가 동작 중인 동일한 데이터베이스는 상호 간섭을 일으켜 부하를 증가시키고 운영 응용프로그램과 분석 처리의 성능을 저하시킬 수 있습니다.
- 성능 트레이드오프 — 효율적인 트랜잭션 처리를 우선시 하는 온라인 트랜잭션 처리(OLTP) 시스템과 복잡한 쿼리 처리에 최적화된 온라인 분석 처리(OLAP) 시스템이 서로 다른 최적화 요구 사항을 갖는 것은, 두 작업에 모두 최적이 되기 어렵다는 것을 의미합니다.
- 강하게 결합됨 — 통합된 데이터 저장소 패턴은 운영 및 분석 영역 간 강한 상호 연결성을 유발하여 양쪽 영역 중 하나에서 유연성이 제한되거나 없을 수 있습니다.

이러한 제약 사항을 고려하면, 대규모 데이터셋을 처리하거나 여러 물리적 데이터 소스를 다룰 때 통합된 데이터 저장소 접근 방식은 일반적으로 권장되지 않습니다. 복잡성이 너무 커지지 않는 강력한 데이터베이스에서 운영되는 소규모 응용프로그램에는 적합할 수 있습니다.

# 패턴 2: 데이터 가상화

초기 패턴을 기반으로, 데이터 가상화 접근 방식은 특수화된 소프트웨어를 활용하여 다수의 기존 데이터 소스 위에 가상 데이터 레이어를 구축합니다. 이 중간 계층을 통해 원본 데이터 소스에 부분적으로 처리되는 쿼리를 실행하여 결과를 통합하여 분석을 위한 일관된 데이터 집합을 생성합니다.

<div class="content-ad"></div>


![Table](/assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_3.png)


이 방식의 주요 이점은 다음과 같습니다:

- 거의 실시간 데이터 액세스 - 데이터가 분석용 데이터베이스로 물리적으로 이동되지 않고 소스에서 직접 쿼리되기 때문에 이 패턴은 신속한 데이터 사용 가능성을 제공하며 실시간에 근접합니다.
- 지능형 캐싱 - 데이터 가상화 시스템은 일반적으로 고급 캐싱 기능으로 설계되어 소스 시스템에 대한 수요를 최소화하고 성능을 최적화할 수 있습니다.

그러나 이 방식은 몇 가지 우려 사항도 도입합니다:

<div class="content-ad"></div>

- 소스 시스템 제한 사항 - 소스 데이터베이스가 특정 쿼리 유형에 최적화되지 않은 경우에는 성능 병목 현상이 발생할 수 있습니다. 특히 쿼리 실행에 소스 응답에 의존하는 경우 가상 레이어로 확장될 수 있습니다.
- 네트워크 오버헤드 - 다양한 네트워크 존에 분산된 데이터 소스와 인터페이스하는 가상화 레이어는 지연을 겪을 수 있어 전반적인 성능에 영향을 줄 수 있습니다.
- 역사적 데이터 추적 - 가상 레이어는 데이터를 내재적으로 저장하지 않으므로 데이터 수집 타임라인을 통해 "시간 여행"이라고 일반적으로 언급되는 역사적 분석에 대한 도전을 제공합니다.

특정 데이터 가상화 솔루션이 이러한 문제를 해결하는 고유한 메커니즘을 제공할 수 있다는 점을 강조하고 싶습니다. 이러한 중요한 아키텍처 결정을 포함한 경우에는 귀하의 특정 인프라에서 데이터 가상화 솔루션을 철저히 테스트하는 것이 가장 좋습니다. 이를 통해 해당 기능과 한계를 이해하고 적절한 확장 및 세밀한 조정을 통해 통합 및 분석 프로세스를 최적화할 수 있습니다.

## 패턴 3: ETL

ETL은 Extract, Transform, Load의 약어로 데이터 처리에서 잘 알려진 패러다임을 나타냅니다. 먼저 데이터를 원본에서 수집하여 (추출), 이후 ETL 서버에서 정제하고 (변환) 마지막으로 정제된 결과를 분석 중심 데이터베이스에 넣는 과정을 나타냅니다.

<div class="content-ad"></div>

<img src="/assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_4.png" />

여러 해 동안 다양한 ETL 도구 제공업체가 이 방법을 지원했습니다. 이들은 다양한 전문 변환 기술 및 디자인 스타일을 제공했습니다. 보편적인 스타일은 사용자가 직관적인 비주얼 워크플로우 내에서 추출, 변환 및 적재 작업을 상호 연결할 수 있는 그래픽 인터페이스를 포함합니다. 이러한 프로세스는 종종 스크립팅이나 직접 SQL 쿼리를 통해 더 많이 사용자 정의할 수 있습니다.

ETL의 주요 이점은 다음과 같습니다:

- 중앙 집중식 논리 — ETL 프로세스는 전체 변환 논리를 단일하고 관리 가능한 환경에서 통합할 수 있어 데이터 수집 뿐만 아니라 데이터를 분석 요구에 맞게 가공하는 데 도움이 됩니다.
- 사용자 친화적 디자인 — ETL 도구의 비주얼적 성격은 데이터 변환 프로세스를 민주화하여 다양한 기술 수준의 사용자가 데이터 파이프라인 작성에 참여할 수 있도록 합니다.

<div class="content-ad"></div>

그러나 ETL에는 단점이 있습니다. 이러한 단점으로 대체 모델이 등장했습니다:

- 특정 업체에 의존 — ETL 도구 의존은 벤더 락인 형태로 이어질 수 있으며, 현재 도구에서 요금을 변경하거나 기능을 중단하는 경우 다른 플랫폼으로의 전환을 비싸고 복잡하게 만들 수 있습니다.
- 성능 제약 — ETL 변환은 지정된 서버에서 실행되는데, 현대 데이터 웨어하우스에서 제공되는 고성능 컴퓨팅 자원과 비교할 수 없을 수 있으며, 잠재적으로 병목 현상이 발생할 수 있습니다. 이 상황은 역설을 제시합니다: 쿼리 실행을 위한 매우 효율적인 데이터 웨어하우스 엔진이 있더라도 ETL 서버에 의해 전체 파이프라인 처리량이 상당히 느린 속도로 처리되면서 제한됩니다.
- 불명확한 데이터 이력 — 시각적 구성 요소로 간소화된 ETL 변환은 종종 데이터 변환의 복잡성을 숨기며, 데이터의 이동(데이터 이력)을 이해하고 감사하기 어렵게 만들 수 있습니다.
- 한정된 확장성 — ETL 도구는 폭넓은 접근성을 위해 설계되었지만, 데이터 플랫폼이 성장할 때 필수적인 확장 및 산업화를 위한 강력한 기능을 갖추지 못할 수 있으며(DataOps 프레임워크에서 설명한 내용과 같음), 이는 데이터 플랫폼이 성장하는 상황에서 중요합니다.
- 강성 — ETL 도구가 고유한 데이터 수집 요구 사항을 수용하지 못할 때 융통성이 제한되며, 기술 부채에 기여하는 해결책으로 이어질 수 있습니다.

ETL 패턴의 이러한 일반적인 제한사항은 특정 ETL 공급업체에 의해 해결될 수 있습니다. 특히 ETL 도구가 특정 클라우드 DWH를 위해 설계된 포괄적인 스위트에 통합되었을 때, 속도와 성능과 관련된 문제가 완화될 수 있습니다. 그러나, ETL 도구의 발전 궤적을 파악하여 계속해서 데이터 입수 요구 사항과 같은 성장하는 데이터 볼륨이나 신종 데이터 소스 등과 일치하도록 하는 것이 중요합니다.

# 패턴 4: ELT

<div class="content-ad"></div>

ELT은 ETL의 기본 단계를 공유하면서 이러한 프로세스를 재구성하고 재정의합니다. ELT에서는 다음과 같은 과정이 수행됩니다:

- EL — 먼저 추출 및 적재 작업이 수행되어 원시 데이터를 즉시 변환 없이 데이터 플랫폼으로 직접 전송합니다.
- T — 변환은 그 후에 발생하여 원시 데이터를 실행 가능한 통찰력으로 변환합니다. 중요한 것은 변환 작업이 추출 및 적재와 독립적으로 다른 일정으로 동작할 수 있다는 점입니다.

![이미지](/assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_5.png)

이 재구성된 프로세스는 여러 ETL 제약 사항을 해결합니다:

<div class="content-ad"></div>

- 더 많은 유연성 - 추출/로딩과 변환 도구를 분리함으로써 다양한 데이터 유형 및 변환 표준에 알맞은 도구를 선택할 수 있는 능력이 높아집니다.
- 성능 일치 - 변환은 데이터 플랫폼 내에서 이루어지며, 완전한 컴퓨팅 능력을 활용하여 대규모 데이터 세트를 분산 컴퓨팅 엔진으로 처리하기에 특히 효과적입니다.
- 확장성 향상 - ELT의 내재된 유연성은 자동화 및 확장성에서 뛰어난 변환 도구를 선택할 수 있도록 돕습니다.

이러한 개선점이 있음에도 불구하고 ELT 모델은 새로운 복잡성을 도입합니다:

- 다양한 도구의 관리 - 추출, 로딩, 변환에 대해 다른 도구를 사용하는 것은 라이선스, 가격, 업데이트 주기 및 지원 구조를 관리하기 위해 엄격한 관리가 필요합니다.
- 조율 도전 - 보다 다양한 툴킷은 성공적인 데이터 추출 및 로딩 이후에 변환을 계속 진행할 수 있도록 Directed Acyclic Graphs(DAG)를 기반으로 한 복잡한 조율이 필요합니다.

ELT 패턴은 그 유연성 때문에 개인적으로 좋아하지만, 다양한 도구 환경을 관리하고 복잡한 조율 전략을 수립할 의지가 필요합니다.

<div class="content-ad"></div>

# 새로운 패턴 등장

확립된 패턴 이상으로, 새로운 방법론과 패턴이 계속해서 등장하고 있습니다. 이 부분에서는 'Push' 및 스트림 처리와 같은 두 가지 새로운 패턴에 대해 논의합니다.

## Push (vs Pull)

이전에 언급된 전통적인 패턴들은 주로 "Pull" 유형으로, 여기서는 분석 평면이 운영 평면에서 데이터를 적극적으로 검색합니다. 그에 반해, "Push" 방법론은 흐름을 뒤집습니다: 운영 평면이 변경이 발생하는 즉시 데이터를 분석 평면으로 '밀어넣는' 방식으로 작동합니다. 이러한 변경은 생성(Create), 검색(Read), 업데이트(Update), 삭제(Delete) (CRUD) 작업과 같습니다.

<div class="content-ad"></div>

![Data Ingestion](/assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_6.png)

푸시 방식은 스트리밍 아키텍처 내에서 자주 발견되지만 그것에 국한되지는 않습니다. 기본적으로 운영 평면은 분석 평면이 지정한 엔드포인트로 데이터 전송을 시작하는 것을 의미합니다. 이러한 설정은 일반적으로 개발 팀이 푸시 메커니즘을 구현하도록 요구하며, 별도의 구성 요소를 통해 또는 기존의 운영 응용 프로그램을 강화하여 구현될 수 있습니다.

이 접근 방식의 주요 이점은 분석 팀이 데이터 가치 변환에 집중할 수 있도록 하여 데이터 수집 파이프라인을 구축하는 것에 주의를 기울이지 않게 한다는 것입니다. 그러나 결국 두 가지 주요 단점이 있습니다:

- 전용 애플리케이션 개발팀이 필요함 - 사전 패키지 소프트웨어, 소프트웨어 서비스(SaaS) 제공물 또는 IoT 장치와 같은 외부 하드웨어 때문에 이러한 팀이 존재하지 않거나 쉽게 사용할 수 없는 경우 문제가 될 수 있습니다. 이러한 상황에서는 분석 환경으로의 푸시를 용이하게 하는 전문화된 '데이터 통합 팀'을 설립하는 것이 필요할 수 있지만, 이는 신속하게 병목현상으로 변할 수 있습니다.
- 푸시 실패 처리 - 풀 방식 아키텍처는 일반적으로 푸시 아키텍처보다 파이프라인 중단에 대한 강한 내성을 나타냅니다. 풀 실패의 경우 분석 플랫폼이 프로세스를 다시 시작할 수 있습니다. 그러나 푸시가 실패하는 경우 분석 플랫폼은 누락된 푸시 메시지에 대해 알지 못할 수 있습니다. 이러한 단점을 극복하기 위해 푸시 기반 파이프라인은 주로 고가용성 스트리밍 아키텍처에 통합되어 있으며 동시 운영 및 강력한 가용성을 위해 설계되어 있습니다.

<div class="content-ad"></div>

푸시 패턴은 고도의 소프트웨어 개발 성숙도를 갖춘 조직이나 상용 솔루션을 구매할 때 데이터 푸시 기능을 협상할 수 있는 조직에 가장 적합합니다. 이것이 불가능한 상황에서는 푸시를 다른 데이터 수집 패턴과 결합하여 데이터 통합이 원할하고 효율적으로 이루어지도록 하는 것이 바람직할 수 있습니다.

## 스트림 처리

스트림 처리 또는 이벤트 스트리밍으로도 알려진 스트림 처리는 데이터가 생성됨과 동시에 지속적으로 흐르는 것을 의미하며, 실시간 처리와 분석을 가능케하여 즉각적인 통찰력을 제공합니다. 이러한 시스템은 즉각적인 의사 결정 작업에 중요하며, 금융 거래, 실시간 분석, IoT 모니터링과 같은 활동을 위해 고용량, 저지연 처리를 지원합니다.

![이미지](/assets/img/2024-06-20-DataIngestionPart1ArchitecturalPatterns_7.png)

<div class="content-ad"></div>

스트림 처리와 분석을 결합할 때 두 가지 접근법이 엿보입니다:

- 스트리밍을 위한 ELT(또는 ETL) 적응 - 이는 실시간 이벤트를 추출하여 데이터 플랫폼으로 로드함으로써 기존 데이터 워크플로우를 특별하거나 전문화된 스트리밍 컨슈머를 통해 현대적 데이터 원천을 유지함을 내포합니다.
- 스트리밍 캐시 활용 - 중앙집중식이고 내구성 있는 스트리밍 캐시는 이벤트 데이터의 고성능 저장소로 작용합니다. 일부 혁신적인 패턴은 이러한 캐시를 분석적으로 활용하여 공유 데이터 저장소의 현대적이고 효율적인 변형을 만듭니다. 여기에 중요한 고려 사항은 스트리밍 데이터를 정적 데이터 원천과 통합하는 것이며, 스트리밍 캐시를 통해 전달되지 않을 수도 있습니다.

스트림 데이터와 정적 데이터의 통합은 KAPPA 및 LAMBDA와 같은 데이터 아키텍처 패턴에서 설계되어 있습니다. 이 두 가지 아키텍처는 필요할 때 두 세계를 통합할 수 있는 방법을 제공합니다.

# 결론

<div class="content-ad"></div>

데이터 수집 방법의 전략적 통합은 데이터 분석 분야의 발전하는 풍경에서 중추적인 위치를 차지하고 있습니다. 이 글은 통합 데이터 저장소, 데이터 가상화, ETL 및 ELT라는 네 가지 주요 데이터 수집 패턴을 강조했습니다. 각각은 각기 독특한 장점과 제약이 있습니다. 이러한 패턴을 분석하면서, 통합 데이터 저장소의 간결함과 제한된 확장 가능성, 데이터 가상화의 거의 실시간 기능과 성능에 대한 잠정적인 비용, ETL의 중앙 집중 제어와 잠재적인 병목 현상 및 강제성, 그리고 ELT의 유연성과 확장 가능성이 균형을 이루면서 조정 문제에 직면하는 것을 볼 수 있습니다.

또한, 신생 스트림 처리 패러다임은 산업이 실시간 분석으로의 전환을 역설합니다. 이러한 방법들은 비교적 신생이지만, 정보 생성의 끊임없는 속도에 대응하여 좀 더 즉각적이고 동적인 데이터 처리 방식으로 나아가게 됩니다.

제 다음 글에서는 데이터 플랫폼에 적합한 데이터 수집 도구를 선택하는 데 더 심층적으로 다룰 것입니다. 이 과정에서 중요한 고려 사항은 해당 도구가 통합될 구조적 패턴입니다.

질문이 있으신가요? 피드백이 필요하신가요? LinkedIn에서 저와 연결하거나 직접 Jan@Sievax.be로 연락해 주세요!

<div class="content-ad"></div>

이 기사는 데이터 우수성을 향한 당신을 안내하는 컨설팅 기업 Sievax에서 자랑스럽게 제공합니다. 더 알고 싶으신가요? 저희 웹사이트를 방문해보세요! 데이터 전략 마스터 클래스를 제공하여 데이터 전략의 세계를 깊게 이해할 수 있습니다.